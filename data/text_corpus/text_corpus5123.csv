index,text
25615,there is a debate regarding the suitability of global integrated assessment models iams for long term planning exercises of the global energy system this study informs this debate from a power system perspective and proposes a methodological framework for soft linking of global iams with detailed global power system models with the proposed open source framework the scenario results from iams can be fed into a power system model to assess given scenarios with enhanced modelling resolution results from these simulations can be redirected to the iam through iterative bi directional soft linking a proof of concept application is presented by linking global iam messageix globiom with global power system model plexos world among others the results suggest that the assumption of unconstrained electricity flows inside large regional copperplates without internal network constraints causes an overestimation of the potential of variable renewables within messageix globiom we propose areas for informed improvements in messageix globiom and for iams in general keywords integrated assessment power systems modelling energy system model soft link climate change mitigation variable renewables 1 introduction 1 1 background integrated assessment models iams are widely used to assess scenarios for the long term evolution of the global energy system over multiple decades pietzcker et al 2017 iams are intended to broadly assess the long term impact of interlinked developments such as the impact of emission mitigation policies on climate change and the economy rogelj et al 2018 iams therefore not only represent different energy demand and supply sectors but also integrate the constraints and impacts associated with material and land use requirements and emissions as well as water consumption and fossil and renewable resource availability collins et al 2017a in addition to the broad sectoral representation iams are commonly applied for analysing policy questions that deal with large spatial coverage often global and long modelling horizons of up to one century hence to remain computationally tractable limits must be placed on the overall computational details of model simulations pfenninger et al 2014 and as such iams are restricted in temporal resolution with a significant geographical aggregation of model regions iwanaga et al 2020 a significant challenge for iams is the modelling of the variability in electricity demand and supply as a result of the integration of large amounts of distributed variable renewable energy sources vres in emission mitigation scenarios pietzcker et al 2017 traditional power systems with high levels of dispatchable technologies whose output can be controlled and requested on demand can be well represented in iams due to their often predictable operation however due to the limited amount or absence of sub annual time resolution a weakness of iams lies in realistically representing the operation of vres technologies and the corresponding integration challenges collins et al 2017a to account for the above global iams tend to integrate generic relationships to represent the integration of vres technologies in a stylized manner for example in the global iam messageix globiom the amount of solar and wind curtailment per region is accounted for using a marginal curve with increasing curtailment at higher vres penetration levels johnson et al 2017 curtailment in power systems refers to the unplanned reduction of generation output a number of model improvements have been made in recent years regarding power system representation in iams as well as general efforts regarding model evaluation and transparency in model inputs iamc 2019 and outputs huppmann et al 2018 following the advance project luderer et al 2016 the global iams aim cge dai et al 2017 image de boer and van vuuren 2017 messageix globiom johnson et al 2017 poles després et al 2017 remind ueckerdt et al 2017 and witch carrara and marangoni 2017 have made model specific improvements regarding vres integration ueckerdt et al 2017 developed residual load duration curves rldcs that represent the electricity demand of a specific region that must be met by non vres these curves have been adopted by a number of global iams for enhanced parameterization of vres integration challenges pietzcker et al 2017 developed a set of qualitative and quantitative criteria which allows for critical scrutiny of power system representation in iams based on these criteria additional required improvements for future versions of global iams have been identified this includes the overall modelling of electricity transmission infrastructure with a focus on the general pooling effect of shared generation resources through transmission integration as well as limitations on internal electricity flows in large model regions like latin america due to power transmission constraints furthermore mentioned as the most critical improvement in iams is to extend the data basis to enhance the overall spatial representation as well as refined implementation of region specific model input and assumptions however as argued in the literature there is a limit on internal iam model improvement both regarding computational functionality as regarding available time and resources for model development gambhir et al 2019 to fill this gap additional modelling tools can be utilized to complement iams regarding assessments of sectoral specific detailed dynamics for integration of new model assumptions in iams it is recommended to benchmark simulation results with operational power system dispatch models collins et al 2017a power system models can assess operational aspects of a given power system with high spatial temporal and technological detail due to the dedicated sectoral scope a range of state of the art energy and power system models such as artelys crystal super grid artelys 2020 brinkerink and shivakumar 2018 lusym van den bergh et al 2015 delarue and van den bergh 2016 lut energy system transition model bogdanov et al 2019 plexos energy exemplar 2020 brinkerink et al 2021 and pypsa brown et al 2018 2019 have the proven ability to simulate spatially rich continental or global scale models with hourly temporal resolution at minimum 1 2 model interlinkage by accepting that all sets of simulation models have clear limitations it is possible to make use of the strengths of one type of model to inform and improve the other by means of inter model linkages that facilitate data flows chang et al 2021 there are two main approaches that can be distinguished one being a soft link approach in which results from the iam are being fed into the power system model to gain insights into important aspects of power system design and operation and to assess the overall feasibility of a given scenario deane et al 2012 for example collins et al 2017b used power system model plexos to assess scenarios from the primes energy systems model as used to inform european union energy and climate policy to provide additional insights from a power system perspective results highlight among others an overestimation of vres generation within primes optionally by means of an iterative process between the two models through bi directional coupling the results from the power system model simulations can be used to adjust the model input and reparameterize the iam the other main approach that can be applied is a hard link method in which the optimization occurs in a parallel fashion by means of an algorithm that communicates dynamically between both models and leads to a singular set of results wene 1996 an example application of this can be found in després et al 2017 where the authors use a hard coupled implementation of global iam poles with the european unit commitment and dispatch model eucad in this study the hard coupling is only utilized for countries within europe other regions solely rely on the simulation equations in poles despite successful applications both linking methods have their disadvantages that can act as barriers for implementation soft linking often requires manual data manipulation and as time passes or the users involved in the specific soft link change it becomes challenging to repeat the exercise johnson et al 2017 wene 1996 hard linking involves significant time and resources to develop a smooth operation of co optimization of both models which is not always feasible wene 1996 nor are all modelling tools computationally able to function in this setting next to the above collins et al 2017a argue that due to the small number of very sizable regions in global iams each of which is assumed to be a copperplate without internal network constraints as well as long modelling horizons it can be challenging to perform power system model simulations for every iam region for all years in the modelling horizon a common approach therefore is to make use of a power system model based on a limited spatial scale to benchmark given scenarios from global iams the results from these spatially limited power system model simulations are often used to develop stylized relationships for power system representation in the iam uniformly for all regions sullivan et al 2013 this approach is viable given practical constraints such as availability of data to construct accurate power system models for all regions globally yet recent open data initiatives have made the development of detailed global power system models such as the lut energy system transition model bogdanov et al 2019 osemosys global 1 1 https github com osemosys osemosys global plexos world brinkerink et al 2021 and supergrid 2 2 https github com niclasmattsson supergrid possible open access model input data from plexos world brinkerink and deane 2020 and supergrid can easily be transferred to other modelling tools 1 3 contribution of this study this paper proposes a methodological framework for soft linking of continental or global iams with power system models with the proposed framework output from iams can be fed into a power system model to assess given scenarios with increased spatial technological and temporal resolution the power system model output can in turn be redirected to the iam to use assessment outcomes for internal improvements such as renewed region specific power system input and model assumptions the novelty of this framework and paper is multifold and developed in response to the identified limitations of iams and existing model linking methodologies first the framework is not used to assess scenarios with the often coarse spatial representation of iams as is but actually uses the long term capacity expansion module within the power system model to downscale the regional copperplates as used in the iam to a more spatially detailed level this allows for a more accurate assessment of local power system dynamics within the given iam scenario secondly the framework promotes using a standardized data format making it non discriminatory and useful for a wide range of iams and power system models while simultaneously allowing the exercise to be easily repeated when needed lastly being a first of its kind the framework is designed and applied in this paper to link a global iam with a global power system model considering the importance of global iams for key scientific reports such as chapter 2 of the special report on global warming of 1 5 c by the intergovernmental panel on climate change ipcc rogelj et al 2018 and chapter 3 of the forthcoming sixth assessment report ar6 an ongoing debate exists within the scientific community gambhir et al 2019 pindyck 2017 schwanitz 2013 whether global iams are suitable for long term planning of the global energy system due to among others the limitations as described in this section the proposed framework informs this debate from a power system perspective by providing the ability to scrutinize iam scenarios in dedicated power system models while simultaneously supporting internal improvements of power system representation within the iams as a proof of concept the global iam messageix globiom krey et al 2016 fricko et al 2017 is soft linked to plexos world brinkerink et al 2021 brinkerink and deane 2020 a 258 regional detailed global power system model developed in plexos energy exemplar 2020 in the past johnson et al 2017 had concerns regarding the reproducibility of soft linking messageix globiom to a detailed power system model however they stated that it would be useful to compare the results of message with those from a detailed power system model with high temporal resolution to validate how well message simulates the impacts of vres deployment the proposed standardized framework for soft linking iams and power system models makes the soft link easier to reproduce and hence the envisioned exercise can be applied as shown in this study by means of a snapshot analysis for the year 2050 a 1 5 c and high vres scenario from messageix globiom is assessed regarding its technical feasibility furthermore results from plexos world are used to improve parts of the power system representation of messageix globiom to show the frameworks potential for bi directional soft linking section 2 describes the proposed methodological framework and section 3 includes the results of the proof of concept application of the framework section 4 includes a discussion regarding the results of this paper and regarding the power system representation of messageix globiom including suggested improvements section 5 concludes with the main findings including a commentary on the theoretical discussion regarding the suitability of iams for planning exercises of the global energy system 2 methods the proposed methodological framework for soft linking iams with dedicated power system models allows for assessments of the technical feasibility of specific iam scenarios with higher spatial technological and temporal resolution this model soft linking enables enhanced insights regarding vres integration and provides the ability to assess the suitability of uniformly applied stylized relationships and model inputs for the power system representation in iams even though the framework is designed to be generally applicable to most global iams and power system models this paper includes a proof of concept soft linking the global iam messageix globiom with global power system model plexos world this allows for a general understanding of the framework steps and also provides an example of a practical application before diving into the details of the framework a general introduction of the modelling tools and how they represent power system dynamics is merited aspects specific to the integration of scenario data from messageix globiom in plexos world and vice versa as well as modelling assumptions relevant to a specific step in the framework will be covered in section 2 3 2 1 messageix globiom messageix globiom is a global iam with a detailed representation of technological socioeconomic and biophysical processes in energy and land use systems iiasa energy program 2020 the model has different spatial resolutions typically ranging between 11 and 15 world regions with the spatial resolution of the 11 region model as assessed in this study visualized in fig 1 messageix globiom is built using the open source messageix modelling framework huppmann et al 2019 although the messageix framework is capable of model simulations with sub annual timeslices the global model messageix globiom generally runs with yearly resolution the main characteristics of messageix globiom with respect to the representation of the power system is summarized and compared with other global iams in pietzcker et al 2017 to account for challenges associated with vres integration and power system reliability sullivan et al 2013 introduced four constraints in messageix globiom including i capacity reserves to meet peak electricity demand at all times with a desirable reserve margin ii operating reserves to provide short term system flexibility based on the amount of load and electricity from vres in the system iii expected curtailment values relative to different penetrations levels of vres and iv grid integration costs also relative to vres penetration levels johnson et al 2017 argues that the approach in sullivan et al 2013 has a range of limitations for example the fact that the parametrization of the introduced constraints were uniformly applied for all messageix globiom regions solely based on simulations from a single region power system model sullivan et al 2013 sioshansi 2010 johnson et al 2017 therefore applied a hybrid approach using region specific rldcs from ueckerdt et al 2017 to create regionally stylized parameterization for the impact of vres deployment on for example curtailment and non vres flexibility requirements minimum firm capacity requirements following johnson et al 2017 have been defined per region and decade as a multiplier of average annual electricity demand firm capacity represents capacity that is available at any given time the multiplier is based on the region specific relative ratio between average demand and peak demand combined with a 20 reserve margin where the margin is intended to ensure sufficient available capacity at all times capacity factors cfs 3 3 cfs refer to the ratio of actual electricity output compared to the theoretical maximum generation of a powerplant in case of renewables this is affected by the availability of wind solar irradiation or water inflow for vres technologies are based on regional resource potentials identified per range of cfs and assumed cfs for thermal powerplants are year and region specific with globally uniform technological parameters per technology there are a number of short term and long term flexibility options in messageix globiom including a generic storage object hydrogen electrolysis direct air capture electric vehicles and electricity export to neighbouring regions as part of the modelling effort in parallel to this study the representation of inter regional electricity trade in messageix globiom has been adapted to only allow for trade bilaterally by means of investments in transmission grid infrastructure intra regional trade of electricity is accounted for by means of costs as a function of final electricity demand relative vres penetration and the size of a specific region however regions are assumed to be copperplates without restrictions on internal transmission flows 2 2 plexos world plexos energy exemplar 2020 is a transparent energy and power system modelling tool among others used for electricity market modelling and planning freely available for academic use all data input is customizable and the linear equations can be queried and modified by the user plexos has an integrated user interface enabling data management and model simulation to occur within the tool yet also supports automation of data flows and model simulation by means of com or net the tool facilitates use of open source glpk scip and commercial cplex gurobi mosek xpress mp solvers depending on availability of licenses with xpress mp being used for the simulations in this study the model used for this paper is based on the plexos world model a detailed global power system model with 2015 as baseline year capable of simulating the generation of over 30 000 individual powerplants brinkerink et al 2021 brinkerink and deane 2020 the spatial representation of the model specified for this study is visualized in fig 1 with a total of 258 plexos world regions grouped per larger iam region following the spatial representation of messageix globiom powerplants in the plexos world model are modelled per turbine unit with standard unit sizes to be able to incorporate technological generator characteristics relevant for hourly unit commitment economic dispatch uced modelling uced modelling within power system models refers to the optimal utilization of available generator capacity to match system demand within a given simulation period while abiding to technical and operational constraints the model version used includes perfect foresight and market assumptions refer to section 1 of the supplementary material for detailed equations of the uced modelling in plexos world the plexos world model as applied for this study including all input data and timeseries can be found in brinkerink 2020 2 3 soft link framework fig 2 provides an overview of the different steps of the framework the framework is setup in a non discriminatory way allowing it to be applied to most iams and power system models however the scope of this framework from a spatial perspective is to downscale the regional copperplates in iams to a detailed spatial resolution in the power system model the benefits of this framework are therefore more applicable to assessments of global iam scenarios with a coarse spatial representation versus scenarios from already more spatially defined iams the openly available python script 4 4 https github com iiasa iam powersystemmodel linkage accompanying this paper that can be used to coordinate the soft link between iams and power system models is based on iamc data template format 5 5 https data ene iiasa ac at database the iamc data template format is the main data format used for many global iam intercomparison projects as well as for influential reports such as the forthcoming chapter 3 of ipcc ar6 note that the script is a helpful tool to automate the data processing workflow within the soft link yet other languages or manual data conversion e g in excel can also be applied although the methodological framework is developed to address the limitations of global iams the framework is also suitable for soft linking to other long term planning models like energy system optimization models the following sections describe the different steps of the framework in more detail 2 3 1 iam model simulation in general data inputs for iams are model and scenario specific depending on the iam used but most iams include basic parameters for socioeconomic developments e g gdp urbanisation and population projections technology characteristics and inputs for non energy impacts such as land or water use requirements following energy system developments within this framework generally any type of iam can be used with the bare minimum requirement that the iam is able to report technology specific regional powerplant capacities and regional electricity demand however to assess the technical feasibility of a given iam scenario in the power system model it is recommended to use all available iam scenario output data relevant to power systems if not available additional required data for power system models such as carbon and fuel prices technology parameters and capacities of balancing assets that can assist with matching electricity demand and supply such as storage power to gas and electric vehicles can either be standardized pricing or optimized balancing assets in the power system model using additional input data for the power system model not coming from the iam affects the harmonization of both models and the overall representativeness of scenario assessment yet due to the limited power system representation in iams it is often necessary the python script as designed for this paper uses pyam 6 6 https github com iamconsortium pyam an open source python package for analysis and visualization of iam scenario data huppmann et al 2021 the pyam package is used to extract messageix globiom scenario data for integration in plexos world from databases such as the iamc 1 5 c scenario explorer huppmann et al 2018 that among others includes scenario data underpinning chapter 2 of the special report on global warming of 1 5 c by the ipcc rogelj et al 2018 2 3 2 spatial capacity constraints one of the core aspects of the framework is the ability to assess iam scenarios with higher spatial resolution in the power system model especially relevant from a power system perspective this allows for any iam scenario to be assessed in the context of local characteristics with the ability to provide detailed insights that cannot be provided with a coarser representation for this to occur iam scenario data must be downscaled to a newly defined spatial resolution to be used as input for the power system model an exemplary visualization of indicative spatial resolutions of both sets of models is shown in fig 3 the first set of iam scenario output that requires spatial downscaling are regional powerplant and optionally balancing asset capacities within this framework regional capacity expansion and retirement constraints need to be developed that can be calculated by comparing the iam scenario output with existing baseline capacities these constraints determine per scenario region and technology how much capacity needs to be expanded or retired compared to the baseline to match the values provided by the specific iam scenario for a given year the constraints are used as boundary condition for the capacity allocation exercise within the power system model as described in section 2 3 5 they can be setup in multiple ways first a greenfield approach can be used in which existing powerplant capacity portfolios in individual sub country regions are not considered albeit easier to apply existing portfolios are in the near to medium term of significant relevance considering the often long lifetimes of powerplants it is therefore advisable to start with a baseline portfolio which can be based on any preferable source for the messageix globiom and plexos world proof of concept this paper and the accompanying python script uses the plexos world 2015 dataset brinkerink and deane 2020 for baseline capacities the dataset includes global powerplant storage and transmission capacities as of 2015 divided by 258 regions given the high temporal resolution of power system models modelling exercises are often restricted to time horizons of a single year thus providing a snapshot analysis of that given year taking 2050 as an example as intended simulation year scenario specific expansion and retirement constraints e x per region r and technology t for the period up to 2050 can be calculated with eq 1 by subtracting the reported scenario specific capacities from the iam c s from the baseline powerplant capacities c b eq1 e x r t c b c s if the difference is negative it means that expansion of capacity is required for that specific technology and region and vice versa retirement for accurate modelling of powerplant expansion and retirements constraints can be calculated per interval e g constraints for the period 2015 2020 2045 2050 or constraints can be determined for the full period to make the capacity expansion exercise computationally less intensive the latter approach is used for this proof of concept study as automated in the python script fig 4 shows an example of calculated expansion and retirement constraints for the period 2015 2050 for the lam region for messageix globiom 2 3 3 spatial demand downscaling iam scenario and region specific yearly electricity demand values need to be downscaled to the power system model regional level in principle any preferred energy downscaling method can be applied however within the python script we apply a forecasting methodology to project country level yearly electricity demand based on multivariate linear regression with gdp at purchasing power parity x g d p p p p per capita and urbanisation share x u r b as independent variables and electricity consumption per capita y p c as the dependent variable historical country level values h for the above variables have been retrieved by means of the world banks world development indicators and the world bank data python package 7 7 https github com mwouts world bank data country level values are grouped per iam region according to the spatial representation of the specific iam followed by the derivation of the regional regression equations eq 2 for the period 1980 2014 with a being the intercept b g d p p p p and b u r b the respective slopes and e the residual more recent data years for electricity consumption per capita are not available within the world bank world development indicators eq2 y p c h a b g d p p p p x g d p p p p h b u r b x u r b h e for country level projections of the independent variables as well as population projections we used the shared socioeconomic pathways ssp riahi et al 2017 and the accompanying quantifications kc and lutz 2017 dellink et al 2017 crespo cuaresma 2017 leimbach et al 2017 jiang and o neill 2017 all retrievable through the ssp public database 8 8 https tntcat iiasa ac at sspdb the ssps describe five different narratives based on alternative global socio economic development pathways the choice for a specific ssp to follow is in certain cases straightforward but when in doubt it is advisable to use ssp2 as the middle of the road pathway given the regional regressions and the country level ssp projections p for gdp at purchasing power parity x g d p p p p p and urbanisation share x u r b p per capita electricity demand at country level y p c p can be projected specific per ssp eq 3 an example regression is visualized in fig 5 for the lam region eq3 y p c p a b g d p p p p x g d p p p p p b u r b x u r b p by multiplying y p c p with country level population projections for the corresponding ssp x p o p p aggregate projected country level electricity demand y p can be calculated eq 4 the regression can be applied manually as shown in this section yet in the python script we use the linear regression module of the sklearn python package 9 9 https scikit learn org stable modules generated sklearn linear model linearregression html eq4 y p y p c p x p o p p per iam region the y p values can be used as a proxy to downscale the iam scenario regional demand values y r to country level final demand values y f eq 5 within the python script this occurs by making use of downscaling functionalities within pyam fig 6 showcases an example comparison of y p y f and 2015 country level historical demand y h based on the plexos world 2015 dataset brinkerink et al 2021 brinkerink and deane 2020 for contextual purposes compared to the historical demand the graph indicates different demand growth rates as a result of different ssp projections for the independent variables per country it can also be seen that in the given example the projected demand is lower compared to the downscaled scenario demand there are multiple aspects that can affect the relative growth of electricity demand compared to the historical linear regression for example it could be expected that due to efficiency improvements and behavioural change a partial decoupling of economic growth and increase in energy demand could occur in the more developed parts of the world yet on the global scale this trend is less obvious schandl et al 2016 more importantly electricity as end use is expected to gain a more predominant role in a variety of sectors e g transport leading to significant expected growth of the share of electricity in global final energy demand mccollum et al 2018 eq5 y f y p y p y r 2 3 4 temporal demand downscaling global iams and power system models have different modelling horizons and temporal resolution an example of this is visualized in fig 7 iams focus on the long term development of the energy system with planning horizons of up to a century and modelling periods of between 1 and 10 years with a specified baseline year as starting point timesteps in global iams are generally applied on an annual basis with investment decisions reported at the end of every modelling period within the framework the power system model is used to assess iam model output for a specific year with detailed temporal resolution for example on an hourly basis for the full year depending on the aim of the study holttinen et al 2013 results can be reported per timestep or on a yearly basis for direct comparison with the iam the spatially downscaled yearly electricity demand values from section 2 3 3 require additional downscaling in terms of temporal resolution once again multiple approaches are possible yet for the results in this study we use historical timeseries based on the plexos world 2015 dataset brinkerink et al 2021 brinkerink and deane 2020 which includes hourly demand data for all countries globally as well as for a wide range of sub country regions for the 2015 calendar year approximately 50 of profiles in the dataset are based on actual historical operational power system data with the remainder being country specific synthetic demand timeseries adapted from toktarova et al 2019 the country level final electricity demand y f per hourly interval i can be calculated with eq 6 by using the historical hourly values y h i as proxy for linear downscaling eq6 y f i y h i y h i y f for this study the country level final electricity demand profiles are further downscaled to sub country level y f s c i with eq 7 by using historical relative demand shares for sub country regions per interval y h s c i as proxy peak demand for all demand timeseries relative to the total demand is kept equal compared to 2015 values the limitation of this and other applied downscaling steps are discussed in section 4 3 the development of the demand timeseries based on the linear downscaling for all countries globally occurs within the python script eq7 y f s c i y h s c i y h i y f i next to the expansion and retirement constraints and the downscaled demand timeseries used input data for plexos world based on messageix globiom outputs for this exercise consist of regional specific carbon and fuel prices generator heat rates storage capacities and available technical parameters 2 3 5 power system model capacity allocation traditionally capacity expansion exercises in power system models are used to optimize the long term development of the power system in contrast to the traditional application the framework we propose in this article does not allow powerplant capacities to be expanded and retired in an unconstrained fashion instead we use the expansion and retirement decisions from the iam by means of the developed expansion and retirement constraints in section 2 3 2 as boundary condition for the power system model the capacity expansion module in the power system model is used to optimize the allocation of powerplant resources to the different power system model regions with the iam regional capacities as boundary an example application of this exercise for messageix globiom and plexos world can be seen in fig 8 together with the allocation of powerplant capacities the capacity expansion module of the used power system model can optimize the expansion and integration of balancing assets such as transmission infrastructure different storage technologies flexible utilization of electric vehicles and demand side management although these assets can be accounted for in iams their operational benefits and technical limitations are only visible in model simulations with detailed spatial and temporal resolution similar to powerplant capacities if the iam reports capacities of a specific technology it can be used as boundary condition for the allocation exercise rather than unconstrained optimization within this framework uced modelling can either be performed in an integrated singular run with the capacity allocation or as two separate modelling phases with different temporal modelling resolution depending on the defined spatial and technological resolution of the power system model performing long term planning exercises with temporal resolution equal to sub hourly uced modelling can be too computationally complex for the messageix globiom and plexos world proof of concept the decision has been made to separate both modelling phases with different applied temporal resolutions for the capacity allocation exercise a sampling approach is used to select representative timeslices of 3 weeks per year at 4 hourly temporal resolution total of 126 4 hourly timeslices linear optimization is applied for the capacity allocation with generator units rounded to the nearest integer refer to section 2 1 and 2 2 of the supplementary material for more details on the sampling approach used and for applied generator unit sizes and other generator characteristics in plexos world firm capacity requirements in plexos world per sub country region follow the same assumptions as messageix globiom applies per iam region these requirements are determined by taking the relative ratio between average demand and peak demand in addition to a standardized 20 reserve margin whereas in messageix globiom these ratios are approximated in plexos world they are determined by using historic 2015 demand values for all plexos world regions following brinkerink et al 2021 brinkerink and deane 2020 table 1 compares the firm capacity requirements as multiplier of average demand for 2050 following messageix globiom values johnson et al 2017 and the regionally aggregated demand weighted values in plexos world compared to messageix globiom firm capacity requirements per region in plexos world have a much wider range it s also worth noting that the values represent an iam regional average but that values per sub country region in plexos world can range significantly for example values in cpa range from 1 40 to 2 21 refer to section 2 3 of the supplementary material for all used firm capacity requirement values in plexos world modelling of electricity storage in plexos world is in line with messageix globiom where storage is modelled as a single generic technology with a cycle efficiency of 80 storage capacity of 24 h and a capital cost of 800 kilowatt johnson et al 2017 hydrogen electrolysis in plexos world is constrained at the iam regional level following capacities indicated by the messageix globiom scenario without possibilities for conversion back to electricity conversion efficiency is set at 80 in line with messageix globiom the modelling of electricity transmission in plexos world is based on physical transmission grids with customised associated investment costs operational costs and operational losses as a function of transmission distance and specific transmission technology for every unique potential high voltage transmission pathway in the model totalling 582 different to storage technologies the expansion of transmission lines in plexos world is not constrained by output from messageix globiom due to the vastly different spatial resolutions and the fact that intra regional trade is not modelled in messageix globiom section 2 1 of the supplementary material provides more details on transmission modelling in plexos world for the allocation of renewable powerplant capacities limits have been set on the resource potential per plexos world region with the same sources used as messageix globiom to retain uniformity country level resource potentials for solar technologies are based on a study by pietzcker et al 2014 and country level potentials for onshore and offshore wind based on a global assessment by eurek et al 2017 potential for new hydro based capacity is based on a study by gernaat et al 2017 that identifies 60 000 potential locations for new economically viable projects for geothermal and biomass no additional local restrictions are placed on resource potential due to the limited influence of geothermal based electricity generation in the to be assessed messageix globiom scenario and the assumed transportability of biomass between sub country regions within plexos world two sets of input cf timeseries for hydro solar and wind are used in the plexos world model for this study a conservative set of timeseries is used based on the plexos world 2015 dataset which includes profiles based on benchmarked values at year and country level for 2015 brinkerink et al 2021 brinkerink and deane 2020 a second set of timeseries has harmonized values equal to messageix globiom by linearly scaling the original plexos world 2015 timeseries by comparing the regional average to the messageix globiom output due to the large regional copperplates renewable resource potentials for a specific region within messageix globiom consist of the combined potential of a wide range of countries with often very different characteristics in plexos world if domestic resource potentials are to be used for export purposes the electricity must be physically transferred by means of transmission infrastructure including associated costs and losses whereas in messageix globiom no intra regional barriers for trade exist this can lead to different investment dynamics and hence as a sensitivity analysis it is merited to assess the specific messageix globiom scenario in the context of conservative cfs 2 3 6 power system model unit commitment economic dispatch if the decision has been made to separate the capacity allocation exercise from the uced modelling in two distinct modelling phases the main output from the capacity allocation exercise being the generator and balancing asset portfolios of the power system model regions should be used as input for the uced modelling temporally detailed model simulations of the downscaled generator portfolio and balancing assets can provide detailed insights in the technical feasibility of a given iam scenario it furthermore allows for benchmarking of simulation results with generic model assumptions within the iam examples can be assumed generator cfs as well as stylized relationships regarding curtailment and occurrence of possible unserved energy 10 10 different to messageix globiom where occurrence of unserved energy is not possible plexos world allows for unserved energy at a cost of 10 000 megawatt hour the model can determine that often it is more efficient for unserved energy to occur than to invest in additional flexibility assets such as storage or in further transmission expansion to mitigate this unserved energy unserved energy represents the share of final electricity demand that cannot be met with the available generator resources the uced modelling in plexos world based on the output of the allocation exercise is done with hourly modelling resolution based on mixed integer programming mip data flows between both modelling phases in plexos world occurs in an automated fashion 2 3 7 feedback loop the results from the model soft link exercise within this framework consists of quantified simulation output that can assist with optimizing the power system representation in iams while considering the computational requirements of model simulations relevant outputs of the power system model to be used in iams for improved power system representation are for example technology cfs curtailment values and costs of generation before the power system model output data can be used as input for an iam the data needs to be post and pre processed outputs from the power system model need to be converted into a format that is readable for the specific iam in the case of plexos world results can be written to individual flat files per variable and easily be converted to the iamc data template format that messageix globiom and a number of other global iams use as a result of the openentrance 11 11 https github com openentrance nomenclature project the iamc data template format has the extended ability to support sub annual data which is critical for temporally detailed power system modelling results next to format conversion the data also need to be aggregated from the power system model regional level to the iam regions for some output variables this can easily be done by simple aggregation whereas others require more thought for example when it comes to technology cfs a normal average can be taken based on reported values in the different power system model regions or a capacity weighted average can be used as well the potential for a scripted feedback loop within the framework allows for an iterative process between the iam and power system model until the power system representation in the iam is deemed satisfactory in terms of power system adequacy the ability of a power system to meet demand under normal operational conditions or other criteria 2 4 scenarios the engage ssp2 npi2020 500 scenario as simulated by messageix globiom is consistent with end of century warming of 1 5 c without temperature overshoot riahi et al 2021 in 2050 as assessed snapshot year for this study it exhibits high penetration of vres with approximately 64 of electricity in the grid coming from wind 33 and solar pv 31 globally furthermore the share of electricity in final energy demand is slightly over 50 in 2050 cf 20 in 2020 iea 2021 and the share of electric mobility in the transportation sector is 33 in 2050 cf 1 in 2020 iea 2021 both at the global level by assessing this scenario the soft link framework can be used to evaluate messageix globiom in a setting where iams may struggle in terms of adequately incorporating the detailed implications of variability in electricity supply and demand we perform a baseline simulation and a set of sensitivity simulations in plexos world summarized in table 2 as a proof of concept for the potential of the framework to streamline informed model improvements in global iams the results of the model simulations in plexos world related to inter regional electricity trade between the larger iam regions are fed back to messageix globiom and used as model input for a second iteration the simulations in messageix globiom as performed for this study can be found in table 3 it is important to recall that in line with the framework key model input in plexos world such as powerplant capacities and electricity demand are at an aggregate level equal to the messageix globiom model output at all times the baseline simulation represents the reference for the soft link framework in that it attempts to replicate the original messageix globiom scenario with harmonized inputs between both models such as input cf timeseries for hydro solar and wind technologies the conservative cfs model simulation on the other hand uses the original plexos world 2015 dataset timeseries as a sensitivity analysis whereas in the baseline and conservative cfs simulations the expansion of storage capacity is bound at a regional level following the messageix globiom scenario output the no storage constraints simulation allows for full optimization of storage capacity this allows for an assessment of how accurately storage expansion is integrated in messageix globiom and moreover how it impacts other variables such as generator cfs generator reserve requirements and transmission utilization because the no storage constraints simulation allows for unconstrained competition between transmission and storage in the optimization it provides the best indication for the potential of inter regional electricity trade the results from this simulation regarding inter regional trade are therefore used as model input for a second iteration in messageix globiom to optimize its representation of inter regional electricity trade as a proof of concept for the framework in terms of bi directional model soft linking section 2 4 of the supplementary material provides more information regarding the renewed representation of inter regional trade in messageix globiom including a full overview of the adjusted input parameters based on plexos world 3 results this section includes the modelling results for the proof of concept application of the proposed soft link framework where plexos world is used to assess a high vres scenario from messageix globiom with a 64 share of vres in the electricity grid at the global level the results from plexos world will be compared to the model outputs from messageix globiom based on which suggestions are being made for additional internal model improvements regarding power system representation 3 1 generation and storage fig 9 shows the differences in generation mix per plexos world model simulation in comparison to the messageix globiom output the main observation is that for both the baseline as the other simulations in plexos world the total generation output is lower compared to the messageix globiom scenario output for example following the given scenario in messageix globiom the 2050 electricity generation in the cpa region equals approximately 55 5 ej whereas generation in the plexos world simulations ranges between 43 and 45 ej the lower generation compared to messageix globiom is in most cases occurring for both renewable technologies as well as for fossil fuel based powerplants fig 10 shows the technology and region specific cfs based on model output for a range of key generator technologies the baseline and no storage constraints simulations have maximum cf input assumptions for hydro solar and wind technologies in line with the messageix globiom scenario yet as the graphs in fig 10 indicate the equal availability of renewable resources does not always lead to comparable cfs as output for example the regionally aggregated cf for solar pv based on the baseline simulation for the cpa region is 16 2 compared to 17 7 in messageix globiom cfs for hydro solar and wind technologies in the conservative cfs model simulation are based on 2015 benchmarked values and lead to significantly lower vres penetration compared to the messageix globiom scenario output fossil fuel based powerplants partly compensate for the lower availability of renewable resources in this plexos world simulation however besides regional outliers all plexos world simulations indicate that cfs for these technologies are also below par compared to the messageix globiom scenario output the exceptions are gas and coal powerplants without carbon capture and storage ccs from which higher utilization is required to mitigate part of the existing supply shortage from renewables the unconstrained expansion of electricity storage in the no storage constraints leads to lower cfs for solar pv yet higher cfs for other technologies compared to the baseline this is a direct result of lower investments in storage capacity in plexos world for the no storage constraints simulation compared to messageix globiom as highlighted in fig 11 expansion of storage in messageix globiom occurs based on the contribution of storage to system flexibility needs reducing curtailment of vres and provision of firm capacity using stylized relationships leading to e g large scale investments of over 1000 gw in cpa and nam however the results show that with similar capacities in plexos world storage is utilized with lower cfs compared to messageix globiom when plexos world is allowed to freely optimize the expansion of storage not bound to capacities following the messageix globiom output as in the no storage constraints simulation total build capacities are approximately one third of messageix globiom albeit with higher cfs compared to the other simulations in plexos world the conversion of electricity into hydrogen by means of electrolysis is the only long term storage solution integrated in messageix globiom for the assessed scenario fig 12 however indicates that similar to short term storage hydrogen electrolysis is underutilized in all plexos world simulations compared to messageix globiom 3 2 curtailment and unserved energy electricity coming from vres technologies that cannot be instantaneously used stored transmitted to a neighbouring area or converted to other energy carriers gets curtailed curtailment is an important factor in power systems with large penetration of vres and based on the plexos world simulations an element that might be underestimated in messageix globiom for the examined scenario this is visualized in fig 13 which as an example highlights the region specific curtailment values for solar pv messageix globiom accounts for curtailment through stylized relationships as a function of relative vres penetration although this kind of stylized relationship is inherently not incorrect the baseline and conservative cfs plexos world model simulations indicate that curtailment grows in parallel with relative vres penetration the observed curtailment values in plexos world are in almost all cases a magnitude higher compared to messageix globiom the lower investments in storage capacities in the no storage constraints simulation lead to overall highest solar pv curtailment values due to reduced possibilities to mitigate peak solar pv supply on the global scale curtailment values relative to the theoretical generation potential range between 4 and 11 for solar pv depending on the plexos world simulation and comparatively between 4 and 8 for wind based technologies the combined effect of higher vres curtailment compared to messageix globiom in combination with the underutilization of dispatchable technologies leads to the occurrence of unserved energy in the global power system this is visualized in fig 14 which showcases unserved energy values per region and model simulation 3 3 electricity trade in an optimally functioning integrated global power system a spatiotemporal mismatch between demand and supply of electricity can be mitigated by sharing resources between regions by means of transmission integration despite significant intra regional transmission flows within plexos world both land based as well as through long distance subsea interconnectors the built transmission infrastructure cannot sufficiently compensate for the large variability in supply fig 15 shows mapped electricity flows in 2050 for the no storage constraints simulation for contextual purposes 1 ej 278 twh roughly equals the current day electricity demand of australia or mexico fig 16 highlights the occurrence of inter regional trade of electricity between the iam regions for both performed iterations of messageix globiom in comparison to the simulations in plexos world the second iteration of messageix globiom has adjusted input parameters based on the results of the no storage constraints simulation in plexos world and general plexos world input parameters refer to table s2 5 in section 2 4 of the supplementary material for a full overview within the plexos world results the conservative cfs simulation has the overall largest trade for this simulation the inter regional transmission flows are a means to compensate for the lower cfs for renewables compared to messageix globiom the baseline simulation has the lowest trade values correlated to the earlier identified large capacities of electricity storage following messageix globiom values in the no storage constraints simulation where the expansion of storage and transmission occurs in competition the inter regional trade values are significantly higher compared to the baseline simulation at a net total of 6 3 ej 1750 twh versus 2 5 ej 694 twh globally to put these values in context total 2015 inter regional trade values between the iam regions based on simulations of plexos world brinkerink et al 2021 are approximately 0 1 ej 28 twh in line with messageix globiom the fsu region has been identified as resource rich exporting region within plexos world albeit with cpa as main importing region compared to sas in messageix globiom compared to plexos world the inter regional trade values in both iterations of messageix globiom are lower the adjusted input parameters for the second iteration of messageix globiom based on plexos world stimulate higher inter regional trade between fsu and sas as well as a modest uptake of inter regional trade in other regions however considering the relatively small differences between both iterations it is clear that the alignment of input parameters regarding inter regional trade in messageix globiom based on plexos world has minor impact for the examined scenario 4 discussion 4 1 discussion of proof of concept results the proof of concept application of the proposed methodological soft link framework in this paper has revealed that the differences in modelling resolution and assumptions between messageix globiom and plexos world can lead to different results note that the discussion of the results in this paper reflect on a single scenario with high shares of vres and is not intended to shed light on the functionality of both models in all possible contexts the results show that generation values and generator cfs in plexos world are significantly lower than messageix globiom this is both the case for renewables as well as for most thermal generators and applicable for all performed plexos world simulations of the examined messageix globiom scenario cfs for renewables are lowest in the conservative cfs simulation which highlights the sensitivity of modelling assumptions in iams regarding uncertain developments such as the availability of highly efficient untapped renewable resources different to messageix globiom plexos world operates based on perfect market assumptions meaning that there are no emission constraints included that might affect how much fossil fuel based powerplants are allowed to operate to stay within the bounds of a set emission target this contributes to the fact that as an outlier compared to other technologies coal and gas powerplants without ccs in plexos world have higher generation values compared to messageix globiom a key factor for the overall lower generation values in plexos world is the different sectoral representation of both models messageix globiom is a sector coupled model that is not only required to meet electricity demand as end use but also has the ability to convert electricity in other energy carriers for use in for example the transport and heating sectors plexos world focuses solely on the power sector where available generators are utilized to meet final electricity demand in addition to hydrogen electrolysis as a means to limit electricity curtailment however given that there is no modelled demand for hydrogen or other energy carriers in plexos world the model can determine that it is often more efficient to curtail electricity than to invest in additional flexible technologies such as electricity storage to make optimal use of available generation for indirect use in other sectors that said and despite the overall lower demand for electricity compared to messageix globiom the plexos world simulations indicate that demand cannot always be met leading to significant unserved energy in the global power system of between 2 5 and 5 these findings are in line with other literature which highlights that the occurrence of unserved energy in power systems mostly reliant on vres can be expected to become a more important factor tong et al 2021 next to unserved energy higher vres curtailment values can be observed compared to reported values from messageix globiom the more detailed temporal resolution in plexos world highlights how curtailment can occur in some hours versus unserved energy in others next to that the more detailed spatial resolution in plexos world also indicates that both can occur at the same time following oversupply in some regions versus undersupply in others this observation suggests that there is a mismatch in spatiotemporal demand and supply of electricity for the simulated scenario when there is sufficient available transmission capacity within a region or when assuming that regions are copperplates with no intra regional network constraints such as modelled in messageix globiom any spatial mismatch between demand and supply can theoretically be mitigated however the results indicate that despite significant transmission capacities globally network constraints are a key limiting factor that need to be overcome to enable power systems with high penetration levels of vres in the performed plexos world simulations based on the messageix globiom scenario the developed transmission portfolio together with underutilized balancing assets such as electricity storage and hydrogen electrolysis are not able to handle the spatiotemporal variability in demand and supply sufficiently to prevent largescale occurrence of curtailment and unserved energy future work is essential to provide more insights in model uncertainties as a result of the regional copperplates in global iams overall it can be observed that from a regionally and temporally coarse perspective following messageix globiom the projected global power system is deemed technically feasible however the temporally and spatially detailed model simulations in plexos world highlight that the power system adequacy of the assessed scenario in terms of unserved energy without taking into account potential contributions of electric vehicles to load management may be insufficient as part of the modelling effort in parallel to this study the power system representation in messageix globiom regarding inter regional trade of electricity has been adapted by integrating bilateral trade through investments in region specific transmission grid infrastructure model data and simulation results from plexos world have been used to inform the input parameters in messageix globiom for this new setup however modelling results from the updated version of messageix globiom still indicate an underestimation of inter regional trade potential it can therefore be concluded that the differences in spatial and temporal modelling resolution between messageix globiom and plexos world are a direct cause for the underutilization of inter regional trade in messageix globiom due to the absence of sub annual timeslices in the global implementation of messageix globiom there is a singular decision in the optimization to determine whether inter regional import or export of electricity is cost optimal within the modelling period this means that transmission is solely utilized for bulk unilateral flows of electricity within the modelling period yet on an aggregate level it does not provide additional flexibility for the power systems involved in the inter regional trade the uced modelling in plexos world for this study operates based on hourly intervals and hence is not only able to assess unilateral flows but also the occurrence of bilateral flows for the purpose of balancing electricity demand and supply between regions and for contributions to the mitigation of vres variability furthermore whereas a singular inter regional transmission pathway exists between regions in messageix globiom plexos world has transmission pathways between all bordering areas meaning that multiple inter regional transmission lines between two iam regions can be operational at any given time the low spatial and temporal resolution in messageix globiom inherently means that there is a model bias against the uptake of inter regional electricity trade 4 2 feedback on power system representation in messageix globiom there are a number of underlying assumptions in the model structure of messageix globiom as well as general data inputs that affect its accuracy of results the remainder of this section is dedicated to discussing these and to provide suggestions for improvements the focus in this paper has been on the global implementation of the messageix globiom model hence suggestions for improvement of the power system representation in messageix globiom are being made in this context the use of sub annual timeslices would be beneficial for the representation of vres however to date its integration has been hampered due to its impact on computational complexity and resulting model runtime continuous developments regarding faster computers cloud based solutions improved solvers and solving techniques merits a regular reassessment of the feasibility of implementing sub annual timeslices in the global implementation of messageix globiom besides refining the temporal or spatial resolution in messageix globiom there are a number of low hanging fruits that could be implemented for improved power system representation without affecting computational complexity too severely the previous sections have highlighted that the absence of network constraints within the regional copperplates within messageix globiom is one of the main reasons for possible overestimation of vres integration potential in most global iams internal grid expansion is accounted for in terms of costs as a function of total build generator capacity or as a function of final electricity demand the latter is the case for messageix globiom in addition to a cost premium for grid integration of vres depending on the relative penetration and the size of the region it is fair to assume that with longer transmission distances the costs as well as losses for internal electricity transmission increases the results from the modelling in plexos world can benchmark the cost premiums in messageix globiom for internal transmission integration to make sure they are not underestimated which in turn would lead to overestimation of vres integration potential where needed values can be informed and updated on a regional basis all technologies in messageix globiom have pre defined values relative to their capacity for assumed positive or negative contributions to power system flexibility to date it is assumed that inter regional trade of electricity has positive contributions to system flexibility for the exporting region whereas inter regional trade for the importing region has an equal negative contribution i e it needs equally sized additional domestic flexibility to compensate for the import of electricity from another region on a macro level this means that inter regional trade does not contribute to flexibility in the power system within messageix globiom which may restrict investments in new transmission capacity studies assessing the benefit of large scale transmission integration in power systems with high vres penetration highlight the potential for cross border transmission as a means to provide flexibility among others due to often asynchronous occurences of peaks and lows in electricity demand and vres generation in different regions brinkerink et al 2019 transmission integration in this context can decrease the need for domestic reserves providing flexibility as highlighted among others from a pan european rodríguez et al 2014 becker et al 2014 and global grossmann et al 2013 perspective with this in mind it is recommended to reassess whether an equal negative contribution to flexibility for importing regions in messageix globiom is overly conservative the electricity trade values in plexos world can act as a baseline to calibrate the flexibility contributions for inter regional trade in messageix globiom as of now messageix globiom includes a single generic electricity storage technology with 24 h storage potential the underutilization of storage in the plexos world simulations can partly be explained by the fact that at a regional or continental level the sharing of resources through transmission integration can be favourable compared to mostly domestic generation and storage as also observed in recent literature for the african wu et al 2017 southeast asian siala et al 2021 and european tröndle et al 2020 context however the absence of other short and longer term storage technologies in messageix globiom prevents the proper allocation of storage technologies depending on the requirements in the specific power system expansion of long term storage technologies such as pumped hydro storage would be beneficial for seasonal storage purposes for wind based generation furthermore integration of short term storage technologies such as batteries with a relatively higher power versus storage ratio would help with mitigating peaks in supply from especially solar pv next to storage the integration of demand side management technologies could assist with shifting of peaks in electricity demand to decrease the likelihood of occurrence of unserved energy or to provide a better match with peaks in vres generation the plexos world simulations have shown that the large scale integration of vres based on the messageix globiom scenario is accompanied by the occurrence of both significant electricity curtailment as well as unserved energy in electricity demand from a power system adequacy perspective given the limitations in modelling resolution and model assumptions within global iams such as the unconstrained intra regional power pooling a range of stylized parameters and input assumptions such as region specific curtailment parameters and technology cfs could benefit from being updated based on the spatially and temporally detailed modelling in plexos world by means of the developed soft link framework in this study results from plexos world can be directly fed back into messageix globiom as has been shown by the proof of concept for inter regional electricity trade 4 3 study limitations and modelling uncertainties the proposed soft link framework is designed to assess and benchmark existing iam scenarios by means of a snapshot analysis in a power system model with enhanced spatial and temporal resolution the main limitation of this method is that by attempting to replicate the iam scenario as closely as possible in the power system model the risk arises of over constraining the optimization that affects its optimality a complementary approach could be to apply the optimization in context of the iam scenario by making use of projected variables such as electricity demand and commodity prices while allowing the power system model to optimize the long term development of generator portfolios and balancing assets without further constraints this would allow for an actual comparison of the optimal long term planning in the integrated context in the iam versus an optimized long term planning in the power system model from a solely operational power system perspective however modelling in plexos world indicates that performing long term planning exercises in detailed global power system models can be computationally challenging and requires further examination to find appropriate trade offs between modelling resolution and computational time an average model run of plexos world based on the 2050 snapshot analysis in context of this study takes approximately 12 h other study limitations are specific to the proof of concept linking messageix globiom and plexos world for example related to the practical implementation of the different framework steps the applied spatial demand downscaling uses projected demand values as proxy retrieved by means of multivariate linear regression besides the fact that the used values for the regression are for the period 1980 2014 the main limitation of this approach is that historic values are not fully representative for future developments when it comes to electricity demand forecasting due to among others expected increasing electrification in final energy demand that said the projected values are solely used as proxy for the downscaling actual final demand values at an aggregate regional level are equal to the scenario output from messageix globiom more advanced energy downscaling methods designed for iam scenario data have become recently available that can be used for future studies sferra et al 2021 another simplification is the fact that for the temporal demand downscaling demand timeseries in the plexos world model for 2050 are linearly scaled compared to historical timeseries whereas it can be expected that the shape of diurnal electricity demand in the future might change among others due to uptake of electric vehicles future work can address this by using reported sectoral electricity demand from iams as foundation for adjusting demand timeseries like all modelling tools plexos world has its limitations and uncertainties that affect the accuracy of results for the proof of concept as of now the model does not include demand for other energy carriers that indirectly affect how much electricity needs to be supplied for example green hydrogen demand for transport and heating these differences in sectoral coverage contribute to observed differences in model outputs for factors such as technology generation values and cfs for plexos world compared to a sector coupled model like messageix globiom future applications of the model will need to take these intersectoral dynamics into account to be able to compare model outputs with iams in a level playing field furthermore in the used version of plexos world electric vehicles and demand side management are not included which reduces the ability of the power system to compensate for variability in supply demand side management is not actively incorporated in messageix globiom in relation to system flexibility yet electric vehicles can contribute to curtailment reduction and overall system flexibility another important factor is that the sampling approach used for deriving representative timeslices as applied for the capacity allocation exercise in plexos world has to be assessed in more detail increasing the number of timeslices for the full global model is computationally challenging hence it would have added value to benchmark the results with single region model simulations with enhanced time slicing next to the above additional model runs to assess sensitivities and uncertainties on a range of parameters and assumptions such as costs for transmission infrastructure perfect market and foresight assumptions power system adequacy and reliability constraints climatic impact on renewable resource potential switching to different weather years for vres cf timeseries collins et al 2018 and overall to analyse a wider range of scenarios and snapshot years could increase the robustness of the results 5 conclusion this study proposes a novel methodological framework for soft linking of continental or global iams with detailed global power system models by means of a proof of concept application of the soft link framework linking global iam messageix globiom with global power system model plexos world the results of this paper highlight the usefulness of the framework by feeding in to known limitations of global iams as a result of limited modelling resolution and power system representation the spatially and temporally detailed modelling in plexos world of scenarios coming from messageix globiom has identified a number of key limitations in messageix globioms power system representation that affect its accuracy of results overall the results reflect that messageix globiom and global iams in general are not constructed with the aim to perform spatially and temporally detailed assessments of power system dynamics that said it is the authors view that this not necessarily means that global iams are unsuitable for providing boundaries in possible mitigation pathways for the development of the global energy system from a multi disciplinary perspective from a solely power system point of view tools like plexos world would be better suited to optimize the long term planning of the global power system yet as it stands computational requirements for global model simulations without compromising on modelling resolution do not permit simulations for long term horizons furthermore the lack of interaction with other sectors in the energy system and with ecological and economical systems gives power system models a narrow scope considering limitations of both sets of models we conclude that iams can be applied for providing insights in possible long term development pathways for the global energy system and to inform global climate and energy policy assuming benchmarking with dedicated sectoral models occurs regularly by making use of the soft link framework proposed in this study power system models like plexos world can be used in a complimentary fashion to pinpoint areas for model informed improvements in global iams the framework can furthermore be used as a template for soft linking of global iams to other dedicated sectoral models declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the support provided by energy exemplar and science foundation ireland sfi through the marei centre for energy climate and marine grant no 12 rc 2302 p2 j g is supported by a research grant from sfi and the national natural science foundation of china nsfc under the sfi nsfc partnership programme grant no 17 nsfc 5181 part of the research was developed in the young scientists summer program yssp at the international institute for applied systems analysis iiasa laxenburg austria we would like to express our gratitude towards members of the energy climate and environment ece program of iiasa for providing feedback on the methodology and results as included in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105336 
25615,there is a debate regarding the suitability of global integrated assessment models iams for long term planning exercises of the global energy system this study informs this debate from a power system perspective and proposes a methodological framework for soft linking of global iams with detailed global power system models with the proposed open source framework the scenario results from iams can be fed into a power system model to assess given scenarios with enhanced modelling resolution results from these simulations can be redirected to the iam through iterative bi directional soft linking a proof of concept application is presented by linking global iam messageix globiom with global power system model plexos world among others the results suggest that the assumption of unconstrained electricity flows inside large regional copperplates without internal network constraints causes an overestimation of the potential of variable renewables within messageix globiom we propose areas for informed improvements in messageix globiom and for iams in general keywords integrated assessment power systems modelling energy system model soft link climate change mitigation variable renewables 1 introduction 1 1 background integrated assessment models iams are widely used to assess scenarios for the long term evolution of the global energy system over multiple decades pietzcker et al 2017 iams are intended to broadly assess the long term impact of interlinked developments such as the impact of emission mitigation policies on climate change and the economy rogelj et al 2018 iams therefore not only represent different energy demand and supply sectors but also integrate the constraints and impacts associated with material and land use requirements and emissions as well as water consumption and fossil and renewable resource availability collins et al 2017a in addition to the broad sectoral representation iams are commonly applied for analysing policy questions that deal with large spatial coverage often global and long modelling horizons of up to one century hence to remain computationally tractable limits must be placed on the overall computational details of model simulations pfenninger et al 2014 and as such iams are restricted in temporal resolution with a significant geographical aggregation of model regions iwanaga et al 2020 a significant challenge for iams is the modelling of the variability in electricity demand and supply as a result of the integration of large amounts of distributed variable renewable energy sources vres in emission mitigation scenarios pietzcker et al 2017 traditional power systems with high levels of dispatchable technologies whose output can be controlled and requested on demand can be well represented in iams due to their often predictable operation however due to the limited amount or absence of sub annual time resolution a weakness of iams lies in realistically representing the operation of vres technologies and the corresponding integration challenges collins et al 2017a to account for the above global iams tend to integrate generic relationships to represent the integration of vres technologies in a stylized manner for example in the global iam messageix globiom the amount of solar and wind curtailment per region is accounted for using a marginal curve with increasing curtailment at higher vres penetration levels johnson et al 2017 curtailment in power systems refers to the unplanned reduction of generation output a number of model improvements have been made in recent years regarding power system representation in iams as well as general efforts regarding model evaluation and transparency in model inputs iamc 2019 and outputs huppmann et al 2018 following the advance project luderer et al 2016 the global iams aim cge dai et al 2017 image de boer and van vuuren 2017 messageix globiom johnson et al 2017 poles després et al 2017 remind ueckerdt et al 2017 and witch carrara and marangoni 2017 have made model specific improvements regarding vres integration ueckerdt et al 2017 developed residual load duration curves rldcs that represent the electricity demand of a specific region that must be met by non vres these curves have been adopted by a number of global iams for enhanced parameterization of vres integration challenges pietzcker et al 2017 developed a set of qualitative and quantitative criteria which allows for critical scrutiny of power system representation in iams based on these criteria additional required improvements for future versions of global iams have been identified this includes the overall modelling of electricity transmission infrastructure with a focus on the general pooling effect of shared generation resources through transmission integration as well as limitations on internal electricity flows in large model regions like latin america due to power transmission constraints furthermore mentioned as the most critical improvement in iams is to extend the data basis to enhance the overall spatial representation as well as refined implementation of region specific model input and assumptions however as argued in the literature there is a limit on internal iam model improvement both regarding computational functionality as regarding available time and resources for model development gambhir et al 2019 to fill this gap additional modelling tools can be utilized to complement iams regarding assessments of sectoral specific detailed dynamics for integration of new model assumptions in iams it is recommended to benchmark simulation results with operational power system dispatch models collins et al 2017a power system models can assess operational aspects of a given power system with high spatial temporal and technological detail due to the dedicated sectoral scope a range of state of the art energy and power system models such as artelys crystal super grid artelys 2020 brinkerink and shivakumar 2018 lusym van den bergh et al 2015 delarue and van den bergh 2016 lut energy system transition model bogdanov et al 2019 plexos energy exemplar 2020 brinkerink et al 2021 and pypsa brown et al 2018 2019 have the proven ability to simulate spatially rich continental or global scale models with hourly temporal resolution at minimum 1 2 model interlinkage by accepting that all sets of simulation models have clear limitations it is possible to make use of the strengths of one type of model to inform and improve the other by means of inter model linkages that facilitate data flows chang et al 2021 there are two main approaches that can be distinguished one being a soft link approach in which results from the iam are being fed into the power system model to gain insights into important aspects of power system design and operation and to assess the overall feasibility of a given scenario deane et al 2012 for example collins et al 2017b used power system model plexos to assess scenarios from the primes energy systems model as used to inform european union energy and climate policy to provide additional insights from a power system perspective results highlight among others an overestimation of vres generation within primes optionally by means of an iterative process between the two models through bi directional coupling the results from the power system model simulations can be used to adjust the model input and reparameterize the iam the other main approach that can be applied is a hard link method in which the optimization occurs in a parallel fashion by means of an algorithm that communicates dynamically between both models and leads to a singular set of results wene 1996 an example application of this can be found in després et al 2017 where the authors use a hard coupled implementation of global iam poles with the european unit commitment and dispatch model eucad in this study the hard coupling is only utilized for countries within europe other regions solely rely on the simulation equations in poles despite successful applications both linking methods have their disadvantages that can act as barriers for implementation soft linking often requires manual data manipulation and as time passes or the users involved in the specific soft link change it becomes challenging to repeat the exercise johnson et al 2017 wene 1996 hard linking involves significant time and resources to develop a smooth operation of co optimization of both models which is not always feasible wene 1996 nor are all modelling tools computationally able to function in this setting next to the above collins et al 2017a argue that due to the small number of very sizable regions in global iams each of which is assumed to be a copperplate without internal network constraints as well as long modelling horizons it can be challenging to perform power system model simulations for every iam region for all years in the modelling horizon a common approach therefore is to make use of a power system model based on a limited spatial scale to benchmark given scenarios from global iams the results from these spatially limited power system model simulations are often used to develop stylized relationships for power system representation in the iam uniformly for all regions sullivan et al 2013 this approach is viable given practical constraints such as availability of data to construct accurate power system models for all regions globally yet recent open data initiatives have made the development of detailed global power system models such as the lut energy system transition model bogdanov et al 2019 osemosys global 1 1 https github com osemosys osemosys global plexos world brinkerink et al 2021 and supergrid 2 2 https github com niclasmattsson supergrid possible open access model input data from plexos world brinkerink and deane 2020 and supergrid can easily be transferred to other modelling tools 1 3 contribution of this study this paper proposes a methodological framework for soft linking of continental or global iams with power system models with the proposed framework output from iams can be fed into a power system model to assess given scenarios with increased spatial technological and temporal resolution the power system model output can in turn be redirected to the iam to use assessment outcomes for internal improvements such as renewed region specific power system input and model assumptions the novelty of this framework and paper is multifold and developed in response to the identified limitations of iams and existing model linking methodologies first the framework is not used to assess scenarios with the often coarse spatial representation of iams as is but actually uses the long term capacity expansion module within the power system model to downscale the regional copperplates as used in the iam to a more spatially detailed level this allows for a more accurate assessment of local power system dynamics within the given iam scenario secondly the framework promotes using a standardized data format making it non discriminatory and useful for a wide range of iams and power system models while simultaneously allowing the exercise to be easily repeated when needed lastly being a first of its kind the framework is designed and applied in this paper to link a global iam with a global power system model considering the importance of global iams for key scientific reports such as chapter 2 of the special report on global warming of 1 5 c by the intergovernmental panel on climate change ipcc rogelj et al 2018 and chapter 3 of the forthcoming sixth assessment report ar6 an ongoing debate exists within the scientific community gambhir et al 2019 pindyck 2017 schwanitz 2013 whether global iams are suitable for long term planning of the global energy system due to among others the limitations as described in this section the proposed framework informs this debate from a power system perspective by providing the ability to scrutinize iam scenarios in dedicated power system models while simultaneously supporting internal improvements of power system representation within the iams as a proof of concept the global iam messageix globiom krey et al 2016 fricko et al 2017 is soft linked to plexos world brinkerink et al 2021 brinkerink and deane 2020 a 258 regional detailed global power system model developed in plexos energy exemplar 2020 in the past johnson et al 2017 had concerns regarding the reproducibility of soft linking messageix globiom to a detailed power system model however they stated that it would be useful to compare the results of message with those from a detailed power system model with high temporal resolution to validate how well message simulates the impacts of vres deployment the proposed standardized framework for soft linking iams and power system models makes the soft link easier to reproduce and hence the envisioned exercise can be applied as shown in this study by means of a snapshot analysis for the year 2050 a 1 5 c and high vres scenario from messageix globiom is assessed regarding its technical feasibility furthermore results from plexos world are used to improve parts of the power system representation of messageix globiom to show the frameworks potential for bi directional soft linking section 2 describes the proposed methodological framework and section 3 includes the results of the proof of concept application of the framework section 4 includes a discussion regarding the results of this paper and regarding the power system representation of messageix globiom including suggested improvements section 5 concludes with the main findings including a commentary on the theoretical discussion regarding the suitability of iams for planning exercises of the global energy system 2 methods the proposed methodological framework for soft linking iams with dedicated power system models allows for assessments of the technical feasibility of specific iam scenarios with higher spatial technological and temporal resolution this model soft linking enables enhanced insights regarding vres integration and provides the ability to assess the suitability of uniformly applied stylized relationships and model inputs for the power system representation in iams even though the framework is designed to be generally applicable to most global iams and power system models this paper includes a proof of concept soft linking the global iam messageix globiom with global power system model plexos world this allows for a general understanding of the framework steps and also provides an example of a practical application before diving into the details of the framework a general introduction of the modelling tools and how they represent power system dynamics is merited aspects specific to the integration of scenario data from messageix globiom in plexos world and vice versa as well as modelling assumptions relevant to a specific step in the framework will be covered in section 2 3 2 1 messageix globiom messageix globiom is a global iam with a detailed representation of technological socioeconomic and biophysical processes in energy and land use systems iiasa energy program 2020 the model has different spatial resolutions typically ranging between 11 and 15 world regions with the spatial resolution of the 11 region model as assessed in this study visualized in fig 1 messageix globiom is built using the open source messageix modelling framework huppmann et al 2019 although the messageix framework is capable of model simulations with sub annual timeslices the global model messageix globiom generally runs with yearly resolution the main characteristics of messageix globiom with respect to the representation of the power system is summarized and compared with other global iams in pietzcker et al 2017 to account for challenges associated with vres integration and power system reliability sullivan et al 2013 introduced four constraints in messageix globiom including i capacity reserves to meet peak electricity demand at all times with a desirable reserve margin ii operating reserves to provide short term system flexibility based on the amount of load and electricity from vres in the system iii expected curtailment values relative to different penetrations levels of vres and iv grid integration costs also relative to vres penetration levels johnson et al 2017 argues that the approach in sullivan et al 2013 has a range of limitations for example the fact that the parametrization of the introduced constraints were uniformly applied for all messageix globiom regions solely based on simulations from a single region power system model sullivan et al 2013 sioshansi 2010 johnson et al 2017 therefore applied a hybrid approach using region specific rldcs from ueckerdt et al 2017 to create regionally stylized parameterization for the impact of vres deployment on for example curtailment and non vres flexibility requirements minimum firm capacity requirements following johnson et al 2017 have been defined per region and decade as a multiplier of average annual electricity demand firm capacity represents capacity that is available at any given time the multiplier is based on the region specific relative ratio between average demand and peak demand combined with a 20 reserve margin where the margin is intended to ensure sufficient available capacity at all times capacity factors cfs 3 3 cfs refer to the ratio of actual electricity output compared to the theoretical maximum generation of a powerplant in case of renewables this is affected by the availability of wind solar irradiation or water inflow for vres technologies are based on regional resource potentials identified per range of cfs and assumed cfs for thermal powerplants are year and region specific with globally uniform technological parameters per technology there are a number of short term and long term flexibility options in messageix globiom including a generic storage object hydrogen electrolysis direct air capture electric vehicles and electricity export to neighbouring regions as part of the modelling effort in parallel to this study the representation of inter regional electricity trade in messageix globiom has been adapted to only allow for trade bilaterally by means of investments in transmission grid infrastructure intra regional trade of electricity is accounted for by means of costs as a function of final electricity demand relative vres penetration and the size of a specific region however regions are assumed to be copperplates without restrictions on internal transmission flows 2 2 plexos world plexos energy exemplar 2020 is a transparent energy and power system modelling tool among others used for electricity market modelling and planning freely available for academic use all data input is customizable and the linear equations can be queried and modified by the user plexos has an integrated user interface enabling data management and model simulation to occur within the tool yet also supports automation of data flows and model simulation by means of com or net the tool facilitates use of open source glpk scip and commercial cplex gurobi mosek xpress mp solvers depending on availability of licenses with xpress mp being used for the simulations in this study the model used for this paper is based on the plexos world model a detailed global power system model with 2015 as baseline year capable of simulating the generation of over 30 000 individual powerplants brinkerink et al 2021 brinkerink and deane 2020 the spatial representation of the model specified for this study is visualized in fig 1 with a total of 258 plexos world regions grouped per larger iam region following the spatial representation of messageix globiom powerplants in the plexos world model are modelled per turbine unit with standard unit sizes to be able to incorporate technological generator characteristics relevant for hourly unit commitment economic dispatch uced modelling uced modelling within power system models refers to the optimal utilization of available generator capacity to match system demand within a given simulation period while abiding to technical and operational constraints the model version used includes perfect foresight and market assumptions refer to section 1 of the supplementary material for detailed equations of the uced modelling in plexos world the plexos world model as applied for this study including all input data and timeseries can be found in brinkerink 2020 2 3 soft link framework fig 2 provides an overview of the different steps of the framework the framework is setup in a non discriminatory way allowing it to be applied to most iams and power system models however the scope of this framework from a spatial perspective is to downscale the regional copperplates in iams to a detailed spatial resolution in the power system model the benefits of this framework are therefore more applicable to assessments of global iam scenarios with a coarse spatial representation versus scenarios from already more spatially defined iams the openly available python script 4 4 https github com iiasa iam powersystemmodel linkage accompanying this paper that can be used to coordinate the soft link between iams and power system models is based on iamc data template format 5 5 https data ene iiasa ac at database the iamc data template format is the main data format used for many global iam intercomparison projects as well as for influential reports such as the forthcoming chapter 3 of ipcc ar6 note that the script is a helpful tool to automate the data processing workflow within the soft link yet other languages or manual data conversion e g in excel can also be applied although the methodological framework is developed to address the limitations of global iams the framework is also suitable for soft linking to other long term planning models like energy system optimization models the following sections describe the different steps of the framework in more detail 2 3 1 iam model simulation in general data inputs for iams are model and scenario specific depending on the iam used but most iams include basic parameters for socioeconomic developments e g gdp urbanisation and population projections technology characteristics and inputs for non energy impacts such as land or water use requirements following energy system developments within this framework generally any type of iam can be used with the bare minimum requirement that the iam is able to report technology specific regional powerplant capacities and regional electricity demand however to assess the technical feasibility of a given iam scenario in the power system model it is recommended to use all available iam scenario output data relevant to power systems if not available additional required data for power system models such as carbon and fuel prices technology parameters and capacities of balancing assets that can assist with matching electricity demand and supply such as storage power to gas and electric vehicles can either be standardized pricing or optimized balancing assets in the power system model using additional input data for the power system model not coming from the iam affects the harmonization of both models and the overall representativeness of scenario assessment yet due to the limited power system representation in iams it is often necessary the python script as designed for this paper uses pyam 6 6 https github com iamconsortium pyam an open source python package for analysis and visualization of iam scenario data huppmann et al 2021 the pyam package is used to extract messageix globiom scenario data for integration in plexos world from databases such as the iamc 1 5 c scenario explorer huppmann et al 2018 that among others includes scenario data underpinning chapter 2 of the special report on global warming of 1 5 c by the ipcc rogelj et al 2018 2 3 2 spatial capacity constraints one of the core aspects of the framework is the ability to assess iam scenarios with higher spatial resolution in the power system model especially relevant from a power system perspective this allows for any iam scenario to be assessed in the context of local characteristics with the ability to provide detailed insights that cannot be provided with a coarser representation for this to occur iam scenario data must be downscaled to a newly defined spatial resolution to be used as input for the power system model an exemplary visualization of indicative spatial resolutions of both sets of models is shown in fig 3 the first set of iam scenario output that requires spatial downscaling are regional powerplant and optionally balancing asset capacities within this framework regional capacity expansion and retirement constraints need to be developed that can be calculated by comparing the iam scenario output with existing baseline capacities these constraints determine per scenario region and technology how much capacity needs to be expanded or retired compared to the baseline to match the values provided by the specific iam scenario for a given year the constraints are used as boundary condition for the capacity allocation exercise within the power system model as described in section 2 3 5 they can be setup in multiple ways first a greenfield approach can be used in which existing powerplant capacity portfolios in individual sub country regions are not considered albeit easier to apply existing portfolios are in the near to medium term of significant relevance considering the often long lifetimes of powerplants it is therefore advisable to start with a baseline portfolio which can be based on any preferable source for the messageix globiom and plexos world proof of concept this paper and the accompanying python script uses the plexos world 2015 dataset brinkerink and deane 2020 for baseline capacities the dataset includes global powerplant storage and transmission capacities as of 2015 divided by 258 regions given the high temporal resolution of power system models modelling exercises are often restricted to time horizons of a single year thus providing a snapshot analysis of that given year taking 2050 as an example as intended simulation year scenario specific expansion and retirement constraints e x per region r and technology t for the period up to 2050 can be calculated with eq 1 by subtracting the reported scenario specific capacities from the iam c s from the baseline powerplant capacities c b eq1 e x r t c b c s if the difference is negative it means that expansion of capacity is required for that specific technology and region and vice versa retirement for accurate modelling of powerplant expansion and retirements constraints can be calculated per interval e g constraints for the period 2015 2020 2045 2050 or constraints can be determined for the full period to make the capacity expansion exercise computationally less intensive the latter approach is used for this proof of concept study as automated in the python script fig 4 shows an example of calculated expansion and retirement constraints for the period 2015 2050 for the lam region for messageix globiom 2 3 3 spatial demand downscaling iam scenario and region specific yearly electricity demand values need to be downscaled to the power system model regional level in principle any preferred energy downscaling method can be applied however within the python script we apply a forecasting methodology to project country level yearly electricity demand based on multivariate linear regression with gdp at purchasing power parity x g d p p p p per capita and urbanisation share x u r b as independent variables and electricity consumption per capita y p c as the dependent variable historical country level values h for the above variables have been retrieved by means of the world banks world development indicators and the world bank data python package 7 7 https github com mwouts world bank data country level values are grouped per iam region according to the spatial representation of the specific iam followed by the derivation of the regional regression equations eq 2 for the period 1980 2014 with a being the intercept b g d p p p p and b u r b the respective slopes and e the residual more recent data years for electricity consumption per capita are not available within the world bank world development indicators eq2 y p c h a b g d p p p p x g d p p p p h b u r b x u r b h e for country level projections of the independent variables as well as population projections we used the shared socioeconomic pathways ssp riahi et al 2017 and the accompanying quantifications kc and lutz 2017 dellink et al 2017 crespo cuaresma 2017 leimbach et al 2017 jiang and o neill 2017 all retrievable through the ssp public database 8 8 https tntcat iiasa ac at sspdb the ssps describe five different narratives based on alternative global socio economic development pathways the choice for a specific ssp to follow is in certain cases straightforward but when in doubt it is advisable to use ssp2 as the middle of the road pathway given the regional regressions and the country level ssp projections p for gdp at purchasing power parity x g d p p p p p and urbanisation share x u r b p per capita electricity demand at country level y p c p can be projected specific per ssp eq 3 an example regression is visualized in fig 5 for the lam region eq3 y p c p a b g d p p p p x g d p p p p p b u r b x u r b p by multiplying y p c p with country level population projections for the corresponding ssp x p o p p aggregate projected country level electricity demand y p can be calculated eq 4 the regression can be applied manually as shown in this section yet in the python script we use the linear regression module of the sklearn python package 9 9 https scikit learn org stable modules generated sklearn linear model linearregression html eq4 y p y p c p x p o p p per iam region the y p values can be used as a proxy to downscale the iam scenario regional demand values y r to country level final demand values y f eq 5 within the python script this occurs by making use of downscaling functionalities within pyam fig 6 showcases an example comparison of y p y f and 2015 country level historical demand y h based on the plexos world 2015 dataset brinkerink et al 2021 brinkerink and deane 2020 for contextual purposes compared to the historical demand the graph indicates different demand growth rates as a result of different ssp projections for the independent variables per country it can also be seen that in the given example the projected demand is lower compared to the downscaled scenario demand there are multiple aspects that can affect the relative growth of electricity demand compared to the historical linear regression for example it could be expected that due to efficiency improvements and behavioural change a partial decoupling of economic growth and increase in energy demand could occur in the more developed parts of the world yet on the global scale this trend is less obvious schandl et al 2016 more importantly electricity as end use is expected to gain a more predominant role in a variety of sectors e g transport leading to significant expected growth of the share of electricity in global final energy demand mccollum et al 2018 eq5 y f y p y p y r 2 3 4 temporal demand downscaling global iams and power system models have different modelling horizons and temporal resolution an example of this is visualized in fig 7 iams focus on the long term development of the energy system with planning horizons of up to a century and modelling periods of between 1 and 10 years with a specified baseline year as starting point timesteps in global iams are generally applied on an annual basis with investment decisions reported at the end of every modelling period within the framework the power system model is used to assess iam model output for a specific year with detailed temporal resolution for example on an hourly basis for the full year depending on the aim of the study holttinen et al 2013 results can be reported per timestep or on a yearly basis for direct comparison with the iam the spatially downscaled yearly electricity demand values from section 2 3 3 require additional downscaling in terms of temporal resolution once again multiple approaches are possible yet for the results in this study we use historical timeseries based on the plexos world 2015 dataset brinkerink et al 2021 brinkerink and deane 2020 which includes hourly demand data for all countries globally as well as for a wide range of sub country regions for the 2015 calendar year approximately 50 of profiles in the dataset are based on actual historical operational power system data with the remainder being country specific synthetic demand timeseries adapted from toktarova et al 2019 the country level final electricity demand y f per hourly interval i can be calculated with eq 6 by using the historical hourly values y h i as proxy for linear downscaling eq6 y f i y h i y h i y f for this study the country level final electricity demand profiles are further downscaled to sub country level y f s c i with eq 7 by using historical relative demand shares for sub country regions per interval y h s c i as proxy peak demand for all demand timeseries relative to the total demand is kept equal compared to 2015 values the limitation of this and other applied downscaling steps are discussed in section 4 3 the development of the demand timeseries based on the linear downscaling for all countries globally occurs within the python script eq7 y f s c i y h s c i y h i y f i next to the expansion and retirement constraints and the downscaled demand timeseries used input data for plexos world based on messageix globiom outputs for this exercise consist of regional specific carbon and fuel prices generator heat rates storage capacities and available technical parameters 2 3 5 power system model capacity allocation traditionally capacity expansion exercises in power system models are used to optimize the long term development of the power system in contrast to the traditional application the framework we propose in this article does not allow powerplant capacities to be expanded and retired in an unconstrained fashion instead we use the expansion and retirement decisions from the iam by means of the developed expansion and retirement constraints in section 2 3 2 as boundary condition for the power system model the capacity expansion module in the power system model is used to optimize the allocation of powerplant resources to the different power system model regions with the iam regional capacities as boundary an example application of this exercise for messageix globiom and plexos world can be seen in fig 8 together with the allocation of powerplant capacities the capacity expansion module of the used power system model can optimize the expansion and integration of balancing assets such as transmission infrastructure different storage technologies flexible utilization of electric vehicles and demand side management although these assets can be accounted for in iams their operational benefits and technical limitations are only visible in model simulations with detailed spatial and temporal resolution similar to powerplant capacities if the iam reports capacities of a specific technology it can be used as boundary condition for the allocation exercise rather than unconstrained optimization within this framework uced modelling can either be performed in an integrated singular run with the capacity allocation or as two separate modelling phases with different temporal modelling resolution depending on the defined spatial and technological resolution of the power system model performing long term planning exercises with temporal resolution equal to sub hourly uced modelling can be too computationally complex for the messageix globiom and plexos world proof of concept the decision has been made to separate both modelling phases with different applied temporal resolutions for the capacity allocation exercise a sampling approach is used to select representative timeslices of 3 weeks per year at 4 hourly temporal resolution total of 126 4 hourly timeslices linear optimization is applied for the capacity allocation with generator units rounded to the nearest integer refer to section 2 1 and 2 2 of the supplementary material for more details on the sampling approach used and for applied generator unit sizes and other generator characteristics in plexos world firm capacity requirements in plexos world per sub country region follow the same assumptions as messageix globiom applies per iam region these requirements are determined by taking the relative ratio between average demand and peak demand in addition to a standardized 20 reserve margin whereas in messageix globiom these ratios are approximated in plexos world they are determined by using historic 2015 demand values for all plexos world regions following brinkerink et al 2021 brinkerink and deane 2020 table 1 compares the firm capacity requirements as multiplier of average demand for 2050 following messageix globiom values johnson et al 2017 and the regionally aggregated demand weighted values in plexos world compared to messageix globiom firm capacity requirements per region in plexos world have a much wider range it s also worth noting that the values represent an iam regional average but that values per sub country region in plexos world can range significantly for example values in cpa range from 1 40 to 2 21 refer to section 2 3 of the supplementary material for all used firm capacity requirement values in plexos world modelling of electricity storage in plexos world is in line with messageix globiom where storage is modelled as a single generic technology with a cycle efficiency of 80 storage capacity of 24 h and a capital cost of 800 kilowatt johnson et al 2017 hydrogen electrolysis in plexos world is constrained at the iam regional level following capacities indicated by the messageix globiom scenario without possibilities for conversion back to electricity conversion efficiency is set at 80 in line with messageix globiom the modelling of electricity transmission in plexos world is based on physical transmission grids with customised associated investment costs operational costs and operational losses as a function of transmission distance and specific transmission technology for every unique potential high voltage transmission pathway in the model totalling 582 different to storage technologies the expansion of transmission lines in plexos world is not constrained by output from messageix globiom due to the vastly different spatial resolutions and the fact that intra regional trade is not modelled in messageix globiom section 2 1 of the supplementary material provides more details on transmission modelling in plexos world for the allocation of renewable powerplant capacities limits have been set on the resource potential per plexos world region with the same sources used as messageix globiom to retain uniformity country level resource potentials for solar technologies are based on a study by pietzcker et al 2014 and country level potentials for onshore and offshore wind based on a global assessment by eurek et al 2017 potential for new hydro based capacity is based on a study by gernaat et al 2017 that identifies 60 000 potential locations for new economically viable projects for geothermal and biomass no additional local restrictions are placed on resource potential due to the limited influence of geothermal based electricity generation in the to be assessed messageix globiom scenario and the assumed transportability of biomass between sub country regions within plexos world two sets of input cf timeseries for hydro solar and wind are used in the plexos world model for this study a conservative set of timeseries is used based on the plexos world 2015 dataset which includes profiles based on benchmarked values at year and country level for 2015 brinkerink et al 2021 brinkerink and deane 2020 a second set of timeseries has harmonized values equal to messageix globiom by linearly scaling the original plexos world 2015 timeseries by comparing the regional average to the messageix globiom output due to the large regional copperplates renewable resource potentials for a specific region within messageix globiom consist of the combined potential of a wide range of countries with often very different characteristics in plexos world if domestic resource potentials are to be used for export purposes the electricity must be physically transferred by means of transmission infrastructure including associated costs and losses whereas in messageix globiom no intra regional barriers for trade exist this can lead to different investment dynamics and hence as a sensitivity analysis it is merited to assess the specific messageix globiom scenario in the context of conservative cfs 2 3 6 power system model unit commitment economic dispatch if the decision has been made to separate the capacity allocation exercise from the uced modelling in two distinct modelling phases the main output from the capacity allocation exercise being the generator and balancing asset portfolios of the power system model regions should be used as input for the uced modelling temporally detailed model simulations of the downscaled generator portfolio and balancing assets can provide detailed insights in the technical feasibility of a given iam scenario it furthermore allows for benchmarking of simulation results with generic model assumptions within the iam examples can be assumed generator cfs as well as stylized relationships regarding curtailment and occurrence of possible unserved energy 10 10 different to messageix globiom where occurrence of unserved energy is not possible plexos world allows for unserved energy at a cost of 10 000 megawatt hour the model can determine that often it is more efficient for unserved energy to occur than to invest in additional flexibility assets such as storage or in further transmission expansion to mitigate this unserved energy unserved energy represents the share of final electricity demand that cannot be met with the available generator resources the uced modelling in plexos world based on the output of the allocation exercise is done with hourly modelling resolution based on mixed integer programming mip data flows between both modelling phases in plexos world occurs in an automated fashion 2 3 7 feedback loop the results from the model soft link exercise within this framework consists of quantified simulation output that can assist with optimizing the power system representation in iams while considering the computational requirements of model simulations relevant outputs of the power system model to be used in iams for improved power system representation are for example technology cfs curtailment values and costs of generation before the power system model output data can be used as input for an iam the data needs to be post and pre processed outputs from the power system model need to be converted into a format that is readable for the specific iam in the case of plexos world results can be written to individual flat files per variable and easily be converted to the iamc data template format that messageix globiom and a number of other global iams use as a result of the openentrance 11 11 https github com openentrance nomenclature project the iamc data template format has the extended ability to support sub annual data which is critical for temporally detailed power system modelling results next to format conversion the data also need to be aggregated from the power system model regional level to the iam regions for some output variables this can easily be done by simple aggregation whereas others require more thought for example when it comes to technology cfs a normal average can be taken based on reported values in the different power system model regions or a capacity weighted average can be used as well the potential for a scripted feedback loop within the framework allows for an iterative process between the iam and power system model until the power system representation in the iam is deemed satisfactory in terms of power system adequacy the ability of a power system to meet demand under normal operational conditions or other criteria 2 4 scenarios the engage ssp2 npi2020 500 scenario as simulated by messageix globiom is consistent with end of century warming of 1 5 c without temperature overshoot riahi et al 2021 in 2050 as assessed snapshot year for this study it exhibits high penetration of vres with approximately 64 of electricity in the grid coming from wind 33 and solar pv 31 globally furthermore the share of electricity in final energy demand is slightly over 50 in 2050 cf 20 in 2020 iea 2021 and the share of electric mobility in the transportation sector is 33 in 2050 cf 1 in 2020 iea 2021 both at the global level by assessing this scenario the soft link framework can be used to evaluate messageix globiom in a setting where iams may struggle in terms of adequately incorporating the detailed implications of variability in electricity supply and demand we perform a baseline simulation and a set of sensitivity simulations in plexos world summarized in table 2 as a proof of concept for the potential of the framework to streamline informed model improvements in global iams the results of the model simulations in plexos world related to inter regional electricity trade between the larger iam regions are fed back to messageix globiom and used as model input for a second iteration the simulations in messageix globiom as performed for this study can be found in table 3 it is important to recall that in line with the framework key model input in plexos world such as powerplant capacities and electricity demand are at an aggregate level equal to the messageix globiom model output at all times the baseline simulation represents the reference for the soft link framework in that it attempts to replicate the original messageix globiom scenario with harmonized inputs between both models such as input cf timeseries for hydro solar and wind technologies the conservative cfs model simulation on the other hand uses the original plexos world 2015 dataset timeseries as a sensitivity analysis whereas in the baseline and conservative cfs simulations the expansion of storage capacity is bound at a regional level following the messageix globiom scenario output the no storage constraints simulation allows for full optimization of storage capacity this allows for an assessment of how accurately storage expansion is integrated in messageix globiom and moreover how it impacts other variables such as generator cfs generator reserve requirements and transmission utilization because the no storage constraints simulation allows for unconstrained competition between transmission and storage in the optimization it provides the best indication for the potential of inter regional electricity trade the results from this simulation regarding inter regional trade are therefore used as model input for a second iteration in messageix globiom to optimize its representation of inter regional electricity trade as a proof of concept for the framework in terms of bi directional model soft linking section 2 4 of the supplementary material provides more information regarding the renewed representation of inter regional trade in messageix globiom including a full overview of the adjusted input parameters based on plexos world 3 results this section includes the modelling results for the proof of concept application of the proposed soft link framework where plexos world is used to assess a high vres scenario from messageix globiom with a 64 share of vres in the electricity grid at the global level the results from plexos world will be compared to the model outputs from messageix globiom based on which suggestions are being made for additional internal model improvements regarding power system representation 3 1 generation and storage fig 9 shows the differences in generation mix per plexos world model simulation in comparison to the messageix globiom output the main observation is that for both the baseline as the other simulations in plexos world the total generation output is lower compared to the messageix globiom scenario output for example following the given scenario in messageix globiom the 2050 electricity generation in the cpa region equals approximately 55 5 ej whereas generation in the plexos world simulations ranges between 43 and 45 ej the lower generation compared to messageix globiom is in most cases occurring for both renewable technologies as well as for fossil fuel based powerplants fig 10 shows the technology and region specific cfs based on model output for a range of key generator technologies the baseline and no storage constraints simulations have maximum cf input assumptions for hydro solar and wind technologies in line with the messageix globiom scenario yet as the graphs in fig 10 indicate the equal availability of renewable resources does not always lead to comparable cfs as output for example the regionally aggregated cf for solar pv based on the baseline simulation for the cpa region is 16 2 compared to 17 7 in messageix globiom cfs for hydro solar and wind technologies in the conservative cfs model simulation are based on 2015 benchmarked values and lead to significantly lower vres penetration compared to the messageix globiom scenario output fossil fuel based powerplants partly compensate for the lower availability of renewable resources in this plexos world simulation however besides regional outliers all plexos world simulations indicate that cfs for these technologies are also below par compared to the messageix globiom scenario output the exceptions are gas and coal powerplants without carbon capture and storage ccs from which higher utilization is required to mitigate part of the existing supply shortage from renewables the unconstrained expansion of electricity storage in the no storage constraints leads to lower cfs for solar pv yet higher cfs for other technologies compared to the baseline this is a direct result of lower investments in storage capacity in plexos world for the no storage constraints simulation compared to messageix globiom as highlighted in fig 11 expansion of storage in messageix globiom occurs based on the contribution of storage to system flexibility needs reducing curtailment of vres and provision of firm capacity using stylized relationships leading to e g large scale investments of over 1000 gw in cpa and nam however the results show that with similar capacities in plexos world storage is utilized with lower cfs compared to messageix globiom when plexos world is allowed to freely optimize the expansion of storage not bound to capacities following the messageix globiom output as in the no storage constraints simulation total build capacities are approximately one third of messageix globiom albeit with higher cfs compared to the other simulations in plexos world the conversion of electricity into hydrogen by means of electrolysis is the only long term storage solution integrated in messageix globiom for the assessed scenario fig 12 however indicates that similar to short term storage hydrogen electrolysis is underutilized in all plexos world simulations compared to messageix globiom 3 2 curtailment and unserved energy electricity coming from vres technologies that cannot be instantaneously used stored transmitted to a neighbouring area or converted to other energy carriers gets curtailed curtailment is an important factor in power systems with large penetration of vres and based on the plexos world simulations an element that might be underestimated in messageix globiom for the examined scenario this is visualized in fig 13 which as an example highlights the region specific curtailment values for solar pv messageix globiom accounts for curtailment through stylized relationships as a function of relative vres penetration although this kind of stylized relationship is inherently not incorrect the baseline and conservative cfs plexos world model simulations indicate that curtailment grows in parallel with relative vres penetration the observed curtailment values in plexos world are in almost all cases a magnitude higher compared to messageix globiom the lower investments in storage capacities in the no storage constraints simulation lead to overall highest solar pv curtailment values due to reduced possibilities to mitigate peak solar pv supply on the global scale curtailment values relative to the theoretical generation potential range between 4 and 11 for solar pv depending on the plexos world simulation and comparatively between 4 and 8 for wind based technologies the combined effect of higher vres curtailment compared to messageix globiom in combination with the underutilization of dispatchable technologies leads to the occurrence of unserved energy in the global power system this is visualized in fig 14 which showcases unserved energy values per region and model simulation 3 3 electricity trade in an optimally functioning integrated global power system a spatiotemporal mismatch between demand and supply of electricity can be mitigated by sharing resources between regions by means of transmission integration despite significant intra regional transmission flows within plexos world both land based as well as through long distance subsea interconnectors the built transmission infrastructure cannot sufficiently compensate for the large variability in supply fig 15 shows mapped electricity flows in 2050 for the no storage constraints simulation for contextual purposes 1 ej 278 twh roughly equals the current day electricity demand of australia or mexico fig 16 highlights the occurrence of inter regional trade of electricity between the iam regions for both performed iterations of messageix globiom in comparison to the simulations in plexos world the second iteration of messageix globiom has adjusted input parameters based on the results of the no storage constraints simulation in plexos world and general plexos world input parameters refer to table s2 5 in section 2 4 of the supplementary material for a full overview within the plexos world results the conservative cfs simulation has the overall largest trade for this simulation the inter regional transmission flows are a means to compensate for the lower cfs for renewables compared to messageix globiom the baseline simulation has the lowest trade values correlated to the earlier identified large capacities of electricity storage following messageix globiom values in the no storage constraints simulation where the expansion of storage and transmission occurs in competition the inter regional trade values are significantly higher compared to the baseline simulation at a net total of 6 3 ej 1750 twh versus 2 5 ej 694 twh globally to put these values in context total 2015 inter regional trade values between the iam regions based on simulations of plexos world brinkerink et al 2021 are approximately 0 1 ej 28 twh in line with messageix globiom the fsu region has been identified as resource rich exporting region within plexos world albeit with cpa as main importing region compared to sas in messageix globiom compared to plexos world the inter regional trade values in both iterations of messageix globiom are lower the adjusted input parameters for the second iteration of messageix globiom based on plexos world stimulate higher inter regional trade between fsu and sas as well as a modest uptake of inter regional trade in other regions however considering the relatively small differences between both iterations it is clear that the alignment of input parameters regarding inter regional trade in messageix globiom based on plexos world has minor impact for the examined scenario 4 discussion 4 1 discussion of proof of concept results the proof of concept application of the proposed methodological soft link framework in this paper has revealed that the differences in modelling resolution and assumptions between messageix globiom and plexos world can lead to different results note that the discussion of the results in this paper reflect on a single scenario with high shares of vres and is not intended to shed light on the functionality of both models in all possible contexts the results show that generation values and generator cfs in plexos world are significantly lower than messageix globiom this is both the case for renewables as well as for most thermal generators and applicable for all performed plexos world simulations of the examined messageix globiom scenario cfs for renewables are lowest in the conservative cfs simulation which highlights the sensitivity of modelling assumptions in iams regarding uncertain developments such as the availability of highly efficient untapped renewable resources different to messageix globiom plexos world operates based on perfect market assumptions meaning that there are no emission constraints included that might affect how much fossil fuel based powerplants are allowed to operate to stay within the bounds of a set emission target this contributes to the fact that as an outlier compared to other technologies coal and gas powerplants without ccs in plexos world have higher generation values compared to messageix globiom a key factor for the overall lower generation values in plexos world is the different sectoral representation of both models messageix globiom is a sector coupled model that is not only required to meet electricity demand as end use but also has the ability to convert electricity in other energy carriers for use in for example the transport and heating sectors plexos world focuses solely on the power sector where available generators are utilized to meet final electricity demand in addition to hydrogen electrolysis as a means to limit electricity curtailment however given that there is no modelled demand for hydrogen or other energy carriers in plexos world the model can determine that it is often more efficient to curtail electricity than to invest in additional flexible technologies such as electricity storage to make optimal use of available generation for indirect use in other sectors that said and despite the overall lower demand for electricity compared to messageix globiom the plexos world simulations indicate that demand cannot always be met leading to significant unserved energy in the global power system of between 2 5 and 5 these findings are in line with other literature which highlights that the occurrence of unserved energy in power systems mostly reliant on vres can be expected to become a more important factor tong et al 2021 next to unserved energy higher vres curtailment values can be observed compared to reported values from messageix globiom the more detailed temporal resolution in plexos world highlights how curtailment can occur in some hours versus unserved energy in others next to that the more detailed spatial resolution in plexos world also indicates that both can occur at the same time following oversupply in some regions versus undersupply in others this observation suggests that there is a mismatch in spatiotemporal demand and supply of electricity for the simulated scenario when there is sufficient available transmission capacity within a region or when assuming that regions are copperplates with no intra regional network constraints such as modelled in messageix globiom any spatial mismatch between demand and supply can theoretically be mitigated however the results indicate that despite significant transmission capacities globally network constraints are a key limiting factor that need to be overcome to enable power systems with high penetration levels of vres in the performed plexos world simulations based on the messageix globiom scenario the developed transmission portfolio together with underutilized balancing assets such as electricity storage and hydrogen electrolysis are not able to handle the spatiotemporal variability in demand and supply sufficiently to prevent largescale occurrence of curtailment and unserved energy future work is essential to provide more insights in model uncertainties as a result of the regional copperplates in global iams overall it can be observed that from a regionally and temporally coarse perspective following messageix globiom the projected global power system is deemed technically feasible however the temporally and spatially detailed model simulations in plexos world highlight that the power system adequacy of the assessed scenario in terms of unserved energy without taking into account potential contributions of electric vehicles to load management may be insufficient as part of the modelling effort in parallel to this study the power system representation in messageix globiom regarding inter regional trade of electricity has been adapted by integrating bilateral trade through investments in region specific transmission grid infrastructure model data and simulation results from plexos world have been used to inform the input parameters in messageix globiom for this new setup however modelling results from the updated version of messageix globiom still indicate an underestimation of inter regional trade potential it can therefore be concluded that the differences in spatial and temporal modelling resolution between messageix globiom and plexos world are a direct cause for the underutilization of inter regional trade in messageix globiom due to the absence of sub annual timeslices in the global implementation of messageix globiom there is a singular decision in the optimization to determine whether inter regional import or export of electricity is cost optimal within the modelling period this means that transmission is solely utilized for bulk unilateral flows of electricity within the modelling period yet on an aggregate level it does not provide additional flexibility for the power systems involved in the inter regional trade the uced modelling in plexos world for this study operates based on hourly intervals and hence is not only able to assess unilateral flows but also the occurrence of bilateral flows for the purpose of balancing electricity demand and supply between regions and for contributions to the mitigation of vres variability furthermore whereas a singular inter regional transmission pathway exists between regions in messageix globiom plexos world has transmission pathways between all bordering areas meaning that multiple inter regional transmission lines between two iam regions can be operational at any given time the low spatial and temporal resolution in messageix globiom inherently means that there is a model bias against the uptake of inter regional electricity trade 4 2 feedback on power system representation in messageix globiom there are a number of underlying assumptions in the model structure of messageix globiom as well as general data inputs that affect its accuracy of results the remainder of this section is dedicated to discussing these and to provide suggestions for improvements the focus in this paper has been on the global implementation of the messageix globiom model hence suggestions for improvement of the power system representation in messageix globiom are being made in this context the use of sub annual timeslices would be beneficial for the representation of vres however to date its integration has been hampered due to its impact on computational complexity and resulting model runtime continuous developments regarding faster computers cloud based solutions improved solvers and solving techniques merits a regular reassessment of the feasibility of implementing sub annual timeslices in the global implementation of messageix globiom besides refining the temporal or spatial resolution in messageix globiom there are a number of low hanging fruits that could be implemented for improved power system representation without affecting computational complexity too severely the previous sections have highlighted that the absence of network constraints within the regional copperplates within messageix globiom is one of the main reasons for possible overestimation of vres integration potential in most global iams internal grid expansion is accounted for in terms of costs as a function of total build generator capacity or as a function of final electricity demand the latter is the case for messageix globiom in addition to a cost premium for grid integration of vres depending on the relative penetration and the size of the region it is fair to assume that with longer transmission distances the costs as well as losses for internal electricity transmission increases the results from the modelling in plexos world can benchmark the cost premiums in messageix globiom for internal transmission integration to make sure they are not underestimated which in turn would lead to overestimation of vres integration potential where needed values can be informed and updated on a regional basis all technologies in messageix globiom have pre defined values relative to their capacity for assumed positive or negative contributions to power system flexibility to date it is assumed that inter regional trade of electricity has positive contributions to system flexibility for the exporting region whereas inter regional trade for the importing region has an equal negative contribution i e it needs equally sized additional domestic flexibility to compensate for the import of electricity from another region on a macro level this means that inter regional trade does not contribute to flexibility in the power system within messageix globiom which may restrict investments in new transmission capacity studies assessing the benefit of large scale transmission integration in power systems with high vres penetration highlight the potential for cross border transmission as a means to provide flexibility among others due to often asynchronous occurences of peaks and lows in electricity demand and vres generation in different regions brinkerink et al 2019 transmission integration in this context can decrease the need for domestic reserves providing flexibility as highlighted among others from a pan european rodríguez et al 2014 becker et al 2014 and global grossmann et al 2013 perspective with this in mind it is recommended to reassess whether an equal negative contribution to flexibility for importing regions in messageix globiom is overly conservative the electricity trade values in plexos world can act as a baseline to calibrate the flexibility contributions for inter regional trade in messageix globiom as of now messageix globiom includes a single generic electricity storage technology with 24 h storage potential the underutilization of storage in the plexos world simulations can partly be explained by the fact that at a regional or continental level the sharing of resources through transmission integration can be favourable compared to mostly domestic generation and storage as also observed in recent literature for the african wu et al 2017 southeast asian siala et al 2021 and european tröndle et al 2020 context however the absence of other short and longer term storage technologies in messageix globiom prevents the proper allocation of storage technologies depending on the requirements in the specific power system expansion of long term storage technologies such as pumped hydro storage would be beneficial for seasonal storage purposes for wind based generation furthermore integration of short term storage technologies such as batteries with a relatively higher power versus storage ratio would help with mitigating peaks in supply from especially solar pv next to storage the integration of demand side management technologies could assist with shifting of peaks in electricity demand to decrease the likelihood of occurrence of unserved energy or to provide a better match with peaks in vres generation the plexos world simulations have shown that the large scale integration of vres based on the messageix globiom scenario is accompanied by the occurrence of both significant electricity curtailment as well as unserved energy in electricity demand from a power system adequacy perspective given the limitations in modelling resolution and model assumptions within global iams such as the unconstrained intra regional power pooling a range of stylized parameters and input assumptions such as region specific curtailment parameters and technology cfs could benefit from being updated based on the spatially and temporally detailed modelling in plexos world by means of the developed soft link framework in this study results from plexos world can be directly fed back into messageix globiom as has been shown by the proof of concept for inter regional electricity trade 4 3 study limitations and modelling uncertainties the proposed soft link framework is designed to assess and benchmark existing iam scenarios by means of a snapshot analysis in a power system model with enhanced spatial and temporal resolution the main limitation of this method is that by attempting to replicate the iam scenario as closely as possible in the power system model the risk arises of over constraining the optimization that affects its optimality a complementary approach could be to apply the optimization in context of the iam scenario by making use of projected variables such as electricity demand and commodity prices while allowing the power system model to optimize the long term development of generator portfolios and balancing assets without further constraints this would allow for an actual comparison of the optimal long term planning in the integrated context in the iam versus an optimized long term planning in the power system model from a solely operational power system perspective however modelling in plexos world indicates that performing long term planning exercises in detailed global power system models can be computationally challenging and requires further examination to find appropriate trade offs between modelling resolution and computational time an average model run of plexos world based on the 2050 snapshot analysis in context of this study takes approximately 12 h other study limitations are specific to the proof of concept linking messageix globiom and plexos world for example related to the practical implementation of the different framework steps the applied spatial demand downscaling uses projected demand values as proxy retrieved by means of multivariate linear regression besides the fact that the used values for the regression are for the period 1980 2014 the main limitation of this approach is that historic values are not fully representative for future developments when it comes to electricity demand forecasting due to among others expected increasing electrification in final energy demand that said the projected values are solely used as proxy for the downscaling actual final demand values at an aggregate regional level are equal to the scenario output from messageix globiom more advanced energy downscaling methods designed for iam scenario data have become recently available that can be used for future studies sferra et al 2021 another simplification is the fact that for the temporal demand downscaling demand timeseries in the plexos world model for 2050 are linearly scaled compared to historical timeseries whereas it can be expected that the shape of diurnal electricity demand in the future might change among others due to uptake of electric vehicles future work can address this by using reported sectoral electricity demand from iams as foundation for adjusting demand timeseries like all modelling tools plexos world has its limitations and uncertainties that affect the accuracy of results for the proof of concept as of now the model does not include demand for other energy carriers that indirectly affect how much electricity needs to be supplied for example green hydrogen demand for transport and heating these differences in sectoral coverage contribute to observed differences in model outputs for factors such as technology generation values and cfs for plexos world compared to a sector coupled model like messageix globiom future applications of the model will need to take these intersectoral dynamics into account to be able to compare model outputs with iams in a level playing field furthermore in the used version of plexos world electric vehicles and demand side management are not included which reduces the ability of the power system to compensate for variability in supply demand side management is not actively incorporated in messageix globiom in relation to system flexibility yet electric vehicles can contribute to curtailment reduction and overall system flexibility another important factor is that the sampling approach used for deriving representative timeslices as applied for the capacity allocation exercise in plexos world has to be assessed in more detail increasing the number of timeslices for the full global model is computationally challenging hence it would have added value to benchmark the results with single region model simulations with enhanced time slicing next to the above additional model runs to assess sensitivities and uncertainties on a range of parameters and assumptions such as costs for transmission infrastructure perfect market and foresight assumptions power system adequacy and reliability constraints climatic impact on renewable resource potential switching to different weather years for vres cf timeseries collins et al 2018 and overall to analyse a wider range of scenarios and snapshot years could increase the robustness of the results 5 conclusion this study proposes a novel methodological framework for soft linking of continental or global iams with detailed global power system models by means of a proof of concept application of the soft link framework linking global iam messageix globiom with global power system model plexos world the results of this paper highlight the usefulness of the framework by feeding in to known limitations of global iams as a result of limited modelling resolution and power system representation the spatially and temporally detailed modelling in plexos world of scenarios coming from messageix globiom has identified a number of key limitations in messageix globioms power system representation that affect its accuracy of results overall the results reflect that messageix globiom and global iams in general are not constructed with the aim to perform spatially and temporally detailed assessments of power system dynamics that said it is the authors view that this not necessarily means that global iams are unsuitable for providing boundaries in possible mitigation pathways for the development of the global energy system from a multi disciplinary perspective from a solely power system point of view tools like plexos world would be better suited to optimize the long term planning of the global power system yet as it stands computational requirements for global model simulations without compromising on modelling resolution do not permit simulations for long term horizons furthermore the lack of interaction with other sectors in the energy system and with ecological and economical systems gives power system models a narrow scope considering limitations of both sets of models we conclude that iams can be applied for providing insights in possible long term development pathways for the global energy system and to inform global climate and energy policy assuming benchmarking with dedicated sectoral models occurs regularly by making use of the soft link framework proposed in this study power system models like plexos world can be used in a complimentary fashion to pinpoint areas for model informed improvements in global iams the framework can furthermore be used as a template for soft linking of global iams to other dedicated sectoral models declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the support provided by energy exemplar and science foundation ireland sfi through the marei centre for energy climate and marine grant no 12 rc 2302 p2 j g is supported by a research grant from sfi and the national natural science foundation of china nsfc under the sfi nsfc partnership programme grant no 17 nsfc 5181 part of the research was developed in the young scientists summer program yssp at the international institute for applied systems analysis iiasa laxenburg austria we would like to express our gratitude towards members of the energy climate and environment ece program of iiasa for providing feedback on the methodology and results as included in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105336 
25616,this work presents a methodology for analyzing the influence of urbanization in a long term approach on the number of floods in an urban catchment the mathematical model presented for predicting the multiannual number of stormwater floods accounts for dynamic changes in the urban catchment in the subsequent years covered by the simulations logistic regression was applied to predict flooding occurring during rainfall events the model may be applied to catchments with different characteristics the assumed solution allows the development of early warning systems by modeling the occurrence of stormwater flooding in a studied catchment area based on the identification of the rainfall origin to verify the simulations with a mathematical model an innovative concept based on a hydrodynamic model is used this concept includes the changes in the impervious area that occur during the simulation period keywords logistic regression stormwater flooding urban catchment swmm computer software ovfsim ver 1 1 introduction climatic changes and progressing land use changes driven by urbanization are leading to an increase in runoff streams from catchments hettiarachchi et al 2018 zhou et al 2019 this in turn leads to an increase in the amount of contaminants directly introduced into receivers mostly rivers disturbing their ecological balance astaraie imani et al 2012 miller and hutchins 2017 müller et al 2020 an increase in the number of storm overflows the overfilling of structures in stormwater networks and an increase in the number of sewer floods have been observed these factors negatively influence the quality of life in cities and result in significant material losses caused by intense rainfall events therefore to limit the occurrence of unfavorable phenomena in stormwater systems as well as to improve the operating conditions of stormwater networks there is a need to model these systems barbosa et al 2012 kirshen et al 2015 baek et al 2015 gdv 2016 leandro and martins 2016 when measuring the operation of stormwater systems the number of sewer floods is very significant these system functions are regulated by appropriate guidelines mark et al 2004 dwa a 118e 2006 teng et al 2017 moreover the occurrence of floods has a strong influence on the living standards of inhabitants in urbanized areas and this is reflected in the costs of the services offered in city centers huong and pathirana 2013 a review of the literature siekmann and pinnekamp 2011 willems 2013 hammond et al 2015 schmitt and scheid 2020 szeląg et al 2021 indicates that floods in urbanized catchments should be considered an important indicator that should be accounted for during stormwater network modernization depending on the number of floods applying appropriate sustainable development solutions for urban catchments may also be necessary which would affect the management of water resources this concept has been confirmed by an increasing number of studies on the topic zhou et al 2012 huong and pathirana 2013 hegger et al 2016 jato espino et al 2016 wang et al 2018 in which state of the art design solutions and the materials contributing to surface runoff reductions were discussed meerow and newell 2017 these results lead to the improved hydraulic conditions of stormwater systems and thus decrease the occurrence of stormwater floods as well as their volumes currently to assess the operation of a stormwater network and simultaneously establish the number of sewer floods in an area it is necessary to carry out constant simulations using a hydrodynamic model representing the catchment and at least 30 years of rainfall characteristics schmitt et al 2004 guo and dai 2009 thorndahl 2009 muhaisen et al 2009 collecting data in this way is difficult as indicated by the fact that many studies involve designing tools for predicting synthetic rainfall events thorndahl and willems 2008 fu and kapelan 2013 fu and butler 2014 however since these models are local in nature it is necessary to collect data on the specific catchment and stormwater network and perform high resolution measurements of the rainfall depths and flows in the region this is not always economically viable moreover due to the strong interactions among the parameters identified in the model and technical problems at the stage of carrying out measurements the obtained models are not always characterized by satisfactory prognostic abilities this has been confirmed by a number of papers fu et al 2011 chen et al 2012 2018 fraga et al 2016 in which the influences of the uncertainties of the collected data type of land development stormwater networks rainfall and flow data flooded areas etc and identified model parameters on the simulation results were investigated these data are of great importance because they create the basis for selecting appropriate solutions aimed at improving the operating conditions of stormwater networks elliott and trowsdale 2007 currently the influences of changes in catchment imperviousness land use and stormwater networks have been discussed in numerous works miller et al 2014 fraga et al 2016 paule mercado et al 2017 recanatesi and petroselli 2020 calculations concerning the influence of climate change and complex catchment imperviousness values appropriately varied have also been performed shuster et al 2005 jacobson 2011 huong and pathirana 2013 their influences on the variabilities of stormwater flows flooding volumes and the number of overflowing manholes have thus been determined notaro et al 2015 eshtawi et al 2016 however the dynamics of changes in catchment imperviousness have only been discussed to a limited extent this is important because in line with the literature data guan et al 2015 land use changes dynamically affect the operating conditions of stormwater networks at present there are no calculation tools that can be employed without calibration for urban areas with varied land use types catchment areas catchment imperviousness degrees road surfaces lengths of stormwater networks etc such a solution would be highly useful and enable rapid analyses of stormwater system operation at the planning stage of the spatial development of urban areas this type of solution would be a highly practical tool enabling appropriate decision making connected with the rate of city development this ability is essential with regard to the standards of living of urban residents as well as the functioning of cities examples of work that used statistical models to simulate sewer floods can be found in the literature thorndahl and willems 2008 applied the form method first order reliability model to simulate flooding of manhole in an urban catchment located within denmark however the solution they proposed had a local character with no possibility of being applied to other catchments the developed statistical models to identify stormwater floodings in small urban catchments based on classification tools have focused on stormwater flooodings from a single manhole jato espino et al 2018 li and willems 2020 in these models the identification of stormwater flooding jato espino et al 2018 requires an parametrization of the stormwater network the characteristics of the catchments and the frequency of rainfall events a similar solution was employed by li and willems 2020 who analyzed of the two catchments ghent and antwerp in belgium in that model a number of parameters connected with the channel retention water depth in the manhole and time concentration were considered the proposed solutions are an alternative to the hydrodynamic models used including the resolution of the collected rainfall data which can be reduced because the effect of the temporal rainfall pattern on the occurrence of stormwater flooding in the catchment has not been demonstrated thorndahl 2009 jato espino et al 2018 2019 li and willems 2020 however in their analyses the authors omitted the uncertainty of the catchment model which in the context of the literature data fraga et al 2016 szeląg et al 2021 affects the calibration results and the flooding simulations the proposed input data required extensive knowledge on the course of the stormwater network and the hydraulic conditions in pipes therefore the implementation of these models under stormwater network extension and or catchment extension and modernization conditions may be hindered due to problems with the acquisition of accurate input data for the calculation models when modeling the identification of stormwater flooding from the literature review presented above it seems that the problem of sewer floods continues to be recognized within a limited scope from the point of view of stormwater network operation it is unknown whether flooding can be identified based on simplified rainfall data e g rainfall origin data it is currently known that simulating of rainfall is complex and the results obtained from these simulations are not always consistent with measurements this situation appears to be the case regarding the identification of the rainfall origin this problem usually disappears when identifying rainfall events caused by processes occurring in the zones on the border of air masses with various thermal characteristics thorndahl and willems 2008 fu and kapelan 2013 the literature data wasko and sharma 2015 cristiano et al 2017 hettiarachchi et al 2018 cheng et al 2019 show that more and more often the temporal rainfall pattern determining the occurrence of problems with stormwater system operation flooding inundation etc resulting in material losses and deterioration of the quality of life in cities are sought at the stage of modeling hydrological processes in urban catchments the short intense rainfall events are important from the point of view of stormwater system operation as they cause the maximum hydraulic overload of the system li and willems 2020 the analyses conducted by szeląg et al 2020 indicated that rainfall origin data may be useful for identifying stormwater overflow structures therefore the information about the rainfall origin collected online can be part of predicting the performance of the stormwater system and developing an early warning system for urban drainage flooding garcía bartual and andrés doménech 2017 and balbastre soldevila et al 2019 2021 developed convective rainfall simulation models for valencia spain that used in modeling and improving the stormwater network performance the attempts to determine idf intensity duration frequency curves for short intense rainfall events in mexico are given in the study of alfonso gutierrez lopez et al 2019 the great importance of heavy rainfall has also led to the development of maximum rainfall maps for the city of graz austria maier et al 2020 which using a hydrodynamic model allows the identifying problematic locations in the stormwater network the role of convective rainfall resulting from its origin is beginning to be increasingly recognized as models are being developed to simulate sewers under extreme overload conditions wang et al 2019 this is supported by the attempts to develop the models to identify rainfall thresholds for determining the events that may lead to stormwater flooding dao et al 2021 rainfall origin with an emphasis on convective rainfall has been used in flood analysis kreienkamp et al 2021 in july 2021 in eastern europe in addition to rainfall origin the temporal rainfall pattern is important in modeling the stormwater system performance area volume depth of the stormwater this is confirmed by the results of simulation performed for stormwater networks using hydrodynamic catchment models therefore the number of models for rainfall simulations is increasing multidimensional rainfall distributions using copula functions modifications of the monte carlo method accounting for the temporal rainfall pattern vandenberghe et al 2010 vernieuwe et al 2015 szeląg et al 2021 in this context it seems advisable to introduce modifications at the stage of creating models for their simulation in such a way as to separate the rainfall events that may lead to problems with the stormwater network operation therefore it is reasonable to divide rainfall events based on their origin convective in air mass frontal in a convergence zone and to compare the obtained results in relation to these types the modeling the operation of the stormwater system and the facilities located within taking into account the rainfall origin seems to be justified and can contribute to a significant risk reduction by minimizing the expected effects in an urbanized catchment identification of the origin type of rainfall from a few to several hours in advance is possible through the analysis of short term weather forecasts these forecasts allow the determination of numerous physical parameters of the atmosphere and consequently they enable to predict phenomena and processes occurring in it in addition to the stages of development convective flows in the air mass as well as the rate of movement of weather fronts and centers of low atmospheric pressure as a result of their analysis it is possible to determine the rainfall origin and thus to estimate its duration rainfall depth and average intensity this approach is supported by the fact that mesoscale numerical weather prediction models are used to develop large scale weather forecasts the results of which are often presented online open source license in an clear graphical form meteograms detailed maps animations thus they can facilitate the work in dispatching centers responsible for urbanized catchment management among the mesoscale weather models due to their practical use in the prediction of rainfall with high depth or intensity the weather research and forecasting wrf model is noteworthy which is the result of the collaboration of several u s institutions weisman et al 2008 chawla et al 2018 rogelis and werner 2018 da cunha luz barcellos and cataldi 2020 chang et al 2020 it uses high resolution geographic data including topography and land use relatively few studies have discussed how dynamic urban changes in catchments influence the functioning of stormwater networks mikovits et al 2014 löwe et al 2018 taking into account the complex physics of the stormwater flooding phenomenon in urban catchments and the necessity of accumulating data on land development and stormwater networks an innovative software tool was developed for simulating the influence of catchment characteristics and their changes in the calculation period as well as the rainfall origin on the number of stormwater floods in the applied approach the focus was placed on well known independent variables describing stormwater floods that are easy to identify and do not require conducting multiannual online studies governing the possibility of model application the proposed solution was developed to be available for a wide range of users including administrative bodies during the preparation of land development plans and stormwater network construction when access to detailed catchment and stormwater network data is limited the model takes into account a single rainfall event analyzes the time period and includes the possibility of analyzing the influence of dynamics of changes in catchment characteristics catchment imperviousness density of stormwater network together with the origin of rainfall on flooding the obtained results indicate that at the stage of the sustainable development of a catchment it is possible to choose the spatial development concept of land on annual basis to limit the number of floods and decrease the negative effects of high rainfall intensities 2 methods the study presented a mathematical model for simulating stormwater foods in small urban catchments in relation to a single rainfall event and the assumed period of time a year two years or longer the model creation and the analysis of the stormwater network operation using the developed model involved twelve steps fig 1 step 1 consisted of the collection of data necessary for the model to predict stormwater flooding in a rainfall event the model was developed by using the obtained stormwater network operation results accounting for the identification of stormwater flooding events to indicate an individual stormwater flood in a catchment during an independent rainfall events the following parameters were determined rainfall temporal pattern depth and duration and the characteristics of the catchment area of the catchment impervious area of the catchment length of the main channel in the catchment maximum difference of the land coordinates in the catchment such as height difference in step 2 a logistic regression model was created to identify stormwater flooding in a rainfall event simultaneously the model enables the identification of independent variables the evaluation of the predictive capacity of the model and the carrying out of the model sensitivity analysis in step 3 a verification of the calculation results obtained from the proposed model was performed using a calibrated hydrodynamic catchment model created in swmm storm water management model software thus the obtained logistic regression model lr was employed for further analyses in step 4 the rainfall events were separated into time series and the obtained data were grouped according to the rainfall origin step 5 hence the empirical and theoretical distributions of rainfall characteristics contributing to stormwater flooding in a rainfall event were determined step 6 the theoretical distributions were determined by means of bootstrap versioning of the univariate goodness of fit test results hence synthetic rainfall generators based on the monte carlo method accounting for the diversified rainfall characteristics depending on the rainfall origin were developed step 7 continuous rainfall measurements over a 45 year period were used to develop the synthetic rainfall generator on the basis of the logistic regression model and synthetic rainfall generator simulations were conducted to determine the influence of the rainfall origin and urban catchment characteristics on the probability of stormwater flooding in a given rainfall event with a given mean rainfall intensity step 8 as well as the number of stormwater flood events in a given catchment step 9 the dynamics of changes in catchment characteristics on the number of stormwater flood events step 10 and the variable number of annual rainfall events on the number of stormwater flood events step 11 the differentiation of the number of annual rainfall events stems from the stochastic nature of rainfall events the accounting of rainfall genesis in a computational model can be an important aspect of an early warning system for use against the threat of air circulation dynamics affecting the intensity of rainfall processes in the troposphere resulting in high rainfall depths or intensities to verify the obtained number of stormwater flood events in a specific catchment during the calculation period 1 2 or 5 years continuous simulations were performed with the calibrated hydrodynamic model step 12 consecutive steps 1 12 enumerated in the calculation algorithm fig 1 are discussed in detail in subsequent sections 2 1 software on the basis of the calculation algorithm presented in fig 1 the original computer software ovfsim ver 1 was developed by the authors in r and used to model the number of stormwater flood events in a catchment the developed software tool consists of four independent modules fig 2 the first module input data was fed data to create a logistic regression model based on the rainfall data and urban catchment characteristics in line with step 1 shown in fig 1 the data import was carried out using the rio library any import function can be used for this purpose in the second module the stormwater flooding simulator on the basis of the imported data a logit model for predicting stormwater flooding in a rainfall event was created the independent variables were identified and the measures of fit between the calculation and measurement results were determined the logistic regression model was created using the logit function of ovfsim the goodness of fit of the model was evaluated by means of the roc curve using the rocit function of rocit this enabled to determine the optimal probability value of classifying p states based on the yourden criterion in line with step 2 moreover a local sensitivity analysis was performed in this module based on the logit model in addition the sensitivity coefficients of the assumed rainfall data and catchment characteristics were determined in the third module rainfall simulator the rainfall events separated from the time series were imported into the r environment by means of the import function of rio in line with step 4 shown in fig 1 on the basis of the assumed criteria for rainfall classification these events were grouped into homogeneous classes then convective frontal and convergence zone rainfall events were separated step 5 thus the empirical and theoretical distributions of the rainfall data were determined step 6 the theoretical distributions of the rainfall characteristics were fitted using the fit distribution and rain dist functions of ovfsim delignette muller and dutang 2015 in the fourth module simulations of synthetic rainfall time series were carried out by means of the mc and mc logit functions of ovfsim step 7 using the created logit model rl the following tasks were solved the influences of the theoretical distributions of the rainfall data and catchment characteristics on the probability of stormwater flooding in a given rainfall event and for a given mean rainfall intensity step 8 were determined by means of the mc logit function of ovfsim for the simulated distributions of the rainfall data and catchment characteristics the empirical cumulative distribution functions were determined using the ggplot2 data visualization package the numbers of stormwater flood events in the catchment throughout the calculation period resulting from convective frontal and convergence zone rainfall were modeled for the assumed tested catchment characteristics step 9 the mc logit function of ovfsim was used to model stormwater flood events for the set rainfall parameters and selected catchment characteristics the number of stormwater flood events in the catchment resulting from the convective frontal and convergence zone rainfall events associated with the dynamic changes in catchment characteristics that occurred during the calculation period were modeled using the mc logit procedure of ovfsim it enabled dynamic changes in the imperviousness parameters and unit length of the main channel in the catchment area per the impervious area while simultaneously maintaining the correlations among the analyzed characteristics using the iman conover method the number of stormwater flood events occurring in the catchment for the assumed rainfall characteristics during the calculation period was modeled while accounting for the stochastic nature of the number of rainfall events throughout a year step 11 the mc logit function of ovfsim was also employed in this case 2 2 research area step 1 the subject of investigation includes four subcatchments a b c and d located within the si9 canal within kielce fig 3 the city is found in the central part of poland and is the capital of the świętokrzyskie voivodeship the average population density of the city is 19 5 people ha and in the study area the average population density is 21 4 people ha the analyzed stormwater system is a separate sewage system stormwater runoff from the catchment area is drained directly by the s1 main channel to the diversion chamber dc in cases in which the stormwater depth is no higher than 0 42 m the stormwater is directed to the stormwater treatment plant stp after exceeding this value stormwater is discharged through an overflow ov into the silnica river the analyses showed that the annual rainfall depth was 537 757 mm and the number of days with rainfall ranged from 155 to 266 the average annual air temperature varied between 8 1 c and 9 6 c while the number of days with snowfall was between 36 and 84 constant monitoring of the stormwater flowing out of the catchment showed that during dry weather stormwater flowed from the catchment at discharges between 0 001 and 0 011 m3 s this resulted from the infiltration of water to stormwater channels as indicated by a field inspection lisowska and szeląg 2014 the choice of subcatchments for this study resulted from their varying characteristics see table 1 and the relatively small distances between them these factors made it possible to simultaneously carry out field studies in all subcatchments the selected characteristics of subcatchments a b c and d are given in table 1 in turn fig 4 shows the scheme of a virtual catchment with a stormwater network described using the characteristics given in table 1 f area of the catchment imp impervious area of the catchment ltot length of the main channel in the catchment dh maximum difference of the land coordinates in the catchment height difference lk length of the main channel measured from point xa b c d to the dc diversion chamber impu imperviousness of the downstream area point xa b c d gk unitary length of the main channel in the catchment per impervious area fimp impervious area in the catchment in which flooding was observed fu area of the stormwater catchment below the analyzed cross section xa closing catchment a downstream fimpu area of impervious downstream xa vk volume of the main collector discharging downstream from diversion chamber dc to the cross section closing catchment a as a part of the continuous monitoring campaign from 2008 to 2019 water level and flow measurements were carried out using a mes1 flow meter located at a distance of 4 0 m before the diversion chamber dc the flow values were noted with a 1 min resolution in the same period field studies of stormwater flooding in sub catchments a b c and d were also carried out the identification of periods with rainfall events potentially resulting in flooding in the considered multiannual period was possible based on downscaling short term numerical analyses of weather forecasts determined by the interdisciplinary centre for mathematical and computational modeling of warsaw university https mapy meteo pl as well as those published by the institute of meteorology and water management of the national research institute https meteo imgw pl the first were based on the results of the met office unified model um with a horizontal resolution of 4 km brown et al 2012 whereas the second were based on the wrf model resolution 2 5 km and cosmo model 2 8 km alaro 4 km and arome 2 km developed by the european consortium for small scale modeling dierer et al 2009 klasa et al 2018 the rainfall depth measurements taken prior to flooding and during the course of flooding were performed using a seba rain gauge with a 1 min resolution located within the si9 catchment szelag et al 2016 during the study period the flood measurements in the studied subcatchments a b c and d covered 159 rainfall events stormwater floods occurred in 41 of these events szeląg and drewnowski 2019 the approaches taken to select catchments and conduct measurements were in line with those used in studies conducted by other researchers thorndahl and willems 2008 fu and butler 2014 jato espino et al 2018 li and willems 2020 who carried out stormwater flooding measurements in urban catchments in england finland and belgium a flooding event was defined as a situation in which due to an insufficient drainage network capacity stormwater accumulated locally and flooding occurred in other words a situation in which the stormwater depth at the manhole node exceeded the ground level jato espino et al 2018 2019 li and willems 2020 the assumed criterion corresponded to the flooding conditions as confirmed in previous papers on this topic chang et al 2021 gebreegziabher and demissie 2020 2 3 logistic regression step 2 logistic regression i e the binomial logit model is a classification model comprising supervised learning methods methods with teachers and was applied to analyze the relationships between predictors and response variables of binary types zero and one in contrast to other models random forests regression trees neuron networks and the linear discriminative model this method enables modeling of the probability of the occurrence of an event phenomenon process etc moreover the relationship obtained using the logit model has an explicit form in which the coefficients allow individual independent variables associated with the analyzed phenomena to be assessed the numerous advantages of the logistic regression model mean that it is applied in many fields of science from economics medicine microbiology and ecology bagley et al 2001 harrell 2001 heyer and stamm 2013 to the simulations of processes in wastewater treatment plants and the modeling of stormwater network operation jato espino et al 2018 szeląg et al 2019 the logit model is a particular case of a generalized linear model glm which takes the following form 1 f μ α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k where α0 is the intercept α1 α2 αq are the empirical coefficients established using the maximum likelihood method xk denotes the independent variables the characteristics of the catchment area table 1 and rainfall in separated events were assumed i e depth and duration maximum 20 30 min rainfall depth in a rainfall event jato espino et al 2018 zhou et al 2019 li and willems 2019 2020 and f is the link function determining the relationship of the average value of the explanatory variable with the linear combination of predictors the identification of independent variables was performed with the forward stepwise algorithm which is preferred for logistic regression models senaviratna and cooray 2019 assuming that μ p and introducing the link logit function the modeled values of the dependent variables can be transformed into the binary form 2 f p f μ l o g i t p l n p 1 p α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k by applying the appropriate transformations to equation 2 the following expression can be written 3 p e x p α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k 1 exp α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k on the basis of equation 3 the probability of the occurrence of stormwater flooding in a rainfall event can be determined at the same time it is necessary to determine the minimum p value that is exceeded when a flood occurs there are some techniques for determining the best p threshold based on the roc curve takahashi et al 2006 beger 2016 such as the youden criterion or geometric mean criterion youden 1950 roc curves were also employed to assess the goodness of fit the flooding occurrence applied in the logit model as p 0 5 is universal equally accounting for the odds of the occurrence of either phenomena flooding and the lack thereof another approach to estimating the best p threshold is the use of the precision recall curve maximizing the harmonic mean which is defined as follows 4 f 2 p r e c i s i o n r e c a l l p r e c i s i o n r e c a l l where precision is the ratio of the number of true positives divided by the sum of the true positives and false positives and recall is calculated as the ratio of the number of true positives divided by the sum of the true positives and the false negatives mei and radev 2016 in some classification tasks one of the sensitivities or specificities is the most important to the researcher in such a situation the p threshold can be determined based on the sensitivity specificity trade off nevertheless p 0 5 was assumed to be a boundary condition in the software because the capacity of the model to be generalized for application to new sets of rainfall events with completely different catchment characteristics was the primary goal a boundary condition that is optimal for one set of data may be suboptimal for another observation set chen et al 2006 to assess the predictive abilities of the logistic regression model a confusion matrix arboretti and salmaso 2007 kononen et al 2011 was applied along with the following metrics accuracy 5 a c c t p t n t p t n f p f n sensitivity 6 s e n s t p t p f n and specificity 7 s p e c t n t n f p where t p t n f p and f n denote true positives correctly identified overflows true negatives correctly identified lack of overflows false positives lack of overflows incorrectly identified as overflows and false negatives overflows incorrectly identified as lack of overflows respectively the prepared logit model was verified by means of a calibrated catchment model fig 3 and by performing calculations for the selected rainfall events a local sensitivity analysis was performed based on the developed logit model this is a commonly employed approach used to analyze sensitivity in hydrological and hydraulic models morio 2011 pianosi et al 2016 the conducted analyses of the impacts of selected independent variables on the probability of occurrence of stormwater flooding in a rainfall event involved the local sensitivity analysis one factor at a time analysis a relative change in the kinetic parameters at 5 of their default values was used to calculate the sensitivity coefficient sx i as follows petersen et al 2002 8 s x i δ y δ x x y y x 0 i δ x i j y x 0 i j x 0 i δ x i x 0 i x 0 i y x 0 i j where xi is the model input parameter and yj is the model output variable on the basis of equation 8 it can be stated that the determined sxi value depends on the initial xo i values therefore the influence of rainfall data on the sxi values was analyzed with regard to the ranges of the variable catchment characteristics table 1 2 4 logit model verification with the calibrated hydrodynamic catchment model swmm step 3 to assess the functioning of stormwater networks and subcatchments located within them subjected to stormwater flood observations a hydrodynamic model of the catchment elaborated in swmm software was used fig 3 the total catchment area equaled 62 ha the areas of catchments a b c and d equaled 8 07 ha 3 45 ha 6 16 ha and 7 02 ha respectively the model comprised 55 subcatchments with areas of 0 12 2 10 ha the model was built of 200 nodes representing manholes and 72 channels catchment a comprised 3 subcatchments 10 manholes and 11 channels catchment b consisted of 4 subcatchments 12 manholes and 11 channels in turn catchments c and d included 4 subcatchments 10 manholes and 11 channels each the identification of the model parameters was carried out using the results concerning the variabilities in flows and stormwater flooding events in subcatchments a b c and d since 2009 szeląg 2013 2021 the deterministic and probabilistic calibration of the model glue sa relative to the simulations of hydrographs obtained within the studied catchment the operation of the stormwater treatment plant and the overflows showed that the model predicted the abovementioned processes with high accuracy this has been discussed in detail in the papers published by szelag et al 2016 and kiczko et al 2018 in the catchment model the retention values of the impervious and pervious areas equaled 2 5 mm and 6 0 mm respectively for a weighted average value of 3 80 mm the manning s roughness coefficient values for the impervious and pervious areas were 0 015 m 1 3 s and 0 15 m 1 3 s respectively the calibration szelag et al 2016 showed that the mean manning s roughness coefficient value of the stormwater network channels was equal to 0 018 m 1 3 s due to the methodology of identifying sewer floods in individual analyzed research catchments the simulation calculations conducted using the prepared catchment model relied on the verification and confirmation of whether a stormwater flood occurred during the course of an observed rainfall event in the areas of subcatchments a b c and d for a selected rainfall event in an appropriate catchment the probability of a flood occurrence p was calculated using equation 3 simultaneously the stormwater system operation in the investigated catchment was simulated by determining the manhole overflows if a flood was observed in the area of a catchment for a given rainfall amount and was also predicted by the model based calculations using swmm and the determined p value for the analyzed rainfall event was greater than the cutoff threshold the agreement of the swmm results with the logit model was assumed 2 5 rainfall data for model 2 5 1 separating independent rainfall events and their origin steps 4 and 5 in this paper the source material included data collected from may october of 1961 2005 the data were obtained using a traditional float pluviograph recording the rainfall depth duration and mean intensity installed at the imgw meteorological station in kielce the dwa a 118e 2006 guidelines served as the basis for separating independent rainfall events in this manner the period between subsequent rainfall events was 4 h whereas the minimal rainfall depth of an event equal to 3 0 mm was in accordance with fu and kapelan 2013 and fu and butler 2014 each of the rainfall events was assigned an origin convective in an air mass frontal or in a convergence zone the allocation of the separated rainfall events to particular origin types was performed based on the analysis of synoptic situations and local weather conditions at the station in kielce the rainfall origin was determined on the basis of surface synoptic charts of europe every 12 h published in the daily meteorological bulletin of the institute of meteorology and water management in warsaw and a calendar describing atmospheric circulation air masses and atmospheric fronts covering southern poland niedźwiedź 2019 the aforementioned calendar has been used in numerous scientific studies e g lupikasza 2010 twardosz et al 2011 bartoszek and skiba 2016 wypych et al 2018 szeląg et al 2020 while separating the rainfall characteristics in time series for modeling stormwater floods in a rainfall event the authors were guided by the information found in the literature zhang and singh 2007 thorndahl et al 2008 zhou et al 2019 indicating that the analyzed phenomenon was affected by the rainfall depth duration and mean intensity and by the maximum instantaneous rainfall depth in a rainfall event in the period of 1961 2005 1526 rainfall events were observed in the kielce in which the total rainfall depth was greater than 3 mm average of 33 8 events per year the majority 723 of these events were of frontal origin approximately 16 events per year these rainfall events lasted for 2 5 10 5 h they were connected with the movements of atmospheric fronts quickly moving cold fronts along with the dynamic processes occurring within their zones generated high rainfall intensities during rainfall events lasting for 2 5 5 5 h max 54 l s 1 ha 1 as shown in fig 5 the maximum 20 min rainfall intensity recorded during one of these events equaled 18 4 l s 1 ha 1 pt 20 0 1 29 2 mm whereas for 30 min rainfall events the maximum intensity equaled 24 7 l s 1 ha 1 pt 30 0 1 33 4 mm in turn the processes in the warm front zone caused generally higher rainfall depth however due to their long durations 5 5 10 5 h their intensity was even halved up to 11 l s 1 ha 1 the 20 min rainfall intensity in these events was equal to 17 6 l s 1 ha 1 pt 20 0 1 16 8 mm while for 30 min rainfall events the intensity was 20 1 l s 1 ha 1 pt 30 0 1 20 3 mm the mean annual number of rainfall events caused by convection in air masses reached 14 3 the duration of these rainfall events in kielce did not exceed 150 min these events were characterized by low depths that rapidly increased along with the duration up to 40 5 mm over 137 min these rainfall events had high mean intensities reaching 136 l s 1 ha 1 fig 5 the mean 20 min rainfall intensity in these events reached 11 2 l s 1 ha 1 pt 20 0 1 24 8 mm whereas that of the 30 min events was 14 0 l s 1 ha 1 pt 30 0 1 28 1 mm rainfall events in convergence zones occurred in kielce 2 3 times a year on average their origins were connected with deep centers of low atmospheric pressure or a series of low pressure centers highly dynamic and high magnitude processes caused long lasting rainfall events 10 5 h with increasing rainfall depths max 155 2 mm but these events did not have very high mean intensities not exceeding 22 l s 1 ha 1 szeląg et al 2020 the maximum 20 and 30 min rainfall intensities recorded during these events were comparable and reached 4 7 l s 1 ha 1 pt 20 0 2 21 7 mm and 5 0 l s 1 ha 1 pt 30 0 2 21 6 mm respectively 2 5 2 determination of the empirical rainfall distribution and fitting the theoretical distribution using bootstrap versioning of the univariate goodness of fit test results step 6 on the basis of the selected rainfall events the time series of rainfall events with different origins convective in air mass frontal convergence zone were determined based on their durations next the empirical distributions of the selected rainfall data were indicated and fitted with theoretical distributions to obtain the best possible fit between the theoretical distributions and empirical data continuous data the following distributions were considered gamma gev log normal exponential pareto and weibull guo and adams 1998 adams and papa 2000 guo et al 2018 the assessment of correspondence of the empirical and theoretical distributions was performed using the bootstrap version of the kolmogorov smirnov k s test with stephenson modification the anderson darling test and the cramer von mises test darling 1957 anderson 1962 stephenson 2002 razali and wah 2011 the whole monte carlo simulation procedure in goodness of fit testing was presented in savapandit and gogoi 2015 the proposed number of resampled data was 40 times larger than the number of samples in the original data wang et al 2011 there are two types of bootstrap estimations namely parametric and nonparametric estimations the former is more popular in the context of goodness of fit testing in which samples are drawn from theoretical distributions with parameters estimated based on the original data in the other estimation samples are drawn from original data the main reason the resampled version of the k s test was used was that the distribution parameters were estimated from the data the issue with the classical kolmogorov smirnov goodness of fit test in such situations has been widely commented on stephens 1974 d agostino 2017 a total of 5000 samples were taken for the simulation and a nonparametric approach was used savapandit and gogoi 2015 for empirical distributions covering the number of rainfall events in the assumed time period t 5 10 years the following distributions were analyzed poisson s and geometric guo and dai 2009 to assess the compatibility of the matching empirical and theoretical distributions the χ2 values were calculated nist sematech 2012 2 5 3 synthetic rainfall generators the monte carlo method step 7 the mathematical model employed the synthetic rainfall generator created for modeling the operating conditions of a storm overflow as discussed by szeląg et al 2020 this approach accounted for the possible correlations of independent variables in the logit model to the identification of stormwater flooding in a single rainfall event the iman and conover 1982 modification in the stratified latin hypercube sampling monte carlo method was employed for this purpose yin et al 2011 schmidt et al 2019 in the applied approach the rainfall data were separated according to their origin convective frontal or in a convergence zone and rainfall simulations were carried out independently for each group apart from the rainfall origin this paper analyzed the impact of rainfall generator simplifications on the results of stormwater flood events simulations in the assumed period of time two approaches were analyzed in the work in the first approach the number of stormwater flood events was calculated by assuming the mean annual number of rainfall events convective frontal and convergent zones in the synthetic rainfall time series obtained in this way the number of rainfall events in t consecutive years was constant in turn in the other approach based on the theoretical distributions of the annual number of rainfall events of the appropriate origin the number of rainfall events over a given year was first modeled followed by the rainfall characteristics for instance 5 year synthetic rainfall time series were obtained by combining five independent synthetic rainfall time series szeląg et al 2020 2 6 calculation of the influence of catchment characteristics and rainfall origin on the probability of stormwater flooding in a rainfall event step 8 based on the synthetic rainfall generator szeląg et al 2020 calculations of statistically significant rainfall data were performed n 10 000 samples with a stratified monte carlo method iman conover these analyses were conducted for convective and frontal rainfall events and for rainfall events that occurred in convergence zones the obtained calculation results were substituted into equation 6 and the probability of stormwater flooding in a single rainfall event p caused by rainfall with the defined origin was calculated for the assumed catchment characteristics table 1 shows only the statistically significant outputs at the assumed confidence interval in each of the samples convective frontal and convergence zone rainfall each involving 10 000 simulations based on the determined p value the indicated number of stormwater flood events was identified for the cases in which the determined p value indicated rainfall flooding in a rainfall event the mean rainfall intensity equal to i 166 7 ptot tr l s 1 ha 1 was determined based on the pf value calculations for convective frontal and convergence zone rainfall as well as the determined values the empirical distribution function cumulative density function cfd was used using the obtained calculation results p and novf denoting the number of stormwater flood events in a rainfall event in 10 000 samples histograms were created first then the probability density distributions and on their basis the cumulative density distributions were determined 2 7 modeling the number of flood events in the catchment considering the rainfall origin step 9 the methodology for determining the number of stormwater flood events was based on a logit model equation 3 and a synthetic rainfall generator accounting for the rainfall event origins the mean annual numbers of rainfall events m caused by convective mconv frontal mfron and convergence zone mc zone rainfall given in section 2 5 1 were assumed for the calculations to model the t yearly synthetic rainfall time series using the rainfall generator m t n simulations were carried out for convective frontal and convergence zone rainfall the applied approach has been used in the literature and has been confirmed by numerous works on the topic muhaisen et al 2009 fu and butler 2014 szeląg et al 2020 for instance to model 5 year time series of convective frontal and convergence zone rainfall 14 3 5 10 000 16 5 10 000 and 2 6 5 10 000 rainfall event simulations were conducted respectively the obtained rainfall data for the assumed catchment characteristics were substituted into the logit model equation 3 thus the p value was determined and in the period of t years the number of stormwater flood events caused by rainfall with the corresponding origin was calculated on the basis of the calculation results the total number of stormwater flood events novf in the studied period was calculated as the total number of stormwater flood events caused by convective frontal and convergence zone rainfall thus the empirical distributions cdfs were calculated in the manuscript the number of stormwater flood events was simulated for test catchments a b c and d over periods of 5 and 10 years accounting for the rainfall origin 2 8 modeling the number of stormwater flood events while taking into account the dynamics of changes in the catchment characteristics step 10 the land use changes within the catchment area and the stormwater network development e g impervious and pervious areas length and volume of channels unit channel length per impervious area were described using the following model ciupa 2009 freni et al 2010 jacobson 2011 triantakonstantis and mountrakis 2012 zhuk et al 2020 9 d t d 0 d m a x d 0 t t a where d0 is the initial numerical value of a selected catchment or stormwater network characteristic dmax is the maximum numerical value of the catchment characteristic after period t t is the number of consecutive simulated years where t 0 1 2 3 t and a is a shape parameter determining the dynamics of changes in the characteristics of the catchment over time t the relationship proposed above makes it possible to simulate any given dynamics of changes in the selected characteristics of the catchment the advantage of this method is that it makes it possible to model slow and rapid changes in selected variable values d in a short period of time by appropriately selecting the shape parameter the algorithms used to prepare the input data to simulate the multiannual number of stormwater flood events with changing catchment characteristics in consecutive analyzed years is presented in fig 6 for the 5 and 10 year periods with the number of samples n 10 000 and two catchment characteristics changing within the calculation period d 1 f t and d 2 t initially in line with the methodology described in section 2 5 3 the synthetic time series of rainfall of convective frontal and convergence zone origins were modeled in the analyzed time period t the calculations were performed assuming a mean number of rainfall events the simulations involved only the rainfall characteristics contributing to stormwater flood events the catchment characteristics were assumed to change annually i e the values of d obtained by means of equation 9 corresponded to consecutive annual synthetic rainfall periods d where t 0 1 2 3 t consecutive simulated years d1 0 d1 1 d1 2 d1 3 d1 4 values of catchment d1 characteristics calculated from equation 9 for consecutive t years d2 0 d2 1 d2 2 d2 3 d2 4 values of catchment d2 characteristics calculated from equation 9 for consecutive t years n number of samples from the monte carlo simulation dc0 dc1 dc2 dc9 yearly synthetic time series of rainfall events for convective rainfall df0 df1 df2 df9 yearly synthetic time series of rainfall events for frontal rainfall dcz0 dcz1 dcz2 dcz9 yearly synthetic time series of rainfall events for a convergence zone the exemplary allocation of catchment characteristics imp impu and gk in line with fig 6 over a 5 year period for values of imp0 0 40 impu0 0 35 and gk0 0 035 m ha 1 as well as a 1 0 is presented in fig 1si 2 9 modeling the number of floods in the catchment taking into account the changing number of rainfall events per year of convective frontal and convergence zone origins step 11 in this study the number of stormwater flood events in a catchment was simulated based on the determined discrete distributions describing the annual number of rainfall events of convective frontal and convergence zone origins and distributions of continuous values describing rainfall characteristics for this purpose the calculations of the annual number of rainfall events of respective origin were conducted first in the case of a calculation period longer than a year the number of rainfall events of the assumed origin was added until the assumed length of the time period t was achieved the number of samples of periods describing the series of rainfall events adopted to calculate the number of stormwater flood events equaled 500 using the developed rainfall characteristic generators section 2 5 3 rainfall data simulations with 10 000 samples were conducted for the assumed calculation period t yielding 500 10 000 simulated events for the assumed catchment characteristics and developed synthetic rainfall time series accounting for the stochastic nature of the number of rainfall events the probability of stormwater flooding in a catchment was calculated enabling the determination of the number of flood events and the preparation of cdf curves 2 10 verification of the model results of the number of stormwater flood events in the catchments obtained by applying a hydrodynamic model swmm step 12 in this study an original method was proposed for verifying the results of simulations obtained with a mathematical model in these simulations changes in catchment characteristics occurred in consecutive simulated years table 1 in this approach the allocation of the numerical values of catchment characteristics to consecutive years created the basis for analyses as discussed in section 2 8 while verifying the proposed mathematical model for simulating the number of stormwater floods in period t using a hydrodynamic model it should be kept in mind that the catchment characteristics assumed for analyses figs 6 and 1si can differ from the numerical values measured in the models of catchments a b c and d fig 3 therefore appropriate modifications must be prepared as shown in fig 7 the catchment imperviousness imp modification is shown as an example where b 1 2 3 p number of subcatchments in the hydrodynamic model below catchment c analyzed for stormwater flooding bc 1 2 3 number of subcatchments in catchment c analyzed for stormwater flooding fu fimpu impu gk xc dc ltot lk markings correspond to those in fig 2 β βu calculation coefficients determined as the quotient of imp after modification and imp present model and mof t β βu swmm model with the values of catchment characteristics d f t corrected with β and βu the exemplary allocation of catchment characteristics imp impu and gk in line with fig 7 over a 5 year period for values of imp0 0 40 impu0 0 35 and gk0 0 035 m ha 1 as well as a 1 0 is presented in fig 2si in this paper the verification of the number of stormwater resulting from convective frontal and convergence zone rainfall obtained with the proposed model in catchments a b c and d over periods of t 5 and 10 years was performed using the hydrodynamic catchment model section 2 4 assuming constant catchment characteristic values the verification of the correctness of the developed mathematical model was conducted using the hydrodynamic model in line with the algorithm shown in fig 7 for dynamically changing catchment characteristics for periods t 5 and 10 years using the example of catchment c fig 3 catchment c was selected for these analyses because it can be considered a small urban catchment typical for kielce and other cities in poland imp impu 0 40 0 50 ciupa 2009 wałek 2019 3 results 3 1 the logistic regression step 2 in an effort to generalize the measurements of the stormwater network operation rainfall data and catchment characteristics a logistic regression model was developed to simulate floods in a single rainfall event on this basis the relationship can be expressed as follows 10 p e x p α 1 p t o t α 2 t r α 3 i m p α 3 i m p u α 4 g k α 0 1 e x p α 1 p t o t α 2 t r α 3 i m p α 3 i m p u α 4 g k α 0 where ptot is the rainfall depth in a given rainfall event and tr is the duration of rainfall the numerical values of αi coefficients in equation 10 the standard error of the estimations and the measures of fit of the calculations to the measurements including the sensitivity specificity and accuracy are given in table 2 based on the data listed in table 2 it can be stated that among the analyzed model parameters the rainfall depth and duration the imperviousness of the surface and the stormwater network density significantly influence the probability of occurrence of stormwater flooding in a rainfall event at the established significance level this is confirmed by the results of test probability calculations which do not exceed the critical value of 0 05 for statistically significant independent variables the obtained results are confirmed by the findings from the analyses conducted by zhang and singh 2007 and fu and butler 2014 who used rainfall depths and durations while modeling the stormwater network operation and identifying the flood events to determine their volumes these results are also confirmed by the results obtained by thorndahl et al 2008 who analyzed the stormwater network operation by accounting for the uncertainty of the hydrodynamic model using the glue method and proved the significant influence of the ptot and tr values on stormwater flooding similar results were also obtained by zhou et al 2019 who reported that the mean rainfall intensity influenced stormwater flooding in jixing and zhejiang provinces in china the simulations performed by jato espino et al 2018 for a small urban catchment 10 35 ha confirmed the results obtained in this paper and the effect of imperviousness of the catchment affected by the flooding and the areas located downstream on stormwater flooding the obtained relationships are also confirmed by the calculations of jato espino et al 2018 2019 in the espoo catchment finland as well as li and willems 2019 in the marxem and duerne catchment belgium which showed that there is no influence of the temporal rainfall distribution on the stormwater flooding in the catchment in turn the results of jato espino et al 2018 as well as li and willems 2020 showed the influence of rainfall frequency on the stormwater flooding phenomenon while analyzing the models for the espoo finland as well as marksem and duerne belgium catchments it was found that it is not possible to apply them for rainfall event with an observed rainfall depth and duration the model proposed in this paper is devoid of this limitation which enables its practical use for calculating the number of stormwater flood events for the assumed catchment characteristics the influence of temporal rainfall pattern on stormwater flooding in quantitative terms volume area depth water velocity rather than qualitative terms as presented in the studies of jato espino et al 2018 2019 and li and willems 2019 2020 has been demonstrated by many researchers studying on hydrodynamic modeling of catchments wang et al 2019 zeng et al 2021 szeląg et al 2021 these authors have also expressed the need to develop rainfall models to simulate the rainfall events that condition maximum hydraulic overloads of stormwater networks ball 1994 dao et al 2021 the obtained results show high correlations with the measured data as indicated by the sensitivity specificity and accuracy values out of 41 stormwater flood episodes the calculations agreed with the measurements in 39 events sens 95 29 whereas for 110 events where floods did not occur concurrent results were obtained in 101 events spec 92 23 therefore out of 151 rainfall events the simulation results agreed with the measurements in 140 episodes the course of the receiver operating characteristic function also indicated a good fit of the model the graph presents the optimal p threshold according to the youden index which simultaneously maximizes the sensitivity and specificity fig 8 the fit obtained in this work indicates that the developed model does not entirely explain the stormwater flooding phenomenon in an urban catchment the considered processes in the analyzed catchments may also be affected by dry periods the humidity of pervious areas the retention of impervious and pervious areas and the network geometry in the studied catchments teng et al 2017 mignot et al 2019 the calculation results of li and willems 2019 for a small urban catchment in belgium showed the influence of catchment retention and dry period on the occurrence of stormwater flooding it cannot be ruled out that in the analyzed case the temporal rainfall pattern in the event affects the volume stormwater flooding and the method applied to identify its variability during the rainfall is a simplification determination of maximum rainfall depths at 20 and 30 min nevertheless it can be widely applied at the stage of developing statistical models and analyzing stormwater flooding in urban catchments jato espino et al 2018 li and willems 2020 considering the remarks above it is advisable to continue the simulation analyses aimed at implementing advanced computational methods to identify the temporal rainfall pattern in an event e g fractal geometry methods topological methods chaos theory etc and to determine their influence on the occurrence of stormwater flooding in a catchment gutiérrez et al 2006 in this context it is also advisable to extend in future the scope of the research conducted in the considered catchments taking into account the other definitions of stormwater flooding schmitt and scheid 2020 and to develop the models to identify this phenomenon considering the increasing role of catchment retention land use and landform as well as channel retention further analyses are recommended to determine the influence of uncertainty in calibrated parameters of hydrodynamic models using the glue method and catchment characteristics on the occurrence of stormwater flooding in addition to the selection of appropriate independent variables to identify stormwater flooding the appropriate choice of machine learning method is also of great importance jato espino et al 2019 reported higher agreement of calculation results to measurements in the multilayer perceptron model than in the logistic regression model in addition the calculations conducted by ke et al 2020 for catchments in china s jixing and zhejiang provinces confirmed the feasibility of using the random forest method and boosted trees to simulate stormwater flooding therefore further analyses are needed to reduce the uncertainty of calculation results table 2 and improve the predictive ability of the model this approach combined with advanced methods to describe the temporal rainfall pattern in an event can confirm its influence on stormwater flooding 3 1 1 sensitivity analysis while developing the statistical models in this case logit apart from identifying statistically significant parameters it is important to identify the influence of the determined independent variables on the calculation results i e stormwater flooding probability thus following the calculation algorithm fig 1 and using the obtained logistic regression model a sensitivity analysis was performed by determining the sensitivity coefficients from equation 8 the sxi values were determined by analyzing the influence of each parameter in the logit model on the results of the pf calculation for the data according to table 1 in the convective frontal and convergence zone rainfall groups table 3 on the basis of the data shown in table 3 it can be stated that the longer the rainfall event duration tr is and thus the lower the rainfall intensity i is the higher the sensitivity of the model for identifying stormwater flooding is this was confirmed by the calculated values of sptot and str which were equal to 3 57 and 15 19 for convective rainfall and to 11 38 and 19 99 convergence zone rainfall respectively in the case of simp simpu and sgk different sensitivity coefficients were obtained in each catchment taking these results into account simp f impu imp simpu f imp impu sptot f ptot tr and str f tr ptot were determined for the highest intensity rainfall during a rainfall event and gk 0 03 m ha 1 mean value for the investigated catchments the results of the analysis are presented in fig 9 the curves in fig 9a and b confirm the linear increases in the simp and simpu values respectively resulting from the increased catchment imperviousness imp and impu the determined sensitivity coefficient values indicate that the value of imp has a greater effect on the p value than the value of impu does simp imp 0 3 0 5 impu 0 3 0 5 3 2 5 6 and simpu imp 0 3 0 5 impu 0 3 0 5 1 6 2 8 the obtained values of sptot and str are greater than those of simp and simpu fig 9a d in the case of sptot it was noted that for tr 90 240 min an increase in the rainfall depth leads to a greater sensitivity coefficient value fig 9c for the analyzed values tr 30 40 50 and 60 min it was observed that in an appropriate range of ptot an increase in sptot occurs up to a maximum value then a further increase in ptot reduces sptot fig 9c moreover it was observed that the longer a rainfall event was the higher the str value was fig 9d in the tr range of 25 90 min ptot also affected the str value as confirmed in the analysis of the curves in relation to the literature brown et al 2007 fraga et al 2016 the influence of the rainfall intensity and catchment characteristics on the determined sxi values has not been presented thus far this fact is of practical importance because it may be used for modifying the model calibration methodology which requires further detailed analyses in urban catchments this aspect can be used while developing models to simulate stormwater flooding in terms of volume and the methods to identify the parameters of hydrodynamic models behrouz et al 2020 kim et al 2021 in addition in the context of models to simulate the volume or area of stormwater flooding cheng et al 2019 the analyses aimed at capturing the temporal rainfall pattern in an event at the stage of sensitivity analysis seem advisable which may enable the appropriate selection of calibrated model parameters and thus reduce the uncertainty of simulation results on the basis of the prepared curves it can be observed that the rainfall characteristics have a key influence on the probability of occurrence of stormwater flooding in a rainfall event fig 9 out of the considered parameters the rainfall depth has the greatest influence whereas the rainfall duration has a much smaller effect this relationship was confirmed by the analyses conducted by brown et al 2007 on the example of an urban catchment in the united kingdom as well as by the analyses performed by thorndahl and willems 2008 who employed the form modeling method the relationships connected with the catchment characteristics obtained in the study were confirmed in the paper by jato espino et al 2018 who investigated the phenomenon of stormwater flooding in a small urban catchment in finland the relationships obtained in the present work confirmed the influence of the imperviousness of the catchment and the stormwater network characteristics on the occurrence of stormwater flooding 3 2 logit model verification with the calibrated hydrodynamic catchment model swmm step 3 to verify the prepared logit regression model simulations were carried out with a hydrodynamic model within the location of subcatchments a b c and d for this purpose the data obtained from the measurements used to build a logit model were utilized a comparison of the measurements and the calculations using the swmm hydrodynamic model and logit model for selected rainfall events highest intensity in catchments a b c and d is presented in table 4 where meas the observed measured stormwater flood events in catchments a b c and d respectively swmm results of the simulations performed with the swmm model in catchments a b c and d for the observed rainfall events when stormwater flooding was confirmed logit results of calculations carried out with the logit model pertaining to the number of stormwater flood events for the observed rainfall events on the basis of the numerical data listed in table 4 it can be stated that the logit model predicts a similar number of stormwater floods in individual catchments in subsequent years as the hydrodynamic model the performed calculations indicate that for most of the analyzed rainfall events in the multiannual period 2008 2019 the calculation results with regard to stormwater flood events during the observed rainfall events are in line with the measurements on the basis of these calculations it can be stated that for catchments a 10 years and b 12 years the number of stormwater flood events obtained from the measurements and simulations with the logit model are identical and are equal to 8 and 12 respectively in the case of catchment c 9 years the number of stormwater flood events obtained from measurements 13 is lower than the value indicated by the logit model 15 by two events for catchment d the stormwater flood events obtained from the measurements is equal to 10 while the number obtained from the logit model is 9 the results obtained in such a way confirm that the logit model is a useful tool and can be used to simulate stormwater floods in urban catchments on the basis of the prepared model it can be stated that there is no need to conduct continuous measurements of stormwater network operations the conducted analyses focused on seeking the independent variables and these values were quick and easy to determine e g by using the available spatial data on land development or the stormwater network without the need to conduct additional calculations or identify the hydrological characteristics of the catchment such as the runoff path or concentration time which requires hydrological knowledge this is a significant simplification compared to the models used thus far for identifying stormwater flooding in rainfall events jato espino et al 2018 li and willems 2020 at the same time a mathematical model was applied for further simulation analyses this process is described in later sections 3 3 determination of the empirical rainfall distribution and the fitting of the theoretical distribution using bootstrap versioning of the univariate goodness of fit test results step 6 the theoretical distributions were adjusted based on the empirical distributions in accordance with the dwa a 118e 2006 guidelines and independent variables describing stormwater flood events ptot tr and m the calculation results of the selected distributions empirical parameters and the test statistics used to assess the fit of the theoretical and empirical distributions are presented in tables 5 and 6 general equations describing the theoretical distributions of the log normal gev gamma geometric and poisson distributions are given in si 3 4 calculation of the influences of the catchment characteristics and rainfall origin on the probability of stormwater flooding in a rainfall event step 8 using the developed calculation algorithm fig 1 and accounting for the varied values of the catchment characteristics imp and impu as well as the rainfall origin the probability of flooding in a rainfall event was determined for this purpose simulations of rainfall series n 10 000 were carried out using the mc method with the iman conover modification the results of the calculations are presented in fig 10 on the basis of the resultant curves it can be said that stormwater flooding in the studied catchment takes place during convective fig 10 and frontal rainfall events fig 3asi support information this is confirmed by the specific stormwater flooding occurrence probability values in a rainfall event p no stormwater flood events were noted in the convergence zone rainfall events fig 3bsi on the basis of the calculations it was noted that for convective rainfall the percentile values for which p 0 are not lower than 0 72 while for frontal rainfall the percentile values for which p 0 are not lower than 0 999 these results confirm that in the catchment the stormwater flood events resulting from frontal rainfall events is unlikely the observed stormwater flood events in the catchment are a result of convective rainfall in the air mass in terms of stormwater system operation and in the context of literature data garcía bartual and andrés doménech 2017 dao et al 2021 it enables identifying the hydraulic overload of the drainage system this is extremely important from the point of view of making decisions on potential stormwater system modernization and appropriate selection of solutions enabling improvement of its operating conditions the sole information on the influence of area imperviousness at the stage of hydrodynamic modeling of a catchment is a simplification of the modeled phenomenon and there is a need to also account for the catchment retention and stormwater network capacity however from the point of view of analyses at the urban spatial planning stage this is in fact the only reliable information which can be useful for modeling the stormwater flooding processes in catchment areas it can be stated that the increases of imperviousness of the analyzed catchment imp and the areas located downstream impu influence the occurrence of stormwater flooding on this basis it was found that the higher the imperviousness of a catchment is the greater the probability of the occurrence of flooding in the catchment is this finding is confirmed by the analyses of the results obtained by jiang et al 2018 for selected cities in china in which the annual rainfall depth was equal to 500 1700 mm this result is also confirmed in the analyses by ress et al 2020 who investigated the operation of stormwater networks in the rocky banch catchment in columbia for impu 0 50 as well as for imp 0 50 and imp 0 40 the values of p 90th percentile equal 0 038 and 0 151 respectively in turn for impu 0 40 as well as for imp 0 50 and imp 0 40 the values of p 90th percentile are equal to 0 276 and 0 535 respectively this indicates that the urbanization of the catchment in general impu and locally imp has an impact on the stormwater flood events occurring during rainfall events which is important at the catchment management stage the results of the analyses are in accordance with the studies by jato espino et al 2019 who conducted research on a small urban catchment in finland as a result they only analyzed the stormwater flood events resulting from rainfall events the occurrence of which is difficult to connect with atmospheric circulation the formation of air masses or rainfall data that can be measured using a rain gauge barnes et al 2020 in the presented solution these shortcomings were eliminated to enable the identification of stormwater flood events in a catchment for rainfall event to complete the calculations described above the curves fig 11 showing the probability that the rainfall intensity would not exceed the value leading to stormwater flooding within the studied catchment with the selected characteristics were indicated the calculations assumed values of impu and imp in the range of 0 30 0 50 and gk 0 01 m ha 1 based on the appropriate curves it can be established that for convective rainfall the minimal mean rainfall intensity i value is not lower than 74 l s 1 ha 1 the relationships obtained below indicate that for convective rainfall the variability between the 5th and 95th percentiles in i leading to stormwater flooding in a small urban catchment is equal to 83 176 l s 1 ha 1 in the case of frontal rainfall for the analyzed range of imp impu 0 3 0 50 and gk 0 01 m ha 1 it was observed that i figs 4si and 5si the obtained curves confirm the significant influence of changes in catchment imperviousness on the maximum rainfall intensity i value causing stormwater flooding in a small urban catchment for example for impu 0 50 and convective rainfall an increase in imp from 0 30 to 0 50 results in a reduction in the maximum rainfall intensity 50th percentile leading to stormwater flooding from 127 l s 1 ha 1 to 113 l s 1 ha 1 the relationships described above have not been investigated by other authors working within similar topics thorndahl and willems 2008 thorndahl 2009 despite their practical application in preparing early warning systems against flooding risks in urban catchments caused by intensive rainfall garcía bartual and andrés doménech 2017 maier et al 2020 the proposed solution would enable appropriate decisions to be made regarding the further development of catchments in the context of reducing the number of stormwater floodings improving the operating conditions of the stormwater system and maintaining high living standards for residents in urban areas currently the abovementioned aspects have only been considered in the literature where they were identified with simulations that used calibrated models of the studied catchments and did not consider the origin of rainfall fu et al 2011 fu and kapelan 2013 garcía bartual and andrés doménech 2017 it seems advisable to integrate the weather forecast models including extreme rainfall and to use on line data enabling their identification at the same time it seems necessary to extend the logit model and include the criterion of flooding in the calculations as a condition in which the road lane is filled with stormwater and flooding occurs leading to economic losses in this approach considering temporal pattern of rainfall may be crucial in identifying flooding due to the dynamics of filling retention within the road lane schmitt et al 2004 3 5 modeling the number of flood events in the studied catchment considering the rainfall origin steps 9 and 12 in an effort to assess the veracity of the obtained results calculations of the multiannual numbers of stormwater floods t 5 and 10 years in subcatchments a b c and d were carried out using the mathematical model described above and the hydrodynamic model of the catchment these calculations were performed for convective and frontal rainfall events the measurement results of the number of floods 2008 2019 the calculations performed using the catchment model constant simulations and the mathematical model developed with measured data for t 5 years are included in fig 12 the results of analyses for the period of t 10 years are presented in the support information fig 6si on the basis of the determined curves it can be stated that the calculated values of 50 percentiles number of stormwater flooding for the period of 5 and 10 years calculated by means of swmm and proposed model for subcatchments a b c and d indicate high convergence the difference in value n ovf for convective rainfall figs 6sia 12a obtained by means of continuous calculations and the model described in fig 2 does not exceed two floodings which proves the usefulness of the proposed simulation algorithm this indicates that the proposed model can be applied to further analysis involving the assessment of the impact of catchment characteristics on the number of stormwater floodings in an urban catchment moreover while analyzing the number of stormwater floodings in the considered catchments a 3 5 b 5 c 7 8 and d 8 9 for a 5 year period fig 12a it can be stated that the results of swmm simulations and measurement data table 4 are within the range of the obtained solution on the basis of the performed simulation it can be stated that number of stormwater floods for analyzed period t 5 and t 10 years indicates the issues related with problems of the stormwater network operation which confirms the necessity of implementing the sustainable development policy simultaneously the results confirm that the obtained model can be a useful tool for preliminary analyses of land use in urban catchments it is especially important in the course of making the decisions concerning the directions of urban development issuing building permits and development conditions taking into account construction solutions and materials used for building roads parking lots etc 3 6 modeling the number of flood events taking into account the dynamics of changes in the catchment characteristics steps 10 and 12 the presented paper analyzed several calculation variants of land use changes over periods of 5 and 10 years table 7 in variants i iii it was assumed that the dynamic changes that occur over time involve catchment imperviousness imp f t whereas impu was considered to be constant the variability in gk f t in catchment c which resulted from changes in the catchment imperviousness in consecutive simulated years was accounted for in the calculations the gk value was calculated for the set values of imp equation 9 in line with the methodology presented in section 2 10 in the variants iw iiw and iiiw both the values of imp f t and impu f t were determined according to equation 5 in subsequent simulated years t the assumed values of a table 7 enable an analysis of the changes in catchment characteristics over time which may have a practical influence on the spatial development plans in urban catchment areas and thus the sustainable development of urbanized areas the numbers of stormwater flood events resulting from convective and frontal rainfall events were calculated for the assumptions presented in table 7 the paper showed the results of calculations variant i iii and iw iiiw for the period of 5 years figs 13 and 14 and the data for a period of 10 years were presented in si figs 7si and 8si the results of the calculations performed with the proposed model were verified based on catchment c as a representative of the city of kielce ciupa 2009 taking into account the land development slope and density of the stormwater network the calculations presented above fig 12 confirm the relationships shown in fig 14 therefore it can be stated that the dynamics of changes in the selected catchment characteristics influence the number of multiannual stormwater floods in the catchment in the case of frontal rainfall it was observed that in each of the considered calculation variants in the 5 year period the number of stormwater flood events was equal to zero up to the 99th percentile value this was also confirmed by the results of calculations performed for the considered variants using the hydrodynamic model on the basis of the obtained curves fig 13 a b 14 a b it was observed that the highest number of stormwater flood events was obtained for a 0 5 in the impu range of 0 3 0 5 for instance for a 0 5 with impu 0 3 and impu 0 5 the numbers of stormwater flood events in a 5 year period are equal to 7 and 8 respectively 50 percentile whereas for the 10 year period these numbers are equal to 14 and 17 respectively for a 2 0 the calculated number of stormwater flood events in a 5 year period is the lowest among the analyzed variants i iii the numbers of stormwater flood events in the 5 year period for a 2 0 with impu 0 3 and impu 0 5 equal 6 and 7 respectively in turn for the 10 year period these numbers equal 13 and 15 respectively while analyzing the obtained results figs 13 and 7si it was noted that when modeling the number of stormwater flood events in the 5 and 10 year periods attention should be given to the relationship between imp and impu for instance the numbers of stormwater flood events for the 10 year period for a 2 0 and impu 0 5 and for a 0 5 and impu 0 4 are identical and equal 15 moreover on the basis of these calculations it was established that 14 stormwater flood events occurred for a 0 5 and impu 0 3 as well as for a 1 0 and imp 0 4 the results of the analyses in figs 13 and 14 and 8si are also confirmed in the simulations performed assuming simultaneous changes in imp f t and impu f t in consecutive years the number of stormwater flood events in the 10 year period for a 2 0 is the lowest out of the analyzed variants and is equal to 7 whereas for the 10 year period it equals 15 for the 5 year period the numbers of stormwater flood events for a 0 5 and a 1 0 are identical and equal 8 for the 10 year period the highest number of stormwater flood events novf 17 was obtained for a 0 5 and at least one fewer flood event was obtained for a 1 0 in the case of frontal rainfall the numbers of stormwater flood events in the periods of 5 and 10 years are equal to 0 for the 50th percentile for the 5 year period the number of stormwater flood events for the 99th percentile was equal to 1 while for the 10 year period it was equal to 0 96 empirical distributions determining the total number of stormwater flood events over the period of 5 10 years figs 9 12 si were also determined for the analyzed cases figs 13 and 14 their course confirms that the values of the number of stormwater flood events are identical in comparison with the distributions prepared for convective rainfall it proves that stormwater floodings occur due to convective rainfall which may constitute the basis for determining the extreme most unfavorable conditions of stormwater system operation the analysis of the obtained stormwater flooding simulation results over periods of 5 and 10 years 50th percentile performed using a hydrodynamic model and the developed mathematical model indicated a high goodness of fit of the stormwater flooding calculations the difference between the calculation results obtained with the swmm model and the devised tool for the 5 and 10 year period equaled 1 flood event therefore the obtained result confirms the possibility of employing the developed tool for conducting stormwater network operation analyses in terms of spatial development plans the curves obtained in figs 13 and 14 confirm the effect of catchment imperviousness included in the analyses imp and catchment area below the analyzed cross section on the flooding phenomenon impu this is very important in terms of using the developed computational tool in urban spatial planning the calculations confirmed that in the case of increased catchment imperviousness and in the catchment area below the analyzed cross section the most favorable long term urbanization variant from the point of view of catchment management which determines the lowest number of stormwater flood events in the simulated period was obtained for a 2 equation 9 the assumed solution although limited to the exponential form of the model imp f t enables to calculate the number of stormwater flood events with changing dynamics of catchment imperviousness in the simulated period it is possible due to optimal selection of coefficients in equation 8 this is particularly useful when urbanization of the catchment is occurring very rapidly with respect to reducing sewer floods this would improve the effectiveness of the stormwater network and the structures located within it the approach developed here provides the possibility of simplified managing at the stage of preliminary analyses including spatial planning the catchment through spatial arrangement and by the modernization of the stormwater network the changes of imperviousness can be balanced by limiting the volume of stormwater flowing directly into the stormwater network by the construction of green roofs or by replacing the impervious areas with other types of surfaces however this requires that extend proposed model to identification of flooding events considering that the determined number of stormwater flood events for the assumed calculation period is the result of the integration of a logit model and a rainfall model in which the estimated coefficients are subject to uncertainty it seems advisable to extend the proposed approach and determine the impact of uncertainty on the number of stormwater flood events this is important from the point of view of using the obtained results to improve the conditions of stormwater system operation on a long term basis the calculations performed by szeląg et al 2020 showed that the uncertainty in the coefficients of the log normal distribution describing the average rainfall intensity in an event can be ignored in the calculation of the probability of overflow performance these results confirmed the calculations of fu et al 2011 who modeled stormwater floodings in a catchment located in the uk based on a stochastic rainfall model in order to reduce the uncertainty of the simulation results with the logit model it is advisable to improve the predictive ability of the model and implement machine learning methods used to identify stormwater flooding neural networks random forests boosted trees etc and to evaluate the impact of the simplifications adopted in the model equation 10 on the number of stormwater flood events during the calculation period the model developed in this way is particularly important in the context of its application engineering practice confirms that simple models with a small number of independent variables are widely used in practice despite the fact that their results are only a certain approximation mignot et al 2019 3 7 modeling the number of flooding events in the studied catchment taking into account the changing number of rainfall events per year convective frontal and convergence zone rainfall step 11 calculations of the number of stormwater flood events recorded over 5 and 10 year periods were performed for two cases using the developed mathematical model in the first case the mean constant number of rainfall events in a year was assumed for frontal convective and convergence zone rainfall in the second case it was assumed that the number of rainfall events throughout a year was modeled from the determined theoretical distributions the calculation results for these two cases i e the 5 and 10 year periods and imp impu 0 40 are presented in fig 15 on the basis of these results it was noted that the simulation results concerning the number of stormwater flood events obtained by assuming a constant mean number of rainfall events in the analyzed period are very similar to the calculation results obtained when the number of rainfall events is modeled this was confirmed by the determined percentile values on the basis of the created curves it was observed that omitting the variability in the annual number of rainfall events for the percentiles of 0 73 5 years and 0 67 10 years leads underestimated stormwater flood events by 1 and 3 respectively for the percentiles of 0 47 5 years and 0 40 10 years the results of the calculations related to the number of stormwater flood events were underestimated when the variability in the annual number of rainfall events was accounted for compared to the case in which a mean annual number of rainfall events was assumed for the 50th percentile identical numbers of stormwater flood events were obtained for the considered cases i e when using the mean annual number of rainfall events and the number obtained from simulations for the 5 year period 6 stormwater flood events occurred whereas for the 10 year period 12 flood events were observed in the context of the obtained results it can be stated that from the perspective of design at the conception and development stage of urban catchments it is advisable to account for the variability in rainfall events throughout a year while modeling the number of stormwater floodings in order to obtain the most accurate description of the actual conditions during the initial analyses involving the spatial development plans assuming a mean number of rainfall events enables the evaluation of the influence of the applied planning solutions on the stormwater network operation conditions and the urban development directions 4 conclusions on the basis of the analyses conducted in this study it can be concluded that the developed mathematical model can be applied to simulate the number of stormwater floods in an urban catchment in a multiannual approach from the presented simulations it can be confirmed that stormwater flooding in urban catchments can be modeled based on rainfall data the rainfall depth and duration in a given rainfall event and the characteristics of the studied catchment imperviousness of the analyzed area and land located downstream and the unit length of the main channel per the impervious area these simulations confirm that the rainfall origin has a significant influence on the modeling of the number of stormwater floods its omission results in an underestimation of the number of floods it was also determined that stormwater floods are strictly connected with the characteristics of a catchment usually occur in events caused by convective rainfalls and are rarely seen in association with frontal rainfalls it was also established that the dynamics of urbanization and changes in catchment characteristics strongly influence flooding the presented innovative method for verifying the number of stormwater flood events obtained using the developed ovfsim ver 1 software indicated a good fit with the simulation results performed using a hydrodynamic model the proposed methodology for verifying the simulations of the number of stormwater flood events in a given catchment using hydrodynamic models in which catchment characteristics change as functions of time can also be employed for the validation of models in which the development method changes during the simulated period e g as a result of the implementation of green infrastructure objects moreover the conducted studies confirm the usefulness of the developed tool for simulating the number of stormwater flood events in a catchment which constitutes a simplification in comparison to the currently used calculation tools this simplicity enables the use of the software in dispatching centers managing drainage systems in the course of stormwater network operations this tool could have a significant effect on designing and modernizing stormwater networks and on decision making connected with the development of sustainable catchments in long term planning such an approach could be used to improve the selection of concepts of land use planning with a view to reduce flooding improve the performance of stormwater systems limit the amount of contaminants introduced to receivers as well as consider the economic and social aspects of improving the stormwater system functioning the presented model also has certain limitations except for the of imperviousness of a catchment area the model does not account for stormwater retention which is usually required by local regulations the share of the impervious area in an urban catchment does not always account for the influence of the stormwater management infrastructure which is increasingly often considered during urban planning therefore at the next stage of the study it is planned to extend the model by adding parameters describing retention of imperviousness area channel retention and network layout which will enable to broaden the scope of its applicability conducting further analyses to identify stormwater flooding taking into account other criteria of its occurrence is advised in this context it is recommended to apply advanced machine learning methods modifications to logistic regression regression trees etc to identify stormwater flooding which is important from the point of view of selecting appropriate independent variables for its calculation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105335 
25616,this work presents a methodology for analyzing the influence of urbanization in a long term approach on the number of floods in an urban catchment the mathematical model presented for predicting the multiannual number of stormwater floods accounts for dynamic changes in the urban catchment in the subsequent years covered by the simulations logistic regression was applied to predict flooding occurring during rainfall events the model may be applied to catchments with different characteristics the assumed solution allows the development of early warning systems by modeling the occurrence of stormwater flooding in a studied catchment area based on the identification of the rainfall origin to verify the simulations with a mathematical model an innovative concept based on a hydrodynamic model is used this concept includes the changes in the impervious area that occur during the simulation period keywords logistic regression stormwater flooding urban catchment swmm computer software ovfsim ver 1 1 introduction climatic changes and progressing land use changes driven by urbanization are leading to an increase in runoff streams from catchments hettiarachchi et al 2018 zhou et al 2019 this in turn leads to an increase in the amount of contaminants directly introduced into receivers mostly rivers disturbing their ecological balance astaraie imani et al 2012 miller and hutchins 2017 müller et al 2020 an increase in the number of storm overflows the overfilling of structures in stormwater networks and an increase in the number of sewer floods have been observed these factors negatively influence the quality of life in cities and result in significant material losses caused by intense rainfall events therefore to limit the occurrence of unfavorable phenomena in stormwater systems as well as to improve the operating conditions of stormwater networks there is a need to model these systems barbosa et al 2012 kirshen et al 2015 baek et al 2015 gdv 2016 leandro and martins 2016 when measuring the operation of stormwater systems the number of sewer floods is very significant these system functions are regulated by appropriate guidelines mark et al 2004 dwa a 118e 2006 teng et al 2017 moreover the occurrence of floods has a strong influence on the living standards of inhabitants in urbanized areas and this is reflected in the costs of the services offered in city centers huong and pathirana 2013 a review of the literature siekmann and pinnekamp 2011 willems 2013 hammond et al 2015 schmitt and scheid 2020 szeląg et al 2021 indicates that floods in urbanized catchments should be considered an important indicator that should be accounted for during stormwater network modernization depending on the number of floods applying appropriate sustainable development solutions for urban catchments may also be necessary which would affect the management of water resources this concept has been confirmed by an increasing number of studies on the topic zhou et al 2012 huong and pathirana 2013 hegger et al 2016 jato espino et al 2016 wang et al 2018 in which state of the art design solutions and the materials contributing to surface runoff reductions were discussed meerow and newell 2017 these results lead to the improved hydraulic conditions of stormwater systems and thus decrease the occurrence of stormwater floods as well as their volumes currently to assess the operation of a stormwater network and simultaneously establish the number of sewer floods in an area it is necessary to carry out constant simulations using a hydrodynamic model representing the catchment and at least 30 years of rainfall characteristics schmitt et al 2004 guo and dai 2009 thorndahl 2009 muhaisen et al 2009 collecting data in this way is difficult as indicated by the fact that many studies involve designing tools for predicting synthetic rainfall events thorndahl and willems 2008 fu and kapelan 2013 fu and butler 2014 however since these models are local in nature it is necessary to collect data on the specific catchment and stormwater network and perform high resolution measurements of the rainfall depths and flows in the region this is not always economically viable moreover due to the strong interactions among the parameters identified in the model and technical problems at the stage of carrying out measurements the obtained models are not always characterized by satisfactory prognostic abilities this has been confirmed by a number of papers fu et al 2011 chen et al 2012 2018 fraga et al 2016 in which the influences of the uncertainties of the collected data type of land development stormwater networks rainfall and flow data flooded areas etc and identified model parameters on the simulation results were investigated these data are of great importance because they create the basis for selecting appropriate solutions aimed at improving the operating conditions of stormwater networks elliott and trowsdale 2007 currently the influences of changes in catchment imperviousness land use and stormwater networks have been discussed in numerous works miller et al 2014 fraga et al 2016 paule mercado et al 2017 recanatesi and petroselli 2020 calculations concerning the influence of climate change and complex catchment imperviousness values appropriately varied have also been performed shuster et al 2005 jacobson 2011 huong and pathirana 2013 their influences on the variabilities of stormwater flows flooding volumes and the number of overflowing manholes have thus been determined notaro et al 2015 eshtawi et al 2016 however the dynamics of changes in catchment imperviousness have only been discussed to a limited extent this is important because in line with the literature data guan et al 2015 land use changes dynamically affect the operating conditions of stormwater networks at present there are no calculation tools that can be employed without calibration for urban areas with varied land use types catchment areas catchment imperviousness degrees road surfaces lengths of stormwater networks etc such a solution would be highly useful and enable rapid analyses of stormwater system operation at the planning stage of the spatial development of urban areas this type of solution would be a highly practical tool enabling appropriate decision making connected with the rate of city development this ability is essential with regard to the standards of living of urban residents as well as the functioning of cities examples of work that used statistical models to simulate sewer floods can be found in the literature thorndahl and willems 2008 applied the form method first order reliability model to simulate flooding of manhole in an urban catchment located within denmark however the solution they proposed had a local character with no possibility of being applied to other catchments the developed statistical models to identify stormwater floodings in small urban catchments based on classification tools have focused on stormwater flooodings from a single manhole jato espino et al 2018 li and willems 2020 in these models the identification of stormwater flooding jato espino et al 2018 requires an parametrization of the stormwater network the characteristics of the catchments and the frequency of rainfall events a similar solution was employed by li and willems 2020 who analyzed of the two catchments ghent and antwerp in belgium in that model a number of parameters connected with the channel retention water depth in the manhole and time concentration were considered the proposed solutions are an alternative to the hydrodynamic models used including the resolution of the collected rainfall data which can be reduced because the effect of the temporal rainfall pattern on the occurrence of stormwater flooding in the catchment has not been demonstrated thorndahl 2009 jato espino et al 2018 2019 li and willems 2020 however in their analyses the authors omitted the uncertainty of the catchment model which in the context of the literature data fraga et al 2016 szeląg et al 2021 affects the calibration results and the flooding simulations the proposed input data required extensive knowledge on the course of the stormwater network and the hydraulic conditions in pipes therefore the implementation of these models under stormwater network extension and or catchment extension and modernization conditions may be hindered due to problems with the acquisition of accurate input data for the calculation models when modeling the identification of stormwater flooding from the literature review presented above it seems that the problem of sewer floods continues to be recognized within a limited scope from the point of view of stormwater network operation it is unknown whether flooding can be identified based on simplified rainfall data e g rainfall origin data it is currently known that simulating of rainfall is complex and the results obtained from these simulations are not always consistent with measurements this situation appears to be the case regarding the identification of the rainfall origin this problem usually disappears when identifying rainfall events caused by processes occurring in the zones on the border of air masses with various thermal characteristics thorndahl and willems 2008 fu and kapelan 2013 the literature data wasko and sharma 2015 cristiano et al 2017 hettiarachchi et al 2018 cheng et al 2019 show that more and more often the temporal rainfall pattern determining the occurrence of problems with stormwater system operation flooding inundation etc resulting in material losses and deterioration of the quality of life in cities are sought at the stage of modeling hydrological processes in urban catchments the short intense rainfall events are important from the point of view of stormwater system operation as they cause the maximum hydraulic overload of the system li and willems 2020 the analyses conducted by szeląg et al 2020 indicated that rainfall origin data may be useful for identifying stormwater overflow structures therefore the information about the rainfall origin collected online can be part of predicting the performance of the stormwater system and developing an early warning system for urban drainage flooding garcía bartual and andrés doménech 2017 and balbastre soldevila et al 2019 2021 developed convective rainfall simulation models for valencia spain that used in modeling and improving the stormwater network performance the attempts to determine idf intensity duration frequency curves for short intense rainfall events in mexico are given in the study of alfonso gutierrez lopez et al 2019 the great importance of heavy rainfall has also led to the development of maximum rainfall maps for the city of graz austria maier et al 2020 which using a hydrodynamic model allows the identifying problematic locations in the stormwater network the role of convective rainfall resulting from its origin is beginning to be increasingly recognized as models are being developed to simulate sewers under extreme overload conditions wang et al 2019 this is supported by the attempts to develop the models to identify rainfall thresholds for determining the events that may lead to stormwater flooding dao et al 2021 rainfall origin with an emphasis on convective rainfall has been used in flood analysis kreienkamp et al 2021 in july 2021 in eastern europe in addition to rainfall origin the temporal rainfall pattern is important in modeling the stormwater system performance area volume depth of the stormwater this is confirmed by the results of simulation performed for stormwater networks using hydrodynamic catchment models therefore the number of models for rainfall simulations is increasing multidimensional rainfall distributions using copula functions modifications of the monte carlo method accounting for the temporal rainfall pattern vandenberghe et al 2010 vernieuwe et al 2015 szeląg et al 2021 in this context it seems advisable to introduce modifications at the stage of creating models for their simulation in such a way as to separate the rainfall events that may lead to problems with the stormwater network operation therefore it is reasonable to divide rainfall events based on their origin convective in air mass frontal in a convergence zone and to compare the obtained results in relation to these types the modeling the operation of the stormwater system and the facilities located within taking into account the rainfall origin seems to be justified and can contribute to a significant risk reduction by minimizing the expected effects in an urbanized catchment identification of the origin type of rainfall from a few to several hours in advance is possible through the analysis of short term weather forecasts these forecasts allow the determination of numerous physical parameters of the atmosphere and consequently they enable to predict phenomena and processes occurring in it in addition to the stages of development convective flows in the air mass as well as the rate of movement of weather fronts and centers of low atmospheric pressure as a result of their analysis it is possible to determine the rainfall origin and thus to estimate its duration rainfall depth and average intensity this approach is supported by the fact that mesoscale numerical weather prediction models are used to develop large scale weather forecasts the results of which are often presented online open source license in an clear graphical form meteograms detailed maps animations thus they can facilitate the work in dispatching centers responsible for urbanized catchment management among the mesoscale weather models due to their practical use in the prediction of rainfall with high depth or intensity the weather research and forecasting wrf model is noteworthy which is the result of the collaboration of several u s institutions weisman et al 2008 chawla et al 2018 rogelis and werner 2018 da cunha luz barcellos and cataldi 2020 chang et al 2020 it uses high resolution geographic data including topography and land use relatively few studies have discussed how dynamic urban changes in catchments influence the functioning of stormwater networks mikovits et al 2014 löwe et al 2018 taking into account the complex physics of the stormwater flooding phenomenon in urban catchments and the necessity of accumulating data on land development and stormwater networks an innovative software tool was developed for simulating the influence of catchment characteristics and their changes in the calculation period as well as the rainfall origin on the number of stormwater floods in the applied approach the focus was placed on well known independent variables describing stormwater floods that are easy to identify and do not require conducting multiannual online studies governing the possibility of model application the proposed solution was developed to be available for a wide range of users including administrative bodies during the preparation of land development plans and stormwater network construction when access to detailed catchment and stormwater network data is limited the model takes into account a single rainfall event analyzes the time period and includes the possibility of analyzing the influence of dynamics of changes in catchment characteristics catchment imperviousness density of stormwater network together with the origin of rainfall on flooding the obtained results indicate that at the stage of the sustainable development of a catchment it is possible to choose the spatial development concept of land on annual basis to limit the number of floods and decrease the negative effects of high rainfall intensities 2 methods the study presented a mathematical model for simulating stormwater foods in small urban catchments in relation to a single rainfall event and the assumed period of time a year two years or longer the model creation and the analysis of the stormwater network operation using the developed model involved twelve steps fig 1 step 1 consisted of the collection of data necessary for the model to predict stormwater flooding in a rainfall event the model was developed by using the obtained stormwater network operation results accounting for the identification of stormwater flooding events to indicate an individual stormwater flood in a catchment during an independent rainfall events the following parameters were determined rainfall temporal pattern depth and duration and the characteristics of the catchment area of the catchment impervious area of the catchment length of the main channel in the catchment maximum difference of the land coordinates in the catchment such as height difference in step 2 a logistic regression model was created to identify stormwater flooding in a rainfall event simultaneously the model enables the identification of independent variables the evaluation of the predictive capacity of the model and the carrying out of the model sensitivity analysis in step 3 a verification of the calculation results obtained from the proposed model was performed using a calibrated hydrodynamic catchment model created in swmm storm water management model software thus the obtained logistic regression model lr was employed for further analyses in step 4 the rainfall events were separated into time series and the obtained data were grouped according to the rainfall origin step 5 hence the empirical and theoretical distributions of rainfall characteristics contributing to stormwater flooding in a rainfall event were determined step 6 the theoretical distributions were determined by means of bootstrap versioning of the univariate goodness of fit test results hence synthetic rainfall generators based on the monte carlo method accounting for the diversified rainfall characteristics depending on the rainfall origin were developed step 7 continuous rainfall measurements over a 45 year period were used to develop the synthetic rainfall generator on the basis of the logistic regression model and synthetic rainfall generator simulations were conducted to determine the influence of the rainfall origin and urban catchment characteristics on the probability of stormwater flooding in a given rainfall event with a given mean rainfall intensity step 8 as well as the number of stormwater flood events in a given catchment step 9 the dynamics of changes in catchment characteristics on the number of stormwater flood events step 10 and the variable number of annual rainfall events on the number of stormwater flood events step 11 the differentiation of the number of annual rainfall events stems from the stochastic nature of rainfall events the accounting of rainfall genesis in a computational model can be an important aspect of an early warning system for use against the threat of air circulation dynamics affecting the intensity of rainfall processes in the troposphere resulting in high rainfall depths or intensities to verify the obtained number of stormwater flood events in a specific catchment during the calculation period 1 2 or 5 years continuous simulations were performed with the calibrated hydrodynamic model step 12 consecutive steps 1 12 enumerated in the calculation algorithm fig 1 are discussed in detail in subsequent sections 2 1 software on the basis of the calculation algorithm presented in fig 1 the original computer software ovfsim ver 1 was developed by the authors in r and used to model the number of stormwater flood events in a catchment the developed software tool consists of four independent modules fig 2 the first module input data was fed data to create a logistic regression model based on the rainfall data and urban catchment characteristics in line with step 1 shown in fig 1 the data import was carried out using the rio library any import function can be used for this purpose in the second module the stormwater flooding simulator on the basis of the imported data a logit model for predicting stormwater flooding in a rainfall event was created the independent variables were identified and the measures of fit between the calculation and measurement results were determined the logistic regression model was created using the logit function of ovfsim the goodness of fit of the model was evaluated by means of the roc curve using the rocit function of rocit this enabled to determine the optimal probability value of classifying p states based on the yourden criterion in line with step 2 moreover a local sensitivity analysis was performed in this module based on the logit model in addition the sensitivity coefficients of the assumed rainfall data and catchment characteristics were determined in the third module rainfall simulator the rainfall events separated from the time series were imported into the r environment by means of the import function of rio in line with step 4 shown in fig 1 on the basis of the assumed criteria for rainfall classification these events were grouped into homogeneous classes then convective frontal and convergence zone rainfall events were separated step 5 thus the empirical and theoretical distributions of the rainfall data were determined step 6 the theoretical distributions of the rainfall characteristics were fitted using the fit distribution and rain dist functions of ovfsim delignette muller and dutang 2015 in the fourth module simulations of synthetic rainfall time series were carried out by means of the mc and mc logit functions of ovfsim step 7 using the created logit model rl the following tasks were solved the influences of the theoretical distributions of the rainfall data and catchment characteristics on the probability of stormwater flooding in a given rainfall event and for a given mean rainfall intensity step 8 were determined by means of the mc logit function of ovfsim for the simulated distributions of the rainfall data and catchment characteristics the empirical cumulative distribution functions were determined using the ggplot2 data visualization package the numbers of stormwater flood events in the catchment throughout the calculation period resulting from convective frontal and convergence zone rainfall were modeled for the assumed tested catchment characteristics step 9 the mc logit function of ovfsim was used to model stormwater flood events for the set rainfall parameters and selected catchment characteristics the number of stormwater flood events in the catchment resulting from the convective frontal and convergence zone rainfall events associated with the dynamic changes in catchment characteristics that occurred during the calculation period were modeled using the mc logit procedure of ovfsim it enabled dynamic changes in the imperviousness parameters and unit length of the main channel in the catchment area per the impervious area while simultaneously maintaining the correlations among the analyzed characteristics using the iman conover method the number of stormwater flood events occurring in the catchment for the assumed rainfall characteristics during the calculation period was modeled while accounting for the stochastic nature of the number of rainfall events throughout a year step 11 the mc logit function of ovfsim was also employed in this case 2 2 research area step 1 the subject of investigation includes four subcatchments a b c and d located within the si9 canal within kielce fig 3 the city is found in the central part of poland and is the capital of the świętokrzyskie voivodeship the average population density of the city is 19 5 people ha and in the study area the average population density is 21 4 people ha the analyzed stormwater system is a separate sewage system stormwater runoff from the catchment area is drained directly by the s1 main channel to the diversion chamber dc in cases in which the stormwater depth is no higher than 0 42 m the stormwater is directed to the stormwater treatment plant stp after exceeding this value stormwater is discharged through an overflow ov into the silnica river the analyses showed that the annual rainfall depth was 537 757 mm and the number of days with rainfall ranged from 155 to 266 the average annual air temperature varied between 8 1 c and 9 6 c while the number of days with snowfall was between 36 and 84 constant monitoring of the stormwater flowing out of the catchment showed that during dry weather stormwater flowed from the catchment at discharges between 0 001 and 0 011 m3 s this resulted from the infiltration of water to stormwater channels as indicated by a field inspection lisowska and szeląg 2014 the choice of subcatchments for this study resulted from their varying characteristics see table 1 and the relatively small distances between them these factors made it possible to simultaneously carry out field studies in all subcatchments the selected characteristics of subcatchments a b c and d are given in table 1 in turn fig 4 shows the scheme of a virtual catchment with a stormwater network described using the characteristics given in table 1 f area of the catchment imp impervious area of the catchment ltot length of the main channel in the catchment dh maximum difference of the land coordinates in the catchment height difference lk length of the main channel measured from point xa b c d to the dc diversion chamber impu imperviousness of the downstream area point xa b c d gk unitary length of the main channel in the catchment per impervious area fimp impervious area in the catchment in which flooding was observed fu area of the stormwater catchment below the analyzed cross section xa closing catchment a downstream fimpu area of impervious downstream xa vk volume of the main collector discharging downstream from diversion chamber dc to the cross section closing catchment a as a part of the continuous monitoring campaign from 2008 to 2019 water level and flow measurements were carried out using a mes1 flow meter located at a distance of 4 0 m before the diversion chamber dc the flow values were noted with a 1 min resolution in the same period field studies of stormwater flooding in sub catchments a b c and d were also carried out the identification of periods with rainfall events potentially resulting in flooding in the considered multiannual period was possible based on downscaling short term numerical analyses of weather forecasts determined by the interdisciplinary centre for mathematical and computational modeling of warsaw university https mapy meteo pl as well as those published by the institute of meteorology and water management of the national research institute https meteo imgw pl the first were based on the results of the met office unified model um with a horizontal resolution of 4 km brown et al 2012 whereas the second were based on the wrf model resolution 2 5 km and cosmo model 2 8 km alaro 4 km and arome 2 km developed by the european consortium for small scale modeling dierer et al 2009 klasa et al 2018 the rainfall depth measurements taken prior to flooding and during the course of flooding were performed using a seba rain gauge with a 1 min resolution located within the si9 catchment szelag et al 2016 during the study period the flood measurements in the studied subcatchments a b c and d covered 159 rainfall events stormwater floods occurred in 41 of these events szeląg and drewnowski 2019 the approaches taken to select catchments and conduct measurements were in line with those used in studies conducted by other researchers thorndahl and willems 2008 fu and butler 2014 jato espino et al 2018 li and willems 2020 who carried out stormwater flooding measurements in urban catchments in england finland and belgium a flooding event was defined as a situation in which due to an insufficient drainage network capacity stormwater accumulated locally and flooding occurred in other words a situation in which the stormwater depth at the manhole node exceeded the ground level jato espino et al 2018 2019 li and willems 2020 the assumed criterion corresponded to the flooding conditions as confirmed in previous papers on this topic chang et al 2021 gebreegziabher and demissie 2020 2 3 logistic regression step 2 logistic regression i e the binomial logit model is a classification model comprising supervised learning methods methods with teachers and was applied to analyze the relationships between predictors and response variables of binary types zero and one in contrast to other models random forests regression trees neuron networks and the linear discriminative model this method enables modeling of the probability of the occurrence of an event phenomenon process etc moreover the relationship obtained using the logit model has an explicit form in which the coefficients allow individual independent variables associated with the analyzed phenomena to be assessed the numerous advantages of the logistic regression model mean that it is applied in many fields of science from economics medicine microbiology and ecology bagley et al 2001 harrell 2001 heyer and stamm 2013 to the simulations of processes in wastewater treatment plants and the modeling of stormwater network operation jato espino et al 2018 szeląg et al 2019 the logit model is a particular case of a generalized linear model glm which takes the following form 1 f μ α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k where α0 is the intercept α1 α2 αq are the empirical coefficients established using the maximum likelihood method xk denotes the independent variables the characteristics of the catchment area table 1 and rainfall in separated events were assumed i e depth and duration maximum 20 30 min rainfall depth in a rainfall event jato espino et al 2018 zhou et al 2019 li and willems 2019 2020 and f is the link function determining the relationship of the average value of the explanatory variable with the linear combination of predictors the identification of independent variables was performed with the forward stepwise algorithm which is preferred for logistic regression models senaviratna and cooray 2019 assuming that μ p and introducing the link logit function the modeled values of the dependent variables can be transformed into the binary form 2 f p f μ l o g i t p l n p 1 p α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k by applying the appropriate transformations to equation 2 the following expression can be written 3 p e x p α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k 1 exp α 0 α 1 x 1 α 2 x 2 α 3 x 3 α k x k on the basis of equation 3 the probability of the occurrence of stormwater flooding in a rainfall event can be determined at the same time it is necessary to determine the minimum p value that is exceeded when a flood occurs there are some techniques for determining the best p threshold based on the roc curve takahashi et al 2006 beger 2016 such as the youden criterion or geometric mean criterion youden 1950 roc curves were also employed to assess the goodness of fit the flooding occurrence applied in the logit model as p 0 5 is universal equally accounting for the odds of the occurrence of either phenomena flooding and the lack thereof another approach to estimating the best p threshold is the use of the precision recall curve maximizing the harmonic mean which is defined as follows 4 f 2 p r e c i s i o n r e c a l l p r e c i s i o n r e c a l l where precision is the ratio of the number of true positives divided by the sum of the true positives and false positives and recall is calculated as the ratio of the number of true positives divided by the sum of the true positives and the false negatives mei and radev 2016 in some classification tasks one of the sensitivities or specificities is the most important to the researcher in such a situation the p threshold can be determined based on the sensitivity specificity trade off nevertheless p 0 5 was assumed to be a boundary condition in the software because the capacity of the model to be generalized for application to new sets of rainfall events with completely different catchment characteristics was the primary goal a boundary condition that is optimal for one set of data may be suboptimal for another observation set chen et al 2006 to assess the predictive abilities of the logistic regression model a confusion matrix arboretti and salmaso 2007 kononen et al 2011 was applied along with the following metrics accuracy 5 a c c t p t n t p t n f p f n sensitivity 6 s e n s t p t p f n and specificity 7 s p e c t n t n f p where t p t n f p and f n denote true positives correctly identified overflows true negatives correctly identified lack of overflows false positives lack of overflows incorrectly identified as overflows and false negatives overflows incorrectly identified as lack of overflows respectively the prepared logit model was verified by means of a calibrated catchment model fig 3 and by performing calculations for the selected rainfall events a local sensitivity analysis was performed based on the developed logit model this is a commonly employed approach used to analyze sensitivity in hydrological and hydraulic models morio 2011 pianosi et al 2016 the conducted analyses of the impacts of selected independent variables on the probability of occurrence of stormwater flooding in a rainfall event involved the local sensitivity analysis one factor at a time analysis a relative change in the kinetic parameters at 5 of their default values was used to calculate the sensitivity coefficient sx i as follows petersen et al 2002 8 s x i δ y δ x x y y x 0 i δ x i j y x 0 i j x 0 i δ x i x 0 i x 0 i y x 0 i j where xi is the model input parameter and yj is the model output variable on the basis of equation 8 it can be stated that the determined sxi value depends on the initial xo i values therefore the influence of rainfall data on the sxi values was analyzed with regard to the ranges of the variable catchment characteristics table 1 2 4 logit model verification with the calibrated hydrodynamic catchment model swmm step 3 to assess the functioning of stormwater networks and subcatchments located within them subjected to stormwater flood observations a hydrodynamic model of the catchment elaborated in swmm software was used fig 3 the total catchment area equaled 62 ha the areas of catchments a b c and d equaled 8 07 ha 3 45 ha 6 16 ha and 7 02 ha respectively the model comprised 55 subcatchments with areas of 0 12 2 10 ha the model was built of 200 nodes representing manholes and 72 channels catchment a comprised 3 subcatchments 10 manholes and 11 channels catchment b consisted of 4 subcatchments 12 manholes and 11 channels in turn catchments c and d included 4 subcatchments 10 manholes and 11 channels each the identification of the model parameters was carried out using the results concerning the variabilities in flows and stormwater flooding events in subcatchments a b c and d since 2009 szeląg 2013 2021 the deterministic and probabilistic calibration of the model glue sa relative to the simulations of hydrographs obtained within the studied catchment the operation of the stormwater treatment plant and the overflows showed that the model predicted the abovementioned processes with high accuracy this has been discussed in detail in the papers published by szelag et al 2016 and kiczko et al 2018 in the catchment model the retention values of the impervious and pervious areas equaled 2 5 mm and 6 0 mm respectively for a weighted average value of 3 80 mm the manning s roughness coefficient values for the impervious and pervious areas were 0 015 m 1 3 s and 0 15 m 1 3 s respectively the calibration szelag et al 2016 showed that the mean manning s roughness coefficient value of the stormwater network channels was equal to 0 018 m 1 3 s due to the methodology of identifying sewer floods in individual analyzed research catchments the simulation calculations conducted using the prepared catchment model relied on the verification and confirmation of whether a stormwater flood occurred during the course of an observed rainfall event in the areas of subcatchments a b c and d for a selected rainfall event in an appropriate catchment the probability of a flood occurrence p was calculated using equation 3 simultaneously the stormwater system operation in the investigated catchment was simulated by determining the manhole overflows if a flood was observed in the area of a catchment for a given rainfall amount and was also predicted by the model based calculations using swmm and the determined p value for the analyzed rainfall event was greater than the cutoff threshold the agreement of the swmm results with the logit model was assumed 2 5 rainfall data for model 2 5 1 separating independent rainfall events and their origin steps 4 and 5 in this paper the source material included data collected from may october of 1961 2005 the data were obtained using a traditional float pluviograph recording the rainfall depth duration and mean intensity installed at the imgw meteorological station in kielce the dwa a 118e 2006 guidelines served as the basis for separating independent rainfall events in this manner the period between subsequent rainfall events was 4 h whereas the minimal rainfall depth of an event equal to 3 0 mm was in accordance with fu and kapelan 2013 and fu and butler 2014 each of the rainfall events was assigned an origin convective in an air mass frontal or in a convergence zone the allocation of the separated rainfall events to particular origin types was performed based on the analysis of synoptic situations and local weather conditions at the station in kielce the rainfall origin was determined on the basis of surface synoptic charts of europe every 12 h published in the daily meteorological bulletin of the institute of meteorology and water management in warsaw and a calendar describing atmospheric circulation air masses and atmospheric fronts covering southern poland niedźwiedź 2019 the aforementioned calendar has been used in numerous scientific studies e g lupikasza 2010 twardosz et al 2011 bartoszek and skiba 2016 wypych et al 2018 szeląg et al 2020 while separating the rainfall characteristics in time series for modeling stormwater floods in a rainfall event the authors were guided by the information found in the literature zhang and singh 2007 thorndahl et al 2008 zhou et al 2019 indicating that the analyzed phenomenon was affected by the rainfall depth duration and mean intensity and by the maximum instantaneous rainfall depth in a rainfall event in the period of 1961 2005 1526 rainfall events were observed in the kielce in which the total rainfall depth was greater than 3 mm average of 33 8 events per year the majority 723 of these events were of frontal origin approximately 16 events per year these rainfall events lasted for 2 5 10 5 h they were connected with the movements of atmospheric fronts quickly moving cold fronts along with the dynamic processes occurring within their zones generated high rainfall intensities during rainfall events lasting for 2 5 5 5 h max 54 l s 1 ha 1 as shown in fig 5 the maximum 20 min rainfall intensity recorded during one of these events equaled 18 4 l s 1 ha 1 pt 20 0 1 29 2 mm whereas for 30 min rainfall events the maximum intensity equaled 24 7 l s 1 ha 1 pt 30 0 1 33 4 mm in turn the processes in the warm front zone caused generally higher rainfall depth however due to their long durations 5 5 10 5 h their intensity was even halved up to 11 l s 1 ha 1 the 20 min rainfall intensity in these events was equal to 17 6 l s 1 ha 1 pt 20 0 1 16 8 mm while for 30 min rainfall events the intensity was 20 1 l s 1 ha 1 pt 30 0 1 20 3 mm the mean annual number of rainfall events caused by convection in air masses reached 14 3 the duration of these rainfall events in kielce did not exceed 150 min these events were characterized by low depths that rapidly increased along with the duration up to 40 5 mm over 137 min these rainfall events had high mean intensities reaching 136 l s 1 ha 1 fig 5 the mean 20 min rainfall intensity in these events reached 11 2 l s 1 ha 1 pt 20 0 1 24 8 mm whereas that of the 30 min events was 14 0 l s 1 ha 1 pt 30 0 1 28 1 mm rainfall events in convergence zones occurred in kielce 2 3 times a year on average their origins were connected with deep centers of low atmospheric pressure or a series of low pressure centers highly dynamic and high magnitude processes caused long lasting rainfall events 10 5 h with increasing rainfall depths max 155 2 mm but these events did not have very high mean intensities not exceeding 22 l s 1 ha 1 szeląg et al 2020 the maximum 20 and 30 min rainfall intensities recorded during these events were comparable and reached 4 7 l s 1 ha 1 pt 20 0 2 21 7 mm and 5 0 l s 1 ha 1 pt 30 0 2 21 6 mm respectively 2 5 2 determination of the empirical rainfall distribution and fitting the theoretical distribution using bootstrap versioning of the univariate goodness of fit test results step 6 on the basis of the selected rainfall events the time series of rainfall events with different origins convective in air mass frontal convergence zone were determined based on their durations next the empirical distributions of the selected rainfall data were indicated and fitted with theoretical distributions to obtain the best possible fit between the theoretical distributions and empirical data continuous data the following distributions were considered gamma gev log normal exponential pareto and weibull guo and adams 1998 adams and papa 2000 guo et al 2018 the assessment of correspondence of the empirical and theoretical distributions was performed using the bootstrap version of the kolmogorov smirnov k s test with stephenson modification the anderson darling test and the cramer von mises test darling 1957 anderson 1962 stephenson 2002 razali and wah 2011 the whole monte carlo simulation procedure in goodness of fit testing was presented in savapandit and gogoi 2015 the proposed number of resampled data was 40 times larger than the number of samples in the original data wang et al 2011 there are two types of bootstrap estimations namely parametric and nonparametric estimations the former is more popular in the context of goodness of fit testing in which samples are drawn from theoretical distributions with parameters estimated based on the original data in the other estimation samples are drawn from original data the main reason the resampled version of the k s test was used was that the distribution parameters were estimated from the data the issue with the classical kolmogorov smirnov goodness of fit test in such situations has been widely commented on stephens 1974 d agostino 2017 a total of 5000 samples were taken for the simulation and a nonparametric approach was used savapandit and gogoi 2015 for empirical distributions covering the number of rainfall events in the assumed time period t 5 10 years the following distributions were analyzed poisson s and geometric guo and dai 2009 to assess the compatibility of the matching empirical and theoretical distributions the χ2 values were calculated nist sematech 2012 2 5 3 synthetic rainfall generators the monte carlo method step 7 the mathematical model employed the synthetic rainfall generator created for modeling the operating conditions of a storm overflow as discussed by szeląg et al 2020 this approach accounted for the possible correlations of independent variables in the logit model to the identification of stormwater flooding in a single rainfall event the iman and conover 1982 modification in the stratified latin hypercube sampling monte carlo method was employed for this purpose yin et al 2011 schmidt et al 2019 in the applied approach the rainfall data were separated according to their origin convective frontal or in a convergence zone and rainfall simulations were carried out independently for each group apart from the rainfall origin this paper analyzed the impact of rainfall generator simplifications on the results of stormwater flood events simulations in the assumed period of time two approaches were analyzed in the work in the first approach the number of stormwater flood events was calculated by assuming the mean annual number of rainfall events convective frontal and convergent zones in the synthetic rainfall time series obtained in this way the number of rainfall events in t consecutive years was constant in turn in the other approach based on the theoretical distributions of the annual number of rainfall events of the appropriate origin the number of rainfall events over a given year was first modeled followed by the rainfall characteristics for instance 5 year synthetic rainfall time series were obtained by combining five independent synthetic rainfall time series szeląg et al 2020 2 6 calculation of the influence of catchment characteristics and rainfall origin on the probability of stormwater flooding in a rainfall event step 8 based on the synthetic rainfall generator szeląg et al 2020 calculations of statistically significant rainfall data were performed n 10 000 samples with a stratified monte carlo method iman conover these analyses were conducted for convective and frontal rainfall events and for rainfall events that occurred in convergence zones the obtained calculation results were substituted into equation 6 and the probability of stormwater flooding in a single rainfall event p caused by rainfall with the defined origin was calculated for the assumed catchment characteristics table 1 shows only the statistically significant outputs at the assumed confidence interval in each of the samples convective frontal and convergence zone rainfall each involving 10 000 simulations based on the determined p value the indicated number of stormwater flood events was identified for the cases in which the determined p value indicated rainfall flooding in a rainfall event the mean rainfall intensity equal to i 166 7 ptot tr l s 1 ha 1 was determined based on the pf value calculations for convective frontal and convergence zone rainfall as well as the determined values the empirical distribution function cumulative density function cfd was used using the obtained calculation results p and novf denoting the number of stormwater flood events in a rainfall event in 10 000 samples histograms were created first then the probability density distributions and on their basis the cumulative density distributions were determined 2 7 modeling the number of flood events in the catchment considering the rainfall origin step 9 the methodology for determining the number of stormwater flood events was based on a logit model equation 3 and a synthetic rainfall generator accounting for the rainfall event origins the mean annual numbers of rainfall events m caused by convective mconv frontal mfron and convergence zone mc zone rainfall given in section 2 5 1 were assumed for the calculations to model the t yearly synthetic rainfall time series using the rainfall generator m t n simulations were carried out for convective frontal and convergence zone rainfall the applied approach has been used in the literature and has been confirmed by numerous works on the topic muhaisen et al 2009 fu and butler 2014 szeląg et al 2020 for instance to model 5 year time series of convective frontal and convergence zone rainfall 14 3 5 10 000 16 5 10 000 and 2 6 5 10 000 rainfall event simulations were conducted respectively the obtained rainfall data for the assumed catchment characteristics were substituted into the logit model equation 3 thus the p value was determined and in the period of t years the number of stormwater flood events caused by rainfall with the corresponding origin was calculated on the basis of the calculation results the total number of stormwater flood events novf in the studied period was calculated as the total number of stormwater flood events caused by convective frontal and convergence zone rainfall thus the empirical distributions cdfs were calculated in the manuscript the number of stormwater flood events was simulated for test catchments a b c and d over periods of 5 and 10 years accounting for the rainfall origin 2 8 modeling the number of stormwater flood events while taking into account the dynamics of changes in the catchment characteristics step 10 the land use changes within the catchment area and the stormwater network development e g impervious and pervious areas length and volume of channels unit channel length per impervious area were described using the following model ciupa 2009 freni et al 2010 jacobson 2011 triantakonstantis and mountrakis 2012 zhuk et al 2020 9 d t d 0 d m a x d 0 t t a where d0 is the initial numerical value of a selected catchment or stormwater network characteristic dmax is the maximum numerical value of the catchment characteristic after period t t is the number of consecutive simulated years where t 0 1 2 3 t and a is a shape parameter determining the dynamics of changes in the characteristics of the catchment over time t the relationship proposed above makes it possible to simulate any given dynamics of changes in the selected characteristics of the catchment the advantage of this method is that it makes it possible to model slow and rapid changes in selected variable values d in a short period of time by appropriately selecting the shape parameter the algorithms used to prepare the input data to simulate the multiannual number of stormwater flood events with changing catchment characteristics in consecutive analyzed years is presented in fig 6 for the 5 and 10 year periods with the number of samples n 10 000 and two catchment characteristics changing within the calculation period d 1 f t and d 2 t initially in line with the methodology described in section 2 5 3 the synthetic time series of rainfall of convective frontal and convergence zone origins were modeled in the analyzed time period t the calculations were performed assuming a mean number of rainfall events the simulations involved only the rainfall characteristics contributing to stormwater flood events the catchment characteristics were assumed to change annually i e the values of d obtained by means of equation 9 corresponded to consecutive annual synthetic rainfall periods d where t 0 1 2 3 t consecutive simulated years d1 0 d1 1 d1 2 d1 3 d1 4 values of catchment d1 characteristics calculated from equation 9 for consecutive t years d2 0 d2 1 d2 2 d2 3 d2 4 values of catchment d2 characteristics calculated from equation 9 for consecutive t years n number of samples from the monte carlo simulation dc0 dc1 dc2 dc9 yearly synthetic time series of rainfall events for convective rainfall df0 df1 df2 df9 yearly synthetic time series of rainfall events for frontal rainfall dcz0 dcz1 dcz2 dcz9 yearly synthetic time series of rainfall events for a convergence zone the exemplary allocation of catchment characteristics imp impu and gk in line with fig 6 over a 5 year period for values of imp0 0 40 impu0 0 35 and gk0 0 035 m ha 1 as well as a 1 0 is presented in fig 1si 2 9 modeling the number of floods in the catchment taking into account the changing number of rainfall events per year of convective frontal and convergence zone origins step 11 in this study the number of stormwater flood events in a catchment was simulated based on the determined discrete distributions describing the annual number of rainfall events of convective frontal and convergence zone origins and distributions of continuous values describing rainfall characteristics for this purpose the calculations of the annual number of rainfall events of respective origin were conducted first in the case of a calculation period longer than a year the number of rainfall events of the assumed origin was added until the assumed length of the time period t was achieved the number of samples of periods describing the series of rainfall events adopted to calculate the number of stormwater flood events equaled 500 using the developed rainfall characteristic generators section 2 5 3 rainfall data simulations with 10 000 samples were conducted for the assumed calculation period t yielding 500 10 000 simulated events for the assumed catchment characteristics and developed synthetic rainfall time series accounting for the stochastic nature of the number of rainfall events the probability of stormwater flooding in a catchment was calculated enabling the determination of the number of flood events and the preparation of cdf curves 2 10 verification of the model results of the number of stormwater flood events in the catchments obtained by applying a hydrodynamic model swmm step 12 in this study an original method was proposed for verifying the results of simulations obtained with a mathematical model in these simulations changes in catchment characteristics occurred in consecutive simulated years table 1 in this approach the allocation of the numerical values of catchment characteristics to consecutive years created the basis for analyses as discussed in section 2 8 while verifying the proposed mathematical model for simulating the number of stormwater floods in period t using a hydrodynamic model it should be kept in mind that the catchment characteristics assumed for analyses figs 6 and 1si can differ from the numerical values measured in the models of catchments a b c and d fig 3 therefore appropriate modifications must be prepared as shown in fig 7 the catchment imperviousness imp modification is shown as an example where b 1 2 3 p number of subcatchments in the hydrodynamic model below catchment c analyzed for stormwater flooding bc 1 2 3 number of subcatchments in catchment c analyzed for stormwater flooding fu fimpu impu gk xc dc ltot lk markings correspond to those in fig 2 β βu calculation coefficients determined as the quotient of imp after modification and imp present model and mof t β βu swmm model with the values of catchment characteristics d f t corrected with β and βu the exemplary allocation of catchment characteristics imp impu and gk in line with fig 7 over a 5 year period for values of imp0 0 40 impu0 0 35 and gk0 0 035 m ha 1 as well as a 1 0 is presented in fig 2si in this paper the verification of the number of stormwater resulting from convective frontal and convergence zone rainfall obtained with the proposed model in catchments a b c and d over periods of t 5 and 10 years was performed using the hydrodynamic catchment model section 2 4 assuming constant catchment characteristic values the verification of the correctness of the developed mathematical model was conducted using the hydrodynamic model in line with the algorithm shown in fig 7 for dynamically changing catchment characteristics for periods t 5 and 10 years using the example of catchment c fig 3 catchment c was selected for these analyses because it can be considered a small urban catchment typical for kielce and other cities in poland imp impu 0 40 0 50 ciupa 2009 wałek 2019 3 results 3 1 the logistic regression step 2 in an effort to generalize the measurements of the stormwater network operation rainfall data and catchment characteristics a logistic regression model was developed to simulate floods in a single rainfall event on this basis the relationship can be expressed as follows 10 p e x p α 1 p t o t α 2 t r α 3 i m p α 3 i m p u α 4 g k α 0 1 e x p α 1 p t o t α 2 t r α 3 i m p α 3 i m p u α 4 g k α 0 where ptot is the rainfall depth in a given rainfall event and tr is the duration of rainfall the numerical values of αi coefficients in equation 10 the standard error of the estimations and the measures of fit of the calculations to the measurements including the sensitivity specificity and accuracy are given in table 2 based on the data listed in table 2 it can be stated that among the analyzed model parameters the rainfall depth and duration the imperviousness of the surface and the stormwater network density significantly influence the probability of occurrence of stormwater flooding in a rainfall event at the established significance level this is confirmed by the results of test probability calculations which do not exceed the critical value of 0 05 for statistically significant independent variables the obtained results are confirmed by the findings from the analyses conducted by zhang and singh 2007 and fu and butler 2014 who used rainfall depths and durations while modeling the stormwater network operation and identifying the flood events to determine their volumes these results are also confirmed by the results obtained by thorndahl et al 2008 who analyzed the stormwater network operation by accounting for the uncertainty of the hydrodynamic model using the glue method and proved the significant influence of the ptot and tr values on stormwater flooding similar results were also obtained by zhou et al 2019 who reported that the mean rainfall intensity influenced stormwater flooding in jixing and zhejiang provinces in china the simulations performed by jato espino et al 2018 for a small urban catchment 10 35 ha confirmed the results obtained in this paper and the effect of imperviousness of the catchment affected by the flooding and the areas located downstream on stormwater flooding the obtained relationships are also confirmed by the calculations of jato espino et al 2018 2019 in the espoo catchment finland as well as li and willems 2019 in the marxem and duerne catchment belgium which showed that there is no influence of the temporal rainfall distribution on the stormwater flooding in the catchment in turn the results of jato espino et al 2018 as well as li and willems 2020 showed the influence of rainfall frequency on the stormwater flooding phenomenon while analyzing the models for the espoo finland as well as marksem and duerne belgium catchments it was found that it is not possible to apply them for rainfall event with an observed rainfall depth and duration the model proposed in this paper is devoid of this limitation which enables its practical use for calculating the number of stormwater flood events for the assumed catchment characteristics the influence of temporal rainfall pattern on stormwater flooding in quantitative terms volume area depth water velocity rather than qualitative terms as presented in the studies of jato espino et al 2018 2019 and li and willems 2019 2020 has been demonstrated by many researchers studying on hydrodynamic modeling of catchments wang et al 2019 zeng et al 2021 szeląg et al 2021 these authors have also expressed the need to develop rainfall models to simulate the rainfall events that condition maximum hydraulic overloads of stormwater networks ball 1994 dao et al 2021 the obtained results show high correlations with the measured data as indicated by the sensitivity specificity and accuracy values out of 41 stormwater flood episodes the calculations agreed with the measurements in 39 events sens 95 29 whereas for 110 events where floods did not occur concurrent results were obtained in 101 events spec 92 23 therefore out of 151 rainfall events the simulation results agreed with the measurements in 140 episodes the course of the receiver operating characteristic function also indicated a good fit of the model the graph presents the optimal p threshold according to the youden index which simultaneously maximizes the sensitivity and specificity fig 8 the fit obtained in this work indicates that the developed model does not entirely explain the stormwater flooding phenomenon in an urban catchment the considered processes in the analyzed catchments may also be affected by dry periods the humidity of pervious areas the retention of impervious and pervious areas and the network geometry in the studied catchments teng et al 2017 mignot et al 2019 the calculation results of li and willems 2019 for a small urban catchment in belgium showed the influence of catchment retention and dry period on the occurrence of stormwater flooding it cannot be ruled out that in the analyzed case the temporal rainfall pattern in the event affects the volume stormwater flooding and the method applied to identify its variability during the rainfall is a simplification determination of maximum rainfall depths at 20 and 30 min nevertheless it can be widely applied at the stage of developing statistical models and analyzing stormwater flooding in urban catchments jato espino et al 2018 li and willems 2020 considering the remarks above it is advisable to continue the simulation analyses aimed at implementing advanced computational methods to identify the temporal rainfall pattern in an event e g fractal geometry methods topological methods chaos theory etc and to determine their influence on the occurrence of stormwater flooding in a catchment gutiérrez et al 2006 in this context it is also advisable to extend in future the scope of the research conducted in the considered catchments taking into account the other definitions of stormwater flooding schmitt and scheid 2020 and to develop the models to identify this phenomenon considering the increasing role of catchment retention land use and landform as well as channel retention further analyses are recommended to determine the influence of uncertainty in calibrated parameters of hydrodynamic models using the glue method and catchment characteristics on the occurrence of stormwater flooding in addition to the selection of appropriate independent variables to identify stormwater flooding the appropriate choice of machine learning method is also of great importance jato espino et al 2019 reported higher agreement of calculation results to measurements in the multilayer perceptron model than in the logistic regression model in addition the calculations conducted by ke et al 2020 for catchments in china s jixing and zhejiang provinces confirmed the feasibility of using the random forest method and boosted trees to simulate stormwater flooding therefore further analyses are needed to reduce the uncertainty of calculation results table 2 and improve the predictive ability of the model this approach combined with advanced methods to describe the temporal rainfall pattern in an event can confirm its influence on stormwater flooding 3 1 1 sensitivity analysis while developing the statistical models in this case logit apart from identifying statistically significant parameters it is important to identify the influence of the determined independent variables on the calculation results i e stormwater flooding probability thus following the calculation algorithm fig 1 and using the obtained logistic regression model a sensitivity analysis was performed by determining the sensitivity coefficients from equation 8 the sxi values were determined by analyzing the influence of each parameter in the logit model on the results of the pf calculation for the data according to table 1 in the convective frontal and convergence zone rainfall groups table 3 on the basis of the data shown in table 3 it can be stated that the longer the rainfall event duration tr is and thus the lower the rainfall intensity i is the higher the sensitivity of the model for identifying stormwater flooding is this was confirmed by the calculated values of sptot and str which were equal to 3 57 and 15 19 for convective rainfall and to 11 38 and 19 99 convergence zone rainfall respectively in the case of simp simpu and sgk different sensitivity coefficients were obtained in each catchment taking these results into account simp f impu imp simpu f imp impu sptot f ptot tr and str f tr ptot were determined for the highest intensity rainfall during a rainfall event and gk 0 03 m ha 1 mean value for the investigated catchments the results of the analysis are presented in fig 9 the curves in fig 9a and b confirm the linear increases in the simp and simpu values respectively resulting from the increased catchment imperviousness imp and impu the determined sensitivity coefficient values indicate that the value of imp has a greater effect on the p value than the value of impu does simp imp 0 3 0 5 impu 0 3 0 5 3 2 5 6 and simpu imp 0 3 0 5 impu 0 3 0 5 1 6 2 8 the obtained values of sptot and str are greater than those of simp and simpu fig 9a d in the case of sptot it was noted that for tr 90 240 min an increase in the rainfall depth leads to a greater sensitivity coefficient value fig 9c for the analyzed values tr 30 40 50 and 60 min it was observed that in an appropriate range of ptot an increase in sptot occurs up to a maximum value then a further increase in ptot reduces sptot fig 9c moreover it was observed that the longer a rainfall event was the higher the str value was fig 9d in the tr range of 25 90 min ptot also affected the str value as confirmed in the analysis of the curves in relation to the literature brown et al 2007 fraga et al 2016 the influence of the rainfall intensity and catchment characteristics on the determined sxi values has not been presented thus far this fact is of practical importance because it may be used for modifying the model calibration methodology which requires further detailed analyses in urban catchments this aspect can be used while developing models to simulate stormwater flooding in terms of volume and the methods to identify the parameters of hydrodynamic models behrouz et al 2020 kim et al 2021 in addition in the context of models to simulate the volume or area of stormwater flooding cheng et al 2019 the analyses aimed at capturing the temporal rainfall pattern in an event at the stage of sensitivity analysis seem advisable which may enable the appropriate selection of calibrated model parameters and thus reduce the uncertainty of simulation results on the basis of the prepared curves it can be observed that the rainfall characteristics have a key influence on the probability of occurrence of stormwater flooding in a rainfall event fig 9 out of the considered parameters the rainfall depth has the greatest influence whereas the rainfall duration has a much smaller effect this relationship was confirmed by the analyses conducted by brown et al 2007 on the example of an urban catchment in the united kingdom as well as by the analyses performed by thorndahl and willems 2008 who employed the form modeling method the relationships connected with the catchment characteristics obtained in the study were confirmed in the paper by jato espino et al 2018 who investigated the phenomenon of stormwater flooding in a small urban catchment in finland the relationships obtained in the present work confirmed the influence of the imperviousness of the catchment and the stormwater network characteristics on the occurrence of stormwater flooding 3 2 logit model verification with the calibrated hydrodynamic catchment model swmm step 3 to verify the prepared logit regression model simulations were carried out with a hydrodynamic model within the location of subcatchments a b c and d for this purpose the data obtained from the measurements used to build a logit model were utilized a comparison of the measurements and the calculations using the swmm hydrodynamic model and logit model for selected rainfall events highest intensity in catchments a b c and d is presented in table 4 where meas the observed measured stormwater flood events in catchments a b c and d respectively swmm results of the simulations performed with the swmm model in catchments a b c and d for the observed rainfall events when stormwater flooding was confirmed logit results of calculations carried out with the logit model pertaining to the number of stormwater flood events for the observed rainfall events on the basis of the numerical data listed in table 4 it can be stated that the logit model predicts a similar number of stormwater floods in individual catchments in subsequent years as the hydrodynamic model the performed calculations indicate that for most of the analyzed rainfall events in the multiannual period 2008 2019 the calculation results with regard to stormwater flood events during the observed rainfall events are in line with the measurements on the basis of these calculations it can be stated that for catchments a 10 years and b 12 years the number of stormwater flood events obtained from the measurements and simulations with the logit model are identical and are equal to 8 and 12 respectively in the case of catchment c 9 years the number of stormwater flood events obtained from measurements 13 is lower than the value indicated by the logit model 15 by two events for catchment d the stormwater flood events obtained from the measurements is equal to 10 while the number obtained from the logit model is 9 the results obtained in such a way confirm that the logit model is a useful tool and can be used to simulate stormwater floods in urban catchments on the basis of the prepared model it can be stated that there is no need to conduct continuous measurements of stormwater network operations the conducted analyses focused on seeking the independent variables and these values were quick and easy to determine e g by using the available spatial data on land development or the stormwater network without the need to conduct additional calculations or identify the hydrological characteristics of the catchment such as the runoff path or concentration time which requires hydrological knowledge this is a significant simplification compared to the models used thus far for identifying stormwater flooding in rainfall events jato espino et al 2018 li and willems 2020 at the same time a mathematical model was applied for further simulation analyses this process is described in later sections 3 3 determination of the empirical rainfall distribution and the fitting of the theoretical distribution using bootstrap versioning of the univariate goodness of fit test results step 6 the theoretical distributions were adjusted based on the empirical distributions in accordance with the dwa a 118e 2006 guidelines and independent variables describing stormwater flood events ptot tr and m the calculation results of the selected distributions empirical parameters and the test statistics used to assess the fit of the theoretical and empirical distributions are presented in tables 5 and 6 general equations describing the theoretical distributions of the log normal gev gamma geometric and poisson distributions are given in si 3 4 calculation of the influences of the catchment characteristics and rainfall origin on the probability of stormwater flooding in a rainfall event step 8 using the developed calculation algorithm fig 1 and accounting for the varied values of the catchment characteristics imp and impu as well as the rainfall origin the probability of flooding in a rainfall event was determined for this purpose simulations of rainfall series n 10 000 were carried out using the mc method with the iman conover modification the results of the calculations are presented in fig 10 on the basis of the resultant curves it can be said that stormwater flooding in the studied catchment takes place during convective fig 10 and frontal rainfall events fig 3asi support information this is confirmed by the specific stormwater flooding occurrence probability values in a rainfall event p no stormwater flood events were noted in the convergence zone rainfall events fig 3bsi on the basis of the calculations it was noted that for convective rainfall the percentile values for which p 0 are not lower than 0 72 while for frontal rainfall the percentile values for which p 0 are not lower than 0 999 these results confirm that in the catchment the stormwater flood events resulting from frontal rainfall events is unlikely the observed stormwater flood events in the catchment are a result of convective rainfall in the air mass in terms of stormwater system operation and in the context of literature data garcía bartual and andrés doménech 2017 dao et al 2021 it enables identifying the hydraulic overload of the drainage system this is extremely important from the point of view of making decisions on potential stormwater system modernization and appropriate selection of solutions enabling improvement of its operating conditions the sole information on the influence of area imperviousness at the stage of hydrodynamic modeling of a catchment is a simplification of the modeled phenomenon and there is a need to also account for the catchment retention and stormwater network capacity however from the point of view of analyses at the urban spatial planning stage this is in fact the only reliable information which can be useful for modeling the stormwater flooding processes in catchment areas it can be stated that the increases of imperviousness of the analyzed catchment imp and the areas located downstream impu influence the occurrence of stormwater flooding on this basis it was found that the higher the imperviousness of a catchment is the greater the probability of the occurrence of flooding in the catchment is this finding is confirmed by the analyses of the results obtained by jiang et al 2018 for selected cities in china in which the annual rainfall depth was equal to 500 1700 mm this result is also confirmed in the analyses by ress et al 2020 who investigated the operation of stormwater networks in the rocky banch catchment in columbia for impu 0 50 as well as for imp 0 50 and imp 0 40 the values of p 90th percentile equal 0 038 and 0 151 respectively in turn for impu 0 40 as well as for imp 0 50 and imp 0 40 the values of p 90th percentile are equal to 0 276 and 0 535 respectively this indicates that the urbanization of the catchment in general impu and locally imp has an impact on the stormwater flood events occurring during rainfall events which is important at the catchment management stage the results of the analyses are in accordance with the studies by jato espino et al 2019 who conducted research on a small urban catchment in finland as a result they only analyzed the stormwater flood events resulting from rainfall events the occurrence of which is difficult to connect with atmospheric circulation the formation of air masses or rainfall data that can be measured using a rain gauge barnes et al 2020 in the presented solution these shortcomings were eliminated to enable the identification of stormwater flood events in a catchment for rainfall event to complete the calculations described above the curves fig 11 showing the probability that the rainfall intensity would not exceed the value leading to stormwater flooding within the studied catchment with the selected characteristics were indicated the calculations assumed values of impu and imp in the range of 0 30 0 50 and gk 0 01 m ha 1 based on the appropriate curves it can be established that for convective rainfall the minimal mean rainfall intensity i value is not lower than 74 l s 1 ha 1 the relationships obtained below indicate that for convective rainfall the variability between the 5th and 95th percentiles in i leading to stormwater flooding in a small urban catchment is equal to 83 176 l s 1 ha 1 in the case of frontal rainfall for the analyzed range of imp impu 0 3 0 50 and gk 0 01 m ha 1 it was observed that i figs 4si and 5si the obtained curves confirm the significant influence of changes in catchment imperviousness on the maximum rainfall intensity i value causing stormwater flooding in a small urban catchment for example for impu 0 50 and convective rainfall an increase in imp from 0 30 to 0 50 results in a reduction in the maximum rainfall intensity 50th percentile leading to stormwater flooding from 127 l s 1 ha 1 to 113 l s 1 ha 1 the relationships described above have not been investigated by other authors working within similar topics thorndahl and willems 2008 thorndahl 2009 despite their practical application in preparing early warning systems against flooding risks in urban catchments caused by intensive rainfall garcía bartual and andrés doménech 2017 maier et al 2020 the proposed solution would enable appropriate decisions to be made regarding the further development of catchments in the context of reducing the number of stormwater floodings improving the operating conditions of the stormwater system and maintaining high living standards for residents in urban areas currently the abovementioned aspects have only been considered in the literature where they were identified with simulations that used calibrated models of the studied catchments and did not consider the origin of rainfall fu et al 2011 fu and kapelan 2013 garcía bartual and andrés doménech 2017 it seems advisable to integrate the weather forecast models including extreme rainfall and to use on line data enabling their identification at the same time it seems necessary to extend the logit model and include the criterion of flooding in the calculations as a condition in which the road lane is filled with stormwater and flooding occurs leading to economic losses in this approach considering temporal pattern of rainfall may be crucial in identifying flooding due to the dynamics of filling retention within the road lane schmitt et al 2004 3 5 modeling the number of flood events in the studied catchment considering the rainfall origin steps 9 and 12 in an effort to assess the veracity of the obtained results calculations of the multiannual numbers of stormwater floods t 5 and 10 years in subcatchments a b c and d were carried out using the mathematical model described above and the hydrodynamic model of the catchment these calculations were performed for convective and frontal rainfall events the measurement results of the number of floods 2008 2019 the calculations performed using the catchment model constant simulations and the mathematical model developed with measured data for t 5 years are included in fig 12 the results of analyses for the period of t 10 years are presented in the support information fig 6si on the basis of the determined curves it can be stated that the calculated values of 50 percentiles number of stormwater flooding for the period of 5 and 10 years calculated by means of swmm and proposed model for subcatchments a b c and d indicate high convergence the difference in value n ovf for convective rainfall figs 6sia 12a obtained by means of continuous calculations and the model described in fig 2 does not exceed two floodings which proves the usefulness of the proposed simulation algorithm this indicates that the proposed model can be applied to further analysis involving the assessment of the impact of catchment characteristics on the number of stormwater floodings in an urban catchment moreover while analyzing the number of stormwater floodings in the considered catchments a 3 5 b 5 c 7 8 and d 8 9 for a 5 year period fig 12a it can be stated that the results of swmm simulations and measurement data table 4 are within the range of the obtained solution on the basis of the performed simulation it can be stated that number of stormwater floods for analyzed period t 5 and t 10 years indicates the issues related with problems of the stormwater network operation which confirms the necessity of implementing the sustainable development policy simultaneously the results confirm that the obtained model can be a useful tool for preliminary analyses of land use in urban catchments it is especially important in the course of making the decisions concerning the directions of urban development issuing building permits and development conditions taking into account construction solutions and materials used for building roads parking lots etc 3 6 modeling the number of flood events taking into account the dynamics of changes in the catchment characteristics steps 10 and 12 the presented paper analyzed several calculation variants of land use changes over periods of 5 and 10 years table 7 in variants i iii it was assumed that the dynamic changes that occur over time involve catchment imperviousness imp f t whereas impu was considered to be constant the variability in gk f t in catchment c which resulted from changes in the catchment imperviousness in consecutive simulated years was accounted for in the calculations the gk value was calculated for the set values of imp equation 9 in line with the methodology presented in section 2 10 in the variants iw iiw and iiiw both the values of imp f t and impu f t were determined according to equation 5 in subsequent simulated years t the assumed values of a table 7 enable an analysis of the changes in catchment characteristics over time which may have a practical influence on the spatial development plans in urban catchment areas and thus the sustainable development of urbanized areas the numbers of stormwater flood events resulting from convective and frontal rainfall events were calculated for the assumptions presented in table 7 the paper showed the results of calculations variant i iii and iw iiiw for the period of 5 years figs 13 and 14 and the data for a period of 10 years were presented in si figs 7si and 8si the results of the calculations performed with the proposed model were verified based on catchment c as a representative of the city of kielce ciupa 2009 taking into account the land development slope and density of the stormwater network the calculations presented above fig 12 confirm the relationships shown in fig 14 therefore it can be stated that the dynamics of changes in the selected catchment characteristics influence the number of multiannual stormwater floods in the catchment in the case of frontal rainfall it was observed that in each of the considered calculation variants in the 5 year period the number of stormwater flood events was equal to zero up to the 99th percentile value this was also confirmed by the results of calculations performed for the considered variants using the hydrodynamic model on the basis of the obtained curves fig 13 a b 14 a b it was observed that the highest number of stormwater flood events was obtained for a 0 5 in the impu range of 0 3 0 5 for instance for a 0 5 with impu 0 3 and impu 0 5 the numbers of stormwater flood events in a 5 year period are equal to 7 and 8 respectively 50 percentile whereas for the 10 year period these numbers are equal to 14 and 17 respectively for a 2 0 the calculated number of stormwater flood events in a 5 year period is the lowest among the analyzed variants i iii the numbers of stormwater flood events in the 5 year period for a 2 0 with impu 0 3 and impu 0 5 equal 6 and 7 respectively in turn for the 10 year period these numbers equal 13 and 15 respectively while analyzing the obtained results figs 13 and 7si it was noted that when modeling the number of stormwater flood events in the 5 and 10 year periods attention should be given to the relationship between imp and impu for instance the numbers of stormwater flood events for the 10 year period for a 2 0 and impu 0 5 and for a 0 5 and impu 0 4 are identical and equal 15 moreover on the basis of these calculations it was established that 14 stormwater flood events occurred for a 0 5 and impu 0 3 as well as for a 1 0 and imp 0 4 the results of the analyses in figs 13 and 14 and 8si are also confirmed in the simulations performed assuming simultaneous changes in imp f t and impu f t in consecutive years the number of stormwater flood events in the 10 year period for a 2 0 is the lowest out of the analyzed variants and is equal to 7 whereas for the 10 year period it equals 15 for the 5 year period the numbers of stormwater flood events for a 0 5 and a 1 0 are identical and equal 8 for the 10 year period the highest number of stormwater flood events novf 17 was obtained for a 0 5 and at least one fewer flood event was obtained for a 1 0 in the case of frontal rainfall the numbers of stormwater flood events in the periods of 5 and 10 years are equal to 0 for the 50th percentile for the 5 year period the number of stormwater flood events for the 99th percentile was equal to 1 while for the 10 year period it was equal to 0 96 empirical distributions determining the total number of stormwater flood events over the period of 5 10 years figs 9 12 si were also determined for the analyzed cases figs 13 and 14 their course confirms that the values of the number of stormwater flood events are identical in comparison with the distributions prepared for convective rainfall it proves that stormwater floodings occur due to convective rainfall which may constitute the basis for determining the extreme most unfavorable conditions of stormwater system operation the analysis of the obtained stormwater flooding simulation results over periods of 5 and 10 years 50th percentile performed using a hydrodynamic model and the developed mathematical model indicated a high goodness of fit of the stormwater flooding calculations the difference between the calculation results obtained with the swmm model and the devised tool for the 5 and 10 year period equaled 1 flood event therefore the obtained result confirms the possibility of employing the developed tool for conducting stormwater network operation analyses in terms of spatial development plans the curves obtained in figs 13 and 14 confirm the effect of catchment imperviousness included in the analyses imp and catchment area below the analyzed cross section on the flooding phenomenon impu this is very important in terms of using the developed computational tool in urban spatial planning the calculations confirmed that in the case of increased catchment imperviousness and in the catchment area below the analyzed cross section the most favorable long term urbanization variant from the point of view of catchment management which determines the lowest number of stormwater flood events in the simulated period was obtained for a 2 equation 9 the assumed solution although limited to the exponential form of the model imp f t enables to calculate the number of stormwater flood events with changing dynamics of catchment imperviousness in the simulated period it is possible due to optimal selection of coefficients in equation 8 this is particularly useful when urbanization of the catchment is occurring very rapidly with respect to reducing sewer floods this would improve the effectiveness of the stormwater network and the structures located within it the approach developed here provides the possibility of simplified managing at the stage of preliminary analyses including spatial planning the catchment through spatial arrangement and by the modernization of the stormwater network the changes of imperviousness can be balanced by limiting the volume of stormwater flowing directly into the stormwater network by the construction of green roofs or by replacing the impervious areas with other types of surfaces however this requires that extend proposed model to identification of flooding events considering that the determined number of stormwater flood events for the assumed calculation period is the result of the integration of a logit model and a rainfall model in which the estimated coefficients are subject to uncertainty it seems advisable to extend the proposed approach and determine the impact of uncertainty on the number of stormwater flood events this is important from the point of view of using the obtained results to improve the conditions of stormwater system operation on a long term basis the calculations performed by szeląg et al 2020 showed that the uncertainty in the coefficients of the log normal distribution describing the average rainfall intensity in an event can be ignored in the calculation of the probability of overflow performance these results confirmed the calculations of fu et al 2011 who modeled stormwater floodings in a catchment located in the uk based on a stochastic rainfall model in order to reduce the uncertainty of the simulation results with the logit model it is advisable to improve the predictive ability of the model and implement machine learning methods used to identify stormwater flooding neural networks random forests boosted trees etc and to evaluate the impact of the simplifications adopted in the model equation 10 on the number of stormwater flood events during the calculation period the model developed in this way is particularly important in the context of its application engineering practice confirms that simple models with a small number of independent variables are widely used in practice despite the fact that their results are only a certain approximation mignot et al 2019 3 7 modeling the number of flooding events in the studied catchment taking into account the changing number of rainfall events per year convective frontal and convergence zone rainfall step 11 calculations of the number of stormwater flood events recorded over 5 and 10 year periods were performed for two cases using the developed mathematical model in the first case the mean constant number of rainfall events in a year was assumed for frontal convective and convergence zone rainfall in the second case it was assumed that the number of rainfall events throughout a year was modeled from the determined theoretical distributions the calculation results for these two cases i e the 5 and 10 year periods and imp impu 0 40 are presented in fig 15 on the basis of these results it was noted that the simulation results concerning the number of stormwater flood events obtained by assuming a constant mean number of rainfall events in the analyzed period are very similar to the calculation results obtained when the number of rainfall events is modeled this was confirmed by the determined percentile values on the basis of the created curves it was observed that omitting the variability in the annual number of rainfall events for the percentiles of 0 73 5 years and 0 67 10 years leads underestimated stormwater flood events by 1 and 3 respectively for the percentiles of 0 47 5 years and 0 40 10 years the results of the calculations related to the number of stormwater flood events were underestimated when the variability in the annual number of rainfall events was accounted for compared to the case in which a mean annual number of rainfall events was assumed for the 50th percentile identical numbers of stormwater flood events were obtained for the considered cases i e when using the mean annual number of rainfall events and the number obtained from simulations for the 5 year period 6 stormwater flood events occurred whereas for the 10 year period 12 flood events were observed in the context of the obtained results it can be stated that from the perspective of design at the conception and development stage of urban catchments it is advisable to account for the variability in rainfall events throughout a year while modeling the number of stormwater floodings in order to obtain the most accurate description of the actual conditions during the initial analyses involving the spatial development plans assuming a mean number of rainfall events enables the evaluation of the influence of the applied planning solutions on the stormwater network operation conditions and the urban development directions 4 conclusions on the basis of the analyses conducted in this study it can be concluded that the developed mathematical model can be applied to simulate the number of stormwater floods in an urban catchment in a multiannual approach from the presented simulations it can be confirmed that stormwater flooding in urban catchments can be modeled based on rainfall data the rainfall depth and duration in a given rainfall event and the characteristics of the studied catchment imperviousness of the analyzed area and land located downstream and the unit length of the main channel per the impervious area these simulations confirm that the rainfall origin has a significant influence on the modeling of the number of stormwater floods its omission results in an underestimation of the number of floods it was also determined that stormwater floods are strictly connected with the characteristics of a catchment usually occur in events caused by convective rainfalls and are rarely seen in association with frontal rainfalls it was also established that the dynamics of urbanization and changes in catchment characteristics strongly influence flooding the presented innovative method for verifying the number of stormwater flood events obtained using the developed ovfsim ver 1 software indicated a good fit with the simulation results performed using a hydrodynamic model the proposed methodology for verifying the simulations of the number of stormwater flood events in a given catchment using hydrodynamic models in which catchment characteristics change as functions of time can also be employed for the validation of models in which the development method changes during the simulated period e g as a result of the implementation of green infrastructure objects moreover the conducted studies confirm the usefulness of the developed tool for simulating the number of stormwater flood events in a catchment which constitutes a simplification in comparison to the currently used calculation tools this simplicity enables the use of the software in dispatching centers managing drainage systems in the course of stormwater network operations this tool could have a significant effect on designing and modernizing stormwater networks and on decision making connected with the development of sustainable catchments in long term planning such an approach could be used to improve the selection of concepts of land use planning with a view to reduce flooding improve the performance of stormwater systems limit the amount of contaminants introduced to receivers as well as consider the economic and social aspects of improving the stormwater system functioning the presented model also has certain limitations except for the of imperviousness of a catchment area the model does not account for stormwater retention which is usually required by local regulations the share of the impervious area in an urban catchment does not always account for the influence of the stormwater management infrastructure which is increasingly often considered during urban planning therefore at the next stage of the study it is planned to extend the model by adding parameters describing retention of imperviousness area channel retention and network layout which will enable to broaden the scope of its applicability conducting further analyses to identify stormwater flooding taking into account other criteria of its occurrence is advised in this context it is recommended to apply advanced machine learning methods modifications to logistic regression regression trees etc to identify stormwater flooding which is important from the point of view of selecting appropriate independent variables for its calculation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105335 
25617,ensemble based data assimilation da methods have displayed strong potential to improve model state and parameter estimation across several disciplines due to their computational efficiency scalability and ability to estimate uncertainty in the dynamic states and the parameters however a barrier to adoption of ensemble da methods remains namely there is currently a lack of available tools that enable efficient and scalable da in a non intrusive fashion and that support implementation flexibility this paper presents an open source software tool pestpp da that implements a range of data assimilation methods ensemble kalman filter ensemble kalman smoother and ensemble smoother using the widely known pest model interface protocols to interact with any model two iterative solutions can be used for nonlinear and or non gaussian assimilation problems to demonstrate the broad range of pestpp da applications two synthetic case studies are presented 1 the lorenz model and 2 a groundwater pumping test in the presence of a non gaussian hydraulic conductivity field keywords data assimilation inverse problem uncertainty analysis hydrology software availability name of software pest for data assimilation pestpp da developers ayman alzraiee jeremy white matthew knowling randall hunt and michael fienen year first available 2021 hardware required basic computer software required only pestpp da executable file is required to run the software for software compilation any compiler that supports c 17 features can be used visual studio project file and cmake solutions are available at https doi org 10 5066 p9ytq5py and an active provisional copy is available at https github com usgs pestpp tree develop src programs pestpp da source code availability source code is available within the open source pest code the main entry point file is named pestpp da cpp executable file standalone binaries for windows and linux are available within the open source pest cost free program language c program size executable file size is 7 48 mb 1 introduction knowledge about physical systems is usually available in two forms models and observations models encapsulate prior knowledge about the way physical processes interact and how they evolve in space and time while observations provide direct information about the natural system often noisy and sparse in space and time the optimal combination of these two sources of information can be achieved by data assimilation da da serves to produce a best representation of the dynamic states and the parameters of a dynamic system evensen 2009 fletcher 2017 law et al 2015 asch et al 2016 leeuwen et al 2015 that in turn improves model forecasts of future system behavior da techniques explicitly recognize that both models and field observations are inherently uncertain model uncertainty can be caused by parameter uncertainty unknown model inputs model inadequacy mathematical and physical process simplification structural uncertainty and parameter spatial and temporal simplification kennedy and o hagan 2001 observation uncertainty can result from inadequate or imprecise instruments human errors poor representation of time integrated dynamics and other environmental factors da methods for example the widely employed ensemble based methods evensen 2009 provide a unified framework to achieve both uncertainty reduction ur in parameters and states and uncertainty quantification uq of the uncertainty that remains ensemble based data assimilation evensen 1994 developed as an alternative to the computationally expensive extended kalman filter approximates a high dimensional first order mapping between parameters and simulated states using an ensemble of both parameter and state realizations ensemble based da methods have shown significant promise in a variety of computational fields owing to their efficiency and scalability burgers et al 1998 montzka et al 2012 a family of ensemble based da algorithms have shown particular promise including the ensemble kalman filter enkf evensen 1994 ensemble kalman smoother enks evensen and leeuwen 2000 and ensemble smooth es leeuwen and evensen 1996 these algorithms are unique in how they formulate the da problem which can be broadly categorized as batch and sequential batch da involves estimation of parameters and or states simultaneously over the entire simulation period and is common in history matching problems aanonsen et al 2009 typically characterized by large number of unknown parameters and computational intensive model runs sequential da evensen 2002 on the other hand involves estimation of parameters and or states sequentially in time which also affords benefits in terms of handling model error and is common in meteorology oceanography and crop yield models and may be characterized by conceptual models chaotic systems and shorter time horizons despite the reported potential of ensemble da methods widespread adoption of these methods is still limited in environmental modelling for decision support a key barrier to adoption is the lack of efficient and scalable da tools that combine non intrusiveness and implementation flexibility the need to make sequential da approaches with general and flexible formulations accessible to practitioners motivated the development of a new software tool pestpp da a widely applicable model independent non intrusive and scalable data assimilation software pestpp da is an open source c implementation of data assimilation methods using the widely known pest model interface protocols doherty 2004 doherty et al 2010 pestpp da fully leverages existing pest pest run management capabilities and file types control file template files and instruction files the model independent design allows the practitioner to bring sophisticated and generalized da approaches to bear in a wide range of situations and different models pestpp da implements the traditional gaussian linear ensemble based methods as described by evensen 1994 including es enkf and enks or any mix of these schemes as well as iterative solutions for these formulations for nonlinear problems that includes the multiple data assimilation mda algorithm emerick and reynolds 2012 and the gauss levenberg marquardt glm solution chen and oliver 2013 white 2018 below we provide a brief overview of the theoretical background of ensemble based data assimilation and terminology used in this paper followed by methods for solving nonlinear and non gaussian problems and some relevant details related to the implementation and function of pestpp da our presentation concludes with two synthetic problems 1 lorenz problem for sequential state estimation for a chaotic system and 2 a synthetic groundwater pumping test problem the pumping test experiment demonstrates the use of pestpp da to estimate the unknown non gaussian hydraulic conductivity field at the resolution of the finite difference grid with the best match to the hydraulic head observations 2 theoretical background this section presents key terminology and notation as well as a theoretical background of da and assimilation methods implemented in pestpp da 2 1 key terminology given the relatively few applications of sequential da with dynamic state estimation within applied environmental modelling for decision support we define the following terms to aid the reader assimilation cycle a discrete period of time during which available state observations are assimilated with the da algorithm static parameter an uncertain time invariant input quantity to the model such as system property dynamic parameter an uncertain time variant input quantity to the model that acts on a discrete interval of simulation time such as a parameter that represents model forcing simulated final state an output quantity from the model that represents the state of the simulated system at the end of the current assimilation cycle this quantity can be thought of as a forecast of system state as evaluated by the model estimated final state a quantity evaluated by the model simulated final state and adjusted by the da algorithm at the end of the current assimilation cycle estimated initial state a quantity that can be estimated by the da algorithm that is the initial condition for the current assimilation cycle simulated equivalent the simulation result that corresponds to an observation 2 2 bayesian formulation of the kalman filter consider a model that has the following generic structure 1 h t 1 u t 1 g m t h t where g is the model functional that can be a linear or nonlinear operator g represents a model that simulates time evolution of a dynamic system across the given assimilation cycle from time t to time t 1 the model requires as an input a vector of parameters m t r n m 1 where n m is the number of parameters in the period t t 1 where parenthesis indicates open interval and bracket indicates closed interval input parameters can include static and or dynamic parameters such that m t p s q t the vector p s represents static parameters p s r n p 1 and q t r n q 1 represents dynamic parameters where n p and n q are number of static parameters and number of dynamic parameters respectively static parameters p s may represent one or more physical properties that are time invariant or spatially variable e g hydraulic conductivity and specific yield in a groundwater model can be represented as a vector of values for each finite difference cell each pilot point doherty et al 2010 or each spatial zone q t 1 represents any transient input parameters in the period t t 1 such as system stresses e g groundwater recharge or pumping in a groundwater model that apply only to discrete interval s of time the model evolves initial dynamic states across the assimilation cycle from h t to h t 1 r n h 1 where n h is the number of simulated dynamic states the model can also produce other quantities u t 1 that are not used as initial conditions for the next assimilation cycle for example simulated baseflow and evapotranspiration are usually simulated states that are not used as initial conditions in hydrologic models given d t 1 r n d 1 a set of field observations that correspond to one or more of the input parameters or simulated quantities in h t 1 p s u t 1 or and q t 1 da attempts to merge prior distributions obtained from uncertain model simulation results with field observations which also contain some uncertainty defining the augmented parameter state vector to be x t 1 q t p s h t 1 h t u t 1 a general formulation of the estimation problem can be written using bayes law as follows 2 p x t 1 d t 1 p d t 1 x t 1 p x t 1 p d t 1 where p x t 1 d t 1 is the posterior probability density function pdf of x t 1 given a set of observations d t 1 p d t 1 x t 1 is the likelihood pdf that describes the deviation of model simulation results from field observations p x t 1 is the prior pdf of x t 1 and p d t 1 is the pdf of field observations also called the evidence term different possible formulations of the generalized estimation problem encapsulated in equation 2 can be defined depending on how simulation time is discretized into assimilation cycles the three main types of estimation problems are wiener 1949 carrassi et al 2018a 1 prediction which estimates p x l d t 0 with l t 2 filtering which estimates p x t d t 0 and 3 smoothing which estimates p x t 0 d t 0 where t is the maximum time index of state or observation and t 0 indicates the set of time indices between 0 and t such that d t 0 d t d t 1 d 0 notice that the formulation of the assimilation problem in equation 2 is generic where both inverse modelling and state updating is achieved simultaneously for a given assimilation cycle a simpler formulation p m d t 1 can be used when one is interested only in the inverse problem or p h t 1 d t 1 when one is interested only in state estimation problem when the model g in equation 1 is linear and when prior pdfs for both model parameters and initial dynamic states are gaussians the posterior p x t 1 d t 1 is also gaussian with a mean x a and covariance matrix c x x a calculated as follows kalman 1960 3 x a x f c x y f c y y f r 1 d t 1 y t 1 4 c x x a c x x f c x y f c y y f 1 c y x f where x f is the forecast mean of x t 1 y t 1 are simulated equivalents to the observations d t 1 c x y f is the cross covariance matrix of x t 1 and y t 1 c y x f is the transpose of c x y f c x x f is the prior covariance matrix of x t 1 c y y f is the prior covariance matrix of y t 1 and r is the measurement error covariance matrix 2 3 ensemble based methods the kf in equations 3 and 4 developed by kalman 1960 and studied in detail by jazwinski 1970 has been widely used in different fields the kf assumes that the pdf of parameters and states are gaussian distributions furthermore in a non intrusive model independent setting the cross covariance matrices in equations 3 and 4 must be evaluated via finite difference perturbations with nonlinear models the simulated states can deviate from the gaussian assumptions making the traditional kf suboptimal or perhaps even unsuitable for da additionally applying kf to high dimensional systems is usually computationally prohibitive as it requires the evaluation of large cross covariance matrices these limitations motivated the development of the ensemble kalman filter evensen 1994 which is a monte carlo based application of a bayesian update on moderately nonlinear and linear systems ensemble based methods are still based on the gaussian assumption however the posterior moments mean and covariance matrix are approximated using an ensemble of realizations of the prior carrassi et al 2018b ensemble based da methods are based on two fundamental steps fig 1 forecast and update the forecast step consists of a monte carlo simulation of the model where initial states and parameters are sampled from their prior distribution and each sampled realization is simulated in the model collectively resulting in an ensemble of simulated states the ensemble of parameters initial states and simulated states can be seen as a discrete approximation of the joint states parameters pdf where the ensemble mean and the ensemble covariance matrix approximate the first and the second moments of the multivariate gaussian distribution respectively the update step consists of conditioning of the model state parameters in each realization on field observations using the following equations evenson 1994 5 x a x f c x y f c y y f r 1 d t 1 y t 1 6 c x x a c x x f c x y f c y y f 1 c y x f where x a r n n is the analysis or updated ensemble of estimated states and or parameters at time t 1 n is the number of states and parameters to be estimated n is the number of realizations in the ensemble x f r n n is the forecast prior ensemble of states and parameters at time t 1 and r is the covariance matrix of measurement error and y t 1 r n d n is the ensemble of simulated equivalents the matrix d t 1 r n d n is the perturbed observations ensemble and is computed as d t 1 d t 1 e t 1 where e t 1 is an ensemble of measurement errors sampled from n 0 r to simplify the notations the simulated equivalents y t 1 is denoted as yf the covariance matrix c y y f r n d n d is the covariance matrix of simulated states and the covariance c x y f r n n d is the cross covariance matrix of estimated state parameters and simulated states these two matrices are computed as follows 7 c y y f y f y f y f y f t n 1 8 c x y f x f x f y f y f t n 1 where y f r n d n is the ensemble mean of y f such that each row in y f is computed as the mean of values in the corresponding row in matrix y f x f is the forecast ensemble mean of matrix x f the analysis matrix computed in equation 5 can be used to compute the posterior mean and covariance matrix of x 3 software description this section describes how different da solution methods are currently incorporated into pestpp da pestpp da is developed entirely in c and is statically linked into a stand alone executable the numerical solution of the da equations uses the eigen numerical linear algebra template library guennebaud and jacob 2010 ensembles can be evaluated in serial or in parallel via built in run managers the parallel model evaluations are implemented using a built in fault tolerant tcp ip run manager described in welter et al 2015 this run manager allows pestpp da to be parallelized across heterogenous networks and in cloud settings 3 1 forward model input output protocols pestpp da implements the widely used model independent pest protocols doherty 2015a these protocols fig 2 allow separate algorithms to interact with models by 1 changing model input files 2 running the models and 3 extracting relevant model outputs which may include unmeasured forecast quantities as well as simulated equivalents simulated equivalents refer to simulated quantities that have equivalent field observations and the difference between simulated and measured quantities are referred to as residuals or innovations pestpp da like all tools based on the pest protocols uses three types of files to achieve this interaction fig 2 these files are 1 a control file 2 template files and 3 instruction files the control file provides information to control the pestpp da solution process for example in the control file a practitioner can specify several options that can be used to control da algorithm behavior such as the size of prior ensembles inflation factors among many others see the pest user s manual in pestpp da repository for a complete description of the options and arguments used by pestpp da template files contain information about how model input files are to be manipulated while instruction files contain information that facilitate extraction of simulation results from model output files according to pest protocols a model can consist of a user defined chain of models and associated processing that are called to simulate salient aspects of a system for a complete description of the formats of template and instruction files and how they can be generated practitioners are referred to doherty 2004 as well as the pest user s manual we also note that the pyemu python package white et al 2016 has multiple utilities that facilitate generation of the entire pest interface needed to apply pestpp da 3 2 sequential data assimilation schemes time evolution of a dynamic model usually occurs according to a specified temporal discretization scheme some models allow the practitioner to choose time step sizes as part of the model inputs while other models compute the time step adaptively transient observations of system state on the other hand might be available at temporal intervals that are different from model temporal discretization to accommodate this wide range of settings pestpp da allows the practitioner to define arbitrary assimilation cycles how these cycles are defined is highly dependent on the problem at hand for example numerical weather prediction models usually assimilate observations at high frequency time steps on the order of minutes for making optimal short term high frequency forecasts while groundwater systems which typically evolve slowly might have assimilation cycles on the order of months or years to facilitate a high degree of flexibility in the specification of assimilation cycles pestpp da requires the practitioner to provide information that identifies the cycle or cycles that every observation and adjustable parameter state belongs to fig 3 this information is beyond that required for a traditional pest pest run the assimilation cycle might consist of a single time step e g cycles c 0 c 1 c 4 in fig 3 multiple time steps e g cycles c 2 and c 3 in fig 3 or even the entire simulation period as a single assimilation cycle when a cycle consists of one time step pestpp da implements sequential data assimilation schemes fig 4 such as ensemble kalman filter enkf or ensemble kalman smoother enks when all observations are assigned to a single assimilation cycle that covers the entire simulation period all the observations are to be assimilated simultaneously referred to herein as batch assimilation scheme leading to an ensemble smoother es implementation e g white 2018 fig 4c between pure sequential assimilation and pure batch assimilation practitioners can mix enkf enks and es approaches arbitrarily fig 4d shows a hypothetical situation in which observations are initially assimilated every time step cycles 1 and 2 followed by batch assimilation of a set of observations in cycle 3 and finally followed by an enks assimilation cycle 4 in which observations at time 6 are assimilated to update all historical parameters and or states although enkf and enks schemes assimilate data in multiple time cycles they differ in that the enkf updates parameters and states in the most recent time cycles using only recent observations while the enks updates all previous updated states and parameters using the most recent observations pestpp da affords the practitioners a high level of flexibility in deciding which observations are used to estimate which state parameters a parameter state indexed using cycle value i will be updated using all observations that are indexed by the cycle i a negative cycle number can be used to flag parameters states that need to be updated during all cycles the practitioner can implement sophisticated rules about how parameters and or observations are used across multiple cycles by using colon delimited expressions for example a parameter or a state indexed with a cycle number equal to 2 5 will be updated from the 3rd cycle to the 4th cycle other expressions are also possible see pest user s manual the concept of an assimilation cycle in pestpp da is abstract and is not limited to indexing the times of assimilation it can be seen as an index of the order in which assimilation of data should take place for example one might choose to assimilate all upstream streamflow gages first and then assimilate downstream gages in this case upstream streamflow observations are indexed as cycle 0 while downstream streamflow gages are indexed as cycle 1 in sequential data assimilation using enkf and or enks the model must be restarted after updating the state parameters typically in enkf and enks the model is restarted from the most recent updated state however pestpp da allows the practitioner to restart the model from any historical point this dynamic restart capability requires additional information to be included in the definition of parameters and observations used by pestpp da specifically in order for pestpp da to implement enkf or enks the definitions of parameters representing dynamic states and observations representing dynamic states must contain additional information so that pestpp da can programmatically transfer simulated or estimated final states to initial state parameters when advancing cycles 3 3 formulations of joint parameter state data assimilation pestpp da can implement a wide range of state parameters and joint state parameter data assimilation scenarios the complete joint state parameter estimation formulation includes static parameters p s dynamic parameters q t initial states h t final estimated states needed as future initial states h t 1 and other arbitrary simulation results u t 1 of interest pestpp da can be used to update any arbitrary combination of these quantities table 1 lists some of the common possible cases that can be implemented within pestpp da model parameters can be estimated in a batch table 1 case 1 or sequential table 1 case 2 manner estimation of only the dynamic states can be achieved in batch mode or sequentially several other schemes for mixing the estimation of the states and parameters can be also implemented with pestpp da in sequential data assimilation the model can be restarted using the estimated updated final state as the initial condition of the next cycle or using the model simulated states from the previous cycle with updated parameters table 1 case 4 initial states that are model simulated are considered to be more physically realistic and maintain conservation laws while using estimated updated initial states might be statistically useful and provide important insights into model behavior but may yield physically unrealistic da results pestpp da allows both options for the practitioner 3 4 algorithms for nonlinear non gaussian da kalman filter based assimilation has been shown to produce optimal solutions for linear systems with gaussian parameters states however in most practical problems at least one of these two conditions are not satisfied for example it is common that the permeability of a subsurface system consists of two or more geological facies and a bimodal or multi modal pdf is used to statistically represent the permeability moreover nonlinear models can produce non gaussian simulated states even when input parameters states are gaussian tarantola 2005 to overcome these limitations pestpp da offers two nonlinear solution methods 1 multiple data assimilation mda and 2 gauss levenberg marquart glm the traditional ensemble based estimation evensen 1994 can be considered a special case for either mda and glm a case with one iteration and without inflation of measurement error covariance and without scaling the upgrade iterative assimilation schemes are commonly used with the es however pestpp da allows the practitioner to use iterative methods with any assimilation scheme fig 5 schematically shows how iterative and sequential da is implemented in pestpp da 3 4 1 multiple data assimilation mda solution emerick and reynolds 2012 showed that multiple da iterations with inflated measurement errors by a factor equal to the number of data assimilation iterations is equivalent to one assimilation update with no inflation when the dynamic system is linear and priors are gaussian inflation factors play a role similar to lambda in marquardt nonlinear solver doherty 2015b which control the magnitude of upgrade vector inflation values greater than 1 reduce the magnitude of upgrade vector resulting in multiple small successive updates for nonlinear systems such successive small upgrades made by mda algorithm produce results that are superior to the non iterative da approaches pestpp da allows the application of mda as implemented in emerick and reynolds 2012 where the practitioner can choose the initial inflation factor reduction factor and the number of inflation factors algorithm 1 in the appendix in the absence of user input pestpp da uses default values for these control options that work well in a range of test problems pestpp da ensures that the reciprocals of all inflation factors sum to 1 since pestpp da like other tools in the pest pest suite ceases the search for an optimal solution when one of the termination criteria is satisfied pestpp da recomputes the last inflation factor such that reciprocals of all inflation factors sum to 1 more about termination criteria can be found in the pest user s manual the analysis scheme using equation 5 may have problems when the number of observations is larger than the number of realizations in the forecast ensemble or when the term c y y f r 1 has poor conditioning evensen 2009 pestpp da implements computationally efficient algorithms algorithms 2 and 3 in the appendix developed by evensen 2004 and evensen 2009 to use low rank representation of the measurement error covariance matrix to solve the analysis equation 5 3 4 2 gauss levenberg marquardt glm solution the glm solution chen and oliver 2013 is an ensembled based approximation to the tangent linear operator jacobian matrix within the iterative procedure the glm procedure minimizes the mismatch between observations and simulated equivalent values similar to pestpp ies white 2018 the glm solution algorithm implemented in pestpp da features an adaptive gauss levenberg marquardt scheme that includes backtracking and evaluation of multiple marquart lambda values each iteration see the pest user s manual for more details white 2018 3 4 3 searching for optimal solution like pestpp ies white 2018 finding the optimal solution is achieved in pestpp da by automated trialing of inflation factors and scaling factors the scaling factor can be used to reduce the magnitude of the upgrade vector in iterative methods for each pair of factors realizations in the ensemble need to be simulated by the model therefore leading to a large number of forward model runs which can be computationally prohibitive to reduce such a high computational cost a practitioner can choose to simulate a small subset of realizations to test the factors pest manual white 2018 the realization subset can be chosen randomly deterministically or based on mean objective function values the number of factors to be tested can also be controlled by the practitioner 3 5 generation of prior ensembles implementing da requires the generation of two ensembles an initial parameter ensemble and an observation error ensemble pestpp da allows practitioners to use ensembles that are generated either as part of or independently of a pestpp da analysis depending on the problem at hand the practitioner can choose to generate conditional or unconditional geostatistical realizations using external tools for example the geostatistical software library gslib deutsch 1998 or stanford geostatistical modeling software sgems bianchi and zheng 2009 to generate spatially correlated fields alternatively pestpp da can be used to generate ensembles for correlated and independent parameters using a practitioner supplied parameter mean vector and covariance matrix 3 6 localization ensemble based da provides a computationally efficient way to approximate the joint pdf of parameters states of a system however when the number of parameters states estimated is larger than the number of realizations which is a common case given the need for high dimensionality to better express uncertainty in some contexts knowling et al 2019 as well as the desire to reduce the number of forward model runs required the resulting ensemble covariance matrix is rank deficient and may produce spurious correlations between variables that are not correlated and variables separated by large distances evensen 2009 using localization can minimize such spurious correlation and allow the use of smaller ensemble sizes localization can be achieved based on prior knowledge or expert opinion of realistic correlation in many physical systems locality is measured as spatial distance or temporal distance or temporal direction e g removing correlation that would violate temporal causality as a result only observations that are close to a state parameter will be used to update that state parameter pestpp da allows practitioners to implement combined local analysis with covariance localization with two localization approaches 1 a user defined localization matrix and 2 automatic adaptive localization luo and bhakta 2020 anderson 2007 and chen and oliver 2017 provide a more detailed discussion about localization concepts 4 benchmarks and examples in practical data assimilation the true parameter state values are unknown and observations are made using imperfect sensing devices or in a noisy environment resulting in noisy observations to evaluate the performance of pestpp da a synthetic truth is constructed a priori the truth states parameters are simulated in the model to generate synthetic truth observations which are artificially contaminated by random noise the estimated parameter state values are then compared to the truth parameter state values to evaluate pestpp da performance this analysis framework is adopted in two benchmark problems as follows we first consider a well known analytical model lorenz 1996 to specifically evaluate the performance of the enkf we then consider a numerical groundwater model to evaluate performance of both sequential and batch da formulations and specifically the mda algorithm 4 1 lorenz 1996 the lorenz 1996 model lorenz 1996 herein referred to as l96 is a classical atmospheric science inspired analytical system that has been widely used to test data assimilation methods l96 is designed to represent a meteorological quantity such as vorticity in the atmosphere at equidistant points along a latitude circle it involves representation of three key atmospheric processes advection quadratic term dissipation linear term and external forcing constant term l96 is given by the following nonlinear system 9 x i t x i 1 x i 2 x i 1 x i f i 1 2 n l where x i is the dynamic state at location i and f is a static parameter representing an external forcing term and nl is the dimensionality i e number of locations along the latitude circle we employ nl 36 and f 8 f values exceeding approximately 5 yield chaotic behavior whereby small perturbations in system state cause significantly different state trajectories uniform initial states of 8 0 are specified with a small perturbation of 0 01 to the state at the 20th location the length of the simulation period is 20 time units discretized into 2000 time steps with a uniform time step of 0 01 time units following lorenz and emanuel 1998 the l96 system is solved using the runge kutta rk4 scheme implemented in scipy s ordinary differential time integrator virtanen et al 2020 here we apply enkf to assimilate spatially and temporally distributed synthetic observations through estimation of final states for each assimilation cycle table 1 case 6 an ensemble of 50 realizations is employed synthetic observations are taken i e sampled from the true trajectory at 8 equidistant sites 0 5 10 35 at a frequency of 0 2 time unit intervals i e each 20 time integration steps following a period of non observation while equilibrium initial conditions are overcome we assume an observation noise standard deviation of 1 0 fig 6 shows that the above described implementation of enkf displays a strong ability to improve system state trajectory while still maintaining variance the level of agreement e g smaller posterior variance in fig 6a reflects the availability of observations on which to condition states at this location as the distance from this sampled location increases fig 6b to c the level of agreement decreases so too does the time where the posterior encompasses the truth as expected similarly even at the 20th site where observations for assimilation are available estimated states in between observation times may show divergence from the true trajectory 4 2 pumping test to estimate non gaussian conductivity field ensemble based da assumes that both model input parameters and model response are multivariate gaussian when models are nonlinear or model input parameters are non gaussian the resulting da estimation of the posterior mean and covariance matrix becomes suboptimal or even unstable iterative da methods chen and oliver 2013 emerick and reynolds 2012 luo et al 2015 were developed and implemented in pestpp da to address this potential issue this synthetic case demonstrates the use of multiple data assimilation method mda implemented in pestpp da the testing of the mda iterative inversion is based on a synthetic two dimensional groundwater problem the two dimensional domain fig 7 a is a 1 km 1 km 50 m thick unconfined aquifer discretized into 10 000 cells 100 grid blocks along the x y horizontal coordinate directions and a single grid block along the z vertical direction the aquifer is subject to general head boundary conditions on the left and right edges of the domain at which the hydraulic head h is set equal to 40 m everywhere else no flow boundary conditions are imposed the true hydraulic conductivity of the aquifer k is assumed to be non gaussian with two facies geological formations fig 7b within each facies the conductivity is assumed stationary gaussian random field and was generated using spectral simulation pardo igúzquiza and chica olmo 1993 the geostatistical properties of the two facies formations are presented in table 2 the reader is referred to table 2 and fig 7 for further details of the model setup the saturated flow simulation code modflow nwt niswonger et al 2011 was used in this numerical experiment the simulated period consists of 24 stress periods each 30 days length each stress period is evenly divided into ten 3 day time steps as groundwater pumping continues a cone of depression develops the transient changes of groundwater level are observed at a network of 100 wells fig 7 the true observed groundwater level is measured every stress period resulting in a total of 2400 transient synthetic observations in this experiment 50 realizations are used to generate the prior k ensemble to demonstrate the capability of pestpp da to implement both standard non iterative da and iterative da for a nonlinear and non gaussian test case we compare the results obtained when implementing the two algorithms in this experiment mda is used to estimate the k field using four iterations with inflation factors all equal to 4 the prior k values are generated from a mixed gaussian distribution which is a probability distribution that is comprised of multiple gaussian distributions the clusters of k values fig 8 a roughly aligned on the one to one line lower left cluster and upper right cluster represent prior conductivity values that have correct prior geological formations while the off diagonal clusters upper left and lower right have incorrect prior formations facies with low true hydraulic conductivity but high hydraulic conductivity sampled values and vice versa when iterative solution schemes are used in pestpp da intermediate ensembles corresponding to each iteration can be saved to evaluate the progress of solution figs 8 and 9 show the progress of the iterative mda solution in the first iteration fig 8b the incorrect prior facies start to be gradually corrected in iteration 2 the estimated distribution is roughly gaussian with large variance that covers both low and high conductivity values and with intermediate mean in iteration 3 the correct multi gaussian distribution starts to emerge while the geological facies are correctly identified but hydraulic conductivity values within each facies are still inaccurate iteration 4 produces more corrections to hydraulic conductivity values within each facies and makes the spread of hydraulic conductivity around the one to one line narrower that is to say correctly estimating the facies types and conductivity values within each facies to demonstrate the performance of mda for nonlinear and non gaussian problems pestpp da was also used to estimate the unknown conductivity field using the es in which all observations are assimilated in one batch and no iterative solution is attempted the goal of this comparison is not to present a comprehensive comparison between standard es and mda but to illustrate some of the solution schemes available in pestpp da fig 10 shows a comparison between reference and estimated conductivity fields using standard es and using the iterative mda method it can be seen that the iterative mda method outperforms the standard es the estimation using the standard es produced an incorrect posterior unimodal gaussian distribution with an average hydraulic conductivity value that is roughly midway between low and high hydraulic conductivity values on the other hand the iterative mda produced the correct multi gaussian distribution and the correct mean of conductivity within each facies 5 conclusions data assimilations da methods integrate uncertain model predictions and uncertain field observations to provide an optimal estimation of the unknown parameters and states of a dynamic system recent advances in ensemble based data assimilation methods opens the road to solve high dimensional nonlinear estimation problems using relatively low computational cost despite the strong potentials of da methods there is a lack of tools that enable efficient and scalable use this paper presented pestpp da an open source scalable to high dimensions and model independent data assimilation tool that uses the widely known pest model interface protocols to interact with any model the tool written entirely in c includes a built in fault tolerant parallel run manager that allows pestpp da to be deployed on heterogeneous and distributed computing systems the tool implements several forms of ensemble based da including ensemble kalman filter ensemble smoother and ensemble kalman smoother pestpp da uses different iterative and non iterative solvers to optimally combine models and observations pestpp da support two localization approaches to solve high dimensional problems with relatively small number of realizations through a generalized assimilation cycle concept pestpp da can be applied to a wide range of da analysis ranging from high assimilation frequency filtering to long duration smoother analysis pestpp da facilitates application in numerous environmental modelling settings where high dimensionality long model runtimes and non linearity require highly efficient and adaptive da approaches the availability of pestpp da as open source tool serves a wide range of practitioners in several fields including environmental hydrologic atmospheric and oceanic modelling using the widely known pest model interface protocols makes emerging technologies in data assimilation field accessible for practitioners to 1 estimate large numbers of unknown models input parameters with relatively low computational cost 2 improve predictions produced by uncertain numerical models 3 determine the best possible forecast of dynamic states using newly received observations and 4 quantify uncertainties associated with system states and parameters the flexibility pestpp da offers to assimilate transient data and the use of efficient iterative solvers are expected to provide decision makers with optimal model predictions while accounting for risks resulting from the remaining irreducible uncertainties declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge support from the u s environmental protection agency great lakes restoration initiative usgs water availability and use science program usgs mississippi alluvial plain project and new zealand s gns science any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government appendix algorithms algorithm 1 multiple data assimilation mda image 1 algorithm 2 efficient subspace pseudo inverse of y y t n 1 c d image 2 algorithm 3 subspace inverse of low rank c d image 3 
25617,ensemble based data assimilation da methods have displayed strong potential to improve model state and parameter estimation across several disciplines due to their computational efficiency scalability and ability to estimate uncertainty in the dynamic states and the parameters however a barrier to adoption of ensemble da methods remains namely there is currently a lack of available tools that enable efficient and scalable da in a non intrusive fashion and that support implementation flexibility this paper presents an open source software tool pestpp da that implements a range of data assimilation methods ensemble kalman filter ensemble kalman smoother and ensemble smoother using the widely known pest model interface protocols to interact with any model two iterative solutions can be used for nonlinear and or non gaussian assimilation problems to demonstrate the broad range of pestpp da applications two synthetic case studies are presented 1 the lorenz model and 2 a groundwater pumping test in the presence of a non gaussian hydraulic conductivity field keywords data assimilation inverse problem uncertainty analysis hydrology software availability name of software pest for data assimilation pestpp da developers ayman alzraiee jeremy white matthew knowling randall hunt and michael fienen year first available 2021 hardware required basic computer software required only pestpp da executable file is required to run the software for software compilation any compiler that supports c 17 features can be used visual studio project file and cmake solutions are available at https doi org 10 5066 p9ytq5py and an active provisional copy is available at https github com usgs pestpp tree develop src programs pestpp da source code availability source code is available within the open source pest code the main entry point file is named pestpp da cpp executable file standalone binaries for windows and linux are available within the open source pest cost free program language c program size executable file size is 7 48 mb 1 introduction knowledge about physical systems is usually available in two forms models and observations models encapsulate prior knowledge about the way physical processes interact and how they evolve in space and time while observations provide direct information about the natural system often noisy and sparse in space and time the optimal combination of these two sources of information can be achieved by data assimilation da da serves to produce a best representation of the dynamic states and the parameters of a dynamic system evensen 2009 fletcher 2017 law et al 2015 asch et al 2016 leeuwen et al 2015 that in turn improves model forecasts of future system behavior da techniques explicitly recognize that both models and field observations are inherently uncertain model uncertainty can be caused by parameter uncertainty unknown model inputs model inadequacy mathematical and physical process simplification structural uncertainty and parameter spatial and temporal simplification kennedy and o hagan 2001 observation uncertainty can result from inadequate or imprecise instruments human errors poor representation of time integrated dynamics and other environmental factors da methods for example the widely employed ensemble based methods evensen 2009 provide a unified framework to achieve both uncertainty reduction ur in parameters and states and uncertainty quantification uq of the uncertainty that remains ensemble based data assimilation evensen 1994 developed as an alternative to the computationally expensive extended kalman filter approximates a high dimensional first order mapping between parameters and simulated states using an ensemble of both parameter and state realizations ensemble based da methods have shown significant promise in a variety of computational fields owing to their efficiency and scalability burgers et al 1998 montzka et al 2012 a family of ensemble based da algorithms have shown particular promise including the ensemble kalman filter enkf evensen 1994 ensemble kalman smoother enks evensen and leeuwen 2000 and ensemble smooth es leeuwen and evensen 1996 these algorithms are unique in how they formulate the da problem which can be broadly categorized as batch and sequential batch da involves estimation of parameters and or states simultaneously over the entire simulation period and is common in history matching problems aanonsen et al 2009 typically characterized by large number of unknown parameters and computational intensive model runs sequential da evensen 2002 on the other hand involves estimation of parameters and or states sequentially in time which also affords benefits in terms of handling model error and is common in meteorology oceanography and crop yield models and may be characterized by conceptual models chaotic systems and shorter time horizons despite the reported potential of ensemble da methods widespread adoption of these methods is still limited in environmental modelling for decision support a key barrier to adoption is the lack of efficient and scalable da tools that combine non intrusiveness and implementation flexibility the need to make sequential da approaches with general and flexible formulations accessible to practitioners motivated the development of a new software tool pestpp da a widely applicable model independent non intrusive and scalable data assimilation software pestpp da is an open source c implementation of data assimilation methods using the widely known pest model interface protocols doherty 2004 doherty et al 2010 pestpp da fully leverages existing pest pest run management capabilities and file types control file template files and instruction files the model independent design allows the practitioner to bring sophisticated and generalized da approaches to bear in a wide range of situations and different models pestpp da implements the traditional gaussian linear ensemble based methods as described by evensen 1994 including es enkf and enks or any mix of these schemes as well as iterative solutions for these formulations for nonlinear problems that includes the multiple data assimilation mda algorithm emerick and reynolds 2012 and the gauss levenberg marquardt glm solution chen and oliver 2013 white 2018 below we provide a brief overview of the theoretical background of ensemble based data assimilation and terminology used in this paper followed by methods for solving nonlinear and non gaussian problems and some relevant details related to the implementation and function of pestpp da our presentation concludes with two synthetic problems 1 lorenz problem for sequential state estimation for a chaotic system and 2 a synthetic groundwater pumping test problem the pumping test experiment demonstrates the use of pestpp da to estimate the unknown non gaussian hydraulic conductivity field at the resolution of the finite difference grid with the best match to the hydraulic head observations 2 theoretical background this section presents key terminology and notation as well as a theoretical background of da and assimilation methods implemented in pestpp da 2 1 key terminology given the relatively few applications of sequential da with dynamic state estimation within applied environmental modelling for decision support we define the following terms to aid the reader assimilation cycle a discrete period of time during which available state observations are assimilated with the da algorithm static parameter an uncertain time invariant input quantity to the model such as system property dynamic parameter an uncertain time variant input quantity to the model that acts on a discrete interval of simulation time such as a parameter that represents model forcing simulated final state an output quantity from the model that represents the state of the simulated system at the end of the current assimilation cycle this quantity can be thought of as a forecast of system state as evaluated by the model estimated final state a quantity evaluated by the model simulated final state and adjusted by the da algorithm at the end of the current assimilation cycle estimated initial state a quantity that can be estimated by the da algorithm that is the initial condition for the current assimilation cycle simulated equivalent the simulation result that corresponds to an observation 2 2 bayesian formulation of the kalman filter consider a model that has the following generic structure 1 h t 1 u t 1 g m t h t where g is the model functional that can be a linear or nonlinear operator g represents a model that simulates time evolution of a dynamic system across the given assimilation cycle from time t to time t 1 the model requires as an input a vector of parameters m t r n m 1 where n m is the number of parameters in the period t t 1 where parenthesis indicates open interval and bracket indicates closed interval input parameters can include static and or dynamic parameters such that m t p s q t the vector p s represents static parameters p s r n p 1 and q t r n q 1 represents dynamic parameters where n p and n q are number of static parameters and number of dynamic parameters respectively static parameters p s may represent one or more physical properties that are time invariant or spatially variable e g hydraulic conductivity and specific yield in a groundwater model can be represented as a vector of values for each finite difference cell each pilot point doherty et al 2010 or each spatial zone q t 1 represents any transient input parameters in the period t t 1 such as system stresses e g groundwater recharge or pumping in a groundwater model that apply only to discrete interval s of time the model evolves initial dynamic states across the assimilation cycle from h t to h t 1 r n h 1 where n h is the number of simulated dynamic states the model can also produce other quantities u t 1 that are not used as initial conditions for the next assimilation cycle for example simulated baseflow and evapotranspiration are usually simulated states that are not used as initial conditions in hydrologic models given d t 1 r n d 1 a set of field observations that correspond to one or more of the input parameters or simulated quantities in h t 1 p s u t 1 or and q t 1 da attempts to merge prior distributions obtained from uncertain model simulation results with field observations which also contain some uncertainty defining the augmented parameter state vector to be x t 1 q t p s h t 1 h t u t 1 a general formulation of the estimation problem can be written using bayes law as follows 2 p x t 1 d t 1 p d t 1 x t 1 p x t 1 p d t 1 where p x t 1 d t 1 is the posterior probability density function pdf of x t 1 given a set of observations d t 1 p d t 1 x t 1 is the likelihood pdf that describes the deviation of model simulation results from field observations p x t 1 is the prior pdf of x t 1 and p d t 1 is the pdf of field observations also called the evidence term different possible formulations of the generalized estimation problem encapsulated in equation 2 can be defined depending on how simulation time is discretized into assimilation cycles the three main types of estimation problems are wiener 1949 carrassi et al 2018a 1 prediction which estimates p x l d t 0 with l t 2 filtering which estimates p x t d t 0 and 3 smoothing which estimates p x t 0 d t 0 where t is the maximum time index of state or observation and t 0 indicates the set of time indices between 0 and t such that d t 0 d t d t 1 d 0 notice that the formulation of the assimilation problem in equation 2 is generic where both inverse modelling and state updating is achieved simultaneously for a given assimilation cycle a simpler formulation p m d t 1 can be used when one is interested only in the inverse problem or p h t 1 d t 1 when one is interested only in state estimation problem when the model g in equation 1 is linear and when prior pdfs for both model parameters and initial dynamic states are gaussians the posterior p x t 1 d t 1 is also gaussian with a mean x a and covariance matrix c x x a calculated as follows kalman 1960 3 x a x f c x y f c y y f r 1 d t 1 y t 1 4 c x x a c x x f c x y f c y y f 1 c y x f where x f is the forecast mean of x t 1 y t 1 are simulated equivalents to the observations d t 1 c x y f is the cross covariance matrix of x t 1 and y t 1 c y x f is the transpose of c x y f c x x f is the prior covariance matrix of x t 1 c y y f is the prior covariance matrix of y t 1 and r is the measurement error covariance matrix 2 3 ensemble based methods the kf in equations 3 and 4 developed by kalman 1960 and studied in detail by jazwinski 1970 has been widely used in different fields the kf assumes that the pdf of parameters and states are gaussian distributions furthermore in a non intrusive model independent setting the cross covariance matrices in equations 3 and 4 must be evaluated via finite difference perturbations with nonlinear models the simulated states can deviate from the gaussian assumptions making the traditional kf suboptimal or perhaps even unsuitable for da additionally applying kf to high dimensional systems is usually computationally prohibitive as it requires the evaluation of large cross covariance matrices these limitations motivated the development of the ensemble kalman filter evensen 1994 which is a monte carlo based application of a bayesian update on moderately nonlinear and linear systems ensemble based methods are still based on the gaussian assumption however the posterior moments mean and covariance matrix are approximated using an ensemble of realizations of the prior carrassi et al 2018b ensemble based da methods are based on two fundamental steps fig 1 forecast and update the forecast step consists of a monte carlo simulation of the model where initial states and parameters are sampled from their prior distribution and each sampled realization is simulated in the model collectively resulting in an ensemble of simulated states the ensemble of parameters initial states and simulated states can be seen as a discrete approximation of the joint states parameters pdf where the ensemble mean and the ensemble covariance matrix approximate the first and the second moments of the multivariate gaussian distribution respectively the update step consists of conditioning of the model state parameters in each realization on field observations using the following equations evenson 1994 5 x a x f c x y f c y y f r 1 d t 1 y t 1 6 c x x a c x x f c x y f c y y f 1 c y x f where x a r n n is the analysis or updated ensemble of estimated states and or parameters at time t 1 n is the number of states and parameters to be estimated n is the number of realizations in the ensemble x f r n n is the forecast prior ensemble of states and parameters at time t 1 and r is the covariance matrix of measurement error and y t 1 r n d n is the ensemble of simulated equivalents the matrix d t 1 r n d n is the perturbed observations ensemble and is computed as d t 1 d t 1 e t 1 where e t 1 is an ensemble of measurement errors sampled from n 0 r to simplify the notations the simulated equivalents y t 1 is denoted as yf the covariance matrix c y y f r n d n d is the covariance matrix of simulated states and the covariance c x y f r n n d is the cross covariance matrix of estimated state parameters and simulated states these two matrices are computed as follows 7 c y y f y f y f y f y f t n 1 8 c x y f x f x f y f y f t n 1 where y f r n d n is the ensemble mean of y f such that each row in y f is computed as the mean of values in the corresponding row in matrix y f x f is the forecast ensemble mean of matrix x f the analysis matrix computed in equation 5 can be used to compute the posterior mean and covariance matrix of x 3 software description this section describes how different da solution methods are currently incorporated into pestpp da pestpp da is developed entirely in c and is statically linked into a stand alone executable the numerical solution of the da equations uses the eigen numerical linear algebra template library guennebaud and jacob 2010 ensembles can be evaluated in serial or in parallel via built in run managers the parallel model evaluations are implemented using a built in fault tolerant tcp ip run manager described in welter et al 2015 this run manager allows pestpp da to be parallelized across heterogenous networks and in cloud settings 3 1 forward model input output protocols pestpp da implements the widely used model independent pest protocols doherty 2015a these protocols fig 2 allow separate algorithms to interact with models by 1 changing model input files 2 running the models and 3 extracting relevant model outputs which may include unmeasured forecast quantities as well as simulated equivalents simulated equivalents refer to simulated quantities that have equivalent field observations and the difference between simulated and measured quantities are referred to as residuals or innovations pestpp da like all tools based on the pest protocols uses three types of files to achieve this interaction fig 2 these files are 1 a control file 2 template files and 3 instruction files the control file provides information to control the pestpp da solution process for example in the control file a practitioner can specify several options that can be used to control da algorithm behavior such as the size of prior ensembles inflation factors among many others see the pest user s manual in pestpp da repository for a complete description of the options and arguments used by pestpp da template files contain information about how model input files are to be manipulated while instruction files contain information that facilitate extraction of simulation results from model output files according to pest protocols a model can consist of a user defined chain of models and associated processing that are called to simulate salient aspects of a system for a complete description of the formats of template and instruction files and how they can be generated practitioners are referred to doherty 2004 as well as the pest user s manual we also note that the pyemu python package white et al 2016 has multiple utilities that facilitate generation of the entire pest interface needed to apply pestpp da 3 2 sequential data assimilation schemes time evolution of a dynamic model usually occurs according to a specified temporal discretization scheme some models allow the practitioner to choose time step sizes as part of the model inputs while other models compute the time step adaptively transient observations of system state on the other hand might be available at temporal intervals that are different from model temporal discretization to accommodate this wide range of settings pestpp da allows the practitioner to define arbitrary assimilation cycles how these cycles are defined is highly dependent on the problem at hand for example numerical weather prediction models usually assimilate observations at high frequency time steps on the order of minutes for making optimal short term high frequency forecasts while groundwater systems which typically evolve slowly might have assimilation cycles on the order of months or years to facilitate a high degree of flexibility in the specification of assimilation cycles pestpp da requires the practitioner to provide information that identifies the cycle or cycles that every observation and adjustable parameter state belongs to fig 3 this information is beyond that required for a traditional pest pest run the assimilation cycle might consist of a single time step e g cycles c 0 c 1 c 4 in fig 3 multiple time steps e g cycles c 2 and c 3 in fig 3 or even the entire simulation period as a single assimilation cycle when a cycle consists of one time step pestpp da implements sequential data assimilation schemes fig 4 such as ensemble kalman filter enkf or ensemble kalman smoother enks when all observations are assigned to a single assimilation cycle that covers the entire simulation period all the observations are to be assimilated simultaneously referred to herein as batch assimilation scheme leading to an ensemble smoother es implementation e g white 2018 fig 4c between pure sequential assimilation and pure batch assimilation practitioners can mix enkf enks and es approaches arbitrarily fig 4d shows a hypothetical situation in which observations are initially assimilated every time step cycles 1 and 2 followed by batch assimilation of a set of observations in cycle 3 and finally followed by an enks assimilation cycle 4 in which observations at time 6 are assimilated to update all historical parameters and or states although enkf and enks schemes assimilate data in multiple time cycles they differ in that the enkf updates parameters and states in the most recent time cycles using only recent observations while the enks updates all previous updated states and parameters using the most recent observations pestpp da affords the practitioners a high level of flexibility in deciding which observations are used to estimate which state parameters a parameter state indexed using cycle value i will be updated using all observations that are indexed by the cycle i a negative cycle number can be used to flag parameters states that need to be updated during all cycles the practitioner can implement sophisticated rules about how parameters and or observations are used across multiple cycles by using colon delimited expressions for example a parameter or a state indexed with a cycle number equal to 2 5 will be updated from the 3rd cycle to the 4th cycle other expressions are also possible see pest user s manual the concept of an assimilation cycle in pestpp da is abstract and is not limited to indexing the times of assimilation it can be seen as an index of the order in which assimilation of data should take place for example one might choose to assimilate all upstream streamflow gages first and then assimilate downstream gages in this case upstream streamflow observations are indexed as cycle 0 while downstream streamflow gages are indexed as cycle 1 in sequential data assimilation using enkf and or enks the model must be restarted after updating the state parameters typically in enkf and enks the model is restarted from the most recent updated state however pestpp da allows the practitioner to restart the model from any historical point this dynamic restart capability requires additional information to be included in the definition of parameters and observations used by pestpp da specifically in order for pestpp da to implement enkf or enks the definitions of parameters representing dynamic states and observations representing dynamic states must contain additional information so that pestpp da can programmatically transfer simulated or estimated final states to initial state parameters when advancing cycles 3 3 formulations of joint parameter state data assimilation pestpp da can implement a wide range of state parameters and joint state parameter data assimilation scenarios the complete joint state parameter estimation formulation includes static parameters p s dynamic parameters q t initial states h t final estimated states needed as future initial states h t 1 and other arbitrary simulation results u t 1 of interest pestpp da can be used to update any arbitrary combination of these quantities table 1 lists some of the common possible cases that can be implemented within pestpp da model parameters can be estimated in a batch table 1 case 1 or sequential table 1 case 2 manner estimation of only the dynamic states can be achieved in batch mode or sequentially several other schemes for mixing the estimation of the states and parameters can be also implemented with pestpp da in sequential data assimilation the model can be restarted using the estimated updated final state as the initial condition of the next cycle or using the model simulated states from the previous cycle with updated parameters table 1 case 4 initial states that are model simulated are considered to be more physically realistic and maintain conservation laws while using estimated updated initial states might be statistically useful and provide important insights into model behavior but may yield physically unrealistic da results pestpp da allows both options for the practitioner 3 4 algorithms for nonlinear non gaussian da kalman filter based assimilation has been shown to produce optimal solutions for linear systems with gaussian parameters states however in most practical problems at least one of these two conditions are not satisfied for example it is common that the permeability of a subsurface system consists of two or more geological facies and a bimodal or multi modal pdf is used to statistically represent the permeability moreover nonlinear models can produce non gaussian simulated states even when input parameters states are gaussian tarantola 2005 to overcome these limitations pestpp da offers two nonlinear solution methods 1 multiple data assimilation mda and 2 gauss levenberg marquart glm the traditional ensemble based estimation evensen 1994 can be considered a special case for either mda and glm a case with one iteration and without inflation of measurement error covariance and without scaling the upgrade iterative assimilation schemes are commonly used with the es however pestpp da allows the practitioner to use iterative methods with any assimilation scheme fig 5 schematically shows how iterative and sequential da is implemented in pestpp da 3 4 1 multiple data assimilation mda solution emerick and reynolds 2012 showed that multiple da iterations with inflated measurement errors by a factor equal to the number of data assimilation iterations is equivalent to one assimilation update with no inflation when the dynamic system is linear and priors are gaussian inflation factors play a role similar to lambda in marquardt nonlinear solver doherty 2015b which control the magnitude of upgrade vector inflation values greater than 1 reduce the magnitude of upgrade vector resulting in multiple small successive updates for nonlinear systems such successive small upgrades made by mda algorithm produce results that are superior to the non iterative da approaches pestpp da allows the application of mda as implemented in emerick and reynolds 2012 where the practitioner can choose the initial inflation factor reduction factor and the number of inflation factors algorithm 1 in the appendix in the absence of user input pestpp da uses default values for these control options that work well in a range of test problems pestpp da ensures that the reciprocals of all inflation factors sum to 1 since pestpp da like other tools in the pest pest suite ceases the search for an optimal solution when one of the termination criteria is satisfied pestpp da recomputes the last inflation factor such that reciprocals of all inflation factors sum to 1 more about termination criteria can be found in the pest user s manual the analysis scheme using equation 5 may have problems when the number of observations is larger than the number of realizations in the forecast ensemble or when the term c y y f r 1 has poor conditioning evensen 2009 pestpp da implements computationally efficient algorithms algorithms 2 and 3 in the appendix developed by evensen 2004 and evensen 2009 to use low rank representation of the measurement error covariance matrix to solve the analysis equation 5 3 4 2 gauss levenberg marquardt glm solution the glm solution chen and oliver 2013 is an ensembled based approximation to the tangent linear operator jacobian matrix within the iterative procedure the glm procedure minimizes the mismatch between observations and simulated equivalent values similar to pestpp ies white 2018 the glm solution algorithm implemented in pestpp da features an adaptive gauss levenberg marquardt scheme that includes backtracking and evaluation of multiple marquart lambda values each iteration see the pest user s manual for more details white 2018 3 4 3 searching for optimal solution like pestpp ies white 2018 finding the optimal solution is achieved in pestpp da by automated trialing of inflation factors and scaling factors the scaling factor can be used to reduce the magnitude of the upgrade vector in iterative methods for each pair of factors realizations in the ensemble need to be simulated by the model therefore leading to a large number of forward model runs which can be computationally prohibitive to reduce such a high computational cost a practitioner can choose to simulate a small subset of realizations to test the factors pest manual white 2018 the realization subset can be chosen randomly deterministically or based on mean objective function values the number of factors to be tested can also be controlled by the practitioner 3 5 generation of prior ensembles implementing da requires the generation of two ensembles an initial parameter ensemble and an observation error ensemble pestpp da allows practitioners to use ensembles that are generated either as part of or independently of a pestpp da analysis depending on the problem at hand the practitioner can choose to generate conditional or unconditional geostatistical realizations using external tools for example the geostatistical software library gslib deutsch 1998 or stanford geostatistical modeling software sgems bianchi and zheng 2009 to generate spatially correlated fields alternatively pestpp da can be used to generate ensembles for correlated and independent parameters using a practitioner supplied parameter mean vector and covariance matrix 3 6 localization ensemble based da provides a computationally efficient way to approximate the joint pdf of parameters states of a system however when the number of parameters states estimated is larger than the number of realizations which is a common case given the need for high dimensionality to better express uncertainty in some contexts knowling et al 2019 as well as the desire to reduce the number of forward model runs required the resulting ensemble covariance matrix is rank deficient and may produce spurious correlations between variables that are not correlated and variables separated by large distances evensen 2009 using localization can minimize such spurious correlation and allow the use of smaller ensemble sizes localization can be achieved based on prior knowledge or expert opinion of realistic correlation in many physical systems locality is measured as spatial distance or temporal distance or temporal direction e g removing correlation that would violate temporal causality as a result only observations that are close to a state parameter will be used to update that state parameter pestpp da allows practitioners to implement combined local analysis with covariance localization with two localization approaches 1 a user defined localization matrix and 2 automatic adaptive localization luo and bhakta 2020 anderson 2007 and chen and oliver 2017 provide a more detailed discussion about localization concepts 4 benchmarks and examples in practical data assimilation the true parameter state values are unknown and observations are made using imperfect sensing devices or in a noisy environment resulting in noisy observations to evaluate the performance of pestpp da a synthetic truth is constructed a priori the truth states parameters are simulated in the model to generate synthetic truth observations which are artificially contaminated by random noise the estimated parameter state values are then compared to the truth parameter state values to evaluate pestpp da performance this analysis framework is adopted in two benchmark problems as follows we first consider a well known analytical model lorenz 1996 to specifically evaluate the performance of the enkf we then consider a numerical groundwater model to evaluate performance of both sequential and batch da formulations and specifically the mda algorithm 4 1 lorenz 1996 the lorenz 1996 model lorenz 1996 herein referred to as l96 is a classical atmospheric science inspired analytical system that has been widely used to test data assimilation methods l96 is designed to represent a meteorological quantity such as vorticity in the atmosphere at equidistant points along a latitude circle it involves representation of three key atmospheric processes advection quadratic term dissipation linear term and external forcing constant term l96 is given by the following nonlinear system 9 x i t x i 1 x i 2 x i 1 x i f i 1 2 n l where x i is the dynamic state at location i and f is a static parameter representing an external forcing term and nl is the dimensionality i e number of locations along the latitude circle we employ nl 36 and f 8 f values exceeding approximately 5 yield chaotic behavior whereby small perturbations in system state cause significantly different state trajectories uniform initial states of 8 0 are specified with a small perturbation of 0 01 to the state at the 20th location the length of the simulation period is 20 time units discretized into 2000 time steps with a uniform time step of 0 01 time units following lorenz and emanuel 1998 the l96 system is solved using the runge kutta rk4 scheme implemented in scipy s ordinary differential time integrator virtanen et al 2020 here we apply enkf to assimilate spatially and temporally distributed synthetic observations through estimation of final states for each assimilation cycle table 1 case 6 an ensemble of 50 realizations is employed synthetic observations are taken i e sampled from the true trajectory at 8 equidistant sites 0 5 10 35 at a frequency of 0 2 time unit intervals i e each 20 time integration steps following a period of non observation while equilibrium initial conditions are overcome we assume an observation noise standard deviation of 1 0 fig 6 shows that the above described implementation of enkf displays a strong ability to improve system state trajectory while still maintaining variance the level of agreement e g smaller posterior variance in fig 6a reflects the availability of observations on which to condition states at this location as the distance from this sampled location increases fig 6b to c the level of agreement decreases so too does the time where the posterior encompasses the truth as expected similarly even at the 20th site where observations for assimilation are available estimated states in between observation times may show divergence from the true trajectory 4 2 pumping test to estimate non gaussian conductivity field ensemble based da assumes that both model input parameters and model response are multivariate gaussian when models are nonlinear or model input parameters are non gaussian the resulting da estimation of the posterior mean and covariance matrix becomes suboptimal or even unstable iterative da methods chen and oliver 2013 emerick and reynolds 2012 luo et al 2015 were developed and implemented in pestpp da to address this potential issue this synthetic case demonstrates the use of multiple data assimilation method mda implemented in pestpp da the testing of the mda iterative inversion is based on a synthetic two dimensional groundwater problem the two dimensional domain fig 7 a is a 1 km 1 km 50 m thick unconfined aquifer discretized into 10 000 cells 100 grid blocks along the x y horizontal coordinate directions and a single grid block along the z vertical direction the aquifer is subject to general head boundary conditions on the left and right edges of the domain at which the hydraulic head h is set equal to 40 m everywhere else no flow boundary conditions are imposed the true hydraulic conductivity of the aquifer k is assumed to be non gaussian with two facies geological formations fig 7b within each facies the conductivity is assumed stationary gaussian random field and was generated using spectral simulation pardo igúzquiza and chica olmo 1993 the geostatistical properties of the two facies formations are presented in table 2 the reader is referred to table 2 and fig 7 for further details of the model setup the saturated flow simulation code modflow nwt niswonger et al 2011 was used in this numerical experiment the simulated period consists of 24 stress periods each 30 days length each stress period is evenly divided into ten 3 day time steps as groundwater pumping continues a cone of depression develops the transient changes of groundwater level are observed at a network of 100 wells fig 7 the true observed groundwater level is measured every stress period resulting in a total of 2400 transient synthetic observations in this experiment 50 realizations are used to generate the prior k ensemble to demonstrate the capability of pestpp da to implement both standard non iterative da and iterative da for a nonlinear and non gaussian test case we compare the results obtained when implementing the two algorithms in this experiment mda is used to estimate the k field using four iterations with inflation factors all equal to 4 the prior k values are generated from a mixed gaussian distribution which is a probability distribution that is comprised of multiple gaussian distributions the clusters of k values fig 8 a roughly aligned on the one to one line lower left cluster and upper right cluster represent prior conductivity values that have correct prior geological formations while the off diagonal clusters upper left and lower right have incorrect prior formations facies with low true hydraulic conductivity but high hydraulic conductivity sampled values and vice versa when iterative solution schemes are used in pestpp da intermediate ensembles corresponding to each iteration can be saved to evaluate the progress of solution figs 8 and 9 show the progress of the iterative mda solution in the first iteration fig 8b the incorrect prior facies start to be gradually corrected in iteration 2 the estimated distribution is roughly gaussian with large variance that covers both low and high conductivity values and with intermediate mean in iteration 3 the correct multi gaussian distribution starts to emerge while the geological facies are correctly identified but hydraulic conductivity values within each facies are still inaccurate iteration 4 produces more corrections to hydraulic conductivity values within each facies and makes the spread of hydraulic conductivity around the one to one line narrower that is to say correctly estimating the facies types and conductivity values within each facies to demonstrate the performance of mda for nonlinear and non gaussian problems pestpp da was also used to estimate the unknown conductivity field using the es in which all observations are assimilated in one batch and no iterative solution is attempted the goal of this comparison is not to present a comprehensive comparison between standard es and mda but to illustrate some of the solution schemes available in pestpp da fig 10 shows a comparison between reference and estimated conductivity fields using standard es and using the iterative mda method it can be seen that the iterative mda method outperforms the standard es the estimation using the standard es produced an incorrect posterior unimodal gaussian distribution with an average hydraulic conductivity value that is roughly midway between low and high hydraulic conductivity values on the other hand the iterative mda produced the correct multi gaussian distribution and the correct mean of conductivity within each facies 5 conclusions data assimilations da methods integrate uncertain model predictions and uncertain field observations to provide an optimal estimation of the unknown parameters and states of a dynamic system recent advances in ensemble based data assimilation methods opens the road to solve high dimensional nonlinear estimation problems using relatively low computational cost despite the strong potentials of da methods there is a lack of tools that enable efficient and scalable use this paper presented pestpp da an open source scalable to high dimensions and model independent data assimilation tool that uses the widely known pest model interface protocols to interact with any model the tool written entirely in c includes a built in fault tolerant parallel run manager that allows pestpp da to be deployed on heterogeneous and distributed computing systems the tool implements several forms of ensemble based da including ensemble kalman filter ensemble smoother and ensemble kalman smoother pestpp da uses different iterative and non iterative solvers to optimally combine models and observations pestpp da support two localization approaches to solve high dimensional problems with relatively small number of realizations through a generalized assimilation cycle concept pestpp da can be applied to a wide range of da analysis ranging from high assimilation frequency filtering to long duration smoother analysis pestpp da facilitates application in numerous environmental modelling settings where high dimensionality long model runtimes and non linearity require highly efficient and adaptive da approaches the availability of pestpp da as open source tool serves a wide range of practitioners in several fields including environmental hydrologic atmospheric and oceanic modelling using the widely known pest model interface protocols makes emerging technologies in data assimilation field accessible for practitioners to 1 estimate large numbers of unknown models input parameters with relatively low computational cost 2 improve predictions produced by uncertain numerical models 3 determine the best possible forecast of dynamic states using newly received observations and 4 quantify uncertainties associated with system states and parameters the flexibility pestpp da offers to assimilate transient data and the use of efficient iterative solvers are expected to provide decision makers with optimal model predictions while accounting for risks resulting from the remaining irreducible uncertainties declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge support from the u s environmental protection agency great lakes restoration initiative usgs water availability and use science program usgs mississippi alluvial plain project and new zealand s gns science any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government appendix algorithms algorithm 1 multiple data assimilation mda image 1 algorithm 2 efficient subspace pseudo inverse of y y t n 1 c d image 2 algorithm 3 subspace inverse of low rank c d image 3 
25618,the diversity of both pedoclimatic and socio economic contexts in agricultural landscapes makes evaluating the impacts of climate change a challenge models are pertinent tools to quantitatively explore possible futures and participatory approaches help account for local diversity we developed a model through an approach that involves stakeholders in the model s construction and testing and in the discussion of results we simulated spatially explicit impacts of climate change on water balance grape phenology and yield in a mediterranean vineyard watershed for two climate scenarios results show a decrease in grape production of 7 14 by 2100 yield decrease would be higher in irrigated high yield areas despite a doubling of irrigation water supply a forecasted 6 c increase in temperature during berry ripening would threaten wine quality the approach allows the communication of model results and limitations to stakeholders it is a promising means of identifying potential local adaptations to climate change keywords climate change grapevine landscape multi scale evaluation spatially explicit model stakeholders 1 introduction viticultural systems are experiencing previously unseen conditions resulting from climate changes at a global scale higher temperatures move phenological stages to earlier periods warmer conditions during berry growth and increased water deficits alter yield and grape quality van leeuwen and darriet 2016 understanding how grapevines are and will be impacted by climate change is challenging and requires a combination of approaches naulleau et al 2021 although process based crop models such as stics brisson et al 2003 and vinelogic walker et al 2020 provide advantages in the use of climate projections at large scales they often do not simulate local growing conditions that might permit viable viticulture under marginal conditions mosedale et al 2016 participatory approaches can help take account of local constraints and diversity and give pertinent information to decision makers delay et al 2015 dynamic crop models are important tools for evaluating long term impacts from an unprecedented combination of change factors climatic technical economic with multiple uncertainties existing crop models for grapevines at field and regional scales have been used with climate projections to evaluate the impacts of climate change on phenology caffarra and eccel 2011 garcia de cortazar atauri et al 2017 webb et al 2007 water status pieri et al 2012 tissot et al 2017 yield fraga et al 2016 and hydrological resources carvalho santos et al 2016 in a comprehensive review of grapevine models developed in a context of climate change moriondo et al 2015 argue for the use of low input dynamic models in order to limit data needs for impact studies at a regional scale although such existing models are able to consider several management practices mainly water nutrient and canopy management knowling et al 2021 their application is still limited to a small number of production systems e g trellis systems bare soil these systems may not be representative of local and diverse biophysical and socio economic contexts thus they neglect the interplay between local conditions and practices knowling et al 2021 interactions that have been highlighted as key factors of climate change vulnerability van leeuwen et al 2013 as a consequence the lack of more detailed and spatially explicit information in previous model based evaluations of climate change impacts limits their contribution to the design of adaptation policies santillán et al 2019 modeling is an iterative process in which the involvement of stakeholders can help offset the limits of crop models by creating a shared representation enhancing the understanding of a dynamic system and supporting decision making voinov 2008 voinov et al 2018 participatory modeling allows the integration of local knowledge in fine resolution analyses murgue et al 2016 discussions about model functioning with stakeholders hossard et al 2013 and the production of meaningful indicators allain et al 2018 involving stakeholders in modeling processes also helps us consider different scales which is crucial to agricultural system analysis delmotte et al 2013 for example the field scale is needed to identify the relationship between plant water requirements and production when adapting management practices while up scaling to the regional level enables the consideration of connectivity hydrology biodiversity spatial heterogeneity climate soil slope and aggregated indicators that facilitate decision making at the policy level e g extension of irrigated areas evolution of total production previous studies have shown that participatory modeling is particularly suitable for analyzing the effects of complex and uncertain situations such as climate change on various agricultural systems like rice delmotte et al 2017 mixed cropping and grazing rodriguez et al 2014 and livestock systems duru et al 2012 to date there have been few quantitative evaluations involving stakeholders that examine the impacts of climate change on grapevine systems we found only two examples delay et al 2015 tissot et al 2017 using agent based modeling approaches delay et al 2015 studied the evolution of grape acidity at field and cooperative cave scales in a medium sized area 39 km2 tissot et al 2017 studied the evolution of grape phenology water balance and ripening as well as work organization at field and farm scales in a small sized area 1 km2 we believe a new modeling approach that includes stakeholders in a specific vineyard can help coordinate the attention to spatial scale and simulated processes in a way that allows the quantitative evaluation of climate change impacts including on grape yield such an approach should be particularly attentive to both model transparency voinov and bousquet 2010 and the representation of model outputs allain et al 2018 with respect to transparency part of our study was dedicated to reducing the model complexity for grape yield in order to improve the understanding of results especially by the stakeholders recent developments show that yield components can be expressed as functions of water stress indicators at critical periods van leeuwen et al 2019 proposed a model based on expert knowledge and guilpart et al 2014 incorporated more experimental data demonstrating a relationship between yield components and grapevine water status during critical periods over the course of two years in a recent review knowling et al 2021 give an overview of the relationship between berry weight and irrigation practices overall evidence seems to indicate that semi empirical modeling with limited parameters would be judicious and appropriate for a participatory approach to simulate grapevine yields the research reported in this paper proposes a new modeling approach that integrates stakeholders in the process of quantifying site specific climate change impacts it was applied to a viticultural watershed in southern france and designed to fulfill the following objectives 1 to use dynamic modeling to incorporate climatic predictions provided by the ipcc over a long time period 2 to involve stakeholders in an effort to increase local pertinence that represents spatial diversity and several scales from the field to the watershed and 3 to produce meaningful indicators that show the impacts of climate change on viticulture and water management in the watershed the participation of stakeholders for conceptualization model testing in the reference situation and discussion of the simulations under future climatic conditions helped improve simulation quality and understanding our study also led to the development of an ad hoc grapevine yield model called gray grape yield included in an original watershed model our results could be useful for local stakeholders and decision makers wine growers public institutions technical adviser etc to identify the most vulnerable areas and then assess site specific solutions for adaptation 2 materials and methods 2 1 study area the study took place in southern france fig 1 where viticulture is an important economic activity and is particularly sensitive to climate change we chose the rieutort watershed 45 km2 43 5 n 3 1 e as a case study because of its location between the southern coastal plain 581 mm mean annual rainfall data puisserguier weather station 2000 2019 and the relief of the hinterland to the north 705 mm mean annual rainfall data cabrerolles weather station 2000 2019 this area encompasses a diversity of active viticultural systems 1500 ha 20 of the vineyards are located on shale soils in the mountainous area to the north 60 are on mainly clay limestone soil in the central foothills and 20 are on more or less differentiated terraces of alluvial soil in the southern part of the watershed the total vineyard area is divided into two main production types a protected designation of origin pdo characterized by low yields of high quality wine and a protected geographic indication pgi characterized by higher yield objectives irrigation is used in 10 of the vineyard area southern portion of the study area 2 2 participatory modeling approach our modeling approach was designed according to the key principles of participatory modeling voinov 2008 it took place in alternating collective workshops and model development phases a preliminary phase of individual interviews was dedicated to the identification of key stakeholders and to the understanding of the main features of the territory and its cropping systems the modeling framework was divided into three main steps which were accomplished over the course of four workshops ws fig 2 the involvement of stakeholders began early in the process the first step was devoted to the construction of the model including the conceptualization of the system with stakeholders the selection of the model components referred as modules hereafter their numerical implementation and the transformation of model outputs into evaluation indicators in the second step the model was parameterized and tested relying on field measurements and the baseline simulation of historical climatic conditions developed with stakeholders analysis of the results from model testing led to refinements of the numerical model a third step entailed simulating the baseline situation in future climatic conditions and discussing its results with the stakeholders table 1 presents the participation of stakeholders participants were drawn from the viticulture and water management sector researchers participated as scientists according to terms described by leenhardt et al 2012 to provide scientific knowledge on the investigated processes and the corresponding computer models one researcher acted as a facilitator the participants in ws3 and ws4 were divided into two sub groups local and regional number of participants was limited by covid 19 restrictions leading to six ws in total july 2019 oct 2019 two in june 2020 and two in feb 2021 the period between workshops varied from three to eight months resulting in a certain amount of time being needed to review the previous discussions 2 2 1 step 1 model construction the first workshop 1 day was dedicated to 1 sharing perceptions on climate change and its impacts and 2 building a conceptual scheme describing the system during the workshop non researcher participants 9 stakeholders were asked to describe an outstanding climatic event they associated with climate change and its consequences participants were then divided into two sub groups and asked to list all adaptation levers they wanted to consider after pooling the levers stakeholders selected the most important and detailed the agricultural context that would allow or prevent their implementation after the workshop researchers synthesized the collected information into a conceptual scheme in which information was classified as input variables processes or output variables we hypothesized that the coupling of existing models could represent the system described by the stakeholders so we examined a collection of existing models recently reviewed in costa et al 2015 and moriondo et al 2011 and made a selection according to the conceptual scheme and the availability of data we identified four modules that aligned with the stakeholders primary aims and could be assembled to constitute a vineyard watershed model fig 3 phenology crop water balance yield and hydrology we chose the grape phenological model recently developed by morales castilla et al 2020 to forecast budburst flowering and veraison dates maturity being fixed 35 days after veraison we used parameters from three varieties chardonnay syrah and cabernet sauvignon that have different phenologies and are grown in the rieutort watershed calculated phenological stages were inputs for the daily water balance model we chose the walis model celette et al 2010 for the simulation of water balance because it has been frequently used in the mediterranean area delpuech and metay 2018 gaudin et al 2014 and was familiar to a number of the stakeholders the walis model allowed the consideration of three adaptation levers cited by stakeholders cover crop management grapevine canopy management and irrigation we implemented an automatic irrigation schedule which was activated when the calculated fraction of transpirable soil water ftsw also converted into predawn water potential according to lebon et al 2003 decreased under thresholds that vary according to the phenological stages and production objectives we used the thresholds proposed by ojeda 2007 to maintain a low to moderate constraint ftsw of 0 21 0 3 mpa between budburst and flowering 0 12 0 4 mpa between flowering and mid flowering veraison 0 07 0 5 mpa between mid flowering veraison and veraison and 0 04 0 6 mpa between veraison and maturity walis includes the calculation of runoff based on the curve number method cn which is determined from given empirical values according to land cover soil hydrological group and soil state surfaces romero et al 2007 usda 1993 it has the advantage working on a daily time step which is consistent with the climatic projection data stakeholders noted total runoff in the watershed as an issue under future climate conditions decreasing river flow flood risk and lower rainfall efficiency therefore we added a hydrological module derived from the mhydas model moussa et al 2002 which instantaneously distributes water into the downstream plots or into streams the connectivity rules between plots and between plots and streams were derived from the geo mhydas model lagacherie et al 2010 finally stakeholders highlighted decreasing yield as one of the major sources of concern when dealing with climate change issues however we determined that the existing grape models knowling et al 2021 moriondo et al 2015 did not fit our specifications in terms of data availability and consistency with the other chosen models consequently we tailored an ad hoc model affholder et al 2012 that coupled the walis model with a grape yield response to water model gray derived from guilpart et al 2014 detailed in section 3 1 2 2 2 2 step 2 model parameterization and testing 2 2 2 1 definition of the baseline situation the second workshop was dedicated to the description of the current grapevine production system the objective being to implement the watershed model in the baseline situation first researchers presented the model together with the conceptual scheme highlighting the processes included in or excluded from the simulation model after a discussion about model components stakeholders described the current situation in order to obtain spatially explicit input parameters researchers presented the available maps on land use irrigated areas pdo delimitation and soils existing information was reviewed by stakeholders and corrected during a participatory mapping exercise the stakeholders also described practices of irrigation supply frequency restrictions canopy management rows spacing canopy height and bud load and cover crop management sowing dates covered surfaces tillage or mowing dates for the different types of grapevine production systems they then localized those practices on the map some information was difficult to collect during the workshop therefore additional information e g varietal distribution in space was provided later by local participating institutions after the workshop the researchers transformed the collected information into model inputs to simulate the baseline situation since we did not have spatialized data for the varieties we calculated the portion of early mid and late ripening varieties by type of production using the data provided by the stakeholders then we attributed a variety type early mid late ripening to each vineyard plot according to its type of production and with respect to the calculated ratios we only simulated the yield response to water gray model for the syrah variety constituting 50 of the rieutort vineyard area because we did not have sufficient data nor the local expertise for calibrating other varieties the third workshops ws3a and ws3b 4 h each were dedicated to the discussion of the simulation results for the baseline situation at the field scale and for historical climate 1981 2010 this included graphical representation of model outputs for 10 representative situations e g yield phenological date daily runoff vine water status during the presentation stakeholders were asked to share their analysis of the simulation results their agreement or disagreement as well as their suggestions to improve the model this step allowed the adjustment of some model inputs and parameters before presenting the results at the watershed scale the adjustments suggested by stakeholders during the parametrization step led us to conduct on farm monitoring this was i helpful in building trust in the model with a quantitative comparison of observed and simulated data and ii it allowed us to estimate soil parameters ttsw total transpirable soil water that could not be estimated by stakeholders during workshop 2 2 2 2 field monitoring network the quantitative evaluation of the walis gray model i e coupling of walis and gray models was based on on farm data collected in the rieutort watershed we monitored the grape water status and yield components of 10 contrasting plots soil type production type cover crop management and irrigation access on the basis of the production systems described by stakeholders in ws2 fig 1 and full description in appendix a table a1 for each plot 30 plants were monitored from march to september 2020 the grapevine water status was monitored during summer three measurements from june to august by measuring the predawn leaf water potential with a pressure chamber soil moisture equipment corp santa barbara usa on 12 fully expanded leaves per plot the yield shoot and bunch numbers were measured on the 30 vine plants on each of these plants one bunch was randomly selected to obtain the number of berries per bunch and the averaged berry weight from a sample of 200 berries to simulate the grapevine yield with the walis gray model we first parameterized the walis model celette et al 2010 that simulates the time course of ftsw fraction of transpirable soil water at a daily time step simulations were conducted for the 10 plots from september 2018 to september 2020 we used the weather data recorded at the weather station of murviel les beziers fig 1 maximum crop coefficient kmax was calculated with the model of riou riou et al 1989 using measurements of the average canopy size height wide porosity of the 30 vine plants in each plot parameters describing spontaneous cover crops e g lai growth rate leaf life span were taken from andrieux et al 2015 total transpirable soil water was estimated by inversion of the walis model pellegrino et al 2006 parameter values for all the simulations are given in appendix a table a2 the quality of the simulations was assessed against observed values of predawn water potential converted into ftsw lebon et al 2003 observed yield and yield components four statistical criteria were calculated to assess the model performance the model efficiency ef the coefficient of determination r 2 the normalized average error nae and the normalized root mean square error nrmse janssen and heuberger 1995 2 2 2 3 choice of output representations the third workshops were also tasked with choosing the evaluation indicators i e the model outputs representations that would be presented at watershed scale during the following workshops after discussing the outputs of the model at the field scale stakeholders selected those of interest for each selected output researchers asked stakeholders to define the relevant temporal aggregation e g seasonal variability annual mean spatial aggregation e g mean by soil type by production type and type of representation map bar plot table 2 2 3 step 3 model simulations at watershed scale future climate data were obtained from the regional climate model cnrm aladin version 5 2 http www umr cnrm fr spip php article125 lang en projections were bias corrected using the cumulative distribution functions cdf transformation proposed by michelangeli et al 2009 we used the daily meteorological data from murviel les beziers weather station fig 1 between 1990 and 2005 to correct the projections on the central climatic area of the watershed table 2 the same correction was then applied to the northern and southern climatic areas appendix a table a3 we simulated the baseline situation described by stakeholders for the historical period 1981 2010 two time horizons 2039 2060 and 2069 2100 and two representative concentration pathways rcp 4 5 and 8 5 the reference evapotranspiration e t 0 was calculated according to penman monteith equation allen et al 1998 in the near future 2031 2060 the increase in temperature and reference evapotranspiration are similar for rcp 4 5 and 8 5 conversely growing season precipitation is predicted to increase in rcp 4 5 while it is predicted to decrease in rcp 8 5 changes in the far future 2071 2100 are accentuated in rcp 8 5 with an increase of 4 c in temperature and a decrease of 12 in rainfall it is worthy to note that the growing season rainfall is projected to increase 12 in rcp 4 5 similar trends are observed for the northern and southern climatic areas by the end of the century in rcp 8 5 temperature increase will be more pronounced in the northern areas 5 c and annual rainfall will decrease below a critical threshold for grapevine growth in the southern areas with an average annual precipitation of 520 mm appendix a table a3 finally we ran the watershed model of the baseline situation with the five climate scenarios the results of the simulations were presented to the two groups of stakeholders in ws4a and ws4b 4 h each after a brief reminder of model characteristics and climate change scenarios the simulations results were presented using the indicators collectively built in ws3 after the presentation stakeholders were asked to share their analyses of the scenario simulations 2 3 modeling software and representations the spatial and temporal model coupling was developed using the openfluid software platform for spatial modeling in landscapes http www openfluid project org fabre et al 2013 the open source software framework and user environment of openfluid was chosen for its original features that are relevant for this work representation of simple and complex landscapes such as agricultural landscapes made of spatial objects with associated attributes and spatial connections easy integration of existing modules or development of new modules spatio temporal model coupling at various scales adaptable input and output data formats for easier pre and post processing the complete coupled model fig 3 was implemented as plugged modules in the openfluid platform using c language and embedded r code eddelbuettel et al 2020 simulations were defined as parameterized openfluid projects and results were post processed using the r software r core team 2018 with ggplot wickham 2016 and cartography packages giraud et al 2020 3 results 3 1 from the conceptual scheme to the simulation model step 1 3 1 1 conceptualization with stakeholders the first workshop ws1 completed two tasks a a list of climate change impacts and corresponding adaptation levers that were collectively discussed and b a conceptual scheme constructed by researchers and based on the workshop discussions during the workshop a consensus around preoccupying climatic events was reached with a particular focus on the water and temperature regimes e g increase in intra annual rainfall variability frequency of heavy rains heat waves strong winds the participants identified a large range of impacted processes following such events agronomic yield plant mortality phenology pest pressure environmental streamflow irrigation water consumption and economic regional economy irrigation costs they considered various adaptation levers which they were asked to classify according to spatial and time scales two groups of adaptation levers were discussed long term adaptations at planting row orientation drought tolerant varieties training system rootstocks etc and seasonal adaptations canopy management organic fertilization irrigation etc the opportunity or challenge to implement these adaptations levers depend on various aspects of the landscape water access pdo delimitation the farm adaptive capacity equipment investment capacity yield objective winery etc and the field soil type vine age slope pdo regulations researchers designed a conceptual scheme based on the elements collected during ws1 fig 4 and presented it to stakeholders for validation in ws2 the comparison between the conceptual scheme and existing simulation models led to the modeling choices described in section 2 2 1 the absence of non simulated processes and adaptation levers could be explained by the lack of data in the watershed e g farm data soil analyses the absence of modeling tools e g farm decision model pest pressure or the lack of certain information rootstock effect yield response to water for different training systems and varieties yield quality and heat damage were not directly modeled because the discussion primarily focused on the relationship between yield quantity and water availability however agro climatic indicators that give information on climatic risk on yield and its quality were designed with the stakeholders later in the process see section 3 2 3 3 1 2 development of the grape yield model gray the complete numerical model is presented in section 2 2 1 here we detail the grape yield model gray which was developed after recognizing the importance that participants gave to the evaluation of grapevine yield evolution under future climatic conditions the grapevine yield was decomposed as in guilpart et al 2014 y i e l d n s h o o t f b u d n b e r r y w b e r r y 10 3 where yield is the fresh yield in kg plant nshoot is the number of shoots per plant fixed by pruning operation fbud nberry are wberry are bud fertility i e number of bunches per shoot the number of berries per bunch and the mean berry weight in g respectively each of these yield components was calculated as a function of the soil water availability simulated by the walis model ftsw at critical phenological phases these response functions were parameterized with data sets from guilpart et al 2014 and gaudin et al 2014 complete dataset description in appendix b table b1 daily simulated ftsw were averaged for thermal time periods of 100 cd cumulative thermal degree in base 10 from budburst to harvest for each period the pearson coefficient between each yield component and mean ftsw was calculated and its significance was tested by this means we identified four critical periods consistent with guilpart et al 2014 during which yield component values are highly and significantly correlated with mean ftsw between 500 and 600 cd in year n 1 for bud fertility between 700 and 800 cd in year n 1 for berry number per bunch between 800 and 900 cd and between 1400 and 1500 cd in year n for berry weight detailed in appendix b fig b1 the response curve of yield components to mean ftsw during critical period f t s w c r i t was derived from these statistical analyses fig 5 a b c each yield component remained at maximum between f t s w c r i t 1 and a threshold value f t s w t h and decreased linearly between f t s w t h and f t s w c r i t 0 yield component maximum minimum and threshold values were obtained using the nelder mead minimization algorithm nelder and mead 1965 bud fertility varied between a minimum of 0 2 bunches shoot and a maximum of 2 bunches shoot number of berries per bunch varied between a minimum of 65 berries bunch and a maximum of 200 berries bunch berry weight varied between a minimum of 1 g and a maximum of 2 g threshold values f t s w t h were 0 7 0 6 and 0 22 respectively simulated and measured yields were compared for the two data sets together fig 5d the overall correlation was significant r2 0 79 p 0 05 and proved the capability of the walis gray model to catch the major sources of variability found in the experimental yield data the values of nrmse 29 and model efficiency 0 6 attest to the ability of the modeling solution to reproduce measured yields simulated yields tended to be higher than the observed ones especially for high yields nae 0 16 a possible reason is the lack of consideration for other limiting factors such as nitrogen as evidenced by guilpart et al 2014 3 2 model testing step 2 3 2 1 description of the baseline situation the second workshop started with the identification of the key location factors that determine the spatial distribution of grapevine production systems stakeholders first considered soil type as the main factor they modified the soil map to delimit five main units alluvial and fersiallitic areas were unchanged but the clay limestone area was divided into two areas that identify the soils from the central part of the watershed as more shallow and stonier they also divided the shale area into two areas indicating more soil heterogeneity in mountainous areas although those areas were difficult to delimit precisely cover crop management was identified as closely linked to soil type due to different levels of weed competition and soil water availability three characteristics of cover crop management were described a destruction date of spontaneous winter cover from the 15th of february for alluvial fersiallitic and non stony clay limestone soils to the 1st of march for other soils a date of mechanical tillage after harvest 15th of october for southern sector only and a number of inter rows kept covered during summer 1 inter row in 4 for 33 ha in the watershed the second factor that stakeholders highlighted as a key determinant of spatial distribution of grapevine production systems was the type of wine production pdo or pgi directly linked with yield objectives the location of pdo production areas was provided by pdo syndicate representatives pgi areas were deducted from all the remaining areas for each type of production stakeholders reported the planting density from 4000 vines ha in pdo area on shale soil to 4500 vines ha for other areas the canopy height from 1 1 m to 1 4 m the bud load from 9 to 15 buds vine and the grapevine varieties we found no early ripening varieties in pdo production sectors which averaged 80 mid ripening varieties and 20 late ripening varieties by contrast the variety distribution in pgi sectors averaged 30 early ripening 40 mid ripening and 30 late ripening varieties the last factor was the access to water irrigation for pgi production in the southern part of the watershed opinions on the irrigation management to implement in the model varied among the local and regional stakeholders but finally irrigation supplies were fixed at 20 mm for the first supply and 10 mm afterwards with unlimited annual supply from budburst to harvest these factors led to eight production sectors which are presented in fig 6 each sector corresponds to a block of similar grape growing systems soil type of production irrigation practices sectors 1 to 3 are in the southern climatic area sectors 4 to 6 are in the central climatic area and sectors 7 and 8 are in the northern climatic area 3 2 2 quantitative evaluation of the walis gray model with on farm measurements the 10 monitored plots located in the eight production sectors produced yields ranging from 1 03 to 7 73 kg vine water status varied significantly during the 2020 season which was characterized by a wet spring 244 mm from march to may and a dry summer 81 mm from june to august thus allowing soil water recharge at the beginning of the season followed by a progressively important water constraint measured predawn water potential in mid august ranged from 0 4 to 0 9 mpa table 3 shows the evaluation indicators of the walis gray model including soil water availability ftsw and yield components the simulated ftsw was in agreement with measured predawn water potential for eight of the 10 plots ef 0 57 the differences between simulated and observed ftsw could partly be explained by the low ability of the walis model to simulate a goblet training system in plot 8 and by the lack of consideration for leaf damage caused by disease that was observed in plot 4 the normalized average error was between 5 and 35 and was negative for seven plots simulated data tended to slightly overestimate soil water availability the gray model was quite proficient at simulating grapevine yield the r2 and ef values were 0 86 and 0 71 respectively the normalized average error was negative 0 21 i e 0 58 kg vine showing a yield underestimation with variation among fields while simulated bud fertility a major determinant of grapevine yield showed a positive model efficiency ef 0 27 the simulated number of berries and berry weight exhibited a negative model efficiency those components may compensate for each other and result in good predictions of yield we presume that the prediction of the number of berries could be further improved by considering the current season s climatic conditions primarily air temperature and rainfall zhu et al 2020 nevertheless r2 and nrmse were satisfactory and significant r2 0 53 and 0 49 nrmse 0 27 and 0 19 resp 3 2 3 evaluation indicators for watershed simulation the second part of the third workshop produced a list of indicators aimed at representing the impacts of climate change at watershed scale table 4 the group of regional stakeholders ws3a selected mainly field scale indicators to represent the level of grape production and water use irrigation and runoff they also designed indicators to estimate the climatic risks on grape production in terms of both quantity and quality those indicators consisted of identifying the temperatures that are detrimental to the vine production frost scalding berry maturation conditions researchers added some indicators which relate to the entire watershed because up to this point the watershed scale had not been fully represented the added indicators relate to climate change impacts highlighted in ws1 table 4 3 3 simulations under current and future climatic conditions step 3 3 3 1 phenological dates and associated climatic risks in the historical period 1981 2010 phenological stages budburst flowering veraison and maturity occur earlier in southern areas than in northern areas fig 7a this 13 day difference between harvest dates was confirmed by stakeholders in ws4 and is mainly due to milder temperatures and late ripening varieties in the northern areas at the horizon 2050 the two climate scenarios show similar predictions with harvest dates being 10 days earlier on average than historical dates at the horizon 2100 phenological advance is more pronounced for rcp 8 5 with a more important advance in the northern areas where budburst occurs 13 days earlier and harvest occurs 23 days earlier projected phenological dates show a shortening of the grapevine cycle ranging from 2 rcp45 2100 to 10 days rcp85 2100 earlier budburst does not lead to an increased risk of frost because the date of the last frost in climate projection also advanced fig 7b however stakeholders professed despite the lesser occurrence of frosts we are still afraid of a late frost the combined effects of advanced phenology and increased temperatures lead to an increased risk of heat damage between flowering and veraison by the horizon 2100 berry maturation conditions change faster for the time horizon 2050 night temperatures increase by 3 5 c and maximal night temperatures exceed 37 c more than two years in three which could alter berry maturation processes for the time horizon 2100 as highlighted by a participant of ws4b a nighttime temperature of 23 c during maturation that s hot 3 3 2 irrigation needs and total grape production mean simulated irrigation requirements for the historical period are 21 mm per year table 5 which seemed low to stakeholders with respect to current practices these are the requirements not the inputs you d be surprised by the difference the reality is more than 100 mm there are several possible reasons for the difference between model outputs and stakeholder statements first the irrigation needs were presented as a 30 year average including many years that do not require irrigation second stakeholders mentioned that the actual irrigation amounts are greater than real needs nonetheless they highlighted the need for efforts to reduce the gap between grapevine water requirement and inputs in future climate scenarios irrigation requirements increase by 62 85 at the horizon 2050 and are predicted to more than double by the end of the century in the rcp 8 5 the largest increases in water requirements occur during spring although historical spring irrigation is almost nil these predicted requirements however remain lower than the current practices estimated by local stakeholders total grapevine production at watershed scale is expected to decrease from 5 to 11 by mid century table 5 the decrease in production is relatively similar in rcp 4 5 for both time horizons 5 to 7 whereas the predicted decrease reaches 14 in rcp 8 5 for 2100 the type of production that undergoes the most important decrease is the pgi irrigated production despite the increase in irrigation water supply an explanation could be the irrigation thresholds that might be too low to maintain high yield under future climatic conditions we expect that yield losses could be limited by higher irrigation levels in any case irrigated production represents a small part of the rieutort grapevine production 20 in volume and maintaining the production in those irrigated areas would not counteract the global drop of production at watershed scale stakeholders argued for a better sharing of water resources and defended the idea to consider other irrigation practices for high quality production in order to reach the objective of limiting irrigation while securing production 3 3 3 grapevine yield during the historical period 1981 2010 lower yields 5 t ha are found in the northern area with pdo production on superficial soil while the highest productivity sectors 14 t ha are located in the southern and irrigated areas fig 8 these patterns showed a general agreement with stakeholders perceptions projections show contrasted yield evolution according to the two rcps in rcp 4 5 modeled yields slightly increase in the northern sectors this could be explained by two factors the more pronounced advance in phenology that avoids drought periods after flowering period critical period for bud fertility and berry number determination and the higher summer rainfall amounts predicted in rcp 4 5 table 2 that refill soil water reserve more efficiently in superficial soils in the other sectors yields decrease by 10 in 2050 and 20 in 2100 in rcp 8 5 the yields in all sectors were predicted to decrease by 10 20 in 2050 and as much as 30 for the southern sectors in 2100 the important yield decrease in the southern irrigated area could be explained by the particularly low annual rainfall amounts predicted with the rcp 8 5 scenario 530 mm it is worth noting that the model could overestimate the yield decrease in the southernmost sector because it does not consider the presence of a groundwater table that could mitigate the vineyard water stress in reaction to these results participants first highlighted the importance of changes in management practices particularly in the southern areas as compared to northern areas for example they suggested that better vigor management could limit the water loss by transpiration stakeholders from the northern area interpreted the predicted low decrease in their yield as good news but pointed out that they must maintain a high economic return for their wine finally the participants suggested broadening the range of evaluation indicators with further details on berry sugar accumulation in relationship with the leaf fruit ratio and economical aspects at farm scale 4 discussion 4 1 model based evaluation of climate change impacts the sources of error in model predictions decrease when the number of simulated processes increases i e the complexity of the model by contrast the uncertainties on the parameter values increase in parallel with model complexity passioura 1996 in our study the crop model i e the coupling of phenological walis and gray models relies on fewer processes in an effort to find the best compromise between the number of processes and the number of parameters needed to estimate grape yield based on the results of guilpart et al 2014 we hypothesize that grape yield is limited by the number of sinks clusters and berries per plant rather than by net assimilation consequently our model does not include any effect of increasing co2 concentration in the atmosphere omitting the positive effect it might have on photosynthesis but this point needs to be further documented for perennial crops toreti et al 2020 it should be noticed that until now co2 enrichment of grapevines has been carried out with no limitation in water and nitrogen supplies and only over the course of 2 3 years bindi et al 2001 moutinho pereira et al 2009 wohlfahrt et al 2019 however studies looking at other perennial systems forests grassland and longer time periods showed that when soil resources are limited the effect of elevated co2 on productivity may be less certain reich and hobbie 2013 similarly our model did not include variety specific responses of yield to water deficit it is likely that such variability exists among the current grapevine varieties duchene 2016 but it is difficult to infer stable parameter values from the available data bases levin et al 2020b despite these two simplifications the walis gray model was able to simulate grapevine yield with quality indicators similar to those in existing grapevine models found in the literature such as unifi grapeml leolini et al 2018 and stics fraga et al 2015 moreover our study emphasized on farm situations which is not the case in the majority of grapevine models knowling et al 2021 other model limitations are related to the availability and quality of the input data stakeholders highlighted two main limitations in the data used first although we distinguished three climatic areas thanks to the medium resolution climate projection data 8 8 km² we did not take into account microclimatic effects which are determinant factors of vulnerability and adaptation in small region studies le roux et al 2017 quénol et al 2017 tissot et al 2017 second the estimation of soil water availability was based on isolated estimations even if experimental fields were chosen with stakeholders to represent soil conditions in the watershed it is difficult to capture small scale variations these estimations of spatial variations could be improved by using high spatial resolution satellite and crowdsourcing data pichon et al 2021 which are promising tools to improve the quality of the spatial representation of the soil parameters future development of the model could focus on three aspects first the structure of the model could be improved by including the effects of other climatic variables during different time periods such as the effects of air temperature and rainfall during flowering zhu et al 2020 second the validity of the model should be tested on other independent databases in the recent literature we have identified relevant databases that consider both grapevine water status and yield components during several years levin et al 2020a zhu et al 2020 this step should include a characterization of model uncertainties arising from model structure parameters and input data in order to address the confidence in our results in different contexts third the model was developed initially for research purposes its current form lacks elements e g an interface and simulation duration that would allow an independent transfer to stakeholders the model could also be made more accessible during workshops with stakeholders for example by facilitating the direct display of model results the present study quantitatively evaluates the impacts of climate change on grapevine phenology irrigation needs and grapevine yield regarding the phenology our simulation shows clear advancement in the timing of each event which is consistent with fraga et al 2016 in their study conducted at european scale the more pronounced advancement at higher elevation corroborates the results of caffarra and eccel 2011 this may be related to a higher phenological sensitivity of mountain sites to climate change previous studies that simulated grapevine yields under future climatic conditions offer contradictory findings in part because the model and data choices depend on the spatial scale for example our findings do not support previous research at the european scale that projected a yield increase in south of france for rcp 8 5 stics model in fraga et al 2016 but we see similarities with a medium scale study led in the tuscany region 61 000 ha vineyard in italy that predicted yields decreasing from 15 to 30 by the end of the century moriondo et al 2011 the comparison of those two studies shows how spatial scale and model choice linked to different climate and soil data sets is crucial nevertheless those studies involved invariant plant material and cultivation practices variety planting density training system our study goes further by simulating different cropping systems according to their localization moreover our findings suggest that the current diversity of practices is a way to limit grapevine vulnerability to climate change the simulated irrigation water requirements are low compared to those reviewed by naulleau et al 2021 one reason for this could be that the irrigated areas are located in deep soils with a ttsw higher than 225 mm in mediterranean areas grapevines are often cultivated in soils more prone to water stress e g ttsw close to 100 mm in gaudin and gary 2012 the main finding of this work is in agreement with fraga et al 2018 it suggests that the increased irrigation supply would not be sufficient to alleviate yield losses in irrigated areas 4 2 benefits and limitations of the participatory approach while model based evaluation of climate change impacts should be carried out with caution due to various sources of uncertainty corbeels et al 2018 they can be beneficial in a participatory approach to hybridize local and scientific knowledge and stimulate discussions in this study the early and frequent involvement of stakeholders was beneficial at multiple points in the modeling process first stakeholders actively helped at defining the representation of the baseline situation in the model information provided by generic datasets commonly used by modelers e g soil cultivation practices appeared too rough to represent the spatial variability in the studied landscape as in murgue et al 2016 we found a compromise between case study spatial extent and level of details in the representation of cropping systems although we reached a simpler representation than theirs nonetheless the participatory mapping exercise significantly enhanced the representation of a common reference situation for grapevine landscape at pertinent scales and accomplished this relatively quickly second as in murgue et al 2016 our participatory framework gave various occasions to explain and to update intermediary objects conceptual scheme baseline description field scale outputs evaluation indicators that evolved as the workshops progressed consequently as in leenhardt et al 2012 the information and concepts shared between stakeholders and modelers were progressively assimilated and improved these frequent interactions with stakeholders together with the reciprocal sharing of data could explain the higher level of trust in the model and the stable participation rate this study impacted the stakeholders through their interactions with the researchers they expressed the benefits they received from the study during a group discussion and in an individual questionnaire at the end of the study they initially identified the limits of current models in representing their systems and the impacts of climate change but they appreciated the quantitative information they obtained from the researchers especially in terms of climate evolution the spatial representation helped clarify the diversity of their systems and constraints and they particularly benefited from the extensive time dedicated to discussions and the sharing of experiences however several limitations to the participatory approach should be acknowledged first the workshop participants were primarily drawn from the viticulture sector and were thus focused on grape production objectives the agro environmental facilitators were also close to this sector and the regional policymaker acted primarily as an observer thus we did not consider other important environmental and economic issues e g other crop productions water for human consumption employment we tried to enroll local and regional policy makers with transversal skills through interviews but they decided to not participate in the workshops although they remained interested in the study results indeed the defined research problem was specific to the viticulture sector and thus drew a specific audience second modelers had difficulty taking account of certain processes that stakeholders highlighted as important we can cite among others the effects of hedges and trees that can create a favorable microclimate for grapevines grimaldi 2018 and processes linked to the evolution of pest pressure under a changing climate bois et al 2017 those two examples are difficult to include in a dynamic model because the underlying processes are complex and not well known processes to be considered are multi factorial climate cultural practices initial pest pressure type of hedges etc they require fine scale data topography vegetation layers humidity rate etc and there are interactions between scales from plant organs grapevine canopy field to landscape nonetheless it is possible to include expert knowledge about these processes into other types of models voinov et al 2018 sacchelli et al 2017 structured expert knowledge around climate change adaptation in tuscany by using cognitive maps semi quantitative model that allowed to detail all important concepts and the action retroaction loops between them other model formalisms such as the agent based models seen in delay et al 2015 are also based on expert knowledge to simulate dynamics at different spatial and temporal scales however such models are specific to the participants and the local conditions their uses and their results would probably be difficult to extrapolate to other areas in our case the watershed model remains generic and could be used to simulate other vineyards in the world providing that necessary input data exist and that grape yield is mainly limited by water our findings should certainly be able to be extrapolated to typical mediterranean vineyards where coastal plains meet inland hills 5 conclusion combining modeling and participatory approaches remains challenging especially in complex and uncertain contexts such as climate change issues the present study was designed to implement a modeling approach that combines scientific and local knowledge to quantitatively evaluate the impacts of climate change in a mediterranean vineyard watershed we illustrate how the interactions between stakeholders and modelers led to an original watershed model whose inputs were spatially defined by local stakeholders the integrated evaluation of climate change impacts reveals the heterogeneity of those impacts on the watershed in terms of local conditions soil and climate and grapevine production systems the entire territory would be impacted by high temperatures increasing risks to production in both quantity and quality but premium wine production areas pdo would be less impacted than high production areas pgi the stakeholders found the generated information on climate change impacts to be relevant and in the next step they will be involved in the design of local adaptation strategies declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was supported by the laccave 2 21 project funded by the meta program adaptation of agriculture and forests to climate change aafcc of the french national research institute for agriculture food and environment inrae this work is part of a phd project funded by the occitanie regional council and the inrae agroecosystem division authors would like to thank all study participants as well as technical staff for their help in field data collection we thank iñaki garcia de cortazar ue agroclim for providing phenological model and parameters ue agroclim and météo france for providing the climate data and frederic huard ue agroclim for his advices on bias correction of climate projections data we thank guillaume coulouma and philippe lagacherie umr lisah for rieutort soil description thierry lacombe umr agap and thierry simonneau umr lepse for their insights on grapevine physiology authors would like to thank ben boswell for english reviewing appendix a supplementary data the following is the supplementary data to this article appendixa naulleau etal ems2021 r3 resubmitted docx appendixa naulleau etal ems2021 r3 resubmitted docx appendixb naulleau etal ems2021 r3 resubmitted docx appendixb naulleau etal ems2021 r3 resubmitted docx appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105342 
25618,the diversity of both pedoclimatic and socio economic contexts in agricultural landscapes makes evaluating the impacts of climate change a challenge models are pertinent tools to quantitatively explore possible futures and participatory approaches help account for local diversity we developed a model through an approach that involves stakeholders in the model s construction and testing and in the discussion of results we simulated spatially explicit impacts of climate change on water balance grape phenology and yield in a mediterranean vineyard watershed for two climate scenarios results show a decrease in grape production of 7 14 by 2100 yield decrease would be higher in irrigated high yield areas despite a doubling of irrigation water supply a forecasted 6 c increase in temperature during berry ripening would threaten wine quality the approach allows the communication of model results and limitations to stakeholders it is a promising means of identifying potential local adaptations to climate change keywords climate change grapevine landscape multi scale evaluation spatially explicit model stakeholders 1 introduction viticultural systems are experiencing previously unseen conditions resulting from climate changes at a global scale higher temperatures move phenological stages to earlier periods warmer conditions during berry growth and increased water deficits alter yield and grape quality van leeuwen and darriet 2016 understanding how grapevines are and will be impacted by climate change is challenging and requires a combination of approaches naulleau et al 2021 although process based crop models such as stics brisson et al 2003 and vinelogic walker et al 2020 provide advantages in the use of climate projections at large scales they often do not simulate local growing conditions that might permit viable viticulture under marginal conditions mosedale et al 2016 participatory approaches can help take account of local constraints and diversity and give pertinent information to decision makers delay et al 2015 dynamic crop models are important tools for evaluating long term impacts from an unprecedented combination of change factors climatic technical economic with multiple uncertainties existing crop models for grapevines at field and regional scales have been used with climate projections to evaluate the impacts of climate change on phenology caffarra and eccel 2011 garcia de cortazar atauri et al 2017 webb et al 2007 water status pieri et al 2012 tissot et al 2017 yield fraga et al 2016 and hydrological resources carvalho santos et al 2016 in a comprehensive review of grapevine models developed in a context of climate change moriondo et al 2015 argue for the use of low input dynamic models in order to limit data needs for impact studies at a regional scale although such existing models are able to consider several management practices mainly water nutrient and canopy management knowling et al 2021 their application is still limited to a small number of production systems e g trellis systems bare soil these systems may not be representative of local and diverse biophysical and socio economic contexts thus they neglect the interplay between local conditions and practices knowling et al 2021 interactions that have been highlighted as key factors of climate change vulnerability van leeuwen et al 2013 as a consequence the lack of more detailed and spatially explicit information in previous model based evaluations of climate change impacts limits their contribution to the design of adaptation policies santillán et al 2019 modeling is an iterative process in which the involvement of stakeholders can help offset the limits of crop models by creating a shared representation enhancing the understanding of a dynamic system and supporting decision making voinov 2008 voinov et al 2018 participatory modeling allows the integration of local knowledge in fine resolution analyses murgue et al 2016 discussions about model functioning with stakeholders hossard et al 2013 and the production of meaningful indicators allain et al 2018 involving stakeholders in modeling processes also helps us consider different scales which is crucial to agricultural system analysis delmotte et al 2013 for example the field scale is needed to identify the relationship between plant water requirements and production when adapting management practices while up scaling to the regional level enables the consideration of connectivity hydrology biodiversity spatial heterogeneity climate soil slope and aggregated indicators that facilitate decision making at the policy level e g extension of irrigated areas evolution of total production previous studies have shown that participatory modeling is particularly suitable for analyzing the effects of complex and uncertain situations such as climate change on various agricultural systems like rice delmotte et al 2017 mixed cropping and grazing rodriguez et al 2014 and livestock systems duru et al 2012 to date there have been few quantitative evaluations involving stakeholders that examine the impacts of climate change on grapevine systems we found only two examples delay et al 2015 tissot et al 2017 using agent based modeling approaches delay et al 2015 studied the evolution of grape acidity at field and cooperative cave scales in a medium sized area 39 km2 tissot et al 2017 studied the evolution of grape phenology water balance and ripening as well as work organization at field and farm scales in a small sized area 1 km2 we believe a new modeling approach that includes stakeholders in a specific vineyard can help coordinate the attention to spatial scale and simulated processes in a way that allows the quantitative evaluation of climate change impacts including on grape yield such an approach should be particularly attentive to both model transparency voinov and bousquet 2010 and the representation of model outputs allain et al 2018 with respect to transparency part of our study was dedicated to reducing the model complexity for grape yield in order to improve the understanding of results especially by the stakeholders recent developments show that yield components can be expressed as functions of water stress indicators at critical periods van leeuwen et al 2019 proposed a model based on expert knowledge and guilpart et al 2014 incorporated more experimental data demonstrating a relationship between yield components and grapevine water status during critical periods over the course of two years in a recent review knowling et al 2021 give an overview of the relationship between berry weight and irrigation practices overall evidence seems to indicate that semi empirical modeling with limited parameters would be judicious and appropriate for a participatory approach to simulate grapevine yields the research reported in this paper proposes a new modeling approach that integrates stakeholders in the process of quantifying site specific climate change impacts it was applied to a viticultural watershed in southern france and designed to fulfill the following objectives 1 to use dynamic modeling to incorporate climatic predictions provided by the ipcc over a long time period 2 to involve stakeholders in an effort to increase local pertinence that represents spatial diversity and several scales from the field to the watershed and 3 to produce meaningful indicators that show the impacts of climate change on viticulture and water management in the watershed the participation of stakeholders for conceptualization model testing in the reference situation and discussion of the simulations under future climatic conditions helped improve simulation quality and understanding our study also led to the development of an ad hoc grapevine yield model called gray grape yield included in an original watershed model our results could be useful for local stakeholders and decision makers wine growers public institutions technical adviser etc to identify the most vulnerable areas and then assess site specific solutions for adaptation 2 materials and methods 2 1 study area the study took place in southern france fig 1 where viticulture is an important economic activity and is particularly sensitive to climate change we chose the rieutort watershed 45 km2 43 5 n 3 1 e as a case study because of its location between the southern coastal plain 581 mm mean annual rainfall data puisserguier weather station 2000 2019 and the relief of the hinterland to the north 705 mm mean annual rainfall data cabrerolles weather station 2000 2019 this area encompasses a diversity of active viticultural systems 1500 ha 20 of the vineyards are located on shale soils in the mountainous area to the north 60 are on mainly clay limestone soil in the central foothills and 20 are on more or less differentiated terraces of alluvial soil in the southern part of the watershed the total vineyard area is divided into two main production types a protected designation of origin pdo characterized by low yields of high quality wine and a protected geographic indication pgi characterized by higher yield objectives irrigation is used in 10 of the vineyard area southern portion of the study area 2 2 participatory modeling approach our modeling approach was designed according to the key principles of participatory modeling voinov 2008 it took place in alternating collective workshops and model development phases a preliminary phase of individual interviews was dedicated to the identification of key stakeholders and to the understanding of the main features of the territory and its cropping systems the modeling framework was divided into three main steps which were accomplished over the course of four workshops ws fig 2 the involvement of stakeholders began early in the process the first step was devoted to the construction of the model including the conceptualization of the system with stakeholders the selection of the model components referred as modules hereafter their numerical implementation and the transformation of model outputs into evaluation indicators in the second step the model was parameterized and tested relying on field measurements and the baseline simulation of historical climatic conditions developed with stakeholders analysis of the results from model testing led to refinements of the numerical model a third step entailed simulating the baseline situation in future climatic conditions and discussing its results with the stakeholders table 1 presents the participation of stakeholders participants were drawn from the viticulture and water management sector researchers participated as scientists according to terms described by leenhardt et al 2012 to provide scientific knowledge on the investigated processes and the corresponding computer models one researcher acted as a facilitator the participants in ws3 and ws4 were divided into two sub groups local and regional number of participants was limited by covid 19 restrictions leading to six ws in total july 2019 oct 2019 two in june 2020 and two in feb 2021 the period between workshops varied from three to eight months resulting in a certain amount of time being needed to review the previous discussions 2 2 1 step 1 model construction the first workshop 1 day was dedicated to 1 sharing perceptions on climate change and its impacts and 2 building a conceptual scheme describing the system during the workshop non researcher participants 9 stakeholders were asked to describe an outstanding climatic event they associated with climate change and its consequences participants were then divided into two sub groups and asked to list all adaptation levers they wanted to consider after pooling the levers stakeholders selected the most important and detailed the agricultural context that would allow or prevent their implementation after the workshop researchers synthesized the collected information into a conceptual scheme in which information was classified as input variables processes or output variables we hypothesized that the coupling of existing models could represent the system described by the stakeholders so we examined a collection of existing models recently reviewed in costa et al 2015 and moriondo et al 2011 and made a selection according to the conceptual scheme and the availability of data we identified four modules that aligned with the stakeholders primary aims and could be assembled to constitute a vineyard watershed model fig 3 phenology crop water balance yield and hydrology we chose the grape phenological model recently developed by morales castilla et al 2020 to forecast budburst flowering and veraison dates maturity being fixed 35 days after veraison we used parameters from three varieties chardonnay syrah and cabernet sauvignon that have different phenologies and are grown in the rieutort watershed calculated phenological stages were inputs for the daily water balance model we chose the walis model celette et al 2010 for the simulation of water balance because it has been frequently used in the mediterranean area delpuech and metay 2018 gaudin et al 2014 and was familiar to a number of the stakeholders the walis model allowed the consideration of three adaptation levers cited by stakeholders cover crop management grapevine canopy management and irrigation we implemented an automatic irrigation schedule which was activated when the calculated fraction of transpirable soil water ftsw also converted into predawn water potential according to lebon et al 2003 decreased under thresholds that vary according to the phenological stages and production objectives we used the thresholds proposed by ojeda 2007 to maintain a low to moderate constraint ftsw of 0 21 0 3 mpa between budburst and flowering 0 12 0 4 mpa between flowering and mid flowering veraison 0 07 0 5 mpa between mid flowering veraison and veraison and 0 04 0 6 mpa between veraison and maturity walis includes the calculation of runoff based on the curve number method cn which is determined from given empirical values according to land cover soil hydrological group and soil state surfaces romero et al 2007 usda 1993 it has the advantage working on a daily time step which is consistent with the climatic projection data stakeholders noted total runoff in the watershed as an issue under future climate conditions decreasing river flow flood risk and lower rainfall efficiency therefore we added a hydrological module derived from the mhydas model moussa et al 2002 which instantaneously distributes water into the downstream plots or into streams the connectivity rules between plots and between plots and streams were derived from the geo mhydas model lagacherie et al 2010 finally stakeholders highlighted decreasing yield as one of the major sources of concern when dealing with climate change issues however we determined that the existing grape models knowling et al 2021 moriondo et al 2015 did not fit our specifications in terms of data availability and consistency with the other chosen models consequently we tailored an ad hoc model affholder et al 2012 that coupled the walis model with a grape yield response to water model gray derived from guilpart et al 2014 detailed in section 3 1 2 2 2 2 step 2 model parameterization and testing 2 2 2 1 definition of the baseline situation the second workshop was dedicated to the description of the current grapevine production system the objective being to implement the watershed model in the baseline situation first researchers presented the model together with the conceptual scheme highlighting the processes included in or excluded from the simulation model after a discussion about model components stakeholders described the current situation in order to obtain spatially explicit input parameters researchers presented the available maps on land use irrigated areas pdo delimitation and soils existing information was reviewed by stakeholders and corrected during a participatory mapping exercise the stakeholders also described practices of irrigation supply frequency restrictions canopy management rows spacing canopy height and bud load and cover crop management sowing dates covered surfaces tillage or mowing dates for the different types of grapevine production systems they then localized those practices on the map some information was difficult to collect during the workshop therefore additional information e g varietal distribution in space was provided later by local participating institutions after the workshop the researchers transformed the collected information into model inputs to simulate the baseline situation since we did not have spatialized data for the varieties we calculated the portion of early mid and late ripening varieties by type of production using the data provided by the stakeholders then we attributed a variety type early mid late ripening to each vineyard plot according to its type of production and with respect to the calculated ratios we only simulated the yield response to water gray model for the syrah variety constituting 50 of the rieutort vineyard area because we did not have sufficient data nor the local expertise for calibrating other varieties the third workshops ws3a and ws3b 4 h each were dedicated to the discussion of the simulation results for the baseline situation at the field scale and for historical climate 1981 2010 this included graphical representation of model outputs for 10 representative situations e g yield phenological date daily runoff vine water status during the presentation stakeholders were asked to share their analysis of the simulation results their agreement or disagreement as well as their suggestions to improve the model this step allowed the adjustment of some model inputs and parameters before presenting the results at the watershed scale the adjustments suggested by stakeholders during the parametrization step led us to conduct on farm monitoring this was i helpful in building trust in the model with a quantitative comparison of observed and simulated data and ii it allowed us to estimate soil parameters ttsw total transpirable soil water that could not be estimated by stakeholders during workshop 2 2 2 2 field monitoring network the quantitative evaluation of the walis gray model i e coupling of walis and gray models was based on on farm data collected in the rieutort watershed we monitored the grape water status and yield components of 10 contrasting plots soil type production type cover crop management and irrigation access on the basis of the production systems described by stakeholders in ws2 fig 1 and full description in appendix a table a1 for each plot 30 plants were monitored from march to september 2020 the grapevine water status was monitored during summer three measurements from june to august by measuring the predawn leaf water potential with a pressure chamber soil moisture equipment corp santa barbara usa on 12 fully expanded leaves per plot the yield shoot and bunch numbers were measured on the 30 vine plants on each of these plants one bunch was randomly selected to obtain the number of berries per bunch and the averaged berry weight from a sample of 200 berries to simulate the grapevine yield with the walis gray model we first parameterized the walis model celette et al 2010 that simulates the time course of ftsw fraction of transpirable soil water at a daily time step simulations were conducted for the 10 plots from september 2018 to september 2020 we used the weather data recorded at the weather station of murviel les beziers fig 1 maximum crop coefficient kmax was calculated with the model of riou riou et al 1989 using measurements of the average canopy size height wide porosity of the 30 vine plants in each plot parameters describing spontaneous cover crops e g lai growth rate leaf life span were taken from andrieux et al 2015 total transpirable soil water was estimated by inversion of the walis model pellegrino et al 2006 parameter values for all the simulations are given in appendix a table a2 the quality of the simulations was assessed against observed values of predawn water potential converted into ftsw lebon et al 2003 observed yield and yield components four statistical criteria were calculated to assess the model performance the model efficiency ef the coefficient of determination r 2 the normalized average error nae and the normalized root mean square error nrmse janssen and heuberger 1995 2 2 2 3 choice of output representations the third workshops were also tasked with choosing the evaluation indicators i e the model outputs representations that would be presented at watershed scale during the following workshops after discussing the outputs of the model at the field scale stakeholders selected those of interest for each selected output researchers asked stakeholders to define the relevant temporal aggregation e g seasonal variability annual mean spatial aggregation e g mean by soil type by production type and type of representation map bar plot table 2 2 3 step 3 model simulations at watershed scale future climate data were obtained from the regional climate model cnrm aladin version 5 2 http www umr cnrm fr spip php article125 lang en projections were bias corrected using the cumulative distribution functions cdf transformation proposed by michelangeli et al 2009 we used the daily meteorological data from murviel les beziers weather station fig 1 between 1990 and 2005 to correct the projections on the central climatic area of the watershed table 2 the same correction was then applied to the northern and southern climatic areas appendix a table a3 we simulated the baseline situation described by stakeholders for the historical period 1981 2010 two time horizons 2039 2060 and 2069 2100 and two representative concentration pathways rcp 4 5 and 8 5 the reference evapotranspiration e t 0 was calculated according to penman monteith equation allen et al 1998 in the near future 2031 2060 the increase in temperature and reference evapotranspiration are similar for rcp 4 5 and 8 5 conversely growing season precipitation is predicted to increase in rcp 4 5 while it is predicted to decrease in rcp 8 5 changes in the far future 2071 2100 are accentuated in rcp 8 5 with an increase of 4 c in temperature and a decrease of 12 in rainfall it is worthy to note that the growing season rainfall is projected to increase 12 in rcp 4 5 similar trends are observed for the northern and southern climatic areas by the end of the century in rcp 8 5 temperature increase will be more pronounced in the northern areas 5 c and annual rainfall will decrease below a critical threshold for grapevine growth in the southern areas with an average annual precipitation of 520 mm appendix a table a3 finally we ran the watershed model of the baseline situation with the five climate scenarios the results of the simulations were presented to the two groups of stakeholders in ws4a and ws4b 4 h each after a brief reminder of model characteristics and climate change scenarios the simulations results were presented using the indicators collectively built in ws3 after the presentation stakeholders were asked to share their analyses of the scenario simulations 2 3 modeling software and representations the spatial and temporal model coupling was developed using the openfluid software platform for spatial modeling in landscapes http www openfluid project org fabre et al 2013 the open source software framework and user environment of openfluid was chosen for its original features that are relevant for this work representation of simple and complex landscapes such as agricultural landscapes made of spatial objects with associated attributes and spatial connections easy integration of existing modules or development of new modules spatio temporal model coupling at various scales adaptable input and output data formats for easier pre and post processing the complete coupled model fig 3 was implemented as plugged modules in the openfluid platform using c language and embedded r code eddelbuettel et al 2020 simulations were defined as parameterized openfluid projects and results were post processed using the r software r core team 2018 with ggplot wickham 2016 and cartography packages giraud et al 2020 3 results 3 1 from the conceptual scheme to the simulation model step 1 3 1 1 conceptualization with stakeholders the first workshop ws1 completed two tasks a a list of climate change impacts and corresponding adaptation levers that were collectively discussed and b a conceptual scheme constructed by researchers and based on the workshop discussions during the workshop a consensus around preoccupying climatic events was reached with a particular focus on the water and temperature regimes e g increase in intra annual rainfall variability frequency of heavy rains heat waves strong winds the participants identified a large range of impacted processes following such events agronomic yield plant mortality phenology pest pressure environmental streamflow irrigation water consumption and economic regional economy irrigation costs they considered various adaptation levers which they were asked to classify according to spatial and time scales two groups of adaptation levers were discussed long term adaptations at planting row orientation drought tolerant varieties training system rootstocks etc and seasonal adaptations canopy management organic fertilization irrigation etc the opportunity or challenge to implement these adaptations levers depend on various aspects of the landscape water access pdo delimitation the farm adaptive capacity equipment investment capacity yield objective winery etc and the field soil type vine age slope pdo regulations researchers designed a conceptual scheme based on the elements collected during ws1 fig 4 and presented it to stakeholders for validation in ws2 the comparison between the conceptual scheme and existing simulation models led to the modeling choices described in section 2 2 1 the absence of non simulated processes and adaptation levers could be explained by the lack of data in the watershed e g farm data soil analyses the absence of modeling tools e g farm decision model pest pressure or the lack of certain information rootstock effect yield response to water for different training systems and varieties yield quality and heat damage were not directly modeled because the discussion primarily focused on the relationship between yield quantity and water availability however agro climatic indicators that give information on climatic risk on yield and its quality were designed with the stakeholders later in the process see section 3 2 3 3 1 2 development of the grape yield model gray the complete numerical model is presented in section 2 2 1 here we detail the grape yield model gray which was developed after recognizing the importance that participants gave to the evaluation of grapevine yield evolution under future climatic conditions the grapevine yield was decomposed as in guilpart et al 2014 y i e l d n s h o o t f b u d n b e r r y w b e r r y 10 3 where yield is the fresh yield in kg plant nshoot is the number of shoots per plant fixed by pruning operation fbud nberry are wberry are bud fertility i e number of bunches per shoot the number of berries per bunch and the mean berry weight in g respectively each of these yield components was calculated as a function of the soil water availability simulated by the walis model ftsw at critical phenological phases these response functions were parameterized with data sets from guilpart et al 2014 and gaudin et al 2014 complete dataset description in appendix b table b1 daily simulated ftsw were averaged for thermal time periods of 100 cd cumulative thermal degree in base 10 from budburst to harvest for each period the pearson coefficient between each yield component and mean ftsw was calculated and its significance was tested by this means we identified four critical periods consistent with guilpart et al 2014 during which yield component values are highly and significantly correlated with mean ftsw between 500 and 600 cd in year n 1 for bud fertility between 700 and 800 cd in year n 1 for berry number per bunch between 800 and 900 cd and between 1400 and 1500 cd in year n for berry weight detailed in appendix b fig b1 the response curve of yield components to mean ftsw during critical period f t s w c r i t was derived from these statistical analyses fig 5 a b c each yield component remained at maximum between f t s w c r i t 1 and a threshold value f t s w t h and decreased linearly between f t s w t h and f t s w c r i t 0 yield component maximum minimum and threshold values were obtained using the nelder mead minimization algorithm nelder and mead 1965 bud fertility varied between a minimum of 0 2 bunches shoot and a maximum of 2 bunches shoot number of berries per bunch varied between a minimum of 65 berries bunch and a maximum of 200 berries bunch berry weight varied between a minimum of 1 g and a maximum of 2 g threshold values f t s w t h were 0 7 0 6 and 0 22 respectively simulated and measured yields were compared for the two data sets together fig 5d the overall correlation was significant r2 0 79 p 0 05 and proved the capability of the walis gray model to catch the major sources of variability found in the experimental yield data the values of nrmse 29 and model efficiency 0 6 attest to the ability of the modeling solution to reproduce measured yields simulated yields tended to be higher than the observed ones especially for high yields nae 0 16 a possible reason is the lack of consideration for other limiting factors such as nitrogen as evidenced by guilpart et al 2014 3 2 model testing step 2 3 2 1 description of the baseline situation the second workshop started with the identification of the key location factors that determine the spatial distribution of grapevine production systems stakeholders first considered soil type as the main factor they modified the soil map to delimit five main units alluvial and fersiallitic areas were unchanged but the clay limestone area was divided into two areas that identify the soils from the central part of the watershed as more shallow and stonier they also divided the shale area into two areas indicating more soil heterogeneity in mountainous areas although those areas were difficult to delimit precisely cover crop management was identified as closely linked to soil type due to different levels of weed competition and soil water availability three characteristics of cover crop management were described a destruction date of spontaneous winter cover from the 15th of february for alluvial fersiallitic and non stony clay limestone soils to the 1st of march for other soils a date of mechanical tillage after harvest 15th of october for southern sector only and a number of inter rows kept covered during summer 1 inter row in 4 for 33 ha in the watershed the second factor that stakeholders highlighted as a key determinant of spatial distribution of grapevine production systems was the type of wine production pdo or pgi directly linked with yield objectives the location of pdo production areas was provided by pdo syndicate representatives pgi areas were deducted from all the remaining areas for each type of production stakeholders reported the planting density from 4000 vines ha in pdo area on shale soil to 4500 vines ha for other areas the canopy height from 1 1 m to 1 4 m the bud load from 9 to 15 buds vine and the grapevine varieties we found no early ripening varieties in pdo production sectors which averaged 80 mid ripening varieties and 20 late ripening varieties by contrast the variety distribution in pgi sectors averaged 30 early ripening 40 mid ripening and 30 late ripening varieties the last factor was the access to water irrigation for pgi production in the southern part of the watershed opinions on the irrigation management to implement in the model varied among the local and regional stakeholders but finally irrigation supplies were fixed at 20 mm for the first supply and 10 mm afterwards with unlimited annual supply from budburst to harvest these factors led to eight production sectors which are presented in fig 6 each sector corresponds to a block of similar grape growing systems soil type of production irrigation practices sectors 1 to 3 are in the southern climatic area sectors 4 to 6 are in the central climatic area and sectors 7 and 8 are in the northern climatic area 3 2 2 quantitative evaluation of the walis gray model with on farm measurements the 10 monitored plots located in the eight production sectors produced yields ranging from 1 03 to 7 73 kg vine water status varied significantly during the 2020 season which was characterized by a wet spring 244 mm from march to may and a dry summer 81 mm from june to august thus allowing soil water recharge at the beginning of the season followed by a progressively important water constraint measured predawn water potential in mid august ranged from 0 4 to 0 9 mpa table 3 shows the evaluation indicators of the walis gray model including soil water availability ftsw and yield components the simulated ftsw was in agreement with measured predawn water potential for eight of the 10 plots ef 0 57 the differences between simulated and observed ftsw could partly be explained by the low ability of the walis model to simulate a goblet training system in plot 8 and by the lack of consideration for leaf damage caused by disease that was observed in plot 4 the normalized average error was between 5 and 35 and was negative for seven plots simulated data tended to slightly overestimate soil water availability the gray model was quite proficient at simulating grapevine yield the r2 and ef values were 0 86 and 0 71 respectively the normalized average error was negative 0 21 i e 0 58 kg vine showing a yield underestimation with variation among fields while simulated bud fertility a major determinant of grapevine yield showed a positive model efficiency ef 0 27 the simulated number of berries and berry weight exhibited a negative model efficiency those components may compensate for each other and result in good predictions of yield we presume that the prediction of the number of berries could be further improved by considering the current season s climatic conditions primarily air temperature and rainfall zhu et al 2020 nevertheless r2 and nrmse were satisfactory and significant r2 0 53 and 0 49 nrmse 0 27 and 0 19 resp 3 2 3 evaluation indicators for watershed simulation the second part of the third workshop produced a list of indicators aimed at representing the impacts of climate change at watershed scale table 4 the group of regional stakeholders ws3a selected mainly field scale indicators to represent the level of grape production and water use irrigation and runoff they also designed indicators to estimate the climatic risks on grape production in terms of both quantity and quality those indicators consisted of identifying the temperatures that are detrimental to the vine production frost scalding berry maturation conditions researchers added some indicators which relate to the entire watershed because up to this point the watershed scale had not been fully represented the added indicators relate to climate change impacts highlighted in ws1 table 4 3 3 simulations under current and future climatic conditions step 3 3 3 1 phenological dates and associated climatic risks in the historical period 1981 2010 phenological stages budburst flowering veraison and maturity occur earlier in southern areas than in northern areas fig 7a this 13 day difference between harvest dates was confirmed by stakeholders in ws4 and is mainly due to milder temperatures and late ripening varieties in the northern areas at the horizon 2050 the two climate scenarios show similar predictions with harvest dates being 10 days earlier on average than historical dates at the horizon 2100 phenological advance is more pronounced for rcp 8 5 with a more important advance in the northern areas where budburst occurs 13 days earlier and harvest occurs 23 days earlier projected phenological dates show a shortening of the grapevine cycle ranging from 2 rcp45 2100 to 10 days rcp85 2100 earlier budburst does not lead to an increased risk of frost because the date of the last frost in climate projection also advanced fig 7b however stakeholders professed despite the lesser occurrence of frosts we are still afraid of a late frost the combined effects of advanced phenology and increased temperatures lead to an increased risk of heat damage between flowering and veraison by the horizon 2100 berry maturation conditions change faster for the time horizon 2050 night temperatures increase by 3 5 c and maximal night temperatures exceed 37 c more than two years in three which could alter berry maturation processes for the time horizon 2100 as highlighted by a participant of ws4b a nighttime temperature of 23 c during maturation that s hot 3 3 2 irrigation needs and total grape production mean simulated irrigation requirements for the historical period are 21 mm per year table 5 which seemed low to stakeholders with respect to current practices these are the requirements not the inputs you d be surprised by the difference the reality is more than 100 mm there are several possible reasons for the difference between model outputs and stakeholder statements first the irrigation needs were presented as a 30 year average including many years that do not require irrigation second stakeholders mentioned that the actual irrigation amounts are greater than real needs nonetheless they highlighted the need for efforts to reduce the gap between grapevine water requirement and inputs in future climate scenarios irrigation requirements increase by 62 85 at the horizon 2050 and are predicted to more than double by the end of the century in the rcp 8 5 the largest increases in water requirements occur during spring although historical spring irrigation is almost nil these predicted requirements however remain lower than the current practices estimated by local stakeholders total grapevine production at watershed scale is expected to decrease from 5 to 11 by mid century table 5 the decrease in production is relatively similar in rcp 4 5 for both time horizons 5 to 7 whereas the predicted decrease reaches 14 in rcp 8 5 for 2100 the type of production that undergoes the most important decrease is the pgi irrigated production despite the increase in irrigation water supply an explanation could be the irrigation thresholds that might be too low to maintain high yield under future climatic conditions we expect that yield losses could be limited by higher irrigation levels in any case irrigated production represents a small part of the rieutort grapevine production 20 in volume and maintaining the production in those irrigated areas would not counteract the global drop of production at watershed scale stakeholders argued for a better sharing of water resources and defended the idea to consider other irrigation practices for high quality production in order to reach the objective of limiting irrigation while securing production 3 3 3 grapevine yield during the historical period 1981 2010 lower yields 5 t ha are found in the northern area with pdo production on superficial soil while the highest productivity sectors 14 t ha are located in the southern and irrigated areas fig 8 these patterns showed a general agreement with stakeholders perceptions projections show contrasted yield evolution according to the two rcps in rcp 4 5 modeled yields slightly increase in the northern sectors this could be explained by two factors the more pronounced advance in phenology that avoids drought periods after flowering period critical period for bud fertility and berry number determination and the higher summer rainfall amounts predicted in rcp 4 5 table 2 that refill soil water reserve more efficiently in superficial soils in the other sectors yields decrease by 10 in 2050 and 20 in 2100 in rcp 8 5 the yields in all sectors were predicted to decrease by 10 20 in 2050 and as much as 30 for the southern sectors in 2100 the important yield decrease in the southern irrigated area could be explained by the particularly low annual rainfall amounts predicted with the rcp 8 5 scenario 530 mm it is worth noting that the model could overestimate the yield decrease in the southernmost sector because it does not consider the presence of a groundwater table that could mitigate the vineyard water stress in reaction to these results participants first highlighted the importance of changes in management practices particularly in the southern areas as compared to northern areas for example they suggested that better vigor management could limit the water loss by transpiration stakeholders from the northern area interpreted the predicted low decrease in their yield as good news but pointed out that they must maintain a high economic return for their wine finally the participants suggested broadening the range of evaluation indicators with further details on berry sugar accumulation in relationship with the leaf fruit ratio and economical aspects at farm scale 4 discussion 4 1 model based evaluation of climate change impacts the sources of error in model predictions decrease when the number of simulated processes increases i e the complexity of the model by contrast the uncertainties on the parameter values increase in parallel with model complexity passioura 1996 in our study the crop model i e the coupling of phenological walis and gray models relies on fewer processes in an effort to find the best compromise between the number of processes and the number of parameters needed to estimate grape yield based on the results of guilpart et al 2014 we hypothesize that grape yield is limited by the number of sinks clusters and berries per plant rather than by net assimilation consequently our model does not include any effect of increasing co2 concentration in the atmosphere omitting the positive effect it might have on photosynthesis but this point needs to be further documented for perennial crops toreti et al 2020 it should be noticed that until now co2 enrichment of grapevines has been carried out with no limitation in water and nitrogen supplies and only over the course of 2 3 years bindi et al 2001 moutinho pereira et al 2009 wohlfahrt et al 2019 however studies looking at other perennial systems forests grassland and longer time periods showed that when soil resources are limited the effect of elevated co2 on productivity may be less certain reich and hobbie 2013 similarly our model did not include variety specific responses of yield to water deficit it is likely that such variability exists among the current grapevine varieties duchene 2016 but it is difficult to infer stable parameter values from the available data bases levin et al 2020b despite these two simplifications the walis gray model was able to simulate grapevine yield with quality indicators similar to those in existing grapevine models found in the literature such as unifi grapeml leolini et al 2018 and stics fraga et al 2015 moreover our study emphasized on farm situations which is not the case in the majority of grapevine models knowling et al 2021 other model limitations are related to the availability and quality of the input data stakeholders highlighted two main limitations in the data used first although we distinguished three climatic areas thanks to the medium resolution climate projection data 8 8 km² we did not take into account microclimatic effects which are determinant factors of vulnerability and adaptation in small region studies le roux et al 2017 quénol et al 2017 tissot et al 2017 second the estimation of soil water availability was based on isolated estimations even if experimental fields were chosen with stakeholders to represent soil conditions in the watershed it is difficult to capture small scale variations these estimations of spatial variations could be improved by using high spatial resolution satellite and crowdsourcing data pichon et al 2021 which are promising tools to improve the quality of the spatial representation of the soil parameters future development of the model could focus on three aspects first the structure of the model could be improved by including the effects of other climatic variables during different time periods such as the effects of air temperature and rainfall during flowering zhu et al 2020 second the validity of the model should be tested on other independent databases in the recent literature we have identified relevant databases that consider both grapevine water status and yield components during several years levin et al 2020a zhu et al 2020 this step should include a characterization of model uncertainties arising from model structure parameters and input data in order to address the confidence in our results in different contexts third the model was developed initially for research purposes its current form lacks elements e g an interface and simulation duration that would allow an independent transfer to stakeholders the model could also be made more accessible during workshops with stakeholders for example by facilitating the direct display of model results the present study quantitatively evaluates the impacts of climate change on grapevine phenology irrigation needs and grapevine yield regarding the phenology our simulation shows clear advancement in the timing of each event which is consistent with fraga et al 2016 in their study conducted at european scale the more pronounced advancement at higher elevation corroborates the results of caffarra and eccel 2011 this may be related to a higher phenological sensitivity of mountain sites to climate change previous studies that simulated grapevine yields under future climatic conditions offer contradictory findings in part because the model and data choices depend on the spatial scale for example our findings do not support previous research at the european scale that projected a yield increase in south of france for rcp 8 5 stics model in fraga et al 2016 but we see similarities with a medium scale study led in the tuscany region 61 000 ha vineyard in italy that predicted yields decreasing from 15 to 30 by the end of the century moriondo et al 2011 the comparison of those two studies shows how spatial scale and model choice linked to different climate and soil data sets is crucial nevertheless those studies involved invariant plant material and cultivation practices variety planting density training system our study goes further by simulating different cropping systems according to their localization moreover our findings suggest that the current diversity of practices is a way to limit grapevine vulnerability to climate change the simulated irrigation water requirements are low compared to those reviewed by naulleau et al 2021 one reason for this could be that the irrigated areas are located in deep soils with a ttsw higher than 225 mm in mediterranean areas grapevines are often cultivated in soils more prone to water stress e g ttsw close to 100 mm in gaudin and gary 2012 the main finding of this work is in agreement with fraga et al 2018 it suggests that the increased irrigation supply would not be sufficient to alleviate yield losses in irrigated areas 4 2 benefits and limitations of the participatory approach while model based evaluation of climate change impacts should be carried out with caution due to various sources of uncertainty corbeels et al 2018 they can be beneficial in a participatory approach to hybridize local and scientific knowledge and stimulate discussions in this study the early and frequent involvement of stakeholders was beneficial at multiple points in the modeling process first stakeholders actively helped at defining the representation of the baseline situation in the model information provided by generic datasets commonly used by modelers e g soil cultivation practices appeared too rough to represent the spatial variability in the studied landscape as in murgue et al 2016 we found a compromise between case study spatial extent and level of details in the representation of cropping systems although we reached a simpler representation than theirs nonetheless the participatory mapping exercise significantly enhanced the representation of a common reference situation for grapevine landscape at pertinent scales and accomplished this relatively quickly second as in murgue et al 2016 our participatory framework gave various occasions to explain and to update intermediary objects conceptual scheme baseline description field scale outputs evaluation indicators that evolved as the workshops progressed consequently as in leenhardt et al 2012 the information and concepts shared between stakeholders and modelers were progressively assimilated and improved these frequent interactions with stakeholders together with the reciprocal sharing of data could explain the higher level of trust in the model and the stable participation rate this study impacted the stakeholders through their interactions with the researchers they expressed the benefits they received from the study during a group discussion and in an individual questionnaire at the end of the study they initially identified the limits of current models in representing their systems and the impacts of climate change but they appreciated the quantitative information they obtained from the researchers especially in terms of climate evolution the spatial representation helped clarify the diversity of their systems and constraints and they particularly benefited from the extensive time dedicated to discussions and the sharing of experiences however several limitations to the participatory approach should be acknowledged first the workshop participants were primarily drawn from the viticulture sector and were thus focused on grape production objectives the agro environmental facilitators were also close to this sector and the regional policymaker acted primarily as an observer thus we did not consider other important environmental and economic issues e g other crop productions water for human consumption employment we tried to enroll local and regional policy makers with transversal skills through interviews but they decided to not participate in the workshops although they remained interested in the study results indeed the defined research problem was specific to the viticulture sector and thus drew a specific audience second modelers had difficulty taking account of certain processes that stakeholders highlighted as important we can cite among others the effects of hedges and trees that can create a favorable microclimate for grapevines grimaldi 2018 and processes linked to the evolution of pest pressure under a changing climate bois et al 2017 those two examples are difficult to include in a dynamic model because the underlying processes are complex and not well known processes to be considered are multi factorial climate cultural practices initial pest pressure type of hedges etc they require fine scale data topography vegetation layers humidity rate etc and there are interactions between scales from plant organs grapevine canopy field to landscape nonetheless it is possible to include expert knowledge about these processes into other types of models voinov et al 2018 sacchelli et al 2017 structured expert knowledge around climate change adaptation in tuscany by using cognitive maps semi quantitative model that allowed to detail all important concepts and the action retroaction loops between them other model formalisms such as the agent based models seen in delay et al 2015 are also based on expert knowledge to simulate dynamics at different spatial and temporal scales however such models are specific to the participants and the local conditions their uses and their results would probably be difficult to extrapolate to other areas in our case the watershed model remains generic and could be used to simulate other vineyards in the world providing that necessary input data exist and that grape yield is mainly limited by water our findings should certainly be able to be extrapolated to typical mediterranean vineyards where coastal plains meet inland hills 5 conclusion combining modeling and participatory approaches remains challenging especially in complex and uncertain contexts such as climate change issues the present study was designed to implement a modeling approach that combines scientific and local knowledge to quantitatively evaluate the impacts of climate change in a mediterranean vineyard watershed we illustrate how the interactions between stakeholders and modelers led to an original watershed model whose inputs were spatially defined by local stakeholders the integrated evaluation of climate change impacts reveals the heterogeneity of those impacts on the watershed in terms of local conditions soil and climate and grapevine production systems the entire territory would be impacted by high temperatures increasing risks to production in both quantity and quality but premium wine production areas pdo would be less impacted than high production areas pgi the stakeholders found the generated information on climate change impacts to be relevant and in the next step they will be involved in the design of local adaptation strategies declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was supported by the laccave 2 21 project funded by the meta program adaptation of agriculture and forests to climate change aafcc of the french national research institute for agriculture food and environment inrae this work is part of a phd project funded by the occitanie regional council and the inrae agroecosystem division authors would like to thank all study participants as well as technical staff for their help in field data collection we thank iñaki garcia de cortazar ue agroclim for providing phenological model and parameters ue agroclim and météo france for providing the climate data and frederic huard ue agroclim for his advices on bias correction of climate projections data we thank guillaume coulouma and philippe lagacherie umr lisah for rieutort soil description thierry lacombe umr agap and thierry simonneau umr lepse for their insights on grapevine physiology authors would like to thank ben boswell for english reviewing appendix a supplementary data the following is the supplementary data to this article appendixa naulleau etal ems2021 r3 resubmitted docx appendixa naulleau etal ems2021 r3 resubmitted docx appendixb naulleau etal ems2021 r3 resubmitted docx appendixb naulleau etal ems2021 r3 resubmitted docx appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105342 
25619,the accurate prediction of storm driven coastal erosion along sandy coastlines is fundamental to addressing coastal hazards now and into the future here four storm erosion models an empirical model the numerical models sbeach and xbeach and a machine learning model were individually trained and tested on a 39 year storm erosion dataset to examine skill and error distributions four weighted average model ensemble approaches were also tested the machine learning method showed the overall best skill for an individual model followed by sbeach the empirical model and xbeach a weighted ensemble combined the models in such a way as to improve prediction over any single model for the largest events while maintaining comparable skill to the machine learning model during smaller events as well these results indicate that a weighted multi model ensemble approach can provide overall improved accuracy and reliability over a wide range of storm conditions compared to individual models keywords neural network sbeach xbeach dune erosion shoreline retreat 1 introduction the accurate prediction of storm driven coastal erosion remains a research focus along populated and high value sandy coastlines worldwide ciavola et al 2011 ferreira et al 2017 harley et al 2017 toimil et al 2020 a number of different approaches are used to predict storm driven coastal erosion including behavioural relationships e g leaman et al 2021 sallenger 2000 stockdon et al 2007 empirically derived relationships larson et al 2004 overton and fisher 1988 palmsten and holman 2012 splinter and palmsten 2012 physics based numerical models kobayashi 2016 larson and kraus 1989 roelvink et al 2009 and data driven models beuzen et al 2019b plant and stockdon 2012 sanuy and jiménez 2021 van verseveld et al 2015 each of these types of approaches has advantages and disadvantages and the user must often assess data availability computational needs and desired outputs in determining the most appropriate model to use empirical models have a basic physical representation of complex processes and learn parameterisations by fitting to data empirical approaches have been widely used to model dune erosion kriebel and dean 1993 larson et al 2004 overton and fisher 1988 palmsten and holman 2012 and may offer comparable performance to numerical approaches splinter and palmsten 2012 they are typically far more efficient computationally and have far fewer free parameters than widely used numerical models such as xbeach roelvink et al 2009 a drawback is that many empirical models only model a certain physical feature such as the dune above and landward of the dune toe or shoreline davidson et al 2013 harley et al 2009 miller and dean 2004 yates et al 2009 and do not account for sediment dynamics on the beach face splinter et al 2018b numerical models which typically involve complicated expressions of hydrodynamic and sediment transport physics have tended to be the most commonly used modelling approaches for site specific application barnard et al 2014 callaghan et al 2013 harley et al 2016 karunarathna et al 2014 mccall et al 2010 splinter et al 2014a while these models strive to provide robust predictions with minimal site specific calibration across a range of different beach types and storm conditions roelvink and reniers 2011 this one size fits all approach can lead to less than optimal performance reeve et al 2016 and often requires extensive calibration where conditions differ significantly from those where the model was formulated elsayed and oumeraci 2017 leadon 2015 matheen et al 2021 simmons et al 2017 2019 however once calibrated to a specific site the expectation is that they remain skilful over a wide range of storm conditions callaghan et al 2013 in contrast to empirical and numerical models data driven approaches such as machine learning ml form no assumptions of the underlying physics or structure and attempt to learn representations implicitly from the data lecun et al 2015 with increasing data availability via remote sensing splinter et al 2018a ml approaches have been growing in popularity in the field of coastal engineering buscombe et al 2020 buscombe and carini 2019 ellenson et al 2020 hashemi et al 2010 iglesias et al 2009 kömürcü et al 2013 lopez et al 2017 pape et al 2007 pape and ruessink 2011 zeinali et al 2021 in particular bayesian networks bns have seen widespread use in the estimation of coastal erosion response beuzen et al 2018 2019b plant and stockdon 2012 sanuy and jiménez 2021 van verseveld et al 2015 wilson et al 2015 with sufficient training data these data driven approaches show good skill in replicating the general observed beach behaviour there are however several drawbacks associated with these models data driven models tend to suffer a performance drop when predicting out of sample e g beuzen et al 2018 this is particularly problematic given there is a general lack of data for coastal storm events from which to train on the extent to which this performance is degraded and the significance of this in the context of comparable problems with numerical modelling approaches is an active research area goldstein et al 2019 in addition like empirical models data driven models often require that continuous geophysical variables be defined in terms of a set of simplified discrete input features this presents a challenge as the variables driving storm erosion are complex time varying and interact with one another e g coco and murray 2007 one approach to leverage the strengths and minimise the weaknesses of different modelling approaches is model ensemble averaging ajami et al 2006 demeritt et al 2007 duan et al 2007 hemer et al 2013 tebaldi and knutti 2007 weigel et al 2008 averaging can be undertaken with varying complexity and commonly uses a simple best fit weight for each of the models arsenault et al 2015 diks and vrugt 2010 shamseldin et al 1997 other approaches such as bayesian model averaging duan et al 2007 raftery et al 2005a can also be used to incorporate uncertainty into these combinations these approaches use a constant weight for each individual model and assume a constant error for each of the models more complex approaches such as hierarchical mixtures of experts hme combine model results with weightings determined dynamically based on variables which describe the event being modelled jeremiah et al 2013 marshall et al 2006 while ensemble methods tend to outperform individual predictions examples are limited in the coastal erosion modelling literature limber et al 2018 applied a multi model ensemble to forecasting sea cliff retreat due to sea level rise using five simple 1 d models recent work by beuzen et al 2019a used a gaussian processes machine learning model to quantify the uncertainty in the prediction of wave runup across a number of data driven parameterisations more recently montaño et al 2020 applied an equal weighted multi model ensemble approach to shoreline modelling on an unseen test data set showing the ensemble significantly outperformed any individual model overall more studies are required to assess the benefits of multi model approaches in coastal engineering applications this study aims to assess the performance of model ensemble averaging when applied to a broad range of different modelling approaches for predicting storm induced erosion volume and change in beach width the performance of each of the individual models and the model ensemble average are evaluated using a 39 year beach transect dataset that encompasses a large number of moderate to large storm events this paper is arranged as follows section 2 provides a site description and a brief introduction of each of the models section 3 summarizes the results of each of the individual models as well as the best performing ensemble approach section 4 is a brief discussion into the effects of model data training and different model averaging approaches section 5 summarizes the results and conclusions are drawn 2 methodology 2 1 site description the dataset used in this study was collected at narrabeen collaroy beach hereafter narrabeen australia shown in fig 1 narrabeen is an embayed beach with large rocky headlands at the north and south ends and adjacent rock reefs that extend offshore these headlands effectively create a closed sediment cell in which morphodynamics are dominated by cross shore sediment transport processes and to a lesser degree beach rotation bracs et al 2015 harley et al 2011a the northern end of the beach is characterised by vegetated foredunes up to 9m above mean sea level msl in height at the southern end the dunes are around 3 4m above msl turner et al 2016 the beach predominantly faces east with the southern headland providing some sheltering to the southern portion of the beach during the dominant south easterly swell conditions along this coastline moderate wave energy conditions average deepwater significant wave height of 1 6m and wave period of 10s prevail in a wave dominated microtidal environment short 2006 tides in this region are semi diurnal with a mean spring tidal range of 1 3m the storm surge is relatively insignificant along this coastline with a peak water level tides and storm surge of 1 5m above msl for a one in one hundred year return period event deepwater wave energy is predominantly south to southeast swell generated by mid latitude cyclones crossing the tasman sea an average of 200 days per year short 2007 east coast lows ecls speer et al 2009 are the most damaging events that occur in the region and bring swells from the east and southeast which can reach deepwater significant wave heights of hs 8m four to five of these events occur each year typically in the winter months short and trenaman 1992 2 2 historical data and storm definition this study uses available wave and profile data from 1979 to 2018 the dataset consists of subaerial cross shore profile surveys taken at nominally monthly with up to weekly temporal resolution in more recent years intervals at five transects along narrabeen beach as shown in fig 1 turner et al 2016 elevation data were collected from the dune crest to msl allowing accurate quantification of the change in shoreline d s h l and subaerial volume d v o l between surveys the shoreline at this beach is represented by the 0 7m australian height datum ahd contour which approximates the mean high water springs harley et al 2011b while the subaerial volume is defined as the volume above msl at this location the rate of shoreline recovery post storm has previously been estimated to average around 0 1 m day phillips et al 2017 a centre for australian weather and climate research cawcr wave hindcast dataset was used to obtain directional wave data at the sydney waverider buoy in a depth of 70m shown in fig 1 the cawcr wave hindcast has been validated at a regional and global scale durrant et al 2014 smith et al 2020 and at a local scale turner et al 2016 using measured data from the sydney waverider buoy 1992 2014 offshore data from the buoy location were transformed to the 15m isobath and breaking wave heights using a lookup table formulated from a swan model turner et al 2016 in sydney storm conditions are typically categorised using the peak over threshold method where the offshore significant wave height exceeds the 95 threshold or about 3m lord and kulmar 2000 in this study individual storm events along the nsw coast were defined using the criteria described in shand et al 2011 a storm is defined when either the significant wave height exceeded the 95 threshold hs 3m for at least 6 h or when the 75 threshold hs 2m was exceeded for 72 h this dual definition accounts for both longer duration and less intense storms as well as more extreme events both of which can cause erosion a meteorological independence criterion was applied whereby if two storms occurred within 24 h of one another these were treated as the same event for the purposes of this study multiple storm events occurring between surveys were also combined into one continuous timeseries in the period between 1979 and 2018 343 survey periods i e with pre and post storm morphology were identified between which one or more storms events as defined above had occurred given the monthly sampling of the data in line with previous works matheen et al 2021 each survey pair was checked to ensure erosion occurred i e dshl 0 dvol 0 this was done as this section of coast receives a storm every two weeks on average and rapid accretion post storm during minor events has been observed and would provide false or overly noisy data to test and train the erosion models on phillips et al 2017 2019 the available data therefore ranged between 140 and 169 storm events at each of the five profiles and included both minor and major erosion events 2 3 model description in this study four modelling approaches that could quantify erosion volumes an empirical model two numerical models sbeach and xbeach and a machine learning model were trialled on a 39 year dataset detailed above the performance of these individual models was compared to a model ensemble approach 2 3 1 empirical model harley et al 2009 developed an empirical model hereafter h09 to model shoreline retreat at narrabeen during storm events the model was empirically derived based on argus shoreline data capturing shoreline change for 89 individual storm events in a four year period between 2004 and 2008 harley et al 2009 observed a relationship between the cumulative offshore wave energy e and the shoreline change d s h l of the form 1 d s h l a e b where a and b are empirically derived parameters these parameters vary based on the exposure exposed partially exposed or sheltered of the profile of interest for narrabeen shoreline change is transformed to a volume change d v o l using the relationship 2 d v o l α δ d s h l β where α and β are empirically derived for each of the exposures the parameters used are shown in table 1 for the profiles of interest 2 3 2 numerical models the sbeach and xbeach models were run for each storm event using profiles constructed from the surveyed subaerial profile immediately preceding the storm event and the average measured subaqueous bathymetry at each profile the subaqueous bathymetry was averaged for each profile using ten surveys spanning the period from 2011 to 2016 as described by matheen et al 2019 the profiles extended to a depth of 15m offshore where the nearshore transformed waves were also available the water level at the offshore boundary was set using astronomical tide data with any storm setup disregarded due to its small magnitude on this coastline for further details of model setup for both xbeach and sbeach at narrabeen see simmons et al 2019 2 3 2 1 sbeach sbeach larson and kraus 1989 is a semi empirical coastal erosion model that centres around the concept of an equilibrium profile for any given wave condition sediment transport within the model is proportional to the disequilibrium of the instantaneous wave energy dissipation the sediment transport is calculated in four distinct zones pre breaking breaker transition broken wave and swash each with different empirically derived sediment transport rate relationships sbeach was run using the previously determined calibration coefficients at narrabeen beach over 5 storm events in 2007 2011 2014 and 2015 simmons et al 2019 these events cover a range of large and small observed erosion volumes a full description of the sbeach model and details of model validation are provided in larson and kraus 1989 2 3 2 2 xbeach xbeach roelvink et al 2009 is a process based model that solves coupled equations for hydrodynamics sediment transport and bed morphology xbeach resolves long wave motions or infragravity waves which in many environments dominate storm energy and drive wave dune collisions raubenheimer and guza 1996 roelvink et al 2009 sediment transport in the surf and swash zone is calculated using van thiel van rijn formulations that determine the magnitude based on the difference between depth averaged and equilibrium sediment concentration van rijn et al 2007 van thiel de vries 2009 an avalanching routine is used to simulate sand slumping during the dune collision regime a full model description is available in roelvink et al 2009 in this study xbeach x in profile mode was used this version significantly improves the estimation of post storm beach slope on steep beaches using a simple empirical correction factor applied to the calculated sediment transport roelvink et al 2019 calibrated values for this model at narrabeen beach were obtained based on the work of matheen et al 2019 that considered three recent storm events in 2014 2015 and 2016 these storms range from some of the most erosive over the last 39 years to relatively minor erosion events the model was run with facas 0 13 facsk 0 106 gamma 0 41 and bermslopefac 19 81 at all profiles 2 3 3 machine learning model a neural network multilayer perceptron regression model was used as the data driven model for predicting storm erosion in this study the python package keras chollet 2015 with the tensorflow backend abadi et al 2016 was used to train a neural network nn with two hidden layers consisting of 200 and 40 neurons respectively the relu rectified linear unit activation function was used for all hidden neurons and a dropout rate of 0 4 was applied to assist in the prevention of overfitting the model was trained using a mean square error loss and an adam optimiser the model was trained separately at each profile for up to 200 epochs with an early stopping policy implemented when the loss on the training data stopped improving meaningfully the full storm data set was available in the model training using a cross validation approach described in section 2 4 the model architecture was chosen through a hyperparameter search with the best performing configuration chosen while the nn architecture and training could be further refined for further improvement e g to improve model predictions for more extreme events it is sufficient given the focus of this study is on model averaging the input variables for the model were chosen using an exhaustive search over the training dataset beuzen and simmons 2019 input variables trialled in the model included mean and maximum significant wave height wave period and wave direction both inshore 15m depth and offshore 70m depth cumulative wave power offshore and at wave breaking 2 exceedance wave runup calculated according to stockdon et al 2006 mean maximum and number of impact hours above an assumed dune toe mean and maximum astronomical water level storm duration pre storm beach width volume and beachface slope all combinations of between 2 and 8 input variables were made available to the nn and the best performing combinations and most informative variables were found after this rigorous testing four input variables were chosen for the data driven model to provide a compromise between maximum performance on unseen data and undesirable model complexity beuzen et al 2018 in order of importance these were the pre storm beach width the cumulative wave power at breaking the maximum offshore significant wave height and the mean 2 exceedance wave runup other ml architectures were trialled including much simpler linear models and different configurations of nn however it is outside the scope of this paper to present an exhaustive comparison of ml methods 2 4 model averaging ensemble model averaging is widely used in climate forecasting i e gcms and an increasing use in coastal evolution modelling where the ensemble mean has been shown to outperform individual model performance montaño et al 2020 averaging the 4 model outputs described above provides the potential to improve performance above any one individual model the output of the model average for predicting the change in beach width dshl avg is found by summing the individual model predictions multiplied by their weights 3 dshl avg w 1 d s h l e m p i r i c a l w 2 d s h l m l w 3 d s h l s b w 4 d s h l x b where w 1 w 2 w 3 and w 4 are the weights for the outputs of the empirical d s h l e m p i r i c a l ml d s h l m l sbeach d s h l s b and xbeach d s h l x b models respectively a bias term can be included in the fit in addition to the weighted model outputs a separate fit following the same approach is found to estimate the weighted ensemble change in subaerial volume d v o l a v g a wide range of approaches are available from simple naïve averaging that weights each model equally to more complex approaches that consider model bias and use optimized least squares the best ensemble weighting method remains largely dependent on the dataset and models being used diks and vrugt 2010 in this study the performance of the bates and granger 1969 ensemble method is compared to the performance of each of the individual models additional weighting methods are discussed and compared for this data in section 4 2 using the bates and granger 1969 method the weights are calculated as proportionate to the model s prediction variance σ 2 whereby the weight for each individual model w i is given by 4 w i 1 σ i 2 j 1 k 1 σ j 2 the prediction variance is estimated using the variance of the model prediction error e g the variance of d s h l x b d s h l over the training data points for the xbeach model over the data available to train the model averaging weights diks and vrugt 2010 the inverse prediction variance for each individual model is normalized using the sum over all k models so that the model weights w sum to 1 to determine the ensemble model weights the data at each profile were split into a training and testing group with 1 3 of the data ranging between 46 and 57 data points depending on the profile reserved for testing a subset of these test data has been presented in figures below representing the top 10 most erosive events in each test group between 4 and 6 storm events at the five profiles within the training set the data were split into two equal size groups one half was used to train the ml model described in section 2 3 2 2 the second half was then used to find the model averaging weights on data unseen by the ml model the test set was used as unseen out of sample data on which to objectively compare the performance of the averaged and individual four models a cross validation type approach was used whereby these three splits of the dataset were varied with 100 random iterations of the test train data groups to compare model performance evenly across the dataset the analysis was carried out individually at each profile and figures presented below summarise the results across all five profiles 3 results 3 1 individual model performance the four modelling approaches an empirical model two numerical models sbeach and xbeach a machine learning model were compared to assess their predictive capabilities for the 39 year narrabeen storm dataset considering the results across the entire test data set as detailed in fig 2 a the ml model provides the most accurate erosion predictions as well as the most consistent performance as measured by the inter quartile range and boxplot range skill is also measured as a function of normalized mean square error nmse e g miller and dean 2004 splinter et al 2014b 5 n m s e o b s m o d e l 2 o b s 2 where obs represent the observations of change in shoreline dshl or change in volume dvol and model the individual model predictions of the respective variables sbeach nmse is roughly twice that of the ml model the empirical model and xbeach model were considerably less skilful over the test data set when compared to the sbeach or the ml model when considering model performance over only the top 10 of storms from the test data set in each of the iterations as shown in fig 2b the results show that the skill as measured by nmse does not significantly change when comparing between extreme events and all of the storm data for the ml and sbeach models however significant changes in skill are seen in the empirical model and xbeach model this change in skill and model sensitivity to calibration data is further discussed in section 4 1 fig 3 shows this more clearly by plotting the distribution of model errors the empirical model and xbeach model tend towards overprediction positive error as well as a much broader distribution of errors over the entire data set fig 3a and the extreme events fig 3b by contrast the distribution of errors for sbeach and the ml model are much narrower and roughly centred around zero when considering all data fig 3a but underpredict with broader distribution in errors for the more extreme events fig 3b distributions in the errors between shoreline change fig 3 left and volume change fig 3 right change slightly between examining all the data or just the extreme events but the overall trends are the same 3 2 ensemble model performance the results of the individual models highlighted which models did well under more extreme conditions compared to a general fit to the data as well as the distribution of these errors while the authors acknowledge that a variety of combinations of the four candidate models could be considered in a wide range of ensembles here all four models are included to represent the four broad types of coastal erosion models considered in this study and the wide range of skill each model had over a wide range of storm conditions fig 3 the error distribution of individual models can then be used to develop an ensemble average estimate of shoreline change and volume change fig 4 shows the performance of a weighted model average in comparison to the performance of the individual models while the ensemble model performs slightly worse than the ml model over the entire dataset fig 4a it performs much better than the empirical model and numerical models despite all these models influencing the ensemble result importantly for the 10 highest impact events fig 4b the ensemble outperforms any individual model using a weighted model average ensemble approach it combines the four models in such a way as to improve prediction for the largest events while maintaining comparable skill to the ml model during smaller events as well this balance is particularly important in a forecasting sense whereby ahead of an impending storm the ensemble model should limit false positive predictions of large erosion impact yet still provide the most accurate predictions possible for the events of most interest the largest events the range of the boxplot in fig 4 also indicates that the ensemble approach provides an increased certainty in predicting the largest events in comparison to the other models to further understand the influence of each of the models in the ensemble fig 5 shows the ensemble model weights found using the bates and granger 1969 approach this approach weights the sbeach and ml models almost twice as much as the empirical model or xbeach model due to their low error variance as shown in fig 3 thereby allowing them to influence the ensemble output more than the less certain empirical model or xbeach model outputs the overall balance of the four models then accounts for the slight under estimation of some models in contrast to the over estimation by other models under certain conditions section 4 2 further discusses the performance of several other model combination approaches trialled and the trade offs observed when choosing between single weight model combination approaches 4 discussion 4 1 sensitivity to model training data sets to further understand the sensitivity of the individual model performance to the training data fig 6 shows the distributions of the observed change in shoreline and volume for the 39 year data set at narrabeen the observations are dominated by smaller erosion events interspersed with less frequent but much more severe erosion events ninety percent of the storm events result in 0 44 m3 m of erosion and in between 0 and 17 m of shoreline erosion the top 10 of events result in between 44 and 150 m3 m of erosion and 17 54 m of erosion this skewed distribution of observations has implications to individual model skill depending on the data used for model training due to the time constraints and lack of data numerical models such as xbeach and sbeach are often trained on only one or a few storm events harley et al 2016 mccall et al 2010 simmons et al 2019 splinter and palmsten 2012 this likely biases the calibration to those often more extreme events observed at a site however a few studies have also shown that increasing the number of storm events beyond three for model calibration doesn t necessarily increase model skill matheen et al 2021 simmons et al 2019 as detailed in simmons et al 2019 xbeach is far more sensitive to individual storms than sbeach with respect to calibration by contrast the empirical model and ml model used here were given a larger range of storm data to train on as shown in fig 2 this influences the skill of each of the individual models over the entire data and on the more extreme events the ml predictions most closely match the overall distribution of observed erosion events fig 6a however they tend to significantly underestimate the probability of larger events fig 6b conversely the xbeach model and empirical model overestimate the frequency of larger impact events however with a much wider spread in the overall distributions considering all four models the predictions of the individual models were mostly distributed about the true value with some tending to overpredict and others to underpredict for most storm events the measured erosion value lay within the range of predictions from the individual models 86 for dshl and 88 for dvol of the remaining events for which the model predictions did not encompass the observed erosion a vast majority 92 for dshl and 84 for dvol of these were among the smallest 50 of events in terms of measured erosion 4 2 comparison of model averaging techniques the ensemble model results presented in section 3 2 used the methods described in bates and granger 1969 and allowed all four model outputs to be considered as part of the ensemble based on individual model skill three additional methods were also compared in this study table 2 and are discussed here this includes a mixture of methods that either constrain the model weights to sum to unity or allow these to vary freely in order not to assume the models of the ensemble to be unbiased shamseldin et al 1997 fig 7 shows the distribution of results of the 4 common approaches described in table 2 for determining the individual model weights due to the range and distribution in model errors shown in fig 3 fitting the ensemble with a fixed weight for each model results in a trade off giving a higher weight to the ml and sbeach models maximises the performance over the entire dataset e g fig 7 ols while giving a higher weight to the xbeach model and empirical model maximises performance for the most extreme events e g fig 7 equal weighting overall the optimized least squares ols fit provides the best performance over the entire range of data and better than any individual model however a number of other methods tested show better performance on the largest events which are often the most interest to a coastal practitioner for this reason the bates and granger 1969 method was chosen as the model averaging approach that best balances the accurate prediction of extreme erosion events and avoids false positive predictions for more moderate events the approaches with positive weights constrained to sum to unity performed better for the storm events than the granger and ramanathan 1984 approach of letting the weights vary freely with an additional bias term allowing the weights to vary more freely worsened performance suggesting overfitting of the small training dataset for model averaging the high performance of the bates and granger method in particular and the data shown in fig 3 suggest that the model errors are uncorrelated and as an ensemble have minimal bias as such simpler bates and granger or equal weighting methods provide significant improvements over the performance of individual models especially when predicting more extreme events 4 3 adaptive model averaging in addition to simple model averaging techniques more advanced approaches exist for learned model combination in particular a number of adaptive approaches have been developed predominately in the hydrological modelling space whereby either the selection or weighting of model results can adapt given the properties of an individual data point duan et al 2007 jeremiah et al 2013 marshall et al 2006 raftery et al 2005b this can allow time varying or event specific combinations of the model outputs to acknowledge the non stationary errors associated with each model i e fig 3 based on the results presented in section 3 1 it would be ideal to condition the weights to favour the empirical model and xbeach model for larger events and ml model and sbeach model during less erosive conditions fig 8 shows the non stationary weightings for each of the four models when a neural network was trained to predict weights summing to unity based on the observed subaerial erosion and shoreline change when these adaptive weights are used the ensemble model dshl prediction nmse was reduced to approximately 0 17 and 0 08 for the entire test set and the top 10 respectively providing a significant increase in skill and certainty compared to all other model weighting schemes tested 0 35 and 0 11 respectively these storm erosion dependent weights indicate that model errors vary to some degree with storm magnitude the challenge of applying this scheme is observed volume change is not available a priori and as such it only provides an estimate of how the model weightings should vary with storm magnitude in an idealised sense in fig 8 we can see that the sbeach model green line is weighted highly for predicting minor events and the ml model orange line for moderate events the contribution of the xbeach model red and to a lesser degree empirical model blue grows steadily with the magnitude of the event with the most extreme events weighted significantly towards the xbeach model within a forecasting sense this adaptive weighting could be incorporated by either learning adaptive weights conditioned on the model outputs for a given storm e g shamseldin et al 1997 or based on some storm properties such as those used to train the ml model e g marshall et al 2006 both these approaches were tested on the available data both measured inputs and model outputs due to the large noise within the limited training data set the resulting weights either showed no clear conditioning or the adaptive weighted average model did not offer an overall improvement over a simple ols fit or bates and granger weights as described in section 4 2 with further research and improved datasets considering both quality and quantity of data such an approach could provide more accurate predictions by fully leveraging the strengths of each model in predicting different types of events 5 conclusion the ability to robustly predict storm erosion along sandy coastlines is an active area of research with advances in the use of data driven and numerical modelling approaches that account for uncertainty and error gaining in popularity a majority of models however are sensitive to calibration and a one size fits all approach may lead to unacceptably large errors when used to predict erosion outside of the range of the training data set here four storm erosion models an empirical model numerical models sbeach and xbeach and a machine learning approach were individually trained and tested on a 39 year storm erosion data set to examine skill and error distributions the results showed that each model was skilful under different conditions the machine learning model showed the overall best skill followed by sbeach the empirical model and then xbeach during the more extreme erosion events xbeach performed well and slightly over predicted erosion whereas the machine learning model tended to under predict the erosion a simple weighted ensemble approach provided the best combined skill across all storms and the more extreme events the ensemble approach incorporated weights learned from the error distribution of each of the individual models it was able to provide a more accurate and reliable prediction of erosion compared to each of the individual models the ensemble provided around the same performance across the whole dataset as the machine learning approach however outperformed all models when considering the top 10 of most erosive events adaptive model averaging also showed potential as an area for future research with different models showing better skill at predicting storms of different magnitudes however the data available in this study were not of sufficient quantity and were potentially too noisy to allow more sophisticated model averaging techniques declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the nsw environmental trust environmental research program rd 2015 0128 and through the unsw faculty of engineering carers award wave and tide data were provided by manly hydraulics laboratory on behalf of the nsw department of planning industry and environment dpie bathymetric data was kindly collected by nsw dpie nearshore wave modelling was undertaken by mitchell harley and edward kearney unsw all narrabeen subaerial profile data and wave data used in this study is available open access at http narrabeen wrl unsw edu au the authors wish to thank the editors and the four reviewers including dr lazarus and dr goldstein for their constructive and thorough reviews which have undoubtedly improved the manuscript 
25619,the accurate prediction of storm driven coastal erosion along sandy coastlines is fundamental to addressing coastal hazards now and into the future here four storm erosion models an empirical model the numerical models sbeach and xbeach and a machine learning model were individually trained and tested on a 39 year storm erosion dataset to examine skill and error distributions four weighted average model ensemble approaches were also tested the machine learning method showed the overall best skill for an individual model followed by sbeach the empirical model and xbeach a weighted ensemble combined the models in such a way as to improve prediction over any single model for the largest events while maintaining comparable skill to the machine learning model during smaller events as well these results indicate that a weighted multi model ensemble approach can provide overall improved accuracy and reliability over a wide range of storm conditions compared to individual models keywords neural network sbeach xbeach dune erosion shoreline retreat 1 introduction the accurate prediction of storm driven coastal erosion remains a research focus along populated and high value sandy coastlines worldwide ciavola et al 2011 ferreira et al 2017 harley et al 2017 toimil et al 2020 a number of different approaches are used to predict storm driven coastal erosion including behavioural relationships e g leaman et al 2021 sallenger 2000 stockdon et al 2007 empirically derived relationships larson et al 2004 overton and fisher 1988 palmsten and holman 2012 splinter and palmsten 2012 physics based numerical models kobayashi 2016 larson and kraus 1989 roelvink et al 2009 and data driven models beuzen et al 2019b plant and stockdon 2012 sanuy and jiménez 2021 van verseveld et al 2015 each of these types of approaches has advantages and disadvantages and the user must often assess data availability computational needs and desired outputs in determining the most appropriate model to use empirical models have a basic physical representation of complex processes and learn parameterisations by fitting to data empirical approaches have been widely used to model dune erosion kriebel and dean 1993 larson et al 2004 overton and fisher 1988 palmsten and holman 2012 and may offer comparable performance to numerical approaches splinter and palmsten 2012 they are typically far more efficient computationally and have far fewer free parameters than widely used numerical models such as xbeach roelvink et al 2009 a drawback is that many empirical models only model a certain physical feature such as the dune above and landward of the dune toe or shoreline davidson et al 2013 harley et al 2009 miller and dean 2004 yates et al 2009 and do not account for sediment dynamics on the beach face splinter et al 2018b numerical models which typically involve complicated expressions of hydrodynamic and sediment transport physics have tended to be the most commonly used modelling approaches for site specific application barnard et al 2014 callaghan et al 2013 harley et al 2016 karunarathna et al 2014 mccall et al 2010 splinter et al 2014a while these models strive to provide robust predictions with minimal site specific calibration across a range of different beach types and storm conditions roelvink and reniers 2011 this one size fits all approach can lead to less than optimal performance reeve et al 2016 and often requires extensive calibration where conditions differ significantly from those where the model was formulated elsayed and oumeraci 2017 leadon 2015 matheen et al 2021 simmons et al 2017 2019 however once calibrated to a specific site the expectation is that they remain skilful over a wide range of storm conditions callaghan et al 2013 in contrast to empirical and numerical models data driven approaches such as machine learning ml form no assumptions of the underlying physics or structure and attempt to learn representations implicitly from the data lecun et al 2015 with increasing data availability via remote sensing splinter et al 2018a ml approaches have been growing in popularity in the field of coastal engineering buscombe et al 2020 buscombe and carini 2019 ellenson et al 2020 hashemi et al 2010 iglesias et al 2009 kömürcü et al 2013 lopez et al 2017 pape et al 2007 pape and ruessink 2011 zeinali et al 2021 in particular bayesian networks bns have seen widespread use in the estimation of coastal erosion response beuzen et al 2018 2019b plant and stockdon 2012 sanuy and jiménez 2021 van verseveld et al 2015 wilson et al 2015 with sufficient training data these data driven approaches show good skill in replicating the general observed beach behaviour there are however several drawbacks associated with these models data driven models tend to suffer a performance drop when predicting out of sample e g beuzen et al 2018 this is particularly problematic given there is a general lack of data for coastal storm events from which to train on the extent to which this performance is degraded and the significance of this in the context of comparable problems with numerical modelling approaches is an active research area goldstein et al 2019 in addition like empirical models data driven models often require that continuous geophysical variables be defined in terms of a set of simplified discrete input features this presents a challenge as the variables driving storm erosion are complex time varying and interact with one another e g coco and murray 2007 one approach to leverage the strengths and minimise the weaknesses of different modelling approaches is model ensemble averaging ajami et al 2006 demeritt et al 2007 duan et al 2007 hemer et al 2013 tebaldi and knutti 2007 weigel et al 2008 averaging can be undertaken with varying complexity and commonly uses a simple best fit weight for each of the models arsenault et al 2015 diks and vrugt 2010 shamseldin et al 1997 other approaches such as bayesian model averaging duan et al 2007 raftery et al 2005a can also be used to incorporate uncertainty into these combinations these approaches use a constant weight for each individual model and assume a constant error for each of the models more complex approaches such as hierarchical mixtures of experts hme combine model results with weightings determined dynamically based on variables which describe the event being modelled jeremiah et al 2013 marshall et al 2006 while ensemble methods tend to outperform individual predictions examples are limited in the coastal erosion modelling literature limber et al 2018 applied a multi model ensemble to forecasting sea cliff retreat due to sea level rise using five simple 1 d models recent work by beuzen et al 2019a used a gaussian processes machine learning model to quantify the uncertainty in the prediction of wave runup across a number of data driven parameterisations more recently montaño et al 2020 applied an equal weighted multi model ensemble approach to shoreline modelling on an unseen test data set showing the ensemble significantly outperformed any individual model overall more studies are required to assess the benefits of multi model approaches in coastal engineering applications this study aims to assess the performance of model ensemble averaging when applied to a broad range of different modelling approaches for predicting storm induced erosion volume and change in beach width the performance of each of the individual models and the model ensemble average are evaluated using a 39 year beach transect dataset that encompasses a large number of moderate to large storm events this paper is arranged as follows section 2 provides a site description and a brief introduction of each of the models section 3 summarizes the results of each of the individual models as well as the best performing ensemble approach section 4 is a brief discussion into the effects of model data training and different model averaging approaches section 5 summarizes the results and conclusions are drawn 2 methodology 2 1 site description the dataset used in this study was collected at narrabeen collaroy beach hereafter narrabeen australia shown in fig 1 narrabeen is an embayed beach with large rocky headlands at the north and south ends and adjacent rock reefs that extend offshore these headlands effectively create a closed sediment cell in which morphodynamics are dominated by cross shore sediment transport processes and to a lesser degree beach rotation bracs et al 2015 harley et al 2011a the northern end of the beach is characterised by vegetated foredunes up to 9m above mean sea level msl in height at the southern end the dunes are around 3 4m above msl turner et al 2016 the beach predominantly faces east with the southern headland providing some sheltering to the southern portion of the beach during the dominant south easterly swell conditions along this coastline moderate wave energy conditions average deepwater significant wave height of 1 6m and wave period of 10s prevail in a wave dominated microtidal environment short 2006 tides in this region are semi diurnal with a mean spring tidal range of 1 3m the storm surge is relatively insignificant along this coastline with a peak water level tides and storm surge of 1 5m above msl for a one in one hundred year return period event deepwater wave energy is predominantly south to southeast swell generated by mid latitude cyclones crossing the tasman sea an average of 200 days per year short 2007 east coast lows ecls speer et al 2009 are the most damaging events that occur in the region and bring swells from the east and southeast which can reach deepwater significant wave heights of hs 8m four to five of these events occur each year typically in the winter months short and trenaman 1992 2 2 historical data and storm definition this study uses available wave and profile data from 1979 to 2018 the dataset consists of subaerial cross shore profile surveys taken at nominally monthly with up to weekly temporal resolution in more recent years intervals at five transects along narrabeen beach as shown in fig 1 turner et al 2016 elevation data were collected from the dune crest to msl allowing accurate quantification of the change in shoreline d s h l and subaerial volume d v o l between surveys the shoreline at this beach is represented by the 0 7m australian height datum ahd contour which approximates the mean high water springs harley et al 2011b while the subaerial volume is defined as the volume above msl at this location the rate of shoreline recovery post storm has previously been estimated to average around 0 1 m day phillips et al 2017 a centre for australian weather and climate research cawcr wave hindcast dataset was used to obtain directional wave data at the sydney waverider buoy in a depth of 70m shown in fig 1 the cawcr wave hindcast has been validated at a regional and global scale durrant et al 2014 smith et al 2020 and at a local scale turner et al 2016 using measured data from the sydney waverider buoy 1992 2014 offshore data from the buoy location were transformed to the 15m isobath and breaking wave heights using a lookup table formulated from a swan model turner et al 2016 in sydney storm conditions are typically categorised using the peak over threshold method where the offshore significant wave height exceeds the 95 threshold or about 3m lord and kulmar 2000 in this study individual storm events along the nsw coast were defined using the criteria described in shand et al 2011 a storm is defined when either the significant wave height exceeded the 95 threshold hs 3m for at least 6 h or when the 75 threshold hs 2m was exceeded for 72 h this dual definition accounts for both longer duration and less intense storms as well as more extreme events both of which can cause erosion a meteorological independence criterion was applied whereby if two storms occurred within 24 h of one another these were treated as the same event for the purposes of this study multiple storm events occurring between surveys were also combined into one continuous timeseries in the period between 1979 and 2018 343 survey periods i e with pre and post storm morphology were identified between which one or more storms events as defined above had occurred given the monthly sampling of the data in line with previous works matheen et al 2021 each survey pair was checked to ensure erosion occurred i e dshl 0 dvol 0 this was done as this section of coast receives a storm every two weeks on average and rapid accretion post storm during minor events has been observed and would provide false or overly noisy data to test and train the erosion models on phillips et al 2017 2019 the available data therefore ranged between 140 and 169 storm events at each of the five profiles and included both minor and major erosion events 2 3 model description in this study four modelling approaches that could quantify erosion volumes an empirical model two numerical models sbeach and xbeach and a machine learning model were trialled on a 39 year dataset detailed above the performance of these individual models was compared to a model ensemble approach 2 3 1 empirical model harley et al 2009 developed an empirical model hereafter h09 to model shoreline retreat at narrabeen during storm events the model was empirically derived based on argus shoreline data capturing shoreline change for 89 individual storm events in a four year period between 2004 and 2008 harley et al 2009 observed a relationship between the cumulative offshore wave energy e and the shoreline change d s h l of the form 1 d s h l a e b where a and b are empirically derived parameters these parameters vary based on the exposure exposed partially exposed or sheltered of the profile of interest for narrabeen shoreline change is transformed to a volume change d v o l using the relationship 2 d v o l α δ d s h l β where α and β are empirically derived for each of the exposures the parameters used are shown in table 1 for the profiles of interest 2 3 2 numerical models the sbeach and xbeach models were run for each storm event using profiles constructed from the surveyed subaerial profile immediately preceding the storm event and the average measured subaqueous bathymetry at each profile the subaqueous bathymetry was averaged for each profile using ten surveys spanning the period from 2011 to 2016 as described by matheen et al 2019 the profiles extended to a depth of 15m offshore where the nearshore transformed waves were also available the water level at the offshore boundary was set using astronomical tide data with any storm setup disregarded due to its small magnitude on this coastline for further details of model setup for both xbeach and sbeach at narrabeen see simmons et al 2019 2 3 2 1 sbeach sbeach larson and kraus 1989 is a semi empirical coastal erosion model that centres around the concept of an equilibrium profile for any given wave condition sediment transport within the model is proportional to the disequilibrium of the instantaneous wave energy dissipation the sediment transport is calculated in four distinct zones pre breaking breaker transition broken wave and swash each with different empirically derived sediment transport rate relationships sbeach was run using the previously determined calibration coefficients at narrabeen beach over 5 storm events in 2007 2011 2014 and 2015 simmons et al 2019 these events cover a range of large and small observed erosion volumes a full description of the sbeach model and details of model validation are provided in larson and kraus 1989 2 3 2 2 xbeach xbeach roelvink et al 2009 is a process based model that solves coupled equations for hydrodynamics sediment transport and bed morphology xbeach resolves long wave motions or infragravity waves which in many environments dominate storm energy and drive wave dune collisions raubenheimer and guza 1996 roelvink et al 2009 sediment transport in the surf and swash zone is calculated using van thiel van rijn formulations that determine the magnitude based on the difference between depth averaged and equilibrium sediment concentration van rijn et al 2007 van thiel de vries 2009 an avalanching routine is used to simulate sand slumping during the dune collision regime a full model description is available in roelvink et al 2009 in this study xbeach x in profile mode was used this version significantly improves the estimation of post storm beach slope on steep beaches using a simple empirical correction factor applied to the calculated sediment transport roelvink et al 2019 calibrated values for this model at narrabeen beach were obtained based on the work of matheen et al 2019 that considered three recent storm events in 2014 2015 and 2016 these storms range from some of the most erosive over the last 39 years to relatively minor erosion events the model was run with facas 0 13 facsk 0 106 gamma 0 41 and bermslopefac 19 81 at all profiles 2 3 3 machine learning model a neural network multilayer perceptron regression model was used as the data driven model for predicting storm erosion in this study the python package keras chollet 2015 with the tensorflow backend abadi et al 2016 was used to train a neural network nn with two hidden layers consisting of 200 and 40 neurons respectively the relu rectified linear unit activation function was used for all hidden neurons and a dropout rate of 0 4 was applied to assist in the prevention of overfitting the model was trained using a mean square error loss and an adam optimiser the model was trained separately at each profile for up to 200 epochs with an early stopping policy implemented when the loss on the training data stopped improving meaningfully the full storm data set was available in the model training using a cross validation approach described in section 2 4 the model architecture was chosen through a hyperparameter search with the best performing configuration chosen while the nn architecture and training could be further refined for further improvement e g to improve model predictions for more extreme events it is sufficient given the focus of this study is on model averaging the input variables for the model were chosen using an exhaustive search over the training dataset beuzen and simmons 2019 input variables trialled in the model included mean and maximum significant wave height wave period and wave direction both inshore 15m depth and offshore 70m depth cumulative wave power offshore and at wave breaking 2 exceedance wave runup calculated according to stockdon et al 2006 mean maximum and number of impact hours above an assumed dune toe mean and maximum astronomical water level storm duration pre storm beach width volume and beachface slope all combinations of between 2 and 8 input variables were made available to the nn and the best performing combinations and most informative variables were found after this rigorous testing four input variables were chosen for the data driven model to provide a compromise between maximum performance on unseen data and undesirable model complexity beuzen et al 2018 in order of importance these were the pre storm beach width the cumulative wave power at breaking the maximum offshore significant wave height and the mean 2 exceedance wave runup other ml architectures were trialled including much simpler linear models and different configurations of nn however it is outside the scope of this paper to present an exhaustive comparison of ml methods 2 4 model averaging ensemble model averaging is widely used in climate forecasting i e gcms and an increasing use in coastal evolution modelling where the ensemble mean has been shown to outperform individual model performance montaño et al 2020 averaging the 4 model outputs described above provides the potential to improve performance above any one individual model the output of the model average for predicting the change in beach width dshl avg is found by summing the individual model predictions multiplied by their weights 3 dshl avg w 1 d s h l e m p i r i c a l w 2 d s h l m l w 3 d s h l s b w 4 d s h l x b where w 1 w 2 w 3 and w 4 are the weights for the outputs of the empirical d s h l e m p i r i c a l ml d s h l m l sbeach d s h l s b and xbeach d s h l x b models respectively a bias term can be included in the fit in addition to the weighted model outputs a separate fit following the same approach is found to estimate the weighted ensemble change in subaerial volume d v o l a v g a wide range of approaches are available from simple naïve averaging that weights each model equally to more complex approaches that consider model bias and use optimized least squares the best ensemble weighting method remains largely dependent on the dataset and models being used diks and vrugt 2010 in this study the performance of the bates and granger 1969 ensemble method is compared to the performance of each of the individual models additional weighting methods are discussed and compared for this data in section 4 2 using the bates and granger 1969 method the weights are calculated as proportionate to the model s prediction variance σ 2 whereby the weight for each individual model w i is given by 4 w i 1 σ i 2 j 1 k 1 σ j 2 the prediction variance is estimated using the variance of the model prediction error e g the variance of d s h l x b d s h l over the training data points for the xbeach model over the data available to train the model averaging weights diks and vrugt 2010 the inverse prediction variance for each individual model is normalized using the sum over all k models so that the model weights w sum to 1 to determine the ensemble model weights the data at each profile were split into a training and testing group with 1 3 of the data ranging between 46 and 57 data points depending on the profile reserved for testing a subset of these test data has been presented in figures below representing the top 10 most erosive events in each test group between 4 and 6 storm events at the five profiles within the training set the data were split into two equal size groups one half was used to train the ml model described in section 2 3 2 2 the second half was then used to find the model averaging weights on data unseen by the ml model the test set was used as unseen out of sample data on which to objectively compare the performance of the averaged and individual four models a cross validation type approach was used whereby these three splits of the dataset were varied with 100 random iterations of the test train data groups to compare model performance evenly across the dataset the analysis was carried out individually at each profile and figures presented below summarise the results across all five profiles 3 results 3 1 individual model performance the four modelling approaches an empirical model two numerical models sbeach and xbeach a machine learning model were compared to assess their predictive capabilities for the 39 year narrabeen storm dataset considering the results across the entire test data set as detailed in fig 2 a the ml model provides the most accurate erosion predictions as well as the most consistent performance as measured by the inter quartile range and boxplot range skill is also measured as a function of normalized mean square error nmse e g miller and dean 2004 splinter et al 2014b 5 n m s e o b s m o d e l 2 o b s 2 where obs represent the observations of change in shoreline dshl or change in volume dvol and model the individual model predictions of the respective variables sbeach nmse is roughly twice that of the ml model the empirical model and xbeach model were considerably less skilful over the test data set when compared to the sbeach or the ml model when considering model performance over only the top 10 of storms from the test data set in each of the iterations as shown in fig 2b the results show that the skill as measured by nmse does not significantly change when comparing between extreme events and all of the storm data for the ml and sbeach models however significant changes in skill are seen in the empirical model and xbeach model this change in skill and model sensitivity to calibration data is further discussed in section 4 1 fig 3 shows this more clearly by plotting the distribution of model errors the empirical model and xbeach model tend towards overprediction positive error as well as a much broader distribution of errors over the entire data set fig 3a and the extreme events fig 3b by contrast the distribution of errors for sbeach and the ml model are much narrower and roughly centred around zero when considering all data fig 3a but underpredict with broader distribution in errors for the more extreme events fig 3b distributions in the errors between shoreline change fig 3 left and volume change fig 3 right change slightly between examining all the data or just the extreme events but the overall trends are the same 3 2 ensemble model performance the results of the individual models highlighted which models did well under more extreme conditions compared to a general fit to the data as well as the distribution of these errors while the authors acknowledge that a variety of combinations of the four candidate models could be considered in a wide range of ensembles here all four models are included to represent the four broad types of coastal erosion models considered in this study and the wide range of skill each model had over a wide range of storm conditions fig 3 the error distribution of individual models can then be used to develop an ensemble average estimate of shoreline change and volume change fig 4 shows the performance of a weighted model average in comparison to the performance of the individual models while the ensemble model performs slightly worse than the ml model over the entire dataset fig 4a it performs much better than the empirical model and numerical models despite all these models influencing the ensemble result importantly for the 10 highest impact events fig 4b the ensemble outperforms any individual model using a weighted model average ensemble approach it combines the four models in such a way as to improve prediction for the largest events while maintaining comparable skill to the ml model during smaller events as well this balance is particularly important in a forecasting sense whereby ahead of an impending storm the ensemble model should limit false positive predictions of large erosion impact yet still provide the most accurate predictions possible for the events of most interest the largest events the range of the boxplot in fig 4 also indicates that the ensemble approach provides an increased certainty in predicting the largest events in comparison to the other models to further understand the influence of each of the models in the ensemble fig 5 shows the ensemble model weights found using the bates and granger 1969 approach this approach weights the sbeach and ml models almost twice as much as the empirical model or xbeach model due to their low error variance as shown in fig 3 thereby allowing them to influence the ensemble output more than the less certain empirical model or xbeach model outputs the overall balance of the four models then accounts for the slight under estimation of some models in contrast to the over estimation by other models under certain conditions section 4 2 further discusses the performance of several other model combination approaches trialled and the trade offs observed when choosing between single weight model combination approaches 4 discussion 4 1 sensitivity to model training data sets to further understand the sensitivity of the individual model performance to the training data fig 6 shows the distributions of the observed change in shoreline and volume for the 39 year data set at narrabeen the observations are dominated by smaller erosion events interspersed with less frequent but much more severe erosion events ninety percent of the storm events result in 0 44 m3 m of erosion and in between 0 and 17 m of shoreline erosion the top 10 of events result in between 44 and 150 m3 m of erosion and 17 54 m of erosion this skewed distribution of observations has implications to individual model skill depending on the data used for model training due to the time constraints and lack of data numerical models such as xbeach and sbeach are often trained on only one or a few storm events harley et al 2016 mccall et al 2010 simmons et al 2019 splinter and palmsten 2012 this likely biases the calibration to those often more extreme events observed at a site however a few studies have also shown that increasing the number of storm events beyond three for model calibration doesn t necessarily increase model skill matheen et al 2021 simmons et al 2019 as detailed in simmons et al 2019 xbeach is far more sensitive to individual storms than sbeach with respect to calibration by contrast the empirical model and ml model used here were given a larger range of storm data to train on as shown in fig 2 this influences the skill of each of the individual models over the entire data and on the more extreme events the ml predictions most closely match the overall distribution of observed erosion events fig 6a however they tend to significantly underestimate the probability of larger events fig 6b conversely the xbeach model and empirical model overestimate the frequency of larger impact events however with a much wider spread in the overall distributions considering all four models the predictions of the individual models were mostly distributed about the true value with some tending to overpredict and others to underpredict for most storm events the measured erosion value lay within the range of predictions from the individual models 86 for dshl and 88 for dvol of the remaining events for which the model predictions did not encompass the observed erosion a vast majority 92 for dshl and 84 for dvol of these were among the smallest 50 of events in terms of measured erosion 4 2 comparison of model averaging techniques the ensemble model results presented in section 3 2 used the methods described in bates and granger 1969 and allowed all four model outputs to be considered as part of the ensemble based on individual model skill three additional methods were also compared in this study table 2 and are discussed here this includes a mixture of methods that either constrain the model weights to sum to unity or allow these to vary freely in order not to assume the models of the ensemble to be unbiased shamseldin et al 1997 fig 7 shows the distribution of results of the 4 common approaches described in table 2 for determining the individual model weights due to the range and distribution in model errors shown in fig 3 fitting the ensemble with a fixed weight for each model results in a trade off giving a higher weight to the ml and sbeach models maximises the performance over the entire dataset e g fig 7 ols while giving a higher weight to the xbeach model and empirical model maximises performance for the most extreme events e g fig 7 equal weighting overall the optimized least squares ols fit provides the best performance over the entire range of data and better than any individual model however a number of other methods tested show better performance on the largest events which are often the most interest to a coastal practitioner for this reason the bates and granger 1969 method was chosen as the model averaging approach that best balances the accurate prediction of extreme erosion events and avoids false positive predictions for more moderate events the approaches with positive weights constrained to sum to unity performed better for the storm events than the granger and ramanathan 1984 approach of letting the weights vary freely with an additional bias term allowing the weights to vary more freely worsened performance suggesting overfitting of the small training dataset for model averaging the high performance of the bates and granger method in particular and the data shown in fig 3 suggest that the model errors are uncorrelated and as an ensemble have minimal bias as such simpler bates and granger or equal weighting methods provide significant improvements over the performance of individual models especially when predicting more extreme events 4 3 adaptive model averaging in addition to simple model averaging techniques more advanced approaches exist for learned model combination in particular a number of adaptive approaches have been developed predominately in the hydrological modelling space whereby either the selection or weighting of model results can adapt given the properties of an individual data point duan et al 2007 jeremiah et al 2013 marshall et al 2006 raftery et al 2005b this can allow time varying or event specific combinations of the model outputs to acknowledge the non stationary errors associated with each model i e fig 3 based on the results presented in section 3 1 it would be ideal to condition the weights to favour the empirical model and xbeach model for larger events and ml model and sbeach model during less erosive conditions fig 8 shows the non stationary weightings for each of the four models when a neural network was trained to predict weights summing to unity based on the observed subaerial erosion and shoreline change when these adaptive weights are used the ensemble model dshl prediction nmse was reduced to approximately 0 17 and 0 08 for the entire test set and the top 10 respectively providing a significant increase in skill and certainty compared to all other model weighting schemes tested 0 35 and 0 11 respectively these storm erosion dependent weights indicate that model errors vary to some degree with storm magnitude the challenge of applying this scheme is observed volume change is not available a priori and as such it only provides an estimate of how the model weightings should vary with storm magnitude in an idealised sense in fig 8 we can see that the sbeach model green line is weighted highly for predicting minor events and the ml model orange line for moderate events the contribution of the xbeach model red and to a lesser degree empirical model blue grows steadily with the magnitude of the event with the most extreme events weighted significantly towards the xbeach model within a forecasting sense this adaptive weighting could be incorporated by either learning adaptive weights conditioned on the model outputs for a given storm e g shamseldin et al 1997 or based on some storm properties such as those used to train the ml model e g marshall et al 2006 both these approaches were tested on the available data both measured inputs and model outputs due to the large noise within the limited training data set the resulting weights either showed no clear conditioning or the adaptive weighted average model did not offer an overall improvement over a simple ols fit or bates and granger weights as described in section 4 2 with further research and improved datasets considering both quality and quantity of data such an approach could provide more accurate predictions by fully leveraging the strengths of each model in predicting different types of events 5 conclusion the ability to robustly predict storm erosion along sandy coastlines is an active area of research with advances in the use of data driven and numerical modelling approaches that account for uncertainty and error gaining in popularity a majority of models however are sensitive to calibration and a one size fits all approach may lead to unacceptably large errors when used to predict erosion outside of the range of the training data set here four storm erosion models an empirical model numerical models sbeach and xbeach and a machine learning approach were individually trained and tested on a 39 year storm erosion data set to examine skill and error distributions the results showed that each model was skilful under different conditions the machine learning model showed the overall best skill followed by sbeach the empirical model and then xbeach during the more extreme erosion events xbeach performed well and slightly over predicted erosion whereas the machine learning model tended to under predict the erosion a simple weighted ensemble approach provided the best combined skill across all storms and the more extreme events the ensemble approach incorporated weights learned from the error distribution of each of the individual models it was able to provide a more accurate and reliable prediction of erosion compared to each of the individual models the ensemble provided around the same performance across the whole dataset as the machine learning approach however outperformed all models when considering the top 10 of most erosive events adaptive model averaging also showed potential as an area for future research with different models showing better skill at predicting storms of different magnitudes however the data available in this study were not of sufficient quantity and were potentially too noisy to allow more sophisticated model averaging techniques declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the nsw environmental trust environmental research program rd 2015 0128 and through the unsw faculty of engineering carers award wave and tide data were provided by manly hydraulics laboratory on behalf of the nsw department of planning industry and environment dpie bathymetric data was kindly collected by nsw dpie nearshore wave modelling was undertaken by mitchell harley and edward kearney unsw all narrabeen subaerial profile data and wave data used in this study is available open access at http narrabeen wrl unsw edu au the authors wish to thank the editors and the four reviewers including dr lazarus and dr goldstein for their constructive and thorough reviews which have undoubtedly improved the manuscript 
