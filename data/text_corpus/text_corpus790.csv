index,text
3950,global gridded precipitation datasets have been developed using rain gauges satellite observations and data assimilation techniques to fulfill the need in regions with a limited contribution of ground observations like iran this study presents a comprehensive evaluation of currently available precipitation datasets over iran at monthly 44 datasets and daily 34 datasets time scales to include the maximum number of datasets and in situ data we consider two periods for the evaluations namely 2003 2010 for the daily and monthly assessment and 2014 2018 for the daily for the assessment a network of more than 1500 rain gauges is utilized within 2003 2010 and 370 rain gauges within 2014 2018 moreover we compare the pixel to pixel interpolated in situ data v s gridded datasets and point to pixel in situ data as a point v s gridded datasets approaches in assessing datasets performances in terms of the kling gupta efficiency kge parameters the datasets perform worse in bias at monthly time scales and correlation at daily time scales however considering in situ precipitation above 5 mm day all datasets perform poorly in estimating precipitation variability we find that in general reanalysis products have a higher kge ranging between 0 41 0 21 and 0 91 0 71 than satellite based products with a kge ranging from 0 14 0 57 to 0 92 0 57 over iran at monthly daily scale moreover gpcc overall matches the validation dataset better than other products over iran s basins whereas cpc era5 and imerg final are more suitable for near real time studies also if latency is a top criterion persiann pdir will be the first option indeed persiann pdir with a kge value of 0 69 0 33 at monthly daily time scale within 2003 2010 performs remarkably well as a non adjusted real time satellite based product the comparison between the point to pixel and the pixel to pixel approaches shows that the point to pixel approach underestimates the quality of the datasets but does not change the ranking of the datasets keywords gauge based products reanalysis products satellite observations statistical evaluation point to pixel approach pixel to pixel approach 1 introduction precipitation drives the water cycle and plays a significant role in the atmospheric circulation kidd and huffman 2011 trenberth et al 2003 it plays a substantial part in research and planning with a wide range of applications e g drought analysis and identification flood prediction and protection hydrological modeling water resources management agriculture and urban planning ebert et al 2007 sorooshian et al 2011 therefore the accuracy of precipitation data directly affects the validity of water resources planning and management projects sharifi et al 2012 xu et al 2016 although the most accurate precipitation data can be obtained from in situ data the network of such stations is sparse in many regions due to geographical topographical and economic constraints su et al 2008 xu et al 2016 faridzad et al 2018 especially in developing countries recently many gridded precipitation datasets have been developed to meet the need for the applications mentioned above these datasets provide the precipitation data with various spatio temporal resolutions from the regional to the global scale they are developed from different sources 1 in situ measurements 2 remote sensing data 3 outputs of numerical models and 4 in some cases as a combination of them using data assimilation techniques hosseini moghari et al 2018 sun et al 2018 the four mentioned types of gridded datasets are commonly used by researchers mainly due to their availability ability to mimic point scale measurements and constant spatio temporal resolution raimonet et al 2017 it is expected to see that gauge based datasets show better performance than satellite based and model based products in regions with adequate and extensive gauge data however unlike gauge based datasets satellite based and model based datasets are almost real time making them suitable for operational applications cavalcante et al 2020 moreover a well performed satellite or a model based product can be adjusted by the gauge data resulting in an enhanced product using the positive features of each dataset adler et al 2001 bui et al 2019 chen et al 2020 although gridded precipitation datasets inherently show lower accuracy compared to in situ data some reports have indicated their considerable potential to be applied in different climatic and water related studies e g scheel et al 2011 poméon et al 2017 salman et al 2019 eghdami and barros 2019 the performance of global gridded precipitation datasets varies in different parts of the world which necessitates the evaluation of their performance before operational applications camici et al 2018 so far many studies have assessed the performance of different datasets at the global or regional scale e g ahmed et al 2019 prakash 2019 hua et al 2019 lorenz and kunstmann 2012 several studies evaluated the validity of the global datasets for different applications e g drought monitoring aghakouchak and nakhjiri 2012 ahmadebrahimpour et al 2019 zhong et al 2019 golian et al 2019 liu et al 2020 trend analysis lin et al 2014 ashouri et al 2016a balling et al 2016 zhan et al 2018 toride et al 2018 stream flow simulation ashouri et al 2016b yuan et al 2017 su et al 2017 nhi et al 2019 try et al 2020 lorenz et al 2014 and flood modeling nanda et al 2016 tekeli and fouli 2016 anagnostou and mei 2018 yuan et al 2019 employing global datasets is an opportunity to eliminate limitations arising from a lack of ground measurements which demands evaluating and validating gridded precipitation datasets against available observed data despite a broad range of investigations no specific type of precipitation dataset has been considered as the most valid one in all regions rajulapati et al 2020 therefore more comprehensive evaluations should be conducted for each area separately since gathering a sufficiently dense network of in situ data for the whole globe is nearly impossible the best way for doing these evaluations is to do it at a regional scale i e on a country scale or basin scale several studies have assessed global precipitation datasets over iran e g javanmard et al 2010 katiraie boroujerdy et al 2013 khalili and rahimi 2014 shokoohi and morovati 2015 katiraie boroujerdy et al 2016 moazami et al 2016 darand et al 2017 dezfooli et al 2018 hosseini moghari et al 2018 hosseini moghari and tang 2020 saemian et al 2020 ghozat et al 2020 darand and khandu 2020 however the literature lacks a comprehensive assessment each of these studies has only considered one or a few datasets for evaluations moreover in situ data and the periods of evaluation are different in all those studies therefore it would be even challenging to compare or combine their results to fill this gap in the current paper we comprehensively assess the performance of 44 global gridded datasets across iran using a dense network of precipitation gauges our assessments include both daily 34 datesets and monthly 44 datasets scales in this study persiann pdir 20crv2 nceps and merra 2 are assessed for the first time over iran we also compared the pixel to pixel interpolated in situ data v s gridded datasets and point to pixel in situ data as a point v s gridded datasets approaches for evaluating global precipitation datasets the finding would be beneficial at least for two groups of users first for the institutes in charge of dataset development they would be able to document the error characteristics of datasets in each region and improve the datasets accuracy in the next version second for users who employ global precipitation as forcing in hydrological modeling or input for other applications either on the regional or global scale considering the number of datasets to the best of our knowledge this is the most comprehensive evaluation of precipitation datasets both regionally and globally 2 study area iran is located in the middle east 25 40 n latitude 44 64 e longitude covering an area of 1 648 195 km 2 see fig 1 two major mountain ranges are located in the country namely the alborz along with the northwest to northeast and the zagros along with the northwest to the southwest the most important water bodies of the country are the caspian sea the biggest lake in the world in the north the persian gulf and the gulf of oman in the south and lake urmia in the northwestern the central part of the country is covered by two large deserts namely the lut and kavir deserts although iran is located in the subtropical high pressure belt of the earth different topographical regions with an elevation range from 25 m to 5600 m result in the presence of diverse climates generally the climate of the country is arid 64 and semi arid 20 khalili and rahimi 2018 humid climate covers only 10 of the country mainly the regions close to the caspian sea and some close to the persian gulf and oman sea the temporal and spatial patterns of precipitation are very diverse due to the complex topography which leads to difficulties for measuring and estimating the spatio temporal distribution of precipitation zhang et al 2020 the annual mean precipitation of the country is less than 250 mm the country is divided into 6 primary basins including 30 sub basins areas the borders and id number of the sub basins are shown in fig 1 3 data 3 1 precipitation datasets we evaluated the performance of 44 34 gridded precipitation datasets at monthly daily time scale see table 1 the datasets are classified into the three main categories as gauge based precipitation products gpps satellite based precipitation products spps and reanalysis precipitation products rpps we included five datasets based only on gauge data referred as gpps in the paper cru gpcc precl udel and cpc nine datasets based on only satellite data referred as sps in the paper persiann persiann ccs persiann pdir trmm 3b42 rt gsmap mvk gsmap nrt gsmap rnl cmorph raw and imerg early and seven datasets fully based on re analysis referred as rps in the paper ncep 1 ncep 2 era interim era5 cfsr 20cr and jra 55 moreover we assessed twelve combined gauge and satellite datasets referred as gsps in the paper gpcp gpcp 1dd cmap persiann cdr persiann ccs cdr trmm 3b42 adj trmm 3b43 gsmap gauge cmorph cdr cmorph bld cmorph crt and imerg final five combined gauge and re analysis datasets referred as grps in the paper agcfsr pgf wfdei wfdei cru and wfdei gpcc and five combined gauge satellite and re analysis datasets referred as gsrps in the paper chirps mswep merra 2 agmerra merra land we also evaluated one dataset which is developed by using the combination of satellite and re analysis data chirp 3 2 in situ data the ministry of energy with more than 4360 stations and the iranian meteorological organization irimo with 433 stations are the primary centers for providing precipitation data over iran in this study the most updated available data from these two centers are collected at daily and monthly time scales it should be noted that the number of stations varies over time two time periods have been selected one from 2003 to 2010 and the other from 2014 to 2018 the former is chosen considering the intersection between all datasets and employing a more dense network of stations the latter is defined to consider mainly the gpm family imerg within 2003 2010 is produced based on trmm data as one of the most recent developed precipitation datasets see fig 2 considering the first time window we ended up with a network of 3130 precipitation stations see fig 1 c we controlled data from stations in terms of gaps coordinates and elevation after doing such a sieving test we had 1561 separate stations with continuous daily precipitation within the study period of 2003 2010 which then were used for the evaluation regarding the second period from 2014 to 2018 370 synoptic stations are obtained after conducting the same quality control checks due to the mismatch between point wise rain gauge data and gridded precipitation datasets it is common to up scale point wise data to the grids using an interpolation method many interpolation techniques have been proposed for precipitation data including the simple averaging xie and xiong 2011 the inverse distance weighting idw hu et al 2014 thiessen polygons liu et al 2015 and different kriging methods goovaerts 2000 lebrenz and bárdossy 2019 the interpolation methods performance depends on many factors including the rain gauge network structure and the topography of the study area hofstra et al 2008 in this study for the period 2003 2010 the ordinary kriging ok method wackernagel 2003 was applied at daily time steps in 11 different spatial resolutions to cover all employed precipitation datasets fig 3 it should be noted that we chose the ok method due to its considerable performance in modeling spatial variations of precipitation in iran javari 2017 here comparison based on interpolated data is called the pixel to pixel approach within 2014 2018 we used a point to pixel approach i e we assessed the datasets directly at the position of each rain gauge due to the lack of a dense network of stations 4 evaluation approach we considered several performance metrics to evaluate the temporal dynamics of the precipitation datasets against the in situ observations the equation and optimal value of each metrics are summarized in table 2 relative bias rbias as a bias indicator represents the degree of overall underestimation negative values or overestimation positive values of predictions to average the magnitude of the error we have used the root mean squared error rmse which is a negatively oriented score i e lower values show better result in comparison to rbias the rmse neutralizes the effect of negative pairwise discrepancies between estimated and observed values this means both negative and positive errors contribute to the overall error moreover rmse gives more importance to big errors by giving higher weights to them which is desirable when emphasizing extremes the pearson correlation coefficient is employed to measure the linear relationship between estimated and measured precipitation errors in estimating any variable can be divided into two components random error and systematic error random errors are unpredictable fluctuations in the estimated precipitation concerning the measured while systematic errors are predictable and reproducible inaccuracies that are consistently in the same direction in our evaluation we have quantified each of random and systematic errors at monthly and daily time scales similarity between the estimated values from datasets and observations can be quantified using model performance metrics like the nash sutcliffe efficiency nse nash and sutcliffe 1970 or the kling gupta efficiency kge gupta et al 2009 in this study we have calculated modified kge scores using the estimation from in situ observations and datasets estimation kling et al 2012 kge is an improved variant of the nse index by decomposing it into several components unlike nse the multi component nature of kge incorporates linear correlation bias and variability within a single objective function providing a more balanced model evaluation 1 kge 1 r 1 2 β 1 2 γ 1 2 where r is the pearson correlation coefficient optimum value 1 β is bias optimum value 1 and γ represents the variability ratio optimum value 1 as follow 2 r σ e o σ e σ o 3 β μ e μ o and γ σ e μ e σ o μ o where μ and σ are the mean standard deviations of the time series respectively the subscripts e and o indicate estimation and observation respectively the optimum value of kge is one categorical statistics can measure the precipitation datasets skill in detecting events at the daily time scale the heidke skill score hss as a categorical statistic quantifies each dataset s capacity compared to a random based prediction to calculate hss we have first detected the daily precipitation events as rainy or not rainy the threshold of 1 mm day is considered to distinguish rainy days considering the pre defined threshold four cases are possible as shown in the so called contingency table table 3 in this table a is called hit b is called false alarm type one error c is called false negative type two error and d is called correct rejection the hss is calculated for each dataset using the results from the contingency table and the following equation 4 hss 2 a d b c a c c d a b b d the hss scores range from to 1 in which the optimum value is one and negative scores indicate that a random based estimation performs better than the evaluated precipitation dataset it should be noted that for calculating the assessment metrics for the whole country we put all precipitation data from all pixels together and then calculated assessment metrics we followed this approach instead of averaging assessment metrics of all pixels to minimize the impact of arid and semi arid regions which are a large fraction on average of assessment metrics finally at monthly scale we divided the pixels into five classes based on their mean annual precipitation inspired by hosseini moghari et al 2018 as a proxy of climatic conditions i e less than 100 mm yr 100 200 mm yr 200 300 mm yr 300 500 mm yr and more than 500 mm yr for daily scale to assess the skill of the datasets in estimating different precipitation intensities we considered four intensity classes were inspired by hosseini moghari and tang 2020 i e less than 5 mm day 5 10 mm day 10 20 mm day and above 20 mm day 5 result 5 1 intercomparison of annual precipitation estimates 2003 2010 this part presents a general overview of datasets performance fig 4 exhibits the spatial distribution of mean annual precipitation retrieved from in situ data and studied datasets from 2003 to 2010 recall that in situ data in this period are interpolated by ordinary kriging based on interpolated in situ data fig 4 top left the country receives a significant portion of its precipitation over the southwest of the caspian sea and along the zagros mountains the mean annual precipitation varies from 1800 mm in the southwest of the caspian sea to less than 50 mm in central part as expected gpps and gauge corrected datasets generally outperform other datasets in estimating the mean annual precipitation s spatial distribution this becomes apparent when comparing in situ data in the top left with all other maps in fig 4 the highest correlation is obtained for gpcc cc 0 96 followed by wfde gpcc cc 0 94 trmm 3b43 cc 0 91 imerg final cc 0 91 and agcfsr cc 0 89 among sps and gsp persiann pdir and imerg final excel at estimating the spatial distribution of the annual precipitation persiann and persiann ccs with an underestimation rbias 0 39 and overestimation rbias 0 68 respectively do not present any specific pattern it is difficult to reach a fair judgment about the spatial performance of cmap gpcp ncep1 ncep2 cfsr and 20cr datasets regarding the low spatial resolution however a general underestimation can be seen in nceps while the opposite is true for gpcp two high resolution products namely chirp and chirps can generally map the annual precipitation however both datasets significantly overestimated the precipitation in the caspian sea coastal areas and the alborz mountain range the same overestimation across the caspian sea coastal areas is observed in the era5 estimation 5 2 intercomparison of monthly precipitation estimates 2003 2010 this section evaluates the reliability of precipitation data of 44 datasets at the monthly scale table 4 presents the assessment metrics at a monthly scale although our focus here is on a pixel to pixel approach the assessment metrics were also calculated based on a point to pixel approach the numbers in parentheses from the table gauge corrected products show almost a similar performance compared to gpps and outperform satellite and reanalysis ones with respect to kge gpcc kge 0 91 persiann pdir kge 0 69 gpcp kge 0 92 era interim kge 0 85 wfdei gpcc kge 0 91 and merra 2 kge 0 80 are the best gpps sps gsps rps grps and gsrps datasets respectively although correlation values between in situ and sps data are generally less than other types of products they are still in an acceptable range the lowest value is equal to 0 32 for gsmap mvk in terms of rbias all gpps underestimate monthly precipitation from very low 0 01 for gpcc to relatively high 0 27 for cpc this underestimation can be explained by the fewer number of stations involved in the interpolation mostly in areas with lower annual precipitation this underestimation is also evident in grps except wfdei gpcc with a maximum rbias of 0 17 for pgf rbias of sps varies considerably from an underestimation of 0 39 for persiann to an overestimation of 0 68 for persiann ccs such a variation can also be seen in gsps rps and gsrps with a lower amplitude ranging from 0 23 for cmap to 0 21 for persiann ccs cdr 0 28 for ncep1 to 0 27 for jra 55 and 0 27 for merra land to 0 11 for chirps respectively the variability ratio indicates that the performance of the datasets does not follow any specific trend fourteen datasets have almost a similar variability compared with in situ data variability ratio between 0 95 to 1 05 while 14 and 16 datasets have lower and higher variability than the observations respectively for instance precl persiann ccs and chirp with a variability ratio equal to 0 81 0 83 and 0 89 respectively have less variability than observed data in contrast gsmap mvk ncep1 and cmorph raw with variability ratio values equal to 1 68 1 42 and 1 13 respectively have more variability three datasets including persiann ccs gsmap mvk and gsmap nrt have high rmse more than 40 mm month therefore due to their large random error values it is unlikely that they can represent in situ data even after applying an accurate conventional bias correction gpcp and gpcc have the best performance among all studied datasets at a monthly scale followed by wfdei gpcc considering their low rbias 0 02 and 0 01 high correlation coefficient 0 92 and 0 94 high kge 0 92 and 0 91 and low rmse 11 6 and 11 5 mm month a comparison between the pixel to pixel approach and the point to pixel approach at a monthly scale suggests generally datasets show better performance when the pixel to pixel approach is considered for instance the kge of gpcc based on the point to pixel approach is 13 less than kge from the pixel to pixel approach among kge components correlation and variability ratio is more sensitive than bias to the approach of evaluation the average correlation bias and variability ratio of all datasets are 0 74 0 98 and 1 03 in the pixel to pixel approach while reaching 0 62 0 98 and 0 87 in the point to pixel approach respectively this finding implies that the total precipitation may not change significantly in different evaluation approaches while the time series behavior would be affected the rmse is higher for the point to pixel approach in most cases up to more than 50 for example the era5 s rmse increase from 19 9 to 30 7 mm month when the point to pixel approach was used instead of pixel to pixel overestimating the systematic error rate is also evident in the point to pixel approach comparing the mean of systematic error in point to pixel approach as 39 with 22 in the pixel to pixel approach despite distinct values for the assessment metrics the evaluation approach from pixel to pixel to point to pixel does not change the datasets ranking fig 5 demonstrates the spatial distribution of the kge between the observed dataset and the precipitation datasets at a monthly scale most datasets perform better over the west and along the zagros mountains imerg early performs the worst in the south while persiann ccs has the worst performance in other regions among the persiann family persiann cdr is the best dataset with a median of kge equals 0 75 especially in the east adjusted datasets almost have a similar pattern to gpcc and cru and in some areas even perform better than gpps among gpps precl performs the worst more likely due to the limited contribution of iran s in situ data in its development gpcc and imerg final with a median of kge equal to 0 80 outperform other datasets among all other datasets cru udel trmm3b42 trmm3b43 gpcp persiann cdr era5 agcfsr pgf wfdei wfdei cru wfdei gpcc mswep merra 2 agmerra and chirps have considerable performance with a median of kge no less than 0 67 it s worth noting that the datasets performance over the central regions of iran should not be over interpreted due to the lack of rain gauges in these regions cf fig 1 c fig 6 presents the box plot of the kge for each dataset in different annual precipitation categories see section 4 based on the results shown in this figure most datasets perform better in the regions with the annual precipitation below 100 mm except low spatial resolution datasets namely ncep1 ncep 2 gpcp and cmap see table 1 generally the kge values decrease slightly with an increase in annual precipitation since arid climate possesses a vast area of the country the performance of the datasets among regions with annual precipitation below 300 mm is more crucial considering regions with annual precipitation below 300 mm persiann ccs has the worst performance for categories 300 500 mm and above 500 mm ncep1 and persiann have the worst performance respectively although gpcp gpcp1d gpcc and imerg final perform better than others in class all their performances in other classes are not the best cru imergv6 final and pgf persiann cdr gpcp gpcp1d and imerg final imerg final and gpcp imerg final and gpcc are the best dataset in classes below 100 100 200 200 300 300 500 and above 500 mm respectively the length of the box plots is minimum in the class below 100 mm which indicates the changes in the given dataset s performance are low within the pixels with annual precipitation below 100 mm considering the median of kge the performance of the datasets varies in different annual precipitation classes fig 7 shows box plots of kges in different pixels along with decomposed kge values into their components at a monthly scale from 2003 to 2010 generally the medians of bias is about 0 25 away from their optimum values while this difference is about 0 2 and 0 1 for correlation and variability ratio respectively because of the squaring of these components in the kge generally the variability ratio plays a negligible role in kge values compared to bias and correlation however some datasets like ncep1 perform worse in terms of the variability ratio than correlation inspecting kge s components for different precipitation classes see figs s1 s3 indicate that the kge values in the class below 100 mm enjoy a large correlation in this class almost all datasets tend to underestimate the precipitation in the class above 500 mm while a fluctuation between underestimation and overestimation is seen in other classes the underestimation in the class above 500 mm is mainly due to underestimating the precipitation in the southwest of the caspian sea see fig 4 changes in the variability ratio between the classes are less than correlation and bias however most datasets particularly in the class above 500 mm tend to show more variation than in situ data 5 3 intercomparison of daily precipitation estimates 5 3 1 part a point to pixel approach 2014 2018 this section evaluates the 25 most up to date datasets covering the period from 2014 to 2018 the point to pixel approach is considered due to the limited numbers of rain gauges for this period fig 1 d table 5 shows the assessment metric values at the daily time scale cpc with a kge value of 0 45 outperforms other datasets trmm3b42 adj gsmap gauge cmorph bld cmorph cdr and cmorph crt have almost the same or even better bias and variability ratio as cpc however their kges are below 0 27 mainly due to lower correlation a comparison between the persiann family shows gauge that adjustment has not enhanced the performance within 2014 2018 conversely the gauge correction has increased gpm based products particularly gsmap i e increasing kge from 0 08 to 0 27 mainly through bias improvement cf table 5 inspecting systematic and random errors reveals that a significant part of the error is related to systematic error in most of the datasets suggesting a need for further improvement in their development algorithms only two datasets i e cpc and persiann pdir have hss above 0 5 indicating a mediocre performance in detecting precipitation events in almost all datasets it is noteworthy to mention that this performance is remarkable for persiann pdir as a satellite based dataset without any gauge adjustments cmorph bld and cmorph crt with the hss below 0 14 show a weak skill in detecting precipitation events in comparison with a random based prediction fig 8 illustrates the spatial distribution of the kge at rain gauges for the precipitation datasets within 2014 2018 generally the best performance of all datasets is observed over the zagros mountains cpc and imerg final with a median kge equal to 0 55 and 0 33 respectively outperform other datasets in most areas even after gauge adjustment almost all satellite based products except imerg final have a poor performance with a median value below 0 30 in most stations all datasets of the persiann family have a poor ability to estimate the precipitation and among them persiann ccs is the worst with considerable negative kge in iran s central regions apart from some large negative kges over the alborz mountain range and northwest the era family shows a decent performance in estimating rainfall across the west of iran with the median kge of 0 33 and 0 28 for era5 and era interim respectively inspecting fig 9 which shows kge and its components based on daily data within 2014 2018 reveals that generally datasets are worse in terms of correlation than bias and variability however gsmap mvk gsmap nrt and persiann ccs suffer from a large bias with a median of 1 69 1 75 and 1 69 respectively many datasets have a variability less than the observations with the worst performance observed from the chirp and persiann cdr datasets with a median variability of 0 54 and 0 57 respectively comparing unadjusted and adjusted gsmap and imerg products shows that the gauge correction has improved the kge from a median of 0 11 and 0 14 to 0 16 and 0 33 for gsmap and imerg respectively this improvement has been achieved through improving bias from a median of 1 75 and 1 43 to 1 05 and 1 17 and improving correlation from a median of 0 35 and 0 41 to 0 37 and 0 48 for gsmap and imerg respectively however the adjustment using gauge values has worsened variability from a median of 1 01 and 0 89 to 1 07 and 0 87 for gsmap and imerg respectively moreover the gauge adjustment enhanced all kge s components related to trmm whereas it has no significant influence on the persiann family fig 10 demonstrates kges for four precipitation intensity categories the highest kges are obtained when all intensities are considered in the assessment for each dataset the length of the interquartile range varies among the different categories of precipitation intensity for example for era5 the kge values with a median of 0 33 vary 0 96 0 77 for all intensities whereas vary within 7 15 0 23 6 35 0 43 6 15 0 46 7 07 0 37 with a median of 1 89 2 96 2 5 and 0 58 for precipitation category below 5 mm between 5 and 10 mm between 5 and 20 mm and larger than 20 mm respectively we have plotted different components of kges for each precipitation intensity category figs s4 s6 from fig s4 generally the correlation for class all is controlled by correlation in the class below 5 mm it means that dry days or wet days with tiny rainfall events have a major impact on the correlation in class all correlation between observed precipitation and precipitation datasets are roughly comparable the results suggest that the correlation cannot be a leading factor in the varying kge pattern observed for various intensity classes moreover fig s5 presents a very large overestimation generally a rbais more than 2 for the class below 5 mm and an underestimation less than near and larger than 0 5 is seen for classes 5 10 mm 10 20 mm and above 20 mm respectively it exposes that some errors such as underestimation overestimation can be downgraded when dealing with the entire time series therefore applying individual events from the datasets for a given goal leads to more errors than the whole time series fig s6 hints at the dataset s markedly poor performance in representing precipitation variability for classes above 5 mm the median of the variability of precipitation data retrieved from datasets is nearly eight times higher than in situ data for classes 5 10 and 10 20 mm and about four times for class larger than 20 mm while it is near one for the class below 5 mm to evaluate the datasets skill in precipitation event detection we have plotted the spatial distribution of hss in fig 11 from 2014 through 2018 from fig 11 hss values does not go greater than 0 8 however cpc and persiann pdir generally show an acceptable performance with a median hss equal to 0 63 and 0 53 respectively rpps show a similar pattern of hss varying from above 0 4 over the zagros mountains to above 0 2 over the rest of the country assessing the effect of gauge adjustment shows no significant improvement in trmm and gsmap in terms of hss however imerg enjoys a slight improvement mostly over the zagros mountains somehow its median hss from 0 37 reaches 0 41 after adjustment the spatial pattern of hsss related to cmorph crt and cmorph bld indicate that in most stations their hss values vary between 0 and 0 2 particularly over the alborz mountains and south of the caspian sea suggesting that these products have no skill to detect the precipitation events and even roughly in half of the area their performance is comparable with a random estimation 5 3 2 part b pixel to pixel approach 2003 2010 this section evaluated 34 precipitation datasets from 2003 to 2010 due to a sufficient number of stations with proper spatial distribution we considered a pixel to pixel approach for this period at the same time we have provided the point to pixel metric values for comparison the values of assessment metrics were presented in table 6 where the numbers in parentheses are related to the point to pixel approach regarding kge era interim kge 0 71 gpcp kge 0 70 and wfdei gpcc kge 0 69 outperform others at daily time scale followed by agmerra kge 0 64 era5 kge 0 63 and imerg final kge 0 57 gsmap mvk with a kge of 0 57 performed worse than the other products mainly due to a large variability ratio 2 32 and low correlation 0 14 a comparison between spps and rpps shows that most rpps are superior to both sps and gsps similar to the period 2014 2018 cpc hss 0 61 is the best dataset in detecting precipitation events followed by persiann pdir gpcc and mswep a comparison between the two approaches suggests a pattern similar to the monthly scale i e a slight difference in bias and more differences in other metrics for instance cpc trmm3b42 rt persiann cdr and era5 have a kge of 0 52 0 26 0 43 and 0 63 from pixel to pixel approach while these values turn to 0 48 0 20 0 25 0 35 with a point to pixel approach respectively rmse values systematically reduce when a pixel to pixel approach is considered and at the same time the random error percentage increases a non negligible improvement in hss values is also evident in most cases for example era5 s hss from 0 43 based on the point to pixel approach reaches 0 56 when the pixel to pixel approach is used it shows that the error associated with the evaluation approach is not a trifling matter nevertheless the ranking of the datasets remains unchanged fig 12 shows the spatial distribution of the kge metric based on a pixel to pixel approach within 2003 2010 as it has been stated in the subsection most of the mid central of the country is ungauged therefore interpolation in this area is prone to error thus to have a more realistic evaluation we have ignored this region in our assessment however the poor performance of perdiann ccs in the central and east of iran is not an issue that should be ignored generally reanalysis products outperform satellite based products practically after gauge adjustment era5 era interim and wfdei gpcc with a median kge equal to 0 46 0 45 and 0 52 respectively perform even better than cpc as a gauge based product with a median kge equals 0 35 similar to the period 2014 2018 we observed all datasets best performances over the west regions climate properties and precipitation regimes e g less contribution of orographic precipitation compared to the south of the caspian sea and more contribution of stations in the west of iran in datasets development could be the possible reasons for this superiority the gauge adjustment generally improved the performance of the datasets concerning the kge for example there is a clear improvement in kge values from persiann ccs with a median kge of 0 32 to 0 15 for persiann ccs cdr fig 13 illustrates kges and their components for daily data in 2003 2010 based on the pixel to pixel approach considering eq 1 and the median of correlation bias and variability ratio it can be concluded that datasets are worse in terms of correlation followed by variability generally the median of cc is below 0 6 with the exception for cpc agmerra era interim era5 gpcp gpcp1dd mswep wfdei cru and wfdei gpcc with a median below 0 7 specifying at least 0 4 difference from its optimum value while this difference generally is less than 0 2 and 0 3 for bias and variability ratio respectively we have also plotted kge and its components for daily data based on a point to pixel approach fig s7 it is interesting to see that correlation gets worse in the point to pixel evaluation while an improvement is seen in variability ratio it means that the interpolation helps to estimate the behavior of precipitation with better accuracy however at the same time the precipitation variability within a pixel gets worse variability of observed data decreased compared with point to pixel approach more likely due to effects of precipitation events in the neighboring pixels or occurrence of precipitation only in some stations and no rain in some others within a given pixel it should be noted that the pattern of kges in different precipitation categories was similar to the point to pixel approach fig 10 therefore we do not repeat it here and put it in the supplementary material fig s8 due to differences in the evaluation period the results of two periods are not entirely comparable but still when we compare results of the point to pixel approach for the period 2014 2018 with the pixel to pixel evaluation for the period 2003 2010 there is a marked difference in the performance of the datasets in the class below 5 mm in terms of bias and variability bias reduced significantly when a pixel to pixel is used compare figs s5 and s10 at the same time the variability gets worse compare figs s6 and s11 in classes above 5 mm there are no noteworthy differences between the two approaches fig 14 shows the spatial distribution of hss for different datasets considering the period 2003 2010 the general pattern is similar to fig 11 but here we have included more datasets in the evaluation generally reanalysis products have better hss values in comparison to satellite products among reanalysis products era interim era5 wfdei cru wfdei gpcc and mswep outperform others among satellite products only persiann pdir with a median hss equals 0 60 has an aptitude to detect precipitation events same as fig 11 the spatial distributions of hss values for cmorph crt and cmorph bld indicate a very weak skill in precipitation event detection in most areas below 0 2 gauge adjustment improved all datasets skills except for chirp where the median hss reduces from 0 46 for chirp to 0 31 for chirps after gauge adjustment generally gpcp and cpc have their best skills over the west of iran whereas persiann pdir works better across other parts 6 discussion in this study we have carried out a comprehensive analysis to evaluate the reliability of the 44 precipitation products at the monthly scale and 34 precipitation products at the daily scale over iran based on the calculated metrics see table 4 and fig 6 generally bias is the primary source of error in the datasets at a monthly scale these results support the findings of satgé et al 2020 who compared 23 gridded precipitation datasets over west africa they stated that bias is the dominant factor that affects the kge score some other studies e g adam and lettenmaier 2003 habib et al 2013 and ahmadebrahimpour et al 2019 reported similar results the results could be different when the evaluation is conducted on a shorter time scale e g daily in this context beck et al 2019a who evaluated 26 precipitation datasets on a daily scale across the continental united states conus found that datasets performed considerably worse in terms of correlation than bias and variability this finding indicates that a change in the assessment time scale might change a given dataset s error characteristic our findings also show the same pattern when the entire time series is considered somehow the median correlation is generally 0 4 less than its optimum values compared with 0 3 and 0 2 for variability and bias respectively see figs 9 13 and tables 5 6 however our analysis reveals that this pattern is not persistent in all precipitation classes indeed datasets are considerably worse in terms of variability than correlation at the daily time scale if we evaluate different precipitation intensities separately see figs s7 s11 therefore it seems that some errors would be underestimated when we deal with the whole time series in line with our results hosseini moghari and tang 2020 reported that the errors in spps are heavily related to precipitation intensity it s worth mentioning that another source of error could be the temporal inconsistency between local and coordinated universal time utc which can reduce the validity of daily assessments satgé et al 2020 our results reveal that among 44 investigated gridded precipitation datasets at a monthly scale gpcc gpcp and wfdei gpcc outperform other datasets see table 4 it is noteworthy that due to the low spatial resolution of gpcp our findings should not be generalized for small areas gpcc outperforms other gpps the reason behind this superiority can be related to a large number of in situ observations that have been contributed to developing the gpcc dataset compared with other gpps sun et al 2018 krakauer et al 2019 in agreement with our results basheer and elagib 2019 fallah et al 2020 salman et al 2019 ahmed et al 2019 satgé et al 2020 and dahri et al 2020 reported that gpcc outperforms other studied datasets across south sudan southwestern iran iraq pakistan west africa and the indus basin respectively on a daily scale from 2014 through 2018 with respect to kge cpc as a gpp works better than others while within 2003 2010 three datasets namely era interim gpcc and wfdei gpcc outperform others see tables 5 and 6 as well as figs 8 and 12 this performance is unexpected for era interim as a model based product the reason that era interim performs worse in the period 2014 2018 can be traced in the regions with lower densities of stations see figs 1 8 and 12 moreover reanalysis products are inherently spatial so a pixel to pixel evaluation would better represent their performance in line with these results li et al 2018 showed the superiority of era interim over many spps across the tibetan plateau however contrary to our results chen et al 2018 stated that spps outperform rpps so that the era interim is unreliable due to large overestimations over the mekong river xu et al 2020 show that rpps perform better than spps over north america europe and australia while they did not report any era interim superiority over other rpps therefore it can be confirmed that the dataset performance varies from one area to the other and depends on the precipitation type topography and climatic factors as reported by seyyedi et al 2015 our results indicate that systematic error plays a significant role in the total error observed in datasets precl persiann cmorph raw and merra land at the monthly time scale and datasets persiann and cmorph raw at a daily scale a high systematic error rate highlights the need to use the bias removal techniques before integrating the datasets in any application prakash 2019 a comparison between two versions on ncep shows a slight improvement in ncep 2 compared to ncep 1 in estimating precipitation over iran besides the higher spatial resolution however the reliability of ncep 2 needs to be developed over regions like iran our finding has aligned the study conducted by ma et al 2009 over china we found that the persiann family datasets perform differently from a considerable underestimation in persiann to a large overestimation in persiann ccs tables 4 and 6 the persiann ccs overestimation is also reported over the conus however globally persiann cdr estimates precipitation more than persiann ccs see table 3 and fig 8 in nguyen et al 2018 however the better performance of persiann cdr infers the importance of gauge adjustment to improve satellite observation that was reported for other spps over the conus beck et al 2019a and west africa satgé et al 2020 the most exciting issue about the persiann family products is the remarkable performance of persiann pdir as a satellite based product persiann pdir performs better than persiann cdr and persiann ccs cdr as gauge corrected persiann family members in most regions particularly in detecting precipitation events given that this database has just been introduced there is no study on its evaluation however we found that persiann pdir performs better over iran than the conus based on the comparison of our results with the evaluations conducted by nguyen et al 2020 almost all datasets underestimate the amount and overestimate the variability of precipitation in regions with an annual rainfall of more than 500 mm see fig 7 and fig s2 in iran the annual precipitation above 500 mm usually can be seen in the south of the caspian sea and in high altitude areas where the number of gauges is quite limited according to fig 5 poor performances are observed mainly in the southern caspian sea regions since the primary rainfall regime in this region is orographic katiraie boroujerdy et al 2013 spps and rpps could not capture the precipitation well under this circumstance zhou et al 2019 wang et al 2019 due to the small number of stations that contributed to the development of gpps they also underestimate the amount of precipitation in this region hosseini moghari et al 2018 all products perform better at the monthly time scale as expected particularly gauge corrected products the reason for such a finding can be traced back to the fact that some daily datasets are adjusted only monthly moreover the mismatch in reporting times of data in global products and in situ is more critical at a daily scale beck et al 2019a satgé et al 2020 a comparison between satellite based products and reanalysis ones reveals that the skill of non adjusted reanalysis products in detecting precipitation events is higher than both the non adjusted and adjusted satellite products with the exception for persiann pdir due to the limited number of overpasses it is possible that the satellite does not capture short precipitation events tian et al 2009 resulted in a lower hss value comparing adjusted and non adjusted spps and rpps suggests that gauge adjustment helps enhance their performance in precipitation events detection but not very sharp indeed the gauge correction adjusts the precipitation volume not the occurrence of precipitation gosset et al 2013 as a result the amount of precipitation might be sited to zero during the gauge adjustment and the rate of false alarm would be reduced while the probability of detection almost remains constant hosseini moghari and tang 2020 many studies e g rivera et al 2018 xu et al 2017 darand and khandu 2020 peng et al 2020 used a point to pixel approach for evaluating global precipitation datasets however our findings show that a point to pixel approach undervalues the gridded dataset s capability in a non negligible way see tables 4 and 6 islam 2018 argued that we could deal with the errors associated with the miss representativeness of a point to pixel approach considering more than three years our results cannot approve this claim since we considered eight years 2003 2010 in our analysis yet a pixel to pixel approach performs significantly better than the point to pixel approach nevertheless database ranking is the same based on two approaches therefore both approaches can be used interchangeably for ranking the datasets regardless of evaluation metrics values although we already introduced some datasets as the best they cannot be employed in all applications indeed different precipitation products would be suitable for specific applications the spatiotemporal resolution spatial coverage temporal span and time delays confine our choices therefore based on our findings and considering the need for different applications we have recommended datasets over iran for both monthly and daily time scales to this end we introduce the best datasets in four categories as follow 1 long term daily datasets that can be operated for analysis of rainfall frequency in infrastructure design and climate change studies 2 long term monthly datasets with the application for drought monitoring trend analysis data gap filling and reconstructing historical streamflow 3 near real time daily datasets in purpose to be utilized for flood forecasting reservoir operations and irrigation management 4 near real time monthly datasets that can be employed for near real time drought monitoring and reservoir operations to rank the datasets in each category we have regarded their kge values moreover we considered a minimum period of 30 and 10 years as long term data for monthly and daily scales respectively the datasets with spatial resolution coarser than half degree are excluded from our assessment as coarse resolution datasets usually are not applicable for iran s basin size fig 15 shows the best datasets based on the mentioned classes in each river basin of iran from the figure gpcc in most cases is the best dataset for long term daily and monthly scales for the near real time monthly time scale in most basins era5 is the best dataset followed by imerg final while at a daily scale cpc outperforms other datasets it is worth mentioning that the persiann pdir is almost a real time product and is the best across all basins so we did not plot it in fig 15 however if the latency matters the first option would be persiann pdir tables s1 s4 illustrate the best reanalysis satellite based and gauge based datasets for each basin 7 summary and conclusions we have conducted a comprehensive evaluation of 44 precipitation datasets at the monthly time scale and 34 daily precipitation datasets over iran we have chosen the period from 2003 to 2010 to include all datasets within 2003 2010 a network of more than 1500 rain gauges is used as the reference to include gpm based products in our evaluation we also consider the period 2014 2018 for daily assessments with fewer datasets i e 25 datasets since the spatial resolutions among datasets varies from 0 04 to 2 5 for the period of 2003 2010 the in situ data were interpolated to the identical spatial resolution of global datasets using the ordinary kriging method the findings of this study can be summarized as follow almost all gauge based precipitation products gpps and gauge adjusted products can map the spatial distribution of annual precipitation however in general unadjusted products such as persiann ccs perform poorly in this regard therefore unadjusted products are not reliable for water balancing studies or creating climate zoning maps in terms of kge on a monthly scale gpcc persiann pdir gpcp era interim wfdei gpcc and merra 2 are the best gauge based precipitation products gpps satellite based precipitation products sps gauge corrected satellite based precipitation products gsps reanalysis products rps gauge corrected reanalysis products grps and gauge corrected satellite and reanalysis products gsrps respectively however the rankings of datasets can vary between different basins in terms of kge on a daily scale era interim gpcp and wfdei gpcc shows the best performance followed by agmerra era5 and imerg final moreover all datasets estimate precipitation with insufficient accuracy for precipitation intensities above 5 mm day regarding the individual components of the kge metric datasets are worse in terms of bias at monthly time scales and correlation at daily time scales our analysis reveals a substantial disagreement between products within persiann family the quality of precipitation estimation ranges from a considerable underestimation of 0 39 for persiann to an overestimation of 0 68 for persiann ccs however the new member of this family i e persian pdir performs remarkably well as a non adjusted real time satellite based product a comparison between the gpm based products i e imerg and gsmap shows that imerg products perform better than gsmaps particularly after gauge adjustment also comparing non adjusted imerg and trmm products within 2003 2010 reveals that in general the imerg algorithm works slightly better and after gauge adjustment imerg is clearly superior to trmm assessing the datasets ability in detecting precipitation events illustrates that gauge products as expected outperform other product types the reanalysis products have a better skill in detecting precipitation events than satellite based products except persiann pdir persian pdir with an hss of 0 60 works as perfectly as gauge based products we found that an evaluation based on the point to pixel approach understates datasets skill compared to the pixel to pixel approach however the ranking of datasets remains the same in both approaches the results of this study can be used as a guide to decide which precipitation dataset should be used for a particular application a small portion of the rain gauges in iran has been incorporated in gauge based satellite based or reanalysis gridded precipitation products moreover the contribution of these in situ measurements is always delayed by one to several months highlights the importance of satellite based precipitation products especially for near real time applications this study represents an unprecedented evaluation of almost all available satellite based products over iran discussing their strengths weaknesses and spatiotemporal discrepancies previous studies highlighted the discrepancy in the comparisons between precipitation estimates from region to region beck et al 2019a sun et al 2018 our findings only pertain to the iranian basins and are not necessarily transferable to other regions author contributions peyman saemian and seyed mohammad hosseini moghari designed the study peyman saemian led the calculation and wrote the initial draft of the paper together with seyed mohammad hosseini moghari iman fatehi vahid shoarinezhad and ehsan modiri prepared the quality controlled in situ data and commented on the initial draft andrás bárdossy conducted the interpolation of in situ data mohammad j tourian qiuhong tang wolfgang nowak andrás bárdossy and nico sneeuw commented on the draft and contributed in analysing all authors reviewed the manuscript and contributed to the final manuscript version declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors are grateful to the product developers for providing the precipitation datasets peyman saemian iman fatehi vahid shoarinezhad and ehsan modiri acknowledge the sustainable water management nawam program from the federal ministry of education and research bmbf and the german academic exchange service daad for the support for their phd grant seyed mohammad hosseini moghari thanks the chinese academy of sciences president s international fellowship initiative grant no 2019vea0019 qiuhong tang acknowledges the national natural science foundation of china 41790424 41730645 and the international partnership program of chinese academy of sciences grant no 131a11kysb20170113 appendix a glossary of precipitation datasets dataset full name gauge based products cru climatic research unit gpcc global precipitation climatology centre prec l precipitation reconstruction over land udel university of delaware cpc climate prediction center satellite based products persiann precipitation estimation from remotely sensed information using artificial neural networks persiann ccs precipitation estimation from remotely sensed information using artificial neural networks cloud classification system persiann pdir precipitation estimation from remotely sensed information using artificial neural networks dynamic infrared rain rate near real time trmm 3b42 rt tropical rainfall measuring mission 3b42 real time gsmap mvk global satellite mapping of precipitation moving vector with kalman filter gsmap nrt global satellite mapping of precipitation near real time gsmap rnl global satellite mapping of precipitation near real time cmorph raw climate prediction center morphing technique raw imerg early integrated multi satellite retrievals early persiann cdr precipitation estimation from remotely sensed information using artificial neural networks climate data record persiann ccs cdr precipitation estimation from remotely sensed information using artificial neural networks cloud classification system climate data record gpcp global precipitation climatology project gpcp1dd gpcp one degree daily cmap cpc merged analysis of precipitation trmm 3b42 adj tropical rainfall measuring mission 3b42 adjusted trmm 3b43 tropical rainfall measuring mission 3b43 cmorph bld climate prediction center morphing technique bld cmorph cdr climate prediction center morphing technique cdr cmorph crt climate prediction center morphing technique crt gsmap gauge global satellite mapping of precipitation gauge imerg final integrated multi satellite retrievals final reanalysis products ncep1 national centers for environmental prediction 1 ncep2 national centers for environmental prediction 2 era interim european centre for medium range weather forecasts reanalysis systems interim era5 european centre for medium range weather forecasts reanalysis systems 5 cfsr climate forest system reanalysis system 20crv3 twentieth century reanalysis system version 03 jra 55 japanese 55 year reanalysis agcfsr agricultural model cfsr pgf princeton global forcing wfdei water and global change applied to era interim wfdei cru water and global change applied to era interim cru wfdei gpcc water and global change applied to era interim gpcc chirp climate hazards group infrared precipitation chirps climate hazards group infrared precipitation with station data mswep multi source weighted ensemble precipitation merra 2 modern era retrospective analysis for research and applications 2 merra land modern era retrospective analysis for research and applications land agmerra agricultural model merra appendix b supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2021 127054 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
3950,global gridded precipitation datasets have been developed using rain gauges satellite observations and data assimilation techniques to fulfill the need in regions with a limited contribution of ground observations like iran this study presents a comprehensive evaluation of currently available precipitation datasets over iran at monthly 44 datasets and daily 34 datasets time scales to include the maximum number of datasets and in situ data we consider two periods for the evaluations namely 2003 2010 for the daily and monthly assessment and 2014 2018 for the daily for the assessment a network of more than 1500 rain gauges is utilized within 2003 2010 and 370 rain gauges within 2014 2018 moreover we compare the pixel to pixel interpolated in situ data v s gridded datasets and point to pixel in situ data as a point v s gridded datasets approaches in assessing datasets performances in terms of the kling gupta efficiency kge parameters the datasets perform worse in bias at monthly time scales and correlation at daily time scales however considering in situ precipitation above 5 mm day all datasets perform poorly in estimating precipitation variability we find that in general reanalysis products have a higher kge ranging between 0 41 0 21 and 0 91 0 71 than satellite based products with a kge ranging from 0 14 0 57 to 0 92 0 57 over iran at monthly daily scale moreover gpcc overall matches the validation dataset better than other products over iran s basins whereas cpc era5 and imerg final are more suitable for near real time studies also if latency is a top criterion persiann pdir will be the first option indeed persiann pdir with a kge value of 0 69 0 33 at monthly daily time scale within 2003 2010 performs remarkably well as a non adjusted real time satellite based product the comparison between the point to pixel and the pixel to pixel approaches shows that the point to pixel approach underestimates the quality of the datasets but does not change the ranking of the datasets keywords gauge based products reanalysis products satellite observations statistical evaluation point to pixel approach pixel to pixel approach 1 introduction precipitation drives the water cycle and plays a significant role in the atmospheric circulation kidd and huffman 2011 trenberth et al 2003 it plays a substantial part in research and planning with a wide range of applications e g drought analysis and identification flood prediction and protection hydrological modeling water resources management agriculture and urban planning ebert et al 2007 sorooshian et al 2011 therefore the accuracy of precipitation data directly affects the validity of water resources planning and management projects sharifi et al 2012 xu et al 2016 although the most accurate precipitation data can be obtained from in situ data the network of such stations is sparse in many regions due to geographical topographical and economic constraints su et al 2008 xu et al 2016 faridzad et al 2018 especially in developing countries recently many gridded precipitation datasets have been developed to meet the need for the applications mentioned above these datasets provide the precipitation data with various spatio temporal resolutions from the regional to the global scale they are developed from different sources 1 in situ measurements 2 remote sensing data 3 outputs of numerical models and 4 in some cases as a combination of them using data assimilation techniques hosseini moghari et al 2018 sun et al 2018 the four mentioned types of gridded datasets are commonly used by researchers mainly due to their availability ability to mimic point scale measurements and constant spatio temporal resolution raimonet et al 2017 it is expected to see that gauge based datasets show better performance than satellite based and model based products in regions with adequate and extensive gauge data however unlike gauge based datasets satellite based and model based datasets are almost real time making them suitable for operational applications cavalcante et al 2020 moreover a well performed satellite or a model based product can be adjusted by the gauge data resulting in an enhanced product using the positive features of each dataset adler et al 2001 bui et al 2019 chen et al 2020 although gridded precipitation datasets inherently show lower accuracy compared to in situ data some reports have indicated their considerable potential to be applied in different climatic and water related studies e g scheel et al 2011 poméon et al 2017 salman et al 2019 eghdami and barros 2019 the performance of global gridded precipitation datasets varies in different parts of the world which necessitates the evaluation of their performance before operational applications camici et al 2018 so far many studies have assessed the performance of different datasets at the global or regional scale e g ahmed et al 2019 prakash 2019 hua et al 2019 lorenz and kunstmann 2012 several studies evaluated the validity of the global datasets for different applications e g drought monitoring aghakouchak and nakhjiri 2012 ahmadebrahimpour et al 2019 zhong et al 2019 golian et al 2019 liu et al 2020 trend analysis lin et al 2014 ashouri et al 2016a balling et al 2016 zhan et al 2018 toride et al 2018 stream flow simulation ashouri et al 2016b yuan et al 2017 su et al 2017 nhi et al 2019 try et al 2020 lorenz et al 2014 and flood modeling nanda et al 2016 tekeli and fouli 2016 anagnostou and mei 2018 yuan et al 2019 employing global datasets is an opportunity to eliminate limitations arising from a lack of ground measurements which demands evaluating and validating gridded precipitation datasets against available observed data despite a broad range of investigations no specific type of precipitation dataset has been considered as the most valid one in all regions rajulapati et al 2020 therefore more comprehensive evaluations should be conducted for each area separately since gathering a sufficiently dense network of in situ data for the whole globe is nearly impossible the best way for doing these evaluations is to do it at a regional scale i e on a country scale or basin scale several studies have assessed global precipitation datasets over iran e g javanmard et al 2010 katiraie boroujerdy et al 2013 khalili and rahimi 2014 shokoohi and morovati 2015 katiraie boroujerdy et al 2016 moazami et al 2016 darand et al 2017 dezfooli et al 2018 hosseini moghari et al 2018 hosseini moghari and tang 2020 saemian et al 2020 ghozat et al 2020 darand and khandu 2020 however the literature lacks a comprehensive assessment each of these studies has only considered one or a few datasets for evaluations moreover in situ data and the periods of evaluation are different in all those studies therefore it would be even challenging to compare or combine their results to fill this gap in the current paper we comprehensively assess the performance of 44 global gridded datasets across iran using a dense network of precipitation gauges our assessments include both daily 34 datesets and monthly 44 datasets scales in this study persiann pdir 20crv2 nceps and merra 2 are assessed for the first time over iran we also compared the pixel to pixel interpolated in situ data v s gridded datasets and point to pixel in situ data as a point v s gridded datasets approaches for evaluating global precipitation datasets the finding would be beneficial at least for two groups of users first for the institutes in charge of dataset development they would be able to document the error characteristics of datasets in each region and improve the datasets accuracy in the next version second for users who employ global precipitation as forcing in hydrological modeling or input for other applications either on the regional or global scale considering the number of datasets to the best of our knowledge this is the most comprehensive evaluation of precipitation datasets both regionally and globally 2 study area iran is located in the middle east 25 40 n latitude 44 64 e longitude covering an area of 1 648 195 km 2 see fig 1 two major mountain ranges are located in the country namely the alborz along with the northwest to northeast and the zagros along with the northwest to the southwest the most important water bodies of the country are the caspian sea the biggest lake in the world in the north the persian gulf and the gulf of oman in the south and lake urmia in the northwestern the central part of the country is covered by two large deserts namely the lut and kavir deserts although iran is located in the subtropical high pressure belt of the earth different topographical regions with an elevation range from 25 m to 5600 m result in the presence of diverse climates generally the climate of the country is arid 64 and semi arid 20 khalili and rahimi 2018 humid climate covers only 10 of the country mainly the regions close to the caspian sea and some close to the persian gulf and oman sea the temporal and spatial patterns of precipitation are very diverse due to the complex topography which leads to difficulties for measuring and estimating the spatio temporal distribution of precipitation zhang et al 2020 the annual mean precipitation of the country is less than 250 mm the country is divided into 6 primary basins including 30 sub basins areas the borders and id number of the sub basins are shown in fig 1 3 data 3 1 precipitation datasets we evaluated the performance of 44 34 gridded precipitation datasets at monthly daily time scale see table 1 the datasets are classified into the three main categories as gauge based precipitation products gpps satellite based precipitation products spps and reanalysis precipitation products rpps we included five datasets based only on gauge data referred as gpps in the paper cru gpcc precl udel and cpc nine datasets based on only satellite data referred as sps in the paper persiann persiann ccs persiann pdir trmm 3b42 rt gsmap mvk gsmap nrt gsmap rnl cmorph raw and imerg early and seven datasets fully based on re analysis referred as rps in the paper ncep 1 ncep 2 era interim era5 cfsr 20cr and jra 55 moreover we assessed twelve combined gauge and satellite datasets referred as gsps in the paper gpcp gpcp 1dd cmap persiann cdr persiann ccs cdr trmm 3b42 adj trmm 3b43 gsmap gauge cmorph cdr cmorph bld cmorph crt and imerg final five combined gauge and re analysis datasets referred as grps in the paper agcfsr pgf wfdei wfdei cru and wfdei gpcc and five combined gauge satellite and re analysis datasets referred as gsrps in the paper chirps mswep merra 2 agmerra merra land we also evaluated one dataset which is developed by using the combination of satellite and re analysis data chirp 3 2 in situ data the ministry of energy with more than 4360 stations and the iranian meteorological organization irimo with 433 stations are the primary centers for providing precipitation data over iran in this study the most updated available data from these two centers are collected at daily and monthly time scales it should be noted that the number of stations varies over time two time periods have been selected one from 2003 to 2010 and the other from 2014 to 2018 the former is chosen considering the intersection between all datasets and employing a more dense network of stations the latter is defined to consider mainly the gpm family imerg within 2003 2010 is produced based on trmm data as one of the most recent developed precipitation datasets see fig 2 considering the first time window we ended up with a network of 3130 precipitation stations see fig 1 c we controlled data from stations in terms of gaps coordinates and elevation after doing such a sieving test we had 1561 separate stations with continuous daily precipitation within the study period of 2003 2010 which then were used for the evaluation regarding the second period from 2014 to 2018 370 synoptic stations are obtained after conducting the same quality control checks due to the mismatch between point wise rain gauge data and gridded precipitation datasets it is common to up scale point wise data to the grids using an interpolation method many interpolation techniques have been proposed for precipitation data including the simple averaging xie and xiong 2011 the inverse distance weighting idw hu et al 2014 thiessen polygons liu et al 2015 and different kriging methods goovaerts 2000 lebrenz and bárdossy 2019 the interpolation methods performance depends on many factors including the rain gauge network structure and the topography of the study area hofstra et al 2008 in this study for the period 2003 2010 the ordinary kriging ok method wackernagel 2003 was applied at daily time steps in 11 different spatial resolutions to cover all employed precipitation datasets fig 3 it should be noted that we chose the ok method due to its considerable performance in modeling spatial variations of precipitation in iran javari 2017 here comparison based on interpolated data is called the pixel to pixel approach within 2014 2018 we used a point to pixel approach i e we assessed the datasets directly at the position of each rain gauge due to the lack of a dense network of stations 4 evaluation approach we considered several performance metrics to evaluate the temporal dynamics of the precipitation datasets against the in situ observations the equation and optimal value of each metrics are summarized in table 2 relative bias rbias as a bias indicator represents the degree of overall underestimation negative values or overestimation positive values of predictions to average the magnitude of the error we have used the root mean squared error rmse which is a negatively oriented score i e lower values show better result in comparison to rbias the rmse neutralizes the effect of negative pairwise discrepancies between estimated and observed values this means both negative and positive errors contribute to the overall error moreover rmse gives more importance to big errors by giving higher weights to them which is desirable when emphasizing extremes the pearson correlation coefficient is employed to measure the linear relationship between estimated and measured precipitation errors in estimating any variable can be divided into two components random error and systematic error random errors are unpredictable fluctuations in the estimated precipitation concerning the measured while systematic errors are predictable and reproducible inaccuracies that are consistently in the same direction in our evaluation we have quantified each of random and systematic errors at monthly and daily time scales similarity between the estimated values from datasets and observations can be quantified using model performance metrics like the nash sutcliffe efficiency nse nash and sutcliffe 1970 or the kling gupta efficiency kge gupta et al 2009 in this study we have calculated modified kge scores using the estimation from in situ observations and datasets estimation kling et al 2012 kge is an improved variant of the nse index by decomposing it into several components unlike nse the multi component nature of kge incorporates linear correlation bias and variability within a single objective function providing a more balanced model evaluation 1 kge 1 r 1 2 β 1 2 γ 1 2 where r is the pearson correlation coefficient optimum value 1 β is bias optimum value 1 and γ represents the variability ratio optimum value 1 as follow 2 r σ e o σ e σ o 3 β μ e μ o and γ σ e μ e σ o μ o where μ and σ are the mean standard deviations of the time series respectively the subscripts e and o indicate estimation and observation respectively the optimum value of kge is one categorical statistics can measure the precipitation datasets skill in detecting events at the daily time scale the heidke skill score hss as a categorical statistic quantifies each dataset s capacity compared to a random based prediction to calculate hss we have first detected the daily precipitation events as rainy or not rainy the threshold of 1 mm day is considered to distinguish rainy days considering the pre defined threshold four cases are possible as shown in the so called contingency table table 3 in this table a is called hit b is called false alarm type one error c is called false negative type two error and d is called correct rejection the hss is calculated for each dataset using the results from the contingency table and the following equation 4 hss 2 a d b c a c c d a b b d the hss scores range from to 1 in which the optimum value is one and negative scores indicate that a random based estimation performs better than the evaluated precipitation dataset it should be noted that for calculating the assessment metrics for the whole country we put all precipitation data from all pixels together and then calculated assessment metrics we followed this approach instead of averaging assessment metrics of all pixels to minimize the impact of arid and semi arid regions which are a large fraction on average of assessment metrics finally at monthly scale we divided the pixels into five classes based on their mean annual precipitation inspired by hosseini moghari et al 2018 as a proxy of climatic conditions i e less than 100 mm yr 100 200 mm yr 200 300 mm yr 300 500 mm yr and more than 500 mm yr for daily scale to assess the skill of the datasets in estimating different precipitation intensities we considered four intensity classes were inspired by hosseini moghari and tang 2020 i e less than 5 mm day 5 10 mm day 10 20 mm day and above 20 mm day 5 result 5 1 intercomparison of annual precipitation estimates 2003 2010 this part presents a general overview of datasets performance fig 4 exhibits the spatial distribution of mean annual precipitation retrieved from in situ data and studied datasets from 2003 to 2010 recall that in situ data in this period are interpolated by ordinary kriging based on interpolated in situ data fig 4 top left the country receives a significant portion of its precipitation over the southwest of the caspian sea and along the zagros mountains the mean annual precipitation varies from 1800 mm in the southwest of the caspian sea to less than 50 mm in central part as expected gpps and gauge corrected datasets generally outperform other datasets in estimating the mean annual precipitation s spatial distribution this becomes apparent when comparing in situ data in the top left with all other maps in fig 4 the highest correlation is obtained for gpcc cc 0 96 followed by wfde gpcc cc 0 94 trmm 3b43 cc 0 91 imerg final cc 0 91 and agcfsr cc 0 89 among sps and gsp persiann pdir and imerg final excel at estimating the spatial distribution of the annual precipitation persiann and persiann ccs with an underestimation rbias 0 39 and overestimation rbias 0 68 respectively do not present any specific pattern it is difficult to reach a fair judgment about the spatial performance of cmap gpcp ncep1 ncep2 cfsr and 20cr datasets regarding the low spatial resolution however a general underestimation can be seen in nceps while the opposite is true for gpcp two high resolution products namely chirp and chirps can generally map the annual precipitation however both datasets significantly overestimated the precipitation in the caspian sea coastal areas and the alborz mountain range the same overestimation across the caspian sea coastal areas is observed in the era5 estimation 5 2 intercomparison of monthly precipitation estimates 2003 2010 this section evaluates the reliability of precipitation data of 44 datasets at the monthly scale table 4 presents the assessment metrics at a monthly scale although our focus here is on a pixel to pixel approach the assessment metrics were also calculated based on a point to pixel approach the numbers in parentheses from the table gauge corrected products show almost a similar performance compared to gpps and outperform satellite and reanalysis ones with respect to kge gpcc kge 0 91 persiann pdir kge 0 69 gpcp kge 0 92 era interim kge 0 85 wfdei gpcc kge 0 91 and merra 2 kge 0 80 are the best gpps sps gsps rps grps and gsrps datasets respectively although correlation values between in situ and sps data are generally less than other types of products they are still in an acceptable range the lowest value is equal to 0 32 for gsmap mvk in terms of rbias all gpps underestimate monthly precipitation from very low 0 01 for gpcc to relatively high 0 27 for cpc this underestimation can be explained by the fewer number of stations involved in the interpolation mostly in areas with lower annual precipitation this underestimation is also evident in grps except wfdei gpcc with a maximum rbias of 0 17 for pgf rbias of sps varies considerably from an underestimation of 0 39 for persiann to an overestimation of 0 68 for persiann ccs such a variation can also be seen in gsps rps and gsrps with a lower amplitude ranging from 0 23 for cmap to 0 21 for persiann ccs cdr 0 28 for ncep1 to 0 27 for jra 55 and 0 27 for merra land to 0 11 for chirps respectively the variability ratio indicates that the performance of the datasets does not follow any specific trend fourteen datasets have almost a similar variability compared with in situ data variability ratio between 0 95 to 1 05 while 14 and 16 datasets have lower and higher variability than the observations respectively for instance precl persiann ccs and chirp with a variability ratio equal to 0 81 0 83 and 0 89 respectively have less variability than observed data in contrast gsmap mvk ncep1 and cmorph raw with variability ratio values equal to 1 68 1 42 and 1 13 respectively have more variability three datasets including persiann ccs gsmap mvk and gsmap nrt have high rmse more than 40 mm month therefore due to their large random error values it is unlikely that they can represent in situ data even after applying an accurate conventional bias correction gpcp and gpcc have the best performance among all studied datasets at a monthly scale followed by wfdei gpcc considering their low rbias 0 02 and 0 01 high correlation coefficient 0 92 and 0 94 high kge 0 92 and 0 91 and low rmse 11 6 and 11 5 mm month a comparison between the pixel to pixel approach and the point to pixel approach at a monthly scale suggests generally datasets show better performance when the pixel to pixel approach is considered for instance the kge of gpcc based on the point to pixel approach is 13 less than kge from the pixel to pixel approach among kge components correlation and variability ratio is more sensitive than bias to the approach of evaluation the average correlation bias and variability ratio of all datasets are 0 74 0 98 and 1 03 in the pixel to pixel approach while reaching 0 62 0 98 and 0 87 in the point to pixel approach respectively this finding implies that the total precipitation may not change significantly in different evaluation approaches while the time series behavior would be affected the rmse is higher for the point to pixel approach in most cases up to more than 50 for example the era5 s rmse increase from 19 9 to 30 7 mm month when the point to pixel approach was used instead of pixel to pixel overestimating the systematic error rate is also evident in the point to pixel approach comparing the mean of systematic error in point to pixel approach as 39 with 22 in the pixel to pixel approach despite distinct values for the assessment metrics the evaluation approach from pixel to pixel to point to pixel does not change the datasets ranking fig 5 demonstrates the spatial distribution of the kge between the observed dataset and the precipitation datasets at a monthly scale most datasets perform better over the west and along the zagros mountains imerg early performs the worst in the south while persiann ccs has the worst performance in other regions among the persiann family persiann cdr is the best dataset with a median of kge equals 0 75 especially in the east adjusted datasets almost have a similar pattern to gpcc and cru and in some areas even perform better than gpps among gpps precl performs the worst more likely due to the limited contribution of iran s in situ data in its development gpcc and imerg final with a median of kge equal to 0 80 outperform other datasets among all other datasets cru udel trmm3b42 trmm3b43 gpcp persiann cdr era5 agcfsr pgf wfdei wfdei cru wfdei gpcc mswep merra 2 agmerra and chirps have considerable performance with a median of kge no less than 0 67 it s worth noting that the datasets performance over the central regions of iran should not be over interpreted due to the lack of rain gauges in these regions cf fig 1 c fig 6 presents the box plot of the kge for each dataset in different annual precipitation categories see section 4 based on the results shown in this figure most datasets perform better in the regions with the annual precipitation below 100 mm except low spatial resolution datasets namely ncep1 ncep 2 gpcp and cmap see table 1 generally the kge values decrease slightly with an increase in annual precipitation since arid climate possesses a vast area of the country the performance of the datasets among regions with annual precipitation below 300 mm is more crucial considering regions with annual precipitation below 300 mm persiann ccs has the worst performance for categories 300 500 mm and above 500 mm ncep1 and persiann have the worst performance respectively although gpcp gpcp1d gpcc and imerg final perform better than others in class all their performances in other classes are not the best cru imergv6 final and pgf persiann cdr gpcp gpcp1d and imerg final imerg final and gpcp imerg final and gpcc are the best dataset in classes below 100 100 200 200 300 300 500 and above 500 mm respectively the length of the box plots is minimum in the class below 100 mm which indicates the changes in the given dataset s performance are low within the pixels with annual precipitation below 100 mm considering the median of kge the performance of the datasets varies in different annual precipitation classes fig 7 shows box plots of kges in different pixels along with decomposed kge values into their components at a monthly scale from 2003 to 2010 generally the medians of bias is about 0 25 away from their optimum values while this difference is about 0 2 and 0 1 for correlation and variability ratio respectively because of the squaring of these components in the kge generally the variability ratio plays a negligible role in kge values compared to bias and correlation however some datasets like ncep1 perform worse in terms of the variability ratio than correlation inspecting kge s components for different precipitation classes see figs s1 s3 indicate that the kge values in the class below 100 mm enjoy a large correlation in this class almost all datasets tend to underestimate the precipitation in the class above 500 mm while a fluctuation between underestimation and overestimation is seen in other classes the underestimation in the class above 500 mm is mainly due to underestimating the precipitation in the southwest of the caspian sea see fig 4 changes in the variability ratio between the classes are less than correlation and bias however most datasets particularly in the class above 500 mm tend to show more variation than in situ data 5 3 intercomparison of daily precipitation estimates 5 3 1 part a point to pixel approach 2014 2018 this section evaluates the 25 most up to date datasets covering the period from 2014 to 2018 the point to pixel approach is considered due to the limited numbers of rain gauges for this period fig 1 d table 5 shows the assessment metric values at the daily time scale cpc with a kge value of 0 45 outperforms other datasets trmm3b42 adj gsmap gauge cmorph bld cmorph cdr and cmorph crt have almost the same or even better bias and variability ratio as cpc however their kges are below 0 27 mainly due to lower correlation a comparison between the persiann family shows gauge that adjustment has not enhanced the performance within 2014 2018 conversely the gauge correction has increased gpm based products particularly gsmap i e increasing kge from 0 08 to 0 27 mainly through bias improvement cf table 5 inspecting systematic and random errors reveals that a significant part of the error is related to systematic error in most of the datasets suggesting a need for further improvement in their development algorithms only two datasets i e cpc and persiann pdir have hss above 0 5 indicating a mediocre performance in detecting precipitation events in almost all datasets it is noteworthy to mention that this performance is remarkable for persiann pdir as a satellite based dataset without any gauge adjustments cmorph bld and cmorph crt with the hss below 0 14 show a weak skill in detecting precipitation events in comparison with a random based prediction fig 8 illustrates the spatial distribution of the kge at rain gauges for the precipitation datasets within 2014 2018 generally the best performance of all datasets is observed over the zagros mountains cpc and imerg final with a median kge equal to 0 55 and 0 33 respectively outperform other datasets in most areas even after gauge adjustment almost all satellite based products except imerg final have a poor performance with a median value below 0 30 in most stations all datasets of the persiann family have a poor ability to estimate the precipitation and among them persiann ccs is the worst with considerable negative kge in iran s central regions apart from some large negative kges over the alborz mountain range and northwest the era family shows a decent performance in estimating rainfall across the west of iran with the median kge of 0 33 and 0 28 for era5 and era interim respectively inspecting fig 9 which shows kge and its components based on daily data within 2014 2018 reveals that generally datasets are worse in terms of correlation than bias and variability however gsmap mvk gsmap nrt and persiann ccs suffer from a large bias with a median of 1 69 1 75 and 1 69 respectively many datasets have a variability less than the observations with the worst performance observed from the chirp and persiann cdr datasets with a median variability of 0 54 and 0 57 respectively comparing unadjusted and adjusted gsmap and imerg products shows that the gauge correction has improved the kge from a median of 0 11 and 0 14 to 0 16 and 0 33 for gsmap and imerg respectively this improvement has been achieved through improving bias from a median of 1 75 and 1 43 to 1 05 and 1 17 and improving correlation from a median of 0 35 and 0 41 to 0 37 and 0 48 for gsmap and imerg respectively however the adjustment using gauge values has worsened variability from a median of 1 01 and 0 89 to 1 07 and 0 87 for gsmap and imerg respectively moreover the gauge adjustment enhanced all kge s components related to trmm whereas it has no significant influence on the persiann family fig 10 demonstrates kges for four precipitation intensity categories the highest kges are obtained when all intensities are considered in the assessment for each dataset the length of the interquartile range varies among the different categories of precipitation intensity for example for era5 the kge values with a median of 0 33 vary 0 96 0 77 for all intensities whereas vary within 7 15 0 23 6 35 0 43 6 15 0 46 7 07 0 37 with a median of 1 89 2 96 2 5 and 0 58 for precipitation category below 5 mm between 5 and 10 mm between 5 and 20 mm and larger than 20 mm respectively we have plotted different components of kges for each precipitation intensity category figs s4 s6 from fig s4 generally the correlation for class all is controlled by correlation in the class below 5 mm it means that dry days or wet days with tiny rainfall events have a major impact on the correlation in class all correlation between observed precipitation and precipitation datasets are roughly comparable the results suggest that the correlation cannot be a leading factor in the varying kge pattern observed for various intensity classes moreover fig s5 presents a very large overestimation generally a rbais more than 2 for the class below 5 mm and an underestimation less than near and larger than 0 5 is seen for classes 5 10 mm 10 20 mm and above 20 mm respectively it exposes that some errors such as underestimation overestimation can be downgraded when dealing with the entire time series therefore applying individual events from the datasets for a given goal leads to more errors than the whole time series fig s6 hints at the dataset s markedly poor performance in representing precipitation variability for classes above 5 mm the median of the variability of precipitation data retrieved from datasets is nearly eight times higher than in situ data for classes 5 10 and 10 20 mm and about four times for class larger than 20 mm while it is near one for the class below 5 mm to evaluate the datasets skill in precipitation event detection we have plotted the spatial distribution of hss in fig 11 from 2014 through 2018 from fig 11 hss values does not go greater than 0 8 however cpc and persiann pdir generally show an acceptable performance with a median hss equal to 0 63 and 0 53 respectively rpps show a similar pattern of hss varying from above 0 4 over the zagros mountains to above 0 2 over the rest of the country assessing the effect of gauge adjustment shows no significant improvement in trmm and gsmap in terms of hss however imerg enjoys a slight improvement mostly over the zagros mountains somehow its median hss from 0 37 reaches 0 41 after adjustment the spatial pattern of hsss related to cmorph crt and cmorph bld indicate that in most stations their hss values vary between 0 and 0 2 particularly over the alborz mountains and south of the caspian sea suggesting that these products have no skill to detect the precipitation events and even roughly in half of the area their performance is comparable with a random estimation 5 3 2 part b pixel to pixel approach 2003 2010 this section evaluated 34 precipitation datasets from 2003 to 2010 due to a sufficient number of stations with proper spatial distribution we considered a pixel to pixel approach for this period at the same time we have provided the point to pixel metric values for comparison the values of assessment metrics were presented in table 6 where the numbers in parentheses are related to the point to pixel approach regarding kge era interim kge 0 71 gpcp kge 0 70 and wfdei gpcc kge 0 69 outperform others at daily time scale followed by agmerra kge 0 64 era5 kge 0 63 and imerg final kge 0 57 gsmap mvk with a kge of 0 57 performed worse than the other products mainly due to a large variability ratio 2 32 and low correlation 0 14 a comparison between spps and rpps shows that most rpps are superior to both sps and gsps similar to the period 2014 2018 cpc hss 0 61 is the best dataset in detecting precipitation events followed by persiann pdir gpcc and mswep a comparison between the two approaches suggests a pattern similar to the monthly scale i e a slight difference in bias and more differences in other metrics for instance cpc trmm3b42 rt persiann cdr and era5 have a kge of 0 52 0 26 0 43 and 0 63 from pixel to pixel approach while these values turn to 0 48 0 20 0 25 0 35 with a point to pixel approach respectively rmse values systematically reduce when a pixel to pixel approach is considered and at the same time the random error percentage increases a non negligible improvement in hss values is also evident in most cases for example era5 s hss from 0 43 based on the point to pixel approach reaches 0 56 when the pixel to pixel approach is used it shows that the error associated with the evaluation approach is not a trifling matter nevertheless the ranking of the datasets remains unchanged fig 12 shows the spatial distribution of the kge metric based on a pixel to pixel approach within 2003 2010 as it has been stated in the subsection most of the mid central of the country is ungauged therefore interpolation in this area is prone to error thus to have a more realistic evaluation we have ignored this region in our assessment however the poor performance of perdiann ccs in the central and east of iran is not an issue that should be ignored generally reanalysis products outperform satellite based products practically after gauge adjustment era5 era interim and wfdei gpcc with a median kge equal to 0 46 0 45 and 0 52 respectively perform even better than cpc as a gauge based product with a median kge equals 0 35 similar to the period 2014 2018 we observed all datasets best performances over the west regions climate properties and precipitation regimes e g less contribution of orographic precipitation compared to the south of the caspian sea and more contribution of stations in the west of iran in datasets development could be the possible reasons for this superiority the gauge adjustment generally improved the performance of the datasets concerning the kge for example there is a clear improvement in kge values from persiann ccs with a median kge of 0 32 to 0 15 for persiann ccs cdr fig 13 illustrates kges and their components for daily data in 2003 2010 based on the pixel to pixel approach considering eq 1 and the median of correlation bias and variability ratio it can be concluded that datasets are worse in terms of correlation followed by variability generally the median of cc is below 0 6 with the exception for cpc agmerra era interim era5 gpcp gpcp1dd mswep wfdei cru and wfdei gpcc with a median below 0 7 specifying at least 0 4 difference from its optimum value while this difference generally is less than 0 2 and 0 3 for bias and variability ratio respectively we have also plotted kge and its components for daily data based on a point to pixel approach fig s7 it is interesting to see that correlation gets worse in the point to pixel evaluation while an improvement is seen in variability ratio it means that the interpolation helps to estimate the behavior of precipitation with better accuracy however at the same time the precipitation variability within a pixel gets worse variability of observed data decreased compared with point to pixel approach more likely due to effects of precipitation events in the neighboring pixels or occurrence of precipitation only in some stations and no rain in some others within a given pixel it should be noted that the pattern of kges in different precipitation categories was similar to the point to pixel approach fig 10 therefore we do not repeat it here and put it in the supplementary material fig s8 due to differences in the evaluation period the results of two periods are not entirely comparable but still when we compare results of the point to pixel approach for the period 2014 2018 with the pixel to pixel evaluation for the period 2003 2010 there is a marked difference in the performance of the datasets in the class below 5 mm in terms of bias and variability bias reduced significantly when a pixel to pixel is used compare figs s5 and s10 at the same time the variability gets worse compare figs s6 and s11 in classes above 5 mm there are no noteworthy differences between the two approaches fig 14 shows the spatial distribution of hss for different datasets considering the period 2003 2010 the general pattern is similar to fig 11 but here we have included more datasets in the evaluation generally reanalysis products have better hss values in comparison to satellite products among reanalysis products era interim era5 wfdei cru wfdei gpcc and mswep outperform others among satellite products only persiann pdir with a median hss equals 0 60 has an aptitude to detect precipitation events same as fig 11 the spatial distributions of hss values for cmorph crt and cmorph bld indicate a very weak skill in precipitation event detection in most areas below 0 2 gauge adjustment improved all datasets skills except for chirp where the median hss reduces from 0 46 for chirp to 0 31 for chirps after gauge adjustment generally gpcp and cpc have their best skills over the west of iran whereas persiann pdir works better across other parts 6 discussion in this study we have carried out a comprehensive analysis to evaluate the reliability of the 44 precipitation products at the monthly scale and 34 precipitation products at the daily scale over iran based on the calculated metrics see table 4 and fig 6 generally bias is the primary source of error in the datasets at a monthly scale these results support the findings of satgé et al 2020 who compared 23 gridded precipitation datasets over west africa they stated that bias is the dominant factor that affects the kge score some other studies e g adam and lettenmaier 2003 habib et al 2013 and ahmadebrahimpour et al 2019 reported similar results the results could be different when the evaluation is conducted on a shorter time scale e g daily in this context beck et al 2019a who evaluated 26 precipitation datasets on a daily scale across the continental united states conus found that datasets performed considerably worse in terms of correlation than bias and variability this finding indicates that a change in the assessment time scale might change a given dataset s error characteristic our findings also show the same pattern when the entire time series is considered somehow the median correlation is generally 0 4 less than its optimum values compared with 0 3 and 0 2 for variability and bias respectively see figs 9 13 and tables 5 6 however our analysis reveals that this pattern is not persistent in all precipitation classes indeed datasets are considerably worse in terms of variability than correlation at the daily time scale if we evaluate different precipitation intensities separately see figs s7 s11 therefore it seems that some errors would be underestimated when we deal with the whole time series in line with our results hosseini moghari and tang 2020 reported that the errors in spps are heavily related to precipitation intensity it s worth mentioning that another source of error could be the temporal inconsistency between local and coordinated universal time utc which can reduce the validity of daily assessments satgé et al 2020 our results reveal that among 44 investigated gridded precipitation datasets at a monthly scale gpcc gpcp and wfdei gpcc outperform other datasets see table 4 it is noteworthy that due to the low spatial resolution of gpcp our findings should not be generalized for small areas gpcc outperforms other gpps the reason behind this superiority can be related to a large number of in situ observations that have been contributed to developing the gpcc dataset compared with other gpps sun et al 2018 krakauer et al 2019 in agreement with our results basheer and elagib 2019 fallah et al 2020 salman et al 2019 ahmed et al 2019 satgé et al 2020 and dahri et al 2020 reported that gpcc outperforms other studied datasets across south sudan southwestern iran iraq pakistan west africa and the indus basin respectively on a daily scale from 2014 through 2018 with respect to kge cpc as a gpp works better than others while within 2003 2010 three datasets namely era interim gpcc and wfdei gpcc outperform others see tables 5 and 6 as well as figs 8 and 12 this performance is unexpected for era interim as a model based product the reason that era interim performs worse in the period 2014 2018 can be traced in the regions with lower densities of stations see figs 1 8 and 12 moreover reanalysis products are inherently spatial so a pixel to pixel evaluation would better represent their performance in line with these results li et al 2018 showed the superiority of era interim over many spps across the tibetan plateau however contrary to our results chen et al 2018 stated that spps outperform rpps so that the era interim is unreliable due to large overestimations over the mekong river xu et al 2020 show that rpps perform better than spps over north america europe and australia while they did not report any era interim superiority over other rpps therefore it can be confirmed that the dataset performance varies from one area to the other and depends on the precipitation type topography and climatic factors as reported by seyyedi et al 2015 our results indicate that systematic error plays a significant role in the total error observed in datasets precl persiann cmorph raw and merra land at the monthly time scale and datasets persiann and cmorph raw at a daily scale a high systematic error rate highlights the need to use the bias removal techniques before integrating the datasets in any application prakash 2019 a comparison between two versions on ncep shows a slight improvement in ncep 2 compared to ncep 1 in estimating precipitation over iran besides the higher spatial resolution however the reliability of ncep 2 needs to be developed over regions like iran our finding has aligned the study conducted by ma et al 2009 over china we found that the persiann family datasets perform differently from a considerable underestimation in persiann to a large overestimation in persiann ccs tables 4 and 6 the persiann ccs overestimation is also reported over the conus however globally persiann cdr estimates precipitation more than persiann ccs see table 3 and fig 8 in nguyen et al 2018 however the better performance of persiann cdr infers the importance of gauge adjustment to improve satellite observation that was reported for other spps over the conus beck et al 2019a and west africa satgé et al 2020 the most exciting issue about the persiann family products is the remarkable performance of persiann pdir as a satellite based product persiann pdir performs better than persiann cdr and persiann ccs cdr as gauge corrected persiann family members in most regions particularly in detecting precipitation events given that this database has just been introduced there is no study on its evaluation however we found that persiann pdir performs better over iran than the conus based on the comparison of our results with the evaluations conducted by nguyen et al 2020 almost all datasets underestimate the amount and overestimate the variability of precipitation in regions with an annual rainfall of more than 500 mm see fig 7 and fig s2 in iran the annual precipitation above 500 mm usually can be seen in the south of the caspian sea and in high altitude areas where the number of gauges is quite limited according to fig 5 poor performances are observed mainly in the southern caspian sea regions since the primary rainfall regime in this region is orographic katiraie boroujerdy et al 2013 spps and rpps could not capture the precipitation well under this circumstance zhou et al 2019 wang et al 2019 due to the small number of stations that contributed to the development of gpps they also underestimate the amount of precipitation in this region hosseini moghari et al 2018 all products perform better at the monthly time scale as expected particularly gauge corrected products the reason for such a finding can be traced back to the fact that some daily datasets are adjusted only monthly moreover the mismatch in reporting times of data in global products and in situ is more critical at a daily scale beck et al 2019a satgé et al 2020 a comparison between satellite based products and reanalysis ones reveals that the skill of non adjusted reanalysis products in detecting precipitation events is higher than both the non adjusted and adjusted satellite products with the exception for persiann pdir due to the limited number of overpasses it is possible that the satellite does not capture short precipitation events tian et al 2009 resulted in a lower hss value comparing adjusted and non adjusted spps and rpps suggests that gauge adjustment helps enhance their performance in precipitation events detection but not very sharp indeed the gauge correction adjusts the precipitation volume not the occurrence of precipitation gosset et al 2013 as a result the amount of precipitation might be sited to zero during the gauge adjustment and the rate of false alarm would be reduced while the probability of detection almost remains constant hosseini moghari and tang 2020 many studies e g rivera et al 2018 xu et al 2017 darand and khandu 2020 peng et al 2020 used a point to pixel approach for evaluating global precipitation datasets however our findings show that a point to pixel approach undervalues the gridded dataset s capability in a non negligible way see tables 4 and 6 islam 2018 argued that we could deal with the errors associated with the miss representativeness of a point to pixel approach considering more than three years our results cannot approve this claim since we considered eight years 2003 2010 in our analysis yet a pixel to pixel approach performs significantly better than the point to pixel approach nevertheless database ranking is the same based on two approaches therefore both approaches can be used interchangeably for ranking the datasets regardless of evaluation metrics values although we already introduced some datasets as the best they cannot be employed in all applications indeed different precipitation products would be suitable for specific applications the spatiotemporal resolution spatial coverage temporal span and time delays confine our choices therefore based on our findings and considering the need for different applications we have recommended datasets over iran for both monthly and daily time scales to this end we introduce the best datasets in four categories as follow 1 long term daily datasets that can be operated for analysis of rainfall frequency in infrastructure design and climate change studies 2 long term monthly datasets with the application for drought monitoring trend analysis data gap filling and reconstructing historical streamflow 3 near real time daily datasets in purpose to be utilized for flood forecasting reservoir operations and irrigation management 4 near real time monthly datasets that can be employed for near real time drought monitoring and reservoir operations to rank the datasets in each category we have regarded their kge values moreover we considered a minimum period of 30 and 10 years as long term data for monthly and daily scales respectively the datasets with spatial resolution coarser than half degree are excluded from our assessment as coarse resolution datasets usually are not applicable for iran s basin size fig 15 shows the best datasets based on the mentioned classes in each river basin of iran from the figure gpcc in most cases is the best dataset for long term daily and monthly scales for the near real time monthly time scale in most basins era5 is the best dataset followed by imerg final while at a daily scale cpc outperforms other datasets it is worth mentioning that the persiann pdir is almost a real time product and is the best across all basins so we did not plot it in fig 15 however if the latency matters the first option would be persiann pdir tables s1 s4 illustrate the best reanalysis satellite based and gauge based datasets for each basin 7 summary and conclusions we have conducted a comprehensive evaluation of 44 precipitation datasets at the monthly time scale and 34 daily precipitation datasets over iran we have chosen the period from 2003 to 2010 to include all datasets within 2003 2010 a network of more than 1500 rain gauges is used as the reference to include gpm based products in our evaluation we also consider the period 2014 2018 for daily assessments with fewer datasets i e 25 datasets since the spatial resolutions among datasets varies from 0 04 to 2 5 for the period of 2003 2010 the in situ data were interpolated to the identical spatial resolution of global datasets using the ordinary kriging method the findings of this study can be summarized as follow almost all gauge based precipitation products gpps and gauge adjusted products can map the spatial distribution of annual precipitation however in general unadjusted products such as persiann ccs perform poorly in this regard therefore unadjusted products are not reliable for water balancing studies or creating climate zoning maps in terms of kge on a monthly scale gpcc persiann pdir gpcp era interim wfdei gpcc and merra 2 are the best gauge based precipitation products gpps satellite based precipitation products sps gauge corrected satellite based precipitation products gsps reanalysis products rps gauge corrected reanalysis products grps and gauge corrected satellite and reanalysis products gsrps respectively however the rankings of datasets can vary between different basins in terms of kge on a daily scale era interim gpcp and wfdei gpcc shows the best performance followed by agmerra era5 and imerg final moreover all datasets estimate precipitation with insufficient accuracy for precipitation intensities above 5 mm day regarding the individual components of the kge metric datasets are worse in terms of bias at monthly time scales and correlation at daily time scales our analysis reveals a substantial disagreement between products within persiann family the quality of precipitation estimation ranges from a considerable underestimation of 0 39 for persiann to an overestimation of 0 68 for persiann ccs however the new member of this family i e persian pdir performs remarkably well as a non adjusted real time satellite based product a comparison between the gpm based products i e imerg and gsmap shows that imerg products perform better than gsmaps particularly after gauge adjustment also comparing non adjusted imerg and trmm products within 2003 2010 reveals that in general the imerg algorithm works slightly better and after gauge adjustment imerg is clearly superior to trmm assessing the datasets ability in detecting precipitation events illustrates that gauge products as expected outperform other product types the reanalysis products have a better skill in detecting precipitation events than satellite based products except persiann pdir persian pdir with an hss of 0 60 works as perfectly as gauge based products we found that an evaluation based on the point to pixel approach understates datasets skill compared to the pixel to pixel approach however the ranking of datasets remains the same in both approaches the results of this study can be used as a guide to decide which precipitation dataset should be used for a particular application a small portion of the rain gauges in iran has been incorporated in gauge based satellite based or reanalysis gridded precipitation products moreover the contribution of these in situ measurements is always delayed by one to several months highlights the importance of satellite based precipitation products especially for near real time applications this study represents an unprecedented evaluation of almost all available satellite based products over iran discussing their strengths weaknesses and spatiotemporal discrepancies previous studies highlighted the discrepancy in the comparisons between precipitation estimates from region to region beck et al 2019a sun et al 2018 our findings only pertain to the iranian basins and are not necessarily transferable to other regions author contributions peyman saemian and seyed mohammad hosseini moghari designed the study peyman saemian led the calculation and wrote the initial draft of the paper together with seyed mohammad hosseini moghari iman fatehi vahid shoarinezhad and ehsan modiri prepared the quality controlled in situ data and commented on the initial draft andrás bárdossy conducted the interpolation of in situ data mohammad j tourian qiuhong tang wolfgang nowak andrás bárdossy and nico sneeuw commented on the draft and contributed in analysing all authors reviewed the manuscript and contributed to the final manuscript version declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors are grateful to the product developers for providing the precipitation datasets peyman saemian iman fatehi vahid shoarinezhad and ehsan modiri acknowledge the sustainable water management nawam program from the federal ministry of education and research bmbf and the german academic exchange service daad for the support for their phd grant seyed mohammad hosseini moghari thanks the chinese academy of sciences president s international fellowship initiative grant no 2019vea0019 qiuhong tang acknowledges the national natural science foundation of china 41790424 41730645 and the international partnership program of chinese academy of sciences grant no 131a11kysb20170113 appendix a glossary of precipitation datasets dataset full name gauge based products cru climatic research unit gpcc global precipitation climatology centre prec l precipitation reconstruction over land udel university of delaware cpc climate prediction center satellite based products persiann precipitation estimation from remotely sensed information using artificial neural networks persiann ccs precipitation estimation from remotely sensed information using artificial neural networks cloud classification system persiann pdir precipitation estimation from remotely sensed information using artificial neural networks dynamic infrared rain rate near real time trmm 3b42 rt tropical rainfall measuring mission 3b42 real time gsmap mvk global satellite mapping of precipitation moving vector with kalman filter gsmap nrt global satellite mapping of precipitation near real time gsmap rnl global satellite mapping of precipitation near real time cmorph raw climate prediction center morphing technique raw imerg early integrated multi satellite retrievals early persiann cdr precipitation estimation from remotely sensed information using artificial neural networks climate data record persiann ccs cdr precipitation estimation from remotely sensed information using artificial neural networks cloud classification system climate data record gpcp global precipitation climatology project gpcp1dd gpcp one degree daily cmap cpc merged analysis of precipitation trmm 3b42 adj tropical rainfall measuring mission 3b42 adjusted trmm 3b43 tropical rainfall measuring mission 3b43 cmorph bld climate prediction center morphing technique bld cmorph cdr climate prediction center morphing technique cdr cmorph crt climate prediction center morphing technique crt gsmap gauge global satellite mapping of precipitation gauge imerg final integrated multi satellite retrievals final reanalysis products ncep1 national centers for environmental prediction 1 ncep2 national centers for environmental prediction 2 era interim european centre for medium range weather forecasts reanalysis systems interim era5 european centre for medium range weather forecasts reanalysis systems 5 cfsr climate forest system reanalysis system 20crv3 twentieth century reanalysis system version 03 jra 55 japanese 55 year reanalysis agcfsr agricultural model cfsr pgf princeton global forcing wfdei water and global change applied to era interim wfdei cru water and global change applied to era interim cru wfdei gpcc water and global change applied to era interim gpcc chirp climate hazards group infrared precipitation chirps climate hazards group infrared precipitation with station data mswep multi source weighted ensemble precipitation merra 2 modern era retrospective analysis for research and applications 2 merra land modern era retrospective analysis for research and applications land agmerra agricultural model merra appendix b supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2021 127054 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
3951,understanding the meanings and identifying the controls for the stormflow generation with complex and nonlinear behaviors is essential for the development of threshold based hydrological theory as well as accurate assessment and prediction for flash flood risks however the study of catchment emergent patterns with three linear threshold behaviors associated with hydrological connectivity has received little attention therefore utilizing soil water storage rainfall and streamflow data spanning 3 years in a humid forest experimental watershed dujiangyan city china we elucidated how and where stormflow was generated with nonlinear behaviors which were affected by antecedent wetness and rainfall amounts stormflow threshold behavior was taken as a function of combined gross precipitation and antecedent soil water storage which was isolated using piecewise regression analysis with the identification of two breakpoints i e generation threshold tg and rising threshold tr it was found that the initial emergent behavior of rainfall runoff was generally activated at the tg and then an abrupt shift from slow to fast flood response was possibly triggered at the tr these processes are important to understand the formation and development of flash floods at the watershed scale it was noted that above the tr considerably higher stormflow amounts generally occurred due to the lateral connectivity extension of runoff contributing area from stream to neighboring hillslopes meanwhile gravity driven water movements in soil and better hydrological connectivity during the above tr phase readily triggered the huge flash flood disasters the above tr flash floods with abrupt shifts were predominantly controlled by rainfall amounts while initial below tg stormflow generation was mainly controlled by unsaturated soil water storage more noteworthy under heavy rainstorm conditions the above tr stormflow was dominantly generated by subsurface flow as was demonstrated at hillslope and watershed scales these findings contribute to increasing our understanding of the controls on three linear threshold based hydrological behaviors as well as of subsurface stormflow generation mechanism associated with hydrological connectivity in humid forest watersheds keywords stormflow generation threshold behaviors soil water storage rainfall amounts hydrological connectivity 1 introduction the stormflow extremes derived by climate and anthropogenic changes become more frequent and globally damaging ali et al 2015 allan and soden 2008 yin et al 2018 and readily increase the extremes of flash floods aghakouchak et al 2020 lumbroso and gaume 2012 the urgency for accurate assessment and prediction for flash floods risk requires a more clear understanding of the stormflow generation mechanism and threshold behaviors in mountain headwater watersheds hapuarachchi et al 2011 ross et al 2021 it was demonstrated that runoff generation mechanism in humid forest watersheds could be predominantly controlled by the limited subsurface stormflow with extremely nonlinear behaviors ali et al 2013 tromp van meerveld and mcdonnell 2006a williams et al 2019 which remarkably differed from the reported saturation excess overland flow mugabe et al 2007 and infiltration excess overland flow cammeraat 2004 huang et al 2003 tromp van meerveld and mcdonnell 2006a elucidated the dominant subsurface stormflow generation in a forested watershed usa which generally presented an emergent threshold behavior associated with hydrological connectivity and fill spill theory mcdonnell et al 2021 tromp van meerveld and mcdonnell 2006b little or no stormflow was generated at hillslopes and contributed to the channel streamflow below the threshold for the precipitation or the sum of precipitation and soil water storage but a significant response for the stormflow was observed once above the threshold detty and mcguire 2010a graham et al 2010 tromp van meerveld and mcdonnell 2006a for example tromp van meerveld and mcdonnell 2006a found an increase of 2 orders of magnitude in subsurface flow for events above the threshold compared to those events below the threshold it well reflects the threshold behaviors for subsurface stormflow and two linear runoff response processes which is greatly important to get insight into the nonlinear runoff generation mechanism at hillslope and watershed scales stormflow threshold behaviors were generally subject to the hydrological connectivity of the flows from hillslope to stream as the watershed runoff contributing area increased ali et al 2015 fu et al 2013 activated by preferential flow and subsurface matrix flow haga et al 2005 tromp van meerveld and mcdonnell 2006a the emergent behavior indicated a storage threshold amount but also a runoff contributing threshold area fu et al 2013 below the threshold the runoff was generated in the near stream zones while the runoff contributing sources possibly extended laterally onto the upper hillslopes detty and mcguire 2010a it was noted that these behaviors could be mainly affected by rainstorm size and intensity buttle et al 2019 haga et al 2005 antecedent soil water storage oswald et al 2011 penna et al 2011 landscape and topography detty and mcguire 2010b soil depth and vertical hydraulic conductivity han et al 2020 and forest canopy response scaife and band 2017 larger storms could lead to more mobile water in the soil and rapid streamflow response they possibly result in a higher value of slope derived from the storage stormflow equation during the above threshold phase fu et al 2013 meanwhile high variability for stormflow amounts was often found during the above threshold phase farrick and branfireun 2014b scaife and band 2017 mostly increasing the uncertainty in assessing and predicting the stormflow amounts affected by heavy rainstorms it restricted our insight into the hierarchical input and output processes within the water cycle and exaggerated the uncertainty in simulating the large storms driven flood hydrographs based on a threshold based hydrological model wei et al 2020a proposed the stormflow generation related to three linear threshold behaviors and demonstrated the possible co existence of the runoff generation and rising thresholds it could well characterize the initial streamflow activation and the transition from slow to the rapid response of stormflow but the issue of how to efficiently elucidate the three linear threshold behaviors is not solved wei et al 2020a the scale issue in rainfall runoff processes inherently exists ali et al 2013 but at the watershed scale insights into the three linear threshold behaviors are very essential to develop the threshold based hydrological theory in this study high resolution data 5 min of rainfall soil water storage and streamflow from 2018 to 2020 were collected in a humid forest experimental watershed southwestern china the stormflow i e quick flow was separated from the total flow based on a two parameter recursive digital filter method eckhardt 2005 while the stormflow thresholds of combined precipitation and soil water storage for the events were identified using the piecewise regression analysis pra method the objectives of this work were to 1 quantitatively identify stormflow generation and rising threshold behaviors at the watershed scale 2 exploit the dynamic controls of antecedent wetness and rainfall amounts to the three linear threshold hydrological behaviors with the transition from slow to rapid runoff generation and 3 gain insight into the dominant subsurface stormflow generation associated with hydrological connectivity at hillslope and watershed scales it is very important for understanding the shift from slow to rapid runoff generation and the causes of the catastrophic flash floods associated with the strategies of prevention and mitigation in humid forest watersheds 2 study area the study was conducted in the longxi river lxr experimental watershed 31 n 103 e 80 km northwest of chengdu city sichuan province china fig 1 a and b this watershed as the first level tributary of the minjiang river basin has a drainage area of 78 3 km2 and a total length of 18 2 km this region is characterized by a subtropical and humid monsoon climate with an average annual temperature of 15 2 the mean annual rainfall is approximately 1135 mm with maximum precipitation occurring in august and 80 of the annual precipitation appears in the flood season may october when high magnitude flash flood disasters probably occur zhang et al 2019 this watershed is dominated by forest land with the occupy 90 3 of the whole watershed area in 2018 zhang et al 2021 mainly including indeciduous dark coniferous and broad leaf forests relatively stable vegetation succession is maintained in the tenth year after the wenchuan earthquake yunus et al 2020 zhang et al 2021 when land development is low the soil is classified as haplic luvisols haplic alisols dystric cambisols and chromic luvisols soil textures mainly consist of gravel with 54 leading to the high surface hydraulic conductivity in forest land with the values of mostly 40 200 mm h the bedrock type is mainly composed of granite rock zou et al 2019 which is mostly with a low degree of rock weathering protected by the soils and vegetation when the bedrock is exposed in some areas strong weathering of the granite rock generally occurs possibly leading to a decrease of rock strength some bedrock depression topographies generally exist on the hillslope detty and mcguire 2010b tromp van meerveld and mcdonnell 2006b influencing the flow paths and runoff generation granite is characterized by poor primary permeability overall but strong secondary permeability through cracks and fractures if they are present may enhance permeability high soil surface infiltration and low granite rock percolation rates lead to a significant soil rock interface readily triggering the subsurface stormflow on the interface under heavy rainfall conditions the region with the elevation of 870 3284 m asl is steep with an average slope of 20 and the stream gradient mostly of 287 626 the stream channels are deeply incised with the free faces of approximately 0 3 7 0 m high the channel width ranges from 0 3 m in the upper reaches to 20 67 m in the middle and lower reaches such conditions with high relief abundant orographic rains and strong erosion properties zhang et al 2021 readily triggered catastrophic flash floods and even debris flow events liu et al 2020 such as the 8 13 debris flow event at the wenchuan earthquake affected region on august 13 2010 with a total volume of debris materials of 7 8 106 m3 cui et al 2013 xu et al 2012 3 methods 3 1 hydrometric observations the surface flow velocity and water level automatically recorded at 5 min intervals at gauging stations s1 s6 distributed the whole watershed fig 1c were measured using non contact radar doppler flow meters measurement accuracy 0 01 m s and ultrasonic water level sensors measurement accuracy 0 001 m respectively zhang et al 2019 six cross sectional geometries were measured using manual surveying in combination with an unmanned aerial vehicle method based on the entropy and probability concepts in hydraulics chen 2013 moramarco et al 2004 we utilized the noncontact method provided by zhang et al 2019 to reasonably estimate the mean cross section velocity and flow discharge at 5 min intervals field open precipitation recorded at 5 min intervals including nine rain gauges r1 r9 distributed into the elevations from 884 to 1834 m asl fig 1c was measured using digital tipping bucket gauges with the resolution of 0 1 mm average surface rainfall in the shuiniqiao snq upper watershed fig 1c was assessed based on the thiessen polygon method zhang et al 2021 and the collected runoff data at s6 next to the watershed outlet are analyzed and discussed fig s1 rain events were defined as a total rainfall of at least 1 mm and individual events were separated by 6 h penna et al 2011 wei et al 2020a based on the definition method for rain events 47 events in total were identified from 2018 to 2020 in the lxr watershed to possibly eliminate the uncertainty and nonstationary in threshold behaviors due to seasonal and inter annual variations of land use and vegetation forest canopy scaife and band 2017 we selected the events mostly from june to august of every year from 2018 to 2020 to identify the hydrological threshold behaviors detty and mcguire 2010a farrick and branfireun 2014b volumetric soil moisture content θ cm3 cm 3 at four soil profiles sw1 sw4 across two hillslopes was continuously measured at 5 min interval from 2018 2020 fig 1c using the insentek sensor probes with temperature 0 5 and soil moisture electromagnetic pulse sensors 1 mm fig 2 provided by insentek technology co ltd hangzhou china qin et al 2018 these sensors were installed in the 80 cm soil profiles below the surface at a 10 cm depth interval powered by the equipped built in battery and solar energy the upper sw1 and lower sw2 monitored locations of one hillslope on the left bank fig 1c and 2 were located in coniferous forest land and a mixture of grass shrub land respectively another monitored hillslope sw3 sw4 on the right bank was located on the landslide the depth equivalent antecedent soil water index dasi mm proposed by haga et al 2005 and wei et al 2020a represented the cumulative value of the initial water content at the soil profiles and elaborated the characteristics of shallow soil water storage capacity the dasi at the start of each rainfall event was calculated from the eight layer soil moisture measurements at each soil profile as farrick and branfireun 2014b wei et al 2020a 1 dasi i 1 n θ i d i d i 1 where θi indicates the average soil content between i and i 1 soil layer cm3 cm 3 i 1 2 3 4 n and n indicates the number of soil layers below the surface for the monitored soil depth of 80 cm di indicates the soil depth at the ith layer 10 20 30 40 50 60 70 and 80 cm d0 0 the index that integrated soil moisture with depth was utilized to well exploit the effects of antecedent wetness on the watershed hydrological behavior penna et al 2011 zhang et al 2018 3 2 hydrograph separation to more clearly understand how and where the stormflow was generated and identify the controls for stormflow to the formation and development of flash floods in a humid forest watershed a two parameter recursive digital filter method proposed by eckhardt 2005 was utilized to separate the quick flow i e stormflow qq and delayed flow i e base flow qb from total discharge for the storm runoff events the maximum base flow index bfimax should be the suggested value of 0 8 for a perennial lxr stream with porous aquifers eckhardt 2005 the storm runoff ratio qq p is expressed by the ratio of stormflow amounts qq to grass precipitation amounts p the minimum contributing area equivalent mca with the parameter qq proposed by dickinson and whiteley 1970 indicated the watershed runoff minimum area contributing to the measured storm runoff 3 3 piecewise regression analysis to efficiently characterize the stormflow threshold behavior of combined gross precipitation p and depth equivalent antecedent soil moisture index dasi a piecewise regression analysis pra proposed by oswald et al 2011 and muggeo 2003 could be utilized to quantitatively assess for threshold behavior at lxh watershed to calculate the threshold values i e breakpoints and the derived linear slope parameters we acknowledge the existence of nonlinear and complex stormflow generation but automatic searching and calculating the breakpoints and slope parameters using pra with top down approaches and maximum likelihood approach muggeo 2003 could relatively efficiently determine the emergent hydrological behavior 3 4 soil hydraulic properties test soil hydraulic properties were quantitatively characterized by measuring saturated soil hydraulic conductivity ks in soil profiles to identify the runoff generation under heavy rainstorm conditions farrick and branfireun 2014a a constant head permeameter test proposed by zhang et al 2020 suitable for measuring ks in coarse grained soil with rapid flow was utilized to measure the ks of the undisturbed soil cores based on a derivation of darcy s law johnson et al 2005 zhang et al 2020 20 soil cores samples in multi depth profiles at the upper and lower positions of the hillslope located on the left bank were obtained using the core cutter method and the multi depth ks values were measured in the laboratory to illustrate how ks changed and storm driven soil water moved 4 results 4 1 rainfall runoff relationships large storm events p 10 mm with the 40 event dataset occupying 89 of the total were monitored and collected from 2018 to 2020 fig s1 event precipitation amounts p ranged from 16 4 to 263 9 mm with an average value of 68 0 mm fig 3 a rainfall durations d ranged from 1 5 to 219 h with the mean value 23 h fig 3c and peak rainfall intensities ip from 0 49 to 46 9 mm h fig 3d the stormflow amounts qq for each event with the values from 0 24 to 193 57 mm shown in fig 3h were separated from the total runoff and showed a statistically significant linear relationship with precipitation amounts p qq 12 0 59 p r 2 0 79 p 0 01 fig 4 a it was found that a quite high variability for qq occurred when the p exceeded 19 mm fig 4a the mean value 0 36 for qq p shown in fig 3g and 4d was analogous to that values with 0 07 0 45 reported by some researchers from europe and australia farrick and branfireun 2014b jin et al 2020 marchi et al 2009 merz et al 2006 and the qq p could exceed 0 8 due to the integrated controls from antecedent wetness and rainstorm intensity smith et al 1996 smith et al 2005 weak linear relationships between qq and mean rainfall intensity im rainfall duration d were found fig 4b c especially the runoff coefficient α appeared an abnormal phenomenon i e α 1 shown in fig 5 a which mostly occurred in the range of event peak rainfall intensity ip with 0 2 5 mm h this is mainly due to the relatively small rainfall intensity and the susceptibility to the control of shallow groundwater outflows around the river channel formed by previous rainfall events penna et al 2011 sidle et al 2000 watershed lag times lp from peak rainfall intensity to peak discharge ranged from 0 58 to 23 83 h fig 3i with two groups 5 h and 10 h the events n 16 with 5 h lag time accounted for 40 of the total events while the events n 18 with long lag time 10 h accounted for 45 of the total meanwhile we found a significant negative power function relationship p 0 05 between ip and lag time lp and the strong variability for the lag time occurred when the ip was lower than 15 mm h fig 5c or the im was lower than 5 mm fig 5d when the peak flow was 59 m3 s 1 the corresponding average lag time was 4 98 h meanwhile the peak discharge with 200 m3 s 1 could reduce the time to 3 h this greatly increased the risk of catastrophic flash floods that are difficult to be prevented and mitigated 4 2 effects of antecedent soil moisture on stormflow the depth equivalent antecedent soil water index dasi for 80 cm soil depth was calculated using eq 1 to characterize the shallow soil water storage with the mean values of 78 93 12 79 mm in forest land and a mean of 104 27 8 84 mm in grass shrub land the statistical relationships between dasi and qq were not significant r2 0 017 p 0 05 in all monitored soil points fig 6 a b indicating a little control of only antecedent soil moisture to stormflow this is consistent with what was found in marine humid temperate climate region coweta hydrologic laboratory with sandy loam in north carolina usa scaife and band 2017 and different from that reported in a semi arid inland climate forest watershed with loess soil in gansu province china jin et al 2020 three exceptions i e 2020 08 15 2020 08 29 and 2019 08 19 were found in fig 6a b characterized by that the lower values of dasi also led to the extremely high stormflow amounts the result suggested that the observed extreme values of qq could be affected by other factors except for the dasi parameter such as physiographic heterogeneity and precipitation input synchronism ali et al 2015 carey et al 2010 4 3 stormflow generation and rising thresholds a significant three linear relationship p 0 001 was observed between dasi p and qq fig 6c d when the antecedent soil moisture was summed with the event precipitation amounts p the relationship acturally was different from the aforementioned relationship of p versus qq with strong variability and uncertainty under high rainfall intensities conditions fig 4a based on piecewise regression analysis pra combined with the levenberg marquardt algorithm lm we could optimize and derive the three linear threshold behaviors for dasi p and qq relationship in the forest and grass shrub lands r 2 0 88 p 0 001 fig 6c d and obtained two thresholds i e breakpoints of each location respectively table 1 the low and high thresholds were identified and demonstrated as the stormflow generation threshold tg and rising threshold tr respectively wei et al 2020a the lower tg value of 111 2 mm and higher tr value of 260 7 mm occurred in dominant forest land compared to the tg 130 4 mm and tr 247 9 mm in grass shrub land the initial runoff generation was mainly controlled by larger values for soil moisture deficits compared to the canopy interception capacities scaife and band 2017 wei et al 2020a resulting in lower tg value in dominant forest land the synthesis for canopy interception capacities soil moisture deficits and hillslope flow pathways buttle et al 2019 ebel and mirus 2014 farrick and branfireun 2015 can need more water input in forest land to trigger the rising threshold behaviors at the output the generation and rising thresholds in an extremely high percentage 90 3 for the forest land zhang et al 2021 could mainly represent the hydrological threshold behaviors at the watershed scale three linear hydrological behaviors above and below the two thresholds were identified and shown in fig 6c d it was found that higher values in slope parameter m 1 of regression equations for threshold behaviors occurred in the third phasecompared to the slopes with 0 21 0 49 in the first and second phases table 1 it indicated the faster increase of runoff volume in the third phase when the catastrophic flash floods readily occurred this finding of threshold based hydrological behaviors was very important to understanding and identifying the abrupt shifts of formation and development of flash floods in a humid steep mountain watershed 5 discussion 5 1 controls for hydrological threshold behaviors it was demonstrated in the tropical dry forest or humid mountain watershed farrick and branfireun 2014b han et al 2020 zuecco et al 2017 that when the initial soil moisture deficits for runoff generation threshold were gradually satisfied the streamflow response can be mainly subject to the rainstorm properties however most studies ali et al 2013 detty and mcguire 2010a fu et al 2013 scaife and band 2017 tromp van meerveld and mcdonnell 2006a williams et al 2019 focused on the generation threshold behaviors with different shapes at hillslope or watershed scales and little is considered about the integrated hydrological behaviors for runoff generation and rising thresholds wei et al 2020a understanding how both hydrological emergent behaviors formed could help to reveal the dominant runoff producing mechanism based on the analysis for the three linear hydrological behaviors above and below the thresholds an abrupt shift for mean qq with the several order of magnitudes was found during the three phases fig 7 e and table 2 with values of 3 14 mm 19 00 mm and 138 34 mm respectively this shift is consistent with that reported by oswald et al 2011 in a small catchment in northwestern ontario canada significantly higher values for qq occurred in the above tr phase with the large value in slope parameter m 2 36 of regression equations table 1 indicating the abrupt shift of flash flood above the rising threshold due to more contribution to runoff recharge from both forest canopy interception and soil water scaife et al 2020 wei et al 2020a wei et al 2020b this is consistent with the results obtained by scaife and band 2017 and buttle et al 2019 under the condition of heavy rainstorms the effects of shallow soil water storage on runoff threshold behaviors are multiple and complex mean shallow soil storage of 19 93 at the 80 cm soil layer readily led to a significant increase in stormflow if the shallow soil storage exceeded 24 29 the stormflow changed more obviously with emergent behaviors the threshold for shallow soil storage is close to the 18 23 recorded by james and roulet 2009 and jin et al 2020 but far below the 41 46 of western and grayson 1998 and penna et al 2011 it was noted that no or little runoff was generated when the shallow soil storage is lower than the threshold of 19 93 during the phase the soil water flow was dominantly controlled by vertical flow movement and showed an active depth of 10 70 cm if it was 24 29 with the emergent behavior of runoff generation in the watershed the flow possibly generated a potential transient saturation layer below 80 cm or lateral flow at the soil bedrock interface and formed an subsurface stormflow processes farrick and branfireun 2014b readily resulting in an abrupt occurrence of flash flood disasters van meerveld et al 2015 additionally the lag times ls and response depths ds of soil water during the three phases fig 7b c were compared and analyzed to clearly understand the controls of soil water storage to the threshold behaviours it was found that significantly shorter in lag time ls shown in fig 7b for soil water response with 0 69 h occurred in the third phase below the rising threshold table 2 but during the below tg threshold phase the lag times lp shown in fig 7a for runoff response were significantly shorter than that ls in shallow soil water response the soil infiltration here could be controlled by soil matric suction with hygroscopic water or film water jin et al 2020 possibly resulting in slow soil water flow and long lag time ls for shallow soil water however shorter ls for shallow soil water with deeper response depth ds 80 cm was identified during the below tg threshold tg 111 2 mm phase fig 7c the hydrological behaviors below and above the two thresholds indicated the transitions from suction driven infiltration both capillary force and gravity driven infiltration to only gravity driven infiltration fig 8 the proportion of freely mobile water increased once above the rising threshold in the ③ phase readily triggering the formation and development of flash floods the stormflow amounts below the tg were mainly subject to the substantially larger fraction 86 31 of dasi from dasi p shown in fig 7d and 8 controlled by the unsaturated soil water storage a larger fraction 72 27 of the p from dasi p was found in the above tr phase phase ③ when the storm amounts p dominated the abrupt shift from slow to rapid flash flood generation fig 8 moreover as in jin et al 2020 and torres et al 1998 the maximum soil moisture content 32 under the heavy rainstorm condition did not indicate that the soil was saturated therefore the qq p transition from 0 24 below the tg to 0 60 above the tr fig 7f and table 2 also reflected the rapid increase of subsurface stormflow under the heavy rainstorm conditions through preferred flow pathways or soil water displacement in the unsaturated zone mcguire and mcdonnell 2010 torres et al 1998 change in the dominant factor from unsaturated soil water storage below the tg to storm size and intensity above the tr indicated that once the deficit for soil and canopy storage became low enough little rainfall readily triggered more runoff translated by the storage and contributed to the formation of flash floods in a humid mountain watershed this result is consistent with that reported by farrick and branfireun 2014b in a tropical dry forest catchment mexico without considering the rising threshold under heavy rainstorm conditions the extension and development for the three linear hydrological threshold behaviors rather than two linearity are helpful to understand the formation and development of flash floods as well as its critical abrupt shift processes induced by heavy rainstorms 5 2 subsurface stormflow generation associated with hydrological connectivity to understand the potential subsurface stormflow generation at the hillslope scale three representative rainfall events 2020 08 29 2020 07 21 and 2020 08 30 shown in fig 9 which were below and above the generation and rising thresholds were selected to exploit the rainfall driven soil water movement and runoff generation associated with hydrological connectivity for the below tg event i e 2020 08 29 event with precipitation amounts of 17 2 mm fig 9a and d the response time of soil water in the upper and lower hillslope was not synchronized and the response depth is mostly within 50 cm below the surface with the small values of wetting curve maximum slope smax lozano parra et al 2016 mallet et al 2020 it indicated the soil water movement dominated by matrix flow but little runoff which mainly occurred in the first phase below the tg for the 2020 07 21 event with higher rainfall amounts of 76 6 mm between tg and tr fig 9b and e the response time at the 30 cm soil layer of the upper hillslope was synchronous with that at 50 cm soil layer of the lower where the time for the instantaneous saturation layer with perched water lasted 5 10 min it was related to the lower saturated hydraulic conductivity measured at 30 cm layer of upper location and 50 cm layer of the lower location of the hillslope fig 10 such short connectivity time at the lower hillslope indicated the extension of the runoff contributing area from the channel nearby to the hillslope han et al 2020 as storm intensity increased 2020 08 30 event with rainfall amount 229 1 mm fig 9c and f the response time of soil water in the upper and lower hillslope was synchronized with the larger smax indicating the dominant preferential flow pathways mallet et al 2020 in the upper hillslope an instantaneous saturated zone was observed at a 30 cm soil layer with a connectivity time of 5 min it suggested that the contributing area affected by a heavy rainstorm possibly expanded laterally onto neighboring upper hillslopes ali et al 2013 detty and mcguire 2010a lee and kim 2020 readily triggering the catastrophic flash flood disasters this finding is important for understanding the subsurface stormflow generation mechanism associated with hydrological connectivity in a steep mountain watershed at the hillslope and watershed scales detty and mcguire 2010a and the associated shallow soil failure in slopes cui et al 2014 cui et al 2019a cui et al 2019b and accompanied disaster chain guo et al 2021 guo et al 2020 at the watershed scale the dominant stormflow generation could be identified using indirect hydrological signatures such as the relationship between stormflow and rainfall intensity and between watershed area and lag time dunne 1978 farrick and branfireun 2015 at a watershed where runoff was dominated by infiltration excess overflow hof a significant positive linear relationship r 2 0 96 p 0 001 between stormflow amounts and rainfall intensity was found and verified cammeraat 2004 dunne 1978 martinez mena et al 1998 however in our study the observed weak relationship between stormflow and rainfall intensity r 2 0 117 p 0 484 0 05 via a non parametric test revealed that the stormflow generation was dominantly controlled by subsurface flow demonstrating the role of subsurface streamflow in flash floods the watershed lag time lp watershed area a relationship l p 0 42 a 0 20 proposed and verified by dunne 1978 indicated the assumption that the small experimental watershed with the size of 57 km2 was dominantly controlled by hof where the mean lag time was calculated to be 0 94 h based on the lp a relationship fig 11 however the lag time in the hof dominated watershed was much shorter than that of 9 65 h observed at our experiment watershed the result suggested that the dominant runoff generation in our experimental watershed was the subsurface stormflow but not the hof the relationship between stormflow and combined total precipitation and antecedent soil moisture indeed indicated the storage threshold behaviors but also the contributing area threshold behaviors with runoff generation bartlett et al 2016 detty and mcguire 2010a kim et al 2005 ross et al 2021 scaife and band 2017 zehe and sivapalan 2009 the significantly higher values of qq and qq p above the tr fig 7e f and table 2 readily increased the hydrological connectivity of the hillslope riparian stream fig 8 triggering the expansion of the runoff contributing area from the river channel nearby to the upper part of the hillslope the process reflected the percolation transition characteristic of soil water storage at the hillslope when the qq increased to a certain extent with rainfall detty and mcguire 2010a han et al 2020 mcdonnell 2013 tromp van meerveld and mcdonnell 2006a the threshold behaviors could result in the continuous expansion of the effective connection area between the river channel and the adjacent hillslope once above the tr the qq increased rapidly while lag time lp shortened significantly fig 7e generating the obvious emergent behaviors the contributing area for stormflow generation in this watershed was estimated in light of the minimum contributing area equivalent mca proposed by dickinson and whiteley 1970 it was found that the mean mcas below and above two thresholds were 13 79 km2 22 52 km2 and 34 43 km2 respectively fig 7g and 12 higher values of mca above the tr exceeded 60 of the watershed area significantly increasing the hydrological connectivity of hillslope riparian stream and readily triggering the catastrophic flash flood disasters therefore a conceptual model presenting the subsurface stormflow generation mechanism associated with hydrological connectivity fig 12 was developed to reveal the three linear threshold based hydrological behaviors under different rainfall intensity conditions the stormflow generation processes below and above the generation and rising thresholds were represented by fig 12a 12b and 12c affected by the low middle and high rainfall intensities respectively fig 12a showed the stormflow generation during the below tg phase when soil water movement was predominantly controlled by matrix flow in the form of immobile water fig 8 9a and d 12a the channel discharge is mostly formed by direct rainfall or the recharge of shallow groundwater at the adjacent hillslope as the rainfall intensity increased soil water movement was gradually controlled by both matrix flow and preferential flow pathways fig 12 b the potential perched water and fill and spill process fu et al 2013 tromp van meerveld and mcdonnell 2006b at the bedrock depression of the bedrock soil interface could efficiently increase the hydrological connectivity of stream adjacent hillslope and runoff minimum contributing area mca leading to significantly higher qq values once above the tr with high rainfall intensity fig 12c significantly higher values of mca and qq were found readily triggering the huge flash flood disasters fig 12c the flood flow was dominated by subsurface stormflow generation controlled by the storm size and intensity mostly formed through the vertical preferential flow in coarse grained soils 5 3 challenges for threshold based hydrological behaviors associated with the stormflow generation to clearly understand possible threshold based hydrological behaviors associated with stormflow generation we summarize some challenges that could be addressed in the future we think this summary is helpful for a reasonable assessment of the threshold behaviors and promote the development of a new unifying hydrological research framework based on nonlinear threshold theory ali et al 2013 5 3 1 lack of watershed multiple processes monitoring field watershed experiment design generally focuses on the hydrological multiple processes separately which even are difficult to be quantitatively captured by our instruments or monitoring networks such as subsurface matrix flow preferential flow pressure wave translation farrick and branfireun 2014b etc additionally limited spatial monitoring possibly increases the uncertainty in assessing the threshold behaviors at the watershed scale 5 3 2 nonstationary in threshold behaviors affected by abrupt disturbances and climate change climate change with hydroclimatic extremes could alter the seasonal and inter annual stormflow thresholds and linear response with the variation of the ecosystem and vegetation forest canopy farrick and branfireun 2014b scaife and band 2017 they indicate the long term complexity and non stationarity in threshold behaviors with the uncertainty of the threshold values meanwhile abrupt disturbance events such as strong earthquakes wildfire ice and snowstorm etc could significantly destroy the landscape vegetation and even the vegetation soil system bazai et al 2021 cui et al 2009 ebel and mirus 2014 wei et al 2020a zhang et al 2021 rapidly impairing the original hydrological behavior at local and regional scales and further aggravating the nonstationary in threshold behavior 5 3 3 multi scale assessment uncertainty for threshold behaviors effective multi scale threshold metrics are difficult to be derived due to the effects of physiographic heterogeneity and precipitation input synchronism ali et al 2015 carey et al 2010 the unified emergent behaviors at hillslope or catchment scales could have not always proven successful mcdonnell et al 2007 possibly resulting in different shapes of nonlinear threshold behaviors ali et al 2013 and increasing the uncertainty in assessing the threshold behaviors these limitations possibly hinder the development and generalization of the unified threshold based hydrological theory 6 conclusions in community level field experiments the current understanding of stormflow generation and the development of threshold based hydrological behaviors is still limited the study examined the relationship among shallow soil water storage rainfall and streamflow in the longxi river experimental watershed and identified a three linear hydrological behavior with two storage breakpoints at the watershed scale i e generation threshold tg and rising threshold tr these findings are very significant for identifying the abrupt shifts from slow to rapid runoff generation and flood response in such watersheds a conceptual model explaining the main subsurface stormflow associated with hydrological connectivity under different rainfall intensity conditions was developed to reveal the threshold based hydrological behaviors at hillslope and watershed scales meanwhile it was found that the dominant factors controlling the shift from slow to rapid runoff generation were from the unsaturated soil storage below the tg to storm amounts above the tr the subsurface flow was identified as the main contribution to flash floods at hillslope and watershed scales more importantly above the tr the connectivity of subsurface saturated flow lasted 5 10 min while significantly higher values of contributing areas and stormflow amounts were found during the above tr phase readily triggering huge flash flood disasters these findings suggested that the source area possibly laterally expanded from stream onto neighboring upper hillslopes and also highlighted the potential threshold behaviors of the contributing area associated with runoff generation credit authorship contribution statement guotao zhang conceptualization methodology software data curation visualization peng cui conceptualization supervision funding acquisition project administration carlo gualtieri supervision writing review editing junlong zhang software data curation nazir ahmed bazai writing review editing zhengtao zhang supervision writing review editing jiao wang writing review editing jinbo tang formal analysis rong chen visualization mingyu lei investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was jointly supported by the national natural science foundation of china grant no 41790432 41941017 and u20a20112 and the second tibetan plateau scientific expedition and research program step grant no 2019qzkk0906 we acknowledge the cooperation with mr zhaopeng song from insentek technology co ltd hangzhou china about the support for the insentek sensor probes and also thank for the communications and suggestions from dr kegan k farrick from the university of the west indies st augustine additionally we are very grateful to the editor marco borga and two anonymous reviewers who provided numerous comments and suggestions resulting in an improved manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127107 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3951,understanding the meanings and identifying the controls for the stormflow generation with complex and nonlinear behaviors is essential for the development of threshold based hydrological theory as well as accurate assessment and prediction for flash flood risks however the study of catchment emergent patterns with three linear threshold behaviors associated with hydrological connectivity has received little attention therefore utilizing soil water storage rainfall and streamflow data spanning 3 years in a humid forest experimental watershed dujiangyan city china we elucidated how and where stormflow was generated with nonlinear behaviors which were affected by antecedent wetness and rainfall amounts stormflow threshold behavior was taken as a function of combined gross precipitation and antecedent soil water storage which was isolated using piecewise regression analysis with the identification of two breakpoints i e generation threshold tg and rising threshold tr it was found that the initial emergent behavior of rainfall runoff was generally activated at the tg and then an abrupt shift from slow to fast flood response was possibly triggered at the tr these processes are important to understand the formation and development of flash floods at the watershed scale it was noted that above the tr considerably higher stormflow amounts generally occurred due to the lateral connectivity extension of runoff contributing area from stream to neighboring hillslopes meanwhile gravity driven water movements in soil and better hydrological connectivity during the above tr phase readily triggered the huge flash flood disasters the above tr flash floods with abrupt shifts were predominantly controlled by rainfall amounts while initial below tg stormflow generation was mainly controlled by unsaturated soil water storage more noteworthy under heavy rainstorm conditions the above tr stormflow was dominantly generated by subsurface flow as was demonstrated at hillslope and watershed scales these findings contribute to increasing our understanding of the controls on three linear threshold based hydrological behaviors as well as of subsurface stormflow generation mechanism associated with hydrological connectivity in humid forest watersheds keywords stormflow generation threshold behaviors soil water storage rainfall amounts hydrological connectivity 1 introduction the stormflow extremes derived by climate and anthropogenic changes become more frequent and globally damaging ali et al 2015 allan and soden 2008 yin et al 2018 and readily increase the extremes of flash floods aghakouchak et al 2020 lumbroso and gaume 2012 the urgency for accurate assessment and prediction for flash floods risk requires a more clear understanding of the stormflow generation mechanism and threshold behaviors in mountain headwater watersheds hapuarachchi et al 2011 ross et al 2021 it was demonstrated that runoff generation mechanism in humid forest watersheds could be predominantly controlled by the limited subsurface stormflow with extremely nonlinear behaviors ali et al 2013 tromp van meerveld and mcdonnell 2006a williams et al 2019 which remarkably differed from the reported saturation excess overland flow mugabe et al 2007 and infiltration excess overland flow cammeraat 2004 huang et al 2003 tromp van meerveld and mcdonnell 2006a elucidated the dominant subsurface stormflow generation in a forested watershed usa which generally presented an emergent threshold behavior associated with hydrological connectivity and fill spill theory mcdonnell et al 2021 tromp van meerveld and mcdonnell 2006b little or no stormflow was generated at hillslopes and contributed to the channel streamflow below the threshold for the precipitation or the sum of precipitation and soil water storage but a significant response for the stormflow was observed once above the threshold detty and mcguire 2010a graham et al 2010 tromp van meerveld and mcdonnell 2006a for example tromp van meerveld and mcdonnell 2006a found an increase of 2 orders of magnitude in subsurface flow for events above the threshold compared to those events below the threshold it well reflects the threshold behaviors for subsurface stormflow and two linear runoff response processes which is greatly important to get insight into the nonlinear runoff generation mechanism at hillslope and watershed scales stormflow threshold behaviors were generally subject to the hydrological connectivity of the flows from hillslope to stream as the watershed runoff contributing area increased ali et al 2015 fu et al 2013 activated by preferential flow and subsurface matrix flow haga et al 2005 tromp van meerveld and mcdonnell 2006a the emergent behavior indicated a storage threshold amount but also a runoff contributing threshold area fu et al 2013 below the threshold the runoff was generated in the near stream zones while the runoff contributing sources possibly extended laterally onto the upper hillslopes detty and mcguire 2010a it was noted that these behaviors could be mainly affected by rainstorm size and intensity buttle et al 2019 haga et al 2005 antecedent soil water storage oswald et al 2011 penna et al 2011 landscape and topography detty and mcguire 2010b soil depth and vertical hydraulic conductivity han et al 2020 and forest canopy response scaife and band 2017 larger storms could lead to more mobile water in the soil and rapid streamflow response they possibly result in a higher value of slope derived from the storage stormflow equation during the above threshold phase fu et al 2013 meanwhile high variability for stormflow amounts was often found during the above threshold phase farrick and branfireun 2014b scaife and band 2017 mostly increasing the uncertainty in assessing and predicting the stormflow amounts affected by heavy rainstorms it restricted our insight into the hierarchical input and output processes within the water cycle and exaggerated the uncertainty in simulating the large storms driven flood hydrographs based on a threshold based hydrological model wei et al 2020a proposed the stormflow generation related to three linear threshold behaviors and demonstrated the possible co existence of the runoff generation and rising thresholds it could well characterize the initial streamflow activation and the transition from slow to the rapid response of stormflow but the issue of how to efficiently elucidate the three linear threshold behaviors is not solved wei et al 2020a the scale issue in rainfall runoff processes inherently exists ali et al 2013 but at the watershed scale insights into the three linear threshold behaviors are very essential to develop the threshold based hydrological theory in this study high resolution data 5 min of rainfall soil water storage and streamflow from 2018 to 2020 were collected in a humid forest experimental watershed southwestern china the stormflow i e quick flow was separated from the total flow based on a two parameter recursive digital filter method eckhardt 2005 while the stormflow thresholds of combined precipitation and soil water storage for the events were identified using the piecewise regression analysis pra method the objectives of this work were to 1 quantitatively identify stormflow generation and rising threshold behaviors at the watershed scale 2 exploit the dynamic controls of antecedent wetness and rainfall amounts to the three linear threshold hydrological behaviors with the transition from slow to rapid runoff generation and 3 gain insight into the dominant subsurface stormflow generation associated with hydrological connectivity at hillslope and watershed scales it is very important for understanding the shift from slow to rapid runoff generation and the causes of the catastrophic flash floods associated with the strategies of prevention and mitigation in humid forest watersheds 2 study area the study was conducted in the longxi river lxr experimental watershed 31 n 103 e 80 km northwest of chengdu city sichuan province china fig 1 a and b this watershed as the first level tributary of the minjiang river basin has a drainage area of 78 3 km2 and a total length of 18 2 km this region is characterized by a subtropical and humid monsoon climate with an average annual temperature of 15 2 the mean annual rainfall is approximately 1135 mm with maximum precipitation occurring in august and 80 of the annual precipitation appears in the flood season may october when high magnitude flash flood disasters probably occur zhang et al 2019 this watershed is dominated by forest land with the occupy 90 3 of the whole watershed area in 2018 zhang et al 2021 mainly including indeciduous dark coniferous and broad leaf forests relatively stable vegetation succession is maintained in the tenth year after the wenchuan earthquake yunus et al 2020 zhang et al 2021 when land development is low the soil is classified as haplic luvisols haplic alisols dystric cambisols and chromic luvisols soil textures mainly consist of gravel with 54 leading to the high surface hydraulic conductivity in forest land with the values of mostly 40 200 mm h the bedrock type is mainly composed of granite rock zou et al 2019 which is mostly with a low degree of rock weathering protected by the soils and vegetation when the bedrock is exposed in some areas strong weathering of the granite rock generally occurs possibly leading to a decrease of rock strength some bedrock depression topographies generally exist on the hillslope detty and mcguire 2010b tromp van meerveld and mcdonnell 2006b influencing the flow paths and runoff generation granite is characterized by poor primary permeability overall but strong secondary permeability through cracks and fractures if they are present may enhance permeability high soil surface infiltration and low granite rock percolation rates lead to a significant soil rock interface readily triggering the subsurface stormflow on the interface under heavy rainfall conditions the region with the elevation of 870 3284 m asl is steep with an average slope of 20 and the stream gradient mostly of 287 626 the stream channels are deeply incised with the free faces of approximately 0 3 7 0 m high the channel width ranges from 0 3 m in the upper reaches to 20 67 m in the middle and lower reaches such conditions with high relief abundant orographic rains and strong erosion properties zhang et al 2021 readily triggered catastrophic flash floods and even debris flow events liu et al 2020 such as the 8 13 debris flow event at the wenchuan earthquake affected region on august 13 2010 with a total volume of debris materials of 7 8 106 m3 cui et al 2013 xu et al 2012 3 methods 3 1 hydrometric observations the surface flow velocity and water level automatically recorded at 5 min intervals at gauging stations s1 s6 distributed the whole watershed fig 1c were measured using non contact radar doppler flow meters measurement accuracy 0 01 m s and ultrasonic water level sensors measurement accuracy 0 001 m respectively zhang et al 2019 six cross sectional geometries were measured using manual surveying in combination with an unmanned aerial vehicle method based on the entropy and probability concepts in hydraulics chen 2013 moramarco et al 2004 we utilized the noncontact method provided by zhang et al 2019 to reasonably estimate the mean cross section velocity and flow discharge at 5 min intervals field open precipitation recorded at 5 min intervals including nine rain gauges r1 r9 distributed into the elevations from 884 to 1834 m asl fig 1c was measured using digital tipping bucket gauges with the resolution of 0 1 mm average surface rainfall in the shuiniqiao snq upper watershed fig 1c was assessed based on the thiessen polygon method zhang et al 2021 and the collected runoff data at s6 next to the watershed outlet are analyzed and discussed fig s1 rain events were defined as a total rainfall of at least 1 mm and individual events were separated by 6 h penna et al 2011 wei et al 2020a based on the definition method for rain events 47 events in total were identified from 2018 to 2020 in the lxr watershed to possibly eliminate the uncertainty and nonstationary in threshold behaviors due to seasonal and inter annual variations of land use and vegetation forest canopy scaife and band 2017 we selected the events mostly from june to august of every year from 2018 to 2020 to identify the hydrological threshold behaviors detty and mcguire 2010a farrick and branfireun 2014b volumetric soil moisture content θ cm3 cm 3 at four soil profiles sw1 sw4 across two hillslopes was continuously measured at 5 min interval from 2018 2020 fig 1c using the insentek sensor probes with temperature 0 5 and soil moisture electromagnetic pulse sensors 1 mm fig 2 provided by insentek technology co ltd hangzhou china qin et al 2018 these sensors were installed in the 80 cm soil profiles below the surface at a 10 cm depth interval powered by the equipped built in battery and solar energy the upper sw1 and lower sw2 monitored locations of one hillslope on the left bank fig 1c and 2 were located in coniferous forest land and a mixture of grass shrub land respectively another monitored hillslope sw3 sw4 on the right bank was located on the landslide the depth equivalent antecedent soil water index dasi mm proposed by haga et al 2005 and wei et al 2020a represented the cumulative value of the initial water content at the soil profiles and elaborated the characteristics of shallow soil water storage capacity the dasi at the start of each rainfall event was calculated from the eight layer soil moisture measurements at each soil profile as farrick and branfireun 2014b wei et al 2020a 1 dasi i 1 n θ i d i d i 1 where θi indicates the average soil content between i and i 1 soil layer cm3 cm 3 i 1 2 3 4 n and n indicates the number of soil layers below the surface for the monitored soil depth of 80 cm di indicates the soil depth at the ith layer 10 20 30 40 50 60 70 and 80 cm d0 0 the index that integrated soil moisture with depth was utilized to well exploit the effects of antecedent wetness on the watershed hydrological behavior penna et al 2011 zhang et al 2018 3 2 hydrograph separation to more clearly understand how and where the stormflow was generated and identify the controls for stormflow to the formation and development of flash floods in a humid forest watershed a two parameter recursive digital filter method proposed by eckhardt 2005 was utilized to separate the quick flow i e stormflow qq and delayed flow i e base flow qb from total discharge for the storm runoff events the maximum base flow index bfimax should be the suggested value of 0 8 for a perennial lxr stream with porous aquifers eckhardt 2005 the storm runoff ratio qq p is expressed by the ratio of stormflow amounts qq to grass precipitation amounts p the minimum contributing area equivalent mca with the parameter qq proposed by dickinson and whiteley 1970 indicated the watershed runoff minimum area contributing to the measured storm runoff 3 3 piecewise regression analysis to efficiently characterize the stormflow threshold behavior of combined gross precipitation p and depth equivalent antecedent soil moisture index dasi a piecewise regression analysis pra proposed by oswald et al 2011 and muggeo 2003 could be utilized to quantitatively assess for threshold behavior at lxh watershed to calculate the threshold values i e breakpoints and the derived linear slope parameters we acknowledge the existence of nonlinear and complex stormflow generation but automatic searching and calculating the breakpoints and slope parameters using pra with top down approaches and maximum likelihood approach muggeo 2003 could relatively efficiently determine the emergent hydrological behavior 3 4 soil hydraulic properties test soil hydraulic properties were quantitatively characterized by measuring saturated soil hydraulic conductivity ks in soil profiles to identify the runoff generation under heavy rainstorm conditions farrick and branfireun 2014a a constant head permeameter test proposed by zhang et al 2020 suitable for measuring ks in coarse grained soil with rapid flow was utilized to measure the ks of the undisturbed soil cores based on a derivation of darcy s law johnson et al 2005 zhang et al 2020 20 soil cores samples in multi depth profiles at the upper and lower positions of the hillslope located on the left bank were obtained using the core cutter method and the multi depth ks values were measured in the laboratory to illustrate how ks changed and storm driven soil water moved 4 results 4 1 rainfall runoff relationships large storm events p 10 mm with the 40 event dataset occupying 89 of the total were monitored and collected from 2018 to 2020 fig s1 event precipitation amounts p ranged from 16 4 to 263 9 mm with an average value of 68 0 mm fig 3 a rainfall durations d ranged from 1 5 to 219 h with the mean value 23 h fig 3c and peak rainfall intensities ip from 0 49 to 46 9 mm h fig 3d the stormflow amounts qq for each event with the values from 0 24 to 193 57 mm shown in fig 3h were separated from the total runoff and showed a statistically significant linear relationship with precipitation amounts p qq 12 0 59 p r 2 0 79 p 0 01 fig 4 a it was found that a quite high variability for qq occurred when the p exceeded 19 mm fig 4a the mean value 0 36 for qq p shown in fig 3g and 4d was analogous to that values with 0 07 0 45 reported by some researchers from europe and australia farrick and branfireun 2014b jin et al 2020 marchi et al 2009 merz et al 2006 and the qq p could exceed 0 8 due to the integrated controls from antecedent wetness and rainstorm intensity smith et al 1996 smith et al 2005 weak linear relationships between qq and mean rainfall intensity im rainfall duration d were found fig 4b c especially the runoff coefficient α appeared an abnormal phenomenon i e α 1 shown in fig 5 a which mostly occurred in the range of event peak rainfall intensity ip with 0 2 5 mm h this is mainly due to the relatively small rainfall intensity and the susceptibility to the control of shallow groundwater outflows around the river channel formed by previous rainfall events penna et al 2011 sidle et al 2000 watershed lag times lp from peak rainfall intensity to peak discharge ranged from 0 58 to 23 83 h fig 3i with two groups 5 h and 10 h the events n 16 with 5 h lag time accounted for 40 of the total events while the events n 18 with long lag time 10 h accounted for 45 of the total meanwhile we found a significant negative power function relationship p 0 05 between ip and lag time lp and the strong variability for the lag time occurred when the ip was lower than 15 mm h fig 5c or the im was lower than 5 mm fig 5d when the peak flow was 59 m3 s 1 the corresponding average lag time was 4 98 h meanwhile the peak discharge with 200 m3 s 1 could reduce the time to 3 h this greatly increased the risk of catastrophic flash floods that are difficult to be prevented and mitigated 4 2 effects of antecedent soil moisture on stormflow the depth equivalent antecedent soil water index dasi for 80 cm soil depth was calculated using eq 1 to characterize the shallow soil water storage with the mean values of 78 93 12 79 mm in forest land and a mean of 104 27 8 84 mm in grass shrub land the statistical relationships between dasi and qq were not significant r2 0 017 p 0 05 in all monitored soil points fig 6 a b indicating a little control of only antecedent soil moisture to stormflow this is consistent with what was found in marine humid temperate climate region coweta hydrologic laboratory with sandy loam in north carolina usa scaife and band 2017 and different from that reported in a semi arid inland climate forest watershed with loess soil in gansu province china jin et al 2020 three exceptions i e 2020 08 15 2020 08 29 and 2019 08 19 were found in fig 6a b characterized by that the lower values of dasi also led to the extremely high stormflow amounts the result suggested that the observed extreme values of qq could be affected by other factors except for the dasi parameter such as physiographic heterogeneity and precipitation input synchronism ali et al 2015 carey et al 2010 4 3 stormflow generation and rising thresholds a significant three linear relationship p 0 001 was observed between dasi p and qq fig 6c d when the antecedent soil moisture was summed with the event precipitation amounts p the relationship acturally was different from the aforementioned relationship of p versus qq with strong variability and uncertainty under high rainfall intensities conditions fig 4a based on piecewise regression analysis pra combined with the levenberg marquardt algorithm lm we could optimize and derive the three linear threshold behaviors for dasi p and qq relationship in the forest and grass shrub lands r 2 0 88 p 0 001 fig 6c d and obtained two thresholds i e breakpoints of each location respectively table 1 the low and high thresholds were identified and demonstrated as the stormflow generation threshold tg and rising threshold tr respectively wei et al 2020a the lower tg value of 111 2 mm and higher tr value of 260 7 mm occurred in dominant forest land compared to the tg 130 4 mm and tr 247 9 mm in grass shrub land the initial runoff generation was mainly controlled by larger values for soil moisture deficits compared to the canopy interception capacities scaife and band 2017 wei et al 2020a resulting in lower tg value in dominant forest land the synthesis for canopy interception capacities soil moisture deficits and hillslope flow pathways buttle et al 2019 ebel and mirus 2014 farrick and branfireun 2015 can need more water input in forest land to trigger the rising threshold behaviors at the output the generation and rising thresholds in an extremely high percentage 90 3 for the forest land zhang et al 2021 could mainly represent the hydrological threshold behaviors at the watershed scale three linear hydrological behaviors above and below the two thresholds were identified and shown in fig 6c d it was found that higher values in slope parameter m 1 of regression equations for threshold behaviors occurred in the third phasecompared to the slopes with 0 21 0 49 in the first and second phases table 1 it indicated the faster increase of runoff volume in the third phase when the catastrophic flash floods readily occurred this finding of threshold based hydrological behaviors was very important to understanding and identifying the abrupt shifts of formation and development of flash floods in a humid steep mountain watershed 5 discussion 5 1 controls for hydrological threshold behaviors it was demonstrated in the tropical dry forest or humid mountain watershed farrick and branfireun 2014b han et al 2020 zuecco et al 2017 that when the initial soil moisture deficits for runoff generation threshold were gradually satisfied the streamflow response can be mainly subject to the rainstorm properties however most studies ali et al 2013 detty and mcguire 2010a fu et al 2013 scaife and band 2017 tromp van meerveld and mcdonnell 2006a williams et al 2019 focused on the generation threshold behaviors with different shapes at hillslope or watershed scales and little is considered about the integrated hydrological behaviors for runoff generation and rising thresholds wei et al 2020a understanding how both hydrological emergent behaviors formed could help to reveal the dominant runoff producing mechanism based on the analysis for the three linear hydrological behaviors above and below the thresholds an abrupt shift for mean qq with the several order of magnitudes was found during the three phases fig 7 e and table 2 with values of 3 14 mm 19 00 mm and 138 34 mm respectively this shift is consistent with that reported by oswald et al 2011 in a small catchment in northwestern ontario canada significantly higher values for qq occurred in the above tr phase with the large value in slope parameter m 2 36 of regression equations table 1 indicating the abrupt shift of flash flood above the rising threshold due to more contribution to runoff recharge from both forest canopy interception and soil water scaife et al 2020 wei et al 2020a wei et al 2020b this is consistent with the results obtained by scaife and band 2017 and buttle et al 2019 under the condition of heavy rainstorms the effects of shallow soil water storage on runoff threshold behaviors are multiple and complex mean shallow soil storage of 19 93 at the 80 cm soil layer readily led to a significant increase in stormflow if the shallow soil storage exceeded 24 29 the stormflow changed more obviously with emergent behaviors the threshold for shallow soil storage is close to the 18 23 recorded by james and roulet 2009 and jin et al 2020 but far below the 41 46 of western and grayson 1998 and penna et al 2011 it was noted that no or little runoff was generated when the shallow soil storage is lower than the threshold of 19 93 during the phase the soil water flow was dominantly controlled by vertical flow movement and showed an active depth of 10 70 cm if it was 24 29 with the emergent behavior of runoff generation in the watershed the flow possibly generated a potential transient saturation layer below 80 cm or lateral flow at the soil bedrock interface and formed an subsurface stormflow processes farrick and branfireun 2014b readily resulting in an abrupt occurrence of flash flood disasters van meerveld et al 2015 additionally the lag times ls and response depths ds of soil water during the three phases fig 7b c were compared and analyzed to clearly understand the controls of soil water storage to the threshold behaviours it was found that significantly shorter in lag time ls shown in fig 7b for soil water response with 0 69 h occurred in the third phase below the rising threshold table 2 but during the below tg threshold phase the lag times lp shown in fig 7a for runoff response were significantly shorter than that ls in shallow soil water response the soil infiltration here could be controlled by soil matric suction with hygroscopic water or film water jin et al 2020 possibly resulting in slow soil water flow and long lag time ls for shallow soil water however shorter ls for shallow soil water with deeper response depth ds 80 cm was identified during the below tg threshold tg 111 2 mm phase fig 7c the hydrological behaviors below and above the two thresholds indicated the transitions from suction driven infiltration both capillary force and gravity driven infiltration to only gravity driven infiltration fig 8 the proportion of freely mobile water increased once above the rising threshold in the ③ phase readily triggering the formation and development of flash floods the stormflow amounts below the tg were mainly subject to the substantially larger fraction 86 31 of dasi from dasi p shown in fig 7d and 8 controlled by the unsaturated soil water storage a larger fraction 72 27 of the p from dasi p was found in the above tr phase phase ③ when the storm amounts p dominated the abrupt shift from slow to rapid flash flood generation fig 8 moreover as in jin et al 2020 and torres et al 1998 the maximum soil moisture content 32 under the heavy rainstorm condition did not indicate that the soil was saturated therefore the qq p transition from 0 24 below the tg to 0 60 above the tr fig 7f and table 2 also reflected the rapid increase of subsurface stormflow under the heavy rainstorm conditions through preferred flow pathways or soil water displacement in the unsaturated zone mcguire and mcdonnell 2010 torres et al 1998 change in the dominant factor from unsaturated soil water storage below the tg to storm size and intensity above the tr indicated that once the deficit for soil and canopy storage became low enough little rainfall readily triggered more runoff translated by the storage and contributed to the formation of flash floods in a humid mountain watershed this result is consistent with that reported by farrick and branfireun 2014b in a tropical dry forest catchment mexico without considering the rising threshold under heavy rainstorm conditions the extension and development for the three linear hydrological threshold behaviors rather than two linearity are helpful to understand the formation and development of flash floods as well as its critical abrupt shift processes induced by heavy rainstorms 5 2 subsurface stormflow generation associated with hydrological connectivity to understand the potential subsurface stormflow generation at the hillslope scale three representative rainfall events 2020 08 29 2020 07 21 and 2020 08 30 shown in fig 9 which were below and above the generation and rising thresholds were selected to exploit the rainfall driven soil water movement and runoff generation associated with hydrological connectivity for the below tg event i e 2020 08 29 event with precipitation amounts of 17 2 mm fig 9a and d the response time of soil water in the upper and lower hillslope was not synchronized and the response depth is mostly within 50 cm below the surface with the small values of wetting curve maximum slope smax lozano parra et al 2016 mallet et al 2020 it indicated the soil water movement dominated by matrix flow but little runoff which mainly occurred in the first phase below the tg for the 2020 07 21 event with higher rainfall amounts of 76 6 mm between tg and tr fig 9b and e the response time at the 30 cm soil layer of the upper hillslope was synchronous with that at 50 cm soil layer of the lower where the time for the instantaneous saturation layer with perched water lasted 5 10 min it was related to the lower saturated hydraulic conductivity measured at 30 cm layer of upper location and 50 cm layer of the lower location of the hillslope fig 10 such short connectivity time at the lower hillslope indicated the extension of the runoff contributing area from the channel nearby to the hillslope han et al 2020 as storm intensity increased 2020 08 30 event with rainfall amount 229 1 mm fig 9c and f the response time of soil water in the upper and lower hillslope was synchronized with the larger smax indicating the dominant preferential flow pathways mallet et al 2020 in the upper hillslope an instantaneous saturated zone was observed at a 30 cm soil layer with a connectivity time of 5 min it suggested that the contributing area affected by a heavy rainstorm possibly expanded laterally onto neighboring upper hillslopes ali et al 2013 detty and mcguire 2010a lee and kim 2020 readily triggering the catastrophic flash flood disasters this finding is important for understanding the subsurface stormflow generation mechanism associated with hydrological connectivity in a steep mountain watershed at the hillslope and watershed scales detty and mcguire 2010a and the associated shallow soil failure in slopes cui et al 2014 cui et al 2019a cui et al 2019b and accompanied disaster chain guo et al 2021 guo et al 2020 at the watershed scale the dominant stormflow generation could be identified using indirect hydrological signatures such as the relationship between stormflow and rainfall intensity and between watershed area and lag time dunne 1978 farrick and branfireun 2015 at a watershed where runoff was dominated by infiltration excess overflow hof a significant positive linear relationship r 2 0 96 p 0 001 between stormflow amounts and rainfall intensity was found and verified cammeraat 2004 dunne 1978 martinez mena et al 1998 however in our study the observed weak relationship between stormflow and rainfall intensity r 2 0 117 p 0 484 0 05 via a non parametric test revealed that the stormflow generation was dominantly controlled by subsurface flow demonstrating the role of subsurface streamflow in flash floods the watershed lag time lp watershed area a relationship l p 0 42 a 0 20 proposed and verified by dunne 1978 indicated the assumption that the small experimental watershed with the size of 57 km2 was dominantly controlled by hof where the mean lag time was calculated to be 0 94 h based on the lp a relationship fig 11 however the lag time in the hof dominated watershed was much shorter than that of 9 65 h observed at our experiment watershed the result suggested that the dominant runoff generation in our experimental watershed was the subsurface stormflow but not the hof the relationship between stormflow and combined total precipitation and antecedent soil moisture indeed indicated the storage threshold behaviors but also the contributing area threshold behaviors with runoff generation bartlett et al 2016 detty and mcguire 2010a kim et al 2005 ross et al 2021 scaife and band 2017 zehe and sivapalan 2009 the significantly higher values of qq and qq p above the tr fig 7e f and table 2 readily increased the hydrological connectivity of the hillslope riparian stream fig 8 triggering the expansion of the runoff contributing area from the river channel nearby to the upper part of the hillslope the process reflected the percolation transition characteristic of soil water storage at the hillslope when the qq increased to a certain extent with rainfall detty and mcguire 2010a han et al 2020 mcdonnell 2013 tromp van meerveld and mcdonnell 2006a the threshold behaviors could result in the continuous expansion of the effective connection area between the river channel and the adjacent hillslope once above the tr the qq increased rapidly while lag time lp shortened significantly fig 7e generating the obvious emergent behaviors the contributing area for stormflow generation in this watershed was estimated in light of the minimum contributing area equivalent mca proposed by dickinson and whiteley 1970 it was found that the mean mcas below and above two thresholds were 13 79 km2 22 52 km2 and 34 43 km2 respectively fig 7g and 12 higher values of mca above the tr exceeded 60 of the watershed area significantly increasing the hydrological connectivity of hillslope riparian stream and readily triggering the catastrophic flash flood disasters therefore a conceptual model presenting the subsurface stormflow generation mechanism associated with hydrological connectivity fig 12 was developed to reveal the three linear threshold based hydrological behaviors under different rainfall intensity conditions the stormflow generation processes below and above the generation and rising thresholds were represented by fig 12a 12b and 12c affected by the low middle and high rainfall intensities respectively fig 12a showed the stormflow generation during the below tg phase when soil water movement was predominantly controlled by matrix flow in the form of immobile water fig 8 9a and d 12a the channel discharge is mostly formed by direct rainfall or the recharge of shallow groundwater at the adjacent hillslope as the rainfall intensity increased soil water movement was gradually controlled by both matrix flow and preferential flow pathways fig 12 b the potential perched water and fill and spill process fu et al 2013 tromp van meerveld and mcdonnell 2006b at the bedrock depression of the bedrock soil interface could efficiently increase the hydrological connectivity of stream adjacent hillslope and runoff minimum contributing area mca leading to significantly higher qq values once above the tr with high rainfall intensity fig 12c significantly higher values of mca and qq were found readily triggering the huge flash flood disasters fig 12c the flood flow was dominated by subsurface stormflow generation controlled by the storm size and intensity mostly formed through the vertical preferential flow in coarse grained soils 5 3 challenges for threshold based hydrological behaviors associated with the stormflow generation to clearly understand possible threshold based hydrological behaviors associated with stormflow generation we summarize some challenges that could be addressed in the future we think this summary is helpful for a reasonable assessment of the threshold behaviors and promote the development of a new unifying hydrological research framework based on nonlinear threshold theory ali et al 2013 5 3 1 lack of watershed multiple processes monitoring field watershed experiment design generally focuses on the hydrological multiple processes separately which even are difficult to be quantitatively captured by our instruments or monitoring networks such as subsurface matrix flow preferential flow pressure wave translation farrick and branfireun 2014b etc additionally limited spatial monitoring possibly increases the uncertainty in assessing the threshold behaviors at the watershed scale 5 3 2 nonstationary in threshold behaviors affected by abrupt disturbances and climate change climate change with hydroclimatic extremes could alter the seasonal and inter annual stormflow thresholds and linear response with the variation of the ecosystem and vegetation forest canopy farrick and branfireun 2014b scaife and band 2017 they indicate the long term complexity and non stationarity in threshold behaviors with the uncertainty of the threshold values meanwhile abrupt disturbance events such as strong earthquakes wildfire ice and snowstorm etc could significantly destroy the landscape vegetation and even the vegetation soil system bazai et al 2021 cui et al 2009 ebel and mirus 2014 wei et al 2020a zhang et al 2021 rapidly impairing the original hydrological behavior at local and regional scales and further aggravating the nonstationary in threshold behavior 5 3 3 multi scale assessment uncertainty for threshold behaviors effective multi scale threshold metrics are difficult to be derived due to the effects of physiographic heterogeneity and precipitation input synchronism ali et al 2015 carey et al 2010 the unified emergent behaviors at hillslope or catchment scales could have not always proven successful mcdonnell et al 2007 possibly resulting in different shapes of nonlinear threshold behaviors ali et al 2013 and increasing the uncertainty in assessing the threshold behaviors these limitations possibly hinder the development and generalization of the unified threshold based hydrological theory 6 conclusions in community level field experiments the current understanding of stormflow generation and the development of threshold based hydrological behaviors is still limited the study examined the relationship among shallow soil water storage rainfall and streamflow in the longxi river experimental watershed and identified a three linear hydrological behavior with two storage breakpoints at the watershed scale i e generation threshold tg and rising threshold tr these findings are very significant for identifying the abrupt shifts from slow to rapid runoff generation and flood response in such watersheds a conceptual model explaining the main subsurface stormflow associated with hydrological connectivity under different rainfall intensity conditions was developed to reveal the threshold based hydrological behaviors at hillslope and watershed scales meanwhile it was found that the dominant factors controlling the shift from slow to rapid runoff generation were from the unsaturated soil storage below the tg to storm amounts above the tr the subsurface flow was identified as the main contribution to flash floods at hillslope and watershed scales more importantly above the tr the connectivity of subsurface saturated flow lasted 5 10 min while significantly higher values of contributing areas and stormflow amounts were found during the above tr phase readily triggering huge flash flood disasters these findings suggested that the source area possibly laterally expanded from stream onto neighboring upper hillslopes and also highlighted the potential threshold behaviors of the contributing area associated with runoff generation credit authorship contribution statement guotao zhang conceptualization methodology software data curation visualization peng cui conceptualization supervision funding acquisition project administration carlo gualtieri supervision writing review editing junlong zhang software data curation nazir ahmed bazai writing review editing zhengtao zhang supervision writing review editing jiao wang writing review editing jinbo tang formal analysis rong chen visualization mingyu lei investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was jointly supported by the national natural science foundation of china grant no 41790432 41941017 and u20a20112 and the second tibetan plateau scientific expedition and research program step grant no 2019qzkk0906 we acknowledge the cooperation with mr zhaopeng song from insentek technology co ltd hangzhou china about the support for the insentek sensor probes and also thank for the communications and suggestions from dr kegan k farrick from the university of the west indies st augustine additionally we are very grateful to the editor marco borga and two anonymous reviewers who provided numerous comments and suggestions resulting in an improved manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127107 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3952,subsurface flow models are inherently imperfect and the associated model error can lead to unreliable flow predictions in this work we introduce treatments for model error in a data space inversion dsi framework dsi is a history matching procedure that constructs posterior flow predictions for quantities of interest directly within a bayesian setting using a large set of prior model flow simulation results and observed data the model error considered in this work derives from the use of upscaled coarsened surrogate models for the prior model flow simulations required by dsi our error treatment entails the simulation of a set of corresponding pairs of fine and upscaled models these results are used to construct a principal component analysis pca representation of error a linear regression approach is introduced to capture the coupled nature of the coarse scale simulation output and model error to construct posterior dsi predictions a joint inversion on coarse scale simulation data and model error is performed using an ensemble smoother with multiple data assimilation both the prior simulation data and error terms are parameterized using pca based procedures results are presented for two phase flow in 3d channelized geomodels the corrected prior and dsi posterior results are compared to reference results generated from fine scale simulations comparisons are presented for flow statistics mahalanobis distance and relative error for multiple synthetic true models the coupled model error treatment is shown to provide highly accurate prior results and posterior predictions that agree closely with reference results significant improvement relative to uncorrected coarse models is observed the treatments developed here can be used to represent error from many different sources in a variety of subsurface flow settings keywords subsurface flow data space inversion data assimilation model error upscaling 1 introduction data assimilation is a challenging but essential step for the efficient management of subsurface flow operations such as aquifer remediation oil gas production or co2 storage the objective of model based data assimilation or history matching is to calibrate geological model parameters based on observed data this generally leads to reduced uncertainty in model predictions in traditional history matching the forward model applied to represent the physical system is usually assumed to be perfect e g unbiased meaning there is no model error model error is however inevitable in practical settings and can result from unresolved scales physics upscaling model coarsening or simplified representations of subsurface fluid properties such as phase behavior neglecting to account for model error in the data assimilation procedure may lead to biased and thus unreliable posterior history matched flow predictions in this paper we implement treatments for representing model error in a data space inversion dsi method data space history matching represents an alternative to traditional approaches as it does not entail the calibration of model parameters instead posterior flow predictions and associated uncertainties are constructed from an ensemble of prior flow responses within a bayesian framework dsi requires the simulation of a large number of prior models typically o 500 1000 which represents the bulk of the computational demand the introduction of model error treatments into the dsi methodology enables us to perform most of the required flow simulations on highly coarsened models this provides significant computational savings and our treatment represents a general approach that can be used to represent model error from a variety of sources many approaches have been developed to account for model error in the inversion process thus far all of these procedures have been implemented with traditional model based rather than data space history matching techniques we classify these methods into two categories based on the error source the first set of approaches aims to treat model errors that derive from unknown sources different approaches involving modification of the error covariance matrix have been applied to account for unknown error vink et al 2015 for example noted that neglecting model error can lead to unreasonably small posterior uncertainty they used a single inflation factor on the measurement error to circumvent this issue sun et al 2017 extended their work by designing different inflation factors for different data types oliver and alfonzo 2018 developed an iterative model improvement workflow that combines model calibration with model criticism and model improvement the model criticism step assesses whether the calibrated models are consistent with the observations model improvement is then applied if large discrepancies exist the total error covariance matrix is determined based on the residual of observation and calibration results alfonzo and oliver 2020 extended this workflow and applied it to seismic data assimilation with more model parameters and observation data evensen 2019 and evensen 2021 formulated the iterative ensemble smoother with model error by representing model error in terms of random variables that are updated during the inversion process the framework requires the proper quantification of error correlation rammay et al 2021 developed a flexible iterative ensemble smoother by introducing a residual ensemble and a split parameter the residual ensemble is divided into model update and model error parts the split parameter which is adjusted in the inversion process balances the quality of the posterior parameters and the quality of the simulation output from the corresponding imperfect models the second set of approaches treats model error from known sources surrogate or upscaled models are widely applied for subsurface flow and model error statistics can be generated by comparing the high fidelity high accuracy reference solutions to the approximate solutions trehan et al 2017 applied high dimensional regression techniques random forest and lasso to estimate model error resulting from the use of a reduced order surrogate model trehan and durlofsky 2018 further developed the random forest based treatment to quantify the model error resulting from an upscaling procedure these methods were applied only for forward modeling and their use in inversion was not considered josset et al 2015 and josset et al 2015 applied functional principal component analysis fpca for dimension reduction and modeled error by constructing linear regressions between the latent space of the exact and proxy simulation results a markov chain monte carlo mcmc procedure was applied for inversion and acceptance results were improved using the error treatment josset et al 2015 köpke et al 2018 developed a local approach in which the basis used to characterize model error statistics was constructed from a small set of paired detailed and approximate models additional high fidelity simulations are required during the inversion procedure to update the model error representation in subsequent work köpke et al 2019 applied pca and constructed a global basis to represent model error rammay et al 2019 and rammay et al 2020 developed a joint inversion framework with an ensemble smoother with multiple data assimilation esmda to correct for upscaling error they took model error to be independent of both simulation input and output and applied pca to represent model error statistics model parameters and latent variables for model error were then updated through application of esmda and improved posterior parameters and predictions were achieved the standard dsi methodology was developed by sun and durlofsky 2017 and sun et al 2017 dsi operates within a bayesian framework to provide posterior flow predictions conditioned to observed data for particular quantities of interest qoi these qoi are typically time series of injection production rates for each well in the subsurface flow model the prior data space includes these time series data realizations for a large number of prior geomodels parameterization of the data vectors which enables their representation in terms of a small set of latent variables is useful in dsi existing parameterizations include pca based methods sun et al 2017 sun and durlofsky 2017 sun and durlofsky 2019 jiang et al 2020 and a recurrent autoencoder rae treatment jiang and durlofsky 2021 jiang et al 2021 posterior sampling in dsi was originally accomplished using a randomized maximum likelihood rml method the use of esmda in this context was introduced by lima et al 2020 jiang and durlofsky 2021 and jiang et al 2021 considered a range of dsi treatments and found rae parameterization with esmda to provide the best overall performance though the pca based parameterization also provided satisfactory results a number of prediction focused methods scheidt et al 2015 satija and caers 2015 satija et al 2017 park and caers 2020 jeong et al 2018 he et al 2017 he et al 2019 which share many similarities with dsi have also been developed and applied for a range of subsurface flow processes the dsi and prediction focused methods noted here were all designed under perfect model assumptions i e model error was not included in the inversion process in this work we implement and evaluate a treatment for model error within a dsi framework we consider model errors that derive from known sources which in our case is an upscaling process the error treatments are incorporated into a dsi procedure that includes pca based data parameterization and esdma for posterior sampling model error is quantified as the difference between the high fidelity fine scale and coarse scale simulation outputs for well rate time series using simulation results for corresponding fine coarse pairs for 20 of the realizations considered in dsi we construct a pca representation for model error our treatment is similar to that applied by rammay et al 2019 in that work model error was assumed to be independent from model parameters or simulation output here we also develop a coupled error treatment which entails the construction of a linear regression model that approximates the relationship between model error and simulation output we consider an ensemble of 3d channelized models and apply our model error treatments to correct both prior and posterior two phase flow predictions dsi results using uncorrected coarse models and coarse models with the model error treatments are compared to reference fine scale predictions detailed assessments are presented for two synthetic true models and summary results are provided for a set of five true models this paper proceeds as follows in section 2 we review the basic dsi procedure the error model treatments used in this work as well as their incorporation into the esmda dsi framework are described in section 3 in section 4 we first present the 3d channelized system and the global single phase transmissibility upscaling procedure applied in this study next detailed prior and posterior results involving the use of uncorrected coarse models and coarse models with two treatments for model error are compared to reference fine scale results for a two phase flow problem finally in section 5 we summarize this work and provide suggestions for future studies in this area 2 dsi with perfect model assumption we begin this section with an overview of the data space inversion dsi procedure for cases without model error i e under the perfect model assumption we describe the basic procedure developed by sun and durlofsky 2017 and sun et al 2017 and then discuss the combination of dsi with ensemble smoother with multiple data assimilation esmda the linkage of dsi with esmda was introduced by lima et al 2020 and later applied by jiang and durlofsky 2021 2 1 basic dsi formulation the dsi procedure entails the direct generation of posterior forecasts conditioned to the observed data for particular quantities of interest qoi in this work these qoi correspond to time series of well by well injection and production rates the key distinction between dsi and model based inversion is that in dsi we do not determine posterior model parameters just posterior predictions for a set of qoi as in most inversion procedures the forward model is assumed to be perfect meaning systematic errors introduced by approximations are neglected in the standard dsi formulation we let m i i 1 2 n r denote the set of prior model realizations where n r o 500 1000 represents the number of prior realizations considered in dsi let g represent the mathematically perfect forward simulation process that provides the qoi the data variable for realization i denoted d i contains concatenated time series of well rate quantities data variables are generated through application of 1 d i g m i the data vector d i r n f 1 includes simulation results d hm r n hm 1 from the historical period and data d pred r n pred 1 from the prediction period i e we can write d i d hm i t d pred i t t note that n f n hm n pred in practice the observed data correspond to well rate measurements from the actual field operation in this work we instead consider synthetic data generated by simulating a new random model that is not contained in the prior ensemble this model is then taken to be the true model m true under the perfect model assumption the observed data d obs r n hm 1 are directly generated from 2 d obs h d true d where d true denotes the data variables corresponding to m true h r n hm n f is a selection matrix containing zeros and ones that extracts data for the observation period from the full data vector and d r n hm 1 denotes the measurement error in standard dsi we include measurement error but neglect model error meaning we assume the forward simulation process g represents the real system the measurement error d is sampled from the gaussian distribution n 0 c d where c d is the data error covariance matrix the dsi process is performed within a bayesian framework in the special case where the data variables are multivariate gaussian distributed the posterior probability density function pdf for data vector d given the observation d obs is given by 3 p d d obs exp 1 2 h d d obs t c d 1 h d d obs 1 2 d d prior t c pd 1 d d prior where d prior and c pd represent the mean and covariance for the prior gaussian distribution of d 2 2 data parameterization in subsurface flow processes the data vector d corresponds to output from a highly nonlinear forward simulation g and as a result it is generally not multivariate gaussian distributed data parameterization is thus introduced to map the high dimensional non gaussian variables d to low dimensional nearly gaussian distributed latent variables ξ r n l 1 where n l denotes the dimension of the latent space thus the data variables are now represented as d d f ξ where d denotes the parameterized data variables generated from the mapping of ξ and f denotes the parameterization function the posterior pdf for latent variable ξ is given by 4 p ξ d obs exp 1 2 h f ξ d obs t c d 1 h f ξ d obs 1 2 ξ t ξ for the parameterization f ξ sun et al 2017 developed a method that combines principal component analysis pca with histogram transformation post processing this method is very efficient and it is capable of handling data of various types e g time series and co2 saturation fields at particular times as in sun and durlofsky 2019 histogram transformation preserves the marginal distribution for single variables but it does not preserve the correlations between different data variables and these can be important in some settings jiang and durlofsky 2021 recently developed a deep learning based parameterization that applies a recurrent autoencoder rae to represent multivariate time series data the rae based method was shown to better preserve the overall physical character and time series correlations in the well rate data although the rae based procedure can provide superior results for some qoi in this work we will apply the standard pca based treatment we proceed in this way because our intent is to construct an error model from results for relatively few e g 100 high fidelity fine scale models these 100 simulations do not provide nearly enough data for the construction of an rae representation for that we would need o 1000 simulations so we are constrained to consider error models of relatively simple form as we will see in section 3 these models involve a pca representation of data error combined with linear regression given this simple form error model there is little if any advantage in applying the sophisticated rae parameterization for the approximate data variables we now give an overview of the pca based data parameterization sun et al 2017 we first construct a data matrix d r n f n r which includes all centered data realizations as columns 5 d 1 n r 1 d 1 d prior d 2 d prior d n r d prior singular value decomposition svd of matrix d is then performed which allows us to write d u σ v t where u and v are the left and right singular matrices and σ is a diagonal matrix containing the singular values the pca basis matrix φ r n f n l is given by φ u σ where u r n f n l and σ r n l n l are truncated such that n l n f an energy criterion sun and durlofsky 2017 is applied to determine an appropriate value for n l a parameterized data realization d pca can now be generated by applying d pca φ ξ d prior if the prior latent variables ξ r n l 1 are sampled from the standard normal distribution the resulting d pca are also gaussian distributed this pca mapping may however generate nonphysical e g negative flow rates especially when the mean of the original prior is close to zero this behavior can be improved by applying histogram transformation ht in a post processing step we apply ht to map the pca realization d pca from a gaussian distribution to the parameterized data d in this way the prior distribution for each variable at each time step is recovered the mapping is based on the cumulative distribution function cdf of the prior ensemble f t d and pca realizations f i d pca we generate the parameterized data d as 6 d h t d pca f t 1 f i d pca where h t denotes the mapping function for the ht process and f t 1 indicates the inverse mapping from the cdf to the prior data this process ensures that the distribution for each variable corresponds to that in the prior though it does not maintain the joint distribution between different time steps or variables 2 3 posterior sampling in the final step of dsi a posterior sampling method is applied to generate posterior predictions for the qoi sun and durlofsky 2017 used an optimization based randomized maximum likelihood rml method for this while lima et al 2020 implemented a data space esmda procedure jiang and durlofsky 2021 applied esmda with both the pca and rae based parameterizations and also found it to be an efficient and effective posterior sampler in the dsi setting therefore esmda will be applied in this work the esmda update equation for the latent variables given by jiang and durlofsky 2021 is written as 7 ξ i k 1 ξ i k c ξ d hm k c d hm k α k c d 1 d obs α k e i k d hm i k for i 1 n r and k 1 n a where n a denotes the number of data assimilation steps and α k denotes the inflation coefficients according to emerick and reynolds 2013 the inflation coefficients α k must satisfy the requirement k 1 n a α k 1 1 in this work we assimilate data four times and use the same inflation coefficient at each step α k 4 for k 1 4 the use of larger n a or different α k was found to have very little impact on our results at each iteration k the historical period data d hm i k are generated from the parameterization process as d hm i k h f ξ i k recall that h is an extraction matrix the updated ensembles of d hm k and ξ k are used to construct the auto covariance matrix c d hm r n hm n hm and the cross covariance matrix c ξ d hm r n l n hm the error vector e i k in each step is sampled from a gaussian distribution n 0 c d we denote the posterior latent variables after n a iterations are completed as ξ post the posterior predictions d post are then constructed through application of d post d post f ξ post please see jiang and durlofsky 2021 for more details on the basic dsi procedure 3 dsi with model error our intent in this study is to apply dsi with imperfect forward models simulation models that are fast but approximate can be highly useful in practice especially in settings where large numbers of simulations must be performed such as data assimilation optimization and uncertainty quantification however without a gauge of the error they induce predictions from approximate models can be difficult to interpret thus the quantification of model error is an important general topic here we consider errors that arise from upscaling this is a particularly useful type of error to study since upscaled models are commonly used in practical studies in this setting we can simulate some number of fine scale models along with their upscaled counterparts these paired results then allow us to construct an explicit error model the approach presented here should also be applicable to any situation where we are able to identify the perfect model corresponding to a particular approximate model examples include the use of a compositional model with a few lumped components in place of a multicomponent model the use of a streamline simulator in place of a standard finite volume or finite element simulator or the use of an isothermal representation in place of a system with thermal effects our approach is not directly applicable when the cause of the model error is unknown though some of the treatments may still be useful 3 1 model error definition we let m denote the imperfect upscaled model and g the associated forward simulation the prior ensemble of approximate imperfect data variables d i is generated via d i g m i for i 1 n r by introducing a model error term denoted by m full i we can express the high fidelity data vector d as 8 d i g m i g m i m full i d i m full i where m full i is due to upscaling as noted earlier observed data in practice would derive from field measurements but here we use synthetic data namely results from the perfect simulation model g to represent the real system it follows from eqs 2 and 8 that the observed data d obs can be represented as 9 d obs h d true d h g m i d h g m i m hm i d where m hm i h m full i denotes the model error during the historical period in the bayesian framework the total error covariance c tot which includes model error and data error covariance is given by 10 c tot c m hm c d hc m full h t c d where matrices c m hm and c m full represent the covariance of model error in the historical and full simulation periods respectively in the dsi framework the correct perfect data vectors correspond to perfect fine scale reservoir models however our goal is to actually simulate only a relatively small fraction of the fine scale models and to simulate most realizations at the coarse scale thus achieving computational savings we use n r to denote the number of coarse scale prior realization simulations and n r e to indicate the number of fine scale simulations for each of the n r e randomly selected fine scale runs we also simulate the corresponding coarse scale model in this work we take n r 500 and n r e 100 this value of n r e was established through numerical experimentation on a related 2d problem some justification for the use of n r e 100 will be provided in section 4 2 we expect that this value could be reduced by using a well designed selection procedure in place of the random selection applied here note that dsi requires many more than 100 prior data realizations so we could not simply apply dsi using only the fine scale d i i 1 n r e data vectors the ensemble of approximate prior simulation results is expressed as d i g m i i 1 2 n r the model error m full i from the upscaling process is computed from corresponding pairs of fine perfect and coarse scale approximate simulation results i e 11 m full i g m i g m i d i d i i 1 2 n r e this set of n r e model error vectors is used to quantify the error statistics when applying dsi with model error we perform joint inversion on approximate data variables d and model error m full to correct the posterior predictions as proposed by rammay et al 2019 model error is represented using a pca based parameterization which we now describe 3 2 model error parameterization from the flow simulations for n r e pairs of fine scale g m i and approximate g m i models we construct the centered matrix d e as 12 d e 1 n r e 1 m full 1 m full m full 2 m full m full n r e m full where m full represents the mean of the prior model error realizations the basis matrix for error φ e r n f n l e is generated by performing svd on the data matrix d e where n l e denotes the number of columns retained the latent variables β r n l e 1 are generated through application of β i φ e t m full i m full the pca representation of each model error realization m full i is 13 m full i φ e β i m full i 1 2 n r e for the model error parameterization we preserve about 80 of the energy which corresponds to a small number 5 of latent variables this approach is consistent with that suggested by rammay et al 2019 and avoids over fitting the error term with this treatment the difference between m full and m full defined as the error residual is not negligible therefore the corresponding residual covariance is incorporated into the overall error covariance term let ζ denote the residual of model error not captured in the pca parameterization i e 14 ζ i m full i m full i the covariance c res for model error residual is 15 c res 1 n r e 1 i 1 n r e ζ i ζ i t in the framework of dsi with model error the residual covariance and measurement error covariance are both included in the total error covariance matrix c tot as 16 c tot c d c res consistent with the treatment suggested by rammay et al 2019 the covariance matrix c res contains only diagonal terms the model error latent variables β are only available for n r e prior realizations however the β for all n r prior realizations are required to correct both the prior and posterior data rammay et al 2019 proposed an input and output independent model error formulation with this approach prior realizations of β i i 1 2 n r are directly sampled from the gaussian distribution n β c β where β and c β denote the mean and covariance of β from the n r e samples this independent model error assumption however neglects any correlations between β and d or ξ as will be shown later this approach is effective for the test cases considered in this work but it can overly inflate the uncertainty associated with some of the prediction statistics we thus consider an alternative approach where we treat β as a specified function of ξ in this work we restrict ourselves to a linear model because we have only a limited number of ξ β pairs and we wish to avoid over fitting the regression model is thus expressed as 17 β w ξ b where matrix w r n l e n l and b r n l e 1 denote the weight and bias terms respectively with this representation prior realizations of β i are generated as β i w ξ i b for i 1 2 n r for the system considered in section 4 the correlation coefficient of the linear regression in eq 17 is 0 68 thus a residual exists and we explored adding random noise to β to account for this effect specifically we assessed the use of β w ξ b e where e denotes random noise generated from a gaussian distribution with zero mean and covariance based on the regression residual we found that this treatment had very little effect on the results i e nearly identical results were achieved using only eq 17 thus in all results in this paper we apply eq 17 as written without random noise e 3 3 joint inversion with esmda a joint inversion for both data and model error using esmda is applied within the dsi framework we first simulate n r upscaled models the upscaling procedure will be discussed in section 4 the latent variables ξ i i 1 2 n r for approximate data variables d i i 1 2 n r are generated through application of ξ i φ t d i d prior we then randomly select n r e realizations from the n r prior upscaled models fine scale simulations are run for these n r e models and the model error statistics are then constructed the latent variables β are generated from the pca parameterization for model error under the independent model error assumption the prior realizations of β i i 1 2 n r are sampled from the gaussian distribution n β c β with the coupled error treatment the prior data β i are generated based on the linear regression model β i w ξ i b for i 1 2 n r the joint inversion with latent variables ξ and β can be expressed as rammay et al 2019 rammay et al 2020 18 ξ i k 1 ξ i k c ξ d hm k c d hm k α k c tot 1 d obs α k e i k d hm i k β i k 1 β i k c β d hm k c d hm k α k c tot 1 d obs α k e i k d hm i k for i 1 n r and k 1 n a where c β d hm denotes the cross covariance between β and d hm the vector e denotes the random noise sampled from n 0 c tot and all other variables are as defined previously the data vector d i k at each assimilation step is generated via 19 d i k f ξ i k φ e β i k m full negative nonphysical data are set to zero during the inversion process to avoid spurious results the data in the historical period are extracted from d i k using d hm i k h d i k after n a iterations the posterior predictions for d are generated from the posterior final ξ and β using eq 19 in the inversion process esmda performs linear updates of the latent variables β and ξ similarly a linear relationship between β and ξ is introduced in the priors when the coupled error model is applied because the esmda updates are linear the relationship between β and ξ is maintained throughout the esmda procedure this important consistency is another reason for using a simple linear relationship in the coupled error model in fact with the linear model in eq 17 we actually do not have to perform the joint inversion as written i e we only need the first expression in eq 18 this is because the linear relationship is perfectly preserved in the esmda inversion process more specifically inverting only for ξ we can construct the corresponding posterior prediction for β from eq 17 the fact that precisely the same results are achieved with either joint inversion or by inverting only for ξ and then applying eq 17 was confirmed numerically we do however need to apply the joint inversion if the independent model error procedure is used or if we specify a more general nonlinear relationship between β and ξ in the latter case the relationship should be rechecked verified after data assimilation is performed to assure consistency the overall framework for dsi with coupled model error is provided in algorithm 1 algorithm 1 dsi with coupled model error 4 model error treatment for flow in 3d channelized system in this section we first describe the general problem setup and the upscaling procedure used to generate the coarse models we then present detailed results using our model error corrections 4 1 problem setup and upscaling procedure the 3d bimodal channelized models used in this work were generated by crain 2020 the models include sand and shale rock types with permeability variation in each facies the fine scale geomodels are defined on a 60 60 30 grid with uniform blocks of size 20 m 20 m 5 m a total of 500 fine scale realizations are considered four realizations of log permeability are shown in fig 1 detailed results will be shown for the models in fig 1 a and b there are two vertical injectors and two vertical producers all four wells penetrate and are open to flow the full formation thickness the fine scale geological realizations were conditioned to hard data at all 30 layers at the well locations the porosity is constant and set to 0 3 in all blocks in the models we model a two phase fully immiscible flow system the setup could correspond to an aquifer remediation project involving a nonaqueous phase liquid referred to as oil recovered through water injection or to a hydrocarbon production scenario the relative permeability curves for the two phases are shown in fig 2 the initial saturations for the two phases are 0 1 water and 0 9 oil the water viscosity is constant at 0 5 cp the viscosity of the oil varies with pressure the range here is from 1 72 1 93 cp the initial formation pressure is 200 bar the two injection wells and two production wells are prescribed to operate at fixed bottom hole pressures of 250 bar and 150 bar respectively note that these pressures bhps are the values at the uppermost well completion wellbore pressure varies with depth due to gravitational effects all flow simulations are performed using ad gprs stanford s automatic differentiation based general purpose research simulator zhou 2012 this simulator is based on a finite volume numerical formulation the coarse scale models are defined on a 12 12 10 grid this corresponds to an overall upscaling factor relative to the fine model of 75 which represents a high degree of coarsening a flow based single phase global transmissibility upscaling procedure is applied to generate the coarse models transmissibility is an interface property defined as the ratio between block to block flow rate and pressure difference the upscaling code was developed by crain 2020 and is based on approaches developed by zhang et al 2008 and chen et al 2008 the upscaled model is defined in terms of the coarse block to block transmissibilities and coarse scale well indices well indices are analogous to transmissibilities as they numerically link the wellbore to the blocks in which it is located referred to as well blocks in the upscaling procedure the global fine scale single phase flow problem is first solved in this solution flow is driven by the two injectors and two producers operating at the bhps noted above this solution is fast to compute because it involves only a single steady state solution in contrast to the transient two phase problem which must be solved through time the fine scale single phase solution provides the pressure in all grid blocks and the flow rates across all cell interfaces the coarse scale transmissibilities and well indices are then calculated from these fine scale simulation results we now present the key equations used in the upscaling all quantities at this point can be viewed as dimensionless let α denote the interface of two fine scale cells and β denote the interface of two coarse scale cells the flow rate f β c between two coarse scale cells is estimated as the sum of the fine scale flow rates f α f over the target interface the pressure p β c in the coarse blocks on each side of coarse scale interface β is the bulk volume average p β of the fine scale pressures in the range of the coarse blocks consistent with the definition of transmissibility the upscaled transmissibility t β is given by 20 t β f β c p β c p β c α β f α f p β p β and the upscaled well index wi by 21 wi f w c p i c p w l f l w f p i p w here the flow rate f w c for the coarse well block i is calculated as the sum of the fine scale well rates f l w f over the coarse block range p i c denotes the coarse scale block pressure bulk volume average of the underlying fine block pressures and p w represents the wellbore pressure evaluated at the center of the coarse block for a small subset of coarse blocks it is possible to have very low flow rates and very little pressure difference between blocks this situation can give rise to nonphysical results for t β computed via eq 20 for these blocks we compute upscaled permeability using a geometric average and then generate t β based on a harmonic average of the block permeabilities consistent with the usual way of constructing transmissibility from block permeabilities this treatment has negligible impact on the accuracy of the overall coarse model because it is applied in very few 1 blocks and these typically lie in regions with little flow please see crain 2020 for additional details on the upscaling procedure the global transmissibility upscaling procedure described above is essentially the most accurate permeability transmissibility upscaling method available nonetheless because the coarse models do not contain any treatment for subgrid transport effects i e we do not upscale the two phase flow functions the high degree of upscaling applied here leads to significant error in two phase simulation results we apply the methodology described in section 3 in order to correct this error our overall procedure is as follows we simulate n r 500 coarse scale models upscaled from fine models using the approach described above to generate the prior ensemble of coarse scale data vectors the simulation time frame is 3050 days the flow data are collected every 30 days starting at day 60 the number of time steps at which data are saved is n t 100 the simulation outputs include the water injection rates from the two injectors denoted i1 and i2 and oil and water production rates from the two producers p1 and p2 we thus consider n qoi 6 quantities of interest the length of the data vector is n f n qoi n t 600 in order to construct the error model we simulate n r e 100 fine models randomly selected from the full set of n r models it is useful to evaluate the computational complexity of dsi with the model error treatment to assess the degree of savings this procedure provides the cost of the overall workflow results almost entirely from the flow simulations that must be performed the application of the dsi process itself is negligible we quantify computational costs in units of fine model flow simulations the cost of the reference procedure which entails the simulation of n r 500 fine models is thus c fine 500 it is important to note that the linear solutions required during two phase flow simulation and upscaling dominate the computational costs of these procedures when we apply dsi with the model error treatment all n r 500 realizations are upscaled from 60 60 30 a total of m fine 108 000 cells in each geomodel to 12 12 10 m coarse 1440 cells in each geomodel the upscaling cost is essentially the computational time required for a fine scale steady state flow solution involving one unknown pressure per grid block in the fine scale two phase flow simulations required for dsi we have two unknowns per grid block pressure and water saturation o 100 time steps and multiple newton iterations and thus linear solutions per time step because the governing flow equations are nonlinear this corresponds to around 500 linear solutions of a system of dimension 216 000 for each run thus the upscaling computations for all 500 models correspond to less than one fine scale two phase flow simulation assuming the computational cost of the two phase flow simulation runs scales linearly with model size super linear scaling which is observed in many cases will lead to higher speedup factors the speedup achieved by the coarse scale models is about m fine m coarse 75 thus the cost of simulating the n r 500 coarse models is about 500 75 7 the error modeling procedure also requires the simulation of n r e 100 fine models the total cost of applying dsi with the model error treatment is therefore about c moderr 1 7 100 108 which represents nearly a factor of 5 speedup relative to c fine 500 it is evident that the speedup factor is essentially equal to n r n r e as the fine scale two phase flow simulations dominate computational cost we note finally that observed speedups may differ from this value due to simulator overhead e g initialization and to communication and i o issues if parallel processing is used 4 2 error model results for prior flow statistics to enable comparisons against reference results in this work we perform forward simulation g on the full set of fine scale geomodels m i i 1 2 n r this provides reference prior statistics for the data variables d i i 1 2 n r note that the point of using the error model is to reduce the fine scale simulation requirement i e simulate only n r e fine models rather than all n r fine models simulation of all fine models is necessary here however because our goal is to assess the performance of our treatments we first apply the model error treatment to correct the coarse scale simulation results for the prior models we generate the ensemble of model error realizations m full i i 1 2 n r e from the simulation results for corresponding pairs of fine and coarse scale models pca parameterization is then applied to generate latent variables β to represent model error we preserve n l e 5 latent variables to parameterize the upscaling error recall that it is important to avoid over fitting we will apply both the independent model error and the coupled output dependent model error treatments to correct the coarse scale prior statistics before presenting results for prior flow quantities it is of interest to consider the effect of n r e on the energy preserved in the pca model relating m full i to β i eq 13 this can give us an idea of an appropriate value for n r e the number of fine scale simulations performed here we use n r e 100 which corresponds to 20 of n r fig 3 shows the energy preserved with n l e 5 components columns in the φ e matrix as a function of n r e for each value of n r e the results in fig 3 represent the average of 100 random samplings of realizations the energy preserved decreases with increasing n r e plateauing at around 0 77 in this case it is evident that the use of small values of n r e can result in overfit high fraction of total energy retained which is important to avoid in the error model while most of the decrease has occurred by n r e 100 similarly shaped curves were also observed for n l e 3 and 7 thus we believe the use of n r e 100 represents an appropriate choice as this value is large enough to avoid overfit with reasonable values of n l e while being small enough to still provide significant efficiency gains the optimal number of fine scale realizations as well as the specific realizations selected should be further investigated in future work we now consider results for prior flow qoi fine coarse and corrected results for water injection rate wir are shown in fig 4 and those for water and oil production rates wpr and opr appear in fig 5 these results are presented in terms of the p10 p50 and p90 10th 50th and 90th percentile responses over the full set of n r results note that the p50 response at different time steps may correspond to different realizations and similarly for p10 and p90 in the figures the red dashed curves which appear in all subfigures show the p10 p50 and p90 fine scale reference results the blue dotted curves in the left columns show the uncorrected coarse scale results the black dash dotted curves in the middle columns represent corrected coarse results using the independent error treatment and the black solid curves in the right columns show corrected coarse results with the coupled model error treatment the results in the left columns in figs 4 and 5 show that the coarse scale prior statistics are biased compared with the reference fine scale results i e the upscaling error is significant due to the high degree of coarsening applied in fig 4 a and d we see that the coarse models underestimate water injection rate in both wells by introducing the model error treatment highly accurate p10 p50 and p90 prior results for water injection are achieved using either of the error treatments the results in fig 5 a and g show water production for wells p1 and p2 the coarse scale results display late water breakthrough and lower water production relative to the fine scale results again using either model error treatment the corrected prior results fig 5 b c h and i are in close agreement with the reference fine scale results prior oil production shown in fig 5 d and j is overestimated by the coarse models this is consistent with the underestimation of water production the corrected prior results with the independent error treatment fig 5 e and k are very accurate in terms of the p50 predictions though the randomly sampled model error associated with this approach leads to a small amount of inaccuracy in the p10 and p90 results and the slight overestimation of overall uncertainty the corrected results with coupled model error fig 5 f and l agree closely with the reference fine scale prior predictions the accurate prior statistics provided by our model error treatments demonstrate the ability of this approach to correct systematic upscaling error we will now apply dsi with the model error treatments to correct posterior forecasts 4 3 dsi posterior results with model error treatment in this work we applied dsi with the model error treatments for five different synthetic true models in this section we present detailed posterior results for two of these cases true model 1 was selected because of the five cases considered dsi results using uncorrected coarse model priors displayed the largest overall error meaning the model error treatment is most needed true model 2 was selected because of the five cases considered our error treatment was the least accurate though the results are still clearly satisfactory summary results for the other three true models will be presented in section 4 5 in the results that follow we will apply dsi using the fine scale priors with n r 500 realizations to generate reference posterior results we then compare these predictions to coarse scale posterior results without any correction and to corrected posterior results with the independent and coupled model error treatments the observed data are generated from the fine scale simulation of the true model with measurement error set to 5 of the true value added the observed data d obs include the values of all qoi at 210 390 and 570 days the number of observations is thus n hm n qoi 3 18 in the application of esmda within dsi we assimilate data n a 4 times and generate n r 500 posterior samples in all cases 4 3 1 posterior results for true model 1 posterior dsi results for true model 1 are shown in fig 6 water injection qoi and fig 7 production qoi in the figures the red dashed curves indicate the true model response from fine scale simulation and the red points display the observed data which include measurement error the p10 and p90 reference fine scale posterior results appear as the lower and upper blue dashed curves the black dotted curves in the left columns show the p10 and p90 coarse scale posterior results without any correction the black dash dotted curves in the middle columns display the corrected p10 and p90 posterior predictions with the independent model error treatment the black solid lines in the right columns show the corrected posterior p10 and p90 results with the coupled error treatment the vertical dashed lines are drawn just after the end of the historical period it is evident from fig 6 a and d that the discrepancies between predictions from fine and coarse scale models with no correction are relatively small for water injection rates the true model response red dashed curve lies within the coarse scale p10 p90 uncertainty interval in fig 6 a and d the bottom row of fig 6 shows the posterior results in the early historical period for i2 water injection there we see noticeable error for time up to 300 days the model error treatments with independent or coupled error provide improved posterior results we do observe slightly larger posterior uncertainty ranges though the overestimation in e g p90 rate in fig 6 f at 3000 days is only 3 4 posterior results for oil and water production rates are shown in fig 7 without any model error correction dsi based on coarse scale simulations significantly underestimates water production for p1 fig 7 a and overestimates oil production fig 7 d for producer p2 water breakthrough occurs during the historical period but dsi without any correction significantly overestimates the p90 response fig 7 g the independent model error correction provides significantly improved posterior results the p10 p90 range is however slightly overestimated for all qoi e g fig 7 h and k the results with the coupled error treatment are in very close agreement with the reference fine scale p10 and p90 posterior results these corrected results slightly overpredict the p90 water rate at early time fig 7 c and i though the coupled model error treatment nonetheless provides excellent overall results for true model 1 in the results above the n r e 100 realizations used to construct the error model were randomly selected from the full set of n r 500 realizations we now consider the impact of different random selections as well as the selection of realizations that provide simulation results that are closest to the data on dsi results we first define the relative error quantities that will be used for these and later assessments relative error is computed for p10 p50 p90 posterior results for different samplings in all cases we use n r e 100 pairs of fine and coarse scale simulation results the average relative error e i j for a particular result p10 p50 or p90 curve for injection rate or oil water production rate for a single well is defined as 22 e i j 0 t q i j t q ref i j t dt 0 t q ref i j t dt i 1 2 n qoi j 1 2 3 where q i 1 t q i 2 t and q i 3 t denote the p10 j 1 p50 j 2 and p90 j 3 result for qoi i from a coarse scale uncorrected or corrected prediction and q ref i j t j 1 2 3 denotes the corresponding fine scale reference results the average relative error for the p10 p50 and p90 predictions over all qoi is 23 e r j 1 n qoi i 1 n qoi e i j j 1 2 3 relative errors for p10 p50 and p90 posterior results with different samplings for true model 1 are presented in fig 8 ten different random samplings which differ from those used in the results shown above as well as results based on the closest prior run predictions are presented to find the closest cases we evaluate h d i d obs 2 i 1 n r for all coarse scale runs and select the n r e 100 that result in the lowest values for these l2 differences fine scale runs are then performed for these cases and the error model is constructed from these pairs the blue and orange boxes in fig 8 show relative errors using the independent and coupled error treatments respectively the solid red lines in the boxes indicate the p50 result over 10 samplings while the top and bottom of the boxes show the p75 and p25 results the lines extending beyond the boxes indicate the minimum and maximum relative error results the blue dashed lines show the results for the random selection used in previous and later results presented in this paper the red dashed lines indicate the results using the closest realizations we see in fig 8 that the error model accuracy does depend on the n r e 100 realizations used to construct the error model the coupled error model generally provides more accurate results than the independent error model there is overlap in the p10 and p50 results though the coupled error model is considerably more accurate for the p90 results we also see that the use of the closest realizations does not consistently outperform other samplings though it does provide the most accurate results for the p10 predictions taken in total these results suggest that a well designed realization selection method which may involve using some realizations that provide results close to the observed data and some selected randomly or using other criteria could lead to improved results this general issue should be considered in future work 4 3 2 posterior results for true model 2 posterior results for water injection rates for true model 2 are displayed in fig 9 for this case the overall error in the uncorrected coarse scale posterior predictions is not as large as in true model 1 we see in fig 9 that dsi with uncorrected coarse model data provides generally reasonable predictions for water injection rates though error is evident at early time both sets of corrected results display high accuracy at early time but we do observe some discrepancy at later time these errors are relatively small however e g about 2 error in both the p10 and p90 water injection rates for well i2 at 3000 days in fig 9 f posterior results for production qoi for true model 2 are presented in fig 10 consistent with the results for true model 1 in the uncorrected coarse scale posterior results for well p1 we observe late water breakthrough along with the overestimation of oil rate fig 10 a and d the results with the coupled model error treatment are quite accurate for these quantities fig 10 c and f results with the independent model error treatment are also satisfactory but we again observe a slight overestimation of posterior uncertainty fig 10 b and e generally similar observations can be made for well p2 though the results with the coupled model error treatment are not quite as accurate for this well as for p1 it is also of interest to assess the amount of uncertainty reduction achieved by dsi and the error in the corrected results relative to this uncertainty reduction these comparisons for true model 2 are displayed in fig 11 for all six qoi in this figure we show the reference prior p10 p90 range gray shaded regions along with reference fine scale posterior p10 p90 results blue dashed curves and posterior p10 p90 results using coarse models with the coupled model error treatment it is apparent that substantial uncertainty reduction is achieved in this case i e the posterior p10 p90 ranges are much smaller than the prior p10 p90 ranges we also see that the errors in the corrected coarse scale dsi results are generally small compared to the uncertainty reduction achieved finally it is worth noting that the error model provides reasonable results for this example even though the p10 p90 posterior predictions fall partially outside the p10 p90 prior results in some cases e g fig 11 c and d 4 3 3 additional investigations for true model 2 in this section we conduct additional investigations with true model 2 we first consider the performance of our methods with more observation data the observed data d obs now include measurements at days 120 210 300 390 480 570 660 750 840 and 930 the total number of observations is thus n hm 60 in previous results we used n hm 18 with data collection ending at day 570 measurement error is again prescribed to be 5 of the true value dsi posterior results for production qoi are shown in fig 12 these results correspond to those previously shown for the shorter history match period in fig 10 as would be expected more uncertainty reduction is evident in fig 12 than in fig 10 the error model treatments are again effective in this case with the coupled procedure generally outperforming the independent error treatment we do observe overestimation of uncertainty in some cases however e g fig 12 f substantial improvement relative to the use of coarse models is observed in the p1 water production rate results compare fig 12 a and c for other qoi the use of coarse models provides reasonable posterior results in this case though we do observe over fitting during the historical period we next consider the impact of the residual covariance on dsi results recall that this term c res defined in eq 15 represents the residual model error not captured in the pca representation its use allows us to avoid over fitting with the error model in fig 13 we present posterior results neglecting this residual covariance for both model error treatments for water and oil production rates in well p2 these results are for the case with n hm 60 the corresponding results with residual covariance included appear in fig 12 without residual covariance dsi provides less accurate results with both error treatments and we now observe clear biases in the predictions these results demonstrate that the residual covariance represents an important component of the error modeling framework 4 4 assessment of model error treatment using mahalanobis distance we now quantify the consistency between the corrected simulation predictions and the reference fine scale results the mahalanobis distance used here to measure the similarity between these results involves assessment of the full data vectors relative to a reference the mahalanobis distance d m applied here is given by sun and durlofsky 2019 as 24 d m d i d i d ref t c d ref 1 d i d ref 1 2 i 1 2 n r where d i denotes the data vector for any prior or posterior realization and d ref and c d ref indicate the mean and covariance of the reference prior or posterior results thus d m is the distance between each data realization d i and the mean reference d ref weighted by c d ref 1 following sun and durlofsky 2019 we approximate c d ref 1 by its pseudo inverse c d ref this is constructed through application of truncated singular value decomposition svd to the scaled centered matrix d ref that contains as its columns the reference data realizations i e d ref 1 n r 1 d ref 1 d ref d ref 2 d ref d ref n r d ref from the svd we have d ref u σ v t we preserve k components with k determined through an energy criterion this gives u r n f k σ r k k and v r n r k where u contains the left singular vectors as its columns σ is a diagonal matrix containing the k largest singular values and v contains the right singular vectors the covariance matrix c d ref can now be represented as c d ref d ref d ref t u σ 2 u t and its pseudo inverse as c d ref u σ 1 σ 1 u t the mahalanobis distance is now written as 25 d m d i d i d ref t u σ 1 σ 1 u t d i d ref 1 2 ω i t ω i 1 2 ω i σ 1 u t d i d ref as suggested in sun and durlofsky 2019 we preserve 95 of the energy in the truncated svd to avoid over fitting this results in values of k of about 5 we now evaluate the performance of the model error treatment for both prior and posterior results we first consider prior results in this case the fine scale prior simulation data provide the reference i e d ref i i 1 2 n r we then compute the mahalanobis distance value d m for each prior data realization d i i 1 2 n r with the d i corresponding to the coarse scale prior simulation results the corrected results using the independent model error treatment and the corrected results using the coupled model error treatment the probability density functions pdfs over n r data realizations for these different cases are then constructed results for the mahalanobis distance pdfs for the various priors are presented in fig 14 a the red dashed curve represents the reference fine scale pdf the pdf constructed from coarse scale prior simulations without any correction is depicted by the blue dotted curve the pdfs with the corrected coarse scale results are indicated by the black solid curve coupled error treatment and the black dash dotted curve independent error treatment the discrepancy between the uncorrected coarse pdf and the reference pdf and the close agreement between the pdfs for the cases with model error treatment and the reference pdf again demonstrate the improvement provided by our procedures the results in fig 14 a are consistent with those shown in figs 4 and 5 the mahalanobis distance pdfs for posterior results for true model 1 and 2 are shown in figs 14 b and c the corresponding fine scale posterior results are used as the reference data for both cases we observe large differences between the fine scale and uncorrected coarse scale posterior pdfs the model error corrections lead to closer agreement with the reference pdfs with the coupled error treatment outperforming the independent error correction for both true model 1 and 2 4 5 results for multiple true models in this section we further evaluate the accuracy of our model error treatments by calculating relative errors compared to reference fine scale results relative error is computed for p10 p50 p90 prior results and for p10 p50 p90 posterior results for five true models two of these are true model 1 and 2 using eq 23 the relative errors for p10 p50 and p90 prior simulation results for the coarse uncorrected and corrected models are presented in table 1 consistent with the results in figs 4 and 5 we see that both error treatments provide significant error reduction compared to the case with uncorrected coarse scale priors interestingly the two error treatments give similar accuracy for p50 results but the coupled error treatment is more accurate for the p10 and p90 results relative errors for dsi posterior results for five true models are displayed in fig 15 none of these five models was included in the prior model ensemble we focus first on the errors for the p50 predictions shown in fig 15 b the uncorrected coarse scale posterior results gray bars display the largest relative errors for all true models meaning that the error model provides improvement in all cases the coupled error treatment yellow bars outperforms the independent error treatment blue bars in all but one case true model 2 for the p10 and p90 results in fig 15 a and c the coupled error treatment consistently provides better accuracy than the independent error treatment finally we note that for some cases true model 3 and 4 the results using the coupled model error are noticeably more accurate than those with independent error for the p10 p50 and p90 results 5 concluding remarks in this work we introduced treatments for handling model error in data space inversion in dsi posterior predictions for a set of qoi are generated directly from a large set of prior simulation results and observed data model parameter calibration is not performed the model error in our case derives from the use of upscaled models in place of high fidelity models for the requisite dsi simulations 500 prior simulations were performed for the example considered our procedure requires some of these simulations 20 in our case to also be performed on the corresponding fine scale models which enables us to build a pca representation of model error two different model error treatments were considered in the first method model error is taken to be independent of coarse scale simulation output in the second approach which was developed in this work we account for the correlation between simulation output and model error this correlation is captured using a linear regression that relates the latent pca space of the model error to the latent space of the prior simulation data posterior predictions are constructed by performing joint inversion in dsi using esmda on the latent spaces of the prior data and model error the model error treatments were evaluated for two phase immiscible well driven flow in a 3d channelized system we compared uncorrected coarse scale results corrected coarse scale results with the independent error treatment and corrected coarse scale results with the coupled correlated error treatment to reference fine scale results the error treatments were first applied to correct prior flow predictions the p10 p50 and p90 prior results were assessed relative to those from reference fine scale simulations both model error treatments performed well for the system considered with the coupled model error approach providing an order of magnitude reduction in relative error compared to uncorrected coarse scale results following the assessment of prior flow results detailed evaluations of dsi with both model error treatments were presented the goal was to assess the quality of posterior predictions relative to those constructed from fine scale results detailed p10 p50 and p90 well rate and mahalanobis distance results were presented for two true models and summary performance metrics were provided for three additional true models these results demonstrated that both error model treatments lead to substantial improvement compared to the use of uncorrected coarse models the coupled error treatment provided the most accurate overall results this demonstrates the importance of accounting for the correlation between the model error correction and simulation results a number of topics can be explored in future work in this area in this work we used randomly selected prior models to construct the model error representation by incorporating a model selection method that considers the full set of coarse scale simulation results it may be possible to devise a method that provides higher accuracy or requires fewer fine scale simulations recall that in the current work we simulated 20 of the models at the fine scale further improvement may also be obtained by enhancing the error parameterization or by using a nonlinear model to capture the correlation between simulation output and error finally it will be of interest to extend the dsi treatments developed in this study to also handle error from unknown sources the combined methodology could then be tested on a range of realistic cases credit authorship contribution statement su jiang conceptualization software louis j durlofsky conceptualization writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we are grateful to the stanford smart fields consortium and the stanford school of earth energy environmental sciences for funding this work we thank dylan crain for providing the 3d models and upscaling code used in this study 
3952,subsurface flow models are inherently imperfect and the associated model error can lead to unreliable flow predictions in this work we introduce treatments for model error in a data space inversion dsi framework dsi is a history matching procedure that constructs posterior flow predictions for quantities of interest directly within a bayesian setting using a large set of prior model flow simulation results and observed data the model error considered in this work derives from the use of upscaled coarsened surrogate models for the prior model flow simulations required by dsi our error treatment entails the simulation of a set of corresponding pairs of fine and upscaled models these results are used to construct a principal component analysis pca representation of error a linear regression approach is introduced to capture the coupled nature of the coarse scale simulation output and model error to construct posterior dsi predictions a joint inversion on coarse scale simulation data and model error is performed using an ensemble smoother with multiple data assimilation both the prior simulation data and error terms are parameterized using pca based procedures results are presented for two phase flow in 3d channelized geomodels the corrected prior and dsi posterior results are compared to reference results generated from fine scale simulations comparisons are presented for flow statistics mahalanobis distance and relative error for multiple synthetic true models the coupled model error treatment is shown to provide highly accurate prior results and posterior predictions that agree closely with reference results significant improvement relative to uncorrected coarse models is observed the treatments developed here can be used to represent error from many different sources in a variety of subsurface flow settings keywords subsurface flow data space inversion data assimilation model error upscaling 1 introduction data assimilation is a challenging but essential step for the efficient management of subsurface flow operations such as aquifer remediation oil gas production or co2 storage the objective of model based data assimilation or history matching is to calibrate geological model parameters based on observed data this generally leads to reduced uncertainty in model predictions in traditional history matching the forward model applied to represent the physical system is usually assumed to be perfect e g unbiased meaning there is no model error model error is however inevitable in practical settings and can result from unresolved scales physics upscaling model coarsening or simplified representations of subsurface fluid properties such as phase behavior neglecting to account for model error in the data assimilation procedure may lead to biased and thus unreliable posterior history matched flow predictions in this paper we implement treatments for representing model error in a data space inversion dsi method data space history matching represents an alternative to traditional approaches as it does not entail the calibration of model parameters instead posterior flow predictions and associated uncertainties are constructed from an ensemble of prior flow responses within a bayesian framework dsi requires the simulation of a large number of prior models typically o 500 1000 which represents the bulk of the computational demand the introduction of model error treatments into the dsi methodology enables us to perform most of the required flow simulations on highly coarsened models this provides significant computational savings and our treatment represents a general approach that can be used to represent model error from a variety of sources many approaches have been developed to account for model error in the inversion process thus far all of these procedures have been implemented with traditional model based rather than data space history matching techniques we classify these methods into two categories based on the error source the first set of approaches aims to treat model errors that derive from unknown sources different approaches involving modification of the error covariance matrix have been applied to account for unknown error vink et al 2015 for example noted that neglecting model error can lead to unreasonably small posterior uncertainty they used a single inflation factor on the measurement error to circumvent this issue sun et al 2017 extended their work by designing different inflation factors for different data types oliver and alfonzo 2018 developed an iterative model improvement workflow that combines model calibration with model criticism and model improvement the model criticism step assesses whether the calibrated models are consistent with the observations model improvement is then applied if large discrepancies exist the total error covariance matrix is determined based on the residual of observation and calibration results alfonzo and oliver 2020 extended this workflow and applied it to seismic data assimilation with more model parameters and observation data evensen 2019 and evensen 2021 formulated the iterative ensemble smoother with model error by representing model error in terms of random variables that are updated during the inversion process the framework requires the proper quantification of error correlation rammay et al 2021 developed a flexible iterative ensemble smoother by introducing a residual ensemble and a split parameter the residual ensemble is divided into model update and model error parts the split parameter which is adjusted in the inversion process balances the quality of the posterior parameters and the quality of the simulation output from the corresponding imperfect models the second set of approaches treats model error from known sources surrogate or upscaled models are widely applied for subsurface flow and model error statistics can be generated by comparing the high fidelity high accuracy reference solutions to the approximate solutions trehan et al 2017 applied high dimensional regression techniques random forest and lasso to estimate model error resulting from the use of a reduced order surrogate model trehan and durlofsky 2018 further developed the random forest based treatment to quantify the model error resulting from an upscaling procedure these methods were applied only for forward modeling and their use in inversion was not considered josset et al 2015 and josset et al 2015 applied functional principal component analysis fpca for dimension reduction and modeled error by constructing linear regressions between the latent space of the exact and proxy simulation results a markov chain monte carlo mcmc procedure was applied for inversion and acceptance results were improved using the error treatment josset et al 2015 köpke et al 2018 developed a local approach in which the basis used to characterize model error statistics was constructed from a small set of paired detailed and approximate models additional high fidelity simulations are required during the inversion procedure to update the model error representation in subsequent work köpke et al 2019 applied pca and constructed a global basis to represent model error rammay et al 2019 and rammay et al 2020 developed a joint inversion framework with an ensemble smoother with multiple data assimilation esmda to correct for upscaling error they took model error to be independent of both simulation input and output and applied pca to represent model error statistics model parameters and latent variables for model error were then updated through application of esmda and improved posterior parameters and predictions were achieved the standard dsi methodology was developed by sun and durlofsky 2017 and sun et al 2017 dsi operates within a bayesian framework to provide posterior flow predictions conditioned to observed data for particular quantities of interest qoi these qoi are typically time series of injection production rates for each well in the subsurface flow model the prior data space includes these time series data realizations for a large number of prior geomodels parameterization of the data vectors which enables their representation in terms of a small set of latent variables is useful in dsi existing parameterizations include pca based methods sun et al 2017 sun and durlofsky 2017 sun and durlofsky 2019 jiang et al 2020 and a recurrent autoencoder rae treatment jiang and durlofsky 2021 jiang et al 2021 posterior sampling in dsi was originally accomplished using a randomized maximum likelihood rml method the use of esmda in this context was introduced by lima et al 2020 jiang and durlofsky 2021 and jiang et al 2021 considered a range of dsi treatments and found rae parameterization with esmda to provide the best overall performance though the pca based parameterization also provided satisfactory results a number of prediction focused methods scheidt et al 2015 satija and caers 2015 satija et al 2017 park and caers 2020 jeong et al 2018 he et al 2017 he et al 2019 which share many similarities with dsi have also been developed and applied for a range of subsurface flow processes the dsi and prediction focused methods noted here were all designed under perfect model assumptions i e model error was not included in the inversion process in this work we implement and evaluate a treatment for model error within a dsi framework we consider model errors that derive from known sources which in our case is an upscaling process the error treatments are incorporated into a dsi procedure that includes pca based data parameterization and esdma for posterior sampling model error is quantified as the difference between the high fidelity fine scale and coarse scale simulation outputs for well rate time series using simulation results for corresponding fine coarse pairs for 20 of the realizations considered in dsi we construct a pca representation for model error our treatment is similar to that applied by rammay et al 2019 in that work model error was assumed to be independent from model parameters or simulation output here we also develop a coupled error treatment which entails the construction of a linear regression model that approximates the relationship between model error and simulation output we consider an ensemble of 3d channelized models and apply our model error treatments to correct both prior and posterior two phase flow predictions dsi results using uncorrected coarse models and coarse models with the model error treatments are compared to reference fine scale predictions detailed assessments are presented for two synthetic true models and summary results are provided for a set of five true models this paper proceeds as follows in section 2 we review the basic dsi procedure the error model treatments used in this work as well as their incorporation into the esmda dsi framework are described in section 3 in section 4 we first present the 3d channelized system and the global single phase transmissibility upscaling procedure applied in this study next detailed prior and posterior results involving the use of uncorrected coarse models and coarse models with two treatments for model error are compared to reference fine scale results for a two phase flow problem finally in section 5 we summarize this work and provide suggestions for future studies in this area 2 dsi with perfect model assumption we begin this section with an overview of the data space inversion dsi procedure for cases without model error i e under the perfect model assumption we describe the basic procedure developed by sun and durlofsky 2017 and sun et al 2017 and then discuss the combination of dsi with ensemble smoother with multiple data assimilation esmda the linkage of dsi with esmda was introduced by lima et al 2020 and later applied by jiang and durlofsky 2021 2 1 basic dsi formulation the dsi procedure entails the direct generation of posterior forecasts conditioned to the observed data for particular quantities of interest qoi in this work these qoi correspond to time series of well by well injection and production rates the key distinction between dsi and model based inversion is that in dsi we do not determine posterior model parameters just posterior predictions for a set of qoi as in most inversion procedures the forward model is assumed to be perfect meaning systematic errors introduced by approximations are neglected in the standard dsi formulation we let m i i 1 2 n r denote the set of prior model realizations where n r o 500 1000 represents the number of prior realizations considered in dsi let g represent the mathematically perfect forward simulation process that provides the qoi the data variable for realization i denoted d i contains concatenated time series of well rate quantities data variables are generated through application of 1 d i g m i the data vector d i r n f 1 includes simulation results d hm r n hm 1 from the historical period and data d pred r n pred 1 from the prediction period i e we can write d i d hm i t d pred i t t note that n f n hm n pred in practice the observed data correspond to well rate measurements from the actual field operation in this work we instead consider synthetic data generated by simulating a new random model that is not contained in the prior ensemble this model is then taken to be the true model m true under the perfect model assumption the observed data d obs r n hm 1 are directly generated from 2 d obs h d true d where d true denotes the data variables corresponding to m true h r n hm n f is a selection matrix containing zeros and ones that extracts data for the observation period from the full data vector and d r n hm 1 denotes the measurement error in standard dsi we include measurement error but neglect model error meaning we assume the forward simulation process g represents the real system the measurement error d is sampled from the gaussian distribution n 0 c d where c d is the data error covariance matrix the dsi process is performed within a bayesian framework in the special case where the data variables are multivariate gaussian distributed the posterior probability density function pdf for data vector d given the observation d obs is given by 3 p d d obs exp 1 2 h d d obs t c d 1 h d d obs 1 2 d d prior t c pd 1 d d prior where d prior and c pd represent the mean and covariance for the prior gaussian distribution of d 2 2 data parameterization in subsurface flow processes the data vector d corresponds to output from a highly nonlinear forward simulation g and as a result it is generally not multivariate gaussian distributed data parameterization is thus introduced to map the high dimensional non gaussian variables d to low dimensional nearly gaussian distributed latent variables ξ r n l 1 where n l denotes the dimension of the latent space thus the data variables are now represented as d d f ξ where d denotes the parameterized data variables generated from the mapping of ξ and f denotes the parameterization function the posterior pdf for latent variable ξ is given by 4 p ξ d obs exp 1 2 h f ξ d obs t c d 1 h f ξ d obs 1 2 ξ t ξ for the parameterization f ξ sun et al 2017 developed a method that combines principal component analysis pca with histogram transformation post processing this method is very efficient and it is capable of handling data of various types e g time series and co2 saturation fields at particular times as in sun and durlofsky 2019 histogram transformation preserves the marginal distribution for single variables but it does not preserve the correlations between different data variables and these can be important in some settings jiang and durlofsky 2021 recently developed a deep learning based parameterization that applies a recurrent autoencoder rae to represent multivariate time series data the rae based method was shown to better preserve the overall physical character and time series correlations in the well rate data although the rae based procedure can provide superior results for some qoi in this work we will apply the standard pca based treatment we proceed in this way because our intent is to construct an error model from results for relatively few e g 100 high fidelity fine scale models these 100 simulations do not provide nearly enough data for the construction of an rae representation for that we would need o 1000 simulations so we are constrained to consider error models of relatively simple form as we will see in section 3 these models involve a pca representation of data error combined with linear regression given this simple form error model there is little if any advantage in applying the sophisticated rae parameterization for the approximate data variables we now give an overview of the pca based data parameterization sun et al 2017 we first construct a data matrix d r n f n r which includes all centered data realizations as columns 5 d 1 n r 1 d 1 d prior d 2 d prior d n r d prior singular value decomposition svd of matrix d is then performed which allows us to write d u σ v t where u and v are the left and right singular matrices and σ is a diagonal matrix containing the singular values the pca basis matrix φ r n f n l is given by φ u σ where u r n f n l and σ r n l n l are truncated such that n l n f an energy criterion sun and durlofsky 2017 is applied to determine an appropriate value for n l a parameterized data realization d pca can now be generated by applying d pca φ ξ d prior if the prior latent variables ξ r n l 1 are sampled from the standard normal distribution the resulting d pca are also gaussian distributed this pca mapping may however generate nonphysical e g negative flow rates especially when the mean of the original prior is close to zero this behavior can be improved by applying histogram transformation ht in a post processing step we apply ht to map the pca realization d pca from a gaussian distribution to the parameterized data d in this way the prior distribution for each variable at each time step is recovered the mapping is based on the cumulative distribution function cdf of the prior ensemble f t d and pca realizations f i d pca we generate the parameterized data d as 6 d h t d pca f t 1 f i d pca where h t denotes the mapping function for the ht process and f t 1 indicates the inverse mapping from the cdf to the prior data this process ensures that the distribution for each variable corresponds to that in the prior though it does not maintain the joint distribution between different time steps or variables 2 3 posterior sampling in the final step of dsi a posterior sampling method is applied to generate posterior predictions for the qoi sun and durlofsky 2017 used an optimization based randomized maximum likelihood rml method for this while lima et al 2020 implemented a data space esmda procedure jiang and durlofsky 2021 applied esmda with both the pca and rae based parameterizations and also found it to be an efficient and effective posterior sampler in the dsi setting therefore esmda will be applied in this work the esmda update equation for the latent variables given by jiang and durlofsky 2021 is written as 7 ξ i k 1 ξ i k c ξ d hm k c d hm k α k c d 1 d obs α k e i k d hm i k for i 1 n r and k 1 n a where n a denotes the number of data assimilation steps and α k denotes the inflation coefficients according to emerick and reynolds 2013 the inflation coefficients α k must satisfy the requirement k 1 n a α k 1 1 in this work we assimilate data four times and use the same inflation coefficient at each step α k 4 for k 1 4 the use of larger n a or different α k was found to have very little impact on our results at each iteration k the historical period data d hm i k are generated from the parameterization process as d hm i k h f ξ i k recall that h is an extraction matrix the updated ensembles of d hm k and ξ k are used to construct the auto covariance matrix c d hm r n hm n hm and the cross covariance matrix c ξ d hm r n l n hm the error vector e i k in each step is sampled from a gaussian distribution n 0 c d we denote the posterior latent variables after n a iterations are completed as ξ post the posterior predictions d post are then constructed through application of d post d post f ξ post please see jiang and durlofsky 2021 for more details on the basic dsi procedure 3 dsi with model error our intent in this study is to apply dsi with imperfect forward models simulation models that are fast but approximate can be highly useful in practice especially in settings where large numbers of simulations must be performed such as data assimilation optimization and uncertainty quantification however without a gauge of the error they induce predictions from approximate models can be difficult to interpret thus the quantification of model error is an important general topic here we consider errors that arise from upscaling this is a particularly useful type of error to study since upscaled models are commonly used in practical studies in this setting we can simulate some number of fine scale models along with their upscaled counterparts these paired results then allow us to construct an explicit error model the approach presented here should also be applicable to any situation where we are able to identify the perfect model corresponding to a particular approximate model examples include the use of a compositional model with a few lumped components in place of a multicomponent model the use of a streamline simulator in place of a standard finite volume or finite element simulator or the use of an isothermal representation in place of a system with thermal effects our approach is not directly applicable when the cause of the model error is unknown though some of the treatments may still be useful 3 1 model error definition we let m denote the imperfect upscaled model and g the associated forward simulation the prior ensemble of approximate imperfect data variables d i is generated via d i g m i for i 1 n r by introducing a model error term denoted by m full i we can express the high fidelity data vector d as 8 d i g m i g m i m full i d i m full i where m full i is due to upscaling as noted earlier observed data in practice would derive from field measurements but here we use synthetic data namely results from the perfect simulation model g to represent the real system it follows from eqs 2 and 8 that the observed data d obs can be represented as 9 d obs h d true d h g m i d h g m i m hm i d where m hm i h m full i denotes the model error during the historical period in the bayesian framework the total error covariance c tot which includes model error and data error covariance is given by 10 c tot c m hm c d hc m full h t c d where matrices c m hm and c m full represent the covariance of model error in the historical and full simulation periods respectively in the dsi framework the correct perfect data vectors correspond to perfect fine scale reservoir models however our goal is to actually simulate only a relatively small fraction of the fine scale models and to simulate most realizations at the coarse scale thus achieving computational savings we use n r to denote the number of coarse scale prior realization simulations and n r e to indicate the number of fine scale simulations for each of the n r e randomly selected fine scale runs we also simulate the corresponding coarse scale model in this work we take n r 500 and n r e 100 this value of n r e was established through numerical experimentation on a related 2d problem some justification for the use of n r e 100 will be provided in section 4 2 we expect that this value could be reduced by using a well designed selection procedure in place of the random selection applied here note that dsi requires many more than 100 prior data realizations so we could not simply apply dsi using only the fine scale d i i 1 n r e data vectors the ensemble of approximate prior simulation results is expressed as d i g m i i 1 2 n r the model error m full i from the upscaling process is computed from corresponding pairs of fine perfect and coarse scale approximate simulation results i e 11 m full i g m i g m i d i d i i 1 2 n r e this set of n r e model error vectors is used to quantify the error statistics when applying dsi with model error we perform joint inversion on approximate data variables d and model error m full to correct the posterior predictions as proposed by rammay et al 2019 model error is represented using a pca based parameterization which we now describe 3 2 model error parameterization from the flow simulations for n r e pairs of fine scale g m i and approximate g m i models we construct the centered matrix d e as 12 d e 1 n r e 1 m full 1 m full m full 2 m full m full n r e m full where m full represents the mean of the prior model error realizations the basis matrix for error φ e r n f n l e is generated by performing svd on the data matrix d e where n l e denotes the number of columns retained the latent variables β r n l e 1 are generated through application of β i φ e t m full i m full the pca representation of each model error realization m full i is 13 m full i φ e β i m full i 1 2 n r e for the model error parameterization we preserve about 80 of the energy which corresponds to a small number 5 of latent variables this approach is consistent with that suggested by rammay et al 2019 and avoids over fitting the error term with this treatment the difference between m full and m full defined as the error residual is not negligible therefore the corresponding residual covariance is incorporated into the overall error covariance term let ζ denote the residual of model error not captured in the pca parameterization i e 14 ζ i m full i m full i the covariance c res for model error residual is 15 c res 1 n r e 1 i 1 n r e ζ i ζ i t in the framework of dsi with model error the residual covariance and measurement error covariance are both included in the total error covariance matrix c tot as 16 c tot c d c res consistent with the treatment suggested by rammay et al 2019 the covariance matrix c res contains only diagonal terms the model error latent variables β are only available for n r e prior realizations however the β for all n r prior realizations are required to correct both the prior and posterior data rammay et al 2019 proposed an input and output independent model error formulation with this approach prior realizations of β i i 1 2 n r are directly sampled from the gaussian distribution n β c β where β and c β denote the mean and covariance of β from the n r e samples this independent model error assumption however neglects any correlations between β and d or ξ as will be shown later this approach is effective for the test cases considered in this work but it can overly inflate the uncertainty associated with some of the prediction statistics we thus consider an alternative approach where we treat β as a specified function of ξ in this work we restrict ourselves to a linear model because we have only a limited number of ξ β pairs and we wish to avoid over fitting the regression model is thus expressed as 17 β w ξ b where matrix w r n l e n l and b r n l e 1 denote the weight and bias terms respectively with this representation prior realizations of β i are generated as β i w ξ i b for i 1 2 n r for the system considered in section 4 the correlation coefficient of the linear regression in eq 17 is 0 68 thus a residual exists and we explored adding random noise to β to account for this effect specifically we assessed the use of β w ξ b e where e denotes random noise generated from a gaussian distribution with zero mean and covariance based on the regression residual we found that this treatment had very little effect on the results i e nearly identical results were achieved using only eq 17 thus in all results in this paper we apply eq 17 as written without random noise e 3 3 joint inversion with esmda a joint inversion for both data and model error using esmda is applied within the dsi framework we first simulate n r upscaled models the upscaling procedure will be discussed in section 4 the latent variables ξ i i 1 2 n r for approximate data variables d i i 1 2 n r are generated through application of ξ i φ t d i d prior we then randomly select n r e realizations from the n r prior upscaled models fine scale simulations are run for these n r e models and the model error statistics are then constructed the latent variables β are generated from the pca parameterization for model error under the independent model error assumption the prior realizations of β i i 1 2 n r are sampled from the gaussian distribution n β c β with the coupled error treatment the prior data β i are generated based on the linear regression model β i w ξ i b for i 1 2 n r the joint inversion with latent variables ξ and β can be expressed as rammay et al 2019 rammay et al 2020 18 ξ i k 1 ξ i k c ξ d hm k c d hm k α k c tot 1 d obs α k e i k d hm i k β i k 1 β i k c β d hm k c d hm k α k c tot 1 d obs α k e i k d hm i k for i 1 n r and k 1 n a where c β d hm denotes the cross covariance between β and d hm the vector e denotes the random noise sampled from n 0 c tot and all other variables are as defined previously the data vector d i k at each assimilation step is generated via 19 d i k f ξ i k φ e β i k m full negative nonphysical data are set to zero during the inversion process to avoid spurious results the data in the historical period are extracted from d i k using d hm i k h d i k after n a iterations the posterior predictions for d are generated from the posterior final ξ and β using eq 19 in the inversion process esmda performs linear updates of the latent variables β and ξ similarly a linear relationship between β and ξ is introduced in the priors when the coupled error model is applied because the esmda updates are linear the relationship between β and ξ is maintained throughout the esmda procedure this important consistency is another reason for using a simple linear relationship in the coupled error model in fact with the linear model in eq 17 we actually do not have to perform the joint inversion as written i e we only need the first expression in eq 18 this is because the linear relationship is perfectly preserved in the esmda inversion process more specifically inverting only for ξ we can construct the corresponding posterior prediction for β from eq 17 the fact that precisely the same results are achieved with either joint inversion or by inverting only for ξ and then applying eq 17 was confirmed numerically we do however need to apply the joint inversion if the independent model error procedure is used or if we specify a more general nonlinear relationship between β and ξ in the latter case the relationship should be rechecked verified after data assimilation is performed to assure consistency the overall framework for dsi with coupled model error is provided in algorithm 1 algorithm 1 dsi with coupled model error 4 model error treatment for flow in 3d channelized system in this section we first describe the general problem setup and the upscaling procedure used to generate the coarse models we then present detailed results using our model error corrections 4 1 problem setup and upscaling procedure the 3d bimodal channelized models used in this work were generated by crain 2020 the models include sand and shale rock types with permeability variation in each facies the fine scale geomodels are defined on a 60 60 30 grid with uniform blocks of size 20 m 20 m 5 m a total of 500 fine scale realizations are considered four realizations of log permeability are shown in fig 1 detailed results will be shown for the models in fig 1 a and b there are two vertical injectors and two vertical producers all four wells penetrate and are open to flow the full formation thickness the fine scale geological realizations were conditioned to hard data at all 30 layers at the well locations the porosity is constant and set to 0 3 in all blocks in the models we model a two phase fully immiscible flow system the setup could correspond to an aquifer remediation project involving a nonaqueous phase liquid referred to as oil recovered through water injection or to a hydrocarbon production scenario the relative permeability curves for the two phases are shown in fig 2 the initial saturations for the two phases are 0 1 water and 0 9 oil the water viscosity is constant at 0 5 cp the viscosity of the oil varies with pressure the range here is from 1 72 1 93 cp the initial formation pressure is 200 bar the two injection wells and two production wells are prescribed to operate at fixed bottom hole pressures of 250 bar and 150 bar respectively note that these pressures bhps are the values at the uppermost well completion wellbore pressure varies with depth due to gravitational effects all flow simulations are performed using ad gprs stanford s automatic differentiation based general purpose research simulator zhou 2012 this simulator is based on a finite volume numerical formulation the coarse scale models are defined on a 12 12 10 grid this corresponds to an overall upscaling factor relative to the fine model of 75 which represents a high degree of coarsening a flow based single phase global transmissibility upscaling procedure is applied to generate the coarse models transmissibility is an interface property defined as the ratio between block to block flow rate and pressure difference the upscaling code was developed by crain 2020 and is based on approaches developed by zhang et al 2008 and chen et al 2008 the upscaled model is defined in terms of the coarse block to block transmissibilities and coarse scale well indices well indices are analogous to transmissibilities as they numerically link the wellbore to the blocks in which it is located referred to as well blocks in the upscaling procedure the global fine scale single phase flow problem is first solved in this solution flow is driven by the two injectors and two producers operating at the bhps noted above this solution is fast to compute because it involves only a single steady state solution in contrast to the transient two phase problem which must be solved through time the fine scale single phase solution provides the pressure in all grid blocks and the flow rates across all cell interfaces the coarse scale transmissibilities and well indices are then calculated from these fine scale simulation results we now present the key equations used in the upscaling all quantities at this point can be viewed as dimensionless let α denote the interface of two fine scale cells and β denote the interface of two coarse scale cells the flow rate f β c between two coarse scale cells is estimated as the sum of the fine scale flow rates f α f over the target interface the pressure p β c in the coarse blocks on each side of coarse scale interface β is the bulk volume average p β of the fine scale pressures in the range of the coarse blocks consistent with the definition of transmissibility the upscaled transmissibility t β is given by 20 t β f β c p β c p β c α β f α f p β p β and the upscaled well index wi by 21 wi f w c p i c p w l f l w f p i p w here the flow rate f w c for the coarse well block i is calculated as the sum of the fine scale well rates f l w f over the coarse block range p i c denotes the coarse scale block pressure bulk volume average of the underlying fine block pressures and p w represents the wellbore pressure evaluated at the center of the coarse block for a small subset of coarse blocks it is possible to have very low flow rates and very little pressure difference between blocks this situation can give rise to nonphysical results for t β computed via eq 20 for these blocks we compute upscaled permeability using a geometric average and then generate t β based on a harmonic average of the block permeabilities consistent with the usual way of constructing transmissibility from block permeabilities this treatment has negligible impact on the accuracy of the overall coarse model because it is applied in very few 1 blocks and these typically lie in regions with little flow please see crain 2020 for additional details on the upscaling procedure the global transmissibility upscaling procedure described above is essentially the most accurate permeability transmissibility upscaling method available nonetheless because the coarse models do not contain any treatment for subgrid transport effects i e we do not upscale the two phase flow functions the high degree of upscaling applied here leads to significant error in two phase simulation results we apply the methodology described in section 3 in order to correct this error our overall procedure is as follows we simulate n r 500 coarse scale models upscaled from fine models using the approach described above to generate the prior ensemble of coarse scale data vectors the simulation time frame is 3050 days the flow data are collected every 30 days starting at day 60 the number of time steps at which data are saved is n t 100 the simulation outputs include the water injection rates from the two injectors denoted i1 and i2 and oil and water production rates from the two producers p1 and p2 we thus consider n qoi 6 quantities of interest the length of the data vector is n f n qoi n t 600 in order to construct the error model we simulate n r e 100 fine models randomly selected from the full set of n r models it is useful to evaluate the computational complexity of dsi with the model error treatment to assess the degree of savings this procedure provides the cost of the overall workflow results almost entirely from the flow simulations that must be performed the application of the dsi process itself is negligible we quantify computational costs in units of fine model flow simulations the cost of the reference procedure which entails the simulation of n r 500 fine models is thus c fine 500 it is important to note that the linear solutions required during two phase flow simulation and upscaling dominate the computational costs of these procedures when we apply dsi with the model error treatment all n r 500 realizations are upscaled from 60 60 30 a total of m fine 108 000 cells in each geomodel to 12 12 10 m coarse 1440 cells in each geomodel the upscaling cost is essentially the computational time required for a fine scale steady state flow solution involving one unknown pressure per grid block in the fine scale two phase flow simulations required for dsi we have two unknowns per grid block pressure and water saturation o 100 time steps and multiple newton iterations and thus linear solutions per time step because the governing flow equations are nonlinear this corresponds to around 500 linear solutions of a system of dimension 216 000 for each run thus the upscaling computations for all 500 models correspond to less than one fine scale two phase flow simulation assuming the computational cost of the two phase flow simulation runs scales linearly with model size super linear scaling which is observed in many cases will lead to higher speedup factors the speedup achieved by the coarse scale models is about m fine m coarse 75 thus the cost of simulating the n r 500 coarse models is about 500 75 7 the error modeling procedure also requires the simulation of n r e 100 fine models the total cost of applying dsi with the model error treatment is therefore about c moderr 1 7 100 108 which represents nearly a factor of 5 speedup relative to c fine 500 it is evident that the speedup factor is essentially equal to n r n r e as the fine scale two phase flow simulations dominate computational cost we note finally that observed speedups may differ from this value due to simulator overhead e g initialization and to communication and i o issues if parallel processing is used 4 2 error model results for prior flow statistics to enable comparisons against reference results in this work we perform forward simulation g on the full set of fine scale geomodels m i i 1 2 n r this provides reference prior statistics for the data variables d i i 1 2 n r note that the point of using the error model is to reduce the fine scale simulation requirement i e simulate only n r e fine models rather than all n r fine models simulation of all fine models is necessary here however because our goal is to assess the performance of our treatments we first apply the model error treatment to correct the coarse scale simulation results for the prior models we generate the ensemble of model error realizations m full i i 1 2 n r e from the simulation results for corresponding pairs of fine and coarse scale models pca parameterization is then applied to generate latent variables β to represent model error we preserve n l e 5 latent variables to parameterize the upscaling error recall that it is important to avoid over fitting we will apply both the independent model error and the coupled output dependent model error treatments to correct the coarse scale prior statistics before presenting results for prior flow quantities it is of interest to consider the effect of n r e on the energy preserved in the pca model relating m full i to β i eq 13 this can give us an idea of an appropriate value for n r e the number of fine scale simulations performed here we use n r e 100 which corresponds to 20 of n r fig 3 shows the energy preserved with n l e 5 components columns in the φ e matrix as a function of n r e for each value of n r e the results in fig 3 represent the average of 100 random samplings of realizations the energy preserved decreases with increasing n r e plateauing at around 0 77 in this case it is evident that the use of small values of n r e can result in overfit high fraction of total energy retained which is important to avoid in the error model while most of the decrease has occurred by n r e 100 similarly shaped curves were also observed for n l e 3 and 7 thus we believe the use of n r e 100 represents an appropriate choice as this value is large enough to avoid overfit with reasonable values of n l e while being small enough to still provide significant efficiency gains the optimal number of fine scale realizations as well as the specific realizations selected should be further investigated in future work we now consider results for prior flow qoi fine coarse and corrected results for water injection rate wir are shown in fig 4 and those for water and oil production rates wpr and opr appear in fig 5 these results are presented in terms of the p10 p50 and p90 10th 50th and 90th percentile responses over the full set of n r results note that the p50 response at different time steps may correspond to different realizations and similarly for p10 and p90 in the figures the red dashed curves which appear in all subfigures show the p10 p50 and p90 fine scale reference results the blue dotted curves in the left columns show the uncorrected coarse scale results the black dash dotted curves in the middle columns represent corrected coarse results using the independent error treatment and the black solid curves in the right columns show corrected coarse results with the coupled model error treatment the results in the left columns in figs 4 and 5 show that the coarse scale prior statistics are biased compared with the reference fine scale results i e the upscaling error is significant due to the high degree of coarsening applied in fig 4 a and d we see that the coarse models underestimate water injection rate in both wells by introducing the model error treatment highly accurate p10 p50 and p90 prior results for water injection are achieved using either of the error treatments the results in fig 5 a and g show water production for wells p1 and p2 the coarse scale results display late water breakthrough and lower water production relative to the fine scale results again using either model error treatment the corrected prior results fig 5 b c h and i are in close agreement with the reference fine scale results prior oil production shown in fig 5 d and j is overestimated by the coarse models this is consistent with the underestimation of water production the corrected prior results with the independent error treatment fig 5 e and k are very accurate in terms of the p50 predictions though the randomly sampled model error associated with this approach leads to a small amount of inaccuracy in the p10 and p90 results and the slight overestimation of overall uncertainty the corrected results with coupled model error fig 5 f and l agree closely with the reference fine scale prior predictions the accurate prior statistics provided by our model error treatments demonstrate the ability of this approach to correct systematic upscaling error we will now apply dsi with the model error treatments to correct posterior forecasts 4 3 dsi posterior results with model error treatment in this work we applied dsi with the model error treatments for five different synthetic true models in this section we present detailed posterior results for two of these cases true model 1 was selected because of the five cases considered dsi results using uncorrected coarse model priors displayed the largest overall error meaning the model error treatment is most needed true model 2 was selected because of the five cases considered our error treatment was the least accurate though the results are still clearly satisfactory summary results for the other three true models will be presented in section 4 5 in the results that follow we will apply dsi using the fine scale priors with n r 500 realizations to generate reference posterior results we then compare these predictions to coarse scale posterior results without any correction and to corrected posterior results with the independent and coupled model error treatments the observed data are generated from the fine scale simulation of the true model with measurement error set to 5 of the true value added the observed data d obs include the values of all qoi at 210 390 and 570 days the number of observations is thus n hm n qoi 3 18 in the application of esmda within dsi we assimilate data n a 4 times and generate n r 500 posterior samples in all cases 4 3 1 posterior results for true model 1 posterior dsi results for true model 1 are shown in fig 6 water injection qoi and fig 7 production qoi in the figures the red dashed curves indicate the true model response from fine scale simulation and the red points display the observed data which include measurement error the p10 and p90 reference fine scale posterior results appear as the lower and upper blue dashed curves the black dotted curves in the left columns show the p10 and p90 coarse scale posterior results without any correction the black dash dotted curves in the middle columns display the corrected p10 and p90 posterior predictions with the independent model error treatment the black solid lines in the right columns show the corrected posterior p10 and p90 results with the coupled error treatment the vertical dashed lines are drawn just after the end of the historical period it is evident from fig 6 a and d that the discrepancies between predictions from fine and coarse scale models with no correction are relatively small for water injection rates the true model response red dashed curve lies within the coarse scale p10 p90 uncertainty interval in fig 6 a and d the bottom row of fig 6 shows the posterior results in the early historical period for i2 water injection there we see noticeable error for time up to 300 days the model error treatments with independent or coupled error provide improved posterior results we do observe slightly larger posterior uncertainty ranges though the overestimation in e g p90 rate in fig 6 f at 3000 days is only 3 4 posterior results for oil and water production rates are shown in fig 7 without any model error correction dsi based on coarse scale simulations significantly underestimates water production for p1 fig 7 a and overestimates oil production fig 7 d for producer p2 water breakthrough occurs during the historical period but dsi without any correction significantly overestimates the p90 response fig 7 g the independent model error correction provides significantly improved posterior results the p10 p90 range is however slightly overestimated for all qoi e g fig 7 h and k the results with the coupled error treatment are in very close agreement with the reference fine scale p10 and p90 posterior results these corrected results slightly overpredict the p90 water rate at early time fig 7 c and i though the coupled model error treatment nonetheless provides excellent overall results for true model 1 in the results above the n r e 100 realizations used to construct the error model were randomly selected from the full set of n r 500 realizations we now consider the impact of different random selections as well as the selection of realizations that provide simulation results that are closest to the data on dsi results we first define the relative error quantities that will be used for these and later assessments relative error is computed for p10 p50 p90 posterior results for different samplings in all cases we use n r e 100 pairs of fine and coarse scale simulation results the average relative error e i j for a particular result p10 p50 or p90 curve for injection rate or oil water production rate for a single well is defined as 22 e i j 0 t q i j t q ref i j t dt 0 t q ref i j t dt i 1 2 n qoi j 1 2 3 where q i 1 t q i 2 t and q i 3 t denote the p10 j 1 p50 j 2 and p90 j 3 result for qoi i from a coarse scale uncorrected or corrected prediction and q ref i j t j 1 2 3 denotes the corresponding fine scale reference results the average relative error for the p10 p50 and p90 predictions over all qoi is 23 e r j 1 n qoi i 1 n qoi e i j j 1 2 3 relative errors for p10 p50 and p90 posterior results with different samplings for true model 1 are presented in fig 8 ten different random samplings which differ from those used in the results shown above as well as results based on the closest prior run predictions are presented to find the closest cases we evaluate h d i d obs 2 i 1 n r for all coarse scale runs and select the n r e 100 that result in the lowest values for these l2 differences fine scale runs are then performed for these cases and the error model is constructed from these pairs the blue and orange boxes in fig 8 show relative errors using the independent and coupled error treatments respectively the solid red lines in the boxes indicate the p50 result over 10 samplings while the top and bottom of the boxes show the p75 and p25 results the lines extending beyond the boxes indicate the minimum and maximum relative error results the blue dashed lines show the results for the random selection used in previous and later results presented in this paper the red dashed lines indicate the results using the closest realizations we see in fig 8 that the error model accuracy does depend on the n r e 100 realizations used to construct the error model the coupled error model generally provides more accurate results than the independent error model there is overlap in the p10 and p50 results though the coupled error model is considerably more accurate for the p90 results we also see that the use of the closest realizations does not consistently outperform other samplings though it does provide the most accurate results for the p10 predictions taken in total these results suggest that a well designed realization selection method which may involve using some realizations that provide results close to the observed data and some selected randomly or using other criteria could lead to improved results this general issue should be considered in future work 4 3 2 posterior results for true model 2 posterior results for water injection rates for true model 2 are displayed in fig 9 for this case the overall error in the uncorrected coarse scale posterior predictions is not as large as in true model 1 we see in fig 9 that dsi with uncorrected coarse model data provides generally reasonable predictions for water injection rates though error is evident at early time both sets of corrected results display high accuracy at early time but we do observe some discrepancy at later time these errors are relatively small however e g about 2 error in both the p10 and p90 water injection rates for well i2 at 3000 days in fig 9 f posterior results for production qoi for true model 2 are presented in fig 10 consistent with the results for true model 1 in the uncorrected coarse scale posterior results for well p1 we observe late water breakthrough along with the overestimation of oil rate fig 10 a and d the results with the coupled model error treatment are quite accurate for these quantities fig 10 c and f results with the independent model error treatment are also satisfactory but we again observe a slight overestimation of posterior uncertainty fig 10 b and e generally similar observations can be made for well p2 though the results with the coupled model error treatment are not quite as accurate for this well as for p1 it is also of interest to assess the amount of uncertainty reduction achieved by dsi and the error in the corrected results relative to this uncertainty reduction these comparisons for true model 2 are displayed in fig 11 for all six qoi in this figure we show the reference prior p10 p90 range gray shaded regions along with reference fine scale posterior p10 p90 results blue dashed curves and posterior p10 p90 results using coarse models with the coupled model error treatment it is apparent that substantial uncertainty reduction is achieved in this case i e the posterior p10 p90 ranges are much smaller than the prior p10 p90 ranges we also see that the errors in the corrected coarse scale dsi results are generally small compared to the uncertainty reduction achieved finally it is worth noting that the error model provides reasonable results for this example even though the p10 p90 posterior predictions fall partially outside the p10 p90 prior results in some cases e g fig 11 c and d 4 3 3 additional investigations for true model 2 in this section we conduct additional investigations with true model 2 we first consider the performance of our methods with more observation data the observed data d obs now include measurements at days 120 210 300 390 480 570 660 750 840 and 930 the total number of observations is thus n hm 60 in previous results we used n hm 18 with data collection ending at day 570 measurement error is again prescribed to be 5 of the true value dsi posterior results for production qoi are shown in fig 12 these results correspond to those previously shown for the shorter history match period in fig 10 as would be expected more uncertainty reduction is evident in fig 12 than in fig 10 the error model treatments are again effective in this case with the coupled procedure generally outperforming the independent error treatment we do observe overestimation of uncertainty in some cases however e g fig 12 f substantial improvement relative to the use of coarse models is observed in the p1 water production rate results compare fig 12 a and c for other qoi the use of coarse models provides reasonable posterior results in this case though we do observe over fitting during the historical period we next consider the impact of the residual covariance on dsi results recall that this term c res defined in eq 15 represents the residual model error not captured in the pca representation its use allows us to avoid over fitting with the error model in fig 13 we present posterior results neglecting this residual covariance for both model error treatments for water and oil production rates in well p2 these results are for the case with n hm 60 the corresponding results with residual covariance included appear in fig 12 without residual covariance dsi provides less accurate results with both error treatments and we now observe clear biases in the predictions these results demonstrate that the residual covariance represents an important component of the error modeling framework 4 4 assessment of model error treatment using mahalanobis distance we now quantify the consistency between the corrected simulation predictions and the reference fine scale results the mahalanobis distance used here to measure the similarity between these results involves assessment of the full data vectors relative to a reference the mahalanobis distance d m applied here is given by sun and durlofsky 2019 as 24 d m d i d i d ref t c d ref 1 d i d ref 1 2 i 1 2 n r where d i denotes the data vector for any prior or posterior realization and d ref and c d ref indicate the mean and covariance of the reference prior or posterior results thus d m is the distance between each data realization d i and the mean reference d ref weighted by c d ref 1 following sun and durlofsky 2019 we approximate c d ref 1 by its pseudo inverse c d ref this is constructed through application of truncated singular value decomposition svd to the scaled centered matrix d ref that contains as its columns the reference data realizations i e d ref 1 n r 1 d ref 1 d ref d ref 2 d ref d ref n r d ref from the svd we have d ref u σ v t we preserve k components with k determined through an energy criterion this gives u r n f k σ r k k and v r n r k where u contains the left singular vectors as its columns σ is a diagonal matrix containing the k largest singular values and v contains the right singular vectors the covariance matrix c d ref can now be represented as c d ref d ref d ref t u σ 2 u t and its pseudo inverse as c d ref u σ 1 σ 1 u t the mahalanobis distance is now written as 25 d m d i d i d ref t u σ 1 σ 1 u t d i d ref 1 2 ω i t ω i 1 2 ω i σ 1 u t d i d ref as suggested in sun and durlofsky 2019 we preserve 95 of the energy in the truncated svd to avoid over fitting this results in values of k of about 5 we now evaluate the performance of the model error treatment for both prior and posterior results we first consider prior results in this case the fine scale prior simulation data provide the reference i e d ref i i 1 2 n r we then compute the mahalanobis distance value d m for each prior data realization d i i 1 2 n r with the d i corresponding to the coarse scale prior simulation results the corrected results using the independent model error treatment and the corrected results using the coupled model error treatment the probability density functions pdfs over n r data realizations for these different cases are then constructed results for the mahalanobis distance pdfs for the various priors are presented in fig 14 a the red dashed curve represents the reference fine scale pdf the pdf constructed from coarse scale prior simulations without any correction is depicted by the blue dotted curve the pdfs with the corrected coarse scale results are indicated by the black solid curve coupled error treatment and the black dash dotted curve independent error treatment the discrepancy between the uncorrected coarse pdf and the reference pdf and the close agreement between the pdfs for the cases with model error treatment and the reference pdf again demonstrate the improvement provided by our procedures the results in fig 14 a are consistent with those shown in figs 4 and 5 the mahalanobis distance pdfs for posterior results for true model 1 and 2 are shown in figs 14 b and c the corresponding fine scale posterior results are used as the reference data for both cases we observe large differences between the fine scale and uncorrected coarse scale posterior pdfs the model error corrections lead to closer agreement with the reference pdfs with the coupled error treatment outperforming the independent error correction for both true model 1 and 2 4 5 results for multiple true models in this section we further evaluate the accuracy of our model error treatments by calculating relative errors compared to reference fine scale results relative error is computed for p10 p50 p90 prior results and for p10 p50 p90 posterior results for five true models two of these are true model 1 and 2 using eq 23 the relative errors for p10 p50 and p90 prior simulation results for the coarse uncorrected and corrected models are presented in table 1 consistent with the results in figs 4 and 5 we see that both error treatments provide significant error reduction compared to the case with uncorrected coarse scale priors interestingly the two error treatments give similar accuracy for p50 results but the coupled error treatment is more accurate for the p10 and p90 results relative errors for dsi posterior results for five true models are displayed in fig 15 none of these five models was included in the prior model ensemble we focus first on the errors for the p50 predictions shown in fig 15 b the uncorrected coarse scale posterior results gray bars display the largest relative errors for all true models meaning that the error model provides improvement in all cases the coupled error treatment yellow bars outperforms the independent error treatment blue bars in all but one case true model 2 for the p10 and p90 results in fig 15 a and c the coupled error treatment consistently provides better accuracy than the independent error treatment finally we note that for some cases true model 3 and 4 the results using the coupled model error are noticeably more accurate than those with independent error for the p10 p50 and p90 results 5 concluding remarks in this work we introduced treatments for handling model error in data space inversion in dsi posterior predictions for a set of qoi are generated directly from a large set of prior simulation results and observed data model parameter calibration is not performed the model error in our case derives from the use of upscaled models in place of high fidelity models for the requisite dsi simulations 500 prior simulations were performed for the example considered our procedure requires some of these simulations 20 in our case to also be performed on the corresponding fine scale models which enables us to build a pca representation of model error two different model error treatments were considered in the first method model error is taken to be independent of coarse scale simulation output in the second approach which was developed in this work we account for the correlation between simulation output and model error this correlation is captured using a linear regression that relates the latent pca space of the model error to the latent space of the prior simulation data posterior predictions are constructed by performing joint inversion in dsi using esmda on the latent spaces of the prior data and model error the model error treatments were evaluated for two phase immiscible well driven flow in a 3d channelized system we compared uncorrected coarse scale results corrected coarse scale results with the independent error treatment and corrected coarse scale results with the coupled correlated error treatment to reference fine scale results the error treatments were first applied to correct prior flow predictions the p10 p50 and p90 prior results were assessed relative to those from reference fine scale simulations both model error treatments performed well for the system considered with the coupled model error approach providing an order of magnitude reduction in relative error compared to uncorrected coarse scale results following the assessment of prior flow results detailed evaluations of dsi with both model error treatments were presented the goal was to assess the quality of posterior predictions relative to those constructed from fine scale results detailed p10 p50 and p90 well rate and mahalanobis distance results were presented for two true models and summary performance metrics were provided for three additional true models these results demonstrated that both error model treatments lead to substantial improvement compared to the use of uncorrected coarse models the coupled error treatment provided the most accurate overall results this demonstrates the importance of accounting for the correlation between the model error correction and simulation results a number of topics can be explored in future work in this area in this work we used randomly selected prior models to construct the model error representation by incorporating a model selection method that considers the full set of coarse scale simulation results it may be possible to devise a method that provides higher accuracy or requires fewer fine scale simulations recall that in the current work we simulated 20 of the models at the fine scale further improvement may also be obtained by enhancing the error parameterization or by using a nonlinear model to capture the correlation between simulation output and error finally it will be of interest to extend the dsi treatments developed in this study to also handle error from unknown sources the combined methodology could then be tested on a range of realistic cases credit authorship contribution statement su jiang conceptualization software louis j durlofsky conceptualization writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we are grateful to the stanford smart fields consortium and the stanford school of earth energy environmental sciences for funding this work we thank dylan crain for providing the 3d models and upscaling code used in this study 
3953,rivers provide the basis for sustainable socio economic development but increasingly intense human activities poses a threat to river health to comprehensively investigate the river health in the qinghai tibet plateau china the lhasa river is selected as study area and a comprehensive indicator system incorporating ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services is constructed the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction combined weights of river health indicators are calculated using the minimum deviation principle a novel multidimensional similarity cloud model mscm is then developed for assessing river health with fuzzy monitoring data results show that the upper reaches of lhasa river is healthy in terms of ecosystem integrity and non ecological performance and the health level exhibits significant spatial variability influenced by urban construction and water conservancy projects with decreasing health level from upper to lower reaches 52 of the sampling sites are at excellent or healthy levels 40 are subhealthy and 8 are unhealthy in the lhasa river accordingly recommendations and measures are proposed to improve river health level and explore sustainable water management policies in the qinghai tibet plateau china keywords river health assessment cloud model multidimensional similarity ecosystem integrity non ecological performance 1 introduction rivers around the world have experienced long term degradation as a result of human disturbance maddock 1999 yang et al 2017 phenomena such as channel modification river blockage and water pollution have changed the structure and function of river ecosystems wang et al 2019 the concept of river health was first introduced in 1972 in the clean water act enacted by the u s environmental protection agency to maintain and restore the chemical physical and biological integrity of waters downing et al 2003 integrity means maintaining the river ecosystem in good condition in terms of natural structure and function karr 1999 boulton 1999 reviewed the development history of river health and incorporated ecological integrity and human values into the definition of river health the eu water framework directive issued in 2 000 further proposes to build an integrated management pattern for water ecosystem health in the watersheds voulvoulis et al 2017 the management of global water environment is gradually shifting from pollution control to ecological restoration yang et al 2021 river health assessment provides comprehensive measurement and diagnosis of river conditions in a basin and is a prerequisite for river restoration and management the united states fesenmyer et al 2020 united kingdom zeng et al 2020 and australia chessman 2021 have established river health assessment systems tailored to the characteristics of their rivers which play an important role in the restoration and management of the water environment petersen 1992 established the riparian channel and environmental inventory and used it to guide river monitoring and evaluation in agricultural areas currently a convincing international definition of river health is that a healthy river should not only meet ecological integrity but also take into account the non ecological performance of the river system anwar sadat et al 2020 yang and wang 2020 wan et al 2021 compared with international research experience river health research was carried out later in china over the past 30 years although promising results have been achieved in water pollution control and management the focus has been mainly on the improvement and restoration of water quality xu et al 2019 research on ecosystem integrity is lacking and river management systems based on water ecosystem health have not been established the responsibilities of china s river management and policies are scattered and unclear over the past few decades liu et al 2019b in recent years a series of measures designed to improve river health level are implemented in china since 2010 ecological restoration and regular health evaluations of typical rivers were implemented in china liu et al 2019a zhang et al 2021 in 2016 a new policy for improving river management was announced known as river chief system responsibility for protecting water environment is placed on the shoulders of government officials and is linked to government performance in this policy liu et al 2020a wang and chen 2020 river chiefs are divided into four levels with diminishing power namely provinces cities counties and townships who are assigned to be responsible for rivers within their jurisdiction tang et al 2020 accordingly the prevention and control of river pollution are gradually being taken seriously by government officials in addition a public supervision system and an open information platform for river management are developed and then the conflicts between different sectors are relieved effectively through the river chief system to accurately determine the river health level with fuzziness various models were applied by previous researchers existing research methods associated with river health mainly include multivariate statistical analysis pinto and maheshwari 2011 fuzzy theory xu and liu 2014 ren et al 2018 gray correlation wang et al 2019 set pair analysis zhao et al 2019b topsis model xu et al 2019 matter element model deng et al 2015 artificial neural network jeong et al 2001 and combined models of these methods pan et al 2015 wan et al 2021 zhang et al 2018a conceptually river health assessment can be considered as a multi indicator decision making process with qualitative and quantitative uncertainties the multi indicator decision model is built with quantitative indicators of river health as inputs and qualitative evaluation as outputs yao et al 2019 uncertainties in river health assessment mainly include three aspects i uncertainty in the monitoring data caused by the sampling process li et al 2018a zhang and li 2020 ii uncertainty introduced by changing external environment and different analysis methods deng et al 2015 kang et al 2018 and iii uncertainty generated by multiple indicators with different attributes zhao et al 2019b these uncertainties complicate river health assessments and introduce inherent fuzziness in the evaluation process yan et al 2017 although the aforesaid methods play an important role in river health assessment they still ignore a comprehensive consideration for the fuzziness of river health and are limited to specific conditions on applicabilities li et al 2020b in addition the robustness of decision outcomes may be significantly affected by the oversimplification of the fuzzy factors lu et al 2017 this may lead to wrong decisions to some extent accordingly this study introduces a new hybrid model cloud model to overcome the above mentioned shortcomings referring to the research frameworks of lu et al 2017 and yao et al 2021 the cloud model based on cloud digital characteristics achieves the conversion between quantitative indicators and qualitative evaluation through the cloud generator which can effectively integrate the fuzziness of river health assessment yang and wang 2020 cloud droplets are the basic units that form clouds and the distribution area of cloud droplets is called domain space li et al 2009 cloud digital characteristics consist of expectation e x entropy e n and hyper entropy h e which are important parameters for determining the river health level e x represents the expectation distribution of cloud droplets in the domain space yao et al 2019 yang and wang 2020 e n reveals the dispersion degree of cloud droplets which can effectively reflect the fuzziness of river health h e is used to measure the uncertainty of the entropy and demonstrates the cohesiveness between cloud drops yao et al 2019 and the cloud generators are divided into forward and reverse cloud generators quantitative information and distribution patterns are extracted from the qualitative information using a forward cloud generator cloud digital characteristics e x e n h e are then calculated using a reverse cloud generator based on monitoring data wang et al 2014 the normal cloud model is one of the most common cloud models and can be constructed using the normal membership and distribution function to comprehensively investigate the river health level in the qinghai tibet plateau china the lhasa river is selected as study area an indicator system incorporating ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services is constructed the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction and the combined weights of river health indicators are calculated using the minimum deviation principle a novel multidimensional similarity cloud model mscm is then developed for assessing river health levels with fuzzy monitoring data in light of this the accuracy and reliability of river health assessment can be effectively improved by maximizing the information content provided by monitoring data and reducing the impact of fuzziness the objectives of this study mainly include i developing a novel multidimensional similarity cloud model to comprehensively investigate the river health with fuzzy monitoring data ii constructing a comprehensive indicator system to quantitatively investigate the river health level in the qinghai tibet plateau from the perspective of ecosystem integrity and non ecological performance and iii applying this model to evaluate river health and proposing ecological restoration recommendations based on the evaluation results 2 materials and methods 2 1 study area lhasa river is located in the southeastern qinghai tibet plateau and is one of the highest rivers in the world with an average altitude of over 3600 m the total length of the river is about 551 km mao et al 2020 lhasa river basin is the economic and population center of tibet ranging from 90 05 e 93 20 e to 29 20 n 31 15 n with an area of 32 588 km2 li et al 2020a precipitation meltwater and lateral infiltration of groundwater are the main recharged sources for the lhasa river basin the climate in lhasa river basin is semi arid monsoon with distinct dry and wet seasons the average annual temperature is 5 3 c and the average annual precipitation is about 400 500 mm tian et al 2020 in addition the lhasa river basin is characterized by concentrated summer precipitation low annual temperature differences and high daily temperature differences due to the influence of warm and humid air from the indian ocean study area has high mountains and deep ravines which slops from southwest to northeast with an elevation difference of more than 3500 m liu et al 2014 more than 90 of the land is covered by grassland and sparse vegetation and human activities are mainly concentrated in the lower valley of lhasa river which is below 4200 m above sea level fig 1 there are two large hydropower stations in the middle reaches of lhasa river namely zhikong hydropower station 100 mw and pengduo hydropower station 160 mw land use changes in the lhasa river valley mainly include urbanization in lhasa reservoir construction in the middle reaches and afforestation in the flood plain fig 2 2 2 river health indicator system and score criteria to comprehensively investigate the health status of lhasa river it is necessary to evaluate the various elements of river health and select indicators to describe each element the critical indicators are obtained based on expert consultation and previous studies makokha et al 2016 kebede et al 2020 chen et al 2021 the river health indicator system is shown in table 1 river health indicator system integrates the ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services of the river physical habitat is primarily used to measure the morphological and structural integrity of a river and encompasses river connectivity c1 riparian naturalness c2 and land development c3 the ecological resilience of the river is examined in terms of both water quantity and quality which mainly includes the ecological flow satisfaction c4 water quantity mutation c5 oxygen consuming organics c6 heavy metal c7 and substrate contamination c8 aquatic life is used to reveal the aquatic ecological integrity and biodiversity of the river including phytoplankton c9 macroinvertebrate c10 fish c11 and waterbirds c12 and the indicators reflecting the sustainability of social service functions contain flood protection c13 water supply c14 water resources development c15 and public satisfaction c16 the specific calculation methods of the above indicators and the corresponding indicator health scores refer to the technical guidelines for river and lake health assessment tgrl 2020 and the river and lake health evaluation guide trial rlhe 2020 2 3 data collection lhasa river is divided into upper middle and lower reaches according to the characteristics of hydrology riparian zone morphology water quality aquatic life and socio economic development considering the features of evaluation indicators the representativeness of sampling sites and the safety and convenience of sampling the sampling sites within each evaluation river section are initially determined based on the site surveys and expert consultations 25 sampling sites are finally selected to investigate the health level of lhasa river sampling sites s1 s7 s8 s16 and s17 s25 are set in the upper middle and lower reaches of lhasa river respectively fig 1 in this study 25 sampling sites were selected to comprehensively investigate the health level of lhasa river in terms of physical habitat water quantity and quality aquatic life and social services data of physical habitat water quantity and quality aquatic life and social services were collected from 2017 to 2020 the monitoring frequency of physical habitat and social services was once a year and of water quantity was once a week table1 the monitoring frequency of water quality indicators was once a week except the substrate contamination c8 that was twice a year given the safety and convenience of sampling in the qinghai tibet plateau field sampling and laboratory analysis of aquatic life were conducted from october to december 2020 non flood season at each sampling site 50 l water samples were collected from the surface layer 0 5 m layer and 1 m water layer with a 2 5 l water sampler the water samples were filtered through the 25 μm polyethylene filter screen and then stored in a 100 ml bottle qualitative analysis of phytoplankton was also carried out using the 25 μm micron plankton net lugol reagent was added to the water samples to fix the phytoplankton and the supernatant was concentrated to 30 ml after 48 h of sedimentation phytoplankton species and genera were identified and counted using a microscope nikon eclipse 50i eight subsamples were collected at each sampling site to assess the condition of the macroinvertebrates macroinvertebrates were sorted from sediment and other debris using a 500 μm sieve bucket fish resources were surveyed in different river sections and the collected fish samples were preserved by formalin fixation fish age species abundance and density were assessed and analyzed to determine the condition of fish resources 10 trained and experienced observers counted the species numbers and densities of waterbirds observers walked along the lhasa river and used binoculars to observe waterbirds in addition the online information published in china bird report http www birdreport cn was also referenced in this study 2 4 multidimensional similarity cloud model for river health assessment to obtain the cloud digital characteristics of samples and river health grades sample data and evaluation indicator grades are submitted as inputs to the inverse cloud generator the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction the combined weights of river health indicators are then calculated using analytic hierarchy process ahp and information entropy ie weighting methods based on the minimum deviation principle finally the integrated cloud digital characteristics for the target level and criteria level are gained through combined weights in river health indicators one of the purposes of this study is to accurately evaluate the river health in the qinghai tibet plateau under the conditions of fully considering the complex relationships between river health indicators as well as the fuzziness in evaluation process therefore a novel mscm is developed and the cloud digital characteristic vectors associated with each sample and health grade are constructed in light of this the health levels of the upper middle and lower reaches of lhasa river are determined according to the fuzzy similarity measurement between samples and health grades in this study the mscm is developed by drawing on the research framework of yao et al 2019 the specific calculation process of mscm is shown in fig 3 2 4 1 cloud digital characteristics of health grades the river health grades and the corresponding cloud digital characteristics are shown in table 2 the specific calculation method is as follows 1 e x b min b max 2 e n b max b min 6 h e k e n where e x is the expectation e n is the entropy and h e is the hyper entropy in cloud model e x reflects the representativeness of the grade threshold range in all cloud droplets e n can measure the randomness and uncertainty represent the correlation between stochasticity and fuzziness and determine the scope of cloud droplet h e is usually used to reveal the uncertainty of e n cloud digital characteristic vector is expressed as e x e n h e b min and b max are the minimum and maximum values of the grade threshold range respectively k is an adjustment coefficient used to adjust the cohesion of cloud droplets in this study k 0 1 yao et al 2019 zhang et al 2020 2 4 2 cloud digital characteristics of indicator samples the random impacts of sampling methods and environmental factors on the accuracy of monitoring data can be effectively reduced by the wavelet noise reduction simoncelli and adelson 1996 jansen 2012 therefore wavelet noise reduction is applied to preprocess the sample data and accurately calculate the cloud digital characteristics of indicator samples 2 f x a j f x d j f x a j f x k z c j k φ j k x d j f x k z d j k ψ j k x where f x is the monitoring data sequence a j f x and d j f x are different frequency components decomposed by the mallal algorithm a j f x and d j f x are the projections of f x on the low frequency and high frequency signals respectively to reduce the noise interference the high frequency signal associated with the noise is eliminated and the reconstructed signal is then obtained 3 f x k z c j k φ j k x 4 t median d 1 0 6745 2 ln n where f x is the smooth signal of f x after wavelet noise reduction that is the extracted real signal t denotes the threshold function d 1 is the adjustment coefficient for the first level of decomposition and n is the data length daubechies wavelet db2 is used and data are decomposed in five layers in this study the evaluation samples after wavelet noise reduction are then utilized as inputs in the reverse cloud generator to calculate the cloud digital characteristics of indicator samples specific calculation process is as follows 5 e x j 1 m i 1 m x ij e n j π 2 1 m i 1 m x ij e x j i 1 2 m j 1 2 n h e j s j 2 e n j 2 where x ij is the cloud droplet value of the j th indicator in the i th evaluation sample s j 2 1 m 1 i 1 m x ij e x j 2 2 4 3 calculation of the combined weights the analytic hierarchy process ahp method can decompose a multi attribute decision problem into more comprehensible hierarchical structures to determine the weights of evaluation indicators liu et al 2020b it is one of the most important subjective weighting methods in multi attribute decision making and carries the advantages of flexibility and simplicity the indicator weights are determined based on the information content provided by data itself zhang and wang 2021 this method is called information entropy ie weighting method it balances the subjective preferences of decision makers reduces the unfairness of the decision making process and is highly objective to accurately assess the river health status with fuzzy monitoring data a combined weighting method drawing on the advantages of ahp and ie is applied in this study suppose there are r weighting methods and m river health indicators the weight vector w k can be expressed as follows 6 w k w k 1 w k 2 w k 3 w km t k 1 2 3 r i 1 m w ki 1 combined weights are obtained based on minimum deviation principle and the calculation process is as follows 7 min d j 1 n k 1 r i 1 m α k w ki α j w ij 2 8 s t k 1 r α k 1 α k 0 k 1 2 r where d represents the deviation between different weighting methods the purpose is to minimize the weight deviation α k and α j are the combination coefficient between different weighting methods the above conditional extremum problem can be solved by lagrangian function lagrange multipliers 9 l α λ j 1 n k 1 r i 1 m α k w ki α j w ij 2 λ t 1 r α t 1 the partial derivatives of eq 9 can be calculated according to the following formulas 10 l α k i 1 m α k w ki α 1 w 1 i α k w ki α 2 w 2 i α k w ki α r w ri w ki λ 2 0 l α k r α k i 1 m w ki 2 α 1 i 1 m w 1 i w ki α 2 i 1 m w 2 i w ki α r i 1 m w ri w ki λ 2 0 l λ k 1 r α k 1 0 where eqs 9 and 10 are multi dimensional linear equations containing r 1 unknowns if the determinant of the coefficient is not 0 the aforesaid equations have unique solution vector α α 1 α 2 α 3 α r 2 4 4 integrated cloud digital characteristics the weighted integration of multiple arbitrary clouds c i e xi e ni h ei designed to develop an integrated cloud ic c 1 c 2 c n the construction of ic and the corresponding cloud digital characteristics are as follows 11 ic c 1 c 2 c n c e x e n h e 12 e x i 1 n w i e xi e n i 1 n w i e ni 2 h e i 1 n w i h ei 2 where ic is the integrated cloud and w i is the combined weight of river health indicator 2 4 5 river health assessment based on mscm a novel mscm based on the fuzzy similarity principle is developed to measure the matching degree of cloud digital characteristic vectors between samples and river health grades it is assumed that c s e xs e ns h es and c g e xg e ng h eg are the cloud digital characteristic vectors in samples and river health grades respectively the calculation process of similarity degree between them is as follows 13 s i c s c g 1 2 1 2 φ ξ 2 φ ξ 14 ξ e xg e xs e ns 2 h es 2 e ng 2 h eg 2 φ ξ ξ 1 2 π exp t 2 2 d t where s i denotes similarity degree between c s and c g river health levels can be revealed through the health grades with the greatest s i 3 results 3 1 cloud digital characteristics of evaluation indicators sample data of evaluation indicators are submitted as inputs to the reverse cloud generator and the cloud digital characteristics of samples are then obtained in the upper middle and lower reaches of lhasa river and the cloud diagrams of river health grades and evaluation indicators are shown in figs 4 and 5 the general scores of evaluation indicators in lhasa river are upper reaches middle reaches lower reaches fig 5 the dispersion of cloud droplets in lower reaches is significantly larger than upper reaches suggesting greater differences exist in the downstream samples in addition the health scores are higher for all indicators except for c9 c10 and c11 indicators this indicates that the overall health level of lhasa river is good 3 2 integrated cloud digital characteristics for criteria level and target level the ahp and ie weighting methods are optimized by the minimum deviation principle to obtain the combined weights cw of river health indicators as shown in fig 6 the cw is between ahp and ie drawing on the advantages of two weighting methods with more reasonable values based on the combined weights the integrated cloud models of the upper middle and lower reaches of lhasa river are established the integrated cloud digital characteristics are calculated and the cloud diagrams for criteria level are then drawn fig 7 differences in the upper middle and lower reaches of lhasa river are relatively obvious in terms of the physical habitat water quantity and quality and show a trend of upper reaches middle reaches lower reaches the smaller differences and higher health scores exhibit in the upstream samples fig 7a and b the health scores of aquatic life in the midstream and downstream are closer which are lower than the upstream scores fig 7c high social services scores occur in the upstream midstream and downstream indicating that lhasa river has sustainable social services functions fig 7d the cloud diagram of the target level is shown in fig 8 river health scores of the integrated cloud in turn are upper reaches middle reaches lower reaches and the agglomeration of cloud droplets in integrated clouds are upper reaches middle reaches lower reaches this means that the health levels of the upper reaches of lhasa river are better than the middle and lower reaches overall the health level is better in the upper reaches and is closer in the middle and lower reaches 3 3 determination of river health status 3 3 1 health status of evaluation indicators the health status of evaluation indicators can be determined by calculating the similarity degree between evaluation indicators and river health grades fig 9 the river health grade corresponding to the maximum similarity degree represents the health level of each indicator as shown in fig 9a there are ten indicators c4 c5 c6 c7 c8 c12 c13 c14 c15 and c16 in the excellent level and six indicators c1 c2 c3 c9 c10 and c11 in the healthy level and no indicators occurs in the subhealthy unhealthy and sick levels in the middle reaches of lhasa river six indicators c6 c12 c13 c14 c15 and c16 belong to the excellent level five indicators c2 c4 c5 c7 and c8 are healthy four indicators c1 c3 c10 and c11 are subhealthy one indicator c9 is unhealthy and no indicator belongs to the sick level fig 9b indicators in subhealthy and unhealthy levels increase by five in the middle reaches compared with the upper reaches this indicates a downward trend exists in the health level of evaluation indicators in the lower reaches of lhasa river indicators in excellent and healthy levels are five c6 c13 c14 c15 and c16 and six c2 c4 c5 c7 c8 and c12 respectively fig 9c c3 c9 c10 and c11 are subhealthy c1 is unhealthy and no indicator is sick compared with the middle reaches of lhasa river c12 changes from excellent to healthy level and c1 trends from subhealthy to unhealthy level 3 3 2 health status of criteria levels similarity degrees between the criteria levels and river health grades are shown in fig 10 in the upper reaches of lhasa river the social services water quantity and quality are excellent and physical habitat and aquatic life belong to healthy level fig 10a the overall health statuses of the criteria levels are good in the upper reaches of lhasa river in the middle reaches of lhasa river the social services are the same health level as upper reaches fig 10b a clear downward trend appears in the water quantity and quality physical habitat and aquatic life water quantity and quality decrease from excellent to healthy level meanwhile the physical habitat and aquatic life change from healthy to subhealthy level compared with the upper reaches of lhasa river the physical habitat water quantity and quality aquatic life and social services all show significant downtrends the physical habitat and aquatic life decline to subhealthy level and the social services water quantity and quality transform from excellent to healthy level fig 10c overall the health status of criteria levels in turn are upper reaches middle reaches lower reaches differences in health status of the upper middle and lower reaches of lhasa river are relatively obvious in terms of the water quantity and quality physical habitat and aquatic life and show a trend of upper reaches middle reaches lower reaches a similar trend also emerges in the social services i e upper reaches middle reaches lower reaches 3 3 3 health levels of the lhasa river the health levels of the upper middle and lower reaches of lhasa river are determined by integrating the performances in terms of physical habitat water quantity and quality aquatic life and social services fig 11 on the whole the upper reaches of lhasa river are at a healthy level while the middle and lower reaches are at a subhealthy level this indicates that the upper reaches are healthy in terms of ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services however the middle and lower reaches are still subhealthy especially in ecosystem integrity additionally there is an increasing trend in similarity degree associated with unhealthy and sick grades indicating the river health level declines gradually fig 11b and c 4 discussion 4 1 ecosystem integrity 4 1 1 physical habitat physical habitat is primarily used to measure the morphological and structural integrity of lhasa river and encompasses river connectivity c1 riparian naturalness c2 and land development c3 the upper reaches of lhasa river are at the confluence of the basin without hydropower stations and sluice gates therefore the river flow is unobstructed and the river connectivity is in good condition i e healthy level fig 9 the ecological flow regime is influenced by two hydropower stations in middle reaches and several rubber dams and sluice gates in lower reaches which significantly reduces the river connectivity tian et al 2020 this forces the river connectivity in the middle and lower reaches of lhasa river to be at subhealthy and unhealthy grades respectively as the middle and upper reaches of lhasa river are less affected by human activities the riverbank is still in a natural state and the riparian naturalness is at a healthy level fig 9 the lhasa city locates on the lower reaches of lhasa river is the political and economic center of tibet the reduction of riparian stability and vegetation cover triggered by socio economic development and urbanization is the main reason for the significant reduction of riparian naturalness in the lower reaches of lhasa river tao et al 2019 and the construction of reservoirs in middle reaches and urban development in lower reaches intensify the degree of land development causing it to be at a subhealthy level over the past 30 years a dramatic change occurred in urban and built up areas economic development and population growth transformed more than 47 km2 of forest and arable land into urban construction land li et al 2020a in addition the lhasa municipal government vigorously promoted the construction of water conservancy projects and nearly 27 km2 of forest land was utilized to construct reservoirs during this period chen et al 2019 the physical habitat of lhasa river is strongly influenced by the construction of water conservation projects increasing the river connectivity and optimizing the water conservation projects are practical measures to improve the physical habitat 4 1 2 water quantity and quality the ecological resilience of lhasa river is examined in terms of water quantity and quality which mainly includes the ecological flow satisfaction c4 water quantity mutation c5 oxygen consuming organics c6 heavy metal c7 and substrate contamination c8 the ecological flow satisfaction and water quantity mutation of upper reaches are little affected by human activities which are in excellent levels fig 9 although the reservoirs in middle reaches and urban construction in lower reaches have a negative impact on the ecological flow regime they still meet the water quantity requirements for maintaining natural ecosystems the c4 and c5 are also in the healthy level for the water quality the oxygen consuming organics in lhasa river belongs to the excellent level meanwhile heavy metal and substrate contamination are excellent in upper reaches healthy in middle and lower reaches this indicates that the water quality conditions of lhasa river are good and basically meet the ecological water requirements in summary the water quantity and quality belong to an excellent or healthy level which means that the water quantity and quality conditions are relatively good in lhasa river fig 10 there is a strong potential for urban water supply and ecological resilience in the lhasa river currently water supply in lhasa city is from the three water intakes in lower reaches of lhasa river water quantity and quality meet regional standards and requirements for living industry agriculture ecology and landscape recreation this phenomenon should be maintained to achieve a win win situation between socio economic development and water environment in the lhasa river basin 4 1 3 aquatic life aquatic life is used to reveal the aquatic ecological integrity and biodiversity of lhasa river including phytoplankton c9 macroinvertebrate c10 fish c11 and waterbirds c12 in this study the phytoplankton of lhasa river is investigated comprehensively from four aspects namely species composition distribution density and biomass field sampling and laboratory analysis are conducted from october to december 2020 the monitoring results show that the phytoplankton in the upper reaches of lhasa river is at a healthy level although the reservoirs in the middle reaches play a major role in flood control and economic development they also have a negative impact on the regional ecological environment for instance phytoplankton in the upper reaches can only move to upper reaches and that in the lower reaches can only spread to lower reaches mao et al 2020 phytoplankton loses their natural habitat in the middle reaches which reduces the biodiversity and self purification capacity of the river to some extent even though ecological flow requirements are met in the lower reaches multiple rubber dams and sluice gates reduce river connectivity and phytoplankton health the above reasons put the phytoplankton in the middle and lower reaches at unhealthy and subhealthy levels respectively fig 9 macroinvertebrates mainly inhabit the water bottom or attach to aquatic plants and rocks bighiu et al 2020 similar to the phytoplankton findings macroinvertebrates are less affected by human activities in the upper reaches and are in healthy level fig 9 the macroinvertebrates reduce to subhealthy levels due to the impact of the reservoirs in middle reaches as well as the rubber dams and sluices in lower reaches on ecological flow regimes the fish resources in the upper reaches are relatively good and belong to the healthy level the performances of fish resources in the middle and lower reaches mainly include i changes in river nutrient structure and biodiversity caused by reservoir construction force a decline in poorly adapted fish species lin et al 2017 ii tibetan buddhism is prevalent in tibet and fish release activities are common leading to the introduction of a large number of exotic fish such as crucian carp pseudorasbora parva and loach yang et al 2007 the released fishes gradually form invasive species and crowd out the survival environment of indigenous fish species therefore fish resources are subhealthy in the middle and lower reaches fig 9 the lhasa river basin provides suitable habitats for waterbirds that are rich in both species and numbers which are in excellent or healthy level previous studies have shown that species and number of waterbird in lhasa river exhibited an increasing trend during 2014 2018 with tadorna ferruginea anser indicus and grus nigricollis accounting for about 91 9 of the total number of waterbirds jia et al 2019 li et al 2018b in general aquatic life is healthy in the upper reaches and is subhealthy in the middle and lower reaches fig 10 in future water conservation planning ecological water replenishment can be properly carried out in the middle reaches and the rubber dams and sluices also can be removed in the lower reaches to balance the water conservation projects and river ecological functions and reduce the impact on aquatic life 4 2 non ecological performance social services are applied to reflect non ecological performance in this study and the indicators revealing the sustainability of social service functions contain flood protection c13 water supply c14 water resources development c15 and public satisfaction c16 at present population is sparse and flood control requirements are low in the upper reaches therefore large scale embankment improvements have not yet been carried out the total storage capacity of pangduo reservoir and zhikong reservoir in the middle reaches is 1 23 billion m3 and 0 224 billion m3 respectively they are fully adequate to meet the demands for flood control population and businesses in lhasa river basin are mainly concentrated in the lower reaches currently an embankment with a length of 43 4 km exists in the lower reaches qin et al 2019 it provides a strong guarantee for flood control in lhasa city there are 13 drinking water sources in the lhasa river basin with a water supply area of 55 km2 and an annual water supply of 131 9 million tons to lhasa city supply water quality all meets the drinking water quality standards stipulated in the environmental quality standards for surface water gb 3838 2002 so the water supply is excellent in the lhasa river fig 9 the tibet water resources bulletin shows that the total water resource in lhasa river basin from 2003 to 2012 is 115 4 billion m3 and the average annual water consumption is 5 16 billion m3 chen et al 2020 li et al 2021 in the past 10 years the water resources development in the lhasa river basin is relatively low with an average annual development rate of 4 5 at present this low water resources development is able to meet the water demand for socio economic development in the basin therefore the water resources development is excellent in the lhasa river fig 9 to investigate the c16 of lhasa river basin in terms of ecosystem integrity and non ecological performance the questionnaires are developed and distributed to local residents in this study and the survey results are then tallied 200 questionnaires 20 in upstream 60 in midstream and 120 in downstream are distributed according to the distribution of administrative area and residents survey results show that a high c16 exists in the lhasa river basin which is at excellent level fig 9 overall the social services of lhasa river belongs to an excellent or healthy level flood protection water supply and water resources development provide an important foundation for the economic development in the basin fig 10 meanwhile a high level of public satisfaction exists in the lhasa river basin efforts should be made to maintain this phenomenon in the future and to improve the sustainability of social service functions in lhasa river 4 3 health level of sampling sites the health level of each sampling site is shown in fig 12 in the upper reaches of lhasa river s1 s5 are in excellent level and s6 s7 are healthy caused by small scale grazing comprehensive result calculated by the mscm indicates that a healthy level appears in the upper reaches fig 11 in the middle reaches s9 is excellent s8 s10 and s11 are healthy sampling sites s12 s16 are reduced to subhealthy levels due to the influence of two reservoirs and the comprehensive level is subhealthy fig 11 in the lower reaches two sampling sites s18 and s19 are healthy and five sampling sites s17 s20 s21 s24 and s25 belong to the subhealthy level besides s22 and s23 are located in urban river sections which are highly influenced by human activities and exhibit an unhealthy level the main reason is that a significant decline in physical habitat and aquatic life caused by the superimposed effects of water conservancy projects rubber dams and sluices and human activities fish release fig 10 so the comprehensive level is subhealthy in the lower reaches fig 11 overall 13 of the 25 sampling sites in the lhasa river are excellent or healthy accounting for 52 of the total sampling sites ten monitoring sites five each in the middle and lower reaches are at subhealthy levels accounting for 40 of the total only two sampling sites in the urban section of lhasa river are at unhealthy levels meanwhile the health level of lhasa river exhibits significant spatial variability influenced by urban construction and water conservancy projects with decreasing health level from upper to lower reaches 4 4 comparison of different models for river health assessment to reveal the effectiveness of mscm for assessing river health with fuzzy monitoring data a comparative investigation is performed with reference to zhang et al 2004 li et al 2011 and ren et al 2016 in this study maximum boundary based cloud model mcm yao et al 2017 expectation based cloud model ecm li et al 2019 similar cloud measurement scm hou et al 2021 and mscm are used to calculate the similarity degree and results are shown in fig 13 compared with mscm the health level of s7 improves and of s9 decreases when using the scm method s17 shows an increased trend in the ecm calculation a significant difference exists in s6 s9 s11 s18 s19 s22 and s23 when utilizing the mcm method the similarity between mscm and scm is 92 between mscm and ecm is 96 while between mscm and mcm is only 72 to further reveal the statistical significance of the proposed model a hypothesis testing paired sample t test method is utilized drawing on pham and jimenez 2012 s research framework the descriptive statistics of different models are shown in table 3 results show that the sig value of paired model mscm ecm is 0 038 the sig value is less than 0 05 indicating that a statistical significance is reached in mscm and ecm the upper and lower limits of the 95 confidence interval are negative indicating that the results obtained by mscm are significantly smaller than those of ecm however the sig values of mscm scm mscm mcm scm ecm scm mcm and ecm mcm are 0 976 0 130 0 066 0 137 and 0 554 which are all greater than 0 05 this suggests that the results of above paired models are not statistically significant in addition the larger values of standard deviation and standard error mean appear in mscm mcm scm mcm and ecm mcm this means that the mcm model differs significantly from the mscm ecm and mcm models overall the calculated results of mscm scm and ecm are more similar but the results of mcm differ significantly from them scm is a distance measure the smaller the distance is the more similar the two clouds are scm calculates the distance between two clouds by computing the average of random cloud droplets and this method usually causes unstable results gong et al 2015 the ecm does not take into account the effect of h e and the calculated results of ecm are slightly larger than mscm fig 13 and table 3 although h e is considered in the mcm the maximum boundary method used expands the role of h e leading to different results from the other three methods yan et al 2019 mscm uses fuzzy theory to improve the expectation curve of cloud model and integrate the cloud digital characteristics which can better reveal the similarity of normal clouds this method can overcome the shortcomings of existing methods and provide an effective and feasible way for assessing river health with fuzzy monitoring data 4 5 comparison of different weights for river health assessment the combined weights of river health indicators are gained by optimizing the ahp and ie weighting methods weights calculated by ahp usually rely on the preferences of decision makers for indicator attributes liu et al 2020b and weights obtained by ie depend on the information content provided by data itself zhang and wang 2021 the hybrid model architecture is established by drawing on the advantages of ahp and ie weighting methods to accurately assess the river health levels with fuzzy monitoring data this study uses ahp and ie weighting methods based on minimum deviation principle to obtain the cw of river health indicators the health levels of lhasa river based on different weighting methods are shown in fig 14 the health levels at two sampling sites s6 and s17 are altered when using ahp and cw and the health levels of s9 and s23 are changed using ie and cw however the use of ahp and ie shifts the health levels of s6 s9 s17 and s23 the similarity between ahp and cw is 92 between ie and cw is 92 while between ahp and ie is only 84 in addition there is only one grade difference in river health when using different weighting methods indicating that indicator weights are not particularly sensitive to the mscm overall different weighting methods have a few effects on the river health assessment different weights make the health levels of four sampling sites s6 s9 s17 and s23 change in the lhasa river and indicator weights are not particularly sensitive to the mscm the cw based on minimum deviation principle not only considers relative importance of indicator attributes but can also make full use of the information content provided by the data this method integrates the subjective preferences and the objective information content which can make the weights more reliable and reasonable in the river health assessment 4 6 health restoration measures for the lhasa river there are 17 global goals in the united nations un sustainable development goals sdgs zhang and li 2020 the specific target of sdgs 6 is clean water and sanitation liu et al 2020c more opportunities for sustainable water resources management and water environmental protection are provided by the un sdgs 6 to expand their focus zhang et al 2018b to relieve the increasing frequency and severity of river pollution caused by human activities it is essential to improve river health more effectively river health assessment is an important component for promoting sustainable water management with rapid urbanization and industrialization a large scale wastewater is discharged into rivers which brings great pressure on the water environment in china it is important for tibet to achieve the sustainable management of river health in future urban planning although the socio economic development in lhasa river basin have achieved gratifying results in recent years the river management influenced by urban construction and water conservancy projects still face persistent challenges clarifying the responsibilities of river chiefs and improving the management capacity are practical measures in lhasa river basin to mitigate the adverse effects of midstream reservoirs on river health it is necessary to strengthen river monitoring efforts in terms of water quantity and quality physical habitat and aquatic life possible measures include i setting up more monitoring sites in the reservoir area to achieve real time dynamic monitoring and reveal the impact of water conservancy projects on river ecosystems ii developing a reasonable reservoir scheduling plan to meet the production living and ecological water requirements in the lhasa river iii removing the rubber dams and sluices in lower reaches to balance the water conservation projects and river ecological functions and reduce the impact on aquatic life iv focusing on the protection of indigenous fish species especially the invasion of exotic fish caused by fish release setting up special fish release areas and releasing indigenous fish species and v formulating inclusive policies for river management and increasing public participation in the river chief system 4 7 limitations and future research the lhasa river is located in the qinghai tibetan plateau and is less affected by human activities early researches about the lhasa river are relatively few historical data contain only a small amount of runoff and remote sensing images moreover tibet has concentrated rainfall from june to september every year and geological disasters such as flash floods landslides and mudslides occur frequently there are also limitations in this study due to the availability of data and the spatial variability of river health restricted by the safety and convenience of sampling in study area we only use monitoring data from 25 sampling sites to evaluate the health levels in lhasa river additionally field sampling and laboratory analysis of aquatic life are conducted from october to december 2020 non flood season without considering the river health during the flood season possible future studies based on this study include i increasing the number of sampling sites according to the hydrological water quality hydrodynamic and biological characteristics of lhasa river ii optimizing the indicator system and evaluation methods iii increasing the study period and sampling frequency to comprehensively investigate the river health level in flood and non flood periods iv investigating seasonal changes in river health based on regular monitoring in terms of physical habitat water quantity and quality aquatic life and social services and v creating a complete monitoring system by closely integrating the results of river health assessment with the characteristics of qinghai tibet plateau 5 conclusion to comprehensively investigate the river health in the qinghai tibet plateau china the lhasa river is selected as study area an indicator system incorporating ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services is constructed the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction combined weights of river health indicators are calculated using the minimum deviation principle a novel multidimensional similarity cloud model is then developed for assessing river health with fuzzy monitoring data the main conclusions are reached as follows 1 the upper reaches of lhasa river are healthy in terms of ecosystem integrity and non ecological performance and the health level exhibits significant spatial variability influenced by urban construction and water conservancy projects with decreasing health level from upper to lower reaches 2 13 of the 25 sampling sites in the lhasa river are excellent or healthy accounting for 52 of the total sampling sites ten monitoring sites five each in the middle and lower reaches are subhealthy accounting for 40 of the total only two sampling sites in the urban section of lhasa river are at unhealthy levels 3 an excellent or healthy level occurs in terms of social services water quantity and quality physical habitat and aquatic life are greatly influenced by reservoir construction in middle reaches and urbanization in lower reaches and river health levels show significant decline 4 compared with conventional cloud models the mscm developed in this study can better identify river health level with fuzzy monitoring data this model provides a more effective approach to accurately evaluate the river health level in the qinghai tibet plateau china credit authorship contribution statement zhengxian zhang investigation methodology software visualization writing original draft writing review editing yun li conceptualization supervision writing review editing xiaogang wang funding acquisition supervision validation hongze li data curation validation feidong zheng data curation validation yipeng liao project administration resources nanbo tang project administration resources guangyu chen data curation supervision chang yang data curation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by major key technology research on water resources in china sl no y121016 and health assessment of rivers and lakes in tibet autonomous region sl hnsy 54000021210200000202 
3953,rivers provide the basis for sustainable socio economic development but increasingly intense human activities poses a threat to river health to comprehensively investigate the river health in the qinghai tibet plateau china the lhasa river is selected as study area and a comprehensive indicator system incorporating ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services is constructed the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction combined weights of river health indicators are calculated using the minimum deviation principle a novel multidimensional similarity cloud model mscm is then developed for assessing river health with fuzzy monitoring data results show that the upper reaches of lhasa river is healthy in terms of ecosystem integrity and non ecological performance and the health level exhibits significant spatial variability influenced by urban construction and water conservancy projects with decreasing health level from upper to lower reaches 52 of the sampling sites are at excellent or healthy levels 40 are subhealthy and 8 are unhealthy in the lhasa river accordingly recommendations and measures are proposed to improve river health level and explore sustainable water management policies in the qinghai tibet plateau china keywords river health assessment cloud model multidimensional similarity ecosystem integrity non ecological performance 1 introduction rivers around the world have experienced long term degradation as a result of human disturbance maddock 1999 yang et al 2017 phenomena such as channel modification river blockage and water pollution have changed the structure and function of river ecosystems wang et al 2019 the concept of river health was first introduced in 1972 in the clean water act enacted by the u s environmental protection agency to maintain and restore the chemical physical and biological integrity of waters downing et al 2003 integrity means maintaining the river ecosystem in good condition in terms of natural structure and function karr 1999 boulton 1999 reviewed the development history of river health and incorporated ecological integrity and human values into the definition of river health the eu water framework directive issued in 2 000 further proposes to build an integrated management pattern for water ecosystem health in the watersheds voulvoulis et al 2017 the management of global water environment is gradually shifting from pollution control to ecological restoration yang et al 2021 river health assessment provides comprehensive measurement and diagnosis of river conditions in a basin and is a prerequisite for river restoration and management the united states fesenmyer et al 2020 united kingdom zeng et al 2020 and australia chessman 2021 have established river health assessment systems tailored to the characteristics of their rivers which play an important role in the restoration and management of the water environment petersen 1992 established the riparian channel and environmental inventory and used it to guide river monitoring and evaluation in agricultural areas currently a convincing international definition of river health is that a healthy river should not only meet ecological integrity but also take into account the non ecological performance of the river system anwar sadat et al 2020 yang and wang 2020 wan et al 2021 compared with international research experience river health research was carried out later in china over the past 30 years although promising results have been achieved in water pollution control and management the focus has been mainly on the improvement and restoration of water quality xu et al 2019 research on ecosystem integrity is lacking and river management systems based on water ecosystem health have not been established the responsibilities of china s river management and policies are scattered and unclear over the past few decades liu et al 2019b in recent years a series of measures designed to improve river health level are implemented in china since 2010 ecological restoration and regular health evaluations of typical rivers were implemented in china liu et al 2019a zhang et al 2021 in 2016 a new policy for improving river management was announced known as river chief system responsibility for protecting water environment is placed on the shoulders of government officials and is linked to government performance in this policy liu et al 2020a wang and chen 2020 river chiefs are divided into four levels with diminishing power namely provinces cities counties and townships who are assigned to be responsible for rivers within their jurisdiction tang et al 2020 accordingly the prevention and control of river pollution are gradually being taken seriously by government officials in addition a public supervision system and an open information platform for river management are developed and then the conflicts between different sectors are relieved effectively through the river chief system to accurately determine the river health level with fuzziness various models were applied by previous researchers existing research methods associated with river health mainly include multivariate statistical analysis pinto and maheshwari 2011 fuzzy theory xu and liu 2014 ren et al 2018 gray correlation wang et al 2019 set pair analysis zhao et al 2019b topsis model xu et al 2019 matter element model deng et al 2015 artificial neural network jeong et al 2001 and combined models of these methods pan et al 2015 wan et al 2021 zhang et al 2018a conceptually river health assessment can be considered as a multi indicator decision making process with qualitative and quantitative uncertainties the multi indicator decision model is built with quantitative indicators of river health as inputs and qualitative evaluation as outputs yao et al 2019 uncertainties in river health assessment mainly include three aspects i uncertainty in the monitoring data caused by the sampling process li et al 2018a zhang and li 2020 ii uncertainty introduced by changing external environment and different analysis methods deng et al 2015 kang et al 2018 and iii uncertainty generated by multiple indicators with different attributes zhao et al 2019b these uncertainties complicate river health assessments and introduce inherent fuzziness in the evaluation process yan et al 2017 although the aforesaid methods play an important role in river health assessment they still ignore a comprehensive consideration for the fuzziness of river health and are limited to specific conditions on applicabilities li et al 2020b in addition the robustness of decision outcomes may be significantly affected by the oversimplification of the fuzzy factors lu et al 2017 this may lead to wrong decisions to some extent accordingly this study introduces a new hybrid model cloud model to overcome the above mentioned shortcomings referring to the research frameworks of lu et al 2017 and yao et al 2021 the cloud model based on cloud digital characteristics achieves the conversion between quantitative indicators and qualitative evaluation through the cloud generator which can effectively integrate the fuzziness of river health assessment yang and wang 2020 cloud droplets are the basic units that form clouds and the distribution area of cloud droplets is called domain space li et al 2009 cloud digital characteristics consist of expectation e x entropy e n and hyper entropy h e which are important parameters for determining the river health level e x represents the expectation distribution of cloud droplets in the domain space yao et al 2019 yang and wang 2020 e n reveals the dispersion degree of cloud droplets which can effectively reflect the fuzziness of river health h e is used to measure the uncertainty of the entropy and demonstrates the cohesiveness between cloud drops yao et al 2019 and the cloud generators are divided into forward and reverse cloud generators quantitative information and distribution patterns are extracted from the qualitative information using a forward cloud generator cloud digital characteristics e x e n h e are then calculated using a reverse cloud generator based on monitoring data wang et al 2014 the normal cloud model is one of the most common cloud models and can be constructed using the normal membership and distribution function to comprehensively investigate the river health level in the qinghai tibet plateau china the lhasa river is selected as study area an indicator system incorporating ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services is constructed the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction and the combined weights of river health indicators are calculated using the minimum deviation principle a novel multidimensional similarity cloud model mscm is then developed for assessing river health levels with fuzzy monitoring data in light of this the accuracy and reliability of river health assessment can be effectively improved by maximizing the information content provided by monitoring data and reducing the impact of fuzziness the objectives of this study mainly include i developing a novel multidimensional similarity cloud model to comprehensively investigate the river health with fuzzy monitoring data ii constructing a comprehensive indicator system to quantitatively investigate the river health level in the qinghai tibet plateau from the perspective of ecosystem integrity and non ecological performance and iii applying this model to evaluate river health and proposing ecological restoration recommendations based on the evaluation results 2 materials and methods 2 1 study area lhasa river is located in the southeastern qinghai tibet plateau and is one of the highest rivers in the world with an average altitude of over 3600 m the total length of the river is about 551 km mao et al 2020 lhasa river basin is the economic and population center of tibet ranging from 90 05 e 93 20 e to 29 20 n 31 15 n with an area of 32 588 km2 li et al 2020a precipitation meltwater and lateral infiltration of groundwater are the main recharged sources for the lhasa river basin the climate in lhasa river basin is semi arid monsoon with distinct dry and wet seasons the average annual temperature is 5 3 c and the average annual precipitation is about 400 500 mm tian et al 2020 in addition the lhasa river basin is characterized by concentrated summer precipitation low annual temperature differences and high daily temperature differences due to the influence of warm and humid air from the indian ocean study area has high mountains and deep ravines which slops from southwest to northeast with an elevation difference of more than 3500 m liu et al 2014 more than 90 of the land is covered by grassland and sparse vegetation and human activities are mainly concentrated in the lower valley of lhasa river which is below 4200 m above sea level fig 1 there are two large hydropower stations in the middle reaches of lhasa river namely zhikong hydropower station 100 mw and pengduo hydropower station 160 mw land use changes in the lhasa river valley mainly include urbanization in lhasa reservoir construction in the middle reaches and afforestation in the flood plain fig 2 2 2 river health indicator system and score criteria to comprehensively investigate the health status of lhasa river it is necessary to evaluate the various elements of river health and select indicators to describe each element the critical indicators are obtained based on expert consultation and previous studies makokha et al 2016 kebede et al 2020 chen et al 2021 the river health indicator system is shown in table 1 river health indicator system integrates the ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services of the river physical habitat is primarily used to measure the morphological and structural integrity of a river and encompasses river connectivity c1 riparian naturalness c2 and land development c3 the ecological resilience of the river is examined in terms of both water quantity and quality which mainly includes the ecological flow satisfaction c4 water quantity mutation c5 oxygen consuming organics c6 heavy metal c7 and substrate contamination c8 aquatic life is used to reveal the aquatic ecological integrity and biodiversity of the river including phytoplankton c9 macroinvertebrate c10 fish c11 and waterbirds c12 and the indicators reflecting the sustainability of social service functions contain flood protection c13 water supply c14 water resources development c15 and public satisfaction c16 the specific calculation methods of the above indicators and the corresponding indicator health scores refer to the technical guidelines for river and lake health assessment tgrl 2020 and the river and lake health evaluation guide trial rlhe 2020 2 3 data collection lhasa river is divided into upper middle and lower reaches according to the characteristics of hydrology riparian zone morphology water quality aquatic life and socio economic development considering the features of evaluation indicators the representativeness of sampling sites and the safety and convenience of sampling the sampling sites within each evaluation river section are initially determined based on the site surveys and expert consultations 25 sampling sites are finally selected to investigate the health level of lhasa river sampling sites s1 s7 s8 s16 and s17 s25 are set in the upper middle and lower reaches of lhasa river respectively fig 1 in this study 25 sampling sites were selected to comprehensively investigate the health level of lhasa river in terms of physical habitat water quantity and quality aquatic life and social services data of physical habitat water quantity and quality aquatic life and social services were collected from 2017 to 2020 the monitoring frequency of physical habitat and social services was once a year and of water quantity was once a week table1 the monitoring frequency of water quality indicators was once a week except the substrate contamination c8 that was twice a year given the safety and convenience of sampling in the qinghai tibet plateau field sampling and laboratory analysis of aquatic life were conducted from october to december 2020 non flood season at each sampling site 50 l water samples were collected from the surface layer 0 5 m layer and 1 m water layer with a 2 5 l water sampler the water samples were filtered through the 25 μm polyethylene filter screen and then stored in a 100 ml bottle qualitative analysis of phytoplankton was also carried out using the 25 μm micron plankton net lugol reagent was added to the water samples to fix the phytoplankton and the supernatant was concentrated to 30 ml after 48 h of sedimentation phytoplankton species and genera were identified and counted using a microscope nikon eclipse 50i eight subsamples were collected at each sampling site to assess the condition of the macroinvertebrates macroinvertebrates were sorted from sediment and other debris using a 500 μm sieve bucket fish resources were surveyed in different river sections and the collected fish samples were preserved by formalin fixation fish age species abundance and density were assessed and analyzed to determine the condition of fish resources 10 trained and experienced observers counted the species numbers and densities of waterbirds observers walked along the lhasa river and used binoculars to observe waterbirds in addition the online information published in china bird report http www birdreport cn was also referenced in this study 2 4 multidimensional similarity cloud model for river health assessment to obtain the cloud digital characteristics of samples and river health grades sample data and evaluation indicator grades are submitted as inputs to the inverse cloud generator the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction the combined weights of river health indicators are then calculated using analytic hierarchy process ahp and information entropy ie weighting methods based on the minimum deviation principle finally the integrated cloud digital characteristics for the target level and criteria level are gained through combined weights in river health indicators one of the purposes of this study is to accurately evaluate the river health in the qinghai tibet plateau under the conditions of fully considering the complex relationships between river health indicators as well as the fuzziness in evaluation process therefore a novel mscm is developed and the cloud digital characteristic vectors associated with each sample and health grade are constructed in light of this the health levels of the upper middle and lower reaches of lhasa river are determined according to the fuzzy similarity measurement between samples and health grades in this study the mscm is developed by drawing on the research framework of yao et al 2019 the specific calculation process of mscm is shown in fig 3 2 4 1 cloud digital characteristics of health grades the river health grades and the corresponding cloud digital characteristics are shown in table 2 the specific calculation method is as follows 1 e x b min b max 2 e n b max b min 6 h e k e n where e x is the expectation e n is the entropy and h e is the hyper entropy in cloud model e x reflects the representativeness of the grade threshold range in all cloud droplets e n can measure the randomness and uncertainty represent the correlation between stochasticity and fuzziness and determine the scope of cloud droplet h e is usually used to reveal the uncertainty of e n cloud digital characteristic vector is expressed as e x e n h e b min and b max are the minimum and maximum values of the grade threshold range respectively k is an adjustment coefficient used to adjust the cohesion of cloud droplets in this study k 0 1 yao et al 2019 zhang et al 2020 2 4 2 cloud digital characteristics of indicator samples the random impacts of sampling methods and environmental factors on the accuracy of monitoring data can be effectively reduced by the wavelet noise reduction simoncelli and adelson 1996 jansen 2012 therefore wavelet noise reduction is applied to preprocess the sample data and accurately calculate the cloud digital characteristics of indicator samples 2 f x a j f x d j f x a j f x k z c j k φ j k x d j f x k z d j k ψ j k x where f x is the monitoring data sequence a j f x and d j f x are different frequency components decomposed by the mallal algorithm a j f x and d j f x are the projections of f x on the low frequency and high frequency signals respectively to reduce the noise interference the high frequency signal associated with the noise is eliminated and the reconstructed signal is then obtained 3 f x k z c j k φ j k x 4 t median d 1 0 6745 2 ln n where f x is the smooth signal of f x after wavelet noise reduction that is the extracted real signal t denotes the threshold function d 1 is the adjustment coefficient for the first level of decomposition and n is the data length daubechies wavelet db2 is used and data are decomposed in five layers in this study the evaluation samples after wavelet noise reduction are then utilized as inputs in the reverse cloud generator to calculate the cloud digital characteristics of indicator samples specific calculation process is as follows 5 e x j 1 m i 1 m x ij e n j π 2 1 m i 1 m x ij e x j i 1 2 m j 1 2 n h e j s j 2 e n j 2 where x ij is the cloud droplet value of the j th indicator in the i th evaluation sample s j 2 1 m 1 i 1 m x ij e x j 2 2 4 3 calculation of the combined weights the analytic hierarchy process ahp method can decompose a multi attribute decision problem into more comprehensible hierarchical structures to determine the weights of evaluation indicators liu et al 2020b it is one of the most important subjective weighting methods in multi attribute decision making and carries the advantages of flexibility and simplicity the indicator weights are determined based on the information content provided by data itself zhang and wang 2021 this method is called information entropy ie weighting method it balances the subjective preferences of decision makers reduces the unfairness of the decision making process and is highly objective to accurately assess the river health status with fuzzy monitoring data a combined weighting method drawing on the advantages of ahp and ie is applied in this study suppose there are r weighting methods and m river health indicators the weight vector w k can be expressed as follows 6 w k w k 1 w k 2 w k 3 w km t k 1 2 3 r i 1 m w ki 1 combined weights are obtained based on minimum deviation principle and the calculation process is as follows 7 min d j 1 n k 1 r i 1 m α k w ki α j w ij 2 8 s t k 1 r α k 1 α k 0 k 1 2 r where d represents the deviation between different weighting methods the purpose is to minimize the weight deviation α k and α j are the combination coefficient between different weighting methods the above conditional extremum problem can be solved by lagrangian function lagrange multipliers 9 l α λ j 1 n k 1 r i 1 m α k w ki α j w ij 2 λ t 1 r α t 1 the partial derivatives of eq 9 can be calculated according to the following formulas 10 l α k i 1 m α k w ki α 1 w 1 i α k w ki α 2 w 2 i α k w ki α r w ri w ki λ 2 0 l α k r α k i 1 m w ki 2 α 1 i 1 m w 1 i w ki α 2 i 1 m w 2 i w ki α r i 1 m w ri w ki λ 2 0 l λ k 1 r α k 1 0 where eqs 9 and 10 are multi dimensional linear equations containing r 1 unknowns if the determinant of the coefficient is not 0 the aforesaid equations have unique solution vector α α 1 α 2 α 3 α r 2 4 4 integrated cloud digital characteristics the weighted integration of multiple arbitrary clouds c i e xi e ni h ei designed to develop an integrated cloud ic c 1 c 2 c n the construction of ic and the corresponding cloud digital characteristics are as follows 11 ic c 1 c 2 c n c e x e n h e 12 e x i 1 n w i e xi e n i 1 n w i e ni 2 h e i 1 n w i h ei 2 where ic is the integrated cloud and w i is the combined weight of river health indicator 2 4 5 river health assessment based on mscm a novel mscm based on the fuzzy similarity principle is developed to measure the matching degree of cloud digital characteristic vectors between samples and river health grades it is assumed that c s e xs e ns h es and c g e xg e ng h eg are the cloud digital characteristic vectors in samples and river health grades respectively the calculation process of similarity degree between them is as follows 13 s i c s c g 1 2 1 2 φ ξ 2 φ ξ 14 ξ e xg e xs e ns 2 h es 2 e ng 2 h eg 2 φ ξ ξ 1 2 π exp t 2 2 d t where s i denotes similarity degree between c s and c g river health levels can be revealed through the health grades with the greatest s i 3 results 3 1 cloud digital characteristics of evaluation indicators sample data of evaluation indicators are submitted as inputs to the reverse cloud generator and the cloud digital characteristics of samples are then obtained in the upper middle and lower reaches of lhasa river and the cloud diagrams of river health grades and evaluation indicators are shown in figs 4 and 5 the general scores of evaluation indicators in lhasa river are upper reaches middle reaches lower reaches fig 5 the dispersion of cloud droplets in lower reaches is significantly larger than upper reaches suggesting greater differences exist in the downstream samples in addition the health scores are higher for all indicators except for c9 c10 and c11 indicators this indicates that the overall health level of lhasa river is good 3 2 integrated cloud digital characteristics for criteria level and target level the ahp and ie weighting methods are optimized by the minimum deviation principle to obtain the combined weights cw of river health indicators as shown in fig 6 the cw is between ahp and ie drawing on the advantages of two weighting methods with more reasonable values based on the combined weights the integrated cloud models of the upper middle and lower reaches of lhasa river are established the integrated cloud digital characteristics are calculated and the cloud diagrams for criteria level are then drawn fig 7 differences in the upper middle and lower reaches of lhasa river are relatively obvious in terms of the physical habitat water quantity and quality and show a trend of upper reaches middle reaches lower reaches the smaller differences and higher health scores exhibit in the upstream samples fig 7a and b the health scores of aquatic life in the midstream and downstream are closer which are lower than the upstream scores fig 7c high social services scores occur in the upstream midstream and downstream indicating that lhasa river has sustainable social services functions fig 7d the cloud diagram of the target level is shown in fig 8 river health scores of the integrated cloud in turn are upper reaches middle reaches lower reaches and the agglomeration of cloud droplets in integrated clouds are upper reaches middle reaches lower reaches this means that the health levels of the upper reaches of lhasa river are better than the middle and lower reaches overall the health level is better in the upper reaches and is closer in the middle and lower reaches 3 3 determination of river health status 3 3 1 health status of evaluation indicators the health status of evaluation indicators can be determined by calculating the similarity degree between evaluation indicators and river health grades fig 9 the river health grade corresponding to the maximum similarity degree represents the health level of each indicator as shown in fig 9a there are ten indicators c4 c5 c6 c7 c8 c12 c13 c14 c15 and c16 in the excellent level and six indicators c1 c2 c3 c9 c10 and c11 in the healthy level and no indicators occurs in the subhealthy unhealthy and sick levels in the middle reaches of lhasa river six indicators c6 c12 c13 c14 c15 and c16 belong to the excellent level five indicators c2 c4 c5 c7 and c8 are healthy four indicators c1 c3 c10 and c11 are subhealthy one indicator c9 is unhealthy and no indicator belongs to the sick level fig 9b indicators in subhealthy and unhealthy levels increase by five in the middle reaches compared with the upper reaches this indicates a downward trend exists in the health level of evaluation indicators in the lower reaches of lhasa river indicators in excellent and healthy levels are five c6 c13 c14 c15 and c16 and six c2 c4 c5 c7 c8 and c12 respectively fig 9c c3 c9 c10 and c11 are subhealthy c1 is unhealthy and no indicator is sick compared with the middle reaches of lhasa river c12 changes from excellent to healthy level and c1 trends from subhealthy to unhealthy level 3 3 2 health status of criteria levels similarity degrees between the criteria levels and river health grades are shown in fig 10 in the upper reaches of lhasa river the social services water quantity and quality are excellent and physical habitat and aquatic life belong to healthy level fig 10a the overall health statuses of the criteria levels are good in the upper reaches of lhasa river in the middle reaches of lhasa river the social services are the same health level as upper reaches fig 10b a clear downward trend appears in the water quantity and quality physical habitat and aquatic life water quantity and quality decrease from excellent to healthy level meanwhile the physical habitat and aquatic life change from healthy to subhealthy level compared with the upper reaches of lhasa river the physical habitat water quantity and quality aquatic life and social services all show significant downtrends the physical habitat and aquatic life decline to subhealthy level and the social services water quantity and quality transform from excellent to healthy level fig 10c overall the health status of criteria levels in turn are upper reaches middle reaches lower reaches differences in health status of the upper middle and lower reaches of lhasa river are relatively obvious in terms of the water quantity and quality physical habitat and aquatic life and show a trend of upper reaches middle reaches lower reaches a similar trend also emerges in the social services i e upper reaches middle reaches lower reaches 3 3 3 health levels of the lhasa river the health levels of the upper middle and lower reaches of lhasa river are determined by integrating the performances in terms of physical habitat water quantity and quality aquatic life and social services fig 11 on the whole the upper reaches of lhasa river are at a healthy level while the middle and lower reaches are at a subhealthy level this indicates that the upper reaches are healthy in terms of ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services however the middle and lower reaches are still subhealthy especially in ecosystem integrity additionally there is an increasing trend in similarity degree associated with unhealthy and sick grades indicating the river health level declines gradually fig 11b and c 4 discussion 4 1 ecosystem integrity 4 1 1 physical habitat physical habitat is primarily used to measure the morphological and structural integrity of lhasa river and encompasses river connectivity c1 riparian naturalness c2 and land development c3 the upper reaches of lhasa river are at the confluence of the basin without hydropower stations and sluice gates therefore the river flow is unobstructed and the river connectivity is in good condition i e healthy level fig 9 the ecological flow regime is influenced by two hydropower stations in middle reaches and several rubber dams and sluice gates in lower reaches which significantly reduces the river connectivity tian et al 2020 this forces the river connectivity in the middle and lower reaches of lhasa river to be at subhealthy and unhealthy grades respectively as the middle and upper reaches of lhasa river are less affected by human activities the riverbank is still in a natural state and the riparian naturalness is at a healthy level fig 9 the lhasa city locates on the lower reaches of lhasa river is the political and economic center of tibet the reduction of riparian stability and vegetation cover triggered by socio economic development and urbanization is the main reason for the significant reduction of riparian naturalness in the lower reaches of lhasa river tao et al 2019 and the construction of reservoirs in middle reaches and urban development in lower reaches intensify the degree of land development causing it to be at a subhealthy level over the past 30 years a dramatic change occurred in urban and built up areas economic development and population growth transformed more than 47 km2 of forest and arable land into urban construction land li et al 2020a in addition the lhasa municipal government vigorously promoted the construction of water conservancy projects and nearly 27 km2 of forest land was utilized to construct reservoirs during this period chen et al 2019 the physical habitat of lhasa river is strongly influenced by the construction of water conservation projects increasing the river connectivity and optimizing the water conservation projects are practical measures to improve the physical habitat 4 1 2 water quantity and quality the ecological resilience of lhasa river is examined in terms of water quantity and quality which mainly includes the ecological flow satisfaction c4 water quantity mutation c5 oxygen consuming organics c6 heavy metal c7 and substrate contamination c8 the ecological flow satisfaction and water quantity mutation of upper reaches are little affected by human activities which are in excellent levels fig 9 although the reservoirs in middle reaches and urban construction in lower reaches have a negative impact on the ecological flow regime they still meet the water quantity requirements for maintaining natural ecosystems the c4 and c5 are also in the healthy level for the water quality the oxygen consuming organics in lhasa river belongs to the excellent level meanwhile heavy metal and substrate contamination are excellent in upper reaches healthy in middle and lower reaches this indicates that the water quality conditions of lhasa river are good and basically meet the ecological water requirements in summary the water quantity and quality belong to an excellent or healthy level which means that the water quantity and quality conditions are relatively good in lhasa river fig 10 there is a strong potential for urban water supply and ecological resilience in the lhasa river currently water supply in lhasa city is from the three water intakes in lower reaches of lhasa river water quantity and quality meet regional standards and requirements for living industry agriculture ecology and landscape recreation this phenomenon should be maintained to achieve a win win situation between socio economic development and water environment in the lhasa river basin 4 1 3 aquatic life aquatic life is used to reveal the aquatic ecological integrity and biodiversity of lhasa river including phytoplankton c9 macroinvertebrate c10 fish c11 and waterbirds c12 in this study the phytoplankton of lhasa river is investigated comprehensively from four aspects namely species composition distribution density and biomass field sampling and laboratory analysis are conducted from october to december 2020 the monitoring results show that the phytoplankton in the upper reaches of lhasa river is at a healthy level although the reservoirs in the middle reaches play a major role in flood control and economic development they also have a negative impact on the regional ecological environment for instance phytoplankton in the upper reaches can only move to upper reaches and that in the lower reaches can only spread to lower reaches mao et al 2020 phytoplankton loses their natural habitat in the middle reaches which reduces the biodiversity and self purification capacity of the river to some extent even though ecological flow requirements are met in the lower reaches multiple rubber dams and sluice gates reduce river connectivity and phytoplankton health the above reasons put the phytoplankton in the middle and lower reaches at unhealthy and subhealthy levels respectively fig 9 macroinvertebrates mainly inhabit the water bottom or attach to aquatic plants and rocks bighiu et al 2020 similar to the phytoplankton findings macroinvertebrates are less affected by human activities in the upper reaches and are in healthy level fig 9 the macroinvertebrates reduce to subhealthy levels due to the impact of the reservoirs in middle reaches as well as the rubber dams and sluices in lower reaches on ecological flow regimes the fish resources in the upper reaches are relatively good and belong to the healthy level the performances of fish resources in the middle and lower reaches mainly include i changes in river nutrient structure and biodiversity caused by reservoir construction force a decline in poorly adapted fish species lin et al 2017 ii tibetan buddhism is prevalent in tibet and fish release activities are common leading to the introduction of a large number of exotic fish such as crucian carp pseudorasbora parva and loach yang et al 2007 the released fishes gradually form invasive species and crowd out the survival environment of indigenous fish species therefore fish resources are subhealthy in the middle and lower reaches fig 9 the lhasa river basin provides suitable habitats for waterbirds that are rich in both species and numbers which are in excellent or healthy level previous studies have shown that species and number of waterbird in lhasa river exhibited an increasing trend during 2014 2018 with tadorna ferruginea anser indicus and grus nigricollis accounting for about 91 9 of the total number of waterbirds jia et al 2019 li et al 2018b in general aquatic life is healthy in the upper reaches and is subhealthy in the middle and lower reaches fig 10 in future water conservation planning ecological water replenishment can be properly carried out in the middle reaches and the rubber dams and sluices also can be removed in the lower reaches to balance the water conservation projects and river ecological functions and reduce the impact on aquatic life 4 2 non ecological performance social services are applied to reflect non ecological performance in this study and the indicators revealing the sustainability of social service functions contain flood protection c13 water supply c14 water resources development c15 and public satisfaction c16 at present population is sparse and flood control requirements are low in the upper reaches therefore large scale embankment improvements have not yet been carried out the total storage capacity of pangduo reservoir and zhikong reservoir in the middle reaches is 1 23 billion m3 and 0 224 billion m3 respectively they are fully adequate to meet the demands for flood control population and businesses in lhasa river basin are mainly concentrated in the lower reaches currently an embankment with a length of 43 4 km exists in the lower reaches qin et al 2019 it provides a strong guarantee for flood control in lhasa city there are 13 drinking water sources in the lhasa river basin with a water supply area of 55 km2 and an annual water supply of 131 9 million tons to lhasa city supply water quality all meets the drinking water quality standards stipulated in the environmental quality standards for surface water gb 3838 2002 so the water supply is excellent in the lhasa river fig 9 the tibet water resources bulletin shows that the total water resource in lhasa river basin from 2003 to 2012 is 115 4 billion m3 and the average annual water consumption is 5 16 billion m3 chen et al 2020 li et al 2021 in the past 10 years the water resources development in the lhasa river basin is relatively low with an average annual development rate of 4 5 at present this low water resources development is able to meet the water demand for socio economic development in the basin therefore the water resources development is excellent in the lhasa river fig 9 to investigate the c16 of lhasa river basin in terms of ecosystem integrity and non ecological performance the questionnaires are developed and distributed to local residents in this study and the survey results are then tallied 200 questionnaires 20 in upstream 60 in midstream and 120 in downstream are distributed according to the distribution of administrative area and residents survey results show that a high c16 exists in the lhasa river basin which is at excellent level fig 9 overall the social services of lhasa river belongs to an excellent or healthy level flood protection water supply and water resources development provide an important foundation for the economic development in the basin fig 10 meanwhile a high level of public satisfaction exists in the lhasa river basin efforts should be made to maintain this phenomenon in the future and to improve the sustainability of social service functions in lhasa river 4 3 health level of sampling sites the health level of each sampling site is shown in fig 12 in the upper reaches of lhasa river s1 s5 are in excellent level and s6 s7 are healthy caused by small scale grazing comprehensive result calculated by the mscm indicates that a healthy level appears in the upper reaches fig 11 in the middle reaches s9 is excellent s8 s10 and s11 are healthy sampling sites s12 s16 are reduced to subhealthy levels due to the influence of two reservoirs and the comprehensive level is subhealthy fig 11 in the lower reaches two sampling sites s18 and s19 are healthy and five sampling sites s17 s20 s21 s24 and s25 belong to the subhealthy level besides s22 and s23 are located in urban river sections which are highly influenced by human activities and exhibit an unhealthy level the main reason is that a significant decline in physical habitat and aquatic life caused by the superimposed effects of water conservancy projects rubber dams and sluices and human activities fish release fig 10 so the comprehensive level is subhealthy in the lower reaches fig 11 overall 13 of the 25 sampling sites in the lhasa river are excellent or healthy accounting for 52 of the total sampling sites ten monitoring sites five each in the middle and lower reaches are at subhealthy levels accounting for 40 of the total only two sampling sites in the urban section of lhasa river are at unhealthy levels meanwhile the health level of lhasa river exhibits significant spatial variability influenced by urban construction and water conservancy projects with decreasing health level from upper to lower reaches 4 4 comparison of different models for river health assessment to reveal the effectiveness of mscm for assessing river health with fuzzy monitoring data a comparative investigation is performed with reference to zhang et al 2004 li et al 2011 and ren et al 2016 in this study maximum boundary based cloud model mcm yao et al 2017 expectation based cloud model ecm li et al 2019 similar cloud measurement scm hou et al 2021 and mscm are used to calculate the similarity degree and results are shown in fig 13 compared with mscm the health level of s7 improves and of s9 decreases when using the scm method s17 shows an increased trend in the ecm calculation a significant difference exists in s6 s9 s11 s18 s19 s22 and s23 when utilizing the mcm method the similarity between mscm and scm is 92 between mscm and ecm is 96 while between mscm and mcm is only 72 to further reveal the statistical significance of the proposed model a hypothesis testing paired sample t test method is utilized drawing on pham and jimenez 2012 s research framework the descriptive statistics of different models are shown in table 3 results show that the sig value of paired model mscm ecm is 0 038 the sig value is less than 0 05 indicating that a statistical significance is reached in mscm and ecm the upper and lower limits of the 95 confidence interval are negative indicating that the results obtained by mscm are significantly smaller than those of ecm however the sig values of mscm scm mscm mcm scm ecm scm mcm and ecm mcm are 0 976 0 130 0 066 0 137 and 0 554 which are all greater than 0 05 this suggests that the results of above paired models are not statistically significant in addition the larger values of standard deviation and standard error mean appear in mscm mcm scm mcm and ecm mcm this means that the mcm model differs significantly from the mscm ecm and mcm models overall the calculated results of mscm scm and ecm are more similar but the results of mcm differ significantly from them scm is a distance measure the smaller the distance is the more similar the two clouds are scm calculates the distance between two clouds by computing the average of random cloud droplets and this method usually causes unstable results gong et al 2015 the ecm does not take into account the effect of h e and the calculated results of ecm are slightly larger than mscm fig 13 and table 3 although h e is considered in the mcm the maximum boundary method used expands the role of h e leading to different results from the other three methods yan et al 2019 mscm uses fuzzy theory to improve the expectation curve of cloud model and integrate the cloud digital characteristics which can better reveal the similarity of normal clouds this method can overcome the shortcomings of existing methods and provide an effective and feasible way for assessing river health with fuzzy monitoring data 4 5 comparison of different weights for river health assessment the combined weights of river health indicators are gained by optimizing the ahp and ie weighting methods weights calculated by ahp usually rely on the preferences of decision makers for indicator attributes liu et al 2020b and weights obtained by ie depend on the information content provided by data itself zhang and wang 2021 the hybrid model architecture is established by drawing on the advantages of ahp and ie weighting methods to accurately assess the river health levels with fuzzy monitoring data this study uses ahp and ie weighting methods based on minimum deviation principle to obtain the cw of river health indicators the health levels of lhasa river based on different weighting methods are shown in fig 14 the health levels at two sampling sites s6 and s17 are altered when using ahp and cw and the health levels of s9 and s23 are changed using ie and cw however the use of ahp and ie shifts the health levels of s6 s9 s17 and s23 the similarity between ahp and cw is 92 between ie and cw is 92 while between ahp and ie is only 84 in addition there is only one grade difference in river health when using different weighting methods indicating that indicator weights are not particularly sensitive to the mscm overall different weighting methods have a few effects on the river health assessment different weights make the health levels of four sampling sites s6 s9 s17 and s23 change in the lhasa river and indicator weights are not particularly sensitive to the mscm the cw based on minimum deviation principle not only considers relative importance of indicator attributes but can also make full use of the information content provided by the data this method integrates the subjective preferences and the objective information content which can make the weights more reliable and reasonable in the river health assessment 4 6 health restoration measures for the lhasa river there are 17 global goals in the united nations un sustainable development goals sdgs zhang and li 2020 the specific target of sdgs 6 is clean water and sanitation liu et al 2020c more opportunities for sustainable water resources management and water environmental protection are provided by the un sdgs 6 to expand their focus zhang et al 2018b to relieve the increasing frequency and severity of river pollution caused by human activities it is essential to improve river health more effectively river health assessment is an important component for promoting sustainable water management with rapid urbanization and industrialization a large scale wastewater is discharged into rivers which brings great pressure on the water environment in china it is important for tibet to achieve the sustainable management of river health in future urban planning although the socio economic development in lhasa river basin have achieved gratifying results in recent years the river management influenced by urban construction and water conservancy projects still face persistent challenges clarifying the responsibilities of river chiefs and improving the management capacity are practical measures in lhasa river basin to mitigate the adverse effects of midstream reservoirs on river health it is necessary to strengthen river monitoring efforts in terms of water quantity and quality physical habitat and aquatic life possible measures include i setting up more monitoring sites in the reservoir area to achieve real time dynamic monitoring and reveal the impact of water conservancy projects on river ecosystems ii developing a reasonable reservoir scheduling plan to meet the production living and ecological water requirements in the lhasa river iii removing the rubber dams and sluices in lower reaches to balance the water conservation projects and river ecological functions and reduce the impact on aquatic life iv focusing on the protection of indigenous fish species especially the invasion of exotic fish caused by fish release setting up special fish release areas and releasing indigenous fish species and v formulating inclusive policies for river management and increasing public participation in the river chief system 4 7 limitations and future research the lhasa river is located in the qinghai tibetan plateau and is less affected by human activities early researches about the lhasa river are relatively few historical data contain only a small amount of runoff and remote sensing images moreover tibet has concentrated rainfall from june to september every year and geological disasters such as flash floods landslides and mudslides occur frequently there are also limitations in this study due to the availability of data and the spatial variability of river health restricted by the safety and convenience of sampling in study area we only use monitoring data from 25 sampling sites to evaluate the health levels in lhasa river additionally field sampling and laboratory analysis of aquatic life are conducted from october to december 2020 non flood season without considering the river health during the flood season possible future studies based on this study include i increasing the number of sampling sites according to the hydrological water quality hydrodynamic and biological characteristics of lhasa river ii optimizing the indicator system and evaluation methods iii increasing the study period and sampling frequency to comprehensively investigate the river health level in flood and non flood periods iv investigating seasonal changes in river health based on regular monitoring in terms of physical habitat water quantity and quality aquatic life and social services and v creating a complete monitoring system by closely integrating the results of river health assessment with the characteristics of qinghai tibet plateau 5 conclusion to comprehensively investigate the river health in the qinghai tibet plateau china the lhasa river is selected as study area an indicator system incorporating ecosystem integrity physical habitat water quantity and quality aquatic life and non ecological performance social services is constructed the random impacts of sampling methods and environmental factors on the accuracy of monitoring data are effectively reduced by the wavelet noise reduction combined weights of river health indicators are calculated using the minimum deviation principle a novel multidimensional similarity cloud model is then developed for assessing river health with fuzzy monitoring data the main conclusions are reached as follows 1 the upper reaches of lhasa river are healthy in terms of ecosystem integrity and non ecological performance and the health level exhibits significant spatial variability influenced by urban construction and water conservancy projects with decreasing health level from upper to lower reaches 2 13 of the 25 sampling sites in the lhasa river are excellent or healthy accounting for 52 of the total sampling sites ten monitoring sites five each in the middle and lower reaches are subhealthy accounting for 40 of the total only two sampling sites in the urban section of lhasa river are at unhealthy levels 3 an excellent or healthy level occurs in terms of social services water quantity and quality physical habitat and aquatic life are greatly influenced by reservoir construction in middle reaches and urbanization in lower reaches and river health levels show significant decline 4 compared with conventional cloud models the mscm developed in this study can better identify river health level with fuzzy monitoring data this model provides a more effective approach to accurately evaluate the river health level in the qinghai tibet plateau china credit authorship contribution statement zhengxian zhang investigation methodology software visualization writing original draft writing review editing yun li conceptualization supervision writing review editing xiaogang wang funding acquisition supervision validation hongze li data curation validation feidong zheng data curation validation yipeng liao project administration resources nanbo tang project administration resources guangyu chen data curation supervision chang yang data curation supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by major key technology research on water resources in china sl no y121016 and health assessment of rivers and lakes in tibet autonomous region sl hnsy 54000021210200000202 
3954,seawater intrusion swi is one of the most important phenomena which occurs in shorelines and islands and affects groundwater storage in the region this study aims to investigate how far seawater has intruded in a coastal area and what is its extent variation the results can lead to different management plans to achieve these goals a geoelectrical method is applied in the coastal aquifer of chaouia morocco in order to choose the best inversion process different settings are applied in two different software packages namely res2dinv and bert and the results are compared using the taylor diagram also to determine the minimum and maximum swi extent in the region a new approach of uncertainty analysis is applied in the inversion process by the monte carlo method the general results indicate that the seawater has intruded about 2 km into the shore the obtained results show that by considering uncertainty there is a sensible difference between the maximum and minimum extent of swi maximum 9 variation in the area of swi which should be noted when doing water research management studies the methodology procedure in this study can be applied to different coastal areas around the world keywords electrical resistivity tomography monte carlo uncertainty analysis taylor diagram seawater intrusion chaouia 1 introduction due to population growth and climate change in most parts of the world the need for freshwater has become a severe challenge for governments water resources are in danger of overuse and contamination and management of these resources plays a vital role in the water supply karamouz et al 2016 a significant portion of the water consumption is supplied by groundwater resources in many parts of the world especially in coastal areas and islands where considerable populations live hence it is critical to supply the water need erostate et al 2020 groundwater resources are among the most crucial water supply resources in coastal areas overexploitation of groundwater resources sea level rise due to climate changes extreme conditions such as flooding and droughts lead to seawater intrusion in coastal zones it can pose a serious threat to groundwater quality hence it is essential to estimate the extent of saltwater intrusion to plan appropriate mitigation strategies zeynolabedin and ghiassi 2019 it is necessary to characterize the coastal aquifer and the seawater intrusion to evaluate and mitigate the environmental risks of this phenomenon electrical resistivity tomography ert and time domain electromagnetic tdem are among the essential methods applied to determine the soil categorization and seawater extent in coastal areas satriani et al 2012 carried out geoelectrical surveys to assess seawater intrusion in the metapontum forest reserve in southern italy they used two dimensional 2d ert along the coastline and validated the obtained results by the geochemical method the results revealed the presence of saltwater which has caused desertification problems in the region the results also indicated that a large part of the coastline is affected by seawater intrusion kazakis et al 2016 mapped seawater intrusion in the coastal area of eastern thermaikos gulf greece using ert and hydrochemical data the obtained results showed that up to 150 km2 was influenced by seawater intrusion and the salinization of the aquifer exceeded 1 km toward the mainland with 200 m depth najib et al 2017 identified groundwater salinization origin and determined seawater intrusion extension toward the inland in chaouia morocco they analyzed 46 groundwater samples during january 2012 and used 10 ert profiles the hydrochemical facies evolution diagram hfe d showed the succession of different water facies developed between intrusion and freshening phases they concluded that the seawater intrusion depth varied between 5 and 40 m from the surface salem and osman 2017 mapped the boundaries between freshwater and saltwater by applying geoelectrical resistivity in egypt s northwestern part of the nile delta they used a total of 30 vertical electrical soundings ves and found two zones of groundwater quality in the southern region there was a slightly freshwater zone with resistivity values of 20 90 ω m while the saltwater zone had a low resistivity of 10 ω m in the northwestern parts martínez moreno et al 2017 examined seawater intrusion in ferragudo albufeira aquifer located in the algarve region south of portugal using 1d and quasi 2d joint inversion of tdem and ves data they utilized three different inversion methods single inversion of the ert and tdem data 1d joint inversion and quasi 2d joint inversion they concluded that single inversion could not identify the sedimentary layers detected in exploration drilling while 1d joint inversion improved the results but the quasi 2d joint inversion revealed the best output identifying seawater intrusion and sedimentary layers with higher accuracy ardali et al 2018 applied ert and transient electromagnetic tem measurements along six parallel profiles to investigate if saltwater has intruded into the durusu lake the most significant and most important freshwater source supplying drinking water to the european side of istanbul they inverted tem data with occam marquardt and laterally constrained inversion lci which are 1d inversion methods while the ert data were interpreted using 2d inversion techniques the obtained results showed that saltwater intrusion was minimal and occurred in a particular area where the distance between the lake and sea was very close alabjah et al 2018 determined the extent and the geometric characteristics of the saltwater intrusion extent in the coastal aquifer of chaouia morocco they performed 399 ves and 48 ert profiles perpendicular to the ocean the results of the interpretation of the ves and erts showed that the extension of the saltwater wedge exceeded 2 km toward the land and its depth reached 45 m torres martinez et al 2019 developed a geophysical model to assess seawater intrusion in a coastal aquifer in mexico this model was based on a density dependent flow model with the tem method to simulate groundwater flow and seawater intrusion the results indicated that due to the high rate of pumping for agricultural use in the past decade a large cone of depression had formed leading to the seawater intrusion advancement on the order of 6 8 km inland in the northern central part of the aquifer other researchers tried to investigate seawater intrusion extent using new and revised models hermans et al 2012 carried out ert profiles together with borehole electromagnetic measurements to estimate the extent of saltwater infiltration in the dune area in belgium a comparison with borehole data showed that the inversion results with geostatistical constraints were much more representative of the seawater body in terms of tds extension and height than results using standard smoothness constrained inversion beaujean et al 2014 presented a sequential approach to evaluate the feasibility of identifying hydraulic conductivity and dispersivity in density dependent flow and transport models from surface ert derived mass fraction the geophysical inversion was performed using a smoothness constraint tikhonov approach whereas the hydrological inversion was performed using a gradient based levenberg marquardt algorithm with this approach they explored the capability of sensitivity filtered ert images using ground surface data only to recover in both synthetic cases the hydraulic conductivity de pasquale et al 2019 presented a probabilistic formulation to the geophysical inversion of inferring interfaces in the presence of significant subsurface heterogeneity they implemented an empirical bayes within gibbs formulation they concluded that the proposed algorithm offered distinct advantages compared to manual detection using deterministic geophysical tomograms reviewing the previous studies revealed that most of them concentrated on applying geophysical surveys in seawater intrusion assessment ignoring the uncertainty nature of this method and the difference between different model settings the uncertainty analysis applied in previous studies was mainly applied to numerical models than geophysical models this study covers these limits by a new approach for considering uncertainty analysis focusing on geophysical model data points by applying the probabilistic distribution this new approach can represent the real uncertainty nature and the possible variation in seawater intrusion extent considering the possibility of different resistivity values also two different packages with different model settings are applied to investigate the performance of each setting in the inversion process giving researchers a helpful view 2 study area setting the coastal aquifer of chaouia located in morocco north africa is selected as the case study the oumer rbia river bounds it in the southwest the atlantic ocean in the northwest casablanca city in the northeast and berrechid plain in the southeast it is characterized by the presence of an unconfined aquifer that is used for agricultural activities and population supply the region mainly consists of paleozoic impermeable or semi permeable layer and cenomanian limestone cretaceous permeable layer formations bentayeb 1972 they are covered by plio quaternary deposits that are generally composed of marine sandstones and consolidated dunes therefore the coastal chaouia water table exists in paleozoic cretaceous or plio quaternary aquifers in the northeastern part of coastal chaouia the unconfined aquifer is formed by plio quaternary sandstone limestone and paleozoic weathered schist in the southwest part between azemmour and tnine chtouka the aquifer is formed by cretaceous limestone these aquifers are in lateral hydraulic communication younsi 2001 the aquifer s permeability ranges between 10 6 and 10 4 m s where values greater than 3 10 4 m s correspond to the plio quaternary sandstone and limestone younsi 2001 according to najib 2014 the hydraulic gradient is relatively strong in the northeast 1 6 and low in the southwest 0 3 primarily because of groundwater exploitation and aquifer permeability variation the geological map hydrogeological cross section the location of groundwater wells and ert profiles are shown in fig 1 3 methodology in this research four ert profiles namely 1 2 3 and 4 are carried out to investigate seawater intrusion the data are collected by syscal junior from iris instruments with a roll along technique in which the last cable is moved successively to the front of the profile and connected to the first cable dahlin 1996 a total of 72 electrodes are used with equal distances from each other 5 m the array used in this research is the wenner schlumberger characterized by noise reduction larger signal to noise ratio and good deeper penetration loke et al 2010 the number of data points and the length of each profile is delivered in table 1 the methodology is divided into three main steps 1 inversion method selection 2 ert inversion and 3 uncertainty analysis different settings are compared in the inversion process to evaluate each set s accuracy delivered in the taylor diagram for selecting the best inversion method then the ert profiles are inverted using the selected inversion process by both bert and res2dinv software to determine the seawater intrusion extent also an uncertainty analysis is done by applying the monte carlo method in each data point to investigate seawater intrusion extent variation in order to validate the results groundwater samples cl concentration and ec and borehole data are used which were collected during january 2012 najib et al 2017 3 1 ert the inversion process is done by two different software namely res2dinv and bert res2dinv uses data obtained from electrical imaging surveys to determine a 2d resistivity model for the subsurface loke and barker 1996 it can invert large data sets with a large number of electrodes and handle data sets with a non uniform electrode spacing griffiths and barker 1993 boundless electrical resistivity tomography software which is known as bert is a python based software package for modeling and inverting ert data developed by günther et al 2006 it is programmed as c apps based on the pygimli core library plus bash scripts for the command line and uses python through pygimli and pybert for visualization and computing rücker et al 2017 in order to calculate the true resistivity values finite element forward modeling and an optimization method are used for the inversion process loke and barker 1996 the optimization method is based on reducing the difference between the calculated and measured apparent resistivity values the simplest methods for solving the inversion problem are based on measures of the size or length of the estimated model parameters and of the predicted data for each observation a prediction error or misfit e i d i obs d i pre is defined the ln norm can be applied in the optimization which is based on the sum of some power of the elements of a vector the term norm is used to refer to some measure of length or size and is indicated by a set of double vertical bars e which is the norm of the vector e and is delivered in the following menke 2018 1 ln n o r m e n i e i n 1 n in this study l1 and l2 norms are selected for the inversion process which are more common more details regarding the inversion process can be found in menke 2018 and günther et al 2006 the optimization equation is delivered in the following 2 j t j u f d j t g f f x f x t f z f z t where fx and fz are horizontal and vertical flatness filter j is the matrix of partial derivatives u is the damping factor d is the model perturbation vector and g is discrepancy vector the damping factor and flatness filters can be adjusted to suit different types of data the relative rms error is used to assess the model in predicting the resistivity values which is delivered in the following loke 2001 3 rms e r r o r 1 n i n d i obs d i pre d i obs 2 where d i obs is the observed and d i pre predicted data by the inversion model loke 2001 suggested that the most efficient approach is to choose the model at the iteration after which the rms error does not change significantly in order to determine the best inversion process different methods and models are carried out to evaluate their accuracy according to table 2 eleven different models are considered the categorization is based on both 1 software and 2 different parameter settings applied as for software the categorization is based on bert and res2dinv the res2dinv is a very user friendly and straightforward software that researchers can easily apply for standard arrays it provides limited options for results visualization unlike res2dinv the bert is a free and open source package it can be applied to complicated geometry cases in bert it is possible to use mixed data sets as well as non standard arrays it is joined with paraview an open source multi platform data analysis and visualization application for displaying the results it offers different options for visualization both models have their strengths and weaknesses hence they are both applied in this study to assess their capability to invert ert data as for different settings the categorization is based on smoothing inversion method and mesh type smoothing refers to the model constraint and robust blocky inversion refers to the data constraint an example of a coarse and fine mesh setting is delivered in fig 2 the other parameters which are not mentioned in table 2 are considered constant through different models in the bert setting a smoother surface with a mesh quality of 35 is considered increasing the accuracy of the model near the surface as in the current model the topography is considered the regularization parameter λ is a trade off between data fit and model roughness small values lead to rough models with good data fit whereas large values correspond to smoother models with weak data fit the default value is selected and applied in this study λ 20 tikhonov and arsenin 1977 the methods are compared based on the taylor diagram taylor 2001 taylor diagram provides graphically summarizing how closely a pattern or a set of patterns matches observations the similarity between the two patterns is quantified in terms of their correlation their centered root mean square and standard deviation hence the taylor diagram is used because of its capability to graphically show how the different settings affect the output providing a good visual sense also it shows the main statistics for showing the accuracy of geophysical models in one diagram taylor diagram can represent these three different statistics simultaneously in a 2d space as the following equation relates these statistics 4 e 2 σ f 2 σ r 2 2 σ f σ r r where e is centered root mean square r is the correlation and σ f 2 and σ r 2 are variances of test and reference fields respectively the diagram is especially useful in evaluating multiple aspects of complex models or evaluating the relative accuracy of many different models 3 2 uncertainty analysis procedure a meaningful solution to an inversion problem should be composed of the preferred inversion model and its uncertainty the model uncertainty estimate describes an equivalent model domain in which each model generates responses that fit the observed data within a threshold value the resistivity values obtained from the inversion process could be subject to error and different sources of uncertainties data noise is one of the sources which results in output uncertainty and should be considered and investigated for data interpretation other sources of uncertainty are numerical solution error inversion approach and inversion parameters which result in different outputs ren and kalscheuer 2020 one of the important parts of this study is the determination of the variability of the estimated actual value of resistivity and investigating seawater intrusion extent variation the monte carlo simulation is used in this study for uncertainty analysis the monte carlo simulation is a numerical procedure to reproduce random variables that preserve the specified distributional properties tung and yen 2005 in monte carlo simulation the system s response such as inversion results is repeatedly measured under various system parameter sets generated from the known or assumed probabilistic distributions it offers a practical approach for uncertainty analysis because the random behavior of the system response can be probabilistically duplicated in this study an uncertainty analysis is applied to examine maximum and minimum possible seawater intrusion extent in the profiles in order to apply the monte carlo uncertainty method a matlab code is developed in the following the uncertainty analysis procedure is explained based on profile 1 to make the methodology clear profile 1 has 1900 data points based on the monte carlo method a specific normal distribution is assigned to each data point the normal distribution is shown in the following equation 5 f x μ σ 2 1 2 π σ 2 e x μ 2 2 σ 2 where μ and σ 2 are the mean and variance of input series x by running uncertainty code for the first time each of the 1900 data points will be assigned with a randomly generated resistivity value based on each data point specific normal distribution as a possible resistivity value in that data point these random resistivity values are generated based on μ and σ 2 in the normal distribution in each data point the μ is considered as the observed value which represents that the mean value for randomly generated values also these random values should be generated within a specific range which is determined by σ 2 shown in the following equation 6 σ m i n ρ ρ max a n d ρ ρ min 3 where ρ is the data point observed resistivity value ρ max and ρ min are the maximum and minimum observed resistive values in profile 1 the term min ρ ρ max a n d ρ ρ min indicates that the specific range for generating values is based on the minimum distance of the observed value from the maximum or minimum value in the profile the occurrence possibility of the values near the measured value is much higher hence the equation is divided by three as in the normal distribution more percentage of data lies within three times of standard deviation of the mean olyaei and karamouz 2020 based on normal distribution spreading about 68 of generated data will be near the mean value also the occurrence of higher values is considered but with a lower occurrence probability this approach can represent the real uncertainty nature and the possible variation in seawater intrusion extent also the occurrence possibility of higher values will not be neglected entirely considering all new 1900 made data points there will be a new data set for profile 1 profile 1 1 this procedure will continue 50 times making profile 1 2 1 3 1 50 hence there will be 50 different scenarios for profile 1 meaning that any of these scenarios could have been occurred instead of the initial observed values for resistivity because of uncertainty after inverting 50 different data sets for profile 1 the variation of seawater intrusion extent including the maximum and minimum states can be obtained furthermore it provides an idea of how far seawater can intrude considering the uncertainty of applied methods it should be noted that the number of iterations is case study dependent and cannot be generalized the same procedure is applied to other profiles as well 4 results and discussion 4 1 inversion method selection different model settings table 2 are compared to each other to examine their accuracy based on distance from the reference point the reference point is the standard deviation of observed resistivity values a smaller distance from the reference point indicates that the observation and calculated values are near each other which means higher accuracy the results are delivered in figs 3 to 6 as taylor diagrams in profile 1 fig 3 models 1 and 3 show the best result and are the nearest point to the reference point models 5 and 7 are close to each other meaning that mesh characteristics coarse or fine do not considerably impact output accuracy profile 2 fig 4 shows the same results as profile 1 but model 3 is a bit closer to the reference point uncertainty models have higher rms error and lower correlations profile 3 fig 5 has the highest rms error among other profiles so that the point has a higher distance from the reference point in the taylor diagram figs 4 5 and 6 show that models 1 and 3 have the best results and are the nearest to the reference point however model 3 is a bit closer to the reference point than model 1 which indicates that smoothing in the inversion process can improve the accuracy comparing the results from all the profiles it can be concluded that models 1 res2dinv robust l1 inversion and 6 bert coarse mesh l1 inversion show the best accuracy changing from coarse mesh to fine mesh or using combined inversion marquardt and occam methods does not significantly improve the model s accuracy uncertainty analysis shows higher rms error and lower correlation for all models however between them model 11 bert shows lower rms error and higher correlation resulting in the nearest point to the reference point due to better standard deviation according to the results the robust l1 inversion process is selected as the best method for assessing seawater intrusion extent based on lower rms error it should be noted that having a lower rms error does not always guaranty that the selected method performs the best to validate the inversion process s performance the results are compared with borehole data and groundwater samples in the region 4 2 ert results and discussion after selecting the best inversion method the measured apparent resistivity data are inverted by applying res2dinv and the bert software fig 7 the resistivity values of the seawater intrusion are influenced by several characteristic parameters of the aquifer such as porosity temperature water saturation and the mineralization process archie 1942 the saltwater electrical resistivity value is considered as 0 2 ω m parasnis 2012 however the area where seawater has intruded can vary between 8 and 50 ω m in this research the low resistivity value 15 ω m is considered as an indicator for determining seawater intrusion bauer et al 2006 which is the basis of categorization delivered in fig 7 alongside borehole data the results are verified with groundwater quality data delivered in table 3 profile 1 has 445 m in length with 64 m depth and is located 1 km away from the coastline the inversion results show good accuracy with bert and res2dinv having 2 8 and 5 2 rms error respectively table 4 the results show that seawater has intruded in about 350 m within the profile which is expected as it is located near the shoreline a high resistant section with a resistivity value of about 700 ω m is also observed in the depth of 10 m near the surface within 80 m through the profile representing an unsaturated zone in the profile the results are validated with the nearest observation well well 1 which has a cl ion concentration and ec of 1220 mg l and 4 3 ms cm respectively indicating seawater intrusion also geological borehole data 1388 19 indicates a dry plio quaternary formation sand and alluvium as a resistant level and a cretaceous aquifer marl and limestone as a conductive level encroached by seawater both groundwater samples and borehole data validate the inversion results profile 2 is located at 1200 m from shore and has a 535 m length with a depth of 64 m the inversion process results in 8 6 rms error in res2dinv and 5 rms error in bert table 4 which accounts for acceptable as shown in fig 7 b seawater intrusion occurs between 10 and 20 m in depth through almost whole the profile the surface 0 10 m has high resistivity values indicating more resistant areas in the profile the cl concentration obtained from the nearest well observation well 2 is 2706 7 mg l at about 10 m depth with ec of 8 5 ms cm which validates the inversion results the borehole 3267 19 shows dry plioquaternary formation and cretaceous aquifer affected by seawater which is in line with the inversion results profile 3 extends profile 2 with an 1800 m distance from shoreline 445 m length and 64 m depth res2dinv inversion results in 17 1 rms error while bert shows 16 9 rms error table 4 seawater has intruded within only 100 m through the profile and 10 20 m in depth a resistant formation 200 to 700 ω m appears between the surface and over 25 m depth followed by a conductive section it is validated by the lithological borehole 4104 19 it shows a resistant level corresponds to dry plio quaternary sand and alluvium since profile 3 is the extension of profile 2 it can be concluded that the seawater effect is limited to 2000 m from the ocean according to the samples from the nearest well observation well 3 the cl concentration is 1920 mg l and ec of 6 ms cm at a depth of 25 m profile 4 is carried out at 1100 m from the ocean with a length of 445 m and 50 m depth the inverted ert model presents an rms error of 5 3 and 4 7 from res2dinv and bert models respectively table 4 this profile also shows a resistant formation at the surface where resistivity varies between 300 and 800 ω m followed by a conductive part showing low resistivity borehole 4044 19 shows conductive formations cretaceous aquifer saturated by saltwater and a resistant formation which validates the results at 31 m depth ec and cl concentrations are 4 2 ms cm and 595 5 mg l respectively representing seawater seawater has intruded into the profile to a limited extent at a deep depth the inversion summary is provided in table 4 the results indicate that the bert software takes less iteration to achieve higher accuracy than res2dinv considering the output of the inversion process for all four profiles the results indicated that robust l1 inversion shows the best result hence it is selected for the inversion process this could be due to the strength of the l1 method in sharp boundary situations there is a sharp variation in resistivity value between seawater and freshwater resistivity in the seawater intrusion context on the other hand the l2 method is generally applicable in situations where there is gradual variation in resistivity with a small and specific range of resistivity also using coarse mesh or fine mesh methods does not improve the accuracy of the model significantly usually the meshes around the electrodes and near the surface are finer and the mesh becomes coarser with the depth seawater intrusion generally occurs in depth not surface where the meshes fine and coarse do not vary considerably that could be the reason why mesh sizes do not improve the inversion model results significantly 4 3 uncertainty evaluation and discussion based on different sources of uncertainty data noise numerical error inversion approach inversion parameters etc the initial geoelectrical survey inversion results may not represent the actual status of the region and how far seawater has intruded considering and running uncertainty analysis may give researchers an idea to estimate on the possible length of seawater intrusion profile 1 uncertainty analysis results are shown in fig 8 as can be seen the maximum and minimum states have a considerable difference it shows that the seawater intrusion in its minimum state may have intruded 240 m into the shore while in the maximum state it may have intruded 340 m there is about a 100 m difference in length of intrusion which is significant the results are exported from res2dinv to surfer software to calculate the area affected by seawater intrusion in surfer the area with a low resistivity value 15 ω m is calculated using the volume function as an indicator for determining seawater intrusion bauer et al 2006 according to the surfer output the minimum and maximum seawater intrusion areas are about 6359 and 7994 m2 equal to 35 and 44 percent of the entire profile area it shows that a 1639 m2 difference in the area affected by seawater intrusion can be observed when considering uncertainty analysis in profile 2 fig 9 7850 m2 34 of the profile area is the minimum seawater intrusion extent while the maximum area is 8764 m2 37 of the profile area profiles 3 fig 10 and 4 fig 11 show a more considerable variation in uncertainty analysis the surfer output indicates that seawater intrusion extent varies from 1 to 8 in profile 3 while in profile 4 it varies from 5 to 15 the results are summarized in table 5 and fig 12 as can be seen in figs 8 to 11 the uncertainty results have high rms error values this can be due to the variance value considered for each data point in the normal distribution this variable shows the interval in which random resistivity values are generated however considering higher variance results in a broader interval range for generating values but affects noise level in the model in other words lowering the variance may cause the rms error to reduce but it also makes the random value interval small which does not represent actual uncertainty 5 summary and conclusion this study pursues three objectives 1 which inversion method results in better output 2 how far seawater has intruded and 3 what s the possible seawater intrusion variation extent considering uncertainty to achieve these goals four ert profiles are carried out in the coastal aquifer of chaouia morocco using the wenner schlumberger array with 72 vertical electrodes and a roll a long procedure for the inversion process selection eleven different settings are used with two different software namely res2dinv and bert comparing bert and res2dinv is done to give researchers insight and ideas to assess each model s capabilities in the seawater intrusion context additionally an uncertainty analysis is applied to examine maximum and minimum possible seawater intrusion extent in the profiles by developing a matlab code based on the monte carlo method the results indicate that robust l1 inversion shows the best result hence it is selected for the inversion process the inversion results show that seawater can intrude up to 2 km in the coastal region which can greatly affect groundwater resources in the region also the uncertainty results indicate that seawater intrusion extent can vary up to 9 which should be considered this can help managers in different ways such as optimized localization of observation wells in the groundwater quality monitoring networks and investigating methods of prevention based on the extent of seawater intrusion the methodology proposed in this study is not case study dependent and can be generalized into different coastal areas however the specific results may change in different case studies which should be considered by researchers for further investigation a 3d inversion process can be applied considering the proposed uncertainty analysis approach to have a better understanding of the status of the region credit authorship contribution statement amin zeynolabedin conceptualization methodology software formal analysis data curation writing original draft writing review editing validation visualization reza ghiassi supervision conceptualization methodology software formal analysis data curation writing original draft writing review editing validation visualization reyhaneh norooz formal analysis data curation software writing review editing saliha najib investigation resources writing review editing ahmed fadili investigation resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
3954,seawater intrusion swi is one of the most important phenomena which occurs in shorelines and islands and affects groundwater storage in the region this study aims to investigate how far seawater has intruded in a coastal area and what is its extent variation the results can lead to different management plans to achieve these goals a geoelectrical method is applied in the coastal aquifer of chaouia morocco in order to choose the best inversion process different settings are applied in two different software packages namely res2dinv and bert and the results are compared using the taylor diagram also to determine the minimum and maximum swi extent in the region a new approach of uncertainty analysis is applied in the inversion process by the monte carlo method the general results indicate that the seawater has intruded about 2 km into the shore the obtained results show that by considering uncertainty there is a sensible difference between the maximum and minimum extent of swi maximum 9 variation in the area of swi which should be noted when doing water research management studies the methodology procedure in this study can be applied to different coastal areas around the world keywords electrical resistivity tomography monte carlo uncertainty analysis taylor diagram seawater intrusion chaouia 1 introduction due to population growth and climate change in most parts of the world the need for freshwater has become a severe challenge for governments water resources are in danger of overuse and contamination and management of these resources plays a vital role in the water supply karamouz et al 2016 a significant portion of the water consumption is supplied by groundwater resources in many parts of the world especially in coastal areas and islands where considerable populations live hence it is critical to supply the water need erostate et al 2020 groundwater resources are among the most crucial water supply resources in coastal areas overexploitation of groundwater resources sea level rise due to climate changes extreme conditions such as flooding and droughts lead to seawater intrusion in coastal zones it can pose a serious threat to groundwater quality hence it is essential to estimate the extent of saltwater intrusion to plan appropriate mitigation strategies zeynolabedin and ghiassi 2019 it is necessary to characterize the coastal aquifer and the seawater intrusion to evaluate and mitigate the environmental risks of this phenomenon electrical resistivity tomography ert and time domain electromagnetic tdem are among the essential methods applied to determine the soil categorization and seawater extent in coastal areas satriani et al 2012 carried out geoelectrical surveys to assess seawater intrusion in the metapontum forest reserve in southern italy they used two dimensional 2d ert along the coastline and validated the obtained results by the geochemical method the results revealed the presence of saltwater which has caused desertification problems in the region the results also indicated that a large part of the coastline is affected by seawater intrusion kazakis et al 2016 mapped seawater intrusion in the coastal area of eastern thermaikos gulf greece using ert and hydrochemical data the obtained results showed that up to 150 km2 was influenced by seawater intrusion and the salinization of the aquifer exceeded 1 km toward the mainland with 200 m depth najib et al 2017 identified groundwater salinization origin and determined seawater intrusion extension toward the inland in chaouia morocco they analyzed 46 groundwater samples during january 2012 and used 10 ert profiles the hydrochemical facies evolution diagram hfe d showed the succession of different water facies developed between intrusion and freshening phases they concluded that the seawater intrusion depth varied between 5 and 40 m from the surface salem and osman 2017 mapped the boundaries between freshwater and saltwater by applying geoelectrical resistivity in egypt s northwestern part of the nile delta they used a total of 30 vertical electrical soundings ves and found two zones of groundwater quality in the southern region there was a slightly freshwater zone with resistivity values of 20 90 ω m while the saltwater zone had a low resistivity of 10 ω m in the northwestern parts martínez moreno et al 2017 examined seawater intrusion in ferragudo albufeira aquifer located in the algarve region south of portugal using 1d and quasi 2d joint inversion of tdem and ves data they utilized three different inversion methods single inversion of the ert and tdem data 1d joint inversion and quasi 2d joint inversion they concluded that single inversion could not identify the sedimentary layers detected in exploration drilling while 1d joint inversion improved the results but the quasi 2d joint inversion revealed the best output identifying seawater intrusion and sedimentary layers with higher accuracy ardali et al 2018 applied ert and transient electromagnetic tem measurements along six parallel profiles to investigate if saltwater has intruded into the durusu lake the most significant and most important freshwater source supplying drinking water to the european side of istanbul they inverted tem data with occam marquardt and laterally constrained inversion lci which are 1d inversion methods while the ert data were interpreted using 2d inversion techniques the obtained results showed that saltwater intrusion was minimal and occurred in a particular area where the distance between the lake and sea was very close alabjah et al 2018 determined the extent and the geometric characteristics of the saltwater intrusion extent in the coastal aquifer of chaouia morocco they performed 399 ves and 48 ert profiles perpendicular to the ocean the results of the interpretation of the ves and erts showed that the extension of the saltwater wedge exceeded 2 km toward the land and its depth reached 45 m torres martinez et al 2019 developed a geophysical model to assess seawater intrusion in a coastal aquifer in mexico this model was based on a density dependent flow model with the tem method to simulate groundwater flow and seawater intrusion the results indicated that due to the high rate of pumping for agricultural use in the past decade a large cone of depression had formed leading to the seawater intrusion advancement on the order of 6 8 km inland in the northern central part of the aquifer other researchers tried to investigate seawater intrusion extent using new and revised models hermans et al 2012 carried out ert profiles together with borehole electromagnetic measurements to estimate the extent of saltwater infiltration in the dune area in belgium a comparison with borehole data showed that the inversion results with geostatistical constraints were much more representative of the seawater body in terms of tds extension and height than results using standard smoothness constrained inversion beaujean et al 2014 presented a sequential approach to evaluate the feasibility of identifying hydraulic conductivity and dispersivity in density dependent flow and transport models from surface ert derived mass fraction the geophysical inversion was performed using a smoothness constraint tikhonov approach whereas the hydrological inversion was performed using a gradient based levenberg marquardt algorithm with this approach they explored the capability of sensitivity filtered ert images using ground surface data only to recover in both synthetic cases the hydraulic conductivity de pasquale et al 2019 presented a probabilistic formulation to the geophysical inversion of inferring interfaces in the presence of significant subsurface heterogeneity they implemented an empirical bayes within gibbs formulation they concluded that the proposed algorithm offered distinct advantages compared to manual detection using deterministic geophysical tomograms reviewing the previous studies revealed that most of them concentrated on applying geophysical surveys in seawater intrusion assessment ignoring the uncertainty nature of this method and the difference between different model settings the uncertainty analysis applied in previous studies was mainly applied to numerical models than geophysical models this study covers these limits by a new approach for considering uncertainty analysis focusing on geophysical model data points by applying the probabilistic distribution this new approach can represent the real uncertainty nature and the possible variation in seawater intrusion extent considering the possibility of different resistivity values also two different packages with different model settings are applied to investigate the performance of each setting in the inversion process giving researchers a helpful view 2 study area setting the coastal aquifer of chaouia located in morocco north africa is selected as the case study the oumer rbia river bounds it in the southwest the atlantic ocean in the northwest casablanca city in the northeast and berrechid plain in the southeast it is characterized by the presence of an unconfined aquifer that is used for agricultural activities and population supply the region mainly consists of paleozoic impermeable or semi permeable layer and cenomanian limestone cretaceous permeable layer formations bentayeb 1972 they are covered by plio quaternary deposits that are generally composed of marine sandstones and consolidated dunes therefore the coastal chaouia water table exists in paleozoic cretaceous or plio quaternary aquifers in the northeastern part of coastal chaouia the unconfined aquifer is formed by plio quaternary sandstone limestone and paleozoic weathered schist in the southwest part between azemmour and tnine chtouka the aquifer is formed by cretaceous limestone these aquifers are in lateral hydraulic communication younsi 2001 the aquifer s permeability ranges between 10 6 and 10 4 m s where values greater than 3 10 4 m s correspond to the plio quaternary sandstone and limestone younsi 2001 according to najib 2014 the hydraulic gradient is relatively strong in the northeast 1 6 and low in the southwest 0 3 primarily because of groundwater exploitation and aquifer permeability variation the geological map hydrogeological cross section the location of groundwater wells and ert profiles are shown in fig 1 3 methodology in this research four ert profiles namely 1 2 3 and 4 are carried out to investigate seawater intrusion the data are collected by syscal junior from iris instruments with a roll along technique in which the last cable is moved successively to the front of the profile and connected to the first cable dahlin 1996 a total of 72 electrodes are used with equal distances from each other 5 m the array used in this research is the wenner schlumberger characterized by noise reduction larger signal to noise ratio and good deeper penetration loke et al 2010 the number of data points and the length of each profile is delivered in table 1 the methodology is divided into three main steps 1 inversion method selection 2 ert inversion and 3 uncertainty analysis different settings are compared in the inversion process to evaluate each set s accuracy delivered in the taylor diagram for selecting the best inversion method then the ert profiles are inverted using the selected inversion process by both bert and res2dinv software to determine the seawater intrusion extent also an uncertainty analysis is done by applying the monte carlo method in each data point to investigate seawater intrusion extent variation in order to validate the results groundwater samples cl concentration and ec and borehole data are used which were collected during january 2012 najib et al 2017 3 1 ert the inversion process is done by two different software namely res2dinv and bert res2dinv uses data obtained from electrical imaging surveys to determine a 2d resistivity model for the subsurface loke and barker 1996 it can invert large data sets with a large number of electrodes and handle data sets with a non uniform electrode spacing griffiths and barker 1993 boundless electrical resistivity tomography software which is known as bert is a python based software package for modeling and inverting ert data developed by günther et al 2006 it is programmed as c apps based on the pygimli core library plus bash scripts for the command line and uses python through pygimli and pybert for visualization and computing rücker et al 2017 in order to calculate the true resistivity values finite element forward modeling and an optimization method are used for the inversion process loke and barker 1996 the optimization method is based on reducing the difference between the calculated and measured apparent resistivity values the simplest methods for solving the inversion problem are based on measures of the size or length of the estimated model parameters and of the predicted data for each observation a prediction error or misfit e i d i obs d i pre is defined the ln norm can be applied in the optimization which is based on the sum of some power of the elements of a vector the term norm is used to refer to some measure of length or size and is indicated by a set of double vertical bars e which is the norm of the vector e and is delivered in the following menke 2018 1 ln n o r m e n i e i n 1 n in this study l1 and l2 norms are selected for the inversion process which are more common more details regarding the inversion process can be found in menke 2018 and günther et al 2006 the optimization equation is delivered in the following 2 j t j u f d j t g f f x f x t f z f z t where fx and fz are horizontal and vertical flatness filter j is the matrix of partial derivatives u is the damping factor d is the model perturbation vector and g is discrepancy vector the damping factor and flatness filters can be adjusted to suit different types of data the relative rms error is used to assess the model in predicting the resistivity values which is delivered in the following loke 2001 3 rms e r r o r 1 n i n d i obs d i pre d i obs 2 where d i obs is the observed and d i pre predicted data by the inversion model loke 2001 suggested that the most efficient approach is to choose the model at the iteration after which the rms error does not change significantly in order to determine the best inversion process different methods and models are carried out to evaluate their accuracy according to table 2 eleven different models are considered the categorization is based on both 1 software and 2 different parameter settings applied as for software the categorization is based on bert and res2dinv the res2dinv is a very user friendly and straightforward software that researchers can easily apply for standard arrays it provides limited options for results visualization unlike res2dinv the bert is a free and open source package it can be applied to complicated geometry cases in bert it is possible to use mixed data sets as well as non standard arrays it is joined with paraview an open source multi platform data analysis and visualization application for displaying the results it offers different options for visualization both models have their strengths and weaknesses hence they are both applied in this study to assess their capability to invert ert data as for different settings the categorization is based on smoothing inversion method and mesh type smoothing refers to the model constraint and robust blocky inversion refers to the data constraint an example of a coarse and fine mesh setting is delivered in fig 2 the other parameters which are not mentioned in table 2 are considered constant through different models in the bert setting a smoother surface with a mesh quality of 35 is considered increasing the accuracy of the model near the surface as in the current model the topography is considered the regularization parameter λ is a trade off between data fit and model roughness small values lead to rough models with good data fit whereas large values correspond to smoother models with weak data fit the default value is selected and applied in this study λ 20 tikhonov and arsenin 1977 the methods are compared based on the taylor diagram taylor 2001 taylor diagram provides graphically summarizing how closely a pattern or a set of patterns matches observations the similarity between the two patterns is quantified in terms of their correlation their centered root mean square and standard deviation hence the taylor diagram is used because of its capability to graphically show how the different settings affect the output providing a good visual sense also it shows the main statistics for showing the accuracy of geophysical models in one diagram taylor diagram can represent these three different statistics simultaneously in a 2d space as the following equation relates these statistics 4 e 2 σ f 2 σ r 2 2 σ f σ r r where e is centered root mean square r is the correlation and σ f 2 and σ r 2 are variances of test and reference fields respectively the diagram is especially useful in evaluating multiple aspects of complex models or evaluating the relative accuracy of many different models 3 2 uncertainty analysis procedure a meaningful solution to an inversion problem should be composed of the preferred inversion model and its uncertainty the model uncertainty estimate describes an equivalent model domain in which each model generates responses that fit the observed data within a threshold value the resistivity values obtained from the inversion process could be subject to error and different sources of uncertainties data noise is one of the sources which results in output uncertainty and should be considered and investigated for data interpretation other sources of uncertainty are numerical solution error inversion approach and inversion parameters which result in different outputs ren and kalscheuer 2020 one of the important parts of this study is the determination of the variability of the estimated actual value of resistivity and investigating seawater intrusion extent variation the monte carlo simulation is used in this study for uncertainty analysis the monte carlo simulation is a numerical procedure to reproduce random variables that preserve the specified distributional properties tung and yen 2005 in monte carlo simulation the system s response such as inversion results is repeatedly measured under various system parameter sets generated from the known or assumed probabilistic distributions it offers a practical approach for uncertainty analysis because the random behavior of the system response can be probabilistically duplicated in this study an uncertainty analysis is applied to examine maximum and minimum possible seawater intrusion extent in the profiles in order to apply the monte carlo uncertainty method a matlab code is developed in the following the uncertainty analysis procedure is explained based on profile 1 to make the methodology clear profile 1 has 1900 data points based on the monte carlo method a specific normal distribution is assigned to each data point the normal distribution is shown in the following equation 5 f x μ σ 2 1 2 π σ 2 e x μ 2 2 σ 2 where μ and σ 2 are the mean and variance of input series x by running uncertainty code for the first time each of the 1900 data points will be assigned with a randomly generated resistivity value based on each data point specific normal distribution as a possible resistivity value in that data point these random resistivity values are generated based on μ and σ 2 in the normal distribution in each data point the μ is considered as the observed value which represents that the mean value for randomly generated values also these random values should be generated within a specific range which is determined by σ 2 shown in the following equation 6 σ m i n ρ ρ max a n d ρ ρ min 3 where ρ is the data point observed resistivity value ρ max and ρ min are the maximum and minimum observed resistive values in profile 1 the term min ρ ρ max a n d ρ ρ min indicates that the specific range for generating values is based on the minimum distance of the observed value from the maximum or minimum value in the profile the occurrence possibility of the values near the measured value is much higher hence the equation is divided by three as in the normal distribution more percentage of data lies within three times of standard deviation of the mean olyaei and karamouz 2020 based on normal distribution spreading about 68 of generated data will be near the mean value also the occurrence of higher values is considered but with a lower occurrence probability this approach can represent the real uncertainty nature and the possible variation in seawater intrusion extent also the occurrence possibility of higher values will not be neglected entirely considering all new 1900 made data points there will be a new data set for profile 1 profile 1 1 this procedure will continue 50 times making profile 1 2 1 3 1 50 hence there will be 50 different scenarios for profile 1 meaning that any of these scenarios could have been occurred instead of the initial observed values for resistivity because of uncertainty after inverting 50 different data sets for profile 1 the variation of seawater intrusion extent including the maximum and minimum states can be obtained furthermore it provides an idea of how far seawater can intrude considering the uncertainty of applied methods it should be noted that the number of iterations is case study dependent and cannot be generalized the same procedure is applied to other profiles as well 4 results and discussion 4 1 inversion method selection different model settings table 2 are compared to each other to examine their accuracy based on distance from the reference point the reference point is the standard deviation of observed resistivity values a smaller distance from the reference point indicates that the observation and calculated values are near each other which means higher accuracy the results are delivered in figs 3 to 6 as taylor diagrams in profile 1 fig 3 models 1 and 3 show the best result and are the nearest point to the reference point models 5 and 7 are close to each other meaning that mesh characteristics coarse or fine do not considerably impact output accuracy profile 2 fig 4 shows the same results as profile 1 but model 3 is a bit closer to the reference point uncertainty models have higher rms error and lower correlations profile 3 fig 5 has the highest rms error among other profiles so that the point has a higher distance from the reference point in the taylor diagram figs 4 5 and 6 show that models 1 and 3 have the best results and are the nearest to the reference point however model 3 is a bit closer to the reference point than model 1 which indicates that smoothing in the inversion process can improve the accuracy comparing the results from all the profiles it can be concluded that models 1 res2dinv robust l1 inversion and 6 bert coarse mesh l1 inversion show the best accuracy changing from coarse mesh to fine mesh or using combined inversion marquardt and occam methods does not significantly improve the model s accuracy uncertainty analysis shows higher rms error and lower correlation for all models however between them model 11 bert shows lower rms error and higher correlation resulting in the nearest point to the reference point due to better standard deviation according to the results the robust l1 inversion process is selected as the best method for assessing seawater intrusion extent based on lower rms error it should be noted that having a lower rms error does not always guaranty that the selected method performs the best to validate the inversion process s performance the results are compared with borehole data and groundwater samples in the region 4 2 ert results and discussion after selecting the best inversion method the measured apparent resistivity data are inverted by applying res2dinv and the bert software fig 7 the resistivity values of the seawater intrusion are influenced by several characteristic parameters of the aquifer such as porosity temperature water saturation and the mineralization process archie 1942 the saltwater electrical resistivity value is considered as 0 2 ω m parasnis 2012 however the area where seawater has intruded can vary between 8 and 50 ω m in this research the low resistivity value 15 ω m is considered as an indicator for determining seawater intrusion bauer et al 2006 which is the basis of categorization delivered in fig 7 alongside borehole data the results are verified with groundwater quality data delivered in table 3 profile 1 has 445 m in length with 64 m depth and is located 1 km away from the coastline the inversion results show good accuracy with bert and res2dinv having 2 8 and 5 2 rms error respectively table 4 the results show that seawater has intruded in about 350 m within the profile which is expected as it is located near the shoreline a high resistant section with a resistivity value of about 700 ω m is also observed in the depth of 10 m near the surface within 80 m through the profile representing an unsaturated zone in the profile the results are validated with the nearest observation well well 1 which has a cl ion concentration and ec of 1220 mg l and 4 3 ms cm respectively indicating seawater intrusion also geological borehole data 1388 19 indicates a dry plio quaternary formation sand and alluvium as a resistant level and a cretaceous aquifer marl and limestone as a conductive level encroached by seawater both groundwater samples and borehole data validate the inversion results profile 2 is located at 1200 m from shore and has a 535 m length with a depth of 64 m the inversion process results in 8 6 rms error in res2dinv and 5 rms error in bert table 4 which accounts for acceptable as shown in fig 7 b seawater intrusion occurs between 10 and 20 m in depth through almost whole the profile the surface 0 10 m has high resistivity values indicating more resistant areas in the profile the cl concentration obtained from the nearest well observation well 2 is 2706 7 mg l at about 10 m depth with ec of 8 5 ms cm which validates the inversion results the borehole 3267 19 shows dry plioquaternary formation and cretaceous aquifer affected by seawater which is in line with the inversion results profile 3 extends profile 2 with an 1800 m distance from shoreline 445 m length and 64 m depth res2dinv inversion results in 17 1 rms error while bert shows 16 9 rms error table 4 seawater has intruded within only 100 m through the profile and 10 20 m in depth a resistant formation 200 to 700 ω m appears between the surface and over 25 m depth followed by a conductive section it is validated by the lithological borehole 4104 19 it shows a resistant level corresponds to dry plio quaternary sand and alluvium since profile 3 is the extension of profile 2 it can be concluded that the seawater effect is limited to 2000 m from the ocean according to the samples from the nearest well observation well 3 the cl concentration is 1920 mg l and ec of 6 ms cm at a depth of 25 m profile 4 is carried out at 1100 m from the ocean with a length of 445 m and 50 m depth the inverted ert model presents an rms error of 5 3 and 4 7 from res2dinv and bert models respectively table 4 this profile also shows a resistant formation at the surface where resistivity varies between 300 and 800 ω m followed by a conductive part showing low resistivity borehole 4044 19 shows conductive formations cretaceous aquifer saturated by saltwater and a resistant formation which validates the results at 31 m depth ec and cl concentrations are 4 2 ms cm and 595 5 mg l respectively representing seawater seawater has intruded into the profile to a limited extent at a deep depth the inversion summary is provided in table 4 the results indicate that the bert software takes less iteration to achieve higher accuracy than res2dinv considering the output of the inversion process for all four profiles the results indicated that robust l1 inversion shows the best result hence it is selected for the inversion process this could be due to the strength of the l1 method in sharp boundary situations there is a sharp variation in resistivity value between seawater and freshwater resistivity in the seawater intrusion context on the other hand the l2 method is generally applicable in situations where there is gradual variation in resistivity with a small and specific range of resistivity also using coarse mesh or fine mesh methods does not improve the accuracy of the model significantly usually the meshes around the electrodes and near the surface are finer and the mesh becomes coarser with the depth seawater intrusion generally occurs in depth not surface where the meshes fine and coarse do not vary considerably that could be the reason why mesh sizes do not improve the inversion model results significantly 4 3 uncertainty evaluation and discussion based on different sources of uncertainty data noise numerical error inversion approach inversion parameters etc the initial geoelectrical survey inversion results may not represent the actual status of the region and how far seawater has intruded considering and running uncertainty analysis may give researchers an idea to estimate on the possible length of seawater intrusion profile 1 uncertainty analysis results are shown in fig 8 as can be seen the maximum and minimum states have a considerable difference it shows that the seawater intrusion in its minimum state may have intruded 240 m into the shore while in the maximum state it may have intruded 340 m there is about a 100 m difference in length of intrusion which is significant the results are exported from res2dinv to surfer software to calculate the area affected by seawater intrusion in surfer the area with a low resistivity value 15 ω m is calculated using the volume function as an indicator for determining seawater intrusion bauer et al 2006 according to the surfer output the minimum and maximum seawater intrusion areas are about 6359 and 7994 m2 equal to 35 and 44 percent of the entire profile area it shows that a 1639 m2 difference in the area affected by seawater intrusion can be observed when considering uncertainty analysis in profile 2 fig 9 7850 m2 34 of the profile area is the minimum seawater intrusion extent while the maximum area is 8764 m2 37 of the profile area profiles 3 fig 10 and 4 fig 11 show a more considerable variation in uncertainty analysis the surfer output indicates that seawater intrusion extent varies from 1 to 8 in profile 3 while in profile 4 it varies from 5 to 15 the results are summarized in table 5 and fig 12 as can be seen in figs 8 to 11 the uncertainty results have high rms error values this can be due to the variance value considered for each data point in the normal distribution this variable shows the interval in which random resistivity values are generated however considering higher variance results in a broader interval range for generating values but affects noise level in the model in other words lowering the variance may cause the rms error to reduce but it also makes the random value interval small which does not represent actual uncertainty 5 summary and conclusion this study pursues three objectives 1 which inversion method results in better output 2 how far seawater has intruded and 3 what s the possible seawater intrusion variation extent considering uncertainty to achieve these goals four ert profiles are carried out in the coastal aquifer of chaouia morocco using the wenner schlumberger array with 72 vertical electrodes and a roll a long procedure for the inversion process selection eleven different settings are used with two different software namely res2dinv and bert comparing bert and res2dinv is done to give researchers insight and ideas to assess each model s capabilities in the seawater intrusion context additionally an uncertainty analysis is applied to examine maximum and minimum possible seawater intrusion extent in the profiles by developing a matlab code based on the monte carlo method the results indicate that robust l1 inversion shows the best result hence it is selected for the inversion process the inversion results show that seawater can intrude up to 2 km in the coastal region which can greatly affect groundwater resources in the region also the uncertainty results indicate that seawater intrusion extent can vary up to 9 which should be considered this can help managers in different ways such as optimized localization of observation wells in the groundwater quality monitoring networks and investigating methods of prevention based on the extent of seawater intrusion the methodology proposed in this study is not case study dependent and can be generalized into different coastal areas however the specific results may change in different case studies which should be considered by researchers for further investigation a 3d inversion process can be applied considering the proposed uncertainty analysis approach to have a better understanding of the status of the region credit authorship contribution statement amin zeynolabedin conceptualization methodology software formal analysis data curation writing original draft writing review editing validation visualization reza ghiassi supervision conceptualization methodology software formal analysis data curation writing original draft writing review editing validation visualization reyhaneh norooz formal analysis data curation software writing review editing saliha najib investigation resources writing review editing ahmed fadili investigation resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
