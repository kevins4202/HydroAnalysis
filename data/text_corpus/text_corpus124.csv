index,text
620,fluid transport in nanoporous shale is known to be affected by the nanoscale fluid transport mechanisms surface wettability and heterogeneous pore structure the pores of shale are believed to be dual surface wettability with gas wet organic pores and water wet inorganic pores investigation on the nanoscale multiphase transport behavior in dual surface wettability nanoporous shale has practical implication in understanding inject water distribution during injected water flow in and flow back process in this study we propose a nanoscale gas and water multiphase pore network transport model to study nanoscale confined gas and water transport behavior in dual wettability nanoporous shale a 3 d shale pore network model is constructed from 3 d image that is reconstructed from 2 d shale sem image of organic rich sample water transport considers the boundary slip length determined by the contact angle bulk gas transport in inorganic pores considers slip effect while bulk gas transport and surface diffusion for adsorbed gas are both considered in organic pores injected water flow in process is modeled by water displacing gas process while injected water flow back process is modeled by gas displacing water process gas and water relative permeabilities during injected water flow in and flow back process at different toc volumes and inorganic pore contact angle are analyzed in detail and are compared with relative permeabilities without nanoscale transport mechanisms study results reveal that nanoscale gas and water relative permeabilities are influenced by the total organic carbon toc in volumes and inorganic pore water contact angle while nanoscale transport mechanisms influence on the relative permeabilities can be neglected keywords nanoscale confined phenomena multiphase transport pore network model nanoporous shale dual surface wettability 1 introduction the complexities of nanoporous shale are expressed in terms of heterogeneous pore structure and various pore types guo et al 2018 kelly et al 2016 song et al 2019 tahmasebi et al 2016 the pore types in shale are generally categorised into three types interparticle mineral pores intraparticle mineral pores and intraparticle organic matter pores loucks et al 2012 intraparticle organic matter pores are referred to as organic pores and the other two types of pores are referred to as inorganic pores the inorganic pores are generally suggested to be water wet while the organic pores formed during hydrocarbon accumulation and generation processes are deem as hydrophobic odusina et al 2011 a significant amount of adsorbed gas molecules are distributed in the organic pore with large specific surface area clarkson et al 2013 therefore adsorbed gas and bulk gas coexist in organic pores as the inorganic matter tends to be water wet it is generally believed only bulk gas exists in the inorganic pore the bulk gas transport deviates from viscous flow javadpour 2009 landry et al 2016 song et al 2016 because of the nanoscale pore size and the flow regime is conventionally subdivided according to the knudsen number which is defined as the ratio of molecular mean free path to the pore radius in addition the adsorbed gas transport on the pore wall in the forms of surface diffusion to enhance the gas transport ability choi et al 2001 large amounts of water is injected into the shale formation during hydraulic fracturing process gallegos et al 2015 osiptsov 2017 reagan et al 2015 zeng et al 2019 however the majority of the injected water does not return to the surface during the flow back period more and more attention is paid to the inject water distribution after hydraulic fracturing birdsell et al 2015a hu et al 2015 wang et al 2016 numerous studies barrat and bocquet 1999 belyaev and vinogradova 2010 javadpour et al 2015 jin et al 2016 lauga and stone 2003 neto et al 2005 sun et al 2019 vinogradova 1999 suggest that non slip flow boundary condition for water is not valid in shale nanopores holt et al 2006 and majumder et al 2005 showed that the flow rates for water flow through membranes of carbon nanotubes cnts with diameters of 1 3 7 0 nm are two to five orders of magnitude larger than those calculated by the no slip hagen poiseuille equation the flow rate of water through 44 nm carbon nanopipes measured by whitby et al 2008 is an order of magnitude larger than the no slip hagen poiseuille equation multiphase transport behavior in dual surface wettability nanoporous shale has been investigated by both physical experiments and theoretical methods including analytical solutions and numerical models bennion and bachu 2007 measured relative permeabilities of devonian and cretaceous shales at reservoir conditions by conducting brine and co2 drainage and imbibition tests dacy 2010 estimated relative permeability curves for sub microdarcy shales by combining up to seven or more separate core measurements jung 2015 established a workflow of bakken shale relative permeability measurement method using nuclear magnetic resonance nmr spectroscopy to measure fluid saturations and a relative permeability measurements under a confining pressure rpc set up to conduct the displacement suhrer et al 2013 calculated oil water relative permeability during imbibition process in shale formation by lattice boltzmann method daigle et al 2015 considered the influences of pore structure on unsaturated advection and diffusion based on the critical path analysis and percolation theory to model shale relative permeability based on daigle et al 2015 model ojha et al 2017 proposed a method to estimate relative permeability in shale by processing the low pressure nitrogen adsorption desorption isotherm measurements yassin et al 2016 extended purcell 1949 to develop a conceptual model for relative permeability of gas and water in a dual wettability system mohammadmoradi and kantzas 2018 developed a semi analytical formulation of the spontaneous capillary imbibition and predicted relative permeabilities based on the general adjustable relationships proposed by luckner et al 1989 modeling multiphase flow in mixed wet subsurface porous media has benefited from the development of pore network work modeling approach ali et al 2015 khaksar et al 2013 sahimi 2011 mcdougall and sorbie 1997 1995 studied relative permeability with a regular cubic network by assigning different wettabilities to different pores in the network blunt 1997 established a pore network model to study wettability effect considering different pore level displacement processes oren et al 1997 predicted transport properties of a mixed wet reservoir rock using a pore network obtained from reconstructed pore space since then numerous quasi static pore network models have been extensively applied to study mixed wettability in order to match with experimental results al futaisi and patzek 2004 høiland et al 2007 jackson et al 2003 kallel et al 2017 valvatne and blunt 2004 zhao et al 2010 as well as three phase flow process al dhahli et al 2013 hui and blunt 2000 piri and blunt 2005a 2005b van dijke et al 2007 on the other hand the dynamic pore network models were developed to consider both capillary force and viscous force joekar niasar and hassanizadeh 2012 li et al 2017 wang et al 2015 hammond and unsal 2012 proposed a dynamic pore network model for oil displacement in an initially mixed wet medium by wettability altering surfactant solution aghaei and piri 2015 developed a dynamic pore network model considering viscous capillary and gravity forces as well as mixed wettability obtained from micro ct images huang et al 2016 studied gas and water relative permeability during imbibition process based on the conceptual shale dynamic pore network model to the best knowledge of the authors most of the current pore network modeling studies under mixed wet conditions focus on conventional rocks or conceptual pore network models the comprehensive nanoconfinement effects of both gas and water phases gas adsorption pore types organic pore inorganic pore real gas property have not been considered in an existing pore network model to model multiphase flow behavior in a mixed wet shale rocks at typical reservoir conditions furthermore the current theoretical shale relative permeability models have not considered the heterogeneous pore structure fluid transport mechanisms dual surface wettability and pore type altogether the purpose of this study is to propose a nanoscale gas and water pore network transport model to study nano confined gas and water multiphase transport behavior in dual surface wettability nanoporous shale we first propose a workflow to construct a shale pore network model to model both organic pores and inorganic pores and accurately consider different wettability in these two different pore types next we further consider nanoconfinement effects and pore surface physicochemical property influence on fluid flow compared with previous quasi static pore network model multiple fluid transport mechanisms related with pore type gas adsorption critical property change with pore size and real gas equation of state are modeled more specifically water transport considers the boundary slip length determined by the contact angle bulk gas transport in inorganic pores considers slip effect while bulk gas transport and surface diffusion for adsorbed gas are both considered in organic pores gas and water relative permeabilities during injected water flow in and flow back process are analyzed in detail this paper is organized as follows in section 2 nanoscale gas and water pore network transport model is established in section 3 detailed results and discussions are demonstrated this is followed by a section of conclusion 2 nanoscale gas and water pore network transport model 2 1 construction of dual pore type shale pore network model although 3d imaging of shale rock can accurately describe the nanopore characteristics the imaging process is costly and time consuming tahmasebi et al 2016 wang et al 2017b zhou et al 2016 in this work three binary high resolution sem images in fig 1 obtained from the shale sample are applied to reconstruct the 3 d shale digital core by representing three mutually perpendicular planes according to markov chain monte carlo mcmc method chen et al 2015 okabe and blunt 2007 wu et al 2007 2006 2004 yang et al 2015 zhang et al 2015 each binary sem image has the pixel size of 400 400 pixels and the pixel size of the sem image taken is 27 62 nm 27 62 nm the constructed 3 d shale digital core in fig 2 contains 400 400 400 voxels at a voxel size of about 27 62 nm the physical size of the constructed 3 d shale digital core is 11 048 μm 11 048 μm 11 048 μm the porosity of the constructed 3 d shale digital core is about 0 13 the dual pore type shale pore network model in fig 3 is constructed as follows first the pore network model is extracted from 3 d shale digital core by the maximal ball fitting method blunt et al 2013 dong and blunt 2009 the shapes of the pore bodies and pore throats used in our study for individual network elements include circle pore square pore and irregular triangle pore characterized by the shape factor g mason and morrow 1991 concrete pores and throats identification method can be found in the supporting information then the total pore space volume and the volume of each pore and throat on the pore network are calculated next the total organic pore and throat volume is given according to the total organic carbon toc in volume in this study the toc in volume value is given as 5 as the organic pore size is generally smaller than the inorganic pore size naraghi and javadpour 2015 the organic pores and throats are labelled starting from the smallest size of pore and throat until the given total organic pore and throat volume is matched the remaining parts on the pore network are deemed as the inorganic pores and throats organic and inorganic pore type size distributions are shown in figs 4 and 5 respectively since the organic throats does not necessarily connect organic pores and can connect inorganic pores therefore the organic throat size sometimes can be larger than the organic pore size the coordination number distribution is shown in fig 6 2 2 gas and water distribution in a single nano capillary under two phase transport condition previous experimental studies reveal that the water advancing contact angle in shale notably increases with the increase of pressure and can reach around 90 at high pressure arif 2017 iglauer et al 2015 pan et al 2018 therefore we assume that the water advancing contact angle is large enough and only piston like advance occurs during injected water imbibition process the wetting water transports in the inorganic pore corner while gas transports in the pore center during injected water flow back process molecular simulation results lee et al 2016 li et al 2019 indicate that for organic carbon material with hydrophobic pore surface adsorbed gas molecules occupy pore surface and water molecules locate at the center of the pore therefore we assumes that once injected water flows into the organic pore under certain pressure drop the bulk gas is displaced and water transports in the center of the pore while adsorbed gas transports at the boundary of pore in the forms of surface diffusion the water in the organic pore center can be displaced by gas during the injected water flow back process illustrations of gas and water distribution in a single nano capillary during injected water flow in and flow back process are shown in figs 7 and 8 respectively consider the cross section of a polygonal shaped inorganic pore the gas and water distribution in one corner is shown in fig 9 the interface lengths can be determined from elementary geometry valvatne and blunt 2004 1 a e f f a r 2 i 1 n cos θ r cos θ r β i sin β i θ r β i π 2 2 a c b sin β cos θ r β 2 cos θ r cos θ r β sin β θ r β π 2 r 2 s 1 3 b r cos θ r β sin β 4 r σ p c 5 d s 1 2 i 1 n cos θ r β sin β cos θ r s 3 6 l g w 2 r i 1 n π 2 θ r β r s 3 7 g c a c 4 b 2 1 sin β cos θ r β θ r β π 2 2 8 g sin β cos β 4 1 sin β 2 9 c v a l 0 364 0 28 g g c where β is the corner half angle θr is the contact angle n is the total number of corners containing arc menisci β π 2 θr g is shape factor of the pore cross section dimensionless a r2 4g is the total pore cross section area aeff is the pore area occupied by gas ac is the corner area for a single corner b is the water solid interface length of water in the corner r is the radius of curvature of the interface lgs is the gas soild interface length of gas in the pore center lgw is the length of the gas water interface gc is the shape factor for the corner section containing the fluid g is the shape factor without any curvature on the fluid interface for polygonal shaped elements the capillary entry pressure expressions are found by calculating the force balance acting on the interface in the duct this method has become known as the mayer stowe and princen ms p method mason and morrow 1991 and we follow oren et al s 1998 generalization of it given by 10 p c σ cos θ r 1 2 π g r f d θ r g β where fd is a dimensionless correction factor for wetting fluid that might be retained in the corners 11 f d θ r g β 1 1 4 g d cos 2 θ r 1 2 π g in the case of a circular tube where there are no corners fd will be 1 and eq 10 will be reduced to 12 p c 2 σ cos θ r r as we assume the injected water completely fills the inorganic pore and there is no contact angle hysteresis the threshold capillary pressure is the same as eq 12 during the injected water flow in process based on experiment and molecular simulation data the water surface tension σ0 change versus temperature t can be given as vega and de miguel 2007 13 σ 0 227 86 1 t t c w a t e r 11 9 1 0 6413 1 t t c w a t e r 10 3 where tc water is the critical temperature for water 641 4 k the dependence of surface tension σ on water curvature radius rc is given in eqs 14 and 15 lu and jiang 2005 and curvature radius rc is related with effective radius reff water by eq 16 kloubek 1981 14 σ σ 0 1 1 4 r c h 1 exp 2 s b 3 r 1 4 r c h 1 15 s b e 0 t b 16 r c r e f f w a t e r cos θ r where h is oh bond length 0 096 nm r is the ideal gas constant 8 314 j k mol sb is solid vapor transition entropy of water e0 is the bulk solid vapor transition enthalpy j mol tb is bulk solid vapor transition temperature of water k reff water denotes reff or in organic pores and r in inorganic pores 2 3 gas and water transport through a single nano capillary under single phase condition langmuir monolayer adsorption model langmuir 1918 is suggested to be able to model shale gas adsorption behaviors at the typical shale gas reservoir condition heller and zoback 2014 the gas coverage of adsorbed gas in organic pore can be expressed as 17 θ p z p l p z adsorbed gas molecules on the pore surface reduce the organic pore space available for the remaining gas molecules to transport the effective pore radius for bulk gas transport in organic pore can be expressed as song et al 2017 wu et al 2016a 18 r e f f o r r d m θ the mean free path of molecules for a real gas can be expressed as michel villazon et al 2011 19 λ π z r g t 2 m μ p the knudsen number in organic and inorganic pores can be written as 20 k n λ r e f f reff refers to the radius of an inorganic pore r and the effective radius of an organic pore reff or in this work a unified hagen poiseuille type equation developed by beskok and karniadakis 1999 is used for modeling bulk gas transport for a capillary with a circular cross section the volumetric gas flux q through a single nano capillary is given as follows 21 q f k n π r e f f 4 8 μ δ p l where the flow condition function f kn is given by 22 f k n 1 α k n 1 4 k n 1 β k n the parameter α in eq 22 is a dimensionless rarefaction coefficient which can be written as 23 α 128 15 π 2 tan 1 4 0 k n 0 4 though the slip coefficient β 1 was initially considered only applicable to a slip flow condition evidence from the dsmc simulations and boltzmann solutions karniadakis et al 2006 showed that β 1 is valid within in the full range of flow regimes according to eq 21 bulk gas transport conductance can be written as 24 g f r e e π r e f f 4 f k n 8 μ l surface diffusion of adsorbed gas molecules has long been considered as one of the key transport mechanisms in organic pores because of the large amount of adsorbed gas in organic shales it can be modelled as a the general diffusion process using the molar flow rate per unit area of the concentration gradient within the adsorbed monolayer as developed in cunningham and williams 1980 25 j a d s d c a d x ca is calculated assuming langmuir adsorption and is given by 26 c a c a max θ the maximum adsorbed gas concentration camax inside the organic pore space can be given based on the measured maximum adsorbed gas concentration cmax and toc in volume 27 c a max c max t o c v o l combining eqs 25 27 molar flow rate in the adsorbed layer is then expressed below 28 j a d s c a max d θ d p π r 2 r e f f o r 2 d p d x from eq 28 volumetric flux is 29 v a m ρ d s c a max d θ d p π r 2 r e f f o r 2 d p d x according to gas adsorption experimental data and molecular simulation data song et al 2018 the surface diffusion coefficient at zero gas coverage can be expressed in eqs 30 based on guo et al 2008 hwang and kammermeyer 1966 30 d s 0 3 1321 10 7 t 0 5 exp δ h 0 8 r t in order to consider the influence of gas coverage on surface diffusion needs to be considered chen and yang 1991 used the kinetic method to calculate the surface diffusion coefficient 31 d s d s 0 1 θ κ 2 θ 2 θ h 1 κ 1 κ κ 2 θ 2 1 θ κ 2 θ 2 32 h 1 κ 0 κ 1 1 0 κ 1 33 κ κ b κ m where κb is the rate constant for blockage and κm is the rate constant for forward migration when κm κ b surface diffusion occurs when κm κ b gas molecules are blocked and surface diffusion stops according to eq 29 adsorbed gas transport conductance can be written as 34 g s u r f a c e 1 l m ρ d s c a max d θ d p π r 2 r e f f o r 2 according to eqs 24 and 34 gas transport conductance in organic pore and inorganic pore can be given respectively as 35 g o r π r e f f o r 4 8 μ l 1 128 15 π 2 tan 1 4 0 k n 0 4 k n 1 4 k n 1 k n 1 l m ρ d s c a max d θ d p π r 2 r e f f o r 2 36 g i n π r 4 8 μ l 1 128 15 π 2 tan 1 4 0 k n 0 4 k n 1 4 k n 1 k n the constant water viscosity as a function of temperature t is given in eq 37 and viscosity of water μ t can be predicted with accuracy to within 2 5 from 273 k to 643 k al shemmeri 2012 37 μ t 2 414 10 5 10 247 8 t 140 wu et al 2017 derived a scaling function for the slip length based on the published md simulation data shown in eq 38 and the confined water flux qwater for circle pore is given in eq 39 38 l s t 0 41 cos θ w 1 2 39 q w a t e r π 8 μ r r 4 4 r 3 l s t d p d x where lst is the water slip length in nanometer unit eq 39 can be reorganized as 40 q w a t e r s f π r 4 8 μ r d p d x where the slip factor is defined as 41 s f 1 4 l s t r according to eq 40 water transport conductance can be given as 42 g w s f π r 4 8 μ r l 2 4 gas and water transport through a single nano capillary under two phase condition for water transport in a single corner we first define the constants c2 c3 to simplify the later derivation 43 c 2 cos θ r β sin β 44 c 3 π 2 θ r β the perimeter of single corner occupied by water is 45 p c o r 2 r c 2 2 r c 3 the equivalent radius for water transport in the corner is defined as 46 r c o r 2 a c p c o r r s 1 c 2 c 3 according to eq 41 the slip factor for water flow in the corner can be defined as 47 s f c 1 4 l s t r c o r 1 c 4 r where c4 is defined as 48 c 4 4 c 2 c 3 l s t s 1 the relationship between corner flow flux and pressure drop for no slip hagen poiseuille condition is given in eq 49 the performance of this correlation was tested using a 2 d finite element code for incompressible laminar flow for a variety of corner configurations it was found to predict the conductance well within a 10 error margin valvatne and blunt 2004 49 q w c n s c v a l a c 2 g c μ d p d x considering the slip factor the corner flow flux for a given pressure drop δp can be written as 50 q w c s s f c c v a l a c 2 g c μ δ p l according to eq 50 water transport conductance in the single pore corner can be given as 51 g w c s s f c c v a l a c 2 g c μ l for gas flow in the center we continue to use eqs 35 and 36 but multiply it by the fraction of the cross section area occupied by the gas phase according to eq 1 2 5 nanoscale gas and water quasi static pore network transport model the constructed dual pore type pore network is initially saturated with gas and all possible displacement events are sorted in terms of capillary entry pressure with the event with the highest capillary pressure executed first the feasibility of quasi static pore network model to model injected water flow in process in nanoporous shale is explained in the supporting information based on the capillary number concept and previous studies birdsell et al 2015b cheng 2010 the injected water first flows into the inorganic pores with positive capillary pressure and fills in the order of increasing radius with the narrowest filling first patzek 2001 in the next displacement stage the injected water starts to flows into the organic pores with negative capillary pressure under the drainage pressure and displaces bulk gas in the order of decreasing radius with the largest organic pore first during the injected water flow back process the injected water in the organic pore is first displaced by gas with positive capillary pressure in the order of increasing radius then the injected water in the inorganic pore is displaced by gas with negative capillary pressure in the order of decreasing radius under the drainage pressure the hydraulic radius can be expressed as eq 52 as done in ma et al 2014 oren et al 1998 and valvatne and blunt 2004 detailed model parameters are given in table 1 the water saturation is calculated by the total water volume in the pores and throats divided by the total pore and throat volume on the pore network visualization of gas and water distribution on the shale pore network during injected water flow in and flow back process is shown in fig 10 the flowchart of the modeling process is given in the supporting information 52 r 2 a p d 2 a g where pd is the perimeter of the pore cross section because of the existence of water slip and gas rarefied effect in nanopores the absolute permeability kabs water value calculated by water is different from the absolute permeability kabs gas value calculated by gas therefore unlike the traditional pore network models the absolute permeability should be calculated for each phase to obtain the reasonable value of relative permeability the water phase absolute permeability is obtained by eq 53 because the viscosity is variable across pores and throats and pressure dependent gas phase absolute permeability is calculated using a different way to that which would be normally done see oren et al 1998 by eq 53 that is the product of gas flux and viscosity is calculated for every inlet pore voxel to compute the sum of the total flux at the inlet face and gas phase absolute permeability by eq 54 53 k a b s w a t e r μ l p n m i 1 n i n l e t q i n l e t a p n m δ p 54 k a b s g a s i 1 n i n l e t q i n l e t μ i n l e t l p n m a p n m δ p where qinlet is gas flux in inlet pores ninlet is the number of the inlet pores lpnm is the length of the 3d model apnm is area of the 3d model cross section μinlet is the gas viscosity in inlet pores p is the pressure drop on the 3d model the relative permeability is then given by 55 k r w a t e r q t m p w a t e r q t s p w a t e r 56 k r g a s q t m p g a s q t s p g a s qtmp is the total flux of phase p in multiphase conditions with the same imposed pressure drop the total flux is found by solving for the pressure everywhere imposing mass conservation at every pore i the mass balance equations for gas phase are non linear functions of gas pressures due to pressure dependent conductance and viscosity and they must be solved iteratively taking an initial pressure distribution as that for the darcy flow the system of equations is solved iteratively in a similar fashion as in ma et al 2014 until the volumetric flux converges 57 j 1 n i q i j 0 where j runs over all the throats connected to pore i the flow rate qij between two pores i and j is given by 58 q i j g i j p i p j the conductance between two pore bodies gij is taken to be the harmonic mean of each individual conductance as similar done in valvatne 2004 59 1 g i j 1 g i 1 g t 1 g j where li lj lt are the length of pore i and pore j and the throat that connects pore i and pore j respectively gi gj gt are the gas transport conductance of pore i and pore j and the throat that connect pore i and pore j respectively 3 results and discussions fig 11 a shows calculated gas and water relative permeability during injected water flow in process the gas phase relative permeability first declines fast and then gradually decreases with the increase of water saturation when the water saturation is larger than 0 4 the water phase relative permeability gradually increases and then increases more rapidly when the water saturation is larger than 0 6 the corresponding water saturation for the relative permeability crosspoint during injected water flow back process is less than 0 5 this can be attributed to the fact that the gas wet organic pores makes the pore network show mixed wet characteristic the gas phase relative permeability increases rapidly and water phase relative permeability declines rapidly with the increase of gas saturation during injected water flow back process in fig 11 b fig 12 shows gas and water relative permeability at different toc in volumes the increase of toc in volumes makes the pore network tend to be more gas wet and the corresponding water saturation for the relative permeability crosspoint shifts to the smaller value around 0 5 fig 13 shows gas and water relative permeability during injected water flow back process at different inorganic pore water contact angle and uniform wettability condition the corresponding water saturation for the water wet displacement relative permeability crosspoint is generally larger than 0 5 while the increase of water contact angle makes the pore network tend to be less water wet and the corresponding water saturation for the relative permeability crosspoint shifts to the smaller value close to 0 5 this indicate that gas and water relative permeability in nanoporous shale is mutually influenced by the toc in volumes and water contact angle it is also can be seen that there is notable difference between the uniform wettability relative permeability curve and dual wettability relative permeability curve the corresponding water saturation for the uniform wettability relative permeability crosspoint is larger than that for the dual wettability relative permeability crosspoint because of the strong water wet pore network under the uniform wettability condition in this work we deem that water can enter the organic pores as a nonwetting phase because the injected water driving force during hydraulic fracturing process should overcome the capillary pressure inside organic pores however there are different views on whether water can enter the organic pores therefore we calculated the gas water relative permeabilities when water does not invade into the organic pores and compared with those when water invades into the organic pores in fig 14 the endpoint water saturation for gas and water relative permeability during injected water flow in process decreases and the gas water relative permeabilities during injected water flow in process coincide with each other before the water saturation reaching the endpoint in fig 14 a this is because the injected water first invades the inorganic pores and there is difference only when water enters the organic pores at the final displacement stage if we assume water does not invade into the organic pores during the injected water flow in process the gas will first invade the inorganic pores in the order of decreasing radius and the gas inside the organic pores will connect with the invaded gas at certain drainage stage during injected water flow back process the gas water relative permeabilities consequently show notable difference during injected water flow back process in fig 14 b we further model the gas and water transport in the forms in the darcy flow and calculate the relative permeability during flow in and flow back process it s can be seen in fig 15 that nanoscale transport mechanisms influence on the relative permeability can be neglected this can be attributed to the two aspects first relative permeability curve is mostly controlled by the sample wettability and pore structure second the relative permeability is defined by the effective phase permeability divided by the absolute permeability under single phase condition and is a dimensionless form however the effective permeability at different saturation is different from that based on the darcy flow and can be larger than that based on the darcy flow this is because the nanoconfinement effects can increase the absolute permeability and the calculated absolute permeability is larger than the intrinsic permeability as discussed in our previous study song et al 2017 fig 16 a shows capillary pressure versus gas saturation during injected water flow back process the capillary pressure first increases rapidly with the increase of gas saturation and then becomes flat when the gas saturation is larger than 0 7 the capillary pressure starts to gradually increase with the increase of gas saturation at typical shale gas reservoir production condition the pressure difference between gas phase and water phase causes the injected water flow back and the pressure difference value is larger in the near wellbore than that away from the wellbore region however given the large capillary pressure 1 mpa shown in fig 16 a the pressure difference is not always larger than the capillary pressure especially in the region far away from the wellbore and large amounts of injected water is retained as a consequence this indicates that gas and water relative permeability during injected water flow back process shall be used at a certain range of gas saturation because the irreducible water saturation corresponds to the condition that the pressure difference between gas phase and water phase can overcome the largest capillary pressure generated by the interface between water phase and gas phase in the smallest inorganic pores at the final displacement stage fig 16 b shows the irreducible water saturation versus inorganic pore water contact angle during injected water flow back process the decrease of inorganic pore water contact angle causes more and more water resides in the inorganic pore corner and the irreducible water saturation increases consequently this means that the injected water retention volume also increases with the decrease of inorganic pore water contact angle 4 conclusion in this work we studied the nanoscale confined gas and water transport behavior in dual surface wettability nanoporous shale based on the proposed nanoscale multiphase pore network transport model water transport considers the boundary slip length determined by the contact angle bulk gas transport in inorganic pores considers slip effect while bulk gas transport and surface diffusion for adsorbed gas are both considered in organic pores the gas water distribution in a single nano capillary is determined by the mayer stowe and princen ms p method the results indicate that gas and water relative permeability in nanoporous shale is both influenced by the toc in volumes and inorganic pore water contact angle the larger value of toc in volumes and inorganic pore water contact angle can cause the corresponding water saturation for the relative permeability crosspoint shifts to the smaller value less than 0 5 while nanoscale transport mechanisms only influence effective peremeability and its influence on the relative permeabilities can be neglected furthermore the injected water retention volume is influenced by the capillary pressure and inorganic pore water contact angle our study reveals that accurate modeling nanoscale gas and water transport behavior must consider the significant different surface wettability in the dual organic inorganic nanoporous shale pore system the limitation of current study is that we assume piston displacement during injected water flow in process according to water advancing contact angle measurement results in literature in the future work we will consider to obtain an advancing contact angle from studied shale sample at reservoir pressure condition and determine piston like displacement or wetting film flow in each irregular pore and throat on the shale pore network in addition we deem that the injected water can enter the organic pores and there are different views on whether water can enter the organic pores as we have mentioned to deal with this the fractured shale core sample will be imaged using high resolution focused ion beam milling combined with scanning electron microscopy fib sem to detect whether there is injected water distribution inside the organic matter in the future study declarations of interest none acknowledgments the authors gratefully acknowledge two anonymous referees for their constructive comments this project was supported by the major projects of the national science and technology 2016zx05061 fundamental research funds for the central universities 18cx06007a 18cx06008a 17cx05003 16cx05018a national natural science foundation of china no 51504276 no 51490654 shandong provincial natural science foundation china no zr2014eep018 applied basic research projects of qingdao innovation plan 16 5 1 38 jch the data used are listed in the figures and tables in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 06 012 appendix b supplementary materials image application 1 appendix a real gas property considering nanoscale confined effect in this work islam s equations given in islam et al 2015 are applied to describe the relationship between critical property and nanopore size in eqs 60 and 61 60 t c 8 27 b r a 2 γ 3 ε n 2 γ r 2 6275 0 6743 γ r 61 p c 8 27 b 2 a 2 γ 3 ε n 2 γ r 2 6275 0 6743 γ r where a is the vdw energy parameter b is the vdw energy parameter γ is the lennard jones size parameter ε is the lennard jones energy parameter gas compressibility factor z eq 64 is calculated according to mahmoud 2014 which is valid over a wide pressure range 62 p p r p p c 63 t p r t t c 64 z 0 702 e 2 5 t p r p p r 2 5 524 e 2 5 t p r p p r 0 044 t p r 2 0 164 t p r 1 15 lee et al 1966 developed an empirical gas viscosity model for natural gases that has been adopted for the confined pores bui et al 2016 kim et al 2016 landry et al 2016 wang et al 2017a to determine gas viscosity and density as follows 65 k 9 379 0 01607 m t 1 5 209 2 19 26 m t 66 x 3 448 986 4 t 0 01009 m 67 y 2 447 0 2224 x 68 μ 1 10 4 k exp x ρ y 69 ρ 1 4935 10 3 p m z t 
620,fluid transport in nanoporous shale is known to be affected by the nanoscale fluid transport mechanisms surface wettability and heterogeneous pore structure the pores of shale are believed to be dual surface wettability with gas wet organic pores and water wet inorganic pores investigation on the nanoscale multiphase transport behavior in dual surface wettability nanoporous shale has practical implication in understanding inject water distribution during injected water flow in and flow back process in this study we propose a nanoscale gas and water multiphase pore network transport model to study nanoscale confined gas and water transport behavior in dual wettability nanoporous shale a 3 d shale pore network model is constructed from 3 d image that is reconstructed from 2 d shale sem image of organic rich sample water transport considers the boundary slip length determined by the contact angle bulk gas transport in inorganic pores considers slip effect while bulk gas transport and surface diffusion for adsorbed gas are both considered in organic pores injected water flow in process is modeled by water displacing gas process while injected water flow back process is modeled by gas displacing water process gas and water relative permeabilities during injected water flow in and flow back process at different toc volumes and inorganic pore contact angle are analyzed in detail and are compared with relative permeabilities without nanoscale transport mechanisms study results reveal that nanoscale gas and water relative permeabilities are influenced by the total organic carbon toc in volumes and inorganic pore water contact angle while nanoscale transport mechanisms influence on the relative permeabilities can be neglected keywords nanoscale confined phenomena multiphase transport pore network model nanoporous shale dual surface wettability 1 introduction the complexities of nanoporous shale are expressed in terms of heterogeneous pore structure and various pore types guo et al 2018 kelly et al 2016 song et al 2019 tahmasebi et al 2016 the pore types in shale are generally categorised into three types interparticle mineral pores intraparticle mineral pores and intraparticle organic matter pores loucks et al 2012 intraparticle organic matter pores are referred to as organic pores and the other two types of pores are referred to as inorganic pores the inorganic pores are generally suggested to be water wet while the organic pores formed during hydrocarbon accumulation and generation processes are deem as hydrophobic odusina et al 2011 a significant amount of adsorbed gas molecules are distributed in the organic pore with large specific surface area clarkson et al 2013 therefore adsorbed gas and bulk gas coexist in organic pores as the inorganic matter tends to be water wet it is generally believed only bulk gas exists in the inorganic pore the bulk gas transport deviates from viscous flow javadpour 2009 landry et al 2016 song et al 2016 because of the nanoscale pore size and the flow regime is conventionally subdivided according to the knudsen number which is defined as the ratio of molecular mean free path to the pore radius in addition the adsorbed gas transport on the pore wall in the forms of surface diffusion to enhance the gas transport ability choi et al 2001 large amounts of water is injected into the shale formation during hydraulic fracturing process gallegos et al 2015 osiptsov 2017 reagan et al 2015 zeng et al 2019 however the majority of the injected water does not return to the surface during the flow back period more and more attention is paid to the inject water distribution after hydraulic fracturing birdsell et al 2015a hu et al 2015 wang et al 2016 numerous studies barrat and bocquet 1999 belyaev and vinogradova 2010 javadpour et al 2015 jin et al 2016 lauga and stone 2003 neto et al 2005 sun et al 2019 vinogradova 1999 suggest that non slip flow boundary condition for water is not valid in shale nanopores holt et al 2006 and majumder et al 2005 showed that the flow rates for water flow through membranes of carbon nanotubes cnts with diameters of 1 3 7 0 nm are two to five orders of magnitude larger than those calculated by the no slip hagen poiseuille equation the flow rate of water through 44 nm carbon nanopipes measured by whitby et al 2008 is an order of magnitude larger than the no slip hagen poiseuille equation multiphase transport behavior in dual surface wettability nanoporous shale has been investigated by both physical experiments and theoretical methods including analytical solutions and numerical models bennion and bachu 2007 measured relative permeabilities of devonian and cretaceous shales at reservoir conditions by conducting brine and co2 drainage and imbibition tests dacy 2010 estimated relative permeability curves for sub microdarcy shales by combining up to seven or more separate core measurements jung 2015 established a workflow of bakken shale relative permeability measurement method using nuclear magnetic resonance nmr spectroscopy to measure fluid saturations and a relative permeability measurements under a confining pressure rpc set up to conduct the displacement suhrer et al 2013 calculated oil water relative permeability during imbibition process in shale formation by lattice boltzmann method daigle et al 2015 considered the influences of pore structure on unsaturated advection and diffusion based on the critical path analysis and percolation theory to model shale relative permeability based on daigle et al 2015 model ojha et al 2017 proposed a method to estimate relative permeability in shale by processing the low pressure nitrogen adsorption desorption isotherm measurements yassin et al 2016 extended purcell 1949 to develop a conceptual model for relative permeability of gas and water in a dual wettability system mohammadmoradi and kantzas 2018 developed a semi analytical formulation of the spontaneous capillary imbibition and predicted relative permeabilities based on the general adjustable relationships proposed by luckner et al 1989 modeling multiphase flow in mixed wet subsurface porous media has benefited from the development of pore network work modeling approach ali et al 2015 khaksar et al 2013 sahimi 2011 mcdougall and sorbie 1997 1995 studied relative permeability with a regular cubic network by assigning different wettabilities to different pores in the network blunt 1997 established a pore network model to study wettability effect considering different pore level displacement processes oren et al 1997 predicted transport properties of a mixed wet reservoir rock using a pore network obtained from reconstructed pore space since then numerous quasi static pore network models have been extensively applied to study mixed wettability in order to match with experimental results al futaisi and patzek 2004 høiland et al 2007 jackson et al 2003 kallel et al 2017 valvatne and blunt 2004 zhao et al 2010 as well as three phase flow process al dhahli et al 2013 hui and blunt 2000 piri and blunt 2005a 2005b van dijke et al 2007 on the other hand the dynamic pore network models were developed to consider both capillary force and viscous force joekar niasar and hassanizadeh 2012 li et al 2017 wang et al 2015 hammond and unsal 2012 proposed a dynamic pore network model for oil displacement in an initially mixed wet medium by wettability altering surfactant solution aghaei and piri 2015 developed a dynamic pore network model considering viscous capillary and gravity forces as well as mixed wettability obtained from micro ct images huang et al 2016 studied gas and water relative permeability during imbibition process based on the conceptual shale dynamic pore network model to the best knowledge of the authors most of the current pore network modeling studies under mixed wet conditions focus on conventional rocks or conceptual pore network models the comprehensive nanoconfinement effects of both gas and water phases gas adsorption pore types organic pore inorganic pore real gas property have not been considered in an existing pore network model to model multiphase flow behavior in a mixed wet shale rocks at typical reservoir conditions furthermore the current theoretical shale relative permeability models have not considered the heterogeneous pore structure fluid transport mechanisms dual surface wettability and pore type altogether the purpose of this study is to propose a nanoscale gas and water pore network transport model to study nano confined gas and water multiphase transport behavior in dual surface wettability nanoporous shale we first propose a workflow to construct a shale pore network model to model both organic pores and inorganic pores and accurately consider different wettability in these two different pore types next we further consider nanoconfinement effects and pore surface physicochemical property influence on fluid flow compared with previous quasi static pore network model multiple fluid transport mechanisms related with pore type gas adsorption critical property change with pore size and real gas equation of state are modeled more specifically water transport considers the boundary slip length determined by the contact angle bulk gas transport in inorganic pores considers slip effect while bulk gas transport and surface diffusion for adsorbed gas are both considered in organic pores gas and water relative permeabilities during injected water flow in and flow back process are analyzed in detail this paper is organized as follows in section 2 nanoscale gas and water pore network transport model is established in section 3 detailed results and discussions are demonstrated this is followed by a section of conclusion 2 nanoscale gas and water pore network transport model 2 1 construction of dual pore type shale pore network model although 3d imaging of shale rock can accurately describe the nanopore characteristics the imaging process is costly and time consuming tahmasebi et al 2016 wang et al 2017b zhou et al 2016 in this work three binary high resolution sem images in fig 1 obtained from the shale sample are applied to reconstruct the 3 d shale digital core by representing three mutually perpendicular planes according to markov chain monte carlo mcmc method chen et al 2015 okabe and blunt 2007 wu et al 2007 2006 2004 yang et al 2015 zhang et al 2015 each binary sem image has the pixel size of 400 400 pixels and the pixel size of the sem image taken is 27 62 nm 27 62 nm the constructed 3 d shale digital core in fig 2 contains 400 400 400 voxels at a voxel size of about 27 62 nm the physical size of the constructed 3 d shale digital core is 11 048 μm 11 048 μm 11 048 μm the porosity of the constructed 3 d shale digital core is about 0 13 the dual pore type shale pore network model in fig 3 is constructed as follows first the pore network model is extracted from 3 d shale digital core by the maximal ball fitting method blunt et al 2013 dong and blunt 2009 the shapes of the pore bodies and pore throats used in our study for individual network elements include circle pore square pore and irregular triangle pore characterized by the shape factor g mason and morrow 1991 concrete pores and throats identification method can be found in the supporting information then the total pore space volume and the volume of each pore and throat on the pore network are calculated next the total organic pore and throat volume is given according to the total organic carbon toc in volume in this study the toc in volume value is given as 5 as the organic pore size is generally smaller than the inorganic pore size naraghi and javadpour 2015 the organic pores and throats are labelled starting from the smallest size of pore and throat until the given total organic pore and throat volume is matched the remaining parts on the pore network are deemed as the inorganic pores and throats organic and inorganic pore type size distributions are shown in figs 4 and 5 respectively since the organic throats does not necessarily connect organic pores and can connect inorganic pores therefore the organic throat size sometimes can be larger than the organic pore size the coordination number distribution is shown in fig 6 2 2 gas and water distribution in a single nano capillary under two phase transport condition previous experimental studies reveal that the water advancing contact angle in shale notably increases with the increase of pressure and can reach around 90 at high pressure arif 2017 iglauer et al 2015 pan et al 2018 therefore we assume that the water advancing contact angle is large enough and only piston like advance occurs during injected water imbibition process the wetting water transports in the inorganic pore corner while gas transports in the pore center during injected water flow back process molecular simulation results lee et al 2016 li et al 2019 indicate that for organic carbon material with hydrophobic pore surface adsorbed gas molecules occupy pore surface and water molecules locate at the center of the pore therefore we assumes that once injected water flows into the organic pore under certain pressure drop the bulk gas is displaced and water transports in the center of the pore while adsorbed gas transports at the boundary of pore in the forms of surface diffusion the water in the organic pore center can be displaced by gas during the injected water flow back process illustrations of gas and water distribution in a single nano capillary during injected water flow in and flow back process are shown in figs 7 and 8 respectively consider the cross section of a polygonal shaped inorganic pore the gas and water distribution in one corner is shown in fig 9 the interface lengths can be determined from elementary geometry valvatne and blunt 2004 1 a e f f a r 2 i 1 n cos θ r cos θ r β i sin β i θ r β i π 2 2 a c b sin β cos θ r β 2 cos θ r cos θ r β sin β θ r β π 2 r 2 s 1 3 b r cos θ r β sin β 4 r σ p c 5 d s 1 2 i 1 n cos θ r β sin β cos θ r s 3 6 l g w 2 r i 1 n π 2 θ r β r s 3 7 g c a c 4 b 2 1 sin β cos θ r β θ r β π 2 2 8 g sin β cos β 4 1 sin β 2 9 c v a l 0 364 0 28 g g c where β is the corner half angle θr is the contact angle n is the total number of corners containing arc menisci β π 2 θr g is shape factor of the pore cross section dimensionless a r2 4g is the total pore cross section area aeff is the pore area occupied by gas ac is the corner area for a single corner b is the water solid interface length of water in the corner r is the radius of curvature of the interface lgs is the gas soild interface length of gas in the pore center lgw is the length of the gas water interface gc is the shape factor for the corner section containing the fluid g is the shape factor without any curvature on the fluid interface for polygonal shaped elements the capillary entry pressure expressions are found by calculating the force balance acting on the interface in the duct this method has become known as the mayer stowe and princen ms p method mason and morrow 1991 and we follow oren et al s 1998 generalization of it given by 10 p c σ cos θ r 1 2 π g r f d θ r g β where fd is a dimensionless correction factor for wetting fluid that might be retained in the corners 11 f d θ r g β 1 1 4 g d cos 2 θ r 1 2 π g in the case of a circular tube where there are no corners fd will be 1 and eq 10 will be reduced to 12 p c 2 σ cos θ r r as we assume the injected water completely fills the inorganic pore and there is no contact angle hysteresis the threshold capillary pressure is the same as eq 12 during the injected water flow in process based on experiment and molecular simulation data the water surface tension σ0 change versus temperature t can be given as vega and de miguel 2007 13 σ 0 227 86 1 t t c w a t e r 11 9 1 0 6413 1 t t c w a t e r 10 3 where tc water is the critical temperature for water 641 4 k the dependence of surface tension σ on water curvature radius rc is given in eqs 14 and 15 lu and jiang 2005 and curvature radius rc is related with effective radius reff water by eq 16 kloubek 1981 14 σ σ 0 1 1 4 r c h 1 exp 2 s b 3 r 1 4 r c h 1 15 s b e 0 t b 16 r c r e f f w a t e r cos θ r where h is oh bond length 0 096 nm r is the ideal gas constant 8 314 j k mol sb is solid vapor transition entropy of water e0 is the bulk solid vapor transition enthalpy j mol tb is bulk solid vapor transition temperature of water k reff water denotes reff or in organic pores and r in inorganic pores 2 3 gas and water transport through a single nano capillary under single phase condition langmuir monolayer adsorption model langmuir 1918 is suggested to be able to model shale gas adsorption behaviors at the typical shale gas reservoir condition heller and zoback 2014 the gas coverage of adsorbed gas in organic pore can be expressed as 17 θ p z p l p z adsorbed gas molecules on the pore surface reduce the organic pore space available for the remaining gas molecules to transport the effective pore radius for bulk gas transport in organic pore can be expressed as song et al 2017 wu et al 2016a 18 r e f f o r r d m θ the mean free path of molecules for a real gas can be expressed as michel villazon et al 2011 19 λ π z r g t 2 m μ p the knudsen number in organic and inorganic pores can be written as 20 k n λ r e f f reff refers to the radius of an inorganic pore r and the effective radius of an organic pore reff or in this work a unified hagen poiseuille type equation developed by beskok and karniadakis 1999 is used for modeling bulk gas transport for a capillary with a circular cross section the volumetric gas flux q through a single nano capillary is given as follows 21 q f k n π r e f f 4 8 μ δ p l where the flow condition function f kn is given by 22 f k n 1 α k n 1 4 k n 1 β k n the parameter α in eq 22 is a dimensionless rarefaction coefficient which can be written as 23 α 128 15 π 2 tan 1 4 0 k n 0 4 though the slip coefficient β 1 was initially considered only applicable to a slip flow condition evidence from the dsmc simulations and boltzmann solutions karniadakis et al 2006 showed that β 1 is valid within in the full range of flow regimes according to eq 21 bulk gas transport conductance can be written as 24 g f r e e π r e f f 4 f k n 8 μ l surface diffusion of adsorbed gas molecules has long been considered as one of the key transport mechanisms in organic pores because of the large amount of adsorbed gas in organic shales it can be modelled as a the general diffusion process using the molar flow rate per unit area of the concentration gradient within the adsorbed monolayer as developed in cunningham and williams 1980 25 j a d s d c a d x ca is calculated assuming langmuir adsorption and is given by 26 c a c a max θ the maximum adsorbed gas concentration camax inside the organic pore space can be given based on the measured maximum adsorbed gas concentration cmax and toc in volume 27 c a max c max t o c v o l combining eqs 25 27 molar flow rate in the adsorbed layer is then expressed below 28 j a d s c a max d θ d p π r 2 r e f f o r 2 d p d x from eq 28 volumetric flux is 29 v a m ρ d s c a max d θ d p π r 2 r e f f o r 2 d p d x according to gas adsorption experimental data and molecular simulation data song et al 2018 the surface diffusion coefficient at zero gas coverage can be expressed in eqs 30 based on guo et al 2008 hwang and kammermeyer 1966 30 d s 0 3 1321 10 7 t 0 5 exp δ h 0 8 r t in order to consider the influence of gas coverage on surface diffusion needs to be considered chen and yang 1991 used the kinetic method to calculate the surface diffusion coefficient 31 d s d s 0 1 θ κ 2 θ 2 θ h 1 κ 1 κ κ 2 θ 2 1 θ κ 2 θ 2 32 h 1 κ 0 κ 1 1 0 κ 1 33 κ κ b κ m where κb is the rate constant for blockage and κm is the rate constant for forward migration when κm κ b surface diffusion occurs when κm κ b gas molecules are blocked and surface diffusion stops according to eq 29 adsorbed gas transport conductance can be written as 34 g s u r f a c e 1 l m ρ d s c a max d θ d p π r 2 r e f f o r 2 according to eqs 24 and 34 gas transport conductance in organic pore and inorganic pore can be given respectively as 35 g o r π r e f f o r 4 8 μ l 1 128 15 π 2 tan 1 4 0 k n 0 4 k n 1 4 k n 1 k n 1 l m ρ d s c a max d θ d p π r 2 r e f f o r 2 36 g i n π r 4 8 μ l 1 128 15 π 2 tan 1 4 0 k n 0 4 k n 1 4 k n 1 k n the constant water viscosity as a function of temperature t is given in eq 37 and viscosity of water μ t can be predicted with accuracy to within 2 5 from 273 k to 643 k al shemmeri 2012 37 μ t 2 414 10 5 10 247 8 t 140 wu et al 2017 derived a scaling function for the slip length based on the published md simulation data shown in eq 38 and the confined water flux qwater for circle pore is given in eq 39 38 l s t 0 41 cos θ w 1 2 39 q w a t e r π 8 μ r r 4 4 r 3 l s t d p d x where lst is the water slip length in nanometer unit eq 39 can be reorganized as 40 q w a t e r s f π r 4 8 μ r d p d x where the slip factor is defined as 41 s f 1 4 l s t r according to eq 40 water transport conductance can be given as 42 g w s f π r 4 8 μ r l 2 4 gas and water transport through a single nano capillary under two phase condition for water transport in a single corner we first define the constants c2 c3 to simplify the later derivation 43 c 2 cos θ r β sin β 44 c 3 π 2 θ r β the perimeter of single corner occupied by water is 45 p c o r 2 r c 2 2 r c 3 the equivalent radius for water transport in the corner is defined as 46 r c o r 2 a c p c o r r s 1 c 2 c 3 according to eq 41 the slip factor for water flow in the corner can be defined as 47 s f c 1 4 l s t r c o r 1 c 4 r where c4 is defined as 48 c 4 4 c 2 c 3 l s t s 1 the relationship between corner flow flux and pressure drop for no slip hagen poiseuille condition is given in eq 49 the performance of this correlation was tested using a 2 d finite element code for incompressible laminar flow for a variety of corner configurations it was found to predict the conductance well within a 10 error margin valvatne and blunt 2004 49 q w c n s c v a l a c 2 g c μ d p d x considering the slip factor the corner flow flux for a given pressure drop δp can be written as 50 q w c s s f c c v a l a c 2 g c μ δ p l according to eq 50 water transport conductance in the single pore corner can be given as 51 g w c s s f c c v a l a c 2 g c μ l for gas flow in the center we continue to use eqs 35 and 36 but multiply it by the fraction of the cross section area occupied by the gas phase according to eq 1 2 5 nanoscale gas and water quasi static pore network transport model the constructed dual pore type pore network is initially saturated with gas and all possible displacement events are sorted in terms of capillary entry pressure with the event with the highest capillary pressure executed first the feasibility of quasi static pore network model to model injected water flow in process in nanoporous shale is explained in the supporting information based on the capillary number concept and previous studies birdsell et al 2015b cheng 2010 the injected water first flows into the inorganic pores with positive capillary pressure and fills in the order of increasing radius with the narrowest filling first patzek 2001 in the next displacement stage the injected water starts to flows into the organic pores with negative capillary pressure under the drainage pressure and displaces bulk gas in the order of decreasing radius with the largest organic pore first during the injected water flow back process the injected water in the organic pore is first displaced by gas with positive capillary pressure in the order of increasing radius then the injected water in the inorganic pore is displaced by gas with negative capillary pressure in the order of decreasing radius under the drainage pressure the hydraulic radius can be expressed as eq 52 as done in ma et al 2014 oren et al 1998 and valvatne and blunt 2004 detailed model parameters are given in table 1 the water saturation is calculated by the total water volume in the pores and throats divided by the total pore and throat volume on the pore network visualization of gas and water distribution on the shale pore network during injected water flow in and flow back process is shown in fig 10 the flowchart of the modeling process is given in the supporting information 52 r 2 a p d 2 a g where pd is the perimeter of the pore cross section because of the existence of water slip and gas rarefied effect in nanopores the absolute permeability kabs water value calculated by water is different from the absolute permeability kabs gas value calculated by gas therefore unlike the traditional pore network models the absolute permeability should be calculated for each phase to obtain the reasonable value of relative permeability the water phase absolute permeability is obtained by eq 53 because the viscosity is variable across pores and throats and pressure dependent gas phase absolute permeability is calculated using a different way to that which would be normally done see oren et al 1998 by eq 53 that is the product of gas flux and viscosity is calculated for every inlet pore voxel to compute the sum of the total flux at the inlet face and gas phase absolute permeability by eq 54 53 k a b s w a t e r μ l p n m i 1 n i n l e t q i n l e t a p n m δ p 54 k a b s g a s i 1 n i n l e t q i n l e t μ i n l e t l p n m a p n m δ p where qinlet is gas flux in inlet pores ninlet is the number of the inlet pores lpnm is the length of the 3d model apnm is area of the 3d model cross section μinlet is the gas viscosity in inlet pores p is the pressure drop on the 3d model the relative permeability is then given by 55 k r w a t e r q t m p w a t e r q t s p w a t e r 56 k r g a s q t m p g a s q t s p g a s qtmp is the total flux of phase p in multiphase conditions with the same imposed pressure drop the total flux is found by solving for the pressure everywhere imposing mass conservation at every pore i the mass balance equations for gas phase are non linear functions of gas pressures due to pressure dependent conductance and viscosity and they must be solved iteratively taking an initial pressure distribution as that for the darcy flow the system of equations is solved iteratively in a similar fashion as in ma et al 2014 until the volumetric flux converges 57 j 1 n i q i j 0 where j runs over all the throats connected to pore i the flow rate qij between two pores i and j is given by 58 q i j g i j p i p j the conductance between two pore bodies gij is taken to be the harmonic mean of each individual conductance as similar done in valvatne 2004 59 1 g i j 1 g i 1 g t 1 g j where li lj lt are the length of pore i and pore j and the throat that connects pore i and pore j respectively gi gj gt are the gas transport conductance of pore i and pore j and the throat that connect pore i and pore j respectively 3 results and discussions fig 11 a shows calculated gas and water relative permeability during injected water flow in process the gas phase relative permeability first declines fast and then gradually decreases with the increase of water saturation when the water saturation is larger than 0 4 the water phase relative permeability gradually increases and then increases more rapidly when the water saturation is larger than 0 6 the corresponding water saturation for the relative permeability crosspoint during injected water flow back process is less than 0 5 this can be attributed to the fact that the gas wet organic pores makes the pore network show mixed wet characteristic the gas phase relative permeability increases rapidly and water phase relative permeability declines rapidly with the increase of gas saturation during injected water flow back process in fig 11 b fig 12 shows gas and water relative permeability at different toc in volumes the increase of toc in volumes makes the pore network tend to be more gas wet and the corresponding water saturation for the relative permeability crosspoint shifts to the smaller value around 0 5 fig 13 shows gas and water relative permeability during injected water flow back process at different inorganic pore water contact angle and uniform wettability condition the corresponding water saturation for the water wet displacement relative permeability crosspoint is generally larger than 0 5 while the increase of water contact angle makes the pore network tend to be less water wet and the corresponding water saturation for the relative permeability crosspoint shifts to the smaller value close to 0 5 this indicate that gas and water relative permeability in nanoporous shale is mutually influenced by the toc in volumes and water contact angle it is also can be seen that there is notable difference between the uniform wettability relative permeability curve and dual wettability relative permeability curve the corresponding water saturation for the uniform wettability relative permeability crosspoint is larger than that for the dual wettability relative permeability crosspoint because of the strong water wet pore network under the uniform wettability condition in this work we deem that water can enter the organic pores as a nonwetting phase because the injected water driving force during hydraulic fracturing process should overcome the capillary pressure inside organic pores however there are different views on whether water can enter the organic pores therefore we calculated the gas water relative permeabilities when water does not invade into the organic pores and compared with those when water invades into the organic pores in fig 14 the endpoint water saturation for gas and water relative permeability during injected water flow in process decreases and the gas water relative permeabilities during injected water flow in process coincide with each other before the water saturation reaching the endpoint in fig 14 a this is because the injected water first invades the inorganic pores and there is difference only when water enters the organic pores at the final displacement stage if we assume water does not invade into the organic pores during the injected water flow in process the gas will first invade the inorganic pores in the order of decreasing radius and the gas inside the organic pores will connect with the invaded gas at certain drainage stage during injected water flow back process the gas water relative permeabilities consequently show notable difference during injected water flow back process in fig 14 b we further model the gas and water transport in the forms in the darcy flow and calculate the relative permeability during flow in and flow back process it s can be seen in fig 15 that nanoscale transport mechanisms influence on the relative permeability can be neglected this can be attributed to the two aspects first relative permeability curve is mostly controlled by the sample wettability and pore structure second the relative permeability is defined by the effective phase permeability divided by the absolute permeability under single phase condition and is a dimensionless form however the effective permeability at different saturation is different from that based on the darcy flow and can be larger than that based on the darcy flow this is because the nanoconfinement effects can increase the absolute permeability and the calculated absolute permeability is larger than the intrinsic permeability as discussed in our previous study song et al 2017 fig 16 a shows capillary pressure versus gas saturation during injected water flow back process the capillary pressure first increases rapidly with the increase of gas saturation and then becomes flat when the gas saturation is larger than 0 7 the capillary pressure starts to gradually increase with the increase of gas saturation at typical shale gas reservoir production condition the pressure difference between gas phase and water phase causes the injected water flow back and the pressure difference value is larger in the near wellbore than that away from the wellbore region however given the large capillary pressure 1 mpa shown in fig 16 a the pressure difference is not always larger than the capillary pressure especially in the region far away from the wellbore and large amounts of injected water is retained as a consequence this indicates that gas and water relative permeability during injected water flow back process shall be used at a certain range of gas saturation because the irreducible water saturation corresponds to the condition that the pressure difference between gas phase and water phase can overcome the largest capillary pressure generated by the interface between water phase and gas phase in the smallest inorganic pores at the final displacement stage fig 16 b shows the irreducible water saturation versus inorganic pore water contact angle during injected water flow back process the decrease of inorganic pore water contact angle causes more and more water resides in the inorganic pore corner and the irreducible water saturation increases consequently this means that the injected water retention volume also increases with the decrease of inorganic pore water contact angle 4 conclusion in this work we studied the nanoscale confined gas and water transport behavior in dual surface wettability nanoporous shale based on the proposed nanoscale multiphase pore network transport model water transport considers the boundary slip length determined by the contact angle bulk gas transport in inorganic pores considers slip effect while bulk gas transport and surface diffusion for adsorbed gas are both considered in organic pores the gas water distribution in a single nano capillary is determined by the mayer stowe and princen ms p method the results indicate that gas and water relative permeability in nanoporous shale is both influenced by the toc in volumes and inorganic pore water contact angle the larger value of toc in volumes and inorganic pore water contact angle can cause the corresponding water saturation for the relative permeability crosspoint shifts to the smaller value less than 0 5 while nanoscale transport mechanisms only influence effective peremeability and its influence on the relative permeabilities can be neglected furthermore the injected water retention volume is influenced by the capillary pressure and inorganic pore water contact angle our study reveals that accurate modeling nanoscale gas and water transport behavior must consider the significant different surface wettability in the dual organic inorganic nanoporous shale pore system the limitation of current study is that we assume piston displacement during injected water flow in process according to water advancing contact angle measurement results in literature in the future work we will consider to obtain an advancing contact angle from studied shale sample at reservoir pressure condition and determine piston like displacement or wetting film flow in each irregular pore and throat on the shale pore network in addition we deem that the injected water can enter the organic pores and there are different views on whether water can enter the organic pores as we have mentioned to deal with this the fractured shale core sample will be imaged using high resolution focused ion beam milling combined with scanning electron microscopy fib sem to detect whether there is injected water distribution inside the organic matter in the future study declarations of interest none acknowledgments the authors gratefully acknowledge two anonymous referees for their constructive comments this project was supported by the major projects of the national science and technology 2016zx05061 fundamental research funds for the central universities 18cx06007a 18cx06008a 17cx05003 16cx05018a national natural science foundation of china no 51504276 no 51490654 shandong provincial natural science foundation china no zr2014eep018 applied basic research projects of qingdao innovation plan 16 5 1 38 jch the data used are listed in the figures and tables in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 06 012 appendix b supplementary materials image application 1 appendix a real gas property considering nanoscale confined effect in this work islam s equations given in islam et al 2015 are applied to describe the relationship between critical property and nanopore size in eqs 60 and 61 60 t c 8 27 b r a 2 γ 3 ε n 2 γ r 2 6275 0 6743 γ r 61 p c 8 27 b 2 a 2 γ 3 ε n 2 γ r 2 6275 0 6743 γ r where a is the vdw energy parameter b is the vdw energy parameter γ is the lennard jones size parameter ε is the lennard jones energy parameter gas compressibility factor z eq 64 is calculated according to mahmoud 2014 which is valid over a wide pressure range 62 p p r p p c 63 t p r t t c 64 z 0 702 e 2 5 t p r p p r 2 5 524 e 2 5 t p r p p r 0 044 t p r 2 0 164 t p r 1 15 lee et al 1966 developed an empirical gas viscosity model for natural gases that has been adopted for the confined pores bui et al 2016 kim et al 2016 landry et al 2016 wang et al 2017a to determine gas viscosity and density as follows 65 k 9 379 0 01607 m t 1 5 209 2 19 26 m t 66 x 3 448 986 4 t 0 01009 m 67 y 2 447 0 2224 x 68 μ 1 10 4 k exp x ρ y 69 ρ 1 4935 10 3 p m z t 
621,virtual water flows have been extensively analyzed at the national level using complex network approaches however less is known about the regional structure of subnational virtual water flows even though virtual water flows can vary greatly within a country additionally subnational level studies are needed since water policy and decision making tend to be local or regional in scope here we characterize and model virtual water flows for aggregated agricultural and industrial commodities at the us subnational level using subnational trade data for the us we build and analyze unweighted and weighted directed virtual water trade networks vwtns to model and explore the drivers of subnational virtual water flows we build and implement a gravity type spatial interaction model using different network metrics we find that the subnational vwtns differ from previous well studied networks including national level vwtns the network metrics also show a high connectivity for the unweighted vwtns with no community structure while the weighted vwtns reveal spatially coherent communities of intense trade activity the gravity model shows that the subnational weighted vwtns are mainly controlled by distance agricultural land gross domestic product and population despite the high connectivity of the vwtns the presence of community structure indicates that large volumes of virtual water are traded regionally this suggests the possibility of having hydroeconomic boundaries that differ from known physical boundaries e g watersheds and aquifers such boundaries could have implications for the design of consumption based strategies for water sustainability keywords complex networks water consumption network science modularity water footprint 1 introduction water is embodied or virtually present in every step of economic production processes allan 2010 2011 linking water to all sectors of the product economy to study the dependence of the product economy on water one can analyze the virtual water flows entering and leaving a geographic area due to the trade of commodities distefano and kelly 2017 fracasso 2014 hoekstra and mekonnen 2012 konar et al 2011 sartori and schiavo 2015 such flows form a virtual water trade network vwtn when the interconnections among multiple geographic areas are considered vwtns can be used to understand and potentially enhance water sustainability particularly when combined with water scarcity information distefano and kelly 2017 vanham et al 2018 or environmental cost metrics soligno et al 2017 2019 for example vwtns can be used to foster greater shareholder accountability of water resources hoekstra 2009 hoekstra and mekonnen 2012 ridoutt and pfister 2010 wichelns 2001 identify systemic drivers of water use allan et al 2015 distefano et al 2018 suweis et al 2013 and devise innovative strategies for alleviating water stress chapagain and hoekstra 2006 dalin et al 2014 dang et al 2015 distefano and kelly 2017 konar et al 2011 through network science approaches several studies have investigated the topology and evolution of national level vwtns dalin et al 2012a b konar et al 2011 sartori et al 2017 suweis et al 2011 as well as national level commodity trade networks fagiolo et al 2010 sartori and schiavo 2015 shutters and muneepeerakul 2012 fewer studies have explored and analyzed subnational level vwtns chini et al 2017 dang et al 2015 marston et al 2015 rushforth and ruddell 2016 the focus of subnational vwtn studies has been until now on food and agricultural commodities konar et al 2018 because of their high virtual water content while industrial commodities have mostly been ignored industrial commodities however can have an important influence on virtual water flows at the subnational level for instance at the subnational level some of the vwtn nodes may be cities which can have higher production outflows of industrial commodities than agricultural ones ahams et al 2017 here we use subnational trade data to characterize and model the subnational vwtns of us agricultural and industrial commodities moreover previous subnational vwtn studies have sometimes employed network metrics e g centrality metrics computed using shortest path algorithms that are unsuitable for analyzing vwtns formed from origin destination trade data dang et al 2015 these centrality metrics are useful when nodes can act as intermediate points in the distribution of a commodity e g warehouses where commodities are not being produced or transformed in the case of origin destination networks intermediate points have been removed from the data in this study we employ metrics that are consistent with origin destination networks to analyze the us subnational vwtn of agricultural and industrial commodities furthermore the tendency of nodes to form well defined groups of tightly connected nodes or communities d odorico et al 2012 which we identify and characterize here has not been explored before at the us subnational level identifying the existence of communities in networks is crucial because when present they form the building blocks of the network s topology and are capable of influencing the network s entire functioning aldecoa and marín 2013 fortunato 2010 gao et al 2018 girvan and newman 2002 for example communities play an important role in understanding and analyzing spreading processes in complex networks lin et al 2014 nguyen et al 2013 salathé and jones 2010 where they can act as barriers that restrict the spreading of cascading events to study and model vwtn flows statistical and economic models have been employed bergstrand 1985 d odorico et al 2012 duenas and fagiolo 2013 one approach has been to couple network modeling with a fitness function this approach was developed by garlaschelli et al 2004 and later applied by both suweis et al 2011 and dalin et al 2012 to national level vwtns another approach has been to use gravity models batty and mackie 1972 bergstrand 1985 hesse 2010 wilson 1967 gravity models are part of a broader category of spatial interaction models wilson 1971 which estimate network flows using the relationship between the properties e g population gross domestic product gdp and employment of two connected areas and the distance between them using spatial interaction models of the gravity type different socioeconomic flows have been modeled including commodities duenas and fagiolo 2013 information krings et al 2009 migrants davis et al 2018 and commuters guo et al 2012 simini et al 2012 to develop models that attempt to strike a balance between parsimony and fit gravity models have been used to model and identify the main controls of national level vwtns fracasso 2014 sartori et al 2017 tamea et al 2014 for example tuninetti et al 2017 recently developed a novel approach to predict vwtns using gravity models which they applied to national level virtual water flows from international food trade additionally several link prediction algorithms have been proposed based on network similarity lu and zhou 2011 these algorithms however emphasize topological or structural properties as opposed to node properties the focus on node properties e g as done in spatial interaction models is desirable to understand the drivers of flows gravity models have successfully been used to model national level vwtns fracasso 2014 sartori et al 2017 to our knowledge they have not been systematically applied to study subnational vwtns by serving as a modeling baseline for future studies we view this as a necessary step in advancing our understanding of subnational vwtns our goal with this study is twofold firstly to characterize the topology and connectivity of the us subnational vwtn of agricultural and industrial commodity flows secondly to model vwtn flows using a spatial interaction model with this goal we address the following questions how do subnational vwtns differ from other well studied complex networks including national level vwtns do subnational vwtns reveal community structure can subnational vwtn flows be modeled using spatial interaction models what are the key drivers of subnational virtual water flows how can the subnational vwtn results help inform water resources sustainability the paper is organized as follows section 2 describes the methodology and data used section 3 presents the main results lastly section 4 summarizes key conclusions and discusses the implications and limitations of our results 2 materials and methods this section describes i the data and approach used to build the empirical vwtns ii the metrics used to characterize the topology and connectivity patterns of the vwtns and iii our approach to modeling virtual water flows 2 1 empirical virtual water trade networks we built the us vwtns of agricultural and industrial commodities using the freight analysis framework version 3 faf3 commodity trade data fhwa 2018 a separate vwtn was built for the agricultural and industrial commodities the faf3 data represents for the year 2007 the annual flow of commodities for the entire us product economy by dividing the country into 123 distinct geographic origin destination areas and the economy into 43 different commodity classes to build the vwtns we considered the 120 geographical areas covering the coterminous us fig 1 and 30 different commodity classes out of these 120 areas 64 are metropolitan or consolidated statistical areas hereafter cities consisting of the largest and some of the major mid sized cities in the us we aggregated into a single area the consolidated statistical areas 6 out of the 64 in the faf3 data belonging to the same city but located in different states this resulted in a total of 112 distinct geographical areas including 64 city and 48 non city areas table s1 in the supplementary material lists the names of the 112 geographical areas fig 1 illustrates the 112 areas and provides an example of the interactions between city and non city areas the non city areas either represent i entire states that do not have a faf3 city in them or ii remainders of states consisting of the faf3 non city area of a state the 30 commodities considered include most of the faf3 agricultural and industrial commodity classes leaving out mostly the energy related and mining commodities the list of commodities used is included in table s2 of the supplementary material we multiplied the agricultural and industrial commodity flows in the faf3 data by their corresponding virtual water contents to obtain virtual water flows for each of the 30 commodity classes considered the virtual water content values were obtained from the study by ahams et al 2017 who used data from and the methodology of the water footprint network to derive the values hoekstra 2011 hoekstra and mekonnen 2012 the virtual water content estimates used are average values over the period 1996 2005 lastly to build the empirical weighted directed vwtns we first assigned a network node to each of the 112 geographic areas in the faf3 then we assigned weighted directed links in volume of virtual water traded over the year 2007 to any pair of connected nodes in the faf3 data specifically the weight of a link was determined as follows 1 w i j c τ i j c v i c where wij c m3 yr is the virtual water flow between nodes i and j for the commodity class c τij c ton yr is the faf3 commodity flow between i and j for commodity class c and vi c m3 ton is the virtual water content of commodity c in the origin node i we aggregated the commodity flows for the different agricultural classes into a single macro agricultural class the same aggregation process was performed for the industrial commodities this resulted in two aggregated weighted directed vwtns one for agricultural commodities fig 2 a and another one for industrial commodities fig 2b which are hereafter simply referred to as vwtns note that the links in the vwtns represent the total aggregated agricultural or industrial virtual water flows for every pair of origin and destination nodes in the faf3 data all of our network analysis and modeling was performed separately for these two aggregated vwtns 2 2 network metrics to compute the different network metrics we represented the n nodes in our vwtns by an n n matrix w wij of origin destination pairs each matrix element wij m3 yr is the aggregated agricultural or industrial virtual water flow from origin node i to destination node j i j 1 2 n and has a zero value assigned to it if the nodes are not linked in addition we obtained unweighted vwtns by replacing the matrix elements with binary values resulting in an adjacency matrix the unweighted adjacency matrix is denoted by a aij where the elements are equal to 1 if a virtual water flow exists between two nodes and zero otherwise the unweighted vwtns were used to isolate the connectivity of the network from the virtual water flows we employed both network configurations unweighted and weighted to analyze the agricultural and industrial vwtns for both configurations we considered the case of an asymmetric matrix with positive weights aij aji 0 1 or wij wji 0 and no self links links connecting a node to itself a ij j i 0 or w ij j i 0 the asymmetry of the adjacency matrix is a consequence of taking into account the directionality of the flows while the positivity of the weights only indicates that flows must be real positive values in the case of vwtns the directionality is crucial to properly distinguish incoming and outgoing connections at every node the exclusion of self links is justified by the fact that a relatively large fraction of the internal production of commodities at each node stays within the node for consumption or transformation these large internal flows can overshadow the dispersed demand of commodities in vwtns therefore they were omitted from our analysis one of the most common properties of a complex network is the degree distribution p k and its weighted version the strength distribution p s newman 2010 the degree ki of a node i is defined as the number of neighbors or links incident to it in the weighted version of the network node degree becomes the sum of the flows associated with node i the degree weighted degree distribution indicates the probability that a randomly chosen node has k connections s amount of flow newman 2003 both degree and weighted degree can be seen through the perspective of inflows or outflows of virtual water leading to the formulation of different degree distributions indegree kj in outdegree ki out weighted indegree sj in and weighted outdegree si out we used these different degree distributions to characterize the connectivity and flows of the agricultural and industrial vwtns to determine the degree distributions multiple theoretical cumulative distribution functions cdfs were fitted to the data and compared against each other using the akaike information criterion aic then the kolmogorov smirnov ks test was applied to the theoretical distribution with the lowest aic in addition we used the following metrics to characterize the vwtns clustering coefficient watts and strogatz 1998 assortativity leung and chau 2007 newman 2002a weighted distances tamea et al 2013 and modularity blondel et al 2008 newman 2006 the clustering coefficient c measures the tendency of the network to form groups of tightly connected nodes the assortativity ρ measures the preference of highly connected nodes to be linked to other high degree nodes the value of ρ lies in the range 1 ρ 1 with ρ 1 indicating perfect assortativity ρ 1 indicating perfect disassortativity and 0 indicating no assortative mixing or neutral assortativity the weighted distance d i measures for a node i the weighted average of the euclidean distance between each i j pair of trading partners where the weights are computed using the virtual water flows lastly the modularity q measures the presence of tightly connected groups of nodes communities in a network differently from the clustering coefficient which employs triangulated connections modularity is based on the density of links within communities the mathematical definition and interpretation of each of these metrics is provided in text s1 of the supplementary material 2 3 network model our network building algorithm consisted of two main steps analogous to both the first two steps used in transportation forecasting analysis evans 1973 schneider 2005 and the zero inflated algorithms used in economic theory to estimate zero trade flows burger et al 2009 that is the first step was used to estimate the links and the second step the weights of the network for the first step the unweighted directed vwtn was estimated using a logistic regression model barigozzi et al 2010 zanin et al 2016 as follows 2 ln y 1 y β 0 m 1 m β m x m where y identifies the activity or inactivity of a link through a linear combination of m explanatory variables xm and their corresponding parameters βm the following pool of potential explanatory variables were considered population gdp area of productive agricultural land euclidean distance latitude longitude community membership obtained from the modularity measure shared borders and type of faf3 area i e city state or remainder of state the parameters βm were estimated using maximum likelihood in the second step for the links identified as active by eq 2 the following gravity type spatial interaction model was used 3 w i j m i α 1 m j α 2 d i j α 3 where wij m3 yr same as before is the virtual water flow from node i to j mi and mj are variables representing relevant characteristics of node i and j respectively the α superscripts are the coefficients determined by regression analysis and dij is the euclidean distance between the nodes alternatively eq 3 can be written as an exponential function such that 4 w i j exp α 0 α 1 ln m i α 2 ln m j α 3 ln d i j ε i j where ε ij is the error term to estimate the parameters in eq 4 the poisson pseudo maximum likelihood ppml estimator was employed silva and tenreyro 2006 this estimator has several advantages over the traditional ordinary least squares ols approach it is independent of the underlying distribution of the data silva and tenreyro 2006 accounts for heteroskedastic error terms burger et al 2009 fracasso 2014 silva and tenreyro 2006 and preserves the total amount of flows arvis and shepherd 2013 when applied to gravity models the ppml has been shown to result in more consistent parameter estimates than ols over a wide range of conditions silva and tenreyro 2011 to select the explanatory variables for eqs 2 and 4 we used stepwise regression with a selection criterion of p values 0 05 the stepwise regression was applied separately to the agricultural and industrial vwtns however for each network the same set of variables were used to implement eqs 2 and 4 thus the same variables or node characteristics are used to both generate links and assign weights to each link in addition to compute all the network metrics and apply the network model the smallest virtual water flows consisting of less than 5 of the total flows were not considered for both the agricultural and industrial vwtns because they tended to deviate from the rest of the flows 3 results this section presents the results for the characterization and modeling of the vwtns the characterization results are separated into i degree distributions and assortativity and ii weighted distances clustering coefficient and modularity while the modeling results are separated into i unweighted and ii weighted vwtns 3 1 characterization of the virtual water trade networks 3 1 1 degree distributions and assortativity to characterize the topology and connectivity patterns of the vwtns we first analyzed the degree distributions of the unweighted and weighted versions of the agricultural and industrial networks the indegree and outdegree cdfs of the agricultural vwtn tended both to be approximately normal with p values of 0 22 and 0 69 for the ks test respectively the probability density functions pdfs and cdfs for the unweighted networks are shown in figures s1 and s2 respectively of the supplementary material the average degree of both the indegree and outdegree distributions was approximately 80 connections indicating a high connectivity since the total number of nodes is 112 for the indegree and outdegree cdfs of the industrial vwtn not shown we found that every node in the network is connected to all the other nodes indicating the network is complete the weighted indegree and outdegree cdfs for both the agricultural fig 3 a and b and industrial fig 3c and d networks tended to be approximately log normal the pdfs are shown in figure s1 of the supplementary material such peaked distributions are generally a distinguishing feature of spatially embedded networks barthelemy 2011 the p values for the ks tests were 0 65 and 0 99 for the agricultural weighted indegree and outdegree distributions respectively and 0 72 and 0 89 for the industrial weighted indegree and outdegree distributions respectively using assortativity to assess the connectivity of the networks we found that the unweighted and weighted versions of both the agricultural and industrial vwtns are characterized by an almost neutral slightly negative assortativity table 1 the significance of the assortativity results was assessed by computing the standard error following the approach of newman 2002b the generally small standard errors in table 1 relative to the values of the assortativity ρ indicate that ρ tends to be strong this means that for both vwtns the degree and the strength of the nodes are not strong determinants of the networks connectivity pattern the slightly negative assortativity values indicate that in this case nodes with relatively higher virtual water outflows inflows are slightly more frequently and strongly connected to nodes with relatively lower virtual water outflows inflows similar assortativity behavior is displayed by some technological networks such as the world wide web newman 2002a the slightly negative assortativity also indicates the absence of the rich club phenomena displayed by several social networks and linear preferential attachment network models newman and girvan 2002 this is useful because it highlights that nodes in the vwtns some of which at first sight might appear dominant e g nodes representing large cities such as new york or los angeles are connected to or dependent on nodes with heterogeneous degrees and strengths thus the structure of the vwtns is more subtle than implied by metrics used to assess node strength which in contradistinction are considered important for characterizing national level vwtns 3 1 2 weighted distances clustering coefficient and modularity to assess the effect of the spatial distribution of nodes on the vwtns we used the weighted average distance of virtual water flows this metric is useful because it allows to directly measure independently of any network based algorithm the potential for nodes to have a regional influence the expected value of the weighted average distance of outflows and inflows is 616 and 719 kms respectively for the agricultural vwtn and 893 and 917 kms respectively for the industrial vwtn figure s3 in the supplementary material illustrates the weighted average distance for a few selected nodes which were selected to include large and small cities as well as non city areas these weighted average distances indicate that most of the virtual water flows have a regional extend e g the average euclidean distance between the us west and east coasts is approximately 4040 kms this is in contrast with the national reach implied by the high connectivity displayed by the different versions of the degree distributions to further explore the regional characteristics of the vwtns we used the network clustering coefficient and modularity measure we found the network clustering coefficient is relatively high for both the agricultural c 0 77 and industrial c 0 69 vwtns as compared to the random version of both graphs c 0 35 and c 0 5 respectively the c values for the random networks had standard deviations 0 01 a high clustering coefficient for both vwtns confirms that there is a tendency in the networks to form clusters or communities in addition considering both the almost neutral assortativity and weighted average distance of the vwtns communities can be expected to be formed by nodes with diverse levels of connectivity degree or weighted degree and to be spatially constrained indeed using the community detection algorithm of blondel et al 2008 we found 7 and 5 spatially distinct communities for the agricultural fig 4 a and industrial fig 4b vwtns respectively note that the detection algorithm does not employ any information about the location or distance of nodes an alternative could have been that communities were present but in a geographically discontiguous fashion the presence of communities implies that intra community virtual water trade is stronger than inter community trade the intra and inter community virtual water trade is illustrated in fig 4c and d using chord diagrams for the agricultural and industrial vwtns respectively the seven communities identified in the agricultural vwtn are as follows fig 4a the north atlantic region traditionally characterized by its relatively early historical development and current high levels of urbanization the south atlantic region grouped together with the piedmont atlantic region extends to the north of the country partially covering the great lakes area the mississippi valley region characterized by its major inland waterways the midwest region covering part of the bread basket and upper mississippi watershed the southwestern region known for the texas triangle megaregion and gulf coast ports the northwestern region covering the cascadia megaregion and inland states towards the rocky mountains and the south pacific region primarily covering california and extending towards nevada arizona and new mexico the regions identified in the industrial vwtn fig 4b are more aggregated than in the agricultural vwtn fig 4a for example the west portion of the country is aggregated into one larger region in the industrial vwtn the mississippi region disappears because in contrast with agricultural commodities inland waterways are not a prevalent transportation mode for industrial commodities also slightly different configurations of the north atlantic south atlantic southwest and midwest regions are seen in the industrial vwtn fig 4b in addition we tested whether the unweighted agricultural vwtn is characterized by community structure and found that it is not the unweighted industrial vwtn was not tested since it is a complete graph for the agricultural vwtn this means that the communities do not emerge from the adjacency matrix which is shared by the native faf3 data moreover the native faf3 networks with flows in units of tonnage or dollars were also analyzed for community structure results now shown communities also emerged for those networks but differed somewhat both in the number of communities and node assignments from the ones found with the vwtns 3 2 modeling of the virtual water trade networks 3 2 1 unweighted virtual water trade networks using our two step network model we found the following logistic regression model gives the best performance for the unweighted agricultural vwtn 5 ln y 1 y 0 45 5 58 10 4 d i j 3 5 10 7 p j 2 65 10 8 a i where y is the probability of the origin node i being connected to the destination node j pj number of persons is the population at the destination node j and ai km2 is the area of productive agricultural land at the origin node i based on the standardized coefficients for eq 5 we found that population at the destination node is the most dominant variable followed by area of productive agricultural land at the origin node and finally by distance table 2 note that the standardized coefficients are comparable among themselves regardless of the units of their corresponding variables by comparing the model in eq 5 against the empirical vwtn obtained from the faf3 data we found the accuracy of the model is approximately 70 accuracy was calculated as the fraction of links active and inactive that were correctly predicted by the model the unweighted agricultural vwtn showed a tendency to be normally distributed figure s2 and to be characterized by neutral assortativity since this suggests the network may be structurally similar to a random network which is typically reproduced with the erdös rényi er model erdös and rényi 1959 the er model was used as an alternative link generation model to evaluate against the logistic regression in eq 5 the er model is employed because even though it is characterized by a poisson distribution in the large limit a poisson distribution can be approximated by a gaussian distribution the er model was employed to generate the unweighted agricultural vwtn and it misclassified 50 of the flows active and inactive comparing the performance of the er model against that of eq 5 it is seen that the connections among nodes in the unweighted agricultural vwtn are not merely random but are influenced by node properties relevant to agricultural commodity production consumption and trade for the industrial vwtn since the network is a complete graph we simply connected every node to the rest of the nodes instead of using the logistic regression model for this same reason the er model was not tested for the unweighted industrial vwtn 3 2 2 weighted virtual water trade networks from the predicted connections implied by eq 5 in the case of the agricultural vwtn and assuming a complete graph in the case of the industrial vwtn we assigned weights to each connection using a gravity type model the explanatory variables for each node in the model were selected from the pool of variables through stepwise regression for consistency the variables for the agricultural vwtn are the same ones used in eq 5 the fitted gravity models for the agricultural and industrial vwtns were respectively 6 w i j exp 10 48 1 41 ln d i j 0 57 ln a i 0 077 ln p j and 7 w i j exp 0 14 1 28 ln d i j 0 97 ln p i 0 70 ln p j 0 34 ln g i where pi number of persons is the population at the origin node i and gi dollars is the gdp at the origin node i all the other variables were previously defined table 2 shows the standardized coefficients for eqs 6 and 7 the coefficients indicate that distance with a negative correlation is the strongest determinant of virtual water trade for both the agricultural and industrial commodities the agricultural vwtn is also highly positively driven by the availability of agricultural land while the industrial vwtn is more strongly driven by the population and gdp of the sending and receiving nodes respectively the fitted gravity models performed reasonably well in estimating virtual water flows with r 2 values of 0 56 and 0 63 for the agricultural and industrial networks respectively these r 2 values compare well with previous applications of gravity models for estimating subnational level socioeconomic flows masucci et al 2013 simini et al 2012 and national level virtual water flows tamea et al 2014 the r2 values were calculated using the kullback leibler divergence see text s2 of the supplementary material since the network model is nonlinear cameron and windmeijer 1997 we also computed the correlation between the flows estimated by eqs 6 and 7 and the empirical flows we found the correlations to be 0 48 and 0 62 for the agricultural fig 5 a and industrial fig 5d vwtns respectively we determined the total inflows and outflows i e weighted indegree and outdegree at each node from the gravity model and compared those values against the empirical ones we found that the estimated and empirical values of the total inflows and outflows are reasonably correlated for both the agricultural fig 5b and c and industrial fig 5e and f vwtns the inflow and outflow correlations are 0 6 and 0 86 respectively for the agricultural vwtn and 0 83 and 0 74 respectively for the industrial vwtn the correlation of virtual water flows for the agricultural vwtn fig 5a is lower than the other correlations possibly due to the aggregation of commodity classes by aggregating all the agricultural and industrial commodities into macro commodity networks we are unable to represent and track the effect of regional specialization industrial agglomeration or product differentiation on the network in addition we tested the ability of the gravity models to reproduce the community structure found in the empirical networks fig 6 the modeled agricultural and industrial vwtn communities fig 6a and b are for the most part comparable to the communities in the empirical networks fig 4a and b notwithstanding a few differences the similarity between the empirical and modeled communities is noteworthy given that the models were only based on a few node properties the differences are more evident in the agricultural vwtn than in the industrial network for example in the modeled agricultural vwtn the west portion of the country is consolidated into one single community fig 6a whereas the empirical network shows two separate communities fig 4a also for the community covering the mississippi river in the empirical agricultural vwtn fig 4a the modeled network only detects the lower mississippi river area fig 6a 4 discussion and conclusion network science has identified a set of unifying structural properties shared by many real world complex networks boccaletti 2006 to quantify those properties network metrics and models are used here we used the network metrics of degree distribution clustering coefficient assortativity weighted distances and modularity as well as a spatial interaction network model to explore the topology and connectivity patterns of the us subnational agricultural and industrial vwtns subnational level studies are needed to bring the insights gained from applying network science to vwtns down to the spatial scales at which water resources decision and policy making take place and to better understand the ability to translate findings from national level studies to subnational vwtns in this study we have for the first time at the us subnational level characterized the degree and weighted degree distributions of agricultural and industrial vwtns identified the regional community structure of agricultural and industrial virtual water flows and benchmarked the ability of gravity type models to estimate subnational virtual water flows the interpretation limitations and implications of these findings are discussed next 4 1 interpretation and limitations of results we found the degree distributions indegree and outdegree of the agricultural vwtn tend to be approximately normal figure s2 the network degrees of the us highway system where major cities are the nodes connected by highways are normally distributed barabasi and bonabeau 2003 since trucking is the main mode of transportation for agricultural commodities it seems likely that the connectivity pattern of the highway system is reflected in the unweighted agricultural vwtn the unweighted industrial vwtn was found to be a complete graph due to the high connectivity of nodes this high connectivity is not surprising since our industrial vwtn combines 25 different faf3 industry classes making it very likely that every node produces consumes different industry products that are consumed produced by the other nodes in the network this result highlights the need to analyze in the future the industrial vwtns for individual commodity classes as they are more likely to reveal unique connectivity patterns the log normal peaked distribution of weighted connections for both the agricultural and industrial fig 4 vwtns is characteristic of spatially embedded networks where geographical space and distance play a fundamental role in the network structure barthelemy 2011 indeed the distribution not shown of the euclidean distance of virtual water flows for the agricultural and industrial vwtns were also found to be approximately log normally distributed supporting our observation that distance is a key factor influencing the configuration of the subnational networks this is because distance acts as a friction on trade through transportation costs and travel times the log normal distribution of the virtual water flows also supports the ability to use gravity type models with subnational vwtns and it clearly differentiates the agricultural and industrial vwtns from many other well studied complex networks characterized by power law distributions garlaschelli and loffredo 2004 girvan and newman 2002 networks with power law distributions are often modeled with linear preferential attachment models such models without additional refinements would generally not be adequate for modeling subnational agricultural and industrial vwtns national level vwtns do seem to be characterized by power law distributions carr et al 2013 distefano et al 2018 sartori et al 2017 which may be due to nations having strong individual interests the effect of trade agreements and distance having a lesser role than in the subnational vwtns this indicates that one needs to be careful in translating methods and findings from national level vwtn studies which have been more extensively analyzed to subnational networks the results obtained for the higher order metrics assortativity and clustering show that subnational vtwns share some common characteristics with several other kinds of networks e g social infrastructural and technological networks overall we find that the collective properties of the vwtns analyzed set them apart from complex networks commonly studied in the literature this might be due to vwtns being derived networks whose functioning ultimately depends on multiple interacting factors e g water availability economic activity social connections demographics transportation of commodities and information exchange and their associated networks this observation seems supported by the log normal distributions obtained for the weighted vwtns given that the log normal distribution can be seen as maximum entropy realizations of the product of multiple independent variables to corroborate the regional structure of virtual water flows modularity was used together with an optimization algorithm the use of modularity allows identifying communities based on the topology of the network in this sense the communities can be said to emerge naturally from the connectivity of the network we found that the agricultural and industrial vwtns exhibit community structure fig 4 that is both networks are characterized by spatially coherent regions of intense trade activity and virtual water exchanges an overarching reason for the regionalization of subnational vwtns is due to the combined effects of industry specialization and agglomeration as well as the dispersion of commodity production industry specialization and agglomeration can attract similar and co dependent industries to a particular geographic area fujita et al 1999 the outputs from those industries may be used by other geographically collocated industries to generate different products ellison et al 2010 this process of industry specialization agglomeration and collocation can ultimately lead to a regional intensification of trade activity fujita et al 1999 at the same time industry dispersion can result in the relatively widespread production of certain staple products across the country for example commodities such as wheat corn and beef cattle are produced and available in all the communities identified in the agricultural vwtn such dispersed production can lead to regional trade patterns due to transportation costs the communities in the vwtns seem to be influenced by hydrological features for example the southwest community in the agricultural vwtn is encompassed by roughly three major watersheds california lower colorado and great basin and the mississippi community is organized around the mississippi river furthermore the communities detected in the agricultural vwtn tend to resemble the spatial boundaries of the us army corps of engineers usace divisions usace 2018 these usace boundaries originally emerged from the interaction of multiple co evolving factors with water being one key factor this specific role of water in the topology of the agricultural vwtn seems to be captured by the virtual water flows the ppml gravity model performed reasonably well in estimating agricultural and industrial virtual water flows the model demonstrated that the interactions between the spatial patterns of water use and the economic demand driving those patterns can be captured to first order by few key factors e g distance gdp population and arable land the network model suggests that it might be feasible to reconstruct subnational vwtns using the key factors identified for years where trade data are not available this is currently a key impediment to the analysis of the temporal evolution of subnational vwtns the time series reconstruction of subnational vwtns could facilitate in the future studying how different socioeconomic and environmental drivers influence the network dynamics the network model was also used to assess the community structure of the modeled vwtns the model was able for the most part to reproduce the empirical communities it did not completely identify the southwest and mississippi communities fig 5a in the agricultural vwtn this seemed mainly due to the effect of hydrological features on trade patterns for instance the watersheds that roughly conform the southwest community could be acting as a natural barrier to trade in the case of the mississippi community the water transportation mode is dominant with inland waterways serving as a commodity exchange corridor the network model employed is more representative of virtual water trade associated with the truck transportation mode since truck transportation is by far the most dominant mode 4 2 policy implications and future directions the seeming reflection of the us highway system on the degree distributions of the agricultural vwtn suggests that transportation patterns can interact with spatial water use patterns to influence virtual water flows for instance the ability to reallocate production within a country based on insights from global virtual water flow studies will be constrained by transportation infrastructure these sectors will need to be jointly analyzed at the subnational level to assess the feasibility of any production reallocation strategy this would require however resolving commodity flows down to the level of individual transportation networks e g major highways additionally this implies that global virtual water strategies for water stress will need to account for the spatial variability of subnational virtual water flows to be effective since subnational virtual water flows show distinct spatial community organization the community structure found for the subnational vwtns may be particularly relevant to regional hydroeconomic analysis for example in the context of the food water nexus the communities in the agricultural vwtn identify regions where the coupling between the biophysical and economic geography is particularly strong these are regions where stresses e g droughts or economic shocks are likely to spread to neighboring nodes and where virtual water feedbacks arising from the interactions between production and consumption nodes may be strong furthermore a key initial step in the analysis of any complex coupled natural human system and often one that is challenging to perform for highly interconnected systems is the identification of relevant system boundaries the communities identified could potentially serve as boundaries to support more detailed regional studies of the interactions between water resources and other economic sectors the communities could also be used to identify coherent geographic areas for coordinating water resources policy e g in the design of regional water use reduction strategies through combined production and consumption side interventions for example the usace boundaries are used in planning and management decisions for water related projects the communities identified could be used to provide a broader spatial and system wide context to those decisions and to better understand how changes in water use might propagate across space in summary using aggregated agricultural and industrial commodity classes we were able to reveal the presence of community structure in and model virtual water flows for subnational vwtns future work could consider individual commodity classes and their economic interdependencies to account for the effects of intermediate and final demands on virtual water flows this could be done using a multiregional input output model which have been widely used to analyze global vwtns distefano and kelly 2017 additionally the use of an input output model would facilitate our ability to study the propagation of shocks distefano et al 2018 and would allow performing different economic analyses e g spillover and feedback effects on subnational vwtns acknowledgments this material is partially based upon work supported by the national science foundation nsf under grant no aci 1639529 any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of the nsf we are thankful to the two anonymous reviewers whose comments helped improve the overall quality of the original manuscript supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 06 013 appendix supplementary materials image application 1 
621,virtual water flows have been extensively analyzed at the national level using complex network approaches however less is known about the regional structure of subnational virtual water flows even though virtual water flows can vary greatly within a country additionally subnational level studies are needed since water policy and decision making tend to be local or regional in scope here we characterize and model virtual water flows for aggregated agricultural and industrial commodities at the us subnational level using subnational trade data for the us we build and analyze unweighted and weighted directed virtual water trade networks vwtns to model and explore the drivers of subnational virtual water flows we build and implement a gravity type spatial interaction model using different network metrics we find that the subnational vwtns differ from previous well studied networks including national level vwtns the network metrics also show a high connectivity for the unweighted vwtns with no community structure while the weighted vwtns reveal spatially coherent communities of intense trade activity the gravity model shows that the subnational weighted vwtns are mainly controlled by distance agricultural land gross domestic product and population despite the high connectivity of the vwtns the presence of community structure indicates that large volumes of virtual water are traded regionally this suggests the possibility of having hydroeconomic boundaries that differ from known physical boundaries e g watersheds and aquifers such boundaries could have implications for the design of consumption based strategies for water sustainability keywords complex networks water consumption network science modularity water footprint 1 introduction water is embodied or virtually present in every step of economic production processes allan 2010 2011 linking water to all sectors of the product economy to study the dependence of the product economy on water one can analyze the virtual water flows entering and leaving a geographic area due to the trade of commodities distefano and kelly 2017 fracasso 2014 hoekstra and mekonnen 2012 konar et al 2011 sartori and schiavo 2015 such flows form a virtual water trade network vwtn when the interconnections among multiple geographic areas are considered vwtns can be used to understand and potentially enhance water sustainability particularly when combined with water scarcity information distefano and kelly 2017 vanham et al 2018 or environmental cost metrics soligno et al 2017 2019 for example vwtns can be used to foster greater shareholder accountability of water resources hoekstra 2009 hoekstra and mekonnen 2012 ridoutt and pfister 2010 wichelns 2001 identify systemic drivers of water use allan et al 2015 distefano et al 2018 suweis et al 2013 and devise innovative strategies for alleviating water stress chapagain and hoekstra 2006 dalin et al 2014 dang et al 2015 distefano and kelly 2017 konar et al 2011 through network science approaches several studies have investigated the topology and evolution of national level vwtns dalin et al 2012a b konar et al 2011 sartori et al 2017 suweis et al 2011 as well as national level commodity trade networks fagiolo et al 2010 sartori and schiavo 2015 shutters and muneepeerakul 2012 fewer studies have explored and analyzed subnational level vwtns chini et al 2017 dang et al 2015 marston et al 2015 rushforth and ruddell 2016 the focus of subnational vwtn studies has been until now on food and agricultural commodities konar et al 2018 because of their high virtual water content while industrial commodities have mostly been ignored industrial commodities however can have an important influence on virtual water flows at the subnational level for instance at the subnational level some of the vwtn nodes may be cities which can have higher production outflows of industrial commodities than agricultural ones ahams et al 2017 here we use subnational trade data to characterize and model the subnational vwtns of us agricultural and industrial commodities moreover previous subnational vwtn studies have sometimes employed network metrics e g centrality metrics computed using shortest path algorithms that are unsuitable for analyzing vwtns formed from origin destination trade data dang et al 2015 these centrality metrics are useful when nodes can act as intermediate points in the distribution of a commodity e g warehouses where commodities are not being produced or transformed in the case of origin destination networks intermediate points have been removed from the data in this study we employ metrics that are consistent with origin destination networks to analyze the us subnational vwtn of agricultural and industrial commodities furthermore the tendency of nodes to form well defined groups of tightly connected nodes or communities d odorico et al 2012 which we identify and characterize here has not been explored before at the us subnational level identifying the existence of communities in networks is crucial because when present they form the building blocks of the network s topology and are capable of influencing the network s entire functioning aldecoa and marín 2013 fortunato 2010 gao et al 2018 girvan and newman 2002 for example communities play an important role in understanding and analyzing spreading processes in complex networks lin et al 2014 nguyen et al 2013 salathé and jones 2010 where they can act as barriers that restrict the spreading of cascading events to study and model vwtn flows statistical and economic models have been employed bergstrand 1985 d odorico et al 2012 duenas and fagiolo 2013 one approach has been to couple network modeling with a fitness function this approach was developed by garlaschelli et al 2004 and later applied by both suweis et al 2011 and dalin et al 2012 to national level vwtns another approach has been to use gravity models batty and mackie 1972 bergstrand 1985 hesse 2010 wilson 1967 gravity models are part of a broader category of spatial interaction models wilson 1971 which estimate network flows using the relationship between the properties e g population gross domestic product gdp and employment of two connected areas and the distance between them using spatial interaction models of the gravity type different socioeconomic flows have been modeled including commodities duenas and fagiolo 2013 information krings et al 2009 migrants davis et al 2018 and commuters guo et al 2012 simini et al 2012 to develop models that attempt to strike a balance between parsimony and fit gravity models have been used to model and identify the main controls of national level vwtns fracasso 2014 sartori et al 2017 tamea et al 2014 for example tuninetti et al 2017 recently developed a novel approach to predict vwtns using gravity models which they applied to national level virtual water flows from international food trade additionally several link prediction algorithms have been proposed based on network similarity lu and zhou 2011 these algorithms however emphasize topological or structural properties as opposed to node properties the focus on node properties e g as done in spatial interaction models is desirable to understand the drivers of flows gravity models have successfully been used to model national level vwtns fracasso 2014 sartori et al 2017 to our knowledge they have not been systematically applied to study subnational vwtns by serving as a modeling baseline for future studies we view this as a necessary step in advancing our understanding of subnational vwtns our goal with this study is twofold firstly to characterize the topology and connectivity of the us subnational vwtn of agricultural and industrial commodity flows secondly to model vwtn flows using a spatial interaction model with this goal we address the following questions how do subnational vwtns differ from other well studied complex networks including national level vwtns do subnational vwtns reveal community structure can subnational vwtn flows be modeled using spatial interaction models what are the key drivers of subnational virtual water flows how can the subnational vwtn results help inform water resources sustainability the paper is organized as follows section 2 describes the methodology and data used section 3 presents the main results lastly section 4 summarizes key conclusions and discusses the implications and limitations of our results 2 materials and methods this section describes i the data and approach used to build the empirical vwtns ii the metrics used to characterize the topology and connectivity patterns of the vwtns and iii our approach to modeling virtual water flows 2 1 empirical virtual water trade networks we built the us vwtns of agricultural and industrial commodities using the freight analysis framework version 3 faf3 commodity trade data fhwa 2018 a separate vwtn was built for the agricultural and industrial commodities the faf3 data represents for the year 2007 the annual flow of commodities for the entire us product economy by dividing the country into 123 distinct geographic origin destination areas and the economy into 43 different commodity classes to build the vwtns we considered the 120 geographical areas covering the coterminous us fig 1 and 30 different commodity classes out of these 120 areas 64 are metropolitan or consolidated statistical areas hereafter cities consisting of the largest and some of the major mid sized cities in the us we aggregated into a single area the consolidated statistical areas 6 out of the 64 in the faf3 data belonging to the same city but located in different states this resulted in a total of 112 distinct geographical areas including 64 city and 48 non city areas table s1 in the supplementary material lists the names of the 112 geographical areas fig 1 illustrates the 112 areas and provides an example of the interactions between city and non city areas the non city areas either represent i entire states that do not have a faf3 city in them or ii remainders of states consisting of the faf3 non city area of a state the 30 commodities considered include most of the faf3 agricultural and industrial commodity classes leaving out mostly the energy related and mining commodities the list of commodities used is included in table s2 of the supplementary material we multiplied the agricultural and industrial commodity flows in the faf3 data by their corresponding virtual water contents to obtain virtual water flows for each of the 30 commodity classes considered the virtual water content values were obtained from the study by ahams et al 2017 who used data from and the methodology of the water footprint network to derive the values hoekstra 2011 hoekstra and mekonnen 2012 the virtual water content estimates used are average values over the period 1996 2005 lastly to build the empirical weighted directed vwtns we first assigned a network node to each of the 112 geographic areas in the faf3 then we assigned weighted directed links in volume of virtual water traded over the year 2007 to any pair of connected nodes in the faf3 data specifically the weight of a link was determined as follows 1 w i j c τ i j c v i c where wij c m3 yr is the virtual water flow between nodes i and j for the commodity class c τij c ton yr is the faf3 commodity flow between i and j for commodity class c and vi c m3 ton is the virtual water content of commodity c in the origin node i we aggregated the commodity flows for the different agricultural classes into a single macro agricultural class the same aggregation process was performed for the industrial commodities this resulted in two aggregated weighted directed vwtns one for agricultural commodities fig 2 a and another one for industrial commodities fig 2b which are hereafter simply referred to as vwtns note that the links in the vwtns represent the total aggregated agricultural or industrial virtual water flows for every pair of origin and destination nodes in the faf3 data all of our network analysis and modeling was performed separately for these two aggregated vwtns 2 2 network metrics to compute the different network metrics we represented the n nodes in our vwtns by an n n matrix w wij of origin destination pairs each matrix element wij m3 yr is the aggregated agricultural or industrial virtual water flow from origin node i to destination node j i j 1 2 n and has a zero value assigned to it if the nodes are not linked in addition we obtained unweighted vwtns by replacing the matrix elements with binary values resulting in an adjacency matrix the unweighted adjacency matrix is denoted by a aij where the elements are equal to 1 if a virtual water flow exists between two nodes and zero otherwise the unweighted vwtns were used to isolate the connectivity of the network from the virtual water flows we employed both network configurations unweighted and weighted to analyze the agricultural and industrial vwtns for both configurations we considered the case of an asymmetric matrix with positive weights aij aji 0 1 or wij wji 0 and no self links links connecting a node to itself a ij j i 0 or w ij j i 0 the asymmetry of the adjacency matrix is a consequence of taking into account the directionality of the flows while the positivity of the weights only indicates that flows must be real positive values in the case of vwtns the directionality is crucial to properly distinguish incoming and outgoing connections at every node the exclusion of self links is justified by the fact that a relatively large fraction of the internal production of commodities at each node stays within the node for consumption or transformation these large internal flows can overshadow the dispersed demand of commodities in vwtns therefore they were omitted from our analysis one of the most common properties of a complex network is the degree distribution p k and its weighted version the strength distribution p s newman 2010 the degree ki of a node i is defined as the number of neighbors or links incident to it in the weighted version of the network node degree becomes the sum of the flows associated with node i the degree weighted degree distribution indicates the probability that a randomly chosen node has k connections s amount of flow newman 2003 both degree and weighted degree can be seen through the perspective of inflows or outflows of virtual water leading to the formulation of different degree distributions indegree kj in outdegree ki out weighted indegree sj in and weighted outdegree si out we used these different degree distributions to characterize the connectivity and flows of the agricultural and industrial vwtns to determine the degree distributions multiple theoretical cumulative distribution functions cdfs were fitted to the data and compared against each other using the akaike information criterion aic then the kolmogorov smirnov ks test was applied to the theoretical distribution with the lowest aic in addition we used the following metrics to characterize the vwtns clustering coefficient watts and strogatz 1998 assortativity leung and chau 2007 newman 2002a weighted distances tamea et al 2013 and modularity blondel et al 2008 newman 2006 the clustering coefficient c measures the tendency of the network to form groups of tightly connected nodes the assortativity ρ measures the preference of highly connected nodes to be linked to other high degree nodes the value of ρ lies in the range 1 ρ 1 with ρ 1 indicating perfect assortativity ρ 1 indicating perfect disassortativity and 0 indicating no assortative mixing or neutral assortativity the weighted distance d i measures for a node i the weighted average of the euclidean distance between each i j pair of trading partners where the weights are computed using the virtual water flows lastly the modularity q measures the presence of tightly connected groups of nodes communities in a network differently from the clustering coefficient which employs triangulated connections modularity is based on the density of links within communities the mathematical definition and interpretation of each of these metrics is provided in text s1 of the supplementary material 2 3 network model our network building algorithm consisted of two main steps analogous to both the first two steps used in transportation forecasting analysis evans 1973 schneider 2005 and the zero inflated algorithms used in economic theory to estimate zero trade flows burger et al 2009 that is the first step was used to estimate the links and the second step the weights of the network for the first step the unweighted directed vwtn was estimated using a logistic regression model barigozzi et al 2010 zanin et al 2016 as follows 2 ln y 1 y β 0 m 1 m β m x m where y identifies the activity or inactivity of a link through a linear combination of m explanatory variables xm and their corresponding parameters βm the following pool of potential explanatory variables were considered population gdp area of productive agricultural land euclidean distance latitude longitude community membership obtained from the modularity measure shared borders and type of faf3 area i e city state or remainder of state the parameters βm were estimated using maximum likelihood in the second step for the links identified as active by eq 2 the following gravity type spatial interaction model was used 3 w i j m i α 1 m j α 2 d i j α 3 where wij m3 yr same as before is the virtual water flow from node i to j mi and mj are variables representing relevant characteristics of node i and j respectively the α superscripts are the coefficients determined by regression analysis and dij is the euclidean distance between the nodes alternatively eq 3 can be written as an exponential function such that 4 w i j exp α 0 α 1 ln m i α 2 ln m j α 3 ln d i j ε i j where ε ij is the error term to estimate the parameters in eq 4 the poisson pseudo maximum likelihood ppml estimator was employed silva and tenreyro 2006 this estimator has several advantages over the traditional ordinary least squares ols approach it is independent of the underlying distribution of the data silva and tenreyro 2006 accounts for heteroskedastic error terms burger et al 2009 fracasso 2014 silva and tenreyro 2006 and preserves the total amount of flows arvis and shepherd 2013 when applied to gravity models the ppml has been shown to result in more consistent parameter estimates than ols over a wide range of conditions silva and tenreyro 2011 to select the explanatory variables for eqs 2 and 4 we used stepwise regression with a selection criterion of p values 0 05 the stepwise regression was applied separately to the agricultural and industrial vwtns however for each network the same set of variables were used to implement eqs 2 and 4 thus the same variables or node characteristics are used to both generate links and assign weights to each link in addition to compute all the network metrics and apply the network model the smallest virtual water flows consisting of less than 5 of the total flows were not considered for both the agricultural and industrial vwtns because they tended to deviate from the rest of the flows 3 results this section presents the results for the characterization and modeling of the vwtns the characterization results are separated into i degree distributions and assortativity and ii weighted distances clustering coefficient and modularity while the modeling results are separated into i unweighted and ii weighted vwtns 3 1 characterization of the virtual water trade networks 3 1 1 degree distributions and assortativity to characterize the topology and connectivity patterns of the vwtns we first analyzed the degree distributions of the unweighted and weighted versions of the agricultural and industrial networks the indegree and outdegree cdfs of the agricultural vwtn tended both to be approximately normal with p values of 0 22 and 0 69 for the ks test respectively the probability density functions pdfs and cdfs for the unweighted networks are shown in figures s1 and s2 respectively of the supplementary material the average degree of both the indegree and outdegree distributions was approximately 80 connections indicating a high connectivity since the total number of nodes is 112 for the indegree and outdegree cdfs of the industrial vwtn not shown we found that every node in the network is connected to all the other nodes indicating the network is complete the weighted indegree and outdegree cdfs for both the agricultural fig 3 a and b and industrial fig 3c and d networks tended to be approximately log normal the pdfs are shown in figure s1 of the supplementary material such peaked distributions are generally a distinguishing feature of spatially embedded networks barthelemy 2011 the p values for the ks tests were 0 65 and 0 99 for the agricultural weighted indegree and outdegree distributions respectively and 0 72 and 0 89 for the industrial weighted indegree and outdegree distributions respectively using assortativity to assess the connectivity of the networks we found that the unweighted and weighted versions of both the agricultural and industrial vwtns are characterized by an almost neutral slightly negative assortativity table 1 the significance of the assortativity results was assessed by computing the standard error following the approach of newman 2002b the generally small standard errors in table 1 relative to the values of the assortativity ρ indicate that ρ tends to be strong this means that for both vwtns the degree and the strength of the nodes are not strong determinants of the networks connectivity pattern the slightly negative assortativity values indicate that in this case nodes with relatively higher virtual water outflows inflows are slightly more frequently and strongly connected to nodes with relatively lower virtual water outflows inflows similar assortativity behavior is displayed by some technological networks such as the world wide web newman 2002a the slightly negative assortativity also indicates the absence of the rich club phenomena displayed by several social networks and linear preferential attachment network models newman and girvan 2002 this is useful because it highlights that nodes in the vwtns some of which at first sight might appear dominant e g nodes representing large cities such as new york or los angeles are connected to or dependent on nodes with heterogeneous degrees and strengths thus the structure of the vwtns is more subtle than implied by metrics used to assess node strength which in contradistinction are considered important for characterizing national level vwtns 3 1 2 weighted distances clustering coefficient and modularity to assess the effect of the spatial distribution of nodes on the vwtns we used the weighted average distance of virtual water flows this metric is useful because it allows to directly measure independently of any network based algorithm the potential for nodes to have a regional influence the expected value of the weighted average distance of outflows and inflows is 616 and 719 kms respectively for the agricultural vwtn and 893 and 917 kms respectively for the industrial vwtn figure s3 in the supplementary material illustrates the weighted average distance for a few selected nodes which were selected to include large and small cities as well as non city areas these weighted average distances indicate that most of the virtual water flows have a regional extend e g the average euclidean distance between the us west and east coasts is approximately 4040 kms this is in contrast with the national reach implied by the high connectivity displayed by the different versions of the degree distributions to further explore the regional characteristics of the vwtns we used the network clustering coefficient and modularity measure we found the network clustering coefficient is relatively high for both the agricultural c 0 77 and industrial c 0 69 vwtns as compared to the random version of both graphs c 0 35 and c 0 5 respectively the c values for the random networks had standard deviations 0 01 a high clustering coefficient for both vwtns confirms that there is a tendency in the networks to form clusters or communities in addition considering both the almost neutral assortativity and weighted average distance of the vwtns communities can be expected to be formed by nodes with diverse levels of connectivity degree or weighted degree and to be spatially constrained indeed using the community detection algorithm of blondel et al 2008 we found 7 and 5 spatially distinct communities for the agricultural fig 4 a and industrial fig 4b vwtns respectively note that the detection algorithm does not employ any information about the location or distance of nodes an alternative could have been that communities were present but in a geographically discontiguous fashion the presence of communities implies that intra community virtual water trade is stronger than inter community trade the intra and inter community virtual water trade is illustrated in fig 4c and d using chord diagrams for the agricultural and industrial vwtns respectively the seven communities identified in the agricultural vwtn are as follows fig 4a the north atlantic region traditionally characterized by its relatively early historical development and current high levels of urbanization the south atlantic region grouped together with the piedmont atlantic region extends to the north of the country partially covering the great lakes area the mississippi valley region characterized by its major inland waterways the midwest region covering part of the bread basket and upper mississippi watershed the southwestern region known for the texas triangle megaregion and gulf coast ports the northwestern region covering the cascadia megaregion and inland states towards the rocky mountains and the south pacific region primarily covering california and extending towards nevada arizona and new mexico the regions identified in the industrial vwtn fig 4b are more aggregated than in the agricultural vwtn fig 4a for example the west portion of the country is aggregated into one larger region in the industrial vwtn the mississippi region disappears because in contrast with agricultural commodities inland waterways are not a prevalent transportation mode for industrial commodities also slightly different configurations of the north atlantic south atlantic southwest and midwest regions are seen in the industrial vwtn fig 4b in addition we tested whether the unweighted agricultural vwtn is characterized by community structure and found that it is not the unweighted industrial vwtn was not tested since it is a complete graph for the agricultural vwtn this means that the communities do not emerge from the adjacency matrix which is shared by the native faf3 data moreover the native faf3 networks with flows in units of tonnage or dollars were also analyzed for community structure results now shown communities also emerged for those networks but differed somewhat both in the number of communities and node assignments from the ones found with the vwtns 3 2 modeling of the virtual water trade networks 3 2 1 unweighted virtual water trade networks using our two step network model we found the following logistic regression model gives the best performance for the unweighted agricultural vwtn 5 ln y 1 y 0 45 5 58 10 4 d i j 3 5 10 7 p j 2 65 10 8 a i where y is the probability of the origin node i being connected to the destination node j pj number of persons is the population at the destination node j and ai km2 is the area of productive agricultural land at the origin node i based on the standardized coefficients for eq 5 we found that population at the destination node is the most dominant variable followed by area of productive agricultural land at the origin node and finally by distance table 2 note that the standardized coefficients are comparable among themselves regardless of the units of their corresponding variables by comparing the model in eq 5 against the empirical vwtn obtained from the faf3 data we found the accuracy of the model is approximately 70 accuracy was calculated as the fraction of links active and inactive that were correctly predicted by the model the unweighted agricultural vwtn showed a tendency to be normally distributed figure s2 and to be characterized by neutral assortativity since this suggests the network may be structurally similar to a random network which is typically reproduced with the erdös rényi er model erdös and rényi 1959 the er model was used as an alternative link generation model to evaluate against the logistic regression in eq 5 the er model is employed because even though it is characterized by a poisson distribution in the large limit a poisson distribution can be approximated by a gaussian distribution the er model was employed to generate the unweighted agricultural vwtn and it misclassified 50 of the flows active and inactive comparing the performance of the er model against that of eq 5 it is seen that the connections among nodes in the unweighted agricultural vwtn are not merely random but are influenced by node properties relevant to agricultural commodity production consumption and trade for the industrial vwtn since the network is a complete graph we simply connected every node to the rest of the nodes instead of using the logistic regression model for this same reason the er model was not tested for the unweighted industrial vwtn 3 2 2 weighted virtual water trade networks from the predicted connections implied by eq 5 in the case of the agricultural vwtn and assuming a complete graph in the case of the industrial vwtn we assigned weights to each connection using a gravity type model the explanatory variables for each node in the model were selected from the pool of variables through stepwise regression for consistency the variables for the agricultural vwtn are the same ones used in eq 5 the fitted gravity models for the agricultural and industrial vwtns were respectively 6 w i j exp 10 48 1 41 ln d i j 0 57 ln a i 0 077 ln p j and 7 w i j exp 0 14 1 28 ln d i j 0 97 ln p i 0 70 ln p j 0 34 ln g i where pi number of persons is the population at the origin node i and gi dollars is the gdp at the origin node i all the other variables were previously defined table 2 shows the standardized coefficients for eqs 6 and 7 the coefficients indicate that distance with a negative correlation is the strongest determinant of virtual water trade for both the agricultural and industrial commodities the agricultural vwtn is also highly positively driven by the availability of agricultural land while the industrial vwtn is more strongly driven by the population and gdp of the sending and receiving nodes respectively the fitted gravity models performed reasonably well in estimating virtual water flows with r 2 values of 0 56 and 0 63 for the agricultural and industrial networks respectively these r 2 values compare well with previous applications of gravity models for estimating subnational level socioeconomic flows masucci et al 2013 simini et al 2012 and national level virtual water flows tamea et al 2014 the r2 values were calculated using the kullback leibler divergence see text s2 of the supplementary material since the network model is nonlinear cameron and windmeijer 1997 we also computed the correlation between the flows estimated by eqs 6 and 7 and the empirical flows we found the correlations to be 0 48 and 0 62 for the agricultural fig 5 a and industrial fig 5d vwtns respectively we determined the total inflows and outflows i e weighted indegree and outdegree at each node from the gravity model and compared those values against the empirical ones we found that the estimated and empirical values of the total inflows and outflows are reasonably correlated for both the agricultural fig 5b and c and industrial fig 5e and f vwtns the inflow and outflow correlations are 0 6 and 0 86 respectively for the agricultural vwtn and 0 83 and 0 74 respectively for the industrial vwtn the correlation of virtual water flows for the agricultural vwtn fig 5a is lower than the other correlations possibly due to the aggregation of commodity classes by aggregating all the agricultural and industrial commodities into macro commodity networks we are unable to represent and track the effect of regional specialization industrial agglomeration or product differentiation on the network in addition we tested the ability of the gravity models to reproduce the community structure found in the empirical networks fig 6 the modeled agricultural and industrial vwtn communities fig 6a and b are for the most part comparable to the communities in the empirical networks fig 4a and b notwithstanding a few differences the similarity between the empirical and modeled communities is noteworthy given that the models were only based on a few node properties the differences are more evident in the agricultural vwtn than in the industrial network for example in the modeled agricultural vwtn the west portion of the country is consolidated into one single community fig 6a whereas the empirical network shows two separate communities fig 4a also for the community covering the mississippi river in the empirical agricultural vwtn fig 4a the modeled network only detects the lower mississippi river area fig 6a 4 discussion and conclusion network science has identified a set of unifying structural properties shared by many real world complex networks boccaletti 2006 to quantify those properties network metrics and models are used here we used the network metrics of degree distribution clustering coefficient assortativity weighted distances and modularity as well as a spatial interaction network model to explore the topology and connectivity patterns of the us subnational agricultural and industrial vwtns subnational level studies are needed to bring the insights gained from applying network science to vwtns down to the spatial scales at which water resources decision and policy making take place and to better understand the ability to translate findings from national level studies to subnational vwtns in this study we have for the first time at the us subnational level characterized the degree and weighted degree distributions of agricultural and industrial vwtns identified the regional community structure of agricultural and industrial virtual water flows and benchmarked the ability of gravity type models to estimate subnational virtual water flows the interpretation limitations and implications of these findings are discussed next 4 1 interpretation and limitations of results we found the degree distributions indegree and outdegree of the agricultural vwtn tend to be approximately normal figure s2 the network degrees of the us highway system where major cities are the nodes connected by highways are normally distributed barabasi and bonabeau 2003 since trucking is the main mode of transportation for agricultural commodities it seems likely that the connectivity pattern of the highway system is reflected in the unweighted agricultural vwtn the unweighted industrial vwtn was found to be a complete graph due to the high connectivity of nodes this high connectivity is not surprising since our industrial vwtn combines 25 different faf3 industry classes making it very likely that every node produces consumes different industry products that are consumed produced by the other nodes in the network this result highlights the need to analyze in the future the industrial vwtns for individual commodity classes as they are more likely to reveal unique connectivity patterns the log normal peaked distribution of weighted connections for both the agricultural and industrial fig 4 vwtns is characteristic of spatially embedded networks where geographical space and distance play a fundamental role in the network structure barthelemy 2011 indeed the distribution not shown of the euclidean distance of virtual water flows for the agricultural and industrial vwtns were also found to be approximately log normally distributed supporting our observation that distance is a key factor influencing the configuration of the subnational networks this is because distance acts as a friction on trade through transportation costs and travel times the log normal distribution of the virtual water flows also supports the ability to use gravity type models with subnational vwtns and it clearly differentiates the agricultural and industrial vwtns from many other well studied complex networks characterized by power law distributions garlaschelli and loffredo 2004 girvan and newman 2002 networks with power law distributions are often modeled with linear preferential attachment models such models without additional refinements would generally not be adequate for modeling subnational agricultural and industrial vwtns national level vwtns do seem to be characterized by power law distributions carr et al 2013 distefano et al 2018 sartori et al 2017 which may be due to nations having strong individual interests the effect of trade agreements and distance having a lesser role than in the subnational vwtns this indicates that one needs to be careful in translating methods and findings from national level vwtn studies which have been more extensively analyzed to subnational networks the results obtained for the higher order metrics assortativity and clustering show that subnational vtwns share some common characteristics with several other kinds of networks e g social infrastructural and technological networks overall we find that the collective properties of the vwtns analyzed set them apart from complex networks commonly studied in the literature this might be due to vwtns being derived networks whose functioning ultimately depends on multiple interacting factors e g water availability economic activity social connections demographics transportation of commodities and information exchange and their associated networks this observation seems supported by the log normal distributions obtained for the weighted vwtns given that the log normal distribution can be seen as maximum entropy realizations of the product of multiple independent variables to corroborate the regional structure of virtual water flows modularity was used together with an optimization algorithm the use of modularity allows identifying communities based on the topology of the network in this sense the communities can be said to emerge naturally from the connectivity of the network we found that the agricultural and industrial vwtns exhibit community structure fig 4 that is both networks are characterized by spatially coherent regions of intense trade activity and virtual water exchanges an overarching reason for the regionalization of subnational vwtns is due to the combined effects of industry specialization and agglomeration as well as the dispersion of commodity production industry specialization and agglomeration can attract similar and co dependent industries to a particular geographic area fujita et al 1999 the outputs from those industries may be used by other geographically collocated industries to generate different products ellison et al 2010 this process of industry specialization agglomeration and collocation can ultimately lead to a regional intensification of trade activity fujita et al 1999 at the same time industry dispersion can result in the relatively widespread production of certain staple products across the country for example commodities such as wheat corn and beef cattle are produced and available in all the communities identified in the agricultural vwtn such dispersed production can lead to regional trade patterns due to transportation costs the communities in the vwtns seem to be influenced by hydrological features for example the southwest community in the agricultural vwtn is encompassed by roughly three major watersheds california lower colorado and great basin and the mississippi community is organized around the mississippi river furthermore the communities detected in the agricultural vwtn tend to resemble the spatial boundaries of the us army corps of engineers usace divisions usace 2018 these usace boundaries originally emerged from the interaction of multiple co evolving factors with water being one key factor this specific role of water in the topology of the agricultural vwtn seems to be captured by the virtual water flows the ppml gravity model performed reasonably well in estimating agricultural and industrial virtual water flows the model demonstrated that the interactions between the spatial patterns of water use and the economic demand driving those patterns can be captured to first order by few key factors e g distance gdp population and arable land the network model suggests that it might be feasible to reconstruct subnational vwtns using the key factors identified for years where trade data are not available this is currently a key impediment to the analysis of the temporal evolution of subnational vwtns the time series reconstruction of subnational vwtns could facilitate in the future studying how different socioeconomic and environmental drivers influence the network dynamics the network model was also used to assess the community structure of the modeled vwtns the model was able for the most part to reproduce the empirical communities it did not completely identify the southwest and mississippi communities fig 5a in the agricultural vwtn this seemed mainly due to the effect of hydrological features on trade patterns for instance the watersheds that roughly conform the southwest community could be acting as a natural barrier to trade in the case of the mississippi community the water transportation mode is dominant with inland waterways serving as a commodity exchange corridor the network model employed is more representative of virtual water trade associated with the truck transportation mode since truck transportation is by far the most dominant mode 4 2 policy implications and future directions the seeming reflection of the us highway system on the degree distributions of the agricultural vwtn suggests that transportation patterns can interact with spatial water use patterns to influence virtual water flows for instance the ability to reallocate production within a country based on insights from global virtual water flow studies will be constrained by transportation infrastructure these sectors will need to be jointly analyzed at the subnational level to assess the feasibility of any production reallocation strategy this would require however resolving commodity flows down to the level of individual transportation networks e g major highways additionally this implies that global virtual water strategies for water stress will need to account for the spatial variability of subnational virtual water flows to be effective since subnational virtual water flows show distinct spatial community organization the community structure found for the subnational vwtns may be particularly relevant to regional hydroeconomic analysis for example in the context of the food water nexus the communities in the agricultural vwtn identify regions where the coupling between the biophysical and economic geography is particularly strong these are regions where stresses e g droughts or economic shocks are likely to spread to neighboring nodes and where virtual water feedbacks arising from the interactions between production and consumption nodes may be strong furthermore a key initial step in the analysis of any complex coupled natural human system and often one that is challenging to perform for highly interconnected systems is the identification of relevant system boundaries the communities identified could potentially serve as boundaries to support more detailed regional studies of the interactions between water resources and other economic sectors the communities could also be used to identify coherent geographic areas for coordinating water resources policy e g in the design of regional water use reduction strategies through combined production and consumption side interventions for example the usace boundaries are used in planning and management decisions for water related projects the communities identified could be used to provide a broader spatial and system wide context to those decisions and to better understand how changes in water use might propagate across space in summary using aggregated agricultural and industrial commodity classes we were able to reveal the presence of community structure in and model virtual water flows for subnational vwtns future work could consider individual commodity classes and their economic interdependencies to account for the effects of intermediate and final demands on virtual water flows this could be done using a multiregional input output model which have been widely used to analyze global vwtns distefano and kelly 2017 additionally the use of an input output model would facilitate our ability to study the propagation of shocks distefano et al 2018 and would allow performing different economic analyses e g spillover and feedback effects on subnational vwtns acknowledgments this material is partially based upon work supported by the national science foundation nsf under grant no aci 1639529 any opinions findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the view of the nsf we are thankful to the two anonymous reviewers whose comments helped improve the overall quality of the original manuscript supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 06 013 appendix supplementary materials image application 1 
622,dynamic behavior of extreme rainfall characteristics heightened by the abrupt warming of the environment has affected the sustainability of the existing water resources systems and infrastructure which were designed employing the traditional stationary assumption here we propose a realistic and efficient framework to detect non stationarity in the observed hydrologic variables to overcome a few limitations suffered by the traditional non stationary approaches the methodology is demonstrated over the short period rainfall series of four major metropolitan cities of india where the intensity of the rainfall is reportedly increasing sharply accompanied by the changes in the pattern of rainfall since direct runoff is influenced by the intensity and duration of rainfall it is important to study the joint characteristics of intensity and duration in the context of non stationarity especially in urban regions where the relationship is more distinct hence we estimated the time varying joint return period return level of its extremes utilizing a dynamic bayesian copula we have implemented time varying multivariate probability frequency analysis to derive the time varying intensity duration relationship here we employed a bayesian approach through differential evolution markov chain de mc algorithm to estimate the uncertainty bound of the time varying return level the results emphasize that the probabilistic distribution parameters vary both temporally and spatially and recommend the incorporation of non stationarity in the extreme event modeling only if there is a change in the probabilistic distribution parameters this non stationary model can be seamlessly employed to compute return levels with better accuracy and reliability than traditional stationary non stationary methods we observe that the short duration return level increases at a faster rate than the longer ones with the credibility interval larger than that of long duration return levels the results also highlight the importance of adopting event based non stationary idf curves for the design of water resource systems and to devise long term decision making strategies to address the changing climate however we do not draw any conclusion concerning climate change in general from the short duration rainfall records used in this study keywords non stationarity bayesian inference return period return level copula 1 introduction abrupt changes in the frequency and magnitude of extreme hydroclimatological events across the world have triggered major threats to human life infrastructure and agriculture thereby adversely impacting the society and economy according to the intergovernmental panel on climate change ipcc special report on extremes srex the risks due to the impact of extreme events on populations and assets have risen beyond expectation ipcc 2012 additionally numerous studies report that the magnitude and frequency of extreme precipitation is increasing faster than the average precipitation in the recent decades and demand a paradigm shift in the adaptation management of hydrological events aguilar et al 2005 alexander et al 2006 gordon et al 1992 goswami et al 2006 vinnarasi and dhanya 2016 vittal et al 2013 this is particularly pertinent to the design of hydraulic structures such as dams sewers and stormwater drainage networks which are traditionally designed on the assumption of a stationary climate cheng et al 2014 sarhadi et al 2016 sarhadi and soulis 2017 the term stationary extreme event modeling assumes that the probabilistic distribution parameters herein called distribution parameters and exceedance probability of events are unchanging over time jakob 2013 nevertheless it is apparent that extreme events are changing and are likely to change in the future milly et al 2008 which in turn puts doubt on the reliability of the stationary methods this prompts the necessity for upgrading the existing methodologies to estimate the exceedance probability of different hydrological variables by incorporating the dynamic behavior of the ever changing climate cancelliere 2017 salas and obeysekera 2014 zwiers et al 2013 traditionally non stationarity in a time series is addressed using differencing detrending approaches cave beatrice m and pearson 1914 khaliq et al 2006 these methods remove the inherent natural variability in the time series however khaliq et al 2006 this can be overcome by modelling the non stationarity in the form of changing distribution parameters over time generally approximated using a linear or non linear trend agilan and umamahesh 2016 cheng et al 2014 cheng and aghakouchak 2015 coles 2001 el adlouni et al 2007 katz et al 2002 luke et al 2017 mondal and mujumdar 2015 risser and wehner 2017 sarhadi and soulis 2017 steirou et al 2018 sugahara et al 2009 yilmaz and perera 2014 zhang et al 2015 zhang and zwiers 2013 the concept of non stationarity was first introduced through univariate hydrologic frequency analysis owing to its mathematical simplicity mishra and singh 2011 singh and zhang 2007 but univariate analysis may not be adequate for all cases especially for integrated flood drought risk management and may not capture all hydrologic hydraulic design risks appropriately chebana and ouarda 2011 katz et al 2002 schumann 2017 hence multivariate modeling incorporating temporal dynamics in the marginal distribution was proposed by chebana and ouarda 2011 which is enhanced by employing copulas to develop multi variate non stationary models of storm events corbella and stretch 2013 and severity duration frequency curves kwon and lall 2016 moreover copula based multivariate non stationary analysis can be further improved by incorporating dynamic behavior into the dependent structure jiang et al 2015 sarhadi et al 2016 non stationary modeling is further improved by incorporating multiple time varying distribution parameters traditional non stationary models here on abbreviated as traditional nsm addressing non stationarity have considered temporal variation of either only location parameter or different combinations of distribution parameters for example past studies have addressed non stationarity by changing either location agilan and umamahesh 2017b cheng and aghakouchak 2015 sarhadi et al 2016 or both location and scale parameters agilan and umamahesh 2017a cheng et al 2014 sarhadi and soulis 2017 few studies have determined the best parameter combination by considering all possible combinations of the parameters and choosing the best one based on an information criterion agilan and umamahesh 2017a sarhadi and soulis 2017 such approaches increase the complexity and uncertainty in modeling especially while adopting a multivariate analysis and also lack any realism in bringing out the non stationary characteristics of the time series a non stationary process essentially implies change s in the statistical properties like mean variance skewness or distribution parameters over time coles 2001 and not necessarily a trend in the variable hence the above traditional nsm approaches are questionable since the presence of mere trend may not be sufficient to ensure non stationarity in the time series even though the trend in the time series will indeed reflect as variations in the distribution parameter s in general the trend in the time series may be reflected as variations non stationarity in the mean but may not necessarily cause any changes in other parameters another possibility is that a time series can be non stationary even if it does not exhibit any significant trend e g the dynamic behavior in the variance of the events may not be reflected in the trend the lack of conviction on the necessity of non stationary modeling even for a non stationary time series ganguli and coulibaly 2017 might be due to the possible flaws in the approaches which are based merely on the existence of trend and selection of best combinations as explained earlier to counter the limitations mentioned above it is necessary to detect the signature of non stationarity in the distribution parameters rather than the mere trend in the original time series before finalizing the technique of modeling sadegh et al 2015 if non stationarity is not evident in the parameters it is reasonable to use a stationary model with known uncertainty hence we propose a modified approach to bring realism into the selection of stationary non stationary model considering the importance of detection of non stationarity and the need of enhanced methodology in time varying multivariate extreme event modeling the focus of this study is to develop an innovative approach to detect the non stationarity in the distribution parameters and to apply a robust technique for time varying multivariate risk analysis utilizing bayesian inference according to authors knowledge time varying bivariate intensity duration modeling has not yet been attempted the proposed methodology is used to develop storm intensity duration models for four major metropolitan cities of india as short duration high intensity rainfall events reportedly increasing agilan and umamahesh 2017b cheng et al 2014 ganguli and coulibaly 2017 sarhadi and soulis 2017 especially over urbanized regions shastri et al 2015 vittal et al 2013 2 data and methodology 2 1 study area and data description in the present study we selected four major metropolitan cities in india bengaluru formerly bangalore mumbai formerly bombay kolkata formerly calcutta and chennai formerly madras which are the state capitals of karnataka maharashtra west bengal and tamil nadu states respectively see details in section s1 of supplementary information the autographic hourly rainfall data of these cities is procured from the indian meteorological department imd the choice of the four datasets used in the study is strictly based on the availability of high resolution station data with reasonable temporal coverage however the methodology is generic and can be applied to any dataset with varying characteristics the station numbers duration of the data available and missing data information are given in table 1 2 2 methodology the steps involved in computing the non stationary return levels are outlined here firstly the storm events are extracted from the rainfall series using event based approach then the extreme storm attributes viz intensity and duration are also extracted using peak over threshold pot method then each attribute is fit into a suitable marginal distribution a suitable copula is selected further the distribution and copula parameters are then checked for non stationarity using time sliding window tsw approach if a parameter exhibits significant non stationarity it is modeled as linear time varying parameter else it is kept constant the marginal parameters along with their uncertainty bounds are estimated using bayesian inference which is the first stage bayesian then the joint distribution of both the attributes are computed using copula and the copula parameter is estimated along with its uncertainty bound using bayesian inference which is the second stage bayesian finally the joint extreme characteristics like return level rl and return period are computed the overall procedure adopted in the computation of non stationary joint rl is given in figure s1 the above steps are briefly explained in the following subsections 2 2 1 definition and extraction of storm events storm events are characterized using the concept of inter event time definition ietd ariff et al 2012 which is based on the minimum duration of a dry spell between two successive storm events and ensures the statistical independence between the events we have fixed ietd as 6 h for the present study since all the four stations are in urban catchments ariff et al 2012 huff 1967 palynchuk and guo 2008 the total accumulated rainfall in a storm event is defined as storm depth the total length of a storm event is storm duration while the ratio of storm depth to storm duration is termed as storm intensity over the study region the duration of storm events are reportedly reducing without any significant change in the storm depth singh et al 2014 vinnarasi and dhanya 2016 vittal et al 2013 hence in order to model the dynamic behavior of the longer and shorter duration high intensity storm events we employed the pot method to extract the storm depths exceeding the 90th percentile threshold since it ensures the selection of at least one event per year the corresponding storm duration and average storm intensity are also computed for more information on ietd and pot please refer to section s2 of supplementary information 2 2 2 marginal distribution of storm events and its dependence structure once the extreme storm attributes i e storm duration and storm intensity are extracted it is necessary to identify the suitable marginal distribution of each attribute and its dependence structure to detect the changing parameter the two attributes strongly correlate with each other and possess unique probabilistic characteristics ariff et al 2012 singh and zhang 2007 the joint distribution between these two variables considering the dissimilarity in their probabilistic characteristics is computed employing copulas sklar 1959 copulas are functions that join or couple the multivariate distribution into their one dimensional marginal distribution functions in which the multivariate distribution is based on a univariate probability distribution regardless of their structure or type nelsen 2006 firstly appropriate marginal probability distributions need to be identified for average storm intensity and storm duration while conventional practice is to adopt either a gamma or lognormal distribution for storm intensity and an exponential distribution for storm duration menabde and sivapalan 2000 these distributions may not always guarantee a good fit ariff et al 2012 menabde and sivapalan 2000 singh and zhang 2007 hence a well fitted distribution for each station is found from a basket of eight different distributions namely generalized extreme value gev generalized pareto gp lognormal gamma exponential weibull gumbel and logistic using the kolmogorov smirnov test k s test and bayesian information criterion bic the expressions used for computing the distribution and their parameters are given in table 2 after finding the best fit marginal distribution a suitable copula should be selected to model the dependence structure between storm intensity and storm duration based on the correlation between the random variables the archimedean copula family comprising nearly 22 copula families is chosen in this study since the copula function from this family is utilized extensively in hydrological frequency analysis brunner et al 2016 de michele and salvadori 2003 favre et al 2004 salvadori and de michele 2004 singh and zhang 2007 the primary advantage of archimedean copula over other families of copula is its mathematical simplicity and its applicability despite the positive or negative correlation among hydrologic variables since the correlation between intensity and duration is known to be negative the suitable copulas among the archimedean family are ali mikhail haq and frank copulas ariff et al 2012 singh and zhang 2007 while the ali mikhail copula is not recommended for significantly negative correlated random variables the frank copula is successfully utilized by many studies for various hydrological analysis ariff et al 2012 de michele and salvadori 2003 singh and zhang 2007 hence the frank copula a one parameter archimedean copula that allows maximum range of dependence i e positive and negative dependence is deployed in this study and is expressed as 1 c u v 1 θ ln e θ 1 1 e θ 1 e θ u 1 e θ v θ r 0 where u f it μ σ ξ v f dt μ σ θ is the copula parameter which is related to the kendall s τ as 2 τ 1 4 θ d 1 θ 1 whose values range in 1 1 0 d 1is the first order debye function given by 3 d 1 θ 1 θ 0 θ t e t 1 d t θ 2 since the value of storm intensity is conditioned on its duration the conditional frank copula is expressed as 4 c i d d e θ i 1 e θ d e θ d 1 e θ i 1 e θ 1 2 2 3 detection of non stationarity as mentioned already since the basic definition of non stationarity implies a change in the statistical properties like mean variance and skewness over time in this study the distribution parameters of the time series are primarily checked for any signature of non stationarity then stationary non stationary modeling is adapted accordingly for this the trend in the distribution parameters of the time series is detected using a tsw approach as described below 1 using a pre defined time sliding window of length m the original time series x t x 1 x 2 xn is divided into many realizations r 1 r 2 r n m as follows r 1 x 1 x 2 x m r 2 x 2 x 3 x m 1 r n m x n m x n m 1 x n 2 each realization r 1 r 2 r n m is fitted into the most appropriate distribution that is determined for the entire time series x t and the distribution parameters are computed using a maximum likelihood estimate for example if the best fit distribution for storm intensity is the generalized extreme value gev distribution the distribution parameters are calculated by fitting the realization r 1 in the following equation 5 f g e v r 1 μ r 1 σ r 1 κ r 1 e x p 1 κ r 1 μ σ 1 κ the log likelihood for the gev distribution is 6 log l μ r 1 σ r 1 κ r 1 r 1 n log σ 1 1 κ i 1 n log 1 κ x i μ σ i 1 n 1 κ x i μ σ 1 κ the maximum likelihood can be estimated by maximizing the equation with respect to the parameter vector 3 using the parameters obtained from the realizations a new parameter vector based on the sub series is constructed for example μ x μ r 1 μ r 2 μ r n m 4 then a non parametric moving block bootstrap mann kendall test is used to detect any significant trend in each parameter series 5 if the parameter shows a significant trend estimated at 10 significance levels using standardized test static z and p value then it is considered to be non stationary and the time varying parameter is estimated using a linear trend model μ x μ xt1 μ xt2 t otherwise the parameter is estimated using a stationary value μ x the parameters are estimated using bayesian inference as explained in the next section here we restrict our analysis to a simple linear model to avoid the complexity and uncertainty due to the additional parameters arising from non linear trends luke et al 2017 serinaldi and kilsby 2015 the increase in the number of parameters in non stationary modeling may increase the uncertainty in the estimation when compared to that of a stationary model the steps followed for choosing between the proposed tsw nsm and the traditional nsm is demonstrated in fig 1 2 2 4 parameter estimation using bayesian inference once the non stationarity is detected and the time dependent model is identified the distribution parameters of the extreme value marginals can be estimated traditionally these parameters are estimated using the method of maximum likelihood estimate mle agilan and umamahesh 2017b 2016 coles 2001 mondal and mujumdar 2015 zhang and zwiers 2013 however the classical methods like mle the method of moments and l moments give a single point estimate of the parameters and fail to convey the uncertainty persistent in the parameter estimation luke et al 2017 in addition these classical methods become less effective for small size samples chandra et al 2015 coles and tawn 1996 hence the scarcity of data and inherent uncertainty pertinent to the extreme value analysis motivated us to choose bayesian inference for estimating the parameters of marginals bayesian inference offers an attractive framework to estimate the posterior distribution of non stationary models and to quantify the predictive uncertainties renard et al 2013 it is one of the preferred methods for analyzing sparse data chandra et al 2015 coles et al 2003 huard et al 2010 in this study bayesian inference is implemented based on the differential evolution markov chain de mc algorithm by integrating differential evolution de learning strategy and monte carlo markov chain mcmc simulation to robustly estimate the posterior distribution of the parameters of both the marginals and the copula function the posterior distribution p φ x can computed by applying bayes theorem as given below 7 p φ x p φ l φ x the likelihood function is calculated as 8 l φ x i 1 n p x i φ where φ is the parameter of the particular distribution in this study a two step bayesian approach sarhadi et al 2016 is used firstly the parameters of the univariate marginal are estimated along with their uncertainty bounds further the parameter of the multivariate copula function joining the transformed marginals is estimated using the input from the first step in case of the intensity attribute having the gev distribution computation of the parameter in the first step involves the following 9 p φ i i p φ i l φ i i 10 p φ i i p φ i i 1 n p i i φ i where φ i μ i σ i ξ i similarly the parameter for the duration attribute is computed as 11 p φ d d p φ d l φ d d 12 p φ d d p φ d i 1 n p d i φ d where φ d μ d σ d ξ d in case of the gamma distribution with time varying location and scale parameters 13 φ d μ d 1 μ d 2 σ d 1 σ d 2 p φ d d p φ d i 1 n p d i μ d t σ d t for extreme value analysis using gev and gp distributions the prior for location and scale parameters are weakly informative normal distribution i e a normal distribution with large variance n 0 1000 which uses the knowledge conveyed by the likelihood function of the observation vector x bracken et al 2018 cheng et al 2014 gelman et al 2014 while the prior for shape parameter is a normal distribution with 0 3 standard deviation renard et al 2013 whereas in case of gamma and lognormal distributions the conjugate prior for location is normal distribution and that of scale is gamma distribution kwon and lall 2016 sarhadi et al 2016 if the scale parameter is time invariant it is preferable to use gamma prior whereas a time varying parameter can take either positive or negative value therefore in this study we have used a weakly informative normal prior for scale parameter then the corresponding marginal distribution is calculated using the bayesian mean of the extracted parameters for instance the marginal of intensity for the gev distribution having a time varying location parameter is given as 14 φ i n μ i 1 n μ i 2 n σ i n κ i n 15 φ i 1 n i 1 n φ i i 16 f i φ i f g e v i μ i 1 μ i 2 σ i κ i where n is the number of realizations of the mcmc sampling in the second stage of bayesian inference the parameter of the copula function will be estimated utilizing the marginal computed in the first stage as follows 17 p θ i d p θ l θ i d 18 l θ i d i 1 n c u i u i θ t where u f it β i v f dt β d and θ is the copula parameter if non stationarity is observed in the copula parameter then it will be modeled using a linear trend θ θ1 θ2 t the weakly informative prior chosen for the copula parameter θ is θ u 50 0 however if reliable information of the prior distribution is available then it could be exploited instead of adopting a weakly informative prior as mentioned earlier the parameters are estimated using de mc which employs the differential evolution genetic algorithm to globally optimize the parameter space while the metropolis hastings algorithm is used as the sampling technique vrugt et al 2009 in this study five different markov chains were run in parallel de mc is preferred because of its simplicity adaptability computational efficiency and convergence cheng and aghakouchak 2015 ter braak 2006 ter braak and vrugt 2008 moreover the convergence is tested using a statistical criterion known as r proposed by gelman and shirley 2011 the value of r is checked whether it is 1 1 otherwise the sampling is done again by running a new set of simulations 2 2 5 return level and return period the conditional return period and joint return period are further computed by incorporating the probability exceedance of a storm for a particular intensity and duration shiau 2003 zhang and singh 2007 the conditional return period in years is computed as 19 t i d d 1 1 c i d d where c i d d is defined in eq 4 the joint return period in years is calculated as 20 t i 0 d 0 e t i a 1 f i t i 0 f d t d 0 p d d 0 i i 0 where tia is the interarrival time the non stationary rl of rainfall intensity with a t year return period is evaluated using eqs 4 and 19 the time varying distribution parameters are evaluated using the design exceedance probability cheng et al 2014 cheng and aghakouchak 2015 and effective rl katz et al 2002 for more details see section s4 in supplementary information for non stationary rl and return period computation the 95th percentile of time varying parameter generated using de mc is considered in order to account for the low risk more conservative extreme value analysis for instance the model parameter σ is the 95th percentile of values sampled using de mc σ t 1 σ t 2 σ t 100 cheng et al 2014 cheng and aghakouchak 2015 3 results and discussion 3 1 preliminary analysis the proposed methodology is applied to four major cities in india to generate the non stationary intensity duration model firstly the attributes of storm events viz their intensity and duration are extracted using the event based approach as mentioned in section 2 2 1 and the characteristics of the events are given in table s1 in the supplementary information then the best fit distributions for both the attributes for each station are determined through the goodness of fit test as mentioned in section 2 2 2 the best fit distributions for each attribute found using the ks test and minimum bic values are given in table 1 in case of storm intensity the gev distribution fits well for all stations except for calcutta where the gp distribution fits well similarly for storm duration the lognormal distribution is found to fit well for all other stations except bombay where the gamma distribution matched the best the scatter plots of storm intensity and duration along with their respective distributions as shown in fig 2 reveal that while storm intensity and duration are negatively correlated to each other each station exhibits distinct storm characteristics for instance the storm events are concentrated near short duration in bangalore in the case of madras and calcutta it is dispersed storm events having longer duration are observed in bombay than any other stations further the correlation between the storm intensity and duration in terms of kendall s rank correlation coefficient is found to be 0 63 for bangalore 0 34 for bombay 0 71 for calcutta and 0 57 for madras due to the observed negative correlation the frank copula with the domain for τ as 1 1 0 which suitably represents bivariate distribution of intensity and duration ariff et al 2012 nelsen 2006 is chosen to compute the multivariate joint cdf and its goodness of fit is checked using ks statistics at the 5 level of significance after computing the marginal and choosing the copula the data is assessed for any possible signature of non stationarity by evaluating the distribution parameters 3 2 detecting and estimating non stationary parameters before applying bayesian inference to estimate the probability distribution parameters location scale shape of storm intensity storm duration and its joint function copula parameter θ the signature of non stationarity is first detected using the proposed tsw approach as mentioned in section 2 2 3 here a 20 year time sliding window is chosen to divide the original time series into many realizations to ensure sufficient samples a 30 year or even longer window can be considered if sufficient rainfall data is available a parameter series is constructed from the distribution parameters computed for each realization the significance of trend for each parameter series is estimated by a non parametric moving block bootstrap mann kendall test sonali and nagesh kumar 2013 vinnarasi and dhanya 2016 and is summarized in table 1 as an illustration the details of the distribution parameters computed using tsw series and their trend for bangalore are shown in fig 3 the same information for other stations are shown in figs s2 s4 in the supplementary information while the scale parameter of storm intensity shows the signature of non stationarity in all the four stations the location parameter exhibit non stationarity only in bombay and bangalore the non stationarity in scale parameter can be explained from the previously reported observations of significant changes in the rainfall variance with respect to the mean rainfall over india goswami et al 2006 vittal et al 2013 though the variation in location scale and shape parameters do change the mean of the gev distribution any variation in the location parameter has more impact on the mean any variations in scale and shape parameters indicate changes in variance increasing trends exhibited by the location and scale parameters of storm intensity in bombay and bangalore indicate an increase in the storm intensity strengthened by a positive shift increasing in the mean and variance longer spread events likewise the probabilistic characteristics of the storm intensity of madras reveal longer spreads of events with a minor change in mean in contrast the scale parameter of calcutta shows a decreasing trend which characterizes a shorter spread of events or a decrease in variance no change is observed for the shape parameter except for the calcutta and madras stations where a significant increase and decrease of 0 0011 and 0 0028 respectively are observed though the proposed methodology allows modelling the shape parameter also as a function of time a constant value is adopted in this study this is primarily due to the use of short period record since time varying modelling of the shape parameter of extreme value model demands long term observation agilan and umamahesh 2016 cheng et al 2014 coles 2001 in the case of storm duration a negative trend is obtained for the location parameter and an increasing trend is observed in the scale parameter of the lognormal distribution of bangalore rainfall madras exhibits a decreasing trend in the scale parameter with no change in location parameter representing a decrease in the spread of duration with no shift in the mean also calcutta shows a positive trend in the location parameter with no change in the scale parameter here the location and scale parameters of the lognormal distribution directly represent the mean and standard deviation of the distribution respectively however in the case of bombay both shape and scale parameters of the gamma distribution influence the mean and variance of the distribution here the scale shows a decreasing trend whereas no trend is observed in shape which infers a decrease in both mean and variance interestingly the parameter of the frank copula does not undergo any change in any of the four stations which signals that the correlation between the storm intensity and storm duration may not have changed over time even though the changes were observed in the respective distribution parameters therefore the one parameter of the frank copula is taken as constant though the proposed methodology is able to model time varying copula a comparison of the presented approach with the traditional nsw approach was performed the presence of any significant trend in each attribute for each station was detected using the non parametric moving block bootstrap mann kendall test significant trends were observed only for both storm intensity and storm duration of bangalore and only for storm duration of calcutta shown in fig s5 in supplementary information different combinations of non stationary models i e case 1 changing location parameter only and case 2 changing both location and scale parameters were developed for bangalore and calcutta for the respective attributes the best model is then selected based on the deviance information criterion dic as shown in table 3 it can be seen that except for storm intensity in bangalore the models selected for the other two cases are the same by both the traditional and the proposed approach however it is to be noted that the selection of model in the traditional approach does depend on the value taken up by dic the difference between dics may not be significant which may put ambiguity on the selection spiegelhalter et al 1998 symonds and moussalli 2011 zhu and carlin 2000 it is worthwhile to highlight here that the traditional nsm would have treated all remaining stations attributes as stationary due to the absence of any significant trend in the mean of the attribute while the tsw nsm approach considers any possible change in the variance 3 3 estimation of time varying parameters using bayesian inference bayesian inference is used to estimate the posterior density of the distribution parameters of the marginals location scale shape and copula the time varying parameters selected through the time sliding window approach is represented using a linear regression model higher degree polynomial models are not utilized due to the uncertainty involved in estimation as suggested by luke et al 2017 the appropriate trend models constant linear for all the parameters of the respective marginals and copula are shown in table s2 in case of the stationary intensity duration model the parameter is assumed to be a constant and bayesian inference is applied to estimate the uncertainty in the distribution parameters and rl bayesian inference is first employed for estimating the parameters of the marginal distribution of both storm intensity and duration five different markov chains having 5000 samples in each chain are created using the de mc metropolis hastings algorithm the first 1000 samples of each markov chain are discarded as burn in and the rest are used to compute the distribution of the parameter being estimated the convergence statistics of each parameter sample are monitored and it is assured that the convergence statistics are less than 1 1 the convergence of the posterior sample is also visually ensured using trace plots and posterior distribution plots of each parameter for instance the trace plot and posterior distribution of storm duration attribute of bangalore station as shown in fig 4 clearly reveal that there is no upward or downward trend in the simulated samples the posterior density of all the distribution parameters for all stations are shown in figs s6 s13 in the supplementary information the posterior mean and 90 credible interval for the parameters along with the posterior standard deviation are summarized in table s2 it is ensured that the median of the posterior distributions is not zero and that the uncertainty range is also relatively narrow the marginals are then computed using the bayesian posterior mean after extracting the posterior distribution of distribution parameters of marginals a similar approach involving bayesian inference is applied for estimating the copula parameter using the non stationary marginals thus the dynamic behavior of the dependence structure of storm intensity and duration is evaluated 3 4 time varying bivariate frequency analysis the analysis is further extended to compute the joint return periods of both storm intensity and duration the rl of storm intensity and duration for 10 30 and 100 year return periods are computed with time varying parameters for each station computed rls corresponding to storm intensity and duration time series along with the associated confidence intervals estimated using the bayesian model are shown in fig 5 while increasing trends of rl are evident in bangalore and bombay a reverse pattern is observed in calcutta the rls of intensity and duration follow opposite trends as expected for example the increasing and decreasing trends of intensity in bombay and calcutta respectively are accompanied by decreasing and increasing trends of rl of duration respectively surprisingly in madras the rl of storm intensity did not undergo any change despite the reporting s of recent flood occurrences however a decreasing trend is obtained for the rl of duration further the joint return period of storm intensity and duration computed using the median parameters of the marginal for both the non stationary as well as stationary models is presented in fig 6 the non stationary model is based on the design exceedance probability since it is recommended for the low risk approach in extreme value analysis cheng et al 2014 in bombay and bangalore the stationary model shows a higher joint return period than the non stationary model whereas a contrasting behavior is observed in calcutta and madras moreover to highlight the difference between the stationary and non stationary models we picked a few events with return periods of approximately 100 years and showed them in the inset of each subplot in fig 6 this reveals that except calcutta all other stations show a decreasing return period further to get a better perception of how the return period of storm events evolve over time we calculated the time varying joint return period for different durations of the storm using the time varying parameters for a specific storm intensity for this purpose the return period is calculated at each station for the maximum intensity with different durations 1 h 48 h and dmax maximum duration in the respective station given in table s1 in supplementary information the variation of joint return periods at each station for a particular intensity and different durations are shown in fig s14 in supplementary information it can be noted that in bangalore and bombay the joint return periods of maximum intensity show a decreasing trend for all three durations in the case of madras the joint return period for longer durations is increasing while that of short duration 1 h events is decreasing this clearly shows that high intensity rainfall events with short duration are becoming more frequent in bangalore bombay and madras which agrees with the findings reported by previous studies narasimhan et al 2016 sen roy 2009 high intensity rainfall will eventually increase the flood peaks in urban catchments and is a major threat to the infrastructure however in calcutta the joint return period increases for all storm durations which can be attributed to the increasing trend in the duration this might be particularly due to a decrease in extreme hourly rainfall sen roy 2009 in addition we attempted to look into the return period of recent floods occurred in these stations and the joint return period for bangalore 129 mm in 24 h duration 5 37 mm h 2017 bharadwaj 2017 bombay 944 mm in 24 h duration 39 33 mm h 2005 gupta 2007 hallegatte et al 2010 kumar et al 2008 and madras 340 mm in 24 h duration 2015 national remote sensing centre nrsc indian space reseach organization isro 2015 are shown in fig 7 all these flood events exhibit a decreasing trend in the return period at a rate of 0 54 yr yr 1 15 yr yr 0 12 yr yr for bangalore bombay and madras respectively further it suggests that the frequency of short duration high intensity rainfall might increase in the future i e rainfall events of longer duration is reducing in these cities it is important to note here that the traditional nsm has failed to capture these changes in bombay and madras therefore it can be argued that neglecting non stationarity due to the absence of any significant trend in the attribute may result in the underestimation of extreme floods which in turn lead to underestimation of the actual risk related to infrastructure and human life for example the return period decreasing at a rate of 1 15 yr yr in bombay will have a severe impact on the design of urban drainage system if un accounted for finally the average idf curves were developed using the conditional frank copula function i e rainfall intensity conditioned on a defined duration or known as the return level rl the average idf relationships for 2 5 10 30 50 and 100 year return periods are computed for each station and are shown in figs 8 to 11 where panel a shows the rl of storms event having a 100 year return period with 90 credible interval along with the time varying rl for selected durations panel a the non stationary and stationary average rl of minimum duration is shown in panel b and their difference is shown in panel c in terms of mm h difference in percent is shown in fig 12 in case of bangalore fig 8 the difference between stationary and non stationary rl for a 100 year event and 1 h duration is 33 45 mm h whereas this difference decreases for higher durations this difference 33 45 mm h of 50 will necessarily increase the flood peak significantly moreover the rl of a 100 year event for a non stationary case using time varying parameters varies at a rate of 0 5 mm h yr 0 04 mm h yr and 0 04 mm h yr for storm durations of 1 h 24 h and 49 h respectively this clearly indicates that short duration events intensify at a faster rate than the longer duration events which if not taken into account can lead to poor design of urban drainage this is also evident from the 1 h non stationary and stationary rls for all the return periods shown in fig 8b and c which clearly indicate an 50 increase in the non stationary case than that in the stationary case in case of bombay fig 9 rl for a 100 year event in the non stationary case is higher than that in the stationary case for all the durations where the difference decreases from 5 6 mm h to 2 mm h for 3 h and 207 h durations respectively this trend holds true for different return periods as well as can be seen in fig s15 in supplementary information where the rl of short duration events increases faster than longer ones similar to bangalore it is clear that the stationary assumption will result in the underestimation of the flood peaks in both the highly urbanized metro cities where the actual flood risk is significantly higher than what the system and infrastructure were designed for gupta 2007 whereas in calcutta the rl of short duration events decreases compared to the longer events as anticipated fig 10 a besides the stationary rl is higher than its non stationary counterpart and hence the use of the stationary approach in calcutta may lead to over estimation finally in madras fig 11 the difference between stationary and non stationary rls is relatively lesser than the other stations where the difference is more for short durations in the non stationary case than the stationary and it decreases as the duration increases moreover the time varying rl shows an increase at a rate of 0 04 mm h year while it decreases at a negligible rate for longer duration events this is in agreement with the trend of intensity and duration mentioned above overall the changes in extreme events happened more in short duration events than in longer duration regardless of whether it intensifies or subsides except bangalore all other stations exhibit stationarity according to traditional nsm which eventually would lead to overestimation or underestimation the dynamic behavior of the attributes of other stations would not have been captured by traditional nsm because of the criterion used to decide time varying models in addition the consideration of multiple combinations models in traditional nsm increases the complexity multi fold agilan and umamahesh 2017a b thereby rendering it computationally inefficient the proposed method averts these limitations by choosing only the relevant combinations hence instead of using the traditional nsm approach by merely detecting the trend in the attributes the policymakers and designers could employ the refined approach proposed in this study for efficient planning and management of water resource systems 4 conclusions this study presents an innovative approach to model the intensity duration relationship of extreme rainfall incorporating the non stationarity in the precipitation time series a dynamic copula based multivariate extreme event modeling utilizing bayesian inference has been developed unlike traditional non stationary modeling traditional nsm the present approach detects the non stationarity in each distribution parameter using a time sliding window then each parameter is modeled using a linear time varying model only if it exhibits the signature of non stationarity it is assumed to be constant stationary otherwise the proposed methodology is employed to develop the time varying intensity duration model for four major metro cities i e bangalore bombay calcutta and madras in india using hourly rainfall data the intensity duration models developed for these stations reveal that the statistical property of variance has undergone more changes than mean which is not captured by the traditional nsm approach further the time varying return period of extreme flood events using representative past flood levels in the respective places shows a decreasing trend of return period at a rate of 0 54 yr yr 1 15 yr yr 0 12 yr yr for bangalore bombay and madras respectively whereas the traditional nsm approach would have modeled bombay and madras as stationary due to lack of trend in the attributes thereby underestimating the return period of the extreme flood our results illustrate that the proposed non stationary model is adaptive in incorporating the non stationary distribution parameter for each station instead of adopting the same parameter for all the stations it also reduces the complexity by bypassing non stationary models for parameters exhibiting insignificant non stationarity making it flexible to incorporate both stationary and non stationary models for multivariate frequency analysis furthermore the proposed framework offers the time varying joint return period and rl along with their uncertainty bounds overall it can be inferred that the proposed non stationary model may be able to estimate the hydrological design variables more realistically than both stationary and traditional non stationary models which over underestimate them the changing extremes in precipitation pose a major threat to existing hydrological system and infrastructure designed based on the stationary methods hence in order to devise adaptation and mitigation strategies it is inevitable to update our water resources practices according to the changes in the characteristics of extremes by incorporating the non stationarity in a realistic manner supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 06 009 appendix supplementary materials image application 1 image application 2 
622,dynamic behavior of extreme rainfall characteristics heightened by the abrupt warming of the environment has affected the sustainability of the existing water resources systems and infrastructure which were designed employing the traditional stationary assumption here we propose a realistic and efficient framework to detect non stationarity in the observed hydrologic variables to overcome a few limitations suffered by the traditional non stationary approaches the methodology is demonstrated over the short period rainfall series of four major metropolitan cities of india where the intensity of the rainfall is reportedly increasing sharply accompanied by the changes in the pattern of rainfall since direct runoff is influenced by the intensity and duration of rainfall it is important to study the joint characteristics of intensity and duration in the context of non stationarity especially in urban regions where the relationship is more distinct hence we estimated the time varying joint return period return level of its extremes utilizing a dynamic bayesian copula we have implemented time varying multivariate probability frequency analysis to derive the time varying intensity duration relationship here we employed a bayesian approach through differential evolution markov chain de mc algorithm to estimate the uncertainty bound of the time varying return level the results emphasize that the probabilistic distribution parameters vary both temporally and spatially and recommend the incorporation of non stationarity in the extreme event modeling only if there is a change in the probabilistic distribution parameters this non stationary model can be seamlessly employed to compute return levels with better accuracy and reliability than traditional stationary non stationary methods we observe that the short duration return level increases at a faster rate than the longer ones with the credibility interval larger than that of long duration return levels the results also highlight the importance of adopting event based non stationary idf curves for the design of water resource systems and to devise long term decision making strategies to address the changing climate however we do not draw any conclusion concerning climate change in general from the short duration rainfall records used in this study keywords non stationarity bayesian inference return period return level copula 1 introduction abrupt changes in the frequency and magnitude of extreme hydroclimatological events across the world have triggered major threats to human life infrastructure and agriculture thereby adversely impacting the society and economy according to the intergovernmental panel on climate change ipcc special report on extremes srex the risks due to the impact of extreme events on populations and assets have risen beyond expectation ipcc 2012 additionally numerous studies report that the magnitude and frequency of extreme precipitation is increasing faster than the average precipitation in the recent decades and demand a paradigm shift in the adaptation management of hydrological events aguilar et al 2005 alexander et al 2006 gordon et al 1992 goswami et al 2006 vinnarasi and dhanya 2016 vittal et al 2013 this is particularly pertinent to the design of hydraulic structures such as dams sewers and stormwater drainage networks which are traditionally designed on the assumption of a stationary climate cheng et al 2014 sarhadi et al 2016 sarhadi and soulis 2017 the term stationary extreme event modeling assumes that the probabilistic distribution parameters herein called distribution parameters and exceedance probability of events are unchanging over time jakob 2013 nevertheless it is apparent that extreme events are changing and are likely to change in the future milly et al 2008 which in turn puts doubt on the reliability of the stationary methods this prompts the necessity for upgrading the existing methodologies to estimate the exceedance probability of different hydrological variables by incorporating the dynamic behavior of the ever changing climate cancelliere 2017 salas and obeysekera 2014 zwiers et al 2013 traditionally non stationarity in a time series is addressed using differencing detrending approaches cave beatrice m and pearson 1914 khaliq et al 2006 these methods remove the inherent natural variability in the time series however khaliq et al 2006 this can be overcome by modelling the non stationarity in the form of changing distribution parameters over time generally approximated using a linear or non linear trend agilan and umamahesh 2016 cheng et al 2014 cheng and aghakouchak 2015 coles 2001 el adlouni et al 2007 katz et al 2002 luke et al 2017 mondal and mujumdar 2015 risser and wehner 2017 sarhadi and soulis 2017 steirou et al 2018 sugahara et al 2009 yilmaz and perera 2014 zhang et al 2015 zhang and zwiers 2013 the concept of non stationarity was first introduced through univariate hydrologic frequency analysis owing to its mathematical simplicity mishra and singh 2011 singh and zhang 2007 but univariate analysis may not be adequate for all cases especially for integrated flood drought risk management and may not capture all hydrologic hydraulic design risks appropriately chebana and ouarda 2011 katz et al 2002 schumann 2017 hence multivariate modeling incorporating temporal dynamics in the marginal distribution was proposed by chebana and ouarda 2011 which is enhanced by employing copulas to develop multi variate non stationary models of storm events corbella and stretch 2013 and severity duration frequency curves kwon and lall 2016 moreover copula based multivariate non stationary analysis can be further improved by incorporating dynamic behavior into the dependent structure jiang et al 2015 sarhadi et al 2016 non stationary modeling is further improved by incorporating multiple time varying distribution parameters traditional non stationary models here on abbreviated as traditional nsm addressing non stationarity have considered temporal variation of either only location parameter or different combinations of distribution parameters for example past studies have addressed non stationarity by changing either location agilan and umamahesh 2017b cheng and aghakouchak 2015 sarhadi et al 2016 or both location and scale parameters agilan and umamahesh 2017a cheng et al 2014 sarhadi and soulis 2017 few studies have determined the best parameter combination by considering all possible combinations of the parameters and choosing the best one based on an information criterion agilan and umamahesh 2017a sarhadi and soulis 2017 such approaches increase the complexity and uncertainty in modeling especially while adopting a multivariate analysis and also lack any realism in bringing out the non stationary characteristics of the time series a non stationary process essentially implies change s in the statistical properties like mean variance skewness or distribution parameters over time coles 2001 and not necessarily a trend in the variable hence the above traditional nsm approaches are questionable since the presence of mere trend may not be sufficient to ensure non stationarity in the time series even though the trend in the time series will indeed reflect as variations in the distribution parameter s in general the trend in the time series may be reflected as variations non stationarity in the mean but may not necessarily cause any changes in other parameters another possibility is that a time series can be non stationary even if it does not exhibit any significant trend e g the dynamic behavior in the variance of the events may not be reflected in the trend the lack of conviction on the necessity of non stationary modeling even for a non stationary time series ganguli and coulibaly 2017 might be due to the possible flaws in the approaches which are based merely on the existence of trend and selection of best combinations as explained earlier to counter the limitations mentioned above it is necessary to detect the signature of non stationarity in the distribution parameters rather than the mere trend in the original time series before finalizing the technique of modeling sadegh et al 2015 if non stationarity is not evident in the parameters it is reasonable to use a stationary model with known uncertainty hence we propose a modified approach to bring realism into the selection of stationary non stationary model considering the importance of detection of non stationarity and the need of enhanced methodology in time varying multivariate extreme event modeling the focus of this study is to develop an innovative approach to detect the non stationarity in the distribution parameters and to apply a robust technique for time varying multivariate risk analysis utilizing bayesian inference according to authors knowledge time varying bivariate intensity duration modeling has not yet been attempted the proposed methodology is used to develop storm intensity duration models for four major metropolitan cities of india as short duration high intensity rainfall events reportedly increasing agilan and umamahesh 2017b cheng et al 2014 ganguli and coulibaly 2017 sarhadi and soulis 2017 especially over urbanized regions shastri et al 2015 vittal et al 2013 2 data and methodology 2 1 study area and data description in the present study we selected four major metropolitan cities in india bengaluru formerly bangalore mumbai formerly bombay kolkata formerly calcutta and chennai formerly madras which are the state capitals of karnataka maharashtra west bengal and tamil nadu states respectively see details in section s1 of supplementary information the autographic hourly rainfall data of these cities is procured from the indian meteorological department imd the choice of the four datasets used in the study is strictly based on the availability of high resolution station data with reasonable temporal coverage however the methodology is generic and can be applied to any dataset with varying characteristics the station numbers duration of the data available and missing data information are given in table 1 2 2 methodology the steps involved in computing the non stationary return levels are outlined here firstly the storm events are extracted from the rainfall series using event based approach then the extreme storm attributes viz intensity and duration are also extracted using peak over threshold pot method then each attribute is fit into a suitable marginal distribution a suitable copula is selected further the distribution and copula parameters are then checked for non stationarity using time sliding window tsw approach if a parameter exhibits significant non stationarity it is modeled as linear time varying parameter else it is kept constant the marginal parameters along with their uncertainty bounds are estimated using bayesian inference which is the first stage bayesian then the joint distribution of both the attributes are computed using copula and the copula parameter is estimated along with its uncertainty bound using bayesian inference which is the second stage bayesian finally the joint extreme characteristics like return level rl and return period are computed the overall procedure adopted in the computation of non stationary joint rl is given in figure s1 the above steps are briefly explained in the following subsections 2 2 1 definition and extraction of storm events storm events are characterized using the concept of inter event time definition ietd ariff et al 2012 which is based on the minimum duration of a dry spell between two successive storm events and ensures the statistical independence between the events we have fixed ietd as 6 h for the present study since all the four stations are in urban catchments ariff et al 2012 huff 1967 palynchuk and guo 2008 the total accumulated rainfall in a storm event is defined as storm depth the total length of a storm event is storm duration while the ratio of storm depth to storm duration is termed as storm intensity over the study region the duration of storm events are reportedly reducing without any significant change in the storm depth singh et al 2014 vinnarasi and dhanya 2016 vittal et al 2013 hence in order to model the dynamic behavior of the longer and shorter duration high intensity storm events we employed the pot method to extract the storm depths exceeding the 90th percentile threshold since it ensures the selection of at least one event per year the corresponding storm duration and average storm intensity are also computed for more information on ietd and pot please refer to section s2 of supplementary information 2 2 2 marginal distribution of storm events and its dependence structure once the extreme storm attributes i e storm duration and storm intensity are extracted it is necessary to identify the suitable marginal distribution of each attribute and its dependence structure to detect the changing parameter the two attributes strongly correlate with each other and possess unique probabilistic characteristics ariff et al 2012 singh and zhang 2007 the joint distribution between these two variables considering the dissimilarity in their probabilistic characteristics is computed employing copulas sklar 1959 copulas are functions that join or couple the multivariate distribution into their one dimensional marginal distribution functions in which the multivariate distribution is based on a univariate probability distribution regardless of their structure or type nelsen 2006 firstly appropriate marginal probability distributions need to be identified for average storm intensity and storm duration while conventional practice is to adopt either a gamma or lognormal distribution for storm intensity and an exponential distribution for storm duration menabde and sivapalan 2000 these distributions may not always guarantee a good fit ariff et al 2012 menabde and sivapalan 2000 singh and zhang 2007 hence a well fitted distribution for each station is found from a basket of eight different distributions namely generalized extreme value gev generalized pareto gp lognormal gamma exponential weibull gumbel and logistic using the kolmogorov smirnov test k s test and bayesian information criterion bic the expressions used for computing the distribution and their parameters are given in table 2 after finding the best fit marginal distribution a suitable copula should be selected to model the dependence structure between storm intensity and storm duration based on the correlation between the random variables the archimedean copula family comprising nearly 22 copula families is chosen in this study since the copula function from this family is utilized extensively in hydrological frequency analysis brunner et al 2016 de michele and salvadori 2003 favre et al 2004 salvadori and de michele 2004 singh and zhang 2007 the primary advantage of archimedean copula over other families of copula is its mathematical simplicity and its applicability despite the positive or negative correlation among hydrologic variables since the correlation between intensity and duration is known to be negative the suitable copulas among the archimedean family are ali mikhail haq and frank copulas ariff et al 2012 singh and zhang 2007 while the ali mikhail copula is not recommended for significantly negative correlated random variables the frank copula is successfully utilized by many studies for various hydrological analysis ariff et al 2012 de michele and salvadori 2003 singh and zhang 2007 hence the frank copula a one parameter archimedean copula that allows maximum range of dependence i e positive and negative dependence is deployed in this study and is expressed as 1 c u v 1 θ ln e θ 1 1 e θ 1 e θ u 1 e θ v θ r 0 where u f it μ σ ξ v f dt μ σ θ is the copula parameter which is related to the kendall s τ as 2 τ 1 4 θ d 1 θ 1 whose values range in 1 1 0 d 1is the first order debye function given by 3 d 1 θ 1 θ 0 θ t e t 1 d t θ 2 since the value of storm intensity is conditioned on its duration the conditional frank copula is expressed as 4 c i d d e θ i 1 e θ d e θ d 1 e θ i 1 e θ 1 2 2 3 detection of non stationarity as mentioned already since the basic definition of non stationarity implies a change in the statistical properties like mean variance and skewness over time in this study the distribution parameters of the time series are primarily checked for any signature of non stationarity then stationary non stationary modeling is adapted accordingly for this the trend in the distribution parameters of the time series is detected using a tsw approach as described below 1 using a pre defined time sliding window of length m the original time series x t x 1 x 2 xn is divided into many realizations r 1 r 2 r n m as follows r 1 x 1 x 2 x m r 2 x 2 x 3 x m 1 r n m x n m x n m 1 x n 2 each realization r 1 r 2 r n m is fitted into the most appropriate distribution that is determined for the entire time series x t and the distribution parameters are computed using a maximum likelihood estimate for example if the best fit distribution for storm intensity is the generalized extreme value gev distribution the distribution parameters are calculated by fitting the realization r 1 in the following equation 5 f g e v r 1 μ r 1 σ r 1 κ r 1 e x p 1 κ r 1 μ σ 1 κ the log likelihood for the gev distribution is 6 log l μ r 1 σ r 1 κ r 1 r 1 n log σ 1 1 κ i 1 n log 1 κ x i μ σ i 1 n 1 κ x i μ σ 1 κ the maximum likelihood can be estimated by maximizing the equation with respect to the parameter vector 3 using the parameters obtained from the realizations a new parameter vector based on the sub series is constructed for example μ x μ r 1 μ r 2 μ r n m 4 then a non parametric moving block bootstrap mann kendall test is used to detect any significant trend in each parameter series 5 if the parameter shows a significant trend estimated at 10 significance levels using standardized test static z and p value then it is considered to be non stationary and the time varying parameter is estimated using a linear trend model μ x μ xt1 μ xt2 t otherwise the parameter is estimated using a stationary value μ x the parameters are estimated using bayesian inference as explained in the next section here we restrict our analysis to a simple linear model to avoid the complexity and uncertainty due to the additional parameters arising from non linear trends luke et al 2017 serinaldi and kilsby 2015 the increase in the number of parameters in non stationary modeling may increase the uncertainty in the estimation when compared to that of a stationary model the steps followed for choosing between the proposed tsw nsm and the traditional nsm is demonstrated in fig 1 2 2 4 parameter estimation using bayesian inference once the non stationarity is detected and the time dependent model is identified the distribution parameters of the extreme value marginals can be estimated traditionally these parameters are estimated using the method of maximum likelihood estimate mle agilan and umamahesh 2017b 2016 coles 2001 mondal and mujumdar 2015 zhang and zwiers 2013 however the classical methods like mle the method of moments and l moments give a single point estimate of the parameters and fail to convey the uncertainty persistent in the parameter estimation luke et al 2017 in addition these classical methods become less effective for small size samples chandra et al 2015 coles and tawn 1996 hence the scarcity of data and inherent uncertainty pertinent to the extreme value analysis motivated us to choose bayesian inference for estimating the parameters of marginals bayesian inference offers an attractive framework to estimate the posterior distribution of non stationary models and to quantify the predictive uncertainties renard et al 2013 it is one of the preferred methods for analyzing sparse data chandra et al 2015 coles et al 2003 huard et al 2010 in this study bayesian inference is implemented based on the differential evolution markov chain de mc algorithm by integrating differential evolution de learning strategy and monte carlo markov chain mcmc simulation to robustly estimate the posterior distribution of the parameters of both the marginals and the copula function the posterior distribution p φ x can computed by applying bayes theorem as given below 7 p φ x p φ l φ x the likelihood function is calculated as 8 l φ x i 1 n p x i φ where φ is the parameter of the particular distribution in this study a two step bayesian approach sarhadi et al 2016 is used firstly the parameters of the univariate marginal are estimated along with their uncertainty bounds further the parameter of the multivariate copula function joining the transformed marginals is estimated using the input from the first step in case of the intensity attribute having the gev distribution computation of the parameter in the first step involves the following 9 p φ i i p φ i l φ i i 10 p φ i i p φ i i 1 n p i i φ i where φ i μ i σ i ξ i similarly the parameter for the duration attribute is computed as 11 p φ d d p φ d l φ d d 12 p φ d d p φ d i 1 n p d i φ d where φ d μ d σ d ξ d in case of the gamma distribution with time varying location and scale parameters 13 φ d μ d 1 μ d 2 σ d 1 σ d 2 p φ d d p φ d i 1 n p d i μ d t σ d t for extreme value analysis using gev and gp distributions the prior for location and scale parameters are weakly informative normal distribution i e a normal distribution with large variance n 0 1000 which uses the knowledge conveyed by the likelihood function of the observation vector x bracken et al 2018 cheng et al 2014 gelman et al 2014 while the prior for shape parameter is a normal distribution with 0 3 standard deviation renard et al 2013 whereas in case of gamma and lognormal distributions the conjugate prior for location is normal distribution and that of scale is gamma distribution kwon and lall 2016 sarhadi et al 2016 if the scale parameter is time invariant it is preferable to use gamma prior whereas a time varying parameter can take either positive or negative value therefore in this study we have used a weakly informative normal prior for scale parameter then the corresponding marginal distribution is calculated using the bayesian mean of the extracted parameters for instance the marginal of intensity for the gev distribution having a time varying location parameter is given as 14 φ i n μ i 1 n μ i 2 n σ i n κ i n 15 φ i 1 n i 1 n φ i i 16 f i φ i f g e v i μ i 1 μ i 2 σ i κ i where n is the number of realizations of the mcmc sampling in the second stage of bayesian inference the parameter of the copula function will be estimated utilizing the marginal computed in the first stage as follows 17 p θ i d p θ l θ i d 18 l θ i d i 1 n c u i u i θ t where u f it β i v f dt β d and θ is the copula parameter if non stationarity is observed in the copula parameter then it will be modeled using a linear trend θ θ1 θ2 t the weakly informative prior chosen for the copula parameter θ is θ u 50 0 however if reliable information of the prior distribution is available then it could be exploited instead of adopting a weakly informative prior as mentioned earlier the parameters are estimated using de mc which employs the differential evolution genetic algorithm to globally optimize the parameter space while the metropolis hastings algorithm is used as the sampling technique vrugt et al 2009 in this study five different markov chains were run in parallel de mc is preferred because of its simplicity adaptability computational efficiency and convergence cheng and aghakouchak 2015 ter braak 2006 ter braak and vrugt 2008 moreover the convergence is tested using a statistical criterion known as r proposed by gelman and shirley 2011 the value of r is checked whether it is 1 1 otherwise the sampling is done again by running a new set of simulations 2 2 5 return level and return period the conditional return period and joint return period are further computed by incorporating the probability exceedance of a storm for a particular intensity and duration shiau 2003 zhang and singh 2007 the conditional return period in years is computed as 19 t i d d 1 1 c i d d where c i d d is defined in eq 4 the joint return period in years is calculated as 20 t i 0 d 0 e t i a 1 f i t i 0 f d t d 0 p d d 0 i i 0 where tia is the interarrival time the non stationary rl of rainfall intensity with a t year return period is evaluated using eqs 4 and 19 the time varying distribution parameters are evaluated using the design exceedance probability cheng et al 2014 cheng and aghakouchak 2015 and effective rl katz et al 2002 for more details see section s4 in supplementary information for non stationary rl and return period computation the 95th percentile of time varying parameter generated using de mc is considered in order to account for the low risk more conservative extreme value analysis for instance the model parameter σ is the 95th percentile of values sampled using de mc σ t 1 σ t 2 σ t 100 cheng et al 2014 cheng and aghakouchak 2015 3 results and discussion 3 1 preliminary analysis the proposed methodology is applied to four major cities in india to generate the non stationary intensity duration model firstly the attributes of storm events viz their intensity and duration are extracted using the event based approach as mentioned in section 2 2 1 and the characteristics of the events are given in table s1 in the supplementary information then the best fit distributions for both the attributes for each station are determined through the goodness of fit test as mentioned in section 2 2 2 the best fit distributions for each attribute found using the ks test and minimum bic values are given in table 1 in case of storm intensity the gev distribution fits well for all stations except for calcutta where the gp distribution fits well similarly for storm duration the lognormal distribution is found to fit well for all other stations except bombay where the gamma distribution matched the best the scatter plots of storm intensity and duration along with their respective distributions as shown in fig 2 reveal that while storm intensity and duration are negatively correlated to each other each station exhibits distinct storm characteristics for instance the storm events are concentrated near short duration in bangalore in the case of madras and calcutta it is dispersed storm events having longer duration are observed in bombay than any other stations further the correlation between the storm intensity and duration in terms of kendall s rank correlation coefficient is found to be 0 63 for bangalore 0 34 for bombay 0 71 for calcutta and 0 57 for madras due to the observed negative correlation the frank copula with the domain for τ as 1 1 0 which suitably represents bivariate distribution of intensity and duration ariff et al 2012 nelsen 2006 is chosen to compute the multivariate joint cdf and its goodness of fit is checked using ks statistics at the 5 level of significance after computing the marginal and choosing the copula the data is assessed for any possible signature of non stationarity by evaluating the distribution parameters 3 2 detecting and estimating non stationary parameters before applying bayesian inference to estimate the probability distribution parameters location scale shape of storm intensity storm duration and its joint function copula parameter θ the signature of non stationarity is first detected using the proposed tsw approach as mentioned in section 2 2 3 here a 20 year time sliding window is chosen to divide the original time series into many realizations to ensure sufficient samples a 30 year or even longer window can be considered if sufficient rainfall data is available a parameter series is constructed from the distribution parameters computed for each realization the significance of trend for each parameter series is estimated by a non parametric moving block bootstrap mann kendall test sonali and nagesh kumar 2013 vinnarasi and dhanya 2016 and is summarized in table 1 as an illustration the details of the distribution parameters computed using tsw series and their trend for bangalore are shown in fig 3 the same information for other stations are shown in figs s2 s4 in the supplementary information while the scale parameter of storm intensity shows the signature of non stationarity in all the four stations the location parameter exhibit non stationarity only in bombay and bangalore the non stationarity in scale parameter can be explained from the previously reported observations of significant changes in the rainfall variance with respect to the mean rainfall over india goswami et al 2006 vittal et al 2013 though the variation in location scale and shape parameters do change the mean of the gev distribution any variation in the location parameter has more impact on the mean any variations in scale and shape parameters indicate changes in variance increasing trends exhibited by the location and scale parameters of storm intensity in bombay and bangalore indicate an increase in the storm intensity strengthened by a positive shift increasing in the mean and variance longer spread events likewise the probabilistic characteristics of the storm intensity of madras reveal longer spreads of events with a minor change in mean in contrast the scale parameter of calcutta shows a decreasing trend which characterizes a shorter spread of events or a decrease in variance no change is observed for the shape parameter except for the calcutta and madras stations where a significant increase and decrease of 0 0011 and 0 0028 respectively are observed though the proposed methodology allows modelling the shape parameter also as a function of time a constant value is adopted in this study this is primarily due to the use of short period record since time varying modelling of the shape parameter of extreme value model demands long term observation agilan and umamahesh 2016 cheng et al 2014 coles 2001 in the case of storm duration a negative trend is obtained for the location parameter and an increasing trend is observed in the scale parameter of the lognormal distribution of bangalore rainfall madras exhibits a decreasing trend in the scale parameter with no change in location parameter representing a decrease in the spread of duration with no shift in the mean also calcutta shows a positive trend in the location parameter with no change in the scale parameter here the location and scale parameters of the lognormal distribution directly represent the mean and standard deviation of the distribution respectively however in the case of bombay both shape and scale parameters of the gamma distribution influence the mean and variance of the distribution here the scale shows a decreasing trend whereas no trend is observed in shape which infers a decrease in both mean and variance interestingly the parameter of the frank copula does not undergo any change in any of the four stations which signals that the correlation between the storm intensity and storm duration may not have changed over time even though the changes were observed in the respective distribution parameters therefore the one parameter of the frank copula is taken as constant though the proposed methodology is able to model time varying copula a comparison of the presented approach with the traditional nsw approach was performed the presence of any significant trend in each attribute for each station was detected using the non parametric moving block bootstrap mann kendall test significant trends were observed only for both storm intensity and storm duration of bangalore and only for storm duration of calcutta shown in fig s5 in supplementary information different combinations of non stationary models i e case 1 changing location parameter only and case 2 changing both location and scale parameters were developed for bangalore and calcutta for the respective attributes the best model is then selected based on the deviance information criterion dic as shown in table 3 it can be seen that except for storm intensity in bangalore the models selected for the other two cases are the same by both the traditional and the proposed approach however it is to be noted that the selection of model in the traditional approach does depend on the value taken up by dic the difference between dics may not be significant which may put ambiguity on the selection spiegelhalter et al 1998 symonds and moussalli 2011 zhu and carlin 2000 it is worthwhile to highlight here that the traditional nsm would have treated all remaining stations attributes as stationary due to the absence of any significant trend in the mean of the attribute while the tsw nsm approach considers any possible change in the variance 3 3 estimation of time varying parameters using bayesian inference bayesian inference is used to estimate the posterior density of the distribution parameters of the marginals location scale shape and copula the time varying parameters selected through the time sliding window approach is represented using a linear regression model higher degree polynomial models are not utilized due to the uncertainty involved in estimation as suggested by luke et al 2017 the appropriate trend models constant linear for all the parameters of the respective marginals and copula are shown in table s2 in case of the stationary intensity duration model the parameter is assumed to be a constant and bayesian inference is applied to estimate the uncertainty in the distribution parameters and rl bayesian inference is first employed for estimating the parameters of the marginal distribution of both storm intensity and duration five different markov chains having 5000 samples in each chain are created using the de mc metropolis hastings algorithm the first 1000 samples of each markov chain are discarded as burn in and the rest are used to compute the distribution of the parameter being estimated the convergence statistics of each parameter sample are monitored and it is assured that the convergence statistics are less than 1 1 the convergence of the posterior sample is also visually ensured using trace plots and posterior distribution plots of each parameter for instance the trace plot and posterior distribution of storm duration attribute of bangalore station as shown in fig 4 clearly reveal that there is no upward or downward trend in the simulated samples the posterior density of all the distribution parameters for all stations are shown in figs s6 s13 in the supplementary information the posterior mean and 90 credible interval for the parameters along with the posterior standard deviation are summarized in table s2 it is ensured that the median of the posterior distributions is not zero and that the uncertainty range is also relatively narrow the marginals are then computed using the bayesian posterior mean after extracting the posterior distribution of distribution parameters of marginals a similar approach involving bayesian inference is applied for estimating the copula parameter using the non stationary marginals thus the dynamic behavior of the dependence structure of storm intensity and duration is evaluated 3 4 time varying bivariate frequency analysis the analysis is further extended to compute the joint return periods of both storm intensity and duration the rl of storm intensity and duration for 10 30 and 100 year return periods are computed with time varying parameters for each station computed rls corresponding to storm intensity and duration time series along with the associated confidence intervals estimated using the bayesian model are shown in fig 5 while increasing trends of rl are evident in bangalore and bombay a reverse pattern is observed in calcutta the rls of intensity and duration follow opposite trends as expected for example the increasing and decreasing trends of intensity in bombay and calcutta respectively are accompanied by decreasing and increasing trends of rl of duration respectively surprisingly in madras the rl of storm intensity did not undergo any change despite the reporting s of recent flood occurrences however a decreasing trend is obtained for the rl of duration further the joint return period of storm intensity and duration computed using the median parameters of the marginal for both the non stationary as well as stationary models is presented in fig 6 the non stationary model is based on the design exceedance probability since it is recommended for the low risk approach in extreme value analysis cheng et al 2014 in bombay and bangalore the stationary model shows a higher joint return period than the non stationary model whereas a contrasting behavior is observed in calcutta and madras moreover to highlight the difference between the stationary and non stationary models we picked a few events with return periods of approximately 100 years and showed them in the inset of each subplot in fig 6 this reveals that except calcutta all other stations show a decreasing return period further to get a better perception of how the return period of storm events evolve over time we calculated the time varying joint return period for different durations of the storm using the time varying parameters for a specific storm intensity for this purpose the return period is calculated at each station for the maximum intensity with different durations 1 h 48 h and dmax maximum duration in the respective station given in table s1 in supplementary information the variation of joint return periods at each station for a particular intensity and different durations are shown in fig s14 in supplementary information it can be noted that in bangalore and bombay the joint return periods of maximum intensity show a decreasing trend for all three durations in the case of madras the joint return period for longer durations is increasing while that of short duration 1 h events is decreasing this clearly shows that high intensity rainfall events with short duration are becoming more frequent in bangalore bombay and madras which agrees with the findings reported by previous studies narasimhan et al 2016 sen roy 2009 high intensity rainfall will eventually increase the flood peaks in urban catchments and is a major threat to the infrastructure however in calcutta the joint return period increases for all storm durations which can be attributed to the increasing trend in the duration this might be particularly due to a decrease in extreme hourly rainfall sen roy 2009 in addition we attempted to look into the return period of recent floods occurred in these stations and the joint return period for bangalore 129 mm in 24 h duration 5 37 mm h 2017 bharadwaj 2017 bombay 944 mm in 24 h duration 39 33 mm h 2005 gupta 2007 hallegatte et al 2010 kumar et al 2008 and madras 340 mm in 24 h duration 2015 national remote sensing centre nrsc indian space reseach organization isro 2015 are shown in fig 7 all these flood events exhibit a decreasing trend in the return period at a rate of 0 54 yr yr 1 15 yr yr 0 12 yr yr for bangalore bombay and madras respectively further it suggests that the frequency of short duration high intensity rainfall might increase in the future i e rainfall events of longer duration is reducing in these cities it is important to note here that the traditional nsm has failed to capture these changes in bombay and madras therefore it can be argued that neglecting non stationarity due to the absence of any significant trend in the attribute may result in the underestimation of extreme floods which in turn lead to underestimation of the actual risk related to infrastructure and human life for example the return period decreasing at a rate of 1 15 yr yr in bombay will have a severe impact on the design of urban drainage system if un accounted for finally the average idf curves were developed using the conditional frank copula function i e rainfall intensity conditioned on a defined duration or known as the return level rl the average idf relationships for 2 5 10 30 50 and 100 year return periods are computed for each station and are shown in figs 8 to 11 where panel a shows the rl of storms event having a 100 year return period with 90 credible interval along with the time varying rl for selected durations panel a the non stationary and stationary average rl of minimum duration is shown in panel b and their difference is shown in panel c in terms of mm h difference in percent is shown in fig 12 in case of bangalore fig 8 the difference between stationary and non stationary rl for a 100 year event and 1 h duration is 33 45 mm h whereas this difference decreases for higher durations this difference 33 45 mm h of 50 will necessarily increase the flood peak significantly moreover the rl of a 100 year event for a non stationary case using time varying parameters varies at a rate of 0 5 mm h yr 0 04 mm h yr and 0 04 mm h yr for storm durations of 1 h 24 h and 49 h respectively this clearly indicates that short duration events intensify at a faster rate than the longer duration events which if not taken into account can lead to poor design of urban drainage this is also evident from the 1 h non stationary and stationary rls for all the return periods shown in fig 8b and c which clearly indicate an 50 increase in the non stationary case than that in the stationary case in case of bombay fig 9 rl for a 100 year event in the non stationary case is higher than that in the stationary case for all the durations where the difference decreases from 5 6 mm h to 2 mm h for 3 h and 207 h durations respectively this trend holds true for different return periods as well as can be seen in fig s15 in supplementary information where the rl of short duration events increases faster than longer ones similar to bangalore it is clear that the stationary assumption will result in the underestimation of the flood peaks in both the highly urbanized metro cities where the actual flood risk is significantly higher than what the system and infrastructure were designed for gupta 2007 whereas in calcutta the rl of short duration events decreases compared to the longer events as anticipated fig 10 a besides the stationary rl is higher than its non stationary counterpart and hence the use of the stationary approach in calcutta may lead to over estimation finally in madras fig 11 the difference between stationary and non stationary rls is relatively lesser than the other stations where the difference is more for short durations in the non stationary case than the stationary and it decreases as the duration increases moreover the time varying rl shows an increase at a rate of 0 04 mm h year while it decreases at a negligible rate for longer duration events this is in agreement with the trend of intensity and duration mentioned above overall the changes in extreme events happened more in short duration events than in longer duration regardless of whether it intensifies or subsides except bangalore all other stations exhibit stationarity according to traditional nsm which eventually would lead to overestimation or underestimation the dynamic behavior of the attributes of other stations would not have been captured by traditional nsm because of the criterion used to decide time varying models in addition the consideration of multiple combinations models in traditional nsm increases the complexity multi fold agilan and umamahesh 2017a b thereby rendering it computationally inefficient the proposed method averts these limitations by choosing only the relevant combinations hence instead of using the traditional nsm approach by merely detecting the trend in the attributes the policymakers and designers could employ the refined approach proposed in this study for efficient planning and management of water resource systems 4 conclusions this study presents an innovative approach to model the intensity duration relationship of extreme rainfall incorporating the non stationarity in the precipitation time series a dynamic copula based multivariate extreme event modeling utilizing bayesian inference has been developed unlike traditional non stationary modeling traditional nsm the present approach detects the non stationarity in each distribution parameter using a time sliding window then each parameter is modeled using a linear time varying model only if it exhibits the signature of non stationarity it is assumed to be constant stationary otherwise the proposed methodology is employed to develop the time varying intensity duration model for four major metro cities i e bangalore bombay calcutta and madras in india using hourly rainfall data the intensity duration models developed for these stations reveal that the statistical property of variance has undergone more changes than mean which is not captured by the traditional nsm approach further the time varying return period of extreme flood events using representative past flood levels in the respective places shows a decreasing trend of return period at a rate of 0 54 yr yr 1 15 yr yr 0 12 yr yr for bangalore bombay and madras respectively whereas the traditional nsm approach would have modeled bombay and madras as stationary due to lack of trend in the attributes thereby underestimating the return period of the extreme flood our results illustrate that the proposed non stationary model is adaptive in incorporating the non stationary distribution parameter for each station instead of adopting the same parameter for all the stations it also reduces the complexity by bypassing non stationary models for parameters exhibiting insignificant non stationarity making it flexible to incorporate both stationary and non stationary models for multivariate frequency analysis furthermore the proposed framework offers the time varying joint return period and rl along with their uncertainty bounds overall it can be inferred that the proposed non stationary model may be able to estimate the hydrological design variables more realistically than both stationary and traditional non stationary models which over underestimate them the changing extremes in precipitation pose a major threat to existing hydrological system and infrastructure designed based on the stationary methods hence in order to devise adaptation and mitigation strategies it is inevitable to update our water resources practices according to the changes in the characteristics of extremes by incorporating the non stationarity in a realistic manner supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 06 009 appendix supplementary materials image application 1 image application 2 
623,a 2d depth integrated subgrid hydrodynamic model frehdc is designed to simulate effects of subgrid scale topography on flow and scalar transport in shallow coastal marshes using computationally efficient grid cells that are coarser than many of the channelized paths through the marsh the subgrid scale topography is parametrized into four depth dependent variables subgrid cell volume and three subgrid face areas that characterize the high resolution features of coarse grid cells these variables are pre stored in a table and embedded into the governing equations as model inputs to scale cell storage mass and momentum fluxes across cell faces a block checking procedure is designed to automatically preserve high resolution surface connectivity during grid coarsening by testing on both synthetic domain and real marshes this new model is able to approximate fine grid simulation results of surface elevation inundation area flow rate and salinity with less computational cost keywords subgrid topography model hydrodynamic modeling shallow coastal marsh scalar transport surface connectivity 1 introduction high resolution topographic data obtained from lidar typically at a 1 m scale are difficult to directly use in a fine resolution hydrodynamic model for an extensive marsh system due to the small model time step and large number of computational cells that would be required for example a 10 10 km marsh would require 108 grid cells and a time step of less than 10 s using a highly efficient computational model with 100 floating point operations per time step per grid cell would requires a petaflop supercomputer with terabytes of memory to achieve practical computation speeds of 100 faster than real time while such computers exist they are typically not available for scientists and engineers studying flow and transport through marshlands thus to effectively use high resolution data some form of grid coarsening scheme must be employed the challenge of handling known but unresolved bathymetry complicates the challenge of handling unknown or poorly known bottom roughness wang et al 2009 unfortunately a coarse grid cannot directly represent many of the small but hydrodynamically important topographical features that are evident in lidar data e g hodges 2015 grid coarsening or topographic upscaling usually involves filtering the high resolution data to get approximations of the bottom elevations which introduces errors in hydrodynamic modeling of the flow depths that in turn affects the modeled velocities and fluxes cea and french 2012 furthermore subgrid scale channels and water blocking ridges are often widened or smoothed on coarse grids which leads to i overestimated flow rates in channels that are widened ii underestimated resistance where surface roughness is smoothed cea et al 2014 iii erroneous surface connectivity and iv different flow patterns either channelized flow or shallow sheet flow due to shifts in the wetting drying front sullivan et al 2015 torres and styles 2007 these problems have been previously noted and subgrid methods have been developed by a number of researchers to represent high resolution topographic effects on coarse grids e g bates et al 2003 casas et al 2010 d alpaos and defina 2007 duan et al 2017 guinot 2012 guinot et al 2018 hodges 2015 jan et al 2018 kim et al 2015 loftis et al 2016 neal et al 2012 ozgen et al 2016a ozgen et al 2015 ozgen et al 2016b sanders and schubert 2019 stelling 2012 viero and valipour 2017 volp et al 2013 yu and lane 2006a yu and lane 2006b of interest for the present work are methods using artificial porosity to scale the volumetric flow rates in out of the grid cells as proposed by defina et al 1994 artificial porosity can be treated as a function of the free surface elevation as well as the high resolution topography by multiplying porosity into the governing equations the high resolution topographic information is embedded into coarse grid models however dependency between artificial porosity and surface elevation introduces another nonlinearity to the governing equations early attempts used empirical relationship between porosity and depth for linearization defina 2000 which showed good performance on simple idealized topography bates 2000 a recent approach by wu et al 2016 used pre stored porosity parameters calculated for all possible surface elevations in a look up table model porosity was updated for each grid at each time step by searching in the table since the pre stored porosities are calculated from high resolution data the method can be used on domains with complex topography where empirical relationships do not hold casulli 2009 developed an algorithm to solve the mildly nonlinear system produced by porosity depth coupling with minimal additional computational cost and ensured conservation of mass in the free surface solution this method was proven to improve the model performance on sections of the elbe river platzek et al 2016 sehili et al 2014 artificial porosity has also been used for modeling urban floods where buildings are difficult to represent with an integral porosity ip model sanders et al 2008 this approach embeds volumetric and anisotropic areal porosities in the governing equations although anisotropy of areal porosity was proven necessary the ip model was subsequently shown to be sensitive to mesh design guinot 2017a further improvement on the ip model was made by correcting the flux terms referred as dip model that alleviated dependencies on the mesh guinot 2017b guinot et al 2017 nevertheless a practical application involving a levee breach flow through a residential neighborhood showed that the dip model cannot capture the full distribution of velocity directions and magnitude that are resolved by finer resolution models furthermore the dip mesh must be strategically placed so that the cell edges intersect with water blocking structures otherwise the effects of these structures will not be correctly reflected from areal porosity despite the noted progress in subgrid methods a key unsolved problem is the lack of a method that automatically preserves high resolution surface connectivity during grid coarsening in the present study surface connectivity refers to the network of flux paths through a marsh system which is controlled by channels and blockages in topography connectivity is generally increased when a channel is widened by grid coarsening however grid coarsening can also interrupt surface connectivity where it eliminates narrow channels from the high resolution topography this effect has been noted to be a function of a coarsening ratio r which is defined as the ratio of the coarse grid length scale to the fine grid length scale wu et al 2016 has reported unreasonable model results when r 4 due to interrupted connectivity li and hodges 2018 showed that poor representation of surface connectivity caused significant discrepancies between modeled salinity fluxes and observations in a coastal marsh identifying small but hydraulically important topographical features that must be represented to maintain adequate surface connectivity remains a challenging task yu and lane 2011 detected water blocking features and added artificial walls to maintain surface connectivity by hand which was time and labor consuming chen et al 2012 used a multi layer method solving the model equations for the two regions bisected by the water blocking feature separately but for general marsh topography where the use of multiple layers more than two is expected this approach could severely increase computational cost neal et al 2012 used a subgrid method that simulates effects of narrow channels in floodplains but it requires characterization of channel geometry for coastal marshes with frequent wetting drying it is not easy to separate the domain into distinct channels and floodplains hodges 2015 designed an automatic channel and cell edge identification method to detect small scale water blocking features but some narrow channels still needed to be manually identified in practical applications li and hodges 2018 a recent study on urban floods sanders and schubert 2019 also emphasized the needs of automatically detecting small scale topographic features many subgrid methods have been developed for flood modeling where free surface elevation and inundation area are the variables of interest in contrast the coarse grid effects on scalar transport processes e g salinity have not been extensively studied scalar transport modeling typically has greater uncertainties than modeling surface elevation aizinger et al 2013 inoue et al 2008 wang et al 2009 because scalar error is inherently accumulative over the residence time scale of the modeled system and does not have a feedback effect in contrast by definition for slow moving marsh waters the errors leading to local accumulations or deficits in surface elevations must also lead to changes in the surface gradients with neighbor cells which in turn induce errors in the local fluxes that will counteract the accumulation or deficit of surface elevation furthermore modeling advective scalar transport in shallow marshes requires accurate reproduction of the velocity field which is more sensitive to grid coarsening errors than is surface elevation mazzolari et al 2015 it has been shown that a subgrid model with minimal surface error could still contain large errors for the modeled flux shin 2016 the present study is an outgrowth of efforts to understand the effectiveness of freshwater inundation in reducing salinities across tidal marshes of the nueces river delta texas usa as described in li and hodges 2018 we previously identified two key issues that limited the existing models i stability of numerical methods for wetting drying fronts and ii obtaining correct connectivity at the practical model grid resolution the former was addressed in new methods proposed in li and hodges 2018 and herein we examine how the new subgrid model improves the representation of marsh connectivity and salinity scalar transport the new method section 2 borrows the concept of artificial porosity and uses a pre store of high resolution topographic information similar to wu et al 2016 the relationships between the coarse and the fine grid are stored as a group of subgrid variables similar to artificial porosity which saves computation efforts section 2 1 the governing equations are discretized by including the subgrid variables as parameters section 2 2 an automatic checking routine is designed to effectively capture narrow water blocking features section 2 4 model results are evaluated with respect to surface elevation inundation area and salinity through comparisons with high resolution simulation results and field data section 3 the advances and limitations of the proposed model are summarized in section 4 2 methods the new subgrid method is implemented in a two dimensional 2d depth integrated solution of the shallow water equations the numerical methods for the solution are a hybrid finite volume difference approach developed from the three dimensional 3d fine resolution environmental hydrodynamic model frehd which is a descendent of trim casulli and cattani 1994 and elcom hodges et al 2000 models the 3d frehd model was written in matlab scripting to develop and test new algorithms for 3d flow and transport in natural environments hodges 2004 2014 2015 hodges and rueda 2008 rueda et al 2007 wadzuk and hodges 2009 for seasonal to annual simulations the serial matlab implementation of frehd is too slow for more than 104 grid cells and does not parallelize well the code structure was designed to allow implementation and testing of new algorithms which hampers parallel solution efficiency the basic frehd algorithms for 2d have been rewritten in the c programming language to improve computation efficiency parallelization is achieved using the message passing interface mpi where the entire model domain is divided into sub domains of equal sizes a range of 1 to 32 threads are used for the simulations performed in the present study good scaling property is observed within this range results not shown because parallelization is not the focus of the present study this new 2d version is named frehdc 2 1 subgrid geometry definitions before presenting the governing equations and discretization schemes of the frehdc model it is useful to define the subgrid geometry variables that describe the high resolution characteristics of a coarse grid consider a coarse grid cell i j in a 2d domain with dimensions δx by δy which contains λ ψ high resolution subgrid cells let ω to represent the domain of cell i j and γ its boundary the size of one subgrid cell is δx δy where λ δ x δ x and ψ δ y δ y fig 1 shows an example of a coarse grid cell with λ ψ 4 each subgrid cell is labeled using λ ψ where 1 λ λ and 1 ψ ψ the bottom elevation of a subgrid cell is denoted as z i j λ ψ the coarse grid cell ω i j is characterized by a single value of surface elevation η i j a single value for bottom elevation z i j is defined as 1 z i j min λ ψ ω z i j λ ψ the use of min function ensures the cell is identified as wet i e contains some water even when only a single of the λ ψ subgrid cells is below the free surface for regions with frequent wetting and drying this definition is necessary to represent the inundation area and flux paths the volume of cell ω i j is defined as 2 v i j λ ψ ω max η i j z i j λ ψ 0 δ x δ y where the max function ensures that dry subgrid cells are not counted as negative volumes if no subgrid topography exists eq 2 simply reduces to v i j h i j δ x δ y where h i j η i j z i j is the depth similarly we may define the cell face areas as illustrated in fig 1 for example the face areas normal to the x axis on the plus and minus sides of ω i j are 3 a x i 1 2 j k 1 ψ max η i j z i j λ k 0 δ y a x i 1 2 j k 1 ψ max η i j z i j 1 k 0 δ y the face areas normal to the y axis on the plus and minus sides of ω i j are 4 a y i j 1 2 k 1 λ max η i j z i j k ψ 0 δ x a y i j 1 2 k 1 λ max η i j z i j k 1 0 δ x and the face area on the top face of the grid cell is 5 a z i j λ ψ ω ϵ i j λ ψ δ x δ y 6 ϵ i j λ ψ 1 η i j z i j λ ψ 0 η i j z i j λ ψ for use in discrete equations the subgrid variables v ax ay and az are labeled by its i j indices which are the coordinates of its center for example we can also write ax i j to represent the face area normal to the x axis centered at i j or v i 1 2 j to represent the cell volume centered at i 1 2 j these subgrid variables are introduced into the discrete governing equations as illustrated in the following section 2 2 governing equations the 2d depth integrated free surface equation momentum equations and the scalar transport equation can be written in an integral form similar to sanders et al 2008 7 t ω η d ω γ u n d a 0 8 v u t u n u x d v γ g η n d a γ τ ν n d a ω τ b d ω 9 t v c d v γ u n c d a γ τ κ n d a where η is the free surface elevation u u v t are depth averaged velocities x x y t are the corresponding cartesian axes n is the normal unit vector to a flux surface γ τb is the bottom stress τ ν is the viscous stress c is the scalar concentration and τ κ is the scalar diffusion term an infinitesimal volume inside the grid cell is dv with infinitesimal cell face areas da which can be written as d a h γ d γ where h γ is the depth function along the cell boundary the density is assumed to be a constant the bottom stress and viscous stress are defined as 10 τ b 1 2 c d u u 11 τ ν ν u x ν u y t where ν is the eddy viscosity and cd is the drag coefficient defined as 12 c d g n 2 h 1 3 h v δ x δ y in eq 12 n is the manning s roughness coefficient which is assumed to be a constant in the present study the scalar diffusion terms are computed as 13 τ κ κ c x κ c y t where κ is the eddy diffusivity we use κ ν 10 4 m 2 s 1 because the frehd model has been shown to be insensitive to eddy viscosity for shallow estuaries and tidal marshes li and hodges 2018 indeed it can be argued that any depth averaged coarse grid hydrodynamic model will be insensitive to eddy viscosity in a marsh simulation because bottom drag and form drag associated with torturous channelization will dominate the effects of horizontal shear at the low velocities that are typical of such systems arega and sanders 2004 although dispersion at channel bends could have strong effects on the flow field begnudelli et al 2010 in narrow coastal channels there often lacks sufficient grid resolution to fully resolve the bends which makes numerical dissipation to be the dominant process li and hodges 2018 a detailed study on the relations between eddy diffusion numerical diffusion and dispersion especially under the existence of subgrid scale topography is beyond the scope of the present study but it deserves further investigation in the future unlike some existing 2d subgrid models that are shock capturing e g guinot et al 2018 frehdc does not include any specific treatments regarding shock waves because flow in coastal marshes is generally slow inundation is often tidal driven which occurs at longer time scales than flash floods highly irregular topography and existence of vegetation further decelerates propagation of inundation extent making shock capturing a secondary task the solution algorithm of frehdc uses the semi implicit approach of casulli and cattani 1994 where the free surface gradient is discretized with a θ method weighted implicit scheme however the nonlinear advective terms are discretized using first order upwind as discussed in li and hodges 2018 using a finite volume method the free surface equation eq 7 is discretized with subgrid derived areas as 14 η i j n 1 a z i j n δ t u i 1 2 j n 1 a x i 1 2 j n u i 1 2 j n 1 a x i 1 2 j n v i j 1 2 n 1 a y i j 1 2 n v i j 1 2 n 1 a y i j 1 2 n η i j n a z i j n δ t i i j n 1 2 where i i j is the volumetric flow rate of the inflow boundary condition n represents time level when appears as superscript the above applies a time linearization of the subgrid areas e g the a x n is a coefficient of the u n 1 which is similar to the time linearization of geometry δz that appears in many conventional semi implicit schemes hodges 2004 the momentum equation eq 8 is discretized with respect to a staggered grid volume ω i 1 2 j as for simplicity only the momentum equation in x direction is derived 15 u i 1 2 j n 1 g δ t a x i 1 2 j n v i 1 2 j n k i 1 2 j n η i j n 1 η i 1 j n 1 k i 1 2 j n e i 1 2 j n where k i 1 2 j n is the inverse of the coefficient of implicit velocity u n 1 that appears due to time linearization of the drag term to maintain stability during flow reversals li and hodges 2018 and e i 1 2 j n contains all the explicit terms specifically these are 16 k i 1 2 j n 1 a z i 1 2 j n 2 v i 1 2 j n c d x u 1 17 e i 1 2 j n u i 1 2 j n δ t ν a x i 1 2 j n v i 1 2 j n u x i 1 j u x i j δ t ν a y i 1 2 j n v i 1 2 j n u y i 1 2 j 1 2 u y i 1 2 j 1 2 δ t u u x v u y i 1 2 j at each time step the velocities u n 1 and v n 1 from eq 15 and the corresponding y momentum equation are substituted into eq 14 forming a five diagonal linear system for the free surface elevations 18 η i j n 1 a z i j n g x p i j n g x m i j n g y p i j n g y m i j n η i 1 j n 1 g x p i j n η i 1 j n 1 g x m i j n η i j 1 n 1 g y p i j n η i j 1 n 1 g y m i j n η i j n a z i j n δ t i i j n 1 2 δ t e i 1 2 j n e i 1 2 j n e i j 1 2 n e i j 1 2 n where the matrix coefficients are defined as 19 g x p i j n g δ t 2 a x i 1 2 j n 2 v i 1 2 j n k i 1 2 j n g x m i j n g δ t 2 a x i 1 2 j n 2 v i 1 2 j n k i 1 2 j n g y p i j n g δ t 2 a y i j 1 2 n 2 v i j 1 2 n k i j 1 2 n g y m i j n g δ t 2 a y i j 1 2 n 2 v i j 1 2 j n k i j 1 2 n in frehdc this linear system is solved by applying conjugate gradient method with symmetric successive over relaxation preconditioner available through laspack the η n 1 from solution of eq 18 are substituted into eq 15 and a similar y momentum equation to get updated velocities u n 1 and v n 1 the scalar transport equation eq 9 is discretized using finite volume method at the x plus face the net scalar mass mc across the face is 20 δ m c i 1 2 j n 1 δ t a x i 1 2 j n 1 u i 1 2 j n 1 c i j n κ c x i 1 2 j summing mass fluxes on all four faces and allowing sources sinks of mass provides 21 m c i j n 1 m c i j n δ m c i 1 2 j n 1 δ m c i 1 2 j n 1 δ m c i j 1 2 n 1 δ m c i j 1 2 n 1 s o u r c e s i n k the updated scalar concentration is 22 c i j n 1 m c i j n 1 v i j n 1 2 3 subgrid geometry update the subgrid geometry variables defined in section 2 1 are all functions of the free surface elevation ideally their values should be updated simultaneously with the free surface elevation to maintain mass conservation casulli 2009 in practice the geometry time linearization discussed in section 2 2 allows a simple linear implicit solver to be used for the free surface solution a pre stored approach wu et al 2016 is adopted herein for the update computation at the solution start we initialize an array that contains pre defined free surface elevations and their corresponding subgrid geometry i e an array indexed by η p d η min η min δ η η min 2 δ η η max where η min and η max are based on expected maximum and minimum values for the system for each η in ηpd the corresponding subgrid geometry variables are computed and stored for each time step when the new free surface elevation η i j n 1 is computed we search in ηpd for η p d k η i j n 1 η p d k 1 and interpolate the subgrid variables between ηpd k and η p d k 1 for computational efficiency in searching in the pre defined array of surface elevations our algorithm begins from the last known interval η p d k η p d k 1 if η n 1 does not fall within in this interval we continue by searching neighbor intervals this strategy significantly reduces the computation costs compared to an arbitrary search over η min η max 2 4 block checking for internal features in section 2 1 the cell face areas are defined using only the high resolution data that is coincident with the cell faces which naturally creates a water blockage if all the subgrid cells are dry along a face however a water blocking feature in the interior of a cell cannot be directly represented by the cell face areas using the subgrid geometry as defined above for example we can imagine a case where a x i 1 2 j 0 and a x i 1 2 j 0 combined with a x i j 0 which would allow flow from the i 1 j cell to the i 1 j cell through the i j cell because the ax i j does not appear in the discrete equations thus an additional algorithm is required to locally alter the subgrid geometry and account for internal blocking effects this is similar to the problem addressed in hodges 2015 where the interior blocking height of subgrid geometry across a coarse grid cell was identified and the feature was snapped to the nearest face the result was a static face geometry that included effects of interior blockages which was accomplished as a pre processing step to a hydrodynamic model herein we develop an approach that accomplishes a similar task but is integrated in the approach for the hydrodynamic solution through direct effect on the ax and ay internal blocking is handled through a discrete analysis of subgrid geometry at each of the ηpd k elevations in the pre stored subgrid geometry array a five step process is used to modify the ax and ay on each face that is the face areas at a given ηpd k retain their values computed by the faces unless an effective interior blockage is detected in which case the appropriate face area is set to zero the process for each coarse grid cell is 1 at each pre defined surface elevation ηpd k create a binary wet dry map within a coarse grid cell that contains λ ψ subgrid cells 2 cycle through each of the ηpd k computing steps 3 5 below and modifying the subgrid geometry array 3 identify the single largest fully connected wet patch in this coarse grid cell at this elevation mark the remainder of this cell as dry 4 if the intersection between the wet patch and a coarse cell face at this elevation is zero this face is blocked and has a subgrid face area of zero 5 for two adjacent coarse grids both with nonzero areas on their common face at the same elevation if the intersection of their wet subgrid indices on this face is an empty set their common face area is zero in the present implementation this algorithm is used only at the start of the simulation to pre store the effects of internal blocking however the algorithm could be easily introduced within the hydrodynamic time stepping loop to allow dynamic modification of subgrid geometry erosion or aggradation issues that are worthy of further investigation an example of the block checking technique is shown in fig 2 a where the water regions blue are divided by the land brown forming a river channel from left to right that is mostly not connected to the surrounding marshes following eqs 3 and 4 at r 15 without block checking the river bank would only be partially identified and blocked as shown by the light blue faces that are the only subgrid faces with zero areas thus näive application of the subgrid definitions in section 2 1 will allow imaginary flow paths between the channel and its surrounding marshes the new block checking method identifies the red faces as additional blocked faces based on the high resolution topography of the interior of each coarse grid cell which fully delineates the channel banks at an r 15 coarsening as shown in fig 2a however the block checking method does not allow coarsening to arbitrarily large r as illustrated in fig 2b for r 30 as the coarsening ratio increases there is an increasing likelihood that multiple unconnected flow paths could exist in a single coarse grid cell but the block checking method step 3 is limited to considering only the largest inundation area in a grid as the true connected region of a single cell this approach inherently blocks other flow paths because only one velocity is allowed to exist on each face in fig 2c one cell from fig 2b delineated by a green box is examined in detail the top panel shows the binary wet dry map step 1 of the original cell which contains two disconnected water regions a1 and a2 comparing to fig 2b we found that a2 belongs to the river channel and a1 is located in its surrounding marshes the bottom panel of fig 2c shows the wet dry map after performing step 3 where a2 is turned into land because its area is less than a1 this leads to blocking of the east face through step 4 and the south face through step 5 of the target cell which interrupts channel connectivity despite the failure behavior of the block checking method at large r it still shows advantages over naïve upscaling and the edge identification method by hodges 2015 in maintaining surface connectivity which will be verified in section 3 it should be aware that model dependency on r varies for different domains so to improve applicability over a variety of domains the proposed block checking method could be combined with some quantifications that reflect the complexity of topography which is a topic that deserves further investigation 3 test cases and results the new subgrid methods are tested on three bathymetries i an idealized channel ii a highly resolved portion 170 hectare of a narrow waterway at the west end of the nueces delta the upper rincon bayou urb and iii a larger portion 2178 hectare of the nueces delta the upper nueces delta und to understand the effects of the subgrid model we generate a range of model bathymetries to use for comparisons the baseline comparison cases m use a 2δx median filter for upscaling topography as described in hodges 2015 the m simulations are a naïve grid coarsening that is applied without any consideration of subgrid features in the upscaling or in the numerical solution the second set of comparison cases are mb cases median filter with block checking which use the approaches of hodges 2015 and li and hodges 2018 to upscale topography as edge blocking and channelization but do not include the new subgrid model described above the test cases with the new subgrid model section 2 1 2 3 are labeled the s test cases the test cases using the new subgrid model together with the new block checking method section 2 4 are named sb note that the letter b indicates the use of a block checking method to identify small scale water blocking features but identification processes are different for mb and sb the former comes from hodges 2015 and the latter follows section 2 4 the difference between tested scenarios are summarized in table 1 3 1 idealized channel the idealized channel bathymetry uses a uniform flat bottom with bottom elevation 0 5 m with a varying width wide channel 50 to 120 m width connected internally by a narrow channel 5 m wide and accompanied by two non submerged vertical walls as illustrated in fig 3 the forcing boundary condition for this test case is a sinusoidal tide range from 0 8 to 1 2 m above the z 0 bottom with a period of 6 h along the open boundary of the model domain the initial surface elevation is uniform at the tidal elevation for t 0 the initial velocities are all zero the initial scalar concentrations herein salinity are created with a piecewise constant function that can be visualized in fig 3 which makes it easy to observe instantaneous flow patterns all over the domain the salinity at the tidal boundary is fixed to a constant value of 25 psu for idealized channel test cases we apply a grid coarsening ratio of r 10 δ x 10 m which is the point where the narrow channel and the walls are entirely lost in the m coarse grid but still appear in the mb grid however the mb overestimates the interior wall heights and the width of the narrow channel the modeled salinity transport in the idealized channel at t 7 h is shown in fig 4 the fine grid simulation fig 4a shows the higher salinity wrapping around the unsubmerged walls and a small flux through the narrow channel these features are qualitatively reproduced by the subgrid model fig 4d the coarse grid simulation m fig 4b produces a significantly different transport result due to the loss of the interior walls and the narrow channel the mb simulation fig 4c shows some effects of the walls but allows greater flux through the narrow channel because the channel is widened to match grid size note that the blocking walls that are evident in the control solution do not appear in the visualization of the subgrid model results because the min function is used for bottom elevations eq 1 but their effect is captured by the subgrid model as can be clearly seen in the sharp rectilinear change in the salinity contour where the walls should be in fig 4d a quantitative evaluation of the subgrid model is performed by estimating the absolute error of salt flux over one tidal period across two cross sections in the wide and narrow channel respectively x1 and x2 as labeled in fig 4a the fine grid simulation is used as the true solution for computing error as shown in fig 5 the sb simulations produce minimal errors among all test simulations for both channels the interquartile ranges iqr for the subgrid simulations are also much smaller indicating that the sb scenarios consistently outperform the other scenarios over the entire tidal period error for the coarse grid simulation m is not shown at x2 because the narrow channel is completed ignored after filtering 3 2 the upper rincon bayou urb the two test cases with real world bathymetry use a lidar data set from the nueces river delta along the texas usa coast near the city of corpus christi this data was previously used in studies of hodges 2015 li and hodges 2018 ryan 2011 wherein further details can be found the nueces delta is a shallow micro tidal river delta with limited freshwater inflows the river now debouches through a main channel that is isolated from the delta and upstream dams have reduced overbanking events that previously flooded the system increasing episodes of hypersalinity became subject of a lawsuit and eventually an agreed order to mitigate the impact of the dams on the wetlands lloyd et al 2013 towards this end a pumping system was installed for controlled introduction of freshwater into the upstream end of the delta del rosario and montagna 2018 hill et al 2015 lloyd et al 2013 the delta system has been subject of a number of studies and physical modifications over the past two decades the test bathymetry for the upper rincon bayou urb shown in fig 6 is a small section extracted and slightly modified from the full 1 1 m data set this is a section of the rincon bayou where the shallow depth and complex flow paths caused poor model data agreement in a prior study li and hodges 2018 an artificial bay on the east end of the model domain is connected by a narrow channel to the rincon bayou to provide the tidally driven forcing the channel dimensions are similar to those in the rincon overflow channel roc that was created to improve flushing in the upper marsh dunton et al 2000 the west end of the domain is blocked with a fixed wall a sinusoidal tide with range from 0 3 m to 0 7 m and period of 24 h is added to the open boundary on the east for the urb test case for the urb simulations the control simulation uses δ x δ x 1 m the reference cases mb and the sb test simulations use grid coarsening with r 4 8 16 32 i e δx 4 8 16 32 m since we have shown the effectiveness of mb over m in fig 5 and in li and hodges 2018 the subgrid model is only compared to mb fig 7 shows the surface elevations at t 34 h for r 1 16 32 results at coarse resolutions are downscaled onto the high resolution bathymetry following sanders and schubert 2019 the overall differences between the surface elevations in the control 1 1 m simulation the reference simulations mb and the test simulations sb are small in magnitude mostly a few cm across the majority of the domain all the coarse grid simulations tend to overestimate the surface elevation with the mb scenarios having a more substantial disagreement than the sb scenarios a clear quantitative difference is in the marginal wetland flooding that shows up as dark purple along the lower left edge of fig 7a the dark purple indicates lower water surface elevation due to constricted connectivity between the bayou and this wetland area all of the sb results preserve the reduced connectivity and lower water surface elevations however for the coarse grid r 16 scenario with mb the connectivity to the wetland is increased and it floods to higher water surface elevations we can better understand this effect by examining areal flooding extent as shown by the time evolution of the integrated inundation area in fig 8 for the s and sb scenarios inundation area is simply the sum of subgrid face areas az for an mb scenario performed at r 1 two methods are used to estimate inundation area the first method is based on the coarse grid bathymetry at r where all wet coarse cells have a surface area of δxδy fig 8a the second method downscales the modeled surface elevation onto r 1 fine grid bathymetry sanders and schubert 2019 and sums the areas of the wet fine cells fig 8b for both methods at r 8 the disagreement in the mb begins to increase and has significantly diverged from the other simulations at r 16 and r 32 in contrast the sb results at r 16 and r 32 remain quite similar to the control case at r 16 the s scenario generates higher errors than sb but it still outperforms mb the block checking method section 2 4 prevents creation of unexisted new flow paths during grid coarsening whereas the use of minimum bottom elevation eq 1 prevents removal of existing narrow flow paths the comparison between mb s and sb indicates both methods are important in maintaining surface connectivity when coarsening the shallow marsh bathymetry more insights are obtained by analyzing the different behaviors of mb scenarios between fig 8a and b the difference in inundation areas between the mb and sb scenarios are affected by three factors i surface connectivity of key flow paths ii surface area within the coarse grid cells using az versus δxδy and iii predicted surface elevations in fig 8a the mb scenarios overestimate inundation area because the dominant factor here is ii in fig 8b however the effects of factor ii is removed because the surface area is calculated at fine scale underestimation of inundation area is thus caused by factor i where many deep subgrid cells near the wetting drying front are smoothed on the mb bathymetries factor iii has negligible effects on the tested scenarios because the difference in predicted surface elevations are small only a few centimeters fig 7 with either fig 8a or b the results verify the effectiveness of the new subgrid method sb in maintaining high resolution surface connectivity and inundation patterns at large r quantification of flow rate error in the channel between the bay and the rincon bayou over one tidal period is provided in fig 9 since we have shown that sb is superior over s in maintaining surface connectivity the following analysis only focus on the difference between sb and mb the mb scenarios show maximum error at r 32 and decreasing error as r increases from 4 to 16 since natural topography is spatially heterogeneous grid refinement does not necessarily reduce model error the grid coarsening method adopted hodges 2015 involves filtering as well as edge and channel identification so its ability to resolve high resolution topography does not depend on r alone furthermore grid coarsening enhances numerical diffusion which reduces flow rates the reduction of model error for r 16 mb may be caused by a balance between multiple error sources despite the complex behaviors of model error two observations can be made regarding the proposed subgrid model first the sb model errors show weak dependency on r which allows it to perform well at very coarse grid in fig 9 the mb error abruptly increases at r 32 the sb error however maintains a mild increase second the sb errors produce smaller iqr than the mb scenarios indicating stable variations over the entire tidal period this is an evidence that the sb error does not come from occasional balance between multiple sources but from processes that are not simulated in the present subgrid model e g topographical features in the cell interior although the mb simulation can produce a slightly smaller median error e g at r 16 it always has a larger interquartile range indicating the subgrid model has better applicability over a variety of domains coarsening ratios and flow characteristics 3 3 the upper nueces delta und the texas water development board twdb collected field data of water depth and salinity at 14 monitoring stations in the nueces delta which enables us to test the subgrid model with realistic boundary conditions the final test case upper nueces delta und uses a larger portion for the nueces delta as shown in fig 10 the pump station where freshwater is introduced is noted at the left side of the figure the region between the pump station and the rincon overflow channel is the area extracted for the urb test case in fig 6 six of the 14 twdb monitoring stations are located within this domain which are labeled from nueces1 to nueces6 a 7th station is located at the east boundary which is used to provide tidal and salinity boundary conditions other boundary conditions involved are wind data available at texas coastal ocean observation network tcoon as well as pump inflow that is available from nueces river authority nra three cross sections y1 to y3 are labeled in fig 10 flow rates across these sections will be used as indicators for evaluating model performance for the und running a multi month simulation at δ x 1 m is impractical with our available computational power so we use only coarser simulations along with field data for real world evaluation of the model performance in modeling the upper nueces delta und the tested coarsening ratios are r 5 10 15 30 50 75 to avoid overlong spin up at fine resolutions we use a 45 day spin up time from apr 1st to may 15th of 2013 at r 15 followed by a 15 day spin up at each tested value of r previously the full nueces delta modeled at coarse resolution was shown to have a 60 day spin up for salinity li and hodges 2018 the model results are reported for a 15 day period in the first half of june 2013 which brackets an 11 day period during which the pumping system was providing a total of 106 m3 freshwater into the upstream end of the delta nra fig 11 shows a qualitative comparison of the salinity fields during pumping for r 5 30 50 it can be seen that the three subgrid scenarios predict similar spatial distribution of freshwater but as r increases stronger numerical diffusion smooths salinity gradient at the interface of fresh and saline water compared to the sb scenario the mb at r 5 predicts more freshwater entering the west lake via rincon overflow channel roc and less freshwater down through rincon bayou but this difference is negligible compare to the differences at larger r the mb at r 30 underestimates pump flow in both channels which is likely caused by an overestimation of volume as the mb grid coarsening procedures are not volume conservative at r 50 freshwater into the west lake is completely omitted in mb scenario because the surface connectivity of the roc is cut off we may conclude that the subgrid model is relatively insensitive to r as it better approximates the high resolution surface connectivity and salinity transport patterns at relatively large r r 30 50 owing to the conservation of subgrid cell volume as well as the block checking procedure a quantitative comparison of absolute values of flow rates not flow rate errors for all und tested scenarios are given in fig 12 for the three cross sections labeled in fig 10 two main observations can be made 1 for most values of r the sb scenarios have relatively smaller iqrs than the mb scenarios and they show relatively weak dependency on r this phenomenon is particularly obvious at y3 fig 12c 2 for r 50 surface connectivity of the mb scenarios begins to be interrupted which is reflected by a sudden decrease of median flow rate and iqr at y1 this matches the observation from the salinity contour fig 11e the interruption of connectivity is also found for sb but at a higher value of r 75 these two observations again indicate than compare to mb the proposed subgrid model better preserves the high resolution topographical characteristics surface connectivity and volume at large grid coarsening ratios the sb bathymetry is able to maintain surface connectivity at higher r than mb even if both scenarios maintain surface connectivity using mb bathymetry overestimates flow rate due to expansion of channel width to match the grid size li and hodges 2018 which leads to higher iqr and strong dependency on r however since the cell volumes are also overestimated given the same inflow rate from pumping it decelerates salinity transport towards the west lake because freshwater accumulates in the rincon bayou the modeled salinities are compared to the field data in fig 13 to provide further insights it should be noted that although comparisons at all six stations in fig 10 can be made they do not necessarily highlight the effectiveness of the subgrid method because the stations might be located in regions where variation of subgrid scale topography is smooth and trivial or other error sources might dominate fig 13 only shows results at nueces3 and nueces5 located near y1 and y2 fig 10 where scalar patterns are strongly affected by subgrid topography results at other stations are provided as supplemental material a detailed analysis of model data agreements and other dominant error sources can be found in li and hodges 2018 at nueces3 fig 13a the decrease of salinity upon freshwater pumping is successfully reproduced by all sb scenarios but for the mb scenarios salinity displays oscillatory behaviors at r 30 50 it implies weaker freshwater flushing which is in agreement with fig 9 as stated above this is caused by an overestimation of volume that slows down spreading of salinity at nueces5 fig 13b all test scenarios predict delayed response to freshwater pumping it comes from a combination of errors such as bathymetry boundary condition and possibly field data itself li and hodges 2018 due to the complex nature of shallow marsh modeling the subgrid model is not expected to correct all errors in one step but it certainly provides improvements over existing mb models especially at large r and at locations where surface connectivity is easily broken 3 4 computational cost the key advantage of any subgrid method is in the ability to model a system faster than would be required at fine grid resolution thus there is always a question as to how much additional cost is incurred by the subgrid algorithm itself the effective computational cost of the subgrid algorithm can be evaluated by a speed up ratio δτ coarse δτ fine where δτ is the computational time for a simulation and subscripts indicate the coarse and fine grid computational cost is evaluated for the urb scenarios by plotting the speed up relative to 1 m simulation on fig 14 all scenarios shown in fig 14 are executed in serial with intel xeon platinum 8160 skylake nodes in stampede2 at the texas advanced computing center we use the same time step δ t 0 5 s for the control cases and the test cases with different grid coarsening ratios so that the relationship between cost and coarsening ratio is more clear in practical applications δt for coarse grid simulations can be further increased as long as the courant friedrichs lewy cfl condition is met so an additional test scenario is performed with r 8 and a larger time step δ t 10 s it can be seen from fig 14 that the subgrid scenarios generally have lower speed ups compared with the corresponding mb scenarios the reduction is caused by searching and interpolating among the pre defined surface elevations as well as increased number of wet cells for the sb scenarios which is not equivalent to increased inundation area due to the use of eq 1 given this reduction in speed up adapting subgrid method is still much more efficient than performing a 2 grid refinement even with the same time step δt by using a larger time step δ t 10 s the speed up can be further increased 4 conclusions a method that simulates effects of subgrid scale topography using practical coarse grids is designed and coded into the fine resolution environmental hydrodynamic model frehd for modeling hydrodynamics and salinity in shallow coastal wetlands the proposed subgrid method parametrizes the subgrid scale topography into four subgrid variables subgrid cell volume and three subgrid face areas that represent the high resolution grid volumes and face areas these variables are included in the continuity and momentum equations as parameters to scale mass momentum storage and transport of coarse grids an automatic block checking method is developed to maintain high resolution surface connectivity upon grid coarsening the subgrid frehd model frehdc after parallelization is evaluated using three test cases ranging from simple idealized channel bathymetry to real coastal marsh bathymetry derived from lidar data for all cases compare to existing coarse grid models the surface elevation inundation area flow rate and salinity predicted by the subgrid model are closer to simulation results performed at finer resolutions model data agreement for salinity is also improved with subgrid modeling the subgrid simulation results show weak sensitivity to grid resolution which means topographical features at finer scales are successfully captured compare to coarse grid models this resolution independent behavior makes the subgrid model suitable for shallow marsh modeling at large grid coarsening ratio r as long as the surface connectivity is not interrupted three key components that contribute to the advantages of the subgrid model are 1 the use of minimum bottom elevation eq 1 which guarantees accurate assessment of a cell s wet dry status 2 the conservation of cell volume during grid coarsening eq 2 which is critical in simulating salinity transport 3 the automatic block checking procedure section 2 4 which maintains high resolution surface connectivity patterns at coarse grids applying the subgrid method slightly increases computation cost compared to simulating on traditional coarse cartesian grids but it is still much more efficient than performing grid refinement it should be acknowledged that there exists an upper limit for r beyond which surface connectivity is no longer maintained even with the block checking method but the range of applicable r values are proven larger than existing coarse grid models acknowledgements the authors wish to thank the texas water development board for providing field data this work has been supported by the texas water development board under interagency cooperation contracts 1400011719 1600011928 and 1800012195 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 05 004 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
623,a 2d depth integrated subgrid hydrodynamic model frehdc is designed to simulate effects of subgrid scale topography on flow and scalar transport in shallow coastal marshes using computationally efficient grid cells that are coarser than many of the channelized paths through the marsh the subgrid scale topography is parametrized into four depth dependent variables subgrid cell volume and three subgrid face areas that characterize the high resolution features of coarse grid cells these variables are pre stored in a table and embedded into the governing equations as model inputs to scale cell storage mass and momentum fluxes across cell faces a block checking procedure is designed to automatically preserve high resolution surface connectivity during grid coarsening by testing on both synthetic domain and real marshes this new model is able to approximate fine grid simulation results of surface elevation inundation area flow rate and salinity with less computational cost keywords subgrid topography model hydrodynamic modeling shallow coastal marsh scalar transport surface connectivity 1 introduction high resolution topographic data obtained from lidar typically at a 1 m scale are difficult to directly use in a fine resolution hydrodynamic model for an extensive marsh system due to the small model time step and large number of computational cells that would be required for example a 10 10 km marsh would require 108 grid cells and a time step of less than 10 s using a highly efficient computational model with 100 floating point operations per time step per grid cell would requires a petaflop supercomputer with terabytes of memory to achieve practical computation speeds of 100 faster than real time while such computers exist they are typically not available for scientists and engineers studying flow and transport through marshlands thus to effectively use high resolution data some form of grid coarsening scheme must be employed the challenge of handling known but unresolved bathymetry complicates the challenge of handling unknown or poorly known bottom roughness wang et al 2009 unfortunately a coarse grid cannot directly represent many of the small but hydrodynamically important topographical features that are evident in lidar data e g hodges 2015 grid coarsening or topographic upscaling usually involves filtering the high resolution data to get approximations of the bottom elevations which introduces errors in hydrodynamic modeling of the flow depths that in turn affects the modeled velocities and fluxes cea and french 2012 furthermore subgrid scale channels and water blocking ridges are often widened or smoothed on coarse grids which leads to i overestimated flow rates in channels that are widened ii underestimated resistance where surface roughness is smoothed cea et al 2014 iii erroneous surface connectivity and iv different flow patterns either channelized flow or shallow sheet flow due to shifts in the wetting drying front sullivan et al 2015 torres and styles 2007 these problems have been previously noted and subgrid methods have been developed by a number of researchers to represent high resolution topographic effects on coarse grids e g bates et al 2003 casas et al 2010 d alpaos and defina 2007 duan et al 2017 guinot 2012 guinot et al 2018 hodges 2015 jan et al 2018 kim et al 2015 loftis et al 2016 neal et al 2012 ozgen et al 2016a ozgen et al 2015 ozgen et al 2016b sanders and schubert 2019 stelling 2012 viero and valipour 2017 volp et al 2013 yu and lane 2006a yu and lane 2006b of interest for the present work are methods using artificial porosity to scale the volumetric flow rates in out of the grid cells as proposed by defina et al 1994 artificial porosity can be treated as a function of the free surface elevation as well as the high resolution topography by multiplying porosity into the governing equations the high resolution topographic information is embedded into coarse grid models however dependency between artificial porosity and surface elevation introduces another nonlinearity to the governing equations early attempts used empirical relationship between porosity and depth for linearization defina 2000 which showed good performance on simple idealized topography bates 2000 a recent approach by wu et al 2016 used pre stored porosity parameters calculated for all possible surface elevations in a look up table model porosity was updated for each grid at each time step by searching in the table since the pre stored porosities are calculated from high resolution data the method can be used on domains with complex topography where empirical relationships do not hold casulli 2009 developed an algorithm to solve the mildly nonlinear system produced by porosity depth coupling with minimal additional computational cost and ensured conservation of mass in the free surface solution this method was proven to improve the model performance on sections of the elbe river platzek et al 2016 sehili et al 2014 artificial porosity has also been used for modeling urban floods where buildings are difficult to represent with an integral porosity ip model sanders et al 2008 this approach embeds volumetric and anisotropic areal porosities in the governing equations although anisotropy of areal porosity was proven necessary the ip model was subsequently shown to be sensitive to mesh design guinot 2017a further improvement on the ip model was made by correcting the flux terms referred as dip model that alleviated dependencies on the mesh guinot 2017b guinot et al 2017 nevertheless a practical application involving a levee breach flow through a residential neighborhood showed that the dip model cannot capture the full distribution of velocity directions and magnitude that are resolved by finer resolution models furthermore the dip mesh must be strategically placed so that the cell edges intersect with water blocking structures otherwise the effects of these structures will not be correctly reflected from areal porosity despite the noted progress in subgrid methods a key unsolved problem is the lack of a method that automatically preserves high resolution surface connectivity during grid coarsening in the present study surface connectivity refers to the network of flux paths through a marsh system which is controlled by channels and blockages in topography connectivity is generally increased when a channel is widened by grid coarsening however grid coarsening can also interrupt surface connectivity where it eliminates narrow channels from the high resolution topography this effect has been noted to be a function of a coarsening ratio r which is defined as the ratio of the coarse grid length scale to the fine grid length scale wu et al 2016 has reported unreasonable model results when r 4 due to interrupted connectivity li and hodges 2018 showed that poor representation of surface connectivity caused significant discrepancies between modeled salinity fluxes and observations in a coastal marsh identifying small but hydraulically important topographical features that must be represented to maintain adequate surface connectivity remains a challenging task yu and lane 2011 detected water blocking features and added artificial walls to maintain surface connectivity by hand which was time and labor consuming chen et al 2012 used a multi layer method solving the model equations for the two regions bisected by the water blocking feature separately but for general marsh topography where the use of multiple layers more than two is expected this approach could severely increase computational cost neal et al 2012 used a subgrid method that simulates effects of narrow channels in floodplains but it requires characterization of channel geometry for coastal marshes with frequent wetting drying it is not easy to separate the domain into distinct channels and floodplains hodges 2015 designed an automatic channel and cell edge identification method to detect small scale water blocking features but some narrow channels still needed to be manually identified in practical applications li and hodges 2018 a recent study on urban floods sanders and schubert 2019 also emphasized the needs of automatically detecting small scale topographic features many subgrid methods have been developed for flood modeling where free surface elevation and inundation area are the variables of interest in contrast the coarse grid effects on scalar transport processes e g salinity have not been extensively studied scalar transport modeling typically has greater uncertainties than modeling surface elevation aizinger et al 2013 inoue et al 2008 wang et al 2009 because scalar error is inherently accumulative over the residence time scale of the modeled system and does not have a feedback effect in contrast by definition for slow moving marsh waters the errors leading to local accumulations or deficits in surface elevations must also lead to changes in the surface gradients with neighbor cells which in turn induce errors in the local fluxes that will counteract the accumulation or deficit of surface elevation furthermore modeling advective scalar transport in shallow marshes requires accurate reproduction of the velocity field which is more sensitive to grid coarsening errors than is surface elevation mazzolari et al 2015 it has been shown that a subgrid model with minimal surface error could still contain large errors for the modeled flux shin 2016 the present study is an outgrowth of efforts to understand the effectiveness of freshwater inundation in reducing salinities across tidal marshes of the nueces river delta texas usa as described in li and hodges 2018 we previously identified two key issues that limited the existing models i stability of numerical methods for wetting drying fronts and ii obtaining correct connectivity at the practical model grid resolution the former was addressed in new methods proposed in li and hodges 2018 and herein we examine how the new subgrid model improves the representation of marsh connectivity and salinity scalar transport the new method section 2 borrows the concept of artificial porosity and uses a pre store of high resolution topographic information similar to wu et al 2016 the relationships between the coarse and the fine grid are stored as a group of subgrid variables similar to artificial porosity which saves computation efforts section 2 1 the governing equations are discretized by including the subgrid variables as parameters section 2 2 an automatic checking routine is designed to effectively capture narrow water blocking features section 2 4 model results are evaluated with respect to surface elevation inundation area and salinity through comparisons with high resolution simulation results and field data section 3 the advances and limitations of the proposed model are summarized in section 4 2 methods the new subgrid method is implemented in a two dimensional 2d depth integrated solution of the shallow water equations the numerical methods for the solution are a hybrid finite volume difference approach developed from the three dimensional 3d fine resolution environmental hydrodynamic model frehd which is a descendent of trim casulli and cattani 1994 and elcom hodges et al 2000 models the 3d frehd model was written in matlab scripting to develop and test new algorithms for 3d flow and transport in natural environments hodges 2004 2014 2015 hodges and rueda 2008 rueda et al 2007 wadzuk and hodges 2009 for seasonal to annual simulations the serial matlab implementation of frehd is too slow for more than 104 grid cells and does not parallelize well the code structure was designed to allow implementation and testing of new algorithms which hampers parallel solution efficiency the basic frehd algorithms for 2d have been rewritten in the c programming language to improve computation efficiency parallelization is achieved using the message passing interface mpi where the entire model domain is divided into sub domains of equal sizes a range of 1 to 32 threads are used for the simulations performed in the present study good scaling property is observed within this range results not shown because parallelization is not the focus of the present study this new 2d version is named frehdc 2 1 subgrid geometry definitions before presenting the governing equations and discretization schemes of the frehdc model it is useful to define the subgrid geometry variables that describe the high resolution characteristics of a coarse grid consider a coarse grid cell i j in a 2d domain with dimensions δx by δy which contains λ ψ high resolution subgrid cells let ω to represent the domain of cell i j and γ its boundary the size of one subgrid cell is δx δy where λ δ x δ x and ψ δ y δ y fig 1 shows an example of a coarse grid cell with λ ψ 4 each subgrid cell is labeled using λ ψ where 1 λ λ and 1 ψ ψ the bottom elevation of a subgrid cell is denoted as z i j λ ψ the coarse grid cell ω i j is characterized by a single value of surface elevation η i j a single value for bottom elevation z i j is defined as 1 z i j min λ ψ ω z i j λ ψ the use of min function ensures the cell is identified as wet i e contains some water even when only a single of the λ ψ subgrid cells is below the free surface for regions with frequent wetting and drying this definition is necessary to represent the inundation area and flux paths the volume of cell ω i j is defined as 2 v i j λ ψ ω max η i j z i j λ ψ 0 δ x δ y where the max function ensures that dry subgrid cells are not counted as negative volumes if no subgrid topography exists eq 2 simply reduces to v i j h i j δ x δ y where h i j η i j z i j is the depth similarly we may define the cell face areas as illustrated in fig 1 for example the face areas normal to the x axis on the plus and minus sides of ω i j are 3 a x i 1 2 j k 1 ψ max η i j z i j λ k 0 δ y a x i 1 2 j k 1 ψ max η i j z i j 1 k 0 δ y the face areas normal to the y axis on the plus and minus sides of ω i j are 4 a y i j 1 2 k 1 λ max η i j z i j k ψ 0 δ x a y i j 1 2 k 1 λ max η i j z i j k 1 0 δ x and the face area on the top face of the grid cell is 5 a z i j λ ψ ω ϵ i j λ ψ δ x δ y 6 ϵ i j λ ψ 1 η i j z i j λ ψ 0 η i j z i j λ ψ for use in discrete equations the subgrid variables v ax ay and az are labeled by its i j indices which are the coordinates of its center for example we can also write ax i j to represent the face area normal to the x axis centered at i j or v i 1 2 j to represent the cell volume centered at i 1 2 j these subgrid variables are introduced into the discrete governing equations as illustrated in the following section 2 2 governing equations the 2d depth integrated free surface equation momentum equations and the scalar transport equation can be written in an integral form similar to sanders et al 2008 7 t ω η d ω γ u n d a 0 8 v u t u n u x d v γ g η n d a γ τ ν n d a ω τ b d ω 9 t v c d v γ u n c d a γ τ κ n d a where η is the free surface elevation u u v t are depth averaged velocities x x y t are the corresponding cartesian axes n is the normal unit vector to a flux surface γ τb is the bottom stress τ ν is the viscous stress c is the scalar concentration and τ κ is the scalar diffusion term an infinitesimal volume inside the grid cell is dv with infinitesimal cell face areas da which can be written as d a h γ d γ where h γ is the depth function along the cell boundary the density is assumed to be a constant the bottom stress and viscous stress are defined as 10 τ b 1 2 c d u u 11 τ ν ν u x ν u y t where ν is the eddy viscosity and cd is the drag coefficient defined as 12 c d g n 2 h 1 3 h v δ x δ y in eq 12 n is the manning s roughness coefficient which is assumed to be a constant in the present study the scalar diffusion terms are computed as 13 τ κ κ c x κ c y t where κ is the eddy diffusivity we use κ ν 10 4 m 2 s 1 because the frehd model has been shown to be insensitive to eddy viscosity for shallow estuaries and tidal marshes li and hodges 2018 indeed it can be argued that any depth averaged coarse grid hydrodynamic model will be insensitive to eddy viscosity in a marsh simulation because bottom drag and form drag associated with torturous channelization will dominate the effects of horizontal shear at the low velocities that are typical of such systems arega and sanders 2004 although dispersion at channel bends could have strong effects on the flow field begnudelli et al 2010 in narrow coastal channels there often lacks sufficient grid resolution to fully resolve the bends which makes numerical dissipation to be the dominant process li and hodges 2018 a detailed study on the relations between eddy diffusion numerical diffusion and dispersion especially under the existence of subgrid scale topography is beyond the scope of the present study but it deserves further investigation in the future unlike some existing 2d subgrid models that are shock capturing e g guinot et al 2018 frehdc does not include any specific treatments regarding shock waves because flow in coastal marshes is generally slow inundation is often tidal driven which occurs at longer time scales than flash floods highly irregular topography and existence of vegetation further decelerates propagation of inundation extent making shock capturing a secondary task the solution algorithm of frehdc uses the semi implicit approach of casulli and cattani 1994 where the free surface gradient is discretized with a θ method weighted implicit scheme however the nonlinear advective terms are discretized using first order upwind as discussed in li and hodges 2018 using a finite volume method the free surface equation eq 7 is discretized with subgrid derived areas as 14 η i j n 1 a z i j n δ t u i 1 2 j n 1 a x i 1 2 j n u i 1 2 j n 1 a x i 1 2 j n v i j 1 2 n 1 a y i j 1 2 n v i j 1 2 n 1 a y i j 1 2 n η i j n a z i j n δ t i i j n 1 2 where i i j is the volumetric flow rate of the inflow boundary condition n represents time level when appears as superscript the above applies a time linearization of the subgrid areas e g the a x n is a coefficient of the u n 1 which is similar to the time linearization of geometry δz that appears in many conventional semi implicit schemes hodges 2004 the momentum equation eq 8 is discretized with respect to a staggered grid volume ω i 1 2 j as for simplicity only the momentum equation in x direction is derived 15 u i 1 2 j n 1 g δ t a x i 1 2 j n v i 1 2 j n k i 1 2 j n η i j n 1 η i 1 j n 1 k i 1 2 j n e i 1 2 j n where k i 1 2 j n is the inverse of the coefficient of implicit velocity u n 1 that appears due to time linearization of the drag term to maintain stability during flow reversals li and hodges 2018 and e i 1 2 j n contains all the explicit terms specifically these are 16 k i 1 2 j n 1 a z i 1 2 j n 2 v i 1 2 j n c d x u 1 17 e i 1 2 j n u i 1 2 j n δ t ν a x i 1 2 j n v i 1 2 j n u x i 1 j u x i j δ t ν a y i 1 2 j n v i 1 2 j n u y i 1 2 j 1 2 u y i 1 2 j 1 2 δ t u u x v u y i 1 2 j at each time step the velocities u n 1 and v n 1 from eq 15 and the corresponding y momentum equation are substituted into eq 14 forming a five diagonal linear system for the free surface elevations 18 η i j n 1 a z i j n g x p i j n g x m i j n g y p i j n g y m i j n η i 1 j n 1 g x p i j n η i 1 j n 1 g x m i j n η i j 1 n 1 g y p i j n η i j 1 n 1 g y m i j n η i j n a z i j n δ t i i j n 1 2 δ t e i 1 2 j n e i 1 2 j n e i j 1 2 n e i j 1 2 n where the matrix coefficients are defined as 19 g x p i j n g δ t 2 a x i 1 2 j n 2 v i 1 2 j n k i 1 2 j n g x m i j n g δ t 2 a x i 1 2 j n 2 v i 1 2 j n k i 1 2 j n g y p i j n g δ t 2 a y i j 1 2 n 2 v i j 1 2 n k i j 1 2 n g y m i j n g δ t 2 a y i j 1 2 n 2 v i j 1 2 j n k i j 1 2 n in frehdc this linear system is solved by applying conjugate gradient method with symmetric successive over relaxation preconditioner available through laspack the η n 1 from solution of eq 18 are substituted into eq 15 and a similar y momentum equation to get updated velocities u n 1 and v n 1 the scalar transport equation eq 9 is discretized using finite volume method at the x plus face the net scalar mass mc across the face is 20 δ m c i 1 2 j n 1 δ t a x i 1 2 j n 1 u i 1 2 j n 1 c i j n κ c x i 1 2 j summing mass fluxes on all four faces and allowing sources sinks of mass provides 21 m c i j n 1 m c i j n δ m c i 1 2 j n 1 δ m c i 1 2 j n 1 δ m c i j 1 2 n 1 δ m c i j 1 2 n 1 s o u r c e s i n k the updated scalar concentration is 22 c i j n 1 m c i j n 1 v i j n 1 2 3 subgrid geometry update the subgrid geometry variables defined in section 2 1 are all functions of the free surface elevation ideally their values should be updated simultaneously with the free surface elevation to maintain mass conservation casulli 2009 in practice the geometry time linearization discussed in section 2 2 allows a simple linear implicit solver to be used for the free surface solution a pre stored approach wu et al 2016 is adopted herein for the update computation at the solution start we initialize an array that contains pre defined free surface elevations and their corresponding subgrid geometry i e an array indexed by η p d η min η min δ η η min 2 δ η η max where η min and η max are based on expected maximum and minimum values for the system for each η in ηpd the corresponding subgrid geometry variables are computed and stored for each time step when the new free surface elevation η i j n 1 is computed we search in ηpd for η p d k η i j n 1 η p d k 1 and interpolate the subgrid variables between ηpd k and η p d k 1 for computational efficiency in searching in the pre defined array of surface elevations our algorithm begins from the last known interval η p d k η p d k 1 if η n 1 does not fall within in this interval we continue by searching neighbor intervals this strategy significantly reduces the computation costs compared to an arbitrary search over η min η max 2 4 block checking for internal features in section 2 1 the cell face areas are defined using only the high resolution data that is coincident with the cell faces which naturally creates a water blockage if all the subgrid cells are dry along a face however a water blocking feature in the interior of a cell cannot be directly represented by the cell face areas using the subgrid geometry as defined above for example we can imagine a case where a x i 1 2 j 0 and a x i 1 2 j 0 combined with a x i j 0 which would allow flow from the i 1 j cell to the i 1 j cell through the i j cell because the ax i j does not appear in the discrete equations thus an additional algorithm is required to locally alter the subgrid geometry and account for internal blocking effects this is similar to the problem addressed in hodges 2015 where the interior blocking height of subgrid geometry across a coarse grid cell was identified and the feature was snapped to the nearest face the result was a static face geometry that included effects of interior blockages which was accomplished as a pre processing step to a hydrodynamic model herein we develop an approach that accomplishes a similar task but is integrated in the approach for the hydrodynamic solution through direct effect on the ax and ay internal blocking is handled through a discrete analysis of subgrid geometry at each of the ηpd k elevations in the pre stored subgrid geometry array a five step process is used to modify the ax and ay on each face that is the face areas at a given ηpd k retain their values computed by the faces unless an effective interior blockage is detected in which case the appropriate face area is set to zero the process for each coarse grid cell is 1 at each pre defined surface elevation ηpd k create a binary wet dry map within a coarse grid cell that contains λ ψ subgrid cells 2 cycle through each of the ηpd k computing steps 3 5 below and modifying the subgrid geometry array 3 identify the single largest fully connected wet patch in this coarse grid cell at this elevation mark the remainder of this cell as dry 4 if the intersection between the wet patch and a coarse cell face at this elevation is zero this face is blocked and has a subgrid face area of zero 5 for two adjacent coarse grids both with nonzero areas on their common face at the same elevation if the intersection of their wet subgrid indices on this face is an empty set their common face area is zero in the present implementation this algorithm is used only at the start of the simulation to pre store the effects of internal blocking however the algorithm could be easily introduced within the hydrodynamic time stepping loop to allow dynamic modification of subgrid geometry erosion or aggradation issues that are worthy of further investigation an example of the block checking technique is shown in fig 2 a where the water regions blue are divided by the land brown forming a river channel from left to right that is mostly not connected to the surrounding marshes following eqs 3 and 4 at r 15 without block checking the river bank would only be partially identified and blocked as shown by the light blue faces that are the only subgrid faces with zero areas thus näive application of the subgrid definitions in section 2 1 will allow imaginary flow paths between the channel and its surrounding marshes the new block checking method identifies the red faces as additional blocked faces based on the high resolution topography of the interior of each coarse grid cell which fully delineates the channel banks at an r 15 coarsening as shown in fig 2a however the block checking method does not allow coarsening to arbitrarily large r as illustrated in fig 2b for r 30 as the coarsening ratio increases there is an increasing likelihood that multiple unconnected flow paths could exist in a single coarse grid cell but the block checking method step 3 is limited to considering only the largest inundation area in a grid as the true connected region of a single cell this approach inherently blocks other flow paths because only one velocity is allowed to exist on each face in fig 2c one cell from fig 2b delineated by a green box is examined in detail the top panel shows the binary wet dry map step 1 of the original cell which contains two disconnected water regions a1 and a2 comparing to fig 2b we found that a2 belongs to the river channel and a1 is located in its surrounding marshes the bottom panel of fig 2c shows the wet dry map after performing step 3 where a2 is turned into land because its area is less than a1 this leads to blocking of the east face through step 4 and the south face through step 5 of the target cell which interrupts channel connectivity despite the failure behavior of the block checking method at large r it still shows advantages over naïve upscaling and the edge identification method by hodges 2015 in maintaining surface connectivity which will be verified in section 3 it should be aware that model dependency on r varies for different domains so to improve applicability over a variety of domains the proposed block checking method could be combined with some quantifications that reflect the complexity of topography which is a topic that deserves further investigation 3 test cases and results the new subgrid methods are tested on three bathymetries i an idealized channel ii a highly resolved portion 170 hectare of a narrow waterway at the west end of the nueces delta the upper rincon bayou urb and iii a larger portion 2178 hectare of the nueces delta the upper nueces delta und to understand the effects of the subgrid model we generate a range of model bathymetries to use for comparisons the baseline comparison cases m use a 2δx median filter for upscaling topography as described in hodges 2015 the m simulations are a naïve grid coarsening that is applied without any consideration of subgrid features in the upscaling or in the numerical solution the second set of comparison cases are mb cases median filter with block checking which use the approaches of hodges 2015 and li and hodges 2018 to upscale topography as edge blocking and channelization but do not include the new subgrid model described above the test cases with the new subgrid model section 2 1 2 3 are labeled the s test cases the test cases using the new subgrid model together with the new block checking method section 2 4 are named sb note that the letter b indicates the use of a block checking method to identify small scale water blocking features but identification processes are different for mb and sb the former comes from hodges 2015 and the latter follows section 2 4 the difference between tested scenarios are summarized in table 1 3 1 idealized channel the idealized channel bathymetry uses a uniform flat bottom with bottom elevation 0 5 m with a varying width wide channel 50 to 120 m width connected internally by a narrow channel 5 m wide and accompanied by two non submerged vertical walls as illustrated in fig 3 the forcing boundary condition for this test case is a sinusoidal tide range from 0 8 to 1 2 m above the z 0 bottom with a period of 6 h along the open boundary of the model domain the initial surface elevation is uniform at the tidal elevation for t 0 the initial velocities are all zero the initial scalar concentrations herein salinity are created with a piecewise constant function that can be visualized in fig 3 which makes it easy to observe instantaneous flow patterns all over the domain the salinity at the tidal boundary is fixed to a constant value of 25 psu for idealized channel test cases we apply a grid coarsening ratio of r 10 δ x 10 m which is the point where the narrow channel and the walls are entirely lost in the m coarse grid but still appear in the mb grid however the mb overestimates the interior wall heights and the width of the narrow channel the modeled salinity transport in the idealized channel at t 7 h is shown in fig 4 the fine grid simulation fig 4a shows the higher salinity wrapping around the unsubmerged walls and a small flux through the narrow channel these features are qualitatively reproduced by the subgrid model fig 4d the coarse grid simulation m fig 4b produces a significantly different transport result due to the loss of the interior walls and the narrow channel the mb simulation fig 4c shows some effects of the walls but allows greater flux through the narrow channel because the channel is widened to match grid size note that the blocking walls that are evident in the control solution do not appear in the visualization of the subgrid model results because the min function is used for bottom elevations eq 1 but their effect is captured by the subgrid model as can be clearly seen in the sharp rectilinear change in the salinity contour where the walls should be in fig 4d a quantitative evaluation of the subgrid model is performed by estimating the absolute error of salt flux over one tidal period across two cross sections in the wide and narrow channel respectively x1 and x2 as labeled in fig 4a the fine grid simulation is used as the true solution for computing error as shown in fig 5 the sb simulations produce minimal errors among all test simulations for both channels the interquartile ranges iqr for the subgrid simulations are also much smaller indicating that the sb scenarios consistently outperform the other scenarios over the entire tidal period error for the coarse grid simulation m is not shown at x2 because the narrow channel is completed ignored after filtering 3 2 the upper rincon bayou urb the two test cases with real world bathymetry use a lidar data set from the nueces river delta along the texas usa coast near the city of corpus christi this data was previously used in studies of hodges 2015 li and hodges 2018 ryan 2011 wherein further details can be found the nueces delta is a shallow micro tidal river delta with limited freshwater inflows the river now debouches through a main channel that is isolated from the delta and upstream dams have reduced overbanking events that previously flooded the system increasing episodes of hypersalinity became subject of a lawsuit and eventually an agreed order to mitigate the impact of the dams on the wetlands lloyd et al 2013 towards this end a pumping system was installed for controlled introduction of freshwater into the upstream end of the delta del rosario and montagna 2018 hill et al 2015 lloyd et al 2013 the delta system has been subject of a number of studies and physical modifications over the past two decades the test bathymetry for the upper rincon bayou urb shown in fig 6 is a small section extracted and slightly modified from the full 1 1 m data set this is a section of the rincon bayou where the shallow depth and complex flow paths caused poor model data agreement in a prior study li and hodges 2018 an artificial bay on the east end of the model domain is connected by a narrow channel to the rincon bayou to provide the tidally driven forcing the channel dimensions are similar to those in the rincon overflow channel roc that was created to improve flushing in the upper marsh dunton et al 2000 the west end of the domain is blocked with a fixed wall a sinusoidal tide with range from 0 3 m to 0 7 m and period of 24 h is added to the open boundary on the east for the urb test case for the urb simulations the control simulation uses δ x δ x 1 m the reference cases mb and the sb test simulations use grid coarsening with r 4 8 16 32 i e δx 4 8 16 32 m since we have shown the effectiveness of mb over m in fig 5 and in li and hodges 2018 the subgrid model is only compared to mb fig 7 shows the surface elevations at t 34 h for r 1 16 32 results at coarse resolutions are downscaled onto the high resolution bathymetry following sanders and schubert 2019 the overall differences between the surface elevations in the control 1 1 m simulation the reference simulations mb and the test simulations sb are small in magnitude mostly a few cm across the majority of the domain all the coarse grid simulations tend to overestimate the surface elevation with the mb scenarios having a more substantial disagreement than the sb scenarios a clear quantitative difference is in the marginal wetland flooding that shows up as dark purple along the lower left edge of fig 7a the dark purple indicates lower water surface elevation due to constricted connectivity between the bayou and this wetland area all of the sb results preserve the reduced connectivity and lower water surface elevations however for the coarse grid r 16 scenario with mb the connectivity to the wetland is increased and it floods to higher water surface elevations we can better understand this effect by examining areal flooding extent as shown by the time evolution of the integrated inundation area in fig 8 for the s and sb scenarios inundation area is simply the sum of subgrid face areas az for an mb scenario performed at r 1 two methods are used to estimate inundation area the first method is based on the coarse grid bathymetry at r where all wet coarse cells have a surface area of δxδy fig 8a the second method downscales the modeled surface elevation onto r 1 fine grid bathymetry sanders and schubert 2019 and sums the areas of the wet fine cells fig 8b for both methods at r 8 the disagreement in the mb begins to increase and has significantly diverged from the other simulations at r 16 and r 32 in contrast the sb results at r 16 and r 32 remain quite similar to the control case at r 16 the s scenario generates higher errors than sb but it still outperforms mb the block checking method section 2 4 prevents creation of unexisted new flow paths during grid coarsening whereas the use of minimum bottom elevation eq 1 prevents removal of existing narrow flow paths the comparison between mb s and sb indicates both methods are important in maintaining surface connectivity when coarsening the shallow marsh bathymetry more insights are obtained by analyzing the different behaviors of mb scenarios between fig 8a and b the difference in inundation areas between the mb and sb scenarios are affected by three factors i surface connectivity of key flow paths ii surface area within the coarse grid cells using az versus δxδy and iii predicted surface elevations in fig 8a the mb scenarios overestimate inundation area because the dominant factor here is ii in fig 8b however the effects of factor ii is removed because the surface area is calculated at fine scale underestimation of inundation area is thus caused by factor i where many deep subgrid cells near the wetting drying front are smoothed on the mb bathymetries factor iii has negligible effects on the tested scenarios because the difference in predicted surface elevations are small only a few centimeters fig 7 with either fig 8a or b the results verify the effectiveness of the new subgrid method sb in maintaining high resolution surface connectivity and inundation patterns at large r quantification of flow rate error in the channel between the bay and the rincon bayou over one tidal period is provided in fig 9 since we have shown that sb is superior over s in maintaining surface connectivity the following analysis only focus on the difference between sb and mb the mb scenarios show maximum error at r 32 and decreasing error as r increases from 4 to 16 since natural topography is spatially heterogeneous grid refinement does not necessarily reduce model error the grid coarsening method adopted hodges 2015 involves filtering as well as edge and channel identification so its ability to resolve high resolution topography does not depend on r alone furthermore grid coarsening enhances numerical diffusion which reduces flow rates the reduction of model error for r 16 mb may be caused by a balance between multiple error sources despite the complex behaviors of model error two observations can be made regarding the proposed subgrid model first the sb model errors show weak dependency on r which allows it to perform well at very coarse grid in fig 9 the mb error abruptly increases at r 32 the sb error however maintains a mild increase second the sb errors produce smaller iqr than the mb scenarios indicating stable variations over the entire tidal period this is an evidence that the sb error does not come from occasional balance between multiple sources but from processes that are not simulated in the present subgrid model e g topographical features in the cell interior although the mb simulation can produce a slightly smaller median error e g at r 16 it always has a larger interquartile range indicating the subgrid model has better applicability over a variety of domains coarsening ratios and flow characteristics 3 3 the upper nueces delta und the texas water development board twdb collected field data of water depth and salinity at 14 monitoring stations in the nueces delta which enables us to test the subgrid model with realistic boundary conditions the final test case upper nueces delta und uses a larger portion for the nueces delta as shown in fig 10 the pump station where freshwater is introduced is noted at the left side of the figure the region between the pump station and the rincon overflow channel is the area extracted for the urb test case in fig 6 six of the 14 twdb monitoring stations are located within this domain which are labeled from nueces1 to nueces6 a 7th station is located at the east boundary which is used to provide tidal and salinity boundary conditions other boundary conditions involved are wind data available at texas coastal ocean observation network tcoon as well as pump inflow that is available from nueces river authority nra three cross sections y1 to y3 are labeled in fig 10 flow rates across these sections will be used as indicators for evaluating model performance for the und running a multi month simulation at δ x 1 m is impractical with our available computational power so we use only coarser simulations along with field data for real world evaluation of the model performance in modeling the upper nueces delta und the tested coarsening ratios are r 5 10 15 30 50 75 to avoid overlong spin up at fine resolutions we use a 45 day spin up time from apr 1st to may 15th of 2013 at r 15 followed by a 15 day spin up at each tested value of r previously the full nueces delta modeled at coarse resolution was shown to have a 60 day spin up for salinity li and hodges 2018 the model results are reported for a 15 day period in the first half of june 2013 which brackets an 11 day period during which the pumping system was providing a total of 106 m3 freshwater into the upstream end of the delta nra fig 11 shows a qualitative comparison of the salinity fields during pumping for r 5 30 50 it can be seen that the three subgrid scenarios predict similar spatial distribution of freshwater but as r increases stronger numerical diffusion smooths salinity gradient at the interface of fresh and saline water compared to the sb scenario the mb at r 5 predicts more freshwater entering the west lake via rincon overflow channel roc and less freshwater down through rincon bayou but this difference is negligible compare to the differences at larger r the mb at r 30 underestimates pump flow in both channels which is likely caused by an overestimation of volume as the mb grid coarsening procedures are not volume conservative at r 50 freshwater into the west lake is completely omitted in mb scenario because the surface connectivity of the roc is cut off we may conclude that the subgrid model is relatively insensitive to r as it better approximates the high resolution surface connectivity and salinity transport patterns at relatively large r r 30 50 owing to the conservation of subgrid cell volume as well as the block checking procedure a quantitative comparison of absolute values of flow rates not flow rate errors for all und tested scenarios are given in fig 12 for the three cross sections labeled in fig 10 two main observations can be made 1 for most values of r the sb scenarios have relatively smaller iqrs than the mb scenarios and they show relatively weak dependency on r this phenomenon is particularly obvious at y3 fig 12c 2 for r 50 surface connectivity of the mb scenarios begins to be interrupted which is reflected by a sudden decrease of median flow rate and iqr at y1 this matches the observation from the salinity contour fig 11e the interruption of connectivity is also found for sb but at a higher value of r 75 these two observations again indicate than compare to mb the proposed subgrid model better preserves the high resolution topographical characteristics surface connectivity and volume at large grid coarsening ratios the sb bathymetry is able to maintain surface connectivity at higher r than mb even if both scenarios maintain surface connectivity using mb bathymetry overestimates flow rate due to expansion of channel width to match the grid size li and hodges 2018 which leads to higher iqr and strong dependency on r however since the cell volumes are also overestimated given the same inflow rate from pumping it decelerates salinity transport towards the west lake because freshwater accumulates in the rincon bayou the modeled salinities are compared to the field data in fig 13 to provide further insights it should be noted that although comparisons at all six stations in fig 10 can be made they do not necessarily highlight the effectiveness of the subgrid method because the stations might be located in regions where variation of subgrid scale topography is smooth and trivial or other error sources might dominate fig 13 only shows results at nueces3 and nueces5 located near y1 and y2 fig 10 where scalar patterns are strongly affected by subgrid topography results at other stations are provided as supplemental material a detailed analysis of model data agreements and other dominant error sources can be found in li and hodges 2018 at nueces3 fig 13a the decrease of salinity upon freshwater pumping is successfully reproduced by all sb scenarios but for the mb scenarios salinity displays oscillatory behaviors at r 30 50 it implies weaker freshwater flushing which is in agreement with fig 9 as stated above this is caused by an overestimation of volume that slows down spreading of salinity at nueces5 fig 13b all test scenarios predict delayed response to freshwater pumping it comes from a combination of errors such as bathymetry boundary condition and possibly field data itself li and hodges 2018 due to the complex nature of shallow marsh modeling the subgrid model is not expected to correct all errors in one step but it certainly provides improvements over existing mb models especially at large r and at locations where surface connectivity is easily broken 3 4 computational cost the key advantage of any subgrid method is in the ability to model a system faster than would be required at fine grid resolution thus there is always a question as to how much additional cost is incurred by the subgrid algorithm itself the effective computational cost of the subgrid algorithm can be evaluated by a speed up ratio δτ coarse δτ fine where δτ is the computational time for a simulation and subscripts indicate the coarse and fine grid computational cost is evaluated for the urb scenarios by plotting the speed up relative to 1 m simulation on fig 14 all scenarios shown in fig 14 are executed in serial with intel xeon platinum 8160 skylake nodes in stampede2 at the texas advanced computing center we use the same time step δ t 0 5 s for the control cases and the test cases with different grid coarsening ratios so that the relationship between cost and coarsening ratio is more clear in practical applications δt for coarse grid simulations can be further increased as long as the courant friedrichs lewy cfl condition is met so an additional test scenario is performed with r 8 and a larger time step δ t 10 s it can be seen from fig 14 that the subgrid scenarios generally have lower speed ups compared with the corresponding mb scenarios the reduction is caused by searching and interpolating among the pre defined surface elevations as well as increased number of wet cells for the sb scenarios which is not equivalent to increased inundation area due to the use of eq 1 given this reduction in speed up adapting subgrid method is still much more efficient than performing a 2 grid refinement even with the same time step δt by using a larger time step δ t 10 s the speed up can be further increased 4 conclusions a method that simulates effects of subgrid scale topography using practical coarse grids is designed and coded into the fine resolution environmental hydrodynamic model frehd for modeling hydrodynamics and salinity in shallow coastal wetlands the proposed subgrid method parametrizes the subgrid scale topography into four subgrid variables subgrid cell volume and three subgrid face areas that represent the high resolution grid volumes and face areas these variables are included in the continuity and momentum equations as parameters to scale mass momentum storage and transport of coarse grids an automatic block checking method is developed to maintain high resolution surface connectivity upon grid coarsening the subgrid frehd model frehdc after parallelization is evaluated using three test cases ranging from simple idealized channel bathymetry to real coastal marsh bathymetry derived from lidar data for all cases compare to existing coarse grid models the surface elevation inundation area flow rate and salinity predicted by the subgrid model are closer to simulation results performed at finer resolutions model data agreement for salinity is also improved with subgrid modeling the subgrid simulation results show weak sensitivity to grid resolution which means topographical features at finer scales are successfully captured compare to coarse grid models this resolution independent behavior makes the subgrid model suitable for shallow marsh modeling at large grid coarsening ratio r as long as the surface connectivity is not interrupted three key components that contribute to the advantages of the subgrid model are 1 the use of minimum bottom elevation eq 1 which guarantees accurate assessment of a cell s wet dry status 2 the conservation of cell volume during grid coarsening eq 2 which is critical in simulating salinity transport 3 the automatic block checking procedure section 2 4 which maintains high resolution surface connectivity patterns at coarse grids applying the subgrid method slightly increases computation cost compared to simulating on traditional coarse cartesian grids but it is still much more efficient than performing grid refinement it should be acknowledged that there exists an upper limit for r beyond which surface connectivity is no longer maintained even with the block checking method but the range of applicable r values are proven larger than existing coarse grid models acknowledgements the authors wish to thank the texas water development board for providing field data this work has been supported by the texas water development board under interagency cooperation contracts 1400011719 1600011928 and 1800012195 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2019 05 004 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
624,regardless of the complexity of the hydrological model employed uncertainty assessment ua is predominantly performed for the aggregated catchment response discharge for coupled integrated models that simulate various hydrological states and fluxes on a grid cell basis this represents a severe shortcoming we test a simple data driven technique k nn resampling to evaluate its ability to provide reliable residual uncertainty estimates for the multi variable discharge hydraulic head soil moisture and actual evapotranspiration deterministic output of two coupled groundwater surface water models with different complexities being a nonparametric method no explicit prior assumptions about the error distribution of different hydrological variables are required when conditioning the algorithm we propose to limit the number of error lags to be included based on inspection of the partial autocorrelation function pacf our results confirm previous findings regarding reliability and robustness of the k nn technique for discharge simulations and conclude that k nn resampling also provides reliable and robust results for other variables like hydraulic head soil moisture and actual evapotranspiration even for underlying hydrological models with varying levels of performance the 90 prediction intervals pi capture the observations in the testing period satisfactorily for all hydrological variables 92 6 97 3 while alpha indices 0 84 0 95 indicate very reliable pis for all error quantiles differences in error structure between hydrological variables are successfully inferred from historical data and reflected in the results we conclude that k nn resampling represents a potent cost efficient ua technique for applications in operational hydrology facilitating a near simultaneous easy uncertainty assessment for various outputs of computationally heavy hydrological models keywords distributed hydrological model post processor k nearest neighbor resampling residual uncertainty multivariate uncertainty assessment autocorrelation heteroscedasticity 1 introduction the intricate dynamics of natural hydrological processes are difficult to reproduce using even the most sophisticated physically based hydrological models as hydrological models represent mere approximations of real world systems it follows that model predictions are uncertain cf e g beven 2012 in order to provide a reliable basis for decision makers model outputs need to be accompanied by an estimate of the uncertainties associated with them as research conducted in the past two decades ascertains effectiveness and sustainability of water resource management critically depend on a thorough uncertainty assessment ua see for example beven 2002 refsgaard and henriksen 2004 wagener and gupta 2005 and ajami et al 2008 accordingly quantification of uncertainties in hydrological modeling is considered good scientific practice e g refsgaard et al 2007 among the first to recognize the necessity of acknowledging the presence of uncertainty in hydrological model simulations were beven and binley 1992 they developed the generalized likelihood uncertainty estimator glue which uses monte carlo mc simulation the authors coined the term equifinality assuming that model imperfection and incomplete process understanding entail that a potentially endless number of hydrological models and parameter combinations will result in equally acceptable model performance however glue has been shown to have limitations due to the usage of an informal likelihood function for model parameter identification cf mantovan and todini 2006 and stedinger et al 2008 with the aim to quantify the contributions of different sources of uncertainty to predictive uncertainty individually a number of formal ua approaches based on bayesian inference were introduced in this context particular attention was given to the explicit consideration of input uncertainty rainfall a prominent example is the bayesian total error analysis batea kavetski et al 2006a kavetski et al 2006b in which uncertainty in rainfall is accounted for by means of a rainfall multiplier while often neglected model structural uncertainty is a major source of predictive uncertainty see for example refsgaard et al 2006 for a comprehensive review on this matter in contrast ajami et al 2007 developed the integrated bayesian uncertainty estimator ibune which allows combining the rainfall multiplier concept with consideration of model structural deficiencies by using a variety of model structures by means of bayesian model averaging bma see hoeting et al 1999 however finding an adequately representative likelihood function for hydrology capturing autocorrelated non normal and heteroscedastic errors is a matter of ongoing research e g schoups and vrugt 2010 mcinerney et al 2017 and han and zheng 2018 bayesian approaches and more generally speaking mc based ua techniques require a vast number of model evaluations orders of magnitude of 103 105 the parameter samples generated during inference need to be propagated through the hydrological model until convergence is diagnosed in operational hydrology this can represent a serious obstacle for several reasons for example when commercial software is employed to perform hydrological simulations parallelization may be limited by license availability in addition while bayesian methods are often tested using fast conceptual rainfall runoff models computational costs are incrementally larger when applied to complex coupled integrated hydrological models although likely only being a matter of time this currently still restricts their applicability e g juston et al 2013 for these reasons computationally less demanding ua methods represent an attractive alternative especially for applications in operational hydrology to this end one possibility is to resort to meta modeling in which outputs of a complex hydrological models simulator are being approximated through a surrogate model emulator cf o hagan 2006 the emulator is obtained by establishing a statistical relationship between the model outputs reichert et al 2011 a recent example is given by carbajal et al 2017 who compared the performance of data driven and mechanistic emulators in an urban drainage context similarly miller et al 2018 use polynomial chaos expansion conceptually being an emulator for uncertainty quantification of an integrated surface subsurface hydrological model another possibility for more time efficient ua is to apply post processing techniques to deterministic hydrological model runs post processors are based on the assumption that the model parameters are identifiable using optimization of a cost function i e that there is a single optimized model with well constrained parameters which entails an implicit likelihood function uncertainty estimation is then based on the application of data driven techniques that require comprehensive historical data to generate anticipated model errors this would be equivalent to producing samples from a likelihood function for a defined set of model parameters post processors have been applied in various hydrological modeling studies mostly in conjunction with short term streamflow forecasts prominent examples include quantile regression qr weerts et al 2011 estimation based on local errors and clustering uneec solomatine and shrestha 2009 or the dynamic uncertainty model by regression on absolute error dumbrae method pianosi and raso 2012 despite their relative conceptual simplicity post processors are generally robust see for example pokhrel et al 2013 evin et al 2014 even report a post processor approach to outperform a joint bayesian technique in terms of robustness in the presence of error heteroscedasticity and autocorrelation among post processing techniques k nearest neighbor k nn resampling is comparatively simple and easy to implement its univariate predecessor was introduced to the hydrological modeling community by karlsson and yakowitz 1987 who used it as a tool to predict streamflow k nn resampling is a nonparametric method which implies that no explicit assumptions gaussian zero mean about the nature of model error are made see for example hollander et al 2015 instead the error structure is reproduced by sampling realizations from the space of historical model errors resulting in multiple local approximations of the complex target function during prediction solomatine et al 2008 recent applications of k nn in hydrology include work by sikorska et al 2015 beckers et al 2016 and wani et al 2017 sikorska et al 2015 used k nn resampling for uncertainty estimation while accounting for input uncertainty by means of an ensemble and parameter uncertainty separately the authors found the method to outperform a formal statistical meta gaussian technique devised by montanari and brath 2004 beckers et al 2016 adopted k nn to select ensemble streamflow prediction esp traces from original esps based on climate index values prior to generating new ensemble traces in a resampling procedure in wani et al 2017 k nn resampling was applied to estimate residual uncertainty for streamflow forecasting a comparison with two more complex post processors qr and uneec showed that k nn in spite of its simplicity performed well in terms of accuracy and reliability of its uncertainty estimation this work represents an application of the k nn configuration detailed in wani et al 2017 while k nn thus has been successfully applied for generating short term streamflow predictions in a forecasting context and in combination with simple rainfall runoff models there is no documentation in the literature on tests of k nn resampling to perform uncertainty analysis for multiple variables in a complex coupled groundwater surface water model therefore the main objective of this study is to test the potential of k nn resampling for generating reliable residual uncertainty intervals for the multi variable output of a complex coupled integrated hydrological model the hydrological variables incorporated in the ua were discharge hydraulic heads soil moisture and actual evapotranspiration which in addition represents model response at interior catchment locations in doing so we take a step further towards fully exploiting the full potential of this class of hydrological models this will furthermore allow the communication of the associated uncertainties to public and end users which in turn may lead to an increased level of trust in scientific results juston et al 2013 moreover we contribute to a formalization of the process of composing the k nn input variable vector ivv by suggesting a hierarchical approach that is primarily based on analysis of partial autocorrelation of model errors using a flexible and fast post processing technique coded in freely available software for uncertainty quantification r development core team 2018 we do our part to further establish ua as a routine in hydrology pappenberger and beven 2006 especially with regard to complex hydrological models whose computational costs preclude mc simulation 2 study area the study area is the 1055 km2 ahlergaarde catchment on the jutland peninsula in western denmark fig 1 the catchment is the headwater of the skjern river which has its source at the jutland ridge towards the eastern boundary of the catchment and discharges into the north sea via ringkøbing fjord the annual mean discharge is 37 m3 s ovesen et al 2000 making the skjern the largest river in denmark in terms of discharge volume geologically the ahlergaarde catchment is a former glacial outwash plain the surface is largely made up of quaternary sandy sediments while the subsurface geology predominantly consists of pre quaternary clay which in several locations contains miocene sand lenses scharling et al 2009 the topography is mostly flat with a maximum elevation at 130 m a s l in the east of the catchment the climate is temperate maritime with an annual mean temperature of 8 2 c annual precipitation of 1050 mm and annual reference evapotranspiration of 570 mm stisen et al 2011 due to its topographical geological and climate characteristics the ahlergaarde catchment exhibits high groundwater recharge rates and a hydrogeological system that is mostly groundwater controlled the ahlergaarde catchment is part of the danish hydrological observatory hobe jensen and refsgaard 2018 3 methodology 3 1 hydrological models we employ two hydrological models in this study both of them based on the mike she code abbott et al 1986 graham and butts 2005 both models belong to the class of fully integrated spatially distributed hydrological models and feature fully coupled modules describing 3d groundwater flow overland flow river routing and land surface processes their model setup is largely based on the national water resources model of denmark dk model which was developed and is maintained by the geological survey of denmark and greenland hojberg et al 2013 climate data are provided as 10 10 km grids for rainfall and 20 20 km grids for reference evapotranspiration and air temperature the gridded rainfall product represents dynamically corrected rainfall accounting for undercatch stisen et al 2012 the two models henceforth referred to as model 1 and model 2 are characterized by different levels of complexity translating into notably diverging simulation run times table 1 moreover the models represent two different calibration paradigms a traditional calibration based on discharge and hydraulic heads versus a multi objective calibration scheme calibration additionally based on spatially distributed soil moisture remote sensing based evapotranspiration and soil surface temperature table 1 while testing the capability of k nn resampling to perform uncertainty assessment for multiple hydrological model outputs we also intend to answer the question of whether or not k nn performs equally good for both hydrological model set ups 3 1 1 model 1 simple in model 1 the unsaturated zone is assumed 1d and described by mike she s gravity flow solver where only wilting point and field capacity as given by the soil water retention curves are utilized the effects of capillary forces on the movement of water through the soil column are ignored the saturated zone is described by 3d flows using a vertical discretization of the permeable part of the subsurface around 500 m into seven layers actual evapotranspiration is calculated adopting the approach presented by kristensen and jensen 1975 where reference evapotranspiration and leaf area index lai are used as forcing data and soil moisture as a depending variable in order to avoid a long warm up period and to ensure stable initial conditions a hot start file was generated by performing a simulation covering the years 1990 2006 the hydrological model was then subject to a sensitivity analysis seventeen parameters were included in the sensitivity analysis the initial parameter values were taken from a structurally similar and previously optimized hydrological model sensitivity analysis was performed using pest doherty 2016 to reduce dimensionality we selected only the five most sensitive parameters cf table 2 for subsequent calibration calibration was performed for the years 2007 2010 using pest s sceua p utility which is an implementation of the sce shuffled complex evolution global optimization algorithm duan et al 1992 calibration targets were discharge from a set of gauges and hydraulic head in the layers of the geological model rmse root mean square error and pbias percent bias cf section 3 3 were used as objective functions 3 1 2 model 2 complex in model 2 unsaturated zone dynamics were calculated using the full 1d richards equation as implemented in mike she in contrast to model 1 actual evapotranspiration was simulated using the sw et model an energy balance module requiring hourly climate input data overgaard 2005 due to this modification model 2 is classified as a coupled subsurface surface atmosphere model especially the coupling with the sw et model is causing significantly longer run times of model 2 table 1 representing a rare example of a rigorous inverse calibration not least due to the immense computational demands the model had been calibrated in a previous study stisen et al 2018 using a multi objective calibration approach calibration was carried out using a global optimizer cma es covariance matrix adaptation evolution strategy five different calibration targets table 1 and eleven objective functions this ensured both a balanced calibration and the finding of a pareto optimal solution as defined in e g madsen 2003 3 2 uncertainty estimation k nn resampling k nn resampling as the name suggests resamples historical errors made by the model this technique is based on the assumption that the response of a hydrological system is documented by a sufficiently long record of observations and thus if the system is stationary that the statistical properties of errors can be inferred from a comparison between historical data and model predictions sikorska et al 2015 the foundations of the approach used in this study were recently presented by wani et al 2017 we adopt this approach while suggesting improvements to the workflow which involves the consideration of error autocorrelation upon choosing the variables that control the identification of nearest neighbors by the k nn algorithm the k nn resampling procedure is illustrated by the flow chart given in fig 2 and described systematically in the following for a detailed mathematical description the reader is referred to wani et al 2017 step 1 split data record the data record is split into two periods the first period represents a repository for the sampling of past errors in other words the k nn algorithm learns about the typical response of the hydrological system under different hydrological conditions the second period is a testing period for which the k nn algorithm predicts residual uncertainty based on the error samples collected from the repository the error e is defined as the difference between simulated and observed hydrological system response at any time step step 2 inspect acf pacf in order to establish which variables are suitable to condition the estimation of residual uncertainty on we suggest a hierarchical approach we propose to first focus on the error time series and check whether there is evidence for an autoregressive process ar of order p the order p would then be equivalent to the number of error lags to be included in the input variable vector ivv this can be achieved by plotting and visually examining the autocorrelation function acf and partial autocorrelation function pacf box et al 2008 for an ar of order p the acf will exhibit an exponential decay while the pacf will have significant nonzero correlation coefficients for lags smaller than or equal p and cut off thereafter being essentially zero box et al 2008 it is worth noting that we are not actually suggesting fitting an ar model to the data but merely use acf and pacf as guidance regarding the selection of ivv candidates subsequently dependence between the error time series and other hydrological variables is investigated using correlation analysis pearson s r this can be useful if the analysis of acf and pacf is inconclusive or in order to find supplementary variables for the ivv to also be able to capture nonlinear association between error and other variables which manifests in heteroscedastic residuals we additionally employ the distance correlation metric szekely et al 2007 another possible solution to choose ivv candidates for k nn is to employ the concept of partial information sharma and mehrotra 2014 but this will not be further addressed here to ensure that potential differences in units or amplitude between the error and hydrological variables do not affect the analysis standard scores need to be calculated a priori viable ivv candidates are then selected based on the strength of their interdependence with the error time series only including those with a high statistical dependence here user defined threshold of pearson s r 0 5 and keeping the number of ivv elements to a minimum step 3 compile ivv assemble the input variable vector using error number of lags included equals p and possibly auxiliary hydrological variables such as simulated discharge qsim etc with high explanatory power as identified in the step before the ivv is to be understood as a collection of variables which help to identify similar hydrometeorological conditions as those encountered at the respective prediction time step step 4 sample k errors the k nn algorithm is used to sample k historical errors from the repository to estimate residual uncertainty for the testing period determining an appropriate number of k is not straightforward and will be addressed in the discussion the error sampling works as follows for each day within the testing period the input variable vector points to a specific location in n dimensional ivv space the algorithm then searches the repository and identifies k days with the most similar conditions therefore being closest to that location in n dimensional ivv space nearest neighbors usually the euclidean distance is used to determine proximity to avoid having to standardize variables usage of the mahalanobis distance represents an alternative cf yates et al 2003 step 5 prediction intervals the k historical errors associated with the k nearest neighbors define an error distribution which under the assumption of stationarity and hence considering them as being representative for the testing period provides an estimate of residual uncertainty for each day of the testing period mathematically this can be expressed as 1 c t e i v v i v v t c p e r p r k where ct is the cumulative distribution function cdf of residual error at time step t conditioned on ivv ivvt similarity of input variable vector ivv ct is being approximated empirically by cp the cdf composed of k historical errors that satisfy rp rk where r is the euclidean distance and p stands for past then by calculating the 5th and 95th quantiles q i 0 05 q i 0 95 of the error sample 90 prediction intervals for each day of the testing period can be generated their width being defined by the difference between the percentiles 3 3 metrics 3 3 1 metrics for assessing hydrological model performance nash sutcliffe efficiency nse nash and sutcliffe 1970 2 nse 1 i 1 n q sim i q obs i 2 i 1 n q obs i q obs 2 where q sim i is the simulated discharge q obs i is the observed discharge at time step i and q obs is the mean observed discharge root mean square error rmse 3 r m s e i 1 n y o b s i y sim i n where n is the number of data pairs y o b s i are the observations y sim i the simulations at each time step i mean error me 4 me 1 n i 1 n y o b s i y sim i where n is the number of data pairs y o b s i are the observations y sim i the simulations at each time step i pearson s r 5 ρ y o b s i y sim i cov y o b s i y sim i σ y o b s i σ y sim i where cov is the covariance of y o b s i observations and y sim i simulations while σ is the standard deviation percent bias pbias 6 pbias i 1 n y o b s i y sim i 100 i 1 n y o b s i where n is the number of data pairs y o b s i are the observations y sim i the simulations at each time step i 3 3 2 metrics for assessing uncertainty estimates in order to assess the performance of k nn resampling for uncertainty prediction and analogous to wani et al 2017 three validation metrics were calculated the prediction interval coverage probability picppi the mean prediction interval mpipi see for example shrestha and solomatine 2008 and the alpha index α cf renard et al 2010 prediction interval coverage probability picp90 the picp90 is the percentage of instances c90 for which an observation is contained within the limits of the 90 prediction interval 7 p i c p 90 1 n i 1 n c 90 100 8 c 90 1 i f q i 0 05 q i q i 0 95 0 e l s e mean prediction interval mpi90 the mean prediction interval allows expressing uncertainty as the average width of the 90 prediction interval based on the k nn error distribution the 90 prediction interval is defined by the difference between the 5th and 95th quantile q i 0 05 and q i 0 95 respectively of the k nn error distribution at every time step i 9 m p i 90 1 n i 1 n q i 0 95 q i 0 05 we further test the reliability of quantiles of k nn based error prediction by plotting them against the quantiles of observed error in a reliability diagram additionally the alpha index α provides a numerical measure of reliability as it relates to the area α that is defined by calibration function and identity line 10 α 1 100 j 1 100 q o b s j j 100 11 α 1 2 α where α is the area between calibration function and identity line q obs j are the quantiles of observed errors and j 100 gives the quantiles of predicted errors 3 4 experimental set up k nn resampling was applied to model outputs from deterministic simulations by model 1 and model 2 both covering the historical period january 2011 to august 2016 repository for the k nn resampling was the entire period provided data were available apart from the year 2014 which was selected as the testing period looking at an entire year enabled us to study the performance of k nn across seasons including changes in dynamics etc in addition the year 2014 represents the most recent complete year in the historical period for which all four hydrological variables that were examined had observational data cf table 3 despite excluding 2014 from the k nn resampling the repository was treated as if it were continuous k nn resampling was carried out using the rann package arya et al 2015 implemented in the scientific progamming environment r r development core team 2018 eight individual k nn input variable vectors were established one for each of the four hydrological variables discharge hydraulic head soil moisture and evapotranspiration and each of them for the two hydrological models the input variable vectors for the k nn models were composed based on analysis of acf and pacf additionally correlations and distance correlations were calculated in order to test whether there were non linear dependencies between the error time series and a set of additional hydrological variables which potentially could have an impact on the magnitude of errors generated by the model e g heavy rainfall might be correlated with large errors generated by the model the hydrological variables that were analyzed in this context were observed and simulated discharge soil moisture hydraulic head actual evapotanspiration respectively observed rainfall both at catchment and at single grid cell scale observed soil moisture hydraulic head and actual evapotraspiration in all cases distance correlations not shown here with other hydrological variables were found to be relatively weaker as compared to error autocorrelation potential commensurability issues beven 2012 will be addressed in the discussion therefore we decided to restrict the conditioning to observed error including as many lags as the analysis of acf and pacf suggested an overview of the input variable vector composition derived based on the considerations detailed in section 3 2 is given in table 3 for the period of interest regarding the application of k nn resampling 2011 2016 observational data were retrieved from the hobe database locations of observational sites are shown in fig 1 discharge observations daily mean in m3 s were collected by a gauge located at the outlet of ahlergaarde catchment while the soil moisture observations were made by a decagon ech2o data logger id nw 2 1 depth of 22 5 cm bircher et al 2012 hydraulic head observations stem from a groundwater well id 8014 and actual evapotranspiration from an eddy covariance flux tower ringgaard et al 2011 at the forest site in gludsted fig 1 while the hobe database contains a vast amount of data for a variety of hydrological variables measured at numerous sites within the catchment the measurement sites and data periods used in this study were selected based on the criterion of longest possible gap free observational record as shown in table 3 this selection criterion led to differences in the lengths of the observational records and consequently to differences in the lengths of the respective training period for different hydrological variables when compared to other studies that employ k nn as a post processor e g sikorska et al 2015 it must be stated that the length of the testing period in our study is comparatively short the implications of this will be further addressed in the discussion the number of k i e the number of nearest neighbors to be sampled from the repository was chosen to be 199 as opposed to e g k 99 in wani et al 2017 we did this for two reasons first we wanted to ensure that the error quantiles would coincide with an actual error sample and two we chose k to be larger than 99 because our historical data record was considerably shorter than those used in other studies potentially reducing the number of contained examples of hydrologically similar conditions therefore requiring us to somewhat relax the k nn search requirements 4 results 4 1 hydrological model performance the performance metrics of the hydrological simulation of the testing year 2014 by the two hydrological models before applying k nn are shown in table 4 based on the metrics alone it cannot be concluded that one of the models performs better than the other one in all aspects for discharge the complex model model 2 is seen to perform better regarding dynamics while the simple model model 1 has a smaller bias for soil moisture and evapotranspiration the two models are almost equally good at simulating the dynamic behaviour while model 1 exhibits the smaller biases with regard to groundwater heads model 1 shows a better performance 4 2 hydrographs and residual uncertainty model 1 simple hydrographs simulated by model 1 for discharge as well as equivalents for soil moisture hydraulic head and actual evapotranspiration in the testing year 2014 are presented in fig 3 while the k nn prediction intervals look different depending on the hydrological variable pipc90 is generally close to the expected value of 90 88 2 87 4 93 4 90 7 for q sm h et note that the fact that the prediction intervals depart from the simulation in certain places is due to the property of k nn to allow the residuals to have a non zero mean in places where the prediction interval departs the k nn algorithm learned that in similar situations in the past the errors were not centered around the simulation but systematically above or below the k nn algorithm automatically corrects for systematic over or underprediction by the model and may result in narrow prediction intervals in cases where the actual spread of the sampled errors is small with regard to discharge the resulting prediction interval while being relatively constant overall mpi 4 03 m3 s table 5 is slightly wider during low flow conditions and slightly narrower during high flow conditions this corresponds well with the fact that the largest mismatch between observations and simulation is indeed found during low flow conditions throughout the summer period while the model reproduces observed peak flow relatively well around day 200 the prediction interval departs from the simulation successfully encapsulating most of the observations this is exemplary for a situation where k nn resampling leads to an error distribution that effectively corrects for systematic over or underprediction by the model assocated with similar hydrological conditions in the past compared to discharge the prediction interval for soil moisture is highly unsteady exhibiting an erratic structure and a partly extremly wide prediction interval mpi 0 104 table 5 although picp90 87 9 is near the expected value k nn was clearly unable to obtain informative error samples from the repository this is probably a result of the short training period and may also be linked to the choice of using gravity flow as unsaturated zone solver resulting in a failure of the model to reproduce soil moisture content and dynamics for most parts of the testing year crude overestimation up to day 100 and past day 225 underestimation between day 125 and 225 especially depletion of soil moisture during spring summer is not reproduced as for hydraulic head the prediction interval is very narrow mpi 0 32 m table 5 with a number of local expansions the picp90 93 4 slightly exceeds the expected value the substantial bias between observations and simulation is successfully corrected for by k nn resampling a visual assessement of the prediction interval for actual evapotranspiration is impeded by the large fluctuations of simulation and observations from day to day especially during the summer period generally the prediction interval is relatively wide 2 2 mm d while the picp90 is very good 90 7 4 3 hydrographs and residual uncertainty model 2 complex hydrographs simulated by model 2 for discharge as well as equivalents for soil moisture hydraulic head and actual evapotranspiration in the testing year 2014 are presented in fig 4 the pipc90 is close to but consistently exceeds the expected value of 90 94 0 97 3 96 2 92 6 for q sm h et with regard to discharge the resulting prediction interval is narrower mpi 3 28 m3 s table 5 varies notably more and generally seems to be better fitted than its counterpart obtained for model 1 contrary to what was observed before the prediction interval is narrowest during low flow conditions wider for high flow conditions and has its maximum width in the transitionary period between winter and spring ca day 75 100 coinciding with the largest difference between observations and simulation apart from a short period in summer around day 200 the prediction interval effectively only extends in an upward direction heteroscedasticity is captured as illustrated by the increasing width in mpi for different discharge flow categories cf table 5 when looking at soil moisture the prediction interval is distinctly less erratic and on average narrower mpi 0 048 table 5 than the one obtained using model 1 however the prediction interval shows little differences in width thoughout the testing year in comparison to model 1 the usage of the richards equation as unsaturated zone solver clearly led to an improved although biased simulation of the soil moisture dynamics while k nn resampling results in error prediction intervals that contain more than the expected 90 of all observations picp90 of 97 2 they do correct for the systematic deviation of simulation and observations overestimation by the model with regard to hydraulic head the k nn based prediction interval is yet again very narrow mpi 0 34 m table 5 however it appears to be systematically wider for the first systematically narrower for the second half of the testing year the picp90 96 2 moderately exceeds the expected value as seen for model 1 the bias between observations and simulation is successfully corrected for by k nn resampling when comparing the graphs for model 1 and 2 it appears that the hydraulic head simulation for model 2 shows somewhat larger fluctuations this is very likely connected to the different unsaturated zone solvers as was the case for model 1 the prediction interval for actual evapotranspiration is difficult to assess as the large day to day fluctuations of simulation and observations prevents this it is worth noting that simulated actual evapotranspiration for model 2 is derived using the sw et model the prediction interval is relatively wide 3 05 mm d while the picp90 is rather good 92 6 4 4 reliability diagrams the performance of k nn resampling regarding the reliability of the error quantiles for all flows is evaluated by generating realiability diagrams fig 5 and calculating the alpha index table 5 reliability diagrams are typically used in ensemble forecasting we employ them to assess the performance of the k nn method with regard to residual uncertainty prediction the probability of non exceedence relates to the respective error quantile based on k 199 error samples the observed relative frequency relates to the percentage of cases in n 365 days year 2014 for which the error was above the respective quantile the closer the dots fall with regard to the 1 1 line of the reliability diagram the more reliable the error prediction can be considered with regard to discharge the reliability diagram for model 1 suggests high reliability of the error quantiles as nearly all points fall along the identity line the alpha index of 0 94 supports this conclusion above a probability of non exceedance of ca 0 5 a slight trend towards overprediction probabilities too high deviation of calibration function to the right of the 1 1 line is detectable the corresponding reliability diagram for model 2 shows a slight downward deviation of the calibration function from the 1 1 line for probabilities of non exceedance of ca 0 05 to 0 3 yet again indicating overprediction however the graph returns back to the identity line thereafter overall the reliability of the error quantiles can be considered very high alpha index of 0 93 as for soil moisture the points of the calibration function for the error quantiles of model 1 are close to the identity line up to a non exceedance probability of 0 5 for larger probabilities the graph begins to deviate from the identity line in an upward direction underprediction with the largest deviation found at a probability of non exceedance around 0 7 the graph eventually returns to the desired 45 line around a probability of non exceedance of 1 the alpha index is 0 89 in comparison the reliability diagram for error quantiles of model 2 despicts a calibration function that shows comparatively smaller but constant deviations from the identity line between probabilities of non exceedance of 0 2 and up to nearly 1 before returning to the 1 1 line the alpha index is equal to 0 93 and thus notably better than that of model 1 the reliability diagrams for error quantiles of hydraulic head represent the ones with the strongest deviations from the identity line and therefore lowest reliability for both model 1 and model 2 there is an overprediction up to a probability of non exceedance of about 0 4 above which there is a transition towards underprediction with peaks at a probability of non exceedance of 0 7 and 0 6 respectively the graph eventually returns to the identity line around 1 according to wilks 2006 the reliability diagrams have good resolution but are underconfident the alpha index is equal to 0 86 and 0 84 for model 1 and model 2 respectively suggesting reasonable reliability finally the reliability diagrams for error quantiles of actual evapotranspiration suggest a very reliable error prediction for both model 1 and model 2 as for model 1 a slight underprediction at probability of non exceedance of 0 1 0 2 respectively is followed by an equally minor overprediction probability of non exceedance of 0 5 0 8 while the scatter is still located very closely to the identity line regarding model 2 there is a slight overprediction around a probability of non exceedance of 0 3 while the remaining calibration function largely falls along the identity line alpha indices of 0 93 and 0 95 indicate high reliability in summary the reliability diagrams in fig 4 show that the k nn error quantiles are indeed reliable for all hydrological variables and both models when looking at the alpha indices reliability of the k nn error quantiles appears to be slightly higher for model 2 in the case of soil moisture and actual evapotranspiration while being higher for model 1 in the case of discharge and hydraulic head however the numerical differences are small 4 5 reproduction of error acf fig 5 compares autocorrelation functions for observed and k nn predicted errors in the testing year 2014 given that the respective ivv cf table 3 informed the k nn algorithm well and the historical record held sufficient examples of relevant hydrological conditions the acf of observed errors should be reproduced by the acf of k nn sampled errors a look at the acf for discharge fig 6 first row shows that the autocorrelation function is only roughly repoduced for both models in both cases the k nn based acf exhibits correlation coefficients with a higher magnitude than found in the observed ones however the overall decline in autocorrelation with increasing lag is reflected to some extent for model 2 the increase in correlation at lag 6 to 8 can be found in the k nn based acf when looking at the acfs of soil moisture it seems that the k nn based acf agrees well with the acf of observed errors for model 1 the continuous decline in correlation is well reproduced for model 2 both the decline as well as the increase of correlation around lag 25 are mirrored in the k nn based acf as for hydraulich head k nn resampling appears to have performed better with regard to model 2 the k nn based acf matches the one of observed errors quite well in terms of slope of the decline in correlation and magnitude of correlation coefficients for model 1 this is clearly not the case finally the k nn based acfs for actual evapotranspiration are well reproduced for both models even though they are very different in appearance while the acfs associated with model 1 exhibits correlation coefficients which are significant for all lags model 2 shows considerably lower correlation including insignificant peaks from at e g lag 2 to 5 hence it can be concluded that on average k nn resampling was able to reproduce observed error autocorrelation well this is true for both models albeit the k nn based acfs obtained for model 2 appear to agree a bit better with the observed error autocorrelation than those of model 1 5 discussion 5 1 k nn resampling applied to complex multi variate model in this study we employed a nonparametric method called k nn resampling to perform uncertainty assessment for two deterministic simulations carried out using two configurations of a coupled integrated hydrological model while previous applications in hydrological literature are limited to prediction of streamflow lall and sharma 1996 souza and lall 2003 or e g weather variables rajagopalan and lall 1999 our study presents an application with a multi site multi variable prediction we simultaneously quantify residual uncertainty for multiple model outputs soil moisture hydraulic head and actual evapotranspiration in addition to discharge despite a number of differences between the two employed models see discussion in section 5 3 the results indicate that k nn resampling is capable of producing reliable prediction intervals for this class of hydrological models consideration of error autocorrelation led to smooth prediction intervals pis for discharge highest order p longest memory which is in line with observations made by evin et al 2014 for all four examined hydrological variables k nn based prediction intervals achieved coverage probabilities that were close to but mostly exceeded the expected value of 90 similar results were obtained by sikorska et al 2015 using k nn picp coverage of 97 9 compared to expectation of 95 and montanari and koutsoyiannis 2012 using a meta gaussian approach picp coverage of 90 3 compared to expectation of 95 as demonstrated by fig 6 k nn rather successfully mimicked the autocorrelation of errors observed in the testing period year 2014 systematic biases in the hydrological model simulation such as observed for hydraulic head cf figs 3 and 4 are accurately estimated resulting in narrow prediction intervals encapsulating most of the observations and error quantiles that achieve high reliability this is in line with findings by wani et al 2017 who showed that the reliability was not impeded when imposing an artificial bias on the simulation learning from past errors k nn accounts for systematic deviations resulting in prediction intervals that may depart significantly from the deterministic model prediction this would not be possible if e g using a parametric method which assume zero mean normally distributed residuals we proposed to exploit information contained in the error time series by analyzing acf and pacf to determine the order of the autoregressive process and formalize input variable vector composition for cases where conclusive demonstrably the performance based on error alone was very good 5 2 ability to compensate for errors due to scale commensurability issues when comparing hydrological variables simulated by spatially distributed models at within catchment locations with field observations commensurability issues often occur due to differences in support scale between model grid cells and field sample volumes beven 2012 in our case model grid cells have lengths of 500 m while e g soil moisture samples represent about 0 1 m and groundwater head observations are merely point values as soil properties exhibit large spatial variability and groundwater heads may vary considerably within 500 m systematic biases are typically seen when comparing model results and field observations ehlers et al 2019 it is therefore interesting to assess to which extent k nn is able to compensate for such scale commensurability issues our results are encouraging in this respect as they show that k nn is capable of estimating and handling biases caused by scale mismatch because the biases are reasonably constant in time and k nn learns from past errors 5 3 comparison between the two hydrological models to assess the robustness of our findings and evaluate how k nn resampling performs for different simulations of the same variable we tested k nn resampling on top of two different configurations of the same hydrological model the two model configurations were characterized by differences in structural complexity process description and calibration data both the picp and the alpha index allowed no clear conclusion as to which model k nn performs better on it is however interesting to note that the alpha index is better for model 2 for soil moisture and actual et which were included in the calibration of model 2 but not model 1 while the alpha index is better for model 1 regarding discharge and hydraulic head as the performance in the underlying hydrological models table 4 is less clear on this and as the differences in alpha index between the models are quite small we cannot draw firm general conclusions on the relation between hydrological model performance calibration targets and performance of the k nn for discharge the mpis are considerably smaller for model 2 than for model 1 table 5 implying that model 2 k nn predictions would be more useful in practice although the metrics in table 4 are unclear as to which hydrological model exhibits the best performance a visual inspection of the hydrographs reveals that model 2 has a more realistic simulation of the dynamics for low flows while model 1 has a systematic overprediction of low flows it is noted that it is also for low flows the smallest 10 of river discharges that the mpi shows the largest difference between the two models 3 22 m3 s for model 1 versus 1 80 m3 s for model 2 table 5 for low flows simulated by model 1 k nn results in wide prediction intervals reflecting a large variation of the residuals as can be seen from fig 3 the prediction intervals width results in a good coverage of the observed discharge for soil moisture the mpis are considerably smaller for model 2 than for model 1 table 5 while picp is good for both models the resulting pi of model 1 looks very inconsistent while the one of model 2 gives a notably better impression while the model 2 k nn thus is seen to perform better for soil moisture it cannot be concluded from table 4 which of the two underlying hydrological models is superior a likely reason why k nn results in more consistent pis for model 2 may be that the errors in model 2 show a rather constant bias overprediction and are hence relatively easy for the k nn to reproduce while model 1 errors show both overprediction and underprediction this difference in performance of the underlying hydrological models is likely a result of the superior simulation using the richards equation model 2 instead of gravity flow model 1 for hydraulic head where model 2 performs significantly better than model 1 table 4 there is almost no difference in k nn performance table 5 this implies that k nn is able to compensate a poorer simulation by model 1 to achieve the same performance as k nn model 2 although model 2 had a significantly better point of departure the better performance of the underlying hydrological model 2 is probably a consequence of the more complex descriptions of the unsaturated and the saturated zones table 1 compared to other hydrological variables the alpha index suggests an inferior reliability of the predicted error quantiles 0 86 and 0 84 the only ones below 0 9 possibly the k nn resampling is at a disadvantage for this particular variable due to comparatively short length of the observational data set for hydraulic heads n 1393 and the fact that both observation and simulation time series do not fluctuate much i e errors tend to be very similar basically everywhere for actual et the metrics for the underlying hydrological models table 4 indicate that model 2 is better at simulating dynamics higher correlation 0 77 vs 0 72 while model 1 has the smaller bias the performance of the k nn table 5 shows that the error quantiles are better for model 2 alpha index 0 93 vs 0 95 yet the mpi is significantly wider a visual inspection of the hydrographs reveals that model 2 fig 4 has a much more erratic simulation of actual et than model 1 fig 3 with the result that the errors show significantly less autocorrelation for model 2 than for model 1 fig 5 this combination of a larger day to day fluctuation of simulated actual et values and hence a more erratic structure of the errors causes k nn to produce wide prediction intervals which in turn do encapsulate a large portion of the observations 5 4 limitations of the present k nn test one limitation in the present study is that we kept the value of k in this study at 199 for all four hydrological variables and did not investigate the sensitivity of the results to other choices of k a rule of thumb to obtain a robust number of k sivakumar 2017 is to take the square root of the number of available observations n which would have resulted in a value of k around 45 which is significantly smaller than our value of k 199 given the relatively short length of our observational records ranging from 1393 to 2070 days table 3 as compared to other applications of k nn and the picp coverage exceeding the expected value our k value is possibly too high hence introducing a high number of not so similar error samples into the uncertainty prediction as k is effectively a smoothing parameter sivakumar 2017 the resulting empirical error distributions might be close to the marginal distribution of the error associated with the respective hydrological variable this in turn might result in prediction intervals that have a rather constant width regardless of hydrological conditions yet as visual inspection of our prediction intervals as well as the mpis for different flow categories table 5 shows our prediction intervals are not constant in width ergo the value of k appears not to result in an empirical error distribution that equals the marginal distribution also sikorska et al 2015 found the value of k when varied between 5 and 100 to have little impact on the prediction intervals another weakness of our study is that the testing period for the k nn was limited to one year which is a short period compared to previous studies for example sikorska et al 2015 use 10 years for error sampling and 10 years for testing while wani et al 2017 use 6 years but at a resolution of 12 h for error sampling and testing for their upper severn catchment case study it should be noted however that we use data for a 10 years period 2007 2016 four years are used for calibrating the hydrological models and five out of the six remaining years are used as repository for the k nn learning leaving only one year for the k nn testing our results indicate that both five years of repository data and a one year test period are critically short periods while less than 10 years typically are sufficient to obtain robust calibration and validation tests of a hydrological model stisen et al 2018 k nn resampling as a data driven method which cannot even use data from the calibration period of the hydrological model requires a longer data period while this is typically not a limitation for discharge we have e g a 100 year record for our catchment karlsson et al 2014 10 year data records of spatially distributed observations of groundwater heads soil moisture as well as evaporation flux are quite unique and typically only available from long term research monitoring programs such as hydrological observatories jensen and refsgaard 2018 we believe this is a serious limitation for the use of k nn resampling in connection with complex multivariate models among these limitations that inevitably cause uncertainty on the details of our findings we assess the short data period as the most severe weakness 5 5 practical applicability of k nn resampling for complex multivariate models the application of k nn in this paper demonstrated that the technique works well with a complex coupled integrated hydrological model the method is very flexible and allows near simultaneous ua time efficient 1 min per hydrological variable as opposed to several weeks for mc based ua on a standard desktop computer another characteristic is that the k nn predicts a lumped measure of uncertainty implicitly accounting for e g input and model structural uncertainty unless there is an explicit consideration of the contributing sources see e g sikorska et al 2015 in contrast mc based uncertainty approaches often neglect some of the sources typically the model structure uncertainty refsgaard et al 2006 2007 while knowing the relative contributions of individual sources of uncertainty to the overall uncertainty might be insightful when aiming for an enhanced process understanding or the devleopment of strategies to reduce predictive uncertainties a lumped estimate as produced by k nn resampling may be sufficient to support practical decision making in hydrology k nn resampling has been used for short term streamflow forecasting in combination with simple rainfall runoff models for the models presented in our paper the k nn setup could easily be reconfigured to be able to make short term forecasts of streamflow hydraulic head soil moisture and actual et another possible practical application of k nn resampling in the configuration presented in this paper would be to estimate prediction uncertainty at ungauged locations within a catchment this could e g be done by analyzing groundwater wells in known geological units perform k nn based uncertainty analysis for them and then use the obtained uncertainty as being representative for the respective geological unit the well is located in in doing so simulation grids for e g groundwater head could be assigned spatially varying uncertainties in this way a few monitoring sites may be used to correct model predictions and assess prediction uncertainties for several ungauged sites a basic assumption in this respect is that catchment conditions are stationary over time requiring that anthropogenic alterations such as changes in climate land use and groundwater abstraction are insignificant a well known limitation for the practical use of data driven methods such as k nn resampling is that they are unable to predict outside the observed range this can be overcome using innovations to perturb the observations rajagopalan and lall 1999 using a kernel density estimator sharma et al 1997 or modifying the setup of the k nn algorithm prairie et al 2006 6 conclusions we have tested the ability of k nn resampling to generate reliable residual uncertainty for multi variable output of a complex coupled integrated hydrological model for the 1055 km2 ahlergaarde catchment constituting the danish hydrological observatory with unique monitoring data the tests included four types of variables discharge hydraulic head soil moisture and actual evapotranspiration and two different hydrological model configurations characterized with very different dynamics and error structures our results document that the k nn resampling performs efficiently and reliably for complex multivariate models and that this conclusion is robust for all the four tested types of variables and both the applied models k nn resampling has proven to be very efficient in estimating and compensating for errors occurring due to commensurability scale mismatch between model grid cells and point scale field observations which typically causes local biases in simulation results of spatially distributed models ehlers et al 2019 the use of four variables and two models allows comparison of performances of k nn resampling for a variety of error structures comparisons of k nn resampling applied on top of a simple and a complex hydrological model show that we cannot make firm general conclusions between the performance of the hydrological model and the k nn resampling i e better performance of the underlying hydrological model does not necessarily lead to better performance after applying k nn resampling this is opposite to common knowledge in data assimilation refsgaard 1997 more detailed analyses of the results indicate that k nn resampling is most efficient in producing narrow prediction intervals when the residuals are relatively constant in time while erratic residuals result in relatively wide prediction intervals in our case study we did not perform sensitivity analyses for the k value and we have a short period for testing the k nn resampling while acknowledging that these factors inevitably lead to uncertainty on our specific findings we do not assess these uncertainties to change the above main conclusions although we had ten years of excellent data from our research catchment we consider this a critically short data period because part of the period needs to be used for calibration of the hydrological model and the majority of the remaining period has to be used for training calibration of the k nn resampling setup while it is relatively easy to find longer time series 15 years for discharge this is very difficult for combined data series discharge hydraulic head soil moisture actual evapotranspiration because these data are not part of standard monitoring programs but only collected in research catchments we consider this lack of long data series as the most serious limitation for a widespread use of k nn resampling for complex multivariate hydrological models while k nn resampling is a comparative lightweight amongst ua methods in terms of mathematical sophistication its strengths are its robustness in the face of model bias and the ease with which in can be implemented and set up to carry out ua for multiple model outputs the latter property renders it a potent tool for applied hydrology and situations where uncertainty assessment is to be performed for multiple hydrological model outputs individually thus providing decision makers with valuable information about uncertainty of secondary model outputs shifting focus away from discharge only oriented ua will help fully exploiting the enormous potential of complex hydrological models acknowledgments this study has been carried out as part of the hobe project hydrological observatory www hobecenter dk which is funded by the v illum foundation all data used in this study is stored in the project database www hobedata dk to obtain access contact frederik uldall fu ign ku dk declarations of interest none 
624,regardless of the complexity of the hydrological model employed uncertainty assessment ua is predominantly performed for the aggregated catchment response discharge for coupled integrated models that simulate various hydrological states and fluxes on a grid cell basis this represents a severe shortcoming we test a simple data driven technique k nn resampling to evaluate its ability to provide reliable residual uncertainty estimates for the multi variable discharge hydraulic head soil moisture and actual evapotranspiration deterministic output of two coupled groundwater surface water models with different complexities being a nonparametric method no explicit prior assumptions about the error distribution of different hydrological variables are required when conditioning the algorithm we propose to limit the number of error lags to be included based on inspection of the partial autocorrelation function pacf our results confirm previous findings regarding reliability and robustness of the k nn technique for discharge simulations and conclude that k nn resampling also provides reliable and robust results for other variables like hydraulic head soil moisture and actual evapotranspiration even for underlying hydrological models with varying levels of performance the 90 prediction intervals pi capture the observations in the testing period satisfactorily for all hydrological variables 92 6 97 3 while alpha indices 0 84 0 95 indicate very reliable pis for all error quantiles differences in error structure between hydrological variables are successfully inferred from historical data and reflected in the results we conclude that k nn resampling represents a potent cost efficient ua technique for applications in operational hydrology facilitating a near simultaneous easy uncertainty assessment for various outputs of computationally heavy hydrological models keywords distributed hydrological model post processor k nearest neighbor resampling residual uncertainty multivariate uncertainty assessment autocorrelation heteroscedasticity 1 introduction the intricate dynamics of natural hydrological processes are difficult to reproduce using even the most sophisticated physically based hydrological models as hydrological models represent mere approximations of real world systems it follows that model predictions are uncertain cf e g beven 2012 in order to provide a reliable basis for decision makers model outputs need to be accompanied by an estimate of the uncertainties associated with them as research conducted in the past two decades ascertains effectiveness and sustainability of water resource management critically depend on a thorough uncertainty assessment ua see for example beven 2002 refsgaard and henriksen 2004 wagener and gupta 2005 and ajami et al 2008 accordingly quantification of uncertainties in hydrological modeling is considered good scientific practice e g refsgaard et al 2007 among the first to recognize the necessity of acknowledging the presence of uncertainty in hydrological model simulations were beven and binley 1992 they developed the generalized likelihood uncertainty estimator glue which uses monte carlo mc simulation the authors coined the term equifinality assuming that model imperfection and incomplete process understanding entail that a potentially endless number of hydrological models and parameter combinations will result in equally acceptable model performance however glue has been shown to have limitations due to the usage of an informal likelihood function for model parameter identification cf mantovan and todini 2006 and stedinger et al 2008 with the aim to quantify the contributions of different sources of uncertainty to predictive uncertainty individually a number of formal ua approaches based on bayesian inference were introduced in this context particular attention was given to the explicit consideration of input uncertainty rainfall a prominent example is the bayesian total error analysis batea kavetski et al 2006a kavetski et al 2006b in which uncertainty in rainfall is accounted for by means of a rainfall multiplier while often neglected model structural uncertainty is a major source of predictive uncertainty see for example refsgaard et al 2006 for a comprehensive review on this matter in contrast ajami et al 2007 developed the integrated bayesian uncertainty estimator ibune which allows combining the rainfall multiplier concept with consideration of model structural deficiencies by using a variety of model structures by means of bayesian model averaging bma see hoeting et al 1999 however finding an adequately representative likelihood function for hydrology capturing autocorrelated non normal and heteroscedastic errors is a matter of ongoing research e g schoups and vrugt 2010 mcinerney et al 2017 and han and zheng 2018 bayesian approaches and more generally speaking mc based ua techniques require a vast number of model evaluations orders of magnitude of 103 105 the parameter samples generated during inference need to be propagated through the hydrological model until convergence is diagnosed in operational hydrology this can represent a serious obstacle for several reasons for example when commercial software is employed to perform hydrological simulations parallelization may be limited by license availability in addition while bayesian methods are often tested using fast conceptual rainfall runoff models computational costs are incrementally larger when applied to complex coupled integrated hydrological models although likely only being a matter of time this currently still restricts their applicability e g juston et al 2013 for these reasons computationally less demanding ua methods represent an attractive alternative especially for applications in operational hydrology to this end one possibility is to resort to meta modeling in which outputs of a complex hydrological models simulator are being approximated through a surrogate model emulator cf o hagan 2006 the emulator is obtained by establishing a statistical relationship between the model outputs reichert et al 2011 a recent example is given by carbajal et al 2017 who compared the performance of data driven and mechanistic emulators in an urban drainage context similarly miller et al 2018 use polynomial chaos expansion conceptually being an emulator for uncertainty quantification of an integrated surface subsurface hydrological model another possibility for more time efficient ua is to apply post processing techniques to deterministic hydrological model runs post processors are based on the assumption that the model parameters are identifiable using optimization of a cost function i e that there is a single optimized model with well constrained parameters which entails an implicit likelihood function uncertainty estimation is then based on the application of data driven techniques that require comprehensive historical data to generate anticipated model errors this would be equivalent to producing samples from a likelihood function for a defined set of model parameters post processors have been applied in various hydrological modeling studies mostly in conjunction with short term streamflow forecasts prominent examples include quantile regression qr weerts et al 2011 estimation based on local errors and clustering uneec solomatine and shrestha 2009 or the dynamic uncertainty model by regression on absolute error dumbrae method pianosi and raso 2012 despite their relative conceptual simplicity post processors are generally robust see for example pokhrel et al 2013 evin et al 2014 even report a post processor approach to outperform a joint bayesian technique in terms of robustness in the presence of error heteroscedasticity and autocorrelation among post processing techniques k nearest neighbor k nn resampling is comparatively simple and easy to implement its univariate predecessor was introduced to the hydrological modeling community by karlsson and yakowitz 1987 who used it as a tool to predict streamflow k nn resampling is a nonparametric method which implies that no explicit assumptions gaussian zero mean about the nature of model error are made see for example hollander et al 2015 instead the error structure is reproduced by sampling realizations from the space of historical model errors resulting in multiple local approximations of the complex target function during prediction solomatine et al 2008 recent applications of k nn in hydrology include work by sikorska et al 2015 beckers et al 2016 and wani et al 2017 sikorska et al 2015 used k nn resampling for uncertainty estimation while accounting for input uncertainty by means of an ensemble and parameter uncertainty separately the authors found the method to outperform a formal statistical meta gaussian technique devised by montanari and brath 2004 beckers et al 2016 adopted k nn to select ensemble streamflow prediction esp traces from original esps based on climate index values prior to generating new ensemble traces in a resampling procedure in wani et al 2017 k nn resampling was applied to estimate residual uncertainty for streamflow forecasting a comparison with two more complex post processors qr and uneec showed that k nn in spite of its simplicity performed well in terms of accuracy and reliability of its uncertainty estimation this work represents an application of the k nn configuration detailed in wani et al 2017 while k nn thus has been successfully applied for generating short term streamflow predictions in a forecasting context and in combination with simple rainfall runoff models there is no documentation in the literature on tests of k nn resampling to perform uncertainty analysis for multiple variables in a complex coupled groundwater surface water model therefore the main objective of this study is to test the potential of k nn resampling for generating reliable residual uncertainty intervals for the multi variable output of a complex coupled integrated hydrological model the hydrological variables incorporated in the ua were discharge hydraulic heads soil moisture and actual evapotranspiration which in addition represents model response at interior catchment locations in doing so we take a step further towards fully exploiting the full potential of this class of hydrological models this will furthermore allow the communication of the associated uncertainties to public and end users which in turn may lead to an increased level of trust in scientific results juston et al 2013 moreover we contribute to a formalization of the process of composing the k nn input variable vector ivv by suggesting a hierarchical approach that is primarily based on analysis of partial autocorrelation of model errors using a flexible and fast post processing technique coded in freely available software for uncertainty quantification r development core team 2018 we do our part to further establish ua as a routine in hydrology pappenberger and beven 2006 especially with regard to complex hydrological models whose computational costs preclude mc simulation 2 study area the study area is the 1055 km2 ahlergaarde catchment on the jutland peninsula in western denmark fig 1 the catchment is the headwater of the skjern river which has its source at the jutland ridge towards the eastern boundary of the catchment and discharges into the north sea via ringkøbing fjord the annual mean discharge is 37 m3 s ovesen et al 2000 making the skjern the largest river in denmark in terms of discharge volume geologically the ahlergaarde catchment is a former glacial outwash plain the surface is largely made up of quaternary sandy sediments while the subsurface geology predominantly consists of pre quaternary clay which in several locations contains miocene sand lenses scharling et al 2009 the topography is mostly flat with a maximum elevation at 130 m a s l in the east of the catchment the climate is temperate maritime with an annual mean temperature of 8 2 c annual precipitation of 1050 mm and annual reference evapotranspiration of 570 mm stisen et al 2011 due to its topographical geological and climate characteristics the ahlergaarde catchment exhibits high groundwater recharge rates and a hydrogeological system that is mostly groundwater controlled the ahlergaarde catchment is part of the danish hydrological observatory hobe jensen and refsgaard 2018 3 methodology 3 1 hydrological models we employ two hydrological models in this study both of them based on the mike she code abbott et al 1986 graham and butts 2005 both models belong to the class of fully integrated spatially distributed hydrological models and feature fully coupled modules describing 3d groundwater flow overland flow river routing and land surface processes their model setup is largely based on the national water resources model of denmark dk model which was developed and is maintained by the geological survey of denmark and greenland hojberg et al 2013 climate data are provided as 10 10 km grids for rainfall and 20 20 km grids for reference evapotranspiration and air temperature the gridded rainfall product represents dynamically corrected rainfall accounting for undercatch stisen et al 2012 the two models henceforth referred to as model 1 and model 2 are characterized by different levels of complexity translating into notably diverging simulation run times table 1 moreover the models represent two different calibration paradigms a traditional calibration based on discharge and hydraulic heads versus a multi objective calibration scheme calibration additionally based on spatially distributed soil moisture remote sensing based evapotranspiration and soil surface temperature table 1 while testing the capability of k nn resampling to perform uncertainty assessment for multiple hydrological model outputs we also intend to answer the question of whether or not k nn performs equally good for both hydrological model set ups 3 1 1 model 1 simple in model 1 the unsaturated zone is assumed 1d and described by mike she s gravity flow solver where only wilting point and field capacity as given by the soil water retention curves are utilized the effects of capillary forces on the movement of water through the soil column are ignored the saturated zone is described by 3d flows using a vertical discretization of the permeable part of the subsurface around 500 m into seven layers actual evapotranspiration is calculated adopting the approach presented by kristensen and jensen 1975 where reference evapotranspiration and leaf area index lai are used as forcing data and soil moisture as a depending variable in order to avoid a long warm up period and to ensure stable initial conditions a hot start file was generated by performing a simulation covering the years 1990 2006 the hydrological model was then subject to a sensitivity analysis seventeen parameters were included in the sensitivity analysis the initial parameter values were taken from a structurally similar and previously optimized hydrological model sensitivity analysis was performed using pest doherty 2016 to reduce dimensionality we selected only the five most sensitive parameters cf table 2 for subsequent calibration calibration was performed for the years 2007 2010 using pest s sceua p utility which is an implementation of the sce shuffled complex evolution global optimization algorithm duan et al 1992 calibration targets were discharge from a set of gauges and hydraulic head in the layers of the geological model rmse root mean square error and pbias percent bias cf section 3 3 were used as objective functions 3 1 2 model 2 complex in model 2 unsaturated zone dynamics were calculated using the full 1d richards equation as implemented in mike she in contrast to model 1 actual evapotranspiration was simulated using the sw et model an energy balance module requiring hourly climate input data overgaard 2005 due to this modification model 2 is classified as a coupled subsurface surface atmosphere model especially the coupling with the sw et model is causing significantly longer run times of model 2 table 1 representing a rare example of a rigorous inverse calibration not least due to the immense computational demands the model had been calibrated in a previous study stisen et al 2018 using a multi objective calibration approach calibration was carried out using a global optimizer cma es covariance matrix adaptation evolution strategy five different calibration targets table 1 and eleven objective functions this ensured both a balanced calibration and the finding of a pareto optimal solution as defined in e g madsen 2003 3 2 uncertainty estimation k nn resampling k nn resampling as the name suggests resamples historical errors made by the model this technique is based on the assumption that the response of a hydrological system is documented by a sufficiently long record of observations and thus if the system is stationary that the statistical properties of errors can be inferred from a comparison between historical data and model predictions sikorska et al 2015 the foundations of the approach used in this study were recently presented by wani et al 2017 we adopt this approach while suggesting improvements to the workflow which involves the consideration of error autocorrelation upon choosing the variables that control the identification of nearest neighbors by the k nn algorithm the k nn resampling procedure is illustrated by the flow chart given in fig 2 and described systematically in the following for a detailed mathematical description the reader is referred to wani et al 2017 step 1 split data record the data record is split into two periods the first period represents a repository for the sampling of past errors in other words the k nn algorithm learns about the typical response of the hydrological system under different hydrological conditions the second period is a testing period for which the k nn algorithm predicts residual uncertainty based on the error samples collected from the repository the error e is defined as the difference between simulated and observed hydrological system response at any time step step 2 inspect acf pacf in order to establish which variables are suitable to condition the estimation of residual uncertainty on we suggest a hierarchical approach we propose to first focus on the error time series and check whether there is evidence for an autoregressive process ar of order p the order p would then be equivalent to the number of error lags to be included in the input variable vector ivv this can be achieved by plotting and visually examining the autocorrelation function acf and partial autocorrelation function pacf box et al 2008 for an ar of order p the acf will exhibit an exponential decay while the pacf will have significant nonzero correlation coefficients for lags smaller than or equal p and cut off thereafter being essentially zero box et al 2008 it is worth noting that we are not actually suggesting fitting an ar model to the data but merely use acf and pacf as guidance regarding the selection of ivv candidates subsequently dependence between the error time series and other hydrological variables is investigated using correlation analysis pearson s r this can be useful if the analysis of acf and pacf is inconclusive or in order to find supplementary variables for the ivv to also be able to capture nonlinear association between error and other variables which manifests in heteroscedastic residuals we additionally employ the distance correlation metric szekely et al 2007 another possible solution to choose ivv candidates for k nn is to employ the concept of partial information sharma and mehrotra 2014 but this will not be further addressed here to ensure that potential differences in units or amplitude between the error and hydrological variables do not affect the analysis standard scores need to be calculated a priori viable ivv candidates are then selected based on the strength of their interdependence with the error time series only including those with a high statistical dependence here user defined threshold of pearson s r 0 5 and keeping the number of ivv elements to a minimum step 3 compile ivv assemble the input variable vector using error number of lags included equals p and possibly auxiliary hydrological variables such as simulated discharge qsim etc with high explanatory power as identified in the step before the ivv is to be understood as a collection of variables which help to identify similar hydrometeorological conditions as those encountered at the respective prediction time step step 4 sample k errors the k nn algorithm is used to sample k historical errors from the repository to estimate residual uncertainty for the testing period determining an appropriate number of k is not straightforward and will be addressed in the discussion the error sampling works as follows for each day within the testing period the input variable vector points to a specific location in n dimensional ivv space the algorithm then searches the repository and identifies k days with the most similar conditions therefore being closest to that location in n dimensional ivv space nearest neighbors usually the euclidean distance is used to determine proximity to avoid having to standardize variables usage of the mahalanobis distance represents an alternative cf yates et al 2003 step 5 prediction intervals the k historical errors associated with the k nearest neighbors define an error distribution which under the assumption of stationarity and hence considering them as being representative for the testing period provides an estimate of residual uncertainty for each day of the testing period mathematically this can be expressed as 1 c t e i v v i v v t c p e r p r k where ct is the cumulative distribution function cdf of residual error at time step t conditioned on ivv ivvt similarity of input variable vector ivv ct is being approximated empirically by cp the cdf composed of k historical errors that satisfy rp rk where r is the euclidean distance and p stands for past then by calculating the 5th and 95th quantiles q i 0 05 q i 0 95 of the error sample 90 prediction intervals for each day of the testing period can be generated their width being defined by the difference between the percentiles 3 3 metrics 3 3 1 metrics for assessing hydrological model performance nash sutcliffe efficiency nse nash and sutcliffe 1970 2 nse 1 i 1 n q sim i q obs i 2 i 1 n q obs i q obs 2 where q sim i is the simulated discharge q obs i is the observed discharge at time step i and q obs is the mean observed discharge root mean square error rmse 3 r m s e i 1 n y o b s i y sim i n where n is the number of data pairs y o b s i are the observations y sim i the simulations at each time step i mean error me 4 me 1 n i 1 n y o b s i y sim i where n is the number of data pairs y o b s i are the observations y sim i the simulations at each time step i pearson s r 5 ρ y o b s i y sim i cov y o b s i y sim i σ y o b s i σ y sim i where cov is the covariance of y o b s i observations and y sim i simulations while σ is the standard deviation percent bias pbias 6 pbias i 1 n y o b s i y sim i 100 i 1 n y o b s i where n is the number of data pairs y o b s i are the observations y sim i the simulations at each time step i 3 3 2 metrics for assessing uncertainty estimates in order to assess the performance of k nn resampling for uncertainty prediction and analogous to wani et al 2017 three validation metrics were calculated the prediction interval coverage probability picppi the mean prediction interval mpipi see for example shrestha and solomatine 2008 and the alpha index α cf renard et al 2010 prediction interval coverage probability picp90 the picp90 is the percentage of instances c90 for which an observation is contained within the limits of the 90 prediction interval 7 p i c p 90 1 n i 1 n c 90 100 8 c 90 1 i f q i 0 05 q i q i 0 95 0 e l s e mean prediction interval mpi90 the mean prediction interval allows expressing uncertainty as the average width of the 90 prediction interval based on the k nn error distribution the 90 prediction interval is defined by the difference between the 5th and 95th quantile q i 0 05 and q i 0 95 respectively of the k nn error distribution at every time step i 9 m p i 90 1 n i 1 n q i 0 95 q i 0 05 we further test the reliability of quantiles of k nn based error prediction by plotting them against the quantiles of observed error in a reliability diagram additionally the alpha index α provides a numerical measure of reliability as it relates to the area α that is defined by calibration function and identity line 10 α 1 100 j 1 100 q o b s j j 100 11 α 1 2 α where α is the area between calibration function and identity line q obs j are the quantiles of observed errors and j 100 gives the quantiles of predicted errors 3 4 experimental set up k nn resampling was applied to model outputs from deterministic simulations by model 1 and model 2 both covering the historical period january 2011 to august 2016 repository for the k nn resampling was the entire period provided data were available apart from the year 2014 which was selected as the testing period looking at an entire year enabled us to study the performance of k nn across seasons including changes in dynamics etc in addition the year 2014 represents the most recent complete year in the historical period for which all four hydrological variables that were examined had observational data cf table 3 despite excluding 2014 from the k nn resampling the repository was treated as if it were continuous k nn resampling was carried out using the rann package arya et al 2015 implemented in the scientific progamming environment r r development core team 2018 eight individual k nn input variable vectors were established one for each of the four hydrological variables discharge hydraulic head soil moisture and evapotranspiration and each of them for the two hydrological models the input variable vectors for the k nn models were composed based on analysis of acf and pacf additionally correlations and distance correlations were calculated in order to test whether there were non linear dependencies between the error time series and a set of additional hydrological variables which potentially could have an impact on the magnitude of errors generated by the model e g heavy rainfall might be correlated with large errors generated by the model the hydrological variables that were analyzed in this context were observed and simulated discharge soil moisture hydraulic head actual evapotanspiration respectively observed rainfall both at catchment and at single grid cell scale observed soil moisture hydraulic head and actual evapotraspiration in all cases distance correlations not shown here with other hydrological variables were found to be relatively weaker as compared to error autocorrelation potential commensurability issues beven 2012 will be addressed in the discussion therefore we decided to restrict the conditioning to observed error including as many lags as the analysis of acf and pacf suggested an overview of the input variable vector composition derived based on the considerations detailed in section 3 2 is given in table 3 for the period of interest regarding the application of k nn resampling 2011 2016 observational data were retrieved from the hobe database locations of observational sites are shown in fig 1 discharge observations daily mean in m3 s were collected by a gauge located at the outlet of ahlergaarde catchment while the soil moisture observations were made by a decagon ech2o data logger id nw 2 1 depth of 22 5 cm bircher et al 2012 hydraulic head observations stem from a groundwater well id 8014 and actual evapotranspiration from an eddy covariance flux tower ringgaard et al 2011 at the forest site in gludsted fig 1 while the hobe database contains a vast amount of data for a variety of hydrological variables measured at numerous sites within the catchment the measurement sites and data periods used in this study were selected based on the criterion of longest possible gap free observational record as shown in table 3 this selection criterion led to differences in the lengths of the observational records and consequently to differences in the lengths of the respective training period for different hydrological variables when compared to other studies that employ k nn as a post processor e g sikorska et al 2015 it must be stated that the length of the testing period in our study is comparatively short the implications of this will be further addressed in the discussion the number of k i e the number of nearest neighbors to be sampled from the repository was chosen to be 199 as opposed to e g k 99 in wani et al 2017 we did this for two reasons first we wanted to ensure that the error quantiles would coincide with an actual error sample and two we chose k to be larger than 99 because our historical data record was considerably shorter than those used in other studies potentially reducing the number of contained examples of hydrologically similar conditions therefore requiring us to somewhat relax the k nn search requirements 4 results 4 1 hydrological model performance the performance metrics of the hydrological simulation of the testing year 2014 by the two hydrological models before applying k nn are shown in table 4 based on the metrics alone it cannot be concluded that one of the models performs better than the other one in all aspects for discharge the complex model model 2 is seen to perform better regarding dynamics while the simple model model 1 has a smaller bias for soil moisture and evapotranspiration the two models are almost equally good at simulating the dynamic behaviour while model 1 exhibits the smaller biases with regard to groundwater heads model 1 shows a better performance 4 2 hydrographs and residual uncertainty model 1 simple hydrographs simulated by model 1 for discharge as well as equivalents for soil moisture hydraulic head and actual evapotranspiration in the testing year 2014 are presented in fig 3 while the k nn prediction intervals look different depending on the hydrological variable pipc90 is generally close to the expected value of 90 88 2 87 4 93 4 90 7 for q sm h et note that the fact that the prediction intervals depart from the simulation in certain places is due to the property of k nn to allow the residuals to have a non zero mean in places where the prediction interval departs the k nn algorithm learned that in similar situations in the past the errors were not centered around the simulation but systematically above or below the k nn algorithm automatically corrects for systematic over or underprediction by the model and may result in narrow prediction intervals in cases where the actual spread of the sampled errors is small with regard to discharge the resulting prediction interval while being relatively constant overall mpi 4 03 m3 s table 5 is slightly wider during low flow conditions and slightly narrower during high flow conditions this corresponds well with the fact that the largest mismatch between observations and simulation is indeed found during low flow conditions throughout the summer period while the model reproduces observed peak flow relatively well around day 200 the prediction interval departs from the simulation successfully encapsulating most of the observations this is exemplary for a situation where k nn resampling leads to an error distribution that effectively corrects for systematic over or underprediction by the model assocated with similar hydrological conditions in the past compared to discharge the prediction interval for soil moisture is highly unsteady exhibiting an erratic structure and a partly extremly wide prediction interval mpi 0 104 table 5 although picp90 87 9 is near the expected value k nn was clearly unable to obtain informative error samples from the repository this is probably a result of the short training period and may also be linked to the choice of using gravity flow as unsaturated zone solver resulting in a failure of the model to reproduce soil moisture content and dynamics for most parts of the testing year crude overestimation up to day 100 and past day 225 underestimation between day 125 and 225 especially depletion of soil moisture during spring summer is not reproduced as for hydraulic head the prediction interval is very narrow mpi 0 32 m table 5 with a number of local expansions the picp90 93 4 slightly exceeds the expected value the substantial bias between observations and simulation is successfully corrected for by k nn resampling a visual assessement of the prediction interval for actual evapotranspiration is impeded by the large fluctuations of simulation and observations from day to day especially during the summer period generally the prediction interval is relatively wide 2 2 mm d while the picp90 is very good 90 7 4 3 hydrographs and residual uncertainty model 2 complex hydrographs simulated by model 2 for discharge as well as equivalents for soil moisture hydraulic head and actual evapotranspiration in the testing year 2014 are presented in fig 4 the pipc90 is close to but consistently exceeds the expected value of 90 94 0 97 3 96 2 92 6 for q sm h et with regard to discharge the resulting prediction interval is narrower mpi 3 28 m3 s table 5 varies notably more and generally seems to be better fitted than its counterpart obtained for model 1 contrary to what was observed before the prediction interval is narrowest during low flow conditions wider for high flow conditions and has its maximum width in the transitionary period between winter and spring ca day 75 100 coinciding with the largest difference between observations and simulation apart from a short period in summer around day 200 the prediction interval effectively only extends in an upward direction heteroscedasticity is captured as illustrated by the increasing width in mpi for different discharge flow categories cf table 5 when looking at soil moisture the prediction interval is distinctly less erratic and on average narrower mpi 0 048 table 5 than the one obtained using model 1 however the prediction interval shows little differences in width thoughout the testing year in comparison to model 1 the usage of the richards equation as unsaturated zone solver clearly led to an improved although biased simulation of the soil moisture dynamics while k nn resampling results in error prediction intervals that contain more than the expected 90 of all observations picp90 of 97 2 they do correct for the systematic deviation of simulation and observations overestimation by the model with regard to hydraulic head the k nn based prediction interval is yet again very narrow mpi 0 34 m table 5 however it appears to be systematically wider for the first systematically narrower for the second half of the testing year the picp90 96 2 moderately exceeds the expected value as seen for model 1 the bias between observations and simulation is successfully corrected for by k nn resampling when comparing the graphs for model 1 and 2 it appears that the hydraulic head simulation for model 2 shows somewhat larger fluctuations this is very likely connected to the different unsaturated zone solvers as was the case for model 1 the prediction interval for actual evapotranspiration is difficult to assess as the large day to day fluctuations of simulation and observations prevents this it is worth noting that simulated actual evapotranspiration for model 2 is derived using the sw et model the prediction interval is relatively wide 3 05 mm d while the picp90 is rather good 92 6 4 4 reliability diagrams the performance of k nn resampling regarding the reliability of the error quantiles for all flows is evaluated by generating realiability diagrams fig 5 and calculating the alpha index table 5 reliability diagrams are typically used in ensemble forecasting we employ them to assess the performance of the k nn method with regard to residual uncertainty prediction the probability of non exceedence relates to the respective error quantile based on k 199 error samples the observed relative frequency relates to the percentage of cases in n 365 days year 2014 for which the error was above the respective quantile the closer the dots fall with regard to the 1 1 line of the reliability diagram the more reliable the error prediction can be considered with regard to discharge the reliability diagram for model 1 suggests high reliability of the error quantiles as nearly all points fall along the identity line the alpha index of 0 94 supports this conclusion above a probability of non exceedance of ca 0 5 a slight trend towards overprediction probabilities too high deviation of calibration function to the right of the 1 1 line is detectable the corresponding reliability diagram for model 2 shows a slight downward deviation of the calibration function from the 1 1 line for probabilities of non exceedance of ca 0 05 to 0 3 yet again indicating overprediction however the graph returns back to the identity line thereafter overall the reliability of the error quantiles can be considered very high alpha index of 0 93 as for soil moisture the points of the calibration function for the error quantiles of model 1 are close to the identity line up to a non exceedance probability of 0 5 for larger probabilities the graph begins to deviate from the identity line in an upward direction underprediction with the largest deviation found at a probability of non exceedance around 0 7 the graph eventually returns to the desired 45 line around a probability of non exceedance of 1 the alpha index is 0 89 in comparison the reliability diagram for error quantiles of model 2 despicts a calibration function that shows comparatively smaller but constant deviations from the identity line between probabilities of non exceedance of 0 2 and up to nearly 1 before returning to the 1 1 line the alpha index is equal to 0 93 and thus notably better than that of model 1 the reliability diagrams for error quantiles of hydraulic head represent the ones with the strongest deviations from the identity line and therefore lowest reliability for both model 1 and model 2 there is an overprediction up to a probability of non exceedance of about 0 4 above which there is a transition towards underprediction with peaks at a probability of non exceedance of 0 7 and 0 6 respectively the graph eventually returns to the identity line around 1 according to wilks 2006 the reliability diagrams have good resolution but are underconfident the alpha index is equal to 0 86 and 0 84 for model 1 and model 2 respectively suggesting reasonable reliability finally the reliability diagrams for error quantiles of actual evapotranspiration suggest a very reliable error prediction for both model 1 and model 2 as for model 1 a slight underprediction at probability of non exceedance of 0 1 0 2 respectively is followed by an equally minor overprediction probability of non exceedance of 0 5 0 8 while the scatter is still located very closely to the identity line regarding model 2 there is a slight overprediction around a probability of non exceedance of 0 3 while the remaining calibration function largely falls along the identity line alpha indices of 0 93 and 0 95 indicate high reliability in summary the reliability diagrams in fig 4 show that the k nn error quantiles are indeed reliable for all hydrological variables and both models when looking at the alpha indices reliability of the k nn error quantiles appears to be slightly higher for model 2 in the case of soil moisture and actual evapotranspiration while being higher for model 1 in the case of discharge and hydraulic head however the numerical differences are small 4 5 reproduction of error acf fig 5 compares autocorrelation functions for observed and k nn predicted errors in the testing year 2014 given that the respective ivv cf table 3 informed the k nn algorithm well and the historical record held sufficient examples of relevant hydrological conditions the acf of observed errors should be reproduced by the acf of k nn sampled errors a look at the acf for discharge fig 6 first row shows that the autocorrelation function is only roughly repoduced for both models in both cases the k nn based acf exhibits correlation coefficients with a higher magnitude than found in the observed ones however the overall decline in autocorrelation with increasing lag is reflected to some extent for model 2 the increase in correlation at lag 6 to 8 can be found in the k nn based acf when looking at the acfs of soil moisture it seems that the k nn based acf agrees well with the acf of observed errors for model 1 the continuous decline in correlation is well reproduced for model 2 both the decline as well as the increase of correlation around lag 25 are mirrored in the k nn based acf as for hydraulich head k nn resampling appears to have performed better with regard to model 2 the k nn based acf matches the one of observed errors quite well in terms of slope of the decline in correlation and magnitude of correlation coefficients for model 1 this is clearly not the case finally the k nn based acfs for actual evapotranspiration are well reproduced for both models even though they are very different in appearance while the acfs associated with model 1 exhibits correlation coefficients which are significant for all lags model 2 shows considerably lower correlation including insignificant peaks from at e g lag 2 to 5 hence it can be concluded that on average k nn resampling was able to reproduce observed error autocorrelation well this is true for both models albeit the k nn based acfs obtained for model 2 appear to agree a bit better with the observed error autocorrelation than those of model 1 5 discussion 5 1 k nn resampling applied to complex multi variate model in this study we employed a nonparametric method called k nn resampling to perform uncertainty assessment for two deterministic simulations carried out using two configurations of a coupled integrated hydrological model while previous applications in hydrological literature are limited to prediction of streamflow lall and sharma 1996 souza and lall 2003 or e g weather variables rajagopalan and lall 1999 our study presents an application with a multi site multi variable prediction we simultaneously quantify residual uncertainty for multiple model outputs soil moisture hydraulic head and actual evapotranspiration in addition to discharge despite a number of differences between the two employed models see discussion in section 5 3 the results indicate that k nn resampling is capable of producing reliable prediction intervals for this class of hydrological models consideration of error autocorrelation led to smooth prediction intervals pis for discharge highest order p longest memory which is in line with observations made by evin et al 2014 for all four examined hydrological variables k nn based prediction intervals achieved coverage probabilities that were close to but mostly exceeded the expected value of 90 similar results were obtained by sikorska et al 2015 using k nn picp coverage of 97 9 compared to expectation of 95 and montanari and koutsoyiannis 2012 using a meta gaussian approach picp coverage of 90 3 compared to expectation of 95 as demonstrated by fig 6 k nn rather successfully mimicked the autocorrelation of errors observed in the testing period year 2014 systematic biases in the hydrological model simulation such as observed for hydraulic head cf figs 3 and 4 are accurately estimated resulting in narrow prediction intervals encapsulating most of the observations and error quantiles that achieve high reliability this is in line with findings by wani et al 2017 who showed that the reliability was not impeded when imposing an artificial bias on the simulation learning from past errors k nn accounts for systematic deviations resulting in prediction intervals that may depart significantly from the deterministic model prediction this would not be possible if e g using a parametric method which assume zero mean normally distributed residuals we proposed to exploit information contained in the error time series by analyzing acf and pacf to determine the order of the autoregressive process and formalize input variable vector composition for cases where conclusive demonstrably the performance based on error alone was very good 5 2 ability to compensate for errors due to scale commensurability issues when comparing hydrological variables simulated by spatially distributed models at within catchment locations with field observations commensurability issues often occur due to differences in support scale between model grid cells and field sample volumes beven 2012 in our case model grid cells have lengths of 500 m while e g soil moisture samples represent about 0 1 m and groundwater head observations are merely point values as soil properties exhibit large spatial variability and groundwater heads may vary considerably within 500 m systematic biases are typically seen when comparing model results and field observations ehlers et al 2019 it is therefore interesting to assess to which extent k nn is able to compensate for such scale commensurability issues our results are encouraging in this respect as they show that k nn is capable of estimating and handling biases caused by scale mismatch because the biases are reasonably constant in time and k nn learns from past errors 5 3 comparison between the two hydrological models to assess the robustness of our findings and evaluate how k nn resampling performs for different simulations of the same variable we tested k nn resampling on top of two different configurations of the same hydrological model the two model configurations were characterized by differences in structural complexity process description and calibration data both the picp and the alpha index allowed no clear conclusion as to which model k nn performs better on it is however interesting to note that the alpha index is better for model 2 for soil moisture and actual et which were included in the calibration of model 2 but not model 1 while the alpha index is better for model 1 regarding discharge and hydraulic head as the performance in the underlying hydrological models table 4 is less clear on this and as the differences in alpha index between the models are quite small we cannot draw firm general conclusions on the relation between hydrological model performance calibration targets and performance of the k nn for discharge the mpis are considerably smaller for model 2 than for model 1 table 5 implying that model 2 k nn predictions would be more useful in practice although the metrics in table 4 are unclear as to which hydrological model exhibits the best performance a visual inspection of the hydrographs reveals that model 2 has a more realistic simulation of the dynamics for low flows while model 1 has a systematic overprediction of low flows it is noted that it is also for low flows the smallest 10 of river discharges that the mpi shows the largest difference between the two models 3 22 m3 s for model 1 versus 1 80 m3 s for model 2 table 5 for low flows simulated by model 1 k nn results in wide prediction intervals reflecting a large variation of the residuals as can be seen from fig 3 the prediction intervals width results in a good coverage of the observed discharge for soil moisture the mpis are considerably smaller for model 2 than for model 1 table 5 while picp is good for both models the resulting pi of model 1 looks very inconsistent while the one of model 2 gives a notably better impression while the model 2 k nn thus is seen to perform better for soil moisture it cannot be concluded from table 4 which of the two underlying hydrological models is superior a likely reason why k nn results in more consistent pis for model 2 may be that the errors in model 2 show a rather constant bias overprediction and are hence relatively easy for the k nn to reproduce while model 1 errors show both overprediction and underprediction this difference in performance of the underlying hydrological models is likely a result of the superior simulation using the richards equation model 2 instead of gravity flow model 1 for hydraulic head where model 2 performs significantly better than model 1 table 4 there is almost no difference in k nn performance table 5 this implies that k nn is able to compensate a poorer simulation by model 1 to achieve the same performance as k nn model 2 although model 2 had a significantly better point of departure the better performance of the underlying hydrological model 2 is probably a consequence of the more complex descriptions of the unsaturated and the saturated zones table 1 compared to other hydrological variables the alpha index suggests an inferior reliability of the predicted error quantiles 0 86 and 0 84 the only ones below 0 9 possibly the k nn resampling is at a disadvantage for this particular variable due to comparatively short length of the observational data set for hydraulic heads n 1393 and the fact that both observation and simulation time series do not fluctuate much i e errors tend to be very similar basically everywhere for actual et the metrics for the underlying hydrological models table 4 indicate that model 2 is better at simulating dynamics higher correlation 0 77 vs 0 72 while model 1 has the smaller bias the performance of the k nn table 5 shows that the error quantiles are better for model 2 alpha index 0 93 vs 0 95 yet the mpi is significantly wider a visual inspection of the hydrographs reveals that model 2 fig 4 has a much more erratic simulation of actual et than model 1 fig 3 with the result that the errors show significantly less autocorrelation for model 2 than for model 1 fig 5 this combination of a larger day to day fluctuation of simulated actual et values and hence a more erratic structure of the errors causes k nn to produce wide prediction intervals which in turn do encapsulate a large portion of the observations 5 4 limitations of the present k nn test one limitation in the present study is that we kept the value of k in this study at 199 for all four hydrological variables and did not investigate the sensitivity of the results to other choices of k a rule of thumb to obtain a robust number of k sivakumar 2017 is to take the square root of the number of available observations n which would have resulted in a value of k around 45 which is significantly smaller than our value of k 199 given the relatively short length of our observational records ranging from 1393 to 2070 days table 3 as compared to other applications of k nn and the picp coverage exceeding the expected value our k value is possibly too high hence introducing a high number of not so similar error samples into the uncertainty prediction as k is effectively a smoothing parameter sivakumar 2017 the resulting empirical error distributions might be close to the marginal distribution of the error associated with the respective hydrological variable this in turn might result in prediction intervals that have a rather constant width regardless of hydrological conditions yet as visual inspection of our prediction intervals as well as the mpis for different flow categories table 5 shows our prediction intervals are not constant in width ergo the value of k appears not to result in an empirical error distribution that equals the marginal distribution also sikorska et al 2015 found the value of k when varied between 5 and 100 to have little impact on the prediction intervals another weakness of our study is that the testing period for the k nn was limited to one year which is a short period compared to previous studies for example sikorska et al 2015 use 10 years for error sampling and 10 years for testing while wani et al 2017 use 6 years but at a resolution of 12 h for error sampling and testing for their upper severn catchment case study it should be noted however that we use data for a 10 years period 2007 2016 four years are used for calibrating the hydrological models and five out of the six remaining years are used as repository for the k nn learning leaving only one year for the k nn testing our results indicate that both five years of repository data and a one year test period are critically short periods while less than 10 years typically are sufficient to obtain robust calibration and validation tests of a hydrological model stisen et al 2018 k nn resampling as a data driven method which cannot even use data from the calibration period of the hydrological model requires a longer data period while this is typically not a limitation for discharge we have e g a 100 year record for our catchment karlsson et al 2014 10 year data records of spatially distributed observations of groundwater heads soil moisture as well as evaporation flux are quite unique and typically only available from long term research monitoring programs such as hydrological observatories jensen and refsgaard 2018 we believe this is a serious limitation for the use of k nn resampling in connection with complex multivariate models among these limitations that inevitably cause uncertainty on the details of our findings we assess the short data period as the most severe weakness 5 5 practical applicability of k nn resampling for complex multivariate models the application of k nn in this paper demonstrated that the technique works well with a complex coupled integrated hydrological model the method is very flexible and allows near simultaneous ua time efficient 1 min per hydrological variable as opposed to several weeks for mc based ua on a standard desktop computer another characteristic is that the k nn predicts a lumped measure of uncertainty implicitly accounting for e g input and model structural uncertainty unless there is an explicit consideration of the contributing sources see e g sikorska et al 2015 in contrast mc based uncertainty approaches often neglect some of the sources typically the model structure uncertainty refsgaard et al 2006 2007 while knowing the relative contributions of individual sources of uncertainty to the overall uncertainty might be insightful when aiming for an enhanced process understanding or the devleopment of strategies to reduce predictive uncertainties a lumped estimate as produced by k nn resampling may be sufficient to support practical decision making in hydrology k nn resampling has been used for short term streamflow forecasting in combination with simple rainfall runoff models for the models presented in our paper the k nn setup could easily be reconfigured to be able to make short term forecasts of streamflow hydraulic head soil moisture and actual et another possible practical application of k nn resampling in the configuration presented in this paper would be to estimate prediction uncertainty at ungauged locations within a catchment this could e g be done by analyzing groundwater wells in known geological units perform k nn based uncertainty analysis for them and then use the obtained uncertainty as being representative for the respective geological unit the well is located in in doing so simulation grids for e g groundwater head could be assigned spatially varying uncertainties in this way a few monitoring sites may be used to correct model predictions and assess prediction uncertainties for several ungauged sites a basic assumption in this respect is that catchment conditions are stationary over time requiring that anthropogenic alterations such as changes in climate land use and groundwater abstraction are insignificant a well known limitation for the practical use of data driven methods such as k nn resampling is that they are unable to predict outside the observed range this can be overcome using innovations to perturb the observations rajagopalan and lall 1999 using a kernel density estimator sharma et al 1997 or modifying the setup of the k nn algorithm prairie et al 2006 6 conclusions we have tested the ability of k nn resampling to generate reliable residual uncertainty for multi variable output of a complex coupled integrated hydrological model for the 1055 km2 ahlergaarde catchment constituting the danish hydrological observatory with unique monitoring data the tests included four types of variables discharge hydraulic head soil moisture and actual evapotranspiration and two different hydrological model configurations characterized with very different dynamics and error structures our results document that the k nn resampling performs efficiently and reliably for complex multivariate models and that this conclusion is robust for all the four tested types of variables and both the applied models k nn resampling has proven to be very efficient in estimating and compensating for errors occurring due to commensurability scale mismatch between model grid cells and point scale field observations which typically causes local biases in simulation results of spatially distributed models ehlers et al 2019 the use of four variables and two models allows comparison of performances of k nn resampling for a variety of error structures comparisons of k nn resampling applied on top of a simple and a complex hydrological model show that we cannot make firm general conclusions between the performance of the hydrological model and the k nn resampling i e better performance of the underlying hydrological model does not necessarily lead to better performance after applying k nn resampling this is opposite to common knowledge in data assimilation refsgaard 1997 more detailed analyses of the results indicate that k nn resampling is most efficient in producing narrow prediction intervals when the residuals are relatively constant in time while erratic residuals result in relatively wide prediction intervals in our case study we did not perform sensitivity analyses for the k value and we have a short period for testing the k nn resampling while acknowledging that these factors inevitably lead to uncertainty on our specific findings we do not assess these uncertainties to change the above main conclusions although we had ten years of excellent data from our research catchment we consider this a critically short data period because part of the period needs to be used for calibration of the hydrological model and the majority of the remaining period has to be used for training calibration of the k nn resampling setup while it is relatively easy to find longer time series 15 years for discharge this is very difficult for combined data series discharge hydraulic head soil moisture actual evapotranspiration because these data are not part of standard monitoring programs but only collected in research catchments we consider this lack of long data series as the most serious limitation for a widespread use of k nn resampling for complex multivariate hydrological models while k nn resampling is a comparative lightweight amongst ua methods in terms of mathematical sophistication its strengths are its robustness in the face of model bias and the ease with which in can be implemented and set up to carry out ua for multiple model outputs the latter property renders it a potent tool for applied hydrology and situations where uncertainty assessment is to be performed for multiple hydrological model outputs individually thus providing decision makers with valuable information about uncertainty of secondary model outputs shifting focus away from discharge only oriented ua will help fully exploiting the enormous potential of complex hydrological models acknowledgments this study has been carried out as part of the hobe project hydrological observatory www hobecenter dk which is funded by the v illum foundation all data used in this study is stored in the project database www hobedata dk to obtain access contact frederik uldall fu ign ku dk declarations of interest none 
