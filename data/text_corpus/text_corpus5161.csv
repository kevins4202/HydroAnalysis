index,text
25805,human made reservoirs are now recognized as potentially significant sources of greenhouse gases comparable to other anthropogenic sources yet efforts to estimate these reservoir emissions have been hampered by the complexity of the underlying processes and a lack of coherent budgeting approaches here we present a unique modelling framework the g res tool which was explicitly designed to estimate the net c footprint of reservoirs across the globe the framework involves the development of statistically robust empirical models describing the four major emission pathways for carbon based greenhouse gases ghg from reservoirs diffusive co2 and ch4 emissions bubbling ch4 emissions from the reservoir surface and ch4 emissions due to degassing downstream the reservoir based on an extensive meta analysis of published data from the past three decades these empirical models allow the prediction of reservoir specific emissions how they may shift over time and account for naturally occurring ghg generating pathways in aquatic networks graphical abstract image 1 keywords carbon dioxide methane reservoir g res model greenhouse gas emission 1 introduction the creation of reservoirs by damming of rivers is one of the oldest and most profound landscape transformations exerted by humans the inundation of a largely terrestrial ecosystem can radically change the carbon dynamics of the affected domain indeed terrestrial systems are generally viewed as carbon sinks while freshwater ecosystems are most often sources of greenhouse gases ghg relative to the atmosphere borges et al 2014 cole et al 2007 raymond et al 2013 tranvik et al 2009 drake et al 2018 with negative net ecosystem production e g ferland et al 2014 this is the case because such systems often receive large amounts of organic carbon from the terrestrial ecosystems they drain and because the inland water network is a site for intense c processing unsurprisingly freshwater reservoirs also emit ghgs in many cases at higher areal rates than their natural counterparts lakes and large rivers because the flooded land under freshwater reservoirs provides a new source of organic matter available for decomposition and because it creates new environments conducive to the production of methane a more potent ghg than co2 recent studies have concluded that the magnitude of ghg emissions from reservoirs can be of global significance to date most global assessments have simply used averages of measured values per climatic or geographic region that are then extrapolated worldwide although reasonable as a first order estimate the validity of this approach rests on a number of implicit assumptions for example it assumes that the sampled systems are statistically representative of the global population of reservoirs the accuracy of this method is also highly dependent upon the sampling strategy used to obtain reservoir wide annual estimates a potential shortcoming given the known large and highly skewed spatial and temporal variability of such estimates both within and among reservoirs deemer et al 2016 deemer and holgerson 2021 delsontro et al 2018a b grinham et al 2011 prairie et al 2018 prairie et al 2017 rosentreter et al 2021 similarly such an approach largely ignores the known temporal decrease in emission rates after flooding abril et al 2005 barros et al 2011 teodoru et al 2012 lastly not all emissions occurring at the surface of reservoirs specifically co2 emissions should be considered new and attributable to impoundments since organic carbon loading from upstream catchments would sustain aquatic co2 emissions even in the absence of a reservoir e g via co2 emissions from lakes rivers estuaries or the coastal ocean tools to quantify the current and future carbon footprint of reservoirs have not yet been developed in part due to the complexity of the processes involved in generating reservoir ghg emissions the multiple pathways through which ghgs are emitted from reservoirs diffusion ebullition and degassing and the difficulty of accounting for pre flooding ghg balances hindering the development of such tools is the fact that there have been only a handful of case studies that have quantified the complete c footprint of individual reservoirs teodoru et al 2012 abril et al 2005 and these cannot be easily extrapolated to other sites in spite of this there have been a number of regional or global studies that have modelled specific aspects of reservoir c dynamics such as co2 or ch4 diffusive emissions barros et al 2011 deemer et al 2016 but there is presently no platform that integrates the various aspects that make up the overall reservoir c footprint in a coherent and predictive context to this end we have developed an online modelling platform hereafter the g res tool that takes into account the specific environmental conditions of a reservoir to predict its associated emissions of both carbon dioxide co2 and methane ch4 partition fluxes among the main emission pathways and characterize the evolution of ghg fluxes over the expected lifetime of a given reservoir here assumed to be 100 years in addition the g res tool estimates the ghg balance of the affected landscape prior to flooding thereby allowing the estimation of the net ghg impact of reservoir creation by difference the g res tool closely follows the conceptual approach outlined in prairie et al 2018 which ultimately aims at predicting the reservoir induced change in ghg fluxes to the atmosphere of the flooded landscape the g res tool is applicable globally harrison et al 2021 and can be used with an earth engine functionality prairie et al 2017 so that it can be used dynamically on existing reservoirs as well as on potential or planned reservoir locations the core of the g res tool relies on a series of empirical models developed from a synthesis of published literature on reservoir emissions these models are based on the influence of local to regional environmental controls on ghg emission and on the characteristics of the individual reservoirs and their catchments in this paper we report on the development of the underlying models predicting the magnitude of each emission pathway their linkages with global databases as well as their integration into a comprehensive and publicly available platform in addition to further validate ability to predict the temporal evolution of emissions in individual reservoirs we compare model predictions with measured ghg fluxes in two of the most studied reservoirs located in very contrasting climates boreal and tropical that were sampled extensively over a 12 year and 20 year period respectively 2 methods 2 1 1 modelling approach the g res tool is designed to assess in a comprehensive manner the net ghg footprint of a reservoir over its lifetime assumed to be 100 years gagnon et al 2002 iaea advisoring group 1996 1995 including the footprint associated with its construction however the present paper reports only on the biogenic components of the ghg balance of the reservoir area i e without the construction both prior to and after impoundment the g res tool can therefore provide an estimate of the net ghg impact of reservoir creation similarly the g res tool provides calculations to estimate the portion of ghg emissions that are likely the result of nutrient enrichment so called unrelated anthropogenic sources uas ipcc srren kumar et al 2011 due to phosphorus inputs associated with human activities in the reservoir catchment based on the expected difference in phosphorus load in the absence of human induced catchment perturbations details of the approach can be found in the g res tool technical document prairie et al 2017 the method is useful primarily in allocating reservoir ghg emissions to particular services or practices however emissions potentially attributable to uas are not excluded from the present calculations of the ghg footprint of reservoirs and are therefore not addressed further in this paper see prairie et al 2017 for further details 2 2 database to develop the ghg emissions models we undertook an extensive review of the pre 2016 scientific literature and collected data from 223 globally distributed reservoirs with co2 and ch4 emissions measurements 279 field assessments of diffusive co2 emissions 205 of diffusive ch4 emissions 59 of bubbling ch4 emissions and 52 of degassing ch4 emissions see supplementary material figure s1 and reference list and prairie et al 2017 and available at https zenodo org record 4711132 yoiwxy295om this database is largely overlapping with the one developed by deemer et al 2016 because the assembled dataset of ghg emissions depended entirely on the availability of published data we compared the size and climate distributions of the sampled reservoirs with that of a more exhaustive and larger set of reservoirs worldwide grand database lehner et al 2011 in general our database essentially covered the full range of reservoir surface areas our dataset also covered all climate zones although boreal and to a lower extent sub tropical and tropical reservoirs were somewhat over represented relative to the grand see supplementary material table s2 in addition to ghg flux data we also collated information on climatic geographic edaphic and hydrologic conditions of each reservoir and its catchment these variables were obtained from a variety of open sources including the literature worldwide gis layers see table 1 and information contained in the grand database lehner et al 2011 the complete list of potential predictor variables from both reservoirs and catchments used in the models is listed in table 1 geographical information systems gis were used to acquire two sets of data pertaining either to the reservoir themselves or their catchments we used the gis polygons provided in the grand database 156 reservoirs when available and added 67 reservoirs that were delineated using contemporary satellite imagery zonal statistics tools applied to global raster layers were then used to estimate the variables of interests for each reservoir e g soil carbon content surface temperature and wind speed similarly the catchment dataset was built largely around the hydrobasins gis product lehner and grill 2013 to which was added several catchments that were delineated using the digital elevation model dem of the shuttle radar topography mission srtm and hydrological spatial analysis tools 2 3 standardization of data 2 3 1 annualization since the ghg emissions data of the 223 reservoirs gleaned from the literature were sampled at different temporal scales single time points seasonal averages annual averages we standardized all the diffusive fluxes of co2 and ch4 and the ch4 bubbling flux extracted from the literature using a procedure that combined the annual temperature cycle at the reservoir location with the known temperature dependence associated with co2 and ch4 production inglett et al 2012 liikanen et al 2002 yvon durocher et al 2014 also see prairie et al 2017 for colder climates where reservoirs develop an ice cover winter ghg accumulation under ice is accounted for by assuming that gas production occurs continuously at 4 degrees c although it is likely that ghgs produced during ice cover are released during a short period spring overturn in brief the procedure consisted of assigning a temperature to the observed ghg flux measurements and estimating the flux from the unsampled period by modulating the measured flux up or downwards using the temperature sensitivity metric appropriate for co2 q10 2 inglett et al 2012 and ch4 q10 4 yvon durocher et al 2014 this method was applied for each unsampled month and all months were summed this annualization procedure led to a modest adjustment downward for diffusive ch4 emission from an average 39 4 152 5 measured flux to an average 33 5 114 6 mg c m 2 d 1 annualized flux because many measurements in regions with strong annual cycles were done exclusively in the summer months however the significantly reduced variability suggests that part of the initial noise in the collated data set was the result of sampling regime differences reservoirs with multiple years of measurements were used to evaluate the potential impact of reservoir aging on ghg emissions barros et al 2011 if several independent measurements occurred at the same age an average of all the measurements was calculated 2 3 2 system wide estimate of ch4 ebullition in most cases ch4 ebullition rates were reported either directly as system wide estimates or as littoral specific rates with the corresponding surface area however some studies reported littoral ch4 ebullition rates without defining the surface the littoral zone encompassed since bubbling intensity is known to decrease with depth bastviken et al 2008 delsontro et al 2010 delsontro et al 2011 mcginnis et al 2006 applying the littoral emission rates to the whole reservoir surface area would overestimate whole reservoir fluxes to avoid this potential bias for all studies reporting only littoral flux measurements ch4 ebullition flux rates were applied only to an area we defined as 3 m depth see appendix a from details and then expressed as rates per unit surface area of the entire reservoir we acknowledge that ch4 bubbling can occur in some specific cases at greater depths mcginnis et al 2006 and that this assumption may therefore result in an underestimate of reservoir wide emissions nevertheless given the physical inverse dependence of bubbling on depth bazhin 2003 we view this as an improvement over simply assuming littoral emissions rates occur over an entire reservoir s surface area at equal rates deemer et al 2016 2 3 3 prioritization of data sources for any given reservoir several estimates of the same variables can be extracted from various sources when such cases occurred data gleaned directly from the scientific literature were prioritized for inclusion in the database followed by the data from the grand database lehner et al 2011 if values were unavailable from the peer reviewed literature we extracted the relevant values from global gis layers see table 1 or estimated them from general models found in the literature see prairie et al 2017 for details 2 4 statistical analysis and model development using the annualized ghg emission estimates described in section 2 2 1 we developed a series of multivariate statistical models to predict each flux pathway using both reservoir and catchment predictor variables variable selection was carried out using the elastic net regression procedure see prairie et al 2017 for more details implemented in jmp pro 14 or 15 elastic net regression is a penalty based variable selection method particularly well suited to modelling cases with a large number of potential predictor variables even in cases with low sample size n zou and hastie 2005 the elastic net procedure reduces the variance inflation problem associated with highly collinear variables by imposing a penalty on large coefficients depending on the penalty parameter the algorithm can reduce regression coefficients to zero i e no effect thereby providing an objective variable selection procedure variable transformations mostly logarithmic were necessary to fulfill assumptions of the regression approach e g normality of residuals or desirability of the predictor variable distribution across their ranges for each emission pathway outliers were identified using cook s distance cook 1977 which combines the studentized residual and the observation s departure from the mean using 3 times the mean μd as a threshold and removed from the analysis 2 4 pre impoundment ghg footprint large landscapes are generally a mosaic of ecosystems forests wetlands cropland settlements lakes streams rivers etc that all process carbon in different ways each of these ecosystems can emit or sequester carbon at different rates contributing to the total carbon footprint of a defined area for example growing forests absorb co2 while wetlands tend to emit methane while sequestering co2 soil type will also influence carbon processing as organic soil will emit more ghg than mineral soil natural waterbodies on the other hand generally emit co2 and to a lesser extent methane the pre impoundment ghg balance of a reservoir area is therefore the weighted sum of the ghg balance of each landscape component because of the multiplicity of ecosystem types we associated each landscape component within the impounded area with default co2 and ch4 emission factors ef from the ipcc ipcc 2013 specifically for the forest with mineral soils we have used the default value from pan et al 2011 and for the methane emissions from water bodies we used the equation developed in rasilo et al 2014 combined with appropriate gas exchange coefficients prairie et al 2017 vachon and prairie 2013 to follow the ipcc classification of ef the top 30 cm of soil was assigned as mineral or organic soils using a threshold of 40 kg c m 2 and the land impounded was associated to one of four climate zones tropical subtropical temperate and boreal table 1 the general equation to estimate the pre impoundment ghg balance was then 2 pre impoundment ghg fooprint j 1 2 i 1 8 e f l c i a r e a l c i a r e a r e s e r v o i r where ef lc ij emission factor specific to each land cover category and each gas prairie et al 2017 area lc i inundated area of each land cover category km2 i land cover category 8 categories see table 1 j pre impoundment co2 or ch4 emissions area reservoir total reservoir area km2 including both existing river lake area and inundated area 3 results and discussion 3 1 empirical modelling for both ch4 and co2 diffusive emissions the age of the reservoirs was selected as one of the strongest predictors as also found in barros et al 2011 and the regression equations therefore express emissions at a specific reservoir age to evaluate the net footprint over the total lifetime of a reservoir the non linear regression equation was integrated using basic calculus to yield the 100 yr average annual emission rate equations 4 and 8 table 2 methane emissions from reservoirs are more complex than co2 because three different pathways degassing bubbling and diffusion can each deliver substantial amounts of ch4 to the atmosphere and because each pathway is controlled by different drivers and must thus be modelled separately the statistics of the four empirical models developed are detailed in table 2 3 1 1 ch4 diffusive emissions to predict diffusive ch4 emissions the elastic net procedure retained reservoir age mean annual temperature and percent littoral area table 2 eq 3 as the only useful predictors p 0 0001 the age of the reservoir had the strongest influence particularly at high temperatures fig 1 a similarly the decrease in ghg emission with age was strongest in reservoirs with extensive littoral zones fig 1b all three predictor variables confirmed trends previously reported in the literature for reservoirs and lakes barros et al 2011 delsontro et al 2016 liikanen et al 2002 yvon durocher et al 2014 3 1 2 ch4 bubbling emissions ch4 is only sparingly soluble and can reach very high partial pressures when produced in sediments leading to bubble formation when ch4 partial pressure exceeds the sum of barometric and hydrostatic pressures as bubbles grow larger or after a sudden change in pressure bubbles can be released from the sediment into the water column largely bypassing exchange within the water column mcginnis et al 2006 and emitted directly to the atmosphere because of its dependence on hydrostatic pressure the release of ch4 bubbles is inversely proportional to water depth and in many aquatic systems confined to shallow zones in combination with areas of high sediment deposition a logarithmic equation using the cumulative global horizontal radiance following the work of wik et al 2014 and percent littoral area as predictor variables was found to best represent ch4 bubbling reservoir wide values for ch4 ebullition the age of reservoir was not selected as a useful predictor by the elastic net regression procedure which explains the absence of integrated model equation for this pathway table 2 eq 5 given the limited number of bubble flux measurements n 46 and the wide confidence limits of the model the emissions estimates associated with this pathway carry more uncertainty than the diffusive pathways see table 2 in this particular model 4 observations were deemed outliers using the u 3 cook s distance criterion three of these systems were removed from the analysis but we retained one eastmain 1 reservoir because it represented one of the few points where the cumulative irradiance was low thereby extending the model prediction range its inclusion did not affect the rmse of the model but conferred more stability to the associated regression coefficient 3 1 3 ch4 degassing emissions downstream of reservoirs reservoir outflows can originate from various depths through various conduits through turbines spillways bottom gates and bypass channels with important implications for ch4 degassing fluxes deeper intakes are often preferred for hydropower stations for added operational flexibility for thermally stratified systems or periods drawing water from the hypolimnion can lead to high emission of methane downstream of a dam because high concentrations of ch4 often accumulate in anoxic or sub oxic hypolimnia the sudden pressure drop after exiting a turbine can release a large fraction of the dissolved gas directly to the atmosphere the so called degassing process ch4 rich water drawn from a reservoir may also be released to the atmosphere in turbulent waters downstream the reservoir note that degassing emissions does not include these ghg emissions further downstream this component is particularly difficult to predict given that methane oxidation can vary widely between ecosystems soued and prairie 2020 thottathil et al 2018 2019 thus a first requirement in assessing degassing emissions is to compare water intake and thermocline depths to determine whether water flowing downstream from dams is from the hypolimnion if it is it is likely to be ch4 rich leading to high degassing emissions conversely if the water flows downstream from the epilimnion it is likely to be comparatively ch4 poor leading to low degassing emissions to account for this the g res tool estimates degassing emissions only when the water intake is located below the thermocline to develop the g res ch4 degassing model we calculated measured degassing flux as the difference in published ch4 concentrations upstream and downstream of dams multiplied by mean annual flow through the turbines we then tested for significant predictors of the difference between upstream reservoir and downstream ch4 concentrations the magnitude of these concentration differences was best predicted table 2 eq 6 as a function of water residence time wrt and post impoundment annual ch4 diffusive emission itself estimated by the model described in section 3 1 1 as a proxy of ch4 production this provides an efficient method for predicting degassing emissions average discharge through the turbines was estimated as 90 of the annual runoff as default value although this value can vary substantially depending on the reservoir operations and maintenance 3 1 4 co2 diffusive emissions the best model for diffusive co2 flux also determined using an elastic net regression procedure includes reservoir age mean annual temperature modelled phosphorus concentration prairie et al 2017 reservoir area and pre inundation reservoir surface soil carbon content as shown in table 2 eq 7 because of the logarithmic nature of the relationship negative co2 fluxes i e reservoir acting as an atmospheric sink are currently not included in the modelling persistent co2 influx is generally observed only under eutrophic conditions and or when there are very low organic allochthonous carbon inputs soued and prairie 2021 as a result g res can be construed as providing an upper limit to the co2 footprint of eutrophic systems compared to diffusive ch4 the decline of co2 emissions over time is much steeper at first and stabilizes more quickly to a new equilibrium fig 2 this temporal decrease has been reported in several cases abril et al 2005 demarty and tremblay 2017 galy lacaux et al 1997 teodoru et al 2012 predicted co2 diffusive emissions from both individual reservoirs and reservoirs collectively are highly influenced by temperature fig 2a and somewhat less sensitive to the amount of organic carbon contained in the flooded soil fig 2b harrison et al 2021 suggesting that diffusive co2 emissions from reservoirs could increase with increasing water temperatures anticipated to accompany ongoing climate change these models describe well both the main drivers and the temporal trajectory of co2 emissions and can therefore be used to estimate the expected emissions at any particular time post flooding unlike ch4 emissions see prairie et al 2017 not all surface co2 emissions should be attributed to reservoir creation because as with all inland aquatic systems reservoir co2 emissions are also sustained by the mineralization biological and photochemical of allochthonous organic carbon largely dissolved originating from the upstream catchment in the absence of a reservoir allochthonous doc would still have been mineralized to co2 albeit mostly further downstream furthermore the longer water residence time of reservoirs relative to the river it replaced allows for more doc mineralization to occur at the reservoir site algesten et al 2005 dillon and molot 1997 vachon et al 2017 exacerbating the magnitude of displaced emissions sensu prairie et al 2017 the g res tool allows for an estimation of this portion of the co2 diffusive flux that can be legitimately attributed to the creation of a reservoir to calculate this fraction the g res tool assumes that the predicted co2 emission rate at year 100 post flooding corresponds to naturally sustained emissions which are subtracted from the temporal trajectory to provide an estimate of the co2 attributable to mineralization of the flooded terrestrial biomass and soil c see prairie et al 2017 for details under this assumption the rate of decline through time i e the age variable coefficient in the regression model 0 330 can be used to calculate that over the 100 year lifetime of reservoirs an average of about 31 6 of the co2 emissions can be attributed to the impoundment with the remaining being sustained by continuous allochthonous organic carbon the g res platform also accounts for the co2 emissions from natural aquatic ecosystems located within the impoundment area prior to flooding for example when a lake is only slightly expanded by impoundment or when several lakes were submerged g res calculates reservoir co2 emission by applying the predicted areal rates eqs 7 or 8 only to the newly flooded area rates using 9 newly impounded land ratio 1 w a t e r b o d y b e f o r e i m p o u n d m e n t 100 3 2 net ghg footprint the sum of the 4 different components of emission gives the total post impoundment emissions from which the pre impoundment emissions can be subtracted or added to obtain an estimate of the net ghg footprint illustrated in the graphical abstract 3 3 validation 3 3 1 g res modelling approach versus averages of measured values the range of ghg emission rates found in the literature regardless of emission pathway or ecosystem type consistently shows a highly skewed distribution with a few very high values leading to mean values that are much higher than other measures of central tendency by using log transformed models predictions from the g res correspond to the geometric mean of the distribution of annualized area adjusted ghg flux measurements however because g res relies on the main drivers of emissions from a set of local environmental factors through statistical relationships it is less prone to overestimation than the often used approach of simply applying the average value derived from a highly skewed set of measured fluxes to estimate the flux of unsampled reservoirs to validate this claim we used reservoirs for which ch4 diffusive emissions had been measured to compare the predictive ability of our g res model estimation of reservoir wide ch4 diffusive emissions with those calculated by simply applying the average of all measured areal emission rates 38 5 mg c m 2 d 1 from measurements used in this comparison to the same systems as expected g res predictions did not deviate significantly from the 1 1 line fig 3 a while simply applying the observed mean to all reservoirs overestimated reservoir emissions in 84 1 of the cases and by an average of nearly an order of magnitude over the entire range of prediction fig 3b the corresponding nash sutcliffe efficiency statistics were 0 67 and 0 25 respectively this underlines the importance of model based predictions when dealing with highly skewed data the same pattern was observed albeit to a varying degree when the individual pathways were examined separately see supplementary material figure s2 and table s1 3 4 emissions through time the case study of two contrasting reservoirs the general decline in ghg as a function of age of the reservoir observed in our models eq 3 and 7 and reported elsewhere barros et al 2011 is cross sectional in nature i e through the observations of different reservoirs of varying ages to explore the longitudinal applicability of the models to individual reservoirs over time we tested it to two well studied but contrasting reservoirs from a boreal eastmain 1 and a tropical climate petit saut eastmain 1 a 603 km2 reservoir in the boreal region of quebec 53 n was flooded over the november 2005 to february 2006 period the reservoir emissions were monitored and published in the scientific literature for seven 7 years after impoundment year 2006 2009 bastien and demarty 2013 demarty et al 2009 demarty and tremblay 2017 teodoru et al 2012 tremblay et al 2008 tremblay et al 2009 and further measured recently in 2018 unpublished data p del giorgio prior to flooding the impounded area was dominated by forest 74 with a small coverage of grassland shrubland 10 5 water bodies 11 5 and wetlands 3 and the impounded soils have organic carbon rich content 22 3 kg c m 2 on average this remote area has very limited human occupation or activities and the reservoir is considered oligotrophic total phosphorus concentration estimated by the g res is 7 1 μg l 1 and measured as 9 3 μg l 1 in 2018 unpublished data p del giorgio in contrast petit saut is a tropical reservoir 4 n located in french guiana where 305 5 km2 of forest 37 wetlands 25 7 and water bodies 32 9 were flooded in 1994 the reservoir emissions were measured and published in the scientific literature for the first ten 10 years after impoundment year 1994 2004 abril et al 2005 but were also continuously monitored in 2004 2014 unpublished data v chanudet the impounded soil carbon content is 10 4 kgc m 2 on average and the reservoir is considered oligotrophic to compare eastmain 1 observations with g res tool predictions eight years of measurements for the ice free period were annualized to account for the seasonal temperature cycle and corresponding ghg production see section 2 2 1 prairie et al 2017b for petit saut no such annualization was necessary given that measurements monthly were available from all seasons for the purpose of this comparison we did not distinguish between natural and anthropogenic co2 emissions section 3 2 4 prairie et al 2017a b also because of the lack of time series data on multiple ghg emission pathways the comparison was only possible for co2 and ch4 diffusive emissions for co2 fig 4 a and b shows that both the magnitude and the decline in the rate of post impoundment co2 emissions are for the two contrasting reservoirs reasonably well predicted by g res as predicted the initial emission rates were much higher in petit saut than in eastmain 1 eastmain 1a but exhibited a similar rate of relative decline nevertheless the model underpredicted emissions in the initial years at eastmain 1 but g res estimations and observations converged after a few years post impoundment fig 4a for petit saut the g res model predicted the initial rates quite well but tended to overestimate later on while the details of the temporal projections are important the long term cumulative footprint is particularly relevant given the overall purpose of the g res platform fig 4c d illustrate how the estimated and observed cumulative co2 footprints track one another for eastmain 1 the g res cumulative footprint was on average 17 lower that the cumulative observed co2 over the course of the observation period 12 years for petit saut the cumulative co2 emission curve was nearly perfectly matched by g res estimation fig 4d for ch4 the g res model correctly predicted the one order of magnitude difference between diffusive ch4 emission rates of the two reservoirs fig 5 however the temporal trends in measured emissions did not follow the g res predicted rate of decline for the tropical reservoir petit saut the observed decline was faster than predicted while the eastmain 1 reservoir exhibited the reverse pattern g res predicted diffusive ch4 flux to decline faster than it actually did this suggests that in its current form table 2 eq 3 the g res ch4 diffusive model apparently captures an average rate of decline but that the cross sectional data was unable to detect the slower decline in very cold environments and the steeper decline in tropical climates this putative interaction between climate and the rate of temporal decline following impoundment can only be resolved by the incorporation of multiple long time series of ch4 from other reservoirs 3 5 uncertainty estimation the g res tool ultimately aims at predicting the ghg footprint of reservoirs over their assumed lifetime 100 years and therefore implies the integration over time of each of four statistical models summarized in table 2 this operation is akin to estimating the long term mean emission rate as a result we developed an uncertainty estimate to reflect the error variability of the estimated mean ghg footprint using monte carlo simulations in brief the predicted fluxes log scale from each emission pathway were contaminated randomly with normally distributed noise corresponding to the standard error of the residuals of each model and then summed after log de transformation we repeated the procedure to obtain 1000 estimates of the reservoir ghg emissions footprint from which we extracted the non parametric 95 confidence limits while these varied between reservoirs the average lower and upper values corresponded to 87 and 120 of the mean note that if the g res equations are instead used to estimate a reservoir s ghg footprint at a given age uncertainty limits will be wider than for its lifetime integrated footprint and would require accounting for de transformation bias 3 6 g res tool user interface to make the predictive models described above widely available we developed a web interface hereafter called the g res tool this online tool www hydropower org gres tool allows users to use reservoir specific input data to calculate net ghg footprint estimates the g res tool also provides auxiliary modules to estimate emissions for the construction phase as well as to allocate ghg footprint to the different services associated with a particular reservoir hydroelectricity water supply flood control irrigation fisheries recreation navigation and environmental flow the methods used in these modules are described in more detail in a technical document prairie et al 2017 in this paper we focus only on the pre and post flooding ghg balance of the reservoir area from the main introductory g res tool web page nine other interacting tabs can be selected and used for several purposes including 1 entering input variables about the reservoir and its catchment 2 entering information about the usage of the reservoir to allocate services 3 entering information about the construction phase of the reservoir to estimate construction related ghg footprint 4 viewing calculated reservoir post impoundment ghg emissions including the relative contribution of each emissions pathway and each ghg the magnitude of unrelated anthropogenic sources and an estimate of total ghg flux including an evaluation of the pre and post impoundment footprint and 5 implementing a pre programmed earth engine functionality to assist in obtaining all relevant and required input information from globally available and consistent sources prairie et al 2017 this latter functionality can be used to obtain all required data by providing basic information dam location dam height for existing reservoirs but can also be used to explore the ghg footprint of future or planned sites since the g res tool is cloud based the user can save input parameters locally and re import them back in a subsequent use of g res various report and export functions are available fig 6 displays the main user interface outlook and the total ghg footprint results page the g res tool has been available for use since 2017 from version 1 onwards and is now recommended by multiple stakeholders and international organizations with now more than 900 registered users and an average of 150 visits per month while the g res has been mostly used to estimate the carbon footprint of individual reservoirs it has recently been used to estimate the biogenic ghg component in a life cycle assessment of hydroelectricity generation for the whole province of quebec levasseur et al 2021 a further strategic importance of g res lies in its ability to estimate ghg emissions for future projects allowing better decision making to build new reservoirs that have low carbon footprint for example estimates of high degassing emissions can lead to dam design changes i e water intake depth to reduce the importance of this pathway similarly estimating the total ghg footprint is particularly important for banking institutions in their decision to finance future reservoir projects 4 discussion 4 1 comparison to previous models it is important to emphasize that there is currently no other modelling platform that can be used to compute in a comprehensive and globally applicable framework all four ghg emission pathways the g res integration of several components and flux estimates due to individual ghg emissions pathways moves beyond past efforts to quantify ghg emission from reservoirs barros et al 2011 bastviken et al 2011 deemer et al 2016 hertwich 2013 st louis et al 2000 similarly the ability to distinguish between natural and anthropogenic co2 emissions is unique to g res as well as the estimation of the net ghg footprint through the estimation and accounting of the landscape ghg balance prior to flooding thus the comparison between g res and previously published models revolves around the driver variables identified the extensiveness of the database used and consequently the robustness of the individual empirical models barros et al 2011 highlighted the influence of age and temperature using latitude on reservoir ghg emissions using 85 reservoirs similarly the more recently published study from deemer et al 2016 has improved the estimation of ghg emissions from reservoirs by using a much bigger database 267 reservoir years largely overlapping with ours as well as showing that reservoir productivity plays an important role in ghg emissions along with age temperature and hydrology the g res model developed here builds on these studies and has confirmed many of these drivers previously identified while integrating several new ones to develop a globally consistent modelling platform for each component of reservoir ghg emission based on a much larger number of potential predictor variables 40 see table 2 for the variables retained the incorporation of the more recently available ghg measurements into empirical models has improved predictive power and in particular the robustness of the estimated model coefficients for models where the age of the reservoir was deemed a significant predictor diffusive co2 and ch4 emissions the larger dataset helped better define the temporal evolution of emissions and therefore the integrated lifetime 100 years ghg footprint also a unique feature of g res while their predictive abilities are far from perfect regression based models are also less prone to introduce biases than a simple application of average per area rates particularly in the case of ghg pathways mostly for ch4 known to have a highly skewed distribution for example regional or global estimates of ghg emissions from reservoirs derived from simply applying an average value inherently assumes that the sampled systems are representative of the population distribution validation of the g res models provided in this study fig 4 illustrates that the regression based approach can considerably reduce biases another important feature unique to the g res modelling platform is that it can provide estimates of so called displaced emissions of co2 i e emissions that take place at the reservoir surface that are sustained by upstream loading of organic carbon mineralized within the reservoir but that would have occurred regardless of the presence of the reservoir albeit elsewhere downstream in the hydrological network section 3 1 4 sensu prairie et al 2018 4 2 partitioning among emission pathways the heterogeneity of the modelling database precluded the direct comparison of the relative importance of the various ghg components because very few reservoirs had concurrent measurements of all emission pathways however the modelled emission rates to the same dataset shows that excluding the ch4 degassing component the overall ghg footprint is dominated by the co2 diffusion pathway in about 73 of the cases while ch4 diffusion and bubbling is the main pathway in 10 and 16 of the reservoirs respectively see supplementary material figure s3 in this analysis ch4 degassing was omitted because its contribution to the overall ghg footprint was relatively small mean 14 median 4 and it would assume that all reservoirs have the required configuration for significant degassing to occur i e hydropower reservoirs with deep water intake note that these numbers apply specifically to the dataset assembled here and can differ in a more global context harrison et al 2021 4 3 limitations of the models while the g res model predictions carry large numerical uncertainty the g res tool is to our knowledge the most complete and the only globally consistent framework to predict the ghg footprint of reservoirs however proper usage of g res also requires an understanding of its current limitations for example because the models are regression based one of the inherent limits of application is the observation range in the predictor variables of the assembled model dataset while the observational ranges in our dataset captures most the variability of the global database provided in the grand database lehner et al 2011 table s2 we recommend applying g res only to reservoirs that fall within the limits of the current data furthermore the g res development has helped identify a number of knowledge gaps that deserve additional attention and research these include 1 the impact on ghg fluxes of reservoir location operation and water transfers between reservoirs and power plants within watersheds 2 the potential for reservoirs to act as ghg sinks 3 newly identified flux pathways 4 potential carbon burial in sediments and 5 the impact of eutrophication on reservoir ghg emissions the first important element not considered in the g res framework is the prediction for cascade systems where outflow from one reservoir or a series of reservoirs flows into one or more reservoirs further downstream at present reservoirs are considered independent and g res therefore assumes that carbon processing in one reservoir does not affect that of downstream reservoirs there is very little empirical information in the scientific literature on whether this assumption is reasonable however given that part of the allochthonous organic carbon input to the first reservoir of a cascade will be mineralized and lost from the hydrological system one would hypothesize that at least the co2 emission in a downstream reservoir is likely to be lower than it would have been in the absence of a reservoir upstream ch4 emissions are less likely to be affected by upstream conditions since they result largely from the creation of new anoxic environments liu et al 2020 nevertheless given that systems of cascading reservoirs and inter basin transfers are common in many areas of the world measurement campaigns aiming to test these hypotheses would be useful another area that would benefit the development of more robust co2 models is the ability to quantify reservoirs with negative diffusive co2 fluxes i e where reservoirs act as co2 sinks the logarithmic nature of our models is not well suited for this purpose while not common co2 uptake has been observed chanudet et al 2011 generally in eutrophic reservoirs although recent report shows that it can also occur periodically in oligotrophic conditions with very low organic carbon concentrations soued and prairie 2021 it also highlights that predicting co2 fluxes sustained by allochthonous input is paramount to the accurate estimation of the true co2 footprint of reservoirs a related limitation of the current g res version is the absence of an explicit carbon sedimentation component cases of persistent negative fluxes indicate reservoirs that necessarily accumulate carbon through sedimentation and burial recent measurements have shown that sediment carbon accumulation can be large in reservoirs mendonça et al 2014 2017 while the ensuing carbon accumulation cannot from a mass balance perspective be simply subtracted from the flux at the air water interface see prairie et al 2017 for details to obtain a net footprint there are circumstances in which a portion of the carbon burial can be construed as a new sink isidorova et al 2019 i e carbon burial that would not otherwise occur either at the reservoir site or further downstream there are currently too little data to estimate the portion of the carbon accumulation that can be rightfully considered a new sink but future versions of g res and other yet to be created reservoir ghg models should incorporate this pathway to offer a more complete representation of the reservoir ghg footprint another limitation of the current g res model is that new emission pathways are being identified but for which observations are too few and therefore difficult to generalize identified nearly two decades ago fearnside 2002 recent studies have suggested that ghg fluxes from drawdown zones can be important although highly variable because they depend in part on the carbon and moisture content of the exposed soil sediments marcé et al 2019 serça et al 2016 such emissions have been shown to be very high in some systems amorim et al 2019 given the paucity of literature on the subject the emissions from drawdown areas are not explicitly included in g res although assumed implicitly to be of same magnitude as surface flux since g res uses the maximum surface of the reservoir in the footprint calculations similarly assessments of degassing emissions have been largely confined to ch4 although co2 is known to be also emitted through this pathway however as additional data become available ghg emissions from these pathways should be modelled explicitly and integrated in future iterations of g res another improvement would be the incorporation of an explicit representation of the relationship between ghg emissions and trophic status recent analyses have reported strong positive correlations between ch4 emissions and lake trophic status both within single lakes across time and space grinham et al 2018 li et al 2018 and in multiple lake syntheses beaulieu et al 2019 deemer et al 2016 delsontro et al 2018 harrison et al 2017 a positive relationship between primary production and ch4 emissions makes sense as organic matter can stimulate ch4 production as an organic substrate for acetoclastic ch4 production and it can also foster the anaerobic conditions necessary for ch4 production and inhibit ch4 oxidation limited experimental work has also indicated a relationship between ch4 production and organic c quality west et al 2016 intriguingly recent work also shows that direct production of ch4 in oxic surface waters by cyanobacteria could strongly link primary production and ch4 emissions bižić et al 2020 although the importance of this process in controlling ch4 emissions is under debate günthel et al 2021 peeters and hofmann 2021 furthermore future emissions are likely to be sensitive to changes in organic c delivery bayer et al 2019 to date the absence of global scale information on chl a concentrations or trophic status has precluded the effective incorporation of such a driver in the global g res model however efforts are underway to develop such information and it may soon be possible to include such information in a global reservoir ghg model as eutrophication may often be linked to uas loading see 2 1 1 improving the incorporation of the relationship between ghg emissions and trophic state will also be useful for identifying the impact of uas lastly the net ghg footprint i e the difference in the ghg balance before and after impoundment currently relies on generic ch4 and co2 emissions factors from the ipcc for different land cover types in different climate zones application of our current approach to our modelling dataset suggests that while significant in areas where the flooded terrestrial landscape is rich in highly organic soils or if the flooded land has special characteristics leading to large fluxes of ghg the importance of the ghg balance of the pre flooding landscape is generally modest altering the median footprint by only 4 while a useful first order approach we fully acknowledge that further improvements will require a more explicit modelling approach to the ghg balance of the individual components of the terrestrial mosaic in place before flooding 5 conclusion the g res model framework proposes a novel integrative approach to the prediction of net ghg footprint from reservoirs whereby predictions include the local environmental conditions and physical configuration of each reservoir in a globally consistent predictive framework it allows for a quantification of relative contribution of various emission pathways of ch4 and co2 and how emissions of these gases change over time after impoundment accounting for temporal trends provides a means to assess its ghg footprint over the lifetime of reservoirs and also the estimation of the share of co2 emissions that are sustained by external organic inputs that would have occurred even in the absence of the reservoir the so called displaced emissions prairie et al 2018 the g res tool and associated models are freely available in a cloud based modelling portal that will allow the scientific community to further probe the past and future geography of carbon emissions from reservoirs by applying the framework to larger datasets than the one used to develop it the framework and its components will continue to evolve as new data become available that allow for the core models to be extended and improved as new information on reservoir functioning emerges and as users provide feedback and insight on its structure and components in a changing world where assessing ghg emissions of projects such as reservoir creation becomes standard practice such a tool will be essential for decision makers to quantitatively evaluate alternative projects in order to select those with the lowest possible environmental footprints the tool could also help in locating and designing new dams and their corresponding reservoirs in guiding the operation of existing reservoirs and in the potential retro fitting of existing hydropower plants and dams to reduce ghg emissions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the g res tool was developed with the financial support of the international hydropower association and from the worldbank special thanks to rikard liden richard taylor and mathis rogner for many discussions further funding to ytp was provided by the nserc discovery grant this is a contribution to the unesco chair in global environmental change funding to jah was provided by an nsf infews grant nsf ear1639458 a gril fellowship grant the cox visiting professorship fund at stanford university a u s army corps of engineers climate preparedness and resilience programs grant and a nsf deb grant 135211 appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105117 appendices a additionnal equations used a 1 air density kg m3 a i r d e n s i t y 101325 287 05 m e a n t e m p e r a t u r e o f t h e 4 w a r m e r m o n t h s 273 15 a 2 bottom temperature c if mean temperature of the colder month 1 4 b o t t o m t e m p e r a t u r e 0 656 m e a n t e m p e r a t u r e o f t h e c o l d e r m o n t h 10 7 if mean temperature of the colder month 1 4 b o t t o m t e m p e r a t u r e 0 2345 m e a n t e m p e r a t u r e o f t h e c o l d e r m o n t h 10 11 a 3 bottom water density kg m3 b o t t o m w a t e r d e n s i t y 1 b o t t o m t e m p e r a t u r e 288 9414 508929 2 b o t t o m t e m p e r a t u r e 68 12923 b o t t o m t e m p e r a t u r e 3 9863 2 1000 a 4 surface temperature c s u r f a c e t e m p e r a t u r e m e a n t e m p e r a t u r e o f t h e 4 w a r m e r m o n t h s a 5 surface water density kg m3 s u r f a c e w a t e r d e n s i t y 1 s u r f a c e t e m p e r a t u r e 288 9414 508929 2 s u r f a c e t e m p e r a t u r e 68 12923 s u r f a c e t e m p e r a t u r e 3 9863 2 1000 a 6 cd c d i f r e s e r v o i r m e a n w i n d s p e e d 5 0 001 0 000015 a 7 annual wind speed at 10m m s a n n u a l w i n d s p e e d a t 10 m r e s e r v o i r m e a n w i n d s p e e d a t x m 1 c d 0 5 0 4 l o g 10 10 x 1 x equal 50 m in our database a 8 reservoir volume km3 r e s e r v o i r v o l u m e r e s e r v o i r a r e a m e a n d e p t h 1000 a 9 reservoir area km2 r e s e r v o i r a r e a r e s e r v o i r v o l u m e m e a n d e p t h 1000 a 10 mean depth m m e a n d e p t h v o l u m e r e s e r v o i r a r e a 1000 a 11 thermocline depth m t h e r m o c l i n e d e p t h 2 0 c d a i r d e n s i t y a n n u a l w i n d s p e e d a t 10 m 2 9 80665 b o t t o m w a t e r d e n s i t y s u r f a c e w a t e r d e n s i t y r e s e r v o i r a r e a 1000000 gorham and boyce 1989 a 12 temperature correction coefficient ch4 to do for each month t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c h 4 10 t e m p e r a t u r e p e r m o n t h 0 052 0 052 is the slope of the temperature vs ch4 flux function in our database if temperature per month lower then 4 c use 4 c a 13 temperature correction coefficient co2 to do for each month t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c o 2 10 t e m p e r a t u r e p e r m o n t h 0 05 0 05 is the slope of the temperature vs co2 flux function in our database if temperature per month lower then 4 c use 4 c a 14 effective temperature ch4 c e f f e c t i v e t e m p e r a t u r e c h 4 l o g 10 a v e r a g e 12 m o n t h t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c h 4 0 052 0 052 is the slope of the temperature vs ch4 flux function in our database a 15 effective temperature co2 c e f f e c t i v e t e m p e r a t u r e c o 2 l o g 10 a v e r a g e 12 m o n t h t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c o 2 0 05 0 05 is the slope of the temperature vs co2 flux function in our database a 16 k600 k 600 0 24 2 51 1 48 a n n u a l w i n d s p e e d a t 10 m 2 0 39 a n n u a l w i n d s p e e d a t 10 m 2 l o g r e s e r v o i r a r e a vachon and prairie 2013 a 17 kh k h e x p 115 6477 6 1698 e f f e c t i v e t e m p e r a t u r e c h 4 273 15 100 155 5756 e f f e c t i v e t e m p e r a t u r e c h 4 273 15 100 65 2553 l n e f f e c t i v e t e m p e r a t u r e c h 4 273 15 100 1000 18 0153 lide 1994 a 18 pch4 p c h 4 10 1 46 0 03 e f f e c t i v e t e m p e r a t u r e c h 4 0 29 l o g r e s e r v o i r a r e a rasilo et al 2014 a 19 surface water ch4 concentration s u r f a c e w a t e r c h 4 c o n c e n t r a t i o n k h p c h 4 a 20 ch4 emission factor for water bodies kg ch4 ha yr c h 4 e m i s s i o n f a c t o r f o r w a t e r b o d i e s s u r f a c e w a t e r c h 4 c o n c e n t r a t i o n k 600 16 365 100 a 21 q bathymetric shape q b a t h y m e t r i c s h a p e m a x i m u m d e p t h m e a n d e p t h 1 a 22 littoral area l i t t o r a l a r e a 1 1 3 m a x i m u m d e p t h q b a t h y m e t r i c s h a p e 100 a 23 phosphorus load forest kg ha yr p h o s p h o r u s l o a d f a c t o r f o r e s t 10 0 914 l o g 10 c a t c h m e n t l a n d c o v e r f o r e s t 100 c a t c h m e n t a r e a 0 014 100 a 24 phosphorus load croplands kg ha yr p h o s p h o r u s l o a d f a c t o r c r o p l a n d s 10 1 818 l o g 10 c a t c h m e n t l a n d c o v e r c r o p l a n d s 100 c a t c h m e n t a r e a 0 227 100 a 25 population in the catchment person p o p u l a t i o n i n t h e c a t c h m e n t c a t c h m e n t a r e a p o p u l a t i o n d e n s i t y a 26 annual discharge mm yr a n n u a l d i s c h a r g e a n n u a l r u n o f f 0 001 c a t c h m e n t a r e a 1000000 31536000 a 27 water residence time wrt yrs w r t m e a n d e p t h r e s e r v o i r a r e a c a t c h m e n t a r e a a n n u a l r u n o f f 1000 a 28 river area before impoundment km2 r i v e r a r e a b e f o r e i m p o u n d m e n t r i v e r l e n g t h b e f o r e i m p o u n d m e n t 5 9 c a t c h m e n t a r e a 0 32 1000000 a 29 reservoir cumulative global horizontal radiance kwh m2 period if 40 latitude 40 r e s e r v o i r c u m u l a t i v e g l o b a l h o r i z o n t a l r a d i a n c e a v e r a g e 12 m o n t h r e s e r v o i r m e a n g l o b a l h o r i z o n t a l r a d i a n c e n u m b e r o f m o n t h o v e r 0 c if 40 latitude r e s e r v o i r c u m u l a t i v e g l o b a l h o r i z o n t a l r a d i a n c e a v e r a g e m a y j u n e j u l y a u g u s t s e p t e m b e r r e s e r v o i r m e a n g l o b a l h o r i z o n t a l r a d i a n c e n u m b e r o f m o n t h o v e r 0 c if 40 latitude r e s e r v o i r c u m u l a t i v e g l o b a l h o r i z o n t a l r a d i a n c e a v e r a g e n o v e m b e r d e c e m b e r j a n u a r y f e b r u a r y m a r c h r e s e r v o i r m e a n g l o b a l h o r i z o n t a l r a d i a n c e n u m b e r o f m o n t h o v e r 0 c 
25805,human made reservoirs are now recognized as potentially significant sources of greenhouse gases comparable to other anthropogenic sources yet efforts to estimate these reservoir emissions have been hampered by the complexity of the underlying processes and a lack of coherent budgeting approaches here we present a unique modelling framework the g res tool which was explicitly designed to estimate the net c footprint of reservoirs across the globe the framework involves the development of statistically robust empirical models describing the four major emission pathways for carbon based greenhouse gases ghg from reservoirs diffusive co2 and ch4 emissions bubbling ch4 emissions from the reservoir surface and ch4 emissions due to degassing downstream the reservoir based on an extensive meta analysis of published data from the past three decades these empirical models allow the prediction of reservoir specific emissions how they may shift over time and account for naturally occurring ghg generating pathways in aquatic networks graphical abstract image 1 keywords carbon dioxide methane reservoir g res model greenhouse gas emission 1 introduction the creation of reservoirs by damming of rivers is one of the oldest and most profound landscape transformations exerted by humans the inundation of a largely terrestrial ecosystem can radically change the carbon dynamics of the affected domain indeed terrestrial systems are generally viewed as carbon sinks while freshwater ecosystems are most often sources of greenhouse gases ghg relative to the atmosphere borges et al 2014 cole et al 2007 raymond et al 2013 tranvik et al 2009 drake et al 2018 with negative net ecosystem production e g ferland et al 2014 this is the case because such systems often receive large amounts of organic carbon from the terrestrial ecosystems they drain and because the inland water network is a site for intense c processing unsurprisingly freshwater reservoirs also emit ghgs in many cases at higher areal rates than their natural counterparts lakes and large rivers because the flooded land under freshwater reservoirs provides a new source of organic matter available for decomposition and because it creates new environments conducive to the production of methane a more potent ghg than co2 recent studies have concluded that the magnitude of ghg emissions from reservoirs can be of global significance to date most global assessments have simply used averages of measured values per climatic or geographic region that are then extrapolated worldwide although reasonable as a first order estimate the validity of this approach rests on a number of implicit assumptions for example it assumes that the sampled systems are statistically representative of the global population of reservoirs the accuracy of this method is also highly dependent upon the sampling strategy used to obtain reservoir wide annual estimates a potential shortcoming given the known large and highly skewed spatial and temporal variability of such estimates both within and among reservoirs deemer et al 2016 deemer and holgerson 2021 delsontro et al 2018a b grinham et al 2011 prairie et al 2018 prairie et al 2017 rosentreter et al 2021 similarly such an approach largely ignores the known temporal decrease in emission rates after flooding abril et al 2005 barros et al 2011 teodoru et al 2012 lastly not all emissions occurring at the surface of reservoirs specifically co2 emissions should be considered new and attributable to impoundments since organic carbon loading from upstream catchments would sustain aquatic co2 emissions even in the absence of a reservoir e g via co2 emissions from lakes rivers estuaries or the coastal ocean tools to quantify the current and future carbon footprint of reservoirs have not yet been developed in part due to the complexity of the processes involved in generating reservoir ghg emissions the multiple pathways through which ghgs are emitted from reservoirs diffusion ebullition and degassing and the difficulty of accounting for pre flooding ghg balances hindering the development of such tools is the fact that there have been only a handful of case studies that have quantified the complete c footprint of individual reservoirs teodoru et al 2012 abril et al 2005 and these cannot be easily extrapolated to other sites in spite of this there have been a number of regional or global studies that have modelled specific aspects of reservoir c dynamics such as co2 or ch4 diffusive emissions barros et al 2011 deemer et al 2016 but there is presently no platform that integrates the various aspects that make up the overall reservoir c footprint in a coherent and predictive context to this end we have developed an online modelling platform hereafter the g res tool that takes into account the specific environmental conditions of a reservoir to predict its associated emissions of both carbon dioxide co2 and methane ch4 partition fluxes among the main emission pathways and characterize the evolution of ghg fluxes over the expected lifetime of a given reservoir here assumed to be 100 years in addition the g res tool estimates the ghg balance of the affected landscape prior to flooding thereby allowing the estimation of the net ghg impact of reservoir creation by difference the g res tool closely follows the conceptual approach outlined in prairie et al 2018 which ultimately aims at predicting the reservoir induced change in ghg fluxes to the atmosphere of the flooded landscape the g res tool is applicable globally harrison et al 2021 and can be used with an earth engine functionality prairie et al 2017 so that it can be used dynamically on existing reservoirs as well as on potential or planned reservoir locations the core of the g res tool relies on a series of empirical models developed from a synthesis of published literature on reservoir emissions these models are based on the influence of local to regional environmental controls on ghg emission and on the characteristics of the individual reservoirs and their catchments in this paper we report on the development of the underlying models predicting the magnitude of each emission pathway their linkages with global databases as well as their integration into a comprehensive and publicly available platform in addition to further validate ability to predict the temporal evolution of emissions in individual reservoirs we compare model predictions with measured ghg fluxes in two of the most studied reservoirs located in very contrasting climates boreal and tropical that were sampled extensively over a 12 year and 20 year period respectively 2 methods 2 1 1 modelling approach the g res tool is designed to assess in a comprehensive manner the net ghg footprint of a reservoir over its lifetime assumed to be 100 years gagnon et al 2002 iaea advisoring group 1996 1995 including the footprint associated with its construction however the present paper reports only on the biogenic components of the ghg balance of the reservoir area i e without the construction both prior to and after impoundment the g res tool can therefore provide an estimate of the net ghg impact of reservoir creation similarly the g res tool provides calculations to estimate the portion of ghg emissions that are likely the result of nutrient enrichment so called unrelated anthropogenic sources uas ipcc srren kumar et al 2011 due to phosphorus inputs associated with human activities in the reservoir catchment based on the expected difference in phosphorus load in the absence of human induced catchment perturbations details of the approach can be found in the g res tool technical document prairie et al 2017 the method is useful primarily in allocating reservoir ghg emissions to particular services or practices however emissions potentially attributable to uas are not excluded from the present calculations of the ghg footprint of reservoirs and are therefore not addressed further in this paper see prairie et al 2017 for further details 2 2 database to develop the ghg emissions models we undertook an extensive review of the pre 2016 scientific literature and collected data from 223 globally distributed reservoirs with co2 and ch4 emissions measurements 279 field assessments of diffusive co2 emissions 205 of diffusive ch4 emissions 59 of bubbling ch4 emissions and 52 of degassing ch4 emissions see supplementary material figure s1 and reference list and prairie et al 2017 and available at https zenodo org record 4711132 yoiwxy295om this database is largely overlapping with the one developed by deemer et al 2016 because the assembled dataset of ghg emissions depended entirely on the availability of published data we compared the size and climate distributions of the sampled reservoirs with that of a more exhaustive and larger set of reservoirs worldwide grand database lehner et al 2011 in general our database essentially covered the full range of reservoir surface areas our dataset also covered all climate zones although boreal and to a lower extent sub tropical and tropical reservoirs were somewhat over represented relative to the grand see supplementary material table s2 in addition to ghg flux data we also collated information on climatic geographic edaphic and hydrologic conditions of each reservoir and its catchment these variables were obtained from a variety of open sources including the literature worldwide gis layers see table 1 and information contained in the grand database lehner et al 2011 the complete list of potential predictor variables from both reservoirs and catchments used in the models is listed in table 1 geographical information systems gis were used to acquire two sets of data pertaining either to the reservoir themselves or their catchments we used the gis polygons provided in the grand database 156 reservoirs when available and added 67 reservoirs that were delineated using contemporary satellite imagery zonal statistics tools applied to global raster layers were then used to estimate the variables of interests for each reservoir e g soil carbon content surface temperature and wind speed similarly the catchment dataset was built largely around the hydrobasins gis product lehner and grill 2013 to which was added several catchments that were delineated using the digital elevation model dem of the shuttle radar topography mission srtm and hydrological spatial analysis tools 2 3 standardization of data 2 3 1 annualization since the ghg emissions data of the 223 reservoirs gleaned from the literature were sampled at different temporal scales single time points seasonal averages annual averages we standardized all the diffusive fluxes of co2 and ch4 and the ch4 bubbling flux extracted from the literature using a procedure that combined the annual temperature cycle at the reservoir location with the known temperature dependence associated with co2 and ch4 production inglett et al 2012 liikanen et al 2002 yvon durocher et al 2014 also see prairie et al 2017 for colder climates where reservoirs develop an ice cover winter ghg accumulation under ice is accounted for by assuming that gas production occurs continuously at 4 degrees c although it is likely that ghgs produced during ice cover are released during a short period spring overturn in brief the procedure consisted of assigning a temperature to the observed ghg flux measurements and estimating the flux from the unsampled period by modulating the measured flux up or downwards using the temperature sensitivity metric appropriate for co2 q10 2 inglett et al 2012 and ch4 q10 4 yvon durocher et al 2014 this method was applied for each unsampled month and all months were summed this annualization procedure led to a modest adjustment downward for diffusive ch4 emission from an average 39 4 152 5 measured flux to an average 33 5 114 6 mg c m 2 d 1 annualized flux because many measurements in regions with strong annual cycles were done exclusively in the summer months however the significantly reduced variability suggests that part of the initial noise in the collated data set was the result of sampling regime differences reservoirs with multiple years of measurements were used to evaluate the potential impact of reservoir aging on ghg emissions barros et al 2011 if several independent measurements occurred at the same age an average of all the measurements was calculated 2 3 2 system wide estimate of ch4 ebullition in most cases ch4 ebullition rates were reported either directly as system wide estimates or as littoral specific rates with the corresponding surface area however some studies reported littoral ch4 ebullition rates without defining the surface the littoral zone encompassed since bubbling intensity is known to decrease with depth bastviken et al 2008 delsontro et al 2010 delsontro et al 2011 mcginnis et al 2006 applying the littoral emission rates to the whole reservoir surface area would overestimate whole reservoir fluxes to avoid this potential bias for all studies reporting only littoral flux measurements ch4 ebullition flux rates were applied only to an area we defined as 3 m depth see appendix a from details and then expressed as rates per unit surface area of the entire reservoir we acknowledge that ch4 bubbling can occur in some specific cases at greater depths mcginnis et al 2006 and that this assumption may therefore result in an underestimate of reservoir wide emissions nevertheless given the physical inverse dependence of bubbling on depth bazhin 2003 we view this as an improvement over simply assuming littoral emissions rates occur over an entire reservoir s surface area at equal rates deemer et al 2016 2 3 3 prioritization of data sources for any given reservoir several estimates of the same variables can be extracted from various sources when such cases occurred data gleaned directly from the scientific literature were prioritized for inclusion in the database followed by the data from the grand database lehner et al 2011 if values were unavailable from the peer reviewed literature we extracted the relevant values from global gis layers see table 1 or estimated them from general models found in the literature see prairie et al 2017 for details 2 4 statistical analysis and model development using the annualized ghg emission estimates described in section 2 2 1 we developed a series of multivariate statistical models to predict each flux pathway using both reservoir and catchment predictor variables variable selection was carried out using the elastic net regression procedure see prairie et al 2017 for more details implemented in jmp pro 14 or 15 elastic net regression is a penalty based variable selection method particularly well suited to modelling cases with a large number of potential predictor variables even in cases with low sample size n zou and hastie 2005 the elastic net procedure reduces the variance inflation problem associated with highly collinear variables by imposing a penalty on large coefficients depending on the penalty parameter the algorithm can reduce regression coefficients to zero i e no effect thereby providing an objective variable selection procedure variable transformations mostly logarithmic were necessary to fulfill assumptions of the regression approach e g normality of residuals or desirability of the predictor variable distribution across their ranges for each emission pathway outliers were identified using cook s distance cook 1977 which combines the studentized residual and the observation s departure from the mean using 3 times the mean μd as a threshold and removed from the analysis 2 4 pre impoundment ghg footprint large landscapes are generally a mosaic of ecosystems forests wetlands cropland settlements lakes streams rivers etc that all process carbon in different ways each of these ecosystems can emit or sequester carbon at different rates contributing to the total carbon footprint of a defined area for example growing forests absorb co2 while wetlands tend to emit methane while sequestering co2 soil type will also influence carbon processing as organic soil will emit more ghg than mineral soil natural waterbodies on the other hand generally emit co2 and to a lesser extent methane the pre impoundment ghg balance of a reservoir area is therefore the weighted sum of the ghg balance of each landscape component because of the multiplicity of ecosystem types we associated each landscape component within the impounded area with default co2 and ch4 emission factors ef from the ipcc ipcc 2013 specifically for the forest with mineral soils we have used the default value from pan et al 2011 and for the methane emissions from water bodies we used the equation developed in rasilo et al 2014 combined with appropriate gas exchange coefficients prairie et al 2017 vachon and prairie 2013 to follow the ipcc classification of ef the top 30 cm of soil was assigned as mineral or organic soils using a threshold of 40 kg c m 2 and the land impounded was associated to one of four climate zones tropical subtropical temperate and boreal table 1 the general equation to estimate the pre impoundment ghg balance was then 2 pre impoundment ghg fooprint j 1 2 i 1 8 e f l c i a r e a l c i a r e a r e s e r v o i r where ef lc ij emission factor specific to each land cover category and each gas prairie et al 2017 area lc i inundated area of each land cover category km2 i land cover category 8 categories see table 1 j pre impoundment co2 or ch4 emissions area reservoir total reservoir area km2 including both existing river lake area and inundated area 3 results and discussion 3 1 empirical modelling for both ch4 and co2 diffusive emissions the age of the reservoirs was selected as one of the strongest predictors as also found in barros et al 2011 and the regression equations therefore express emissions at a specific reservoir age to evaluate the net footprint over the total lifetime of a reservoir the non linear regression equation was integrated using basic calculus to yield the 100 yr average annual emission rate equations 4 and 8 table 2 methane emissions from reservoirs are more complex than co2 because three different pathways degassing bubbling and diffusion can each deliver substantial amounts of ch4 to the atmosphere and because each pathway is controlled by different drivers and must thus be modelled separately the statistics of the four empirical models developed are detailed in table 2 3 1 1 ch4 diffusive emissions to predict diffusive ch4 emissions the elastic net procedure retained reservoir age mean annual temperature and percent littoral area table 2 eq 3 as the only useful predictors p 0 0001 the age of the reservoir had the strongest influence particularly at high temperatures fig 1 a similarly the decrease in ghg emission with age was strongest in reservoirs with extensive littoral zones fig 1b all three predictor variables confirmed trends previously reported in the literature for reservoirs and lakes barros et al 2011 delsontro et al 2016 liikanen et al 2002 yvon durocher et al 2014 3 1 2 ch4 bubbling emissions ch4 is only sparingly soluble and can reach very high partial pressures when produced in sediments leading to bubble formation when ch4 partial pressure exceeds the sum of barometric and hydrostatic pressures as bubbles grow larger or after a sudden change in pressure bubbles can be released from the sediment into the water column largely bypassing exchange within the water column mcginnis et al 2006 and emitted directly to the atmosphere because of its dependence on hydrostatic pressure the release of ch4 bubbles is inversely proportional to water depth and in many aquatic systems confined to shallow zones in combination with areas of high sediment deposition a logarithmic equation using the cumulative global horizontal radiance following the work of wik et al 2014 and percent littoral area as predictor variables was found to best represent ch4 bubbling reservoir wide values for ch4 ebullition the age of reservoir was not selected as a useful predictor by the elastic net regression procedure which explains the absence of integrated model equation for this pathway table 2 eq 5 given the limited number of bubble flux measurements n 46 and the wide confidence limits of the model the emissions estimates associated with this pathway carry more uncertainty than the diffusive pathways see table 2 in this particular model 4 observations were deemed outliers using the u 3 cook s distance criterion three of these systems were removed from the analysis but we retained one eastmain 1 reservoir because it represented one of the few points where the cumulative irradiance was low thereby extending the model prediction range its inclusion did not affect the rmse of the model but conferred more stability to the associated regression coefficient 3 1 3 ch4 degassing emissions downstream of reservoirs reservoir outflows can originate from various depths through various conduits through turbines spillways bottom gates and bypass channels with important implications for ch4 degassing fluxes deeper intakes are often preferred for hydropower stations for added operational flexibility for thermally stratified systems or periods drawing water from the hypolimnion can lead to high emission of methane downstream of a dam because high concentrations of ch4 often accumulate in anoxic or sub oxic hypolimnia the sudden pressure drop after exiting a turbine can release a large fraction of the dissolved gas directly to the atmosphere the so called degassing process ch4 rich water drawn from a reservoir may also be released to the atmosphere in turbulent waters downstream the reservoir note that degassing emissions does not include these ghg emissions further downstream this component is particularly difficult to predict given that methane oxidation can vary widely between ecosystems soued and prairie 2020 thottathil et al 2018 2019 thus a first requirement in assessing degassing emissions is to compare water intake and thermocline depths to determine whether water flowing downstream from dams is from the hypolimnion if it is it is likely to be ch4 rich leading to high degassing emissions conversely if the water flows downstream from the epilimnion it is likely to be comparatively ch4 poor leading to low degassing emissions to account for this the g res tool estimates degassing emissions only when the water intake is located below the thermocline to develop the g res ch4 degassing model we calculated measured degassing flux as the difference in published ch4 concentrations upstream and downstream of dams multiplied by mean annual flow through the turbines we then tested for significant predictors of the difference between upstream reservoir and downstream ch4 concentrations the magnitude of these concentration differences was best predicted table 2 eq 6 as a function of water residence time wrt and post impoundment annual ch4 diffusive emission itself estimated by the model described in section 3 1 1 as a proxy of ch4 production this provides an efficient method for predicting degassing emissions average discharge through the turbines was estimated as 90 of the annual runoff as default value although this value can vary substantially depending on the reservoir operations and maintenance 3 1 4 co2 diffusive emissions the best model for diffusive co2 flux also determined using an elastic net regression procedure includes reservoir age mean annual temperature modelled phosphorus concentration prairie et al 2017 reservoir area and pre inundation reservoir surface soil carbon content as shown in table 2 eq 7 because of the logarithmic nature of the relationship negative co2 fluxes i e reservoir acting as an atmospheric sink are currently not included in the modelling persistent co2 influx is generally observed only under eutrophic conditions and or when there are very low organic allochthonous carbon inputs soued and prairie 2021 as a result g res can be construed as providing an upper limit to the co2 footprint of eutrophic systems compared to diffusive ch4 the decline of co2 emissions over time is much steeper at first and stabilizes more quickly to a new equilibrium fig 2 this temporal decrease has been reported in several cases abril et al 2005 demarty and tremblay 2017 galy lacaux et al 1997 teodoru et al 2012 predicted co2 diffusive emissions from both individual reservoirs and reservoirs collectively are highly influenced by temperature fig 2a and somewhat less sensitive to the amount of organic carbon contained in the flooded soil fig 2b harrison et al 2021 suggesting that diffusive co2 emissions from reservoirs could increase with increasing water temperatures anticipated to accompany ongoing climate change these models describe well both the main drivers and the temporal trajectory of co2 emissions and can therefore be used to estimate the expected emissions at any particular time post flooding unlike ch4 emissions see prairie et al 2017 not all surface co2 emissions should be attributed to reservoir creation because as with all inland aquatic systems reservoir co2 emissions are also sustained by the mineralization biological and photochemical of allochthonous organic carbon largely dissolved originating from the upstream catchment in the absence of a reservoir allochthonous doc would still have been mineralized to co2 albeit mostly further downstream furthermore the longer water residence time of reservoirs relative to the river it replaced allows for more doc mineralization to occur at the reservoir site algesten et al 2005 dillon and molot 1997 vachon et al 2017 exacerbating the magnitude of displaced emissions sensu prairie et al 2017 the g res tool allows for an estimation of this portion of the co2 diffusive flux that can be legitimately attributed to the creation of a reservoir to calculate this fraction the g res tool assumes that the predicted co2 emission rate at year 100 post flooding corresponds to naturally sustained emissions which are subtracted from the temporal trajectory to provide an estimate of the co2 attributable to mineralization of the flooded terrestrial biomass and soil c see prairie et al 2017 for details under this assumption the rate of decline through time i e the age variable coefficient in the regression model 0 330 can be used to calculate that over the 100 year lifetime of reservoirs an average of about 31 6 of the co2 emissions can be attributed to the impoundment with the remaining being sustained by continuous allochthonous organic carbon the g res platform also accounts for the co2 emissions from natural aquatic ecosystems located within the impoundment area prior to flooding for example when a lake is only slightly expanded by impoundment or when several lakes were submerged g res calculates reservoir co2 emission by applying the predicted areal rates eqs 7 or 8 only to the newly flooded area rates using 9 newly impounded land ratio 1 w a t e r b o d y b e f o r e i m p o u n d m e n t 100 3 2 net ghg footprint the sum of the 4 different components of emission gives the total post impoundment emissions from which the pre impoundment emissions can be subtracted or added to obtain an estimate of the net ghg footprint illustrated in the graphical abstract 3 3 validation 3 3 1 g res modelling approach versus averages of measured values the range of ghg emission rates found in the literature regardless of emission pathway or ecosystem type consistently shows a highly skewed distribution with a few very high values leading to mean values that are much higher than other measures of central tendency by using log transformed models predictions from the g res correspond to the geometric mean of the distribution of annualized area adjusted ghg flux measurements however because g res relies on the main drivers of emissions from a set of local environmental factors through statistical relationships it is less prone to overestimation than the often used approach of simply applying the average value derived from a highly skewed set of measured fluxes to estimate the flux of unsampled reservoirs to validate this claim we used reservoirs for which ch4 diffusive emissions had been measured to compare the predictive ability of our g res model estimation of reservoir wide ch4 diffusive emissions with those calculated by simply applying the average of all measured areal emission rates 38 5 mg c m 2 d 1 from measurements used in this comparison to the same systems as expected g res predictions did not deviate significantly from the 1 1 line fig 3 a while simply applying the observed mean to all reservoirs overestimated reservoir emissions in 84 1 of the cases and by an average of nearly an order of magnitude over the entire range of prediction fig 3b the corresponding nash sutcliffe efficiency statistics were 0 67 and 0 25 respectively this underlines the importance of model based predictions when dealing with highly skewed data the same pattern was observed albeit to a varying degree when the individual pathways were examined separately see supplementary material figure s2 and table s1 3 4 emissions through time the case study of two contrasting reservoirs the general decline in ghg as a function of age of the reservoir observed in our models eq 3 and 7 and reported elsewhere barros et al 2011 is cross sectional in nature i e through the observations of different reservoirs of varying ages to explore the longitudinal applicability of the models to individual reservoirs over time we tested it to two well studied but contrasting reservoirs from a boreal eastmain 1 and a tropical climate petit saut eastmain 1 a 603 km2 reservoir in the boreal region of quebec 53 n was flooded over the november 2005 to february 2006 period the reservoir emissions were monitored and published in the scientific literature for seven 7 years after impoundment year 2006 2009 bastien and demarty 2013 demarty et al 2009 demarty and tremblay 2017 teodoru et al 2012 tremblay et al 2008 tremblay et al 2009 and further measured recently in 2018 unpublished data p del giorgio prior to flooding the impounded area was dominated by forest 74 with a small coverage of grassland shrubland 10 5 water bodies 11 5 and wetlands 3 and the impounded soils have organic carbon rich content 22 3 kg c m 2 on average this remote area has very limited human occupation or activities and the reservoir is considered oligotrophic total phosphorus concentration estimated by the g res is 7 1 μg l 1 and measured as 9 3 μg l 1 in 2018 unpublished data p del giorgio in contrast petit saut is a tropical reservoir 4 n located in french guiana where 305 5 km2 of forest 37 wetlands 25 7 and water bodies 32 9 were flooded in 1994 the reservoir emissions were measured and published in the scientific literature for the first ten 10 years after impoundment year 1994 2004 abril et al 2005 but were also continuously monitored in 2004 2014 unpublished data v chanudet the impounded soil carbon content is 10 4 kgc m 2 on average and the reservoir is considered oligotrophic to compare eastmain 1 observations with g res tool predictions eight years of measurements for the ice free period were annualized to account for the seasonal temperature cycle and corresponding ghg production see section 2 2 1 prairie et al 2017b for petit saut no such annualization was necessary given that measurements monthly were available from all seasons for the purpose of this comparison we did not distinguish between natural and anthropogenic co2 emissions section 3 2 4 prairie et al 2017a b also because of the lack of time series data on multiple ghg emission pathways the comparison was only possible for co2 and ch4 diffusive emissions for co2 fig 4 a and b shows that both the magnitude and the decline in the rate of post impoundment co2 emissions are for the two contrasting reservoirs reasonably well predicted by g res as predicted the initial emission rates were much higher in petit saut than in eastmain 1 eastmain 1a but exhibited a similar rate of relative decline nevertheless the model underpredicted emissions in the initial years at eastmain 1 but g res estimations and observations converged after a few years post impoundment fig 4a for petit saut the g res model predicted the initial rates quite well but tended to overestimate later on while the details of the temporal projections are important the long term cumulative footprint is particularly relevant given the overall purpose of the g res platform fig 4c d illustrate how the estimated and observed cumulative co2 footprints track one another for eastmain 1 the g res cumulative footprint was on average 17 lower that the cumulative observed co2 over the course of the observation period 12 years for petit saut the cumulative co2 emission curve was nearly perfectly matched by g res estimation fig 4d for ch4 the g res model correctly predicted the one order of magnitude difference between diffusive ch4 emission rates of the two reservoirs fig 5 however the temporal trends in measured emissions did not follow the g res predicted rate of decline for the tropical reservoir petit saut the observed decline was faster than predicted while the eastmain 1 reservoir exhibited the reverse pattern g res predicted diffusive ch4 flux to decline faster than it actually did this suggests that in its current form table 2 eq 3 the g res ch4 diffusive model apparently captures an average rate of decline but that the cross sectional data was unable to detect the slower decline in very cold environments and the steeper decline in tropical climates this putative interaction between climate and the rate of temporal decline following impoundment can only be resolved by the incorporation of multiple long time series of ch4 from other reservoirs 3 5 uncertainty estimation the g res tool ultimately aims at predicting the ghg footprint of reservoirs over their assumed lifetime 100 years and therefore implies the integration over time of each of four statistical models summarized in table 2 this operation is akin to estimating the long term mean emission rate as a result we developed an uncertainty estimate to reflect the error variability of the estimated mean ghg footprint using monte carlo simulations in brief the predicted fluxes log scale from each emission pathway were contaminated randomly with normally distributed noise corresponding to the standard error of the residuals of each model and then summed after log de transformation we repeated the procedure to obtain 1000 estimates of the reservoir ghg emissions footprint from which we extracted the non parametric 95 confidence limits while these varied between reservoirs the average lower and upper values corresponded to 87 and 120 of the mean note that if the g res equations are instead used to estimate a reservoir s ghg footprint at a given age uncertainty limits will be wider than for its lifetime integrated footprint and would require accounting for de transformation bias 3 6 g res tool user interface to make the predictive models described above widely available we developed a web interface hereafter called the g res tool this online tool www hydropower org gres tool allows users to use reservoir specific input data to calculate net ghg footprint estimates the g res tool also provides auxiliary modules to estimate emissions for the construction phase as well as to allocate ghg footprint to the different services associated with a particular reservoir hydroelectricity water supply flood control irrigation fisheries recreation navigation and environmental flow the methods used in these modules are described in more detail in a technical document prairie et al 2017 in this paper we focus only on the pre and post flooding ghg balance of the reservoir area from the main introductory g res tool web page nine other interacting tabs can be selected and used for several purposes including 1 entering input variables about the reservoir and its catchment 2 entering information about the usage of the reservoir to allocate services 3 entering information about the construction phase of the reservoir to estimate construction related ghg footprint 4 viewing calculated reservoir post impoundment ghg emissions including the relative contribution of each emissions pathway and each ghg the magnitude of unrelated anthropogenic sources and an estimate of total ghg flux including an evaluation of the pre and post impoundment footprint and 5 implementing a pre programmed earth engine functionality to assist in obtaining all relevant and required input information from globally available and consistent sources prairie et al 2017 this latter functionality can be used to obtain all required data by providing basic information dam location dam height for existing reservoirs but can also be used to explore the ghg footprint of future or planned sites since the g res tool is cloud based the user can save input parameters locally and re import them back in a subsequent use of g res various report and export functions are available fig 6 displays the main user interface outlook and the total ghg footprint results page the g res tool has been available for use since 2017 from version 1 onwards and is now recommended by multiple stakeholders and international organizations with now more than 900 registered users and an average of 150 visits per month while the g res has been mostly used to estimate the carbon footprint of individual reservoirs it has recently been used to estimate the biogenic ghg component in a life cycle assessment of hydroelectricity generation for the whole province of quebec levasseur et al 2021 a further strategic importance of g res lies in its ability to estimate ghg emissions for future projects allowing better decision making to build new reservoirs that have low carbon footprint for example estimates of high degassing emissions can lead to dam design changes i e water intake depth to reduce the importance of this pathway similarly estimating the total ghg footprint is particularly important for banking institutions in their decision to finance future reservoir projects 4 discussion 4 1 comparison to previous models it is important to emphasize that there is currently no other modelling platform that can be used to compute in a comprehensive and globally applicable framework all four ghg emission pathways the g res integration of several components and flux estimates due to individual ghg emissions pathways moves beyond past efforts to quantify ghg emission from reservoirs barros et al 2011 bastviken et al 2011 deemer et al 2016 hertwich 2013 st louis et al 2000 similarly the ability to distinguish between natural and anthropogenic co2 emissions is unique to g res as well as the estimation of the net ghg footprint through the estimation and accounting of the landscape ghg balance prior to flooding thus the comparison between g res and previously published models revolves around the driver variables identified the extensiveness of the database used and consequently the robustness of the individual empirical models barros et al 2011 highlighted the influence of age and temperature using latitude on reservoir ghg emissions using 85 reservoirs similarly the more recently published study from deemer et al 2016 has improved the estimation of ghg emissions from reservoirs by using a much bigger database 267 reservoir years largely overlapping with ours as well as showing that reservoir productivity plays an important role in ghg emissions along with age temperature and hydrology the g res model developed here builds on these studies and has confirmed many of these drivers previously identified while integrating several new ones to develop a globally consistent modelling platform for each component of reservoir ghg emission based on a much larger number of potential predictor variables 40 see table 2 for the variables retained the incorporation of the more recently available ghg measurements into empirical models has improved predictive power and in particular the robustness of the estimated model coefficients for models where the age of the reservoir was deemed a significant predictor diffusive co2 and ch4 emissions the larger dataset helped better define the temporal evolution of emissions and therefore the integrated lifetime 100 years ghg footprint also a unique feature of g res while their predictive abilities are far from perfect regression based models are also less prone to introduce biases than a simple application of average per area rates particularly in the case of ghg pathways mostly for ch4 known to have a highly skewed distribution for example regional or global estimates of ghg emissions from reservoirs derived from simply applying an average value inherently assumes that the sampled systems are representative of the population distribution validation of the g res models provided in this study fig 4 illustrates that the regression based approach can considerably reduce biases another important feature unique to the g res modelling platform is that it can provide estimates of so called displaced emissions of co2 i e emissions that take place at the reservoir surface that are sustained by upstream loading of organic carbon mineralized within the reservoir but that would have occurred regardless of the presence of the reservoir albeit elsewhere downstream in the hydrological network section 3 1 4 sensu prairie et al 2018 4 2 partitioning among emission pathways the heterogeneity of the modelling database precluded the direct comparison of the relative importance of the various ghg components because very few reservoirs had concurrent measurements of all emission pathways however the modelled emission rates to the same dataset shows that excluding the ch4 degassing component the overall ghg footprint is dominated by the co2 diffusion pathway in about 73 of the cases while ch4 diffusion and bubbling is the main pathway in 10 and 16 of the reservoirs respectively see supplementary material figure s3 in this analysis ch4 degassing was omitted because its contribution to the overall ghg footprint was relatively small mean 14 median 4 and it would assume that all reservoirs have the required configuration for significant degassing to occur i e hydropower reservoirs with deep water intake note that these numbers apply specifically to the dataset assembled here and can differ in a more global context harrison et al 2021 4 3 limitations of the models while the g res model predictions carry large numerical uncertainty the g res tool is to our knowledge the most complete and the only globally consistent framework to predict the ghg footprint of reservoirs however proper usage of g res also requires an understanding of its current limitations for example because the models are regression based one of the inherent limits of application is the observation range in the predictor variables of the assembled model dataset while the observational ranges in our dataset captures most the variability of the global database provided in the grand database lehner et al 2011 table s2 we recommend applying g res only to reservoirs that fall within the limits of the current data furthermore the g res development has helped identify a number of knowledge gaps that deserve additional attention and research these include 1 the impact on ghg fluxes of reservoir location operation and water transfers between reservoirs and power plants within watersheds 2 the potential for reservoirs to act as ghg sinks 3 newly identified flux pathways 4 potential carbon burial in sediments and 5 the impact of eutrophication on reservoir ghg emissions the first important element not considered in the g res framework is the prediction for cascade systems where outflow from one reservoir or a series of reservoirs flows into one or more reservoirs further downstream at present reservoirs are considered independent and g res therefore assumes that carbon processing in one reservoir does not affect that of downstream reservoirs there is very little empirical information in the scientific literature on whether this assumption is reasonable however given that part of the allochthonous organic carbon input to the first reservoir of a cascade will be mineralized and lost from the hydrological system one would hypothesize that at least the co2 emission in a downstream reservoir is likely to be lower than it would have been in the absence of a reservoir upstream ch4 emissions are less likely to be affected by upstream conditions since they result largely from the creation of new anoxic environments liu et al 2020 nevertheless given that systems of cascading reservoirs and inter basin transfers are common in many areas of the world measurement campaigns aiming to test these hypotheses would be useful another area that would benefit the development of more robust co2 models is the ability to quantify reservoirs with negative diffusive co2 fluxes i e where reservoirs act as co2 sinks the logarithmic nature of our models is not well suited for this purpose while not common co2 uptake has been observed chanudet et al 2011 generally in eutrophic reservoirs although recent report shows that it can also occur periodically in oligotrophic conditions with very low organic carbon concentrations soued and prairie 2021 it also highlights that predicting co2 fluxes sustained by allochthonous input is paramount to the accurate estimation of the true co2 footprint of reservoirs a related limitation of the current g res version is the absence of an explicit carbon sedimentation component cases of persistent negative fluxes indicate reservoirs that necessarily accumulate carbon through sedimentation and burial recent measurements have shown that sediment carbon accumulation can be large in reservoirs mendonça et al 2014 2017 while the ensuing carbon accumulation cannot from a mass balance perspective be simply subtracted from the flux at the air water interface see prairie et al 2017 for details to obtain a net footprint there are circumstances in which a portion of the carbon burial can be construed as a new sink isidorova et al 2019 i e carbon burial that would not otherwise occur either at the reservoir site or further downstream there are currently too little data to estimate the portion of the carbon accumulation that can be rightfully considered a new sink but future versions of g res and other yet to be created reservoir ghg models should incorporate this pathway to offer a more complete representation of the reservoir ghg footprint another limitation of the current g res model is that new emission pathways are being identified but for which observations are too few and therefore difficult to generalize identified nearly two decades ago fearnside 2002 recent studies have suggested that ghg fluxes from drawdown zones can be important although highly variable because they depend in part on the carbon and moisture content of the exposed soil sediments marcé et al 2019 serça et al 2016 such emissions have been shown to be very high in some systems amorim et al 2019 given the paucity of literature on the subject the emissions from drawdown areas are not explicitly included in g res although assumed implicitly to be of same magnitude as surface flux since g res uses the maximum surface of the reservoir in the footprint calculations similarly assessments of degassing emissions have been largely confined to ch4 although co2 is known to be also emitted through this pathway however as additional data become available ghg emissions from these pathways should be modelled explicitly and integrated in future iterations of g res another improvement would be the incorporation of an explicit representation of the relationship between ghg emissions and trophic status recent analyses have reported strong positive correlations between ch4 emissions and lake trophic status both within single lakes across time and space grinham et al 2018 li et al 2018 and in multiple lake syntheses beaulieu et al 2019 deemer et al 2016 delsontro et al 2018 harrison et al 2017 a positive relationship between primary production and ch4 emissions makes sense as organic matter can stimulate ch4 production as an organic substrate for acetoclastic ch4 production and it can also foster the anaerobic conditions necessary for ch4 production and inhibit ch4 oxidation limited experimental work has also indicated a relationship between ch4 production and organic c quality west et al 2016 intriguingly recent work also shows that direct production of ch4 in oxic surface waters by cyanobacteria could strongly link primary production and ch4 emissions bižić et al 2020 although the importance of this process in controlling ch4 emissions is under debate günthel et al 2021 peeters and hofmann 2021 furthermore future emissions are likely to be sensitive to changes in organic c delivery bayer et al 2019 to date the absence of global scale information on chl a concentrations or trophic status has precluded the effective incorporation of such a driver in the global g res model however efforts are underway to develop such information and it may soon be possible to include such information in a global reservoir ghg model as eutrophication may often be linked to uas loading see 2 1 1 improving the incorporation of the relationship between ghg emissions and trophic state will also be useful for identifying the impact of uas lastly the net ghg footprint i e the difference in the ghg balance before and after impoundment currently relies on generic ch4 and co2 emissions factors from the ipcc for different land cover types in different climate zones application of our current approach to our modelling dataset suggests that while significant in areas where the flooded terrestrial landscape is rich in highly organic soils or if the flooded land has special characteristics leading to large fluxes of ghg the importance of the ghg balance of the pre flooding landscape is generally modest altering the median footprint by only 4 while a useful first order approach we fully acknowledge that further improvements will require a more explicit modelling approach to the ghg balance of the individual components of the terrestrial mosaic in place before flooding 5 conclusion the g res model framework proposes a novel integrative approach to the prediction of net ghg footprint from reservoirs whereby predictions include the local environmental conditions and physical configuration of each reservoir in a globally consistent predictive framework it allows for a quantification of relative contribution of various emission pathways of ch4 and co2 and how emissions of these gases change over time after impoundment accounting for temporal trends provides a means to assess its ghg footprint over the lifetime of reservoirs and also the estimation of the share of co2 emissions that are sustained by external organic inputs that would have occurred even in the absence of the reservoir the so called displaced emissions prairie et al 2018 the g res tool and associated models are freely available in a cloud based modelling portal that will allow the scientific community to further probe the past and future geography of carbon emissions from reservoirs by applying the framework to larger datasets than the one used to develop it the framework and its components will continue to evolve as new data become available that allow for the core models to be extended and improved as new information on reservoir functioning emerges and as users provide feedback and insight on its structure and components in a changing world where assessing ghg emissions of projects such as reservoir creation becomes standard practice such a tool will be essential for decision makers to quantitatively evaluate alternative projects in order to select those with the lowest possible environmental footprints the tool could also help in locating and designing new dams and their corresponding reservoirs in guiding the operation of existing reservoirs and in the potential retro fitting of existing hydropower plants and dams to reduce ghg emissions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the g res tool was developed with the financial support of the international hydropower association and from the worldbank special thanks to rikard liden richard taylor and mathis rogner for many discussions further funding to ytp was provided by the nserc discovery grant this is a contribution to the unesco chair in global environmental change funding to jah was provided by an nsf infews grant nsf ear1639458 a gril fellowship grant the cox visiting professorship fund at stanford university a u s army corps of engineers climate preparedness and resilience programs grant and a nsf deb grant 135211 appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105117 appendices a additionnal equations used a 1 air density kg m3 a i r d e n s i t y 101325 287 05 m e a n t e m p e r a t u r e o f t h e 4 w a r m e r m o n t h s 273 15 a 2 bottom temperature c if mean temperature of the colder month 1 4 b o t t o m t e m p e r a t u r e 0 656 m e a n t e m p e r a t u r e o f t h e c o l d e r m o n t h 10 7 if mean temperature of the colder month 1 4 b o t t o m t e m p e r a t u r e 0 2345 m e a n t e m p e r a t u r e o f t h e c o l d e r m o n t h 10 11 a 3 bottom water density kg m3 b o t t o m w a t e r d e n s i t y 1 b o t t o m t e m p e r a t u r e 288 9414 508929 2 b o t t o m t e m p e r a t u r e 68 12923 b o t t o m t e m p e r a t u r e 3 9863 2 1000 a 4 surface temperature c s u r f a c e t e m p e r a t u r e m e a n t e m p e r a t u r e o f t h e 4 w a r m e r m o n t h s a 5 surface water density kg m3 s u r f a c e w a t e r d e n s i t y 1 s u r f a c e t e m p e r a t u r e 288 9414 508929 2 s u r f a c e t e m p e r a t u r e 68 12923 s u r f a c e t e m p e r a t u r e 3 9863 2 1000 a 6 cd c d i f r e s e r v o i r m e a n w i n d s p e e d 5 0 001 0 000015 a 7 annual wind speed at 10m m s a n n u a l w i n d s p e e d a t 10 m r e s e r v o i r m e a n w i n d s p e e d a t x m 1 c d 0 5 0 4 l o g 10 10 x 1 x equal 50 m in our database a 8 reservoir volume km3 r e s e r v o i r v o l u m e r e s e r v o i r a r e a m e a n d e p t h 1000 a 9 reservoir area km2 r e s e r v o i r a r e a r e s e r v o i r v o l u m e m e a n d e p t h 1000 a 10 mean depth m m e a n d e p t h v o l u m e r e s e r v o i r a r e a 1000 a 11 thermocline depth m t h e r m o c l i n e d e p t h 2 0 c d a i r d e n s i t y a n n u a l w i n d s p e e d a t 10 m 2 9 80665 b o t t o m w a t e r d e n s i t y s u r f a c e w a t e r d e n s i t y r e s e r v o i r a r e a 1000000 gorham and boyce 1989 a 12 temperature correction coefficient ch4 to do for each month t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c h 4 10 t e m p e r a t u r e p e r m o n t h 0 052 0 052 is the slope of the temperature vs ch4 flux function in our database if temperature per month lower then 4 c use 4 c a 13 temperature correction coefficient co2 to do for each month t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c o 2 10 t e m p e r a t u r e p e r m o n t h 0 05 0 05 is the slope of the temperature vs co2 flux function in our database if temperature per month lower then 4 c use 4 c a 14 effective temperature ch4 c e f f e c t i v e t e m p e r a t u r e c h 4 l o g 10 a v e r a g e 12 m o n t h t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c h 4 0 052 0 052 is the slope of the temperature vs ch4 flux function in our database a 15 effective temperature co2 c e f f e c t i v e t e m p e r a t u r e c o 2 l o g 10 a v e r a g e 12 m o n t h t e m p e r a t u r e c o r r e c t i o n c o e f f i c i e n t c o 2 0 05 0 05 is the slope of the temperature vs co2 flux function in our database a 16 k600 k 600 0 24 2 51 1 48 a n n u a l w i n d s p e e d a t 10 m 2 0 39 a n n u a l w i n d s p e e d a t 10 m 2 l o g r e s e r v o i r a r e a vachon and prairie 2013 a 17 kh k h e x p 115 6477 6 1698 e f f e c t i v e t e m p e r a t u r e c h 4 273 15 100 155 5756 e f f e c t i v e t e m p e r a t u r e c h 4 273 15 100 65 2553 l n e f f e c t i v e t e m p e r a t u r e c h 4 273 15 100 1000 18 0153 lide 1994 a 18 pch4 p c h 4 10 1 46 0 03 e f f e c t i v e t e m p e r a t u r e c h 4 0 29 l o g r e s e r v o i r a r e a rasilo et al 2014 a 19 surface water ch4 concentration s u r f a c e w a t e r c h 4 c o n c e n t r a t i o n k h p c h 4 a 20 ch4 emission factor for water bodies kg ch4 ha yr c h 4 e m i s s i o n f a c t o r f o r w a t e r b o d i e s s u r f a c e w a t e r c h 4 c o n c e n t r a t i o n k 600 16 365 100 a 21 q bathymetric shape q b a t h y m e t r i c s h a p e m a x i m u m d e p t h m e a n d e p t h 1 a 22 littoral area l i t t o r a l a r e a 1 1 3 m a x i m u m d e p t h q b a t h y m e t r i c s h a p e 100 a 23 phosphorus load forest kg ha yr p h o s p h o r u s l o a d f a c t o r f o r e s t 10 0 914 l o g 10 c a t c h m e n t l a n d c o v e r f o r e s t 100 c a t c h m e n t a r e a 0 014 100 a 24 phosphorus load croplands kg ha yr p h o s p h o r u s l o a d f a c t o r c r o p l a n d s 10 1 818 l o g 10 c a t c h m e n t l a n d c o v e r c r o p l a n d s 100 c a t c h m e n t a r e a 0 227 100 a 25 population in the catchment person p o p u l a t i o n i n t h e c a t c h m e n t c a t c h m e n t a r e a p o p u l a t i o n d e n s i t y a 26 annual discharge mm yr a n n u a l d i s c h a r g e a n n u a l r u n o f f 0 001 c a t c h m e n t a r e a 1000000 31536000 a 27 water residence time wrt yrs w r t m e a n d e p t h r e s e r v o i r a r e a c a t c h m e n t a r e a a n n u a l r u n o f f 1000 a 28 river area before impoundment km2 r i v e r a r e a b e f o r e i m p o u n d m e n t r i v e r l e n g t h b e f o r e i m p o u n d m e n t 5 9 c a t c h m e n t a r e a 0 32 1000000 a 29 reservoir cumulative global horizontal radiance kwh m2 period if 40 latitude 40 r e s e r v o i r c u m u l a t i v e g l o b a l h o r i z o n t a l r a d i a n c e a v e r a g e 12 m o n t h r e s e r v o i r m e a n g l o b a l h o r i z o n t a l r a d i a n c e n u m b e r o f m o n t h o v e r 0 c if 40 latitude r e s e r v o i r c u m u l a t i v e g l o b a l h o r i z o n t a l r a d i a n c e a v e r a g e m a y j u n e j u l y a u g u s t s e p t e m b e r r e s e r v o i r m e a n g l o b a l h o r i z o n t a l r a d i a n c e n u m b e r o f m o n t h o v e r 0 c if 40 latitude r e s e r v o i r c u m u l a t i v e g l o b a l h o r i z o n t a l r a d i a n c e a v e r a g e n o v e m b e r d e c e m b e r j a n u a r y f e b r u a r y m a r c h r e s e r v o i r m e a n g l o b a l h o r i z o n t a l r a d i a n c e n u m b e r o f m o n t h o v e r 0 c 
25806,the freeware discoverframework provides new tools to build spatial and temporal data visualization applications accessible to stakeholders policy makers scientists and educators by focusing on environmental data and supporting applications accessible via laptops tablets and cell phones the discoverframework can be used to increase public awareness and inspire responsible use of complex environmental systems upon which human society depends discoverframework enables computer savvy domain scientists to develop interactive applications using elements and workflows defined to make visualization easy and address common problems such as spatio temporal scales and user engagement two applications are used to demonstrate discoverframework discoverwater and discoverhabs discoverwater uses map chart and text elements to relate streamflow changes to groundwater withdrawals discoverhabs uses the scenario element to aid stakeholders such as resource managers and users struggling to identify when and where harmful algal blooms habs are likely given that causal relations in these systems remain poorly understood keywords data visualization web application knowledge discovery water resources harmful algal blooms habs 1 introduction communicating with stakeholders about environmental resources is difficult even though their livelihoods broader human society and global economies depend upon the environment yet reducing destructive impacts on critical earth resources requires enhanced communication between stakeholders ranging from rural farmers to urban executives to policy makers elshall et al 2020 gleeson et al 2012 meinzen dick 2014 pierce et al 2016 sanderson and frey 2015 rich data are available in some parts of the world however data do not by themselves convey information and knowledge garcía et al 2015 yigitbasioglu and velcu 2012 despite the importance of many fields within earth science and looming difficulties posed by progressively diminishing resources current methods of using web page designs to bring earth science data to a popular audience rarely motivate good resource management this work seeks to enhance communication about environmental systems the goal is to improve engagement that leads to data based collaborative environmental decision making efforts important to scientists stakeholders societies businesses governments personal finances and local national and international economies the discoverframework seeks to motivate improved environmental stewardship by enabling greater access and understanding of data through new freeware based visualization strategies and foundational infrastructure freeware is important for the goals of accessibility transparency portability and flexibility the scientific and mathematical context produced by discoverframework applications can provide information and knowledge about underlying physical chemical and biological relations and correlations anthropological sociological public policy and economic context enabled through selection of discoverframework application content can provide information and knowledge about broad consequences of environmental concerns the discoverframework tools provide a mechanism to combine data with these contexts to create user friendly engaging interactive experiences for spatio temporal data to do this the discoverframework focuses on providing tools to reveal system trends correlations characteristics dynamics and broader context through well designed data presentation and resulting insights from visual analysis grainger et al 2016 yigitbasioglu and velcu 2012 to begin it is necessary to discover important spatio temporal data and download display and analyze it these steps often require advanced scientific and computer science knowledge caquard and fiset 2014 kehrer and hauser 2013 lienert et al 2009 rübel et al 2010 thus the data and the insights that data contain are largely inaccessible to most stakeholders the discoverframework fills this gap by taking advantage of recent approaches that support analysis and visualization of complex spatio temporal multivariate data sets lundblad and jern 2012 yang et al 2017 yigitbasioglu and velcu 2012 of most importance to discoverframework are 1 the widespread and ever increasing access to technologies such as laptops tablets and smart phones 2 expanding web access to public domain data sets on environmental systems 3 access to free cloud data storage 4 new web access and design ideas that enable increasingly comprehensive displays of data 5 increasingly robust free gis capabilities through qgis and 6 increasing ability to include interactive maps charts and communication between users in a single web page recently applied mostly in financial and news sectors discoverframework makes selected new developments readily accessible for environmental applications discoverframework supports creation of the modular web page elements shown in fig 1 which can be configured in many ways using one two or all three elements discoverframework provides the following 1 integrates multiple spatio temporal data sets coalescing data sets in this way captures multiple aspects of environmental systems and encourages questions about trends correlations and potential consequences of natural and anthropogenic impacts 2 interactive animations enable discoverframework users including scientists students policy makers and stakeholders to visualize and investigate spatial and temporal correlations 3 visual analysis drives qualitative measures and correlations 4 a potentially user driven significant events list identifies trends and interdependencies in environmental applications these often suggest anthropogenic and climate impacts help to create a cohesive picture of the environmental system and identify where to focus development and conservation efforts this article describes the discoverframework design concept elements and typical application workflows discoverframework is demonstrated using two applications discoverwater and discoverhabs the following subsections describe how discoverframework uses and fits in with 1 the current state of cyber infrastructure 2 data discovery and processing 3 visualization and animation methods and 4 applications and dashboards for earth science 1 1 cyberinfrastructure the discoverframework includes display techniques enabled by hypertext markup language html hypertext preprocessor php cascading style sheet css and javascript application programming interfaces apis html provides the framework for content display css provides advanced styling and formatting javascript allows users to interact with the website and asynchronous javascript and xml ajax acts as a bridge as it communicates with servers for the transfer of information such as data in javascript object notation json formatted files caquard and fiset 2014 rübel et al 2010 there are numerous open source apis written in these languages and it is often necessary to use a combination of capabilities from different apis caquard and fiset 2014 kirk 2018 the approach taken in this work this allows discoverframework to remain adaptable and leverage the many computing technologies already available without needing to invest in expensive servers or high performance computing centers 1 2 data discovery procurement and processing there are challenges associated with existing methods to discover procure and process data in many fields of science these challenges include avoiding bottlenecks and resulting delays in data transfer cumbersome decoding steps using various markup languages li et al 2015 and advanced scripting to implement automated data mining and preprocessing algorithms garcía et al 2015 attempts to make data access easier are being actively pursued in several ways including the following examples from hydrology the consortium of universities for the advancement of the hydrological sciences inc cuahsi sequentially produced hydrodesktop https hydrodesktop codeplex com ames et al 2012 hydroclient crawley et al 2017 and hydroshare https data cuahsi org hydroshare combines web services and an interactive graphical user interface gui accessed via a web interface hydroshare provides a map element to search multiple data sets by location and variable type this capability will be needed for discoverframework to allow the end user to control the location for which data is displayed cuahsi s waterml zaslavsky et al 2007 is a type of extensive markup language xml specifically designed for dynamic data exchange of hydrological time series data such as network common data format netcdf data arrays following geographic markup language gml encoding rules palmer 2012 the open geospatial consortium ogc is working toward making waterml the universal standard for hydrological data this advance makes it easier to use data in tools such as discoverframework the united states geological survey usgs statistics web service u s geological survey 2020a uses representational state transfer rest to generate a static link with defined parameters that returns a table of daily monthly or annual statistics for streamflow and groundwater level data directly from the usgs national water information system nwis database u s geological survey 2020b discoverframework is compatible with rest services the discoverframework version 1 described in this work emphasizes the design of the display and interactive capabilities for the case studies shown in section 3 data were manually downloaded to be used in the case study demonstrations 1 3 visualization and animation the prevalence of internet access and mobile devices has revolutionized geographic information systems gis promoting web enabled geo visualizations the advent of cloud computing facilitates incorporating spatio temporal analysis of remotely sensed data provides a new platform for expressing various approaches to visualization interaction and analysis of scientific data of complex earth systems kehrer and hauser 2013 tulbure et al 2016 the move to web based geo visualization enables a visualized narrative for communicating spatio temporal characteristics of multiple data sets and is essential for making comparisons between data sets scientific analyses and popular comprehension of how complex natural systems change over time require the ability to see when and where the change occurs by viewing time series data in continuous succession rather than as static events or snapshots caquard and fiset 2014 kehrer and hauser 2013 rübel et al 2010 the implementation of many different visualization strategies is essential to interpret data seamlessly and effectively while embodying the greater context dong et al 2012 grainger et al 2016 kehrer and hauser 2013 yigitbasioglu and velcu 2012 problems with existing strategies include 1 statistical or dimensionality reduction to reduce data set size which reduces resolution 2 cluttering of multiple variables can result in crowded displays and reduced comprehension and 3 occlusion and bottlenecking of bandwidth and computing power to process multiple large spatio temporal data sets chrisman 1999 kehrer and hauser 2013 kirk 2018 rübel et al 2010 these technological challenges can be seen in many earth science visualization examples of maps that classify measured data with varying symbology and color of vectors in looped animations of static images the usgs water watch tool https waterwatch usgs gov index php id ww animation real uses a color indicator to illustrate relative daily average streamflow conditions at stream gage stations with 30 years or more of recorded measurements stream gages are shown as points to reduce occlusion and only one month of daily average data is animated on a loop of a series of static images for each day the interactive user experience is limited to the user choosing which month is displayed the 10 day forecast 6 hr interval arcgis online map https www arcgis com home webmap viewer html webmap 8890035d5add40858335f402864df457 from the national water center 2016 shows a looped animation of the forecasted stream flows across the contiguous united states as time advances on a looped playback the quantity of streamflow expected in the stream is depicted by changing the width of the line representing stream segments and the amount of streamflow relative to historic flow is depicted by changing the color of the stream segments the playback loop is predetermined no user interaction is supported geo visualization has lacked support for interactive animation and effective methods for spatially and temporally displaying multiple heterogeneous data sets common concerns around spatio temporal animations include motion distracting the user s attention poor retention lack of clear visual expression of information e g smoothness and user interface issues hindering animation johnson and nelson 1998 lienert et al 2009 rana and dykes 2003 map displays integrated with chart tools produce a multidimensional spatio temporal display for interactive data exploration brendel et al 2019 lundblad and jern 2012 rübel et al 2010 yigitbasioglu and velcu 2012 deltares aqua monitor https www aqua monitor appspot com donchyts et al 2016 web app runs on the cloud computing power of google earth engine real time computations from global landsat imagery to detect increases and decreases in the water present from raster image to raster image represented in high contrast colors as land and water changes while foregoing true animation users have increased interaction with the static raster images at the user s chosen location using a time slider to advance through 30 years of remote sensed data and a transparency slider to compare the transformation of the landscape over time the usgs california drought viz https labs waterdata usgs gov visualizations ca drought index html combines two different types of data u s drought monitor andmeasured reservoir storage charts overlay the map and change with the map data as the user changes the time frame by scrolling the mouse even with limited user interaction this application demonstrates how cluttering and user distractibility can quickly become a challenge when multiple variables are displayed with charts and maps while important advances these efforts show the challenges in displaying data effectively for interpretation of heterogeneous earth systems compromises are often made to address temporal animation multi variate relationships simultaneous map and chart representations of data and user interaction discoverframework is unique in the level of user interaction through animated charts and maps and question driven approach to supporting multivariate data organized in a dashboard interface 1 4 applications and dashboards for earth science holistic data exploration apps geared towards data analysis and decision support have been developed using dashboard interfaces four of these apps most applicable to the discoverframework are described here the nsf funded web app flyover country myrbo et al 2015 supports several basemap options and downloads a recent geologic map and data from wikipedia and selected other sites to provide geologic information within a spatial context for people traveling by foot bike car boat and plane no time dependence of the geologic and environmental variables is supported the stream hydrology and rainfall knowledge system sharks web app allows users to retrieve data for multiple variables and view interactive plots aimed at curating data for decision support brendel et al 2019 the sharks app implements a tab based navigation panel where one panel is for maps one for time series charts and so on the lack of integration of spatial and temporal components may inhibit decision makers from gleaning the necessary information they need yigitbasioglu and velcu 2012 watershed restoration using spatio temporal optimization of resources wrestore web app aims to optimize decision support to improve environmental conservation efforts babbar sebens et al 2015 unlike the browser run discoverframework wrestore runs on a high performance computer and requires users to create an account to login which limits access the usgs national climate change viewer nccv uses a web based dashboard interface to combine spatial data temporal data and statistics with the goal of easily visualizing and summarizing climate data alder and hostetler 2015 discoverframework provides temporal analysis unlike flyover country it integrates spatial and temporal aspects within one web page unlike the sharks visualizations it differs from nccv and wrestore by emphasizing simultaneous display of multiple spatio temporal data sets and providing an adaptive storytelling data dashboard lundblad and jern 2012 yigitbasioglu and velcu 2012 2 methods discoverframework workflows and toolkit elements of the discoverframework toolkit from fig 1 are shown again in fig 2 placed in the context of a typical workflow there are four main steps in the workflow 1 prepare data for use with the toolkit through data acquisition and processing 2 render the interactive maps and charts using display techniques 3 identify correlations using domain supported knowledge and 4 develop a given application using workflow tools selected aspects of spatio temporal scaling are covered as examples in section 3 2 1 data acquisition and processing this version of discoverframework accommodates a variety of data types and sources this section discusses the data sources and temporal and spatial data processing and formatting so that the data is compatible for use in the discoverframework toolkit 2 1 1 data sources in most fields for which data are acquired programs have been developed for data discovery and download for example hydroclient has been developed to access selected hydrological data bases and earthcube s data discovery studio that indexes over 1 6 million data sets across scientific disciplines for discoverframework toolkit compatibility the source data need to have a timestamp spatial reference and be organized in a table format once in table format the data need to be reformatted as one to many json arrays one json file per chart see fig 2 for some data sources data can also be directly accessed from structured query language sql databases or public databases using rest services additional customized coding is required when using sql and rest services to process and format the data retrieved as each data source has nuances in formatting and retrieval method private data or model results can be processed using spreadsheet software or customized coding tailored to the data set challenges with timestamp formatting and file handling in this work shaped strategies for file formatting python or r code can be written to retrieve and process data but some data sets may require additional manual processing using spreadsheet software for the discoverwater and discoverhabs applications presented in section 3 the data downloads were conducted via a process with sql and rest using rstudio in combination with libreoffice calc version 5 3 4 the document foundation 2020 which is an open source spreadsheet software 2 1 2 temporal data processing and formatting in general comparative data analysis is constrained by the length of available historical records pyrce 2004 tharme 2003 the data sets attributes need to be normalized to defined spatial and temporal scales garcía et al 2015 to facilitate comparisons between data sets whether converting from csv a web service sql database or other source the data are arranged as an array composed of lines such as yyyy mm value yyyy mm value this array format is important to index operations in discoverframework elements this in turn improves load time of the website discoverframework supports higher resolution temporal scales such as for data sets containing daily or hourly data as discussed in section 3 programming languages such as python or r can be used to retrieve process and format data for use with discoverframework 2 1 3 spatial data processing and formatting qgis the leading open source gis freeware qgis 2020 is used to create custom shapefiles and export them as geojson files a common type of json file designed for web mapping discoverframework elements run on geographic web mapping apis that process geographic information as a geojson file for example in the discoverwater application for a portion of the arkansas river in kansas the csv files containing latitude longitude time and data are pre processed using libreoffice calc as explained in section 2 1 2 these are imported into qgis as a point using the longitude and latitude of the gage station then exported as a geojson file saved to local storage errors such as numbers being read as strings by gis software which leads to inoperable animation and numerical data driven formatting are eliminated by imposing uniform formatting of timestamps of data for csv files the shapefiles for county boundaries and the high plains aquifer were downloaded from the kansas data access and services center kansas geological survey 2020a imported into qgis and exported as geojson files 2 2 display techniques the php html and json files for the website can be stored using a free web hosting control panel such as x10hosting 5gbfree or freehostia discoverframework is hosted under the university of kansas subscription to the commercial hosting software cpanel cpanel inc 2020 the discoverframework is a php file that serves as an index page that loads when the discoverframework application website is visited php is used to retrieve the html files for discoverframework element 1 map and discoverframework element 2 charts so that they are displayed according the layout in fig 1 element 2 calls the json files from the cpanel file manager and parses them using jquery version 3 5 1 the jquery foundation 2020 once the json file is parsed it is ready to be displayed using javascript apis described in section 2 2 1 the geojson files are uploaded to mapboxstudio mapbox 2020a element 1 uses javascript apis described in section 2 2 2 to display the geojson files there are numerous open source web mapping and data visualization javascript apis available discoverframework elements use mapbox and highcharts apis to generate elements 1 and 2 respectively in fig 1 2 2 1 mapbox for geo visualization highcharts and its complimentary mapping library highmaps version 5 0 12 highsoft as 2020 have the potential to develop and seamlessly integrate both the map element 1 and charts element 2 of the display highmaps and qgis when investigated 2015 2016 were not found to be robust enough to animate time series spatial data interactively mapbox had this capability and was chosen for use in discoverframework mapbox is comprised of mapbox studio mapbox 2020a a web based gui for designing and building basic maps and mapbox gl js mapbox 2020b a javascript library for advanced development the map component element 1 of the discoverframework figs 1 and 2 is powered by the mapbox hybrid development platform using mapbox studio and mapbox gl js version 1 12 0 time series data plotted on the map is controlled by a time slider as the user slides the bar the colors of the geojson objects on the map change to reflect the value at that time the time slider in element 1 will simultaneously control the synchronized cursors on the charts in element 2 the synchronized cursors on the charts can be operated independently of the time slider on the map moving the time slider on the map always moves the synchronized cursors on the charts this was accomplished using html code to link the mapbox and highcharts apis by user input 2 2 2 highcharts for synchronized time series graphs the interactive aesthetically effective charts of discoverframework element 2 is powered by highcharts version 8 2 0 highsoft as 2020 because of its robust library ease of use and in line javascript formatting data driven formatting can be implemented in using highcharts zones capability to assign different colors to the data based on whether a value is greater than or less than the qualifying criteria such as percentile there is at least one json data set per chart and each chart has a designated html container discover framework element 2 supports multiple data sets per chart using the secondary y axis options of highcharts and can be enabled by removing comment notation around the block of code such as in the discoverhabs application these charts are wrapped within one main html container to allow cursors to be synchronized across all four charts when the mouse hovers over the plot on any chart the markers are highlighted as the user slides the mouse or their finger across the charts they see a vertical line synchronized with respect to the x axis temporally connecting all four time series data sets so that they are viewed collectively yigitbasioglu and velcu 2012 the highlighted values are displayed in a fixed position tooltip at the top right of each chart an example is provided in section 3 3 1 environmental problems are complex and often there are more than four variables involved using the framework described above scenarios can be created grainger et al 2016 this is demonstrated in section 3 where it is used to show the interactions between different combinations of variables and model simulations to address a defined set of questions 2 3 domain specific knowledge expected relationships between data sets can be determined by domain specific knowledge discoverframework supports developing and communicating knowledge through descriptive statistics for each plot and manual entry of story like narratives into element 3 element 3 is an html container which gives it the flexibility for a wide variety of uses and the ability to add tools such as a comment section to engage in a two way conversation between app users and scientists babbar sebens et al 2015 further development of this element of the discoverframework is discussed in section 3 2 4 develop applications using the discoverframework starting with the discoverframework code sample files and documentation available on github scientists can develop their own discover applications the data sourcing code will generally need to be edited to connect to databases data sets produced by other web services model results and other data sources each data set is stored in a unique data variable used by discoverframework element 1 and element 2 fig 1 the first data source read by the code will be stored in the variable data1 the second data source will be stored as data2 and so on it is important to have metadata related to the data source and the data displayed discoverframework code includes some custom options for this metadata within the javascript code for each chart or using a custom css for advanced formatting control for example element 1 allows developers to add custom titles to charts so that data set names can be audience specific the web app can be published using a free account with a web or file hosting service such as those mentioned in section 2 2 discoverframework developers need a free mapbox studio account and access to the mapbox gl js and highcharts library documentation api code can be download from their respective websites both mapbox and highcharts are ported from an api repository like cloudflare or github mapbox provides considerable free access to get developers started with a large limit on the number of monthly map loads see terms defined on the mapbox website highcharts is free for non profit use and which encompasses education and government there are premium pricing plans for commercial developers there are currently no use limits on charts 3 addressing selected application challenges using discoverframework ways in which discoverframework addresses three challenges are presented using two applications discoverwater and discoverhabs the challenges are 1 data sources and scales 2 display of multi variate data and 3 data presentation design and evaluation of user engagement discoverwater uses the discoverframework to visualize spatial and temporal changes in streamflow and related anthropomorphic and natural environmental variables discoverhabs uses the discoverframework scenario capability to combine data from high frequency hourly sensors laboratory analysis and model results for analyses and prediction of harmful algal blooms habs 3 1 data sources and spatio temporal scales a major step in creating environmental applications is managing data sources metadata and the spatio temporal scales for each data set so that they can work together across different formats discoverwater uses data sources from multiple institutions whereas discoverhabs uses multiple parameters from one data source data source metadata are determined by the institution hosting the data metadata such as names are often not useful to a non scientific audience and alternatives can be advantageous temporal scales vary between hours to years in the data for the applications shown discoverframework uses a defined mutual temporal scale to plot data in a way that helps users identify correlations spatial scales vary between points to zonal polygons in the applications considered discoverframework uses a defined mutual spatial scale to develop maps scientists define these temporal and spatial scales to make them mutual for facilitating identification of trends in the relevant context being investigated the ability of the discoverframework to support qualitative spatio temporal trend analysis within or initiated through the discoverwater map element 1 is demonstrated using color dots representing stream gage stations along the river change color to show changes in streamflow values from october of each year are shown because this dry time of year is dominated by groundwater interactions the variability of all monthly values obscures evaluation of system dynamics dominated by wet and dry years the ability of discoverframework to manage numerous variables and unknown causal relations is demonstrated through select scenarios in discoverhabs discoverhabs presents an example from cheney reservoir dam outside of wichita kansas cheney reservoir has one of the most complete and longest continuous high frequency water quality data sets for a reservoir system and also uses results from probability models for taste odor compounds and the cyanotoxin microcystin developed by the usgs harris and graham 2017 3 1 1 hydrologic data sources and scales in discoverwater discoverwater is demonstrated using data from the high plains aquifer hpa in kansas listed in table 1 showing both the data set name and corresponding name that appears as the chart title data names can vary based on source this is handled by providing an ontological map to pair the given data set name to an audience friendly chart title discoverwater data types visualized include streamflow groundwater level irrigation and climate and each one is displayed on a separate chart file sizes range from 13 to 17 kb the desired timeframe extends back to at least 1950 which is before the hpa was developed for large scale irrigation buchanan et al 2015 data are filtered so only data in and after 1950 are used the temporal range of the data sets in table 1 differs this is handled by using a select time range and reclassifying missing values in the time series as null to preserve indexing the temporal resolution of the data sets is monthly or annual this is handled by repeating the yearly value over 12 months to create a monthly time step streamflow data sets are local and limited to stream gage stations long term stream gage stations appear as large black dots with a white outline on the map using discoverframework element 1 fig 3 other stream gage stations along the arkansas river have less complete data sets and appear as small black dots without an outline web users click on the dots with white outlines to activate the dot and its color is controlled by the time slider of element 1 monthly data for the active dot is plotted in the charts using discoverframework element 2 annual average groundwater level is the depth to water from the surface averaged for the year over the wells in a given county the lower temporal resolution annual data set is left joined to the higher temporal resolution monthly data set the values from the monthly data set are dropped so that the resulting dataframe consists of the monthly timestamps and the annual values which are repeated for each month of the year this procedure serves two purposes 1 it aligns the monthly and annual temporal scales and 2 it facilitates indexing and synchronizing the data sets when plotted groundwater level values are from kansas geological survey kgs synoptic measurement campaigns from january of each year for each county groundwater levels are arithmetically averaged by the kgs to obtain the county representative value the number of wells per county in kansas vary from 26 to 2377 most of the wells are used for irrigation and sampling and are well distributed over the area of the high plains and alluvial aquifers this is important for two reasons 1 values more typical of regional conditions are represented and 2 the average annual groundwater level data and average annual pumping data are applied to all stations within the county irrigation data is the total annual water used by wells designated for irrigation in the county in kansas values are submitted annually by all water right holders for each county water use reporting began in the late 1950s and became fully mandated in the 1990s kansas geological survey 2020b counties in kansas are similar in size providing a useful spatial definition for the purposes of this work counties are shown in fig 3 county based values for groundwater levels and irrigation work well in kansas because counties are similar in size this spatial representation is thus useful for the purposes of discoverwater different spatial representations are used for other variables as needed the monthly palmer drought severity index pdsi is a monthly or annual index for identifying the intensity of wet and dry periods based on current weather plus cumulative patterns of previous months noaa national centers for environmental information 2020 values are derived from the global historical climatology network daily ghcn daily temperature and precipitation station data as well from several different additional networks pdsi data are reported for 344 climate divisions nationally climate divisions of interest in this work are listed in table 1 and the monthly resolution pdsi data set was used climate divisions span several counties as shown in fig 3 pdsi values apply to all gage stations within a climate division 3 1 2 biogeochemical data sources and scales in discoverhabs the data set included in discoverhabs was routinely collected by the usgs at a single sampling site near the water intake at cheney reservoir dam fig 4 since april 2001 providing more than 20 years of measurements basic water quality data shown in table 2 including water temperature dissolved oxygen conductivity ph turbidity chlorophyll pigment fluorescence total algal concentrations and phycocyanin pigment fluorescence i e cyanobacteria concentrations was collected using high frequency sensors at 1 m of depth throughout the collection period sensors collected data at 1 h intervals throughout the time period resulting in an 11 000 kb database geosmin and microcystin probability were calculated for each timestamp using logistic regression models and trained with data collected by the sensors graham et al 2017 concurrent and additional discrete water quality data shown in table 3 were also collected at weekly bi weekly or monthly time intervals at the same sampling site collected data includes wind direction total dissolved nitrogen total dissolved phosphorus total dissolved solids total geosmin taste odor compound and total microcystin cyanotoxin the high frequency data discrete data and real time model results were aggregated into a database totaling 26 500 kb data from table 2 appear as a continuous line of time series data data from table 3 appear as discrete points where the sampling date aligns with the timestamp of data from table 2 variables displayed in discoverhabs were chosen by their variable importance based on model sensitivity results graham et al 2017 harris and graham 2017 the data collection was primarily focused on detecting harmful or nuisance cyanobacterial blooms known as cyanobacterial harmful algal blooms cyanohabs cyanohabs are driven by a complex set of physical chemical and biological factors making outbreaks difficult to predict and understand thus the purpose of the hab related discoverframework application is to allow users to input and test scenarios using previously collected data for this application a scenario feature of the discoverframework allows users to explore data combinations designed to reveal how environmental and biogeochemical variables relate to the probability that a cyanohab will occur and create harmful or nuisance compounds 3 2 multivariate data presentation presenting multivariate data using different formatting options and arrangements helps users glean information about the data from a glance complex variables may require data driven formatting to help distinguish ranges of values that may impact the user of discoverwater and discoverhabs 3 2 1 hydrologic variables in discoverwater the discoverframework supports data driven formatting which can be used to improve user understanding of data significance in discoverwater two types of data are formatted based on the value of the data pdsi to highlight wet and dry periods and streamflow to categorize the wide range of flow values shown in fig 5 the other two data types irrigation pumping and groundwater levels are given a single distinct color for all values this is illustrated in the example of the discoverwater charts in fig 6 for pdsi values greater than 0 are shaded blue and identify wet periods values less than 0 are shaded red and identify dry periods the degree of saturation of the color corresponds to the severity of the drought or wet period i e bright red is a severe drought whereas light red is a less severe drought the national center for atmospheric research ncar classifies above 4 0 as an extremely moist spell and below 4 0 as an extreme drought dai and national center for atmospheric research staff 2019 streamflow is classified by percentile of historical flow following the same method currently used for the usgs waterwatch maps u s geological survey 2020c the dark blue extreme flow classification denotes very high stream flows statistical outliers such as these are calculated from the interquartile range of the data set as defined by tukey s upper fence q 3 1 5 q 3 q 1 tukey 1977 where q1 is the 25th percentile and q3 is the 75th percentile the monthly average streamflow data derived for each gage station are normalized to the historic record at that station percentiles serve as break points to determine the color assigned to each data point within that percentile range the color scale shown in fig 5 is a useful classification approach for direct streamflow visualization kehrer and hauser 2013 the colors of fig 5 are used in two ways in streamflow time series charts and to color dots that locate gaging stations on the map 3 2 2 harmful algal bacteria variables in discoverhabs in discoverhabs cyanobacterial abundance is colored using data driven formatting corresponding to the alert levels determined by the kansas department of health and environment kdhe mosier 2015 observed microcystin was colored using the advisory values established by the environmental protection agency epa and the kdhe observed geosmin was colored using the minimum human detection level of 5 ng l the highest analytical limit of detection in the data set and the concentration at which humans start to smell the compound microcystin and geosmin probability are colored using the threshold probability for positive classification tppc for the corresponding model values above the 0 43 tppc for microcystin indicate the probability that microcystin will occur at or exceed the 0 1 μg l analytical detection threshold which denotes a cyanotoxin event values above the 0 41 tppc for geosmin indicate the probability that geosmin will occur at or exceed the 5 ng l human detection threshold which denotes a taste and odor event graham et al 2017 events of either compound tangibly mean that drinking water sourced from the reservoir requires more advance treatment before being finished for public consumption otten et al 2016 all other data sets that do not have specific alert levels were given a unique color affiliated with how the variable is perceived i e grey for dissolved oxygen brown for turbidity teal for nitrogen 3 3 presentation and user engagement the number of variables to show the order the variables appear and the type of axis used help present relevant information without overwhelming the user presentation of data helps it tell its story by engaging users and make insights accessible 3 3 1 hydrologic insights from discoverwater three selected insights provided by the discoverwater application are presented to illustrate the power of the approach taken the discoverwater example in fig 6 shows that floods and storm events or droughts heavily influence streamflow and groundwater level as time progresses from past to present in the high plains aquifer hpa system groundwater depletion caused by irrigation is reflected by increased frequency of low streamflows as lower percentile colors for flow occur more frequently after large scale pumping starts fig 6 provides a clear example of the kind of insight the data selection and design in discoverwater can achieve at the syracuse gage station october 1953 fig 6a was during the worst drought on record the arkansas river streamflow decreased to 27 4 ft3 s 0 78 m3 s in the yellow 10 25 range groundwater declined to 39 3 ft 12 m below the surface 14 ft 4 3 m deeper than the preceding year this shows that declines in streamflow and groundwater level within the hpa occur naturally during the driest period on record which occurred prior to major pumping in the county surrounding the syracuse gage station pumping of groundwater to serve irrigation became significant in the 1960s and increased rapidly through mid 1980s declines in streamflow and groundwater level are even greater due to over allocation of groundwater haacker et al 2016 october 1973 fig 6b was in the middle of a very wet period with a pdsi of 5 5 streamflow was normal in the 25 75 range but groundwater level in the aquifer did not increase this highlights how the presence of streamflow can create a false sense of water abundance masking the impacts on the aquifer as elevated pumping of the aquifer impedes natural recovery of the aquifer during wet periods butler et al 2018 lower streamflows occur during droughts that were much less severe than the 1950 s drought fig 6a such as those of the late the 1970 s figs 6b 2002 fig 6c and 2011 fig 6d in these less severe droughts streamflow drastically declined to much lower flows in the red 10 range fig 6d shows october 2011 during a moderate drought with a pdsi of 3 7 the aquifer was pumped at an average of 72 ft3 s 2 m3 s throughout the year streamflow was barely flowing at 0 5 ft3 s 0 01 m3 s and groundwater was 73 2 ft 22 3 m below the surface before dropping to 94 5 ft 28 5 m the following year pumping the aquifer during a moderate drought has a larger impact on streamflow and groundwater declines than a severe drought before the aquifer was heavily pumped for irrigation ou et al 2018 salem et al 2018 in summary discoverwater uses the discoverframework to integrate streamflow groundwater pumping groundwater levels and palmer drought severity index data sets it is demonstrated using a major agricultural center that produces food for the nation in an arid region of the hpa in western kansas discoverwater shows how groundwater supported irrigation has caused a progressive decrease in streamflow over time in the arkansas river flows during drought conditions decreased from 7 ft3 s in november 1956 at the end of the 1950s drought of record to 0 04 ft3 s in august 2013 during the most recent less severe drought it also shows how a predominantly wet period obscured the effect of irrigation for 20 years from 1983 to 2003 the discoverwater charts allows the user to focus on many other inter and intra data set relationships 3 3 2 water quality inquiry from discoverhabs a complex set of environmental factors cause cyanohabs to occur different sets of data can be used to evaluate different process ideas a list of all the scenarios available from discoverhabs is provided in table 4 as an example scenario 1 of discoverhabs is chosen to address specific scientific questions using data only from the year 2012 because of the presence of a bloom event 3 3 2 1 scenario 1 are physical variables correlated to increases in cyanobacteria population changes fig 7 shows scenario 1 consisting of cyanobacteria reservoir elevation average daily precipitation and water temperature from table 2 the cyanobacteria chart shows the time specific cell count per ml present in the reservoir a spike in cyanobacteria cells on july 6 through july 9 2012 indicates a bloom occurred this bloom was not large enough to require in lake mitigation as indicated by the green color the environmental conditions preceding the bloom may help determine the proximal causes relatively high water temperatures possibly connected to lower than average reservoir elevation or water level can help spur cyanohabs huisman et al 2018 the reservoir elevation in scenario 1 has been declining since the end of may but it is not at its lowest point yet suggesting other factors are contributing to the bloom as the last precipitation event was july 21 this long stretch without precipitation leaves the reservoir undisturbed and prone to evaporation so cells can grow and could favor a bloom by concentrating nutrients the temperature plot shows temperatures above 27 c which increases the likelihood for a cyanohab in cheney reservoir harris and graham 2017 3 3 2 2 scenarios using 14 years of data challenge of large data high temporal resolution scenarios using the entire 14 year data record instead of just one year 2012 were attempted as well but were met with technical obstacles each of the four charts consisting of 220 000 data points meant the browser had to load 880 000 data points the browser was slow to load the data and was slow to respond to user input when the synchronizer was moved the highcharts boost module provided the capability to load the full data sets quickly in the browser however it resulted in the loss in functionality of the synchronized cursor and zoned coloring for geosmin and microcystin probability these are among the most impactful of the technology limitations encountered the combination of discrete measurements high frequency hourly data and developed probability models provide water managers with data visualizations of the information needed to justify implementation of expensive treatment methods to remove taste odor compounds from drinking water or when to close a reservoir for recreational use due to elevated toxins overall an implementation of the discoverhabs application to other reservoirs may help determine why blooms have dramatically increased since the 2000s in some kansas reservoirs harris et al 2020a 2020b 3 3 3 evaluating user engagement user engagement has been evaluated using a combination of website traffic data from google analytics and responses from an assignment given to an undergraduate introductory geology class google analytics has been collecting website traffic data since november 4 2018 fig 8 shows the audience overview data provided by the google analytics dashboard throughout this time there have been 527 unique users to the site from 10 different countries and 13 1 of new users return to the site users spend an average of 3 min when they visit the site 87 5 of users visit discoverwater with their desktop browser 12 with their mobile device browser and 0 5 with a tablet browser this may indicate a need to improve the mobile and tablet interfaces an undergraduate introductory geology class consisting of primarily freshmen and sophomores with little prior knowledge about hydrogeology was given an assignment to use discoverwater to answer six questions listed in table 5 responses are used here to evaluate how well discoverwater conveyed intended information of the students enrolled in the course that semester 98 submitted the assignment summarizes correct responses from students for each question and how they performed on the assignment overall on average students got 3 out of the six questions correct questions were designed to see if students could perform non interpretive tasks such as data query and interpretive tasks such as inferring cause and effect inferences discussed in section 3 3 1 are related to questions 4 6 correct answers did not require exact wording for example for question 5 comments such as combined impact of climate and irrigation or that ground water is no longer dependent on streamflow due to new irrigation and pumping technology were counted as correct student performance has been used to guide improvements in discoverwater it has also been used to redesign the assignment to improve measurement of engagement and knowledge transfer 4 conclusions the ways in which discoverframework expands what is possible through freeware data visualization is demonstrated using data from groundwater depletion and harmful algal blooms the examples illustrate design concepts from other fields such as news media and business presentations to increase the dimensionality of data displays here the simultaneous display of a map time series and multiple variables is new to environmental science and the field of hydrology we expect this advance to enable users to relate many aspects of actual systems including space time and spatio temporal variables and provides important insights more quickly than other visualization designs analytical features such as evaluating multiple data sets using machine learning and artificial intelligence would provide additional information to be displayed and could include other relevant data such as associated metadata discoverframework is a customizable framework and the limit lies within what is technologically possible there is a vast potential of features that can be developed for the discoverframework that will improve the user experience so that interacting with complex data can be streamlined and more intuitive two applications of discoverframework are used to address water and harmful algal bloom questions communicating and understanding human influence on environmental systems requires seeing the big picture of how different human and natural components interact and affect each other this is accomplished by developing a visualization template able to bring together interrelated data sets with long historical records for the discoverwater implementation discussed in this work groundwater level streamflow climate and water use for irrigation are combined into a synchronized interactive visualization comparisons are made from the period of pre agricultural irrigation groundwater withdrawal to present time through data driven visualization methods the dynamic map and charts allow for analyses to be made on various temporal scales from across historical record to a select season and spatial scales from individual gage stations to the entire arkansas river discoverwater shows users the spatial and temporal variability of the groundwater and surface water as well as the intricate dynamics between pumping for irrigation and climates for the discoverhabs implementation discussed in this work scenarios of different combinations of variables allow a visual investigation into selected questions about the causes of blooms and associated geosmin and microcystin events some scenarios present a visually clear connection whereas others show the knowledge gaps that remain these gaps in turn cause less than desired model performance for the nuisance and toxic compounds that disrupt drinking water treatment facilities discoverframework challenges freeware developers database managers and scientists to fill in identified gaps gaps identified in this work are 1 interactive animation of multivariate spatial data section 2 2 1 2 representing discrete vs continuous data section 3 2 and 3 speed of data processing section 3 3 scenarios using 14 years of data there is also a need for 4 improved automated data retrieval and interoperability to reduce the time spent manually preprocessing data current data retrieval technologies for many of the data sets involved make it difficult to accomplish the anticipated ability of element 2 in which the map window could be moved to a new location future functionality depends on data that follow fair principles for scientific data management https go fair org fair principles and are stored in established data repositories that can be accessed with apis these improvements and evolving technological advances will provide an even more dynamic and intuitive experience for users through comprehensive displays such as those supported by the discoverframework software availability the discoverframework github repository is available at https github com mistyblue17 discoverframework v1 2 the discoverwater web interface is available at https interactiveviz ku edu discoverwater the discoverhabs web interface is available at http interactiveviz ku edu discoverhabs cheney scenario1 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we greatly acknowledge funding from the university of kansas research excellence grant ref 2017 18 and the u s geological survey powell center grant g20ac00197 the authors acknowledge significant contributions from the national science foundation earthcube program and is geo rcn contributions to the code from matthew garret of the university of kansas and michael gloystein of spotx are much appreciated appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105104 
25806,the freeware discoverframework provides new tools to build spatial and temporal data visualization applications accessible to stakeholders policy makers scientists and educators by focusing on environmental data and supporting applications accessible via laptops tablets and cell phones the discoverframework can be used to increase public awareness and inspire responsible use of complex environmental systems upon which human society depends discoverframework enables computer savvy domain scientists to develop interactive applications using elements and workflows defined to make visualization easy and address common problems such as spatio temporal scales and user engagement two applications are used to demonstrate discoverframework discoverwater and discoverhabs discoverwater uses map chart and text elements to relate streamflow changes to groundwater withdrawals discoverhabs uses the scenario element to aid stakeholders such as resource managers and users struggling to identify when and where harmful algal blooms habs are likely given that causal relations in these systems remain poorly understood keywords data visualization web application knowledge discovery water resources harmful algal blooms habs 1 introduction communicating with stakeholders about environmental resources is difficult even though their livelihoods broader human society and global economies depend upon the environment yet reducing destructive impacts on critical earth resources requires enhanced communication between stakeholders ranging from rural farmers to urban executives to policy makers elshall et al 2020 gleeson et al 2012 meinzen dick 2014 pierce et al 2016 sanderson and frey 2015 rich data are available in some parts of the world however data do not by themselves convey information and knowledge garcía et al 2015 yigitbasioglu and velcu 2012 despite the importance of many fields within earth science and looming difficulties posed by progressively diminishing resources current methods of using web page designs to bring earth science data to a popular audience rarely motivate good resource management this work seeks to enhance communication about environmental systems the goal is to improve engagement that leads to data based collaborative environmental decision making efforts important to scientists stakeholders societies businesses governments personal finances and local national and international economies the discoverframework seeks to motivate improved environmental stewardship by enabling greater access and understanding of data through new freeware based visualization strategies and foundational infrastructure freeware is important for the goals of accessibility transparency portability and flexibility the scientific and mathematical context produced by discoverframework applications can provide information and knowledge about underlying physical chemical and biological relations and correlations anthropological sociological public policy and economic context enabled through selection of discoverframework application content can provide information and knowledge about broad consequences of environmental concerns the discoverframework tools provide a mechanism to combine data with these contexts to create user friendly engaging interactive experiences for spatio temporal data to do this the discoverframework focuses on providing tools to reveal system trends correlations characteristics dynamics and broader context through well designed data presentation and resulting insights from visual analysis grainger et al 2016 yigitbasioglu and velcu 2012 to begin it is necessary to discover important spatio temporal data and download display and analyze it these steps often require advanced scientific and computer science knowledge caquard and fiset 2014 kehrer and hauser 2013 lienert et al 2009 rübel et al 2010 thus the data and the insights that data contain are largely inaccessible to most stakeholders the discoverframework fills this gap by taking advantage of recent approaches that support analysis and visualization of complex spatio temporal multivariate data sets lundblad and jern 2012 yang et al 2017 yigitbasioglu and velcu 2012 of most importance to discoverframework are 1 the widespread and ever increasing access to technologies such as laptops tablets and smart phones 2 expanding web access to public domain data sets on environmental systems 3 access to free cloud data storage 4 new web access and design ideas that enable increasingly comprehensive displays of data 5 increasingly robust free gis capabilities through qgis and 6 increasing ability to include interactive maps charts and communication between users in a single web page recently applied mostly in financial and news sectors discoverframework makes selected new developments readily accessible for environmental applications discoverframework supports creation of the modular web page elements shown in fig 1 which can be configured in many ways using one two or all three elements discoverframework provides the following 1 integrates multiple spatio temporal data sets coalescing data sets in this way captures multiple aspects of environmental systems and encourages questions about trends correlations and potential consequences of natural and anthropogenic impacts 2 interactive animations enable discoverframework users including scientists students policy makers and stakeholders to visualize and investigate spatial and temporal correlations 3 visual analysis drives qualitative measures and correlations 4 a potentially user driven significant events list identifies trends and interdependencies in environmental applications these often suggest anthropogenic and climate impacts help to create a cohesive picture of the environmental system and identify where to focus development and conservation efforts this article describes the discoverframework design concept elements and typical application workflows discoverframework is demonstrated using two applications discoverwater and discoverhabs the following subsections describe how discoverframework uses and fits in with 1 the current state of cyber infrastructure 2 data discovery and processing 3 visualization and animation methods and 4 applications and dashboards for earth science 1 1 cyberinfrastructure the discoverframework includes display techniques enabled by hypertext markup language html hypertext preprocessor php cascading style sheet css and javascript application programming interfaces apis html provides the framework for content display css provides advanced styling and formatting javascript allows users to interact with the website and asynchronous javascript and xml ajax acts as a bridge as it communicates with servers for the transfer of information such as data in javascript object notation json formatted files caquard and fiset 2014 rübel et al 2010 there are numerous open source apis written in these languages and it is often necessary to use a combination of capabilities from different apis caquard and fiset 2014 kirk 2018 the approach taken in this work this allows discoverframework to remain adaptable and leverage the many computing technologies already available without needing to invest in expensive servers or high performance computing centers 1 2 data discovery procurement and processing there are challenges associated with existing methods to discover procure and process data in many fields of science these challenges include avoiding bottlenecks and resulting delays in data transfer cumbersome decoding steps using various markup languages li et al 2015 and advanced scripting to implement automated data mining and preprocessing algorithms garcía et al 2015 attempts to make data access easier are being actively pursued in several ways including the following examples from hydrology the consortium of universities for the advancement of the hydrological sciences inc cuahsi sequentially produced hydrodesktop https hydrodesktop codeplex com ames et al 2012 hydroclient crawley et al 2017 and hydroshare https data cuahsi org hydroshare combines web services and an interactive graphical user interface gui accessed via a web interface hydroshare provides a map element to search multiple data sets by location and variable type this capability will be needed for discoverframework to allow the end user to control the location for which data is displayed cuahsi s waterml zaslavsky et al 2007 is a type of extensive markup language xml specifically designed for dynamic data exchange of hydrological time series data such as network common data format netcdf data arrays following geographic markup language gml encoding rules palmer 2012 the open geospatial consortium ogc is working toward making waterml the universal standard for hydrological data this advance makes it easier to use data in tools such as discoverframework the united states geological survey usgs statistics web service u s geological survey 2020a uses representational state transfer rest to generate a static link with defined parameters that returns a table of daily monthly or annual statistics for streamflow and groundwater level data directly from the usgs national water information system nwis database u s geological survey 2020b discoverframework is compatible with rest services the discoverframework version 1 described in this work emphasizes the design of the display and interactive capabilities for the case studies shown in section 3 data were manually downloaded to be used in the case study demonstrations 1 3 visualization and animation the prevalence of internet access and mobile devices has revolutionized geographic information systems gis promoting web enabled geo visualizations the advent of cloud computing facilitates incorporating spatio temporal analysis of remotely sensed data provides a new platform for expressing various approaches to visualization interaction and analysis of scientific data of complex earth systems kehrer and hauser 2013 tulbure et al 2016 the move to web based geo visualization enables a visualized narrative for communicating spatio temporal characteristics of multiple data sets and is essential for making comparisons between data sets scientific analyses and popular comprehension of how complex natural systems change over time require the ability to see when and where the change occurs by viewing time series data in continuous succession rather than as static events or snapshots caquard and fiset 2014 kehrer and hauser 2013 rübel et al 2010 the implementation of many different visualization strategies is essential to interpret data seamlessly and effectively while embodying the greater context dong et al 2012 grainger et al 2016 kehrer and hauser 2013 yigitbasioglu and velcu 2012 problems with existing strategies include 1 statistical or dimensionality reduction to reduce data set size which reduces resolution 2 cluttering of multiple variables can result in crowded displays and reduced comprehension and 3 occlusion and bottlenecking of bandwidth and computing power to process multiple large spatio temporal data sets chrisman 1999 kehrer and hauser 2013 kirk 2018 rübel et al 2010 these technological challenges can be seen in many earth science visualization examples of maps that classify measured data with varying symbology and color of vectors in looped animations of static images the usgs water watch tool https waterwatch usgs gov index php id ww animation real uses a color indicator to illustrate relative daily average streamflow conditions at stream gage stations with 30 years or more of recorded measurements stream gages are shown as points to reduce occlusion and only one month of daily average data is animated on a loop of a series of static images for each day the interactive user experience is limited to the user choosing which month is displayed the 10 day forecast 6 hr interval arcgis online map https www arcgis com home webmap viewer html webmap 8890035d5add40858335f402864df457 from the national water center 2016 shows a looped animation of the forecasted stream flows across the contiguous united states as time advances on a looped playback the quantity of streamflow expected in the stream is depicted by changing the width of the line representing stream segments and the amount of streamflow relative to historic flow is depicted by changing the color of the stream segments the playback loop is predetermined no user interaction is supported geo visualization has lacked support for interactive animation and effective methods for spatially and temporally displaying multiple heterogeneous data sets common concerns around spatio temporal animations include motion distracting the user s attention poor retention lack of clear visual expression of information e g smoothness and user interface issues hindering animation johnson and nelson 1998 lienert et al 2009 rana and dykes 2003 map displays integrated with chart tools produce a multidimensional spatio temporal display for interactive data exploration brendel et al 2019 lundblad and jern 2012 rübel et al 2010 yigitbasioglu and velcu 2012 deltares aqua monitor https www aqua monitor appspot com donchyts et al 2016 web app runs on the cloud computing power of google earth engine real time computations from global landsat imagery to detect increases and decreases in the water present from raster image to raster image represented in high contrast colors as land and water changes while foregoing true animation users have increased interaction with the static raster images at the user s chosen location using a time slider to advance through 30 years of remote sensed data and a transparency slider to compare the transformation of the landscape over time the usgs california drought viz https labs waterdata usgs gov visualizations ca drought index html combines two different types of data u s drought monitor andmeasured reservoir storage charts overlay the map and change with the map data as the user changes the time frame by scrolling the mouse even with limited user interaction this application demonstrates how cluttering and user distractibility can quickly become a challenge when multiple variables are displayed with charts and maps while important advances these efforts show the challenges in displaying data effectively for interpretation of heterogeneous earth systems compromises are often made to address temporal animation multi variate relationships simultaneous map and chart representations of data and user interaction discoverframework is unique in the level of user interaction through animated charts and maps and question driven approach to supporting multivariate data organized in a dashboard interface 1 4 applications and dashboards for earth science holistic data exploration apps geared towards data analysis and decision support have been developed using dashboard interfaces four of these apps most applicable to the discoverframework are described here the nsf funded web app flyover country myrbo et al 2015 supports several basemap options and downloads a recent geologic map and data from wikipedia and selected other sites to provide geologic information within a spatial context for people traveling by foot bike car boat and plane no time dependence of the geologic and environmental variables is supported the stream hydrology and rainfall knowledge system sharks web app allows users to retrieve data for multiple variables and view interactive plots aimed at curating data for decision support brendel et al 2019 the sharks app implements a tab based navigation panel where one panel is for maps one for time series charts and so on the lack of integration of spatial and temporal components may inhibit decision makers from gleaning the necessary information they need yigitbasioglu and velcu 2012 watershed restoration using spatio temporal optimization of resources wrestore web app aims to optimize decision support to improve environmental conservation efforts babbar sebens et al 2015 unlike the browser run discoverframework wrestore runs on a high performance computer and requires users to create an account to login which limits access the usgs national climate change viewer nccv uses a web based dashboard interface to combine spatial data temporal data and statistics with the goal of easily visualizing and summarizing climate data alder and hostetler 2015 discoverframework provides temporal analysis unlike flyover country it integrates spatial and temporal aspects within one web page unlike the sharks visualizations it differs from nccv and wrestore by emphasizing simultaneous display of multiple spatio temporal data sets and providing an adaptive storytelling data dashboard lundblad and jern 2012 yigitbasioglu and velcu 2012 2 methods discoverframework workflows and toolkit elements of the discoverframework toolkit from fig 1 are shown again in fig 2 placed in the context of a typical workflow there are four main steps in the workflow 1 prepare data for use with the toolkit through data acquisition and processing 2 render the interactive maps and charts using display techniques 3 identify correlations using domain supported knowledge and 4 develop a given application using workflow tools selected aspects of spatio temporal scaling are covered as examples in section 3 2 1 data acquisition and processing this version of discoverframework accommodates a variety of data types and sources this section discusses the data sources and temporal and spatial data processing and formatting so that the data is compatible for use in the discoverframework toolkit 2 1 1 data sources in most fields for which data are acquired programs have been developed for data discovery and download for example hydroclient has been developed to access selected hydrological data bases and earthcube s data discovery studio that indexes over 1 6 million data sets across scientific disciplines for discoverframework toolkit compatibility the source data need to have a timestamp spatial reference and be organized in a table format once in table format the data need to be reformatted as one to many json arrays one json file per chart see fig 2 for some data sources data can also be directly accessed from structured query language sql databases or public databases using rest services additional customized coding is required when using sql and rest services to process and format the data retrieved as each data source has nuances in formatting and retrieval method private data or model results can be processed using spreadsheet software or customized coding tailored to the data set challenges with timestamp formatting and file handling in this work shaped strategies for file formatting python or r code can be written to retrieve and process data but some data sets may require additional manual processing using spreadsheet software for the discoverwater and discoverhabs applications presented in section 3 the data downloads were conducted via a process with sql and rest using rstudio in combination with libreoffice calc version 5 3 4 the document foundation 2020 which is an open source spreadsheet software 2 1 2 temporal data processing and formatting in general comparative data analysis is constrained by the length of available historical records pyrce 2004 tharme 2003 the data sets attributes need to be normalized to defined spatial and temporal scales garcía et al 2015 to facilitate comparisons between data sets whether converting from csv a web service sql database or other source the data are arranged as an array composed of lines such as yyyy mm value yyyy mm value this array format is important to index operations in discoverframework elements this in turn improves load time of the website discoverframework supports higher resolution temporal scales such as for data sets containing daily or hourly data as discussed in section 3 programming languages such as python or r can be used to retrieve process and format data for use with discoverframework 2 1 3 spatial data processing and formatting qgis the leading open source gis freeware qgis 2020 is used to create custom shapefiles and export them as geojson files a common type of json file designed for web mapping discoverframework elements run on geographic web mapping apis that process geographic information as a geojson file for example in the discoverwater application for a portion of the arkansas river in kansas the csv files containing latitude longitude time and data are pre processed using libreoffice calc as explained in section 2 1 2 these are imported into qgis as a point using the longitude and latitude of the gage station then exported as a geojson file saved to local storage errors such as numbers being read as strings by gis software which leads to inoperable animation and numerical data driven formatting are eliminated by imposing uniform formatting of timestamps of data for csv files the shapefiles for county boundaries and the high plains aquifer were downloaded from the kansas data access and services center kansas geological survey 2020a imported into qgis and exported as geojson files 2 2 display techniques the php html and json files for the website can be stored using a free web hosting control panel such as x10hosting 5gbfree or freehostia discoverframework is hosted under the university of kansas subscription to the commercial hosting software cpanel cpanel inc 2020 the discoverframework is a php file that serves as an index page that loads when the discoverframework application website is visited php is used to retrieve the html files for discoverframework element 1 map and discoverframework element 2 charts so that they are displayed according the layout in fig 1 element 2 calls the json files from the cpanel file manager and parses them using jquery version 3 5 1 the jquery foundation 2020 once the json file is parsed it is ready to be displayed using javascript apis described in section 2 2 1 the geojson files are uploaded to mapboxstudio mapbox 2020a element 1 uses javascript apis described in section 2 2 2 to display the geojson files there are numerous open source web mapping and data visualization javascript apis available discoverframework elements use mapbox and highcharts apis to generate elements 1 and 2 respectively in fig 1 2 2 1 mapbox for geo visualization highcharts and its complimentary mapping library highmaps version 5 0 12 highsoft as 2020 have the potential to develop and seamlessly integrate both the map element 1 and charts element 2 of the display highmaps and qgis when investigated 2015 2016 were not found to be robust enough to animate time series spatial data interactively mapbox had this capability and was chosen for use in discoverframework mapbox is comprised of mapbox studio mapbox 2020a a web based gui for designing and building basic maps and mapbox gl js mapbox 2020b a javascript library for advanced development the map component element 1 of the discoverframework figs 1 and 2 is powered by the mapbox hybrid development platform using mapbox studio and mapbox gl js version 1 12 0 time series data plotted on the map is controlled by a time slider as the user slides the bar the colors of the geojson objects on the map change to reflect the value at that time the time slider in element 1 will simultaneously control the synchronized cursors on the charts in element 2 the synchronized cursors on the charts can be operated independently of the time slider on the map moving the time slider on the map always moves the synchronized cursors on the charts this was accomplished using html code to link the mapbox and highcharts apis by user input 2 2 2 highcharts for synchronized time series graphs the interactive aesthetically effective charts of discoverframework element 2 is powered by highcharts version 8 2 0 highsoft as 2020 because of its robust library ease of use and in line javascript formatting data driven formatting can be implemented in using highcharts zones capability to assign different colors to the data based on whether a value is greater than or less than the qualifying criteria such as percentile there is at least one json data set per chart and each chart has a designated html container discover framework element 2 supports multiple data sets per chart using the secondary y axis options of highcharts and can be enabled by removing comment notation around the block of code such as in the discoverhabs application these charts are wrapped within one main html container to allow cursors to be synchronized across all four charts when the mouse hovers over the plot on any chart the markers are highlighted as the user slides the mouse or their finger across the charts they see a vertical line synchronized with respect to the x axis temporally connecting all four time series data sets so that they are viewed collectively yigitbasioglu and velcu 2012 the highlighted values are displayed in a fixed position tooltip at the top right of each chart an example is provided in section 3 3 1 environmental problems are complex and often there are more than four variables involved using the framework described above scenarios can be created grainger et al 2016 this is demonstrated in section 3 where it is used to show the interactions between different combinations of variables and model simulations to address a defined set of questions 2 3 domain specific knowledge expected relationships between data sets can be determined by domain specific knowledge discoverframework supports developing and communicating knowledge through descriptive statistics for each plot and manual entry of story like narratives into element 3 element 3 is an html container which gives it the flexibility for a wide variety of uses and the ability to add tools such as a comment section to engage in a two way conversation between app users and scientists babbar sebens et al 2015 further development of this element of the discoverframework is discussed in section 3 2 4 develop applications using the discoverframework starting with the discoverframework code sample files and documentation available on github scientists can develop their own discover applications the data sourcing code will generally need to be edited to connect to databases data sets produced by other web services model results and other data sources each data set is stored in a unique data variable used by discoverframework element 1 and element 2 fig 1 the first data source read by the code will be stored in the variable data1 the second data source will be stored as data2 and so on it is important to have metadata related to the data source and the data displayed discoverframework code includes some custom options for this metadata within the javascript code for each chart or using a custom css for advanced formatting control for example element 1 allows developers to add custom titles to charts so that data set names can be audience specific the web app can be published using a free account with a web or file hosting service such as those mentioned in section 2 2 discoverframework developers need a free mapbox studio account and access to the mapbox gl js and highcharts library documentation api code can be download from their respective websites both mapbox and highcharts are ported from an api repository like cloudflare or github mapbox provides considerable free access to get developers started with a large limit on the number of monthly map loads see terms defined on the mapbox website highcharts is free for non profit use and which encompasses education and government there are premium pricing plans for commercial developers there are currently no use limits on charts 3 addressing selected application challenges using discoverframework ways in which discoverframework addresses three challenges are presented using two applications discoverwater and discoverhabs the challenges are 1 data sources and scales 2 display of multi variate data and 3 data presentation design and evaluation of user engagement discoverwater uses the discoverframework to visualize spatial and temporal changes in streamflow and related anthropomorphic and natural environmental variables discoverhabs uses the discoverframework scenario capability to combine data from high frequency hourly sensors laboratory analysis and model results for analyses and prediction of harmful algal blooms habs 3 1 data sources and spatio temporal scales a major step in creating environmental applications is managing data sources metadata and the spatio temporal scales for each data set so that they can work together across different formats discoverwater uses data sources from multiple institutions whereas discoverhabs uses multiple parameters from one data source data source metadata are determined by the institution hosting the data metadata such as names are often not useful to a non scientific audience and alternatives can be advantageous temporal scales vary between hours to years in the data for the applications shown discoverframework uses a defined mutual temporal scale to plot data in a way that helps users identify correlations spatial scales vary between points to zonal polygons in the applications considered discoverframework uses a defined mutual spatial scale to develop maps scientists define these temporal and spatial scales to make them mutual for facilitating identification of trends in the relevant context being investigated the ability of the discoverframework to support qualitative spatio temporal trend analysis within or initiated through the discoverwater map element 1 is demonstrated using color dots representing stream gage stations along the river change color to show changes in streamflow values from october of each year are shown because this dry time of year is dominated by groundwater interactions the variability of all monthly values obscures evaluation of system dynamics dominated by wet and dry years the ability of discoverframework to manage numerous variables and unknown causal relations is demonstrated through select scenarios in discoverhabs discoverhabs presents an example from cheney reservoir dam outside of wichita kansas cheney reservoir has one of the most complete and longest continuous high frequency water quality data sets for a reservoir system and also uses results from probability models for taste odor compounds and the cyanotoxin microcystin developed by the usgs harris and graham 2017 3 1 1 hydrologic data sources and scales in discoverwater discoverwater is demonstrated using data from the high plains aquifer hpa in kansas listed in table 1 showing both the data set name and corresponding name that appears as the chart title data names can vary based on source this is handled by providing an ontological map to pair the given data set name to an audience friendly chart title discoverwater data types visualized include streamflow groundwater level irrigation and climate and each one is displayed on a separate chart file sizes range from 13 to 17 kb the desired timeframe extends back to at least 1950 which is before the hpa was developed for large scale irrigation buchanan et al 2015 data are filtered so only data in and after 1950 are used the temporal range of the data sets in table 1 differs this is handled by using a select time range and reclassifying missing values in the time series as null to preserve indexing the temporal resolution of the data sets is monthly or annual this is handled by repeating the yearly value over 12 months to create a monthly time step streamflow data sets are local and limited to stream gage stations long term stream gage stations appear as large black dots with a white outline on the map using discoverframework element 1 fig 3 other stream gage stations along the arkansas river have less complete data sets and appear as small black dots without an outline web users click on the dots with white outlines to activate the dot and its color is controlled by the time slider of element 1 monthly data for the active dot is plotted in the charts using discoverframework element 2 annual average groundwater level is the depth to water from the surface averaged for the year over the wells in a given county the lower temporal resolution annual data set is left joined to the higher temporal resolution monthly data set the values from the monthly data set are dropped so that the resulting dataframe consists of the monthly timestamps and the annual values which are repeated for each month of the year this procedure serves two purposes 1 it aligns the monthly and annual temporal scales and 2 it facilitates indexing and synchronizing the data sets when plotted groundwater level values are from kansas geological survey kgs synoptic measurement campaigns from january of each year for each county groundwater levels are arithmetically averaged by the kgs to obtain the county representative value the number of wells per county in kansas vary from 26 to 2377 most of the wells are used for irrigation and sampling and are well distributed over the area of the high plains and alluvial aquifers this is important for two reasons 1 values more typical of regional conditions are represented and 2 the average annual groundwater level data and average annual pumping data are applied to all stations within the county irrigation data is the total annual water used by wells designated for irrigation in the county in kansas values are submitted annually by all water right holders for each county water use reporting began in the late 1950s and became fully mandated in the 1990s kansas geological survey 2020b counties in kansas are similar in size providing a useful spatial definition for the purposes of this work counties are shown in fig 3 county based values for groundwater levels and irrigation work well in kansas because counties are similar in size this spatial representation is thus useful for the purposes of discoverwater different spatial representations are used for other variables as needed the monthly palmer drought severity index pdsi is a monthly or annual index for identifying the intensity of wet and dry periods based on current weather plus cumulative patterns of previous months noaa national centers for environmental information 2020 values are derived from the global historical climatology network daily ghcn daily temperature and precipitation station data as well from several different additional networks pdsi data are reported for 344 climate divisions nationally climate divisions of interest in this work are listed in table 1 and the monthly resolution pdsi data set was used climate divisions span several counties as shown in fig 3 pdsi values apply to all gage stations within a climate division 3 1 2 biogeochemical data sources and scales in discoverhabs the data set included in discoverhabs was routinely collected by the usgs at a single sampling site near the water intake at cheney reservoir dam fig 4 since april 2001 providing more than 20 years of measurements basic water quality data shown in table 2 including water temperature dissolved oxygen conductivity ph turbidity chlorophyll pigment fluorescence total algal concentrations and phycocyanin pigment fluorescence i e cyanobacteria concentrations was collected using high frequency sensors at 1 m of depth throughout the collection period sensors collected data at 1 h intervals throughout the time period resulting in an 11 000 kb database geosmin and microcystin probability were calculated for each timestamp using logistic regression models and trained with data collected by the sensors graham et al 2017 concurrent and additional discrete water quality data shown in table 3 were also collected at weekly bi weekly or monthly time intervals at the same sampling site collected data includes wind direction total dissolved nitrogen total dissolved phosphorus total dissolved solids total geosmin taste odor compound and total microcystin cyanotoxin the high frequency data discrete data and real time model results were aggregated into a database totaling 26 500 kb data from table 2 appear as a continuous line of time series data data from table 3 appear as discrete points where the sampling date aligns with the timestamp of data from table 2 variables displayed in discoverhabs were chosen by their variable importance based on model sensitivity results graham et al 2017 harris and graham 2017 the data collection was primarily focused on detecting harmful or nuisance cyanobacterial blooms known as cyanobacterial harmful algal blooms cyanohabs cyanohabs are driven by a complex set of physical chemical and biological factors making outbreaks difficult to predict and understand thus the purpose of the hab related discoverframework application is to allow users to input and test scenarios using previously collected data for this application a scenario feature of the discoverframework allows users to explore data combinations designed to reveal how environmental and biogeochemical variables relate to the probability that a cyanohab will occur and create harmful or nuisance compounds 3 2 multivariate data presentation presenting multivariate data using different formatting options and arrangements helps users glean information about the data from a glance complex variables may require data driven formatting to help distinguish ranges of values that may impact the user of discoverwater and discoverhabs 3 2 1 hydrologic variables in discoverwater the discoverframework supports data driven formatting which can be used to improve user understanding of data significance in discoverwater two types of data are formatted based on the value of the data pdsi to highlight wet and dry periods and streamflow to categorize the wide range of flow values shown in fig 5 the other two data types irrigation pumping and groundwater levels are given a single distinct color for all values this is illustrated in the example of the discoverwater charts in fig 6 for pdsi values greater than 0 are shaded blue and identify wet periods values less than 0 are shaded red and identify dry periods the degree of saturation of the color corresponds to the severity of the drought or wet period i e bright red is a severe drought whereas light red is a less severe drought the national center for atmospheric research ncar classifies above 4 0 as an extremely moist spell and below 4 0 as an extreme drought dai and national center for atmospheric research staff 2019 streamflow is classified by percentile of historical flow following the same method currently used for the usgs waterwatch maps u s geological survey 2020c the dark blue extreme flow classification denotes very high stream flows statistical outliers such as these are calculated from the interquartile range of the data set as defined by tukey s upper fence q 3 1 5 q 3 q 1 tukey 1977 where q1 is the 25th percentile and q3 is the 75th percentile the monthly average streamflow data derived for each gage station are normalized to the historic record at that station percentiles serve as break points to determine the color assigned to each data point within that percentile range the color scale shown in fig 5 is a useful classification approach for direct streamflow visualization kehrer and hauser 2013 the colors of fig 5 are used in two ways in streamflow time series charts and to color dots that locate gaging stations on the map 3 2 2 harmful algal bacteria variables in discoverhabs in discoverhabs cyanobacterial abundance is colored using data driven formatting corresponding to the alert levels determined by the kansas department of health and environment kdhe mosier 2015 observed microcystin was colored using the advisory values established by the environmental protection agency epa and the kdhe observed geosmin was colored using the minimum human detection level of 5 ng l the highest analytical limit of detection in the data set and the concentration at which humans start to smell the compound microcystin and geosmin probability are colored using the threshold probability for positive classification tppc for the corresponding model values above the 0 43 tppc for microcystin indicate the probability that microcystin will occur at or exceed the 0 1 μg l analytical detection threshold which denotes a cyanotoxin event values above the 0 41 tppc for geosmin indicate the probability that geosmin will occur at or exceed the 5 ng l human detection threshold which denotes a taste and odor event graham et al 2017 events of either compound tangibly mean that drinking water sourced from the reservoir requires more advance treatment before being finished for public consumption otten et al 2016 all other data sets that do not have specific alert levels were given a unique color affiliated with how the variable is perceived i e grey for dissolved oxygen brown for turbidity teal for nitrogen 3 3 presentation and user engagement the number of variables to show the order the variables appear and the type of axis used help present relevant information without overwhelming the user presentation of data helps it tell its story by engaging users and make insights accessible 3 3 1 hydrologic insights from discoverwater three selected insights provided by the discoverwater application are presented to illustrate the power of the approach taken the discoverwater example in fig 6 shows that floods and storm events or droughts heavily influence streamflow and groundwater level as time progresses from past to present in the high plains aquifer hpa system groundwater depletion caused by irrigation is reflected by increased frequency of low streamflows as lower percentile colors for flow occur more frequently after large scale pumping starts fig 6 provides a clear example of the kind of insight the data selection and design in discoverwater can achieve at the syracuse gage station october 1953 fig 6a was during the worst drought on record the arkansas river streamflow decreased to 27 4 ft3 s 0 78 m3 s in the yellow 10 25 range groundwater declined to 39 3 ft 12 m below the surface 14 ft 4 3 m deeper than the preceding year this shows that declines in streamflow and groundwater level within the hpa occur naturally during the driest period on record which occurred prior to major pumping in the county surrounding the syracuse gage station pumping of groundwater to serve irrigation became significant in the 1960s and increased rapidly through mid 1980s declines in streamflow and groundwater level are even greater due to over allocation of groundwater haacker et al 2016 october 1973 fig 6b was in the middle of a very wet period with a pdsi of 5 5 streamflow was normal in the 25 75 range but groundwater level in the aquifer did not increase this highlights how the presence of streamflow can create a false sense of water abundance masking the impacts on the aquifer as elevated pumping of the aquifer impedes natural recovery of the aquifer during wet periods butler et al 2018 lower streamflows occur during droughts that were much less severe than the 1950 s drought fig 6a such as those of the late the 1970 s figs 6b 2002 fig 6c and 2011 fig 6d in these less severe droughts streamflow drastically declined to much lower flows in the red 10 range fig 6d shows october 2011 during a moderate drought with a pdsi of 3 7 the aquifer was pumped at an average of 72 ft3 s 2 m3 s throughout the year streamflow was barely flowing at 0 5 ft3 s 0 01 m3 s and groundwater was 73 2 ft 22 3 m below the surface before dropping to 94 5 ft 28 5 m the following year pumping the aquifer during a moderate drought has a larger impact on streamflow and groundwater declines than a severe drought before the aquifer was heavily pumped for irrigation ou et al 2018 salem et al 2018 in summary discoverwater uses the discoverframework to integrate streamflow groundwater pumping groundwater levels and palmer drought severity index data sets it is demonstrated using a major agricultural center that produces food for the nation in an arid region of the hpa in western kansas discoverwater shows how groundwater supported irrigation has caused a progressive decrease in streamflow over time in the arkansas river flows during drought conditions decreased from 7 ft3 s in november 1956 at the end of the 1950s drought of record to 0 04 ft3 s in august 2013 during the most recent less severe drought it also shows how a predominantly wet period obscured the effect of irrigation for 20 years from 1983 to 2003 the discoverwater charts allows the user to focus on many other inter and intra data set relationships 3 3 2 water quality inquiry from discoverhabs a complex set of environmental factors cause cyanohabs to occur different sets of data can be used to evaluate different process ideas a list of all the scenarios available from discoverhabs is provided in table 4 as an example scenario 1 of discoverhabs is chosen to address specific scientific questions using data only from the year 2012 because of the presence of a bloom event 3 3 2 1 scenario 1 are physical variables correlated to increases in cyanobacteria population changes fig 7 shows scenario 1 consisting of cyanobacteria reservoir elevation average daily precipitation and water temperature from table 2 the cyanobacteria chart shows the time specific cell count per ml present in the reservoir a spike in cyanobacteria cells on july 6 through july 9 2012 indicates a bloom occurred this bloom was not large enough to require in lake mitigation as indicated by the green color the environmental conditions preceding the bloom may help determine the proximal causes relatively high water temperatures possibly connected to lower than average reservoir elevation or water level can help spur cyanohabs huisman et al 2018 the reservoir elevation in scenario 1 has been declining since the end of may but it is not at its lowest point yet suggesting other factors are contributing to the bloom as the last precipitation event was july 21 this long stretch without precipitation leaves the reservoir undisturbed and prone to evaporation so cells can grow and could favor a bloom by concentrating nutrients the temperature plot shows temperatures above 27 c which increases the likelihood for a cyanohab in cheney reservoir harris and graham 2017 3 3 2 2 scenarios using 14 years of data challenge of large data high temporal resolution scenarios using the entire 14 year data record instead of just one year 2012 were attempted as well but were met with technical obstacles each of the four charts consisting of 220 000 data points meant the browser had to load 880 000 data points the browser was slow to load the data and was slow to respond to user input when the synchronizer was moved the highcharts boost module provided the capability to load the full data sets quickly in the browser however it resulted in the loss in functionality of the synchronized cursor and zoned coloring for geosmin and microcystin probability these are among the most impactful of the technology limitations encountered the combination of discrete measurements high frequency hourly data and developed probability models provide water managers with data visualizations of the information needed to justify implementation of expensive treatment methods to remove taste odor compounds from drinking water or when to close a reservoir for recreational use due to elevated toxins overall an implementation of the discoverhabs application to other reservoirs may help determine why blooms have dramatically increased since the 2000s in some kansas reservoirs harris et al 2020a 2020b 3 3 3 evaluating user engagement user engagement has been evaluated using a combination of website traffic data from google analytics and responses from an assignment given to an undergraduate introductory geology class google analytics has been collecting website traffic data since november 4 2018 fig 8 shows the audience overview data provided by the google analytics dashboard throughout this time there have been 527 unique users to the site from 10 different countries and 13 1 of new users return to the site users spend an average of 3 min when they visit the site 87 5 of users visit discoverwater with their desktop browser 12 with their mobile device browser and 0 5 with a tablet browser this may indicate a need to improve the mobile and tablet interfaces an undergraduate introductory geology class consisting of primarily freshmen and sophomores with little prior knowledge about hydrogeology was given an assignment to use discoverwater to answer six questions listed in table 5 responses are used here to evaluate how well discoverwater conveyed intended information of the students enrolled in the course that semester 98 submitted the assignment summarizes correct responses from students for each question and how they performed on the assignment overall on average students got 3 out of the six questions correct questions were designed to see if students could perform non interpretive tasks such as data query and interpretive tasks such as inferring cause and effect inferences discussed in section 3 3 1 are related to questions 4 6 correct answers did not require exact wording for example for question 5 comments such as combined impact of climate and irrigation or that ground water is no longer dependent on streamflow due to new irrigation and pumping technology were counted as correct student performance has been used to guide improvements in discoverwater it has also been used to redesign the assignment to improve measurement of engagement and knowledge transfer 4 conclusions the ways in which discoverframework expands what is possible through freeware data visualization is demonstrated using data from groundwater depletion and harmful algal blooms the examples illustrate design concepts from other fields such as news media and business presentations to increase the dimensionality of data displays here the simultaneous display of a map time series and multiple variables is new to environmental science and the field of hydrology we expect this advance to enable users to relate many aspects of actual systems including space time and spatio temporal variables and provides important insights more quickly than other visualization designs analytical features such as evaluating multiple data sets using machine learning and artificial intelligence would provide additional information to be displayed and could include other relevant data such as associated metadata discoverframework is a customizable framework and the limit lies within what is technologically possible there is a vast potential of features that can be developed for the discoverframework that will improve the user experience so that interacting with complex data can be streamlined and more intuitive two applications of discoverframework are used to address water and harmful algal bloom questions communicating and understanding human influence on environmental systems requires seeing the big picture of how different human and natural components interact and affect each other this is accomplished by developing a visualization template able to bring together interrelated data sets with long historical records for the discoverwater implementation discussed in this work groundwater level streamflow climate and water use for irrigation are combined into a synchronized interactive visualization comparisons are made from the period of pre agricultural irrigation groundwater withdrawal to present time through data driven visualization methods the dynamic map and charts allow for analyses to be made on various temporal scales from across historical record to a select season and spatial scales from individual gage stations to the entire arkansas river discoverwater shows users the spatial and temporal variability of the groundwater and surface water as well as the intricate dynamics between pumping for irrigation and climates for the discoverhabs implementation discussed in this work scenarios of different combinations of variables allow a visual investigation into selected questions about the causes of blooms and associated geosmin and microcystin events some scenarios present a visually clear connection whereas others show the knowledge gaps that remain these gaps in turn cause less than desired model performance for the nuisance and toxic compounds that disrupt drinking water treatment facilities discoverframework challenges freeware developers database managers and scientists to fill in identified gaps gaps identified in this work are 1 interactive animation of multivariate spatial data section 2 2 1 2 representing discrete vs continuous data section 3 2 and 3 speed of data processing section 3 3 scenarios using 14 years of data there is also a need for 4 improved automated data retrieval and interoperability to reduce the time spent manually preprocessing data current data retrieval technologies for many of the data sets involved make it difficult to accomplish the anticipated ability of element 2 in which the map window could be moved to a new location future functionality depends on data that follow fair principles for scientific data management https go fair org fair principles and are stored in established data repositories that can be accessed with apis these improvements and evolving technological advances will provide an even more dynamic and intuitive experience for users through comprehensive displays such as those supported by the discoverframework software availability the discoverframework github repository is available at https github com mistyblue17 discoverframework v1 2 the discoverwater web interface is available at https interactiveviz ku edu discoverwater the discoverhabs web interface is available at http interactiveviz ku edu discoverhabs cheney scenario1 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we greatly acknowledge funding from the university of kansas research excellence grant ref 2017 18 and the u s geological survey powell center grant g20ac00197 the authors acknowledge significant contributions from the national science foundation earthcube program and is geo rcn contributions to the code from matthew garret of the university of kansas and michael gloystein of spotx are much appreciated appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105104 
25807,waterlogging on croplands has been a known problem for a long time leading to adverse social physical economic and environmental issues to better solve the problem the complicated plant soil water dynamics system needs to be better understood the challenge is to simulate the interactions between the components in the systems there are models that simulate plant soil water system but either run the processes independently leading to inaccuracy or has high invasiveness of using integrated models this paper presents a tightly coupled model daycent modflow that links a 3d ground water flow modflow model and a 1d agroecosystem model daycent daycent is responsible for plant soil water dynamic in the root zone whereas modflow simulates head and groundwater flow in the saturated zone of the aquifer daycent passes deep percolation from the soil profile to the water table and under conditions of waterlogging in which the water table is within the soil profile daycent soil hydrologic processes are constrained by the presence of the water table simulated by modflow the coupling is achieved by adopting a parallel inter process communication technique mpi message passing interface the model is applied to a waterlogged agricultural area 22 km2 in northern colorado usa and tested against groundwater head and rates of evapotranspiration et the model runs in parallel with multiple processes on the largest aws linux server groundwater heads match measured heads to a reasonable degree and et rates match reference et and are highly correlated with crop type results show the strong hydrologic interaction between the two models greenhouse gas emissions from soil n2o and ch4 were also estimated by the model under the waterlogged conditions although the model can be used to simulate any plant soil aquifer system no matter the depth of the water table results from this study show that the model can be used to assess crop productivity recharge et and greenhouse gas emissions in areas of shallow groundwater keywords groundwater modeling modflow daycent message passing interface mpi waterlogging model coupling 1 introduction the plant soil water system controls the movement of water nutrients and greenhouse gases in agricultural landscapes understanding this system under a variety of hydrologic conditions is important for food production land management water management and nutrient management the plant soil water system is a complex system consisting of surface water runoff infiltration soil water dynamics evapotranspiration recharge and nutrient leaching carbon c nitrogen n cycling and consequent hydro chemical processes such as flow and nutrient transport in aquifers stream discharge and nutrient loading and greenhouse gas emissions the challenge of simulating water transport and nutrient cycling in such a complex system resides mainly in the interaction between zones such as water movement between the soil profile and the saturated zone of the aquifer as stated by alley alley et al 2002 groundwater recharge is the most difficult groundwater budget to simulate due to factors such as precipitation irrigation application evapotranspiration land use crop type and soil type a special condition of plant soil water interaction is the presence of saturated conditions in the root zone of crops i e waterlogging which can decrease crop yield and damage soil health and structure cannell et al 1980 cavazza and pisa 1988 collaku harrison n d houk et al 2006 2006 2006 kaur et al 2017 360 million loss of crop production every year during 2010 2016 is due to waterlogging and even greater loss than drought in the united states ploschuk et al 2018 waterlogging can dramatically change the dynamics of carbon and nitrogen in soil the resulting anaerobic condition decreases the rate of organic matter decomposition meurant and riker 2014 resulting in an accumulation of soil organic matter that affects nitrogen mineralization and available nitrogen for crop uptake and also increases denitrification which can increase methane ch4 emission and nitrous oxide n2o emission bartlett and harriss 1993 parton et al 2001 both of which are greenhouse gases there are many numerical physically based models that simulate a range of hydrologic and chemical processes in the plant water soil system a subset of these models is agronomic models that simulate hydrologic in a one dimensional domain at the soil profile scale these include swap kroes et al 2009 dssat jones et al 2003 and daycent parton et al 1998 zhang et al 2018a b they simulate irrigation runoff infiltration and percolation through soil layers crop et and deep percolation from the bottom of the soil profile however as they do not simulate groundwater flow in the saturated zone of the underlying aquifer the fluctuation of the water table and its possible presence in the soil profile and crop root zone is not represented the soil water assessment tool swat arnold et al 1998 simulates hydrological processes and crop yield at the watershed scale with a water balance occurring at individual hydrologic response units hrus across the watershed landscape the model accounts for groundwater storage and groundwater discharge to streams but does not simulate water table fluctuation in a physically based manner and hence cannot account for waterlogging effects on root zone processes and crop yield even the linked swat modflow model bailey et al 2016 does not account for the condition of shallow groundwater in the root zone modflow may simulate a water table at the elevation of an hru s soil profile but it has no effect on swat s hru soil profile and root zone processes the linked dssat modflow model xiang et al 2020 also does not account for the effect of shallow groundwater on root zone processes as the linkage between the models is performed at the annual time scale and day to day dssat root zone hydrological processes are not affected by modflow simulated water table elevation another subset of models simulates vadose zone hydrologic processes and water table fluctuation but do not simulate near surface hydrology vegetative growth root zone processes and nutrient cycling these include the hydrologic and hydrogeologic models modflow niswonger et al 2011 hydrus šimůnek et al 2012 modflow surfact panday and huyakorn 2008 stomp white and oostrom 2003 tough2 pruess et al 1999 vs2di healy 2008 the vsf package thoms et al 2006 and hydrogeosphere therrien et al 2010 among many others there is a general lack of hydro agronomic models wherein the simulated water table affects root zone processes and root zone processes in turn affect recharge to the water table the objective of this paper is to present a coupled agroecosystem groundwater modeling system that can simulate water movement under waterlogged conditions the daycent and modflow are chosen as the agroecosystem and groundwater models respectively daycent was selected as it includes carbon and nitrogen dynamics in agroecocystems and thus is more versatile in applications modflow is chosen as it is the most widely used groundwater flow model worldwide langevin et al 2017 the models are tightly coupled with system data passed between them on a daily time step using a novel message passing interface mpi gropp et al 1996 that avoids code modification to daycent and modflow codes and therefore can work with updated versions of daycent and modflow daycent improves recharge calculations to modflow and modflow improves the accuracy of crop yield and nutrient cycling of daycent in the presence of a shallow water table although the daycent modflow linked system can be applied to any plant soil water system an application to an irrigated area with shallow groundwater in northern colorado usa will be shown to demonstrate its capability in waterlogged conditions the impact of waterlogged conditions on greenhouse gases will also be briefly described in the model application 2 methods this section provides information about the daycent and modflow models and a description of how they are tightly coupled using the mpi method 2 1 introduction to modflow groundwater flow model modflow is fortran written program koelbel et al 1994 that numerically solves the three dimensional ground water flow equation by using a finite difference method mcdonald and harbaugh 1988 niswonger et al 2011 modflow is the most widely used groundwater flow model in the world versions include modflow 88 mcdonald and harbaugh 1988 modflow 96 harbaugh and mcdonald 1996 modflow 2000 harbaugh et al 2000 modflow nwt niswonger et al 2011 and modflow 6 langevin et al 2017 in this study modflow nwt version is used to couple with daycent due to its efficiency and focus on solving nonlinear systems modflow nwt simulates groundwater head throughout an aquifer system by solving the groundwater flow equation for a porous medium the flow equation for an unconfined aquifer bedekar et al 2012 is 1 x f s k x x h x y f s k y y h y z f f k z z h z w ϕ f s t f s s s h t where x y z are the three dimensions h is groundwater head l k is hydraulic conductivity l t s s is specific storage 1 t ϕ is porosity taken equal to specific yield s y f s is the fraction of the cell thickness that is saturated and f f is a function of f s set to 1 for niswonger et al 2011 modflow also solves the equation for confined aquifers but this study is concerned with water table interaction in soil zones and hence equation 1 is presented the finite difference method is used to solve equation 1 by discretizing the groundwater system spatially into a grid of cells and the simulation time period into time steps each cell is interpreted as a small volume of aquifer material with the same hydraulic properties the equation describes the volumetric water balance within each of the cell with groundwater inputs including groundwater flow from adjacent cells and other groundwater sources e g recharge seepage and groundwater outputs including flow to adjacent cells and other groundwater sinks e g et pumping discharge the aquifer hydraulic properties include hydraulic conductivity k specific yield s y and specific storage s s although the primary variable of solution is groundwater head h flow rates using h can be calculated at each time step 2 2 introduction to daycent agroecosystem model the daycent model william j parton et al 1998 zhang et al 2018 is a medium complexity agroecosystem model the major sub models of daycent are plant growth soil water soil organic carbon soil nitrogen and greenhouse gas fluxes major inputs for the model are daily weather soil physical properties plant type and management practices daycent has been widely used for carbon and nitrogen simulations in agroecosystems s j del grosso et al 2008 stephen j del grosso et al 2006 robertson et al 2018 zhang et al 2013 the model was selected to estimate soil co2 and n2o emissions removals for the us national greenhouse gas inventory usepa 2021 which is annually submitted to the un framework convention on climate change united nations 1992 the crop growth production sub model has been used in simulations of agroecosystem dynamics not only in the u s but also globally cheng et al 2014 s j del grosso et al 2008 gautam et al 2020 lee et al 2012 stehfest et al 2007 zhang et al 2020 recently the daycent model has been improved in simulations of crop canopy development growth and water use zhang et al 2020 zhang et al 2018 zhang et al 2018 this new version of daycent is used in this study for coupling with modflow daycent is written in fortran and c kernighan and ritchie 2006 the daycent modeling code includes the main water balance components for a soil profile infiltration of precipitation and irrigation surface runoff deep percolation from the bottom of the soil profile evapotranspiration et evaporation and transpiration and capillary rise of groundwater 3 δ s i p i n e t e t c r o d p g w where δs i is the net change in soil water at the end of day i and i 1 in this equation p ro and dp are precipitation runoff and deep percolation on day i respectively i net is the net irrigation on day i gw is the ground water contribution if a shallow water table is present et c is the actual evapotranspiration on day i all units are in cm day 1 the soil profile is defined by users which is usually less than 3 m in depth the input soil parameters include soil texture bulk density and field capacity wilting point and saturated hydraulic conductivity reference et is simulated using either the standardized penman monteith method allen et al 1998 or the hargreave s method hargreaves and allen 2003 with the latter used when only air temperature is available the solar radiation wind speed and relative humidity are required to run the penman monteith method crop coefficients are used in conjunction with reference et to estimate potential et for each crop type the et is partitioned into potential evaporation and potential transpiration as a function of the green canopy coverage and residue coverage the green canopy coverage cc is calculated from beer s law monsi and saeki 1953 sellers 1985 4 c c 1 exp k g l a i where k dimensionless is the light extinction coefficient of the vegetation and glai is green leaf area index m m 1 the glai and cc approach was recently added to daycent and the detailed description can be found in zhang et al 2018a b water uptake by root is limited by soil available water regarding potential soil evaporation it can be reduced by the amount of standing dead biomass and litter on the soil surface in daycent actual evaporation is also limited by the soil water potential of the top soil layer and the upward fluxes from underlying layers parton et al 1998 daycent simulates 1d water flows using a combined method a modified tipping bucket approach for water flow above field capacity and a richards approach richards 1931 for water re distribution below field capacity parton et al 1998 water table is simply simulated by turning off the drainage of water at the last soil layer for a user specified period when water table is present the water infiltrated from soil surface starts to saturate soil from the bottom in the linked daycent modflow the presence of water table in daycent simulation is controlled by the water table elevation in modflow section 2 3 nitrogen dynamics are simulated in daycent model using the mass balance of nitrogen in soil 5a δ n n l i t t t e r n f e r t n d e p o s i t n g a s n e r o s i o n n d p n r o o t where n litter is nitrogen added from plant litter n fert includes both organic and inorganic fertilizer n deposit is atmospheric nitrogen deposition n gas is gas removed via nitrification and denitrification and includes n 2 n 2 o and no x gases n erosion is the loss due to soil erosion n dp is the removal from the soil profile via deep percolation both inorganic and organic forms and n root is plant root upake the emission of ch4 is produced in soil under anaerobic conditions by methanogens in daycent the rate is primarily determined by the availability of carbon substrate derived from decomposition and root rhizo deposition for methanogens and the impact of environmental variables including soil texture redox potential ph and soil temperature climate and agricultural practices hartmann et al 2016 methane oxidation under aerated conditions is also modeled by daycent as a function of soil temperature soil water content porosity and field capacity grosso et al 2000 del grosso et al 2000 daycent simulates soil n2o and nox emissions from nitrification and denitrification w j parton et al 2001 nitrification is calculated as a function of soil ammonium nh4 concentration soil moisture soil temperature ph and soil texture denitrification is a function of soil nitrate concentration labile carbon availability o2 availability soil water content and soil physical properties that influence gas diffusivity 2 3 description of daycent modflow theory this section describes the basic linkage between daycent and modflow i e which information is passed between the two models and when section 2 4 provides details regarding the message passing interface mpi used to link the models without invasive code modification to either daycent or modflow section 2 5 describes an application of daycent modflow to a waterlogged site in an agricultural area of northern colorado usa daycent modflow is linked on a daily time step with results from each model providing inputs and constraints on the other therefore the linkage could be termed tight linkage or tight coupling the linkage process through time steps of a simulation is shown in fig 1 each daycent model is mapped to one cell of the top layer of the modflow grid as daycent is a 1d field scale model multiple daycent simulations are included to represent the collection of cultivated fields overlying the unconfined aquifer therefore multiple daycent models are linked to a single modflow model based on the geological locations the simulation runs according to the following steps repeated for each time step 1 modflow passes basic grid cell information to the set of daycent models surface elevation top of modflow grid cells bottom elevation of modflow grid cells specific yield s y of aquifer material and saturated hydraulic conductivity k of top layer table 1 the soil and aquifer properties are shared between daycent and modflow if the time step is the first of the simulation modflow also passes initial groundwater head values for each grid cell 2 the received values are assigned to corresponding model variables for each daycent model 3 each daycent model is run for the time step 4 the recharge rate calculated by each daycent model is sent to corresponding modflow grid cells within the recharge package modflow then runs for the time step modflow groundwater head for each grid cell is passed to the corresponding daycent model in preparation for the next time step run this process is continued until the end of the simulation daycent has two modes of running based on the received groundwater head from modflow the first mode is the normal running of daycent in which the water table is not present in the root zone in the first mode daycent simulates unsaturated water flow crop et and soil water content in the root zone according to the weather and irrigation schedule at the end of the time step it outputs deep percolation from the bottom of the root zone and passes it as recharge to modflow grid cells the second mode is when groundwater head is above the bottom of the root zone i e the water table is present in the root zone this condition is shown in fig 2 illustrating the daycent soil layers the modflow grid cells and the water table located in the root zone this requires an adaptation by daycent to account for groundwater influence on hydrologic and chemical processes in the root zone and a precise accounting of water mass within the root zone between the two models to preserve the mass of water we calculate the change of groundwater storage in modflow grid cells and make the same amount of water change in daycent this is calculated as 5b d e l t a i j s y j h i j h i 1 j where i is the time step j is the location cell delta i j is the water changed in modflow at time step i and location j sy j is the specific yield at location j h i j h i 1 j is the head difference at the end of the day between consecutive time steps depending on the change daycent either drains water from or injects water to the root zone layers to maintain the same condition as simulated by modflow after the time step daycent either passes a positive or negative recharge to modflow based on the change of saturated water level in the root zone equation 6 the positive recharge normally comes from deep percolation whereas negative recharge can be root uptake and capillary rise in the root zone 6 r e c h i j s w c i j s w c i 1 j where rech i j is the groundwater recharge generated by daycent swc i j swc i 1 j is the soil water content between time steps if the simulated groundwater head by modflow is above the ground surface daycent routes the ponded water as surface runoff and passes the same amount as negative recharge to modflow equation 7 7 r u n o f f i j s y j h i j e l v s u r f where runoff i j is the runoff when the water table is above surface 2 4 description of daycent modflow linkage using mpi a key requirement of the daycent modflow linkage is to limit model invasiveness i e the need to change the code of either or both models model code modification such as that performed by bailey et al 2016 to link swat and modflow requires code updating if new functions or changes from their latest versions are needed to be used model updates can be handled more easily if linkage procedures are accomplished strictly via non invasive procedures in this study therefore daycent is not integrated into modflow but instead they are linked using message passing interface gropp et al 1996 an inter process communication technique all communication between modflow and daycent see fig 1 is achieved using mpi mpi is a message passing library in parallel computation mpi specifies the names calling sequences and results of subroutines to be called in fortran or other languages the program is still compiled with ordinary compilers but linked with the mpi library gropp et al 1999 mpi has become the most popular message passing library standard for parallel programming quinn 2003 mpi assumes the underlying hardware is a collection of processors with its own local memory fig 3 a each processor only has access to the instructions and its local memory however the interconnection work allows message passing between processors through implicit channels mpi is served as a communication function that enables processes to communicate with each other mpi also supports synchronization between processors one processer cannot receive the message and continue the process unless another process sends to it mpi has two principal advantages over other message passing models it runs well on mimd multiple instructions multiple data architectures which are used in this study and it is easier to debug than shared variable programs since each processor has its own controls of memory quinn 2003 for linking daycent and modflow the following four main functions are used mpi send mpi recv mpi scatter and mpi gather mpi send and mpi recv are basic calls to send message either as data points or as arrays of values from one processor to another processor each mpi recv must have a corresponding mpi send for the program to continue mpi scatter and mpi gather are one to multiple and multiple to one processes the message in the source processor is scattered to other processors each processor receives a part of the copy from the original message this is often used for array scatter each processor receives a portion of the array mpi gather gathers different messages from other processors into one message and saves it in the source processor mpi scatter and mpi recv are vital when coupling 1d and 2d models such as with daycent and modflow the recharge rates sent from the daycent field scale models to the single modflow model are applied to the top cells of the modflow grid the water table elevation i e groundwater head sent from the modflow grid cells to the daycent models is applied to the soil profiles of each individual daycent simulation hence the mpi process is a set of 1d models daycent communicating with a 3d model modflow and vice versa see fig 3b since there is only one modflow model in the coupled system there is just one processor for modflow all other processors are used for daycent after splitting the processors in each group are assigned a new rank number as their id there are also two communicators one is for communicating between modflow and daycent the second is for communicating between the multiple daycent models as multiple daycent simulations start the source processor rank 0 reads an info array from the soil and crop file which contains the information of the cells soil physical properties crop type and their corresponding locations in modflow the information passed from modflow to the daycent simulations is added to the info array by matching their locations this information is then scattered to all other daycent processors by doing so each daycent simulation is linked to a unique modflow grid cell location with a unique rank and run with unique information such as crop type and associated crop scheduling when there are multiple crops in one grid cell the majority crop is used in daycent model fig 3b shows the forward step with mpi scatter after daycent simulations run for a time step recharge values are gathered using mpi gather and sent to corresponding modflow grid cells which is the reverse step of fig 3b this finishes the entire mpi process in this study open mpi library is employed using the linux system daycent and modflow are run separately using the command mpirun all mpi processes are coded in modules using fortran to make minimum modifications to the original code generally the number of daycent simulations is much more than the number of processors contained in a typical desktop computer one common feature of computer operating systems is multitasking which allows more than one task to run in one processor reilly 2004 multitasking is not a parallel execution as it allows time sharing and scheduling of cpus oracle 2016 one of the disadvantages of mpi is that all processes start at the same time resulting in intensive memory allocation the input file for daycent modflow is the same input file format for original daycent and modflow simulations except for the additional soil and crop file in modflow any recharge values listed in the recharge package input file are eliminated from the simulation as recharge arrays will be populated by daycent deep percolation values in modflow the water budget now includes recharge received from daycent the water balance from daycent consists of irrigation and precipitation infiltration runoff evaporation and transpiration upflux or drainage caused by the change of water table in modflow deep percolation and the change in soil water content 2 5 application of daycent modflow a highly irrigated area in the south platte river basin in northern colorado fig 4 a and b is selected as our study area for the application of the daycent modflow modeling system the study area is approximately 4 7 km 4 7 km fig 4c with 83 of the area covered by crops main crop types include alfalfa corn grass pasture wheat and sugar beets soils are mainly sandy but there are pockets of clay accumulation due to a semi arid climate and low annual rainfall rates 35 cm yr irrigation is used to satisfy crop et irrigation water is supplied during the growing season april october either by groundwater pumping from the underlying unconfined aquifer or by canals that divert water from the south platte river there are 40 pumping wells and 4 canals in the study area see fig 4c model application for this site was chosen due to the prevailing high groundwater levels in the region waterlogging due to high groundwater levels has been a problem for landowners for many years for many areas the water table is within 2 m of the ground surface high groundwater levels are caused by a combination of canal seepage high rates of deep percolation from irrigation events and a decrease in pumping over the previous 15 decades due to water right issues deng and bailey 2020 the modflow model grid consists of 31 rows and 31 columns fig 5 a with each cell 152 m 152 m 500 ft 500 ft and 10 vertical layers that represent the unconfined aquifer from the ground surface to the shale bedrock the thickness of the aquifer ranges from 4 7 m to 36 1 m the values for the grid cells are obtained from a larger modflow model of the study region calibrated and tested against groundwater levels deng and bailey 2020 a 3d hydraulic conductivity k map fig 5b was developed by interpolating data from over 400 boreholes using a 3d kriging method and then mapping to the grid cells deng and bailey 2020 for this study aquifer source sink fluxes for modflow include canal seepage and groundwater pumping with recharge provided by daycent within the coupled system time variant specified head boundary conditions are applied for each grid cell along the perimeter of the model domain using results from the larger regional model the soil physical property data is obtained from ssurgo soil survey geographic database irrigation parcel data were obtained from colorado s decision support system cdss for the region crop rotation data were obtained from the cropland data layer cdl of nass national agricultural statistics service management schedules were set up for nine crops in daycent for each daycent simulation the root zone is divided uniformly into 14 layers for a total thickness of 210 cm parameters for each crop type were based on values from other studies in the south platte river basin dozier et al 2017 zhang et al 2020a b c crop management data including planting dates harvest dates and fertilizer rates were obtained from nass usda nass 2003 2010 each modflow cell that has crop cover in the top layer is corresponding to one daycent model resulting in 806 models fig 5a the coupled model was simulated for the 2000 2012 period using monthly stress periods i e flow rates of external groundwater stresses such as pumping are kept constant over a month for modflow and daily time steps for both models the model was run on an amazon aws linux server with 96 cpus and 384 gb ram with the maximum number of open files changes from 1024 to 1 million the model took 9 h to run model results were compared to 100 observed groundwater head values from five monitoring wells see fig 4c and reference et from the various crop types 3 results and discussion 3 1 modflow head results head comparison depth to water table map simulated groundwater levels are compared to observed levels in figs 6 and 7 fig 6a shows the 1 1 plot of measured groundwater head vs simulated groundwater head for the simulation period the mean absolute error mae is 0 98 m and the root mean square error rmse is 0 78 m the histogram of residuals difference between measured and simulated is shown in fig 6b showing that most of the residuals are 1 m with an average residual mean of errors of 0 48 m knowing that the average aquifer thickness in this region is 5 36 m the residuals between simulated and measured head values indicate that the modflow model simulates the groundwater system in a reasonable manner fig 7 shows an interpolated spatial map of observed groundwater depth ground surface to the water table fig 7a for spring 2012 compared to an interpolated map of simulated groundwater depth values from the modflow cells fig 7b the areas marked in red indicate waterlogging water table 2 m from the ground surface and hence in the root zone of the crops in general the simulated results capture the principal patterns in the system with most waterlogging happening in the areas centered in the irrigation area the shallow groundwater levels were simulated in the northwest portion of the study region due to the thinness of the aquifer near the south platte river fig 8 a shows the cross section of ground surface water table elevation and bedrock elevation through a west east transect of the study area for spring 2012 showing a high water table in the west central portion of the region see fig 7 fig 8b shows the percent of area waterlogged defining waterlogging as groundwater within the root zone 2 m from the ground surface the average waterlogged area between 2000 and 2012 is 8 with more area waterlogged during the initial and later years of the period the increase in waterlogging during the 2006 2010 period is likely due to an overall decrease in groundwater pumping and increase in surface water irrigation in the region due to water right considerations deng and bailey 2020 3 2 et results from daycent et for each crop comparison et map to crop type the daily average crop et over the entire study area is plotted in fig 9 a showing high values during the irrigation season and regular fluctuations from year to year the average daily et is 1 2 mm and high values of et are approximately 4 mm day the average daily et during the irrigation season may september is about 2 2 mm a plot of average simulated et of each daycent model for a single day in june 2010 is shown in fig 9b the average et is 4 mm and the highest et is 5 5 mm the spatial distribution of et is compared to crop type in fig 10 fig 10a shows the crop type for each field and fig 10b shows the simulated et for a selected day in june 2010 with results color coded to match the crop type in fig 10a that generates the specific range of et values results show a high correlation between the crop type and the resulting et for example the areas with corn red correspond to a specific range of et depths generated from a field with corn the result demonstrates the correct spatial mapping between the modflow grid and the daycent models some areas do not match due to the same crop type having various of et depths in different locations because of different soil water conditions also each modflow cell simulates only a single crop and often there are multiple crop types for a single cell the estimated reference et for each crop type is used to test simulation results as there are no field based et measurements in the study area et values were collected from the coagmet colorado agricultural meteorological network data at lasalle colorado just north of the study area and calculated using the asce standardized method fig 11 shows a time series of daily et cm for both reference et and the model for 7 crop types during 2012 the majority of et occurs during the irrigation season between days 100 and 300 april september the reference and simulated et rates for alfalfa corn grass hay and small grain match well with a mean error of approximately 0 02 cm et for small grain is slightly underestimated with a mean error of 0 04 cm et for sugar beets and potatoes are slightly overestimated although generally simulated et rates match reference et rates quite well for each crop type 3 3 general daycent modflow model outputs the rates of water exchange between modflow and daycent are plotted in fig 12 for each day during the 2000 2012 simulation period fig 12a shows the daily average water depth passed to daycent from modflow positive values indicate that the water table is present in the root zone after the modflow daily simulation and water is passed from modflow to the daycent models conversely negative values indicate that water level dropped in the root zone after moflow simulation and daycent receive it as water loss results from fig 12a demonstrate that many interactions are occurring in the root zone between daycent and modflow particularly during the times of increased waterlogging during 2000 2003 and 2007 2012 see fig 8b the increased waterlogging pattern can also be found in fig 12b showing the amount of water passed from daycent to modflow during the simulation period there are no negative values because the time series is a monthly averaged depth positive values indicate deep percolation or water storage increases in the root zone due to precipitation or irrigation whereas negative values occur when there is more et than infiltration 3 4 greenhouse gas results ch4 and n2o greenhouse gas emissions varied with soil saturated conditions the average gas emissions for n2o kg n ha and ch4 kg c ha are shown in fig 13 a study near fort collins co approximately 60 km from the study area estimated annual n2o emissions between around 1 4 and 1 8 kg n ha with high fertilizer application for corn between 2002 and 2006 halvorson et al 2009 in our study due to waterlogging conditions the simulated n2o emission is much lower than the measured rates in halvorson et al 2009 with an average annual emission of 1 2 kg n ha with lower values occurring during the increased waterlogging activity of 2000 2002 and 2007 2012 however even during times of non waterlogging the emission rates are much lower than what is observed in halvorson et al 2009 therefore we note that the model has not been calibrated to field estimated emission rates these results are provided as a proof of concept to demonstrate that emission rates are decreased under waterlogged conditions regarding ch4 emission well drained agriculture soil without waterlogging is usually a sink of ch4 powlson et al 1997 under waterlogging conditions soil becomes a source and the amount of ch4 emission depends on various factors such as crop type water saturated periods and soil temperature bartlett and harriss 1993 average annual ch4 emission simulated in the study area fig 13b is 19350 kg c ha 3 5 model limitations and future work the model is computationally expensive and requires many processors and ram due to parallel processing the set up is quite time consuming due to the need for one daycent model for each modflow grid cell as presented the coupled model is ideal for investigating the influence of shallow groundwater on root zone processes for small 50 km2 agricultural areas one possible solution is to group the grid cells into hydrologic response units hrus which have similar hydrologic characteristics soil type topographic slope land use however this process would decrease the accuracy of the model because the water table varies within the hru and can have an impact on soil variables in daycent in future work the model coupling will be modified to transport nutrients and carbon species between the groundwater and the soil water furthermore the coupled model is a 1d daycent 3d modflow combination in which 2d processes such as surface runoff and overland flow are not explicitly simulated modifications to the modeling code i e routing runoff from daycent simulated fields to nearby streams would need to be included if the model were to be used in a watershed setting where water and nutrient yield to the watershed stream network were important 4 summary and conclusions in this study a new hydro agronomic model is introduced by integrating the modflow 3d groundwater flow model and the daycent 1d agronomic hydrologic model to simulate water table elevation crop et and greenhouse gas emissions in the root zone of waterlogged areas the model can be applied to any agricultural areas but coding has been aimed at ensuring the correct representation of these processes in areas of shallow groundwater the coupling between a single modflow model and a suite of field scale daycent models is achieved by applying mpi message passing interface parallel programing daycent passes recharge to modflow whereas modflow passes soil water to daycent in the case of groundwater head rising to within the root zone of simulated crops there are several advantages of using daycent modflow over other linked agronomic groundwater models 1 groundwater recharge is calculated by daycent an agroecosystem model aimed at field scale processes 2 groundwater recharge is calculated within the root zone under waterlogged conditions considering daily interactions between the two models 3 daycent et algorithms are constrained by the presence of shallow groundwater under waterlogging conditions 4 the models are simulated separately but simultaneously using the mpi infrastructure minimizing code invasiveness for either model 5 the parallel process greatly decreases overall run time the coupled daycent modflow model is applied to a waterlogged irrigated area near lasalle colorado within the semi arid south platte river basin model results are compared against observed groundwater levels and reference et for 7 crop types demonstrating accuracy in simulating these system response variables simulated emission rates kg ha for n2o and ch4 are loosely compared to annual emission rates from the region the model can be used to assess recharge and gas emissions under deep and shallow water table conditions in agricultural areas 5 software availability software name daycent modflow model developer chenda deng yao zhang and ryan t bailey year first official release 2021 hardware requirements amazon web services server system requirements linux program language fortran and c availability the coupled model and its input files can be found in the zenodo online data repository https zenodo org record 4822704 yk 2lrvkibg https doi org 10 5281 zenodo 4822704 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was performed through grants from the colorado water conservation board state of colorado department of natural resources grant no 201900000014 
25807,waterlogging on croplands has been a known problem for a long time leading to adverse social physical economic and environmental issues to better solve the problem the complicated plant soil water dynamics system needs to be better understood the challenge is to simulate the interactions between the components in the systems there are models that simulate plant soil water system but either run the processes independently leading to inaccuracy or has high invasiveness of using integrated models this paper presents a tightly coupled model daycent modflow that links a 3d ground water flow modflow model and a 1d agroecosystem model daycent daycent is responsible for plant soil water dynamic in the root zone whereas modflow simulates head and groundwater flow in the saturated zone of the aquifer daycent passes deep percolation from the soil profile to the water table and under conditions of waterlogging in which the water table is within the soil profile daycent soil hydrologic processes are constrained by the presence of the water table simulated by modflow the coupling is achieved by adopting a parallel inter process communication technique mpi message passing interface the model is applied to a waterlogged agricultural area 22 km2 in northern colorado usa and tested against groundwater head and rates of evapotranspiration et the model runs in parallel with multiple processes on the largest aws linux server groundwater heads match measured heads to a reasonable degree and et rates match reference et and are highly correlated with crop type results show the strong hydrologic interaction between the two models greenhouse gas emissions from soil n2o and ch4 were also estimated by the model under the waterlogged conditions although the model can be used to simulate any plant soil aquifer system no matter the depth of the water table results from this study show that the model can be used to assess crop productivity recharge et and greenhouse gas emissions in areas of shallow groundwater keywords groundwater modeling modflow daycent message passing interface mpi waterlogging model coupling 1 introduction the plant soil water system controls the movement of water nutrients and greenhouse gases in agricultural landscapes understanding this system under a variety of hydrologic conditions is important for food production land management water management and nutrient management the plant soil water system is a complex system consisting of surface water runoff infiltration soil water dynamics evapotranspiration recharge and nutrient leaching carbon c nitrogen n cycling and consequent hydro chemical processes such as flow and nutrient transport in aquifers stream discharge and nutrient loading and greenhouse gas emissions the challenge of simulating water transport and nutrient cycling in such a complex system resides mainly in the interaction between zones such as water movement between the soil profile and the saturated zone of the aquifer as stated by alley alley et al 2002 groundwater recharge is the most difficult groundwater budget to simulate due to factors such as precipitation irrigation application evapotranspiration land use crop type and soil type a special condition of plant soil water interaction is the presence of saturated conditions in the root zone of crops i e waterlogging which can decrease crop yield and damage soil health and structure cannell et al 1980 cavazza and pisa 1988 collaku harrison n d houk et al 2006 2006 2006 kaur et al 2017 360 million loss of crop production every year during 2010 2016 is due to waterlogging and even greater loss than drought in the united states ploschuk et al 2018 waterlogging can dramatically change the dynamics of carbon and nitrogen in soil the resulting anaerobic condition decreases the rate of organic matter decomposition meurant and riker 2014 resulting in an accumulation of soil organic matter that affects nitrogen mineralization and available nitrogen for crop uptake and also increases denitrification which can increase methane ch4 emission and nitrous oxide n2o emission bartlett and harriss 1993 parton et al 2001 both of which are greenhouse gases there are many numerical physically based models that simulate a range of hydrologic and chemical processes in the plant water soil system a subset of these models is agronomic models that simulate hydrologic in a one dimensional domain at the soil profile scale these include swap kroes et al 2009 dssat jones et al 2003 and daycent parton et al 1998 zhang et al 2018a b they simulate irrigation runoff infiltration and percolation through soil layers crop et and deep percolation from the bottom of the soil profile however as they do not simulate groundwater flow in the saturated zone of the underlying aquifer the fluctuation of the water table and its possible presence in the soil profile and crop root zone is not represented the soil water assessment tool swat arnold et al 1998 simulates hydrological processes and crop yield at the watershed scale with a water balance occurring at individual hydrologic response units hrus across the watershed landscape the model accounts for groundwater storage and groundwater discharge to streams but does not simulate water table fluctuation in a physically based manner and hence cannot account for waterlogging effects on root zone processes and crop yield even the linked swat modflow model bailey et al 2016 does not account for the condition of shallow groundwater in the root zone modflow may simulate a water table at the elevation of an hru s soil profile but it has no effect on swat s hru soil profile and root zone processes the linked dssat modflow model xiang et al 2020 also does not account for the effect of shallow groundwater on root zone processes as the linkage between the models is performed at the annual time scale and day to day dssat root zone hydrological processes are not affected by modflow simulated water table elevation another subset of models simulates vadose zone hydrologic processes and water table fluctuation but do not simulate near surface hydrology vegetative growth root zone processes and nutrient cycling these include the hydrologic and hydrogeologic models modflow niswonger et al 2011 hydrus šimůnek et al 2012 modflow surfact panday and huyakorn 2008 stomp white and oostrom 2003 tough2 pruess et al 1999 vs2di healy 2008 the vsf package thoms et al 2006 and hydrogeosphere therrien et al 2010 among many others there is a general lack of hydro agronomic models wherein the simulated water table affects root zone processes and root zone processes in turn affect recharge to the water table the objective of this paper is to present a coupled agroecosystem groundwater modeling system that can simulate water movement under waterlogged conditions the daycent and modflow are chosen as the agroecosystem and groundwater models respectively daycent was selected as it includes carbon and nitrogen dynamics in agroecocystems and thus is more versatile in applications modflow is chosen as it is the most widely used groundwater flow model worldwide langevin et al 2017 the models are tightly coupled with system data passed between them on a daily time step using a novel message passing interface mpi gropp et al 1996 that avoids code modification to daycent and modflow codes and therefore can work with updated versions of daycent and modflow daycent improves recharge calculations to modflow and modflow improves the accuracy of crop yield and nutrient cycling of daycent in the presence of a shallow water table although the daycent modflow linked system can be applied to any plant soil water system an application to an irrigated area with shallow groundwater in northern colorado usa will be shown to demonstrate its capability in waterlogged conditions the impact of waterlogged conditions on greenhouse gases will also be briefly described in the model application 2 methods this section provides information about the daycent and modflow models and a description of how they are tightly coupled using the mpi method 2 1 introduction to modflow groundwater flow model modflow is fortran written program koelbel et al 1994 that numerically solves the three dimensional ground water flow equation by using a finite difference method mcdonald and harbaugh 1988 niswonger et al 2011 modflow is the most widely used groundwater flow model in the world versions include modflow 88 mcdonald and harbaugh 1988 modflow 96 harbaugh and mcdonald 1996 modflow 2000 harbaugh et al 2000 modflow nwt niswonger et al 2011 and modflow 6 langevin et al 2017 in this study modflow nwt version is used to couple with daycent due to its efficiency and focus on solving nonlinear systems modflow nwt simulates groundwater head throughout an aquifer system by solving the groundwater flow equation for a porous medium the flow equation for an unconfined aquifer bedekar et al 2012 is 1 x f s k x x h x y f s k y y h y z f f k z z h z w ϕ f s t f s s s h t where x y z are the three dimensions h is groundwater head l k is hydraulic conductivity l t s s is specific storage 1 t ϕ is porosity taken equal to specific yield s y f s is the fraction of the cell thickness that is saturated and f f is a function of f s set to 1 for niswonger et al 2011 modflow also solves the equation for confined aquifers but this study is concerned with water table interaction in soil zones and hence equation 1 is presented the finite difference method is used to solve equation 1 by discretizing the groundwater system spatially into a grid of cells and the simulation time period into time steps each cell is interpreted as a small volume of aquifer material with the same hydraulic properties the equation describes the volumetric water balance within each of the cell with groundwater inputs including groundwater flow from adjacent cells and other groundwater sources e g recharge seepage and groundwater outputs including flow to adjacent cells and other groundwater sinks e g et pumping discharge the aquifer hydraulic properties include hydraulic conductivity k specific yield s y and specific storage s s although the primary variable of solution is groundwater head h flow rates using h can be calculated at each time step 2 2 introduction to daycent agroecosystem model the daycent model william j parton et al 1998 zhang et al 2018 is a medium complexity agroecosystem model the major sub models of daycent are plant growth soil water soil organic carbon soil nitrogen and greenhouse gas fluxes major inputs for the model are daily weather soil physical properties plant type and management practices daycent has been widely used for carbon and nitrogen simulations in agroecosystems s j del grosso et al 2008 stephen j del grosso et al 2006 robertson et al 2018 zhang et al 2013 the model was selected to estimate soil co2 and n2o emissions removals for the us national greenhouse gas inventory usepa 2021 which is annually submitted to the un framework convention on climate change united nations 1992 the crop growth production sub model has been used in simulations of agroecosystem dynamics not only in the u s but also globally cheng et al 2014 s j del grosso et al 2008 gautam et al 2020 lee et al 2012 stehfest et al 2007 zhang et al 2020 recently the daycent model has been improved in simulations of crop canopy development growth and water use zhang et al 2020 zhang et al 2018 zhang et al 2018 this new version of daycent is used in this study for coupling with modflow daycent is written in fortran and c kernighan and ritchie 2006 the daycent modeling code includes the main water balance components for a soil profile infiltration of precipitation and irrigation surface runoff deep percolation from the bottom of the soil profile evapotranspiration et evaporation and transpiration and capillary rise of groundwater 3 δ s i p i n e t e t c r o d p g w where δs i is the net change in soil water at the end of day i and i 1 in this equation p ro and dp are precipitation runoff and deep percolation on day i respectively i net is the net irrigation on day i gw is the ground water contribution if a shallow water table is present et c is the actual evapotranspiration on day i all units are in cm day 1 the soil profile is defined by users which is usually less than 3 m in depth the input soil parameters include soil texture bulk density and field capacity wilting point and saturated hydraulic conductivity reference et is simulated using either the standardized penman monteith method allen et al 1998 or the hargreave s method hargreaves and allen 2003 with the latter used when only air temperature is available the solar radiation wind speed and relative humidity are required to run the penman monteith method crop coefficients are used in conjunction with reference et to estimate potential et for each crop type the et is partitioned into potential evaporation and potential transpiration as a function of the green canopy coverage and residue coverage the green canopy coverage cc is calculated from beer s law monsi and saeki 1953 sellers 1985 4 c c 1 exp k g l a i where k dimensionless is the light extinction coefficient of the vegetation and glai is green leaf area index m m 1 the glai and cc approach was recently added to daycent and the detailed description can be found in zhang et al 2018a b water uptake by root is limited by soil available water regarding potential soil evaporation it can be reduced by the amount of standing dead biomass and litter on the soil surface in daycent actual evaporation is also limited by the soil water potential of the top soil layer and the upward fluxes from underlying layers parton et al 1998 daycent simulates 1d water flows using a combined method a modified tipping bucket approach for water flow above field capacity and a richards approach richards 1931 for water re distribution below field capacity parton et al 1998 water table is simply simulated by turning off the drainage of water at the last soil layer for a user specified period when water table is present the water infiltrated from soil surface starts to saturate soil from the bottom in the linked daycent modflow the presence of water table in daycent simulation is controlled by the water table elevation in modflow section 2 3 nitrogen dynamics are simulated in daycent model using the mass balance of nitrogen in soil 5a δ n n l i t t t e r n f e r t n d e p o s i t n g a s n e r o s i o n n d p n r o o t where n litter is nitrogen added from plant litter n fert includes both organic and inorganic fertilizer n deposit is atmospheric nitrogen deposition n gas is gas removed via nitrification and denitrification and includes n 2 n 2 o and no x gases n erosion is the loss due to soil erosion n dp is the removal from the soil profile via deep percolation both inorganic and organic forms and n root is plant root upake the emission of ch4 is produced in soil under anaerobic conditions by methanogens in daycent the rate is primarily determined by the availability of carbon substrate derived from decomposition and root rhizo deposition for methanogens and the impact of environmental variables including soil texture redox potential ph and soil temperature climate and agricultural practices hartmann et al 2016 methane oxidation under aerated conditions is also modeled by daycent as a function of soil temperature soil water content porosity and field capacity grosso et al 2000 del grosso et al 2000 daycent simulates soil n2o and nox emissions from nitrification and denitrification w j parton et al 2001 nitrification is calculated as a function of soil ammonium nh4 concentration soil moisture soil temperature ph and soil texture denitrification is a function of soil nitrate concentration labile carbon availability o2 availability soil water content and soil physical properties that influence gas diffusivity 2 3 description of daycent modflow theory this section describes the basic linkage between daycent and modflow i e which information is passed between the two models and when section 2 4 provides details regarding the message passing interface mpi used to link the models without invasive code modification to either daycent or modflow section 2 5 describes an application of daycent modflow to a waterlogged site in an agricultural area of northern colorado usa daycent modflow is linked on a daily time step with results from each model providing inputs and constraints on the other therefore the linkage could be termed tight linkage or tight coupling the linkage process through time steps of a simulation is shown in fig 1 each daycent model is mapped to one cell of the top layer of the modflow grid as daycent is a 1d field scale model multiple daycent simulations are included to represent the collection of cultivated fields overlying the unconfined aquifer therefore multiple daycent models are linked to a single modflow model based on the geological locations the simulation runs according to the following steps repeated for each time step 1 modflow passes basic grid cell information to the set of daycent models surface elevation top of modflow grid cells bottom elevation of modflow grid cells specific yield s y of aquifer material and saturated hydraulic conductivity k of top layer table 1 the soil and aquifer properties are shared between daycent and modflow if the time step is the first of the simulation modflow also passes initial groundwater head values for each grid cell 2 the received values are assigned to corresponding model variables for each daycent model 3 each daycent model is run for the time step 4 the recharge rate calculated by each daycent model is sent to corresponding modflow grid cells within the recharge package modflow then runs for the time step modflow groundwater head for each grid cell is passed to the corresponding daycent model in preparation for the next time step run this process is continued until the end of the simulation daycent has two modes of running based on the received groundwater head from modflow the first mode is the normal running of daycent in which the water table is not present in the root zone in the first mode daycent simulates unsaturated water flow crop et and soil water content in the root zone according to the weather and irrigation schedule at the end of the time step it outputs deep percolation from the bottom of the root zone and passes it as recharge to modflow grid cells the second mode is when groundwater head is above the bottom of the root zone i e the water table is present in the root zone this condition is shown in fig 2 illustrating the daycent soil layers the modflow grid cells and the water table located in the root zone this requires an adaptation by daycent to account for groundwater influence on hydrologic and chemical processes in the root zone and a precise accounting of water mass within the root zone between the two models to preserve the mass of water we calculate the change of groundwater storage in modflow grid cells and make the same amount of water change in daycent this is calculated as 5b d e l t a i j s y j h i j h i 1 j where i is the time step j is the location cell delta i j is the water changed in modflow at time step i and location j sy j is the specific yield at location j h i j h i 1 j is the head difference at the end of the day between consecutive time steps depending on the change daycent either drains water from or injects water to the root zone layers to maintain the same condition as simulated by modflow after the time step daycent either passes a positive or negative recharge to modflow based on the change of saturated water level in the root zone equation 6 the positive recharge normally comes from deep percolation whereas negative recharge can be root uptake and capillary rise in the root zone 6 r e c h i j s w c i j s w c i 1 j where rech i j is the groundwater recharge generated by daycent swc i j swc i 1 j is the soil water content between time steps if the simulated groundwater head by modflow is above the ground surface daycent routes the ponded water as surface runoff and passes the same amount as negative recharge to modflow equation 7 7 r u n o f f i j s y j h i j e l v s u r f where runoff i j is the runoff when the water table is above surface 2 4 description of daycent modflow linkage using mpi a key requirement of the daycent modflow linkage is to limit model invasiveness i e the need to change the code of either or both models model code modification such as that performed by bailey et al 2016 to link swat and modflow requires code updating if new functions or changes from their latest versions are needed to be used model updates can be handled more easily if linkage procedures are accomplished strictly via non invasive procedures in this study therefore daycent is not integrated into modflow but instead they are linked using message passing interface gropp et al 1996 an inter process communication technique all communication between modflow and daycent see fig 1 is achieved using mpi mpi is a message passing library in parallel computation mpi specifies the names calling sequences and results of subroutines to be called in fortran or other languages the program is still compiled with ordinary compilers but linked with the mpi library gropp et al 1999 mpi has become the most popular message passing library standard for parallel programming quinn 2003 mpi assumes the underlying hardware is a collection of processors with its own local memory fig 3 a each processor only has access to the instructions and its local memory however the interconnection work allows message passing between processors through implicit channels mpi is served as a communication function that enables processes to communicate with each other mpi also supports synchronization between processors one processer cannot receive the message and continue the process unless another process sends to it mpi has two principal advantages over other message passing models it runs well on mimd multiple instructions multiple data architectures which are used in this study and it is easier to debug than shared variable programs since each processor has its own controls of memory quinn 2003 for linking daycent and modflow the following four main functions are used mpi send mpi recv mpi scatter and mpi gather mpi send and mpi recv are basic calls to send message either as data points or as arrays of values from one processor to another processor each mpi recv must have a corresponding mpi send for the program to continue mpi scatter and mpi gather are one to multiple and multiple to one processes the message in the source processor is scattered to other processors each processor receives a part of the copy from the original message this is often used for array scatter each processor receives a portion of the array mpi gather gathers different messages from other processors into one message and saves it in the source processor mpi scatter and mpi recv are vital when coupling 1d and 2d models such as with daycent and modflow the recharge rates sent from the daycent field scale models to the single modflow model are applied to the top cells of the modflow grid the water table elevation i e groundwater head sent from the modflow grid cells to the daycent models is applied to the soil profiles of each individual daycent simulation hence the mpi process is a set of 1d models daycent communicating with a 3d model modflow and vice versa see fig 3b since there is only one modflow model in the coupled system there is just one processor for modflow all other processors are used for daycent after splitting the processors in each group are assigned a new rank number as their id there are also two communicators one is for communicating between modflow and daycent the second is for communicating between the multiple daycent models as multiple daycent simulations start the source processor rank 0 reads an info array from the soil and crop file which contains the information of the cells soil physical properties crop type and their corresponding locations in modflow the information passed from modflow to the daycent simulations is added to the info array by matching their locations this information is then scattered to all other daycent processors by doing so each daycent simulation is linked to a unique modflow grid cell location with a unique rank and run with unique information such as crop type and associated crop scheduling when there are multiple crops in one grid cell the majority crop is used in daycent model fig 3b shows the forward step with mpi scatter after daycent simulations run for a time step recharge values are gathered using mpi gather and sent to corresponding modflow grid cells which is the reverse step of fig 3b this finishes the entire mpi process in this study open mpi library is employed using the linux system daycent and modflow are run separately using the command mpirun all mpi processes are coded in modules using fortran to make minimum modifications to the original code generally the number of daycent simulations is much more than the number of processors contained in a typical desktop computer one common feature of computer operating systems is multitasking which allows more than one task to run in one processor reilly 2004 multitasking is not a parallel execution as it allows time sharing and scheduling of cpus oracle 2016 one of the disadvantages of mpi is that all processes start at the same time resulting in intensive memory allocation the input file for daycent modflow is the same input file format for original daycent and modflow simulations except for the additional soil and crop file in modflow any recharge values listed in the recharge package input file are eliminated from the simulation as recharge arrays will be populated by daycent deep percolation values in modflow the water budget now includes recharge received from daycent the water balance from daycent consists of irrigation and precipitation infiltration runoff evaporation and transpiration upflux or drainage caused by the change of water table in modflow deep percolation and the change in soil water content 2 5 application of daycent modflow a highly irrigated area in the south platte river basin in northern colorado fig 4 a and b is selected as our study area for the application of the daycent modflow modeling system the study area is approximately 4 7 km 4 7 km fig 4c with 83 of the area covered by crops main crop types include alfalfa corn grass pasture wheat and sugar beets soils are mainly sandy but there are pockets of clay accumulation due to a semi arid climate and low annual rainfall rates 35 cm yr irrigation is used to satisfy crop et irrigation water is supplied during the growing season april october either by groundwater pumping from the underlying unconfined aquifer or by canals that divert water from the south platte river there are 40 pumping wells and 4 canals in the study area see fig 4c model application for this site was chosen due to the prevailing high groundwater levels in the region waterlogging due to high groundwater levels has been a problem for landowners for many years for many areas the water table is within 2 m of the ground surface high groundwater levels are caused by a combination of canal seepage high rates of deep percolation from irrigation events and a decrease in pumping over the previous 15 decades due to water right issues deng and bailey 2020 the modflow model grid consists of 31 rows and 31 columns fig 5 a with each cell 152 m 152 m 500 ft 500 ft and 10 vertical layers that represent the unconfined aquifer from the ground surface to the shale bedrock the thickness of the aquifer ranges from 4 7 m to 36 1 m the values for the grid cells are obtained from a larger modflow model of the study region calibrated and tested against groundwater levels deng and bailey 2020 a 3d hydraulic conductivity k map fig 5b was developed by interpolating data from over 400 boreholes using a 3d kriging method and then mapping to the grid cells deng and bailey 2020 for this study aquifer source sink fluxes for modflow include canal seepage and groundwater pumping with recharge provided by daycent within the coupled system time variant specified head boundary conditions are applied for each grid cell along the perimeter of the model domain using results from the larger regional model the soil physical property data is obtained from ssurgo soil survey geographic database irrigation parcel data were obtained from colorado s decision support system cdss for the region crop rotation data were obtained from the cropland data layer cdl of nass national agricultural statistics service management schedules were set up for nine crops in daycent for each daycent simulation the root zone is divided uniformly into 14 layers for a total thickness of 210 cm parameters for each crop type were based on values from other studies in the south platte river basin dozier et al 2017 zhang et al 2020a b c crop management data including planting dates harvest dates and fertilizer rates were obtained from nass usda nass 2003 2010 each modflow cell that has crop cover in the top layer is corresponding to one daycent model resulting in 806 models fig 5a the coupled model was simulated for the 2000 2012 period using monthly stress periods i e flow rates of external groundwater stresses such as pumping are kept constant over a month for modflow and daily time steps for both models the model was run on an amazon aws linux server with 96 cpus and 384 gb ram with the maximum number of open files changes from 1024 to 1 million the model took 9 h to run model results were compared to 100 observed groundwater head values from five monitoring wells see fig 4c and reference et from the various crop types 3 results and discussion 3 1 modflow head results head comparison depth to water table map simulated groundwater levels are compared to observed levels in figs 6 and 7 fig 6a shows the 1 1 plot of measured groundwater head vs simulated groundwater head for the simulation period the mean absolute error mae is 0 98 m and the root mean square error rmse is 0 78 m the histogram of residuals difference between measured and simulated is shown in fig 6b showing that most of the residuals are 1 m with an average residual mean of errors of 0 48 m knowing that the average aquifer thickness in this region is 5 36 m the residuals between simulated and measured head values indicate that the modflow model simulates the groundwater system in a reasonable manner fig 7 shows an interpolated spatial map of observed groundwater depth ground surface to the water table fig 7a for spring 2012 compared to an interpolated map of simulated groundwater depth values from the modflow cells fig 7b the areas marked in red indicate waterlogging water table 2 m from the ground surface and hence in the root zone of the crops in general the simulated results capture the principal patterns in the system with most waterlogging happening in the areas centered in the irrigation area the shallow groundwater levels were simulated in the northwest portion of the study region due to the thinness of the aquifer near the south platte river fig 8 a shows the cross section of ground surface water table elevation and bedrock elevation through a west east transect of the study area for spring 2012 showing a high water table in the west central portion of the region see fig 7 fig 8b shows the percent of area waterlogged defining waterlogging as groundwater within the root zone 2 m from the ground surface the average waterlogged area between 2000 and 2012 is 8 with more area waterlogged during the initial and later years of the period the increase in waterlogging during the 2006 2010 period is likely due to an overall decrease in groundwater pumping and increase in surface water irrigation in the region due to water right considerations deng and bailey 2020 3 2 et results from daycent et for each crop comparison et map to crop type the daily average crop et over the entire study area is plotted in fig 9 a showing high values during the irrigation season and regular fluctuations from year to year the average daily et is 1 2 mm and high values of et are approximately 4 mm day the average daily et during the irrigation season may september is about 2 2 mm a plot of average simulated et of each daycent model for a single day in june 2010 is shown in fig 9b the average et is 4 mm and the highest et is 5 5 mm the spatial distribution of et is compared to crop type in fig 10 fig 10a shows the crop type for each field and fig 10b shows the simulated et for a selected day in june 2010 with results color coded to match the crop type in fig 10a that generates the specific range of et values results show a high correlation between the crop type and the resulting et for example the areas with corn red correspond to a specific range of et depths generated from a field with corn the result demonstrates the correct spatial mapping between the modflow grid and the daycent models some areas do not match due to the same crop type having various of et depths in different locations because of different soil water conditions also each modflow cell simulates only a single crop and often there are multiple crop types for a single cell the estimated reference et for each crop type is used to test simulation results as there are no field based et measurements in the study area et values were collected from the coagmet colorado agricultural meteorological network data at lasalle colorado just north of the study area and calculated using the asce standardized method fig 11 shows a time series of daily et cm for both reference et and the model for 7 crop types during 2012 the majority of et occurs during the irrigation season between days 100 and 300 april september the reference and simulated et rates for alfalfa corn grass hay and small grain match well with a mean error of approximately 0 02 cm et for small grain is slightly underestimated with a mean error of 0 04 cm et for sugar beets and potatoes are slightly overestimated although generally simulated et rates match reference et rates quite well for each crop type 3 3 general daycent modflow model outputs the rates of water exchange between modflow and daycent are plotted in fig 12 for each day during the 2000 2012 simulation period fig 12a shows the daily average water depth passed to daycent from modflow positive values indicate that the water table is present in the root zone after the modflow daily simulation and water is passed from modflow to the daycent models conversely negative values indicate that water level dropped in the root zone after moflow simulation and daycent receive it as water loss results from fig 12a demonstrate that many interactions are occurring in the root zone between daycent and modflow particularly during the times of increased waterlogging during 2000 2003 and 2007 2012 see fig 8b the increased waterlogging pattern can also be found in fig 12b showing the amount of water passed from daycent to modflow during the simulation period there are no negative values because the time series is a monthly averaged depth positive values indicate deep percolation or water storage increases in the root zone due to precipitation or irrigation whereas negative values occur when there is more et than infiltration 3 4 greenhouse gas results ch4 and n2o greenhouse gas emissions varied with soil saturated conditions the average gas emissions for n2o kg n ha and ch4 kg c ha are shown in fig 13 a study near fort collins co approximately 60 km from the study area estimated annual n2o emissions between around 1 4 and 1 8 kg n ha with high fertilizer application for corn between 2002 and 2006 halvorson et al 2009 in our study due to waterlogging conditions the simulated n2o emission is much lower than the measured rates in halvorson et al 2009 with an average annual emission of 1 2 kg n ha with lower values occurring during the increased waterlogging activity of 2000 2002 and 2007 2012 however even during times of non waterlogging the emission rates are much lower than what is observed in halvorson et al 2009 therefore we note that the model has not been calibrated to field estimated emission rates these results are provided as a proof of concept to demonstrate that emission rates are decreased under waterlogged conditions regarding ch4 emission well drained agriculture soil without waterlogging is usually a sink of ch4 powlson et al 1997 under waterlogging conditions soil becomes a source and the amount of ch4 emission depends on various factors such as crop type water saturated periods and soil temperature bartlett and harriss 1993 average annual ch4 emission simulated in the study area fig 13b is 19350 kg c ha 3 5 model limitations and future work the model is computationally expensive and requires many processors and ram due to parallel processing the set up is quite time consuming due to the need for one daycent model for each modflow grid cell as presented the coupled model is ideal for investigating the influence of shallow groundwater on root zone processes for small 50 km2 agricultural areas one possible solution is to group the grid cells into hydrologic response units hrus which have similar hydrologic characteristics soil type topographic slope land use however this process would decrease the accuracy of the model because the water table varies within the hru and can have an impact on soil variables in daycent in future work the model coupling will be modified to transport nutrients and carbon species between the groundwater and the soil water furthermore the coupled model is a 1d daycent 3d modflow combination in which 2d processes such as surface runoff and overland flow are not explicitly simulated modifications to the modeling code i e routing runoff from daycent simulated fields to nearby streams would need to be included if the model were to be used in a watershed setting where water and nutrient yield to the watershed stream network were important 4 summary and conclusions in this study a new hydro agronomic model is introduced by integrating the modflow 3d groundwater flow model and the daycent 1d agronomic hydrologic model to simulate water table elevation crop et and greenhouse gas emissions in the root zone of waterlogged areas the model can be applied to any agricultural areas but coding has been aimed at ensuring the correct representation of these processes in areas of shallow groundwater the coupling between a single modflow model and a suite of field scale daycent models is achieved by applying mpi message passing interface parallel programing daycent passes recharge to modflow whereas modflow passes soil water to daycent in the case of groundwater head rising to within the root zone of simulated crops there are several advantages of using daycent modflow over other linked agronomic groundwater models 1 groundwater recharge is calculated by daycent an agroecosystem model aimed at field scale processes 2 groundwater recharge is calculated within the root zone under waterlogged conditions considering daily interactions between the two models 3 daycent et algorithms are constrained by the presence of shallow groundwater under waterlogging conditions 4 the models are simulated separately but simultaneously using the mpi infrastructure minimizing code invasiveness for either model 5 the parallel process greatly decreases overall run time the coupled daycent modflow model is applied to a waterlogged irrigated area near lasalle colorado within the semi arid south platte river basin model results are compared against observed groundwater levels and reference et for 7 crop types demonstrating accuracy in simulating these system response variables simulated emission rates kg ha for n2o and ch4 are loosely compared to annual emission rates from the region the model can be used to assess recharge and gas emissions under deep and shallow water table conditions in agricultural areas 5 software availability software name daycent modflow model developer chenda deng yao zhang and ryan t bailey year first official release 2021 hardware requirements amazon web services server system requirements linux program language fortran and c availability the coupled model and its input files can be found in the zenodo online data repository https zenodo org record 4822704 yk 2lrvkibg https doi org 10 5281 zenodo 4822704 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was performed through grants from the colorado water conservation board state of colorado department of natural resources grant no 201900000014 
25808,releases into the atmosphere resulting from accidents or malicious activities may be extremely diverse in nature and have harmful consequences for human health and the environment successfully managing such releases is a matter of the utmost importance for security services and governmental authorities for some decades atmospheric transport and dispersion at d models embedded in decision support systems dss have been operated in order to simulate the space and time distribution of hazardous materials and to assess their health impact on the population and on first responders in cases of emergency unfortunately the at d models in dss generally oversimplify the local or regional environment and are compromised by insufficient space and time resolution close to the source of the release thus we have developed a dss based on 3d multi scale weather forecast and lagrangian at d models in the frame of a project called emergencies as an emblematic example we have performed dispersion simulations of fictitious noxious releases from the inside or outside of public buildings both at micro scale in a very large domain encompassing the city of paris and its suburbs and at meso scale beyond this domain furthermore results have been produced in a time lapse consistent with emergency management thanks to large yet affordable computational resources providing emergency response actors with such operational accurate and reliable results may be extremely advantageous for both preparedness and response to emergencies ultimately state of the science at d models offer a sound validated new paradigm to support decision making by security services and their authorities facing contingent chemical biological radioactive nuclear or explosive cbrn e releases into the air graphical abstract example of visualizations in the emergencies project the large view is a 2d section of the plumes over the entire city of paris 2 h after the beginning of the first release the vignettes are oblique zooms of the plumes in the museum district bottom left hand side and in the administrative building bottom right hand side 20 min after the start of the fictitious releases in these two areas the green respectively orange tint corresponds to low respectively high concentrations of the released substance image 1 keywords 3d modelling and simulation weather forecast atmospheric dispersion health impact assessment decision support system emergency preparedness and response 1 introduction the air dispersion hazards of the past are infamously exemplified by the bhopal sharan and gopalakrishnan 1997 broughton 2005 and the fukushima christoudias and lelieveld 2013 mori et al 2015 sato et al 2018 catastrophes and also by the tokyo underground sarin attack okomura et al 1998 such events differ by their nature and by the extent of the affected areas from inside and around an infrastructure to regional and worldwide scales but they have in common to have led to dispersion hazards originating from releases of gases or particles into the atmosphere moreover such events are current long term threats due to the numerous industrial plants and the political tensions in our societies the releases into the air may be accidental ranging from minor events to disasters or hopefully less frequent malevolent as in the case of sabotage or terrorist attack they may involve toxic flammable or explosive materials threatening people s health and the environment materials may be as diverse as chemicals biological agents radionuclides or explosives also called cbrn e agents with drastically different effects on human health depending on the type and quantity of the released agents also the affected area may be limited to the vicinity of the source or extend up to very large distances from it in urban or industrial environments the intricate geometry of buildings combines with local and regional geography and topography e g in a coastal area or a rugged terrain to influence the distribution of hazardous materials through transport and dispersion because effective or potential deleterious releases may have dire human consequences and lead to societal disruption especially in crowded urban areas or in huge industrial sites they are considered to be a major concern by public security services and their local and national authorities to tackle the complex situations induced by air dispersion hazards modelers have long tried to provide relevant information such as danger areas but also safe areas to the first responders lee et al 1997 bianconi et al 2004 this makes it necessary to model the dispersion and health impact of hazardous releases over sites which are most often complex from the local scale up to the regional scale and potentially the global scale where noticeable health consequences may be observed or feared atmospheric transport and dispersion at d models need input data regarding the terrain land use and buildings as well as meteorological data the health consequences are estimated on the basis of the computed concentrations of the hazardous materials in the air and the computed deposition on the accessible surfaces the final results are intended to be directly operational as a map of the danger zones or of the counter measures that should be taken in general the suite of dispersion and health impact models is embedded in a computational tool or decision support system dss including a graphical interface displaying the data required by the modelling and the results of the modelling benamrane et al 2013 armand et al 2015a 2016a to be useful for the first responders and subsequently their local and national authorities the results of the dss must be ready in a moderate amount of time which should not exceed 15 30 min to give an order of idea this introduces a considerable constraint for modelling and simulation in past years this constraint has most often led the modelers to oversimplify the at d modelling as discussed later on on the contrary our paper aims at presenting a dss featuring 3d state of the science multi scale weather forecast models combined with an at d model able to handle nested domains and applying this system to a vast and highly resolved domain over paris and its suburbs also called greater paris the distribution in space and time of fictively released hazardous materials is simulated starting from the immediate vicinity of the source of the release up to the largest extent of the affected area as large and distant from the source it can be with this approach we wish to demonstrate not only the scientific value and interest but also the operational practicability of topical 3d modelling to provide security services with realistic and accurate thus reliable and safe impact assessment of dangerous releases concomitantly for huge domains such as those covering large cities at the appropriately high level of detail high performance computing hpc is necessary the paper is structured as follows section 2 is a concise overview of some well known dss and their modelling capabilities and limits section 3 illustrates the up to date capabilities of a dss developed for the so called emergencies project by integrating 3d meso scale and micro scale flow and dispersion models and section 4 discusses how these capabilities may be of benefit to civilian security services in conclusion we argue that state of the science 3d modelling and simulation of air dispersion hazards is the new paradigm for supporting emergency preparedness and response 2 overview of some major decision support systems for some decades the development of industrial activities notably in the nuclear sector has been a source of increased preoccupation for the population living around the facilities or beyond and for the environment in most countries concerns about human health and the environment have been driving forces behind efforts to strengthen regulatory requirements most often industrial plants produce atmospheric or liquid releases that are by products or waste products of their activities the releases may be linked to regular or to special and controlled operations they also may relate to undesired effects in the event of accident or sabotage the wide range of situations likely to affect plants requires that plant operators as well as the authorities in charge of issuing licenses to the operators estimate the consequences of such releases on human health and the environment it is thus understandable that numerous modelling tools have been developed in the aim of helping industry operators assess the impact of their installations and demonstrate if such is the case that the releases have no consequences for human health under normal operating conditions limited consequences in the event of hypothetical accidents and the weakest possible influence on the environment while the operators may also wish or be requested to perform on site measurements or an epidemiological survey such empirical evaluations are costly moreover they are impossible during the project phase of an installation and they are unable to cover all situations particularly accidents that can occur over the lifespan of a facility this highlights the value of at d and impact assessment models integrated in dss nuclear radiological or chemical accidents impairing large industrial installations are dreaded events for the operators of these facilities and also for local or national level authorities depending on the seriousness and consequences of the accidents public authorities also fear terrorist attacks or other malicious actions though different from accidents these actions may also lead to harmful effects for the population and the environment due to adverse atmospheric releases or liquid effluents also in these cases dss prove to be compulsory tools for evaluating the impact of such hopefully infrequent antisocial activities the previous considerations show that dss play an essential role for industrialists and public officials some well known dss dedicated to adverse atmospheric releases are presented hereafter with their main strengths and limitations consistently with the previous remarks the first facts to notice are the great number and worldwide distribution of dss dedicated to the at d prediction and subsequently health impact assessment the next observation is that dss have been designed in response to different motivations and for different purposes for instance institutes in some countries may be in charge of a specific kind of events like industrial accidents or cbrn e threats or a given nature of releases with a typical distinction between chemicals and radionuclides emitted respectively by industries or by nuclear power plants in routine operation or in the course of an accident this leads these institutes to use mainly at d models dedicated to the near field or to both the near field and the far field see the examples of disastrous events cited in the introduction of the paper and dss specialized in terms of released agents and sanitary consequences on the contrary institutes in other parts of the world may have to respond to a very large spectrum of situations implying releases into the air and ideally would like to handle one dss fitting all scenarios in general dss are developed by industrialists or by governmental agencies acting as national authorities for instance in the field of nuclear safety or by consultancy firms specialized in the field of risk assessment or security and counterterrorism most of the major dss have been developed through collaborations with universities and benefit from scientific endorsement the roles and uses of dss may vary considerably while some of them are the official modelling and decision support tools of the national authorities and their agencies in charge of emergency preparation and handling others are operated by corporate units and entities of private national or international companies of various sizes the users of dss may also differ greatly whether they are in charge of only a given industrial installation or act for public authorities at a local or national level and may face a panel of emergency situations involving any types of threat agents a distinction has to be drawn between two categories of potential users while non professional in modelling responders absolutely need being provided with dss having ergonomic graphical interfaces dispersion modelling specialists at a reach back center should be able to activate dss with a larger number of less intuitive options as commented on later in the paper users of 3d models embedded in advanced dss rather belong to the latter category a common trait of the users is that they all wish user friendly tools and agree on the statement that the more useable a dss the more adoptable it is the user interface of the dss is a central issue which would certainly deserve an extensive discussion although beyond the scope of the present paper as highlighted in the previous paragraphs many different dss have been designed to address adverse atmospheric releases thus it would be difficult to try to establish an exhaustive description of them to classify the dss is also trickier than one could expect diverse categorizations could be derived for instance according to the country of their original development but some dss have international ambitions the type of release that the dss handle could be another criterion but some dss consider multiple threat agents or both energetic and non energetic called passive releases alternatively the criterion could be the available models or the size of the simulation domain but dss may have different purposes and choices regarding the precision level in modelling all in all we decided to limit our discussion to a list of well documented dss chosen as examples namely hpac midas safer aloha phast ct analyst rodos argos and c3x without willing to categorize them this set of dss presents interesting advanced features and some of them provide a large number of functionalities while our aim is not to make a comparative study between the dss these systems are used to support the authors observations on the dss table 1 in the annex summarizes the main characteristics of the dss listed above for each of the nine dss reviewed table 1 features nine columns providing information about the acronym the full name the organizations that have been developing it the distribution and users the available at d models the threat agents accounted for as well as the source term models and exposure models the ergonomics of the graphical user interface additional information characterizing the dss and finally an internet link the main characteristics of the dss examined are summarized hereafter hpac usa chang et al 2003 purves and parkes 2016 miner et al 2019 simpson et al 2020 is an internationally known dss dedicated to cbrn e threats implying atmospheric releases it is a reference system in the usa developed under the auspices of the defense threat reduction agency dtra it is widely used by american agencies and in some countries especially the united kingdom hpac s main strength is its toolbox capabilities hpac can deal with numerous and various scenarios of radiological chemical or biological releases it implements three at d models with graduated levels of complexity and inclusion of built up areas the integration of several models in hpac and the models themselves are commented on later in this section meteorological input data are weather predictions local or remote measurements or a combination thereof hpac is not intended to be vastly and publicly distributed and users of hpac belong to usa and security agencies of allied countries midas usa goyal and al jurashi 1991 ccps 1995 and safer usa so et al 2008 tauseef et al 2011 are commercial products dedicated respectively to radiological and chemical risks they are in widespread use in industry in the usa and are also established in other countries worldwide one major strength of midas and safer is their connection to broader systems in charge of monitoring the impact of nuclear or chemical facilities on population health and the environment midas and safer are also able to use various meteorological input data such as weather predictions or measurements they both incorporate interesting and useful features such as source term estimation or assimilation of observations in the simulations however midas and safer have the drawback of being black boxes with a minimum description of the integral and possibly lagrangian at d models within in this regard their actual capabilities to explicitly account for the buildings on industrial sites or in urban areas remain uncertain aloha usa bellasio and bianconi 2005 frysinger et al 2007 tseng et al 2012 yadav et al 2020 is a freely available software associated with the cameo chemical database aloha is used widely around the world notably by various civilian security services such as firefighters aloha is very simple to use yet aloha is restricted to chemical products it relies only on a gaussian plume model with an option to deal with heavy gases and it cannot consider rough terrain or built up areas aloha can be operated with hysplit but even with this lagrangian dispersion model buildings are not accounted for schematically aloha has restrained mapping features even if it is possible to export results to geographic information systems gis phast norway pandya et al 2008 witlox et al 2009 2013 is a commercial software package considered worldwide as a reference by engineering consultants specialized in chemical risk studies but it is not much used by security services like the firefighters phast can deal with a multiplicity of scenarios of passive or energetic releases with special focuses on discharges from containers fires and explosions as far as explosion modelling is concerned the obstacles likely to be present on industrial sites can be accounted for in a simplified way however phast s at d modelling ability is limited to an integral model and it is not able to implicitly or explicitly account for buildings phast is equipped with a graphical user interface dedicated to creating calculation cases and displaying the results while phast has limited mapping features the results provided by the software can be exported to gis ct analyst usa moses et al 2006 leitl et al 2016 has been developed by the research laboratories of the us navy it has also been promoted notably by hamburg university ct analyst does not implement physical models as such but it uses the results of computational fluid dynamics cfd models more precisely large eddy simulation les of the atmospheric flow the at d module uses a combination of gaussian and lagrangian approaches to establish what is called nomographs of the areas impacted by releases as the flow computations are complex and very long the method provides a pre established wind flow database for each site of interest this is a major limitation in the operational use of ct analyst when real evolving meteorological conditions are considered or when a release occurs at an unforeseen place ct analyst is well known but its distribution to actual rescue teams in the usa and in germany remains undocumented rodos eu ehrhardt 1997 bartzis et al 2000 raskob et al 2006 and argos eu hoe and müller 2003 baklanov et al 2006 hoe et al 2009 are dss developed under the initiative of the european union and launched after the chernobyl accident they are essentially dedicated to radioactive releases and are intended for implementation in the european union the main strength of rodos and argos is that they propose a choice of at d models this characteristic originates from the participation of multiple institutions in europe with their own models in the development of rodos and argos dispersion models in these dss are gaussian lagrangian or eulerian models see table 1 in the annex for the list and details of the models another capability of rodos and argos is to be able to use the weather predictions of the national meteorological institutes in the countries where they are operated rodos and argos are mostly oriented toward preparedness and response to radiological or nuclear emergencies such as a more or less serious accident affecting a nuclear power plant more recently their purpose has been extended to emerging terrorist threats that could happen for instance in an urban district in this way rodos implements the lasat model that is also the model present in the lasair system designed for releases in the urban environment and argos is equipped with an urban module that considers the buildings in a simplified manner c3x france quélo et al 2007 champion et al 2013 korsakissok et al 2013 is a computational system developed and exploited by the institute of radiation protection and nuclear safety irsn in france to model and simulate the dispersion and the health consequences of radioactive atmospheric releases c3x comprises two dispersion models a gaussian model dedicated to the near field up to 100 km and an eulerian model dedicated to the far field at intercontinental distances c3x has been distributed to electricité de france which is the french electricity supplier c3x is fully dedicated to preparedness and response to radiological or nuclear emergencies typically in the event of a nuclear power plant accident c3x cannot handle chemical releases and does not involve any modelling features able to implicitly or explicitly account for buildings c3x is not devoted to competing with the dss previously cited in this review due to its status it is mentioned here as an example of a national modelling system developed to inform the safety authorities about the impact on the population and the environment in case of a radiological or nuclear event the description above and table 1 in the annex illustrate that dss have excellent capabilities for anticipating or managing crisis situations related to adverse atmospheric releases the main strength of the dss is either to be very simple to handle or on the contrary to provide numerous options to deal with a variety of emergency cases some dss have been conceived to respond to a single kind of emergency situation or a specific type of release thus their developers cannot be blamed for this factual situation while it is not a limitation a more general purpose of dss could be advisable in order to be capable to face the wide spectrum of release events furthermore dss do not always offer the capacity to use or combine input meteorological data weather predictions observations many of them consider releases only over flat terrains without obstacles or some of them take account indirectly of the orography through the driving meteorological data and of the topography via the surface stress dss can suffer a lack of proper internal potent cartographic capabilities or the absence of coupling with gis above all many dss have limits in terms of modelling the at d in industrial or urban environments indeed most dss implement gaussian models setting buildings aside or using simplified approaches to account for them and or integral models ignoring buildings and or lagrangian or eulerian models that generally do not account for built up areas moreover most dss present the disadvantages of coarse spatial resolution and or allowing computations only in domains with small dimensions some dss may have models adapted to different spatial scales for example a gaussian model in the near field and a lagrangian or eulerian model in the far field still there is no coupling between the scales hindering an actual multi scale approach to the flow and dispersion computations among the dss some of them implement several at d models this is the case of rodos and argos in which dispersion models present certain complementarities for instance regarding the spatial scales that are addressed still the intention behind the assembly of at d models in rodos and argos seems related to the development of the dss in collaborative frameworks between european countries represented by their national institutes more than the idea of tightly coupling several approaches hpac also belongs to the category of dss that combine a variety of dispersion models the models in hpac have been developed in the usa in the uk and in france and they complement each other as they are adapted to either natural or built up environments they can be considered to be of increasing complexity from the scipuff sykes et al 1996 deng et al 2004 advanced second order turbulence closure gaussian model to the udm gaussian model accounting for buildings hall et al 2003 brook et al 2003 and the pmss lagrangian particle dispersion model tinarelli et al 2013 obviously hpac development has been governed by an overall rationale and strategy whose strength is to account for the complexity of the environment moreover hpac takes into account the topography and the presence of built up areas which is consistent with the scales being treated by the models taking advantage of the strengths and removing the limitations of the most widespread dss allow us to establish the profile of an ideal system in terms of its modelling capabilities it should be able to carry out computations from the immediate vicinity of the source of the atmospheric release up to distances as far as necessary where the impact of the release becomes negligible in other words the modelling system should handle multiple spatial scales with high resolution where appropriate especially close to the source this modelling system should also be able to deal in the same calculation with atmospheric dispersion in both natural and anthropic environments it would account for the influence if any of buildings on the atmospheric flow and the dispersion of the release it would allow arbitrary extent for multiple nested domains and would take into account different kinds of meteorological input data weather predictions on a large scale as well as local measurements ultimately it should comprise advanced features such as assimilation of observations in simulations source term estimation from measurements and or the ability to perform ensemble computations to account for the uncertainty on the meteorological data on top of this the numerical results issued by the flow and dispersion models should allow for fast cartographic access for instance through rich cartographic resources and through cloud web services in the next section of the paper we describe state of the science 3d modelling that meets most of these criteria it is worth noting that advanced web capabilities for post processing and visualizing flow and dispersion results at multiple scales are also available though this is beyond the scope of this paper and will be presented in another paper 3 description of the emergencies project the emergencies project was conceived to put into action a system coupling high resolution 3d flow and dispersion models over a very large urbanized area it was initiated in 2014 and established for a short period of three months as it took place in the frame of great challenges organized by the hpc center of the french alternative energies and atomic energy commission cea the project was prepared and realized by the authors of the paper the name emergencies is the acronym for high resolution emergency simulations in huge cities even if running the modelling system over an extensive domain was challenging as such the project ultimately aimed to demonstrate and illustrate that 3d state of the science modelling could be used in a dss in case of an emergency implying adverse radioactive toxic flammable or explosive releases into the air while the next sub sections give an overview of the principles developed in the emergencies project more detailed technical features are presented in oldrini et al 2019 3 1 guidelines of emergencies the basic concept of emergencies was to answer the following question is it feasible to simulate the at d of a deleterious release at high resolution in 3d over a vast geographic area wherever the release might occur but in a time consistent with the management of this emergency situation such an approach could drastically change the way in which dss are operated in crisis preparedness and response and provide rescue teams and their authorities with an accurate reliable evaluation of the health consequences of the release on the population and first responders in real or accelerated time in the emergencies project we chose a domain of interest covering the metropolis of greater paris which encompasses the city of paris and the surrounding suburbs this domain matches the administrative limits under the responsibility of the paris fire brigade the domain has horizontal dimensions of around 40 km 40 km and a horizontal uniform grid resolution of 3 m the vertical grid has 39 stretched levels starting from the ground up to 1000 m the mesh size of the closest to the ground levels is 1 5 m broadening above to the top of the domain in total the 3d grid contains more than 6 billion nodes it is worth noticing that the top of the domain is relatively low and may be inside the atmospheric boundary layer from the meteorological viewpoint higher domains are needed for physical and numerical reasons and utilized in the meso scale weather forecasts see more details below in this sub section still from the dispersion viewpoint we are mostly interested by releases close to the ground influenced by the buildings and the urban canopy and the at d generally occurs at levels lower than 1000 m justifying the domain height would it be necessary for elevated releases or releases entering the domain the top of the domain could be at higher altitude the static data used in the modelling are the topography at an original resolution of 25 m taken from the bd topo of the french national institute of geographic and forest information ign 1 gb of data the land use at the same gridded resolution obtained from the corine land cover 1 gb of data and the buildings in the whole area also taken from the bd topo of ign consisting in 1 15 million of polygons with height attributes 3 gb of data indeed all buildings over greater paris are explicitly accounted for fig 1 shows a 3d view of the domain with the topography and the buildings of paris and its suburbs the emergencies flow simulations at a 3 m resolution accounting for all buildings in the huge 3d domain were performed considering actual meteorological episodes the modelling system dedicated to micro scale meteorological computations is presented in sub section 3 2 the principle was to downscale meso scale forecasts of the weather research and forecasting wrf model skamarock et al 2008 by introducing the fine details of the local topography the land use and particularly the buildings influencing the 3d turbulent flow at local scale using a diagnostic flow model for each simulated day 24 timeframes of the micro scale flow were computed from hourly wrf extraction along vertical profiles inside the huge emergencies domain eventually this 3d flow field at local scale was used as inflow conditions for higher resolution cfd domains in and around some buildings internally meshed at a 1 m resolution the technical details of the wrf simulations performed in the emergencies project are summed up hereafter meso scale weather forecasts were produced with the version 3 3 of wrf and updated every 6 h with a lead time of 5 days there were four wrf nested domains with horizontal resolutions of 45 km over europe 15 km over western europe 5 km over france and 1 666 km over greater paris area wrf domains had 38 vertical levels extending to a pressure level of 18 mbar or a corresponding altitude of circa 15 700 m wrf simulations were driven by the global forecast system gfs at 0 5 spatial resolution produced by the u s national centers for environmental predictions ncep physical parametrizations chosen in wrf were as follows yonsei university scheme for the atmospheric boundary layer mm5 similarity theory for the surface layer with the noah land surface model wrf single moment 3 class scheme for the microphysics and rrtm and dudhia schemes for the respective longwave and shortwave radiation the emergencies scenario was developed as an event that could be faced by civilian security services it was a fictitious attack involving multiple atmospheric releases of substances potentially harmful to the population and the first responders the substances could be chemicals radionuclides or pathogenic biological agents released as gases or fine particulate matter three releases were assumed to happen inside or nearby public buildings and be passively discharged from a container or associated to a weak explosion as any other way to emit potentially noxious substances could be envisaged we decided to favor releases close to the ground in order to enlighten the influence of the buildings and urban canopy on the subsequent propagation of the plumes such releases require that the modelling system be able to track substances either progressing from inner parts of buildings to the outside or occurring in the urban environment and then penetrating into the buildings three places of particular interest were chosen a museum a train station and a strategic administrative building let us recall that the scenario is purely hypothetical but that the parisian environment uses actual data including streets and buildings with actual meteorological conditions 3 2 brief presentation of the pmss modelling system the micro scale modelling system run in the emergencies project was parallel micro swift spray pmss pmss comprises the parallelized versions of the local scale swift flow model and the spray dispersion model these models explicitly take account of the obstacles in built up environments oldrini et al 2011 2017 2019 oldrini and armand 2019 swift moussafir et al 2004 tinarelli et al 2007 is a 3d diagnostic flow model using terrain following coordinates over complex topography and producing velocity pressure turbulence temperature and humidity fields first the model interpolates between meso scale model outputs and or surface and vertical profile meteorological measurements then the first estimate of the velocity is modified using semi analytical flow solutions around isolated buildings or within groups of buildings röckle 1990 kaplan and dinar 1996 finally the mass consistency of the 3d flow is ensured optionally a more accurate computation of the velocity and pressure fields may be carried out with a reynolds averaged navier stokes rans stationary solver oldrini et al 2014 2016 as swift diagnostic approach proved in several test cases to provide a solution close to the cfd reference in a much quicker time baumann stanzer et al 2015 it was exploited for the massive computations in the more than 6 billion nodes domain of the emergencies project spray anfossi et al 1998 tiranelli et al 2007 tinarelli et al 2013 is a lagrangian particle dispersion model that simulates the at d of airborne material by following the trajectories of numerous numerical particles rodean 1996 the velocity of each virtual particle is the sum of transport and turbulent components the transport component is derived from the local average wind vector while the turbulent component is derived from the stochastic scheme developed by thomson 1987 that solves a 3d form of the langevin equation notable characteristics of spray are to consider the bouncing of virtual particles onto the obstacles such as buildings in urban areas and to model dry and wet deposition on all accessible surfaces the rationale for developing pmss was to be able to perform high resolution computations over very large domains in pmss parallelism combines three aspects 1 the decomposition of the large domain into sub domains also called tiles that can be handled by single cores both in flow and dispersion simulations 2 the calculation in parallel of the diagnostic or rans flow at successive timeframes and 3 the distribution of the lagrangian numerical particles among computational cores oldrini et al 2017 2019 moreover pswift and pspray can handle multiple nested domains with either upscaling or downscaling enabling high resolution close to the source of atmospheric release and lower resolution at some distance from the source the pmss modelling system has been thoroughly validated against wind tunnel and full scale experimental results bauman stanzer et al 2015 oldrini et al 2017 trini castelli et al 2018 oldrini and armand 2019 the parallelism was shown to be very efficient from a multicore laptop up to clusters with several hundreds or thousands of cores in the case of a high performance computing center oldrini et al 2019 finally pmss is coupled with code saturne nibart et al 2011 code saturne is a general purpose and environmental application oriented cfd model archambeau et al 2004 milliez et al 2007 in the emergencies project it was utilized to compute the 3d flow in three simulation domains nested in the pmss huge domain meshing the vicinity and the inner parts of the buildings of interest museum train station and administrative building afterwards pmss 3d flow field in the atmospheric environment and code saturne 3d flow fields inside the buildings were used as inputs of pspray in order to evaluate the transfer of airborne materials from the urban environment to the buildings interior spaces or from the inside of buildings to the outside as mentioned above pmss was conceived to be capable to run simulations in a very large and finely meshed 3d domain like in the emergencies project in which code saturne was used to zoom in on the interiors of some buildings obviously this implied large computational resources reaching several hundreds or thousands of cores of a supercomputer comprising 5040 b510 bull x nodes each with two eight core intel sandy bridge ep e5 2680 processors at 2 7 ghz with 64 gb of memory per node 3 3 emergencies results performances and practicality the visualizations supplied in the framework of the emergencies project were graphical static and dynamic results images and videos regarding the atmospheric flow and dispersion at local scale and embracing different zoom levels from the very close vicinity of the release source to a general view of the deleterious plumes through some part of the city of paris or through the whole city itself fig 2 shows an example of multi scale emergencies results the large 2d view is a cross section of the plume over the city of paris 2 h after the beginning of the first fictitious release the cross section is presented at a height of 1 5 m above ground level where people breathe and may inhale the toxic substances the vignettes in fig 2 are oblique zooms of the plumes in the districts of the museum on the left hand side and the administrative building on the right hand side 20 min after the start of each asynchronous fictitious release in the figure the concentrations of the substance initially released into the air near or inside the buildings are colored in green for lower concentrations and in orange for higher concentrations fig 2 reveals many significant mainly urban effects on the wind and subsequently on the dispersion in this regard it is worth noticing that the plumes are channeled through some of the streets they spread inside the street network with complex patterns which would be unforeseeable without numerical predictions all the more so that the plumes partly pass above the buildings they bump into the relief and circumvent it this effect is noticeable even if the city of paris is mostly flat except for some hills of moderate height for instance the butte montmartre finally let us mention that the distribution of the released substance inside the buildings and in their proximity would not be predictable without an appropriate cfd model the numerical results and their operational graphical representation cannot be separated from the computational time needed to obtain these results post process and visualize them which in turn is inseparable from the computational resources that are operated the computational aspects are discussed briefly in the following paragraphs while the strategy for the visualization of the results is a topic in itself for both issues more detailed descriptions are given in oldrini et al 2019 the 3d simulation of the flow over the entire urban domain with the pmss modelling system required a minimum number of computing cores related to the breakdown of the domain into 1088 tiles furthermore the computations of successive timeframes were processed in parallel thus when dealing with eight timeframes concurrently the computational time for the flow decreased from 2 h 40 min to 1 h 20 min using respectively 1089 or 8705 cores for a daily meteorological episode around 5000 cores were required to handle the 24 hourly timeframes in less than 1 h 40 min these figures are noticeable as they prove the ability to downscale 24 timeframes of wrf forecasts to simulate the high resolution 3d flow over greater paris accounting for buildings each day in advance for the following day furthermore they show that the micro scale weather forecast for the next day can be updated 4 or even 8 times a day using the meso scale weather forecast that is provided every 6 h or possibly 3 h thus up to date micro scale meteorological predictions can be obtained as frequently as the meso scale predictions are produced without the risk to use outdated meso scale data the 3d simulations of the fictitious dispersions carried out with the pmss modelling system relied on a lagrangian approach for each release 40 000 numerical particles were emitted at each emission step of 5 s in total 14 4 million of particles were emitted to mimic the three 10 min long releases of noxious substances the particles could move from the vicinity or even from the inside of buildings over paris and its suburbs and vice versa concentrations were calculated every 10 min using 10 min averages the computational time for the dispersion depended on the number of cores for instance it decreased from 2 h 30 min to 1 h 30 min with respectively 250 or 500 cores these figures have to be compared with the simulated physical time of 5 h thus using 500 cores the calculation is 3 3 times faster than the duration of the fictitious dispersions one has to point out that in general it is not necessary to track a plume for 5 h to assess the impact of the release to some kilometers from the source if for instance only 1 h of tracking is adequate dispersion results are obtained in 18 min in the same example as above this result is fully consistent with the objective to inform first responders in 15 30 min as proposed in the introduction of the paper admittedly it is much longer than the computational time of a simpler gaussian or integral at d model but sensible for the benefit of taking account of the complex environment topography land use buildings in a realistic way in the emergencies project nested 3d simulations around and inside emblematic buildings were carried out with code saturne these computations were optionally performed depending on the need to evaluate the indoor outdoor transfers of deleterious substances they exploited around 200 cores per nested domain and timeframe the computational time required between 1 h and 1 h 40 min depending on the size of the nested 3d domain this time turned out to be long compared to the computational time for the flow simulation in the very large domain over the city of paris and its suburbs this is related to the use of a cfd model versus a simplified cfd approach for respectively the simulations inside the buildings and those in the urban environment contrarily to the fast and efficient output of results regarding the distribution of noxious substances in the atmospheric environment see the figures given in the previous paragraphs 3d flow and dispersion simulations inside one or several buildings while informative may significantly burden the production of results and hamper their communication to the decision makers implied in an emergency the functionality of indoor outdoor transfers based on 3d modelling should thus be activated only in time permitting conditions nonetheless such transfers could be evaluated using simpler methods as for instance box models at the expense of the detailed 3d distribution of the deleterious substances inside the buildings in the emergencies project large amounts of data were produced by the pmss simulations they were of around 200 gb for each meteorological timeframe or 4 8 tb for the 24 hourly timeframes of a complete day and around 90 gb for each dispersion simulation still these figures have to be compared to the 5 pb of disk storage offered by the activated supercomputer furthermore the big data would not be transmitted directly to the rescue teams or their authorities but post processed and transformed into images or videos of lightweight file formats or made available through a cloud web service to summarize high resolution flow simulations over the very large domain covering the city of paris and its suburbs prove to be achievable provided a large yet reasonable computing resource is available meso scale weather forecast can be downscaled in order to produce micro scale meteorological fields on a grid with a 3 m horizontal resolution e g 4 times a day in advance for the following day afterwards the highly resolved 3d flow is used as an input of 3d dispersion simulations run in accelerated time compared to the real time beyond the proof of principle study it is essential to consider how in practice the simulations could be integrated in an emergency response procedure flux first of all it is crucial to provide information to the decision makers in a timely manner that is to say no more than 15 30 min to give an order of idea this deadline is challenging as the information about the accidental or malevolent event has to be gathered the simulations must be carried out and their results evaluated and shared with decision makers thus in our opinion the simulations should be performed at an appointed reach back center by at d specialists and then broadcasted to the emergency stakeholders in their own command centers besides the meso scale and the micro scale weather forecasts should be prepared and updated regularly on a routine basis in an emergency situation implying accidental or malevolent releases into the air only dispersion simulations would be carried out on an on demand basis then in the process of informing the rescue teams and their authorities the production and storage of 3d weather forecasts and dispersion results would be in no way a burden for the urgency stakeholders but an acceptable burden for the reach back center one might argue that real world situations are characterized by a high level of uncertainty for instance in case of a malicious event with an unknown source term doubtlessly this can affect the confidence into the simulation results to mention but only an example leadbetter et al 2020 have shown that depending on the considered scenario the largest uncertainties may originate from the source term and the driving meteorological data and to a less extent from the at d model and the space resolution therefore a theoretically very accurate model might lead to an over confidence in the simulations if the uncertainties were not considered in the evaluation how to account for uncertainties is a vast topic beyond the scope of this paper mainly devoted to the practicability of high resolution computations in a huge built up domain this notwithstanding two notes relating to the emergencies project can be made regarding the source term and the meteorological data first the dispersion simulations in the emergencies project run quickly even using a 3d lagrangian model thus it is possible and even advisable to repeat the computations and refine them incrementally as the knowledge on the source term improves when more information pours in from the terrain and the in situ situation is further and better analyzed then resorting to hpc makes possible to downscale not only one realization of the meso scale weather forecast but an ensemble of realizations to integrate at least to some extent the variations of the meteorological conditions moreover it would be feasible to account for the uncertain location of the source by varying its horizontal and vertical coordinates therefore with the brute force of hpc the uncertainties on the meteorology and the source term could be propagated through multiple dispersion simulations whose results would undergo a final probabilistic post processing while the previous considerations demonstrate the practicality of the 3d modelling system developed in the framework of the emergencies project the application of detailed realistic 3d simulations of atmospheric dispersion followed by the evaluation of health impacts are further discussed in the next section with regard to decision making support in an emergency situation 4 benefits of the emergencies project for emergency preparedness and response the emergencies project is the largest and most emblematic application carried out by the authors of 3d flow and dispersion simulations over built up areas like the city of paris and its suburbs yet it is not except for the extent of the area considered the only example of simulations combining on one hand the downscaling of weather prediction from the meso scale to the metric urban micro scale and on the other hand dispersion computations of fictitious deleterious releases whose impact on the health of the population and first responders is assessed while based on smaller computational grids projects in the same vein are presented in armand et al 2015b and in armand and duchenne 2019 the most outstanding feature of the emergencies project and the most recent emergencies mediterranean project armand et al 2017 is their ability to produce in moderate amounts of time information that is both accurate thanks to a 3d flow and dispersion modelling system and also practical and helpful for security services in recent years many simulations carried out by the authors were not dedicated solely to developing validating or applying 3d models in complex configurations but also to demonstrating the actual benefits of such simulations for emergency teams in many cases the computations were performed in the framework of emergency exercises during which danger zones or zones corresponding to recommended counter measures were transmitted to the firefighters and to the authorities armand et al 2013 2014 2016b the modelling system applied in the emergencies project and the computational resources sized for the applications foreseen can provide valuable results to dss this was precisely what we did by leveraging these opportunities to post process and supply operational results to first responders we argue that the information produced in the framework of the emergencies project can be very useful to both emergency preparedness and emergency response in order to enlighten use cases we have chosen to discuss about the security exercises which are common practice by the rescue teams and their authorities in several countries security exercises are representative to a large extent of actual crisis situations and they constitute excellent opportunities to establish dialogue between the emergency stakeholders and the modelers the exercises have two distinct phases which are firstly the preparation of scenarios corresponding to the large panel of emergency situations likely to happen and secondly the handling of fictive emergency situations insofar as such situations can be mimicked obviously all services contributing to the security exercises the firefighters and the administrative authorities at the top of the list wish the most representative as possible conditions for the exercises thus it is of high importance to develop rich and realistic scenario exercises in the preparatory phase and to enact them in the closest manner to real dreaded events in the performing phase based on the experience of the authors in participating to security exercises we argue that they can greatly benefit from modelling and simulation expertise in atmospheric dispersion and health impact assessment without being exhaustive details are given hereafter about the two phases of the exercises preparation and performance and what the role of 3d modelling and simulation could be in association with them as all security exercises do not obey to the same flow diagram we have tried to identify commonalities and propose general recommendations 4 1 elaboration of useful and relevant security exercise scenarios 3d modelling and simulation can be used from the outset of a security exercise project starting from the requests made by security services the modelers can explore various accidental or malicious events implying toxic flammable or explosive materials as examples we have studied exercises corresponding to the explosion of a dirty bomb in a city center armand et al 2013 2014 or a breach in a tank filled with a noxious chemical armand et al 2016b from a modelling perspective meteorological conditions during and after the fictitious release into the air can be chosen by the modelers in agreement with the first responders according a guiding rationale which may be e g to affect a geographic area of interest or multiple areas if evolving meteorological conditions are considered the area can be a crowded district or contain public or administrative buildings of high importance or more generally any locations that are critical regarding the threat of an accident or an attack otherwise actual meteorological situations can be accounted for using weather predictions downscaled from the meso scale to the local scale a variety of releases can also be considered by modelers to support the preparation of a security exercise often the exercises imply chemicals as they are the most widespread hazardous species in transportation handling and storage but sometimes they can involve radionuclides or even pathogenic biological agents the areas affected by the gases or particles emitted into the atmosphere not only depend on the meteorological conditions but also on the quantity and kinetics of the releases proposals can be made by the modelers during the preparation of the exercise about the extent of the affected area which can be chosen to be as large as necessary in order to simulate a serious event and train the first responders and decision makers the kinetics can be carefully pre computed by the modelers in order to fit with real accidental situations as in the case of a breach through a tank a leakage in a pipe the evaporation of a pool etc later the preparatory modelling work can be performed in the run up to a planned exercise by considering the different constraints of this exercise these constraints are connected to the human material and financial means dedicated to the exercise and to the interest of the security services in training for a given event such as an industrial accident implying toxic chemicals or a terrorist attack with a dirty bomb etc it is worth noting that at least at the beginning of the exercise the actual nature of the event may also be ambiguous for example in armand et al 2016b the release from a tanker vehicle could have been purely accidental or been preceded by the hijacking of the vehicle in the frame of the relationships established between the first responders and the modelers the latter can propose to the former several plausible release events corresponding to either accidents or malevolent actions in order to obtain a large panel of situations and also depending on the needs of the security services different weather situations or locations of the release or noxious substances can be studied in any case modelers should be committed to developing realistic scenarios and operating modes for each likely place of the release simulations make it possible to explore many more scenarios than the planning of an actual exercise that requires heavy logistics it is crucial to share the simulation results like those produced in the emergencies project during meetings gathering the numerous parties implied in the security exercise local and regional or national administrative authorities firefighters police health services public transport operators etc while there are various reasons behind the final choice of a security exercise scenario the dispersion and potential health consequences of fictitious toxic releases may be an important deciding factor this is all the more true if the simulations have been carried out using state of the science 3d models and if the results are realistic and reliable if so the relationship established between the security services and the modelers can lead to a well argued relevant and reasonable choice of scenario exercise the discussions between the modelers and security actors should obviously be interactive with the proper expertise of all parties helping the modelers to develop and improve the exercise scenarios it is especially important to check that the features of the scenarios are as realistic as possible and to obey without fail any important requests of the first responders and decision makers for example the protocols and intervention times of the firefighters must be respected it is also beneficial for the security actors to work proactively considering the evolution not only of the resources and means deployed in the field but also of the meteorological conditions which can induce a predictable change for the affected areas over the course of the exercise eventually the result of this strategic and interactive thinking of all security actors including the modelers is to adopt and freeze the parameters of the exercise the field where it takes place the precise nature of the event and of the release the choice of real or imposed meteorological conditions etc for the authors the key points concerning scenario preparation of security exercises are the following exercise preparatory meetings and exchanges enhance the sharing of knowledge between dispersion modelling experts and civilian security services the evaluation of a large panel of accidental or malicious events potentially targeting a large area in a city or a smaller urban district or an industrial site is of great interest as it enhances the anticipation of the resulting human and organizational impact of such events state of the science modelling and simulation allow the development of realistic exercise scenarios that are technically more precise than the usual current practices which means that the in depth work of the emergency actors involved takes precise account of the time sequence 4 2 participation of the modelers in a security exercise or in a real emergency first of all the involvement of the modelers should be decided in advance in agreement with the local and national administrative authorities and with the first responders such as firefighters in the event of a fictitious exercise or a real emergency the modelers in charge should be informed either by the security services or the administrative authority as soon as possible after the beginning of the false or real potentially hazardous release event initial input such as the place of the event and if available an estimate of the source term should be provided to the modelers in order to launch the dispersion calculations of course the modelers should be prepared to face this kind of situation as a recommendation the modelling staff should be present at a reach back center and be ready to use weather predictions both at meso scale and local scale as performed for instance in the emergencies project the modelers should also be prepared to carry out dispersion simulations regardless of the place of the release source in the domain of interest in the emergencies project it was the city of paris and its suburbs an extended geographic area under the responsibility of the paris fire brigade also a representative of the modelling team should be able to join the command center as soon as possible after the beginning of the event and have a designated place among the representatives of all emergency parties administrative authority firefighters police health services etc at the modelling reach back center the first dispersion results should be obtained quickly let us say in 15 30 min as was the case in the emergencies project and made available through e mails or dedicated cloud web services to the firefighters operational center and the command center of the administrative authority which could integrate them directly into their geographic information system gis considering that the computational times are moderate on dedicated appropriate resources simulations can be upgraded i e run repeatedly as new information pours in from the field typically at the very beginning of the event it is most likely that neither the nature nor the quantity of the release is known however the at d of a unit quantity of a provisionally anonymous species can be simulated in order to reveal the concentration pattern of this species in the possibly complex environment urban district or industrial site over a rugged topography and evolving meteorological conditions the early production of this non obvious concentration pattern is extremely valuable for the first responders but it is useful only if the modelling system can cope with the real complex environment without oversimplifying reality after this first stage the dispersion computations can be performed again when the released species is identified and its quantity estimated this new information is acquired thanks to a better understanding of the situation and or the use of measurements carried out in the field in general a simulated or real emergency situation implies many decisions relating to population protection transport hospitals schools etc see e g armand et al 2016b many of these could benefit from the presence of an expert in the field of dispersion modelling and health impact assessment some non exhaustive examples of decision making are given hereafter most often the question of population sheltering or evacuation arises very quickly this aspect is discussed by the firefighters the medical emergency team and the administrative authority as noted in armand et al 2016b the participation of the modelling expert can be very useful as map views of the non intuitive dispersion pattern of the released species can be displayed at the command center these maps are typically of the same type as those produced in the emergencies project as a first action the confinement of the buildings rather than their evacuation may be recommended by the firefighters and as a precaution the administrative authority may give an order to confine the district while waiting for a more accurate evaluation of the situation modelers can contribute to this evaluation with the plume maps that originate from the simulation using a dynamic presentation such as a time evolution through a video of the dispersion it can be made clear if and when the release is finished and the plume is diluted moreover as soon as the released species has been identified and an order of magnitude of the quantity emitted into the air has been cautiously evaluated the concentration values having adverse effects and also no adverse effects on human health can be displayed basically the exposure map presented after the plume has crossed the entire area can be used to delineate the zones where immediate health consequences are expected or where counter measures such as sheltering evacuation or any other required actions should be taken with a safety margin of which the emergency stakeholders are well aware the case of toxic chemicals with a smell is interesting see armand et al 2016b indeed the most severe health effects may be limited to a relatively small area while it is probable that numerous people would detect the abnormal presence of the chemical at much farther distances from the source due to a low olfaction threshold this is obviously considered to be very important information for the firefighters and the emergency medical team as a saturation problem may arise if people who smell the chemical odor head massively to the hospitals over time measures taken in different parts of the affected area especially if it is large may be further examined in light of the simulation results and the measurements coming later on from the terrain for instance the aeration of buildings can be advised when the plume has left the sector or measurements in the field may be used to check that concentration levels are low to a degree consistent with the modelling etc the updates of the real or fictitious emergency are other situations demonstrating the role and value of accurate reliable simulations such as those performed in the emergencies project the arrival of high level decision makers can trigger situation updates during such a sequence a representative of the administration briefly describes the event the firefighters show on a map the presence of the rescue teams in the field and explain the measures taken and the medical team updates the number of casualties and the hospitals taking care of them etc the intervention of the modelling expert can be considered key for making the decision makers aware of the situation in the field through the use of simulation results typically the evolution of the plume is shown with a video and the assessment of the health consequences is cumulated from the beginning of the release to the updated time as most accidental or malicious releases are quite short or do not last more than a couple of hours the situation updates may take place when the risk no longer evolves again simulations are of value for exploring the evolution of the situation and contribute to decision making combined with information from the field regarding the progressive annulment of measures previously taken for the authors the key points concerning the in situ participation of modelling experts to security exercises or actual emergency situations should they occur are the following state of the science modelling and simulation are more relevant than simplistic approaches thus they can be used effectively by the services in charge of population protection the simulation results are helpful for identifying the at d processes especially in complex built up environments for adapting the first actions of the rescue teams and for anticipating the follow up to the event static and dynamic presentations of the results are both of interest maps and videos may be used throughout an exercise or a real emergency situation not only for communication purposes but also for collective appropriation during the situation updates the interactions between the modelers the security services and the first responders are extremely beneficial they make it possible to further improve and to adapt the results provided by the modelling system to better fit the needs and missions of the civilian security organization there is a synergy between the rescue teams first actions which are irreplaceable for short and medium duration releases and the simulations carried out to diagnose the situation and anticipate its evolution even if it is difficult to know the source term in many cases the early visualization of the dispersion pattern and plume is undoubtedly of high interest for supporting the first phase of the response it is certainly also important to share the modelling results between the emergency actors even if their missions and time responses differ for example in the case of an exercise at the local level simulation results may be transmitted to a national emergency command center even if it does not lead the exercise directly but may have a strong interest in the simulation results finally the authors argue that there are two essential benefits in providing state of the science simulation results and expertise in the course of a deleterious atmospheric release the results are relevant for enhancing a common understanding of the space and time distribution of the hazardous materials this can help greatly in making decisions and taking appropriate measures for population protection the results can be used to foster communication with the authorities and all emergency actors this can help generate a shared representation of the situation and an optimal coordination of the command center 5 conclusion even in current practice rescue teams and their local or national authorities are most often provided with results of simplistic at d models should an accidental or malicious atmospheric release of cbrn e agents occur these models such as in the gaussian approach either do not address or else address in only an oversimplified way the complex and non intuitive dispersion pattern that is observed in actual built up urban or industrial areas over rugged topography and in variable and complicated meteorological situations for instance the dispersion upstream of the location of the release or the dispersion in streets perpendicular to the general wind direction above the urban canopy are intrinsically accounted for by 3d models while it may not be the case when using less advanced modelling in that respect simplified models not only provide an inaccurate presentation of the actual 3d distribution of deleterious gaseous or particulate substances but they may also give misleading information to the first responders subsequently emergency procedures in complex atmospheric environments especially built up areas should not be based on models that are inappropriate for these environments and that can result in ineffective or indecisive responses there are numerous dss implementing at d models that can be operated through graphical user interfaces in this paper we propose a brief and presumably non exhaustive overview of some well known dss this set of dss has in common to present a number of interesting functionalities and is used as a testbed for comments on what are or could be if not present in any system valuable features of a dss for instance to face the broad and diversified panel of threats implying releases into the air a dss should be able to deal with different in nature hazardous materials a choice of at d models adapted to natural or built up environments capabilities regarding multi scale modelling simulation at high space and time resolution transfers of materials from the outside to the inside of buildings etc while not mandatory in all dss especially those dedicated to only one kind of threat situations these features would be appreciable and meet issues of prime interest for rescue teams our paper describes the emergencies project which was intended to achieve the twofold ambition of elaborating a system based on state of the science at d models and demonstrating the value of this system for emergency preparedness and response in the project meso scale weather prediction was performed over europe and france and then downscaled to a very large domain encompassing the city of paris and its suburbs at a 3 m resolution and accounting for all buildings the 3d turbulent wind fields were used to transport and disperse hypothetical hazardous releases moreover the domain over greater paris was supplemented with cfd innermost nested domains in and around specific buildings of interest to evaluate indoor outdoor transfers in practice the emergencies concept of use was to perform multi scale weather forecasts the meso scale meteorological fields being downscaled on a routine basis one or several times a day then the dispersion simulations were run for the project or would be carried out in real life on an on demand basis in case of need everywhere in the greater paris domain at one or multiple locations these computations were proven to run faster than real time it is worth noticing that the dispersion simulations may be performed concurrently inside buildings or infrastructures in the large urban domain where all buildings are accounted for explicitly and also beyond in the meso scale domains as the lpdm embedded in the modelling system handles nested domains and upscaling or vice versa downscaling as a short digression it is worth coming back to the examples of infamous events given in the introduction in fact the transposition of the emergencies project to the urban area of tokyo city and the underground station affected by the sarin release would be possible and make our modelling system applicable to this terrorist attack on another note while different in the typology of the event and extent of the impacted area the fukushima nuclear power plant disaster could benefit from the capabilities of our system in weather and dispersion events reconstruction from the near field some kilometers to the intermediate and far fields some hundreds of kilometers this illustrates the multi purpose nature of our modelling approach even if as it stands the consequences on human health are evaluated only at short term while a module for long term impact could be a further development especially in case of radioactive releases obviously the modelling system featured by the emergencies project has also limitations firstly there is place for model improvement as for instance the thermal effects generated by the buildings would need a specific development maintaining moderate computational times more fundamentally real events implying possibly harmful substances into the air are most often imperfectly characterized in terms of the nature quantity timing and location of the release and of the meteorological conditions prevailing during and after the emission it is a general issue for all modelling systems and well beyond the scope of this paper this notwithstanding let us mention that the dispersion computations in the emergencies project run quite rapidly and can be repeated with the intention to account for the field information and interact with the emergency stakeholders furthermore leveraging the power of hpc multiple dispersion simulations could be performed exploiting an ensemble of weather predictions rather than only one realization as done in this project and different possible locations of the release after propagating the meteorological and source term uncertainties in the computations the massive results would be post processed in order to produce probabilistic maps of the impacted areas while the emergencies project was devoted to the greater paris area we have performed similar simulations in extremely large domains over the cities of marseille toulon and nice in the south region of france armand et al 2017 indeed we do not anticipate difficulties in principle to deploy the concepts underlying the emergencies project for other regions and cities using either the pmss modelling system or micro scale models with comparable functionalities the prerequisites are of two types firstly data are needed regarding the topography the land use and the buildings on the one hand global scale or meso scale weather forecasts on the other hand obviously all these data must be at a sufficient resolution to be useful for micro scale 3d simulations secondly significant computational resources are necessary and a key aspect of the project to our knowledge static data are available for more and more cities in the world weather predictions are ubiquitous at increasingly finer resolutions lastly the hpc power is perhaps more hardly accessible but computing centers keep developing worldwide thus for the authors the emergencies project is of general applicability and exportability at least in developed countries while perhaps still less easily in developing countries the emergencies project illustrates the reliability and timeliness of our modelling system in the conditions of an emergency in a vast and complex environment considering the resources and skills needed for the simulations they could be carried out by specialists in dispersion modelling at a reach back center and transmitted to the emergency stakeholders with preferably an expert in the command center in any case the project proves the feasibility of providing rescue teams and their authorities with high resolution simulations whose use and benefits are thoroughly analyzed in the paper both in preparation for emergency situations involving either toxic flammable or explosive materials and in response to these situations in the project the simulation domain was chosen to coincide with the very large area under the responsibility of the paris firefighters who give the authors opportunities to participate in real security exercises this is also a major fact that the amount of computer power engaged in the emergencies project was very large but not unreachable nor inconsistent with the means that could be dedicated to emergency management in the past years our r d efforts in the field of atmospheric dispersion and health impact assessment have not only focused on physical modelling but also encompassed the transfer to operational applications and the adequacy of decision support systems with regard to the organization and missions of the emergency actors activities like the emergencies project are not uniquely theoretical but account for tight relationships built for a long time with emergency stakeholders we argue that this approach is essential to promote the use of state of the science at d models in dss whose results are accepted and trusted by practitioners even if it is still prospective and not yet entered in the current practice of emergency handling it is very likely that supercomputing will become a more and more beneficial commodity for first responders and their authorities in the diagnosis and anticipation of emergency situations to our knowledge the multi scale highly resolved 3d simulations carried out in the framework of the emergencies project are unique as they combine a huge geographic extent with a metric grid resolution we argue that such simulations are the topical way to rigorously account for 3d flow and dispersion in complex atmospheric environments and subsequently to realistically and reliably estimate the health impact of hazardous releases on the population and the first responders thus simulations such as those performed in the emergencies project are not an academic exercise but a new paradigm for supporting emergency preparedness and response declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper annex table 1 overview of some decision support systems for cases of adverse atmospheric releases the acronym the full name the sponsors or companies in charge of development the nature of distribution commercial or not and the main users the atmospheric transport and dispersion models the threat agents the source term and impact assessment models the ergonomics of the graphical user interface other remarks and internet link are identified for each dss described table 1 name acronym full name development sponsors or companies distribution and users atmospheric transport and dispersion models and developers threat agents source term models and impact assessment models ergonomics of the user interface and cartography features comments internet link hpac hazard prediction andassessment capability u s department of defenseu s department of homeland securitydefense threat reduction agency usa executable version distributed to american agencies in charge of civilian or military security issues andto counterpart organizations in allied countries of the usano commercial purpose three models of increasing complexity available scipuff gaussian puff model with advanced capabilities sage management udm gaussian puff model with capabilities to account for isolated buildings or groups of buildings uk dstl pmss lagrangian particle dispersion model aria technologies and cea nrbc e releasessimple modelling of explosions and wide variety of accidental or malevolent scenarios notably for chemicalsradiological exposures compared to countermeasure thresholds for sheltering evacuation iodine prophylaxis chemical concentrations compared to toxicological reference values aegl erpg idlh biological agent contagion models easy handlinguser friendly interface designed to provide easy access to a wide variety of scenarioscartographic capacities dss adapted to many kinds of threat agents and scenarios of releases with a user choice of atmospheric transport and dispersion models adapted to natural or built up environmentscapacities for biological releases which are rarely available in dsscapacities for explosions with simplified models no direct access to any hpac sitemore information about dtra http www dtra mil midas meteorological information and doseassessment system abs consulting usa commercial purposemainly used in the usa with subsidiaries in the world asia europe quite common among u s operators of nuclear plants black box models an integral model and possibly a lagrangian modelquestionable capacity to account for buildings radioactive releases onlyadapted to plants in normal operation or affected by accidentsradiological exposures and protective measures in case of emergency cf module named radiological effluents administration system easy handlingergonomic user interfacelimited cartographic capacities different ways to account for meteorological conditions predictions and or local measurementsallow for safety studies compliant with the norms of the u s nrc nuclear regulatory commission http www absconsulting com midas cfm saferhazmat responder systematic approach for emergency response safer systems usa commercial purposemainly used in the usa with subsidiaries in the world europe used in industry infrequently by firefighters black box model integral model able to deal with heavy gases and accounting for the influence of the topographyno explicit treatmentof buildings crude modelling of outdoorto indoor transfers chemical releases onlyseveral source term models of passive and energetic releaseschemical concentrations compared to toxicological reference values aegl erpg idlh quite easy handling but numerous options relevant graphical interfaceadvanced integrated cartographic capacities connection with gis google earth to be noted the ste source term estimation feature within the abc advanced back calculation modulesafer hazmat responder softwareis integrated into the safer real time global supervision systemagreement between safer systems and the danish company rae systems detectors and protective materials http www safersystems com solutions core products safer hazmat responder aloha areal locations of hazardous atmospheres u s environmental protection agencynational oceanic and atmospheric administration usa free downloadable executable versionvery much used inthe usa and in europe especially by firefighters two basic models gaussian rectilinear plume model and model for heavy gasespossibility of running the hysplit lagrangian particle dispersion model noaa chemical releases onlyseveral accidental chemical scenarios breach in a tank break of a pipe pool evaporation explosive scenarios bleve boiling liquid expanding vapor explosion uvce unconfined vapor cloud explosion etc chemical concentrations compared to toxicological reference values aegl erpg idlh very simple handlingrudimentary graphical interface with limited options for the uservery limited cartographic capacities when using aloha basicallyoption to exportthe results to gis especially when running hysplit in aloha integrated into the cameo computer aided management of emergency operations systemcomprehensive database of chemicalslimited capacities but widespreadstrictly no capacity for dispersion in built up areas http www2 epa gov cameo aloha software phast dnv gl norway commercial purposeintensive use by specialized engineering consultants less usually by firefighters integral model for passive gases and for gases lighter or heavier than air chemical releases onlymultiple scenariosand source term models more sophisticatedthan in aloha e g explosions chemical concentrations compared to toxicological reference values complex graphical interface with numerous optionslimited cartographic capacitiesoption to exportthe results to gis more advanced and also more complexthan alohaa great deal of models for the source termstypically developed for industry subcontracting risk studies to consultants https www dnvgl com services phast modules 1696 ct analyst contaminant transport analyst naval research laboratory usa executable version possibly e licensed to agreed organizationsexcept by the nrl unclear use in the usapossibly used by firefighters in hamburg germany cfd les large eddy simulations complex model of the flow and dispersion with long computational timeno cfd computations in case of emergency requirement to create beforehand a database of wind fields for each site of interestuse of nomographs for the dispersion and impact assessmentof threat agents nrbc releaseschemical concentrations compared to toxicological reference values aegl possibility of evaluating radiological exposures relevant graphical user interface enabling source term definition with its localization on a map and a quick overview of the results owing to the absence of computations only post processing of results obtained beforehand possibly used by firefighters in several cities in the usa andin hamburg germany methodological limitations extremely long pre computations of the wind fields lack of possibility to take changes in the meteorology during the dispersion into account http www nrl navy mil lcp ct analyst rodos real time on line decison support system originally fzk forschungszentrum karlsruhe development funded by the european union eu available for the member states of the eupotentially used by14 european countries austria belgium bulgaria croatia finland germany greece hungary netherlands poland portugal romania slovenia and spain optional access to lasat lagrangian particle dispersion model several available modelsatstep gaussian puff kit iket rimpuff gaussian puff risø dtu dipcot lagrangian puff or particle demokritos match eulerian smhi lasat lagrangian particle bfs radioactive releasesradiological exposures compared to countermeasure thresholds for sheltering evacuation iodine prophylaxis quantification of the effect of protective measures for the population agricultural production management and site remediation simple handlingergonomic graphical user interfacewith coupling to gis option to carry out meso scale dispersion computations usingthe weather predictions of the dwd deutscher wetterdienst no dedicated sitenot referenced onthe site of the joint research centers jrc of the eu argos accident reporting guidance and operational support dema danish emergency management agencydevelopment partially founded by the european union eu available for the member states of the eupotentially used by6 european countries denmark estonia latvia lithuania ireland and sweden and also by extra european countries canada brazil and australia rimpuff gaussian puff risø dtu urd urban gaussian puff accounting simply of the buildings risø heavy gases model for the chemicals radioactive releaseslikewise rodos for the impact assessment and the evaluationof the benefit of countermeasurespossibility of chemical releases simple handlingergonomic graphical user interfacewith coupling to gis option to carry out meso scale dispersion computations with derma and hirlam denmark snai norway or mldp0 canada using the national weather predictions of these countries no dedicated sitenot referenced onthe site of risø dtu c3x irsnradiation protection and nuclear safety institute france used by the irsn for radiological emergency preparedness and responsealso used by électricité de france french electricity supplier and operator of the french nuclear power plants no commercial purpose two models availablepx gaussian puff école centrale de lyon ldx eulerian ditto polair developed by the cerea centre d enseignement et de recherche sur l environnement atmosphérique radioactive releasesradiological exposures compared to countermeasure thresholds for sheltering evacuation iodine prophylaxis unknown graphical user interfacecartographic capacities in the krx module short range up to 100 km computations with px and long range continental or global scale computations with ldx using the national weather predictions of météo france no modelling in the urban environment no dedicated site 
25808,releases into the atmosphere resulting from accidents or malicious activities may be extremely diverse in nature and have harmful consequences for human health and the environment successfully managing such releases is a matter of the utmost importance for security services and governmental authorities for some decades atmospheric transport and dispersion at d models embedded in decision support systems dss have been operated in order to simulate the space and time distribution of hazardous materials and to assess their health impact on the population and on first responders in cases of emergency unfortunately the at d models in dss generally oversimplify the local or regional environment and are compromised by insufficient space and time resolution close to the source of the release thus we have developed a dss based on 3d multi scale weather forecast and lagrangian at d models in the frame of a project called emergencies as an emblematic example we have performed dispersion simulations of fictitious noxious releases from the inside or outside of public buildings both at micro scale in a very large domain encompassing the city of paris and its suburbs and at meso scale beyond this domain furthermore results have been produced in a time lapse consistent with emergency management thanks to large yet affordable computational resources providing emergency response actors with such operational accurate and reliable results may be extremely advantageous for both preparedness and response to emergencies ultimately state of the science at d models offer a sound validated new paradigm to support decision making by security services and their authorities facing contingent chemical biological radioactive nuclear or explosive cbrn e releases into the air graphical abstract example of visualizations in the emergencies project the large view is a 2d section of the plumes over the entire city of paris 2 h after the beginning of the first release the vignettes are oblique zooms of the plumes in the museum district bottom left hand side and in the administrative building bottom right hand side 20 min after the start of the fictitious releases in these two areas the green respectively orange tint corresponds to low respectively high concentrations of the released substance image 1 keywords 3d modelling and simulation weather forecast atmospheric dispersion health impact assessment decision support system emergency preparedness and response 1 introduction the air dispersion hazards of the past are infamously exemplified by the bhopal sharan and gopalakrishnan 1997 broughton 2005 and the fukushima christoudias and lelieveld 2013 mori et al 2015 sato et al 2018 catastrophes and also by the tokyo underground sarin attack okomura et al 1998 such events differ by their nature and by the extent of the affected areas from inside and around an infrastructure to regional and worldwide scales but they have in common to have led to dispersion hazards originating from releases of gases or particles into the atmosphere moreover such events are current long term threats due to the numerous industrial plants and the political tensions in our societies the releases into the air may be accidental ranging from minor events to disasters or hopefully less frequent malevolent as in the case of sabotage or terrorist attack they may involve toxic flammable or explosive materials threatening people s health and the environment materials may be as diverse as chemicals biological agents radionuclides or explosives also called cbrn e agents with drastically different effects on human health depending on the type and quantity of the released agents also the affected area may be limited to the vicinity of the source or extend up to very large distances from it in urban or industrial environments the intricate geometry of buildings combines with local and regional geography and topography e g in a coastal area or a rugged terrain to influence the distribution of hazardous materials through transport and dispersion because effective or potential deleterious releases may have dire human consequences and lead to societal disruption especially in crowded urban areas or in huge industrial sites they are considered to be a major concern by public security services and their local and national authorities to tackle the complex situations induced by air dispersion hazards modelers have long tried to provide relevant information such as danger areas but also safe areas to the first responders lee et al 1997 bianconi et al 2004 this makes it necessary to model the dispersion and health impact of hazardous releases over sites which are most often complex from the local scale up to the regional scale and potentially the global scale where noticeable health consequences may be observed or feared atmospheric transport and dispersion at d models need input data regarding the terrain land use and buildings as well as meteorological data the health consequences are estimated on the basis of the computed concentrations of the hazardous materials in the air and the computed deposition on the accessible surfaces the final results are intended to be directly operational as a map of the danger zones or of the counter measures that should be taken in general the suite of dispersion and health impact models is embedded in a computational tool or decision support system dss including a graphical interface displaying the data required by the modelling and the results of the modelling benamrane et al 2013 armand et al 2015a 2016a to be useful for the first responders and subsequently their local and national authorities the results of the dss must be ready in a moderate amount of time which should not exceed 15 30 min to give an order of idea this introduces a considerable constraint for modelling and simulation in past years this constraint has most often led the modelers to oversimplify the at d modelling as discussed later on on the contrary our paper aims at presenting a dss featuring 3d state of the science multi scale weather forecast models combined with an at d model able to handle nested domains and applying this system to a vast and highly resolved domain over paris and its suburbs also called greater paris the distribution in space and time of fictively released hazardous materials is simulated starting from the immediate vicinity of the source of the release up to the largest extent of the affected area as large and distant from the source it can be with this approach we wish to demonstrate not only the scientific value and interest but also the operational practicability of topical 3d modelling to provide security services with realistic and accurate thus reliable and safe impact assessment of dangerous releases concomitantly for huge domains such as those covering large cities at the appropriately high level of detail high performance computing hpc is necessary the paper is structured as follows section 2 is a concise overview of some well known dss and their modelling capabilities and limits section 3 illustrates the up to date capabilities of a dss developed for the so called emergencies project by integrating 3d meso scale and micro scale flow and dispersion models and section 4 discusses how these capabilities may be of benefit to civilian security services in conclusion we argue that state of the science 3d modelling and simulation of air dispersion hazards is the new paradigm for supporting emergency preparedness and response 2 overview of some major decision support systems for some decades the development of industrial activities notably in the nuclear sector has been a source of increased preoccupation for the population living around the facilities or beyond and for the environment in most countries concerns about human health and the environment have been driving forces behind efforts to strengthen regulatory requirements most often industrial plants produce atmospheric or liquid releases that are by products or waste products of their activities the releases may be linked to regular or to special and controlled operations they also may relate to undesired effects in the event of accident or sabotage the wide range of situations likely to affect plants requires that plant operators as well as the authorities in charge of issuing licenses to the operators estimate the consequences of such releases on human health and the environment it is thus understandable that numerous modelling tools have been developed in the aim of helping industry operators assess the impact of their installations and demonstrate if such is the case that the releases have no consequences for human health under normal operating conditions limited consequences in the event of hypothetical accidents and the weakest possible influence on the environment while the operators may also wish or be requested to perform on site measurements or an epidemiological survey such empirical evaluations are costly moreover they are impossible during the project phase of an installation and they are unable to cover all situations particularly accidents that can occur over the lifespan of a facility this highlights the value of at d and impact assessment models integrated in dss nuclear radiological or chemical accidents impairing large industrial installations are dreaded events for the operators of these facilities and also for local or national level authorities depending on the seriousness and consequences of the accidents public authorities also fear terrorist attacks or other malicious actions though different from accidents these actions may also lead to harmful effects for the population and the environment due to adverse atmospheric releases or liquid effluents also in these cases dss prove to be compulsory tools for evaluating the impact of such hopefully infrequent antisocial activities the previous considerations show that dss play an essential role for industrialists and public officials some well known dss dedicated to adverse atmospheric releases are presented hereafter with their main strengths and limitations consistently with the previous remarks the first facts to notice are the great number and worldwide distribution of dss dedicated to the at d prediction and subsequently health impact assessment the next observation is that dss have been designed in response to different motivations and for different purposes for instance institutes in some countries may be in charge of a specific kind of events like industrial accidents or cbrn e threats or a given nature of releases with a typical distinction between chemicals and radionuclides emitted respectively by industries or by nuclear power plants in routine operation or in the course of an accident this leads these institutes to use mainly at d models dedicated to the near field or to both the near field and the far field see the examples of disastrous events cited in the introduction of the paper and dss specialized in terms of released agents and sanitary consequences on the contrary institutes in other parts of the world may have to respond to a very large spectrum of situations implying releases into the air and ideally would like to handle one dss fitting all scenarios in general dss are developed by industrialists or by governmental agencies acting as national authorities for instance in the field of nuclear safety or by consultancy firms specialized in the field of risk assessment or security and counterterrorism most of the major dss have been developed through collaborations with universities and benefit from scientific endorsement the roles and uses of dss may vary considerably while some of them are the official modelling and decision support tools of the national authorities and their agencies in charge of emergency preparation and handling others are operated by corporate units and entities of private national or international companies of various sizes the users of dss may also differ greatly whether they are in charge of only a given industrial installation or act for public authorities at a local or national level and may face a panel of emergency situations involving any types of threat agents a distinction has to be drawn between two categories of potential users while non professional in modelling responders absolutely need being provided with dss having ergonomic graphical interfaces dispersion modelling specialists at a reach back center should be able to activate dss with a larger number of less intuitive options as commented on later in the paper users of 3d models embedded in advanced dss rather belong to the latter category a common trait of the users is that they all wish user friendly tools and agree on the statement that the more useable a dss the more adoptable it is the user interface of the dss is a central issue which would certainly deserve an extensive discussion although beyond the scope of the present paper as highlighted in the previous paragraphs many different dss have been designed to address adverse atmospheric releases thus it would be difficult to try to establish an exhaustive description of them to classify the dss is also trickier than one could expect diverse categorizations could be derived for instance according to the country of their original development but some dss have international ambitions the type of release that the dss handle could be another criterion but some dss consider multiple threat agents or both energetic and non energetic called passive releases alternatively the criterion could be the available models or the size of the simulation domain but dss may have different purposes and choices regarding the precision level in modelling all in all we decided to limit our discussion to a list of well documented dss chosen as examples namely hpac midas safer aloha phast ct analyst rodos argos and c3x without willing to categorize them this set of dss presents interesting advanced features and some of them provide a large number of functionalities while our aim is not to make a comparative study between the dss these systems are used to support the authors observations on the dss table 1 in the annex summarizes the main characteristics of the dss listed above for each of the nine dss reviewed table 1 features nine columns providing information about the acronym the full name the organizations that have been developing it the distribution and users the available at d models the threat agents accounted for as well as the source term models and exposure models the ergonomics of the graphical user interface additional information characterizing the dss and finally an internet link the main characteristics of the dss examined are summarized hereafter hpac usa chang et al 2003 purves and parkes 2016 miner et al 2019 simpson et al 2020 is an internationally known dss dedicated to cbrn e threats implying atmospheric releases it is a reference system in the usa developed under the auspices of the defense threat reduction agency dtra it is widely used by american agencies and in some countries especially the united kingdom hpac s main strength is its toolbox capabilities hpac can deal with numerous and various scenarios of radiological chemical or biological releases it implements three at d models with graduated levels of complexity and inclusion of built up areas the integration of several models in hpac and the models themselves are commented on later in this section meteorological input data are weather predictions local or remote measurements or a combination thereof hpac is not intended to be vastly and publicly distributed and users of hpac belong to usa and security agencies of allied countries midas usa goyal and al jurashi 1991 ccps 1995 and safer usa so et al 2008 tauseef et al 2011 are commercial products dedicated respectively to radiological and chemical risks they are in widespread use in industry in the usa and are also established in other countries worldwide one major strength of midas and safer is their connection to broader systems in charge of monitoring the impact of nuclear or chemical facilities on population health and the environment midas and safer are also able to use various meteorological input data such as weather predictions or measurements they both incorporate interesting and useful features such as source term estimation or assimilation of observations in the simulations however midas and safer have the drawback of being black boxes with a minimum description of the integral and possibly lagrangian at d models within in this regard their actual capabilities to explicitly account for the buildings on industrial sites or in urban areas remain uncertain aloha usa bellasio and bianconi 2005 frysinger et al 2007 tseng et al 2012 yadav et al 2020 is a freely available software associated with the cameo chemical database aloha is used widely around the world notably by various civilian security services such as firefighters aloha is very simple to use yet aloha is restricted to chemical products it relies only on a gaussian plume model with an option to deal with heavy gases and it cannot consider rough terrain or built up areas aloha can be operated with hysplit but even with this lagrangian dispersion model buildings are not accounted for schematically aloha has restrained mapping features even if it is possible to export results to geographic information systems gis phast norway pandya et al 2008 witlox et al 2009 2013 is a commercial software package considered worldwide as a reference by engineering consultants specialized in chemical risk studies but it is not much used by security services like the firefighters phast can deal with a multiplicity of scenarios of passive or energetic releases with special focuses on discharges from containers fires and explosions as far as explosion modelling is concerned the obstacles likely to be present on industrial sites can be accounted for in a simplified way however phast s at d modelling ability is limited to an integral model and it is not able to implicitly or explicitly account for buildings phast is equipped with a graphical user interface dedicated to creating calculation cases and displaying the results while phast has limited mapping features the results provided by the software can be exported to gis ct analyst usa moses et al 2006 leitl et al 2016 has been developed by the research laboratories of the us navy it has also been promoted notably by hamburg university ct analyst does not implement physical models as such but it uses the results of computational fluid dynamics cfd models more precisely large eddy simulation les of the atmospheric flow the at d module uses a combination of gaussian and lagrangian approaches to establish what is called nomographs of the areas impacted by releases as the flow computations are complex and very long the method provides a pre established wind flow database for each site of interest this is a major limitation in the operational use of ct analyst when real evolving meteorological conditions are considered or when a release occurs at an unforeseen place ct analyst is well known but its distribution to actual rescue teams in the usa and in germany remains undocumented rodos eu ehrhardt 1997 bartzis et al 2000 raskob et al 2006 and argos eu hoe and müller 2003 baklanov et al 2006 hoe et al 2009 are dss developed under the initiative of the european union and launched after the chernobyl accident they are essentially dedicated to radioactive releases and are intended for implementation in the european union the main strength of rodos and argos is that they propose a choice of at d models this characteristic originates from the participation of multiple institutions in europe with their own models in the development of rodos and argos dispersion models in these dss are gaussian lagrangian or eulerian models see table 1 in the annex for the list and details of the models another capability of rodos and argos is to be able to use the weather predictions of the national meteorological institutes in the countries where they are operated rodos and argos are mostly oriented toward preparedness and response to radiological or nuclear emergencies such as a more or less serious accident affecting a nuclear power plant more recently their purpose has been extended to emerging terrorist threats that could happen for instance in an urban district in this way rodos implements the lasat model that is also the model present in the lasair system designed for releases in the urban environment and argos is equipped with an urban module that considers the buildings in a simplified manner c3x france quélo et al 2007 champion et al 2013 korsakissok et al 2013 is a computational system developed and exploited by the institute of radiation protection and nuclear safety irsn in france to model and simulate the dispersion and the health consequences of radioactive atmospheric releases c3x comprises two dispersion models a gaussian model dedicated to the near field up to 100 km and an eulerian model dedicated to the far field at intercontinental distances c3x has been distributed to electricité de france which is the french electricity supplier c3x is fully dedicated to preparedness and response to radiological or nuclear emergencies typically in the event of a nuclear power plant accident c3x cannot handle chemical releases and does not involve any modelling features able to implicitly or explicitly account for buildings c3x is not devoted to competing with the dss previously cited in this review due to its status it is mentioned here as an example of a national modelling system developed to inform the safety authorities about the impact on the population and the environment in case of a radiological or nuclear event the description above and table 1 in the annex illustrate that dss have excellent capabilities for anticipating or managing crisis situations related to adverse atmospheric releases the main strength of the dss is either to be very simple to handle or on the contrary to provide numerous options to deal with a variety of emergency cases some dss have been conceived to respond to a single kind of emergency situation or a specific type of release thus their developers cannot be blamed for this factual situation while it is not a limitation a more general purpose of dss could be advisable in order to be capable to face the wide spectrum of release events furthermore dss do not always offer the capacity to use or combine input meteorological data weather predictions observations many of them consider releases only over flat terrains without obstacles or some of them take account indirectly of the orography through the driving meteorological data and of the topography via the surface stress dss can suffer a lack of proper internal potent cartographic capabilities or the absence of coupling with gis above all many dss have limits in terms of modelling the at d in industrial or urban environments indeed most dss implement gaussian models setting buildings aside or using simplified approaches to account for them and or integral models ignoring buildings and or lagrangian or eulerian models that generally do not account for built up areas moreover most dss present the disadvantages of coarse spatial resolution and or allowing computations only in domains with small dimensions some dss may have models adapted to different spatial scales for example a gaussian model in the near field and a lagrangian or eulerian model in the far field still there is no coupling between the scales hindering an actual multi scale approach to the flow and dispersion computations among the dss some of them implement several at d models this is the case of rodos and argos in which dispersion models present certain complementarities for instance regarding the spatial scales that are addressed still the intention behind the assembly of at d models in rodos and argos seems related to the development of the dss in collaborative frameworks between european countries represented by their national institutes more than the idea of tightly coupling several approaches hpac also belongs to the category of dss that combine a variety of dispersion models the models in hpac have been developed in the usa in the uk and in france and they complement each other as they are adapted to either natural or built up environments they can be considered to be of increasing complexity from the scipuff sykes et al 1996 deng et al 2004 advanced second order turbulence closure gaussian model to the udm gaussian model accounting for buildings hall et al 2003 brook et al 2003 and the pmss lagrangian particle dispersion model tinarelli et al 2013 obviously hpac development has been governed by an overall rationale and strategy whose strength is to account for the complexity of the environment moreover hpac takes into account the topography and the presence of built up areas which is consistent with the scales being treated by the models taking advantage of the strengths and removing the limitations of the most widespread dss allow us to establish the profile of an ideal system in terms of its modelling capabilities it should be able to carry out computations from the immediate vicinity of the source of the atmospheric release up to distances as far as necessary where the impact of the release becomes negligible in other words the modelling system should handle multiple spatial scales with high resolution where appropriate especially close to the source this modelling system should also be able to deal in the same calculation with atmospheric dispersion in both natural and anthropic environments it would account for the influence if any of buildings on the atmospheric flow and the dispersion of the release it would allow arbitrary extent for multiple nested domains and would take into account different kinds of meteorological input data weather predictions on a large scale as well as local measurements ultimately it should comprise advanced features such as assimilation of observations in simulations source term estimation from measurements and or the ability to perform ensemble computations to account for the uncertainty on the meteorological data on top of this the numerical results issued by the flow and dispersion models should allow for fast cartographic access for instance through rich cartographic resources and through cloud web services in the next section of the paper we describe state of the science 3d modelling that meets most of these criteria it is worth noting that advanced web capabilities for post processing and visualizing flow and dispersion results at multiple scales are also available though this is beyond the scope of this paper and will be presented in another paper 3 description of the emergencies project the emergencies project was conceived to put into action a system coupling high resolution 3d flow and dispersion models over a very large urbanized area it was initiated in 2014 and established for a short period of three months as it took place in the frame of great challenges organized by the hpc center of the french alternative energies and atomic energy commission cea the project was prepared and realized by the authors of the paper the name emergencies is the acronym for high resolution emergency simulations in huge cities even if running the modelling system over an extensive domain was challenging as such the project ultimately aimed to demonstrate and illustrate that 3d state of the science modelling could be used in a dss in case of an emergency implying adverse radioactive toxic flammable or explosive releases into the air while the next sub sections give an overview of the principles developed in the emergencies project more detailed technical features are presented in oldrini et al 2019 3 1 guidelines of emergencies the basic concept of emergencies was to answer the following question is it feasible to simulate the at d of a deleterious release at high resolution in 3d over a vast geographic area wherever the release might occur but in a time consistent with the management of this emergency situation such an approach could drastically change the way in which dss are operated in crisis preparedness and response and provide rescue teams and their authorities with an accurate reliable evaluation of the health consequences of the release on the population and first responders in real or accelerated time in the emergencies project we chose a domain of interest covering the metropolis of greater paris which encompasses the city of paris and the surrounding suburbs this domain matches the administrative limits under the responsibility of the paris fire brigade the domain has horizontal dimensions of around 40 km 40 km and a horizontal uniform grid resolution of 3 m the vertical grid has 39 stretched levels starting from the ground up to 1000 m the mesh size of the closest to the ground levels is 1 5 m broadening above to the top of the domain in total the 3d grid contains more than 6 billion nodes it is worth noticing that the top of the domain is relatively low and may be inside the atmospheric boundary layer from the meteorological viewpoint higher domains are needed for physical and numerical reasons and utilized in the meso scale weather forecasts see more details below in this sub section still from the dispersion viewpoint we are mostly interested by releases close to the ground influenced by the buildings and the urban canopy and the at d generally occurs at levels lower than 1000 m justifying the domain height would it be necessary for elevated releases or releases entering the domain the top of the domain could be at higher altitude the static data used in the modelling are the topography at an original resolution of 25 m taken from the bd topo of the french national institute of geographic and forest information ign 1 gb of data the land use at the same gridded resolution obtained from the corine land cover 1 gb of data and the buildings in the whole area also taken from the bd topo of ign consisting in 1 15 million of polygons with height attributes 3 gb of data indeed all buildings over greater paris are explicitly accounted for fig 1 shows a 3d view of the domain with the topography and the buildings of paris and its suburbs the emergencies flow simulations at a 3 m resolution accounting for all buildings in the huge 3d domain were performed considering actual meteorological episodes the modelling system dedicated to micro scale meteorological computations is presented in sub section 3 2 the principle was to downscale meso scale forecasts of the weather research and forecasting wrf model skamarock et al 2008 by introducing the fine details of the local topography the land use and particularly the buildings influencing the 3d turbulent flow at local scale using a diagnostic flow model for each simulated day 24 timeframes of the micro scale flow were computed from hourly wrf extraction along vertical profiles inside the huge emergencies domain eventually this 3d flow field at local scale was used as inflow conditions for higher resolution cfd domains in and around some buildings internally meshed at a 1 m resolution the technical details of the wrf simulations performed in the emergencies project are summed up hereafter meso scale weather forecasts were produced with the version 3 3 of wrf and updated every 6 h with a lead time of 5 days there were four wrf nested domains with horizontal resolutions of 45 km over europe 15 km over western europe 5 km over france and 1 666 km over greater paris area wrf domains had 38 vertical levels extending to a pressure level of 18 mbar or a corresponding altitude of circa 15 700 m wrf simulations were driven by the global forecast system gfs at 0 5 spatial resolution produced by the u s national centers for environmental predictions ncep physical parametrizations chosen in wrf were as follows yonsei university scheme for the atmospheric boundary layer mm5 similarity theory for the surface layer with the noah land surface model wrf single moment 3 class scheme for the microphysics and rrtm and dudhia schemes for the respective longwave and shortwave radiation the emergencies scenario was developed as an event that could be faced by civilian security services it was a fictitious attack involving multiple atmospheric releases of substances potentially harmful to the population and the first responders the substances could be chemicals radionuclides or pathogenic biological agents released as gases or fine particulate matter three releases were assumed to happen inside or nearby public buildings and be passively discharged from a container or associated to a weak explosion as any other way to emit potentially noxious substances could be envisaged we decided to favor releases close to the ground in order to enlighten the influence of the buildings and urban canopy on the subsequent propagation of the plumes such releases require that the modelling system be able to track substances either progressing from inner parts of buildings to the outside or occurring in the urban environment and then penetrating into the buildings three places of particular interest were chosen a museum a train station and a strategic administrative building let us recall that the scenario is purely hypothetical but that the parisian environment uses actual data including streets and buildings with actual meteorological conditions 3 2 brief presentation of the pmss modelling system the micro scale modelling system run in the emergencies project was parallel micro swift spray pmss pmss comprises the parallelized versions of the local scale swift flow model and the spray dispersion model these models explicitly take account of the obstacles in built up environments oldrini et al 2011 2017 2019 oldrini and armand 2019 swift moussafir et al 2004 tinarelli et al 2007 is a 3d diagnostic flow model using terrain following coordinates over complex topography and producing velocity pressure turbulence temperature and humidity fields first the model interpolates between meso scale model outputs and or surface and vertical profile meteorological measurements then the first estimate of the velocity is modified using semi analytical flow solutions around isolated buildings or within groups of buildings röckle 1990 kaplan and dinar 1996 finally the mass consistency of the 3d flow is ensured optionally a more accurate computation of the velocity and pressure fields may be carried out with a reynolds averaged navier stokes rans stationary solver oldrini et al 2014 2016 as swift diagnostic approach proved in several test cases to provide a solution close to the cfd reference in a much quicker time baumann stanzer et al 2015 it was exploited for the massive computations in the more than 6 billion nodes domain of the emergencies project spray anfossi et al 1998 tiranelli et al 2007 tinarelli et al 2013 is a lagrangian particle dispersion model that simulates the at d of airborne material by following the trajectories of numerous numerical particles rodean 1996 the velocity of each virtual particle is the sum of transport and turbulent components the transport component is derived from the local average wind vector while the turbulent component is derived from the stochastic scheme developed by thomson 1987 that solves a 3d form of the langevin equation notable characteristics of spray are to consider the bouncing of virtual particles onto the obstacles such as buildings in urban areas and to model dry and wet deposition on all accessible surfaces the rationale for developing pmss was to be able to perform high resolution computations over very large domains in pmss parallelism combines three aspects 1 the decomposition of the large domain into sub domains also called tiles that can be handled by single cores both in flow and dispersion simulations 2 the calculation in parallel of the diagnostic or rans flow at successive timeframes and 3 the distribution of the lagrangian numerical particles among computational cores oldrini et al 2017 2019 moreover pswift and pspray can handle multiple nested domains with either upscaling or downscaling enabling high resolution close to the source of atmospheric release and lower resolution at some distance from the source the pmss modelling system has been thoroughly validated against wind tunnel and full scale experimental results bauman stanzer et al 2015 oldrini et al 2017 trini castelli et al 2018 oldrini and armand 2019 the parallelism was shown to be very efficient from a multicore laptop up to clusters with several hundreds or thousands of cores in the case of a high performance computing center oldrini et al 2019 finally pmss is coupled with code saturne nibart et al 2011 code saturne is a general purpose and environmental application oriented cfd model archambeau et al 2004 milliez et al 2007 in the emergencies project it was utilized to compute the 3d flow in three simulation domains nested in the pmss huge domain meshing the vicinity and the inner parts of the buildings of interest museum train station and administrative building afterwards pmss 3d flow field in the atmospheric environment and code saturne 3d flow fields inside the buildings were used as inputs of pspray in order to evaluate the transfer of airborne materials from the urban environment to the buildings interior spaces or from the inside of buildings to the outside as mentioned above pmss was conceived to be capable to run simulations in a very large and finely meshed 3d domain like in the emergencies project in which code saturne was used to zoom in on the interiors of some buildings obviously this implied large computational resources reaching several hundreds or thousands of cores of a supercomputer comprising 5040 b510 bull x nodes each with two eight core intel sandy bridge ep e5 2680 processors at 2 7 ghz with 64 gb of memory per node 3 3 emergencies results performances and practicality the visualizations supplied in the framework of the emergencies project were graphical static and dynamic results images and videos regarding the atmospheric flow and dispersion at local scale and embracing different zoom levels from the very close vicinity of the release source to a general view of the deleterious plumes through some part of the city of paris or through the whole city itself fig 2 shows an example of multi scale emergencies results the large 2d view is a cross section of the plume over the city of paris 2 h after the beginning of the first fictitious release the cross section is presented at a height of 1 5 m above ground level where people breathe and may inhale the toxic substances the vignettes in fig 2 are oblique zooms of the plumes in the districts of the museum on the left hand side and the administrative building on the right hand side 20 min after the start of each asynchronous fictitious release in the figure the concentrations of the substance initially released into the air near or inside the buildings are colored in green for lower concentrations and in orange for higher concentrations fig 2 reveals many significant mainly urban effects on the wind and subsequently on the dispersion in this regard it is worth noticing that the plumes are channeled through some of the streets they spread inside the street network with complex patterns which would be unforeseeable without numerical predictions all the more so that the plumes partly pass above the buildings they bump into the relief and circumvent it this effect is noticeable even if the city of paris is mostly flat except for some hills of moderate height for instance the butte montmartre finally let us mention that the distribution of the released substance inside the buildings and in their proximity would not be predictable without an appropriate cfd model the numerical results and their operational graphical representation cannot be separated from the computational time needed to obtain these results post process and visualize them which in turn is inseparable from the computational resources that are operated the computational aspects are discussed briefly in the following paragraphs while the strategy for the visualization of the results is a topic in itself for both issues more detailed descriptions are given in oldrini et al 2019 the 3d simulation of the flow over the entire urban domain with the pmss modelling system required a minimum number of computing cores related to the breakdown of the domain into 1088 tiles furthermore the computations of successive timeframes were processed in parallel thus when dealing with eight timeframes concurrently the computational time for the flow decreased from 2 h 40 min to 1 h 20 min using respectively 1089 or 8705 cores for a daily meteorological episode around 5000 cores were required to handle the 24 hourly timeframes in less than 1 h 40 min these figures are noticeable as they prove the ability to downscale 24 timeframes of wrf forecasts to simulate the high resolution 3d flow over greater paris accounting for buildings each day in advance for the following day furthermore they show that the micro scale weather forecast for the next day can be updated 4 or even 8 times a day using the meso scale weather forecast that is provided every 6 h or possibly 3 h thus up to date micro scale meteorological predictions can be obtained as frequently as the meso scale predictions are produced without the risk to use outdated meso scale data the 3d simulations of the fictitious dispersions carried out with the pmss modelling system relied on a lagrangian approach for each release 40 000 numerical particles were emitted at each emission step of 5 s in total 14 4 million of particles were emitted to mimic the three 10 min long releases of noxious substances the particles could move from the vicinity or even from the inside of buildings over paris and its suburbs and vice versa concentrations were calculated every 10 min using 10 min averages the computational time for the dispersion depended on the number of cores for instance it decreased from 2 h 30 min to 1 h 30 min with respectively 250 or 500 cores these figures have to be compared with the simulated physical time of 5 h thus using 500 cores the calculation is 3 3 times faster than the duration of the fictitious dispersions one has to point out that in general it is not necessary to track a plume for 5 h to assess the impact of the release to some kilometers from the source if for instance only 1 h of tracking is adequate dispersion results are obtained in 18 min in the same example as above this result is fully consistent with the objective to inform first responders in 15 30 min as proposed in the introduction of the paper admittedly it is much longer than the computational time of a simpler gaussian or integral at d model but sensible for the benefit of taking account of the complex environment topography land use buildings in a realistic way in the emergencies project nested 3d simulations around and inside emblematic buildings were carried out with code saturne these computations were optionally performed depending on the need to evaluate the indoor outdoor transfers of deleterious substances they exploited around 200 cores per nested domain and timeframe the computational time required between 1 h and 1 h 40 min depending on the size of the nested 3d domain this time turned out to be long compared to the computational time for the flow simulation in the very large domain over the city of paris and its suburbs this is related to the use of a cfd model versus a simplified cfd approach for respectively the simulations inside the buildings and those in the urban environment contrarily to the fast and efficient output of results regarding the distribution of noxious substances in the atmospheric environment see the figures given in the previous paragraphs 3d flow and dispersion simulations inside one or several buildings while informative may significantly burden the production of results and hamper their communication to the decision makers implied in an emergency the functionality of indoor outdoor transfers based on 3d modelling should thus be activated only in time permitting conditions nonetheless such transfers could be evaluated using simpler methods as for instance box models at the expense of the detailed 3d distribution of the deleterious substances inside the buildings in the emergencies project large amounts of data were produced by the pmss simulations they were of around 200 gb for each meteorological timeframe or 4 8 tb for the 24 hourly timeframes of a complete day and around 90 gb for each dispersion simulation still these figures have to be compared to the 5 pb of disk storage offered by the activated supercomputer furthermore the big data would not be transmitted directly to the rescue teams or their authorities but post processed and transformed into images or videos of lightweight file formats or made available through a cloud web service to summarize high resolution flow simulations over the very large domain covering the city of paris and its suburbs prove to be achievable provided a large yet reasonable computing resource is available meso scale weather forecast can be downscaled in order to produce micro scale meteorological fields on a grid with a 3 m horizontal resolution e g 4 times a day in advance for the following day afterwards the highly resolved 3d flow is used as an input of 3d dispersion simulations run in accelerated time compared to the real time beyond the proof of principle study it is essential to consider how in practice the simulations could be integrated in an emergency response procedure flux first of all it is crucial to provide information to the decision makers in a timely manner that is to say no more than 15 30 min to give an order of idea this deadline is challenging as the information about the accidental or malevolent event has to be gathered the simulations must be carried out and their results evaluated and shared with decision makers thus in our opinion the simulations should be performed at an appointed reach back center by at d specialists and then broadcasted to the emergency stakeholders in their own command centers besides the meso scale and the micro scale weather forecasts should be prepared and updated regularly on a routine basis in an emergency situation implying accidental or malevolent releases into the air only dispersion simulations would be carried out on an on demand basis then in the process of informing the rescue teams and their authorities the production and storage of 3d weather forecasts and dispersion results would be in no way a burden for the urgency stakeholders but an acceptable burden for the reach back center one might argue that real world situations are characterized by a high level of uncertainty for instance in case of a malicious event with an unknown source term doubtlessly this can affect the confidence into the simulation results to mention but only an example leadbetter et al 2020 have shown that depending on the considered scenario the largest uncertainties may originate from the source term and the driving meteorological data and to a less extent from the at d model and the space resolution therefore a theoretically very accurate model might lead to an over confidence in the simulations if the uncertainties were not considered in the evaluation how to account for uncertainties is a vast topic beyond the scope of this paper mainly devoted to the practicability of high resolution computations in a huge built up domain this notwithstanding two notes relating to the emergencies project can be made regarding the source term and the meteorological data first the dispersion simulations in the emergencies project run quickly even using a 3d lagrangian model thus it is possible and even advisable to repeat the computations and refine them incrementally as the knowledge on the source term improves when more information pours in from the terrain and the in situ situation is further and better analyzed then resorting to hpc makes possible to downscale not only one realization of the meso scale weather forecast but an ensemble of realizations to integrate at least to some extent the variations of the meteorological conditions moreover it would be feasible to account for the uncertain location of the source by varying its horizontal and vertical coordinates therefore with the brute force of hpc the uncertainties on the meteorology and the source term could be propagated through multiple dispersion simulations whose results would undergo a final probabilistic post processing while the previous considerations demonstrate the practicality of the 3d modelling system developed in the framework of the emergencies project the application of detailed realistic 3d simulations of atmospheric dispersion followed by the evaluation of health impacts are further discussed in the next section with regard to decision making support in an emergency situation 4 benefits of the emergencies project for emergency preparedness and response the emergencies project is the largest and most emblematic application carried out by the authors of 3d flow and dispersion simulations over built up areas like the city of paris and its suburbs yet it is not except for the extent of the area considered the only example of simulations combining on one hand the downscaling of weather prediction from the meso scale to the metric urban micro scale and on the other hand dispersion computations of fictitious deleterious releases whose impact on the health of the population and first responders is assessed while based on smaller computational grids projects in the same vein are presented in armand et al 2015b and in armand and duchenne 2019 the most outstanding feature of the emergencies project and the most recent emergencies mediterranean project armand et al 2017 is their ability to produce in moderate amounts of time information that is both accurate thanks to a 3d flow and dispersion modelling system and also practical and helpful for security services in recent years many simulations carried out by the authors were not dedicated solely to developing validating or applying 3d models in complex configurations but also to demonstrating the actual benefits of such simulations for emergency teams in many cases the computations were performed in the framework of emergency exercises during which danger zones or zones corresponding to recommended counter measures were transmitted to the firefighters and to the authorities armand et al 2013 2014 2016b the modelling system applied in the emergencies project and the computational resources sized for the applications foreseen can provide valuable results to dss this was precisely what we did by leveraging these opportunities to post process and supply operational results to first responders we argue that the information produced in the framework of the emergencies project can be very useful to both emergency preparedness and emergency response in order to enlighten use cases we have chosen to discuss about the security exercises which are common practice by the rescue teams and their authorities in several countries security exercises are representative to a large extent of actual crisis situations and they constitute excellent opportunities to establish dialogue between the emergency stakeholders and the modelers the exercises have two distinct phases which are firstly the preparation of scenarios corresponding to the large panel of emergency situations likely to happen and secondly the handling of fictive emergency situations insofar as such situations can be mimicked obviously all services contributing to the security exercises the firefighters and the administrative authorities at the top of the list wish the most representative as possible conditions for the exercises thus it is of high importance to develop rich and realistic scenario exercises in the preparatory phase and to enact them in the closest manner to real dreaded events in the performing phase based on the experience of the authors in participating to security exercises we argue that they can greatly benefit from modelling and simulation expertise in atmospheric dispersion and health impact assessment without being exhaustive details are given hereafter about the two phases of the exercises preparation and performance and what the role of 3d modelling and simulation could be in association with them as all security exercises do not obey to the same flow diagram we have tried to identify commonalities and propose general recommendations 4 1 elaboration of useful and relevant security exercise scenarios 3d modelling and simulation can be used from the outset of a security exercise project starting from the requests made by security services the modelers can explore various accidental or malicious events implying toxic flammable or explosive materials as examples we have studied exercises corresponding to the explosion of a dirty bomb in a city center armand et al 2013 2014 or a breach in a tank filled with a noxious chemical armand et al 2016b from a modelling perspective meteorological conditions during and after the fictitious release into the air can be chosen by the modelers in agreement with the first responders according a guiding rationale which may be e g to affect a geographic area of interest or multiple areas if evolving meteorological conditions are considered the area can be a crowded district or contain public or administrative buildings of high importance or more generally any locations that are critical regarding the threat of an accident or an attack otherwise actual meteorological situations can be accounted for using weather predictions downscaled from the meso scale to the local scale a variety of releases can also be considered by modelers to support the preparation of a security exercise often the exercises imply chemicals as they are the most widespread hazardous species in transportation handling and storage but sometimes they can involve radionuclides or even pathogenic biological agents the areas affected by the gases or particles emitted into the atmosphere not only depend on the meteorological conditions but also on the quantity and kinetics of the releases proposals can be made by the modelers during the preparation of the exercise about the extent of the affected area which can be chosen to be as large as necessary in order to simulate a serious event and train the first responders and decision makers the kinetics can be carefully pre computed by the modelers in order to fit with real accidental situations as in the case of a breach through a tank a leakage in a pipe the evaporation of a pool etc later the preparatory modelling work can be performed in the run up to a planned exercise by considering the different constraints of this exercise these constraints are connected to the human material and financial means dedicated to the exercise and to the interest of the security services in training for a given event such as an industrial accident implying toxic chemicals or a terrorist attack with a dirty bomb etc it is worth noting that at least at the beginning of the exercise the actual nature of the event may also be ambiguous for example in armand et al 2016b the release from a tanker vehicle could have been purely accidental or been preceded by the hijacking of the vehicle in the frame of the relationships established between the first responders and the modelers the latter can propose to the former several plausible release events corresponding to either accidents or malevolent actions in order to obtain a large panel of situations and also depending on the needs of the security services different weather situations or locations of the release or noxious substances can be studied in any case modelers should be committed to developing realistic scenarios and operating modes for each likely place of the release simulations make it possible to explore many more scenarios than the planning of an actual exercise that requires heavy logistics it is crucial to share the simulation results like those produced in the emergencies project during meetings gathering the numerous parties implied in the security exercise local and regional or national administrative authorities firefighters police health services public transport operators etc while there are various reasons behind the final choice of a security exercise scenario the dispersion and potential health consequences of fictitious toxic releases may be an important deciding factor this is all the more true if the simulations have been carried out using state of the science 3d models and if the results are realistic and reliable if so the relationship established between the security services and the modelers can lead to a well argued relevant and reasonable choice of scenario exercise the discussions between the modelers and security actors should obviously be interactive with the proper expertise of all parties helping the modelers to develop and improve the exercise scenarios it is especially important to check that the features of the scenarios are as realistic as possible and to obey without fail any important requests of the first responders and decision makers for example the protocols and intervention times of the firefighters must be respected it is also beneficial for the security actors to work proactively considering the evolution not only of the resources and means deployed in the field but also of the meteorological conditions which can induce a predictable change for the affected areas over the course of the exercise eventually the result of this strategic and interactive thinking of all security actors including the modelers is to adopt and freeze the parameters of the exercise the field where it takes place the precise nature of the event and of the release the choice of real or imposed meteorological conditions etc for the authors the key points concerning scenario preparation of security exercises are the following exercise preparatory meetings and exchanges enhance the sharing of knowledge between dispersion modelling experts and civilian security services the evaluation of a large panel of accidental or malicious events potentially targeting a large area in a city or a smaller urban district or an industrial site is of great interest as it enhances the anticipation of the resulting human and organizational impact of such events state of the science modelling and simulation allow the development of realistic exercise scenarios that are technically more precise than the usual current practices which means that the in depth work of the emergency actors involved takes precise account of the time sequence 4 2 participation of the modelers in a security exercise or in a real emergency first of all the involvement of the modelers should be decided in advance in agreement with the local and national administrative authorities and with the first responders such as firefighters in the event of a fictitious exercise or a real emergency the modelers in charge should be informed either by the security services or the administrative authority as soon as possible after the beginning of the false or real potentially hazardous release event initial input such as the place of the event and if available an estimate of the source term should be provided to the modelers in order to launch the dispersion calculations of course the modelers should be prepared to face this kind of situation as a recommendation the modelling staff should be present at a reach back center and be ready to use weather predictions both at meso scale and local scale as performed for instance in the emergencies project the modelers should also be prepared to carry out dispersion simulations regardless of the place of the release source in the domain of interest in the emergencies project it was the city of paris and its suburbs an extended geographic area under the responsibility of the paris fire brigade also a representative of the modelling team should be able to join the command center as soon as possible after the beginning of the event and have a designated place among the representatives of all emergency parties administrative authority firefighters police health services etc at the modelling reach back center the first dispersion results should be obtained quickly let us say in 15 30 min as was the case in the emergencies project and made available through e mails or dedicated cloud web services to the firefighters operational center and the command center of the administrative authority which could integrate them directly into their geographic information system gis considering that the computational times are moderate on dedicated appropriate resources simulations can be upgraded i e run repeatedly as new information pours in from the field typically at the very beginning of the event it is most likely that neither the nature nor the quantity of the release is known however the at d of a unit quantity of a provisionally anonymous species can be simulated in order to reveal the concentration pattern of this species in the possibly complex environment urban district or industrial site over a rugged topography and evolving meteorological conditions the early production of this non obvious concentration pattern is extremely valuable for the first responders but it is useful only if the modelling system can cope with the real complex environment without oversimplifying reality after this first stage the dispersion computations can be performed again when the released species is identified and its quantity estimated this new information is acquired thanks to a better understanding of the situation and or the use of measurements carried out in the field in general a simulated or real emergency situation implies many decisions relating to population protection transport hospitals schools etc see e g armand et al 2016b many of these could benefit from the presence of an expert in the field of dispersion modelling and health impact assessment some non exhaustive examples of decision making are given hereafter most often the question of population sheltering or evacuation arises very quickly this aspect is discussed by the firefighters the medical emergency team and the administrative authority as noted in armand et al 2016b the participation of the modelling expert can be very useful as map views of the non intuitive dispersion pattern of the released species can be displayed at the command center these maps are typically of the same type as those produced in the emergencies project as a first action the confinement of the buildings rather than their evacuation may be recommended by the firefighters and as a precaution the administrative authority may give an order to confine the district while waiting for a more accurate evaluation of the situation modelers can contribute to this evaluation with the plume maps that originate from the simulation using a dynamic presentation such as a time evolution through a video of the dispersion it can be made clear if and when the release is finished and the plume is diluted moreover as soon as the released species has been identified and an order of magnitude of the quantity emitted into the air has been cautiously evaluated the concentration values having adverse effects and also no adverse effects on human health can be displayed basically the exposure map presented after the plume has crossed the entire area can be used to delineate the zones where immediate health consequences are expected or where counter measures such as sheltering evacuation or any other required actions should be taken with a safety margin of which the emergency stakeholders are well aware the case of toxic chemicals with a smell is interesting see armand et al 2016b indeed the most severe health effects may be limited to a relatively small area while it is probable that numerous people would detect the abnormal presence of the chemical at much farther distances from the source due to a low olfaction threshold this is obviously considered to be very important information for the firefighters and the emergency medical team as a saturation problem may arise if people who smell the chemical odor head massively to the hospitals over time measures taken in different parts of the affected area especially if it is large may be further examined in light of the simulation results and the measurements coming later on from the terrain for instance the aeration of buildings can be advised when the plume has left the sector or measurements in the field may be used to check that concentration levels are low to a degree consistent with the modelling etc the updates of the real or fictitious emergency are other situations demonstrating the role and value of accurate reliable simulations such as those performed in the emergencies project the arrival of high level decision makers can trigger situation updates during such a sequence a representative of the administration briefly describes the event the firefighters show on a map the presence of the rescue teams in the field and explain the measures taken and the medical team updates the number of casualties and the hospitals taking care of them etc the intervention of the modelling expert can be considered key for making the decision makers aware of the situation in the field through the use of simulation results typically the evolution of the plume is shown with a video and the assessment of the health consequences is cumulated from the beginning of the release to the updated time as most accidental or malicious releases are quite short or do not last more than a couple of hours the situation updates may take place when the risk no longer evolves again simulations are of value for exploring the evolution of the situation and contribute to decision making combined with information from the field regarding the progressive annulment of measures previously taken for the authors the key points concerning the in situ participation of modelling experts to security exercises or actual emergency situations should they occur are the following state of the science modelling and simulation are more relevant than simplistic approaches thus they can be used effectively by the services in charge of population protection the simulation results are helpful for identifying the at d processes especially in complex built up environments for adapting the first actions of the rescue teams and for anticipating the follow up to the event static and dynamic presentations of the results are both of interest maps and videos may be used throughout an exercise or a real emergency situation not only for communication purposes but also for collective appropriation during the situation updates the interactions between the modelers the security services and the first responders are extremely beneficial they make it possible to further improve and to adapt the results provided by the modelling system to better fit the needs and missions of the civilian security organization there is a synergy between the rescue teams first actions which are irreplaceable for short and medium duration releases and the simulations carried out to diagnose the situation and anticipate its evolution even if it is difficult to know the source term in many cases the early visualization of the dispersion pattern and plume is undoubtedly of high interest for supporting the first phase of the response it is certainly also important to share the modelling results between the emergency actors even if their missions and time responses differ for example in the case of an exercise at the local level simulation results may be transmitted to a national emergency command center even if it does not lead the exercise directly but may have a strong interest in the simulation results finally the authors argue that there are two essential benefits in providing state of the science simulation results and expertise in the course of a deleterious atmospheric release the results are relevant for enhancing a common understanding of the space and time distribution of the hazardous materials this can help greatly in making decisions and taking appropriate measures for population protection the results can be used to foster communication with the authorities and all emergency actors this can help generate a shared representation of the situation and an optimal coordination of the command center 5 conclusion even in current practice rescue teams and their local or national authorities are most often provided with results of simplistic at d models should an accidental or malicious atmospheric release of cbrn e agents occur these models such as in the gaussian approach either do not address or else address in only an oversimplified way the complex and non intuitive dispersion pattern that is observed in actual built up urban or industrial areas over rugged topography and in variable and complicated meteorological situations for instance the dispersion upstream of the location of the release or the dispersion in streets perpendicular to the general wind direction above the urban canopy are intrinsically accounted for by 3d models while it may not be the case when using less advanced modelling in that respect simplified models not only provide an inaccurate presentation of the actual 3d distribution of deleterious gaseous or particulate substances but they may also give misleading information to the first responders subsequently emergency procedures in complex atmospheric environments especially built up areas should not be based on models that are inappropriate for these environments and that can result in ineffective or indecisive responses there are numerous dss implementing at d models that can be operated through graphical user interfaces in this paper we propose a brief and presumably non exhaustive overview of some well known dss this set of dss has in common to present a number of interesting functionalities and is used as a testbed for comments on what are or could be if not present in any system valuable features of a dss for instance to face the broad and diversified panel of threats implying releases into the air a dss should be able to deal with different in nature hazardous materials a choice of at d models adapted to natural or built up environments capabilities regarding multi scale modelling simulation at high space and time resolution transfers of materials from the outside to the inside of buildings etc while not mandatory in all dss especially those dedicated to only one kind of threat situations these features would be appreciable and meet issues of prime interest for rescue teams our paper describes the emergencies project which was intended to achieve the twofold ambition of elaborating a system based on state of the science at d models and demonstrating the value of this system for emergency preparedness and response in the project meso scale weather prediction was performed over europe and france and then downscaled to a very large domain encompassing the city of paris and its suburbs at a 3 m resolution and accounting for all buildings the 3d turbulent wind fields were used to transport and disperse hypothetical hazardous releases moreover the domain over greater paris was supplemented with cfd innermost nested domains in and around specific buildings of interest to evaluate indoor outdoor transfers in practice the emergencies concept of use was to perform multi scale weather forecasts the meso scale meteorological fields being downscaled on a routine basis one or several times a day then the dispersion simulations were run for the project or would be carried out in real life on an on demand basis in case of need everywhere in the greater paris domain at one or multiple locations these computations were proven to run faster than real time it is worth noticing that the dispersion simulations may be performed concurrently inside buildings or infrastructures in the large urban domain where all buildings are accounted for explicitly and also beyond in the meso scale domains as the lpdm embedded in the modelling system handles nested domains and upscaling or vice versa downscaling as a short digression it is worth coming back to the examples of infamous events given in the introduction in fact the transposition of the emergencies project to the urban area of tokyo city and the underground station affected by the sarin release would be possible and make our modelling system applicable to this terrorist attack on another note while different in the typology of the event and extent of the impacted area the fukushima nuclear power plant disaster could benefit from the capabilities of our system in weather and dispersion events reconstruction from the near field some kilometers to the intermediate and far fields some hundreds of kilometers this illustrates the multi purpose nature of our modelling approach even if as it stands the consequences on human health are evaluated only at short term while a module for long term impact could be a further development especially in case of radioactive releases obviously the modelling system featured by the emergencies project has also limitations firstly there is place for model improvement as for instance the thermal effects generated by the buildings would need a specific development maintaining moderate computational times more fundamentally real events implying possibly harmful substances into the air are most often imperfectly characterized in terms of the nature quantity timing and location of the release and of the meteorological conditions prevailing during and after the emission it is a general issue for all modelling systems and well beyond the scope of this paper this notwithstanding let us mention that the dispersion computations in the emergencies project run quite rapidly and can be repeated with the intention to account for the field information and interact with the emergency stakeholders furthermore leveraging the power of hpc multiple dispersion simulations could be performed exploiting an ensemble of weather predictions rather than only one realization as done in this project and different possible locations of the release after propagating the meteorological and source term uncertainties in the computations the massive results would be post processed in order to produce probabilistic maps of the impacted areas while the emergencies project was devoted to the greater paris area we have performed similar simulations in extremely large domains over the cities of marseille toulon and nice in the south region of france armand et al 2017 indeed we do not anticipate difficulties in principle to deploy the concepts underlying the emergencies project for other regions and cities using either the pmss modelling system or micro scale models with comparable functionalities the prerequisites are of two types firstly data are needed regarding the topography the land use and the buildings on the one hand global scale or meso scale weather forecasts on the other hand obviously all these data must be at a sufficient resolution to be useful for micro scale 3d simulations secondly significant computational resources are necessary and a key aspect of the project to our knowledge static data are available for more and more cities in the world weather predictions are ubiquitous at increasingly finer resolutions lastly the hpc power is perhaps more hardly accessible but computing centers keep developing worldwide thus for the authors the emergencies project is of general applicability and exportability at least in developed countries while perhaps still less easily in developing countries the emergencies project illustrates the reliability and timeliness of our modelling system in the conditions of an emergency in a vast and complex environment considering the resources and skills needed for the simulations they could be carried out by specialists in dispersion modelling at a reach back center and transmitted to the emergency stakeholders with preferably an expert in the command center in any case the project proves the feasibility of providing rescue teams and their authorities with high resolution simulations whose use and benefits are thoroughly analyzed in the paper both in preparation for emergency situations involving either toxic flammable or explosive materials and in response to these situations in the project the simulation domain was chosen to coincide with the very large area under the responsibility of the paris firefighters who give the authors opportunities to participate in real security exercises this is also a major fact that the amount of computer power engaged in the emergencies project was very large but not unreachable nor inconsistent with the means that could be dedicated to emergency management in the past years our r d efforts in the field of atmospheric dispersion and health impact assessment have not only focused on physical modelling but also encompassed the transfer to operational applications and the adequacy of decision support systems with regard to the organization and missions of the emergency actors activities like the emergencies project are not uniquely theoretical but account for tight relationships built for a long time with emergency stakeholders we argue that this approach is essential to promote the use of state of the science at d models in dss whose results are accepted and trusted by practitioners even if it is still prospective and not yet entered in the current practice of emergency handling it is very likely that supercomputing will become a more and more beneficial commodity for first responders and their authorities in the diagnosis and anticipation of emergency situations to our knowledge the multi scale highly resolved 3d simulations carried out in the framework of the emergencies project are unique as they combine a huge geographic extent with a metric grid resolution we argue that such simulations are the topical way to rigorously account for 3d flow and dispersion in complex atmospheric environments and subsequently to realistically and reliably estimate the health impact of hazardous releases on the population and the first responders thus simulations such as those performed in the emergencies project are not an academic exercise but a new paradigm for supporting emergency preparedness and response declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper annex table 1 overview of some decision support systems for cases of adverse atmospheric releases the acronym the full name the sponsors or companies in charge of development the nature of distribution commercial or not and the main users the atmospheric transport and dispersion models the threat agents the source term and impact assessment models the ergonomics of the graphical user interface other remarks and internet link are identified for each dss described table 1 name acronym full name development sponsors or companies distribution and users atmospheric transport and dispersion models and developers threat agents source term models and impact assessment models ergonomics of the user interface and cartography features comments internet link hpac hazard prediction andassessment capability u s department of defenseu s department of homeland securitydefense threat reduction agency usa executable version distributed to american agencies in charge of civilian or military security issues andto counterpart organizations in allied countries of the usano commercial purpose three models of increasing complexity available scipuff gaussian puff model with advanced capabilities sage management udm gaussian puff model with capabilities to account for isolated buildings or groups of buildings uk dstl pmss lagrangian particle dispersion model aria technologies and cea nrbc e releasessimple modelling of explosions and wide variety of accidental or malevolent scenarios notably for chemicalsradiological exposures compared to countermeasure thresholds for sheltering evacuation iodine prophylaxis chemical concentrations compared to toxicological reference values aegl erpg idlh biological agent contagion models easy handlinguser friendly interface designed to provide easy access to a wide variety of scenarioscartographic capacities dss adapted to many kinds of threat agents and scenarios of releases with a user choice of atmospheric transport and dispersion models adapted to natural or built up environmentscapacities for biological releases which are rarely available in dsscapacities for explosions with simplified models no direct access to any hpac sitemore information about dtra http www dtra mil midas meteorological information and doseassessment system abs consulting usa commercial purposemainly used in the usa with subsidiaries in the world asia europe quite common among u s operators of nuclear plants black box models an integral model and possibly a lagrangian modelquestionable capacity to account for buildings radioactive releases onlyadapted to plants in normal operation or affected by accidentsradiological exposures and protective measures in case of emergency cf module named radiological effluents administration system easy handlingergonomic user interfacelimited cartographic capacities different ways to account for meteorological conditions predictions and or local measurementsallow for safety studies compliant with the norms of the u s nrc nuclear regulatory commission http www absconsulting com midas cfm saferhazmat responder systematic approach for emergency response safer systems usa commercial purposemainly used in the usa with subsidiaries in the world europe used in industry infrequently by firefighters black box model integral model able to deal with heavy gases and accounting for the influence of the topographyno explicit treatmentof buildings crude modelling of outdoorto indoor transfers chemical releases onlyseveral source term models of passive and energetic releaseschemical concentrations compared to toxicological reference values aegl erpg idlh quite easy handling but numerous options relevant graphical interfaceadvanced integrated cartographic capacities connection with gis google earth to be noted the ste source term estimation feature within the abc advanced back calculation modulesafer hazmat responder softwareis integrated into the safer real time global supervision systemagreement between safer systems and the danish company rae systems detectors and protective materials http www safersystems com solutions core products safer hazmat responder aloha areal locations of hazardous atmospheres u s environmental protection agencynational oceanic and atmospheric administration usa free downloadable executable versionvery much used inthe usa and in europe especially by firefighters two basic models gaussian rectilinear plume model and model for heavy gasespossibility of running the hysplit lagrangian particle dispersion model noaa chemical releases onlyseveral accidental chemical scenarios breach in a tank break of a pipe pool evaporation explosive scenarios bleve boiling liquid expanding vapor explosion uvce unconfined vapor cloud explosion etc chemical concentrations compared to toxicological reference values aegl erpg idlh very simple handlingrudimentary graphical interface with limited options for the uservery limited cartographic capacities when using aloha basicallyoption to exportthe results to gis especially when running hysplit in aloha integrated into the cameo computer aided management of emergency operations systemcomprehensive database of chemicalslimited capacities but widespreadstrictly no capacity for dispersion in built up areas http www2 epa gov cameo aloha software phast dnv gl norway commercial purposeintensive use by specialized engineering consultants less usually by firefighters integral model for passive gases and for gases lighter or heavier than air chemical releases onlymultiple scenariosand source term models more sophisticatedthan in aloha e g explosions chemical concentrations compared to toxicological reference values complex graphical interface with numerous optionslimited cartographic capacitiesoption to exportthe results to gis more advanced and also more complexthan alohaa great deal of models for the source termstypically developed for industry subcontracting risk studies to consultants https www dnvgl com services phast modules 1696 ct analyst contaminant transport analyst naval research laboratory usa executable version possibly e licensed to agreed organizationsexcept by the nrl unclear use in the usapossibly used by firefighters in hamburg germany cfd les large eddy simulations complex model of the flow and dispersion with long computational timeno cfd computations in case of emergency requirement to create beforehand a database of wind fields for each site of interestuse of nomographs for the dispersion and impact assessmentof threat agents nrbc releaseschemical concentrations compared to toxicological reference values aegl possibility of evaluating radiological exposures relevant graphical user interface enabling source term definition with its localization on a map and a quick overview of the results owing to the absence of computations only post processing of results obtained beforehand possibly used by firefighters in several cities in the usa andin hamburg germany methodological limitations extremely long pre computations of the wind fields lack of possibility to take changes in the meteorology during the dispersion into account http www nrl navy mil lcp ct analyst rodos real time on line decison support system originally fzk forschungszentrum karlsruhe development funded by the european union eu available for the member states of the eupotentially used by14 european countries austria belgium bulgaria croatia finland germany greece hungary netherlands poland portugal romania slovenia and spain optional access to lasat lagrangian particle dispersion model several available modelsatstep gaussian puff kit iket rimpuff gaussian puff risø dtu dipcot lagrangian puff or particle demokritos match eulerian smhi lasat lagrangian particle bfs radioactive releasesradiological exposures compared to countermeasure thresholds for sheltering evacuation iodine prophylaxis quantification of the effect of protective measures for the population agricultural production management and site remediation simple handlingergonomic graphical user interfacewith coupling to gis option to carry out meso scale dispersion computations usingthe weather predictions of the dwd deutscher wetterdienst no dedicated sitenot referenced onthe site of the joint research centers jrc of the eu argos accident reporting guidance and operational support dema danish emergency management agencydevelopment partially founded by the european union eu available for the member states of the eupotentially used by6 european countries denmark estonia latvia lithuania ireland and sweden and also by extra european countries canada brazil and australia rimpuff gaussian puff risø dtu urd urban gaussian puff accounting simply of the buildings risø heavy gases model for the chemicals radioactive releaseslikewise rodos for the impact assessment and the evaluationof the benefit of countermeasurespossibility of chemical releases simple handlingergonomic graphical user interfacewith coupling to gis option to carry out meso scale dispersion computations with derma and hirlam denmark snai norway or mldp0 canada using the national weather predictions of these countries no dedicated sitenot referenced onthe site of risø dtu c3x irsnradiation protection and nuclear safety institute france used by the irsn for radiological emergency preparedness and responsealso used by électricité de france french electricity supplier and operator of the french nuclear power plants no commercial purpose two models availablepx gaussian puff école centrale de lyon ldx eulerian ditto polair developed by the cerea centre d enseignement et de recherche sur l environnement atmosphérique radioactive releasesradiological exposures compared to countermeasure thresholds for sheltering evacuation iodine prophylaxis unknown graphical user interfacecartographic capacities in the krx module short range up to 100 km computations with px and long range continental or global scale computations with ldx using the national weather predictions of météo france no modelling in the urban environment no dedicated site 
25809,since the 2010 deepwater horizon dwh oil spill the gulf of mexico research initiative gomri has studied the oil spill from the perspectives of ocean environment ecosystems socioeconomics and human health as gomri sunsets in its tenth year after the dwh oil spill synthesis efforts recently took place to assess the accomplishments of the program in this paper we report on dwh modeling as part of gomri s synthesis and legacy effort we compile a list of 330 published applications by gomri the natural resource damage assessment nrda and others studying the dwh oil spill and look at a wide range of subjects tools achievements and integration with field research we offer highlights and synthesis based on discussions and public webinars held in 2019 and 2020 we synthesize the significant achievements and advancements that have been made in integrating the various disciplines and domains from a modeling perspective there was a large diversity of tools used including at least 74 unique modeling systems most studies employed circulation models these hydrodynamic models were often coupled to wave river and atmosphere models as well as representations of high pressure physics and oil chemistry several research groups used lagrangian transport models and statistical inference to track subsurface oil some coupled biophysical models were also employed to study oil fate and weathering larval transport biological effects and population dynamics in a few cases such biophysical models were linked to marine populations and to humans through socioeconomics effects and ecosystem services we consider models made for response planning and remediation damage assessment and restoration planning there are relatively few socioeconomic or human health models although those few examples make good use of biophysical modeling products our conclusions offer some insights on how the development of new tools has better prepared us for studying environmental management challenges in the gulf of mexico keywords oil spill deepwater horizon oil transport and fate ecosystem socioeconomic numerical modeling 1 introduction 1 1 gomri legacy it is the end of a ten year research program studying the deepwater horizon dwh oil spill the independent gulf of mexico research initiative gomri was funded by a u s 500 million commitment from bp gomri s goal was to improve society s ability to understand respond to and mitigate the impacts of petroleum pollution and related stressors of the marine and coastal ecosystems with an emphasis on conditions found in the gulf of mexico from the gomri mission statement gomri solicited proposals for fast response studies in 2010 and issued six more requests for proposals from 2011 to 2018 these were directed at research consortia consisting of four or more institutes smaller groups and individual researchers altogether 394 research groups 17 consortia and at least 2849 researchers from around the world contributed over the past 10 years griidc 2020 more than 1260 peer reviewed publications have been produced and more than 3154 data sets have been archived on the gulf of mexico research initiative information and data cooperative griidc data repository comprising at least 83 tb of data griidc 2020 as gomri ended in 2020 synthesis and legacy has become a focus a synthesis and legacy committee was established in 2019 to oversee eight areas core area 1 plume and circulation observations and modeling core area 2 fate of oil and weathering core area 3 ecological ecosystem impacts core area 4 human health and socioeconomic impacts core area 5 ecosystem services core area 6 microbiology metagenomics and bioinformatics core area 7 integrated linked modeling systems core area 8 knowledge exchange with user communities this paper reviews the integrated and linked modeling systems in core area 7 these bring together theory and tools developed in areas 1 through 6 into a common predictive framework core area 7 is further divided into areas 7 a and 7b these areas distinguish operational modeling from synthesis modeling although they may be better viewed as including tactical versus strategic modeling tools we include both types in this review because there is a high degree of overlap in concept tools data and expertise herman stachowiak s general theory of models 1973 reminds us that a model is only a limited reproduction and reduction of the real world models only include things assumed to be important by the creators and are designed with a user in mind and specific questions in mind operational and synthesis models are designed for a certain purpose and for a certain time therefore a model should be understood by answering four questions a model of what for whom for what purpose for what time period the distinction between tactical and strategic models is most relevant in terms of the motivation and perspective of the user tactical models operate over a short time horizon hours or days this minimizes assumptions and makes them agile tools for response planners strategic models are more inclusive and heuristic in nature because they offer a framework on which to reconcile many different types of information often cross disciplinary they simulate over weeks years or decades and may be employed for damage assessment and recovery planning they are directed towards managers stakeholders and academics there are many examples in gomri of cross disciplinary integrated modeling systems systems may be loosely connected by data flow from one model to another or more tightly federated to permit feedback among domains examples include use of velocity fields from hydrodynamic models in lagrangian ocean models use of oil constituent distribution from ocean models to evaluate exposures and effects for ecosystem models and further chaining of ocean and ecosystem processes to derive inputs for human health and socioeconomic models the preponderance of ocean ecosystem models discussed below is consistent with the comparatively recent emergence and integration of socioeconomic and health models many unexploited opportunities exist for connecting physical and ecosystem variables to socioeconomic and health models this might entail one way causal connections to enhance the measurement of impacts or full feedback to assess how perceptions of spills condition responses in this paper we attempt to synthesize the advancements that have been made in integrating the various disciplines and domains from a modeling perspective we compile a list of published applications by gomri researchers the natural resource damage assessment nrda and others studying the deepwater horizon oil spill between 2010 and 2020 we looked at the range of subjects studied tools used use of model coupling and integration with field research this allows us to offer some synthesis based on discussions and public webinars in 2019 and 2020 arranged as part of a core 7b review synthesized here are the significant areas of achievement and advancements our conclusions offer some insights on how the development of new tools has better prepared us for studying environmental management challenges in the gulf of mexico 2 methods 2 1 data collection we reviewed modeling applications since 2010 focused on studying the dwh oil spill the literature search was based on project websites citations an informal core 7b knowledge survey and discussions with modelers leads and the gomri research board we documented peer reviewed articles technical reports book chapters and conference proceedings in a few cases we cite griidc datasets if no other published methodological or application papers from a particular model or research group could be located in addition to the literature search we highlight discussions from the core 7b synthesis effort these included a meeting of gomri modelers at the gulf of mexico oil spill and ecosystem science conference in tampa in 2019 a series of webinars and virtual workshops in the spring of 2019 and a series of virtual workshops in may 2020 the goal was to recognize the full range of work done by gomri and the impact that gomri has had on the state of integrated modeling besides this article there are two other manuscripts resulting from the gomri core 7b synthesis webinars and meetings solo gabriele et al 2021 uses causal loop diagrams to visualize connectivity of human and natural systems mauritzen et al unpublished manuscript uses system dynamic modeling to illustrate ecosystem connections made in integrated modeling we concentrated on numerical modeling we have not documented any applications of empirical models though many numerical models incorporate statistical methods in parameterization simulation and validation there were many empirical models developed as part of gomri masi et al 2014 mcdonald et al 2017 but these deserve their own review ordination analytical models chiri et al 2019 chan et al 2015 kuehl 2014 and conceptual models zeinstra helfrich et al 2015 2016 were also not considered despite being active areas of study 2 2 classification of models as we are interested in integrative modeling we emphasize model coupling especially across disciplines some models are better referred to as modeling systems as they integrate modular components all subcomponents will be identified here we include models that provide boundary conditions and common packages used for data assimilation e g ncoda navy coupled data assimilation system cummings 2005 cummings et al 2013 all published algorithms for model forcing parameterization and boundary conditions are included here as well coare 3 0 fairall et al 2003 k profile parameterization kpp large et al 1994 otis egbert et al 1994 for the purposes of categorizing the cross disciplinary nature of dwh modeling we considered whether applications addressed the following four scientific domains 1 the ocean physical and chemical environment 2 the biological system 3 socioeconomics and 4 human health these categories are consistent with other core 7b synthesis and legacy products https gulfseagrant org oilspilloutreach we further divided the applications into 11 categories related to the subject of the study these categories refer to the interests of the applications and do not necessarily reflect the capabilities or most common uses of the models involved models may be used across many categories the categories are 1 circulation mixing 2 abiotic transport far field 3 oil fate 4 biotic transport 5 biological impacts 6 other plume dynamics 7 turbulence local mixing 8 water chemistry 9 atmosphere 10 oil spill response support and 11 other circulation mixing represent a wide range of hydrodynamic studies that do not include explicit particle tracking abiotic transport refers to the large body of work tracking reference particles models in this category treat particles as passive and chemically biologically inert but some use a multi fraction droplet size distribution dsd model to affect processes such as buoyancy deposition rate and oil fate oil fate models may add chemical or biological breakdown or dispersion submodels biotic transport of larvae or eggs implies coupling to biological models where particles can interact with other biological components paris et al 2013 bracco et al 2019 we made particular note of models that crossed two or more scientific domains finally we noted the degree to which models use field data to guide the modeling effort 3 results 3 1 overview of dwh modeling work supplemental table s1 shows 330 numerical modeling applications for the dwh oil spill by gomri nrda and other authors all these applications were published between 2010 and 2020 table s2 shows original references for each numerical modeling system employed we will hereafter refer to the items in table s1 as applications and items in table s2 as models even though table s2 includes a few packages for boundary conditions parameterization and data assimilation table 1 arranges the applications by subject of study 3 2 65 physical models a majority 65 of the studies 214 330 used physical modeling sometimes including chemistry fig 1 at least 11 consortia 6 individual investigator research grants from gomri rfps ii v and vi and nrda efforts contributed these types of products topics included circulation turbulence mixing plume dynamics particle transport deposition and physical chemistry circulation models resolved mixing dynamics based on the contributions of coupled atmosphere ocean and wave xue et al 2015 huang et al 2013 curcic et al 2016 sorourian et al 2020 and or by taking surface oil feedback to ocean atmosphere and wave into account zheng et al 2013 or by including detailed river plume dynamics and their effects on hydrocarbon transport schiller and kourafalou 2010 kourafalou and androulidakis 2013 androulidakis and kourafalou 2013 greer et al 2018 hole et al 2019 particle transport studies used lagrangian models with passive reference particles either integrated into the circulation model directly roms shchepetkin and mcwilliams 2005 fvcom zheng and weisberg 2012 or as a stand alone tool cms paris et al 2012 2013 tracmass döös et al 2013 these systems used innovative model coupling of wave models and river effects huang et al 2013 and surface oil s effects on the atmosphere ocean waves coupling bourassa et al 1999 le hénaff et al 2012 incorporated dispersant effects on oil transport reed et al 1995 french mccay et al 2005 paris et al 2012 french mccay et al 2015a 2018a b c d and potentially in situ skimming and burning lehr et al 2002 buchholz et al 2016 french mccay et al 2018c d some far field modeling studies have used measured currents as well as data produced by circulation models e g french mccay et al 2021 3 3 22 physical biological coupled models another 22 of studies 80 330 coupled physical models with biological models fig 1 the most common uses included lagrangian particle tracking of eggs and larvae by gisr deep c cimage and rfp v shay see research gulfresearchinitiative org for a complete list of gomri consortia and individual researcher awards for example the coupled ocean atmosphere wave sediment transport model coawst warner et al 2010 zambon and warner 2014 employed by the gisr and cimage consortia couple physical processes hydrodynamic atmospheric wave turbulence from roms hycom wrf and swan with larval transport models such as ltrans north et al 2008 and connectivity modeling system cms paris et al 2013 physical and chemical processes come together in oil fate models such as oil cms simap and oscar french mccay 2003 2004 paris et al 2012 lindo atichati 2016 french mccay et al 2018a b c d reed et al 1995 perlin et al 2020 vaz et al 2021 tamoc is a nearfield plume model with chemistry gros et al 2017 2020 within gomri the cimage dropps and gisr consortia engaged in this work socolofsky et al 2015 reviewed near and far field modeling with oscar with plume 3d oil cms oilmap oilmapdeep as well as particle tracking ltrans cms and droplet formation models vdrop j physical biological model coupling also helped to address research questions concerning water quality hypoxia nutrient cycling and red tides and fisheries impacts e g weisberg et al 2016a lenes et al 2013 justic and wang 2014 nrda faced a similar task of modeling oil transport fate and effects using the spill impact model application package simap french mccay et al 2015a b c 2018a to evaluate the impacts of the dwh further developing modeling methods used by french mccay 2003 2004 french mccay et al 2018a c boem nrda utilized roms hycom ngom ncom and atmospheric models narr nogaps and csfr along with simap to evaluate oil transport and fate sensitivity to circulation 3 4 5 biological models less than 5 of modeling studies 15 330 used only biological modeling fig 1 these included population dynamics niche habitat suitability models matrix population models and individual based models by carmmha ecogig deep c ladc gemm rfp v saul studies by the carmmha consortium developed age and cohort based population matrix models for bottlenose dolphins and fish species schwacke et al 2017 these were notable for integrating expert opinion powers and saul 2018 used agent based modeling to assess fish movements 3 5 5 physical biological social coupling full integration across physics biochemistry and socioeconomic domains was achieved by 5 of studies 17 330 these studies coupled an oil fate model with an ecosystem model to incorporate dispersal burial evaporation biodegradation and uptake depuration dynamics the model coupling therefore accounted for exposure and toxicity in 4d and was used to determine both lethal and sublethal impacts ainsworth et al 2018 dornberger et al 2016 berenshtein et al 2020 modeling these processes was supported by targeted laboratory experiments e g mitchelmore et al 2020 table s1 shows applications using amseas fvcom hycom oil cms or simap for circulation oil fate data while applying the ecosystem models habsim ecopath with ecosim ewe or atlantis from these metrics can be computed to measure impacts on human beings fisheries value ainsworth et al 2018 berenshtein et al 2019 food security suprenand et al 2019 toxin exposure walsh et al 2016 lenes et al 2013 environmental services rohal et al 2020 impacts on shore based industries court et al 2019 in this last example court and colleagues went an extra step using an input output model implan to interpret catch predictions from atlantis in terms of impacts on tourism and hospitality this example therefore represents the longest chain of quantitative reasoning in dwh modeling products linking ocean physics biology and socioeconomics 3 6 modeling products by consortia fig 2 shows modeling products by consortium numerical modeling was utilized most by the cimage carthe deep c and gisr consortia with dropps ecogig and various small research groups also making contributions circulation modeling was a major area of study across consortia small research groups nrda carthe deep c and gisr applied these circulation models to abiotic transport questions these studies used simulated drifters to answer near and far field transport questions in addition carthe deep c dropps gisr and small research groups applied this work in the areas of plume dynamics local mixing and biotic particle transport cimage had the most publications relating to the study of biological impacts but ecogig ladc gemm and small research groups contributed implications of oil spill response were mainly supported by the oil spill risk and response planning community outside of gomri e g buchholz et al 2016 crowley et al 2018 french mccay et al 2018d 2019 bock et al 2018 however much gomri science was ancillary to this topic gomri was responsible for improvements in understanding and model formulations for oil transport and fate fig 3 shows the number of models coupled per publication fifty eight percent of studies 192 330 used a single model the rest coupled two or more models together 3 7 advances in ocean physics and chemistry 3 7 1 near field modeling near field modeling represents the movement of oil near the wellhead socolofsky et al 2015 identified the following areas of active study in dwh near field modeling bubble and droplet generation plume modeling intrusion formation coupling to circulation models particle tracking and bubble and droplet fate modeling achievements in near field modeling of the dwh oil spill include an accurate representation of dissolved gas and dissolution of the liquid fraction gros et al 2017 2020 this controls how gas bubbles affect turbulent mixing and entrainment processes fabregat et al 2017 this incorporates the influence of oil chemistry on plume characteristics plume modeling in gomri has benefited from laboratory work in high pressure environments and better model formulations for hydrate formation and dissolution gros et al 2017 2020 3 7 2 far field modeling major circulation models employed in dwh modeling include hydrostatic primitive equations models hycom roms fvcom ncom etc or non hydrostatic large eddy simulations les fig 4 oil cms simap gnome and oscar may be better called oil fate models as they utilize circulation model results to integrate particle movement e g oil rising velocity interacting with ocean temperature and salinity paris et al 2012 and model oil breakdown e g dissolution and photooxidation vaz et al 2021 and dispersal processes see below there are many more circulation models that are used for dwh modeling models of smaller spatial domains utilizing models such as fvcom suntans or roms may be nested inside the gom or global scale circulation models most often hycom and roms to provide boundary conditions circulation models ranged in scale from individual estuaries to submesoscale and basin scale spatial domains aizinger et al 2013 cambazoglu et al 2017 cui et al 2018 taylor 2018 we believe a major advancement in far field modeling following the dwh oil spill is the development of a system of multiple scale numerical models that span the river wetland estuary shelf open ocean continuum and covers physics geomorphology biogeochemistry water quality and coastal food webs in the gulf of mexico when dealing with large spills floating oil can substantially modify wind and ocean waves which in turn modifies the movement of the spill the importance of surface fronts was also identified relating them to freshwater outflows explaining the dynamics using submesoscale physics and characterizing dispersive and anti dispersive properties oil can become thicker when impinging on a front so fronts are important areas for responders to note far field modeling in gomri has benefited from laboratory work in high pressure environments malone et al 2018 pesch et al 2018 and better model formulations for emulsification hydrate formation dissolution and sedimentation nguyen et al 2018 lindo atichati et al 2016 perlin et al 2020 vaz et al 2021 3 7 3 particle tracking and oil fate progress was made in modeling oil dispersion using lagrangian particle tracking liu et al 2011a collected a series of early modeling efforts associated with the dwh oil spill including the rapid response operational models combining satellite imagery inferred oil locations and aerosol formation with trajectory models liu et al 2011c macfadyen et al 2011 degouw et al 2011 spaulding 2017 provides a recent review of far field oil transport and fate modeling in common to these efforts the movement of oil is resolved in three dimensions and fate processes are represented such as dispersion spreading evaporation entrainment emulsification dissolution biodegradation photooxidation and sedimentation examples of these methods for modeling the dwh oil spill includes work done for nrda and boem french mccay et al 2015a 2018a b 2021 carthe uwin cm laser chen and curcic 2018 huntley et al 2011 cimage oil cms paris et al 2012 perlin et al 2020 gisr ltrans chapman et al 2014 and deep c liu et al 2011b 2014 weisberg et al 2011 2016b 2017 some of the studies employ published tracer advection algorithms such as mpdata smolarkiewicz 1984 modeling microbial degradation of oil lags behind modeling efforts in oil transport dispersion and oil chemistry socolofsky et al 2019 presents a review of simple first order degradation models gomri funded researchers have documented microbial degradation rates and microbial community succession patterns during oil degradation kostka et al 2011 rodriguez et al 2015 huettel et al 2018 time series linking in situ petroleum hydrocarbon degradation to microbial community activities allowed predicting a 30 year period for the decomposition of sediment oil agglomerates buried in gulf of mexico sandy beaches bociu et al 2019 shin et al 2019 a searchable genome database cataloguing diversity and global distribution of crude oil associated microbes was established that provides molecular identification tools and spatial distribution data for models integrating microbial community responses karthikeyan et al 2020 the csomio model dukhovskoy et al 2021 combined simulations of oil with microbial degradation and sedimentation using different computational schemes coawst genome and cstms using a two way lagrangian eulerian mapping technique also used in perlin et al 2020 this enables interaction between all of the modeling components for tracking of hydrocarbons from a source blowout to deposition in sediment microbial degradation and evaporation while being transported through the ocean photooxidation of surface dwh oil led to the formation of persistent photooxidized compounds found a decade later studies demonstrated that photooxidation modified both biodegradation rates of the surface oil and the effectiveness of aerial dispersant applications the first step before modeling biodegradation of oil in shoreline sediments is to model the photooxidative changes and track the transport of persistent photooxidized compounds vaz et al 2021 estimated and tracked the likelihood of photooxidation of lagrangian oil droplets by coupling the net shortwave radiation from nogaps to the oil cms the dose of solar radiation upon a droplet is computed with the intensity of the incoming irradiance at the ocean s surface the light attenuation coefficient and the depth of the oil droplets this new dynamic coupling provides a powerful tool to test oil weathering hypotheses refine the oil budget during the dwh and ultimately inform rapid response in future oil spills 3 7 4 subsurface oil tracking before the dwh there was no oil spill model that dynamically computed live oil gas saturated concentrations of oil droplets in the deep sea though models did take other thermodynamic processes pertaining to high pressure environments into account e g johansen 2003 yapa et al 2001 2010 zheng and yapa 2002 in dwh modeling circulation models were effectively combined with 3d lagrangian particle models e g weisberg et al 2011 turbulence waves river atmosphere models and even biodegradation and oil chemistry to form coupled model systems paris et al 2012 combined near far field models like oscar simap with oilmap deep used for the nrda spaulding et al 2015 2017b french mccay et al 2015a 2018a and oil cms offer important complements to noaa s work with more tactical response planning models like gnome these models consider oil transported at the subsurface and at the surface coupling near field and far field models vaz et al 2019 an important conclusion of these models for dwh is that bubble and droplet rise velocity should be accurately predicted accounting for in situ conditions zheng and yapa 2000 and evolving particle sizes due to various fate processes gros et al 2017 pesch et al 2020 the subsurface oil simulator sosim model echavarria gregory and englehardt 2015 jacketti et al 2020 2021 ji et al 2020 2021 offers an alternative bayesian modeling method for tracking subsurface oil including the only model written specifically for sunken bottom oil as well as a module specifically for submerged water column oil starting with the general solution of the advection dispersion equation the model accepts 4 d field concentration data collected in initial sampling campaigns as input to infer the values of model parameters sosim further accepts bathymetric data as bayesian prior information indicating coriolis forcing and settling of sunken oil it also inputs alternative fate transport model output as prior information reflecting hydrodynamic data conditions that influence the movement of submerged oil the approach complements and potentially improves on lagrangian particle tracking alone by rigorously integrating field data with prior information to provide a ground truthed forecast representing the relative probability of finding oil in time and space 3 7 5 atmosphere weather forcing there has been a realization in dwh studies that atmospheric forcing options in models cannot be treated as arbitrary a large number of circulation studies included atmospheric forcing using models like wrf coamps and coawst representation of the air sea interface atmospheric and oceanic boundary layer parameterizations and the selection of the coupling method inclusion of ocean currents sea surface temperature waves and oil slicks have a substantial impact on forecasts le henaff et al 2012 soloviev et al 2014 geng et al 2016 a novelty for the fate of surface oil is the capability to model dynamically photo oxidation of oil based on solar irradiance vaz et al 2021 a new solar irradiance module of oil cms is coupled with navgem navy global environmental model 3 7 6 droplet size distribution dsd near field modeling of the dwh brought about development of droplet size distribution dsd models that can account for the decrease of mean droplet sizes due to dispersant use in subsea dispersant injection ssdi johansen et al 2013 zeinstra helfrich et al 2015 spaulding et al 2015 2017 zhao et al 2016 2017 li et al 2017 gros et al 2017 therefore affecting transport and degradation of oil paris et al 2012 french mccay et al 2018a b c d 2019 an important advancement is the coding of lagrangian reference particles as oil droplet entities with attributes of density and size paris et al 2012 lindo atichati et al 2016 spaulding 2017 perlin et al 2020 these can interact with the ocean model temperature and salinity variables to affect rise velocity terminal velocity and plume characteristics paris et al 2012 droplet size and rise velocity are two of the most important variables to model the far field oil trajectory and dispersal paris et al 2012 zhao et al 2017 gros et al 2017 pesch et al 2018 quantification of both biodegradation and dissolution generates a change in the dsd through time lindo atichati et al 2016 oil spill models in the 1980s and 1990s often did not address the dsd for oil blowouts nissanka and yapa 2018 however numerous experimental and modeling efforts in gomri were directed at resolving oil rise and entrainment dynamics in buoyant plume models socolofsky et al 2015 zhao et al 2017 gros et al 2017 aiyer et al 2019 bracco et al 2020 models applied a fundamental log normal or rosin ramler dsd distribution law johansen et al 2013 gros et al 2017 li et al 2017 perlin et al 2020 or non fundamental distribution function vdrop j in deep sea oil spill models faillettaz et al 2021 demonstrated that the choice of probability distribution function of the dsd for far field modeling is regardless of the mean droplet size d50 consequential for oil spill response 3 7 7 multiphase droplets a breakthrough for deep sea blowout modeling is the capability to model multiphase oil droplets these have a gas and a liquid phase to model the internal degassing process that has been revealed in laboratory experiments malone et al 2018 pesch et al 2018 2019 the gas saturated oil is subjected to a pressure drop similar to the one observed at the oil platform during the dwh blowout the oil cms has a new degassing module that allows both expansion of gas nucleated within the droplet and dissolution of gas pesch et al in review tamoc also models multiphase droplets showing that gas dissolution of free gas was rapid out of the liquid droplets while at depth such that oil droplet rise may have little influence from degassing gros et al 2020 however there has not yet been validation of the percentage of free versus nucleated gas within the liquid oil phase using field data from dwh 3 8 advances in biological modeling gomri has advanced the representation of oil spills on both low and high trophic level communities coupling oil fate and circulation models to ecosystem models has allowed a highly resolved representation of population level effects in space and time this is a necessary feature in estimating impacts on exploited species which are often mobile and spatially partitioned by life stage this allows us to represent different exposure risks in different types of habitat these methodologies can be readily extended to other geospatial pulse disturbance problems like toxic algae blooms and hypoxia ecosystem models have benefited from the 4d representation of oil concentrations at the short spatial and temporal scales native to circulation models e g simap ecospace suprenand et al 2019 french mccay et al 2015b c 2018a c d cms atlantis ainsworth et al 2018 uptake depuration dynamics and dose response relationships can quantify the effects of oil french mcay 2002 2003 2004 the mode of oil uptake by organisms can be represented in biological models to represent transdermal absorption or ingestion ainsworth et al 2018 dornberger et al 2016 methods developed to study dwh were subsequently applied to hypothetical oil spills berenshtein et al 2019 paris et al 2020 suprenand et al 2019 the ixtoc oil spill the exxon valdez oil spill t okey pers comm and oil pollution in the niger delta ndimele e pers comm a lot of the discoveries in gomri centered around developing a better understanding of physical and biological community connectivity many sampling laboratory and modeling efforts were devoted to it investigating pelagic diet linkages especially has become relevant to recent observations about population connectivity paris et al 2020 milligan et al 2018 coupled hycom cosine modeling allowed derada 2019 to explore vertical connectivity of pelagic habitat within the planktonic microbial community coles et al 2017 similarly represented microbial communities implicitly using coupled circulation and genomics models genome coles et al 2017 woodstock et al 2020 coupled a biochemical model roms npzd to osmose an individual based ecosystem model of the upper food web fvcom habsim uses an integrated biological model within a circulation model weisberg et al 2016a zheng and weisberg 2012 lenes et al 2013 walsh et al 2016 again stimulated trophic connectivity in pelagic food webs to demonstrate that fisheries and oil spills can have cumulative effects this has direct consequences for human health weisberg et al 2016a the theme of connectivity in pelagic food webs was also applied to the study of higher trophic levels ainsworth et al 2018 showed how food web impacts near the wellhead were translated to distant areas through impacts on mobile forage fish populations ongoing efforts will determine whether linkages between epi and mesopelagic communities influence vulnerability to subsurface plumes ruzicka et al unpublished manuscript have collaborated with the deepend consortium to develop a set of oceanic food web models gomex ecotran aimed at quantifying trophic connectivity between epi meso and bathypelagic depth zones via particle sinking and diel vertical migration behavior ongoing simulations with gomex ecotran aim to estimate how perturbations to vertical exchange processes and changes to food web structure within each depth zone propagate throughout the entire water column woodstock et al 2021 confirmed that large pelagic fish were highly dependent on mesopelagic forage and therefore potentially vulnerable to deep sea pollution a consistent problem with upper food web simulation studies is that fully probabilistic simulations are difficult due to run time limitations in highly resolved spatial food web models e g suprenand et al 2019 ainsworth et al 2018 morzaria luna et al 2018 made a major advance in the state of the art by using cloud computing and a statistical emulator to predict atlantis responses other studies appealed to semi quantitative expert opinion based approaches to narrow the parameter space suprenand et al 2019 schwacke et al 2017 other biological models like the matrix models of ackleh et al 2019 can be evaluated using a formal sensitivity analysis 3 9 advances in socioeconomics modeling few quantitative models of the socioeconomics of oil spills are available one early attempt was made outside of gomri to assess potential fishery damages through a simple value chain model sumaila et al 2012 court et al 2017 utilized the travel cost method and input output analysis model using to evaluate the economic impacts of cancelled recreational trips to northwest florida after the dwh spill an input output i o model was provided outputs from the atlantis ecosystem model with oil cms inputs to evaluate shifts in commercial and recreational fishing activities due to fishery closures resulting from the dwh spill court et al 2019 this included projections for non consumptive industries like tourism and hospitality another example used oil cms to simulate fisheries and socio economic impacts arising from fishery closures berenshtein et al 2019 2020 in a similar fashion simap integrates the ocean environment and ecosystem domains and provides estimates of ecosystem valuation by providing input to another model the offshore environmental cost model oecm boem 2016 finally one of the gomri rfp v projects developed a bioeconomic spatially explicit agent based model of fisher decision making behavior and demersal fish population dynamics saul et al 2020 the model is being used to understand how coupled fisher fish behaviors interact with hypotheses about oil related toxicological fish mortality and the spatial fishing closures used to protect seafood safety the model represents the important institutional components of the system such as the individual fishing quota system as well as state conditions such as fish and fuel prices weather conditions and others part of the difficulty in the integration of socioeconomic models with models within the ecosystem domain is due to the differences in measures and scales for example the valuation of fisheries is dependent upon the fish species among fish species there is a valuation for commercial versus recreational fishing therefore the ecosystem information requires considerable disaggregation to get at measures that would be useful for socioeconomic models socio economic models are also dependent upon decision making relevant scales yoskowitz et al 2017 cash et al 2006 detail these scales to include jurisdictional institutional management networks and knowledge at the regional to local levels all of which would influence the linkages needed to ocean environment and ecosystem models the requirement for time stepping is also difficult for socio economic models as they typically rely on fixed price relationships which are only appropriate for static modeling court et al 2019 3 10 advances in human health modeling human health during environmental disasters is impacted by physical exposures to contaminants and to the emotional stress which has significant impacts on mental health mental health may also impact physical health but these connections although recognized have not yet been quantified modeling of physical health can be facilitated through risk assessment approaches nrc 2009 epa 2010 which is a process used to estimate the probability of harm model setup begins by identifying the hazard i e chemical concentration at point of human exposure followed by computing exposure through multiple routes dermal ingestion inhalation and ultimately computing the probability distribution of health risk ott et al 2007 impacts to physical health are highly dependent upon the specific chemicals in oil thus coupling ocean environment models to estimate physical human health impacts requires disaggregating the oil into individual chemical compounds crowley et al 2018 provide an example determining air exposure risks for individual volatile organic compounds one approach has been developed through beaches beach exposure and child health study for estimating physical health impacts to children who play at oil impacted beaches ferguson et al 2020 montas et al 2020 integration of the beaches risk assessment approach would require disaggregation of oil into constituent chemical species to represent oil interactions in water air and sediments in beach environments in the context of mental health conceptual and semi quantitative models have been established to evaluate cause disaster direct and secondary effects and effect resilience and recovery within a community as measured by economic stability housing stability physical well being mental well being and social role adaptation abramson et al 2010 2015 new models of human systems are needed to represent some processes thought to be important for example economic models typically omit a number of social or human capital dimensions with important implications for the long term evolution of communities including concepts like resilience that are of clear interest to gulf stakeholders in an economic input output framework such as implan 2020 education and health care activities do not explicitly produce health happiness or productivity as outputs therefore a complementary model of off market phenomena in coastal communities would be a desirable reusable component for future integration of spill impacts on human systems sandifer et al 2017 describe a conceptual framework for a disaster pressure state ecosystem service response health dpserh model the framework emphasizes the importance of capturing broad feedbacks for valuing oil spill impacts and guiding response efforts since the model is conceptual it is underspecified relative to a simulatable implementation of the same scope however it is a useful road map for integration that highlights multiple features that are missing from the current model portfolio subsets of the concept may perhaps be implemented via federation of existing model components by constructing the model de novo one would have the advantage of choosing a practical level of detail for each concept a complementary top down modeling approach that explores physical biological social feedbacks in an aggregate strategic way is explored in the accompanying 7b synthesis products by the authors 3 11 marriage of experiment and modeling gomri can point to many successful examples of where experiment and observations supported modeling physical simulation models benefited from drifter experiments in the 2012 grand lagrangian deployment glad and the 2016 lagrangian submesocale experiment laser projects these were organized by the carthe consortium poje et al 2014 with the purpose of investigating particle dispersion and submesoscale features glad released drifters near the dwh site and louisiana coast laser took place in the de soto canyon region laser deployed even more tracers than the previous glad and used ship based and aerial observations to accompany laser which focused primarily on offshore processes the submesoscale processes and lagrangian analysis on the shelf splash took place in 2017 focusing on nearshore submesoscale dynamics http carthe org another drifter experiment the gulf integrated spill response gisr tracer experiment was conducted in 2012by the gisr consortium ledwell et al 2016 drifters and a chemical tracer were released in the northern gom subsequent cruises monitored the dispersal of the tracer these programs aim to understand the role of large ocean flows in dispersing oil and resolve problems that some transport models have in representing small scale convergence zones haza et al 2018 tracer data were compared with hydrodynamic outputs using sabgom he 2016 and roms hycom bracco et al 2018 khade et al 2017 drifters were similarly used to validate hydrodynamic models beron vera and lacasce 2016 gomri supported hydrodynamic models benefiting from these field observations greatly improved current predictions used for dwh oil transport and fate modeling north et al 2015 french mccay et al 2018a c 2021 there are also experimental data to support near field modeling for example wang et al 2016 took advantage of a field program to characterize turbulent diffusivity in the northern gom this helps control mixing of oil gas pollutants in plume modeling droplet size distribution experiments also informed plume modeling johansen et al 2013 li et al 2017 experimental and field data evaluated by ward et al 2018a b combined with dwh oil fate modeling demonstrated the importance of photo oxidation as a fate pathway previously under estimated in a similar way biological modeling was supported by field and laboratory research field studies were designed concurrently with modeling efforts and with attention to addressing knowledge gaps in modeling physiological experiments in cimage determined the rate of clearance of pahs in fishes snyder et al 2015 and this was used in the calculation of lethal and sub lethal effects in fish populations dornberger et al 2016 high pressure experiments helped set biodegradation rates for oil fate simulations and pressure induced degassing using oil cms lindo atichati et al 2016 pesch et al in review rov observations of reef fish communities helped calibrate toxicological impacts in ecosystem simulations ainsworth et al 2018 plankton and fish sampling including that supported by nrda and gomri informed vertical and horizontal biological distribution models used for nrda injury modeling french mccay et al 2015b c and connectivity modeling for benthic species paris et al 2020 sediment chemistry measurements montagna et al 2013 valentine et al 2014 stout and german 2018 passow and stout 2020 helped modelers better understand and model impacts on the demersal food web due to marine oil snow sedimentation and flocculent accumulation mossfa quigg et al 2016 burd et al 2020 that collaborative effort helped show the mechanism of mossfa enrichment of the detritus based food web 4 discussion 4 1 gomri modeling legacy the volume and quality of modeling work in gomri belies the substantial technical and logistical challenges in achieving model integration across disciplines and systems gomri provided a consistent focus on a large but well defined research problem that held an urgent connection to human health and well being in that context the remarkable pace and innovation is easy to understand and also the value of synthesis modeling the notable achievements in synthesis modeling rested on close collaborations between data providers and modelers and between scientists in different disciplines an estimated 1260 total publications resulted from gomri griidc 2020 the list of 330 modeling applications identified here represents a sizable part of the total scholarly output dwh modeling may have benefited from an economy of scale as researchers shared many common resources by 2021 gomri modeling rests on a mature collection of data well established protocols for data archiving and exchange from griidc and a still expanding library of methods and applications in the public domain the well attended annual gomoses conference offered reliable opportunities for synergies within and outside of gomri other shared resources were managed by gomri administration these included assistance in publication education and outreach networking and coordination the gomri research board provided oversight and coordination responding to new discoveries for example by establishing the marine oil snow sedimentation and flocculent accumulation mossfa working group that cross consortia group coordinated research efforts associated with oiled marine snow the mossfa working group influenced modeling and led to discoveries about benthic food webs dornberger 2018 for modeling long time series are important and the continuity of research funding that gomri offered over the last 10 years supported that need the consistency was more valuable since the pre spill reference data were so insufficient joye 2015 seven consortia were funded by two or more sequential awards dropps cwc cimage carthe ecogig recover addomex the long term interests of gomri offered a rare chance for iterative observations where modeling helped to direct field observations weisberg et al 2015 cooperation outside of gomri was strengthened with the conclusion of the lengthy injury assessment and nrda claim settlement dwh trustees 2016 at that time all nrda data and assessment information became publicly available resolution of the damage assessment phase also enabled increased cooperation between nrda and non nrda researchers many researchers supported by gomri as well as the oil spill response community utilized these vast data sets made publicly available by the nrda as well as data collected under gomri funding the publications of gomri sponsored research and improved hydrodynamic modeling developed under gomri funding greatly improved the accuracy of oil transport and fate modeling by academia over those performed for the nrda by oil consultants french mccay et al 2018a c 2021 this and other research will continue to make use of the valuable data sets collected from the gulf of mexico and coastal areas 4 2 a foundation in ocean physics there were a variety of hydrodynamic and particle tracking systems each offering individual strengths by which we could examine the oil spill from different perspectives the high inshore resolution of fvcom up to 150 m in estuaries and inlets was suitable to model local factors associated with algal bloom dynamics weisberg et al 2016a which is an important link to human health implications due to the potential for aerosolization of toxins zhong and bracco 2013 showed the value of having different spatiotemporal resolutions available for understanding loop current dynamics chapman et al 2014 similarly demonstrated the value of having a range of resolutions available they nested a gulf scale model roms sabcom with a shelf model roms and a bay model suntans to represent seamless movement of oil into estuaries significant developments in far field circulation modeling owe partly to development in both near field plume and turbulence modeling outputs from nearfield models are important to far field models such as buoyant plume trapping and intrusion dynamics particle slip velocity hydrocarbon pseudo components and droplet size distributions thus the physics of oil dispersal and oil fate required close coupling between near field plume dynamics and circulation models with wave river and atmospheric models contributing there were many such examples of modeling coupling and even hybrid approaches which modeled near and far field dynamics in an integrated system e g chen et al 2018 paris et al 2012 vaz et al 2019 lagrangian particle tracking was used with both near and far field models and reference particles represented the transport of the bulk oil and its concentration oil fate models were further linked to biodegradation photooxidation and biological dispersal routines new laboratory experiments in high pressure physics oil chemistry and biology supported this effort emulsification hydrate formation dissolution sedimentation and biodegradation were examined lagrangian tracking partitioned the oil into different chemical species based on a particle size distribution model where each particle size can have unique physical and chemical properties multi fraction particle models allowed modeling dissolution lindo atichati et al 2016 perlin et al 2020 this allowed better study of subsurface dispersant injection as we could contrast the behaviour of oil with and without the presence of dispersants berenshtein et al 2019 french mccay et al 2017 2018d paris et al 2012 this was a prescient matter for the dwh response as both surface and subsea dispersant injection were used data assimilation tools including ncoda and soda were used often going forward heuristic lagrangian models such as sosim and oil cms may become important tools for locating and forecasting the position of oil based on real time data for emergency response decisions damage assessment and study thus we had a well articulated 4d picture of oil transport and fate this provided a strong foundation on which to build biological community and socioeconomic modeling 4 3 biological connections as many as eight consortia and four individual awards contributed to biological modeling one popular area of study involved the use of biotic transport models to study the movement of larvae zooplankton bacteria and ichthyoplankton many of the low trophic level and plankton models used lagrangian methods but there were also examples of plankton community interaction models desai et al 2019 lenes et al 2013 there were many more examples of community models operating at high trophic levels using atlantis ecopath with ecosim ecotran matrix models or other approaches population connectivity was a common theme in biological studies paris et al 2020 food web connectivity was examined by several authors using food web models the connection between epi and mesopelagic food webs is likely to remain a long term research interest in the gom the large biomass and energy demands that the vertically migrating mesopelagic community places on epipelagic production suggests that events impacting either the epipelagic or the deep pelagic communities can propagate widely throughout the entire water column there was a strong case made through the combined observations of deepend and cimage that deep water oil spills like dwh pose a threat to mesopelagic communities that threat is potentially affected by the use of dispersants which has implications for food web dynamics morzaria luna et al in review connections between demersal and pelagic food webs remains an important open question which was considered by gomri in detail these connections were assessed using far field modeling johnston and bernard 2017 genetic approaches bracco et al 2019 field observations murawski et al 2018 and modeling dornberger et al 2016 gomri sponsored models that explicitly include diel vertical movement processes and trophic connectivity between the epipelagic and deep pelagic such as atlantis and gomex ecotran are being applied to simulate how pulse disturbances i e modeled by mortality recruitment or growth forcing functions at different depth zones propagate throughout the water column and ecosystem horizontal connectivity through food web effects and animal movement were demonstrated to be important factors in damage assessment in both the dwh and ixtoc oil spills ainsworth et al 2018 4 4 human systems efforts to understand socioeconomic impacts stand out as the most integrative projects in gomri and dwh studies potentially spanning physical natural and human systems socioeconomic impacts were often based on fisheries impacts but also considered were shore based industries recreation and ecosystem services there were not many researchers working on these problems compared with other physical chemical and biological modeling interests human health and socioeconomics modeling other than fisheries impacts consisted of less quantitative modeling methods with a few exceptions walsh et al 2016 used lower trophic level community modeling to estimate impacts of fishing and oil spills on asthma triggers and red tides walsh et al 2016 other authors calculated impacts on ecosystem services including carbon sequestration and food security rohal et al 2020 suprenand et al 2019 due to the paucity of models in the human health and socioeconomic domains there appear to be many opportunities for connecting ocean ecosystem models to enhanced human system models at least two approaches may be fruitful 1 coupling existing ocean ecosystem models to existing economic models this would likely resemble extensions of the existing 5 of models that already integrate physical biological and socioeconomic knowledge domains table s1 col f these models may allow valuation of ecosystem components and respond to bottom up environmental drivers 2 creation of new health and socioeconomic models that address important feedbacks particularly between mental and physical health and socioeconomic activity and between perceptions of risk and welfare that shape behavior and disaster response results from coupled oil spill models that integrate socioeconomics and human health could be used to assess potential risks and societal level impacts of decisions made during and after clean up efforts model based assessments could provide additional critical information to decision makers about the long term impacts of their decisions 4 5 new modeling tools in stachowiak s general theory of models the motivation of the modeler or client influences model design as much as any other factor when we consider the diversity of stakeholders and the diversity of economic social and cultural interests affected by the oil spill a wide range of modeling capabilities indeed must be needed to capture all the processes of interest gomri modeling has greatly expanded our state of knowledge and put much more of the ecosystem under experimental control this is reflected in the diverse list of applications stakeholder interests are interconnected and synthesis modeling can show us where interests align and where trade offs between competing interests exist these tradeoffs are inevitably connected with oil response decisions for example the use of dispersants influences the relative exposure of surface inshore deepwater pelagic and benthic habitats the use of dispersants therefore affects which resources and stakeholders are likely to be impacted most by the oil paris et al 2012 2018 french mccay et al 2018d bock et al 2018 there is also a trade off in the dispersal of the oil that can be examined with oil fate and effects models with possible links through natural and human systems the applications identified here address needs of emergency personnel managers scientists and many other stakeholders thus gomri s mandate to improve society s ability to respond to oil pollution was well supported by modeling the model applications explore impacts on different systems and at different temporal and spatial scales short and medium term modeling studies focused on plume dynamics fate of oil and aftermath for coastal industries and seafood safety while long term modeling focused on ecosystem state changes and recovery planning hydrostatic primitive equations models like hycom and roms and non hydrostatic les models were the most commonly employed tools together they contributed about one third of the publications nevertheless there was a great diversity of approaches employed in the 330 modeling applications and in the 74 unique models explored here taken together as a suite models developed for the study of dwh form a continuum of processes that can be linked end to end conceptually and often numerically at one end weather and ocean forecasting models are process based and use basic physical principles like newton s laws they have relatively little need for empirical parameterization at the other end socioeconomic and human health modeling is often based on empiricism biological models occupy the middle ground in more than one sense they play an important role in synthesis modeling because the interests of human beings are often affected through impacts on the health of marine populations although gomri has sunsetted operations what will remain are the new tools and a cadre of modeling expertise that remains relevant to addressing new environmental challenges spills of national significance such as the dwh oil spill do not occur very often and the daily responsibilities of regional scientists and managers need to focus on immediate issues during and after an accident like this one public efforts and energy understandably need to be directed toward health and safety environmental clean up and quantifying the extent of the damage for settlement purposes for this reason gomri played an important academic role improving our understanding of the nature and risks of oil spills particularly deep oil spills and the vulnerabilities of natural and human systems in the gom this is important information if we wish to fully consider risks in the calculation of costs and benefits of oil exploration in the gom we recommend that scientists and managers leverage the wealth of models and data amassed by gomri nrda and others to support holistic evaluation of the benefits and risks associated with oil exploration declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests cameron ainsworth reports financial support was provided by gulf of mexico research initiative gomri acknowledgements we acknowledge contributions from participants of the gomri core 7b activities and we acknowledge support from gomri for the writing of this manuscript the following people lent their expertise to the research jim ledwell whoi ping chang tamu ryan takeshita and lori schwake nmmf provided valuable input on the carmmha model appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105070 
25809,since the 2010 deepwater horizon dwh oil spill the gulf of mexico research initiative gomri has studied the oil spill from the perspectives of ocean environment ecosystems socioeconomics and human health as gomri sunsets in its tenth year after the dwh oil spill synthesis efforts recently took place to assess the accomplishments of the program in this paper we report on dwh modeling as part of gomri s synthesis and legacy effort we compile a list of 330 published applications by gomri the natural resource damage assessment nrda and others studying the dwh oil spill and look at a wide range of subjects tools achievements and integration with field research we offer highlights and synthesis based on discussions and public webinars held in 2019 and 2020 we synthesize the significant achievements and advancements that have been made in integrating the various disciplines and domains from a modeling perspective there was a large diversity of tools used including at least 74 unique modeling systems most studies employed circulation models these hydrodynamic models were often coupled to wave river and atmosphere models as well as representations of high pressure physics and oil chemistry several research groups used lagrangian transport models and statistical inference to track subsurface oil some coupled biophysical models were also employed to study oil fate and weathering larval transport biological effects and population dynamics in a few cases such biophysical models were linked to marine populations and to humans through socioeconomics effects and ecosystem services we consider models made for response planning and remediation damage assessment and restoration planning there are relatively few socioeconomic or human health models although those few examples make good use of biophysical modeling products our conclusions offer some insights on how the development of new tools has better prepared us for studying environmental management challenges in the gulf of mexico keywords oil spill deepwater horizon oil transport and fate ecosystem socioeconomic numerical modeling 1 introduction 1 1 gomri legacy it is the end of a ten year research program studying the deepwater horizon dwh oil spill the independent gulf of mexico research initiative gomri was funded by a u s 500 million commitment from bp gomri s goal was to improve society s ability to understand respond to and mitigate the impacts of petroleum pollution and related stressors of the marine and coastal ecosystems with an emphasis on conditions found in the gulf of mexico from the gomri mission statement gomri solicited proposals for fast response studies in 2010 and issued six more requests for proposals from 2011 to 2018 these were directed at research consortia consisting of four or more institutes smaller groups and individual researchers altogether 394 research groups 17 consortia and at least 2849 researchers from around the world contributed over the past 10 years griidc 2020 more than 1260 peer reviewed publications have been produced and more than 3154 data sets have been archived on the gulf of mexico research initiative information and data cooperative griidc data repository comprising at least 83 tb of data griidc 2020 as gomri ended in 2020 synthesis and legacy has become a focus a synthesis and legacy committee was established in 2019 to oversee eight areas core area 1 plume and circulation observations and modeling core area 2 fate of oil and weathering core area 3 ecological ecosystem impacts core area 4 human health and socioeconomic impacts core area 5 ecosystem services core area 6 microbiology metagenomics and bioinformatics core area 7 integrated linked modeling systems core area 8 knowledge exchange with user communities this paper reviews the integrated and linked modeling systems in core area 7 these bring together theory and tools developed in areas 1 through 6 into a common predictive framework core area 7 is further divided into areas 7 a and 7b these areas distinguish operational modeling from synthesis modeling although they may be better viewed as including tactical versus strategic modeling tools we include both types in this review because there is a high degree of overlap in concept tools data and expertise herman stachowiak s general theory of models 1973 reminds us that a model is only a limited reproduction and reduction of the real world models only include things assumed to be important by the creators and are designed with a user in mind and specific questions in mind operational and synthesis models are designed for a certain purpose and for a certain time therefore a model should be understood by answering four questions a model of what for whom for what purpose for what time period the distinction between tactical and strategic models is most relevant in terms of the motivation and perspective of the user tactical models operate over a short time horizon hours or days this minimizes assumptions and makes them agile tools for response planners strategic models are more inclusive and heuristic in nature because they offer a framework on which to reconcile many different types of information often cross disciplinary they simulate over weeks years or decades and may be employed for damage assessment and recovery planning they are directed towards managers stakeholders and academics there are many examples in gomri of cross disciplinary integrated modeling systems systems may be loosely connected by data flow from one model to another or more tightly federated to permit feedback among domains examples include use of velocity fields from hydrodynamic models in lagrangian ocean models use of oil constituent distribution from ocean models to evaluate exposures and effects for ecosystem models and further chaining of ocean and ecosystem processes to derive inputs for human health and socioeconomic models the preponderance of ocean ecosystem models discussed below is consistent with the comparatively recent emergence and integration of socioeconomic and health models many unexploited opportunities exist for connecting physical and ecosystem variables to socioeconomic and health models this might entail one way causal connections to enhance the measurement of impacts or full feedback to assess how perceptions of spills condition responses in this paper we attempt to synthesize the advancements that have been made in integrating the various disciplines and domains from a modeling perspective we compile a list of published applications by gomri researchers the natural resource damage assessment nrda and others studying the deepwater horizon oil spill between 2010 and 2020 we looked at the range of subjects studied tools used use of model coupling and integration with field research this allows us to offer some synthesis based on discussions and public webinars in 2019 and 2020 arranged as part of a core 7b review synthesized here are the significant areas of achievement and advancements our conclusions offer some insights on how the development of new tools has better prepared us for studying environmental management challenges in the gulf of mexico 2 methods 2 1 data collection we reviewed modeling applications since 2010 focused on studying the dwh oil spill the literature search was based on project websites citations an informal core 7b knowledge survey and discussions with modelers leads and the gomri research board we documented peer reviewed articles technical reports book chapters and conference proceedings in a few cases we cite griidc datasets if no other published methodological or application papers from a particular model or research group could be located in addition to the literature search we highlight discussions from the core 7b synthesis effort these included a meeting of gomri modelers at the gulf of mexico oil spill and ecosystem science conference in tampa in 2019 a series of webinars and virtual workshops in the spring of 2019 and a series of virtual workshops in may 2020 the goal was to recognize the full range of work done by gomri and the impact that gomri has had on the state of integrated modeling besides this article there are two other manuscripts resulting from the gomri core 7b synthesis webinars and meetings solo gabriele et al 2021 uses causal loop diagrams to visualize connectivity of human and natural systems mauritzen et al unpublished manuscript uses system dynamic modeling to illustrate ecosystem connections made in integrated modeling we concentrated on numerical modeling we have not documented any applications of empirical models though many numerical models incorporate statistical methods in parameterization simulation and validation there were many empirical models developed as part of gomri masi et al 2014 mcdonald et al 2017 but these deserve their own review ordination analytical models chiri et al 2019 chan et al 2015 kuehl 2014 and conceptual models zeinstra helfrich et al 2015 2016 were also not considered despite being active areas of study 2 2 classification of models as we are interested in integrative modeling we emphasize model coupling especially across disciplines some models are better referred to as modeling systems as they integrate modular components all subcomponents will be identified here we include models that provide boundary conditions and common packages used for data assimilation e g ncoda navy coupled data assimilation system cummings 2005 cummings et al 2013 all published algorithms for model forcing parameterization and boundary conditions are included here as well coare 3 0 fairall et al 2003 k profile parameterization kpp large et al 1994 otis egbert et al 1994 for the purposes of categorizing the cross disciplinary nature of dwh modeling we considered whether applications addressed the following four scientific domains 1 the ocean physical and chemical environment 2 the biological system 3 socioeconomics and 4 human health these categories are consistent with other core 7b synthesis and legacy products https gulfseagrant org oilspilloutreach we further divided the applications into 11 categories related to the subject of the study these categories refer to the interests of the applications and do not necessarily reflect the capabilities or most common uses of the models involved models may be used across many categories the categories are 1 circulation mixing 2 abiotic transport far field 3 oil fate 4 biotic transport 5 biological impacts 6 other plume dynamics 7 turbulence local mixing 8 water chemistry 9 atmosphere 10 oil spill response support and 11 other circulation mixing represent a wide range of hydrodynamic studies that do not include explicit particle tracking abiotic transport refers to the large body of work tracking reference particles models in this category treat particles as passive and chemically biologically inert but some use a multi fraction droplet size distribution dsd model to affect processes such as buoyancy deposition rate and oil fate oil fate models may add chemical or biological breakdown or dispersion submodels biotic transport of larvae or eggs implies coupling to biological models where particles can interact with other biological components paris et al 2013 bracco et al 2019 we made particular note of models that crossed two or more scientific domains finally we noted the degree to which models use field data to guide the modeling effort 3 results 3 1 overview of dwh modeling work supplemental table s1 shows 330 numerical modeling applications for the dwh oil spill by gomri nrda and other authors all these applications were published between 2010 and 2020 table s2 shows original references for each numerical modeling system employed we will hereafter refer to the items in table s1 as applications and items in table s2 as models even though table s2 includes a few packages for boundary conditions parameterization and data assimilation table 1 arranges the applications by subject of study 3 2 65 physical models a majority 65 of the studies 214 330 used physical modeling sometimes including chemistry fig 1 at least 11 consortia 6 individual investigator research grants from gomri rfps ii v and vi and nrda efforts contributed these types of products topics included circulation turbulence mixing plume dynamics particle transport deposition and physical chemistry circulation models resolved mixing dynamics based on the contributions of coupled atmosphere ocean and wave xue et al 2015 huang et al 2013 curcic et al 2016 sorourian et al 2020 and or by taking surface oil feedback to ocean atmosphere and wave into account zheng et al 2013 or by including detailed river plume dynamics and their effects on hydrocarbon transport schiller and kourafalou 2010 kourafalou and androulidakis 2013 androulidakis and kourafalou 2013 greer et al 2018 hole et al 2019 particle transport studies used lagrangian models with passive reference particles either integrated into the circulation model directly roms shchepetkin and mcwilliams 2005 fvcom zheng and weisberg 2012 or as a stand alone tool cms paris et al 2012 2013 tracmass döös et al 2013 these systems used innovative model coupling of wave models and river effects huang et al 2013 and surface oil s effects on the atmosphere ocean waves coupling bourassa et al 1999 le hénaff et al 2012 incorporated dispersant effects on oil transport reed et al 1995 french mccay et al 2005 paris et al 2012 french mccay et al 2015a 2018a b c d and potentially in situ skimming and burning lehr et al 2002 buchholz et al 2016 french mccay et al 2018c d some far field modeling studies have used measured currents as well as data produced by circulation models e g french mccay et al 2021 3 3 22 physical biological coupled models another 22 of studies 80 330 coupled physical models with biological models fig 1 the most common uses included lagrangian particle tracking of eggs and larvae by gisr deep c cimage and rfp v shay see research gulfresearchinitiative org for a complete list of gomri consortia and individual researcher awards for example the coupled ocean atmosphere wave sediment transport model coawst warner et al 2010 zambon and warner 2014 employed by the gisr and cimage consortia couple physical processes hydrodynamic atmospheric wave turbulence from roms hycom wrf and swan with larval transport models such as ltrans north et al 2008 and connectivity modeling system cms paris et al 2013 physical and chemical processes come together in oil fate models such as oil cms simap and oscar french mccay 2003 2004 paris et al 2012 lindo atichati 2016 french mccay et al 2018a b c d reed et al 1995 perlin et al 2020 vaz et al 2021 tamoc is a nearfield plume model with chemistry gros et al 2017 2020 within gomri the cimage dropps and gisr consortia engaged in this work socolofsky et al 2015 reviewed near and far field modeling with oscar with plume 3d oil cms oilmap oilmapdeep as well as particle tracking ltrans cms and droplet formation models vdrop j physical biological model coupling also helped to address research questions concerning water quality hypoxia nutrient cycling and red tides and fisheries impacts e g weisberg et al 2016a lenes et al 2013 justic and wang 2014 nrda faced a similar task of modeling oil transport fate and effects using the spill impact model application package simap french mccay et al 2015a b c 2018a to evaluate the impacts of the dwh further developing modeling methods used by french mccay 2003 2004 french mccay et al 2018a c boem nrda utilized roms hycom ngom ncom and atmospheric models narr nogaps and csfr along with simap to evaluate oil transport and fate sensitivity to circulation 3 4 5 biological models less than 5 of modeling studies 15 330 used only biological modeling fig 1 these included population dynamics niche habitat suitability models matrix population models and individual based models by carmmha ecogig deep c ladc gemm rfp v saul studies by the carmmha consortium developed age and cohort based population matrix models for bottlenose dolphins and fish species schwacke et al 2017 these were notable for integrating expert opinion powers and saul 2018 used agent based modeling to assess fish movements 3 5 5 physical biological social coupling full integration across physics biochemistry and socioeconomic domains was achieved by 5 of studies 17 330 these studies coupled an oil fate model with an ecosystem model to incorporate dispersal burial evaporation biodegradation and uptake depuration dynamics the model coupling therefore accounted for exposure and toxicity in 4d and was used to determine both lethal and sublethal impacts ainsworth et al 2018 dornberger et al 2016 berenshtein et al 2020 modeling these processes was supported by targeted laboratory experiments e g mitchelmore et al 2020 table s1 shows applications using amseas fvcom hycom oil cms or simap for circulation oil fate data while applying the ecosystem models habsim ecopath with ecosim ewe or atlantis from these metrics can be computed to measure impacts on human beings fisheries value ainsworth et al 2018 berenshtein et al 2019 food security suprenand et al 2019 toxin exposure walsh et al 2016 lenes et al 2013 environmental services rohal et al 2020 impacts on shore based industries court et al 2019 in this last example court and colleagues went an extra step using an input output model implan to interpret catch predictions from atlantis in terms of impacts on tourism and hospitality this example therefore represents the longest chain of quantitative reasoning in dwh modeling products linking ocean physics biology and socioeconomics 3 6 modeling products by consortia fig 2 shows modeling products by consortium numerical modeling was utilized most by the cimage carthe deep c and gisr consortia with dropps ecogig and various small research groups also making contributions circulation modeling was a major area of study across consortia small research groups nrda carthe deep c and gisr applied these circulation models to abiotic transport questions these studies used simulated drifters to answer near and far field transport questions in addition carthe deep c dropps gisr and small research groups applied this work in the areas of plume dynamics local mixing and biotic particle transport cimage had the most publications relating to the study of biological impacts but ecogig ladc gemm and small research groups contributed implications of oil spill response were mainly supported by the oil spill risk and response planning community outside of gomri e g buchholz et al 2016 crowley et al 2018 french mccay et al 2018d 2019 bock et al 2018 however much gomri science was ancillary to this topic gomri was responsible for improvements in understanding and model formulations for oil transport and fate fig 3 shows the number of models coupled per publication fifty eight percent of studies 192 330 used a single model the rest coupled two or more models together 3 7 advances in ocean physics and chemistry 3 7 1 near field modeling near field modeling represents the movement of oil near the wellhead socolofsky et al 2015 identified the following areas of active study in dwh near field modeling bubble and droplet generation plume modeling intrusion formation coupling to circulation models particle tracking and bubble and droplet fate modeling achievements in near field modeling of the dwh oil spill include an accurate representation of dissolved gas and dissolution of the liquid fraction gros et al 2017 2020 this controls how gas bubbles affect turbulent mixing and entrainment processes fabregat et al 2017 this incorporates the influence of oil chemistry on plume characteristics plume modeling in gomri has benefited from laboratory work in high pressure environments and better model formulations for hydrate formation and dissolution gros et al 2017 2020 3 7 2 far field modeling major circulation models employed in dwh modeling include hydrostatic primitive equations models hycom roms fvcom ncom etc or non hydrostatic large eddy simulations les fig 4 oil cms simap gnome and oscar may be better called oil fate models as they utilize circulation model results to integrate particle movement e g oil rising velocity interacting with ocean temperature and salinity paris et al 2012 and model oil breakdown e g dissolution and photooxidation vaz et al 2021 and dispersal processes see below there are many more circulation models that are used for dwh modeling models of smaller spatial domains utilizing models such as fvcom suntans or roms may be nested inside the gom or global scale circulation models most often hycom and roms to provide boundary conditions circulation models ranged in scale from individual estuaries to submesoscale and basin scale spatial domains aizinger et al 2013 cambazoglu et al 2017 cui et al 2018 taylor 2018 we believe a major advancement in far field modeling following the dwh oil spill is the development of a system of multiple scale numerical models that span the river wetland estuary shelf open ocean continuum and covers physics geomorphology biogeochemistry water quality and coastal food webs in the gulf of mexico when dealing with large spills floating oil can substantially modify wind and ocean waves which in turn modifies the movement of the spill the importance of surface fronts was also identified relating them to freshwater outflows explaining the dynamics using submesoscale physics and characterizing dispersive and anti dispersive properties oil can become thicker when impinging on a front so fronts are important areas for responders to note far field modeling in gomri has benefited from laboratory work in high pressure environments malone et al 2018 pesch et al 2018 and better model formulations for emulsification hydrate formation dissolution and sedimentation nguyen et al 2018 lindo atichati et al 2016 perlin et al 2020 vaz et al 2021 3 7 3 particle tracking and oil fate progress was made in modeling oil dispersion using lagrangian particle tracking liu et al 2011a collected a series of early modeling efforts associated with the dwh oil spill including the rapid response operational models combining satellite imagery inferred oil locations and aerosol formation with trajectory models liu et al 2011c macfadyen et al 2011 degouw et al 2011 spaulding 2017 provides a recent review of far field oil transport and fate modeling in common to these efforts the movement of oil is resolved in three dimensions and fate processes are represented such as dispersion spreading evaporation entrainment emulsification dissolution biodegradation photooxidation and sedimentation examples of these methods for modeling the dwh oil spill includes work done for nrda and boem french mccay et al 2015a 2018a b 2021 carthe uwin cm laser chen and curcic 2018 huntley et al 2011 cimage oil cms paris et al 2012 perlin et al 2020 gisr ltrans chapman et al 2014 and deep c liu et al 2011b 2014 weisberg et al 2011 2016b 2017 some of the studies employ published tracer advection algorithms such as mpdata smolarkiewicz 1984 modeling microbial degradation of oil lags behind modeling efforts in oil transport dispersion and oil chemistry socolofsky et al 2019 presents a review of simple first order degradation models gomri funded researchers have documented microbial degradation rates and microbial community succession patterns during oil degradation kostka et al 2011 rodriguez et al 2015 huettel et al 2018 time series linking in situ petroleum hydrocarbon degradation to microbial community activities allowed predicting a 30 year period for the decomposition of sediment oil agglomerates buried in gulf of mexico sandy beaches bociu et al 2019 shin et al 2019 a searchable genome database cataloguing diversity and global distribution of crude oil associated microbes was established that provides molecular identification tools and spatial distribution data for models integrating microbial community responses karthikeyan et al 2020 the csomio model dukhovskoy et al 2021 combined simulations of oil with microbial degradation and sedimentation using different computational schemes coawst genome and cstms using a two way lagrangian eulerian mapping technique also used in perlin et al 2020 this enables interaction between all of the modeling components for tracking of hydrocarbons from a source blowout to deposition in sediment microbial degradation and evaporation while being transported through the ocean photooxidation of surface dwh oil led to the formation of persistent photooxidized compounds found a decade later studies demonstrated that photooxidation modified both biodegradation rates of the surface oil and the effectiveness of aerial dispersant applications the first step before modeling biodegradation of oil in shoreline sediments is to model the photooxidative changes and track the transport of persistent photooxidized compounds vaz et al 2021 estimated and tracked the likelihood of photooxidation of lagrangian oil droplets by coupling the net shortwave radiation from nogaps to the oil cms the dose of solar radiation upon a droplet is computed with the intensity of the incoming irradiance at the ocean s surface the light attenuation coefficient and the depth of the oil droplets this new dynamic coupling provides a powerful tool to test oil weathering hypotheses refine the oil budget during the dwh and ultimately inform rapid response in future oil spills 3 7 4 subsurface oil tracking before the dwh there was no oil spill model that dynamically computed live oil gas saturated concentrations of oil droplets in the deep sea though models did take other thermodynamic processes pertaining to high pressure environments into account e g johansen 2003 yapa et al 2001 2010 zheng and yapa 2002 in dwh modeling circulation models were effectively combined with 3d lagrangian particle models e g weisberg et al 2011 turbulence waves river atmosphere models and even biodegradation and oil chemistry to form coupled model systems paris et al 2012 combined near far field models like oscar simap with oilmap deep used for the nrda spaulding et al 2015 2017b french mccay et al 2015a 2018a and oil cms offer important complements to noaa s work with more tactical response planning models like gnome these models consider oil transported at the subsurface and at the surface coupling near field and far field models vaz et al 2019 an important conclusion of these models for dwh is that bubble and droplet rise velocity should be accurately predicted accounting for in situ conditions zheng and yapa 2000 and evolving particle sizes due to various fate processes gros et al 2017 pesch et al 2020 the subsurface oil simulator sosim model echavarria gregory and englehardt 2015 jacketti et al 2020 2021 ji et al 2020 2021 offers an alternative bayesian modeling method for tracking subsurface oil including the only model written specifically for sunken bottom oil as well as a module specifically for submerged water column oil starting with the general solution of the advection dispersion equation the model accepts 4 d field concentration data collected in initial sampling campaigns as input to infer the values of model parameters sosim further accepts bathymetric data as bayesian prior information indicating coriolis forcing and settling of sunken oil it also inputs alternative fate transport model output as prior information reflecting hydrodynamic data conditions that influence the movement of submerged oil the approach complements and potentially improves on lagrangian particle tracking alone by rigorously integrating field data with prior information to provide a ground truthed forecast representing the relative probability of finding oil in time and space 3 7 5 atmosphere weather forcing there has been a realization in dwh studies that atmospheric forcing options in models cannot be treated as arbitrary a large number of circulation studies included atmospheric forcing using models like wrf coamps and coawst representation of the air sea interface atmospheric and oceanic boundary layer parameterizations and the selection of the coupling method inclusion of ocean currents sea surface temperature waves and oil slicks have a substantial impact on forecasts le henaff et al 2012 soloviev et al 2014 geng et al 2016 a novelty for the fate of surface oil is the capability to model dynamically photo oxidation of oil based on solar irradiance vaz et al 2021 a new solar irradiance module of oil cms is coupled with navgem navy global environmental model 3 7 6 droplet size distribution dsd near field modeling of the dwh brought about development of droplet size distribution dsd models that can account for the decrease of mean droplet sizes due to dispersant use in subsea dispersant injection ssdi johansen et al 2013 zeinstra helfrich et al 2015 spaulding et al 2015 2017 zhao et al 2016 2017 li et al 2017 gros et al 2017 therefore affecting transport and degradation of oil paris et al 2012 french mccay et al 2018a b c d 2019 an important advancement is the coding of lagrangian reference particles as oil droplet entities with attributes of density and size paris et al 2012 lindo atichati et al 2016 spaulding 2017 perlin et al 2020 these can interact with the ocean model temperature and salinity variables to affect rise velocity terminal velocity and plume characteristics paris et al 2012 droplet size and rise velocity are two of the most important variables to model the far field oil trajectory and dispersal paris et al 2012 zhao et al 2017 gros et al 2017 pesch et al 2018 quantification of both biodegradation and dissolution generates a change in the dsd through time lindo atichati et al 2016 oil spill models in the 1980s and 1990s often did not address the dsd for oil blowouts nissanka and yapa 2018 however numerous experimental and modeling efforts in gomri were directed at resolving oil rise and entrainment dynamics in buoyant plume models socolofsky et al 2015 zhao et al 2017 gros et al 2017 aiyer et al 2019 bracco et al 2020 models applied a fundamental log normal or rosin ramler dsd distribution law johansen et al 2013 gros et al 2017 li et al 2017 perlin et al 2020 or non fundamental distribution function vdrop j in deep sea oil spill models faillettaz et al 2021 demonstrated that the choice of probability distribution function of the dsd for far field modeling is regardless of the mean droplet size d50 consequential for oil spill response 3 7 7 multiphase droplets a breakthrough for deep sea blowout modeling is the capability to model multiphase oil droplets these have a gas and a liquid phase to model the internal degassing process that has been revealed in laboratory experiments malone et al 2018 pesch et al 2018 2019 the gas saturated oil is subjected to a pressure drop similar to the one observed at the oil platform during the dwh blowout the oil cms has a new degassing module that allows both expansion of gas nucleated within the droplet and dissolution of gas pesch et al in review tamoc also models multiphase droplets showing that gas dissolution of free gas was rapid out of the liquid droplets while at depth such that oil droplet rise may have little influence from degassing gros et al 2020 however there has not yet been validation of the percentage of free versus nucleated gas within the liquid oil phase using field data from dwh 3 8 advances in biological modeling gomri has advanced the representation of oil spills on both low and high trophic level communities coupling oil fate and circulation models to ecosystem models has allowed a highly resolved representation of population level effects in space and time this is a necessary feature in estimating impacts on exploited species which are often mobile and spatially partitioned by life stage this allows us to represent different exposure risks in different types of habitat these methodologies can be readily extended to other geospatial pulse disturbance problems like toxic algae blooms and hypoxia ecosystem models have benefited from the 4d representation of oil concentrations at the short spatial and temporal scales native to circulation models e g simap ecospace suprenand et al 2019 french mccay et al 2015b c 2018a c d cms atlantis ainsworth et al 2018 uptake depuration dynamics and dose response relationships can quantify the effects of oil french mcay 2002 2003 2004 the mode of oil uptake by organisms can be represented in biological models to represent transdermal absorption or ingestion ainsworth et al 2018 dornberger et al 2016 methods developed to study dwh were subsequently applied to hypothetical oil spills berenshtein et al 2019 paris et al 2020 suprenand et al 2019 the ixtoc oil spill the exxon valdez oil spill t okey pers comm and oil pollution in the niger delta ndimele e pers comm a lot of the discoveries in gomri centered around developing a better understanding of physical and biological community connectivity many sampling laboratory and modeling efforts were devoted to it investigating pelagic diet linkages especially has become relevant to recent observations about population connectivity paris et al 2020 milligan et al 2018 coupled hycom cosine modeling allowed derada 2019 to explore vertical connectivity of pelagic habitat within the planktonic microbial community coles et al 2017 similarly represented microbial communities implicitly using coupled circulation and genomics models genome coles et al 2017 woodstock et al 2020 coupled a biochemical model roms npzd to osmose an individual based ecosystem model of the upper food web fvcom habsim uses an integrated biological model within a circulation model weisberg et al 2016a zheng and weisberg 2012 lenes et al 2013 walsh et al 2016 again stimulated trophic connectivity in pelagic food webs to demonstrate that fisheries and oil spills can have cumulative effects this has direct consequences for human health weisberg et al 2016a the theme of connectivity in pelagic food webs was also applied to the study of higher trophic levels ainsworth et al 2018 showed how food web impacts near the wellhead were translated to distant areas through impacts on mobile forage fish populations ongoing efforts will determine whether linkages between epi and mesopelagic communities influence vulnerability to subsurface plumes ruzicka et al unpublished manuscript have collaborated with the deepend consortium to develop a set of oceanic food web models gomex ecotran aimed at quantifying trophic connectivity between epi meso and bathypelagic depth zones via particle sinking and diel vertical migration behavior ongoing simulations with gomex ecotran aim to estimate how perturbations to vertical exchange processes and changes to food web structure within each depth zone propagate throughout the entire water column woodstock et al 2021 confirmed that large pelagic fish were highly dependent on mesopelagic forage and therefore potentially vulnerable to deep sea pollution a consistent problem with upper food web simulation studies is that fully probabilistic simulations are difficult due to run time limitations in highly resolved spatial food web models e g suprenand et al 2019 ainsworth et al 2018 morzaria luna et al 2018 made a major advance in the state of the art by using cloud computing and a statistical emulator to predict atlantis responses other studies appealed to semi quantitative expert opinion based approaches to narrow the parameter space suprenand et al 2019 schwacke et al 2017 other biological models like the matrix models of ackleh et al 2019 can be evaluated using a formal sensitivity analysis 3 9 advances in socioeconomics modeling few quantitative models of the socioeconomics of oil spills are available one early attempt was made outside of gomri to assess potential fishery damages through a simple value chain model sumaila et al 2012 court et al 2017 utilized the travel cost method and input output analysis model using to evaluate the economic impacts of cancelled recreational trips to northwest florida after the dwh spill an input output i o model was provided outputs from the atlantis ecosystem model with oil cms inputs to evaluate shifts in commercial and recreational fishing activities due to fishery closures resulting from the dwh spill court et al 2019 this included projections for non consumptive industries like tourism and hospitality another example used oil cms to simulate fisheries and socio economic impacts arising from fishery closures berenshtein et al 2019 2020 in a similar fashion simap integrates the ocean environment and ecosystem domains and provides estimates of ecosystem valuation by providing input to another model the offshore environmental cost model oecm boem 2016 finally one of the gomri rfp v projects developed a bioeconomic spatially explicit agent based model of fisher decision making behavior and demersal fish population dynamics saul et al 2020 the model is being used to understand how coupled fisher fish behaviors interact with hypotheses about oil related toxicological fish mortality and the spatial fishing closures used to protect seafood safety the model represents the important institutional components of the system such as the individual fishing quota system as well as state conditions such as fish and fuel prices weather conditions and others part of the difficulty in the integration of socioeconomic models with models within the ecosystem domain is due to the differences in measures and scales for example the valuation of fisheries is dependent upon the fish species among fish species there is a valuation for commercial versus recreational fishing therefore the ecosystem information requires considerable disaggregation to get at measures that would be useful for socioeconomic models socio economic models are also dependent upon decision making relevant scales yoskowitz et al 2017 cash et al 2006 detail these scales to include jurisdictional institutional management networks and knowledge at the regional to local levels all of which would influence the linkages needed to ocean environment and ecosystem models the requirement for time stepping is also difficult for socio economic models as they typically rely on fixed price relationships which are only appropriate for static modeling court et al 2019 3 10 advances in human health modeling human health during environmental disasters is impacted by physical exposures to contaminants and to the emotional stress which has significant impacts on mental health mental health may also impact physical health but these connections although recognized have not yet been quantified modeling of physical health can be facilitated through risk assessment approaches nrc 2009 epa 2010 which is a process used to estimate the probability of harm model setup begins by identifying the hazard i e chemical concentration at point of human exposure followed by computing exposure through multiple routes dermal ingestion inhalation and ultimately computing the probability distribution of health risk ott et al 2007 impacts to physical health are highly dependent upon the specific chemicals in oil thus coupling ocean environment models to estimate physical human health impacts requires disaggregating the oil into individual chemical compounds crowley et al 2018 provide an example determining air exposure risks for individual volatile organic compounds one approach has been developed through beaches beach exposure and child health study for estimating physical health impacts to children who play at oil impacted beaches ferguson et al 2020 montas et al 2020 integration of the beaches risk assessment approach would require disaggregation of oil into constituent chemical species to represent oil interactions in water air and sediments in beach environments in the context of mental health conceptual and semi quantitative models have been established to evaluate cause disaster direct and secondary effects and effect resilience and recovery within a community as measured by economic stability housing stability physical well being mental well being and social role adaptation abramson et al 2010 2015 new models of human systems are needed to represent some processes thought to be important for example economic models typically omit a number of social or human capital dimensions with important implications for the long term evolution of communities including concepts like resilience that are of clear interest to gulf stakeholders in an economic input output framework such as implan 2020 education and health care activities do not explicitly produce health happiness or productivity as outputs therefore a complementary model of off market phenomena in coastal communities would be a desirable reusable component for future integration of spill impacts on human systems sandifer et al 2017 describe a conceptual framework for a disaster pressure state ecosystem service response health dpserh model the framework emphasizes the importance of capturing broad feedbacks for valuing oil spill impacts and guiding response efforts since the model is conceptual it is underspecified relative to a simulatable implementation of the same scope however it is a useful road map for integration that highlights multiple features that are missing from the current model portfolio subsets of the concept may perhaps be implemented via federation of existing model components by constructing the model de novo one would have the advantage of choosing a practical level of detail for each concept a complementary top down modeling approach that explores physical biological social feedbacks in an aggregate strategic way is explored in the accompanying 7b synthesis products by the authors 3 11 marriage of experiment and modeling gomri can point to many successful examples of where experiment and observations supported modeling physical simulation models benefited from drifter experiments in the 2012 grand lagrangian deployment glad and the 2016 lagrangian submesocale experiment laser projects these were organized by the carthe consortium poje et al 2014 with the purpose of investigating particle dispersion and submesoscale features glad released drifters near the dwh site and louisiana coast laser took place in the de soto canyon region laser deployed even more tracers than the previous glad and used ship based and aerial observations to accompany laser which focused primarily on offshore processes the submesoscale processes and lagrangian analysis on the shelf splash took place in 2017 focusing on nearshore submesoscale dynamics http carthe org another drifter experiment the gulf integrated spill response gisr tracer experiment was conducted in 2012by the gisr consortium ledwell et al 2016 drifters and a chemical tracer were released in the northern gom subsequent cruises monitored the dispersal of the tracer these programs aim to understand the role of large ocean flows in dispersing oil and resolve problems that some transport models have in representing small scale convergence zones haza et al 2018 tracer data were compared with hydrodynamic outputs using sabgom he 2016 and roms hycom bracco et al 2018 khade et al 2017 drifters were similarly used to validate hydrodynamic models beron vera and lacasce 2016 gomri supported hydrodynamic models benefiting from these field observations greatly improved current predictions used for dwh oil transport and fate modeling north et al 2015 french mccay et al 2018a c 2021 there are also experimental data to support near field modeling for example wang et al 2016 took advantage of a field program to characterize turbulent diffusivity in the northern gom this helps control mixing of oil gas pollutants in plume modeling droplet size distribution experiments also informed plume modeling johansen et al 2013 li et al 2017 experimental and field data evaluated by ward et al 2018a b combined with dwh oil fate modeling demonstrated the importance of photo oxidation as a fate pathway previously under estimated in a similar way biological modeling was supported by field and laboratory research field studies were designed concurrently with modeling efforts and with attention to addressing knowledge gaps in modeling physiological experiments in cimage determined the rate of clearance of pahs in fishes snyder et al 2015 and this was used in the calculation of lethal and sub lethal effects in fish populations dornberger et al 2016 high pressure experiments helped set biodegradation rates for oil fate simulations and pressure induced degassing using oil cms lindo atichati et al 2016 pesch et al in review rov observations of reef fish communities helped calibrate toxicological impacts in ecosystem simulations ainsworth et al 2018 plankton and fish sampling including that supported by nrda and gomri informed vertical and horizontal biological distribution models used for nrda injury modeling french mccay et al 2015b c and connectivity modeling for benthic species paris et al 2020 sediment chemistry measurements montagna et al 2013 valentine et al 2014 stout and german 2018 passow and stout 2020 helped modelers better understand and model impacts on the demersal food web due to marine oil snow sedimentation and flocculent accumulation mossfa quigg et al 2016 burd et al 2020 that collaborative effort helped show the mechanism of mossfa enrichment of the detritus based food web 4 discussion 4 1 gomri modeling legacy the volume and quality of modeling work in gomri belies the substantial technical and logistical challenges in achieving model integration across disciplines and systems gomri provided a consistent focus on a large but well defined research problem that held an urgent connection to human health and well being in that context the remarkable pace and innovation is easy to understand and also the value of synthesis modeling the notable achievements in synthesis modeling rested on close collaborations between data providers and modelers and between scientists in different disciplines an estimated 1260 total publications resulted from gomri griidc 2020 the list of 330 modeling applications identified here represents a sizable part of the total scholarly output dwh modeling may have benefited from an economy of scale as researchers shared many common resources by 2021 gomri modeling rests on a mature collection of data well established protocols for data archiving and exchange from griidc and a still expanding library of methods and applications in the public domain the well attended annual gomoses conference offered reliable opportunities for synergies within and outside of gomri other shared resources were managed by gomri administration these included assistance in publication education and outreach networking and coordination the gomri research board provided oversight and coordination responding to new discoveries for example by establishing the marine oil snow sedimentation and flocculent accumulation mossfa working group that cross consortia group coordinated research efforts associated with oiled marine snow the mossfa working group influenced modeling and led to discoveries about benthic food webs dornberger 2018 for modeling long time series are important and the continuity of research funding that gomri offered over the last 10 years supported that need the consistency was more valuable since the pre spill reference data were so insufficient joye 2015 seven consortia were funded by two or more sequential awards dropps cwc cimage carthe ecogig recover addomex the long term interests of gomri offered a rare chance for iterative observations where modeling helped to direct field observations weisberg et al 2015 cooperation outside of gomri was strengthened with the conclusion of the lengthy injury assessment and nrda claim settlement dwh trustees 2016 at that time all nrda data and assessment information became publicly available resolution of the damage assessment phase also enabled increased cooperation between nrda and non nrda researchers many researchers supported by gomri as well as the oil spill response community utilized these vast data sets made publicly available by the nrda as well as data collected under gomri funding the publications of gomri sponsored research and improved hydrodynamic modeling developed under gomri funding greatly improved the accuracy of oil transport and fate modeling by academia over those performed for the nrda by oil consultants french mccay et al 2018a c 2021 this and other research will continue to make use of the valuable data sets collected from the gulf of mexico and coastal areas 4 2 a foundation in ocean physics there were a variety of hydrodynamic and particle tracking systems each offering individual strengths by which we could examine the oil spill from different perspectives the high inshore resolution of fvcom up to 150 m in estuaries and inlets was suitable to model local factors associated with algal bloom dynamics weisberg et al 2016a which is an important link to human health implications due to the potential for aerosolization of toxins zhong and bracco 2013 showed the value of having different spatiotemporal resolutions available for understanding loop current dynamics chapman et al 2014 similarly demonstrated the value of having a range of resolutions available they nested a gulf scale model roms sabcom with a shelf model roms and a bay model suntans to represent seamless movement of oil into estuaries significant developments in far field circulation modeling owe partly to development in both near field plume and turbulence modeling outputs from nearfield models are important to far field models such as buoyant plume trapping and intrusion dynamics particle slip velocity hydrocarbon pseudo components and droplet size distributions thus the physics of oil dispersal and oil fate required close coupling between near field plume dynamics and circulation models with wave river and atmospheric models contributing there were many such examples of modeling coupling and even hybrid approaches which modeled near and far field dynamics in an integrated system e g chen et al 2018 paris et al 2012 vaz et al 2019 lagrangian particle tracking was used with both near and far field models and reference particles represented the transport of the bulk oil and its concentration oil fate models were further linked to biodegradation photooxidation and biological dispersal routines new laboratory experiments in high pressure physics oil chemistry and biology supported this effort emulsification hydrate formation dissolution sedimentation and biodegradation were examined lagrangian tracking partitioned the oil into different chemical species based on a particle size distribution model where each particle size can have unique physical and chemical properties multi fraction particle models allowed modeling dissolution lindo atichati et al 2016 perlin et al 2020 this allowed better study of subsurface dispersant injection as we could contrast the behaviour of oil with and without the presence of dispersants berenshtein et al 2019 french mccay et al 2017 2018d paris et al 2012 this was a prescient matter for the dwh response as both surface and subsea dispersant injection were used data assimilation tools including ncoda and soda were used often going forward heuristic lagrangian models such as sosim and oil cms may become important tools for locating and forecasting the position of oil based on real time data for emergency response decisions damage assessment and study thus we had a well articulated 4d picture of oil transport and fate this provided a strong foundation on which to build biological community and socioeconomic modeling 4 3 biological connections as many as eight consortia and four individual awards contributed to biological modeling one popular area of study involved the use of biotic transport models to study the movement of larvae zooplankton bacteria and ichthyoplankton many of the low trophic level and plankton models used lagrangian methods but there were also examples of plankton community interaction models desai et al 2019 lenes et al 2013 there were many more examples of community models operating at high trophic levels using atlantis ecopath with ecosim ecotran matrix models or other approaches population connectivity was a common theme in biological studies paris et al 2020 food web connectivity was examined by several authors using food web models the connection between epi and mesopelagic food webs is likely to remain a long term research interest in the gom the large biomass and energy demands that the vertically migrating mesopelagic community places on epipelagic production suggests that events impacting either the epipelagic or the deep pelagic communities can propagate widely throughout the entire water column there was a strong case made through the combined observations of deepend and cimage that deep water oil spills like dwh pose a threat to mesopelagic communities that threat is potentially affected by the use of dispersants which has implications for food web dynamics morzaria luna et al in review connections between demersal and pelagic food webs remains an important open question which was considered by gomri in detail these connections were assessed using far field modeling johnston and bernard 2017 genetic approaches bracco et al 2019 field observations murawski et al 2018 and modeling dornberger et al 2016 gomri sponsored models that explicitly include diel vertical movement processes and trophic connectivity between the epipelagic and deep pelagic such as atlantis and gomex ecotran are being applied to simulate how pulse disturbances i e modeled by mortality recruitment or growth forcing functions at different depth zones propagate throughout the water column and ecosystem horizontal connectivity through food web effects and animal movement were demonstrated to be important factors in damage assessment in both the dwh and ixtoc oil spills ainsworth et al 2018 4 4 human systems efforts to understand socioeconomic impacts stand out as the most integrative projects in gomri and dwh studies potentially spanning physical natural and human systems socioeconomic impacts were often based on fisheries impacts but also considered were shore based industries recreation and ecosystem services there were not many researchers working on these problems compared with other physical chemical and biological modeling interests human health and socioeconomics modeling other than fisheries impacts consisted of less quantitative modeling methods with a few exceptions walsh et al 2016 used lower trophic level community modeling to estimate impacts of fishing and oil spills on asthma triggers and red tides walsh et al 2016 other authors calculated impacts on ecosystem services including carbon sequestration and food security rohal et al 2020 suprenand et al 2019 due to the paucity of models in the human health and socioeconomic domains there appear to be many opportunities for connecting ocean ecosystem models to enhanced human system models at least two approaches may be fruitful 1 coupling existing ocean ecosystem models to existing economic models this would likely resemble extensions of the existing 5 of models that already integrate physical biological and socioeconomic knowledge domains table s1 col f these models may allow valuation of ecosystem components and respond to bottom up environmental drivers 2 creation of new health and socioeconomic models that address important feedbacks particularly between mental and physical health and socioeconomic activity and between perceptions of risk and welfare that shape behavior and disaster response results from coupled oil spill models that integrate socioeconomics and human health could be used to assess potential risks and societal level impacts of decisions made during and after clean up efforts model based assessments could provide additional critical information to decision makers about the long term impacts of their decisions 4 5 new modeling tools in stachowiak s general theory of models the motivation of the modeler or client influences model design as much as any other factor when we consider the diversity of stakeholders and the diversity of economic social and cultural interests affected by the oil spill a wide range of modeling capabilities indeed must be needed to capture all the processes of interest gomri modeling has greatly expanded our state of knowledge and put much more of the ecosystem under experimental control this is reflected in the diverse list of applications stakeholder interests are interconnected and synthesis modeling can show us where interests align and where trade offs between competing interests exist these tradeoffs are inevitably connected with oil response decisions for example the use of dispersants influences the relative exposure of surface inshore deepwater pelagic and benthic habitats the use of dispersants therefore affects which resources and stakeholders are likely to be impacted most by the oil paris et al 2012 2018 french mccay et al 2018d bock et al 2018 there is also a trade off in the dispersal of the oil that can be examined with oil fate and effects models with possible links through natural and human systems the applications identified here address needs of emergency personnel managers scientists and many other stakeholders thus gomri s mandate to improve society s ability to respond to oil pollution was well supported by modeling the model applications explore impacts on different systems and at different temporal and spatial scales short and medium term modeling studies focused on plume dynamics fate of oil and aftermath for coastal industries and seafood safety while long term modeling focused on ecosystem state changes and recovery planning hydrostatic primitive equations models like hycom and roms and non hydrostatic les models were the most commonly employed tools together they contributed about one third of the publications nevertheless there was a great diversity of approaches employed in the 330 modeling applications and in the 74 unique models explored here taken together as a suite models developed for the study of dwh form a continuum of processes that can be linked end to end conceptually and often numerically at one end weather and ocean forecasting models are process based and use basic physical principles like newton s laws they have relatively little need for empirical parameterization at the other end socioeconomic and human health modeling is often based on empiricism biological models occupy the middle ground in more than one sense they play an important role in synthesis modeling because the interests of human beings are often affected through impacts on the health of marine populations although gomri has sunsetted operations what will remain are the new tools and a cadre of modeling expertise that remains relevant to addressing new environmental challenges spills of national significance such as the dwh oil spill do not occur very often and the daily responsibilities of regional scientists and managers need to focus on immediate issues during and after an accident like this one public efforts and energy understandably need to be directed toward health and safety environmental clean up and quantifying the extent of the damage for settlement purposes for this reason gomri played an important academic role improving our understanding of the nature and risks of oil spills particularly deep oil spills and the vulnerabilities of natural and human systems in the gom this is important information if we wish to fully consider risks in the calculation of costs and benefits of oil exploration in the gom we recommend that scientists and managers leverage the wealth of models and data amassed by gomri nrda and others to support holistic evaluation of the benefits and risks associated with oil exploration declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests cameron ainsworth reports financial support was provided by gulf of mexico research initiative gomri acknowledgements we acknowledge contributions from participants of the gomri core 7b activities and we acknowledge support from gomri for the writing of this manuscript the following people lent their expertise to the research jim ledwell whoi ping chang tamu ryan takeshita and lori schwake nmmf provided valuable input on the carmmha model appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105070 
