index,text
5290,spring discharges from karst aquifers are results of spatially and temporally complex hydrologic processes such as precipitation surface runoff infiltration groundwater flow as well as anthropogenic factors these processes are spatially and temporally varying at a multiplicity of scales with nonlinear and nonstationary characteristics for improving the prediction accuracy of karst springs discharge this study first applied the time frequency analysis methods including singular spectrum analysis ssa and ensemble empirical mode decomposition eemd to extract frequency and trend feature of niangziguan springs discharge then the long short term memory lstm was used to simulate each frequency and trend subsequence subsequently the prediction of spring discharge was completed by a combination of the simulated results from lstm finally the performances of lstm ssa lstm and eemd lstm under different inputs were compared the results show that the performance of ssa lstm and eemd lstm are better than lstm and the eemd lstm model achieved the best prediction performance keywords karst spring discharge nonlinear and nonstationary time series singular spectrum analysis ssa ensemble empirical mode decomposition eemd long short term memory lstm deep learning 1 introduction spring discharges from karst aquifers are results of spatially and temporally complex hydrologic processes such as precipitation surface runoff infiltration groundwater flow as well as anthropogenic factors ozyurt and bayari 2008 telesca et al 2013 karst aquifers are highly heterogeneous and contain conduits fractures and pores where may exhibit hierarchical permeability structures or flow paths the hierarchical groundwater flow paths make karst spring discharge fluctuate with multi frequency for example the aquifers of niangziguan springs china exhibit groundwater quick flow belts in the karst conduits and fractures developed areas groundwater convergence zones where fissures occur in networks and groundwater stagnant regions where dominate by pores an et al 2019 the hierarchical flow fields endow the spring discharge with behaviors of multi frequency on the other hand human activities cause karst spring discharge declining for instance previous studies showed that the anthropogenic effects had surpassed the effects of climate change and became the major factor of impacting karst hydrological processes in the niangziguan springs catchment hao et al 2009 2016 consequently karst springs discharge is characterized by a strong nonlinear trend and nonstationary fluctuations due to the complexity caused by random precipitation extreme heterogeneity of karst aquifers and anthropogenic impacts deciphering the spring discharge records using a physical model is a formidable task for understanding contributions from each component and or predicting spring discharge milly et al 2008 duran et al 2020 to resolve this difficulty the deep learning model may offer an alternative approach recently artificial neural networks anns have been employed to analyze the hydrological processes for example anns were employed to streamflow forecasting to deal with the nonlinear problems zhang et al 2015 many researchers have applied anns to modeling and forecasting nonstationary hydrological processes e g sivakumar et al 2002 hu et al 2008 ghumman et al 2011 cui 2013 similar to black box anns models do not require detailed information on the physics of the hydrologic processes el shafie et al 2007 guo et al 2011 he et al 2014 on the other side the drawback of anns is that the sequential order information of input data is lost kratzert et al 2018 to overcome the shortcomings of anns a deep neural network structure i e recurrent neural networks focusing on processing time sequences data was developed to selectively pass information across sequence steps lipton et al 2015 the feedback connectionist models of the recurrent neural networks are convenient to update the residual value and weight value in the previous step which is suitable for time sequences prediction long short term memory lstm neural networks are a special type of recurrent neural networks that were proposed by hochreiter and schmidhuber 1997 the lstm overcomes the problem of the traditional recurrent neural networks of learning long term dependencies and has been widely used in computer science fields such as speech recognition graves et al 2013 han et al 2017 image processing song et al 2016 rajeev et al 2019 and natural language processing sundermeyer et al 2012 wang et al 2019 in recent years hydrologists have applied lstm to hydrological time series for instance kratzert et al 2018 employed lstm for modeling rainfall runoff their results demonstrated that the lstm produced better model performance than recurrent neural networks due to learn and store long term dependencies abilities hu et al 2018 compared the performance of lstm and ann models for flood prediction their study confirmed that the special units of forget gate make lstm a better predictor than the traditional ann model zhang et al 2018 also conducted a comparative study for predicting the water levels of a combined sewer overflow structure in drammen norway using different neural network models i e multilayer perceptron wavelet neural networks and lstm they showed that lstm has superior prediction capabilities for multi step ahead time series to other models although the lstm can satisfactorily predict most of the hydrological time series it fails to obtain satisfactory predictions for strong nonlinear time series liu et al 2019 for improving the accuracy of lstm in the simulation of a strong nonlinear sequence we intend to decompose the sequence using singular spectrum analysis ssa and ensemble empirical mode decomposition eemd subsequently we simulate each of the subsequences using lstm and combined the simulations hopefully the combined methods of ssa lstm and eemd lstm can improve accuracy significantly ssa is a data adaptive technique proposed by colebrook 1978 to extract information from short and noisy time series ssa can separate original time series into independent components such as trend oscillation components and noise and thus it provides insight into the unknown dynamics of the time series the ssa technique has been used in geophysical time series for example vautard and ghil 1989 used ssa to measure noise and the oscillation dynamic of the paleoclimatic time series marques et al 2006 applied ssa to forecast hydrological time series such as precipitation runoff and water temperature time series while luo et al 2015 extracted seasonal signals of these time series by ssa further ssa has been used in other fields such as mathematical statistics moskvina and zhigljavsky 2003 biomedicine you and xu 2003 hassani et al 2017 and image processing zhen et al 2006 rodriguez aragon and zhigljavsky 2010 empirical mode decomposition emd is a data adaptive time frequency analysis method for nonlinear and nonstationary time series proposed by huang et al 1998 time series decomposition is performed at scales without setting any basis functions wu and huang 2009 proposed an improved empirical mode decomposition algorithm called eemd which improved the mode mixing problem of emd in recent years eemd has been applied to analyze hydrological time series sun and ma 2015 hu et al 2017 roushangar and alizadeh 2018 and climate change hawinkel et al 2015 xiao et al 2019 gao and shi 2016 boodhoo et al 2016 kim et al 2018 for acquiring better simulation of nonlinear and nonstationary spring discharge this paper uses time frequency analysis methods i e ssa and eemd to decompose the spring discharge series into multiple subsequences with different frequencies then employs the lstm method to simulate each subsequence and predicts spring discharge by the combination of the simulated results subsequently the predictions are then compared with the lstm models the approaches were applied to the niangziguan springs catchment of china 2 study area and data the niangziguan springs complex is located in the mianhe river valley eastern shanxi province china which receives water from a 7394 km2 basin it is the largest karst springs in northern china fig 1 the major geologic strata in the niangziguan springs catchment from top to bottom are quaternary loss deposits sandstone permian arenaceous shale carboniferous mudstone sandstone and limestone with coal seams ordovician carbonate rocks and cambrian dolomite fig 2 the groundwater in karst aquifers i e ordovician carbonate rocks flows toward the mian river valley in the east where groundwater perches on low permeable strata of cambrian dolomicrite and eventually intersects the ground surface thus creating the niangziguan springs han et al 1993 liang et al 2008 niangziguan springs are distributed along the mianhe river bank which stretches approximately 7 km the river discharge has been monitored at the upper and down streams of the river subtracting the upstream river discharge from the downstream river discharge yields the spring discharge the calculated monthly niangziguan springs discharge records from january 1959 to december 2015 are displayed in fig 3 a it shows that in decadal time scales the spring discharge seems to be declining linearly in inter and intra annual time scales the spring discharge however showed apparent fluctuations with decreasing trend because of climate change and human activities i e groundwater overexploitation and dewatering from coal mining in the catchment that is the spring discharge has distinct nonstationary and nonlinear characteristics monthly precipitation time series are acquired from january 1959 to december 2015 from seven rainfall stations in the niangziguan basin yuxian county shouyang county yangquan city pingding county xiyang county heshun county and zuoquan county and the mean precipitation was calculated by theisen polygons fig 3b 3 method a schematic flowchart for ssa lstm and eemd lstm is listed in fig 4 3 1 singular spectrum analysis ssa ssa constructs a trajectory matrix based on the observed time series and decomposes and reconstructs the trajectory matrix for ssa this method is the procedure that takes a univariate time record and makes it a multivariate set of observations elsner and tsonis 1997 the main steps of ssa are briefly presented as follows stea et al 2008 basic ssa is performed in four steps the first step is called the embedding step 3 1 1 embedding at this step one first selects an appropriate window length m and 1 m n 3 where n is the total number of data of the time series then one transfers the observed time series x x 1 x 2 x n into k lagged vectors x 1 x 2 x k each vector has a length of m x i x i x i 1 x i m 1 t where i 1 k and k n m 1 the k lagged vectors i e x x 1 x 2 x k then forms a trajectory matrix x 1 x x 1 x 2 x 3 x k x 2 x 3 x 4 x k 1 x 3 x 4 x 5 x k 2 x m x m 1 x m 2 x n the trajectory matrix x is a m k hankel matrix with equal elements along the back diagonals that is the elements in x are identical when the sums of the row and column indexes are equal to a constant 3 1 2 singular value decomposition svd in this step using the trajectory matrix x we formulate the m m square matrix c xx t then we find the non zero eigenvalues of matrix c λ 1 λ 2 λ l in decreasing order l m and l is the total number of the non zero eigenvalues and the corresponding eigenvectors of these eigenvalues u 1 u 2 u l afterward the trajectory matrix x can be written as golub and reinsch 1971 2 x u 1 u l λ 1 0 0 0 0 λ 2 0 0 0 0 0 0 0 0 λ l v 1 t v l t in eq 2 λ i is the ith singular value of the matrix x the set λ i i 1 2 l is the x s singular spectrum the ui and vi are the left and right eigenvectors of the matrix x respectively note that u 1 u l are the orthogonal vectors with length 1 i e u i t u j 1 i j 0 i j similarly vi s are also orthogonal vectors with v i t v j 1 i j 0 i j from the above relationship it can be deduced that v i x t u i λ i i 1 l and x i λ i u i v i t as a result the trajectory matrix x can be written as a sum of bi orthogonal elementary matrices 3 x x 1 x 2 x l 3 1 3 grouping divide the set of the subscript i of elementary matrix x i i e 1 2 l into p disjoint subsets i 1 i 2 ip correspondingly the elementary matrix x i is split into p groups let i t i 1 i 2 i r t t 1 2 p the resultant matrix x i t is defined as x i t x i 1 x i 2 x i r t calculate resultant matrices of x i 1 x i 2 x i p respectively and substituting in eq 3 obtains the new expansion hassani 2007 4 x x i 1 x i 2 x i p the choice of the sets i 1 i 2 ip is called the eigentriple grouping 3 1 4 diagonal averaging next diagonal averaging transforms each matrix x i t in eq 4 into a new time series of length n that is consider y be a matrix of m k which elements are y ab 1 a m 1 b k if m k y ab y ab otherwise y ab y ba make m min m k k max m k the diagonal averaging procedure converts the matrix y to a series y 1 y 2 y n by the following formula 5 y k 1 k p 1 k y p k p 1 1 k m 1 m p 1 m y p k p 1 m k k 1 n k 1 p k k 1 n k 1 y p k p 1 k k n eq 5 generates an n length reconstructed signal time series rc t the original series x is decomposed into the sum of p components 6 x rc 1 rc 2 rc p its percentage of the total eigenvalues determines the contribution of component rc t i s i t λ i s i 1 l λ i s 1 2 r t based on the contribution of rc t one can select m effective components then a filtered series is the sum of m components 7 x rc 1 rc 2 rc m the remaining components i e rc m 1 rc m 2 rc p are considered as noises the window length m and the number of reconstructed components m are the two vital parameters in ssa the general rule for the window length is that the length should not be longer than n 3 vautard et al 1992 3 2 ensemble empirical mode decomposition eemd empirical mode decomposition emd is a data adaptive signal preprocessing technique for nonlinear and nonstationary time series it decomposes signals into intrinsic mode functions imfs from high to low frequency through a sifting process which represent a physically meaningful description of the time frequency energy of a time series huang et al 1998 hawinkel et al 2015 the emd must meet the following two rules 1 all the number of extrema and the number of zero crossings must be the same or different at most by one 2 all upper and lower envelopes must be locally symmetrical along with the time axis i e the mean value of the upper and lower envelopes is zero or close to zero these two conditions ensure that the instantaneous frequency obtained by imfs is meaningful the sifting process of emd is as follows huang et al 1998 park et al 2018 1 identify all local extrema of x t 2 a cubic spline interpolation method connects all local minimum value and maximum value forming the lower envelope e min and upper envelope e max respectively 3 calculate the mean of the envelopes by m e min e max 2 4 obtain the detail h t x t m t 5 check the details of h t if h t is an imfs then repeat above steps with residual r t x t h t replacing x t otherwise h t instead of x t to continue above steps 6 repeat the above steps until a stop criterion is satisfied the stop criterion is defined by two consecutive sifting results 8 s d k t 0 t h k 1 t h k t 2 h k 1 2 t where k represents the number of sifting processes when sdk is between 0 2 and 0 3 imfs retain enough physical sense huang et al 1998 however one major problem of emd is the mode mixing i e the decomposed imfs contains multi frequencies peel et al 2011 yu et al 2018 eemd is a noise assisted data adaptive analysis that overcomes the mode fixing of emd the specific steps of eemd decomposition are as follows 1 add gaussian white noise to the original signal 2 decompose the data series into imfs through the sifting process of emd 3 repeat above steps for n times with different white noise series 4 average the summation of corresponding decomposed imf for n times then an ensemble set of imfs can be obtained 9 c j 1 n i 1 n c j i where cj denotes the jth imf component it should be noted that the effect of the added white noise should decrease according to the well established statistical rule 10 ɛ n ɛ n where n is the size of ensemble numbers ɛ is the amplitude of the added noise ɛn represents the standard deviation of the error which means the difference between the original signal and the corresponding imf s in this study the standard deviation of the added white noise is 0 4 and the ensemble number size is 1000 3 3 long short term memory lstm neural networks recurrent neural networks process nonlinear time varying series and predict the future value of the time series based on the historical data extraction rules of the time series lipton et al 2015 however recurrent neural networks are prone to gradient explosion and gradient vanishes when backpropagation errors across many time steps because of this the gradient of training cannot be transmitted in long sequences sahoo et al 2019 in order to solve these problems a special recurrent neural networks model lstm neural networks was proposed by hochreiter and schmidhuber 1997 lstm is suitable for processing and predicting events with relatively long intervals and delays in time series gers et al 1999 fig 5 a is a typical structure of recurrent neural networks which consists of an input layer a hidden layer and an output layer to explain how the networks works we unfold the recurrence unit of the network as shown in fig 5b fig 5c is the internal operation of lstm as is seen from fig 5b at time t neuron unit s receives input from the current data point it and from hidden node st 1 in the network s previous state each network layer shares parameters wi wh wo across time steps recurrent neural networks can be regarded as multiple copies of the same network in simple recurrent neural networks the computation equations at each time step as follows 11 st f wiit whst 1 bh 12 ot g wost by where f and g is the activation function wi is the weights matrix between the input and the hidden layer wh is the matrix of recurrent weights between the hidden layer and itself at adjacent time steps and wo is the weights matrix between the output and the hidden layer the vectors bh and by are bias parameters recurrent neural networks have the form of a chain of repeating modules of neural networks in traditional recurrent neural networks the repeating module has only one state st and it executes the tanh hyperbolic tangent transform while the repeating module of lstm adds an additional cell state ct to stored long term information and three gates forget gate input gate output gate control the cell state fig 5c there are four steps of the lstm 1 forget gate forget gate decides what information is going to be thrown away from the previous cell state ct 1 13 ft σ wf st 1 it bf where σ is the logistic sigmoid function wf bf represents the weight matric and bias vector of the forget gate respectively 2 input gate input gates decide what new information to be updated and stored in the cell state the function i t is as follows 14 i t σ w i s t 1 i t b i where w i b i represents the weight matric and bias vector of the input gate respectively c t is an update vector for the cell state 15 c t t a n h w c s t 1 i t b c where tanh is the hyperbolic tangent wc bc represents the weight matric and bias vector of tanh layer respectively 3 memory update the new cell state is obtained by old memory via the forget gate and new memory via the input gate the cell state is updated from ct 1 to ct by the following equation 16 c t f t c t 1 i t c t 4 output gate output gate decides what information is going to output which is calculated by the following equation 17 ot σ wo st 1 it bo where wo and bo represent the weight matric and bias vector of the output gate respectively the final output of the new hidden layer st of lstm is determined by the output gate and the cell state 18 st tanh ct ot in lstm cell state ct is the key variable the ct executes only simple linear interactions with previous cell state which can store information unchanged over a long period of time during training the weight changes slowly which helps to prevent the problem of the exploding or vanishing gradients in the backpropagation step 3 4 model performance evaluation indicators for training the model we chose loss function i e the mean squared error of the training dataset as a criterion to calibrate the model and the optimal values of the mean squared error were obtained by adam algorithm automatically updating the model parameters to evaluate the prediction performances of the above models i e lstm ssa lstm and eemd lstm models we used the root mean square error rmse the mean absolute error mae the mean absolute percentage error mape and the nash sutcliffe efficiency coefficient nse which are defined as follows 19 rmse 1 n i 1 n y i y i 2 20 mae 1 n i 1 n y i y i 21 mape 1 n i 1 n y i y i y i 100 22 nse 1 i 1 n y i y i 2 i 1 n y i y 2 where yi is the real springs discharge data y i is the predicted value rmse a standard error reflects how the spreads of the prediction errors are mae is the average of absolute errors which measures how far predicted values are away from the original value mape measures model accuracy as a percentage and it works best if there are no extremes to the data as such mape is primarily used to evaluate the abnormality of data swanson et al 2011 the values of rmse mae and mape are all from 0 to a small value of rmse indicates a small deviation between the predicted and the observed time series that is the smaller the value the better the model is on the other hand nse is an efficiency indicator for hydrological models which ranges from to1 a value close to 1 represents the model predictability is satisfactory yoon et al 2011 meng et al 2019 4 results and discussion 4 1 decomposing the springs discharge and precipitation by time frequency methods the decomposed monthly spring discharges and precipitation from january 1959 to december 2015 using ssa are exhibited in fig 6 the window length was set to 68 in this study and therefore the time series of spring discharge was decomposed into 68 subsequences by eq 6 these subsequences were ranked according to their eigenvalue contribution from the largest to the smallest the first eight subsequences with large eigenvalue contribution i e rc1 8 were regards as the main components of the spring discharge and precipitation time series and the total contribution rates are 94 95 and 72 68 respectively which satisfies the requirement to reproduce the spring discharge and precipitation fig 6 after consideration of computational accuracy and efficiency we chose the first eight subsequences to represent the spring discharge and the remainings were regarded as the noise components and were filtered eemd decomposes the monthly spring discharge and precipitation time series into eight imfs as displayed in fig 7 this figure shows the imfs from high to low frequency and one residual trend item r and it shows their amplitudes in descending order combining imfs and the trend r fully restores the original signal fig 6a shows that the rc1 component of the spring discharge derived by ssa is the dominant factor with an apparent decreasing trend which caused by human activity and contributes 85 68 in the spring discharge on the other hand the decomposition of the precipitation data in fig 6b shows no trend in all components of the precipitation data but multifrequency fluctuations similarly the r component dominates the spring discharge record which has obvious declining trend due to human activity and accounts for 83 26 of the total variance of the spring discharge fig 7a further there is no noticeable trend of precipitation components fig 7b besides we have derived the slope of the rc1 component of the spring discharge based on ssa as a function of time in fig 8 a and r based on eemd in fig 8b as illustrated in fig 8 the slopes of the rc1 and r components are approaching to zero which suggest that human activity trend to be alleviated in the niangzuguan springs catchment the behaviors of the rc1 and r components are consistent with the implementation of the sustainable development policy of china in the 1990s we therefore believe that both ssa and eemd can decipher the time series to reveal the impact of human activity moreover fig 8 illustrates that the slope of the rc1 significantly fluctuates although it increases and approaches zero with time on the other hand the slope of r increases over the period with a constant rate due to the constant rate the lstm quickly understands the behavior of the r from eemd therefore the eemd lstm model is expected to simulate the spring discharge better than the ssa lstm model in the niangziguan spring basin the variation of the springs discharge is mainly affected by precipitation and human activities huo et al 2016 precipitation infiltrates through epikarst zones and reaches saturated zones the associated pressure change propagates through the aquifer and reaches outlets of the springs and causes the spring discharge fluctuations on the other hand the local economy has developed over the past five decades the exploitation and utilization of karst water resources have also increased which caused a significant decrease of the spring discharge since 1990s china implemented sustainable development policy the declining trend of the spring discharge has relieved gradually for these reasons the human activities are likely responsible for the spring discharge descending trends and the climate variation explains the spring discharge fluctuations as revealed by the ssa and eemd analysis 4 2 comparison between lstm ssa lstm and eemd lstm the time series of niangziguan spring discharge are divided into three periods training period january 1959 to august 1990 validation period september 1990 to december 1998 and prediction period january 1999 to december 2015 accordingly the length of training validation and prediction periods occupy 50 20 and 30 of the total spring discharge respectively based on the three periods we examined the performance of the lstm ssa lstm and eemd lstm models the lstm model was setup by using spring discharge data for the ssa lstm and eemd lstm models we used the lstm model to simulate each of the subsequences and then combine the results to reproduce the spring discharge for testing whether the model is overfitted in the training and verification periods we employee the diagnostic plot i e loss in the training and validation period in this paper the loss in the training and validation periods of lstm ssa lstm eemd lstm models are showed in fig 9 the loss values of training and validation period decrease at the same time and tend to be stable suggesting that the models are not overfitted and the training performs are perfect the calibration validation and prediction of the niangziguan spring discharge by lstm ssa lstm and eemd lstm are illustrated in fig 10 their performance indexes listed in table 1 for the lstm model the predicted spring discharge do not match the observed values well fig 10a a nse i e eq 22 value of 0 46 is obtained table 1 which is lower than 0 5 indicating that the prediction is not satisfactory meanwhile the quality of the prediction of the ssa lstm and eemd models are better than that of lstm model and the quality of the prediction based on the eemd lstm model is the best fig 10b and c the quantitative evaluation metric for the three models confirms that the lstm model s prediction performance was inferior to those of ssa lstm and eemd lstm models table 1 in comparison with lstm the ssa lstm model reduces the rmse mae and mape values by 17 31 16 22 and 17 92 respectively and increases nse value by 36 96 however the eemd lstm model is superior to the ssa lstm model since it reduces the rmse mae and mape values by 60 47 58 06 and 58 95 respectively and increases nse value by 49 21 these metrics suggest that the eemd lstm yielded the best prediction among the three models the scatter plot of the simulation vs observation of training validation and prediction periods by the three models as displayed in fig 11 reinforces the above conclusions that the ssa lstm model and eemd lstm model have better performance than the lstm model and the accuracy of the eemd lstm model is higher than that of ssa lstm model besides we furtherly discuss the reasons why eemd lstm is better than ssa lstm the metric performances of each component in calibration validation and prediction periods of ssa lstm and eemd lstm models are listed in tables 2 4 respectively table 2 illustrated that the calibration performances of ssa lstm model for rc1 8 is satisfactory the value of rmse and mae is close to 0 and nse reaches 0 99 eemd lstm also yields satisfactory performance although the nse value of imf1 is 0 64 and a little bit small it may be due to its extreme irregularities of the high frequency component overall ssa lstm and eemd lstm perform well in the training dataset the validation performance in table 3 showed that the value of rmse and mae is close to 0 and nse reaches 0 99 suggesting satisfactory quality the prediction performances of ssa lstm and eemd lstm models showed that the values of rmse and mae are close to 0 and the value of nse is close to 1 table 4 for the predictions by ssa lstm and eemd lstm which suggest excellent predictions as indicated in table 4 the mape values of rc6 8 are 407 23 199 97 and 168 05 for ssa lstm meanwhile the mape of imf1is 182 52 for eemd lstm such a low prediction performance is likely due to the high irregularity of the spring discharge during 1985 and 1986 fig 3 these irregularities correspond to two sudden increases of spring discharge in september 1985 and july 1986 in fig 3a three earthquakes in the niangziguan spring basin i e niangziguan town are the causes of the sudden increases one of them occurred on 1985 09 28 with level 1 1 and two took place on 1986 06 06 with level 2 5 and 1 0 the irregular oscillations and the extremely abnormal behaviors due to these earthquakes make prediction performance metric mape low this remark is based on the finding by meng et al 2019 who showed that high irregular oscillations of time series could cause low prediction performance in terms of mape both ssa and eemd are new data adaptive decomposition methods by decomposing data into high to low frequency components and trend items they can simulate each subsequence and derive satisfactory predictions in dealing with nonlinear and nonstationary time series eemd separates the signal into different frequency components while ssa separates it into signals of different energy levels ssa separates signals according to energy but it may create frequency mixing problems zhang et al 2015 besides ssa extracts reliable information from the noisy data and aggregates the desired signal components into a limited portion of the time series without considering the remaining noisy signals the noise signal may contain useful information wang et al 2014 as such some information about the time series may be lost in the ssa in other words the better performance of eemd method in prediction than that of ssa method is mainly due to the capability of eemd for the reconstruction of the original data while the ssa method would filter out some real data after data decomposition specifically ssa decomposes the original data based on the orthogonal transformation retains the components with relatively large eigenvalues referred to as rc and discards the components of small eigenvalues which are considered as noise therefore after adding up all major rcs with large eigenvalues there is still a small gap between the reconstructed data and the original ones for example the sum of eight rcs accounts for only 94 95 of the total variation indicative of a gap of 5 05 variation between this sum and the original data on the other hand the procedure of eemd method subtracts the different frequency components imfs from the original data one by one this substation procedure continues until the remaining component containing no frequencies at all rising or falling monotonously or containing at most one extremum then this remaining component is the trend r thus the sum of r and all imfs leads to a series closely resemble the original data with little data loss huang et al 2014 since the eemd decomposition method retains the original data more completely than ssa method the prediction accuracy based on eemd is better than that based on ssa it is also worth mentioning that the data components dropped by the ssa method are generally irrelevant for prediction these data are small amplitudes and appear to be noise leading to inaccurate predictions therefore eemd appears to be a more robust approach than ssa 5 conclusion for improving the accuracy of simulation of nonlinear and nonstationary karst spring discharge this study examines the various time frequency analysis methods including the singular spectrum analysis ssa and ensemble empirical mode decomposition eemd and long short term memory lstm the methods are then applied to the niangziguan springs time series this study draws the following conclusions 1 compared with lstm the combination of time frequency analysis and lstm methods ssa lstm and eemd lstm are more robust in dealing with time series contains multiple subsequences with strongly nonlinear fluctuations ssa lstm and eemd lstm have higher accuracy than lstm in spring discharge simulation in other words the combination methods overcome the deficiencies of lstm in the simulation of multi frequency time series with strongly nonlinear and fluctuations 2 the eemd lstm model yields a better prediction performance than ssa lstm because the decomposed periodic series of eemd contains more detailed information than that with ssa information loss during the selection of the effective components in ssa is likely the reason 3 ssa lstm and eemd lstm could provide more frequency information about the controlling factors of the karst spring discharge and overcome the deficiencies of lstm credit authorship contribution statement lixing an formal analysis yonghong hao writing original draft tian chyi jim yeh writing review editing yan liu methodology wenqiang liu visualization baoju zhang conceptualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is partially supported by the natural science foundation of tianjin china 18jczdjc39500 and the national natural science foundation of china 41272245 40972165 and 40572150 the authors sincerely thank the three anonymous reviewers for their detailed and constructive comments to improve the quality of this manuscript 
5290,spring discharges from karst aquifers are results of spatially and temporally complex hydrologic processes such as precipitation surface runoff infiltration groundwater flow as well as anthropogenic factors these processes are spatially and temporally varying at a multiplicity of scales with nonlinear and nonstationary characteristics for improving the prediction accuracy of karst springs discharge this study first applied the time frequency analysis methods including singular spectrum analysis ssa and ensemble empirical mode decomposition eemd to extract frequency and trend feature of niangziguan springs discharge then the long short term memory lstm was used to simulate each frequency and trend subsequence subsequently the prediction of spring discharge was completed by a combination of the simulated results from lstm finally the performances of lstm ssa lstm and eemd lstm under different inputs were compared the results show that the performance of ssa lstm and eemd lstm are better than lstm and the eemd lstm model achieved the best prediction performance keywords karst spring discharge nonlinear and nonstationary time series singular spectrum analysis ssa ensemble empirical mode decomposition eemd long short term memory lstm deep learning 1 introduction spring discharges from karst aquifers are results of spatially and temporally complex hydrologic processes such as precipitation surface runoff infiltration groundwater flow as well as anthropogenic factors ozyurt and bayari 2008 telesca et al 2013 karst aquifers are highly heterogeneous and contain conduits fractures and pores where may exhibit hierarchical permeability structures or flow paths the hierarchical groundwater flow paths make karst spring discharge fluctuate with multi frequency for example the aquifers of niangziguan springs china exhibit groundwater quick flow belts in the karst conduits and fractures developed areas groundwater convergence zones where fissures occur in networks and groundwater stagnant regions where dominate by pores an et al 2019 the hierarchical flow fields endow the spring discharge with behaviors of multi frequency on the other hand human activities cause karst spring discharge declining for instance previous studies showed that the anthropogenic effects had surpassed the effects of climate change and became the major factor of impacting karst hydrological processes in the niangziguan springs catchment hao et al 2009 2016 consequently karst springs discharge is characterized by a strong nonlinear trend and nonstationary fluctuations due to the complexity caused by random precipitation extreme heterogeneity of karst aquifers and anthropogenic impacts deciphering the spring discharge records using a physical model is a formidable task for understanding contributions from each component and or predicting spring discharge milly et al 2008 duran et al 2020 to resolve this difficulty the deep learning model may offer an alternative approach recently artificial neural networks anns have been employed to analyze the hydrological processes for example anns were employed to streamflow forecasting to deal with the nonlinear problems zhang et al 2015 many researchers have applied anns to modeling and forecasting nonstationary hydrological processes e g sivakumar et al 2002 hu et al 2008 ghumman et al 2011 cui 2013 similar to black box anns models do not require detailed information on the physics of the hydrologic processes el shafie et al 2007 guo et al 2011 he et al 2014 on the other side the drawback of anns is that the sequential order information of input data is lost kratzert et al 2018 to overcome the shortcomings of anns a deep neural network structure i e recurrent neural networks focusing on processing time sequences data was developed to selectively pass information across sequence steps lipton et al 2015 the feedback connectionist models of the recurrent neural networks are convenient to update the residual value and weight value in the previous step which is suitable for time sequences prediction long short term memory lstm neural networks are a special type of recurrent neural networks that were proposed by hochreiter and schmidhuber 1997 the lstm overcomes the problem of the traditional recurrent neural networks of learning long term dependencies and has been widely used in computer science fields such as speech recognition graves et al 2013 han et al 2017 image processing song et al 2016 rajeev et al 2019 and natural language processing sundermeyer et al 2012 wang et al 2019 in recent years hydrologists have applied lstm to hydrological time series for instance kratzert et al 2018 employed lstm for modeling rainfall runoff their results demonstrated that the lstm produced better model performance than recurrent neural networks due to learn and store long term dependencies abilities hu et al 2018 compared the performance of lstm and ann models for flood prediction their study confirmed that the special units of forget gate make lstm a better predictor than the traditional ann model zhang et al 2018 also conducted a comparative study for predicting the water levels of a combined sewer overflow structure in drammen norway using different neural network models i e multilayer perceptron wavelet neural networks and lstm they showed that lstm has superior prediction capabilities for multi step ahead time series to other models although the lstm can satisfactorily predict most of the hydrological time series it fails to obtain satisfactory predictions for strong nonlinear time series liu et al 2019 for improving the accuracy of lstm in the simulation of a strong nonlinear sequence we intend to decompose the sequence using singular spectrum analysis ssa and ensemble empirical mode decomposition eemd subsequently we simulate each of the subsequences using lstm and combined the simulations hopefully the combined methods of ssa lstm and eemd lstm can improve accuracy significantly ssa is a data adaptive technique proposed by colebrook 1978 to extract information from short and noisy time series ssa can separate original time series into independent components such as trend oscillation components and noise and thus it provides insight into the unknown dynamics of the time series the ssa technique has been used in geophysical time series for example vautard and ghil 1989 used ssa to measure noise and the oscillation dynamic of the paleoclimatic time series marques et al 2006 applied ssa to forecast hydrological time series such as precipitation runoff and water temperature time series while luo et al 2015 extracted seasonal signals of these time series by ssa further ssa has been used in other fields such as mathematical statistics moskvina and zhigljavsky 2003 biomedicine you and xu 2003 hassani et al 2017 and image processing zhen et al 2006 rodriguez aragon and zhigljavsky 2010 empirical mode decomposition emd is a data adaptive time frequency analysis method for nonlinear and nonstationary time series proposed by huang et al 1998 time series decomposition is performed at scales without setting any basis functions wu and huang 2009 proposed an improved empirical mode decomposition algorithm called eemd which improved the mode mixing problem of emd in recent years eemd has been applied to analyze hydrological time series sun and ma 2015 hu et al 2017 roushangar and alizadeh 2018 and climate change hawinkel et al 2015 xiao et al 2019 gao and shi 2016 boodhoo et al 2016 kim et al 2018 for acquiring better simulation of nonlinear and nonstationary spring discharge this paper uses time frequency analysis methods i e ssa and eemd to decompose the spring discharge series into multiple subsequences with different frequencies then employs the lstm method to simulate each subsequence and predicts spring discharge by the combination of the simulated results subsequently the predictions are then compared with the lstm models the approaches were applied to the niangziguan springs catchment of china 2 study area and data the niangziguan springs complex is located in the mianhe river valley eastern shanxi province china which receives water from a 7394 km2 basin it is the largest karst springs in northern china fig 1 the major geologic strata in the niangziguan springs catchment from top to bottom are quaternary loss deposits sandstone permian arenaceous shale carboniferous mudstone sandstone and limestone with coal seams ordovician carbonate rocks and cambrian dolomite fig 2 the groundwater in karst aquifers i e ordovician carbonate rocks flows toward the mian river valley in the east where groundwater perches on low permeable strata of cambrian dolomicrite and eventually intersects the ground surface thus creating the niangziguan springs han et al 1993 liang et al 2008 niangziguan springs are distributed along the mianhe river bank which stretches approximately 7 km the river discharge has been monitored at the upper and down streams of the river subtracting the upstream river discharge from the downstream river discharge yields the spring discharge the calculated monthly niangziguan springs discharge records from january 1959 to december 2015 are displayed in fig 3 a it shows that in decadal time scales the spring discharge seems to be declining linearly in inter and intra annual time scales the spring discharge however showed apparent fluctuations with decreasing trend because of climate change and human activities i e groundwater overexploitation and dewatering from coal mining in the catchment that is the spring discharge has distinct nonstationary and nonlinear characteristics monthly precipitation time series are acquired from january 1959 to december 2015 from seven rainfall stations in the niangziguan basin yuxian county shouyang county yangquan city pingding county xiyang county heshun county and zuoquan county and the mean precipitation was calculated by theisen polygons fig 3b 3 method a schematic flowchart for ssa lstm and eemd lstm is listed in fig 4 3 1 singular spectrum analysis ssa ssa constructs a trajectory matrix based on the observed time series and decomposes and reconstructs the trajectory matrix for ssa this method is the procedure that takes a univariate time record and makes it a multivariate set of observations elsner and tsonis 1997 the main steps of ssa are briefly presented as follows stea et al 2008 basic ssa is performed in four steps the first step is called the embedding step 3 1 1 embedding at this step one first selects an appropriate window length m and 1 m n 3 where n is the total number of data of the time series then one transfers the observed time series x x 1 x 2 x n into k lagged vectors x 1 x 2 x k each vector has a length of m x i x i x i 1 x i m 1 t where i 1 k and k n m 1 the k lagged vectors i e x x 1 x 2 x k then forms a trajectory matrix x 1 x x 1 x 2 x 3 x k x 2 x 3 x 4 x k 1 x 3 x 4 x 5 x k 2 x m x m 1 x m 2 x n the trajectory matrix x is a m k hankel matrix with equal elements along the back diagonals that is the elements in x are identical when the sums of the row and column indexes are equal to a constant 3 1 2 singular value decomposition svd in this step using the trajectory matrix x we formulate the m m square matrix c xx t then we find the non zero eigenvalues of matrix c λ 1 λ 2 λ l in decreasing order l m and l is the total number of the non zero eigenvalues and the corresponding eigenvectors of these eigenvalues u 1 u 2 u l afterward the trajectory matrix x can be written as golub and reinsch 1971 2 x u 1 u l λ 1 0 0 0 0 λ 2 0 0 0 0 0 0 0 0 λ l v 1 t v l t in eq 2 λ i is the ith singular value of the matrix x the set λ i i 1 2 l is the x s singular spectrum the ui and vi are the left and right eigenvectors of the matrix x respectively note that u 1 u l are the orthogonal vectors with length 1 i e u i t u j 1 i j 0 i j similarly vi s are also orthogonal vectors with v i t v j 1 i j 0 i j from the above relationship it can be deduced that v i x t u i λ i i 1 l and x i λ i u i v i t as a result the trajectory matrix x can be written as a sum of bi orthogonal elementary matrices 3 x x 1 x 2 x l 3 1 3 grouping divide the set of the subscript i of elementary matrix x i i e 1 2 l into p disjoint subsets i 1 i 2 ip correspondingly the elementary matrix x i is split into p groups let i t i 1 i 2 i r t t 1 2 p the resultant matrix x i t is defined as x i t x i 1 x i 2 x i r t calculate resultant matrices of x i 1 x i 2 x i p respectively and substituting in eq 3 obtains the new expansion hassani 2007 4 x x i 1 x i 2 x i p the choice of the sets i 1 i 2 ip is called the eigentriple grouping 3 1 4 diagonal averaging next diagonal averaging transforms each matrix x i t in eq 4 into a new time series of length n that is consider y be a matrix of m k which elements are y ab 1 a m 1 b k if m k y ab y ab otherwise y ab y ba make m min m k k max m k the diagonal averaging procedure converts the matrix y to a series y 1 y 2 y n by the following formula 5 y k 1 k p 1 k y p k p 1 1 k m 1 m p 1 m y p k p 1 m k k 1 n k 1 p k k 1 n k 1 y p k p 1 k k n eq 5 generates an n length reconstructed signal time series rc t the original series x is decomposed into the sum of p components 6 x rc 1 rc 2 rc p its percentage of the total eigenvalues determines the contribution of component rc t i s i t λ i s i 1 l λ i s 1 2 r t based on the contribution of rc t one can select m effective components then a filtered series is the sum of m components 7 x rc 1 rc 2 rc m the remaining components i e rc m 1 rc m 2 rc p are considered as noises the window length m and the number of reconstructed components m are the two vital parameters in ssa the general rule for the window length is that the length should not be longer than n 3 vautard et al 1992 3 2 ensemble empirical mode decomposition eemd empirical mode decomposition emd is a data adaptive signal preprocessing technique for nonlinear and nonstationary time series it decomposes signals into intrinsic mode functions imfs from high to low frequency through a sifting process which represent a physically meaningful description of the time frequency energy of a time series huang et al 1998 hawinkel et al 2015 the emd must meet the following two rules 1 all the number of extrema and the number of zero crossings must be the same or different at most by one 2 all upper and lower envelopes must be locally symmetrical along with the time axis i e the mean value of the upper and lower envelopes is zero or close to zero these two conditions ensure that the instantaneous frequency obtained by imfs is meaningful the sifting process of emd is as follows huang et al 1998 park et al 2018 1 identify all local extrema of x t 2 a cubic spline interpolation method connects all local minimum value and maximum value forming the lower envelope e min and upper envelope e max respectively 3 calculate the mean of the envelopes by m e min e max 2 4 obtain the detail h t x t m t 5 check the details of h t if h t is an imfs then repeat above steps with residual r t x t h t replacing x t otherwise h t instead of x t to continue above steps 6 repeat the above steps until a stop criterion is satisfied the stop criterion is defined by two consecutive sifting results 8 s d k t 0 t h k 1 t h k t 2 h k 1 2 t where k represents the number of sifting processes when sdk is between 0 2 and 0 3 imfs retain enough physical sense huang et al 1998 however one major problem of emd is the mode mixing i e the decomposed imfs contains multi frequencies peel et al 2011 yu et al 2018 eemd is a noise assisted data adaptive analysis that overcomes the mode fixing of emd the specific steps of eemd decomposition are as follows 1 add gaussian white noise to the original signal 2 decompose the data series into imfs through the sifting process of emd 3 repeat above steps for n times with different white noise series 4 average the summation of corresponding decomposed imf for n times then an ensemble set of imfs can be obtained 9 c j 1 n i 1 n c j i where cj denotes the jth imf component it should be noted that the effect of the added white noise should decrease according to the well established statistical rule 10 ɛ n ɛ n where n is the size of ensemble numbers ɛ is the amplitude of the added noise ɛn represents the standard deviation of the error which means the difference between the original signal and the corresponding imf s in this study the standard deviation of the added white noise is 0 4 and the ensemble number size is 1000 3 3 long short term memory lstm neural networks recurrent neural networks process nonlinear time varying series and predict the future value of the time series based on the historical data extraction rules of the time series lipton et al 2015 however recurrent neural networks are prone to gradient explosion and gradient vanishes when backpropagation errors across many time steps because of this the gradient of training cannot be transmitted in long sequences sahoo et al 2019 in order to solve these problems a special recurrent neural networks model lstm neural networks was proposed by hochreiter and schmidhuber 1997 lstm is suitable for processing and predicting events with relatively long intervals and delays in time series gers et al 1999 fig 5 a is a typical structure of recurrent neural networks which consists of an input layer a hidden layer and an output layer to explain how the networks works we unfold the recurrence unit of the network as shown in fig 5b fig 5c is the internal operation of lstm as is seen from fig 5b at time t neuron unit s receives input from the current data point it and from hidden node st 1 in the network s previous state each network layer shares parameters wi wh wo across time steps recurrent neural networks can be regarded as multiple copies of the same network in simple recurrent neural networks the computation equations at each time step as follows 11 st f wiit whst 1 bh 12 ot g wost by where f and g is the activation function wi is the weights matrix between the input and the hidden layer wh is the matrix of recurrent weights between the hidden layer and itself at adjacent time steps and wo is the weights matrix between the output and the hidden layer the vectors bh and by are bias parameters recurrent neural networks have the form of a chain of repeating modules of neural networks in traditional recurrent neural networks the repeating module has only one state st and it executes the tanh hyperbolic tangent transform while the repeating module of lstm adds an additional cell state ct to stored long term information and three gates forget gate input gate output gate control the cell state fig 5c there are four steps of the lstm 1 forget gate forget gate decides what information is going to be thrown away from the previous cell state ct 1 13 ft σ wf st 1 it bf where σ is the logistic sigmoid function wf bf represents the weight matric and bias vector of the forget gate respectively 2 input gate input gates decide what new information to be updated and stored in the cell state the function i t is as follows 14 i t σ w i s t 1 i t b i where w i b i represents the weight matric and bias vector of the input gate respectively c t is an update vector for the cell state 15 c t t a n h w c s t 1 i t b c where tanh is the hyperbolic tangent wc bc represents the weight matric and bias vector of tanh layer respectively 3 memory update the new cell state is obtained by old memory via the forget gate and new memory via the input gate the cell state is updated from ct 1 to ct by the following equation 16 c t f t c t 1 i t c t 4 output gate output gate decides what information is going to output which is calculated by the following equation 17 ot σ wo st 1 it bo where wo and bo represent the weight matric and bias vector of the output gate respectively the final output of the new hidden layer st of lstm is determined by the output gate and the cell state 18 st tanh ct ot in lstm cell state ct is the key variable the ct executes only simple linear interactions with previous cell state which can store information unchanged over a long period of time during training the weight changes slowly which helps to prevent the problem of the exploding or vanishing gradients in the backpropagation step 3 4 model performance evaluation indicators for training the model we chose loss function i e the mean squared error of the training dataset as a criterion to calibrate the model and the optimal values of the mean squared error were obtained by adam algorithm automatically updating the model parameters to evaluate the prediction performances of the above models i e lstm ssa lstm and eemd lstm models we used the root mean square error rmse the mean absolute error mae the mean absolute percentage error mape and the nash sutcliffe efficiency coefficient nse which are defined as follows 19 rmse 1 n i 1 n y i y i 2 20 mae 1 n i 1 n y i y i 21 mape 1 n i 1 n y i y i y i 100 22 nse 1 i 1 n y i y i 2 i 1 n y i y 2 where yi is the real springs discharge data y i is the predicted value rmse a standard error reflects how the spreads of the prediction errors are mae is the average of absolute errors which measures how far predicted values are away from the original value mape measures model accuracy as a percentage and it works best if there are no extremes to the data as such mape is primarily used to evaluate the abnormality of data swanson et al 2011 the values of rmse mae and mape are all from 0 to a small value of rmse indicates a small deviation between the predicted and the observed time series that is the smaller the value the better the model is on the other hand nse is an efficiency indicator for hydrological models which ranges from to1 a value close to 1 represents the model predictability is satisfactory yoon et al 2011 meng et al 2019 4 results and discussion 4 1 decomposing the springs discharge and precipitation by time frequency methods the decomposed monthly spring discharges and precipitation from january 1959 to december 2015 using ssa are exhibited in fig 6 the window length was set to 68 in this study and therefore the time series of spring discharge was decomposed into 68 subsequences by eq 6 these subsequences were ranked according to their eigenvalue contribution from the largest to the smallest the first eight subsequences with large eigenvalue contribution i e rc1 8 were regards as the main components of the spring discharge and precipitation time series and the total contribution rates are 94 95 and 72 68 respectively which satisfies the requirement to reproduce the spring discharge and precipitation fig 6 after consideration of computational accuracy and efficiency we chose the first eight subsequences to represent the spring discharge and the remainings were regarded as the noise components and were filtered eemd decomposes the monthly spring discharge and precipitation time series into eight imfs as displayed in fig 7 this figure shows the imfs from high to low frequency and one residual trend item r and it shows their amplitudes in descending order combining imfs and the trend r fully restores the original signal fig 6a shows that the rc1 component of the spring discharge derived by ssa is the dominant factor with an apparent decreasing trend which caused by human activity and contributes 85 68 in the spring discharge on the other hand the decomposition of the precipitation data in fig 6b shows no trend in all components of the precipitation data but multifrequency fluctuations similarly the r component dominates the spring discharge record which has obvious declining trend due to human activity and accounts for 83 26 of the total variance of the spring discharge fig 7a further there is no noticeable trend of precipitation components fig 7b besides we have derived the slope of the rc1 component of the spring discharge based on ssa as a function of time in fig 8 a and r based on eemd in fig 8b as illustrated in fig 8 the slopes of the rc1 and r components are approaching to zero which suggest that human activity trend to be alleviated in the niangzuguan springs catchment the behaviors of the rc1 and r components are consistent with the implementation of the sustainable development policy of china in the 1990s we therefore believe that both ssa and eemd can decipher the time series to reveal the impact of human activity moreover fig 8 illustrates that the slope of the rc1 significantly fluctuates although it increases and approaches zero with time on the other hand the slope of r increases over the period with a constant rate due to the constant rate the lstm quickly understands the behavior of the r from eemd therefore the eemd lstm model is expected to simulate the spring discharge better than the ssa lstm model in the niangziguan spring basin the variation of the springs discharge is mainly affected by precipitation and human activities huo et al 2016 precipitation infiltrates through epikarst zones and reaches saturated zones the associated pressure change propagates through the aquifer and reaches outlets of the springs and causes the spring discharge fluctuations on the other hand the local economy has developed over the past five decades the exploitation and utilization of karst water resources have also increased which caused a significant decrease of the spring discharge since 1990s china implemented sustainable development policy the declining trend of the spring discharge has relieved gradually for these reasons the human activities are likely responsible for the spring discharge descending trends and the climate variation explains the spring discharge fluctuations as revealed by the ssa and eemd analysis 4 2 comparison between lstm ssa lstm and eemd lstm the time series of niangziguan spring discharge are divided into three periods training period january 1959 to august 1990 validation period september 1990 to december 1998 and prediction period january 1999 to december 2015 accordingly the length of training validation and prediction periods occupy 50 20 and 30 of the total spring discharge respectively based on the three periods we examined the performance of the lstm ssa lstm and eemd lstm models the lstm model was setup by using spring discharge data for the ssa lstm and eemd lstm models we used the lstm model to simulate each of the subsequences and then combine the results to reproduce the spring discharge for testing whether the model is overfitted in the training and verification periods we employee the diagnostic plot i e loss in the training and validation period in this paper the loss in the training and validation periods of lstm ssa lstm eemd lstm models are showed in fig 9 the loss values of training and validation period decrease at the same time and tend to be stable suggesting that the models are not overfitted and the training performs are perfect the calibration validation and prediction of the niangziguan spring discharge by lstm ssa lstm and eemd lstm are illustrated in fig 10 their performance indexes listed in table 1 for the lstm model the predicted spring discharge do not match the observed values well fig 10a a nse i e eq 22 value of 0 46 is obtained table 1 which is lower than 0 5 indicating that the prediction is not satisfactory meanwhile the quality of the prediction of the ssa lstm and eemd models are better than that of lstm model and the quality of the prediction based on the eemd lstm model is the best fig 10b and c the quantitative evaluation metric for the three models confirms that the lstm model s prediction performance was inferior to those of ssa lstm and eemd lstm models table 1 in comparison with lstm the ssa lstm model reduces the rmse mae and mape values by 17 31 16 22 and 17 92 respectively and increases nse value by 36 96 however the eemd lstm model is superior to the ssa lstm model since it reduces the rmse mae and mape values by 60 47 58 06 and 58 95 respectively and increases nse value by 49 21 these metrics suggest that the eemd lstm yielded the best prediction among the three models the scatter plot of the simulation vs observation of training validation and prediction periods by the three models as displayed in fig 11 reinforces the above conclusions that the ssa lstm model and eemd lstm model have better performance than the lstm model and the accuracy of the eemd lstm model is higher than that of ssa lstm model besides we furtherly discuss the reasons why eemd lstm is better than ssa lstm the metric performances of each component in calibration validation and prediction periods of ssa lstm and eemd lstm models are listed in tables 2 4 respectively table 2 illustrated that the calibration performances of ssa lstm model for rc1 8 is satisfactory the value of rmse and mae is close to 0 and nse reaches 0 99 eemd lstm also yields satisfactory performance although the nse value of imf1 is 0 64 and a little bit small it may be due to its extreme irregularities of the high frequency component overall ssa lstm and eemd lstm perform well in the training dataset the validation performance in table 3 showed that the value of rmse and mae is close to 0 and nse reaches 0 99 suggesting satisfactory quality the prediction performances of ssa lstm and eemd lstm models showed that the values of rmse and mae are close to 0 and the value of nse is close to 1 table 4 for the predictions by ssa lstm and eemd lstm which suggest excellent predictions as indicated in table 4 the mape values of rc6 8 are 407 23 199 97 and 168 05 for ssa lstm meanwhile the mape of imf1is 182 52 for eemd lstm such a low prediction performance is likely due to the high irregularity of the spring discharge during 1985 and 1986 fig 3 these irregularities correspond to two sudden increases of spring discharge in september 1985 and july 1986 in fig 3a three earthquakes in the niangziguan spring basin i e niangziguan town are the causes of the sudden increases one of them occurred on 1985 09 28 with level 1 1 and two took place on 1986 06 06 with level 2 5 and 1 0 the irregular oscillations and the extremely abnormal behaviors due to these earthquakes make prediction performance metric mape low this remark is based on the finding by meng et al 2019 who showed that high irregular oscillations of time series could cause low prediction performance in terms of mape both ssa and eemd are new data adaptive decomposition methods by decomposing data into high to low frequency components and trend items they can simulate each subsequence and derive satisfactory predictions in dealing with nonlinear and nonstationary time series eemd separates the signal into different frequency components while ssa separates it into signals of different energy levels ssa separates signals according to energy but it may create frequency mixing problems zhang et al 2015 besides ssa extracts reliable information from the noisy data and aggregates the desired signal components into a limited portion of the time series without considering the remaining noisy signals the noise signal may contain useful information wang et al 2014 as such some information about the time series may be lost in the ssa in other words the better performance of eemd method in prediction than that of ssa method is mainly due to the capability of eemd for the reconstruction of the original data while the ssa method would filter out some real data after data decomposition specifically ssa decomposes the original data based on the orthogonal transformation retains the components with relatively large eigenvalues referred to as rc and discards the components of small eigenvalues which are considered as noise therefore after adding up all major rcs with large eigenvalues there is still a small gap between the reconstructed data and the original ones for example the sum of eight rcs accounts for only 94 95 of the total variation indicative of a gap of 5 05 variation between this sum and the original data on the other hand the procedure of eemd method subtracts the different frequency components imfs from the original data one by one this substation procedure continues until the remaining component containing no frequencies at all rising or falling monotonously or containing at most one extremum then this remaining component is the trend r thus the sum of r and all imfs leads to a series closely resemble the original data with little data loss huang et al 2014 since the eemd decomposition method retains the original data more completely than ssa method the prediction accuracy based on eemd is better than that based on ssa it is also worth mentioning that the data components dropped by the ssa method are generally irrelevant for prediction these data are small amplitudes and appear to be noise leading to inaccurate predictions therefore eemd appears to be a more robust approach than ssa 5 conclusion for improving the accuracy of simulation of nonlinear and nonstationary karst spring discharge this study examines the various time frequency analysis methods including the singular spectrum analysis ssa and ensemble empirical mode decomposition eemd and long short term memory lstm the methods are then applied to the niangziguan springs time series this study draws the following conclusions 1 compared with lstm the combination of time frequency analysis and lstm methods ssa lstm and eemd lstm are more robust in dealing with time series contains multiple subsequences with strongly nonlinear fluctuations ssa lstm and eemd lstm have higher accuracy than lstm in spring discharge simulation in other words the combination methods overcome the deficiencies of lstm in the simulation of multi frequency time series with strongly nonlinear and fluctuations 2 the eemd lstm model yields a better prediction performance than ssa lstm because the decomposed periodic series of eemd contains more detailed information than that with ssa information loss during the selection of the effective components in ssa is likely the reason 3 ssa lstm and eemd lstm could provide more frequency information about the controlling factors of the karst spring discharge and overcome the deficiencies of lstm credit authorship contribution statement lixing an formal analysis yonghong hao writing original draft tian chyi jim yeh writing review editing yan liu methodology wenqiang liu visualization baoju zhang conceptualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is partially supported by the natural science foundation of tianjin china 18jczdjc39500 and the national natural science foundation of china 41272245 40972165 and 40572150 the authors sincerely thank the three anonymous reviewers for their detailed and constructive comments to improve the quality of this manuscript 
5291,total dissolved solids tds are recognized as an essential indicator of surface water quality the current research investigates the potential of a novel computer aid approach based on the hybridization of wavelet pre processing with multigene genetic programming w mggp for monthly tds prediction at the sefid rud river in northern iran 20 year historical monthly river flow q and tds data measured at the astaneh station were used for the model training and testing the employed time series data were decomposed into several sub series using three mother wavelets i e daubechies4 db4 biorthogonal bior6 8 and discrete meyer dmey to assess appropriate combinations of the time series and their lag times which were further used for prediction process the w mggp model was compared against the wavelet gene expression programming w gep stand alone mggp and gep models results were evaluated using several performance metrics including root mean square error rmse correlation coefficient r and nash sutcliffe efficiency nse modeling results indicated that w mggp and w gep provided a superior prediction capacity for the tds in comparison with the other stand alone artificial intelligence ai models the discrete meyer method exhibited the best performance in time series data decomposition as a pre processing approach the proposed w mggp model based on the dmey mother wavelet attained the best statistical metrics r 0 942 rmse 90 383 and nse 0 862 the research findings demonstrated the hybridization of the wavelet pre processing approach with mggp predictive model for the tds simulation keywords water quality total dissolved solids wavelet multigene genetic programming wavelet analysis river engineering 1 introduction river water is recognized as one of the essential fresh surface waters that is available naturally to supply multiple human usage such as drinking irrigation and industrial production purposes monitoring and management of surface water quality wq play an undeniable role in environmental protection and sustainable use of these water resources ahmadianfar et al 2020 over the past few decades efforts have been devoted to improving wq management and sustainability through the precise simulation of the physical chemical and biological processes of various pollutants total dissolved solid tds is a well accepted indicator for the wq that is effectively used for assessing the suitability of drinking and irrigation water supply tds consists of a variety of inorganic salts e g sodium na magnesium mg 2 calcium ca 2 and potassium k as cations as well as chloride cl sulfate so4 2 nitrates no 3 and bicarbonates hco 3 as anions and dissolved organic matter based on the reported standard by the world health organization who the acceptable range of tds for drinking water is 300 600 mg l who 2011 also the permissible water concentration range of tdsfor agriculture is 450 2000 mg l ayers and westcot 1985 laboratory investigations and empirical calculation methods have been reported for the tds quantification tiyasha et al 2020 however its laboratory test or the manual calculation is associated with some drawbacks such as time consuming unintentional errors and the generalization for the perfect computation the potential of the ai models exhibited a remarkable advancement on modeling tds of river wq banadkooki et al 2020 the massive implementation of the ai models is due to some limitations that have been recognized in the classical mathematical models in addition to the high stochasticity pattern associated with the wq abba et al 2020 in addition the classical models can only provide predictions for a linear and stationary state of a dataset deng et al 2015 the capacity of the ai models is reported in their potential to handle the non linearity and complexity phenomena of the environmental and hydrological processes overcoming the drawback of the traditional models alizadeh et al 2018 das et al 2020 gholami et al 2016 maier et al 2014 naganna and deka 2019 rezaie balf et al 2019 tiyasha et al 2020 wu and chau 2013 the ai models have been positively employed to address a variety of water quality issues such as water quality index wqi dissolved oxygen do nitrate no3 electrical conductivity ec chemical oxygen demand cod biochemical oxygen demand bod ammoniacal nitrogen nh3 n ph and sodium adsorption ratio sar tiyasha et al 2020 the examples of these ai models include artificial neural network ann support vector machine svm adaptive neuro fuzzy inference system anfis random forest rf decision tree dt genetic programming gp linear genetic programming lgp extreme learning machine elm and gene expression programming gep ay and kisi 2014 azad et al 2017 emamgholizadeh et al 2014 heydari et al 2013 olyaie et al 2017 sengorur et al 2015 sepahvand et al 2019 takdastan et al 2018 tiwari et al 2018 recently the capacity of the svm model was tested to assess different wq variables in rivers mahmoudi et al 2016 to forecast the carlson s trophic state index in reservoirs chou et al 2018 and to predict some wq parameters in the sefid rud river basin in iran bozorg haddad et al 2017 the gep dt and lgp were used to forecast tds levels in the zarinehroud basin in iran zaman zad ghavidel and montaseri 2014 and to assess bod do and cod in the karoun river in iran najafzadeh et al 2018 wq time series data are highly stochastic and chaotic implementation of an individual ai based model has limitations for wq modeling yaseen et al 2018 hence the integration of the time series data pre processing approaches can facilitate decomposition of the time series and improve the predictability performance of the ai models among several powerful data pre processing techniques the discrete wavelet transform dwt has been demonstrated a satisfactory approach for decomposition of environmental hydrological and ecological time series data nourani et al 2014 by providing a time frequency representation of an analyzed signal of time series in the time domain and the information about the physical structure of the input time series the wavelet transform can successfully lead to an accurate prediction especially when input data are limited ghimire et al 2019 recently some researchers investigated the possibility and the advantage of integrating the wavelet transform wt approach with ai based models for diverse river wq simulations barzegar et al 2017 2016 integrated wt with elm anifs and ann models to predict ec and salinity research findings evidenced the improvement of the prediction accuracy using the pre processing approach several other researchers conducted similar studies on the integration of the wt with ai models and demonstrated its successful implementation for river wq simulations montaseri et al 2018 rajaee et al 2018 ravansalar et al 2016b a ravansalar and rajaee 2015 these studies indicated that the hybridization of the wt with ai models presented an optimistic new computer aid approach for environmental modeling the enthusiasm of the exploration of new robust and reliable soft computing predictive models is a new modeling trend for better watershed management and sustainability in the current state of the art research a new hybrid artificial intelligence model called wavelet multigene genetic programming w mggp is developed for accurately predicting the monthly tds levels at the sefid rud river in iran the selection of the mggp model is owing to its feasibility in modeling highly non linear time series mehr and safari 2020 mohammad azari et al 2020 in this study the influence of the discrete wavelet transform is explored in combination with the mggp and gep models the capacity of the new version of gp and mggp has been employed for limited hydrological and environmental forecasting dadandeh mehr and demirel 2016 danandeh mehr and nourani 2017 and thus the current research is devoted to the tds prediction 2 materials and methods 2 1 multigene genetic programming gp is an optimization technique that utilizes the principle of darwin s theory gandomi et al 2010 the principle of gp is similar to that of the genetic algorithm ga and thus both methods use the three main operators crossover mutation and selection danandeh mehr et al 2018 the main difference between these two methods is how to present solutions the ga presents solutions by strings with fixed lengths while the gp expresses the solutions by tree structures with varying sizes garg et al 2014 the gp method begins by producing a set of models randomly these models are created by combining the components that are called functions f and terminals t a set of f involve the basic arithmetic operators ã e t c whereas a set of t consist of numerical constants and input variables of a problem fig 1 a depicts an example of the tree structure in a model the efficiency of preliminary population on the input variables training dataset with the objective function is verified by using the root mean square error rmse 1 rmse k 1 k y a k y p k 2 k where y a k is the actual value of the kth data point y p k is the predicted value of the kth data point and k is the total number of data points of the training dataset the gp algorithm chooses models based on the selection of the genetic operators crossover and mutation based on these operators new population is created for new generation this iterative process of optimization in the gp algorithm continues till the satisfactory criterion is achieved in the current research the maximum number of generations is considered as the termination criterion mggp models is demonstrated as an effective and reliable version of the gp method gandomi and alavi 2011 unlike the conventional gp which relies on the assessment of an individual tree the mggp model is formed by a weighted linear combination of the output variables from a number of trees in the gp method gandomi and alavi 2011 garg et al 2014 in this method each tree is considered as a gene which is a gp tree the main procedure adopted for the mggp model development is summarized as follows step 1 set the initial parameters such as functions and terminals population size number of generations rate of genetic operators and maximum number of genes step 2 randomly initiate an initial population of genes step 3 form a model based on a set of genes step 4 investigate the efficiency of models using the objective function rmse step 5 generate new population using the genetic operators step 6 check the stopping criterion and go back to step 5 if it is not satisfied fig 1b shows the typical formulation of the mggp model the model estimates an output variable utilizing three input variables x 1 x 2 and x 3 and four regression coefficients w 0 w 1 w 2 and w 3 the coefficients are specified by the least squares method for each multi gene the control parameters of the developed mggp model are tabulated in table 1 2 2 gene expression program gep gep is an evolutionary algorithm ferreira 2006 and is an extension of genetic programming koza and koza 1992 and has some properties of the genetic algorithm goldberg and holland 1988 indeed the gep uses the benefits of the ga and gp methods simultaneously this method expresses the chromosomes as linear strings that are then demonstrated as tree forms in the proposed method a chromosome involves one or more genes each of which is divided into a head and a tail the head involves the function operators such as ã and or the terminal components such as x y 5 whereas the tail includes the terminal components only ferreira 2006 the values of the main control parameters used in the gep method are shown in table 2 the development of the gep consists of four main steps step 1 in the first step function operators and terminal components are selected to generate the genes in this study the mathematical functions are power sin cos and the terminal components are six independent variables including td s t 1 t d s t 2 t d s t 3 q t q t 1 q t 2 a n d q t 3 step 2 to create the new population in the gep similar to the ga three main operators are used crossover mutation and transposition step 3 the fitness function f k of the k th program is defined as 2 f k l 1 c k r v c k l v t l where r is the range of selection v c k l is a value designed by using the k th individual chromosome for fitness function l and v t l is the target value for fitness function l step 4 the termination criterion is checked if it is satisfied the optimization process in the gep is stopped otherwise go back to step 2 note that in this study the termination criterion is the maximum number of generations 2 3 discrete wavelet transform dwt wt is one of the widely used signal processing methods achieved by utilizing the fourier transform ft heddam and kisi 2017 the wt analyzes the time series dataset in the frequency and time domains by decomposing the dataset into low and high frequency elements this decomposition process provides an informative detail of the unseen pattern in the historical time series data which can be used for prediction by using the data mining methods thus the wt method can increase the computational accuracy of the data mining methods the wt has received a noticeable popularity for solving diverse environmental and hydrological engineering problems nourani et al 2014 the wt is applied to express a function by a set of functions termed as the mother wavelet ψ b c t zhang et al 2004 3 ψ b c t b 1 2 ψ t c b b c r b 0 where b is a dilation factor c is a translation factor and t is time therefore the wt function f t l 2 r can be written as 4 w ψ f b c b 1 2 r f t ψ t c b d t where ψ t denotes the complex conjugate function of ψ t ψ b c t is often a discrete function in hydrological and water quality applications kisi and cimen 2012 for b b 0 k c l c 0 b 0 k b 0 1 c 0 r l and k are integer numbers therefore the discrete wavelet transform dwt of f t is defined as 5 w ψ f k l b 0 k 2 r f t ψ b 0 k t l c 0 d t generally 2 and 1 are selected for the factors b 0 and c 0 respectively kisi and cimen 2012 accordingly eq 5 becomes 6 w ψ f k l 2 k 2 r f t ψ 2 k t l d t regarding a discrete water quality variable f t i e tds in this study the dwt can be expressed as 7 w ψ f k l 2 k 2 t 0 n f t ψ 2 k t l the term of w ψ f k l denotes the characteristics of the original time series with the dilation factor b and translation domain c dwt decomposes the input dataset into low pass and high pass filters which yields two vectors the approximation a and the details d the framework of w mggp w gep and w mlp is depicted in fig 2 2 4 performance metrics eight statistical performance metrics are computed and used for the modeling evaluation they include correlation coefficient r as an indicator to describe the linear relationship between the measured and forecasted variables wang et al 2009 root mean square error rmse nash sutcliffe efficiency nse coefficient nash and sutcliffe 1970 mean absolute percentage error ma pe mean absolute error mae relative absolute error rae scatter index si and willmott s index of agreement i a willmott 1982 which are respectively defined as follows 8 r i 1 k td s o i tds o td s s i tds s i 1 k td s o i tds o 2 i k td s s i tds s 2 9 rmse 1 k i 1 k td s s i td s o i 2 0 5 10 nse 1 i 1 k td s o i t d s s i 2 i 1 k td s o i tds o 2 11 mape 100 k i 1 k td s o i td s s i td s o i 12 mae i 1 k td s s i td s o i k 13 rae i 1 k td s s i td s o i i 1 k t d s o i tds o 14 si r m s e tds o 15 i a 1 i k td s o i t d s s i 2 i 1 k td s s i tds o td s o i tds o 2 0 i a 1 where k is the total number of datasets td s o i is the ith observed tds value td s s i is the i th simulated tds value tds o and tds s respectively are the average observed and simulated tds values moreover the taylor diagram is utilized to visually assess the similarity between the developed ai based methods and observations in terms of their correlation their centered root mean square error crmse difference and the standard deviations taylor 2001 the taylor diagram was originally used as a visual representation of the observed and predicted data in climatology which can clearly highlight the accuracy of various predictive ai models compared to the observed data as a series of points on a polar plot the azimuthal angle refers to the correlation coefficient the proportional distance to the actual data on the x axis denotes the crmse and the radial distance of the predicted point from the origin on the x axis refers to the amplitude of the standard deviation σ the standard deviations of the observed and predicted tds values and the crmse are given as follows 16 σ o 2 1 k i 1 k td s o i tds o 2 σ s 2 1 k i 1 k td s s i tds s 2 17 crms e 2 σ o 2 σ s 2 2 r σ o σ s 3 case study and data analysis in this study the data monthly time scale are related to the astane gauging station located on the sefid rud river longitude 49 37 40 latitude 36 57 02 the observed data are employed to build the ai based models for tds prediction the sefid rud river has a length of 670 km and a drainage area of 13 450 km2 it is the longest river in northern iran in this study monthly discharge and tds data were obtained over a 20 year period 1985 2005 240 months fig 3 displays the location of the astane station each dataset was further divided into a 168 month sub dataset 1985 1999 for training and a 72 month sub dataset 2000 2005 for testing with a monthly time step for both periods the monthly discharge and tds time series over the 20 year period for testing red line and training black line are displayed in fig 4 the optimal input pattern and the most appropriate combination of time series and their lag times are obtained by using descriptive statistics autocorrelation regarding each time lag and cross correlation coefficient between the tds and discharge q values the statistical parameters of the time series of q and tds used in this study are listed in table 3 the parameters include mean standard deviation σ minimum median maximum skewness kurtosis autocorrelation of various lag times for the time series r 1 r 2 r 3 r 4 and cross correlation coefficients between the current monthly tds and the current and time lagged discharge data q t q t 1 q t 2 and q t 3 these statistical metrics clearly indicate that the testing and training datasets follow a similar trend as shown in table 3 the standard deviation values for the training and testing tds time series are close to each other and their skewness coefficients are also small and hence they are suitable for the predictive ai models moreover the skewness and kurtosis coefficients for both training and testing discharge datasets indicate a normal distribution note that the inputs play a key role in the ai model development process therefore specifying a candidate set of significant input variables is one of the most important steps to ensure suitable characteristics of ai models mohanty et al 2009 although there is no rule of thumb to reveal the appropriate lag length of the time series to determine the input pattern in forecasting models the autocorrelation and cross correlation evaluation can be considered as demonstrated in previous hydrological prediction studies tiwari and adamowski 2013 the evaluation of autocorrelation coefficients for the tds and discharge time series related to the training and testing time series shows that the 1 month lag autocorrelation coefficient is significant in comparison with the 2 and 3 month lag autocorrelations their coefficient values are close to zero the 4 month lag autocorrelation coefficients for both testing and training times series tend to be negative and due to the significant negative impact on the forecasting results it can be neglected in the input pattern combinations as shown in table 3 the cross correlation coefficients between the current month td s t and current month discharge q t and 1 month lag q t 1 are relatively high whereas the cross correlation coefficients between td s t and 2 month lag q t 2 and 3 month lag q t 3 are low in addition the cross correlation is unable to capture nonlinear dependence between variables and may eliminate some significant inputs that have a nonlinear relationship with the output maier and dandy 1998 despite the low correlation with dt s t the discharges with a lag of more than one month e g q t 2 q t 3 are used in the formation of the input combinations according to the outcome of the metric analyses table 3 seven combinations of the monthly tds and the current and time lagged discharges are considered as appropriate inputs to estimate the current tds using the developed ai models as follows i td s t 1 q t ii td s t 1 q t q t 1 iii td s t 1 t d s t 2 q t q t 1 iv td s t 1 t d s t 2 q t q t 1 q t 2 v d s t 1 t d s t 2 q t q t 1 q t 2 q t 3 vi td s t 1 t d s t 2 t d s t 3 q t q t 1 q t 2 vii td s t 1 t d s t 2 t d s t 3 q t q t 1 q t 2 q t 3 4 proposed wavelet multigene genetic programming method in this research the w mggp model is developed by combining the dwt and mggp models to do so the datasets of q and tds are composed into several sub datasets to decompose a dataset using the wavelet transform it is very important to choose a mother wavelet and a decomposition level for modeling according to nourani et al 2014 the mother wavelet db4 is the most efficient in producing time localization properties for time series in addition the mother wavelets of bior6 8 and dmey are the best for decomposing hydrological time series de freire et al 2019 thus these three mother wavelets i e db4 bior6 8 and dmey are chosen to decompose the water quality time series the selection of the decomposition levels of the wt is determined by adamowski and chan 2011 18 m i n t log k where k is the number of the datasets k 240 so m is equal to 2 therefore two wavelet decomposition levels are chosen using the dwt the datasets of q t and td s t are decomposed into the details q t d 1 q t d 2 for q t and td s t d 1 t d s t d 2 for td s t and approximations q t a 2 for q t and td s t a 2 for td s t fig 5 depicts the decomposition of the original tds and q time series into the associated details and approximations 5 results and discussion the efficiencies of the mggp w mggp gep and w gep models were compared and evaluated their statistical performance results for the seven input combinations are shown in tables 4 and 5 for the mggp model table 4 combination 6 which used the tds of the first second and third successive previous months and the q of the current first and second successive previous months as inputs yielded a better performance than the other combinations in terms of r 0 396 rmse 239 718 and nse 0 032 for the gep model table 4 combination 5 yielded more suitable results than the other combinations in terms of r 0 433 rmse 263 414 and nse 0 169 table 5 shows the statistical results of the w mggp and w gep models with the three mother wavelets db4 bior6 8 and dmey for the seven combinations combination 6 had the best performance for all models with different mother wavelets except combination 7 in the w mggp model with the mother wavelet dmey in addition the w mggp model with the mother wavelet dmey yielded the best results in terms of r 0 942 rmse 90 383 and nse 0 862 compared with the w mggp model with the mother wavelets db4 and bior6 8 the w gep model with the mother wavelet dmey provided better results than the w gep model with the other mother wavelets the superiority of the dmey mother wavelet can be mainly attributed to its high ability to explore the low and high frequencies of the time series dataset therefore it can provide a suitable informative detail of the hidden pattern in the dataset it is noteworthy that the w mggp with the mother wavelet bior6 8 yielded more suitable results in terms of r 0 898 rmse 109 850 and nse 0 797 than the w mggp model with the mother wavelet db4 r 0 875 rmse 121 670 and nse 0 751 fig 6 depicts the effects of each implemented mother wavelet on the hybridized models for the seven input pattern combinations using the rmse criterion it can be observed that the hybridized dmey mother wavelet with the mmgp model provided a lower rmse and consequently more accurate prediction of the monthly tds than other developed models to further evaluate the accuracy of the developed ai models the taylor diagrams of the hybrid wavelet mggp w mggp and wavelet gep w gep were created for both training and testing stages fig 7 as shown in fig 7 combinations 6 and 7 provided more accurate forecasts of the monthly tds than other combinations however the taylor diagrams showed the superior performance of the w mggp model using the mother wavelet dmey in contrast to other hybridizations in the prediction of the monthly tds the cumulative frequency of absolute relative errors was also computed for combination 6 as shown in fig 8 more than 80 of the monthly tds values predicted by using the hybrid mother wavelet dmey and the mggp model had an absolute relative error lower than 21 3 whereas less than 80 of the tds values predicted by the hybridized mother wavelet dmey and the gep model had an absolute relative error lower than 24 0 note that among all the models the hybridized mother wavelet db4 and the gep model had the highest absolute relative error up to 36 for 80 of the predicted tds data points hence it can be concluded that the mother wavelet dmey provided the best results due to its better decomposition for specifying the low and high pass frequencies than the bior6 8 and db4 tables 6 and 7 show the different statistical results of the mggp w mggp gep and w gep models for the training and testing stages respectively as shown in table 6 the w mggp model presented the best results with the highest r 0 962 nse 0 925 and ia 0 980 and the smallest rmse 65 325 mape 7 346 mae 50 752 rae 0 281 and si 0 085 for the training stage the w gep with r 0 909 rmse 104 349 nse 0 807 mape 11 195 mae 76 967 rae 0 426 si 0 135 and ia 0 952 was the best among the gep models including w gep and gep for the training stage accordingly the best mggp model i e w mggp provided better results than the best gep model i e w gep for the training stage for the testing stage the statistical metrics of the w mggp mggp w gep and gep models indicated that the w mggp model had the highest r 0 942 nse 0 862 and ia 0 966 and the smallest rmse 90 383 mape 14 548 mae 75 034 rae 0 372 and si 0 139 table 7 the w mggp model showed the best predictability efficiency in comparison with the other models based on the ranking values listed in table 7 the w mggp and w gep models respectively had the first and second ranks overall from the statistical results in tables 6 and 7 it can be evidenced that the proposed w mggp predictive model provided more promising results than the three other models in the prediction of the tds levels figs 9 and 10 depict the comparisons of the tds simulations of the mggp w mggp gep and w gep models against the observed data for the testing and training periods it can be observed that the simulations of the w mggp and w gep models were closer to the corresponding observed tds values than those of the mggp and gep models it can also be concluded that the wavelet decomposition effectively promoted the performances of the mggp and gep models in the prediction of tds as indicated in the scatterplots of the observed and predicted tds values for the four models during the testing and training periods in figs 9 and 10 the tds data points for the w mggp and w gep models are closer to the 45 straight line i e 1 1 line than those from the mggp and gep models which confirms the higher efficiency of these two models in the water quality modeling especially the w mggp model generated a better prediction of tds than the w gep gep and mggp models the current research was devoted to the simulation of the tds of river water using the discharge data and the antecedent values the modeling results proved the significance of the use of the river discharge as hydrologic data the incorporation of the hydrometeorological data for modeling river water quality using the machine learning models can assist the representative authorities for better river management environmental assessment and sustainable development 6 conclusions in the current study a hybrid wavelet multigene genetic programming w mggp model using three mother wavelets db4 bior6 8 and dmey was developed to simulate the monthly tds levels of river water particularly the w wggp was compared with the w gep mggp and gep model and their efficiencies and performances were evaluated the time series of river discharge and tds over a 20 years period were utilized for the development of the predictive models statistical analysis i e autocorrelation and cross correlation of the time series demonstrated that up to three time lagged q t q t 1 q t 2 q t 3 tds t 1 tds t 2 and tds t 3 and two decomposition levels for each mother wavelet were appropriate to the developed models for prediction of monthly tds in the sefid rud river the results showed that in the testing phase the mggp model with combination 6 r 0 396 and rmse 239 718 and the gep model with combination 5 r 0 433 and rmse 263 414 had the best performances compared with other models and combinations of the inputs coupling the wavelet analysis with the mggp and gep methods was examined by using various statistical metrics revealing a remarkable promotion in the performance of the prediction of the tds levels according to the statistical metrics the w mggp r 0 942 rmse 90 383 using the mother wavelet dmey for combination 7 provided the most accurate prediction of the monthly tds whereas the w gep r 0 927 rmse 993 275 with the mother wavelet dmey for combination 6 was the best among the different combinations and mother wavelets all the statistical metrics and graphical comparisons confirmed that the w mggp model developed in this study as the main novel contribution was superior to the other models including w gep mggp and gep in the prediction of the tds levels the mother wavelet dmey was more efficient in hybridization of the mggp model than the mother wavelets bior 6 8 and db4 the combination of the capabilities of the gp model with the weighted linear model in the mggp and its hybridization with the wavelet transfer model created a novel and powerful model compared with the other models the results obtained from w mggp and w gep also indicated that the mother wavelet bior6 8 yielded better predictions of monthly tds than the mother wavelet db4 for future work other variants of the gp model such as linear genetic programming lgp can be hybridized with the wavelet transfer model and compared with the models introduced in this study also a multi objective version of the mggp can be developed and used for water quality modeling furthermore the uncertainty analyses of the related datasets and models can be performed chen and chau 2019 shamshirband et al 2019 credit authorship contribution statement mehdi jamei conceptualization data curation formal analysis investigation methodology project administration resources supervision validation visualization writing original draft writing review editing iman ahmadianfar conceptualization data curation formal analysis investigation methodology project administration resources software supervision validation visualization writing original draft writing review editing xuefeng chu conceptualization investigation supervision validation visualization writing original draft writing review editing zaher mundher yaseen conceptualization formal analysis investigation supervision validation visualization writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge their appreciation for the dataset provider guilan regional water company in addition the authors are very much thankful for the editors and reviewers for their constructive comments and suggestions 
5291,total dissolved solids tds are recognized as an essential indicator of surface water quality the current research investigates the potential of a novel computer aid approach based on the hybridization of wavelet pre processing with multigene genetic programming w mggp for monthly tds prediction at the sefid rud river in northern iran 20 year historical monthly river flow q and tds data measured at the astaneh station were used for the model training and testing the employed time series data were decomposed into several sub series using three mother wavelets i e daubechies4 db4 biorthogonal bior6 8 and discrete meyer dmey to assess appropriate combinations of the time series and their lag times which were further used for prediction process the w mggp model was compared against the wavelet gene expression programming w gep stand alone mggp and gep models results were evaluated using several performance metrics including root mean square error rmse correlation coefficient r and nash sutcliffe efficiency nse modeling results indicated that w mggp and w gep provided a superior prediction capacity for the tds in comparison with the other stand alone artificial intelligence ai models the discrete meyer method exhibited the best performance in time series data decomposition as a pre processing approach the proposed w mggp model based on the dmey mother wavelet attained the best statistical metrics r 0 942 rmse 90 383 and nse 0 862 the research findings demonstrated the hybridization of the wavelet pre processing approach with mggp predictive model for the tds simulation keywords water quality total dissolved solids wavelet multigene genetic programming wavelet analysis river engineering 1 introduction river water is recognized as one of the essential fresh surface waters that is available naturally to supply multiple human usage such as drinking irrigation and industrial production purposes monitoring and management of surface water quality wq play an undeniable role in environmental protection and sustainable use of these water resources ahmadianfar et al 2020 over the past few decades efforts have been devoted to improving wq management and sustainability through the precise simulation of the physical chemical and biological processes of various pollutants total dissolved solid tds is a well accepted indicator for the wq that is effectively used for assessing the suitability of drinking and irrigation water supply tds consists of a variety of inorganic salts e g sodium na magnesium mg 2 calcium ca 2 and potassium k as cations as well as chloride cl sulfate so4 2 nitrates no 3 and bicarbonates hco 3 as anions and dissolved organic matter based on the reported standard by the world health organization who the acceptable range of tds for drinking water is 300 600 mg l who 2011 also the permissible water concentration range of tdsfor agriculture is 450 2000 mg l ayers and westcot 1985 laboratory investigations and empirical calculation methods have been reported for the tds quantification tiyasha et al 2020 however its laboratory test or the manual calculation is associated with some drawbacks such as time consuming unintentional errors and the generalization for the perfect computation the potential of the ai models exhibited a remarkable advancement on modeling tds of river wq banadkooki et al 2020 the massive implementation of the ai models is due to some limitations that have been recognized in the classical mathematical models in addition to the high stochasticity pattern associated with the wq abba et al 2020 in addition the classical models can only provide predictions for a linear and stationary state of a dataset deng et al 2015 the capacity of the ai models is reported in their potential to handle the non linearity and complexity phenomena of the environmental and hydrological processes overcoming the drawback of the traditional models alizadeh et al 2018 das et al 2020 gholami et al 2016 maier et al 2014 naganna and deka 2019 rezaie balf et al 2019 tiyasha et al 2020 wu and chau 2013 the ai models have been positively employed to address a variety of water quality issues such as water quality index wqi dissolved oxygen do nitrate no3 electrical conductivity ec chemical oxygen demand cod biochemical oxygen demand bod ammoniacal nitrogen nh3 n ph and sodium adsorption ratio sar tiyasha et al 2020 the examples of these ai models include artificial neural network ann support vector machine svm adaptive neuro fuzzy inference system anfis random forest rf decision tree dt genetic programming gp linear genetic programming lgp extreme learning machine elm and gene expression programming gep ay and kisi 2014 azad et al 2017 emamgholizadeh et al 2014 heydari et al 2013 olyaie et al 2017 sengorur et al 2015 sepahvand et al 2019 takdastan et al 2018 tiwari et al 2018 recently the capacity of the svm model was tested to assess different wq variables in rivers mahmoudi et al 2016 to forecast the carlson s trophic state index in reservoirs chou et al 2018 and to predict some wq parameters in the sefid rud river basin in iran bozorg haddad et al 2017 the gep dt and lgp were used to forecast tds levels in the zarinehroud basin in iran zaman zad ghavidel and montaseri 2014 and to assess bod do and cod in the karoun river in iran najafzadeh et al 2018 wq time series data are highly stochastic and chaotic implementation of an individual ai based model has limitations for wq modeling yaseen et al 2018 hence the integration of the time series data pre processing approaches can facilitate decomposition of the time series and improve the predictability performance of the ai models among several powerful data pre processing techniques the discrete wavelet transform dwt has been demonstrated a satisfactory approach for decomposition of environmental hydrological and ecological time series data nourani et al 2014 by providing a time frequency representation of an analyzed signal of time series in the time domain and the information about the physical structure of the input time series the wavelet transform can successfully lead to an accurate prediction especially when input data are limited ghimire et al 2019 recently some researchers investigated the possibility and the advantage of integrating the wavelet transform wt approach with ai based models for diverse river wq simulations barzegar et al 2017 2016 integrated wt with elm anifs and ann models to predict ec and salinity research findings evidenced the improvement of the prediction accuracy using the pre processing approach several other researchers conducted similar studies on the integration of the wt with ai models and demonstrated its successful implementation for river wq simulations montaseri et al 2018 rajaee et al 2018 ravansalar et al 2016b a ravansalar and rajaee 2015 these studies indicated that the hybridization of the wt with ai models presented an optimistic new computer aid approach for environmental modeling the enthusiasm of the exploration of new robust and reliable soft computing predictive models is a new modeling trend for better watershed management and sustainability in the current state of the art research a new hybrid artificial intelligence model called wavelet multigene genetic programming w mggp is developed for accurately predicting the monthly tds levels at the sefid rud river in iran the selection of the mggp model is owing to its feasibility in modeling highly non linear time series mehr and safari 2020 mohammad azari et al 2020 in this study the influence of the discrete wavelet transform is explored in combination with the mggp and gep models the capacity of the new version of gp and mggp has been employed for limited hydrological and environmental forecasting dadandeh mehr and demirel 2016 danandeh mehr and nourani 2017 and thus the current research is devoted to the tds prediction 2 materials and methods 2 1 multigene genetic programming gp is an optimization technique that utilizes the principle of darwin s theory gandomi et al 2010 the principle of gp is similar to that of the genetic algorithm ga and thus both methods use the three main operators crossover mutation and selection danandeh mehr et al 2018 the main difference between these two methods is how to present solutions the ga presents solutions by strings with fixed lengths while the gp expresses the solutions by tree structures with varying sizes garg et al 2014 the gp method begins by producing a set of models randomly these models are created by combining the components that are called functions f and terminals t a set of f involve the basic arithmetic operators ã e t c whereas a set of t consist of numerical constants and input variables of a problem fig 1 a depicts an example of the tree structure in a model the efficiency of preliminary population on the input variables training dataset with the objective function is verified by using the root mean square error rmse 1 rmse k 1 k y a k y p k 2 k where y a k is the actual value of the kth data point y p k is the predicted value of the kth data point and k is the total number of data points of the training dataset the gp algorithm chooses models based on the selection of the genetic operators crossover and mutation based on these operators new population is created for new generation this iterative process of optimization in the gp algorithm continues till the satisfactory criterion is achieved in the current research the maximum number of generations is considered as the termination criterion mggp models is demonstrated as an effective and reliable version of the gp method gandomi and alavi 2011 unlike the conventional gp which relies on the assessment of an individual tree the mggp model is formed by a weighted linear combination of the output variables from a number of trees in the gp method gandomi and alavi 2011 garg et al 2014 in this method each tree is considered as a gene which is a gp tree the main procedure adopted for the mggp model development is summarized as follows step 1 set the initial parameters such as functions and terminals population size number of generations rate of genetic operators and maximum number of genes step 2 randomly initiate an initial population of genes step 3 form a model based on a set of genes step 4 investigate the efficiency of models using the objective function rmse step 5 generate new population using the genetic operators step 6 check the stopping criterion and go back to step 5 if it is not satisfied fig 1b shows the typical formulation of the mggp model the model estimates an output variable utilizing three input variables x 1 x 2 and x 3 and four regression coefficients w 0 w 1 w 2 and w 3 the coefficients are specified by the least squares method for each multi gene the control parameters of the developed mggp model are tabulated in table 1 2 2 gene expression program gep gep is an evolutionary algorithm ferreira 2006 and is an extension of genetic programming koza and koza 1992 and has some properties of the genetic algorithm goldberg and holland 1988 indeed the gep uses the benefits of the ga and gp methods simultaneously this method expresses the chromosomes as linear strings that are then demonstrated as tree forms in the proposed method a chromosome involves one or more genes each of which is divided into a head and a tail the head involves the function operators such as ã and or the terminal components such as x y 5 whereas the tail includes the terminal components only ferreira 2006 the values of the main control parameters used in the gep method are shown in table 2 the development of the gep consists of four main steps step 1 in the first step function operators and terminal components are selected to generate the genes in this study the mathematical functions are power sin cos and the terminal components are six independent variables including td s t 1 t d s t 2 t d s t 3 q t q t 1 q t 2 a n d q t 3 step 2 to create the new population in the gep similar to the ga three main operators are used crossover mutation and transposition step 3 the fitness function f k of the k th program is defined as 2 f k l 1 c k r v c k l v t l where r is the range of selection v c k l is a value designed by using the k th individual chromosome for fitness function l and v t l is the target value for fitness function l step 4 the termination criterion is checked if it is satisfied the optimization process in the gep is stopped otherwise go back to step 2 note that in this study the termination criterion is the maximum number of generations 2 3 discrete wavelet transform dwt wt is one of the widely used signal processing methods achieved by utilizing the fourier transform ft heddam and kisi 2017 the wt analyzes the time series dataset in the frequency and time domains by decomposing the dataset into low and high frequency elements this decomposition process provides an informative detail of the unseen pattern in the historical time series data which can be used for prediction by using the data mining methods thus the wt method can increase the computational accuracy of the data mining methods the wt has received a noticeable popularity for solving diverse environmental and hydrological engineering problems nourani et al 2014 the wt is applied to express a function by a set of functions termed as the mother wavelet ψ b c t zhang et al 2004 3 ψ b c t b 1 2 ψ t c b b c r b 0 where b is a dilation factor c is a translation factor and t is time therefore the wt function f t l 2 r can be written as 4 w ψ f b c b 1 2 r f t ψ t c b d t where ψ t denotes the complex conjugate function of ψ t ψ b c t is often a discrete function in hydrological and water quality applications kisi and cimen 2012 for b b 0 k c l c 0 b 0 k b 0 1 c 0 r l and k are integer numbers therefore the discrete wavelet transform dwt of f t is defined as 5 w ψ f k l b 0 k 2 r f t ψ b 0 k t l c 0 d t generally 2 and 1 are selected for the factors b 0 and c 0 respectively kisi and cimen 2012 accordingly eq 5 becomes 6 w ψ f k l 2 k 2 r f t ψ 2 k t l d t regarding a discrete water quality variable f t i e tds in this study the dwt can be expressed as 7 w ψ f k l 2 k 2 t 0 n f t ψ 2 k t l the term of w ψ f k l denotes the characteristics of the original time series with the dilation factor b and translation domain c dwt decomposes the input dataset into low pass and high pass filters which yields two vectors the approximation a and the details d the framework of w mggp w gep and w mlp is depicted in fig 2 2 4 performance metrics eight statistical performance metrics are computed and used for the modeling evaluation they include correlation coefficient r as an indicator to describe the linear relationship between the measured and forecasted variables wang et al 2009 root mean square error rmse nash sutcliffe efficiency nse coefficient nash and sutcliffe 1970 mean absolute percentage error ma pe mean absolute error mae relative absolute error rae scatter index si and willmott s index of agreement i a willmott 1982 which are respectively defined as follows 8 r i 1 k td s o i tds o td s s i tds s i 1 k td s o i tds o 2 i k td s s i tds s 2 9 rmse 1 k i 1 k td s s i td s o i 2 0 5 10 nse 1 i 1 k td s o i t d s s i 2 i 1 k td s o i tds o 2 11 mape 100 k i 1 k td s o i td s s i td s o i 12 mae i 1 k td s s i td s o i k 13 rae i 1 k td s s i td s o i i 1 k t d s o i tds o 14 si r m s e tds o 15 i a 1 i k td s o i t d s s i 2 i 1 k td s s i tds o td s o i tds o 2 0 i a 1 where k is the total number of datasets td s o i is the ith observed tds value td s s i is the i th simulated tds value tds o and tds s respectively are the average observed and simulated tds values moreover the taylor diagram is utilized to visually assess the similarity between the developed ai based methods and observations in terms of their correlation their centered root mean square error crmse difference and the standard deviations taylor 2001 the taylor diagram was originally used as a visual representation of the observed and predicted data in climatology which can clearly highlight the accuracy of various predictive ai models compared to the observed data as a series of points on a polar plot the azimuthal angle refers to the correlation coefficient the proportional distance to the actual data on the x axis denotes the crmse and the radial distance of the predicted point from the origin on the x axis refers to the amplitude of the standard deviation σ the standard deviations of the observed and predicted tds values and the crmse are given as follows 16 σ o 2 1 k i 1 k td s o i tds o 2 σ s 2 1 k i 1 k td s s i tds s 2 17 crms e 2 σ o 2 σ s 2 2 r σ o σ s 3 case study and data analysis in this study the data monthly time scale are related to the astane gauging station located on the sefid rud river longitude 49 37 40 latitude 36 57 02 the observed data are employed to build the ai based models for tds prediction the sefid rud river has a length of 670 km and a drainage area of 13 450 km2 it is the longest river in northern iran in this study monthly discharge and tds data were obtained over a 20 year period 1985 2005 240 months fig 3 displays the location of the astane station each dataset was further divided into a 168 month sub dataset 1985 1999 for training and a 72 month sub dataset 2000 2005 for testing with a monthly time step for both periods the monthly discharge and tds time series over the 20 year period for testing red line and training black line are displayed in fig 4 the optimal input pattern and the most appropriate combination of time series and their lag times are obtained by using descriptive statistics autocorrelation regarding each time lag and cross correlation coefficient between the tds and discharge q values the statistical parameters of the time series of q and tds used in this study are listed in table 3 the parameters include mean standard deviation σ minimum median maximum skewness kurtosis autocorrelation of various lag times for the time series r 1 r 2 r 3 r 4 and cross correlation coefficients between the current monthly tds and the current and time lagged discharge data q t q t 1 q t 2 and q t 3 these statistical metrics clearly indicate that the testing and training datasets follow a similar trend as shown in table 3 the standard deviation values for the training and testing tds time series are close to each other and their skewness coefficients are also small and hence they are suitable for the predictive ai models moreover the skewness and kurtosis coefficients for both training and testing discharge datasets indicate a normal distribution note that the inputs play a key role in the ai model development process therefore specifying a candidate set of significant input variables is one of the most important steps to ensure suitable characteristics of ai models mohanty et al 2009 although there is no rule of thumb to reveal the appropriate lag length of the time series to determine the input pattern in forecasting models the autocorrelation and cross correlation evaluation can be considered as demonstrated in previous hydrological prediction studies tiwari and adamowski 2013 the evaluation of autocorrelation coefficients for the tds and discharge time series related to the training and testing time series shows that the 1 month lag autocorrelation coefficient is significant in comparison with the 2 and 3 month lag autocorrelations their coefficient values are close to zero the 4 month lag autocorrelation coefficients for both testing and training times series tend to be negative and due to the significant negative impact on the forecasting results it can be neglected in the input pattern combinations as shown in table 3 the cross correlation coefficients between the current month td s t and current month discharge q t and 1 month lag q t 1 are relatively high whereas the cross correlation coefficients between td s t and 2 month lag q t 2 and 3 month lag q t 3 are low in addition the cross correlation is unable to capture nonlinear dependence between variables and may eliminate some significant inputs that have a nonlinear relationship with the output maier and dandy 1998 despite the low correlation with dt s t the discharges with a lag of more than one month e g q t 2 q t 3 are used in the formation of the input combinations according to the outcome of the metric analyses table 3 seven combinations of the monthly tds and the current and time lagged discharges are considered as appropriate inputs to estimate the current tds using the developed ai models as follows i td s t 1 q t ii td s t 1 q t q t 1 iii td s t 1 t d s t 2 q t q t 1 iv td s t 1 t d s t 2 q t q t 1 q t 2 v d s t 1 t d s t 2 q t q t 1 q t 2 q t 3 vi td s t 1 t d s t 2 t d s t 3 q t q t 1 q t 2 vii td s t 1 t d s t 2 t d s t 3 q t q t 1 q t 2 q t 3 4 proposed wavelet multigene genetic programming method in this research the w mggp model is developed by combining the dwt and mggp models to do so the datasets of q and tds are composed into several sub datasets to decompose a dataset using the wavelet transform it is very important to choose a mother wavelet and a decomposition level for modeling according to nourani et al 2014 the mother wavelet db4 is the most efficient in producing time localization properties for time series in addition the mother wavelets of bior6 8 and dmey are the best for decomposing hydrological time series de freire et al 2019 thus these three mother wavelets i e db4 bior6 8 and dmey are chosen to decompose the water quality time series the selection of the decomposition levels of the wt is determined by adamowski and chan 2011 18 m i n t log k where k is the number of the datasets k 240 so m is equal to 2 therefore two wavelet decomposition levels are chosen using the dwt the datasets of q t and td s t are decomposed into the details q t d 1 q t d 2 for q t and td s t d 1 t d s t d 2 for td s t and approximations q t a 2 for q t and td s t a 2 for td s t fig 5 depicts the decomposition of the original tds and q time series into the associated details and approximations 5 results and discussion the efficiencies of the mggp w mggp gep and w gep models were compared and evaluated their statistical performance results for the seven input combinations are shown in tables 4 and 5 for the mggp model table 4 combination 6 which used the tds of the first second and third successive previous months and the q of the current first and second successive previous months as inputs yielded a better performance than the other combinations in terms of r 0 396 rmse 239 718 and nse 0 032 for the gep model table 4 combination 5 yielded more suitable results than the other combinations in terms of r 0 433 rmse 263 414 and nse 0 169 table 5 shows the statistical results of the w mggp and w gep models with the three mother wavelets db4 bior6 8 and dmey for the seven combinations combination 6 had the best performance for all models with different mother wavelets except combination 7 in the w mggp model with the mother wavelet dmey in addition the w mggp model with the mother wavelet dmey yielded the best results in terms of r 0 942 rmse 90 383 and nse 0 862 compared with the w mggp model with the mother wavelets db4 and bior6 8 the w gep model with the mother wavelet dmey provided better results than the w gep model with the other mother wavelets the superiority of the dmey mother wavelet can be mainly attributed to its high ability to explore the low and high frequencies of the time series dataset therefore it can provide a suitable informative detail of the hidden pattern in the dataset it is noteworthy that the w mggp with the mother wavelet bior6 8 yielded more suitable results in terms of r 0 898 rmse 109 850 and nse 0 797 than the w mggp model with the mother wavelet db4 r 0 875 rmse 121 670 and nse 0 751 fig 6 depicts the effects of each implemented mother wavelet on the hybridized models for the seven input pattern combinations using the rmse criterion it can be observed that the hybridized dmey mother wavelet with the mmgp model provided a lower rmse and consequently more accurate prediction of the monthly tds than other developed models to further evaluate the accuracy of the developed ai models the taylor diagrams of the hybrid wavelet mggp w mggp and wavelet gep w gep were created for both training and testing stages fig 7 as shown in fig 7 combinations 6 and 7 provided more accurate forecasts of the monthly tds than other combinations however the taylor diagrams showed the superior performance of the w mggp model using the mother wavelet dmey in contrast to other hybridizations in the prediction of the monthly tds the cumulative frequency of absolute relative errors was also computed for combination 6 as shown in fig 8 more than 80 of the monthly tds values predicted by using the hybrid mother wavelet dmey and the mggp model had an absolute relative error lower than 21 3 whereas less than 80 of the tds values predicted by the hybridized mother wavelet dmey and the gep model had an absolute relative error lower than 24 0 note that among all the models the hybridized mother wavelet db4 and the gep model had the highest absolute relative error up to 36 for 80 of the predicted tds data points hence it can be concluded that the mother wavelet dmey provided the best results due to its better decomposition for specifying the low and high pass frequencies than the bior6 8 and db4 tables 6 and 7 show the different statistical results of the mggp w mggp gep and w gep models for the training and testing stages respectively as shown in table 6 the w mggp model presented the best results with the highest r 0 962 nse 0 925 and ia 0 980 and the smallest rmse 65 325 mape 7 346 mae 50 752 rae 0 281 and si 0 085 for the training stage the w gep with r 0 909 rmse 104 349 nse 0 807 mape 11 195 mae 76 967 rae 0 426 si 0 135 and ia 0 952 was the best among the gep models including w gep and gep for the training stage accordingly the best mggp model i e w mggp provided better results than the best gep model i e w gep for the training stage for the testing stage the statistical metrics of the w mggp mggp w gep and gep models indicated that the w mggp model had the highest r 0 942 nse 0 862 and ia 0 966 and the smallest rmse 90 383 mape 14 548 mae 75 034 rae 0 372 and si 0 139 table 7 the w mggp model showed the best predictability efficiency in comparison with the other models based on the ranking values listed in table 7 the w mggp and w gep models respectively had the first and second ranks overall from the statistical results in tables 6 and 7 it can be evidenced that the proposed w mggp predictive model provided more promising results than the three other models in the prediction of the tds levels figs 9 and 10 depict the comparisons of the tds simulations of the mggp w mggp gep and w gep models against the observed data for the testing and training periods it can be observed that the simulations of the w mggp and w gep models were closer to the corresponding observed tds values than those of the mggp and gep models it can also be concluded that the wavelet decomposition effectively promoted the performances of the mggp and gep models in the prediction of tds as indicated in the scatterplots of the observed and predicted tds values for the four models during the testing and training periods in figs 9 and 10 the tds data points for the w mggp and w gep models are closer to the 45 straight line i e 1 1 line than those from the mggp and gep models which confirms the higher efficiency of these two models in the water quality modeling especially the w mggp model generated a better prediction of tds than the w gep gep and mggp models the current research was devoted to the simulation of the tds of river water using the discharge data and the antecedent values the modeling results proved the significance of the use of the river discharge as hydrologic data the incorporation of the hydrometeorological data for modeling river water quality using the machine learning models can assist the representative authorities for better river management environmental assessment and sustainable development 6 conclusions in the current study a hybrid wavelet multigene genetic programming w mggp model using three mother wavelets db4 bior6 8 and dmey was developed to simulate the monthly tds levels of river water particularly the w wggp was compared with the w gep mggp and gep model and their efficiencies and performances were evaluated the time series of river discharge and tds over a 20 years period were utilized for the development of the predictive models statistical analysis i e autocorrelation and cross correlation of the time series demonstrated that up to three time lagged q t q t 1 q t 2 q t 3 tds t 1 tds t 2 and tds t 3 and two decomposition levels for each mother wavelet were appropriate to the developed models for prediction of monthly tds in the sefid rud river the results showed that in the testing phase the mggp model with combination 6 r 0 396 and rmse 239 718 and the gep model with combination 5 r 0 433 and rmse 263 414 had the best performances compared with other models and combinations of the inputs coupling the wavelet analysis with the mggp and gep methods was examined by using various statistical metrics revealing a remarkable promotion in the performance of the prediction of the tds levels according to the statistical metrics the w mggp r 0 942 rmse 90 383 using the mother wavelet dmey for combination 7 provided the most accurate prediction of the monthly tds whereas the w gep r 0 927 rmse 993 275 with the mother wavelet dmey for combination 6 was the best among the different combinations and mother wavelets all the statistical metrics and graphical comparisons confirmed that the w mggp model developed in this study as the main novel contribution was superior to the other models including w gep mggp and gep in the prediction of the tds levels the mother wavelet dmey was more efficient in hybridization of the mggp model than the mother wavelets bior 6 8 and db4 the combination of the capabilities of the gp model with the weighted linear model in the mggp and its hybridization with the wavelet transfer model created a novel and powerful model compared with the other models the results obtained from w mggp and w gep also indicated that the mother wavelet bior6 8 yielded better predictions of monthly tds than the mother wavelet db4 for future work other variants of the gp model such as linear genetic programming lgp can be hybridized with the wavelet transfer model and compared with the models introduced in this study also a multi objective version of the mggp can be developed and used for water quality modeling furthermore the uncertainty analyses of the related datasets and models can be performed chen and chau 2019 shamshirband et al 2019 credit authorship contribution statement mehdi jamei conceptualization data curation formal analysis investigation methodology project administration resources supervision validation visualization writing original draft writing review editing iman ahmadianfar conceptualization data curation formal analysis investigation methodology project administration resources software supervision validation visualization writing original draft writing review editing xuefeng chu conceptualization investigation supervision validation visualization writing original draft writing review editing zaher mundher yaseen conceptualization formal analysis investigation supervision validation visualization writing original draft writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge their appreciation for the dataset provider guilan regional water company in addition the authors are very much thankful for the editors and reviewers for their constructive comments and suggestions 
5292,internal erosion phenomena are a major threat to all earthen structures such as river levees and dams studying these phenomena has been limited because they occur concealed inside the material which makes them difficult to observe and monitor non destructive geophysical monitoring techniques are powerful tools that can provide insight into the processes involved for this reason a test rig has been specifically designed to conduct three dimensional electrical resistivity tomography of soil specimens undergoing internal erosion due to seepage two suffusion tests were conducted where the erosion evolution has been monitored the time series of eroded mass weight were then used to correlate the changes in three dimensional resistivity distribution to the porosity change in media by means of archie s law the results from the first suffusion test were used to calibrate archie s model parameters it was found that the resistivity variations were able to predict changes in the porous matrix structure the data obtained from the second test were used to validate the model parameters and confirmed that the time lapse three dimensional inverted resistivity images were able to successfully quantify the global erosion rate keywords ert resistivity imaging archie s law embankment dams internal erosion suffusion 1 introduction internal erosion in earthen structures occurs when soil particles within the porous medium are transported by seeping water bonelli and nicot 2013 it represents a serious threat to the structural stability of embankment dams because the erosion process takes place deep inside the structure or its foundation wan and fell 2008 the hidden nature of internal erosion makes it both hard to detect as well as limiting the possibility of its investigation here the main problem is the common use of destructive methods to sample the affected soil regions both under field and laboratory conditions there is a pressing need for detection methodologies that can preserve the soil sample in laboratory or in field cases fell et al 2003 geophysical methods are proven to be effective for identifying potential zones for internal erosion without causing any destruction in material the most common methods are ground penetrating radar gpr self potential sp electrical resistivity tomography ert electromagnetic em methods active and passive seismic methods as well as lidar and other remote sensing techniques among these only electrical ert sp and electromagnetic em gpr methods are directly sensitive to the presence of water in the embankment structure ikard et al 2012 panthulu et al 2001 gpr methods have the advantage of providing good resolution of the internal structures and are widely used for mapping lithological and sedimentological characterisation of quaternary deposit properties bakker and van der meer 2003 carlsten et al 1995 smith and jol 1992 trafford 2009 the gpr s signals however get severely attenuated when layers of fine grained soil are present the latter is a prevailing property of earthen structures specifically when the erosion susceptible zones are considered however sp and ert methods are found to be more appropriate for structures that contain fine grained soils hirsch et al 2008 sp and ert are widely used to locate leakage prone and susceptible zones of embankment dams al fares 2014 2011 bolève et al 2011 dahlin and johansson 1995 ikard et al 2015 panthulu et al 2001 rittgers et al 2014 shin et al 2019 sjödahl et al 2008 soueid ahmed et al 2020 titov et al 2000 the ert based techniques have numerous advantages they are cost effective and easy to implement in the field they can cover large earth volumes and the measurement can be performed repeated over time time lapse and they do not require to be supervised i e can be remotely operated moreover they are highly sensitive to electrical conductivity contrasts commonly found in the materials used for embankments construction on the other hand the fact that the method is subjected to site specific conditions and that the success of the study necessarily requires the integration of adequately large data collected for the specific case are considered to be among the main disadvantages dahlin et al 2001 conducted resistivity and sp studies based on the surveying and monitoring data at the sädva embankment in sweden with the aim of to providing baseline information for evaluation of the sp monitoring data the anomalies found in the collected sp data were correlated to known features of the dam construction while the other investigated areas presented smooth results with no major anomalies panthulu et al 2001 used the same method to delineate seepage favourable zones for two of the saddle dams of the som kamla amba in india a combination of sp method with salt tracer injections was used by bolève et al 2011 for localising seepage prone zones and quantifying the leakages in dams there are also a number of studies that use the method to investigate seepage beneath homogeneous dams e g a number of earth dams in colorado ikard et al 2015 and an embankment dam in california moore et al 2011 ert methods are widely tested in dam monitoring johansson and dahlin 1996 aimed to quantify the seepage and detect anomalous infiltration flow through monitoring seasonal resistivity variations in various case studies in lövon and moforsen embankment dam in sweden similar case studies have been conducted by al fares 2014 2011 for characterizing the water leakage in afamia b and abu baara embankment dams in syria sjödahl et al 2010 2008 2005 performed extensive electrical resistivity investigation and monitoring for detection of internal erosion and anomalous seepage for four embankment dams in scandinavia in all of these studies the measured data from the crest of the dams are inverted to a subsurface geoelectric section by various 2d inversion schemes constable et al 1987 loke and barker 1995 and the anomalous low resistivity zones in these 2d sections were interpreted as leakage zones despite the effectiveness of sp and ert methods the 2d interpretation and quantification of the data are substantially affected by the 3d nature of the acquisition data to overcome this limitation one option is to use cross hole resistivity tomography by imaging the region between two boreholes in depth cross hole data acquisition is done in depth in addition to the dam crest readings to provide the additional data the application of this method are presented in numerous studies e g cho and yeom 2007 daily and owen 1991 lesur et al 1999a b park and van 1991 shima 1992 fargier et al 2014 suggest an alternative method for monitoring an embankment dike with the conventional data acquisition procedure with linear arrays they developed a new extended normalisation technique by providing during inversion a set of pre processed apparent resistivities that are not affected by external 3d effects in this way the artifacts of conventional 2d inversion due to the 3d nature of embankment dike are reduced 3d surveys can also be conducted by using a rectangular grid of electrodes instead of linear array at the surface this method has been reported to provide a good resolution chambers et al 2002 2011 dahlin et al 2002 gharibi and bentley 2005 however irrespective of the method to get a workable resolution a larger number of electrodes are needed in the survey grid as well as the need for a larger number of acquisition combination for this reason some 3d array optimization algorithm must be applied to minimize the number of acquisitions of data registering at multiple electrodes with multichannel instrumentation and filtering out potentially unstable arrays loke et al 2014 here stable and robust time lapse inversion techniques which can be incorporated into automatic inversion software should be used to produce interpretable images the foregoing survey suggests that ert method has the potential to monitor the internal erosion processes and their development in a controlled laboratory environment it can provide insight into the internal erosion processes involved and thereby improving our understanding of the factors that affect the resistivity response when internal erosion phenomena are triggered the main aim of the present work is to investigate these processes by time lapse three dimensional electrical resistivity tomography for this purpose a high resolution resistivity probe system was designed and integrated into an apparatus for studying phenomenon of internal erosion e g suffusion phenomenon at laboratory scale 3d electrical resistivity profiles of soil material were produced so that changes in porous matrix could be visualised and quantified 2 materials and methods 2 1 forward modelling using electrical resistivity tomography the distribution of the electrical properties inside the medium can be determined from a set of measurements taken on the boundary it involves defining a forward model in which the response is calculated by assigning electrical properties to the model elements the governing equation for the ert forward model is the poisson s equation 1 j q j in which j a m 2 denotes the electric current density and qj a m 3 is the boundary current source under electrostatic conditions the electric potential v v can be written as e v where e v m 1 is the electric field the flow of current is given by the ohm s law 2 j σ e in which σ s m 1 is the electric conductivity combining eqs 1 and 2 the ert forward problem can be described by 3 σ δ v q j the physical boundaries of the experimental rig consisted of insulating walls therefore neumann boundary conditions were applied at these surfaces the numerical methods used to solve the forward model will be described in the next sections paragraphs 2 7 and 2 8 2 2 inverse modelling the inverse problem involves the determination of the specific parameter distribution i e resistivity that minimizes the discrepancy between measured and calculated values i e the inverse model is used for the calibration of the forward model the approach of inverse problem solving is a process of calculating from a set of data the causal factors that produced them which in turn is characterized by some degree of non uniqueness for the solution consequently formulation of the inverse model usually requires mathematical regularization of the model parameters by introducing additional constraints to reduce the degrees of freedom and achieve convergence of a unique solution binley 2015 the inverse problem is formulated as an optimization problem involving the minimization of the objective function s defined as 4 s φ d α φ m in which фd represents the chi squared measure of data misfit фm is the model objective function containing the selected regularization scheme and α is the regularization parameter used to control the weight of the regularization with respect to the data misfit for n measured data di with associated standard deviation of εi the chi squared measure of the data misfit is defined as 5 φ d i 1 n d i f i m ε i 2 in which fi denotes the forward model operator and m the vector of parameters for inversion the following scheme referred to as occam s inversion involving minimization of the objective function s is considered 6 s w d d f m 2 α w m m 2 in which wd is the data weighting matrix assumed to be diagonal with diagonal values wi i 1 εi and wm is a first order spatial smoothing operator see kemna 2000 the numerical implementation of the minimization of the objective function eq 6 can be achieved by using an iterative process i e gauss newton algorithm which yields the following iterative equation binley and kemna 2005 7 j t w d t w d j α r δ m j t w d t d f m k α rm in which j is the jacobian such that ji j di mj r is the roughness matrix which describes the connectivity of the parameters and δm the model update at each iteration starting from a model m0 the iteration process mk 1 mk δm is carried out an additional algorithm is employed to make an optimal choice of the regularisation parameter α at each iteration degroot hedlin and constable 1990 2 3 porosity resistivity relationship to relate the electrical properties of the soil to its porous matrix structure some constitutive law needs to be introduced the archie s law archie 1942 is the most common law for relating resistivity to porosity this empirical law was first introduced to quantify the relationship between porosity electrical conductivity and brine saturation of hydrocarbon bearing porous sedimentary rocks it laid the foundation for interpretation of electrical conductivity of a media to its porous structure the original form of the archie s law is valid for medium to coarse grained soils and cobbles when clay particles are present the assumption that the soil matrix is an electrical insulator may no longer be valid in this case an additional electrical conduction path namely the surface conductivity exists which originates from the electrical double layer forming around charged clay minerals to include this aspect a petrophysical relationship which includes an additional term for the surface conductivity was proposed by waxman and smits 1968 and later applied in several more recent studies breede et al 2011 schmutz et al 2010 8 σ s w n f σ w σ s s w in which σ is the bulk conductivity of the porous material s m 1 σw is the pore water conductivity s m 1 σs is the surface conductivity s m 1 sw is the water saturation n is the saturation exponent and f is the formation factor the formation factor is defined as f a ϕ m where ϕ is the porosity of the medium m is the cementation exponent and a is 1 in the original archie s formulation in some cases the additional parameter a is 1 for a better fit schön 2015 exponent m is a porous matrix dependent constant which is related to the grains size and shape in the medium porous structure and its network length and distribution for a pore network of parallel capillary tubes m could be assigned 1 for unconsolidated sands m observed is about 1 3 and for porous sedimentary rocks it varies in the range 1 7 4 1 archie 1942 instead as pointed out by glover 2016 the value assumed by a should be as close to 1 as possible since the introduction of this parameter in the archie s law has no actual physical meaning however since in most measurements systematic errors can be present a non unity value of the parameter a is justified to compensate for those errors which may be present in both electrical and porosity data 2 4 experimental apparatus for erosion tests the experimental set up described in ferdos et al 2018 consisted of an erosion rig a water supply system a set of measurement instruments for process monitoring and an ert measurement system a schematic illustration of the experimental apparatus is given in fig 1 the erosion rig assembly consisted of the following parts an inflow section an erosion chamber an outflow section and a sedimentation tank all the parts were made of plexiglas and were externally framed by stainless steel for reinforcement the erosion chamber had inner dimensions of 350 200 150 mm the porous medium test specimen was inserted inside the erosion chamber and it was confined by the rigid walls laterally the specimen was vertically confined by means of perforated plates at the top and at the bottom of the specimen the top plate was 15 mm in thickness with 96 holes each 20 mm holes and was pressed by a piston rod with a specified load the plate at the bottom was 100 mm in thickness with 96 holes each 10 mm in diameter a plastic filter mesh was placed between the specimen and the perforated rigid bottom plate that only permitted water inflow hydraulic loading of the test specimen was applied by means of water head control using inlet and outlet tanks a municipality water system was used to supply the inlet tank with clean water an overflow on the inlet tank bypassed the excess flow and hence maintained a constant water head at the bottom of the test specimen water flow rate was measured by using a magnetic flow meter appropriate for low flows water electrical conductivity and temperature were monitored manually at regular intervals of about 1 h eroded material from the soil specimen was collected in the sedimentation tank located downstream the erosion rig a load cell transducer was installed at the bottom of the sedimentation tank to monitor its weight with a resolution of 0 01 g this setup allowed for continuous monitoring of the mass of the particles eroded from the specimen during the tests the electrodes were placed in 6 rows spaced 80 mm with 16 electrode slots each row spaced 20 mm allowing the installation of up to 96 electrodes the electrode slots were 8 mm in diameter while the electrodes were stainless steel rods with 5 mm diameter in the present work half of the slots were used therefore a total of 48 electrodes spaced 40 mm were installed the choice of the electrode material and positioning is further discussed below 2 5 ert measurement system the ert data acquisition was carried out with a custom built tomography system specifically designed for laboratory measurements with a multi electrode configuration with 48 channels it worked efficiently by the optimization of the acquisition scheme and multi channel measurements the main parts of the system were a pc which controlled i o cards multiplexers through a microcontroller an external current generator a digital acquisition device daq a power supply and the electrodes the whole system was designed based on the system previously developed at central institute for electronics zel forschungszentrum julich germany zimmermann et al 2008 and it is an upgraded version of the system described in masi and losito 2015 modified to implement the multi channel capabilities the block diagram is shown in fig 2 current injection was achieved by using a function generator agilent 33120a and the type of signal injected was a sine wave ac current the current was measured by reading the voltage drop across a precision low resistance shunt resistor of known value the latter signal was amplified using a high precision programmable gain amplifier pga and then fed to one channel of the acquisition card the acquisition card had 8 simultaneous analog inputs with one analog to digital converter adc per channel with 16 bit resolution to perform data acquisition in 48 electrode mode a multiplexer circuit was needed for switching the current injector and voltmeter among the different channels the current injection multiplexer was capable of selecting two electrodes for injecting the current into the sample the voltage multiplexer instead was capable of selecting 6 electrodes to measure the voltage response of the sample at up to 6 locations the electrodes were connected to external circuits which allowed the same electrode to be switched from acquisition to current injection mode by means of relays activated by the current injection multiplexers in acquisition mode the signals from the potential electrodes were fed to an amplifier circuit and then routed to the adcs by the voltage multiplexer the amplifier circuit consisted of a unit gain operational amplifier its high impedance 1 tω prevented the polarization of potential electrodes and its low output impedance reduced the capacitive coupling effects within the instrumentation the whole system was controlled by specifically developed labview code executed on a standard laptop computer the software could generate the acquisition sequence for the scheduling the measurements as well as generating the signals controlling the multiplexers and the acquisition device and post processing the data 2 6 electrode material the choices of electrode material and positioning are particularly critical for ert measurements since the amplitude response can be affected by systematic errors due to the wrong choices of these two factors the common materials employed as current potential electrodes are stainless steel iron copper silver aluminum brass titanium with mixed metal oxide coating carbon and metal salt compound non polarizable electrodes the response of these electrodes were investigated by many authors de donno and cardarelli 2011 deceuster et al 2013 labrecque and daily 2008 vanhala and soininen 1995 in order to evaluate the error in the measurements as a consequence of the materials selected most of the authors agree that the best performing electrodes are the non polarizable ones but they could not be employed in the present work as they were not suitable for the operating conditions of internal erosion tests they are usually built with a porous plug separating the measurement environment from the electrolyte in which the electrodes are immersed for protection the water pressure would allow the water to enter inside the electrode body and thus damaging the electrodes the electrode material has to be stable over time and should not be affected by oxidation corrosion or any other chemical electrochemical effects as reported by labrecque and daily 2008 stainless steel and iron electrodes are observed to have a better response compared to the other investigated materials both for resistivity and chargeability in the time domain the use of carbon graphite electrodes was also considered for installation carbon electrodes are not subjected to redox reactions with the surrounding electrolyte i e the soil water content in erosion tests and they are durable and stable in long term monitoring applications however they have higher resistance that can lead to their polarization ohmic polarization when they are immersed in the current path of an electric field furthermore the response of carbon electrode is subjected to relevant errors especially for chargeability measurements labrecque and daily 2008 in the present study we selected stainless steel electrodes with the aim of minimizing contact resistance with the electrolyte being the most critical aspect within the scope of this work 2 7 electrode positioning in ert measurements electrode polarization is a substantial source of error to minimize the polarization effect due to voltage gradients and ohmic losses through the electrode material the position of the electrodes must to be carefully optimized with respect to the electric field by placing the electrodes outside the current path to study the effect of electrode positioning a forward 3d model was implemented in python language using the open source fenics package alnæs et al 2015 fenics allowed us to solve the ert forward problem eq 3 with the finite element method and compute the electric potential and current density distributions we used the open source software gmsh geuzaine and remacle 2009 to generate the 3d finite element mesh the elements of the mesh had a tetrahedral shape the simulated domain consisted of a box having the dimensions of the erosion chamber 350 200 150 mm and 4 cylindrical electrode slots diameter 8 mm spaced 40 mm the box was filled with a homogeneous material having 200 ωm resistivity simulating the expected resistivity of the soil specimen used for erosion tests two electrodes a and b were used for current injection in the model and two for potential measurements electrode a was assigned a value of electric potential of 5 v while electrode b served as the ground 0 v therefore in the numerical simulations the boundary conditions at the electrodes were of dirichlet type the electric potential and the current density distributions from the simulation are shown in fig 3 the figure shows the middle sections along the z axis the distribution of the current density magnitude is shown in the fig 3b which illustrates the field for the entire section and a detailed view of the m electrode on the right fig 4 shows the current density inside the cavity of the electrode slots along a cut line parallel to the y axis placed at the midpoint of the cavity the current density decreases with the distance from the inner border of the plexiglas wall corresponding to y 0 in fig 3 it can be observed that the current density inside the m electrode slot is about 1 5 10 2 a m2 10 mm from the border in the soil bulk and it decreases substantially inside the cavity on the border of the cavity the current density is 1 0 10 2 a m2 0 mm from the border in which decreases quickly and substantially and reaches the amount 1 5 10 4 a m2 at 10 mm distance from the border and 1 5 10 8 a m2 at the bottom of the cavity 20 mm from the border the numerical simulations suggested that the electrodes must be installed inside the electrode cavity in order to place the electrode outside the current path the tip of the electrode should be at least 5 mm inwards from the border to achieve an attenuation of the current density of about 1 10 with respect to the current density in the bulk therefore the distance should be at least of the order of magnitude of the diameter of the opening for the electrode furthermore when the electrode is placed 10 mm away from the border the attenuation is about 1 100 leading to very small polarization errors which have been adopted in the installation of the electrodes on the erosion chamber 2 8 experimental protocol experimental protocol involved the choices of material properties and experimental conditions the soil used in erosion tests consisted of a mixture composed of gravel and sand with varying specific grain size ranges test specimens were prepared by mixing different size ranges to obtain the target gradation curve tested by skempton and brogan 1994 referred to as the soil a gap graded sandy gravel soil soil mix grading is presented in fig 5 the rationale for performing tests on this specific gap graded and susceptible soil was that the soil fulfilled the granulometric criteria for the internal instability for suffusion erosion phenomena see ferdos et al 2018 the objectives of the suffusion tests were to evaluate the mass erosion rate and quantify the porosity variations of the specimens by means of time lapse 3d tomography two tests were carried out under two different mechanical loading of equivalent to 0 and 10 kpa vertical stress application on the top of the specimen respectively both tests were carried out under constant hydraulic loading where the specimen was loaded until reaching the initiation of erosion after the detection of initiation the mechanical and the upstream water head were kept constant and the mass removal was monitored moreover the hydraulic conductivity of the porous medium was estimated based on darcy s law and monitored during the tests the suffusion process was monitored by conducting 3d resistivity measurements taken at the start of each test then after initiation at one hour intervals until the end of the test a continues monitoring of eroded sediments were also done which were used for calibration and validation studies of the 3d ert acquisitions the protocol for ert measurements involved the selection of the measurement sequence the definition of the inverse model and its validation and the estimation of data errors all the ert measurements were carried out by injecting 20 cycles of a 150 hz sine wave the measurement sequence consisted of dipole dipole arrays the sequences were optimized in order to achieve both the best possible signal to noise ratio snr and model resolution for erosion tests they were further optimized to obtain a faster acquisition because of the time dependent behaviour of the erosion processes the 3d inversions were performed with the software package r3t binley 2019 which solves the forward model by the finite element method and implements the iterative solution of eq 6 through eq 7 in the forward model the boundary conditions at the electrodes were neumann type to represent the injection of the current of known magnitude as performed during the measurements to set up the 3d finite element mesh required as input to r3t we used the gmsh software the mesh consisted of tetrahedral elements and its geometry and characteristics were chosen to be as close as possible to the physical model by individually separating the resistivity zones of the various parts of the experimental rig these included with reference to fig 1 the resistivity of the top perforated plexiglas plate the bottom plexiglas plate the water at the top of the soil in the outflow section the water inside chamber at the inflow section and the specimen in the erosion chamber only the resistivity of the specimen was made variable during the inversions while the resistivity value of the other parts was kept fixed a mesh sensitivity study was also performed in order to identify the required mesh size for the present problem the measurements had to be taken in the shortest time as possible therefore it was not convenient to perform reciprocal measurements because they would have increased significantly the acquisition period for this reason we performed an error analysis based on the noise in the acquired signals the errors in the data were considered to be proportional to the noise measured at the potential electrodes due to the fact that the signal of the electric current was found to be significantly stronger at the range of impedances measured during the experiments and less susceptible to environmental noise than the signals of electric potential moreover the channel for current signal acquisition had a dedicated pga as described above which further helped to increase the signal to noise ratio snr before the adc conversion under this hypothesis for each measurement the snr of the differential signal between electrode m and n was calculated the amplitude of the background noise was computed by summing the amplitude of all harmonic components of the signal excluding the fundamental frequency the standard deviation of the measured resistance was thus considered to be proportional to the standard deviation of the background noise a summary of the ert parameters and experimental conditions for the erosion tests is reported in table 1 3 results and discussion 3 1 ert inverse model validation model validation involved three steps 1 optimal choice seeking of the boundaries 2 numerical model mesh sensitivity tests and 3 inverse model experimental validation 3 1 1 selection of boundaries the mesh used for the inversions is shown in fig 6 to accurately replicate the geometry of the erosion rig and its properties different arrangements of the boundaries were tested both the top and bottom perforated plexiglas plates were included in the model as well as the water at the bottom and at the top in the inlet and outlet sections respectively to include their influence on the measured data a fixed resistivity value was assigned to plexiglas components because their values were constant during the experiments for the water components a constant resistivity value was assigned since the resistivity of water changed slightly during the experiments less than 8 the water temperature was relatively stable during the experiments with a mean value of 14 c and a maximum variation of 2 c thus assigning a constant resistivity value allowed for constraining the model and prevented the inversion procedure from trying to change their values during the inversions the value of the resistivity of the water was directly assigned from the measured data conducted during the tests for the two regions at the top and at the bottom of the 3d domain values are reported in table 1 the resistivity of the plexiglas plates however was not determined directly the difficulty was that the perforated plexiglas plates do not have an isotropic resistivity i e the resistivity depends on the direction of the electric field thus the apparent resistivity of the plexiglas filter cannot be estimated merely on the basis of the filter geometry because of this difficulty in the calculation of the actual resistivity observed from the electrodes the resistivity of these two plexiglas filters were manually calibrated to get the minimum possible error rms misfit between the inverse model and the observed data with this procedure a value of 100 ωm was assigned to the plate at the top and 600 ωm to the thicker plate at the bottom 3 1 2 mesh sensitivity study the results of the inversions must be evaluated with regard to the discrepancy of the optimized model from the measured data it implies that the results could be influenced by the size of the parameter block size discretisation it is therefore necessary to select a mesh size that minimizes the error between the model and monitored data however the number of model parameters must also be limited to avoid any increase in uncertainty due to raising number of parameters to be optimized thus a mesh sensitivity analysis is essential in order to choose the best performing mesh for the problem to examine the influence of the mesh size on the results of the inverse model optimisation studies were carried out for the erosion chamber filled only with tap water whereby the resistivity parameter of the filling material as well as the expected inversion results were known a correct inversion should display a homogeneous resistivity distribution since the filling material is tap water only we conducted two sets of measurements with different mesh sizes by filling the chamber with water having a resistivity of 24 ωm the results of the inversions are shown in fig 7 fig 7 shows that the distribution of the inverted resistivity is not fully homogeneous the origin of this inhomogeneity is related to the measurement process model setup and inversion errors considering the two meshes the coarse mesh with 20 mm mesh block size gave an inverse model which showed a wider spread in the resistivity values in comparison with the finer mesh model this can be seen from the histogram to the right of the resistivity contours the finer mesh produced a resistivity distribution which is closer to the real and expected one for water having less spread of the resistivity values it was found that both increasing the number of elements and decreasing the mesh block sizes to less than 10 mm resulted in increased spreading the histogram of the resistivity values and further inhomogeneity in predicting the resistivity of the mesh elements the conclusion was that a mesh size of 10 mm would be optimal size for discretization of the inverse model the optimized mesh had a total of 42 779 elements 3 1 3 setup validation after the model mesh and boundaries were set a controlled experimental test was carried out to find the best acquisition system and to validate the inverse model the erosion chamber was filled with tap water and tempered with adding some nacl to reach a resistivity of 4 ωm a block of plexiglas was placed in the middle of the chamber and ert measurement was performed the results obtained are shown in fig 8 fig 8 confirms that the inversion resulted in the correct identification of the object s location and its dimensions the contrast between brine and plexiglas object which is an isolating material are inverted to be weaker than the actual contrast due to smoothness constraint type of inversion however the object is well defined and the discrepancy in the background area brine is kept to an acceptable minimum level moreover for a porous material subjected to suffusion erosion processes resolving sharp contrasts between resistivity zones is not of primary interest this is because the erosion patterns are produced smoothly by water flow from this test it was concluded that the acquisition system was working correctly and the inversion model and boundaries were defined with enough accuracy 3 2 3d ert inversion and results ert data acquisitions were taken at the initial state of the specimen after material compaction and saturation and then repeated at predefined time intervals until the test was terminated a total of 18 time lapse measurements were taken during experiment a which had a duration of about 21 h while 26 measurements were taken during experiment b which lasted about 28 h we inverted each dataset independently without adopting any time lapse inversion scheme due to the fact that the changes of resistivity with time were well correlated and smooth the same inversion parameters i e the initial resistivity distribution guess the fixed resistivity zones and error estimation and weighting were kept fixed for all the inversions belonging to each experiment the errors associated to each measurement were used to fit the linear model suggested by slater et al 2000 whose parameters were provided as input to the inversion software after having performed the inversions we calculated the 3d resistivity change from the initial state as follows 9 δ ρ ρ 0 ρ t where ρ0 ωm refers to the initial resistivity distribution and ρt ωm the resistivity distribution at time t hours where a positive value of δρ ωm indicates a decrease in resistivity with respect to the initial distribution a decrease in resistivity is considered to be directly correlated to a decrease of porosity the contours of resistivity changes for suffusion experiment a are presented in fig 9 at selected time intervals for improving the visualization of the areas where the erosion took place i e where a decrease in resistivity was observed only the areas where δρ 0 were retained in the figure in fig 9 the contours show that the resistivity change of the specimen started and developed mainly in the vicinity of one of the walls whereby during the course of experiment the process continued and in addition it has been observed in different locations these resistivity changing spots grew in size of influence and as well as in deference with respect to the original resistivity magnitude in fact after the suffusion process is initiated the soil matrix started to change due to the transport of the fine particles that increased the porosity from the photographic evidence it can be observed that the test specimen s upper surface and the colour shade changed due to the eroded material the grey areas in the picture are those where the finer material is not removed by erosion while the reddish areas indicate the emergence of the coarse sandy gravel matrix where the finer part is removed it is also notable that the final tomography image t 19 h coherently overlaps with the picture of the top of the specimen showing a similar pattern of change of the material being eroded mostly at the walls and less in the middle of the specimen fig 10 shows the resistivity changes at selected time instants for suffusion experiment b patterns similar to those for experiment a were found showing that erosion processes triggered predominantly from areas close to the lateral walls of the erosion chamber however due to the vertical applied load of 10 kpa in this experiment the distribution of the stresses inside the specimen was modified having an impact on the initiation of internal erosion and on its trend with time as observed by ferdos et al 2018 the boundary effects due to the erosion chamber walls caused a non linear stress distributions with depth predominantly close to the walls due both to wall displacement and friction between the grains and the wall these non linear effects may justify the tendency of the processes to initiate in proximity of the sidewalls as the process continued the fine particles were transported out from the specimen and a redistribution of the stresses in the solid compartment of the soil matrix occurred continuously with time this process continued until it reached a critical limit where the forces induced by the fluid flow are no more capable of displacing the particles and the erosion rate decreased to almost zero 3 3 quantitative evaluation of the ert measurements resistivity changes of a specimen in time undergoing an internal erosion process can be successively related to structural changes in the soil mix that is if the tests are conducted under laboratory controlled conditions where the only parameter that causes the resistivity changes in the sample is the structural changes for this purpose we used eq 8 to assess the changes in soil porosity from changes in resistivity in the application of eq 8 to the experiments carried out in the present study we made the assumption that the magnitude of the surface conductivity is significantly smaller than the magnitude of water conductivity thus the surface conductivity term can be neglected this assumption is supported by the fact that the material used in the experiment was mainly composed of particles having a diameter larger than 0 06 mm as shown in fig 5 therefore no clay content was present in the soil mixture the finer fraction of the soil was composed of silty sandy particles and the coarser fraction of sand and gravel for other particle size distributions having comparable diameter ranges the contribution of the surface conductivity has been shown to be negligible by other authors bolève et al 2011 in applying eq 8 we also assumed 100 water saturation sw 1 which remained constant during the experiments this assumption holds also in the first phases of the experiment as the saturation of the material was rapidly obtained after the application of the hydraulic head the following scheme is proposed to be used that relates the resistivity changes to erosion process evolution in the material first for each mesh cell of the model the resistivity values are then transformed into porosity variations by adopting eq 10 10 δ ϕ ϕ ρ t ϕ ρ 0 in which δϕ is the porosity of the mesh cell at time t with respect to the initial state t 0 the total material that is lost due to the erosion processes for each mesh cell is related to the porosity change of the specimen therefore the total eroded volume of material can be calculated from the 3d porosity variation δϕ distribution 11 v e v δ ϕ d v δ ϕ mean v tot in which vtot m3 is the total volume of the domain i e the soil volume dv m3 is the volume of each mesh cell ve m3 is the eroded volume and δϕmean is the volume averaged porosity variation the eroded material volume is also equal to the variation of the pore space void volume vv m3 by 12 v e δ ϕ mean v tot δ v v v tot v tot δ v v when the eroded volume is integrated from all the mesh cells this volume can then be correlated to the eroded soil mass if the average specific weight gs of the soil grains is known and is done by 13 m g s δ v v in which m kg is the eroded mass and gs kg m3 was taken as 2537 kg m3 from ferdos et al 2018 for the soil mix used in their erosion studies the eroded mass calculated from eq 13 is the cumulative eroded mass from the tests start to the time of the acquisition and its inversion to calibrate the archie s law parameters we used the inverted resistivities and the time dependent mass removal data a calibration loop of data fitting for archie s law parameters was produced for each inversion and the resistivity changes were then converted into porosity change in media and finally translated to weight loss by eq 13 the weight loss at that specific time were compared with the cumulative eroded mass measured from the experiments the archie s law parameters were tuned to reach minimum error between the calculated eroded mass from ert analysis and the collected data from the laboratory experiments this calibration process is schematically presented in fig 11 we used the first dataset suffusion experiment a to perform the calibration with the proposed scheme and the dataset of suffusion experiment b to validate the optimized model parameters the optimization was carried out in matlab environment using a constrained version of the nelder mead simplex algorithm the results of the calibration and validation of the archie s law parameters are presented in fig 12 and table 2 in both calibration and validation we used the measured water conductivity as input to the archie s law the ranges of water conductivity are reported in table 2 fig 12 illustrates the comparison between the measured and ert derived time dependent cumulative of the eroded dry mass during the course of the experiments as it can be seen from the results in both experiments the removal rate i e the time derivative of the cumulative curve was larger at the beginning of the experiment and gradually decreased with time the erosion continued for about 20 25 h after reaching a minimum rate under the constant water head applied after which the erosion process stopped the calibration yielded a value of 1 42 for the cementation exponent m which is very close to the values that are available in literature for unconsolidated material e g m 1 3 for unconsolidated sands the parameter a slightly exceeded the expected range a 1 indicating that a source of systematic error may be present in the adopted measurement or inversion scheme this is likely to be related to the inversion process in which the error weights could be overestimated or underestimated due to the lack of reciprocal measurements leading to systematic errors in the resolution of the resistivity distributions however as confirmed by the model validation rmse 0 052 kg r2 0 87 the results are successfully reproducible in the estimated eroded mass curves as shown in fig 12 the overall mass balances are preserved even if the fluctuation of the ert derived points can be observed this may represent a drawback when trying to estimate the global erosion rate i e by taking the time derivative of the cumulate curves the quantification of the instantaneous rate with this method might be rather inaccurate a possible solution is to estimate the overall erosion rate by time averaging multiple points of the ert curves however this operation would decrease the time resolution of the method for fast erosion processes on the contrary when the time scale of the erosion processes is much slower than the measurement periods the time averaging technique would lead to a more accurate estimation of the erosion rates under the specific experimental conditions the resistivity variations captured by ert imaging are related to relatively small changes in the porosity values therefore in this particular case it is crucial to acquire the data with a high resolution technique and tightly spaced electrodes in fact the sensitivity of the calibrated archie s model parameters to the resistivity input may in some cases exceed the sensitivity and resolution of the ert images especially in the zones located far away from the electrode arrays the reduced sensitivity may induce an underestimation of the erosion rates or can bias the results of the model calibration procedures from fig 10 this can be observed in the middle of the specimen where the combination of both reduced sensitivity and lower erosion magnitude lead to the presence of a central zone where resistivity changes are below an observable threshold however the influence of this issue to the overall result may be limited in this study as the validation errors rmse r2 in table 2 are still within an acceptable level the reduction is sensitivity however may pose a critical limitation in the field application of this technique mainly because of the practical obstacles which necessarily cause a reduced sensitivity of ert in the field to name a few the difficulty of installing 3d arrays the limited number of installable electrodes the number of available adc channels of the measurement equipment the higher background electromagnetic noise compared to the laboratory the increased electrode contact impedance the large amount of data to be collected stored and processed and the overall costs related to the implementation of high resolution surveys in conclusion the success of an ert investigation in the field strictly depends on both the spatial and time scale at which the phenomena occur in combination with the adopted measurement and processing strategies 4 conclusions we used electrical resistivity tomography ert technique to monitor internal erosion in porous media induced by seepage flow this phenomenon is one of the most common causes of failure of earthen levees and embankment dams an ert system was specifically designed for the time lapse imaging of the electrical properties of porous media at a laboratory scale the components of the systems were optimized to specific requirements in terms of accuracy and speed of acquisition due to the time dependent nature of erosion processes the electrode material and positioning were investigated the latter by numerical modelling which allowed us to define the proper electrode installation requirements for the minimization of the errors due to electrode polarization the system operated with a total of 48 electrodes with multi channel voltage readings of up to 6 electrodes simultaneously we validated the forward and inverse models by seeking for optimal choice of the boundary conditions studying the numerical model sensitivity to mesh size and by experimentally testing the measurement and inversion setup with a known resistivity distribution two erosion i e suffusion tests were performed to reproduce the process of internal erosion of soil particles by water flow within a purposely prepared soil mixture under two different mechanical loadings 0 and 10 kpa vertical stress application on the top of the specimen 3d time lapse monitoring of internal erosion was carried out at regular intervals of 1 h to relate resistivity variations to material structural changes in time during the erosion processes we calculated the porosity variations through the archie s law with parameters calibrated using both the results from the inversions and the measured cumulate of the material eroded from the test chamber comparison of the 3d tomography results with the mass removal data as well as the validation of the identifies archie s parameters were found to be successful we can conclude that ert technique is potentially capable of detecting and quantifying the erosion processes in dams and levees the practical aspects when conducting an ert survey in the field compared to the controlled conditions in the laboratory may represent a limiting factor to the use this technique in real world applications especially with regards to the electrode installation and the limits in installing high resolution 3d arrays in the field however we successfully demonstrated that the method is robust and reliable provided that extensive supplementary information is necessary which should be integrated with the ert survey data credit authorship contribution statement matteo masi conceptualization methodology software validation data curation writing original draft visualization farzad ferdos conceptualization methodology investigation data curation writing original draft visualization project administration gabriella losito conceptualization formal analysis writing review editing luca solari conceptualization writing review editing supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was performed as part of a joint research project in between the royal institute of technology kth sweden and department of civil and environmental engineering dicea of the university of florence italy and was funded by the swedish hydropower centre svenskt vattenkraft centrum svc with funding project number vk10739 the authors acknowledge vattenfall for the help and support in conducting the experiments at vattenfall r d laboratory in älvkarleby sweden the authors are thankful to two anonymous reviewers whose comments and suggestions helped us to improve the quality of the manuscript 
5292,internal erosion phenomena are a major threat to all earthen structures such as river levees and dams studying these phenomena has been limited because they occur concealed inside the material which makes them difficult to observe and monitor non destructive geophysical monitoring techniques are powerful tools that can provide insight into the processes involved for this reason a test rig has been specifically designed to conduct three dimensional electrical resistivity tomography of soil specimens undergoing internal erosion due to seepage two suffusion tests were conducted where the erosion evolution has been monitored the time series of eroded mass weight were then used to correlate the changes in three dimensional resistivity distribution to the porosity change in media by means of archie s law the results from the first suffusion test were used to calibrate archie s model parameters it was found that the resistivity variations were able to predict changes in the porous matrix structure the data obtained from the second test were used to validate the model parameters and confirmed that the time lapse three dimensional inverted resistivity images were able to successfully quantify the global erosion rate keywords ert resistivity imaging archie s law embankment dams internal erosion suffusion 1 introduction internal erosion in earthen structures occurs when soil particles within the porous medium are transported by seeping water bonelli and nicot 2013 it represents a serious threat to the structural stability of embankment dams because the erosion process takes place deep inside the structure or its foundation wan and fell 2008 the hidden nature of internal erosion makes it both hard to detect as well as limiting the possibility of its investigation here the main problem is the common use of destructive methods to sample the affected soil regions both under field and laboratory conditions there is a pressing need for detection methodologies that can preserve the soil sample in laboratory or in field cases fell et al 2003 geophysical methods are proven to be effective for identifying potential zones for internal erosion without causing any destruction in material the most common methods are ground penetrating radar gpr self potential sp electrical resistivity tomography ert electromagnetic em methods active and passive seismic methods as well as lidar and other remote sensing techniques among these only electrical ert sp and electromagnetic em gpr methods are directly sensitive to the presence of water in the embankment structure ikard et al 2012 panthulu et al 2001 gpr methods have the advantage of providing good resolution of the internal structures and are widely used for mapping lithological and sedimentological characterisation of quaternary deposit properties bakker and van der meer 2003 carlsten et al 1995 smith and jol 1992 trafford 2009 the gpr s signals however get severely attenuated when layers of fine grained soil are present the latter is a prevailing property of earthen structures specifically when the erosion susceptible zones are considered however sp and ert methods are found to be more appropriate for structures that contain fine grained soils hirsch et al 2008 sp and ert are widely used to locate leakage prone and susceptible zones of embankment dams al fares 2014 2011 bolève et al 2011 dahlin and johansson 1995 ikard et al 2015 panthulu et al 2001 rittgers et al 2014 shin et al 2019 sjödahl et al 2008 soueid ahmed et al 2020 titov et al 2000 the ert based techniques have numerous advantages they are cost effective and easy to implement in the field they can cover large earth volumes and the measurement can be performed repeated over time time lapse and they do not require to be supervised i e can be remotely operated moreover they are highly sensitive to electrical conductivity contrasts commonly found in the materials used for embankments construction on the other hand the fact that the method is subjected to site specific conditions and that the success of the study necessarily requires the integration of adequately large data collected for the specific case are considered to be among the main disadvantages dahlin et al 2001 conducted resistivity and sp studies based on the surveying and monitoring data at the sädva embankment in sweden with the aim of to providing baseline information for evaluation of the sp monitoring data the anomalies found in the collected sp data were correlated to known features of the dam construction while the other investigated areas presented smooth results with no major anomalies panthulu et al 2001 used the same method to delineate seepage favourable zones for two of the saddle dams of the som kamla amba in india a combination of sp method with salt tracer injections was used by bolève et al 2011 for localising seepage prone zones and quantifying the leakages in dams there are also a number of studies that use the method to investigate seepage beneath homogeneous dams e g a number of earth dams in colorado ikard et al 2015 and an embankment dam in california moore et al 2011 ert methods are widely tested in dam monitoring johansson and dahlin 1996 aimed to quantify the seepage and detect anomalous infiltration flow through monitoring seasonal resistivity variations in various case studies in lövon and moforsen embankment dam in sweden similar case studies have been conducted by al fares 2014 2011 for characterizing the water leakage in afamia b and abu baara embankment dams in syria sjödahl et al 2010 2008 2005 performed extensive electrical resistivity investigation and monitoring for detection of internal erosion and anomalous seepage for four embankment dams in scandinavia in all of these studies the measured data from the crest of the dams are inverted to a subsurface geoelectric section by various 2d inversion schemes constable et al 1987 loke and barker 1995 and the anomalous low resistivity zones in these 2d sections were interpreted as leakage zones despite the effectiveness of sp and ert methods the 2d interpretation and quantification of the data are substantially affected by the 3d nature of the acquisition data to overcome this limitation one option is to use cross hole resistivity tomography by imaging the region between two boreholes in depth cross hole data acquisition is done in depth in addition to the dam crest readings to provide the additional data the application of this method are presented in numerous studies e g cho and yeom 2007 daily and owen 1991 lesur et al 1999a b park and van 1991 shima 1992 fargier et al 2014 suggest an alternative method for monitoring an embankment dike with the conventional data acquisition procedure with linear arrays they developed a new extended normalisation technique by providing during inversion a set of pre processed apparent resistivities that are not affected by external 3d effects in this way the artifacts of conventional 2d inversion due to the 3d nature of embankment dike are reduced 3d surveys can also be conducted by using a rectangular grid of electrodes instead of linear array at the surface this method has been reported to provide a good resolution chambers et al 2002 2011 dahlin et al 2002 gharibi and bentley 2005 however irrespective of the method to get a workable resolution a larger number of electrodes are needed in the survey grid as well as the need for a larger number of acquisition combination for this reason some 3d array optimization algorithm must be applied to minimize the number of acquisitions of data registering at multiple electrodes with multichannel instrumentation and filtering out potentially unstable arrays loke et al 2014 here stable and robust time lapse inversion techniques which can be incorporated into automatic inversion software should be used to produce interpretable images the foregoing survey suggests that ert method has the potential to monitor the internal erosion processes and their development in a controlled laboratory environment it can provide insight into the internal erosion processes involved and thereby improving our understanding of the factors that affect the resistivity response when internal erosion phenomena are triggered the main aim of the present work is to investigate these processes by time lapse three dimensional electrical resistivity tomography for this purpose a high resolution resistivity probe system was designed and integrated into an apparatus for studying phenomenon of internal erosion e g suffusion phenomenon at laboratory scale 3d electrical resistivity profiles of soil material were produced so that changes in porous matrix could be visualised and quantified 2 materials and methods 2 1 forward modelling using electrical resistivity tomography the distribution of the electrical properties inside the medium can be determined from a set of measurements taken on the boundary it involves defining a forward model in which the response is calculated by assigning electrical properties to the model elements the governing equation for the ert forward model is the poisson s equation 1 j q j in which j a m 2 denotes the electric current density and qj a m 3 is the boundary current source under electrostatic conditions the electric potential v v can be written as e v where e v m 1 is the electric field the flow of current is given by the ohm s law 2 j σ e in which σ s m 1 is the electric conductivity combining eqs 1 and 2 the ert forward problem can be described by 3 σ δ v q j the physical boundaries of the experimental rig consisted of insulating walls therefore neumann boundary conditions were applied at these surfaces the numerical methods used to solve the forward model will be described in the next sections paragraphs 2 7 and 2 8 2 2 inverse modelling the inverse problem involves the determination of the specific parameter distribution i e resistivity that minimizes the discrepancy between measured and calculated values i e the inverse model is used for the calibration of the forward model the approach of inverse problem solving is a process of calculating from a set of data the causal factors that produced them which in turn is characterized by some degree of non uniqueness for the solution consequently formulation of the inverse model usually requires mathematical regularization of the model parameters by introducing additional constraints to reduce the degrees of freedom and achieve convergence of a unique solution binley 2015 the inverse problem is formulated as an optimization problem involving the minimization of the objective function s defined as 4 s φ d α φ m in which фd represents the chi squared measure of data misfit фm is the model objective function containing the selected regularization scheme and α is the regularization parameter used to control the weight of the regularization with respect to the data misfit for n measured data di with associated standard deviation of εi the chi squared measure of the data misfit is defined as 5 φ d i 1 n d i f i m ε i 2 in which fi denotes the forward model operator and m the vector of parameters for inversion the following scheme referred to as occam s inversion involving minimization of the objective function s is considered 6 s w d d f m 2 α w m m 2 in which wd is the data weighting matrix assumed to be diagonal with diagonal values wi i 1 εi and wm is a first order spatial smoothing operator see kemna 2000 the numerical implementation of the minimization of the objective function eq 6 can be achieved by using an iterative process i e gauss newton algorithm which yields the following iterative equation binley and kemna 2005 7 j t w d t w d j α r δ m j t w d t d f m k α rm in which j is the jacobian such that ji j di mj r is the roughness matrix which describes the connectivity of the parameters and δm the model update at each iteration starting from a model m0 the iteration process mk 1 mk δm is carried out an additional algorithm is employed to make an optimal choice of the regularisation parameter α at each iteration degroot hedlin and constable 1990 2 3 porosity resistivity relationship to relate the electrical properties of the soil to its porous matrix structure some constitutive law needs to be introduced the archie s law archie 1942 is the most common law for relating resistivity to porosity this empirical law was first introduced to quantify the relationship between porosity electrical conductivity and brine saturation of hydrocarbon bearing porous sedimentary rocks it laid the foundation for interpretation of electrical conductivity of a media to its porous structure the original form of the archie s law is valid for medium to coarse grained soils and cobbles when clay particles are present the assumption that the soil matrix is an electrical insulator may no longer be valid in this case an additional electrical conduction path namely the surface conductivity exists which originates from the electrical double layer forming around charged clay minerals to include this aspect a petrophysical relationship which includes an additional term for the surface conductivity was proposed by waxman and smits 1968 and later applied in several more recent studies breede et al 2011 schmutz et al 2010 8 σ s w n f σ w σ s s w in which σ is the bulk conductivity of the porous material s m 1 σw is the pore water conductivity s m 1 σs is the surface conductivity s m 1 sw is the water saturation n is the saturation exponent and f is the formation factor the formation factor is defined as f a ϕ m where ϕ is the porosity of the medium m is the cementation exponent and a is 1 in the original archie s formulation in some cases the additional parameter a is 1 for a better fit schön 2015 exponent m is a porous matrix dependent constant which is related to the grains size and shape in the medium porous structure and its network length and distribution for a pore network of parallel capillary tubes m could be assigned 1 for unconsolidated sands m observed is about 1 3 and for porous sedimentary rocks it varies in the range 1 7 4 1 archie 1942 instead as pointed out by glover 2016 the value assumed by a should be as close to 1 as possible since the introduction of this parameter in the archie s law has no actual physical meaning however since in most measurements systematic errors can be present a non unity value of the parameter a is justified to compensate for those errors which may be present in both electrical and porosity data 2 4 experimental apparatus for erosion tests the experimental set up described in ferdos et al 2018 consisted of an erosion rig a water supply system a set of measurement instruments for process monitoring and an ert measurement system a schematic illustration of the experimental apparatus is given in fig 1 the erosion rig assembly consisted of the following parts an inflow section an erosion chamber an outflow section and a sedimentation tank all the parts were made of plexiglas and were externally framed by stainless steel for reinforcement the erosion chamber had inner dimensions of 350 200 150 mm the porous medium test specimen was inserted inside the erosion chamber and it was confined by the rigid walls laterally the specimen was vertically confined by means of perforated plates at the top and at the bottom of the specimen the top plate was 15 mm in thickness with 96 holes each 20 mm holes and was pressed by a piston rod with a specified load the plate at the bottom was 100 mm in thickness with 96 holes each 10 mm in diameter a plastic filter mesh was placed between the specimen and the perforated rigid bottom plate that only permitted water inflow hydraulic loading of the test specimen was applied by means of water head control using inlet and outlet tanks a municipality water system was used to supply the inlet tank with clean water an overflow on the inlet tank bypassed the excess flow and hence maintained a constant water head at the bottom of the test specimen water flow rate was measured by using a magnetic flow meter appropriate for low flows water electrical conductivity and temperature were monitored manually at regular intervals of about 1 h eroded material from the soil specimen was collected in the sedimentation tank located downstream the erosion rig a load cell transducer was installed at the bottom of the sedimentation tank to monitor its weight with a resolution of 0 01 g this setup allowed for continuous monitoring of the mass of the particles eroded from the specimen during the tests the electrodes were placed in 6 rows spaced 80 mm with 16 electrode slots each row spaced 20 mm allowing the installation of up to 96 electrodes the electrode slots were 8 mm in diameter while the electrodes were stainless steel rods with 5 mm diameter in the present work half of the slots were used therefore a total of 48 electrodes spaced 40 mm were installed the choice of the electrode material and positioning is further discussed below 2 5 ert measurement system the ert data acquisition was carried out with a custom built tomography system specifically designed for laboratory measurements with a multi electrode configuration with 48 channels it worked efficiently by the optimization of the acquisition scheme and multi channel measurements the main parts of the system were a pc which controlled i o cards multiplexers through a microcontroller an external current generator a digital acquisition device daq a power supply and the electrodes the whole system was designed based on the system previously developed at central institute for electronics zel forschungszentrum julich germany zimmermann et al 2008 and it is an upgraded version of the system described in masi and losito 2015 modified to implement the multi channel capabilities the block diagram is shown in fig 2 current injection was achieved by using a function generator agilent 33120a and the type of signal injected was a sine wave ac current the current was measured by reading the voltage drop across a precision low resistance shunt resistor of known value the latter signal was amplified using a high precision programmable gain amplifier pga and then fed to one channel of the acquisition card the acquisition card had 8 simultaneous analog inputs with one analog to digital converter adc per channel with 16 bit resolution to perform data acquisition in 48 electrode mode a multiplexer circuit was needed for switching the current injector and voltmeter among the different channels the current injection multiplexer was capable of selecting two electrodes for injecting the current into the sample the voltage multiplexer instead was capable of selecting 6 electrodes to measure the voltage response of the sample at up to 6 locations the electrodes were connected to external circuits which allowed the same electrode to be switched from acquisition to current injection mode by means of relays activated by the current injection multiplexers in acquisition mode the signals from the potential electrodes were fed to an amplifier circuit and then routed to the adcs by the voltage multiplexer the amplifier circuit consisted of a unit gain operational amplifier its high impedance 1 tω prevented the polarization of potential electrodes and its low output impedance reduced the capacitive coupling effects within the instrumentation the whole system was controlled by specifically developed labview code executed on a standard laptop computer the software could generate the acquisition sequence for the scheduling the measurements as well as generating the signals controlling the multiplexers and the acquisition device and post processing the data 2 6 electrode material the choices of electrode material and positioning are particularly critical for ert measurements since the amplitude response can be affected by systematic errors due to the wrong choices of these two factors the common materials employed as current potential electrodes are stainless steel iron copper silver aluminum brass titanium with mixed metal oxide coating carbon and metal salt compound non polarizable electrodes the response of these electrodes were investigated by many authors de donno and cardarelli 2011 deceuster et al 2013 labrecque and daily 2008 vanhala and soininen 1995 in order to evaluate the error in the measurements as a consequence of the materials selected most of the authors agree that the best performing electrodes are the non polarizable ones but they could not be employed in the present work as they were not suitable for the operating conditions of internal erosion tests they are usually built with a porous plug separating the measurement environment from the electrolyte in which the electrodes are immersed for protection the water pressure would allow the water to enter inside the electrode body and thus damaging the electrodes the electrode material has to be stable over time and should not be affected by oxidation corrosion or any other chemical electrochemical effects as reported by labrecque and daily 2008 stainless steel and iron electrodes are observed to have a better response compared to the other investigated materials both for resistivity and chargeability in the time domain the use of carbon graphite electrodes was also considered for installation carbon electrodes are not subjected to redox reactions with the surrounding electrolyte i e the soil water content in erosion tests and they are durable and stable in long term monitoring applications however they have higher resistance that can lead to their polarization ohmic polarization when they are immersed in the current path of an electric field furthermore the response of carbon electrode is subjected to relevant errors especially for chargeability measurements labrecque and daily 2008 in the present study we selected stainless steel electrodes with the aim of minimizing contact resistance with the electrolyte being the most critical aspect within the scope of this work 2 7 electrode positioning in ert measurements electrode polarization is a substantial source of error to minimize the polarization effect due to voltage gradients and ohmic losses through the electrode material the position of the electrodes must to be carefully optimized with respect to the electric field by placing the electrodes outside the current path to study the effect of electrode positioning a forward 3d model was implemented in python language using the open source fenics package alnæs et al 2015 fenics allowed us to solve the ert forward problem eq 3 with the finite element method and compute the electric potential and current density distributions we used the open source software gmsh geuzaine and remacle 2009 to generate the 3d finite element mesh the elements of the mesh had a tetrahedral shape the simulated domain consisted of a box having the dimensions of the erosion chamber 350 200 150 mm and 4 cylindrical electrode slots diameter 8 mm spaced 40 mm the box was filled with a homogeneous material having 200 ωm resistivity simulating the expected resistivity of the soil specimen used for erosion tests two electrodes a and b were used for current injection in the model and two for potential measurements electrode a was assigned a value of electric potential of 5 v while electrode b served as the ground 0 v therefore in the numerical simulations the boundary conditions at the electrodes were of dirichlet type the electric potential and the current density distributions from the simulation are shown in fig 3 the figure shows the middle sections along the z axis the distribution of the current density magnitude is shown in the fig 3b which illustrates the field for the entire section and a detailed view of the m electrode on the right fig 4 shows the current density inside the cavity of the electrode slots along a cut line parallel to the y axis placed at the midpoint of the cavity the current density decreases with the distance from the inner border of the plexiglas wall corresponding to y 0 in fig 3 it can be observed that the current density inside the m electrode slot is about 1 5 10 2 a m2 10 mm from the border in the soil bulk and it decreases substantially inside the cavity on the border of the cavity the current density is 1 0 10 2 a m2 0 mm from the border in which decreases quickly and substantially and reaches the amount 1 5 10 4 a m2 at 10 mm distance from the border and 1 5 10 8 a m2 at the bottom of the cavity 20 mm from the border the numerical simulations suggested that the electrodes must be installed inside the electrode cavity in order to place the electrode outside the current path the tip of the electrode should be at least 5 mm inwards from the border to achieve an attenuation of the current density of about 1 10 with respect to the current density in the bulk therefore the distance should be at least of the order of magnitude of the diameter of the opening for the electrode furthermore when the electrode is placed 10 mm away from the border the attenuation is about 1 100 leading to very small polarization errors which have been adopted in the installation of the electrodes on the erosion chamber 2 8 experimental protocol experimental protocol involved the choices of material properties and experimental conditions the soil used in erosion tests consisted of a mixture composed of gravel and sand with varying specific grain size ranges test specimens were prepared by mixing different size ranges to obtain the target gradation curve tested by skempton and brogan 1994 referred to as the soil a gap graded sandy gravel soil soil mix grading is presented in fig 5 the rationale for performing tests on this specific gap graded and susceptible soil was that the soil fulfilled the granulometric criteria for the internal instability for suffusion erosion phenomena see ferdos et al 2018 the objectives of the suffusion tests were to evaluate the mass erosion rate and quantify the porosity variations of the specimens by means of time lapse 3d tomography two tests were carried out under two different mechanical loading of equivalent to 0 and 10 kpa vertical stress application on the top of the specimen respectively both tests were carried out under constant hydraulic loading where the specimen was loaded until reaching the initiation of erosion after the detection of initiation the mechanical and the upstream water head were kept constant and the mass removal was monitored moreover the hydraulic conductivity of the porous medium was estimated based on darcy s law and monitored during the tests the suffusion process was monitored by conducting 3d resistivity measurements taken at the start of each test then after initiation at one hour intervals until the end of the test a continues monitoring of eroded sediments were also done which were used for calibration and validation studies of the 3d ert acquisitions the protocol for ert measurements involved the selection of the measurement sequence the definition of the inverse model and its validation and the estimation of data errors all the ert measurements were carried out by injecting 20 cycles of a 150 hz sine wave the measurement sequence consisted of dipole dipole arrays the sequences were optimized in order to achieve both the best possible signal to noise ratio snr and model resolution for erosion tests they were further optimized to obtain a faster acquisition because of the time dependent behaviour of the erosion processes the 3d inversions were performed with the software package r3t binley 2019 which solves the forward model by the finite element method and implements the iterative solution of eq 6 through eq 7 in the forward model the boundary conditions at the electrodes were neumann type to represent the injection of the current of known magnitude as performed during the measurements to set up the 3d finite element mesh required as input to r3t we used the gmsh software the mesh consisted of tetrahedral elements and its geometry and characteristics were chosen to be as close as possible to the physical model by individually separating the resistivity zones of the various parts of the experimental rig these included with reference to fig 1 the resistivity of the top perforated plexiglas plate the bottom plexiglas plate the water at the top of the soil in the outflow section the water inside chamber at the inflow section and the specimen in the erosion chamber only the resistivity of the specimen was made variable during the inversions while the resistivity value of the other parts was kept fixed a mesh sensitivity study was also performed in order to identify the required mesh size for the present problem the measurements had to be taken in the shortest time as possible therefore it was not convenient to perform reciprocal measurements because they would have increased significantly the acquisition period for this reason we performed an error analysis based on the noise in the acquired signals the errors in the data were considered to be proportional to the noise measured at the potential electrodes due to the fact that the signal of the electric current was found to be significantly stronger at the range of impedances measured during the experiments and less susceptible to environmental noise than the signals of electric potential moreover the channel for current signal acquisition had a dedicated pga as described above which further helped to increase the signal to noise ratio snr before the adc conversion under this hypothesis for each measurement the snr of the differential signal between electrode m and n was calculated the amplitude of the background noise was computed by summing the amplitude of all harmonic components of the signal excluding the fundamental frequency the standard deviation of the measured resistance was thus considered to be proportional to the standard deviation of the background noise a summary of the ert parameters and experimental conditions for the erosion tests is reported in table 1 3 results and discussion 3 1 ert inverse model validation model validation involved three steps 1 optimal choice seeking of the boundaries 2 numerical model mesh sensitivity tests and 3 inverse model experimental validation 3 1 1 selection of boundaries the mesh used for the inversions is shown in fig 6 to accurately replicate the geometry of the erosion rig and its properties different arrangements of the boundaries were tested both the top and bottom perforated plexiglas plates were included in the model as well as the water at the bottom and at the top in the inlet and outlet sections respectively to include their influence on the measured data a fixed resistivity value was assigned to plexiglas components because their values were constant during the experiments for the water components a constant resistivity value was assigned since the resistivity of water changed slightly during the experiments less than 8 the water temperature was relatively stable during the experiments with a mean value of 14 c and a maximum variation of 2 c thus assigning a constant resistivity value allowed for constraining the model and prevented the inversion procedure from trying to change their values during the inversions the value of the resistivity of the water was directly assigned from the measured data conducted during the tests for the two regions at the top and at the bottom of the 3d domain values are reported in table 1 the resistivity of the plexiglas plates however was not determined directly the difficulty was that the perforated plexiglas plates do not have an isotropic resistivity i e the resistivity depends on the direction of the electric field thus the apparent resistivity of the plexiglas filter cannot be estimated merely on the basis of the filter geometry because of this difficulty in the calculation of the actual resistivity observed from the electrodes the resistivity of these two plexiglas filters were manually calibrated to get the minimum possible error rms misfit between the inverse model and the observed data with this procedure a value of 100 ωm was assigned to the plate at the top and 600 ωm to the thicker plate at the bottom 3 1 2 mesh sensitivity study the results of the inversions must be evaluated with regard to the discrepancy of the optimized model from the measured data it implies that the results could be influenced by the size of the parameter block size discretisation it is therefore necessary to select a mesh size that minimizes the error between the model and monitored data however the number of model parameters must also be limited to avoid any increase in uncertainty due to raising number of parameters to be optimized thus a mesh sensitivity analysis is essential in order to choose the best performing mesh for the problem to examine the influence of the mesh size on the results of the inverse model optimisation studies were carried out for the erosion chamber filled only with tap water whereby the resistivity parameter of the filling material as well as the expected inversion results were known a correct inversion should display a homogeneous resistivity distribution since the filling material is tap water only we conducted two sets of measurements with different mesh sizes by filling the chamber with water having a resistivity of 24 ωm the results of the inversions are shown in fig 7 fig 7 shows that the distribution of the inverted resistivity is not fully homogeneous the origin of this inhomogeneity is related to the measurement process model setup and inversion errors considering the two meshes the coarse mesh with 20 mm mesh block size gave an inverse model which showed a wider spread in the resistivity values in comparison with the finer mesh model this can be seen from the histogram to the right of the resistivity contours the finer mesh produced a resistivity distribution which is closer to the real and expected one for water having less spread of the resistivity values it was found that both increasing the number of elements and decreasing the mesh block sizes to less than 10 mm resulted in increased spreading the histogram of the resistivity values and further inhomogeneity in predicting the resistivity of the mesh elements the conclusion was that a mesh size of 10 mm would be optimal size for discretization of the inverse model the optimized mesh had a total of 42 779 elements 3 1 3 setup validation after the model mesh and boundaries were set a controlled experimental test was carried out to find the best acquisition system and to validate the inverse model the erosion chamber was filled with tap water and tempered with adding some nacl to reach a resistivity of 4 ωm a block of plexiglas was placed in the middle of the chamber and ert measurement was performed the results obtained are shown in fig 8 fig 8 confirms that the inversion resulted in the correct identification of the object s location and its dimensions the contrast between brine and plexiglas object which is an isolating material are inverted to be weaker than the actual contrast due to smoothness constraint type of inversion however the object is well defined and the discrepancy in the background area brine is kept to an acceptable minimum level moreover for a porous material subjected to suffusion erosion processes resolving sharp contrasts between resistivity zones is not of primary interest this is because the erosion patterns are produced smoothly by water flow from this test it was concluded that the acquisition system was working correctly and the inversion model and boundaries were defined with enough accuracy 3 2 3d ert inversion and results ert data acquisitions were taken at the initial state of the specimen after material compaction and saturation and then repeated at predefined time intervals until the test was terminated a total of 18 time lapse measurements were taken during experiment a which had a duration of about 21 h while 26 measurements were taken during experiment b which lasted about 28 h we inverted each dataset independently without adopting any time lapse inversion scheme due to the fact that the changes of resistivity with time were well correlated and smooth the same inversion parameters i e the initial resistivity distribution guess the fixed resistivity zones and error estimation and weighting were kept fixed for all the inversions belonging to each experiment the errors associated to each measurement were used to fit the linear model suggested by slater et al 2000 whose parameters were provided as input to the inversion software after having performed the inversions we calculated the 3d resistivity change from the initial state as follows 9 δ ρ ρ 0 ρ t where ρ0 ωm refers to the initial resistivity distribution and ρt ωm the resistivity distribution at time t hours where a positive value of δρ ωm indicates a decrease in resistivity with respect to the initial distribution a decrease in resistivity is considered to be directly correlated to a decrease of porosity the contours of resistivity changes for suffusion experiment a are presented in fig 9 at selected time intervals for improving the visualization of the areas where the erosion took place i e where a decrease in resistivity was observed only the areas where δρ 0 were retained in the figure in fig 9 the contours show that the resistivity change of the specimen started and developed mainly in the vicinity of one of the walls whereby during the course of experiment the process continued and in addition it has been observed in different locations these resistivity changing spots grew in size of influence and as well as in deference with respect to the original resistivity magnitude in fact after the suffusion process is initiated the soil matrix started to change due to the transport of the fine particles that increased the porosity from the photographic evidence it can be observed that the test specimen s upper surface and the colour shade changed due to the eroded material the grey areas in the picture are those where the finer material is not removed by erosion while the reddish areas indicate the emergence of the coarse sandy gravel matrix where the finer part is removed it is also notable that the final tomography image t 19 h coherently overlaps with the picture of the top of the specimen showing a similar pattern of change of the material being eroded mostly at the walls and less in the middle of the specimen fig 10 shows the resistivity changes at selected time instants for suffusion experiment b patterns similar to those for experiment a were found showing that erosion processes triggered predominantly from areas close to the lateral walls of the erosion chamber however due to the vertical applied load of 10 kpa in this experiment the distribution of the stresses inside the specimen was modified having an impact on the initiation of internal erosion and on its trend with time as observed by ferdos et al 2018 the boundary effects due to the erosion chamber walls caused a non linear stress distributions with depth predominantly close to the walls due both to wall displacement and friction between the grains and the wall these non linear effects may justify the tendency of the processes to initiate in proximity of the sidewalls as the process continued the fine particles were transported out from the specimen and a redistribution of the stresses in the solid compartment of the soil matrix occurred continuously with time this process continued until it reached a critical limit where the forces induced by the fluid flow are no more capable of displacing the particles and the erosion rate decreased to almost zero 3 3 quantitative evaluation of the ert measurements resistivity changes of a specimen in time undergoing an internal erosion process can be successively related to structural changes in the soil mix that is if the tests are conducted under laboratory controlled conditions where the only parameter that causes the resistivity changes in the sample is the structural changes for this purpose we used eq 8 to assess the changes in soil porosity from changes in resistivity in the application of eq 8 to the experiments carried out in the present study we made the assumption that the magnitude of the surface conductivity is significantly smaller than the magnitude of water conductivity thus the surface conductivity term can be neglected this assumption is supported by the fact that the material used in the experiment was mainly composed of particles having a diameter larger than 0 06 mm as shown in fig 5 therefore no clay content was present in the soil mixture the finer fraction of the soil was composed of silty sandy particles and the coarser fraction of sand and gravel for other particle size distributions having comparable diameter ranges the contribution of the surface conductivity has been shown to be negligible by other authors bolève et al 2011 in applying eq 8 we also assumed 100 water saturation sw 1 which remained constant during the experiments this assumption holds also in the first phases of the experiment as the saturation of the material was rapidly obtained after the application of the hydraulic head the following scheme is proposed to be used that relates the resistivity changes to erosion process evolution in the material first for each mesh cell of the model the resistivity values are then transformed into porosity variations by adopting eq 10 10 δ ϕ ϕ ρ t ϕ ρ 0 in which δϕ is the porosity of the mesh cell at time t with respect to the initial state t 0 the total material that is lost due to the erosion processes for each mesh cell is related to the porosity change of the specimen therefore the total eroded volume of material can be calculated from the 3d porosity variation δϕ distribution 11 v e v δ ϕ d v δ ϕ mean v tot in which vtot m3 is the total volume of the domain i e the soil volume dv m3 is the volume of each mesh cell ve m3 is the eroded volume and δϕmean is the volume averaged porosity variation the eroded material volume is also equal to the variation of the pore space void volume vv m3 by 12 v e δ ϕ mean v tot δ v v v tot v tot δ v v when the eroded volume is integrated from all the mesh cells this volume can then be correlated to the eroded soil mass if the average specific weight gs of the soil grains is known and is done by 13 m g s δ v v in which m kg is the eroded mass and gs kg m3 was taken as 2537 kg m3 from ferdos et al 2018 for the soil mix used in their erosion studies the eroded mass calculated from eq 13 is the cumulative eroded mass from the tests start to the time of the acquisition and its inversion to calibrate the archie s law parameters we used the inverted resistivities and the time dependent mass removal data a calibration loop of data fitting for archie s law parameters was produced for each inversion and the resistivity changes were then converted into porosity change in media and finally translated to weight loss by eq 13 the weight loss at that specific time were compared with the cumulative eroded mass measured from the experiments the archie s law parameters were tuned to reach minimum error between the calculated eroded mass from ert analysis and the collected data from the laboratory experiments this calibration process is schematically presented in fig 11 we used the first dataset suffusion experiment a to perform the calibration with the proposed scheme and the dataset of suffusion experiment b to validate the optimized model parameters the optimization was carried out in matlab environment using a constrained version of the nelder mead simplex algorithm the results of the calibration and validation of the archie s law parameters are presented in fig 12 and table 2 in both calibration and validation we used the measured water conductivity as input to the archie s law the ranges of water conductivity are reported in table 2 fig 12 illustrates the comparison between the measured and ert derived time dependent cumulative of the eroded dry mass during the course of the experiments as it can be seen from the results in both experiments the removal rate i e the time derivative of the cumulative curve was larger at the beginning of the experiment and gradually decreased with time the erosion continued for about 20 25 h after reaching a minimum rate under the constant water head applied after which the erosion process stopped the calibration yielded a value of 1 42 for the cementation exponent m which is very close to the values that are available in literature for unconsolidated material e g m 1 3 for unconsolidated sands the parameter a slightly exceeded the expected range a 1 indicating that a source of systematic error may be present in the adopted measurement or inversion scheme this is likely to be related to the inversion process in which the error weights could be overestimated or underestimated due to the lack of reciprocal measurements leading to systematic errors in the resolution of the resistivity distributions however as confirmed by the model validation rmse 0 052 kg r2 0 87 the results are successfully reproducible in the estimated eroded mass curves as shown in fig 12 the overall mass balances are preserved even if the fluctuation of the ert derived points can be observed this may represent a drawback when trying to estimate the global erosion rate i e by taking the time derivative of the cumulate curves the quantification of the instantaneous rate with this method might be rather inaccurate a possible solution is to estimate the overall erosion rate by time averaging multiple points of the ert curves however this operation would decrease the time resolution of the method for fast erosion processes on the contrary when the time scale of the erosion processes is much slower than the measurement periods the time averaging technique would lead to a more accurate estimation of the erosion rates under the specific experimental conditions the resistivity variations captured by ert imaging are related to relatively small changes in the porosity values therefore in this particular case it is crucial to acquire the data with a high resolution technique and tightly spaced electrodes in fact the sensitivity of the calibrated archie s model parameters to the resistivity input may in some cases exceed the sensitivity and resolution of the ert images especially in the zones located far away from the electrode arrays the reduced sensitivity may induce an underestimation of the erosion rates or can bias the results of the model calibration procedures from fig 10 this can be observed in the middle of the specimen where the combination of both reduced sensitivity and lower erosion magnitude lead to the presence of a central zone where resistivity changes are below an observable threshold however the influence of this issue to the overall result may be limited in this study as the validation errors rmse r2 in table 2 are still within an acceptable level the reduction is sensitivity however may pose a critical limitation in the field application of this technique mainly because of the practical obstacles which necessarily cause a reduced sensitivity of ert in the field to name a few the difficulty of installing 3d arrays the limited number of installable electrodes the number of available adc channels of the measurement equipment the higher background electromagnetic noise compared to the laboratory the increased electrode contact impedance the large amount of data to be collected stored and processed and the overall costs related to the implementation of high resolution surveys in conclusion the success of an ert investigation in the field strictly depends on both the spatial and time scale at which the phenomena occur in combination with the adopted measurement and processing strategies 4 conclusions we used electrical resistivity tomography ert technique to monitor internal erosion in porous media induced by seepage flow this phenomenon is one of the most common causes of failure of earthen levees and embankment dams an ert system was specifically designed for the time lapse imaging of the electrical properties of porous media at a laboratory scale the components of the systems were optimized to specific requirements in terms of accuracy and speed of acquisition due to the time dependent nature of erosion processes the electrode material and positioning were investigated the latter by numerical modelling which allowed us to define the proper electrode installation requirements for the minimization of the errors due to electrode polarization the system operated with a total of 48 electrodes with multi channel voltage readings of up to 6 electrodes simultaneously we validated the forward and inverse models by seeking for optimal choice of the boundary conditions studying the numerical model sensitivity to mesh size and by experimentally testing the measurement and inversion setup with a known resistivity distribution two erosion i e suffusion tests were performed to reproduce the process of internal erosion of soil particles by water flow within a purposely prepared soil mixture under two different mechanical loadings 0 and 10 kpa vertical stress application on the top of the specimen 3d time lapse monitoring of internal erosion was carried out at regular intervals of 1 h to relate resistivity variations to material structural changes in time during the erosion processes we calculated the porosity variations through the archie s law with parameters calibrated using both the results from the inversions and the measured cumulate of the material eroded from the test chamber comparison of the 3d tomography results with the mass removal data as well as the validation of the identifies archie s parameters were found to be successful we can conclude that ert technique is potentially capable of detecting and quantifying the erosion processes in dams and levees the practical aspects when conducting an ert survey in the field compared to the controlled conditions in the laboratory may represent a limiting factor to the use this technique in real world applications especially with regards to the electrode installation and the limits in installing high resolution 3d arrays in the field however we successfully demonstrated that the method is robust and reliable provided that extensive supplementary information is necessary which should be integrated with the ert survey data credit authorship contribution statement matteo masi conceptualization methodology software validation data curation writing original draft visualization farzad ferdos conceptualization methodology investigation data curation writing original draft visualization project administration gabriella losito conceptualization formal analysis writing review editing luca solari conceptualization writing review editing supervision project administration declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was performed as part of a joint research project in between the royal institute of technology kth sweden and department of civil and environmental engineering dicea of the university of florence italy and was funded by the swedish hydropower centre svenskt vattenkraft centrum svc with funding project number vk10739 the authors acknowledge vattenfall for the help and support in conducting the experiments at vattenfall r d laboratory in älvkarleby sweden the authors are thankful to two anonymous reviewers whose comments and suggestions helped us to improve the quality of the manuscript 
5293,qualitative and quantitative assessments of the impact of track forecast error on tropical cyclone tc quantitative precipitation forecasts qpfs are presented in this study the original and track error corrected qpfs extracted from the global forecast system gfs of 52 tcs over the coastal region of china during 2015 2017 were compared with the global precipitation measurement gpm observations the track forecast error was corrected by shifting the qpf according to the difference between the forecasted and observed tc centers qualitative evaluations revealed that large track forecast error tends to cause severe under forecast of total rainfall volume over a region quantitative assessments showed that the impact of track forecast error generally increases with track forecast error up to 500 km the rapid decline of qpf skill with lead time is mainly attributed to the fast growing track forecast error track forecast error has large impact on moderate to heavy rainfall and little impact on extremely heavy rainfall based on the assessments a new operational post processing method was developed to reduce the impact of track forecast error on qpfs from numerical models the new technique was able to improve the tc qpfs in general and especially at longer lead times keywords tropical cyclones quantitative precipitation forecast track forecast error model verification 1 introduction tropical cyclones tcs are among the most devastating natural disasters worldwide the widespread torrential rainfall along their path often causes deadly floods and destructive landslides leading to life and property loss at the same time tc rainfall can be crucial to water supplies and agriculture over the coastal regions therefore accurate and timely forecasts are required to mitigate the disaster and utilize the water resource brought by tcs over the past few decades significant improvements have been achieved in tc track forecasts with comparatively less progress in intensity forecasts goerss et al 2004 demaria et al 2014 yamaguchi et al 2017 emanuel and zhang 2016 since the intensity and distribution of tc rainfall are resulted from multi scale interactions between tc vortex underlying surface and storm environment houze 2010 accurate predictions of tc rainfall are even more challenging despite the improvements in observation systems data assimilation and numerical weather prediction nwp models the skill of tc quantitative precipitation forecasts qpfs is not yet sufficient to meet the needs of disaster prevention and mitigation climate change mendelsohn et al 2012 scoccimarro et al 2017 and rapid urbanization niyogi et al 2017 doocy et al 2013 put forward even higher demands on tc qpfs therefore there is an urgent need to improve the skill of nwp models on tc qpfs an effective way to improve tc qpf skill is to assess the deficiencies of nwp models and upgrade the related aspects accordingly tuleya et al 2007 evaluated qpfs of 25 u s landfalling tcs between 1995 and 2002 from the geophysical fluid dynamics laboratory gfdl hurricane forecast model their analyses showed that the gfdl model exhibited higher equitable threat scores etss than did the rainfall climatology and persistence r cliper model but suffered from high bias scores marchok et al 2007 evaluated the forecast skill of storm total rainfall of all u s landfalling tcs from 1998 to 2004 by comparing three operational models they pointed out that the global forecast system gfs model had the best performance the north american mesoscale model predicted too little heavy rain while the gfdl hurricane model predicted too much heavy rain especially near the tc core region chen et al 2018 used contiguous rain area cra method to evaluate the qpfs of tcs in the northwestern pacific during 2012 2013 from the australian community climate and earth system simulator access tc model it was shown that pattern error dominates the total tc qpf error followed by volume and displacement error the main problem of access tc model was the overestimation of rainfall volume in short lead time 24 h forecasts and the significant displacement error in longer lead time 72 h forecasts luitel et al 2018 evaluated the tc qpf skill of five nwp models by examining 15 north atlantic tcs that made landfall along the u s coast during 2007 2012 they concluded that the nwp models can provide skillful tc qpfs with lead times up to 48 h further studies were carried to understand the probable error sources of tc qpfs which include tc location intensity vortex structure large scale environment and the representation of microphysical processes and topographic effect etc evaluating the impact of these factors may deepen our understanding of key physical processes related to tc rainfall and provide guidance on developing cost efficient post processing methods tc track is a key factor that determines the distribution of tc rainfall because most of the tc precipitation falls in a narrow swath close to the tc track lonfat et al 2004 although the impact of track forecast error on tc qpfs may seem apparent comprehensive assessments of such impact remain limited in literature marchok et al 2007 compared error statistics of tc qpfs among different models before and after correcting the track forecast error the track forecast error was shown to be a primary contributor to the tc qpf error and the higher qpf skill of gfs was mainly attributed to its superior track forecast skill xie and zhang 2012 used high resolution mesoscale ensemble forecasts to explore the impact of track forecast error on qpfs of typhoon morakot 2009 they found that the correlation between the track forecast error and the normalized precipitation among different ensemble members was high however marchok et al 2007 only briefly compared storm total rainfall among different models while xie and zhang 2012 focused only on one tc these studies are limited in revealing the full impact of track forecast error on tc qpfs improving tc qpf skill through model development is a long term and challenging task therefore previous studies have tried to improve tc qpfs using statistical or dynamical statistical post processing methods based on nwp outputs yue et al 2016 used moist q vector to dynamically interpret wind temperature and dew point temperature from nwp models hong et al 2014 developed an ensemble tc qpf model by averaging the pick out cases from an ensemble prediction system the qpfs were improved over the ones directly produced by nwp models in these studies which suggests the importance of developing post processing methods for better tc qpfs in this paper the impact of track forecast error on tc qpfs over the coastal region of china is qualitatively and quantitatively evaluated using the gfs output and global precipitation measurement gpm observations it is shown that different aspects of tc qpfs are strongly impacted by the track forecast errors the rapid decrease of qpf skill at longer lead times is mainly caused by the growth of track forecast error based on these assessments an operational post processing method is developed to reduce the impact of model track forecast error on tc qpfs the rest of this paper is organized as follows section 2 details the data and methodology used in this study qualitative and quantitative evaluations of the impact of track forecast error on tc qpfs are given in section 3 section 4 proposes a new post processing method for operational tc qpfs and validates its effectiveness conclusions and discussion are given in section 5 2 data and methodology this study analyzed the impact of track forecast error on tc qpfs using 52 tcs which appeared within the 48 h warning line during their life cycles fig 1 over the coastal region of china during 2015 2017 the qpfs were extracted from the output of the operational gfs produced by national centers for environmental prediction ncep and verified against the integrated multi satellite retrievals for global precipitation measurement imerg final precipitation l3 half hourly v05 3imerghh huffman 2015 which is a multi satellite multi sensor multi algorithm and gauge corrected dataset the temporal and spatial resolutions of the gfs qpfs are 3 h and 0 25 0 25 respectively the 0 1 0 1 3imerghh data were interpolated into the same resolution as the gfs output for verification the impact of track forecast error on tc qpfs was assessed by comparing the original and track error corrected qpfs extracted from gfs track forecast error is defined as the great circle distance between the forecasted and observed centers of a tc validated at the same time the forecasted and observed centers were determined by the gfdl vortex tracker tallapragada et al 2013 and the best track dataset ying et al 2014 from china meteorological administration cma respectively the track error correction procedure applied to the gfs qpfs followed that in marchok et al 2007 and was illustrated in fig 2 the 6 hourly best track data were first interpolated into the same 3 hourly interval as the gfs output each 3 h gfs qpf was then translated so that the forecasted tc center matches that of the observation a forecast was assessed if the storm is classified as a tropical cyclone at both the forecast s initial and valid time in the best track data and the maximum lead time was up to 132 h since operational agencies issue tc qpfs in terms of 24 h accumulated rainfall the half hour 3imerghh and the 3 h original and corrected gfs qpfs were aggregated into 24 h accumulated values before verification to focus on the rainfall directly related to tc only 24 h accumulated rainfall within 500 km of the observed tc track was evaluated nogueira and keim 2010 jiang and zipser 2010 prat and nelson 2012 the verification region the purple dashed lines in fig 2 is the area covered by a circle with a 500 km radius moving along the tc track during a 24 h period to better illustrate the variation of the impact of track forecast error on tc qpfs with lead time the 24 h accumulated rainfall was computed and verified every 6 h each 24 h period is considered as a sample and the end hour of the 24 h period is assigned as the lead time of the sample the average of track forecast errors over a 24 h period was used to represent the track forecast error of a sample the impact of track forecast error on tc qpfs was qualitatively examined in terms of rainfall volume and probability distribution rainfall volume is directly related to the threat of inland flooding and was calculated by summing up the product of the rainfall intensity and the representative area of a grid point within 500 km of the tc center rainfall probability distribution was calculated to depict the impact of track forecast error on different rain rates since the distribution of rainfall intensity is nearly logarithmic marchok et al 2007 it was represented in the decibel scale 1 dbr 5 l o g 10 r where r is the 24 h accumulated rainfall at a grid point and dbr is in the range of 0 1 14 15 the quantitative evaluation of the impact of track forecast error on tc qpfs was based on the ets schaefer 1990 gandin and murphy 1992 doswell et al 1990 which is an extension to the traditional threat score ts with a factor to account for random chance and calculated as below 2 ets hits h i t s random hits m i s s e s f a l s e a l a r m s h i t s random 3 hit s random h i t s m i s s e s h i t s f a l s e a l a r m s total where the hits misses and false alarms are the occurrences of the three outcomes in the contigency table table 1 ets ranges from 1 3 to 1 with 0 indicating no skill and 1 indicating a perfect forecast to better illustrate the effect of track error correction a skill score ss was defined as the ratio between the increase of ets after track error correction and the difference between ets of a perfect forecast ets 1 and that of the original forecast murphy 1995 wheatcroft 2019 4 ss et s c e t s o et s p e t s o where the subscripts o c and p stand for the original forecast the track error corrected forecast and a perfect forecast respectively the ss ranges from to 1 with positive negative value indicating an improvement deterioration after track error correction for example a ss of 0 5 means that half of the total possible increase in ets is achieved by the track error correction to evaluate the effectiveness of the post processing method the relative change of ets after being corrected according to subjective track forecast was calculated as below 5 r s et s s e t s o et s o 100 where the subscript s stands for forecast corrected by subjective track forecast the percentage of increase in ets after being corrected by subjective track forecast relative to the increase after being corrected by observed positions was calculated as below 6 p s et s s e t s o et s c e t s o 100 3 results the distributions of 24 h averaged track forecast errors for all samples are shown in fig 3 both the mean value and interquartile range iqr of the track forecast errors increase monotonically with lead time the mean value increases from 54 km at 24 h to 402 km at 132 h despite the large variability more than two thirds of the track forecast errors are less than 200 km fig 3b the increase of track forecast error with lead time and the associated variability have direct impact on the forecasts of rainfall volume within the verification areas fig 4 a shows the rainfall volume error as a function of lead time for the original and corrected qpfs the increasing iqr indicates greater errors at longer lead times for corrected qpfs the over forecast bias becomes larger as lead time increases and this was verified not being caused by the sample difference among different lead times not shown the mean volume errors are marginal in the original qpfs despite the increasing track forecast error with lead time fig 3a fig 4b indicates that the proportion of forecasts with large 300 km track forecast errors increases with lead time despite that more than half of the forecasts still have small 300 km track forecast errors at each lead time except for 132 h the small mean errors of the original qpfs are likely attributed to the cancelation between positive biases in forecasts with small track forecast errors and negative biases in forecasts with large track forecast errors fig 4c further shows the volume error variation with track forecast error there is no obvious difference between volume error distributions of original forecasts and those of corrected forecasts when track forecast errors are less than 300 km large negative biases are shown in the original forecasts when the track forecast errors are large but are greatly reduced after the correction fig 5 further illustrates the impact of track forecast error on different rain rates for each panel the original and corrected qpfs show the similar unimodal distribution with smaller variation and higher frequency at the mode compared with 3imerghh the model generally under forecasts the frequencies for smaller and larger rain rates and over forecasts for median rain rates as shown in fig 5a e the over forecast of the corrected qpfs near the mode becomes more apparent than that of the original qpfs as lead time increases which is consistent with the positive biases at longer lead times shown in fig 4a similar trends of higher frequency near the mode after the correction are observed when track forecast errors are less than 600 km fig 5f h and the distributions of intense rainfall are not significantly affected by track forecast errors the correction of track forecast error has notable impact on the entire rainfall frequency distribution when track forecast errors are greater than 600 km fig 5i j the probability distribution of track error corrected qpfs is shifted to the right with less light to moderate rain and more moderate to heavy rain which is closer to that of the observations above results show that the track forecast error has significant impact on tc qpfs however they are limited in the sense that the spatial distributions of qpfs are not evaluated in above analyses the impact of track forecast error on the spatial distributions of qpfs manifests in different ways as exemplified by the 4 representative cases shown in fig 6 the information of each case and their etss before and after the track error correction are given in table 2 case1 has large track forecast error but the rainfall distribution is close to the observation after the track error correction fig 6a e i according to table 2 the etss increase significantly from 0 03 to 0 49 at 10 mm threshold and from 0 05 to 0 61 at 50 mm threshold after the track error correction in cases like this track forecast error has significant impact on tc qpf case2 also has large track forecast error but the corrected qpf has even greater difference from the observation fig 6b f j the ets at 10 mm threshold decreases significantly from 0 43 to 0 1 after the track error correction in this case the track error correction has negative contribution to the qpf case3 and case4 are examples of small track forecast errors in case3 the elongated rainfall pattern along the storm track was well forecasted fig 6c after the track error correction the rainfall is adjusted to a more accurate location fig 6g k and the ets at 50 mm threshold increases significantly in case4 the model failed to forecast the rainfall center over land and the qpf is not improved after the correction fig 6d h l which is shown by the low etss for the original qpf and little increase after the correction in table 2 above examples indicate that the impact of track forecast error on tc qpfs is complex therefore it is necessary to quantify the impact using etss of the original and track error corrected qpfs the scatter plots of ets as a function of track forecast error for the original qpfs fig 7 a e are compared with those for the corrected qpfs fig 7f j for the original qpfs the ets decreases rapidly with track forecast error the qpfs with track forecast errors greater than 500 km have very low or negative etss the etss of the corrected qpfs for 10 25 50 and 100 mm thresholds fig 7f i are significantly improved especially for those with large track forecast errors 300 km fig 7f i show that even with large track forecast errors corrected forecasts are still able to achieve high etss especially for 50 and 100 mm thresholds such forecasts well predict the rainfall distributions along the tracks despite of the large track forecast errors for the 250 mm threshold most of the original qpfs have etss equal to or less than 0 fig 7e and the etss are improved slightly after the track error correction fig 7j the low etss at large rainfall thresholds are partly attributed to the fact that extremely heavy rainfall is localized and difficult to forecast regardless of the magnitude of track forecast error the distributions of ss with respect to track forecast error and rainfall threshold are shown in fig 8 the boxplots in fig 8a d show that the median and iqr of sss generally increase with track forecast error up to 500 km it is noted that the sample sizes are much smaller when the track forecast errors are greater than 600 km so the boxplots may not be statistically representative the medians of sss at 25 and 50 mm are larger than those at 10 and 100 mm the range between the minimum and maximum of sss increases rapidly with track forecast error up to 400 km then gradually decreases parts of the forecasts with small track forecast errors have negative sss but the forecasts with track forecast errors greater than 500 km are generally improved after the track error correction fig 8e shows that the majority of sss at 250 mm are around 0 except for a few relatively large values which indicates little impact of track forecast error on extremely heavy rainfall both the magnitude of track forecast error and rainfall distribution around the tc center affect the impact of track forecast error on tc qpfs table 3 summarizes the relative proportions of forecasts with negative impact ss 0 small impact 0 ss 0 2 and large impact ss 0 2 at 50 mm according to the magnitude of track forecast error and the ets of track error corrected qpfs the 50 mm threshold is used because of the increasing potential to cause nature disasters and the large sample size the results are consistent at other thresholds viz 10 25 and 100 mm corrected forecast with ets 0 3 the median of etss for 50 mm is 0 32 is considered as good which indicates that the model has relatively similar prediction of rainfall distribution along forecast track to the observed distribution along observed track before the correction the forecasts are also divided into two groups by the magnitude of track forecast error 300 or 300 km the results are similar using other thresholds e g 400 km forecasts with small track forecast errors and high corrected etss have the highest frequency 50 in this category only 14 of the forecasts have ss 0 for large track forecast errors the frequencies of forecasts with high or low etss are close nearly half of the forecasts can well predict the rainfall structure along their tracks ets 0 3 despite of the large track forecast errors for forecasts with large track errors and low etss only 15 have ss 0 and over a half have 0 ss 0 2 most of the original qpfs with large track forecast errors are improved after the correction track forecast errors are more likely 30 to have negative impact on qpfs when track forecast errors are small and the rainfall distributions are not well predicted along the tracks the mean etss of the original and corrected qpfs at different lead times are shown in fig 9 the ets deteriorates sharply with lead time for the original qpfs while only drops slightly for the corrected qpfs this suggests that the rapid decline of qpf skill with lead time is mainly attributed to the increase of track forecast error the mean values of sss at different lead times are also given in fig 9 the cyan lines which increase up to 0 2 at 132 h except for those at 250 mm the sss are generally larger at 25 and 50 mm indicating that correcting track forecast error is more effective at these rainfall thresholds 4 a post processing method results in the previous section show that tc qpf skill is closely related to the magnitude of track forecast error tc qpfs can be potentially improved if the track forecast errors can be corrected the similar correction procedure used in previous sections can be applied to operational qpfs during active tc periods provided there are better tc track forecasts this is indeed feasible according to the operational qpf schedule at cma cma makes routine 24 h accumulated rainfall forecasts initiated at 00 utc and 12 utc for the next few days and these forecasts are issued at 22 and 10 utc respectively nwp model outputs are used as the primary guidance for these operational qpfs there is always a time lag before nwp model forecasts are available due to computation and data transfer for example the gfs model takes more than 4 h to finish a 120 h forecast and the european centre for medium range weather forecasts ecmwf model takes more than 6 h as shown in fig 10 the latest nwp forecasts that the operational qpf initiated at 12 00 utc can refer to are usually initiated at 00 12 utc the skill of tc qpfs from nwp models drops quickly with lead time as shown in fig 9 therefore the 12 h time lag between the initial time of the operational qpf and that of the nwp model forecast may limit the accuracy of operational qpfs during active tcs independent tc track forecasts up to 120 h are issued operationally by cma every 6 h based on the outputs of multiple ensemble models with subjective adjustments according to the forecaster s experience and the latest observed tc location as illustrated in fig 10 the subjective track forecast initiated at 06 18 utc is released within an hour after locating the tc at 06 18 utc so there is only a 6 h time lag between the initial time of the subjective track forecast and that of the operational qpf the track forecast errors of the cma subjective track forecasts are compared with those of gfs in fig 11 for the same tcs studied in previous sections the errors of the latest available subjective track forecasts are generally smaller than those of the corresponding gfs forecasts since the subjective track forecasts are generally more accurate a new post processing method is developed by correcting the qpfs from nwp models according to the subjective track forecasts three steps are taken for each nwp model qpf at each operational qpf cycle as follows 1 the subjective track forecast is first interpolated into the same interval as nwp model output which is usually 3 h 2 the nwp model qpf at each lead time e g each 3 h rainfall forecast is corrected according to the subjective track forecast validated at the same time using the same procedure described in section 2 no correction is applied if the subjective track forecast is not available 3 the track error corrected qpfs are aggregated into required accumulation intervals for operational use the correcting procedure can be applied as soon as the nwp model qpfs and subjective track forecast are available the corrected qpfs will be ready in a few minutes so they may serve as the guidance to make operational qpfs the mean etss of the gfs qpfs corrected by the above post processing method are compared with those of the original forecasts in fig 12 the etss are generally improved after the correction however they are still far short of the skill corrected using the best track at 10 25 and 50 mm the improvements in mean etss after being corrected by the subjective track forecasts are around 10 30 relative to those being corrected by the observed positions at 100 mm the relative increments are generally smaller negative for small lead times and around 10 for longer lead times relative changes of mean etss after being corrected according to subjective track forecasts show that the improvements of qpfs are most significant after 48 h at 25 50 and 100 mm the etss at 250 mm deteriorate after the post processing procedure which indicates that this method is unable to improve the extremely torrential rainfall forecast skill and should be used with caution dealing with extremely torrential rain in operational forecast 5 summary and conclusion this study assessed the impact of track forecast error on the qpfs of 52 tcs over the coastal region of china during 2015 2017 the qpfs extracted from gfs were evaluated against the gpm satellite observations before and after correcting the track forecast errors qualitative evaluations show that the original forecasts of rainfall volume have small mean errors at different lead times and the track forecast errors have little impact on the forecasts of rainfall volume when the track forecast error are less than 300 km when the track forecast errors are greater than 300 km the under estimation of rainfall volume becomes significant in the original forecasts the impact of the track forecast error varies at different rain rates when the track forecast errors are small the frequencies of light moderate rain rates are higher lower in the original than the corrected forecasts when the track forecast errors are large all rain rates are impacted and the original forecasts have overall lower frequencies for intense rain rates which is consistent with the severe under forecasts in the original forecasts ets is used to quantitatively assess the impact of track forecast error on tc qpfs the ets deteriorates rapidly with track forecast error for the original qpfs and the etss of track error corrected forecasts are significantly improved except for rainfall over 250 mm generally the impact of track forecast error on tc qpfs increases with track forecast error up to 500 km averaged etss show that the qpfs at different lead times can achieve a similar skill after correcting the track forecast errors which indicates that the rapid decline of qpf skill with lead time in the original forecasts is mainly attributed to the fast growing track forecast error the impact of track forecast error is more significant at 25 mm and 50 mm than other thresholds based on the assessments a new post processing method for operational qpfs during active tcs was developed validation results show that this method can improve the tc qpfs especially at longer lead times results of the post processing method show that the mean etss of the tc qpfs at longer lead times can be improved by up to 60 when qpfs are corrected according to the track forecasts with relatively smaller track errors the skill of tc track forecast based on nwp models has been steadily improved in recent decades and not yet reached the predictability limit plu 2011 thus there is still potential for better tc qpfs even if other error sources e g tc intensity forecast error of model qpf are not reduced this paper presents a preliminary assessment of the impact of track forecast error and a tentative method to alleviate its negative effect on tc qpfs near the coast of china future studies will focus on the role of tc intensity to the impact of track forecast error on tc qpfs and the underlying causes credit authorship contribution statement yuan zhuang conceptualization methodology writing original draft visualization xiaowen tang supervision investigation writing original draft yuan wang funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by national key research and development project of china 2018yfc1507301 and the national natural science foundation of china grant 41505045 the tropical cyclone best track data are provided by cma and are available at http tcdata typhoon org cn gfs forecast data can be downloaded freely at https rda ucar edu datasets ds084 1 the satellite data were provided by the nasa s precipitation processing system pps which develop and compute the gpm 3imerghh as a contribution to gpm and archived at the nasa ges disc it can be downloaded freely at https giovanni sci gsfc nasa gov giovanni we thank the two anonymous reviewers for constructive suggestions and comments that greatly improved the manuscript 
5293,qualitative and quantitative assessments of the impact of track forecast error on tropical cyclone tc quantitative precipitation forecasts qpfs are presented in this study the original and track error corrected qpfs extracted from the global forecast system gfs of 52 tcs over the coastal region of china during 2015 2017 were compared with the global precipitation measurement gpm observations the track forecast error was corrected by shifting the qpf according to the difference between the forecasted and observed tc centers qualitative evaluations revealed that large track forecast error tends to cause severe under forecast of total rainfall volume over a region quantitative assessments showed that the impact of track forecast error generally increases with track forecast error up to 500 km the rapid decline of qpf skill with lead time is mainly attributed to the fast growing track forecast error track forecast error has large impact on moderate to heavy rainfall and little impact on extremely heavy rainfall based on the assessments a new operational post processing method was developed to reduce the impact of track forecast error on qpfs from numerical models the new technique was able to improve the tc qpfs in general and especially at longer lead times keywords tropical cyclones quantitative precipitation forecast track forecast error model verification 1 introduction tropical cyclones tcs are among the most devastating natural disasters worldwide the widespread torrential rainfall along their path often causes deadly floods and destructive landslides leading to life and property loss at the same time tc rainfall can be crucial to water supplies and agriculture over the coastal regions therefore accurate and timely forecasts are required to mitigate the disaster and utilize the water resource brought by tcs over the past few decades significant improvements have been achieved in tc track forecasts with comparatively less progress in intensity forecasts goerss et al 2004 demaria et al 2014 yamaguchi et al 2017 emanuel and zhang 2016 since the intensity and distribution of tc rainfall are resulted from multi scale interactions between tc vortex underlying surface and storm environment houze 2010 accurate predictions of tc rainfall are even more challenging despite the improvements in observation systems data assimilation and numerical weather prediction nwp models the skill of tc quantitative precipitation forecasts qpfs is not yet sufficient to meet the needs of disaster prevention and mitigation climate change mendelsohn et al 2012 scoccimarro et al 2017 and rapid urbanization niyogi et al 2017 doocy et al 2013 put forward even higher demands on tc qpfs therefore there is an urgent need to improve the skill of nwp models on tc qpfs an effective way to improve tc qpf skill is to assess the deficiencies of nwp models and upgrade the related aspects accordingly tuleya et al 2007 evaluated qpfs of 25 u s landfalling tcs between 1995 and 2002 from the geophysical fluid dynamics laboratory gfdl hurricane forecast model their analyses showed that the gfdl model exhibited higher equitable threat scores etss than did the rainfall climatology and persistence r cliper model but suffered from high bias scores marchok et al 2007 evaluated the forecast skill of storm total rainfall of all u s landfalling tcs from 1998 to 2004 by comparing three operational models they pointed out that the global forecast system gfs model had the best performance the north american mesoscale model predicted too little heavy rain while the gfdl hurricane model predicted too much heavy rain especially near the tc core region chen et al 2018 used contiguous rain area cra method to evaluate the qpfs of tcs in the northwestern pacific during 2012 2013 from the australian community climate and earth system simulator access tc model it was shown that pattern error dominates the total tc qpf error followed by volume and displacement error the main problem of access tc model was the overestimation of rainfall volume in short lead time 24 h forecasts and the significant displacement error in longer lead time 72 h forecasts luitel et al 2018 evaluated the tc qpf skill of five nwp models by examining 15 north atlantic tcs that made landfall along the u s coast during 2007 2012 they concluded that the nwp models can provide skillful tc qpfs with lead times up to 48 h further studies were carried to understand the probable error sources of tc qpfs which include tc location intensity vortex structure large scale environment and the representation of microphysical processes and topographic effect etc evaluating the impact of these factors may deepen our understanding of key physical processes related to tc rainfall and provide guidance on developing cost efficient post processing methods tc track is a key factor that determines the distribution of tc rainfall because most of the tc precipitation falls in a narrow swath close to the tc track lonfat et al 2004 although the impact of track forecast error on tc qpfs may seem apparent comprehensive assessments of such impact remain limited in literature marchok et al 2007 compared error statistics of tc qpfs among different models before and after correcting the track forecast error the track forecast error was shown to be a primary contributor to the tc qpf error and the higher qpf skill of gfs was mainly attributed to its superior track forecast skill xie and zhang 2012 used high resolution mesoscale ensemble forecasts to explore the impact of track forecast error on qpfs of typhoon morakot 2009 they found that the correlation between the track forecast error and the normalized precipitation among different ensemble members was high however marchok et al 2007 only briefly compared storm total rainfall among different models while xie and zhang 2012 focused only on one tc these studies are limited in revealing the full impact of track forecast error on tc qpfs improving tc qpf skill through model development is a long term and challenging task therefore previous studies have tried to improve tc qpfs using statistical or dynamical statistical post processing methods based on nwp outputs yue et al 2016 used moist q vector to dynamically interpret wind temperature and dew point temperature from nwp models hong et al 2014 developed an ensemble tc qpf model by averaging the pick out cases from an ensemble prediction system the qpfs were improved over the ones directly produced by nwp models in these studies which suggests the importance of developing post processing methods for better tc qpfs in this paper the impact of track forecast error on tc qpfs over the coastal region of china is qualitatively and quantitatively evaluated using the gfs output and global precipitation measurement gpm observations it is shown that different aspects of tc qpfs are strongly impacted by the track forecast errors the rapid decrease of qpf skill at longer lead times is mainly caused by the growth of track forecast error based on these assessments an operational post processing method is developed to reduce the impact of model track forecast error on tc qpfs the rest of this paper is organized as follows section 2 details the data and methodology used in this study qualitative and quantitative evaluations of the impact of track forecast error on tc qpfs are given in section 3 section 4 proposes a new post processing method for operational tc qpfs and validates its effectiveness conclusions and discussion are given in section 5 2 data and methodology this study analyzed the impact of track forecast error on tc qpfs using 52 tcs which appeared within the 48 h warning line during their life cycles fig 1 over the coastal region of china during 2015 2017 the qpfs were extracted from the output of the operational gfs produced by national centers for environmental prediction ncep and verified against the integrated multi satellite retrievals for global precipitation measurement imerg final precipitation l3 half hourly v05 3imerghh huffman 2015 which is a multi satellite multi sensor multi algorithm and gauge corrected dataset the temporal and spatial resolutions of the gfs qpfs are 3 h and 0 25 0 25 respectively the 0 1 0 1 3imerghh data were interpolated into the same resolution as the gfs output for verification the impact of track forecast error on tc qpfs was assessed by comparing the original and track error corrected qpfs extracted from gfs track forecast error is defined as the great circle distance between the forecasted and observed centers of a tc validated at the same time the forecasted and observed centers were determined by the gfdl vortex tracker tallapragada et al 2013 and the best track dataset ying et al 2014 from china meteorological administration cma respectively the track error correction procedure applied to the gfs qpfs followed that in marchok et al 2007 and was illustrated in fig 2 the 6 hourly best track data were first interpolated into the same 3 hourly interval as the gfs output each 3 h gfs qpf was then translated so that the forecasted tc center matches that of the observation a forecast was assessed if the storm is classified as a tropical cyclone at both the forecast s initial and valid time in the best track data and the maximum lead time was up to 132 h since operational agencies issue tc qpfs in terms of 24 h accumulated rainfall the half hour 3imerghh and the 3 h original and corrected gfs qpfs were aggregated into 24 h accumulated values before verification to focus on the rainfall directly related to tc only 24 h accumulated rainfall within 500 km of the observed tc track was evaluated nogueira and keim 2010 jiang and zipser 2010 prat and nelson 2012 the verification region the purple dashed lines in fig 2 is the area covered by a circle with a 500 km radius moving along the tc track during a 24 h period to better illustrate the variation of the impact of track forecast error on tc qpfs with lead time the 24 h accumulated rainfall was computed and verified every 6 h each 24 h period is considered as a sample and the end hour of the 24 h period is assigned as the lead time of the sample the average of track forecast errors over a 24 h period was used to represent the track forecast error of a sample the impact of track forecast error on tc qpfs was qualitatively examined in terms of rainfall volume and probability distribution rainfall volume is directly related to the threat of inland flooding and was calculated by summing up the product of the rainfall intensity and the representative area of a grid point within 500 km of the tc center rainfall probability distribution was calculated to depict the impact of track forecast error on different rain rates since the distribution of rainfall intensity is nearly logarithmic marchok et al 2007 it was represented in the decibel scale 1 dbr 5 l o g 10 r where r is the 24 h accumulated rainfall at a grid point and dbr is in the range of 0 1 14 15 the quantitative evaluation of the impact of track forecast error on tc qpfs was based on the ets schaefer 1990 gandin and murphy 1992 doswell et al 1990 which is an extension to the traditional threat score ts with a factor to account for random chance and calculated as below 2 ets hits h i t s random hits m i s s e s f a l s e a l a r m s h i t s random 3 hit s random h i t s m i s s e s h i t s f a l s e a l a r m s total where the hits misses and false alarms are the occurrences of the three outcomes in the contigency table table 1 ets ranges from 1 3 to 1 with 0 indicating no skill and 1 indicating a perfect forecast to better illustrate the effect of track error correction a skill score ss was defined as the ratio between the increase of ets after track error correction and the difference between ets of a perfect forecast ets 1 and that of the original forecast murphy 1995 wheatcroft 2019 4 ss et s c e t s o et s p e t s o where the subscripts o c and p stand for the original forecast the track error corrected forecast and a perfect forecast respectively the ss ranges from to 1 with positive negative value indicating an improvement deterioration after track error correction for example a ss of 0 5 means that half of the total possible increase in ets is achieved by the track error correction to evaluate the effectiveness of the post processing method the relative change of ets after being corrected according to subjective track forecast was calculated as below 5 r s et s s e t s o et s o 100 where the subscript s stands for forecast corrected by subjective track forecast the percentage of increase in ets after being corrected by subjective track forecast relative to the increase after being corrected by observed positions was calculated as below 6 p s et s s e t s o et s c e t s o 100 3 results the distributions of 24 h averaged track forecast errors for all samples are shown in fig 3 both the mean value and interquartile range iqr of the track forecast errors increase monotonically with lead time the mean value increases from 54 km at 24 h to 402 km at 132 h despite the large variability more than two thirds of the track forecast errors are less than 200 km fig 3b the increase of track forecast error with lead time and the associated variability have direct impact on the forecasts of rainfall volume within the verification areas fig 4 a shows the rainfall volume error as a function of lead time for the original and corrected qpfs the increasing iqr indicates greater errors at longer lead times for corrected qpfs the over forecast bias becomes larger as lead time increases and this was verified not being caused by the sample difference among different lead times not shown the mean volume errors are marginal in the original qpfs despite the increasing track forecast error with lead time fig 3a fig 4b indicates that the proportion of forecasts with large 300 km track forecast errors increases with lead time despite that more than half of the forecasts still have small 300 km track forecast errors at each lead time except for 132 h the small mean errors of the original qpfs are likely attributed to the cancelation between positive biases in forecasts with small track forecast errors and negative biases in forecasts with large track forecast errors fig 4c further shows the volume error variation with track forecast error there is no obvious difference between volume error distributions of original forecasts and those of corrected forecasts when track forecast errors are less than 300 km large negative biases are shown in the original forecasts when the track forecast errors are large but are greatly reduced after the correction fig 5 further illustrates the impact of track forecast error on different rain rates for each panel the original and corrected qpfs show the similar unimodal distribution with smaller variation and higher frequency at the mode compared with 3imerghh the model generally under forecasts the frequencies for smaller and larger rain rates and over forecasts for median rain rates as shown in fig 5a e the over forecast of the corrected qpfs near the mode becomes more apparent than that of the original qpfs as lead time increases which is consistent with the positive biases at longer lead times shown in fig 4a similar trends of higher frequency near the mode after the correction are observed when track forecast errors are less than 600 km fig 5f h and the distributions of intense rainfall are not significantly affected by track forecast errors the correction of track forecast error has notable impact on the entire rainfall frequency distribution when track forecast errors are greater than 600 km fig 5i j the probability distribution of track error corrected qpfs is shifted to the right with less light to moderate rain and more moderate to heavy rain which is closer to that of the observations above results show that the track forecast error has significant impact on tc qpfs however they are limited in the sense that the spatial distributions of qpfs are not evaluated in above analyses the impact of track forecast error on the spatial distributions of qpfs manifests in different ways as exemplified by the 4 representative cases shown in fig 6 the information of each case and their etss before and after the track error correction are given in table 2 case1 has large track forecast error but the rainfall distribution is close to the observation after the track error correction fig 6a e i according to table 2 the etss increase significantly from 0 03 to 0 49 at 10 mm threshold and from 0 05 to 0 61 at 50 mm threshold after the track error correction in cases like this track forecast error has significant impact on tc qpf case2 also has large track forecast error but the corrected qpf has even greater difference from the observation fig 6b f j the ets at 10 mm threshold decreases significantly from 0 43 to 0 1 after the track error correction in this case the track error correction has negative contribution to the qpf case3 and case4 are examples of small track forecast errors in case3 the elongated rainfall pattern along the storm track was well forecasted fig 6c after the track error correction the rainfall is adjusted to a more accurate location fig 6g k and the ets at 50 mm threshold increases significantly in case4 the model failed to forecast the rainfall center over land and the qpf is not improved after the correction fig 6d h l which is shown by the low etss for the original qpf and little increase after the correction in table 2 above examples indicate that the impact of track forecast error on tc qpfs is complex therefore it is necessary to quantify the impact using etss of the original and track error corrected qpfs the scatter plots of ets as a function of track forecast error for the original qpfs fig 7 a e are compared with those for the corrected qpfs fig 7f j for the original qpfs the ets decreases rapidly with track forecast error the qpfs with track forecast errors greater than 500 km have very low or negative etss the etss of the corrected qpfs for 10 25 50 and 100 mm thresholds fig 7f i are significantly improved especially for those with large track forecast errors 300 km fig 7f i show that even with large track forecast errors corrected forecasts are still able to achieve high etss especially for 50 and 100 mm thresholds such forecasts well predict the rainfall distributions along the tracks despite of the large track forecast errors for the 250 mm threshold most of the original qpfs have etss equal to or less than 0 fig 7e and the etss are improved slightly after the track error correction fig 7j the low etss at large rainfall thresholds are partly attributed to the fact that extremely heavy rainfall is localized and difficult to forecast regardless of the magnitude of track forecast error the distributions of ss with respect to track forecast error and rainfall threshold are shown in fig 8 the boxplots in fig 8a d show that the median and iqr of sss generally increase with track forecast error up to 500 km it is noted that the sample sizes are much smaller when the track forecast errors are greater than 600 km so the boxplots may not be statistically representative the medians of sss at 25 and 50 mm are larger than those at 10 and 100 mm the range between the minimum and maximum of sss increases rapidly with track forecast error up to 400 km then gradually decreases parts of the forecasts with small track forecast errors have negative sss but the forecasts with track forecast errors greater than 500 km are generally improved after the track error correction fig 8e shows that the majority of sss at 250 mm are around 0 except for a few relatively large values which indicates little impact of track forecast error on extremely heavy rainfall both the magnitude of track forecast error and rainfall distribution around the tc center affect the impact of track forecast error on tc qpfs table 3 summarizes the relative proportions of forecasts with negative impact ss 0 small impact 0 ss 0 2 and large impact ss 0 2 at 50 mm according to the magnitude of track forecast error and the ets of track error corrected qpfs the 50 mm threshold is used because of the increasing potential to cause nature disasters and the large sample size the results are consistent at other thresholds viz 10 25 and 100 mm corrected forecast with ets 0 3 the median of etss for 50 mm is 0 32 is considered as good which indicates that the model has relatively similar prediction of rainfall distribution along forecast track to the observed distribution along observed track before the correction the forecasts are also divided into two groups by the magnitude of track forecast error 300 or 300 km the results are similar using other thresholds e g 400 km forecasts with small track forecast errors and high corrected etss have the highest frequency 50 in this category only 14 of the forecasts have ss 0 for large track forecast errors the frequencies of forecasts with high or low etss are close nearly half of the forecasts can well predict the rainfall structure along their tracks ets 0 3 despite of the large track forecast errors for forecasts with large track errors and low etss only 15 have ss 0 and over a half have 0 ss 0 2 most of the original qpfs with large track forecast errors are improved after the correction track forecast errors are more likely 30 to have negative impact on qpfs when track forecast errors are small and the rainfall distributions are not well predicted along the tracks the mean etss of the original and corrected qpfs at different lead times are shown in fig 9 the ets deteriorates sharply with lead time for the original qpfs while only drops slightly for the corrected qpfs this suggests that the rapid decline of qpf skill with lead time is mainly attributed to the increase of track forecast error the mean values of sss at different lead times are also given in fig 9 the cyan lines which increase up to 0 2 at 132 h except for those at 250 mm the sss are generally larger at 25 and 50 mm indicating that correcting track forecast error is more effective at these rainfall thresholds 4 a post processing method results in the previous section show that tc qpf skill is closely related to the magnitude of track forecast error tc qpfs can be potentially improved if the track forecast errors can be corrected the similar correction procedure used in previous sections can be applied to operational qpfs during active tc periods provided there are better tc track forecasts this is indeed feasible according to the operational qpf schedule at cma cma makes routine 24 h accumulated rainfall forecasts initiated at 00 utc and 12 utc for the next few days and these forecasts are issued at 22 and 10 utc respectively nwp model outputs are used as the primary guidance for these operational qpfs there is always a time lag before nwp model forecasts are available due to computation and data transfer for example the gfs model takes more than 4 h to finish a 120 h forecast and the european centre for medium range weather forecasts ecmwf model takes more than 6 h as shown in fig 10 the latest nwp forecasts that the operational qpf initiated at 12 00 utc can refer to are usually initiated at 00 12 utc the skill of tc qpfs from nwp models drops quickly with lead time as shown in fig 9 therefore the 12 h time lag between the initial time of the operational qpf and that of the nwp model forecast may limit the accuracy of operational qpfs during active tcs independent tc track forecasts up to 120 h are issued operationally by cma every 6 h based on the outputs of multiple ensemble models with subjective adjustments according to the forecaster s experience and the latest observed tc location as illustrated in fig 10 the subjective track forecast initiated at 06 18 utc is released within an hour after locating the tc at 06 18 utc so there is only a 6 h time lag between the initial time of the subjective track forecast and that of the operational qpf the track forecast errors of the cma subjective track forecasts are compared with those of gfs in fig 11 for the same tcs studied in previous sections the errors of the latest available subjective track forecasts are generally smaller than those of the corresponding gfs forecasts since the subjective track forecasts are generally more accurate a new post processing method is developed by correcting the qpfs from nwp models according to the subjective track forecasts three steps are taken for each nwp model qpf at each operational qpf cycle as follows 1 the subjective track forecast is first interpolated into the same interval as nwp model output which is usually 3 h 2 the nwp model qpf at each lead time e g each 3 h rainfall forecast is corrected according to the subjective track forecast validated at the same time using the same procedure described in section 2 no correction is applied if the subjective track forecast is not available 3 the track error corrected qpfs are aggregated into required accumulation intervals for operational use the correcting procedure can be applied as soon as the nwp model qpfs and subjective track forecast are available the corrected qpfs will be ready in a few minutes so they may serve as the guidance to make operational qpfs the mean etss of the gfs qpfs corrected by the above post processing method are compared with those of the original forecasts in fig 12 the etss are generally improved after the correction however they are still far short of the skill corrected using the best track at 10 25 and 50 mm the improvements in mean etss after being corrected by the subjective track forecasts are around 10 30 relative to those being corrected by the observed positions at 100 mm the relative increments are generally smaller negative for small lead times and around 10 for longer lead times relative changes of mean etss after being corrected according to subjective track forecasts show that the improvements of qpfs are most significant after 48 h at 25 50 and 100 mm the etss at 250 mm deteriorate after the post processing procedure which indicates that this method is unable to improve the extremely torrential rainfall forecast skill and should be used with caution dealing with extremely torrential rain in operational forecast 5 summary and conclusion this study assessed the impact of track forecast error on the qpfs of 52 tcs over the coastal region of china during 2015 2017 the qpfs extracted from gfs were evaluated against the gpm satellite observations before and after correcting the track forecast errors qualitative evaluations show that the original forecasts of rainfall volume have small mean errors at different lead times and the track forecast errors have little impact on the forecasts of rainfall volume when the track forecast error are less than 300 km when the track forecast errors are greater than 300 km the under estimation of rainfall volume becomes significant in the original forecasts the impact of the track forecast error varies at different rain rates when the track forecast errors are small the frequencies of light moderate rain rates are higher lower in the original than the corrected forecasts when the track forecast errors are large all rain rates are impacted and the original forecasts have overall lower frequencies for intense rain rates which is consistent with the severe under forecasts in the original forecasts ets is used to quantitatively assess the impact of track forecast error on tc qpfs the ets deteriorates rapidly with track forecast error for the original qpfs and the etss of track error corrected forecasts are significantly improved except for rainfall over 250 mm generally the impact of track forecast error on tc qpfs increases with track forecast error up to 500 km averaged etss show that the qpfs at different lead times can achieve a similar skill after correcting the track forecast errors which indicates that the rapid decline of qpf skill with lead time in the original forecasts is mainly attributed to the fast growing track forecast error the impact of track forecast error is more significant at 25 mm and 50 mm than other thresholds based on the assessments a new post processing method for operational qpfs during active tcs was developed validation results show that this method can improve the tc qpfs especially at longer lead times results of the post processing method show that the mean etss of the tc qpfs at longer lead times can be improved by up to 60 when qpfs are corrected according to the track forecasts with relatively smaller track errors the skill of tc track forecast based on nwp models has been steadily improved in recent decades and not yet reached the predictability limit plu 2011 thus there is still potential for better tc qpfs even if other error sources e g tc intensity forecast error of model qpf are not reduced this paper presents a preliminary assessment of the impact of track forecast error and a tentative method to alleviate its negative effect on tc qpfs near the coast of china future studies will focus on the role of tc intensity to the impact of track forecast error on tc qpfs and the underlying causes credit authorship contribution statement yuan zhuang conceptualization methodology writing original draft visualization xiaowen tang supervision investigation writing original draft yuan wang funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by national key research and development project of china 2018yfc1507301 and the national natural science foundation of china grant 41505045 the tropical cyclone best track data are provided by cma and are available at http tcdata typhoon org cn gfs forecast data can be downloaded freely at https rda ucar edu datasets ds084 1 the satellite data were provided by the nasa s precipitation processing system pps which develop and compute the gpm 3imerghh as a contribution to gpm and archived at the nasa ges disc it can be downloaded freely at https giovanni sci gsfc nasa gov giovanni we thank the two anonymous reviewers for constructive suggestions and comments that greatly improved the manuscript 
5294,water conducting cracks and mined out area caused by coal mining change the regional hydrological processes to address this issue this research proposed a grid based distributed hydrological model for coal mined out area gdhcma and validated the model in one representative coal mining watershed wujiayao watershed in china the impact of coal mining on wet front depth was further analyzed based on the gdhcma model the results revealed that 1 ground subsidence or cracks induced by coal mining accelerate the leakage of water flow into the mined out area or replenish the groundwater reservoir thereby reducing the flood peak flow 2 the parameters of gdhcma model was calibrated by the shuffled complex evolution sce global search algorithm and the model showed high accuracy before and after coal mining during the pre coal mining period the calculated nse nash sutcliffe efficiency coefficient was above 0 9 and the error percentage of peak flow and flood volume was less than 15 during the coal mining period the main improvement is that the lower boundary conditions for the calculation of unsaturated soil infiltration are treated with free drainage boundaries the calculated mean nse is 0 95 the error percentages of flood peak and flood volume are less than 10 and the peak time error is 0 3 the leading factors affecting the downward depth of the wetting front are rainfall soil type the coal mined out area etc the above are of great practical significance for studying the mechanism of the coal mining on the water cycle keywords coal mined out area agrid based distributed hydrological model maximum wetting front depth wujiayao watershed 1 introduction coal as one of the most important energy sources induces great economic benefits however it also causing a series of environmental problems such as soil erosion vegetation withering damage to surface water and groundwater water pollution etc during coal mining and utilization qiao et al 2016 shang et al 2016 specifically the coal seam is adjacent to the underground aquifer and long term large scope mining will drain into coal seam thereby forming the coal mined out area xin et al 2014a b when coal mining subsidence extends to the ground surface it will cause surface cracking or collapse further accelerating the surface runoff into the ground and reducing the water storage capacity of the reservoir mamurekli 2010 for example in china due to coal mining the total water resources in changzhi city shanxi province decreased from 2 296 billion m3 per year in 1997 to 1 907 billion m3 per year in 2017 ping et al 2017 coal mining can induce surface subsidence and destroy the original hydrological cycle such as affecting the conversion efficient between surface water and groundwater accelerating the infiltration rate of surface runoff further changing the regional water balance which affect the healthy development of the local ecological environment tiwary 2001 xin et al 2014a b moreover large scope coal mining has led to rapid weakening or even disruption of river runoff in some areas wang et al 2018 palmer and hondula 2014 therefore research concerning the coal mining impact on the hydrological process is still inadequate especially for solving the local ecological and environmental problems caused by long term and large scope coal mining research on the impact of coal mining on water resources started from the 1980 s at the beginning it mainly focused on the impact of coal mining on groundwater the research methods mainly included theoretical research experimental analysis and numerical simulation research for example britton et al 1989 and colin and booth 1986 researched the coal mining impact on regional groundwater aquifers and proposed the hydrogeological effect which mainly used to describe the water quantity changes and ecosystem impacts caused by coal mining cuenca and hanssen 2008 adopted satellite observations to research the situation of ground subsidence caused by coal mining in the wassenberg region of germany karaman et al 1999 studied the changes of groundwater table within the boundaries and area of coal mining and predicted the water levels in aquifers kim et al 1997 used the finite element method to study the relationship between overburden rupture and groundwater flow under mining conditions and described the reasons for groundwater level decline utilizing the long term water level monitoring data and wellbore exploration data during the coal mining tonder et al 2007 adopted the hydrodynamic mudflow model to predict the rising water levels in coal mined out areas zhang and liu 2002 established a groundwater seepage model to simulate the changes in groundwater flow fields after coal mining indicating that the pit drainage will continue to increase with the expansion of the mining area cui 2015 used the numerical simulations to verify that coal mining may dredge large areas of submerged aquifers resulting in a significant drop in confined water levels wang 2018 and yan 2011 studied the changes of water content and water level in aquifers with the progress of coal mining based on gms model and then analyzed the relationship between aquifers and other aquifers in recent years with the increasingly serious problem of water resources in mining areas coal mining has also developed from a focus on the impact of groundwater to a study of the impact on surface water shen 2011 jiang et al 2010 duan et al 1992 the impact of coal mining on surface water is mainly reflected by the ground subsidence and cracks formed by coal mining which changed the underlying surface conditions and affected the original slope production and convergence process by intercepting precipitation the research methods can be divided into three classes simple statistical comparison application of multiple regression models and application of distributed hydrological models for example wang and you 2016 analyzed the 32 year 1956 1988 precipitation and discharge relationship of the yangwu river in china and concluded that the ratio coefficient of rainfall to base flow during the large scale mining period has been reduced by nearly 1 3 zhang et al 2011 studied the flow attenuation of the ulan mulun river in the daliuta mining area and concluded that natural factors and human factors accounted for 10 5 and 89 5 respectively of the human factors 77 3 were caused by coal mining activities based on statistical methods and multiple regression methods zhang and liu 2002 found that the annual mean runoff in the shenfu coal mined out area was about one fifth of that before coal mining activities coal mining has reduced annual river runoff by 5 72 million m3 accounting for 32 2 of the total runoff reduction jiang et al 2010 constructed a yellow river water balance model yrwbm and verified that the impacted of coal mining tons on runoff is about 5 27 m3 however to date there are relatively few studies to quantitatively analyze the coal mining impact on the water cycle even if it exists there is a lack of theoretical research on specific processes and details such as the study of coal mining on the specific changes in runoff and convergence multiple regression analysis of factors such as precipitation coal mining volume and surface subsidence area lacks the physical mechanism and requires high data and there is no uniform and mature method exists to accurately study zipper et al 1997 the current research direction is to quantify the impact of coal mining on runoff with the help of distributed hydrological models including complete hydrological processes yang et al 2019 quantitatively attribute runoff changes in a humid subtropical basin the qingliu river basin east china to climate variability land use change and human activity on multiple scales over different periods by using the soil and water assessment tool swat model quantifying the impact of coal mining on runoff with the help of a distributed hydrological model that includes a full hydrological process is the current direction of research therefore this paper analyzes the impact of the coal mined out area and establishes a grid based distributed hydrological model for the coal mined out area which has important practical significance for studying the mechanism of the coal mined out area on the water cycle in the article it first analyzed the production and convergence of small watersheds in the coal mine affected area then the gdhcma model was developed validated in the study area and finally the factors affecting the depth of the wetting front were discussed our objectives were to 1 analyze the runoff mechanism for coal mined out area 2 develop the grid based distributed hydrological model for coal mined out area and further validate its accuracy 3 explore the factors affecting the depth of the wet front s downward movement after the introduction section 2 presents the study area and data section 3 describes the grid based distributed hydrological model section 4 consists of the results and discussion of model results finally a brief summary and the major conclusions are provided in section 5 2 material and data 2 1 study area shanxi province is rich in coal resources and the coal is mainly distributed in the mountainous areas with complex terrain the rivers in these areas are mostly seasonal with small water flow and deep valley cuts the study area is the wujiayao watershed in the southwest of shanxi province with a total area of 78 7 km2 and an average slope of 7 8 including 58 sub watersheds it has 5 rainfall stations and 1 hydrological station coal mining was mainly concentrated in 1990 to 2008 resulting in a coal mined out area of 4 7 km2 accounting for 6 of the total area mainly located in the middle and lower reaches of the watershed under the influence of the continental monsoon climate it has mountain climatic characteristics with obvious vertical changes of precipitation it is dry and windy in spring and hot and rainy in summer the precipitation is mainly concentrated in summer july to september and the mean annual precipitation is about 389 mm the annual evaporation is between 1539 mm and 2368 mm with the largest evaporation distributed between may and july accounting for more than half of the total annual evaporation the mean annual evaporation is 5 times as much as the mean annual precipitation indicating wujiayao watershed is a typical dehydrated area the wujiayao watershed belongs to the haihe river the yongding system 5 rainfall stations and 1 hydrological station located in the watershed is selected for model implementation fig 1 stratigraphic texture of wujiayao watershed is continental coal bearing stratum with lithology of sandstone mudstone and coal interbeds hydrogeological condition is generally simple and locally complicated aquifuge of the basin is thicker than the aquifer which make the soil water quality worse based on the vertical profile analysis the water content of the aquifer increases with increasing depth groundwater drainage belongs to the lateral drainage recharge of groundwater is mainly infiltration of atmospheric precipitation followed by river water leakage recharge in local sections and lateral recharge in different sections and formations the fig 2 showed an increasing trend from 1990 to 2004 and maintained a stable state due to national management after 2004 2 2 data the article data mainly includes geographic information data meteorology hydrology etc firstly the dem of the mountainous watershed is mainly extracted from the high resolution satellite remote sensing data of geospatial data cloud and the characteristic parameters of the sub basin are obtained combined with the on site investigation the basic physical properties of the undisturbed soil the soil moisture characteristic curve and the infiltration parameters were determined by laboratory experiments meanwhile the soil type distribution is mainly obtained through land use classification and field surveys table 1 lists the data collection of wujiaoyao watershed the rainfall and discharge data come from the measured data of the shanxi provincial hydrographic bureau the temperature data is downloaded from the china meteorological website the coal mined out data is provided by the shanxi provincial coal mine administration dem data with 30 m spatial resolution is downloaded from the geospatial data cloud website the soil distribution data is mainly integrated with soil census data which is obtained from on site exploration survey and fig 3 presents the proportion of each soil type which can be seen that the soil type of wujiayao watershed are mainly sandy loam and silt loam accounting for 85 and 15 respectively at the watershed outlet the soil type is sandy loam and distributes a large number of coals mined out area 3 distributed hydrological model for coal mined out area 3 1 coal mined out area affected hydrological processes since the long term exploitation of coal mine resources in shanxi province large scope of coal mine out area appeared resulting in surface cracks and subsidence if the subsidence does not affect the ground there is no direct hydraulic connection between surface water and mine water however the area of surface cracks and subsidence increases with the expansion of the mined out area when a hydraulic connection occurs between surface cracks and surface water surface water supplies groundwater to the mined out area in the form of leakage or direct leakage resulting in a reduction of both surface runoff and storage reservoirs when a rainfall event occurs after the evaporation process part of the precipitation generates the surface runoff while the other part infiltrates to the soil layer and replenish the underground reservoir if rainfall falls on ground with cracks or subsidence the water will seepage to groundwater fig 4 is the generalized grid hydrological process assuming that each square grid can receive the upslope surface runoff upslope lateral flow and upslope groundwater flow the grid outflow will route to the downslope square grid or channel grid the hydrological processes considered on each grid include precipitation evaporation infiltration seepage upslope surface runoff upslope lateral inflow and upstream groundwater inflow the grid of the mined out area also considers the leakage replenishment effect of the fissure and its infiltration process is considered to be a homogenized equivalent infiltration process that is when the infiltration is calculated by the unsaturated infiltration method the saturated hydraulic conductivity adopts the original multiple calculation in addition the surface runoff lateral flow and groundwater outflow of each grid flow into the downstream grid or downstream channel according to the confluence relationship 3 2 enhanced distributed hydrological model the grid model has been developed with the aim of formulating a simple distributed rainfall runoff model suitable for use in coal mined out area within each square grid the model follows a simple water balance where the storage capacity is related to the average slope each grid square is conceptualized as a storage mechanism that receives water in the form of precipitation and loses water through overflow direct surface flow evaporation and drainage using two parallel discrete kinematic routing models the overflow and drainage stored in the grid square are converted into the basin outlet representing fast and slow response paths respectively and each arrival path coincides with the isochronous band the constructed model mainly avoids the over parameterization problems in the grid model through the measurement results of the digital terrain model dtm and the simple link function that is a small number of regional parameters can be adopted to specify many grid scale model parameters bell and moore 1998a b fig 5 3 2 1 runoff production 1 evaporation evaporation dish method is one of the empirical methods for indirect calculation of reference crop evapotranspiration this method combines the measured data with the main meteorological factors for regression analysis and then obtains reference empirical formulas for crop evapotranspiration and water surface evaporation alexandris and kerkides 2003 the formula is as follows 1 e t k k c e p t k where et k is grid evaporation l k c is the evaporating dish conversion coefficient e p t k is the actual evaporation l t is the t th time step of flood event k is the grid number in addition there is a difference between the evaporation volume measured from different diameters of the evaporation pan and the natural water surface therefore when calculating the evaporation loss on the water surface it is used in combination with the time space variation law of the evaporation conversion coefficient and the analysis results of observation data in various places 2 infiltration for infiltration process the one dimensional infiltration and water redistribution calculation methods were used that is using the infiltration rate f t of the green ampt model combined with the brooks corey model of unsaturated water conductivity rate curve k θ and the van genuchten model soil moisture characteristic curve ψ θ calculation method the water content in the discrete interval and the wetting front were both calculated lai et al 2015 if the rainfall intensity is more than the infiltration capacity it will produce the infiltration excess runoff r h t k 2 r h t k m a x p t k e t k f c t k 0 where rh t k is grid total direct surface runoff l pt k is grid rainfall l fc t k is the infiltration capacity within the calculation period l when the mined out area was generated like fig 3 the lower boundary condition of the soil was treated as free drainage boundary condition assuming that the water flowed directly from the fissure to the coal mined out area the calculation formula of surface fissure leakage is as follow 3 r t k r h t k 1 k c g on the coal grid r h t k on the no coal grid where rt k is grid surface runoff l kcg is surface crack leakage coefficient in the process of infiltration the lateral flow ri t k from the grid is described below todini 1995 liu et al 2005 4 r i t k l k k hs k s 0 k δ t s t k β δ x s max k β where ri t k is the grid lateral flow l st k is the grid soil water depth l smax k is the maximum grid soil water depth l s0 k is the grid terrain slope khs k is the grid horizontal saturated hydraulic conductivity lt 1 δ x is the grid width l δ t is the time step t β is a pore size distribution factor linked to the brooks and corey relation for hydraulic conductivity downward percolation q t k p is given by 5 q t k p k p k δ x 2 s t k s m a x t k α p where k p k is the vertical saturated hydraulic conductivity of the soil to k th grid lt 1 and α p is the exponent of the percolation function the outflow of the groundwater reservoir is called the groundwater flow rg t k the calculation formula is as follows 6 r g t k s g t k k g k 7 w g s t k s g t k k g s k where rg t k is the grid groundwater flow l sg t k is the grid water content of groundwater reservoir l kg k is the grid outflow coefficient of groundwater reservoir kgs k is the grid leakage coefficient of groundwater reservoir wgs t k is the leakage of groundwater aquifer l for a flood process the basin total runoff depth r can be expressed as 8 r s k 1 n t 0 t r t k r i t k r g t k δ t a b where rs is the simulated basin total runoff l ab is the basin area l2 n is the number of total grids t is the number of total time steps the rate of change in soil water volume vt k is given by 9 v t k t p t k e t k r i t k r i n t k δ x 2 δ t q t k p where r i t k is the lateral inflow to k th grid at t th time 3 2 2 calculation of flow routing a overland flow routing for a square grid the infiltration excess rainfall calculated by the infiltration module is used as the inflow of the runoff field the partial differential equation of each slope runoff field solved by motion wave is as follows 10 h t k t q t k x r t k δ t where h t k is surface water depth of the square grid l q t k is the grid surface discharge per unit width l2t 1 x is the distance down plane l the relationship between surface water depth h t k and discharge per unit width q t k is as follows 11 q t k α o h t k m o where α of and m o are functions of slope runoff field characteristics when the type of slope is turbulent m o 1 67 and the calculation formula of α o is as follows 12 α o 1 49 i o n o where io is slope and no roughness coefficient when the type of slope is turbulent m o 3 and the calculation formula is as follows 13 α o 64 4 i o 0 0000141 n o b channel flow routing for the channel flow routing part the river network is first generalized as the river channel and nodes for calculation the inflow of the river channel is the lateral inflow of upslope grid and the inflow of the node is the outflow of the upstream river the hydrologic process line of the upstream inflow and the lateral inflow per unit channel length multiplied by the channel length are used as input for the calculation of the river flow the river channel routing is calculated by the finite difference method using the following partial differential equation 14 a t k t q t k x r t k 15 r t k q t k r i t k r g t k δ x δ t where r t k is the lateral inflow to the k th grid at t th time l2t 1 x is the distance down the river l qt k is the outflow from k th at t th time l3t 1 the relationship between river flow and cross section area is as follows 16 q t k α c a t k m c where at k is the outflow from k th reach at time t is the area of flow l2 q t k is the outflow from k th reach at time l3t 1 q t k is the lateral inflow per unit length of channel from the overland plane l2t 1 t is time t x is the distance down the river l αc and mc are kinematic wave parameters if the wetted perimeter w c is a power function of the flow area the manning equation can be used to estimate the kinematic wave parameters αc and mc of the channel flow 17 w c c a t k d 18 h r a t k w c a t k 1 d c where wc is wetted perimeter l c and d are constants h r is hydraulic radius l then manning s equation for the flow rate is 19 q t k a t k v t k 1 49 s nc 2 3 a t k 5 3 2 3 d where vt k is the flow rate lt 1 n is the manning coefficient s is the river slope from equations 17 and 19 20 α c 1 49 s nc 2 3 21 m c 5 3 2 3 d the discrete kinematic wave is expressed as 22 q t k 1 θ q t 1 k θ q t 1 k 1 r t k d c where d c is river width l θ is a dimensionless wave speed ranging from 0 to 1 3 evaluation index for model calibration and verification statistic metrics include nse relative error of peak flood discharge δ q error percentage of runoff depth δ r peak flow present time error δ t are used to evaluate the performance of the grid based distributed hydrological model these metrics are defined as in table 2 where q s t and q o t are the simulated and observed discharge at t respectively qo is the arithmetic the mean observed discharge q s and q o are the simulated and observed peak flow respectively r s and r o are the simulated and observed runoff depth respectively t s and t o are the simulated and the observed peak flow present time respectively 4 results and discussion 4 1 digital terrain grid division in coal mined out area compared with the current grid of 10 km2 this article utilized a grid based distributed hydrological model with 300 m 300 m grid for coal mined out area each grid parameters were determined by the soil type considering the short duration of flood events the model is calculated in hourly while referring to the convergence process of precipitation evaporation infiltration and runoff among them the precipitation interpolation mainly adopts the inverse distance weight interpolation method assume that the lateral flow and confluence paths including groundwater and surface water are the same and the flow direction follows the d8 algorithm the wujiayao watershed based on grid division is shown in fig 6 4 2 model parameter the gdhcma model is employed to simulate the flood process in the wujiayao watershed and is calibrated using the shuffled complex evolution sce algorithm the initial and empirical parameters of each grid are extracted based on the basic data e g terrain soil geology land cover characteristics before the formation of the coal mined out area choose 2 flood events for model calibration and 1 flood event for model validation after the formation of the coal mined out area the time length for calibration and verification is the same as before the formation meanwhile the effects of leakage are mainly considered and the vertical saturated hydraulic conductivity k p of coal mined out grid is set to the 5 times of the vertical saturated hydraulic conductivity of the soil type therefore when the coal mined out area is formed only the parameters affected by the coal mined out area occurrence are calibrated that is the surface crack leakage coefficient k cg and the other parameters are the same as those determined before the formation the obtained model parameters are shown in table 3 4 2 1 before formation of coal mined out area fig 7 presents the detailed simulation for 3 flood events 1980 08 08 1980 08 16 and 1981 08 05 it can be seen that the 3 rainfalls are generally the same in intensity different in rainfall pattern rainfall and duration increased with the shortest raining time in 1980 08 08 and the longest in 1981 08 05 the peak flow of 3 flood events reacted in a short time the maximum peak flow and the peak flow present time error is the same however during the flow fall process the fall speed 1980 08 08 is the largest but the duration is long table 4 presents the simulation results of the 3 floods 1980 08 08 1980 08 16 1981 08 05 it can be seen that the simulated result is consistent with the measured in the first 2 calibrated flood events the error percentage of both the peak flow and the flood volume is within 7 except that the 1980 08 08 is 14 55 the peak flow present time error is 0 and the nse is all above 0 9 verifying the better effect of parameter calibration in the validation flood events the error percentage of both the peak flow and the flood volume are within 11 the peak flow present time error is 0 and the nse is 0 91 indicating that the model has the good simulation accuracy and satisfy the requirement of flood modeling 4 2 2 after formation of coal mined out area the coal mined out area of wujiayao watershed has shown an increasing trend since 1990 when considering the effect of seepage in the coal mined out area the lower boundary condition of the soil unsaturated infiltration calculation is mainly adjusted to the free drainage boundary and the seepage effect of the cracks should be noticed fig 8 shows the simulated result of 3 flood processes using the gdhcma model with and without considering the impact of the coal mined out area 1995 07 12 1999 08 17 and 2000 07 09 1995 07 12 had the highest rainfall intensity 1999 08 17 lasted the longest time and 2000 07 09 is an instantaneous heavy rainfall with short duration combined with flow process line the peak flow of 1999 08 17 is the highest followed by the third one and the first one it may be that the first precipitation has low rainfall and short duration resulting in low soil moisture while the second precipitation is the whole basin precipitation with heavy rainfall long duration and high soil water content prompting the peak discharge to increase to a maximum in a short period table 5 presents the simulation results when considering the effect of the mined out area no matter in 2 calibration flood events or 1 verification flood event the nse is more than 90 the peak flow present time is 0 and the error percentage of both the peak flow and the flood volume also meet the high accuracy requirements meanwhile compared with results that do not consider the impact of the coal mined out area the peak error rate and flood volume are reduced from nearly 40 to less than 10 the peak occurrence error is reduced to 0 the nse increased from 0 88 to 0 95 and the error of the average runoff depth decreased by 23 which significantly improves the model s accuracy obviously after considering the coal mined out area effect the simulated flood peak flow reduction is close to the observed which proves that the mechanism of the coal mined out area generalization affecting production and concentration process is reasonable 4 3 maximum wetting front depth fig 9 shows the information of the 3 floods that occurred in 1995 1999 and 2000 respectively including precipitation the maximum wet front depth with and without considering the coal mined out area combined with table 6 and fig 3 the maximum wetting front depth decreases by 1 14 m after considering the coal mined out area during the flood event in 1995 while during the flood event in 1999 it only decreased by 0 25 m which was significantly lower than 1995 the rainfall center for flood event in 1995 is located into the north and south sides of the watershed the incomplete watershed precipitation less rainfall and shorter durations may lead to insufficient soil water supplies therefore the maximum wetting front depth is related to the spatial distribution of rainfall even if the storm center is located at the outlet of the basin the maximum downward depth of the wetting front is only 0 26 m for the flood event that occurred in 1999 was the whole basin precipitation and when the precipitation reached a certain threshold if the soil is in a sufficient water supply state the wet front moves down deeply therefore the spatial distribution of the wet front is consistent with both the precipitation distribution and soil type and the maximum wetting front depth is significantly increased after considering the coal mined out area in order to further demonstrate the coal mined out area effect on the wetting front depth two soil types were selected for comparison in 3 floods with and without the coal mined out area fig 10 reflects the change process of the wetting front depth with time obviously after considering the mined out area the wetting front depth increased significantly with precipitation recharge while without precipitation recharge the soil water drained faster in the first two hours fig 10c combined with table 6 for different soil types considering the coal mined out area on the wetting front depth the sandy loam is much larger than the silty clay loam for the flood that occurred in 1999 as a whole basin rainfall large rainfall and long duration considering the coal mined out area the wetting front depth of the silty clay loam is only 1 0 m in addition for the flood that occurred in 2000 due to its low rainfall and inadequate soil water supply the change in the wetting front depth was less than 0 1 after considering the mined out area above all when the watershed is under sufficient water supply the maximum wetting front depth is mainly affected by the soil type and the coal mined out area when the watershed is under insufficient water supply it is affected not only by rainfall and the mined out area but also by the soil type meanwhile the maximum wetting front depth of sandy loam is obviously more affected by coal mined out area than that of silty clay loam 5 conclusion this article analyzed the impact of the mining effected area on regional hydrological process including runoff infiltration and confluence and reveals that coal mining often easily induces subsidence or fissures on the surface water flow will generally leak into the coal mined out area or supplement the groundwater reservoir through this preferential flow channel thereby constructing the gdhcma model and the only global optimal parameter of the model is obtained using the sce ua algorithm before and after the formation of coal mined out area the lower boundary conditions in the calculation of soil unsaturated infiltration are mainly treated as free drainage boundaries and it is verified that the mean nse of the mined out area is increased from 0 88 without considering the influence of mined out area to 0 95 with the influence of mined out area the peak present time error is 0 the percentage of flood peak and flood error is reduced to below 10 therefore the accuracy improvement is more obvious and the coal mined out area will significantly reduce the flood peak flow finally the proposed model was used to further explore the factors affecting the maximum wetting front depth namely rainfall soil type coal mined out effect etc and under the influence of the mined out area the maximum wetting front depth of sandy loam is significantly greater than that of silty clay loam credit authorship contribution statement meihong ma conceptualization methodology software investigation writing original draft lei wen validation formal analysis visualization software writing original draft sijia hao validation formal analysis visualization gang zhao validation formal analysis visualization minpei zhou visualization software changjun liu resources writing review editing supervision data curation huixiao wang resources writing review editing zhongliang wang resources supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by national key r d program of china no 2018yfc1508105 research on spatiotemporal variable source mixed runoff generation model and mechanism of innovation team project no jz0145b2017 hunan water conservancy science and technology project research on early warning indicators of mountain flood disasters in small watershed based on three dimensional deduction technology hunan water science design 2016 194 33 major water conservancy science and technology project of hunan province research on flood simulation and forecasting method for small watershed in hilly areas of hunan province based on geomorphological and hydrological response unit hunan water science design 2017 230 35 research and application of key technologies for dynamic early warning of flash flood disasters in henan province hnsw shzh 2015 06 study on the infiltration mechanism of the special underlying surface of the coal mined out area in shanxi province and the application of the results of the production and convergence of the coal mined out area zngz2015 008 2 research on flash flood warning based on machine learning a case study of yunnan province 52xb1903 and research on key technologies of flash flood prevention based on multi machine learning model 2019kj086 
5294,water conducting cracks and mined out area caused by coal mining change the regional hydrological processes to address this issue this research proposed a grid based distributed hydrological model for coal mined out area gdhcma and validated the model in one representative coal mining watershed wujiayao watershed in china the impact of coal mining on wet front depth was further analyzed based on the gdhcma model the results revealed that 1 ground subsidence or cracks induced by coal mining accelerate the leakage of water flow into the mined out area or replenish the groundwater reservoir thereby reducing the flood peak flow 2 the parameters of gdhcma model was calibrated by the shuffled complex evolution sce global search algorithm and the model showed high accuracy before and after coal mining during the pre coal mining period the calculated nse nash sutcliffe efficiency coefficient was above 0 9 and the error percentage of peak flow and flood volume was less than 15 during the coal mining period the main improvement is that the lower boundary conditions for the calculation of unsaturated soil infiltration are treated with free drainage boundaries the calculated mean nse is 0 95 the error percentages of flood peak and flood volume are less than 10 and the peak time error is 0 3 the leading factors affecting the downward depth of the wetting front are rainfall soil type the coal mined out area etc the above are of great practical significance for studying the mechanism of the coal mining on the water cycle keywords coal mined out area agrid based distributed hydrological model maximum wetting front depth wujiayao watershed 1 introduction coal as one of the most important energy sources induces great economic benefits however it also causing a series of environmental problems such as soil erosion vegetation withering damage to surface water and groundwater water pollution etc during coal mining and utilization qiao et al 2016 shang et al 2016 specifically the coal seam is adjacent to the underground aquifer and long term large scope mining will drain into coal seam thereby forming the coal mined out area xin et al 2014a b when coal mining subsidence extends to the ground surface it will cause surface cracking or collapse further accelerating the surface runoff into the ground and reducing the water storage capacity of the reservoir mamurekli 2010 for example in china due to coal mining the total water resources in changzhi city shanxi province decreased from 2 296 billion m3 per year in 1997 to 1 907 billion m3 per year in 2017 ping et al 2017 coal mining can induce surface subsidence and destroy the original hydrological cycle such as affecting the conversion efficient between surface water and groundwater accelerating the infiltration rate of surface runoff further changing the regional water balance which affect the healthy development of the local ecological environment tiwary 2001 xin et al 2014a b moreover large scope coal mining has led to rapid weakening or even disruption of river runoff in some areas wang et al 2018 palmer and hondula 2014 therefore research concerning the coal mining impact on the hydrological process is still inadequate especially for solving the local ecological and environmental problems caused by long term and large scope coal mining research on the impact of coal mining on water resources started from the 1980 s at the beginning it mainly focused on the impact of coal mining on groundwater the research methods mainly included theoretical research experimental analysis and numerical simulation research for example britton et al 1989 and colin and booth 1986 researched the coal mining impact on regional groundwater aquifers and proposed the hydrogeological effect which mainly used to describe the water quantity changes and ecosystem impacts caused by coal mining cuenca and hanssen 2008 adopted satellite observations to research the situation of ground subsidence caused by coal mining in the wassenberg region of germany karaman et al 1999 studied the changes of groundwater table within the boundaries and area of coal mining and predicted the water levels in aquifers kim et al 1997 used the finite element method to study the relationship between overburden rupture and groundwater flow under mining conditions and described the reasons for groundwater level decline utilizing the long term water level monitoring data and wellbore exploration data during the coal mining tonder et al 2007 adopted the hydrodynamic mudflow model to predict the rising water levels in coal mined out areas zhang and liu 2002 established a groundwater seepage model to simulate the changes in groundwater flow fields after coal mining indicating that the pit drainage will continue to increase with the expansion of the mining area cui 2015 used the numerical simulations to verify that coal mining may dredge large areas of submerged aquifers resulting in a significant drop in confined water levels wang 2018 and yan 2011 studied the changes of water content and water level in aquifers with the progress of coal mining based on gms model and then analyzed the relationship between aquifers and other aquifers in recent years with the increasingly serious problem of water resources in mining areas coal mining has also developed from a focus on the impact of groundwater to a study of the impact on surface water shen 2011 jiang et al 2010 duan et al 1992 the impact of coal mining on surface water is mainly reflected by the ground subsidence and cracks formed by coal mining which changed the underlying surface conditions and affected the original slope production and convergence process by intercepting precipitation the research methods can be divided into three classes simple statistical comparison application of multiple regression models and application of distributed hydrological models for example wang and you 2016 analyzed the 32 year 1956 1988 precipitation and discharge relationship of the yangwu river in china and concluded that the ratio coefficient of rainfall to base flow during the large scale mining period has been reduced by nearly 1 3 zhang et al 2011 studied the flow attenuation of the ulan mulun river in the daliuta mining area and concluded that natural factors and human factors accounted for 10 5 and 89 5 respectively of the human factors 77 3 were caused by coal mining activities based on statistical methods and multiple regression methods zhang and liu 2002 found that the annual mean runoff in the shenfu coal mined out area was about one fifth of that before coal mining activities coal mining has reduced annual river runoff by 5 72 million m3 accounting for 32 2 of the total runoff reduction jiang et al 2010 constructed a yellow river water balance model yrwbm and verified that the impacted of coal mining tons on runoff is about 5 27 m3 however to date there are relatively few studies to quantitatively analyze the coal mining impact on the water cycle even if it exists there is a lack of theoretical research on specific processes and details such as the study of coal mining on the specific changes in runoff and convergence multiple regression analysis of factors such as precipitation coal mining volume and surface subsidence area lacks the physical mechanism and requires high data and there is no uniform and mature method exists to accurately study zipper et al 1997 the current research direction is to quantify the impact of coal mining on runoff with the help of distributed hydrological models including complete hydrological processes yang et al 2019 quantitatively attribute runoff changes in a humid subtropical basin the qingliu river basin east china to climate variability land use change and human activity on multiple scales over different periods by using the soil and water assessment tool swat model quantifying the impact of coal mining on runoff with the help of a distributed hydrological model that includes a full hydrological process is the current direction of research therefore this paper analyzes the impact of the coal mined out area and establishes a grid based distributed hydrological model for the coal mined out area which has important practical significance for studying the mechanism of the coal mined out area on the water cycle in the article it first analyzed the production and convergence of small watersheds in the coal mine affected area then the gdhcma model was developed validated in the study area and finally the factors affecting the depth of the wetting front were discussed our objectives were to 1 analyze the runoff mechanism for coal mined out area 2 develop the grid based distributed hydrological model for coal mined out area and further validate its accuracy 3 explore the factors affecting the depth of the wet front s downward movement after the introduction section 2 presents the study area and data section 3 describes the grid based distributed hydrological model section 4 consists of the results and discussion of model results finally a brief summary and the major conclusions are provided in section 5 2 material and data 2 1 study area shanxi province is rich in coal resources and the coal is mainly distributed in the mountainous areas with complex terrain the rivers in these areas are mostly seasonal with small water flow and deep valley cuts the study area is the wujiayao watershed in the southwest of shanxi province with a total area of 78 7 km2 and an average slope of 7 8 including 58 sub watersheds it has 5 rainfall stations and 1 hydrological station coal mining was mainly concentrated in 1990 to 2008 resulting in a coal mined out area of 4 7 km2 accounting for 6 of the total area mainly located in the middle and lower reaches of the watershed under the influence of the continental monsoon climate it has mountain climatic characteristics with obvious vertical changes of precipitation it is dry and windy in spring and hot and rainy in summer the precipitation is mainly concentrated in summer july to september and the mean annual precipitation is about 389 mm the annual evaporation is between 1539 mm and 2368 mm with the largest evaporation distributed between may and july accounting for more than half of the total annual evaporation the mean annual evaporation is 5 times as much as the mean annual precipitation indicating wujiayao watershed is a typical dehydrated area the wujiayao watershed belongs to the haihe river the yongding system 5 rainfall stations and 1 hydrological station located in the watershed is selected for model implementation fig 1 stratigraphic texture of wujiayao watershed is continental coal bearing stratum with lithology of sandstone mudstone and coal interbeds hydrogeological condition is generally simple and locally complicated aquifuge of the basin is thicker than the aquifer which make the soil water quality worse based on the vertical profile analysis the water content of the aquifer increases with increasing depth groundwater drainage belongs to the lateral drainage recharge of groundwater is mainly infiltration of atmospheric precipitation followed by river water leakage recharge in local sections and lateral recharge in different sections and formations the fig 2 showed an increasing trend from 1990 to 2004 and maintained a stable state due to national management after 2004 2 2 data the article data mainly includes geographic information data meteorology hydrology etc firstly the dem of the mountainous watershed is mainly extracted from the high resolution satellite remote sensing data of geospatial data cloud and the characteristic parameters of the sub basin are obtained combined with the on site investigation the basic physical properties of the undisturbed soil the soil moisture characteristic curve and the infiltration parameters were determined by laboratory experiments meanwhile the soil type distribution is mainly obtained through land use classification and field surveys table 1 lists the data collection of wujiaoyao watershed the rainfall and discharge data come from the measured data of the shanxi provincial hydrographic bureau the temperature data is downloaded from the china meteorological website the coal mined out data is provided by the shanxi provincial coal mine administration dem data with 30 m spatial resolution is downloaded from the geospatial data cloud website the soil distribution data is mainly integrated with soil census data which is obtained from on site exploration survey and fig 3 presents the proportion of each soil type which can be seen that the soil type of wujiayao watershed are mainly sandy loam and silt loam accounting for 85 and 15 respectively at the watershed outlet the soil type is sandy loam and distributes a large number of coals mined out area 3 distributed hydrological model for coal mined out area 3 1 coal mined out area affected hydrological processes since the long term exploitation of coal mine resources in shanxi province large scope of coal mine out area appeared resulting in surface cracks and subsidence if the subsidence does not affect the ground there is no direct hydraulic connection between surface water and mine water however the area of surface cracks and subsidence increases with the expansion of the mined out area when a hydraulic connection occurs between surface cracks and surface water surface water supplies groundwater to the mined out area in the form of leakage or direct leakage resulting in a reduction of both surface runoff and storage reservoirs when a rainfall event occurs after the evaporation process part of the precipitation generates the surface runoff while the other part infiltrates to the soil layer and replenish the underground reservoir if rainfall falls on ground with cracks or subsidence the water will seepage to groundwater fig 4 is the generalized grid hydrological process assuming that each square grid can receive the upslope surface runoff upslope lateral flow and upslope groundwater flow the grid outflow will route to the downslope square grid or channel grid the hydrological processes considered on each grid include precipitation evaporation infiltration seepage upslope surface runoff upslope lateral inflow and upstream groundwater inflow the grid of the mined out area also considers the leakage replenishment effect of the fissure and its infiltration process is considered to be a homogenized equivalent infiltration process that is when the infiltration is calculated by the unsaturated infiltration method the saturated hydraulic conductivity adopts the original multiple calculation in addition the surface runoff lateral flow and groundwater outflow of each grid flow into the downstream grid or downstream channel according to the confluence relationship 3 2 enhanced distributed hydrological model the grid model has been developed with the aim of formulating a simple distributed rainfall runoff model suitable for use in coal mined out area within each square grid the model follows a simple water balance where the storage capacity is related to the average slope each grid square is conceptualized as a storage mechanism that receives water in the form of precipitation and loses water through overflow direct surface flow evaporation and drainage using two parallel discrete kinematic routing models the overflow and drainage stored in the grid square are converted into the basin outlet representing fast and slow response paths respectively and each arrival path coincides with the isochronous band the constructed model mainly avoids the over parameterization problems in the grid model through the measurement results of the digital terrain model dtm and the simple link function that is a small number of regional parameters can be adopted to specify many grid scale model parameters bell and moore 1998a b fig 5 3 2 1 runoff production 1 evaporation evaporation dish method is one of the empirical methods for indirect calculation of reference crop evapotranspiration this method combines the measured data with the main meteorological factors for regression analysis and then obtains reference empirical formulas for crop evapotranspiration and water surface evaporation alexandris and kerkides 2003 the formula is as follows 1 e t k k c e p t k where et k is grid evaporation l k c is the evaporating dish conversion coefficient e p t k is the actual evaporation l t is the t th time step of flood event k is the grid number in addition there is a difference between the evaporation volume measured from different diameters of the evaporation pan and the natural water surface therefore when calculating the evaporation loss on the water surface it is used in combination with the time space variation law of the evaporation conversion coefficient and the analysis results of observation data in various places 2 infiltration for infiltration process the one dimensional infiltration and water redistribution calculation methods were used that is using the infiltration rate f t of the green ampt model combined with the brooks corey model of unsaturated water conductivity rate curve k θ and the van genuchten model soil moisture characteristic curve ψ θ calculation method the water content in the discrete interval and the wetting front were both calculated lai et al 2015 if the rainfall intensity is more than the infiltration capacity it will produce the infiltration excess runoff r h t k 2 r h t k m a x p t k e t k f c t k 0 where rh t k is grid total direct surface runoff l pt k is grid rainfall l fc t k is the infiltration capacity within the calculation period l when the mined out area was generated like fig 3 the lower boundary condition of the soil was treated as free drainage boundary condition assuming that the water flowed directly from the fissure to the coal mined out area the calculation formula of surface fissure leakage is as follow 3 r t k r h t k 1 k c g on the coal grid r h t k on the no coal grid where rt k is grid surface runoff l kcg is surface crack leakage coefficient in the process of infiltration the lateral flow ri t k from the grid is described below todini 1995 liu et al 2005 4 r i t k l k k hs k s 0 k δ t s t k β δ x s max k β where ri t k is the grid lateral flow l st k is the grid soil water depth l smax k is the maximum grid soil water depth l s0 k is the grid terrain slope khs k is the grid horizontal saturated hydraulic conductivity lt 1 δ x is the grid width l δ t is the time step t β is a pore size distribution factor linked to the brooks and corey relation for hydraulic conductivity downward percolation q t k p is given by 5 q t k p k p k δ x 2 s t k s m a x t k α p where k p k is the vertical saturated hydraulic conductivity of the soil to k th grid lt 1 and α p is the exponent of the percolation function the outflow of the groundwater reservoir is called the groundwater flow rg t k the calculation formula is as follows 6 r g t k s g t k k g k 7 w g s t k s g t k k g s k where rg t k is the grid groundwater flow l sg t k is the grid water content of groundwater reservoir l kg k is the grid outflow coefficient of groundwater reservoir kgs k is the grid leakage coefficient of groundwater reservoir wgs t k is the leakage of groundwater aquifer l for a flood process the basin total runoff depth r can be expressed as 8 r s k 1 n t 0 t r t k r i t k r g t k δ t a b where rs is the simulated basin total runoff l ab is the basin area l2 n is the number of total grids t is the number of total time steps the rate of change in soil water volume vt k is given by 9 v t k t p t k e t k r i t k r i n t k δ x 2 δ t q t k p where r i t k is the lateral inflow to k th grid at t th time 3 2 2 calculation of flow routing a overland flow routing for a square grid the infiltration excess rainfall calculated by the infiltration module is used as the inflow of the runoff field the partial differential equation of each slope runoff field solved by motion wave is as follows 10 h t k t q t k x r t k δ t where h t k is surface water depth of the square grid l q t k is the grid surface discharge per unit width l2t 1 x is the distance down plane l the relationship between surface water depth h t k and discharge per unit width q t k is as follows 11 q t k α o h t k m o where α of and m o are functions of slope runoff field characteristics when the type of slope is turbulent m o 1 67 and the calculation formula of α o is as follows 12 α o 1 49 i o n o where io is slope and no roughness coefficient when the type of slope is turbulent m o 3 and the calculation formula is as follows 13 α o 64 4 i o 0 0000141 n o b channel flow routing for the channel flow routing part the river network is first generalized as the river channel and nodes for calculation the inflow of the river channel is the lateral inflow of upslope grid and the inflow of the node is the outflow of the upstream river the hydrologic process line of the upstream inflow and the lateral inflow per unit channel length multiplied by the channel length are used as input for the calculation of the river flow the river channel routing is calculated by the finite difference method using the following partial differential equation 14 a t k t q t k x r t k 15 r t k q t k r i t k r g t k δ x δ t where r t k is the lateral inflow to the k th grid at t th time l2t 1 x is the distance down the river l qt k is the outflow from k th at t th time l3t 1 the relationship between river flow and cross section area is as follows 16 q t k α c a t k m c where at k is the outflow from k th reach at time t is the area of flow l2 q t k is the outflow from k th reach at time l3t 1 q t k is the lateral inflow per unit length of channel from the overland plane l2t 1 t is time t x is the distance down the river l αc and mc are kinematic wave parameters if the wetted perimeter w c is a power function of the flow area the manning equation can be used to estimate the kinematic wave parameters αc and mc of the channel flow 17 w c c a t k d 18 h r a t k w c a t k 1 d c where wc is wetted perimeter l c and d are constants h r is hydraulic radius l then manning s equation for the flow rate is 19 q t k a t k v t k 1 49 s nc 2 3 a t k 5 3 2 3 d where vt k is the flow rate lt 1 n is the manning coefficient s is the river slope from equations 17 and 19 20 α c 1 49 s nc 2 3 21 m c 5 3 2 3 d the discrete kinematic wave is expressed as 22 q t k 1 θ q t 1 k θ q t 1 k 1 r t k d c where d c is river width l θ is a dimensionless wave speed ranging from 0 to 1 3 evaluation index for model calibration and verification statistic metrics include nse relative error of peak flood discharge δ q error percentage of runoff depth δ r peak flow present time error δ t are used to evaluate the performance of the grid based distributed hydrological model these metrics are defined as in table 2 where q s t and q o t are the simulated and observed discharge at t respectively qo is the arithmetic the mean observed discharge q s and q o are the simulated and observed peak flow respectively r s and r o are the simulated and observed runoff depth respectively t s and t o are the simulated and the observed peak flow present time respectively 4 results and discussion 4 1 digital terrain grid division in coal mined out area compared with the current grid of 10 km2 this article utilized a grid based distributed hydrological model with 300 m 300 m grid for coal mined out area each grid parameters were determined by the soil type considering the short duration of flood events the model is calculated in hourly while referring to the convergence process of precipitation evaporation infiltration and runoff among them the precipitation interpolation mainly adopts the inverse distance weight interpolation method assume that the lateral flow and confluence paths including groundwater and surface water are the same and the flow direction follows the d8 algorithm the wujiayao watershed based on grid division is shown in fig 6 4 2 model parameter the gdhcma model is employed to simulate the flood process in the wujiayao watershed and is calibrated using the shuffled complex evolution sce algorithm the initial and empirical parameters of each grid are extracted based on the basic data e g terrain soil geology land cover characteristics before the formation of the coal mined out area choose 2 flood events for model calibration and 1 flood event for model validation after the formation of the coal mined out area the time length for calibration and verification is the same as before the formation meanwhile the effects of leakage are mainly considered and the vertical saturated hydraulic conductivity k p of coal mined out grid is set to the 5 times of the vertical saturated hydraulic conductivity of the soil type therefore when the coal mined out area is formed only the parameters affected by the coal mined out area occurrence are calibrated that is the surface crack leakage coefficient k cg and the other parameters are the same as those determined before the formation the obtained model parameters are shown in table 3 4 2 1 before formation of coal mined out area fig 7 presents the detailed simulation for 3 flood events 1980 08 08 1980 08 16 and 1981 08 05 it can be seen that the 3 rainfalls are generally the same in intensity different in rainfall pattern rainfall and duration increased with the shortest raining time in 1980 08 08 and the longest in 1981 08 05 the peak flow of 3 flood events reacted in a short time the maximum peak flow and the peak flow present time error is the same however during the flow fall process the fall speed 1980 08 08 is the largest but the duration is long table 4 presents the simulation results of the 3 floods 1980 08 08 1980 08 16 1981 08 05 it can be seen that the simulated result is consistent with the measured in the first 2 calibrated flood events the error percentage of both the peak flow and the flood volume is within 7 except that the 1980 08 08 is 14 55 the peak flow present time error is 0 and the nse is all above 0 9 verifying the better effect of parameter calibration in the validation flood events the error percentage of both the peak flow and the flood volume are within 11 the peak flow present time error is 0 and the nse is 0 91 indicating that the model has the good simulation accuracy and satisfy the requirement of flood modeling 4 2 2 after formation of coal mined out area the coal mined out area of wujiayao watershed has shown an increasing trend since 1990 when considering the effect of seepage in the coal mined out area the lower boundary condition of the soil unsaturated infiltration calculation is mainly adjusted to the free drainage boundary and the seepage effect of the cracks should be noticed fig 8 shows the simulated result of 3 flood processes using the gdhcma model with and without considering the impact of the coal mined out area 1995 07 12 1999 08 17 and 2000 07 09 1995 07 12 had the highest rainfall intensity 1999 08 17 lasted the longest time and 2000 07 09 is an instantaneous heavy rainfall with short duration combined with flow process line the peak flow of 1999 08 17 is the highest followed by the third one and the first one it may be that the first precipitation has low rainfall and short duration resulting in low soil moisture while the second precipitation is the whole basin precipitation with heavy rainfall long duration and high soil water content prompting the peak discharge to increase to a maximum in a short period table 5 presents the simulation results when considering the effect of the mined out area no matter in 2 calibration flood events or 1 verification flood event the nse is more than 90 the peak flow present time is 0 and the error percentage of both the peak flow and the flood volume also meet the high accuracy requirements meanwhile compared with results that do not consider the impact of the coal mined out area the peak error rate and flood volume are reduced from nearly 40 to less than 10 the peak occurrence error is reduced to 0 the nse increased from 0 88 to 0 95 and the error of the average runoff depth decreased by 23 which significantly improves the model s accuracy obviously after considering the coal mined out area effect the simulated flood peak flow reduction is close to the observed which proves that the mechanism of the coal mined out area generalization affecting production and concentration process is reasonable 4 3 maximum wetting front depth fig 9 shows the information of the 3 floods that occurred in 1995 1999 and 2000 respectively including precipitation the maximum wet front depth with and without considering the coal mined out area combined with table 6 and fig 3 the maximum wetting front depth decreases by 1 14 m after considering the coal mined out area during the flood event in 1995 while during the flood event in 1999 it only decreased by 0 25 m which was significantly lower than 1995 the rainfall center for flood event in 1995 is located into the north and south sides of the watershed the incomplete watershed precipitation less rainfall and shorter durations may lead to insufficient soil water supplies therefore the maximum wetting front depth is related to the spatial distribution of rainfall even if the storm center is located at the outlet of the basin the maximum downward depth of the wetting front is only 0 26 m for the flood event that occurred in 1999 was the whole basin precipitation and when the precipitation reached a certain threshold if the soil is in a sufficient water supply state the wet front moves down deeply therefore the spatial distribution of the wet front is consistent with both the precipitation distribution and soil type and the maximum wetting front depth is significantly increased after considering the coal mined out area in order to further demonstrate the coal mined out area effect on the wetting front depth two soil types were selected for comparison in 3 floods with and without the coal mined out area fig 10 reflects the change process of the wetting front depth with time obviously after considering the mined out area the wetting front depth increased significantly with precipitation recharge while without precipitation recharge the soil water drained faster in the first two hours fig 10c combined with table 6 for different soil types considering the coal mined out area on the wetting front depth the sandy loam is much larger than the silty clay loam for the flood that occurred in 1999 as a whole basin rainfall large rainfall and long duration considering the coal mined out area the wetting front depth of the silty clay loam is only 1 0 m in addition for the flood that occurred in 2000 due to its low rainfall and inadequate soil water supply the change in the wetting front depth was less than 0 1 after considering the mined out area above all when the watershed is under sufficient water supply the maximum wetting front depth is mainly affected by the soil type and the coal mined out area when the watershed is under insufficient water supply it is affected not only by rainfall and the mined out area but also by the soil type meanwhile the maximum wetting front depth of sandy loam is obviously more affected by coal mined out area than that of silty clay loam 5 conclusion this article analyzed the impact of the mining effected area on regional hydrological process including runoff infiltration and confluence and reveals that coal mining often easily induces subsidence or fissures on the surface water flow will generally leak into the coal mined out area or supplement the groundwater reservoir through this preferential flow channel thereby constructing the gdhcma model and the only global optimal parameter of the model is obtained using the sce ua algorithm before and after the formation of coal mined out area the lower boundary conditions in the calculation of soil unsaturated infiltration are mainly treated as free drainage boundaries and it is verified that the mean nse of the mined out area is increased from 0 88 without considering the influence of mined out area to 0 95 with the influence of mined out area the peak present time error is 0 the percentage of flood peak and flood error is reduced to below 10 therefore the accuracy improvement is more obvious and the coal mined out area will significantly reduce the flood peak flow finally the proposed model was used to further explore the factors affecting the maximum wetting front depth namely rainfall soil type coal mined out effect etc and under the influence of the mined out area the maximum wetting front depth of sandy loam is significantly greater than that of silty clay loam credit authorship contribution statement meihong ma conceptualization methodology software investigation writing original draft lei wen validation formal analysis visualization software writing original draft sijia hao validation formal analysis visualization gang zhao validation formal analysis visualization minpei zhou visualization software changjun liu resources writing review editing supervision data curation huixiao wang resources writing review editing zhongliang wang resources supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by national key r d program of china no 2018yfc1508105 research on spatiotemporal variable source mixed runoff generation model and mechanism of innovation team project no jz0145b2017 hunan water conservancy science and technology project research on early warning indicators of mountain flood disasters in small watershed based on three dimensional deduction technology hunan water science design 2016 194 33 major water conservancy science and technology project of hunan province research on flood simulation and forecasting method for small watershed in hilly areas of hunan province based on geomorphological and hydrological response unit hunan water science design 2017 230 35 research and application of key technologies for dynamic early warning of flash flood disasters in henan province hnsw shzh 2015 06 study on the infiltration mechanism of the special underlying surface of the coal mined out area in shanxi province and the application of the results of the production and convergence of the coal mined out area zngz2015 008 2 research on flash flood warning based on machine learning a case study of yunnan province 52xb1903 and research on key technologies of flash flood prevention based on multi machine learning model 2019kj086 
