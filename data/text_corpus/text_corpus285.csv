index,text
1425,the composition of mixed dechlorinating communities varies considerably in field and laboratory conditions dechlorinators thrive alongside with distinctive populations that help or hinder dechlorination the variability of the composition of dechlorinating communities inevitably precludes a firm consensus regarding the optimal strategies for biostimulation this lack of consensus motivated a model based approach for the investigation of how the variability of the composition of a microbial community impacts the electron donor supply strategies for accelerating chloroethene removal to this end a kinetic model accounting for dechlorination in conjunction with cooperative and competing processes was developed model parameters were estimated using a multi experiment multi start algorithm and data from research previously performed with two generations of a methane producing dehalococcoides mccartyi dominated consortium the two generations of the consortium functioned comparably under maintenance conditions but performed divergently under high electron donor surpluses the multi experiment multi start algorithm overcame the hurdles of poor parameter identifiability and offered a probable cause for the different behaviors exhibited by each of the two generations of the chloroethene degrading consortium modest differences in the make up of non dechlorinators which were minority populations significantly influenced the fate of the offered electron donor graphical abstract unlabelled image keywords tce metabolic reductive dechlorination methanogenesis modeling calibration 1 introduction this work searches for model based evidence that supports answers to the following question what is the impact of the variability of microbial community composition on the distribution of electron equivalents and thus on the selection of successful strategies for efficient dechlorination during biostimulation to this end a comprehensive kinetic model was designed and calibrated to study the composition of two generations of a methane producing dehalococcoides mccartyi dominated dechlorinating culture developed at ntua ntua m the present study focused on the utilization of h2 and acetate by dechlorinators and non dechlorinators both competitors and syntrophs in these two generations seeking to interpret similarities and differences observed under substrate limiting conditions and high electron donor surpluses the performance of the two generations of the ntua m culture which will be referred to as ntua m1 and ntua m2 hereafter was investigated in the laboratory by panagiotakis et al 2014 2015 antoniou et al 2019 and antoniou et al 2019 under both low and high electron donor surpluses and provided the stimulus for framing the research question cultures ntua m1 and ntua m2 performed similarly under low electron donor surpluses with butyrate serving as a low h2 ceiling donor source butyrate fermentation is limited by aqueous h2 concentrations greater than 0 35 μμ according to mao et al 2015 yet elevated donor surpluses revealed notable differences ntua m1 required an electron donor surplus of 24 5 surplus is estimated assuming that 1 mol h2 yields 2 eeq 1 mol butyrate yields 20 eeq and 1 mol tce requires 6 eeq for its complete dechlorination and nearly 48 days to dechlorinate tce completely while ntua m2 removed all chloroethenes completely with an electron donor surplus of 12 9 within 9 2 days when ntua m2 was fed directly with h2 as the electron donor it managed to remove trichloroethene tce and daughter products with an electron donor surplus of only 5 4 within 6 days kinetic models were used to corroborate experimental findings as multiple processes underlie laboratory observations the study of dechlorination in mixed microbial communities is challenging model based approaches can decouple dechlorination from its side reactions and thereby systematically assess the mechanisms that potentially affect dechlorination kinetic models must surpass another obstacle the difficulty to estimate a single best set of parameters from batch experimental data i e the problem of the non uniqueness of parameters this difficulty is acknowledged chambon et al 2013 and renders model based evidence insufficient due to non uniqueness the relevance of parameters to other systems or to extrapolating conditions cannot be assessed nonetheless the search for a single best parameter set has been rarely given attention in the literature on dechlorination e g haest et al 2010 in which reports on parameter uncertainties are scarce e g heavner et al 2013 this work develops and employs a multi experiment multi start algorithm to mitigate and assess the impact of non uniqueness the multi experiment component of the algorithm aims to simultaneously optimize the performance of kinetic models to a set of experiments performed under distinctive initial conditions and thereby reduce the potential for non unique parameters the multi start component aspires to detect a best fit solution that is neither bound to the initial guesses for the parameter values nor trapped to sub optimal solutions i e solutions that cannot describe adequately the observations non uniqueness cannot be eradicated but the multi start approach can turn this problem to an opportunity for assessing uncertainty through the examination of the multiple parameter sets that could be acceptable representations of the system under examination and reduce parameter variability see end of section 6 1 and tables s3 1 s3 3 in the supplementary material in what follows after the first two sections introduction and background section 3 includes findings from the experiments with cultures ntua m1 and ntua m2 that motivated the research section 4 presents the conceptual and mathematical formulation of the model used to describe culture performance section 5 discusses the decisions involved in the solution of the inverse problem readers who are not interested in inverse modeling may elect to only skim section 5 beyond its introductory part and focus on the solution outcome presented in section 6 which is split in two subsections and 1 shows the fit of the model to the experimental results for the two cultures and 2 compares the composition of the two cultures in order to relate community structure to performance 2 background methane producing chloroethene degrading consortia constitute complex food webs containing apart from dechlorinators methanogens h2 and acetate utilizing species as well as acetate and h2 producing syntrophs these food webs involve interspecies transfers of h2 and acetate among the members of the consortium during biostimulation the primary concern is how to strategically supply h2 sources and channel reducing power to dechlorinators the dominant view regarding biostimulation posits that substrates necessitating low h2 concentrations for their fermentation low h2 ceiling donor sources selectively enhance dechlorinators which are effective h2 scavengers at such low h2 concentrations in the range of a few nm fennell et al 1997 and yang and mccarty 1998 showed that organic substrates acting as low h2 ceiling donor sources gave dechlorinators an advantage over methanogens and thereafter the findings of yang and mccarty 2000 azizian et al 2010 and wen et al 2015 strengthened this view this dominant view may be interpreted to imply that methane formation in dechlorinating consortia is primarily h2 dependent a valid assumption in a significant share of microbial communities for which reported molecular analyses support the existence of h2 utilizing methanogens for example in dechlorinating culture anas the h2 utilizing methanogens methanobacterium and methanospirillum have been identified richardson et al 2002 brisson et al 2012 in kb 1 subcultures methanogenic populations comprise mainly methanomethylovorans methanol utilizing methanogen and methanomicrobiales an order containing mostly h2 utilizing methanogens duhamel and edwards 2006 yet methane formation in mixed chloroethene degrading consortia is not solely h2 dependent acetate dependent methane formation has also been reported as the main methanogenic pathway in mixed chloroethene degrading consortia and acetate utilizing methanogens have been reported as the major methanogenic population in microbial communities developed under laboratory conditions or established in the field specifically chloroethene degrading culture donna ii comprises the h2 utilizing methanospirillum and the acetate utilizing methanosaeta rowe et al 2008 with methane formation being predominantly acetate dependent heavner et al 2013 dennis et al 2003 detected mostly methanosaeta in a soil column fed with methanol and butyrate while treating pce non aqueous phase liquid macbeth et al 2004 found that methanosaeta were prevailing in a chloroethene degrading consortium established with material from a contaminated site undergoing biostimulation as macbeth et al 2004 postulate low temperatures 15 c may have favored acetate utilizing methanogens thus under field conditions if methane is observed concurrently with dechlorination the probability of acetate dependent methane formation is considerable the community composition variation adds a source of uncertainty in the description of the dynamics of h2 production and consumption thus generalizations stemming from the dominant view that enhanced dechlorination is successful under fermentable electron donors that sustain low h2 concentrations are questionable skepticism for this view is supported by conflicting findings reported in the literature three of the most well studied mixed dechlorinating cultures have been maintained for years with high h2 ceiling substrates various subcultures of the commercially available culture kb 1 have been maintained with mixtures of ethanol and methanol or h2 duhamel and edwards 2006 while cultures anas richardson et al 2002 and sdc 9 schäfer et al 2009 are both fed with lactate a high h2 ceiling donor source even direct addition of h2 has been reported to be a promising approach aulenta et al 2005 2007 in some cultures even if it promoted methane formation in others ma et al 2003 2006 2007 wen et al 2015 the relevance of the variability of community composition has been acknowledged in the literature richardson 2016 current efforts mostly focus on characterizing the community ecology in enrichment cultures e g duhamel and edwards 2006 rowe et al 2008 or contaminated sites e g lee et al 2012 kotik et al 2013 and specifying the niche that each microbial group fills within the dechlorinating communities hug et al 2012 yet a quantitative assessment of how community composition determines electron flow is lacking as only a few kinetic models describe how the activities of non dechlorinators depend upon h2 and acetate availability richardson 2016 chambon et al 2013 this gap is addressed by this study 3 experimental observations this section introduces the two sources of experimental information that are available for the study of dechlorination a the long term performance data of the source cultures and b the six batch tests performed at different instances of the history of the source cultures under varying electron donor surpluses the fact that batch tests are distributed within the lifetime of the cultures makes parameter estimation challenging but it allows also for a meaningful application of the multi experiment approach which aims to identify a single set for most parameters and thereby approximate the inherent dechlorinating capability of mixed microbial communities i e their capabilities regardless of initial conditions or culture history 3 1 long term monitoring of the cultures ntua m1 and ntua m2 source cultures ntua m1 and ntua m2 were maintained under limiting electron donor conditions to mimic the conditions typically encountered in the field under natural attenuation panagiotakis 2010 antoniou 2019 particularly they were maintained on a seven day feeding cycle that included the addition of 500 μμ 66 7 mg l tce and 300 μμ 27 5 mg l butyrate which served as a low h2 ceiling electron donor source at the end of each feeding cycle part of the culture was replaced by fresh medium to achieve a solid retention time of 48 days with respect to their maintenance characteristics these cultures differed only in the addition of yeast extract which was routinely added in the case of ntua m1 at a concentration of 4 5 mg l yeast extract is a nutritional supplement which also serves as a source of slowly fermented volatile fatty acids mainly butyrate and to a lesser degree acetate and propionate fennell and gossett 1998 however the quantity of yeast extract added in culture ntua m1 is low according to yang and mccarty 1998 it yields an equivalent of 780 μeeq l which corresponds to approximately a 10 increase of reducing power if it is consumed within the seven day feeding cycles hence the addition of yeast extract changes mildly the electron equivalent surplus of culture ntua m1 the two cultures had attained a steady state performance regarding dechlorination and butyrate consumption on a weekly basis cultures ntua m1 and ntua m2 dechlorinated on average 64 and 71 of the overall available chloroethenes respectively in ntua m1 vinyl chloride vc was the main daughter product of dechlorination 82 of the total ethene concentration at the end of each feeding cycle followed cis 1 2 dichloroethene cdce 12 and ethene eth 6 in ntua m2 vc and eth were the major end products of dechlorination 88 and 12 respectively cdce was not detected since eth is produced both cultures are classified as dehalococcoides mccartyi enriched cultures a finding that was further verified by fish analysis of microbial community structure the supplied butyrate was steadily consumed on each feeding cycle indicating the existence of a robust butyrate degrading community with respect to methane formation the two cultures failed to reach steady state in both cultures methane formation alternated between two phases of lower and elevated methane formation these phases were accompanied by inversely fluctuating acetate concentrations panagiotakis 2010 antoniou 2019 i e elevated methane formation coincided with low acetate concentrations and vice versa a fluorescence in situ hybridization fish analysis was performed during the operation of culture ntua m1 providing insight into the main microbial groups thriving within the culture panagiotakis et al 2014 specifically fish analysis demonstrated that a dehalococcoides mccartyi spp was the predominant species 49 of the total bacteria b two hydrogenotrophic dechlorinators were present besides dehalococcoides mccartyi spp the partial dechlorinator sulfurospirillum spp was detected and comprised 8 of the total bacteria and c methanogenic archaea were only a small proportion of the culture around 10 of the total cell numbers fish analysis underscored the relevance of dechlorinators and methanogens but it could not a enumerate them rigorously and b provide definite answers as to which and how many other microbial groups should be considered in addition this molecular analysis cannot illustrate the exact composition of culture ntua m2 but given the increase in dechlorinating performance of ntua m2 it is reasonable to assume that culture ntua m2 is also dominated by dehalococcoides mccartyi the end products of the seven day feeding cycles indicated that the major processes occurring within the two mixed cultures are dechlorination butyrate oxidation and methanogenesis what is more dechlorination daughter products at the end of each feeding cycle indicated that syntrophic acetate oxidation should also be considered since as already mentioned a eth was observed at the end of each seven day feeding cycle and b based on the butyrate quantity added direct h2 formation 600 μμ h2 can be readily formed from 300 μμ of butyrate would justify only cdce and vc as the main daughter products of tce dechlorination hence it is reasonable to deduce that a h2 source additional to butyrate sustained dechlorination that is acetate this is true for both ntua m1 and ntua m2 so the additional source cannot be solely the yeast extract decaying biomass does not provide the missing electron equivalents either as it functions as a source that produces butyrate slowly hence decaying biomass cannot act as a readily available source of h2 for dechlorinators or methanogens within the seven day feeding cycles of the cultures 3 2 batch tests performed with cultures ntua m1 and ntua m2 the present section outlines the essential features of the batch tests performed with ntua m1 and ntua m2 a detailed discussion on the outcomes of the batch tests performed with the two cultures is available in the sixth section of this work entitled the outcome of the inverse problem where observations from the batch tests are compared to simulation outcomes as the batch tests in both cultures were not performed simultaneously changes in the initial relative abundance of the microbial groups should be anticipated and could be hypothesized on the basis of the experimental results accounting for these changes was the incentive for the work presented in this paper three butyrate fed batch experiments are available for culture ntua m1 table 1 these tests were performed at different instances of the life of culture ntua m1 with butyrate as an electron donor source and under varying electron donor surpluses a test ls b1 panagiotakis et al 2014 was performed under a low surplus ls of 2 4 b test ms b1 panagiotakis et al 2015 was performed under a moderate surplus 5 5 and c hs b1 panagiotakis et al 2015 was performed under a high surplus 24 5 three batch experiments are available for dechlorinating culture ntua m2 panagiotakis et al 2015 antoniou et al 2019 as well the experiments were performed with varying initial electron donor types and quantities table 1 a test ls b2 panagiotakis et al 2015 was performed under a low surplus 2 4 with butyrate as serving as an electron donor source b test hs b2 antoniou et al 2019 was performed under a high surplus 12 9 with butyrate as serving as an electron donor source and c ms h2 panagiotakis et al 2015 was performed under a moderate surplus 5 4 with h2 being supplied directly as an electron donor 4 mathematical model 4 1 conceptual setup of the model the processes occurring concurrently with the anaerobic degradation of chloroethenes are depicted in fig 1 the associated reactions are presented in table 2 according to this conceptual model a butyrate oxidizing community butyrate oxidizer in fig 1 consumes the supplied butyrate and produces h2 and acetate potential fermentation by products as propionate were measured but never detected in appreciable concentrations in ntua m antoniou 2019 h2 is subsequently used by a tce to eth dechlorinators b tce to cdce dechlorinators and c h2 utilizing methanogens acetate is either converted to methane by acetate utilizing methanogens or consumed by acetate oxidizing bacteria to produce h2 conceptually the modeling of the dechlorinating community builds upon two assumptions first dechlorination is presumably dependent solely on h2 acetate dependent consumption of tce was not included in the model this is a reasonable assumption based on the molecular analysis discussed in section 3 1 members of dehalococcoides mccartyi and sulfurospirillum spp can utilize only h2 from the available electron donor sources second the model considers only two dechlorinating populations this is a simplification of the ecology of mixed dechlorinating communities typically dechlorinating communities comprise clusters of diverse subpopulations with different strains catalyzing specific dechlorination steps mayer blackwell et al 2017 different substrate preferences and metabolic abilities wei et al 2016 however a model describing a complex community would be prone to overfitting errors unless considerably more observational data on the responsible microbial populations and their abundance were available regarding the competition for h2 the model considers only two options dechlorination and methane formation homoacetogens were not included as potential hydrogenotrophic competitors homoacetogenesis requires a threshold concentration above 400 nm h2 to be thermodynamically feasible löffler et al 1999 this explains why homoacetogens are detectable within cultures that are maintained with high ceiling electron donor sources e g lactate richardson 2016 thus their presence in ntua m1 and ntua m2 is highly unlikely additionally the batch test performed with direct h2 addition ms h2 did not indicate acetate production lastly the model does not consider the by products of decaying biomass as a potential source of electron equivalents decaying biomass should be considered as a relevant source of electron equivalents for time horizons significantly greater than those simulated herein i e 6 to 48 days sleep et al 2005 4 2 mathematical formulation of the model in the mathematical formulation of the model the concentration of biological components will be denoted as x j where index j changes for the six microbial groups of interest as follows j is d c for tce to eth complete dechlorinators d p for tce to cdce partial dechlorinators hm for h2 utilizing methanogens am for acetate utilizing methanogens bo for butyrate oxidizers and ao for acetate oxidizers the concentration of chemical components will be denoted as s i where index i changes in order to designate the various chemical components of the model i is tce cdce vc eth for the respective chloroethenes m for methane h for h2 b for butyrate and a for acetate 4 2 1 dechlorination kinetics chloroethene consumption rates r i j were described by dual substrate monod kinetic equations 1 r i j m max j y j x j s i k s i j s i s h s min h j f d j k s h j s h s min h j f d j f d j where μ max j is the maximum specific growth rate of microorganism j day 1 x j is the biomass concentration of microorganism j mg vss l y j is the yield coefficient of microorganism j mg vss μmol cl s i is the concentration of substrate i μμ k s i j is the half velocity coefficient for chloroethene i of microorganism j μμ s h is the concentration of h2 μμ k s h j is the half velocity coefficient for h2 of microorganism j μμ and s min h j is the threshold for h2 use for dechlorinators μμ two sigmoid functions f d j and f d j were used in order to avoid possible instabilities and oscillatory behavior when h2 concentrations approach the h2 threshold values ribes et al 2004 these sigmoid functions are defined as follows 2 f d j 1 1 exp 100 s min h j s min h j s h 3 f d j 1 1 exp 100 s min h j 1 1 s min h j s h in eqs 2 3 and 4 i tce or cdce and j dc for tce to eth dechlorinators or dp for tce to cdce dechlorinators concerning vc consumption possible competitive inhibition of vc by cdce was considered and consequently eq 2 was replaced by cupples et al 2004 4 r vc d 1 m max d 1 y d 1 x d 1 s vc k s vc d 1 1 s cdce k inh cdce s vc s h s min h d 1 f d d 1 k s h d 1 s h s min h d 1 f d d 1 f d d 1 where k inh cdce μm is an inhibition coefficient which was set equal to the half velocity coefficient for the respective chloroethene i e k inh cdce k s cdce j yu et al 2005 inhibition of tce on its daughter products was neglected since tce is rapidly removed and thus the impact of tce on the less chlorinated compounds would be minimal in eqs 1 and 4 μ max j and y j are microorganism related parameters and thus independent from the chloroethene consumed this assumption has been previously applied in several modeling approaches e g lee et al 2004 clapp et al 2004 because it simplifies model structure while preserving the ability to capture the difference in consumption rates r i j among the various chloroethenes kandris et al 2015 finally the progress of dechlorination over time will be tracked with the degree of dechlorination dod an aggregate measure calculated from the concentrations of chloroethenes and eth as follows manoli et al 2012 ranging from 0 to 1 or equivalently 100 for complete dechlorination 5 dod s cdce 2 s vc 3 s eth 3 s tce s cdce s vc s eth 4 2 2 methane formation kinetics methane formation was modeled using monod type kinetic equations which incorporated substrate thresholds for h2 or acetate use by the corresponding methanogen specifically the rates of h2 or acetate consumption from the corresponding methanogen r i j were calculated as follows 6 r i j m max j y j x j s i s min i j f j k s i j s i s min i j f j f j where μ max j day 1 is the maximum specific growth rate of methanogen j y j mg vss μmol substrate is the yield coefficient of methanogen j x j is the biomass concentration of methanogen j mg vss l k s i j μμ is the half velocity coefficient for substrate i of methanogen j and s min i j μμ is the threshold for substrate use i of methanogen j finally the sigmoid functions f j and f j which were defined by eqs 2 and 3 were adjusted to account for the appropriate substrate threshold s min h hm and s min a am instead of s min h j in eq 6 i h or a and j hm or am for h2 or acetate dependent methane formation respectively 4 2 3 butyrate and acetate oxidation kinetics the rate of butyrate or acetate oxidation r i j was described as follows 7 r i j m max j y j x j s i k s i j s i i h j where μ max j day 1 is the maximum specific growth rate of microorganism j yj mg vss μmol substrate is the yield coefficient of microorganism j x j mg vss l is the biomass concentration of microorganism j s i μm is the concentration of substrate i and k s i j μμ is the half velocity coefficient for substrate i and microorganism j the inhibition factor i i j is defined as follows 8 i h j e s h s inh h j where s inh h j μμ is an inhibitory h2 concentration for volatile fatty acid vfa i e butyrate and acetate oxidation by microorganism j in eqs 7 and 8 i b or a and j bo or ao for butyrate or acetate oxidation respectively the inhibition factor in eq 8 which was proposed by kouznetsova et al 2010 describes the distance of vfa oxidation from thermodynamic equilibrium the exponential inhibition factor simplifies the thermodynamic control on the rates of vfa oxidation and it was found more suitable for the solution of the inverse problem compared to more sophisticated models e g the models proposed by jin 2007 and fennell and gossett 1998 when tested these models evoked instabilities and oscillatory behaviors in several local searches during the solution of the inverse problem nevertheless the exponential inhibition factors were compared to the models of jin 2007 and fennell and gossett 1998 as shown in section 2 of the supplementary material the two modeling approaches agreed 4 2 4 kinetic model for biomass growth and decay microbial growth and decay for each microorganism was described in the model as follows 9 dx j dt i y j r i j b j x j where b j day 1 is the first order decay coefficient of microorganism j a single decay coefficient was used for all microbial groups like fennell and gossett 1998 and lee et al 2004 the model assumes that chloroethene supports biomass growth for the dechlorinators and thus cometabolism was not considered this is justified as dechlorination in both generations of ntua m was correlated with the offered electron donor surpluses under high surpluses they completed dechlorination while under low surpluses vc accumulated if chloroethene consumption was cometabolic adding excessive surpluses should not dictate the dechlorination outcome only its rate simulated outputs support the probability of this assumption if this assumption was unrealistic dechlorination rates should have been systematically overpredicted but they were not see section 6 1 for the achieved quality of fit 4 3 limitations of the modeling of ntua m1 and ntua m2 observational data frame the results obtained by the model in two ways first results are constrained by the fact that the model simulates a laboratory microbial community that is maintained under a high tce concentration 6 of its solubility and a low electron donor surplus these conditions favor dechlorinators and could potentially lead to a less diverse community compared to field conditions macbeth et al 2004 richardson 2016 second the modeling effort is constrained by the lack of observational data on h2 the relevance of h2 is two fold h2 observations would allow a more robust solution of the inverse problem additionally data on h2 would confirm the thermodynamic influence on microbial kinetics which is implicitly modeled using threshold eqs 1 and 6 and ceiling functions eq 8 of h2 concentrations in the absence of h2 observations the truthfulness of these functions was only partially inferred by the sufficient prediction of the respective reaction rates e g the stall of butyrate oxidation shown in fig 4f and i and the comparison with reported h2 levels from the literature 5 a multi experiment multi start algorithm for the solution of the inverse problem inverse problems involving monod type kinetic models are typically plagued by the non uniqueness of solutions non uniqueness of solutions derives from the poor reproducibility of biodegradation batch tests sommer et al 1998 the linear correlation of model parameters liu and zachara 2001 parameter insensitivity malaguerra et al 2011 or the limited availability of the information content that could constrain the model behavior e g microbial concentrations are seldom available chambon et al 2013 technically obtaining a solution for the inverse problem of monod type kinetic models is often feasible with optimization routines however the uniqueness of the solution cannot be guaranteed without a systematic search of the solution space in order to ascertain that the obtained solution does not correspond merely to a local minimum in which case the solution of the inverse problem would perform poorly under conditions drastically different than those used for parameter estimation on the other hand the existence of multiple solutions does not guarantee that all of them reproduce the experimental observations with acceptable accuracy finding a parameter set that produces an acceptable fit to the data requires providing the optimization algorithm with a good starting point providing a proper starting point necessitates prior knowledge of the system under consideration which is rarely available thus a poor fit of the model to the experimental observations may falsely lead to the conclusion that the conceptual model is inadequate when poor fit may be attributed to the failure of the optimization algorithm that was provided with an unsuitable starting point the inverse problem for the kinetic model of cultures ntua m1 and ntua m2 is such an ill posed problem as is typically the case with any monod type kinetic model employing field or laboratory scale data model complexity relative to the quantity of available experimental information only chemical concentrations are available microbial concentrations are not observed does not allow for rigorous estimation of all the components of the model model complexity derives from the multiple functionalities that are harbored within the model two methanogenic and two acetoclastic pathways are considered while tce can be consumed by two diverse dechlorinating species herein a multi start optimization algorithm was devised to mitigate the impacts of non uniqueness multi start algorithms are conceptually simple methods that allow the modeler to circumvent the difficulty of providing a single starting point mugunthan et al 2005 as local searches are performed from randomly generated starting points of the parameter space the multi start algorithm developed herein benefits from an added feature the multi experiment fitting kinetic models are fitted simultaneously to six data sets i e the three datasets of batch tests performed with each culture table 1 the datasets derive from diverse times in the life of each culture with different electron donors and different surpluses aiming to resolve non uniqueness issues and specify parameter sets that could describe with high probability the inherent collective dechlorinating capacity of mixed communities the inverse problem is solved in a stepwise rationale estimating different subsets of model parameters in each step parameters referring to the initial biomass concentrations are estimated first and then they are kept constant when the second group of parameters namely the maximum specific growth rates is specified lastly half velocity coefficients are estimated using the biomass distribution and the maximum specific growth rates estimated in the previous steps in this way errors induced by inappropriate parameter values in some model processes are not compensated for by introducing errors in other parameters of the model pechlivanidis and arheimer 2015 hundecha et al 2016 if that was the case an adequate fit would be a summation of counterbalancing errors that cancel each other out rather than a probable approximation of reality the multi start algorithm is realized sequentially as follows first a feasible starting point is generated which consists of initial biomass concentrations maximum specific growth rates and half velocity coefficients for steps 1 to 3 respectively second a local search method is implemented searching for a solution that minimizes the discrepancy between the model output and the observations in all batch tests i e the minimization of an objective function see section 5 2 third a stopping criterion is checked and if it is not met the algorithm re generates another feasible starting point when a stopping criterion is met see section 1 of the supplementary material all solutions are sorted based on their objective function values the solution with the lowest value is considered as the best fit solution solutions that have objective function values with a relative difference less than 1 from the best fit solution are considered equivalent to the best fit solution and constitute what will be described as the family of good fit solutions parameter variability is statistically inferred by the family of good fit solutions discussed in section 6 1 in summary the set up of the multi start algorithm comprises the following decisions a selection of an appropriate objective function b definition of the feasible area of the parameter space c specification of a procedure to generate feasible starting points d choice of a local search method and e formulation of a stopping criterion to prevent the algorithm reiterating perpetually the first two decisions are discussed in sections 5 1 and 5 2 and the remainder in section 1 of the supplementary material 5 1 selection of the objective function the nash sutcliffe efficiency nse coefficient was adopted as the objective function for the solution of the inverse problem 10 nse 1 0 t v test t v mode l t p 2 0 t v test t v test 2 where p is the parameter vector containing the kinetic parameters of the model and the unknown initial microbial concentrations v test is the vector of observed data v test is the vector of the mean of the observed data and v model is the vector of model outputs nse was considered appropriate to deal with differences in the magnitudes of the observed values between chloroethenes methane and volatile fatty acids amos et al 2007 nse ranges from to 1 an nse of 1 indicates a perfect match between model output and observations positive values are desirable as they indicate that model variance is lower than the variance of observed data values of nse greater than 0 60 were considered as a threshold above which the models are adequate to reproduce the observations the nse threshold was estimated from the published data of amos et al 2007 who used nse as an objective function to fit a monod type kinetic model to observed chloroethene concentrations 5 2 definition of the feasible area of the parameter space the feasible area of the parameter space was constructed by judiciously constraining the model parameters following an exhaustive literature review on the kinetic parameters of the problem parameters were considered either fixed to specific values or adjustable and constrained by the range of literature reported values the parameters that are typically measured in the laboratory i e growth yields and substrate thresholds and those that show low variability decay coefficients were considered more reliable and thus were fixed to specific values selected among those reported in the literature for example h2 threshold values for h2 consuming microorganisms were set after yang and mccarty 1998 who examined h2 competition between dechlorinators and their competitors methane and acetate producers in a mixed methane producing dechlorinating culture the parameters that typically result from curve fitting processes comprising maximum specific growth rates μ max j and half velocity coefficients k s i j vary significantly in the literature and hence were considered less reliable therefore they were treated as constrained adjustable parameters an outline of the literature review on model parameters is available in section 3 of the supplemental material table s3 1 summarizes the ranges of parameters reported in the literature for the two dechlorinating species together with the selected values for the fixed parameters and the solution parameter set for the adjustable parameters table s3 2 provides this information for the two types of methanogens and table s3 3 for butyrate and acetate oxidizers initial biomass concentrations were also treated as constrained adjustable parameters their constraints were calculated from the end products of each source culture during the achieved pseudo steady states see section 4 of the supplementary material for a discussion on the performance of the source cultures in order to safeguard against unrealistically high overall biomass concentrations solutions producing an overall biomass concentration greater than the 90 of the measured steady state biomass concentration of the source culture were discarded hence every culture may contain populations other than the six major groups considered herein equal to at most 10 of the overall biomass concentration this part of the biomass mostly consists of primary fermenters that mediate the conversion of decaying cells to short chain fatty acids and inert cells finally the initial concentrations of chemicals added were measured at the beginning of the batch test and hence were treated as fixed parameters 6 the outcome of the inverse problem 6 1 application of the multi experiment multi start strategy fernández et al 1999 and freeborn et al 2005 reported that changes in community structure are probable even in undisturbed microbial ecosystems and do not always imply changes at a functional level this work searches for possible quantitative and qualitative shifts in the two generations of culture ntua m these shifts would support a probable explanation for the diverse efficiency of enhanced dechlorination often reported in the literature that was observed in lab experiments by panagiotakis et al 2015 antoniou et al 2019 and antoniou et al 2019 if such shifts exist they should be reflected in changes in the kinetic properties and the relative abundance of each microbial group thriving in each culture first the multi start optimization algorithm was used in the three steps previously described to estimate the make up of the first generation of culture ntua m i e ntua m1 the initial biomass concentrations six x j values corresponding to the two dechlorinating species h2 and acetate utilizing methanogens and acetate and butyrate oxidizing syntrophs of the mixed microbial community were estimated at step 1 estimated initial x j values for each batch test were then kept constant and the maximum specific growth rates six μ max j values corresponding to the two dechlorinating species h2 and acetate utilizing methanogens and acetate and butyrate oxidizing syntrophs were specified at step 2 half velocity coefficients ten k s i j values corresponding to chloroethene consumption h2 and acetate dependent methane formation and acetate and butyrate oxidation were estimated at step 3 considering the previously estimated initial x j and μ max j fixed during each phase of the parameter estimation problem a sequence of 1000 quasi random starting points from the feasible area of the parameter space was created and local searches with the sqp routine see section 1 2 of the supplementary material were performed second for the second generation of culture ntua m i e ntua m2 only the initial x j and μ max j were treated as adjustable parameters in the inverse problem the values of k s i j for ntua m2 were assumed to be equal to those estimated for ntua m1 and were kept fixed thus only two steps were considered the initial x j concentrations and then μ max j values are estimated at steps 1 and 2 respectively a similar modeling approach has been previously used by berggren et al 2013 who confirmed the microbial shifts occurring in dechlorinating culture pm through their kinetic model in that case changes in the microbial composition were reflected in changes of the maximum specific growth rates and initial biomass concentrations a limitation of this approach is that changes in k s i j values resulting from community shifts will not be detected but given the correlated nature of μ max j and k s i j a change in k s i j will be reflected up to a point in a change of μ max j models were fitted simultaneously to experimental observations from the three batch experiments comprising chloroethenes tce cdce vc eth methane and vfas as listed in table 1 to ensure the accuracy of the solution of the forward problem i e ensure that the system of eqs 1 to 9 is solved accurately the balances of electron equivalents were estimated at each integration time step and the recovery of electron equivalents was estimated electron equivalent recovery it is defined as the percentage of electron equivalents recovered i e the sum of electron equivalents from remaining vfas the electron equivalents required for dechlorination and methane formation over the initially supplied electron equivalents ranged from 99 9 to 100 1 in all simulated tests by necessity this good numerical electron equivalent balance will create fitting problems since the recovery of electron equivalents for the experiments on the final day of each experiment was 108 for ls b1 87 for ms b1 74 for hs b1 127 for ls b2 93 for hs b2 and 128 for ms h2 apart from the objective function i e the nse values for every solution and for convenience purposes the quality of fit was assessed with the mean absolute error meanae and maximum absolute error maxae calculated for chloroethenes ethene methane and vfas finally the progress of dechlorination over time in these tests is assessed with an aggregate measure i e the dod expressed as percentage simulated chloroethene and ethene concentrations are compared with observations in section 5 of the supplementary material the best fit solution for ntua m1 and ntua m2 reproduced the observed data sets sufficiently the final nse values were greater than 0 79 for the six batch tests see the third step in fig 2a for ntua m1 and the second step in fig 2b for ntua m2 and thus greater than the considered threshold value for nse overall based on the solution of the two inverse problems the conceptual model captured the most salient cooperative and competing processes in both cultures as discussed in detail next for the low donor test ls b1 the model simulated accurately dechlorination in conjunction with methane formation fig 3a and b the meanae values for chloroethenes and methane equal 15 2 μμ and 17 1 μμ respectively the corresponding maxaes were 72 μμ for chloroethenes and 67 μμ for methane these are reasonable errors compared with the maximum concentrations of tce 505 μμ table 1 and methane 712 μμ fig 3b the best fit solution reproduced the patterns of acetate consumption and production but overpredicted slightly the peak of acetate concentrations at day 2 possibly due to the lower than 100 recovery of electron equivalents of the test during the first three days simulated meanae for vfas is 50 1 μμ and maxae is equal to 158 μμ which are acceptable considering that the anticipated uncertainty for vfas from the duplicate measurements was comparably high observed meanae and maxae were 70 0 μμ and 240 μμ respectively the best fit solution of the moderate surplus test ms b1 simulated adequately dechlorination and methane formation fig 3d and e but overpredicted acetate concentrations consistently fig 3f the misbalance between recovered and initially supplied electron equivalents electron equivalent recovery was 87 at the end of the experiment explains the discrepancy between modeled and observed acetate concentrations simulated meanaes were 14 1 μμ 61 0 μμ and 293 7 μμ for chloroethenes methane and vfas respectively the corresponding maxaes were 42 4 μμ 135 9 μμ and 387 2 μμ the best fit solution reproduced with adequate accuracy all the observed quantities for the high donor hs b1 apart from the terminal methane level fig 3h methane formation plateaued at a concentration almost 30 higher than the concentration observed in the batch test this discrepancy could be attributed at least partially to the misbalance between the recovered electron equivalents i e the sum of the consumed and accumulated electron equivalents at the end of the test and those initially offered specifically electron equivalent recovery was 74 for hs b1 the best fit solution for the ls b2 test described dechlorination and vfa consumption with fair accuracy fig 4a and c simulated meanaes were 10 4 μμ maxae was 16 6 μμ and 45 4 μμ maxae was 260 6 μμ when the maximum observed vfa concentration was 567 μμ which are comparable to the observed meanaes from the duplicate batch tests performed observed meanaes were 8 1 μμ and 18 μμ for chloroethenes and vfas respectively yet the best fit solution failed to reproduce the final levels of methane production fig 4b probably due to the excess recovery of 127 in the batch experiment i e the recovered electron equivalents accounted for 27 more electron equivalents than those initially offered the batch test appears to be deficient from day 7 in an electron equivalent basis indicating that a significantly better fit cannot be achieved for this data set the model produces balanced electron equivalent production and consumption and therefore it cannot simulate adequately all observed quantities the best fit solution for the hs b2 test predicted adequately a the completion of dechlorination by day 9 with an acceptable meanae of 35 4 μμ maxae was 59 68 μμ see also fig 4d b the accumulation of butyrate fig 4f and c the smooth increase of acetate during the first two days and its relatively low consumption rate thereafter fig 4f yet the simulated methane concentration at the end of the simulation was 1 7 fold greater than its observed counterpart this discrepancy should be attributed mostly to the overprediction of the rate of acetate dependent methane formation and to a lesser extent to the misbalance of the electron equivalents of the batch experiment in which the recovered electron equivalents were on average 9 less than the initially offered electron equivalents for the last three days of the experiment for the ms h2 test the best fit solution described the behavior of the culture sufficiently fig 4g to i simulations predicted the fast and complete removal of tce meanae for dechlorination was 12 0 μμ maxae was 59 7 μμ and the thermodynamic inhibition of butyrate consumption fig 4i resulting from the elevated h2 levels data available in section 6 of the supplementary material finally the best fit solution simulated adequately the observed methanogenic activity meanae was 23 1 μμ and maxae was 72 44 μμ which are both low compared to the maximum observed concentration of 583 μμ methane fig 4h the solution of the inverse problem significantly narrowed the initially considered range of parameter values i e the range of literature reported parameter values allowing for a reliable estimation of the qualitative and quantitative characteristics of the two generations of culture ntua m for example the half velocity coefficient for tce k s tce j varies from 0 05 μμ lee et al 2004 to 12 4 μμ cupples et al 2004 in the literature the solution of the inverse problem narrowed down this range to 10 4 μμ 11 9 μμ i e the range of the good fit solutions of the problem for complete dechlorinators see table s3 1 in the supplementary material parameter ranges were wider for parameters associated with methane formation and acetate consumption the existence of alternate pathways that could offer the same output for both processes complicated parameter estimation efforts which nonetheless resulted in acceptable levels of parameter variability the relative standard deviation of parameters remained reasonable and never exceeded 28 data not shown but all estimated parameter ranges are available in section 3 of the supplementary material parameter variability was comparable to the variability reported by heavner et al 2013 who calibrated a model with similar complexity and observed quantities but with fewer unknown parameters only kinetic parameters were estimated as initial biomass concentrations were measured conclusively the solution of the inverse problem offered an adequate fit to the experimental observations and identified two parameter sets one for each generation of ntua m with acceptable uncertainty thus allowing an interpretation of the differences between the generations as discussed next 6 2 gaining insight into the functional differences between ntua m1 and ntua m2 first this section investigates possible shifts in the community structure of culture ntua m and then re examines the tests performed under varying electron donor surpluses in search of evidence that would explain why the second generation of the culture i e ntua m2 outperformed the first generation i e ntua m1 under high electron donor surpluses i e hs b1 and hs b2 while both cultures functioned comparably under low electron donor surpluses i e ls b1 and ls b2 according to the best fit model solutions the two cultures differ notably in their h2 utilizing methanogenic hm populations as reflected in the different relative abundance fig 5a and kinetic properties of the h2 utilizing methanogens fig 5b a denser population of relatively fast growing h2 utilizing methanogens is present in ntua m1 while h2 utilizing methanogens in ntua m2 are fewer and grow more slowly regarding the remaining non dechlorinators i e acetate scavengers and butyrate oxidizers the two cultures were relatively stable compare the am bo and ao bars in fig 5a and b acetate oxidizing syntrophs were a minor and slow growing population while acetate utilizing methanogens were the most competent acetate scavenging species with respect to dechlorinators the density and growth rates of tce to eth dechlorinators are similar compare d c bars in fig 5a and b the densities of partial dechlorinators are also comparable compare d p bars in fig 5a but the competitive fitness of tce to cdce dechlorinators has changed remarkably compare d p bars in fig 5b the competitive fitness of tce to cdce dechlorinators over time deteriorated in ntua m simulated results indicate that tce consumption patterns in ntua m1 have changed relative to culture ntua m2 in all batch tests examined herein in ntua m1 tce to cdce dechlorinators consumed all the available tce within the first day data not shown as a result of their high μ max dp value and hence tce to eth dechlorinators had a disadvantage during the first day of the experiments this is in line with the high dechlorination rates reported by scholz muramatsu et al 1995 for partial dechlorinators sulfurospirillum spp in ntua m2 tce to eth dechlorinators consumed almost 20 of the available tce data not shown the fact that the active dechlorinating biomass of complete dechlorinators consuming cdce and vc in ntua m1 was sparser than in ntua m2 may have affected dechlorination rates however since the growth rates for complete dechlorinators in ntua m1 and ntua m2 are nearly identical d c bars in fig 5b the estimated one day starvation period for complete dechlorinators in ntua m1 does not justify the severe delays observed in complete chloroethene removal under high electron donor surpluses ntua m1 required nearly 40 days more than ntua m2 and a two fold greater surplus for complete dechlorination consequently the remainder of this section discusses how the differences in the make up of the non dechlorinating communities can explain the sizeable differences in the observed dechlorination rates by contrasting the distribution of reducing power in ntua m1 and ntua m2 under low surplus and high surplus the changes in the community structure of ntua m did not invoke any change in its function under a low electron donor surplus which resembles the maintenance conditions of the cultures the distributions of reducing power in the ntua m1 ls b1 and ntua m2 ls b2 are nearly identical fig 6a dechlorination was the second most efficient metabolism as acetate dependent methane formation consumed nearly 70 of the available electron equivalents in both cultures fig 6a thus acetate dependent methane formation was the prevailing pathway for methane formation h2 dependent methane formation contributed only 5 to the overall methane formation in ntua m1 and 2 in ntua m2 data not shown the prevailing h2 concentrations hindered h2 dependent methane formation in both cultures simulated h2 was maintained around 0 02 μm fig 7 i e only twice the h2 threshold for methane formation yang and mccarty 1998 it should be noted that simulated h2 levels are comparable to observed h2 levels for butyrate fed cultures aulenta et al 2008 consequently h2 was channeled mostly to dechlorinators fig 6b h2 was mostly produced by butyrate oxidation and to a lesser extent from acetate oxidation nearly 20 of the available acetate is oxidized for h2 production fig 6c which corresponds to almost 40 of the overall h2 production data not shown fig 8 provides the same behavior descriptors for high electron donor surplus where shifts in the non dechlorinating part of culture ntua m induced sizeable differences in the efficiency of h2 utilization the larger abundance of faster growing h2 utilizing methanogens in ntua m1 contrast fig 5a and b for hm explains its comparatively inefficient dechlorinating behavior in test hs b1 h2 utilizing methanogens consumed 92 of the available h2 rapidly fig 8b and maintained h2 concentrations in the range of 0 1 μμ for the first week of the experiment fig 9a during this period butyrate oxidation was thermodynamically feasible and thus butyrate was completely removed within the first week of the experiment following the first week the prevailing h2 concentrations were even lower in the range of 0 02 0 03 μμ fig 9a allowing acetate to function as a significant source of h2 acetate oxidizers then consumed 32 of the available acetate fig 8c but due to their lower affinity for acetate they were still outcompeted by acetate utilizing methanogens after the first week h2 never went higher than 0 03 μμ fig 9a and dechlorinators exploited these conditions they grew faster from day 7 to day 48 and eventually dechlorinated cdce and vc during this period h2 dependent methane formation became slower and acetate dependent methane formation became the main methanogenic pathway as the initially few acetate utilizing methanogens grew in numbers under the comparably high electron donor surplus in test hs b2 culture ntua m2 behaved differently than ntua m1 in ntua m2 the slow growing h2 utilizing methanogens did not pose a significant threat to dechlorinators despite the high h2 concentrations that prevailed fig 9b simulated h2 levels are in accordance with the findings reported by mao et al 2015 who observed h2 concentrations as high as 1 2 μμ during vc removal by a syntrophic coculture of dehalococcoides mccartyi 195 and syntrophomonas wolfei 57 of the available h2 was consumed by dechlorinators fig 8b on that account ntua m2 dechlorinated tce rapidly within nine days the high h2 concentrations inhibited vfas oxidation and consequently left much of the supplied reducing power unused as seen by the significant section of the bar that corresponds to remaining vfas in fig 8a 7 conclusions two generations of the mixed dehalococcoides mccartyi dominated community ntua m were studied using a kinetic model developed to account for dechlorination in conjunction with cooperative i e fermentation of h2 precursors and competing processes i e methane formation the kinetic model was inversed using experimental data from the two generations of ntua m the two generations functioned comparably under conditions of low electron donor surplus with respect to h2 yet under conditions of higher electron donor surplus they behaved divergently the multi experiment multi start algorithm that solved the ill posed inverse problem managed to i reproduce the performance of ntua m under varying electron donor surpluses and at different instances of the lifetime of the culture ii describe the kinetic properties and the composition of ntua m with acceptable uncertainty as well as iii suggest a probable cause for the contrasting behaviors exhibited by ntua m as explained below model derived results showed that in mixed chloroethene degrading communities functional similarities under low electron donor surpluses do not preclude community variability in culture ntua m a diverse and dynamic community of non dechlorinators co existed with dechlorinators over time in the two generations of ntua m the non dechlorinating community was rearranged in different ways while demonstrating the same behavior under starvation conditions with respect to h2 differences in the non dechlorinating fraction became important during biostimulation at higher electron donor surplus the model derived results also revealed that these differences dictated the distribution of the offered electron donor source microbial communities that differed mostly in the relative abundance and the competitive fitness of non dechlorinators which were minority populations required drastically different approaches to optimize the complete detoxification of chloroethenes an ample h2 supply would be optimal for ntua m2 but in ntua m1 it would disadvantage the dechlorinators the inquiry presented herein offers a framework through which to interpret the conflicting observations of dechlorination under methanogenic conditions reported in the literature in this framework the collective activities of chloroethene degrading communities are characterized not exclusively by the activity of dechlorinators but also by the relative abundance and the competitive fitness of competitors that hinder and syntrophs that mediate h2 supply certain perceptions of good practices for efficient dechlorination have stemmed from generalizations that should be dealt with caution as the universe of methane producing chloroethene degrading communities is heterogeneous not only due to the variable composition of dechlorinators but also due to the differences in the make up of the non dechlorinating community a selective approach to the adaptation of good practices is even more pertinent to field scale applications where the efforts to decipher the make up of the existing microbial communities can guide remedial decision making if the findings of this study were to be extrapolated to the field an example would be a site where remediation completion time is of interest there an ntua m2 like dominance of acetate utilizing methanogens might support the decision to use a higher electron donor surplus or direct supply of h2 anticipating that excessively high methane levels are unlikely in such context knowledge of the makeup of the community of non dechlorinators would have decision value for the electron donor type and surplus chosen for biostimulation authorship statement all persons who meet authorship criteria are listed as authors and all authors certify that they have participated sufficiently in the work to take public responsibility for the content including participation in the concept design analysis writing or revision of the manuscript declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the present work was supported by the iky fellowships of excellence for postgraduate studies in greece siemens program the authors thank dr iraklis panagiotakis and dr cornelia antoniou for providing the measured values of the published experimental results and the maintenance data of the source culture and the two thoughtful and meticulous anonymous reviewers appendix a supplementary data supplementary material image 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jconhyd 2021 103834 
1425,the composition of mixed dechlorinating communities varies considerably in field and laboratory conditions dechlorinators thrive alongside with distinctive populations that help or hinder dechlorination the variability of the composition of dechlorinating communities inevitably precludes a firm consensus regarding the optimal strategies for biostimulation this lack of consensus motivated a model based approach for the investigation of how the variability of the composition of a microbial community impacts the electron donor supply strategies for accelerating chloroethene removal to this end a kinetic model accounting for dechlorination in conjunction with cooperative and competing processes was developed model parameters were estimated using a multi experiment multi start algorithm and data from research previously performed with two generations of a methane producing dehalococcoides mccartyi dominated consortium the two generations of the consortium functioned comparably under maintenance conditions but performed divergently under high electron donor surpluses the multi experiment multi start algorithm overcame the hurdles of poor parameter identifiability and offered a probable cause for the different behaviors exhibited by each of the two generations of the chloroethene degrading consortium modest differences in the make up of non dechlorinators which were minority populations significantly influenced the fate of the offered electron donor graphical abstract unlabelled image keywords tce metabolic reductive dechlorination methanogenesis modeling calibration 1 introduction this work searches for model based evidence that supports answers to the following question what is the impact of the variability of microbial community composition on the distribution of electron equivalents and thus on the selection of successful strategies for efficient dechlorination during biostimulation to this end a comprehensive kinetic model was designed and calibrated to study the composition of two generations of a methane producing dehalococcoides mccartyi dominated dechlorinating culture developed at ntua ntua m the present study focused on the utilization of h2 and acetate by dechlorinators and non dechlorinators both competitors and syntrophs in these two generations seeking to interpret similarities and differences observed under substrate limiting conditions and high electron donor surpluses the performance of the two generations of the ntua m culture which will be referred to as ntua m1 and ntua m2 hereafter was investigated in the laboratory by panagiotakis et al 2014 2015 antoniou et al 2019 and antoniou et al 2019 under both low and high electron donor surpluses and provided the stimulus for framing the research question cultures ntua m1 and ntua m2 performed similarly under low electron donor surpluses with butyrate serving as a low h2 ceiling donor source butyrate fermentation is limited by aqueous h2 concentrations greater than 0 35 μμ according to mao et al 2015 yet elevated donor surpluses revealed notable differences ntua m1 required an electron donor surplus of 24 5 surplus is estimated assuming that 1 mol h2 yields 2 eeq 1 mol butyrate yields 20 eeq and 1 mol tce requires 6 eeq for its complete dechlorination and nearly 48 days to dechlorinate tce completely while ntua m2 removed all chloroethenes completely with an electron donor surplus of 12 9 within 9 2 days when ntua m2 was fed directly with h2 as the electron donor it managed to remove trichloroethene tce and daughter products with an electron donor surplus of only 5 4 within 6 days kinetic models were used to corroborate experimental findings as multiple processes underlie laboratory observations the study of dechlorination in mixed microbial communities is challenging model based approaches can decouple dechlorination from its side reactions and thereby systematically assess the mechanisms that potentially affect dechlorination kinetic models must surpass another obstacle the difficulty to estimate a single best set of parameters from batch experimental data i e the problem of the non uniqueness of parameters this difficulty is acknowledged chambon et al 2013 and renders model based evidence insufficient due to non uniqueness the relevance of parameters to other systems or to extrapolating conditions cannot be assessed nonetheless the search for a single best parameter set has been rarely given attention in the literature on dechlorination e g haest et al 2010 in which reports on parameter uncertainties are scarce e g heavner et al 2013 this work develops and employs a multi experiment multi start algorithm to mitigate and assess the impact of non uniqueness the multi experiment component of the algorithm aims to simultaneously optimize the performance of kinetic models to a set of experiments performed under distinctive initial conditions and thereby reduce the potential for non unique parameters the multi start component aspires to detect a best fit solution that is neither bound to the initial guesses for the parameter values nor trapped to sub optimal solutions i e solutions that cannot describe adequately the observations non uniqueness cannot be eradicated but the multi start approach can turn this problem to an opportunity for assessing uncertainty through the examination of the multiple parameter sets that could be acceptable representations of the system under examination and reduce parameter variability see end of section 6 1 and tables s3 1 s3 3 in the supplementary material in what follows after the first two sections introduction and background section 3 includes findings from the experiments with cultures ntua m1 and ntua m2 that motivated the research section 4 presents the conceptual and mathematical formulation of the model used to describe culture performance section 5 discusses the decisions involved in the solution of the inverse problem readers who are not interested in inverse modeling may elect to only skim section 5 beyond its introductory part and focus on the solution outcome presented in section 6 which is split in two subsections and 1 shows the fit of the model to the experimental results for the two cultures and 2 compares the composition of the two cultures in order to relate community structure to performance 2 background methane producing chloroethene degrading consortia constitute complex food webs containing apart from dechlorinators methanogens h2 and acetate utilizing species as well as acetate and h2 producing syntrophs these food webs involve interspecies transfers of h2 and acetate among the members of the consortium during biostimulation the primary concern is how to strategically supply h2 sources and channel reducing power to dechlorinators the dominant view regarding biostimulation posits that substrates necessitating low h2 concentrations for their fermentation low h2 ceiling donor sources selectively enhance dechlorinators which are effective h2 scavengers at such low h2 concentrations in the range of a few nm fennell et al 1997 and yang and mccarty 1998 showed that organic substrates acting as low h2 ceiling donor sources gave dechlorinators an advantage over methanogens and thereafter the findings of yang and mccarty 2000 azizian et al 2010 and wen et al 2015 strengthened this view this dominant view may be interpreted to imply that methane formation in dechlorinating consortia is primarily h2 dependent a valid assumption in a significant share of microbial communities for which reported molecular analyses support the existence of h2 utilizing methanogens for example in dechlorinating culture anas the h2 utilizing methanogens methanobacterium and methanospirillum have been identified richardson et al 2002 brisson et al 2012 in kb 1 subcultures methanogenic populations comprise mainly methanomethylovorans methanol utilizing methanogen and methanomicrobiales an order containing mostly h2 utilizing methanogens duhamel and edwards 2006 yet methane formation in mixed chloroethene degrading consortia is not solely h2 dependent acetate dependent methane formation has also been reported as the main methanogenic pathway in mixed chloroethene degrading consortia and acetate utilizing methanogens have been reported as the major methanogenic population in microbial communities developed under laboratory conditions or established in the field specifically chloroethene degrading culture donna ii comprises the h2 utilizing methanospirillum and the acetate utilizing methanosaeta rowe et al 2008 with methane formation being predominantly acetate dependent heavner et al 2013 dennis et al 2003 detected mostly methanosaeta in a soil column fed with methanol and butyrate while treating pce non aqueous phase liquid macbeth et al 2004 found that methanosaeta were prevailing in a chloroethene degrading consortium established with material from a contaminated site undergoing biostimulation as macbeth et al 2004 postulate low temperatures 15 c may have favored acetate utilizing methanogens thus under field conditions if methane is observed concurrently with dechlorination the probability of acetate dependent methane formation is considerable the community composition variation adds a source of uncertainty in the description of the dynamics of h2 production and consumption thus generalizations stemming from the dominant view that enhanced dechlorination is successful under fermentable electron donors that sustain low h2 concentrations are questionable skepticism for this view is supported by conflicting findings reported in the literature three of the most well studied mixed dechlorinating cultures have been maintained for years with high h2 ceiling substrates various subcultures of the commercially available culture kb 1 have been maintained with mixtures of ethanol and methanol or h2 duhamel and edwards 2006 while cultures anas richardson et al 2002 and sdc 9 schäfer et al 2009 are both fed with lactate a high h2 ceiling donor source even direct addition of h2 has been reported to be a promising approach aulenta et al 2005 2007 in some cultures even if it promoted methane formation in others ma et al 2003 2006 2007 wen et al 2015 the relevance of the variability of community composition has been acknowledged in the literature richardson 2016 current efforts mostly focus on characterizing the community ecology in enrichment cultures e g duhamel and edwards 2006 rowe et al 2008 or contaminated sites e g lee et al 2012 kotik et al 2013 and specifying the niche that each microbial group fills within the dechlorinating communities hug et al 2012 yet a quantitative assessment of how community composition determines electron flow is lacking as only a few kinetic models describe how the activities of non dechlorinators depend upon h2 and acetate availability richardson 2016 chambon et al 2013 this gap is addressed by this study 3 experimental observations this section introduces the two sources of experimental information that are available for the study of dechlorination a the long term performance data of the source cultures and b the six batch tests performed at different instances of the history of the source cultures under varying electron donor surpluses the fact that batch tests are distributed within the lifetime of the cultures makes parameter estimation challenging but it allows also for a meaningful application of the multi experiment approach which aims to identify a single set for most parameters and thereby approximate the inherent dechlorinating capability of mixed microbial communities i e their capabilities regardless of initial conditions or culture history 3 1 long term monitoring of the cultures ntua m1 and ntua m2 source cultures ntua m1 and ntua m2 were maintained under limiting electron donor conditions to mimic the conditions typically encountered in the field under natural attenuation panagiotakis 2010 antoniou 2019 particularly they were maintained on a seven day feeding cycle that included the addition of 500 μμ 66 7 mg l tce and 300 μμ 27 5 mg l butyrate which served as a low h2 ceiling electron donor source at the end of each feeding cycle part of the culture was replaced by fresh medium to achieve a solid retention time of 48 days with respect to their maintenance characteristics these cultures differed only in the addition of yeast extract which was routinely added in the case of ntua m1 at a concentration of 4 5 mg l yeast extract is a nutritional supplement which also serves as a source of slowly fermented volatile fatty acids mainly butyrate and to a lesser degree acetate and propionate fennell and gossett 1998 however the quantity of yeast extract added in culture ntua m1 is low according to yang and mccarty 1998 it yields an equivalent of 780 μeeq l which corresponds to approximately a 10 increase of reducing power if it is consumed within the seven day feeding cycles hence the addition of yeast extract changes mildly the electron equivalent surplus of culture ntua m1 the two cultures had attained a steady state performance regarding dechlorination and butyrate consumption on a weekly basis cultures ntua m1 and ntua m2 dechlorinated on average 64 and 71 of the overall available chloroethenes respectively in ntua m1 vinyl chloride vc was the main daughter product of dechlorination 82 of the total ethene concentration at the end of each feeding cycle followed cis 1 2 dichloroethene cdce 12 and ethene eth 6 in ntua m2 vc and eth were the major end products of dechlorination 88 and 12 respectively cdce was not detected since eth is produced both cultures are classified as dehalococcoides mccartyi enriched cultures a finding that was further verified by fish analysis of microbial community structure the supplied butyrate was steadily consumed on each feeding cycle indicating the existence of a robust butyrate degrading community with respect to methane formation the two cultures failed to reach steady state in both cultures methane formation alternated between two phases of lower and elevated methane formation these phases were accompanied by inversely fluctuating acetate concentrations panagiotakis 2010 antoniou 2019 i e elevated methane formation coincided with low acetate concentrations and vice versa a fluorescence in situ hybridization fish analysis was performed during the operation of culture ntua m1 providing insight into the main microbial groups thriving within the culture panagiotakis et al 2014 specifically fish analysis demonstrated that a dehalococcoides mccartyi spp was the predominant species 49 of the total bacteria b two hydrogenotrophic dechlorinators were present besides dehalococcoides mccartyi spp the partial dechlorinator sulfurospirillum spp was detected and comprised 8 of the total bacteria and c methanogenic archaea were only a small proportion of the culture around 10 of the total cell numbers fish analysis underscored the relevance of dechlorinators and methanogens but it could not a enumerate them rigorously and b provide definite answers as to which and how many other microbial groups should be considered in addition this molecular analysis cannot illustrate the exact composition of culture ntua m2 but given the increase in dechlorinating performance of ntua m2 it is reasonable to assume that culture ntua m2 is also dominated by dehalococcoides mccartyi the end products of the seven day feeding cycles indicated that the major processes occurring within the two mixed cultures are dechlorination butyrate oxidation and methanogenesis what is more dechlorination daughter products at the end of each feeding cycle indicated that syntrophic acetate oxidation should also be considered since as already mentioned a eth was observed at the end of each seven day feeding cycle and b based on the butyrate quantity added direct h2 formation 600 μμ h2 can be readily formed from 300 μμ of butyrate would justify only cdce and vc as the main daughter products of tce dechlorination hence it is reasonable to deduce that a h2 source additional to butyrate sustained dechlorination that is acetate this is true for both ntua m1 and ntua m2 so the additional source cannot be solely the yeast extract decaying biomass does not provide the missing electron equivalents either as it functions as a source that produces butyrate slowly hence decaying biomass cannot act as a readily available source of h2 for dechlorinators or methanogens within the seven day feeding cycles of the cultures 3 2 batch tests performed with cultures ntua m1 and ntua m2 the present section outlines the essential features of the batch tests performed with ntua m1 and ntua m2 a detailed discussion on the outcomes of the batch tests performed with the two cultures is available in the sixth section of this work entitled the outcome of the inverse problem where observations from the batch tests are compared to simulation outcomes as the batch tests in both cultures were not performed simultaneously changes in the initial relative abundance of the microbial groups should be anticipated and could be hypothesized on the basis of the experimental results accounting for these changes was the incentive for the work presented in this paper three butyrate fed batch experiments are available for culture ntua m1 table 1 these tests were performed at different instances of the life of culture ntua m1 with butyrate as an electron donor source and under varying electron donor surpluses a test ls b1 panagiotakis et al 2014 was performed under a low surplus ls of 2 4 b test ms b1 panagiotakis et al 2015 was performed under a moderate surplus 5 5 and c hs b1 panagiotakis et al 2015 was performed under a high surplus 24 5 three batch experiments are available for dechlorinating culture ntua m2 panagiotakis et al 2015 antoniou et al 2019 as well the experiments were performed with varying initial electron donor types and quantities table 1 a test ls b2 panagiotakis et al 2015 was performed under a low surplus 2 4 with butyrate as serving as an electron donor source b test hs b2 antoniou et al 2019 was performed under a high surplus 12 9 with butyrate as serving as an electron donor source and c ms h2 panagiotakis et al 2015 was performed under a moderate surplus 5 4 with h2 being supplied directly as an electron donor 4 mathematical model 4 1 conceptual setup of the model the processes occurring concurrently with the anaerobic degradation of chloroethenes are depicted in fig 1 the associated reactions are presented in table 2 according to this conceptual model a butyrate oxidizing community butyrate oxidizer in fig 1 consumes the supplied butyrate and produces h2 and acetate potential fermentation by products as propionate were measured but never detected in appreciable concentrations in ntua m antoniou 2019 h2 is subsequently used by a tce to eth dechlorinators b tce to cdce dechlorinators and c h2 utilizing methanogens acetate is either converted to methane by acetate utilizing methanogens or consumed by acetate oxidizing bacteria to produce h2 conceptually the modeling of the dechlorinating community builds upon two assumptions first dechlorination is presumably dependent solely on h2 acetate dependent consumption of tce was not included in the model this is a reasonable assumption based on the molecular analysis discussed in section 3 1 members of dehalococcoides mccartyi and sulfurospirillum spp can utilize only h2 from the available electron donor sources second the model considers only two dechlorinating populations this is a simplification of the ecology of mixed dechlorinating communities typically dechlorinating communities comprise clusters of diverse subpopulations with different strains catalyzing specific dechlorination steps mayer blackwell et al 2017 different substrate preferences and metabolic abilities wei et al 2016 however a model describing a complex community would be prone to overfitting errors unless considerably more observational data on the responsible microbial populations and their abundance were available regarding the competition for h2 the model considers only two options dechlorination and methane formation homoacetogens were not included as potential hydrogenotrophic competitors homoacetogenesis requires a threshold concentration above 400 nm h2 to be thermodynamically feasible löffler et al 1999 this explains why homoacetogens are detectable within cultures that are maintained with high ceiling electron donor sources e g lactate richardson 2016 thus their presence in ntua m1 and ntua m2 is highly unlikely additionally the batch test performed with direct h2 addition ms h2 did not indicate acetate production lastly the model does not consider the by products of decaying biomass as a potential source of electron equivalents decaying biomass should be considered as a relevant source of electron equivalents for time horizons significantly greater than those simulated herein i e 6 to 48 days sleep et al 2005 4 2 mathematical formulation of the model in the mathematical formulation of the model the concentration of biological components will be denoted as x j where index j changes for the six microbial groups of interest as follows j is d c for tce to eth complete dechlorinators d p for tce to cdce partial dechlorinators hm for h2 utilizing methanogens am for acetate utilizing methanogens bo for butyrate oxidizers and ao for acetate oxidizers the concentration of chemical components will be denoted as s i where index i changes in order to designate the various chemical components of the model i is tce cdce vc eth for the respective chloroethenes m for methane h for h2 b for butyrate and a for acetate 4 2 1 dechlorination kinetics chloroethene consumption rates r i j were described by dual substrate monod kinetic equations 1 r i j m max j y j x j s i k s i j s i s h s min h j f d j k s h j s h s min h j f d j f d j where μ max j is the maximum specific growth rate of microorganism j day 1 x j is the biomass concentration of microorganism j mg vss l y j is the yield coefficient of microorganism j mg vss μmol cl s i is the concentration of substrate i μμ k s i j is the half velocity coefficient for chloroethene i of microorganism j μμ s h is the concentration of h2 μμ k s h j is the half velocity coefficient for h2 of microorganism j μμ and s min h j is the threshold for h2 use for dechlorinators μμ two sigmoid functions f d j and f d j were used in order to avoid possible instabilities and oscillatory behavior when h2 concentrations approach the h2 threshold values ribes et al 2004 these sigmoid functions are defined as follows 2 f d j 1 1 exp 100 s min h j s min h j s h 3 f d j 1 1 exp 100 s min h j 1 1 s min h j s h in eqs 2 3 and 4 i tce or cdce and j dc for tce to eth dechlorinators or dp for tce to cdce dechlorinators concerning vc consumption possible competitive inhibition of vc by cdce was considered and consequently eq 2 was replaced by cupples et al 2004 4 r vc d 1 m max d 1 y d 1 x d 1 s vc k s vc d 1 1 s cdce k inh cdce s vc s h s min h d 1 f d d 1 k s h d 1 s h s min h d 1 f d d 1 f d d 1 where k inh cdce μm is an inhibition coefficient which was set equal to the half velocity coefficient for the respective chloroethene i e k inh cdce k s cdce j yu et al 2005 inhibition of tce on its daughter products was neglected since tce is rapidly removed and thus the impact of tce on the less chlorinated compounds would be minimal in eqs 1 and 4 μ max j and y j are microorganism related parameters and thus independent from the chloroethene consumed this assumption has been previously applied in several modeling approaches e g lee et al 2004 clapp et al 2004 because it simplifies model structure while preserving the ability to capture the difference in consumption rates r i j among the various chloroethenes kandris et al 2015 finally the progress of dechlorination over time will be tracked with the degree of dechlorination dod an aggregate measure calculated from the concentrations of chloroethenes and eth as follows manoli et al 2012 ranging from 0 to 1 or equivalently 100 for complete dechlorination 5 dod s cdce 2 s vc 3 s eth 3 s tce s cdce s vc s eth 4 2 2 methane formation kinetics methane formation was modeled using monod type kinetic equations which incorporated substrate thresholds for h2 or acetate use by the corresponding methanogen specifically the rates of h2 or acetate consumption from the corresponding methanogen r i j were calculated as follows 6 r i j m max j y j x j s i s min i j f j k s i j s i s min i j f j f j where μ max j day 1 is the maximum specific growth rate of methanogen j y j mg vss μmol substrate is the yield coefficient of methanogen j x j is the biomass concentration of methanogen j mg vss l k s i j μμ is the half velocity coefficient for substrate i of methanogen j and s min i j μμ is the threshold for substrate use i of methanogen j finally the sigmoid functions f j and f j which were defined by eqs 2 and 3 were adjusted to account for the appropriate substrate threshold s min h hm and s min a am instead of s min h j in eq 6 i h or a and j hm or am for h2 or acetate dependent methane formation respectively 4 2 3 butyrate and acetate oxidation kinetics the rate of butyrate or acetate oxidation r i j was described as follows 7 r i j m max j y j x j s i k s i j s i i h j where μ max j day 1 is the maximum specific growth rate of microorganism j yj mg vss μmol substrate is the yield coefficient of microorganism j x j mg vss l is the biomass concentration of microorganism j s i μm is the concentration of substrate i and k s i j μμ is the half velocity coefficient for substrate i and microorganism j the inhibition factor i i j is defined as follows 8 i h j e s h s inh h j where s inh h j μμ is an inhibitory h2 concentration for volatile fatty acid vfa i e butyrate and acetate oxidation by microorganism j in eqs 7 and 8 i b or a and j bo or ao for butyrate or acetate oxidation respectively the inhibition factor in eq 8 which was proposed by kouznetsova et al 2010 describes the distance of vfa oxidation from thermodynamic equilibrium the exponential inhibition factor simplifies the thermodynamic control on the rates of vfa oxidation and it was found more suitable for the solution of the inverse problem compared to more sophisticated models e g the models proposed by jin 2007 and fennell and gossett 1998 when tested these models evoked instabilities and oscillatory behaviors in several local searches during the solution of the inverse problem nevertheless the exponential inhibition factors were compared to the models of jin 2007 and fennell and gossett 1998 as shown in section 2 of the supplementary material the two modeling approaches agreed 4 2 4 kinetic model for biomass growth and decay microbial growth and decay for each microorganism was described in the model as follows 9 dx j dt i y j r i j b j x j where b j day 1 is the first order decay coefficient of microorganism j a single decay coefficient was used for all microbial groups like fennell and gossett 1998 and lee et al 2004 the model assumes that chloroethene supports biomass growth for the dechlorinators and thus cometabolism was not considered this is justified as dechlorination in both generations of ntua m was correlated with the offered electron donor surpluses under high surpluses they completed dechlorination while under low surpluses vc accumulated if chloroethene consumption was cometabolic adding excessive surpluses should not dictate the dechlorination outcome only its rate simulated outputs support the probability of this assumption if this assumption was unrealistic dechlorination rates should have been systematically overpredicted but they were not see section 6 1 for the achieved quality of fit 4 3 limitations of the modeling of ntua m1 and ntua m2 observational data frame the results obtained by the model in two ways first results are constrained by the fact that the model simulates a laboratory microbial community that is maintained under a high tce concentration 6 of its solubility and a low electron donor surplus these conditions favor dechlorinators and could potentially lead to a less diverse community compared to field conditions macbeth et al 2004 richardson 2016 second the modeling effort is constrained by the lack of observational data on h2 the relevance of h2 is two fold h2 observations would allow a more robust solution of the inverse problem additionally data on h2 would confirm the thermodynamic influence on microbial kinetics which is implicitly modeled using threshold eqs 1 and 6 and ceiling functions eq 8 of h2 concentrations in the absence of h2 observations the truthfulness of these functions was only partially inferred by the sufficient prediction of the respective reaction rates e g the stall of butyrate oxidation shown in fig 4f and i and the comparison with reported h2 levels from the literature 5 a multi experiment multi start algorithm for the solution of the inverse problem inverse problems involving monod type kinetic models are typically plagued by the non uniqueness of solutions non uniqueness of solutions derives from the poor reproducibility of biodegradation batch tests sommer et al 1998 the linear correlation of model parameters liu and zachara 2001 parameter insensitivity malaguerra et al 2011 or the limited availability of the information content that could constrain the model behavior e g microbial concentrations are seldom available chambon et al 2013 technically obtaining a solution for the inverse problem of monod type kinetic models is often feasible with optimization routines however the uniqueness of the solution cannot be guaranteed without a systematic search of the solution space in order to ascertain that the obtained solution does not correspond merely to a local minimum in which case the solution of the inverse problem would perform poorly under conditions drastically different than those used for parameter estimation on the other hand the existence of multiple solutions does not guarantee that all of them reproduce the experimental observations with acceptable accuracy finding a parameter set that produces an acceptable fit to the data requires providing the optimization algorithm with a good starting point providing a proper starting point necessitates prior knowledge of the system under consideration which is rarely available thus a poor fit of the model to the experimental observations may falsely lead to the conclusion that the conceptual model is inadequate when poor fit may be attributed to the failure of the optimization algorithm that was provided with an unsuitable starting point the inverse problem for the kinetic model of cultures ntua m1 and ntua m2 is such an ill posed problem as is typically the case with any monod type kinetic model employing field or laboratory scale data model complexity relative to the quantity of available experimental information only chemical concentrations are available microbial concentrations are not observed does not allow for rigorous estimation of all the components of the model model complexity derives from the multiple functionalities that are harbored within the model two methanogenic and two acetoclastic pathways are considered while tce can be consumed by two diverse dechlorinating species herein a multi start optimization algorithm was devised to mitigate the impacts of non uniqueness multi start algorithms are conceptually simple methods that allow the modeler to circumvent the difficulty of providing a single starting point mugunthan et al 2005 as local searches are performed from randomly generated starting points of the parameter space the multi start algorithm developed herein benefits from an added feature the multi experiment fitting kinetic models are fitted simultaneously to six data sets i e the three datasets of batch tests performed with each culture table 1 the datasets derive from diverse times in the life of each culture with different electron donors and different surpluses aiming to resolve non uniqueness issues and specify parameter sets that could describe with high probability the inherent collective dechlorinating capacity of mixed communities the inverse problem is solved in a stepwise rationale estimating different subsets of model parameters in each step parameters referring to the initial biomass concentrations are estimated first and then they are kept constant when the second group of parameters namely the maximum specific growth rates is specified lastly half velocity coefficients are estimated using the biomass distribution and the maximum specific growth rates estimated in the previous steps in this way errors induced by inappropriate parameter values in some model processes are not compensated for by introducing errors in other parameters of the model pechlivanidis and arheimer 2015 hundecha et al 2016 if that was the case an adequate fit would be a summation of counterbalancing errors that cancel each other out rather than a probable approximation of reality the multi start algorithm is realized sequentially as follows first a feasible starting point is generated which consists of initial biomass concentrations maximum specific growth rates and half velocity coefficients for steps 1 to 3 respectively second a local search method is implemented searching for a solution that minimizes the discrepancy between the model output and the observations in all batch tests i e the minimization of an objective function see section 5 2 third a stopping criterion is checked and if it is not met the algorithm re generates another feasible starting point when a stopping criterion is met see section 1 of the supplementary material all solutions are sorted based on their objective function values the solution with the lowest value is considered as the best fit solution solutions that have objective function values with a relative difference less than 1 from the best fit solution are considered equivalent to the best fit solution and constitute what will be described as the family of good fit solutions parameter variability is statistically inferred by the family of good fit solutions discussed in section 6 1 in summary the set up of the multi start algorithm comprises the following decisions a selection of an appropriate objective function b definition of the feasible area of the parameter space c specification of a procedure to generate feasible starting points d choice of a local search method and e formulation of a stopping criterion to prevent the algorithm reiterating perpetually the first two decisions are discussed in sections 5 1 and 5 2 and the remainder in section 1 of the supplementary material 5 1 selection of the objective function the nash sutcliffe efficiency nse coefficient was adopted as the objective function for the solution of the inverse problem 10 nse 1 0 t v test t v mode l t p 2 0 t v test t v test 2 where p is the parameter vector containing the kinetic parameters of the model and the unknown initial microbial concentrations v test is the vector of observed data v test is the vector of the mean of the observed data and v model is the vector of model outputs nse was considered appropriate to deal with differences in the magnitudes of the observed values between chloroethenes methane and volatile fatty acids amos et al 2007 nse ranges from to 1 an nse of 1 indicates a perfect match between model output and observations positive values are desirable as they indicate that model variance is lower than the variance of observed data values of nse greater than 0 60 were considered as a threshold above which the models are adequate to reproduce the observations the nse threshold was estimated from the published data of amos et al 2007 who used nse as an objective function to fit a monod type kinetic model to observed chloroethene concentrations 5 2 definition of the feasible area of the parameter space the feasible area of the parameter space was constructed by judiciously constraining the model parameters following an exhaustive literature review on the kinetic parameters of the problem parameters were considered either fixed to specific values or adjustable and constrained by the range of literature reported values the parameters that are typically measured in the laboratory i e growth yields and substrate thresholds and those that show low variability decay coefficients were considered more reliable and thus were fixed to specific values selected among those reported in the literature for example h2 threshold values for h2 consuming microorganisms were set after yang and mccarty 1998 who examined h2 competition between dechlorinators and their competitors methane and acetate producers in a mixed methane producing dechlorinating culture the parameters that typically result from curve fitting processes comprising maximum specific growth rates μ max j and half velocity coefficients k s i j vary significantly in the literature and hence were considered less reliable therefore they were treated as constrained adjustable parameters an outline of the literature review on model parameters is available in section 3 of the supplemental material table s3 1 summarizes the ranges of parameters reported in the literature for the two dechlorinating species together with the selected values for the fixed parameters and the solution parameter set for the adjustable parameters table s3 2 provides this information for the two types of methanogens and table s3 3 for butyrate and acetate oxidizers initial biomass concentrations were also treated as constrained adjustable parameters their constraints were calculated from the end products of each source culture during the achieved pseudo steady states see section 4 of the supplementary material for a discussion on the performance of the source cultures in order to safeguard against unrealistically high overall biomass concentrations solutions producing an overall biomass concentration greater than the 90 of the measured steady state biomass concentration of the source culture were discarded hence every culture may contain populations other than the six major groups considered herein equal to at most 10 of the overall biomass concentration this part of the biomass mostly consists of primary fermenters that mediate the conversion of decaying cells to short chain fatty acids and inert cells finally the initial concentrations of chemicals added were measured at the beginning of the batch test and hence were treated as fixed parameters 6 the outcome of the inverse problem 6 1 application of the multi experiment multi start strategy fernández et al 1999 and freeborn et al 2005 reported that changes in community structure are probable even in undisturbed microbial ecosystems and do not always imply changes at a functional level this work searches for possible quantitative and qualitative shifts in the two generations of culture ntua m these shifts would support a probable explanation for the diverse efficiency of enhanced dechlorination often reported in the literature that was observed in lab experiments by panagiotakis et al 2015 antoniou et al 2019 and antoniou et al 2019 if such shifts exist they should be reflected in changes in the kinetic properties and the relative abundance of each microbial group thriving in each culture first the multi start optimization algorithm was used in the three steps previously described to estimate the make up of the first generation of culture ntua m i e ntua m1 the initial biomass concentrations six x j values corresponding to the two dechlorinating species h2 and acetate utilizing methanogens and acetate and butyrate oxidizing syntrophs of the mixed microbial community were estimated at step 1 estimated initial x j values for each batch test were then kept constant and the maximum specific growth rates six μ max j values corresponding to the two dechlorinating species h2 and acetate utilizing methanogens and acetate and butyrate oxidizing syntrophs were specified at step 2 half velocity coefficients ten k s i j values corresponding to chloroethene consumption h2 and acetate dependent methane formation and acetate and butyrate oxidation were estimated at step 3 considering the previously estimated initial x j and μ max j fixed during each phase of the parameter estimation problem a sequence of 1000 quasi random starting points from the feasible area of the parameter space was created and local searches with the sqp routine see section 1 2 of the supplementary material were performed second for the second generation of culture ntua m i e ntua m2 only the initial x j and μ max j were treated as adjustable parameters in the inverse problem the values of k s i j for ntua m2 were assumed to be equal to those estimated for ntua m1 and were kept fixed thus only two steps were considered the initial x j concentrations and then μ max j values are estimated at steps 1 and 2 respectively a similar modeling approach has been previously used by berggren et al 2013 who confirmed the microbial shifts occurring in dechlorinating culture pm through their kinetic model in that case changes in the microbial composition were reflected in changes of the maximum specific growth rates and initial biomass concentrations a limitation of this approach is that changes in k s i j values resulting from community shifts will not be detected but given the correlated nature of μ max j and k s i j a change in k s i j will be reflected up to a point in a change of μ max j models were fitted simultaneously to experimental observations from the three batch experiments comprising chloroethenes tce cdce vc eth methane and vfas as listed in table 1 to ensure the accuracy of the solution of the forward problem i e ensure that the system of eqs 1 to 9 is solved accurately the balances of electron equivalents were estimated at each integration time step and the recovery of electron equivalents was estimated electron equivalent recovery it is defined as the percentage of electron equivalents recovered i e the sum of electron equivalents from remaining vfas the electron equivalents required for dechlorination and methane formation over the initially supplied electron equivalents ranged from 99 9 to 100 1 in all simulated tests by necessity this good numerical electron equivalent balance will create fitting problems since the recovery of electron equivalents for the experiments on the final day of each experiment was 108 for ls b1 87 for ms b1 74 for hs b1 127 for ls b2 93 for hs b2 and 128 for ms h2 apart from the objective function i e the nse values for every solution and for convenience purposes the quality of fit was assessed with the mean absolute error meanae and maximum absolute error maxae calculated for chloroethenes ethene methane and vfas finally the progress of dechlorination over time in these tests is assessed with an aggregate measure i e the dod expressed as percentage simulated chloroethene and ethene concentrations are compared with observations in section 5 of the supplementary material the best fit solution for ntua m1 and ntua m2 reproduced the observed data sets sufficiently the final nse values were greater than 0 79 for the six batch tests see the third step in fig 2a for ntua m1 and the second step in fig 2b for ntua m2 and thus greater than the considered threshold value for nse overall based on the solution of the two inverse problems the conceptual model captured the most salient cooperative and competing processes in both cultures as discussed in detail next for the low donor test ls b1 the model simulated accurately dechlorination in conjunction with methane formation fig 3a and b the meanae values for chloroethenes and methane equal 15 2 μμ and 17 1 μμ respectively the corresponding maxaes were 72 μμ for chloroethenes and 67 μμ for methane these are reasonable errors compared with the maximum concentrations of tce 505 μμ table 1 and methane 712 μμ fig 3b the best fit solution reproduced the patterns of acetate consumption and production but overpredicted slightly the peak of acetate concentrations at day 2 possibly due to the lower than 100 recovery of electron equivalents of the test during the first three days simulated meanae for vfas is 50 1 μμ and maxae is equal to 158 μμ which are acceptable considering that the anticipated uncertainty for vfas from the duplicate measurements was comparably high observed meanae and maxae were 70 0 μμ and 240 μμ respectively the best fit solution of the moderate surplus test ms b1 simulated adequately dechlorination and methane formation fig 3d and e but overpredicted acetate concentrations consistently fig 3f the misbalance between recovered and initially supplied electron equivalents electron equivalent recovery was 87 at the end of the experiment explains the discrepancy between modeled and observed acetate concentrations simulated meanaes were 14 1 μμ 61 0 μμ and 293 7 μμ for chloroethenes methane and vfas respectively the corresponding maxaes were 42 4 μμ 135 9 μμ and 387 2 μμ the best fit solution reproduced with adequate accuracy all the observed quantities for the high donor hs b1 apart from the terminal methane level fig 3h methane formation plateaued at a concentration almost 30 higher than the concentration observed in the batch test this discrepancy could be attributed at least partially to the misbalance between the recovered electron equivalents i e the sum of the consumed and accumulated electron equivalents at the end of the test and those initially offered specifically electron equivalent recovery was 74 for hs b1 the best fit solution for the ls b2 test described dechlorination and vfa consumption with fair accuracy fig 4a and c simulated meanaes were 10 4 μμ maxae was 16 6 μμ and 45 4 μμ maxae was 260 6 μμ when the maximum observed vfa concentration was 567 μμ which are comparable to the observed meanaes from the duplicate batch tests performed observed meanaes were 8 1 μμ and 18 μμ for chloroethenes and vfas respectively yet the best fit solution failed to reproduce the final levels of methane production fig 4b probably due to the excess recovery of 127 in the batch experiment i e the recovered electron equivalents accounted for 27 more electron equivalents than those initially offered the batch test appears to be deficient from day 7 in an electron equivalent basis indicating that a significantly better fit cannot be achieved for this data set the model produces balanced electron equivalent production and consumption and therefore it cannot simulate adequately all observed quantities the best fit solution for the hs b2 test predicted adequately a the completion of dechlorination by day 9 with an acceptable meanae of 35 4 μμ maxae was 59 68 μμ see also fig 4d b the accumulation of butyrate fig 4f and c the smooth increase of acetate during the first two days and its relatively low consumption rate thereafter fig 4f yet the simulated methane concentration at the end of the simulation was 1 7 fold greater than its observed counterpart this discrepancy should be attributed mostly to the overprediction of the rate of acetate dependent methane formation and to a lesser extent to the misbalance of the electron equivalents of the batch experiment in which the recovered electron equivalents were on average 9 less than the initially offered electron equivalents for the last three days of the experiment for the ms h2 test the best fit solution described the behavior of the culture sufficiently fig 4g to i simulations predicted the fast and complete removal of tce meanae for dechlorination was 12 0 μμ maxae was 59 7 μμ and the thermodynamic inhibition of butyrate consumption fig 4i resulting from the elevated h2 levels data available in section 6 of the supplementary material finally the best fit solution simulated adequately the observed methanogenic activity meanae was 23 1 μμ and maxae was 72 44 μμ which are both low compared to the maximum observed concentration of 583 μμ methane fig 4h the solution of the inverse problem significantly narrowed the initially considered range of parameter values i e the range of literature reported parameter values allowing for a reliable estimation of the qualitative and quantitative characteristics of the two generations of culture ntua m for example the half velocity coefficient for tce k s tce j varies from 0 05 μμ lee et al 2004 to 12 4 μμ cupples et al 2004 in the literature the solution of the inverse problem narrowed down this range to 10 4 μμ 11 9 μμ i e the range of the good fit solutions of the problem for complete dechlorinators see table s3 1 in the supplementary material parameter ranges were wider for parameters associated with methane formation and acetate consumption the existence of alternate pathways that could offer the same output for both processes complicated parameter estimation efforts which nonetheless resulted in acceptable levels of parameter variability the relative standard deviation of parameters remained reasonable and never exceeded 28 data not shown but all estimated parameter ranges are available in section 3 of the supplementary material parameter variability was comparable to the variability reported by heavner et al 2013 who calibrated a model with similar complexity and observed quantities but with fewer unknown parameters only kinetic parameters were estimated as initial biomass concentrations were measured conclusively the solution of the inverse problem offered an adequate fit to the experimental observations and identified two parameter sets one for each generation of ntua m with acceptable uncertainty thus allowing an interpretation of the differences between the generations as discussed next 6 2 gaining insight into the functional differences between ntua m1 and ntua m2 first this section investigates possible shifts in the community structure of culture ntua m and then re examines the tests performed under varying electron donor surpluses in search of evidence that would explain why the second generation of the culture i e ntua m2 outperformed the first generation i e ntua m1 under high electron donor surpluses i e hs b1 and hs b2 while both cultures functioned comparably under low electron donor surpluses i e ls b1 and ls b2 according to the best fit model solutions the two cultures differ notably in their h2 utilizing methanogenic hm populations as reflected in the different relative abundance fig 5a and kinetic properties of the h2 utilizing methanogens fig 5b a denser population of relatively fast growing h2 utilizing methanogens is present in ntua m1 while h2 utilizing methanogens in ntua m2 are fewer and grow more slowly regarding the remaining non dechlorinators i e acetate scavengers and butyrate oxidizers the two cultures were relatively stable compare the am bo and ao bars in fig 5a and b acetate oxidizing syntrophs were a minor and slow growing population while acetate utilizing methanogens were the most competent acetate scavenging species with respect to dechlorinators the density and growth rates of tce to eth dechlorinators are similar compare d c bars in fig 5a and b the densities of partial dechlorinators are also comparable compare d p bars in fig 5a but the competitive fitness of tce to cdce dechlorinators has changed remarkably compare d p bars in fig 5b the competitive fitness of tce to cdce dechlorinators over time deteriorated in ntua m simulated results indicate that tce consumption patterns in ntua m1 have changed relative to culture ntua m2 in all batch tests examined herein in ntua m1 tce to cdce dechlorinators consumed all the available tce within the first day data not shown as a result of their high μ max dp value and hence tce to eth dechlorinators had a disadvantage during the first day of the experiments this is in line with the high dechlorination rates reported by scholz muramatsu et al 1995 for partial dechlorinators sulfurospirillum spp in ntua m2 tce to eth dechlorinators consumed almost 20 of the available tce data not shown the fact that the active dechlorinating biomass of complete dechlorinators consuming cdce and vc in ntua m1 was sparser than in ntua m2 may have affected dechlorination rates however since the growth rates for complete dechlorinators in ntua m1 and ntua m2 are nearly identical d c bars in fig 5b the estimated one day starvation period for complete dechlorinators in ntua m1 does not justify the severe delays observed in complete chloroethene removal under high electron donor surpluses ntua m1 required nearly 40 days more than ntua m2 and a two fold greater surplus for complete dechlorination consequently the remainder of this section discusses how the differences in the make up of the non dechlorinating communities can explain the sizeable differences in the observed dechlorination rates by contrasting the distribution of reducing power in ntua m1 and ntua m2 under low surplus and high surplus the changes in the community structure of ntua m did not invoke any change in its function under a low electron donor surplus which resembles the maintenance conditions of the cultures the distributions of reducing power in the ntua m1 ls b1 and ntua m2 ls b2 are nearly identical fig 6a dechlorination was the second most efficient metabolism as acetate dependent methane formation consumed nearly 70 of the available electron equivalents in both cultures fig 6a thus acetate dependent methane formation was the prevailing pathway for methane formation h2 dependent methane formation contributed only 5 to the overall methane formation in ntua m1 and 2 in ntua m2 data not shown the prevailing h2 concentrations hindered h2 dependent methane formation in both cultures simulated h2 was maintained around 0 02 μm fig 7 i e only twice the h2 threshold for methane formation yang and mccarty 1998 it should be noted that simulated h2 levels are comparable to observed h2 levels for butyrate fed cultures aulenta et al 2008 consequently h2 was channeled mostly to dechlorinators fig 6b h2 was mostly produced by butyrate oxidation and to a lesser extent from acetate oxidation nearly 20 of the available acetate is oxidized for h2 production fig 6c which corresponds to almost 40 of the overall h2 production data not shown fig 8 provides the same behavior descriptors for high electron donor surplus where shifts in the non dechlorinating part of culture ntua m induced sizeable differences in the efficiency of h2 utilization the larger abundance of faster growing h2 utilizing methanogens in ntua m1 contrast fig 5a and b for hm explains its comparatively inefficient dechlorinating behavior in test hs b1 h2 utilizing methanogens consumed 92 of the available h2 rapidly fig 8b and maintained h2 concentrations in the range of 0 1 μμ for the first week of the experiment fig 9a during this period butyrate oxidation was thermodynamically feasible and thus butyrate was completely removed within the first week of the experiment following the first week the prevailing h2 concentrations were even lower in the range of 0 02 0 03 μμ fig 9a allowing acetate to function as a significant source of h2 acetate oxidizers then consumed 32 of the available acetate fig 8c but due to their lower affinity for acetate they were still outcompeted by acetate utilizing methanogens after the first week h2 never went higher than 0 03 μμ fig 9a and dechlorinators exploited these conditions they grew faster from day 7 to day 48 and eventually dechlorinated cdce and vc during this period h2 dependent methane formation became slower and acetate dependent methane formation became the main methanogenic pathway as the initially few acetate utilizing methanogens grew in numbers under the comparably high electron donor surplus in test hs b2 culture ntua m2 behaved differently than ntua m1 in ntua m2 the slow growing h2 utilizing methanogens did not pose a significant threat to dechlorinators despite the high h2 concentrations that prevailed fig 9b simulated h2 levels are in accordance with the findings reported by mao et al 2015 who observed h2 concentrations as high as 1 2 μμ during vc removal by a syntrophic coculture of dehalococcoides mccartyi 195 and syntrophomonas wolfei 57 of the available h2 was consumed by dechlorinators fig 8b on that account ntua m2 dechlorinated tce rapidly within nine days the high h2 concentrations inhibited vfas oxidation and consequently left much of the supplied reducing power unused as seen by the significant section of the bar that corresponds to remaining vfas in fig 8a 7 conclusions two generations of the mixed dehalococcoides mccartyi dominated community ntua m were studied using a kinetic model developed to account for dechlorination in conjunction with cooperative i e fermentation of h2 precursors and competing processes i e methane formation the kinetic model was inversed using experimental data from the two generations of ntua m the two generations functioned comparably under conditions of low electron donor surplus with respect to h2 yet under conditions of higher electron donor surplus they behaved divergently the multi experiment multi start algorithm that solved the ill posed inverse problem managed to i reproduce the performance of ntua m under varying electron donor surpluses and at different instances of the lifetime of the culture ii describe the kinetic properties and the composition of ntua m with acceptable uncertainty as well as iii suggest a probable cause for the contrasting behaviors exhibited by ntua m as explained below model derived results showed that in mixed chloroethene degrading communities functional similarities under low electron donor surpluses do not preclude community variability in culture ntua m a diverse and dynamic community of non dechlorinators co existed with dechlorinators over time in the two generations of ntua m the non dechlorinating community was rearranged in different ways while demonstrating the same behavior under starvation conditions with respect to h2 differences in the non dechlorinating fraction became important during biostimulation at higher electron donor surplus the model derived results also revealed that these differences dictated the distribution of the offered electron donor source microbial communities that differed mostly in the relative abundance and the competitive fitness of non dechlorinators which were minority populations required drastically different approaches to optimize the complete detoxification of chloroethenes an ample h2 supply would be optimal for ntua m2 but in ntua m1 it would disadvantage the dechlorinators the inquiry presented herein offers a framework through which to interpret the conflicting observations of dechlorination under methanogenic conditions reported in the literature in this framework the collective activities of chloroethene degrading communities are characterized not exclusively by the activity of dechlorinators but also by the relative abundance and the competitive fitness of competitors that hinder and syntrophs that mediate h2 supply certain perceptions of good practices for efficient dechlorination have stemmed from generalizations that should be dealt with caution as the universe of methane producing chloroethene degrading communities is heterogeneous not only due to the variable composition of dechlorinators but also due to the differences in the make up of the non dechlorinating community a selective approach to the adaptation of good practices is even more pertinent to field scale applications where the efforts to decipher the make up of the existing microbial communities can guide remedial decision making if the findings of this study were to be extrapolated to the field an example would be a site where remediation completion time is of interest there an ntua m2 like dominance of acetate utilizing methanogens might support the decision to use a higher electron donor surplus or direct supply of h2 anticipating that excessively high methane levels are unlikely in such context knowledge of the makeup of the community of non dechlorinators would have decision value for the electron donor type and surplus chosen for biostimulation authorship statement all persons who meet authorship criteria are listed as authors and all authors certify that they have participated sufficiently in the work to take public responsibility for the content including participation in the concept design analysis writing or revision of the manuscript declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the present work was supported by the iky fellowships of excellence for postgraduate studies in greece siemens program the authors thank dr iraklis panagiotakis and dr cornelia antoniou for providing the measured values of the published experimental results and the maintenance data of the source culture and the two thoughtful and meticulous anonymous reviewers appendix a supplementary data supplementary material image 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jconhyd 2021 103834 
1426,laboratory batch experiments were performed to assess the reduction of trichloroethene tce and oxygen via natural ferrous minerals tce reduction under anoxic conditions was measured via the generation of reduced gases while oxygen reduction via the generation of hydroxyl radicals was measured as a surrogate for potential tce oxidation results showed that tce reduction under anoxic conditions was observed for ankerite siderite and illite but not for biotite acetylene was the primary identified dechlorination product with the exception of biotite first order dechlorination rate constants increased with increasing ferrous content of the mineral with rate constants ranging from 3 1 10 8 to 4 8 10 7 l g 1 d 1 measured reduction potentials mv vs she ranged from 104 for illite to 84 for biotite when normalizing measured first order dechlorination rate constants to the estimated ferrous iron mineral specific surface area where surface area was based on nitrogen adsorption analysis of the minerals tce dechlorination rate constants increased with increasing reduction potentials under oxic conditions hydroxyl radicals were generated with each of the four minerals however mineral activity showed no readily apparent correlation to ferrous content or mineral surface area in terms of tce and oxygen reduced per mole of ferrous iron initially present in each mineral illite was the most reactive of the four minerals together these results suggest that several ferrous minerals may contribute to abiotic dechlorination in the natural environment and at least for tce reduction under anoxic conditions measurement of ferrous mineral content and reduction potential may serve as useful tools for estimating tce first order abiotic dechlorination rate constants graphical abstract unlabelled image keywords tce abiotic ferrous minerals dechlorination 1 introduction the diffusive uptake or release of chlorinated solvents such at trichloroethene tce and tetrachloroethene pce from low permeability rock or clay matrices can have a substantial impact on contaminant migration and longevity within impacted aquifers as previous studies have shown that these matrices can serve as a long term source of these compounds damgaard et al 2013 goode et al 2014 slow abiotic dechlorination reactions in such matrices can impact diffusive uptake and release west and kueper 2010 schaefer et al 2013 schaefer 2016 schaefer et al 2017 yu et al 2018 and therefore limit contaminant longevity the mechanisms controlling abiotic dechlorination reactions and methods to predict reactivity remain on going issues of debate and further insights are needed to apply this information to effectively manage impacted sites there is substantial evidence that ferrous minerals play a prominent role in promoting abiotic reductive dechlorination of pce and tce butler and hayes 1999 liang et al 2009 he et al 2010 he et al 2015 schaefer et al 2017 the majority of these studies were performed under anoxic conditions with single minerals and suggest that ferrous minerals such as pyrite iron sulfides magnetite and green rusts can dechlorinate pce and tce to yield short chained hydrocarbons e g acetylene ethene ethane propane as final products lee and batchelor 2003 schaefer et al 2013 he et al 2015 however there is also evidence that in studies performed with these and other iron minerals small amounts of unidentified reactive mineral intermediates rmis are promoting chlorinated ethene reduction culpepper et al 2018 entwistle et al 2019 the iron minerals controlling reactivity are more difficult to determine in natural systems several researchers have shown that iron containing rock and clay matrices promote pce and tce dechlorination under anoxic and abiotic conditions schaefer et al 2017 yu et al 2018 schaefer et al 2018 and that this reactivity can persist in situ after decades of exposure to the contaminants ferrey et al 2004 schaefer et al 2015 schaefer et al 2018b furthermore the abiotic dechlorination rate constants observed in these natural matrices have been shown to be environmentally relevant schaefer et al 2013 2018 2018b berns et al 2019 in one study the observed first order dechlorination rate constants for natural clayey soils was directly correlated to the ferrous mineral content of the solids determined via hcl extraction schaefer et al 2018 however xrd results indicated that these matrices contained several ferrous iron minerals and no relationship to their relative proportions was apparent therefore it remains unclear what specific ferrous minerals might be responsible for the observed abiotic dechlorination in natural systems or if the mechanisms responsible for dechlorination reactions in unaltered natural minerals differ from those in artificially reduced minerals in addition to reducing chlorinated ethenes ferrous iron minerals have also been shown to reduce oxygen to form hydroxyl radicals and hydrogen peroxide under oxic conditions pham et al 2008 kong et al 2015 tong et al 2016 morrison et al 2016 in natural clays containing ferrous minerals this hydroxyl radical generation process was observed with subsequent oxidative dechlorination of tce at rates much greater than the reductive tce dechlorination observed under anoxic conditions liu et al 2017 schaefer et al 2018 the extent of hydroxyl radical yield per mass of ferrous iron depends on the type of ferrous mineral suggesting a complex mechanism related to the mineral structure likely is involved tong et al 2016 zhu et al 2019 while the extent to which these abiotic oxic dechlorination processes are relevant to the diffusion of chlorinated ethenes into clay or rock matrices is unclear field studies suggest that systems undergoing natural biogeochemical cycling might be conducive to hydroxyl radical generation page et al 2013 tong et al 2016 yuan et al 2017 besides extracted ferrous iron discussed above the soil reduction potential determined electrochemically or with chemical reactivity probes is also being explored as a surrogate for reductive dechlorination rate constants in natural soils and minerals under anoxic conditions fan et al 2016 kocur et al 2020 however to our knowledge this work has yet to be extended to pce or tce which are reduced via ferrous minerals much more slowly than the carbon tetrachloride 4 chloronitrobenzene and 2 chloroacetophenone used by kocur et al 2020 and fan et al 2016 in addition it is currently unclear the extent to which reduction potential measurements provide insight into hydroxyl radical formation observed for ferrous minerals under oxic conditions the ability to relate reduction potential via chemical reactivity probes to hydroxyl radical generation could serve as a surrogate relating to abiotic tce oxidation as the extent of hydroxyl radical generation has been shown to correspond to the subsequent oxidative dechlorination of tce in batch systems pham et al 2008 schaefer et al 2018 while previous studies have focused on tce dechlorination via ferrous minerals comparison of reductive tce dechlorination kinetics among various minerals coupled with the ability to predict such dechlorination using ferrous iron content and reduction potentials has not to our knowledge been performed the purpose of this study was to interrogate the potential for abiotic dechlorination using individual minerals identified in natural clay sediments illite biotite ankerite and siderite that were suspected to be responsible for reducing tce schaefer et al 2018 and to compare the various minerals with respect to tce dechlorination kinetics both tce reduction under anoxic conditions and hydroxyl radical generation under oxic conditions were examined specifically mineral reduction of both tce and oxygen as evidenced by hydroxyl radical generation were compared thereby providing insight into the reduction mechanisms and potential behavior in systems where iron redox cycling may occur in addition assessment of ferrous iron content and reduction potential as tools to estimate tce reduction under anoxic conditions and hydroxyl radical generation under oxic conditions were examined thereby providing a novel assessment of these techniques 2 experimental 2 1 materials tce 99 5 purity and reduced gas standards 15 ppm methane ethane ethene acetylene propane propylene methyl acetylene butane in a nitrogen balance were purchased from sigma aldrich st louis mo an electrolyte solution consisting of 5 mm cacl2 was used in all experiments four natural minerals samples were used for this study siderite purchased from sidco minerals inc texarakana tx illite purchased from greenclays com las vegas nv biotite acquired black crystal from unknown location in ontario ca additional samples available at https www ebay com itm 13 rare shining biotite crystal black mica ontario canada mica110 303174730742 and ankerite mineral crystal acquired from unknown location in eisenerz steiermark austria were used for the abiotic reactivity experiments properties of the minerals are provided in table 1 2 2 batch dechlorination testing using previously developed methods schaefer et al 2017 schaefer et al 2018 batch experiments were performed under anoxic conditions to evaluate the abiotic reductive dechlorination of tce all anoxic experiments were prepared in an anaerobic chamber for each batch system 6 g of a specific mineral was placed in 40 ml amber glass vials bottles were then amended with 35 mls of 5 mm cacl2 that had been sparged with nitrogen an additional set of bottles were prepared similarly but amended with tce for a concentration of approximately 3 2 mm use of elevated tce concentrations facilitated the detection of transformation products for siderite and illite additional experiments were performed at a tce concentration of approximately 0 15 mm comparison of samples amended with tce to those without tce served to verify that generation of suspected dechlorination products were from tce rather than generation from anything associated with the acquired minerals the vials were capped with mininert valves with epoxy seals on the threads to allow for repeated sampling of the vial headspace for hydrocarbon transformation products all anoxic experimental conditions were prepared in triplicate i e vials were prepared in triplicate for each condition controls containing 5 mm cacl2 solution with tce but no minerals also were prepared in triplicate all sampling of the anoxic vials was performed outside of the anaerobic chamber under a stream of nitrogen to limit potential introduction of oxygen into the vials monitoring was typically performed up to approximately 40 days at the end of the experiment select vials were sampled to determine the ph in the supernatant water an additional set of experiments was performed using illite and siderite amended with 1 8 mm of ferrous iron from fecl2 h2o these experiments were performed in duplicate oxic experiments were also prepared similarly to those previously described schaefer et al 2018 and as described above for the anoxic experiments for oxic experiments the focus was to measure the generation of hydroxyl radicals which have shown to subsequently and oxidatively dechlorinate tce pham et al 2008 liu et al 2017 schaefer et al 2018 thus the extent of hydroxyl radical generation among the four ferrous minerals served as a surrogate for evaluating their relative potential effectiveness to facilitate oxidative transformation of tce hydroxyl radical generation was measured using the aminophenyl fluorescein apf method cohn et al 2008 cohn et al 2009 which is based upon hydroxyl radical transformation of the apf into fluorescein for each mineral 1 7 g were placed in the 40 ml amber glass vials with 10 ml of 0 1 m phosphate buffer ph 7 4 vials also were amended with apf to attain a 25 μm concentration with the bottle headspace flushed with air at time zero and daily thereafter periodic aqueous samples were collected during the 6 day duration of the experiments bottles were placed on a shaker 50 rpm during incubation periodic sampling was performed by removing a 400 μl aliquot that was transferred into a 15 ml conical centrifuge tube and centrifuged at 10 000g for 5 min the supernatant was subsequently analyzed using a promega quantus fluorometer where a blue fluorescent channel with an excitation filter at 495 nm and emission filter at 510 580 nm was used to quantify fluorescein all samples including a control containing no minerals were prepared in duplicate 2 3 analytical methods calculation of dechlorination rate constants and soil characterization tce cis 1 2 dichloroethene dce vinyl chloride vc and reduced gas methane ethane ethene propane acetylene butane methyl acetylene and propylene concentrations were determined via headspace analysis using a shimadzu 2010 gas chromatograph equipped with a flame ionization detector fid and an rt qs bond fused silica plot column aqueous concentrations were determined by applying henry s law tce reductive dechlorination in the anoxic systems are described by the following first order expression schaefer et al 2017 schaefer et al 2018 1 c t k an ε v h ε w ε w c 2 k an k an ρk ε w where c is the tce aqueous concentration mm t is time days kan is the bulk first order rate constant d 1 k an is the intrinsic pseudo first order rate constant d 1 ρ is the bulk density 0 2 kg l 1 k is the linear tce adsorption coefficient to both reactive and unreactive sites l kg 1 εv and εw are the dimensionless gas and water porosities in the vial 0 20 and 0 74 respectively and h is the tce dimensionless henry s law constant sander 1999 since the adsorption of tce to the reactive ferrous minerals cannot be determined the reaction rate constant is assessed in terms of kan rather than k an for eq 1 generation of acetylene ethene is used to determine the change in tce concentration this approach has been employed previously schaefer et al 2017 a small approximately 10 tce leakage loss was observed in the controls at the final 40 day sampling point due to volatilization losses from the vials reduced gas transformation products were corrected for this loss using a henry s law based partitioning factor to account for losses of transformation products as follows schaefer et al 2017 3 α i ε v ε w h tce ε v ε w h i where αi is the scaling factor by which tce dechlorination product i is multiplied to correct for leakage losses hi is the dimensionless henry s law constant for tce and dechlorination product i sander 1999 ferrous mineral content was determined using a 2 5 hcl extraction and the 1 10 phenanthroline method standard method 3500 fe b 4 c rice et al 2012 this methodology has been used in previous studies that showed a correlation between ferrous mineral content and reductive tce dechlorination rate constants schaefer et al 2017 schaefer et al 2018 an additional more aggressive ferrous iron extraction was also performed using 12 5 hcl and with heated 95c water bath both of these ferrous mineral extractions were performed by mccampbell analytical inc pittsburg ca reduction potentials were measured after equilibrating minerals in anoxic bicarbonate buffer by shaking in an anaerobic chamber overnight three mediator compounds indigo tetrasulfonate indigo disulfonate and athraquinone disulfonate were used to determine the potentials in the mineral slurries this approach has been shown to be appropriate for predicting abiotic dechlorination using soil and mineral samples fan et al 2016 kocur et al 2020 potentials were measured anaerobically with a ag agcl 3 m kcl mettler toledo redox micro orp electrode and converted to she this approach has been shown using field collected soil samples the electrode was rinsed in 0 1 n hcl for 30 min between each sample all reduction potential measurements were performed in at least duplicate 3 results and discussion 3 1 anoxic experiments the molar fraction of tce transformed to reduced gas products for each mineral over the 40 day experiment is shown in fig 1 acetylene was the primary transformation product observed accounting for 90 of the observed tce transformation the remaining tce removal was accounted for as ethene generation no chlorinated ethene or reduced gas transformation products were observed in the controls no minerals present and tce concentrations in the controls were statistically identical to those in the mineral amended bottles indicating that tce sorption to the minerals was below that which could be measured in this study 1 8 mmol kg 1 trace levels of reduced gas transformation products were observed in the experiments with minerals without tce present but these trace levels of reduced gases were less than 1 of those observed in the tce amended samples with the exception of biotite where no measurable generation of transformation products relative to the non tce amended samples was observed acetylene is not a known biotic tce transformation product and therefore the generation of acetylene as the primary dechlorination product provides strong evidence that the tce dechlorination occurred via an abiotic reductive mechanism tce abiotic reductive dechlorination typically occurs via a reductive beta elimination pathway with the formation of acetylene and with possible further reduction to ethene roberts et al 1996 arnold and roberts 2000 schaefer et al 2018 ethene has been shown to be an abiotic tce dechlorination product in ferrous mineral studies lee and batchelor 2003 entwistle et al 2019 but can also be attributed to the biotic transformation of tce cápiro et al 2015 schaefer et al 2009 no other biotic tce dechlorination products i e dce vc were detected suggesting that the ethene generation likely was due to abiotic mechanisms previous abiotic tce dechlorination experiments using natural clayey soils that based on soil mineral analysis contained minerals similar to those studied herein also primarily yielded acetylene and or ethene as abiotic reductive transformation products under anoxic conditions schaefer et al 2018 results presented in fig 1 show that siderite illite and ankerite each facilitates the abiotic reductive dechlorination of tce suggesting that the presence of these minerals in previously examined natural clayey soils likely played a role in tce dechlorination table 2 shows regressed first order tce reductive dechlorination rate constants on both a mass and estimated mineral surface area basis regression results indicate that dechlorination was reasonably described r2 values typically greater than 0 9 by a first order expression consistent with previous abiotic dechlorination studies in the presence of ferrous minerals butler and hayes 1999 schaefer et al 2013 however it is noted that because the fraction of tce consumed was low which resulted in essentially a constant concentration of tce during the experiment the data provided in fig 1 are unable to discern between a zero and first order rate model with respect to tce concentration in addition the initial t 1 day timepoint for siderite was not used in the first order regressions as a relatively rapid rate of dechlorination occurred between t 1 and t 7 days this transient rate of high dechlorination activity may have been due to consumption and depletion of a highly reactive iron species first order tce reductive rate constants obtained herein along with those obtained in a previous study using similar methodologies with natural clayey soils schaefer et al 2018 are plotted as a function of the ferrous iron content fig 2 with the exception of the visibly outlying biotite mineral the tce dechlorination rate constant generally increases with increasing ferrous content which is consistent with previous studies schaefer et al 2013 schaefer et al 2018 together these results suggest that ferrous minerals facilitate the observed reductive dechlorination reactions under anoxic conditions it is noted that the first order rate constants measured herein with the exception of that measured for biotite are sufficiently large such that they would likely be of environmental relevance for mitigating tce persistence in clay or rock matrices schaefer et al 2018 2018b berns et al 2019 the relationship between the dechlorination rate constant and ferrous mineral content in fig 2 is surprising as the solids used varied in the degree of heterogeneity predominantly single minerals versus natural solids containing multiple mineral species surface area and particle size multiple factors may contribute to this relationship one contributing factor likely is that the reaction rate constants are very slow this can be assessed by comparing the reaction to diffusion velocities in terms of the dimensionless da number cussler 1994 4 da k an l 2 d where l is the diffusion length and d is the effective aqueous diffusion coefficient that accounts for the tortuosity within the clay for reactions that are very slow relative to the diffusional mass transfer da 1 assuming an effective diffusion coefficient of 2 10 5 cm2 d 1 werth et al 1997 and a diffusion length of 0 001 cm based on the mineral particle sizes a reasonable estimate of the diffusion velocity d l 2 is 20 d 1 this value is more than 6 orders of magnitude greater than the first order rate constants shown in table 2 ensuring that da 1 this explains why the variation in particles sizes and surface areas among the solids do not appear to impact results another potential contributing factor is that the acid extraction used to determine the ferrous content for the minerals and soils may be sensitive to the factors that control the reactivity of the ferrous minerals with respect to tce reductive dechlorination thereby facilitating the observed trend observed in fig 2 the 2 5 hcl acid extraction table 1 likely did not extract all of the ferrous iron present in the solids but rather the most extractable iron which is likely a function of accessibility surface area and coordination within the mineral structure the relatively low measured ferrous content for siderite 36 g kg 1 is consistent with this interpretation because the ferrous content based only on stoichiometric mineral composition should be more than 10 times greater the latter was confirmed by the heated acid extraction data for siderite which matches closely with the theoretical ferrous content of 482 g kg 1 based on stoichiometry feco3 table 1 the results presented herein and previously schaefer et al 2013 schaefer et al 2017 schaefer et al 2018 suggest that abiotic reductive dechlorination under anoxic conditions is positively correlated to the ferrous mineral content these results are in apparent contrast to recent mechanistic studies culpepper et al 2018 entwistle et al 2019 that show ferrous minerals alone do not dechlorinate tce nor does the ferrous mineral content correlate to observed dechlorination rates rather culpepper et al and entwistle et al suggest rmis are responsible for the observed dechlorination one possible explanation for this apparent discrepancy is that the reductive dechlorination reactivity observed herein is in fact due to these rmis that have accumulated near the mineral surfaces and the measured ferrous mineral contents table 1 reflect in part the quantity of these reactive particles a second consideration is that the dechlorination rate constants for unaltered natural minerals and soils such as those employed herein occurs via a different and much slower mechanism than that observed for rmis entwistle et al 2019 if the mineral 6 g l 1 and tce 0 07 mm dosage used in the batch experiments performed by entwistle et al 2019 were used for the minerals examined herein no dechlorination would have been observed for any of the minerals tested based on the first order kinetic rate constants presented in table 2 thus the comparatively slow ferrous mineral correlated reactions observed herein and for natural rock and clayey materials schaefer et al 2013 schaefer et al 2018 may be attributable to a mechanism that does not involve rmis or may involve rmis that are far less reactive than those previously observed culpepper et al 2018 entwistle et al 2019 the anoxic dechlorination experiments performed at 0 15 mm tce concentrations yielded first order rate constants that were approximately 4 times greater than those determined for experiments performed at 3 2 mm tce a similar dependence on tce concentration in clayey soils has been reported berns et al 2019 thus while the elevated tce concentrations used herein and in previous studies e g schaefer et al 2018 facilitated the identification and quantification of trace levels of transformation products these elevated tce concentrations likely resulted in an underestimation of the abiotic dechlorination rate constants compared to those rate constants that would have been measured at more dilute tce concentrations and that might be more reflective of tce concentrations at many tce impacted field sites in addition the dependence of the rate constant on concentration suggests as previously proposed berns et al 2019 that dechlorination kinetics at elevated tce concentrations are likely limited by langmuir type sorption to reactive mineral sorption sites the addition of 1 8 mm dissolved ferrous iron did not impact transformation product formation i e acetylene generation was statistically identical with and without the added ferrous iron fig s1 in the supplemental information suggesting that addition of this iron did not result in rmis that impacted tce dechlorination however as discussed in detail by entwistle et al 2019 both the ferrous dosage and geochemical conditions in the batch systems used herein may not have been appropriate for facilitating rmi formation the ferrous iron surface area normalized first order rate constants table 2 as a function of the measured reduction potential are shown in fig 3 the relationship between reduction potential and the dechlorination rate constant has been estimated as follows stewart et al 2018 kocur et al 2020 5 log k sa ae c where ksa is the surface area normalized rate constant table 2 a and c are constants and e is the reduction potential kocur et al 2020 also indicate that a mass normalized rate constant can be used instead of the surface area normalized rate constant for more complex sediment matrices in which it is difficult to get a surface area for the reactive minerals in eq 5 the surface area normalized data in fig 3 are qualitatively consistent with eq 5 suggesting the importance of ferrous mineral surfaces for the observed reductive dechlorination reactions when evaluating the data with respect to measured reduction potential the ferrous iron mass normalized rate constants do not exhibit a functionality that is consistent with eq 5 although the limited number of data points prevents a thorough evaluation of eq 5 with respect to reduction of tce by ferrous minerals no measurable reductive dechlorination for biotite was observed which showed a measured reduction potential of 84 mv vs she the reduction potential was negative for all other minerals thus the reducing potential of the biotite likely was insufficient to facilitate tce reduction under the conditions tested this result highlights a potential useful application of this electrochemical method in identifying ferrous minerals that despite having apparently sufficient ferrous mineral content as shown in fig 2 lack the potential to reductively dechlorinate tce under anoxic conditions the results shown in figs 2 and 3 suggest the importance of considering both the ferrous mineral content and the reduction potential for abiotic tce reduction under anoxic conditions while a trend of increasing rate constant with ferrous content is observed in fig 2 the outlying biotite sample is only explained in the context of its reduction potential thus it is possible that certain ferrous minerals simply do not have sufficient reduction capacity to dechlorinate tce it currently is unclear how other geochemical conditions or the presence of mineral mixtures may impact dechlorination 3 2 oxic experiments results showing the generation of hydroxyl radicals are provided in fig 4 we note that this measure of hydroxyl radical generation is based upon hydroxyl radical reaction with apf and thus represents only the radicals that are available to react with this compound the molar hydroxyl radical generation of each mineral was orders of magnitude less than the oxygen present in each vial so oxygen levels were not limiting and remained essentially constant in the oxic experiments because studies using the apf based approach for hydroxyl radical quantification typically have been performed within approximately 30 h e g cohn et al 2008 cohn et al 2009 results shown in fig 4 are best interpreted by comparing hydroxyl radical generation among the various minerals tested rather than a definitive quantitative value comparison of figs 2 and 4 shows that the order of reactivity for the minerals with respect to hydroxyl radical generation differs from that observed for tce reduction under anoxic conditions most notably illite generates more than twice the hydroxyl radicals than any other mineral whereas illite s reactivity under anoxic conditions with respect to tce dechlorination was greater only than biotite which yielded no measurable tce dechlorination interestingly biotite exhibited the least amount of reactivity for both the oxic and anoxic conditions the differences among the mineral reactivities with respect to hydroxyl radical generation are not readily explained by any apparent differences in the mineral properties presented in table 1 while the high reactivity of the illite appears to correspond to its high specific surface area the specific surface areas for the other 3 minerals differ by over an order of magnitude yet differ by only 34 in their hydroxyl radical yield over the 6 day experiment assuming 3 mol of ferrous iron are required to transform tce to acetylene and 3 mol of ferrous iron are needed to generate 1 mol of hydroxyl radical kong et al 2015 schaefer et al 2018 the fractional ferrous consumption is calculated for each mineral under both oxic and anoxic conditions fig 5 results show that only a relatively small fraction of the ferrous iron was oxidized during both the oxic and anoxic experiments furthermore while the magnitude of the fractional ferrous mineral consumption between the oxic and anoxic experiments was biased to the duration of the experiment 40 days for the anoxic experiments vs 6 days for the oxic experiments fractional oxidation of the minerals occurred in the order of illite biotite siderite ankerite fig 5 which is the reverse order of their ferrous content table 1 the exception is biotite under anoxic conditions which as previously discussed likely did not have sufficient reduction potential to reduce tce fig 5 also provides a measure of the molar tce or oxygen reduced per mole of ferrous iron present in each mineral comparison shows that illite is the most reactive mineral on a mole of tce or oxygen reacted per mole of ferrous iron present of the four minerals tested with the exception of tce reduction via biotite ankerite shows the least reduction of tce oxygen per mole of ferrous iron present while these relationships are apparent from fig 5 it is unclear whether these relationships reflect an intrinsic chemical reactivity of the specific ferrous minerals the available surface area of the ferrous minerals within the bulk mineral structure the formation of reactive mineral intermediates culpepper et al 2018 entwistle et al 2019 within the mineral microstructure and or other structural or chemical factors the fact that the fractional ferrous oxidation in fig 5 correlates inversely with mineral ferrous content and also the ratio of the specific surface area to ferrous content suggests that for these ferrous rich minerals the reduction becomes more efficient at lower ferrous contents potentially due to improved accessibility for tce and oxygen at reactive mineral surfaces i e less crowding of the ferrous iron recent investigations by yuan et al 2018 show that both surface and structural ferrous iron contribute to hydroxyl radical formation the similarity in behavior between the oxic and anoxic experiments in fig 5 suggests that both surface and structural ferrous iron contribute to both the reduction of tce and oxygen for the minerals examined herein additional studies are needed to confirm such mechanisms 3 3 environmental implications under anoxic conditions several ferrous mineral types can facilitate tce reduction either directly or potentially by the facilitating formation of rmis thus mineral screening for ferrous content may serve as a useful tool for estimating tce abiotic dechlorination rate constants in field samples however the mineral reduction potential needs to be sufficiently high to induce dechlorination thus a coupled approach involving measurement of both reduction potential and ferrous mineral content offers a likely improved benefit for potentially estimating abiotic reductive dechlorination rate constants in field samples with respect to oxic conditions while ferrous minerals appear to play an important role in hydroxyl radical generation the relationship between ferrous content and mineral properties are currently unclear further study is needed to understand this relationship 4 conclusion overall the results observed herein and in previous studies schaefer et al 2013 schaefer et al 2018 suggest that several ferrous minerals can play a role in the dechlorination of tce particularly under anoxic conditions that are typically present within rock or clay matrices continued studies with respect to the impacts of geochemical conditions contaminant mixtures and potential roles of reactive intermediates on these reactions are needed to further refine understanding of these naturally occurring dechlorination processes author statement schaefer project lead and primary writer ho led experimental effort and helped develop methods berns led reduction potential experiments and wrote experimental methods related to that work werth technical review of paper and on going technical input on project declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments support for this research was provided by the strategic environmental research and development program serdp under project er 2530 views opinions and or findings contained in this report are those of the authors and should not be construed as an official department of defense position or decision unless so designated by other official documentation the authors appreciate assistance from veronika culina in performing the experiments appendix a supplementary data supplementary material image 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jconhyd 2021 103839 
1426,laboratory batch experiments were performed to assess the reduction of trichloroethene tce and oxygen via natural ferrous minerals tce reduction under anoxic conditions was measured via the generation of reduced gases while oxygen reduction via the generation of hydroxyl radicals was measured as a surrogate for potential tce oxidation results showed that tce reduction under anoxic conditions was observed for ankerite siderite and illite but not for biotite acetylene was the primary identified dechlorination product with the exception of biotite first order dechlorination rate constants increased with increasing ferrous content of the mineral with rate constants ranging from 3 1 10 8 to 4 8 10 7 l g 1 d 1 measured reduction potentials mv vs she ranged from 104 for illite to 84 for biotite when normalizing measured first order dechlorination rate constants to the estimated ferrous iron mineral specific surface area where surface area was based on nitrogen adsorption analysis of the minerals tce dechlorination rate constants increased with increasing reduction potentials under oxic conditions hydroxyl radicals were generated with each of the four minerals however mineral activity showed no readily apparent correlation to ferrous content or mineral surface area in terms of tce and oxygen reduced per mole of ferrous iron initially present in each mineral illite was the most reactive of the four minerals together these results suggest that several ferrous minerals may contribute to abiotic dechlorination in the natural environment and at least for tce reduction under anoxic conditions measurement of ferrous mineral content and reduction potential may serve as useful tools for estimating tce first order abiotic dechlorination rate constants graphical abstract unlabelled image keywords tce abiotic ferrous minerals dechlorination 1 introduction the diffusive uptake or release of chlorinated solvents such at trichloroethene tce and tetrachloroethene pce from low permeability rock or clay matrices can have a substantial impact on contaminant migration and longevity within impacted aquifers as previous studies have shown that these matrices can serve as a long term source of these compounds damgaard et al 2013 goode et al 2014 slow abiotic dechlorination reactions in such matrices can impact diffusive uptake and release west and kueper 2010 schaefer et al 2013 schaefer 2016 schaefer et al 2017 yu et al 2018 and therefore limit contaminant longevity the mechanisms controlling abiotic dechlorination reactions and methods to predict reactivity remain on going issues of debate and further insights are needed to apply this information to effectively manage impacted sites there is substantial evidence that ferrous minerals play a prominent role in promoting abiotic reductive dechlorination of pce and tce butler and hayes 1999 liang et al 2009 he et al 2010 he et al 2015 schaefer et al 2017 the majority of these studies were performed under anoxic conditions with single minerals and suggest that ferrous minerals such as pyrite iron sulfides magnetite and green rusts can dechlorinate pce and tce to yield short chained hydrocarbons e g acetylene ethene ethane propane as final products lee and batchelor 2003 schaefer et al 2013 he et al 2015 however there is also evidence that in studies performed with these and other iron minerals small amounts of unidentified reactive mineral intermediates rmis are promoting chlorinated ethene reduction culpepper et al 2018 entwistle et al 2019 the iron minerals controlling reactivity are more difficult to determine in natural systems several researchers have shown that iron containing rock and clay matrices promote pce and tce dechlorination under anoxic and abiotic conditions schaefer et al 2017 yu et al 2018 schaefer et al 2018 and that this reactivity can persist in situ after decades of exposure to the contaminants ferrey et al 2004 schaefer et al 2015 schaefer et al 2018b furthermore the abiotic dechlorination rate constants observed in these natural matrices have been shown to be environmentally relevant schaefer et al 2013 2018 2018b berns et al 2019 in one study the observed first order dechlorination rate constants for natural clayey soils was directly correlated to the ferrous mineral content of the solids determined via hcl extraction schaefer et al 2018 however xrd results indicated that these matrices contained several ferrous iron minerals and no relationship to their relative proportions was apparent therefore it remains unclear what specific ferrous minerals might be responsible for the observed abiotic dechlorination in natural systems or if the mechanisms responsible for dechlorination reactions in unaltered natural minerals differ from those in artificially reduced minerals in addition to reducing chlorinated ethenes ferrous iron minerals have also been shown to reduce oxygen to form hydroxyl radicals and hydrogen peroxide under oxic conditions pham et al 2008 kong et al 2015 tong et al 2016 morrison et al 2016 in natural clays containing ferrous minerals this hydroxyl radical generation process was observed with subsequent oxidative dechlorination of tce at rates much greater than the reductive tce dechlorination observed under anoxic conditions liu et al 2017 schaefer et al 2018 the extent of hydroxyl radical yield per mass of ferrous iron depends on the type of ferrous mineral suggesting a complex mechanism related to the mineral structure likely is involved tong et al 2016 zhu et al 2019 while the extent to which these abiotic oxic dechlorination processes are relevant to the diffusion of chlorinated ethenes into clay or rock matrices is unclear field studies suggest that systems undergoing natural biogeochemical cycling might be conducive to hydroxyl radical generation page et al 2013 tong et al 2016 yuan et al 2017 besides extracted ferrous iron discussed above the soil reduction potential determined electrochemically or with chemical reactivity probes is also being explored as a surrogate for reductive dechlorination rate constants in natural soils and minerals under anoxic conditions fan et al 2016 kocur et al 2020 however to our knowledge this work has yet to be extended to pce or tce which are reduced via ferrous minerals much more slowly than the carbon tetrachloride 4 chloronitrobenzene and 2 chloroacetophenone used by kocur et al 2020 and fan et al 2016 in addition it is currently unclear the extent to which reduction potential measurements provide insight into hydroxyl radical formation observed for ferrous minerals under oxic conditions the ability to relate reduction potential via chemical reactivity probes to hydroxyl radical generation could serve as a surrogate relating to abiotic tce oxidation as the extent of hydroxyl radical generation has been shown to correspond to the subsequent oxidative dechlorination of tce in batch systems pham et al 2008 schaefer et al 2018 while previous studies have focused on tce dechlorination via ferrous minerals comparison of reductive tce dechlorination kinetics among various minerals coupled with the ability to predict such dechlorination using ferrous iron content and reduction potentials has not to our knowledge been performed the purpose of this study was to interrogate the potential for abiotic dechlorination using individual minerals identified in natural clay sediments illite biotite ankerite and siderite that were suspected to be responsible for reducing tce schaefer et al 2018 and to compare the various minerals with respect to tce dechlorination kinetics both tce reduction under anoxic conditions and hydroxyl radical generation under oxic conditions were examined specifically mineral reduction of both tce and oxygen as evidenced by hydroxyl radical generation were compared thereby providing insight into the reduction mechanisms and potential behavior in systems where iron redox cycling may occur in addition assessment of ferrous iron content and reduction potential as tools to estimate tce reduction under anoxic conditions and hydroxyl radical generation under oxic conditions were examined thereby providing a novel assessment of these techniques 2 experimental 2 1 materials tce 99 5 purity and reduced gas standards 15 ppm methane ethane ethene acetylene propane propylene methyl acetylene butane in a nitrogen balance were purchased from sigma aldrich st louis mo an electrolyte solution consisting of 5 mm cacl2 was used in all experiments four natural minerals samples were used for this study siderite purchased from sidco minerals inc texarakana tx illite purchased from greenclays com las vegas nv biotite acquired black crystal from unknown location in ontario ca additional samples available at https www ebay com itm 13 rare shining biotite crystal black mica ontario canada mica110 303174730742 and ankerite mineral crystal acquired from unknown location in eisenerz steiermark austria were used for the abiotic reactivity experiments properties of the minerals are provided in table 1 2 2 batch dechlorination testing using previously developed methods schaefer et al 2017 schaefer et al 2018 batch experiments were performed under anoxic conditions to evaluate the abiotic reductive dechlorination of tce all anoxic experiments were prepared in an anaerobic chamber for each batch system 6 g of a specific mineral was placed in 40 ml amber glass vials bottles were then amended with 35 mls of 5 mm cacl2 that had been sparged with nitrogen an additional set of bottles were prepared similarly but amended with tce for a concentration of approximately 3 2 mm use of elevated tce concentrations facilitated the detection of transformation products for siderite and illite additional experiments were performed at a tce concentration of approximately 0 15 mm comparison of samples amended with tce to those without tce served to verify that generation of suspected dechlorination products were from tce rather than generation from anything associated with the acquired minerals the vials were capped with mininert valves with epoxy seals on the threads to allow for repeated sampling of the vial headspace for hydrocarbon transformation products all anoxic experimental conditions were prepared in triplicate i e vials were prepared in triplicate for each condition controls containing 5 mm cacl2 solution with tce but no minerals also were prepared in triplicate all sampling of the anoxic vials was performed outside of the anaerobic chamber under a stream of nitrogen to limit potential introduction of oxygen into the vials monitoring was typically performed up to approximately 40 days at the end of the experiment select vials were sampled to determine the ph in the supernatant water an additional set of experiments was performed using illite and siderite amended with 1 8 mm of ferrous iron from fecl2 h2o these experiments were performed in duplicate oxic experiments were also prepared similarly to those previously described schaefer et al 2018 and as described above for the anoxic experiments for oxic experiments the focus was to measure the generation of hydroxyl radicals which have shown to subsequently and oxidatively dechlorinate tce pham et al 2008 liu et al 2017 schaefer et al 2018 thus the extent of hydroxyl radical generation among the four ferrous minerals served as a surrogate for evaluating their relative potential effectiveness to facilitate oxidative transformation of tce hydroxyl radical generation was measured using the aminophenyl fluorescein apf method cohn et al 2008 cohn et al 2009 which is based upon hydroxyl radical transformation of the apf into fluorescein for each mineral 1 7 g were placed in the 40 ml amber glass vials with 10 ml of 0 1 m phosphate buffer ph 7 4 vials also were amended with apf to attain a 25 μm concentration with the bottle headspace flushed with air at time zero and daily thereafter periodic aqueous samples were collected during the 6 day duration of the experiments bottles were placed on a shaker 50 rpm during incubation periodic sampling was performed by removing a 400 μl aliquot that was transferred into a 15 ml conical centrifuge tube and centrifuged at 10 000g for 5 min the supernatant was subsequently analyzed using a promega quantus fluorometer where a blue fluorescent channel with an excitation filter at 495 nm and emission filter at 510 580 nm was used to quantify fluorescein all samples including a control containing no minerals were prepared in duplicate 2 3 analytical methods calculation of dechlorination rate constants and soil characterization tce cis 1 2 dichloroethene dce vinyl chloride vc and reduced gas methane ethane ethene propane acetylene butane methyl acetylene and propylene concentrations were determined via headspace analysis using a shimadzu 2010 gas chromatograph equipped with a flame ionization detector fid and an rt qs bond fused silica plot column aqueous concentrations were determined by applying henry s law tce reductive dechlorination in the anoxic systems are described by the following first order expression schaefer et al 2017 schaefer et al 2018 1 c t k an ε v h ε w ε w c 2 k an k an ρk ε w where c is the tce aqueous concentration mm t is time days kan is the bulk first order rate constant d 1 k an is the intrinsic pseudo first order rate constant d 1 ρ is the bulk density 0 2 kg l 1 k is the linear tce adsorption coefficient to both reactive and unreactive sites l kg 1 εv and εw are the dimensionless gas and water porosities in the vial 0 20 and 0 74 respectively and h is the tce dimensionless henry s law constant sander 1999 since the adsorption of tce to the reactive ferrous minerals cannot be determined the reaction rate constant is assessed in terms of kan rather than k an for eq 1 generation of acetylene ethene is used to determine the change in tce concentration this approach has been employed previously schaefer et al 2017 a small approximately 10 tce leakage loss was observed in the controls at the final 40 day sampling point due to volatilization losses from the vials reduced gas transformation products were corrected for this loss using a henry s law based partitioning factor to account for losses of transformation products as follows schaefer et al 2017 3 α i ε v ε w h tce ε v ε w h i where αi is the scaling factor by which tce dechlorination product i is multiplied to correct for leakage losses hi is the dimensionless henry s law constant for tce and dechlorination product i sander 1999 ferrous mineral content was determined using a 2 5 hcl extraction and the 1 10 phenanthroline method standard method 3500 fe b 4 c rice et al 2012 this methodology has been used in previous studies that showed a correlation between ferrous mineral content and reductive tce dechlorination rate constants schaefer et al 2017 schaefer et al 2018 an additional more aggressive ferrous iron extraction was also performed using 12 5 hcl and with heated 95c water bath both of these ferrous mineral extractions were performed by mccampbell analytical inc pittsburg ca reduction potentials were measured after equilibrating minerals in anoxic bicarbonate buffer by shaking in an anaerobic chamber overnight three mediator compounds indigo tetrasulfonate indigo disulfonate and athraquinone disulfonate were used to determine the potentials in the mineral slurries this approach has been shown to be appropriate for predicting abiotic dechlorination using soil and mineral samples fan et al 2016 kocur et al 2020 potentials were measured anaerobically with a ag agcl 3 m kcl mettler toledo redox micro orp electrode and converted to she this approach has been shown using field collected soil samples the electrode was rinsed in 0 1 n hcl for 30 min between each sample all reduction potential measurements were performed in at least duplicate 3 results and discussion 3 1 anoxic experiments the molar fraction of tce transformed to reduced gas products for each mineral over the 40 day experiment is shown in fig 1 acetylene was the primary transformation product observed accounting for 90 of the observed tce transformation the remaining tce removal was accounted for as ethene generation no chlorinated ethene or reduced gas transformation products were observed in the controls no minerals present and tce concentrations in the controls were statistically identical to those in the mineral amended bottles indicating that tce sorption to the minerals was below that which could be measured in this study 1 8 mmol kg 1 trace levels of reduced gas transformation products were observed in the experiments with minerals without tce present but these trace levels of reduced gases were less than 1 of those observed in the tce amended samples with the exception of biotite where no measurable generation of transformation products relative to the non tce amended samples was observed acetylene is not a known biotic tce transformation product and therefore the generation of acetylene as the primary dechlorination product provides strong evidence that the tce dechlorination occurred via an abiotic reductive mechanism tce abiotic reductive dechlorination typically occurs via a reductive beta elimination pathway with the formation of acetylene and with possible further reduction to ethene roberts et al 1996 arnold and roberts 2000 schaefer et al 2018 ethene has been shown to be an abiotic tce dechlorination product in ferrous mineral studies lee and batchelor 2003 entwistle et al 2019 but can also be attributed to the biotic transformation of tce cápiro et al 2015 schaefer et al 2009 no other biotic tce dechlorination products i e dce vc were detected suggesting that the ethene generation likely was due to abiotic mechanisms previous abiotic tce dechlorination experiments using natural clayey soils that based on soil mineral analysis contained minerals similar to those studied herein also primarily yielded acetylene and or ethene as abiotic reductive transformation products under anoxic conditions schaefer et al 2018 results presented in fig 1 show that siderite illite and ankerite each facilitates the abiotic reductive dechlorination of tce suggesting that the presence of these minerals in previously examined natural clayey soils likely played a role in tce dechlorination table 2 shows regressed first order tce reductive dechlorination rate constants on both a mass and estimated mineral surface area basis regression results indicate that dechlorination was reasonably described r2 values typically greater than 0 9 by a first order expression consistent with previous abiotic dechlorination studies in the presence of ferrous minerals butler and hayes 1999 schaefer et al 2013 however it is noted that because the fraction of tce consumed was low which resulted in essentially a constant concentration of tce during the experiment the data provided in fig 1 are unable to discern between a zero and first order rate model with respect to tce concentration in addition the initial t 1 day timepoint for siderite was not used in the first order regressions as a relatively rapid rate of dechlorination occurred between t 1 and t 7 days this transient rate of high dechlorination activity may have been due to consumption and depletion of a highly reactive iron species first order tce reductive rate constants obtained herein along with those obtained in a previous study using similar methodologies with natural clayey soils schaefer et al 2018 are plotted as a function of the ferrous iron content fig 2 with the exception of the visibly outlying biotite mineral the tce dechlorination rate constant generally increases with increasing ferrous content which is consistent with previous studies schaefer et al 2013 schaefer et al 2018 together these results suggest that ferrous minerals facilitate the observed reductive dechlorination reactions under anoxic conditions it is noted that the first order rate constants measured herein with the exception of that measured for biotite are sufficiently large such that they would likely be of environmental relevance for mitigating tce persistence in clay or rock matrices schaefer et al 2018 2018b berns et al 2019 the relationship between the dechlorination rate constant and ferrous mineral content in fig 2 is surprising as the solids used varied in the degree of heterogeneity predominantly single minerals versus natural solids containing multiple mineral species surface area and particle size multiple factors may contribute to this relationship one contributing factor likely is that the reaction rate constants are very slow this can be assessed by comparing the reaction to diffusion velocities in terms of the dimensionless da number cussler 1994 4 da k an l 2 d where l is the diffusion length and d is the effective aqueous diffusion coefficient that accounts for the tortuosity within the clay for reactions that are very slow relative to the diffusional mass transfer da 1 assuming an effective diffusion coefficient of 2 10 5 cm2 d 1 werth et al 1997 and a diffusion length of 0 001 cm based on the mineral particle sizes a reasonable estimate of the diffusion velocity d l 2 is 20 d 1 this value is more than 6 orders of magnitude greater than the first order rate constants shown in table 2 ensuring that da 1 this explains why the variation in particles sizes and surface areas among the solids do not appear to impact results another potential contributing factor is that the acid extraction used to determine the ferrous content for the minerals and soils may be sensitive to the factors that control the reactivity of the ferrous minerals with respect to tce reductive dechlorination thereby facilitating the observed trend observed in fig 2 the 2 5 hcl acid extraction table 1 likely did not extract all of the ferrous iron present in the solids but rather the most extractable iron which is likely a function of accessibility surface area and coordination within the mineral structure the relatively low measured ferrous content for siderite 36 g kg 1 is consistent with this interpretation because the ferrous content based only on stoichiometric mineral composition should be more than 10 times greater the latter was confirmed by the heated acid extraction data for siderite which matches closely with the theoretical ferrous content of 482 g kg 1 based on stoichiometry feco3 table 1 the results presented herein and previously schaefer et al 2013 schaefer et al 2017 schaefer et al 2018 suggest that abiotic reductive dechlorination under anoxic conditions is positively correlated to the ferrous mineral content these results are in apparent contrast to recent mechanistic studies culpepper et al 2018 entwistle et al 2019 that show ferrous minerals alone do not dechlorinate tce nor does the ferrous mineral content correlate to observed dechlorination rates rather culpepper et al and entwistle et al suggest rmis are responsible for the observed dechlorination one possible explanation for this apparent discrepancy is that the reductive dechlorination reactivity observed herein is in fact due to these rmis that have accumulated near the mineral surfaces and the measured ferrous mineral contents table 1 reflect in part the quantity of these reactive particles a second consideration is that the dechlorination rate constants for unaltered natural minerals and soils such as those employed herein occurs via a different and much slower mechanism than that observed for rmis entwistle et al 2019 if the mineral 6 g l 1 and tce 0 07 mm dosage used in the batch experiments performed by entwistle et al 2019 were used for the minerals examined herein no dechlorination would have been observed for any of the minerals tested based on the first order kinetic rate constants presented in table 2 thus the comparatively slow ferrous mineral correlated reactions observed herein and for natural rock and clayey materials schaefer et al 2013 schaefer et al 2018 may be attributable to a mechanism that does not involve rmis or may involve rmis that are far less reactive than those previously observed culpepper et al 2018 entwistle et al 2019 the anoxic dechlorination experiments performed at 0 15 mm tce concentrations yielded first order rate constants that were approximately 4 times greater than those determined for experiments performed at 3 2 mm tce a similar dependence on tce concentration in clayey soils has been reported berns et al 2019 thus while the elevated tce concentrations used herein and in previous studies e g schaefer et al 2018 facilitated the identification and quantification of trace levels of transformation products these elevated tce concentrations likely resulted in an underestimation of the abiotic dechlorination rate constants compared to those rate constants that would have been measured at more dilute tce concentrations and that might be more reflective of tce concentrations at many tce impacted field sites in addition the dependence of the rate constant on concentration suggests as previously proposed berns et al 2019 that dechlorination kinetics at elevated tce concentrations are likely limited by langmuir type sorption to reactive mineral sorption sites the addition of 1 8 mm dissolved ferrous iron did not impact transformation product formation i e acetylene generation was statistically identical with and without the added ferrous iron fig s1 in the supplemental information suggesting that addition of this iron did not result in rmis that impacted tce dechlorination however as discussed in detail by entwistle et al 2019 both the ferrous dosage and geochemical conditions in the batch systems used herein may not have been appropriate for facilitating rmi formation the ferrous iron surface area normalized first order rate constants table 2 as a function of the measured reduction potential are shown in fig 3 the relationship between reduction potential and the dechlorination rate constant has been estimated as follows stewart et al 2018 kocur et al 2020 5 log k sa ae c where ksa is the surface area normalized rate constant table 2 a and c are constants and e is the reduction potential kocur et al 2020 also indicate that a mass normalized rate constant can be used instead of the surface area normalized rate constant for more complex sediment matrices in which it is difficult to get a surface area for the reactive minerals in eq 5 the surface area normalized data in fig 3 are qualitatively consistent with eq 5 suggesting the importance of ferrous mineral surfaces for the observed reductive dechlorination reactions when evaluating the data with respect to measured reduction potential the ferrous iron mass normalized rate constants do not exhibit a functionality that is consistent with eq 5 although the limited number of data points prevents a thorough evaluation of eq 5 with respect to reduction of tce by ferrous minerals no measurable reductive dechlorination for biotite was observed which showed a measured reduction potential of 84 mv vs she the reduction potential was negative for all other minerals thus the reducing potential of the biotite likely was insufficient to facilitate tce reduction under the conditions tested this result highlights a potential useful application of this electrochemical method in identifying ferrous minerals that despite having apparently sufficient ferrous mineral content as shown in fig 2 lack the potential to reductively dechlorinate tce under anoxic conditions the results shown in figs 2 and 3 suggest the importance of considering both the ferrous mineral content and the reduction potential for abiotic tce reduction under anoxic conditions while a trend of increasing rate constant with ferrous content is observed in fig 2 the outlying biotite sample is only explained in the context of its reduction potential thus it is possible that certain ferrous minerals simply do not have sufficient reduction capacity to dechlorinate tce it currently is unclear how other geochemical conditions or the presence of mineral mixtures may impact dechlorination 3 2 oxic experiments results showing the generation of hydroxyl radicals are provided in fig 4 we note that this measure of hydroxyl radical generation is based upon hydroxyl radical reaction with apf and thus represents only the radicals that are available to react with this compound the molar hydroxyl radical generation of each mineral was orders of magnitude less than the oxygen present in each vial so oxygen levels were not limiting and remained essentially constant in the oxic experiments because studies using the apf based approach for hydroxyl radical quantification typically have been performed within approximately 30 h e g cohn et al 2008 cohn et al 2009 results shown in fig 4 are best interpreted by comparing hydroxyl radical generation among the various minerals tested rather than a definitive quantitative value comparison of figs 2 and 4 shows that the order of reactivity for the minerals with respect to hydroxyl radical generation differs from that observed for tce reduction under anoxic conditions most notably illite generates more than twice the hydroxyl radicals than any other mineral whereas illite s reactivity under anoxic conditions with respect to tce dechlorination was greater only than biotite which yielded no measurable tce dechlorination interestingly biotite exhibited the least amount of reactivity for both the oxic and anoxic conditions the differences among the mineral reactivities with respect to hydroxyl radical generation are not readily explained by any apparent differences in the mineral properties presented in table 1 while the high reactivity of the illite appears to correspond to its high specific surface area the specific surface areas for the other 3 minerals differ by over an order of magnitude yet differ by only 34 in their hydroxyl radical yield over the 6 day experiment assuming 3 mol of ferrous iron are required to transform tce to acetylene and 3 mol of ferrous iron are needed to generate 1 mol of hydroxyl radical kong et al 2015 schaefer et al 2018 the fractional ferrous consumption is calculated for each mineral under both oxic and anoxic conditions fig 5 results show that only a relatively small fraction of the ferrous iron was oxidized during both the oxic and anoxic experiments furthermore while the magnitude of the fractional ferrous mineral consumption between the oxic and anoxic experiments was biased to the duration of the experiment 40 days for the anoxic experiments vs 6 days for the oxic experiments fractional oxidation of the minerals occurred in the order of illite biotite siderite ankerite fig 5 which is the reverse order of their ferrous content table 1 the exception is biotite under anoxic conditions which as previously discussed likely did not have sufficient reduction potential to reduce tce fig 5 also provides a measure of the molar tce or oxygen reduced per mole of ferrous iron present in each mineral comparison shows that illite is the most reactive mineral on a mole of tce or oxygen reacted per mole of ferrous iron present of the four minerals tested with the exception of tce reduction via biotite ankerite shows the least reduction of tce oxygen per mole of ferrous iron present while these relationships are apparent from fig 5 it is unclear whether these relationships reflect an intrinsic chemical reactivity of the specific ferrous minerals the available surface area of the ferrous minerals within the bulk mineral structure the formation of reactive mineral intermediates culpepper et al 2018 entwistle et al 2019 within the mineral microstructure and or other structural or chemical factors the fact that the fractional ferrous oxidation in fig 5 correlates inversely with mineral ferrous content and also the ratio of the specific surface area to ferrous content suggests that for these ferrous rich minerals the reduction becomes more efficient at lower ferrous contents potentially due to improved accessibility for tce and oxygen at reactive mineral surfaces i e less crowding of the ferrous iron recent investigations by yuan et al 2018 show that both surface and structural ferrous iron contribute to hydroxyl radical formation the similarity in behavior between the oxic and anoxic experiments in fig 5 suggests that both surface and structural ferrous iron contribute to both the reduction of tce and oxygen for the minerals examined herein additional studies are needed to confirm such mechanisms 3 3 environmental implications under anoxic conditions several ferrous mineral types can facilitate tce reduction either directly or potentially by the facilitating formation of rmis thus mineral screening for ferrous content may serve as a useful tool for estimating tce abiotic dechlorination rate constants in field samples however the mineral reduction potential needs to be sufficiently high to induce dechlorination thus a coupled approach involving measurement of both reduction potential and ferrous mineral content offers a likely improved benefit for potentially estimating abiotic reductive dechlorination rate constants in field samples with respect to oxic conditions while ferrous minerals appear to play an important role in hydroxyl radical generation the relationship between ferrous content and mineral properties are currently unclear further study is needed to understand this relationship 4 conclusion overall the results observed herein and in previous studies schaefer et al 2013 schaefer et al 2018 suggest that several ferrous minerals can play a role in the dechlorination of tce particularly under anoxic conditions that are typically present within rock or clay matrices continued studies with respect to the impacts of geochemical conditions contaminant mixtures and potential roles of reactive intermediates on these reactions are needed to further refine understanding of these naturally occurring dechlorination processes author statement schaefer project lead and primary writer ho led experimental effort and helped develop methods berns led reduction potential experiments and wrote experimental methods related to that work werth technical review of paper and on going technical input on project declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments support for this research was provided by the strategic environmental research and development program serdp under project er 2530 views opinions and or findings contained in this report are those of the authors and should not be construed as an official department of defense position or decision unless so designated by other official documentation the authors appreciate assistance from veronika culina in performing the experiments appendix a supplementary data supplementary material image 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jconhyd 2021 103839 
1427,accurate prediction of the co 2 plume migration and pressure is imperative for safe operation and economic management of carbon storage projects numerical reservoir simulations of co 2 flow could be used for this purpose allowing the operators and stakeholders to calculate the site response considering different operational scenarios and uncertainties in geological characterization however the computational toll of these high fidelity simulations has motivated the recent development of data driven models such models are less costly but may overfit the data and produce predictions inconsistent with the underlying physical laws here we propose a physics informed deep learning method that uses deep neural networks but also incorporates flow equations to predict a carbon storage site response to co 2 injection a 3d synthetic dataset is used to show the effectiveness of this modeling approach the model approximates the temporal and spatial evolution of pressure and co 2 saturation and predicts water production rate over time outputs given the initial porosity permeability and injection rate inputs first we establish a baseline using data driven deep learning models namely multilayer perceptron mlp and long short term memory lstm to build a physics informed model the loss term is modified using the constraints defined by a simplified form of the governing partial differential equations conservation of mass coupled with darcy s law for a two phase flow system our results indicate that incorporating the domain knowledge significantly improves the accuracy of predictions the proposed modeling approach can be integrated in co 2 storage management to accurately predict the critical site response indicators for a range of relevant input parameters even when limited training data is available keywords co 2 storage site response forecasting multilayer perceptron mlp physics informed deep learning long short term memory lstm 1 introduction developing a cost effective strategy to operate co 2 storage sites requires knowledge and understanding of the site response to co 2 injection considering the uncertainties in characterization of geological formations in contrast to the petroleum industry the experience related to operating and monitoring of large co 2 storage sites is very limited in addition extensive pre injection field tests are not economically viable or strategically feasible the state of the practice is to numerically simulate the reservoir behaviour to predict the storage capacity pressure response and recovery however large scale high fidelity dynamic simulations of fluid flow taking into account the uncertainties in various controlling parameters are cost prohibitive and slow limiting their utility for real time commercial scale co 2 storage management one approach to overcome this barrier is combining numerical simulations and data driven modeling to enable the operators to quickly explore and test co 2 storage site behaviour in various operational scenarios this approach will provide the stakeholders with the necessary tools to observe the impact of different operational parameters on a variety of outcomes over time in recent years machine learning methods have been used to develop various data driven models to predict carbon storage site behaviour during and post injection these models include conditional deep convolutional generative adversarial network cdc gan for forecasting co 2 plume migration in a heterogeneous reservoir zhong et al 2019 support vector regression svr and artificial neural networks ann jeong et al 2018 as well as polynomial response surface modeling ampomah et al 2017 for predicting co 2 storage and oil recovery at a co 2 enhanced oil recovery field multi adaptive regression spline and random forest to evaluate cumulative co 2 storage capacity and oil recovery in residual oil zones pawar et al 2019 and multi variate regression analysis to estimate co 2 storage efficiency in saline aquifers ganesh and mishra 2016 among others these models are often trained and tested using synthetic data generated by numerical reservoir simulators independent of the modeling approach data driven models build a mapping between the input and simulated output that approximates the dynamic system within the bounds of the training data a reasonably accurate and generalizable model requires a large training dataset i e a large number of simulations needs to be run to train the model although the training data is generated through simulations the final trained model is fully data driven consequently the predictions could overfit the training data and may not be consistent with the governing physical laws physics informed deep learning is an alternative supervised learning strategy that respects relevant laws of physics which may be formulated in the form of partial differential equations pdes raissi et al 2017 one popular approach is to penalize the deviation from the underlying physical principles or boundary conditions by adding physical consistency constraints to the cost function raissi et al 2019 incorporating domain knowledge in the neural networks architecture results in more accurate predictions even when there is not much training data available raissi et al 2019 as such physics informed deep learning is gaining popularity in addressing prediction problems in different domains recently physics informed deep neural network is used to estimate hydraulic conductivity in saturated and unsaturated flows through enforcing the pde darcy s law or richards equation by minimizing the pde residual at select points in the simulation domain tartakovsky et al 2020 this work concludes that physics constraints improve the accuracy of estimations for sparsely observed functions and allow for training deep neural networks when few direct measurements of the target functions are available in this paper we use a set of simple two phase flow equations to add constraints to two deep learning models used to predict the simulated response of a co 2 storage site namely multilayer perceptron mlp and long short term memory lstm we compare the performance of data driven and physics informed mlp and lstm models to predict pressure and co 2 saturation fields over time as well as water production rate given the initial co 2 injection rate and hydraulic geological properties of the reservoir permeability and porosity distributions the rest of this paper is organized as follows first we describe the data and the equations incorporated in our physics informed deep learning approach in the following section we describe the data driven mlp and lstm models which are used as baseline next we detail our physics informed modeling approach with and without training on an additional unsupervised dataset for which simulated values of the target quantities pressure gas saturation and water production rate are not available finally we present the prediction results and discuss the performance of different models 2 data and governing equations the deep learning algorithms are trained and tested on a synthetic dataset generated by dynamic numerical fluid flow simulations of a 3d toy reservoir of depth 7500 ft the simulations are conducted using a commercial reservoir simulation software by cmg computer modeling group ltd the model consists of three layers with 25x25x3 simulation grid points along x y and z directions the grid spacing is 300 ft in x and y directions and 11 ft in z direction permeability and porosity are heterogeneous and are taken from a geological model in offshore gulf of mexico we have assumed three realizations for permeability and porosity categorized as p10 p50 and p90 representing three different geological conditions table 1 the model includes one injection well at the center grid point 13 13 and one producer extracting water at grid block 23 23 the injector well is injecting supercritical co 2 at a constant rate and the water production well is set at a constant bottom hole pressure bhp for each of the geological conditions p10 p50 and p90 we run nine different simulations by varying the injection rate while keeping all other parameters the same generating a total of 27 realizations the simulation outputs pressure gas saturation and water production rate are reported on the 25x25x3 grid points at 72 time steps ranging from 0 to 2161 days out of the 27 realizations one from each of the three different geological conditions p10 p50 and p90 are randomly selected for testing the models 3 realizations in total for the remaining 24 realizations we use k fold cross validation 8 folds to perform training and hyperparameter selection 3 realizations for different geological conditions are used for each validation fold hyperparameters that achieve the lowest cross validation error on the 24 realizations are then evaluated on the test set 2 1 input output the predictions models use the following five parameters as input 1 time t there are 72 time steps for each of the 27 realizations the time intervals are equally spaced and are normalized from 0 to 1 using division by the global maximum time step in the training data 2 position x y z the simulation grid point positions are defined by coordinates x 1 25 y 1 25 and z 1 3 the three position coordinates are also normalized between 0 and 1 3 permeability k x y z permeability tensor k at a given x y and z location is passed as input to the prediction models the permeability is assumed to be isotropic and the values are normalized between 0 and 1 using the maximum permeability value found in the training data 4 porosity ϕ x y z porosity is heterogeneous and is correlated with permeability the scalar value is normalized between 0 and 1 using the maximum porosity value found in the training data fig 1 depicts the permeability and porosity distributions over 25 25 grid corresponding to the p10 geological conditions 5 injection rate q g another input to the models is the injection rate at a given well position x g y g z g and time t which is again normalized in the same manner as the other input variables the prediction task is to find how the three following output parameters evolve with respect to time and space 1 pressure p x y z t pressure is a function of time t and varies spatially the values are normalized using the maximum pressure value in the training data 2 gas saturation s g x y z t gas saturation rate is also a function of time t and space x y z 3 water production rate q w t water production rate in these simulations is only a function of time t because the water production well position x w y w z w is fixed the water production rate q w is predicted at the well location irrespective of the input location by our models since it is known to be zero elsewhere additionally the injection rate q g at the well location is always used as an input to the model 2 2 simplified two phase flow equations we use a set of simplified flow equations as physical constraints in our physics informed deep learning approach assuming co 2 and brine are two separate immiscible phases mass balance coupled with darcy s law gives the following system of two phase flow differential equations ebigbo et al 2007 1 ϕ t s g 1 s g μ w k p ρ w g q w 0 2 ϕ t s g s g μ g k p ρ g g q g 0 where μ w is the viscosity of water ρ w and ρ g are the mass densities of water and gas co 2 respectively in these equations the operator is the gradient with respect to the spatial coordinates x y z and denotes the inner product these equations are derived assuming that the formation is isotropic and fluid properties such as density and viscosity are constants additionally they assume that the pressure conditions at the lateral boundaries don t change over time and capillary pressure is negligible as will be discussed later the parameters that are not model inputs or outputs such as the viscosity and mass densities of water and gas are treated as trainable model parameters and are fitted by the model based on the data this avoids mismatch in units 3 methods we present two sets of models one set that uses mlp multi layer perceptron and the other that implements lstm we define data driven mlp models as our baseline and demonstrate how incorporating the pdes given in eqs 1 and 2 improves the mlp model performance similarly we compare the performance of data driven and physics informed lstm networks in predicting the temporal and spatial variation of pressure p and gas saturation s g as well as the evolution of water production rate q w over time for physics informed models we demonstrate how further minimizing the pde residuals over an unsupervised dataset affects the prediction accuracy 3 1 baselines we define two baselines namely a single task data driven and a multi output data driven model for the single task model we train a different mlp model for each of the three different outputs p s g or q w and similarly for lstm the multi output model simultaneously predicts all three outputs using the same model we compare the performance of these baseline models 3 2 data driven multi layer perceptron mlp models we start with a data driven model using a fully connected feed forward deep neural network dnn known as multi layer perceptron mlp the architecture of our multi ouput mlp model is shown schematically in fig 2 the network has an input layer five hidden layers and an output layer let u represent the input data and let θ represent the model parameters the functional form of the dnn v u θ is given as where l is the number of layers in more detail 4 v 1 u relu w 1 u b 1 v 2 v 1 relu w 2 v 1 b 2 v l v l 1 relu w l v l 1 b l v l 1 v l w l 1 v l b l where θ w 1 b 1 w 2 b 2 w l 1 b i is the collection of weight matrices w i and bias vectors b i used by the model here relu rectified linear unit is the activation function when applied to a scalar the rectified linear unit is defined as relu α max 0 α when the input to the rectified linear unit is a vector the relu function is applied element wise here the data u is the input vector consisting of the time t position x y z permeability k porosity ϕ and injection rate q q additionally v l 1 is the output of the model and the w i and b i are learnable weight and bias parameters of the i th layer we compare single output and multi output data driven mlp models each single output model has only one output node while the multi output model has three nodes in the output layer the data driven models use mse mean squared error as the loss function fig 3 3 3 physics informed mlp models with and without unsupervised points to add physics constraints we follow the physics inspired neural network pinn approach raissi et al 2019 tartakovsky et al 2020 we add terms to the loss function that act as penalties when the simplified governing equations shown in section 2 2 are violated fig 3 for readability purposes we define p as the neural network that approximates the true gas pressure function p similarly s g and q w are the neural network approximations for the saturation s g and water production rate q w respectively in other words 5 p x y z t p x y z t k ϕ q g θ s g x y z t s g x y z t k ϕ q g θ q w x y z t q w x y z t k ϕ q g θ there is an important but subtle point here recall that the models are trained to predict the water production rate of the well location no matter what the input location is this gives the model a useful global training signal since the production rate is known to be 0 at non well locations and hence does not need prediction thus in the physics equations q w is the model s prediction only when the input location is the production well location otherwise q w is 0 letting u x y z t k ϕ q g we define the functions f 1 u and f 2 u by plugging the neural network approximations into the governing equations eqs 1 and 2 6 f 1 u θ ϕ t s g u θ 1 s g u θ μ w k p u θ ρ w g q w u θ 7 f 2 u θ ϕ t s g u θ s g u θ μ g k p u θ ρ g g q g the necessary derivatives in eqs 6 and 7 are calculated using automatic differentiation abadi et al 2016 baydin et al 2018 the loss function l θ of the pinn is 8 l θ 1 n i 1 n p u i θ p u i 2 1 n i 1 n s g u i θ s g u i 2 1 n i 1 n q w u i θ q w u i 2 1 m j 1 m f 1 u j θ 2 1 m j 1 m f 2 u j θ 2 the first three terms are the standard mean squared error used to train the purely data driven model using the n sample dataset u1 u n for which the true values of p s g and q w are known hence we call this the supervised data the last two terms are penalties on violating the simplified governing equations and do not require knowledge of p s g and q w hence they can be evaluated over any arbitrary data points which we refer to as the unsupervised data u1 u2 u m there are many possible choices for the unsupervised dataset the naive choice is to set m n and u i u i for all i that is we use the same points as in the supervised data however when dealing with limited training data it is advisable to include additional points m n an alternative we tried is to create the unsupervised dataset using equally spaced linear interpolation of the x y z and time coordinates that appeared in the supervised data since there is no ground truth available the loss function for the interpolated points only contains terms related to the pdes physics mse loss 3 4 training details the tunable hyperparameters of the models are learning rate batch size training epochs number of hidden layers nodes in each layer optimizer dropout activation function and batch normalization the data driven model is trained using adam optimizer with a learning rate of 1e 4 and a batch size of 250 which is tuned by observing the cross validation loss over the training set i e the test set was held out and was not part of the cross validation tuning the data driven model is trained for 500 epochs and checkpoints are saved based on the lowest validation mse loss observed between 200 and 250 epochs we use a 6 layer mlp architecture for data driven and physics based models containing 128 nodes 64 nodes 32 nodes 16 nodes 8 nodes and 3 nodes output layer in order in the first to the sixth layer fig 2 several variations of the mlp model with different number of layers and nodes in each layer were tried before arriving at the optimal architecture based on the cross validation accuracy adding batch normalization after every layer or dropout after the last hidden layer in the model did not result in any significant gains in performance additionally we tested the model with relu activation function and sigmoid activation function after each hidden layer the former was used in our model due to faster convergence the model with the lowest validation loss across all cross validation folds is used as the final model for the testing phase for the physics based model we first train on the supervised dataset with the same set of hyperparameters as used in data driven model until it achieves the best validation loss afterward the model is optimized using interpolated dataset including supervised datapoints using physics mse loss for an additional 200 epochs the best checkpoint observed was around 100 epochs the learning rate is reduced to 1e 6 since only small weight updates are required at this stage any problems related to units of measurement caused by passing the normalized values to the physics equations are handled by the trainable parameters that are fitted by the model for each operation vector multiplication addition scalar multiplication we introduce the required trainable weights and bias terms to handle the different scales of the features like the data driven model the physics informed model is trained using a batch size of 250 however the injection rate and water production rate only enter the physics equations i e are nonzero at the well locations the well locations are a small part of the data and there is a concern that the physics informed model may not see enough of it to learn the physics for nonzero q w and q g to tackle this issue we use stratified sampling this involves resampling infrequent samples samples at well locations to adjust their amount in comparison with predominant samples samples at non well locations based on validation data we determined that a batch optimally should have 20 samples that are at the non well locations for better convergence and performance to avoid catastrophic forgetting mccloskey and cohen 1989 in the neural network we keep training the model on the supervised and interpolated datasets alternatively for 200 epochs using the same learning rate for both until we observe a saturation in validation loss value which usually occurs after two such cycles the k fold cross validation training takes around 8 min per epoch across all folds for the data driven model and 20 min after interpolation per epoch for the physics based model with one nvidia tesla k80 card we include training times without cross validation as part of results in table 3 3 5 data driven lstm models the mlp is a stateless model its prediction for what happens at time t is unrelated to its prediction for time t 1 on the other hand an lstm is a deep learning time series model that carries over a state similar in spirit to hidden markov models hence lstm is a natural candidate for this dataset similar to what is described for data driven mlp models we compare the performance of two baseline models a single output and a multi output data driven model the architecture of our multi output lstm model is illustrated in fig 4 the input to the model at each timepoint is a history of features at timesteps t 3 t 2 t 1 and t near the beginning of the time series where a full history is not available the earliest input is replicated the features at each timestep t include the time t position coordinates x t y t z t permeability k t porosity φ t and the gas injection rate q g the network has an input layer two lstm layers three fully connected layers and an output layer that uses the relu activation function each unit in the lstm layers controls the interdependency of feature vectors between the consecutive timesteps the same network architecture is used for both single output and multi output data driven models with the exception that the output layer produces 3 outputs instead of 1 similar to the mlp models we use mse mean squared error as the loss function 3 6 physics informed lstm models with and without unsupervised points similar to what is described for physics informed mlp models in section 3 3 we modify the loss function eq 8 to penalize the model when the governing equations are violated since we are passing the history of features at the previous timesteps in addition to the current timestep to our lstm model eqs 6 and 7 are calculated by computing the gradient of the corresponding s g and p functions only with respect to the current timestep t and current position coordinates x y and z additionally the network is unrolled in order to compute the second order gradients in the equations with respect to each layer in the lstm model similar to the physics informed mlp this model is trained on the unsupervised dataset generated as described in section 3 3 when training on these data points the loss function only contains the terms related to the governing equations as no ground truth is available 3 7 training details the hyperparameters of the lstm model are the learning rate batch size training epochs number of hidden layers number of nodes in each layer and the optimizer the data driven models are trained using adam optimizer with a learning rate of 1e 4 and a batch size of 250 for 500 epochs these hyper parameters are tuned according to the lowest cross validation loss over the training data the adam optimizer is chosen because of its adaptive learning rate for each parameter of the model the best model is determined from the checkpoints saved according to the validation loss and is observed for around 180 epochs we use a six layer architecture where the first two layers consist of 128 and 64 lstm units and the following layers consist of 32 16 8 and 3 fully connected nodes respectively fig 4 the lstm model architecture is determined after experimenting with a number of lstm 3 layer variant 2 layer variant 1 layer variant and dense layers 2 layer variant 3 layer variant 4 layer variant as well as the number of nodes in each of these layers we also examine different choices for the length of the history window that should be used by the lstm at each time step the choices we considered were a history of length 2 i e at time t the input consisted of features from times t and t 1 a history of length 3 and a history of length 4 the latter was chosen based on validation loss the training time for 1 epoch of the data driven is around 10 min for the physics informed model without unsupervised points we oversample the data points at the well locations to adjust their distribution with the non well samples this is to account for the majority of the zero injection rate and water production rate variables at the non well locations we use a batch size of 250 comprising 60 samples at the non well locations for better performance the ratio of the non well samples to the well samples is determined after experimenting with the respective 80 20 70 30 60 40 and 50 50 splits this model is trained using adam optimizer with a learning rate of 1e 5 for 300 epochs and the checkpoints are saved according to the lowest validation mse loss the model with the lowest validation loss across all folds is used to obtain the test predictions the physics informed model with interpolated points is obtained by alternatively training the lstm model on the supervised dataset and the unsupervised dataset using the physics mse loss the training with interpolated points is done with a learning rate of 1e 5 for 100 epochs until a saturation in the validation loss is observed the training time for 1 epoch of the physics informed model after interpolation is around 40 min 4 results and discussion 4 1 mlp we compare the results of the different implementations of the mlp model in table 2 we achieve better prediction performance with the multi output training model compared to the single output training model for all the three output variables this highlights the interdependency of the three output variables in addition it indicates that the multi output training helps in modeling the joint probability of the three output variables the physics informed models perform better than both data driven models because of the improved supervision provided by the governing equations table 2 shows an especially clear improvement in the mse values of water production rate which has considerably larger prediction errors than the other two outputs when using data driven models finally the results improve significantly for all the three output variables when training a joint physics based model with interpolated points these results indicate that training with interpolated space time coordinates is effective in smoothing the model and hence enhancing the model performance fig 5 shows the qualitative comparison of three implemented versions of the mlp model for prediction of gas saturation s g and pressure p fields 25 25 z 1 as apparent in the figure training using interpolated points reduces the relative error to negligible amounts for both variables fig 6 shows the qualitative comparison of data driven and physics informed models for water production variable q w the physics informed model provides a much more accurate estimation of the ground truth compared to the data driven model fig 7 shows the qualitative comparison of predicted gas saturation using physics informed model across multiple timesteps we can infer that the relative error remains stable across the timesteps for both gas saturation and pressure fields fig 8 shows the relative error while predicting gas saturation and pressure fields using physics informed model across the z dimension table 3 summarizes the results of an ablation study which illustrates how addition of unsupervised data points can lead to improved accuracy there are many different ways to choose unsupervised datapoints therefore we have to answer two questions 1 how to select these datapoints and 2 what is a good balance between the unsupervised and supervised datasets we use a simple strategy to create a huge interpolated dataset considering that the data in our supervised dataset is given at equally spaced temporal and spatial coordinates we define a parameter c that determines the number of unsupervised points to generate between any two neighboring time or position values in the original training dataset eq 9 for example the interpolated timestep t i for our interpolated dataset is defined as 9 t i t 1 t 2 t 1 c 1 i where t 1 and t 2 are any two neighboring timestep values in the original dataset and iε 1 c 1 parameter c is also used to generate new interpolated position x i and y i values as seen in table 3 we empirically find that c 2 is the optimal value i e using an interpolated dataset that is 27 times the size of the original dataset yields the smallest mses larger values of c results in similar or worse performance either due to performance saturation or skewed balance between the supervised and interpolated datasets 4 2 lstm the mse values obtained for the different lstm models are given in table 4 the multi output model performs better than the single task model for all the three output variables as it helps in modeling the interdependency among the variables additionally the physics informed model trained on the supervised dataset achieves less mse loss highlighting the importance of the supervision by the governing equations a steep decrease in the loss while predicting the water production rate is observed when physics is incorporated into the loss function the model performance is further improved for all the three output variables as it is trained jointly with the interpolated space time datapoints the qualitative comparison of the data driven and physics informed models for prediction of gas saturation s g and pressure p variables is illustrated in fig 9 we observe that the relative error for both variables decreases significantly when the model is trained jointly with interpolated points fig 10 qualitatively compares the evolution of the water production rate q w predicted using data driven and physics informed multi output lstm models showing that the physics informed model predictions are considerably more accurate the variations in the gas saturation field with increasing timesteps and the corresponding relative errors are plotted in fig 11 the relative error is quite low and remains stable across all timesteps for both the gas saturation and pressure predictions as shown in fig 11 b and c 5 conclusions we compare data driven and physics informed deep learning models mlp and lstm to predict a carbon storage site response the evolution of pressure and co 2 saturation distributions together with water production rate knowing the site porosity and permeability as well as gas injection rate the mlp is a stateless model while lstm carries over a state and uses input history the lstm model while almost taking twice as long for training performs slightly better than mlp model for pressure and gas saturation fields single output and multi output data driven models perform similarly with multi output models performing slightly better our main finding is that physics informed models deep learning models that incorporate a set of simplified flow equations in their loss functions deliver significantly more accurate predictions moreover training on an interpolated dataset additional data points obtained by time and space interpolations further improves the physics informed model performances here the models are trained validated and tested on a small synthetic toy dataset we will explore the feasibility of our proposed approach on a larger and more realistic dataset in future studies one concern is the longer training time associated with physics informed models such concerns can be addressed by strategies such as optimizing the data loading process pre fetching data use of multiple gpus feature reduction and network pruning which were not needed for the small dataset we use for this study furthermore with large datasets it is possible to create a separate validation set to avoid cross validation in addition we emphasize that while the training time is longer the testing time is largely unaffected therefore depending on the application the advantages of having a generalizable and accurate models may outweigh the added training costs the presented modeling approach combined with numerical reservoir simulations can be integrated in co 2 storage management to accurately and quickly estimate the critical site response to co 2 injection even when limited training data a small number of simulation runs is available declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was completed as part of the science informed machine learning to accelerate real time decision making for carbon storage smart cs initiative edx netl doe gov smart support for this initiative was provided by the u s department of energy s doe office of fossil energy s carbon storage research program through the national energy technology laboratory netl the authors wish to acknowledge mark mckoy netl carbon storage technology manager darin damiani doe office of fossil energy carbon storage program manager and mark ackiewicz doe office of fossil energy director division of carbon capture and storage research and development for programmatic guidance direction and support the authors also wish to acknowledge the anonymous reviewers for their insightful comments which helped improve the manuscript the synthetic dataset used in this study is available for download doi https doi org 10 5281 zenodo 4617269 the codes can be found at https github com sumedha29 co2 sequestration git appendix a permeability porosity realizations fig a 1 the a permeability log scale and b porosity distribution over 25 25 field data corresponds to p50 geological conditions the 1st timestep fig a 1 fig a 2 the a permeability log scale and b porosity distribution over 25 25 field data corresponds to p90 geological conditions the 1st timestep fig a 2 appendix b gas saturation and pressure visualization fig b 1 the gas saturation and pressure distribution over 25 25 field data corresponds to p10 p50 and p90 realizations fig b 1 appendix c water production rate visualization fig c 1 the water production rate distribution across the 72 timesteps data corresponds to p10 p50 and p90 realizations fig c 1 
1427,accurate prediction of the co 2 plume migration and pressure is imperative for safe operation and economic management of carbon storage projects numerical reservoir simulations of co 2 flow could be used for this purpose allowing the operators and stakeholders to calculate the site response considering different operational scenarios and uncertainties in geological characterization however the computational toll of these high fidelity simulations has motivated the recent development of data driven models such models are less costly but may overfit the data and produce predictions inconsistent with the underlying physical laws here we propose a physics informed deep learning method that uses deep neural networks but also incorporates flow equations to predict a carbon storage site response to co 2 injection a 3d synthetic dataset is used to show the effectiveness of this modeling approach the model approximates the temporal and spatial evolution of pressure and co 2 saturation and predicts water production rate over time outputs given the initial porosity permeability and injection rate inputs first we establish a baseline using data driven deep learning models namely multilayer perceptron mlp and long short term memory lstm to build a physics informed model the loss term is modified using the constraints defined by a simplified form of the governing partial differential equations conservation of mass coupled with darcy s law for a two phase flow system our results indicate that incorporating the domain knowledge significantly improves the accuracy of predictions the proposed modeling approach can be integrated in co 2 storage management to accurately predict the critical site response indicators for a range of relevant input parameters even when limited training data is available keywords co 2 storage site response forecasting multilayer perceptron mlp physics informed deep learning long short term memory lstm 1 introduction developing a cost effective strategy to operate co 2 storage sites requires knowledge and understanding of the site response to co 2 injection considering the uncertainties in characterization of geological formations in contrast to the petroleum industry the experience related to operating and monitoring of large co 2 storage sites is very limited in addition extensive pre injection field tests are not economically viable or strategically feasible the state of the practice is to numerically simulate the reservoir behaviour to predict the storage capacity pressure response and recovery however large scale high fidelity dynamic simulations of fluid flow taking into account the uncertainties in various controlling parameters are cost prohibitive and slow limiting their utility for real time commercial scale co 2 storage management one approach to overcome this barrier is combining numerical simulations and data driven modeling to enable the operators to quickly explore and test co 2 storage site behaviour in various operational scenarios this approach will provide the stakeholders with the necessary tools to observe the impact of different operational parameters on a variety of outcomes over time in recent years machine learning methods have been used to develop various data driven models to predict carbon storage site behaviour during and post injection these models include conditional deep convolutional generative adversarial network cdc gan for forecasting co 2 plume migration in a heterogeneous reservoir zhong et al 2019 support vector regression svr and artificial neural networks ann jeong et al 2018 as well as polynomial response surface modeling ampomah et al 2017 for predicting co 2 storage and oil recovery at a co 2 enhanced oil recovery field multi adaptive regression spline and random forest to evaluate cumulative co 2 storage capacity and oil recovery in residual oil zones pawar et al 2019 and multi variate regression analysis to estimate co 2 storage efficiency in saline aquifers ganesh and mishra 2016 among others these models are often trained and tested using synthetic data generated by numerical reservoir simulators independent of the modeling approach data driven models build a mapping between the input and simulated output that approximates the dynamic system within the bounds of the training data a reasonably accurate and generalizable model requires a large training dataset i e a large number of simulations needs to be run to train the model although the training data is generated through simulations the final trained model is fully data driven consequently the predictions could overfit the training data and may not be consistent with the governing physical laws physics informed deep learning is an alternative supervised learning strategy that respects relevant laws of physics which may be formulated in the form of partial differential equations pdes raissi et al 2017 one popular approach is to penalize the deviation from the underlying physical principles or boundary conditions by adding physical consistency constraints to the cost function raissi et al 2019 incorporating domain knowledge in the neural networks architecture results in more accurate predictions even when there is not much training data available raissi et al 2019 as such physics informed deep learning is gaining popularity in addressing prediction problems in different domains recently physics informed deep neural network is used to estimate hydraulic conductivity in saturated and unsaturated flows through enforcing the pde darcy s law or richards equation by minimizing the pde residual at select points in the simulation domain tartakovsky et al 2020 this work concludes that physics constraints improve the accuracy of estimations for sparsely observed functions and allow for training deep neural networks when few direct measurements of the target functions are available in this paper we use a set of simple two phase flow equations to add constraints to two deep learning models used to predict the simulated response of a co 2 storage site namely multilayer perceptron mlp and long short term memory lstm we compare the performance of data driven and physics informed mlp and lstm models to predict pressure and co 2 saturation fields over time as well as water production rate given the initial co 2 injection rate and hydraulic geological properties of the reservoir permeability and porosity distributions the rest of this paper is organized as follows first we describe the data and the equations incorporated in our physics informed deep learning approach in the following section we describe the data driven mlp and lstm models which are used as baseline next we detail our physics informed modeling approach with and without training on an additional unsupervised dataset for which simulated values of the target quantities pressure gas saturation and water production rate are not available finally we present the prediction results and discuss the performance of different models 2 data and governing equations the deep learning algorithms are trained and tested on a synthetic dataset generated by dynamic numerical fluid flow simulations of a 3d toy reservoir of depth 7500 ft the simulations are conducted using a commercial reservoir simulation software by cmg computer modeling group ltd the model consists of three layers with 25x25x3 simulation grid points along x y and z directions the grid spacing is 300 ft in x and y directions and 11 ft in z direction permeability and porosity are heterogeneous and are taken from a geological model in offshore gulf of mexico we have assumed three realizations for permeability and porosity categorized as p10 p50 and p90 representing three different geological conditions table 1 the model includes one injection well at the center grid point 13 13 and one producer extracting water at grid block 23 23 the injector well is injecting supercritical co 2 at a constant rate and the water production well is set at a constant bottom hole pressure bhp for each of the geological conditions p10 p50 and p90 we run nine different simulations by varying the injection rate while keeping all other parameters the same generating a total of 27 realizations the simulation outputs pressure gas saturation and water production rate are reported on the 25x25x3 grid points at 72 time steps ranging from 0 to 2161 days out of the 27 realizations one from each of the three different geological conditions p10 p50 and p90 are randomly selected for testing the models 3 realizations in total for the remaining 24 realizations we use k fold cross validation 8 folds to perform training and hyperparameter selection 3 realizations for different geological conditions are used for each validation fold hyperparameters that achieve the lowest cross validation error on the 24 realizations are then evaluated on the test set 2 1 input output the predictions models use the following five parameters as input 1 time t there are 72 time steps for each of the 27 realizations the time intervals are equally spaced and are normalized from 0 to 1 using division by the global maximum time step in the training data 2 position x y z the simulation grid point positions are defined by coordinates x 1 25 y 1 25 and z 1 3 the three position coordinates are also normalized between 0 and 1 3 permeability k x y z permeability tensor k at a given x y and z location is passed as input to the prediction models the permeability is assumed to be isotropic and the values are normalized between 0 and 1 using the maximum permeability value found in the training data 4 porosity ϕ x y z porosity is heterogeneous and is correlated with permeability the scalar value is normalized between 0 and 1 using the maximum porosity value found in the training data fig 1 depicts the permeability and porosity distributions over 25 25 grid corresponding to the p10 geological conditions 5 injection rate q g another input to the models is the injection rate at a given well position x g y g z g and time t which is again normalized in the same manner as the other input variables the prediction task is to find how the three following output parameters evolve with respect to time and space 1 pressure p x y z t pressure is a function of time t and varies spatially the values are normalized using the maximum pressure value in the training data 2 gas saturation s g x y z t gas saturation rate is also a function of time t and space x y z 3 water production rate q w t water production rate in these simulations is only a function of time t because the water production well position x w y w z w is fixed the water production rate q w is predicted at the well location irrespective of the input location by our models since it is known to be zero elsewhere additionally the injection rate q g at the well location is always used as an input to the model 2 2 simplified two phase flow equations we use a set of simplified flow equations as physical constraints in our physics informed deep learning approach assuming co 2 and brine are two separate immiscible phases mass balance coupled with darcy s law gives the following system of two phase flow differential equations ebigbo et al 2007 1 ϕ t s g 1 s g μ w k p ρ w g q w 0 2 ϕ t s g s g μ g k p ρ g g q g 0 where μ w is the viscosity of water ρ w and ρ g are the mass densities of water and gas co 2 respectively in these equations the operator is the gradient with respect to the spatial coordinates x y z and denotes the inner product these equations are derived assuming that the formation is isotropic and fluid properties such as density and viscosity are constants additionally they assume that the pressure conditions at the lateral boundaries don t change over time and capillary pressure is negligible as will be discussed later the parameters that are not model inputs or outputs such as the viscosity and mass densities of water and gas are treated as trainable model parameters and are fitted by the model based on the data this avoids mismatch in units 3 methods we present two sets of models one set that uses mlp multi layer perceptron and the other that implements lstm we define data driven mlp models as our baseline and demonstrate how incorporating the pdes given in eqs 1 and 2 improves the mlp model performance similarly we compare the performance of data driven and physics informed lstm networks in predicting the temporal and spatial variation of pressure p and gas saturation s g as well as the evolution of water production rate q w over time for physics informed models we demonstrate how further minimizing the pde residuals over an unsupervised dataset affects the prediction accuracy 3 1 baselines we define two baselines namely a single task data driven and a multi output data driven model for the single task model we train a different mlp model for each of the three different outputs p s g or q w and similarly for lstm the multi output model simultaneously predicts all three outputs using the same model we compare the performance of these baseline models 3 2 data driven multi layer perceptron mlp models we start with a data driven model using a fully connected feed forward deep neural network dnn known as multi layer perceptron mlp the architecture of our multi ouput mlp model is shown schematically in fig 2 the network has an input layer five hidden layers and an output layer let u represent the input data and let θ represent the model parameters the functional form of the dnn v u θ is given as where l is the number of layers in more detail 4 v 1 u relu w 1 u b 1 v 2 v 1 relu w 2 v 1 b 2 v l v l 1 relu w l v l 1 b l v l 1 v l w l 1 v l b l where θ w 1 b 1 w 2 b 2 w l 1 b i is the collection of weight matrices w i and bias vectors b i used by the model here relu rectified linear unit is the activation function when applied to a scalar the rectified linear unit is defined as relu α max 0 α when the input to the rectified linear unit is a vector the relu function is applied element wise here the data u is the input vector consisting of the time t position x y z permeability k porosity ϕ and injection rate q q additionally v l 1 is the output of the model and the w i and b i are learnable weight and bias parameters of the i th layer we compare single output and multi output data driven mlp models each single output model has only one output node while the multi output model has three nodes in the output layer the data driven models use mse mean squared error as the loss function fig 3 3 3 physics informed mlp models with and without unsupervised points to add physics constraints we follow the physics inspired neural network pinn approach raissi et al 2019 tartakovsky et al 2020 we add terms to the loss function that act as penalties when the simplified governing equations shown in section 2 2 are violated fig 3 for readability purposes we define p as the neural network that approximates the true gas pressure function p similarly s g and q w are the neural network approximations for the saturation s g and water production rate q w respectively in other words 5 p x y z t p x y z t k ϕ q g θ s g x y z t s g x y z t k ϕ q g θ q w x y z t q w x y z t k ϕ q g θ there is an important but subtle point here recall that the models are trained to predict the water production rate of the well location no matter what the input location is this gives the model a useful global training signal since the production rate is known to be 0 at non well locations and hence does not need prediction thus in the physics equations q w is the model s prediction only when the input location is the production well location otherwise q w is 0 letting u x y z t k ϕ q g we define the functions f 1 u and f 2 u by plugging the neural network approximations into the governing equations eqs 1 and 2 6 f 1 u θ ϕ t s g u θ 1 s g u θ μ w k p u θ ρ w g q w u θ 7 f 2 u θ ϕ t s g u θ s g u θ μ g k p u θ ρ g g q g the necessary derivatives in eqs 6 and 7 are calculated using automatic differentiation abadi et al 2016 baydin et al 2018 the loss function l θ of the pinn is 8 l θ 1 n i 1 n p u i θ p u i 2 1 n i 1 n s g u i θ s g u i 2 1 n i 1 n q w u i θ q w u i 2 1 m j 1 m f 1 u j θ 2 1 m j 1 m f 2 u j θ 2 the first three terms are the standard mean squared error used to train the purely data driven model using the n sample dataset u1 u n for which the true values of p s g and q w are known hence we call this the supervised data the last two terms are penalties on violating the simplified governing equations and do not require knowledge of p s g and q w hence they can be evaluated over any arbitrary data points which we refer to as the unsupervised data u1 u2 u m there are many possible choices for the unsupervised dataset the naive choice is to set m n and u i u i for all i that is we use the same points as in the supervised data however when dealing with limited training data it is advisable to include additional points m n an alternative we tried is to create the unsupervised dataset using equally spaced linear interpolation of the x y z and time coordinates that appeared in the supervised data since there is no ground truth available the loss function for the interpolated points only contains terms related to the pdes physics mse loss 3 4 training details the tunable hyperparameters of the models are learning rate batch size training epochs number of hidden layers nodes in each layer optimizer dropout activation function and batch normalization the data driven model is trained using adam optimizer with a learning rate of 1e 4 and a batch size of 250 which is tuned by observing the cross validation loss over the training set i e the test set was held out and was not part of the cross validation tuning the data driven model is trained for 500 epochs and checkpoints are saved based on the lowest validation mse loss observed between 200 and 250 epochs we use a 6 layer mlp architecture for data driven and physics based models containing 128 nodes 64 nodes 32 nodes 16 nodes 8 nodes and 3 nodes output layer in order in the first to the sixth layer fig 2 several variations of the mlp model with different number of layers and nodes in each layer were tried before arriving at the optimal architecture based on the cross validation accuracy adding batch normalization after every layer or dropout after the last hidden layer in the model did not result in any significant gains in performance additionally we tested the model with relu activation function and sigmoid activation function after each hidden layer the former was used in our model due to faster convergence the model with the lowest validation loss across all cross validation folds is used as the final model for the testing phase for the physics based model we first train on the supervised dataset with the same set of hyperparameters as used in data driven model until it achieves the best validation loss afterward the model is optimized using interpolated dataset including supervised datapoints using physics mse loss for an additional 200 epochs the best checkpoint observed was around 100 epochs the learning rate is reduced to 1e 6 since only small weight updates are required at this stage any problems related to units of measurement caused by passing the normalized values to the physics equations are handled by the trainable parameters that are fitted by the model for each operation vector multiplication addition scalar multiplication we introduce the required trainable weights and bias terms to handle the different scales of the features like the data driven model the physics informed model is trained using a batch size of 250 however the injection rate and water production rate only enter the physics equations i e are nonzero at the well locations the well locations are a small part of the data and there is a concern that the physics informed model may not see enough of it to learn the physics for nonzero q w and q g to tackle this issue we use stratified sampling this involves resampling infrequent samples samples at well locations to adjust their amount in comparison with predominant samples samples at non well locations based on validation data we determined that a batch optimally should have 20 samples that are at the non well locations for better convergence and performance to avoid catastrophic forgetting mccloskey and cohen 1989 in the neural network we keep training the model on the supervised and interpolated datasets alternatively for 200 epochs using the same learning rate for both until we observe a saturation in validation loss value which usually occurs after two such cycles the k fold cross validation training takes around 8 min per epoch across all folds for the data driven model and 20 min after interpolation per epoch for the physics based model with one nvidia tesla k80 card we include training times without cross validation as part of results in table 3 3 5 data driven lstm models the mlp is a stateless model its prediction for what happens at time t is unrelated to its prediction for time t 1 on the other hand an lstm is a deep learning time series model that carries over a state similar in spirit to hidden markov models hence lstm is a natural candidate for this dataset similar to what is described for data driven mlp models we compare the performance of two baseline models a single output and a multi output data driven model the architecture of our multi output lstm model is illustrated in fig 4 the input to the model at each timepoint is a history of features at timesteps t 3 t 2 t 1 and t near the beginning of the time series where a full history is not available the earliest input is replicated the features at each timestep t include the time t position coordinates x t y t z t permeability k t porosity φ t and the gas injection rate q g the network has an input layer two lstm layers three fully connected layers and an output layer that uses the relu activation function each unit in the lstm layers controls the interdependency of feature vectors between the consecutive timesteps the same network architecture is used for both single output and multi output data driven models with the exception that the output layer produces 3 outputs instead of 1 similar to the mlp models we use mse mean squared error as the loss function 3 6 physics informed lstm models with and without unsupervised points similar to what is described for physics informed mlp models in section 3 3 we modify the loss function eq 8 to penalize the model when the governing equations are violated since we are passing the history of features at the previous timesteps in addition to the current timestep to our lstm model eqs 6 and 7 are calculated by computing the gradient of the corresponding s g and p functions only with respect to the current timestep t and current position coordinates x y and z additionally the network is unrolled in order to compute the second order gradients in the equations with respect to each layer in the lstm model similar to the physics informed mlp this model is trained on the unsupervised dataset generated as described in section 3 3 when training on these data points the loss function only contains the terms related to the governing equations as no ground truth is available 3 7 training details the hyperparameters of the lstm model are the learning rate batch size training epochs number of hidden layers number of nodes in each layer and the optimizer the data driven models are trained using adam optimizer with a learning rate of 1e 4 and a batch size of 250 for 500 epochs these hyper parameters are tuned according to the lowest cross validation loss over the training data the adam optimizer is chosen because of its adaptive learning rate for each parameter of the model the best model is determined from the checkpoints saved according to the validation loss and is observed for around 180 epochs we use a six layer architecture where the first two layers consist of 128 and 64 lstm units and the following layers consist of 32 16 8 and 3 fully connected nodes respectively fig 4 the lstm model architecture is determined after experimenting with a number of lstm 3 layer variant 2 layer variant 1 layer variant and dense layers 2 layer variant 3 layer variant 4 layer variant as well as the number of nodes in each of these layers we also examine different choices for the length of the history window that should be used by the lstm at each time step the choices we considered were a history of length 2 i e at time t the input consisted of features from times t and t 1 a history of length 3 and a history of length 4 the latter was chosen based on validation loss the training time for 1 epoch of the data driven is around 10 min for the physics informed model without unsupervised points we oversample the data points at the well locations to adjust their distribution with the non well samples this is to account for the majority of the zero injection rate and water production rate variables at the non well locations we use a batch size of 250 comprising 60 samples at the non well locations for better performance the ratio of the non well samples to the well samples is determined after experimenting with the respective 80 20 70 30 60 40 and 50 50 splits this model is trained using adam optimizer with a learning rate of 1e 5 for 300 epochs and the checkpoints are saved according to the lowest validation mse loss the model with the lowest validation loss across all folds is used to obtain the test predictions the physics informed model with interpolated points is obtained by alternatively training the lstm model on the supervised dataset and the unsupervised dataset using the physics mse loss the training with interpolated points is done with a learning rate of 1e 5 for 100 epochs until a saturation in the validation loss is observed the training time for 1 epoch of the physics informed model after interpolation is around 40 min 4 results and discussion 4 1 mlp we compare the results of the different implementations of the mlp model in table 2 we achieve better prediction performance with the multi output training model compared to the single output training model for all the three output variables this highlights the interdependency of the three output variables in addition it indicates that the multi output training helps in modeling the joint probability of the three output variables the physics informed models perform better than both data driven models because of the improved supervision provided by the governing equations table 2 shows an especially clear improvement in the mse values of water production rate which has considerably larger prediction errors than the other two outputs when using data driven models finally the results improve significantly for all the three output variables when training a joint physics based model with interpolated points these results indicate that training with interpolated space time coordinates is effective in smoothing the model and hence enhancing the model performance fig 5 shows the qualitative comparison of three implemented versions of the mlp model for prediction of gas saturation s g and pressure p fields 25 25 z 1 as apparent in the figure training using interpolated points reduces the relative error to negligible amounts for both variables fig 6 shows the qualitative comparison of data driven and physics informed models for water production variable q w the physics informed model provides a much more accurate estimation of the ground truth compared to the data driven model fig 7 shows the qualitative comparison of predicted gas saturation using physics informed model across multiple timesteps we can infer that the relative error remains stable across the timesteps for both gas saturation and pressure fields fig 8 shows the relative error while predicting gas saturation and pressure fields using physics informed model across the z dimension table 3 summarizes the results of an ablation study which illustrates how addition of unsupervised data points can lead to improved accuracy there are many different ways to choose unsupervised datapoints therefore we have to answer two questions 1 how to select these datapoints and 2 what is a good balance between the unsupervised and supervised datasets we use a simple strategy to create a huge interpolated dataset considering that the data in our supervised dataset is given at equally spaced temporal and spatial coordinates we define a parameter c that determines the number of unsupervised points to generate between any two neighboring time or position values in the original training dataset eq 9 for example the interpolated timestep t i for our interpolated dataset is defined as 9 t i t 1 t 2 t 1 c 1 i where t 1 and t 2 are any two neighboring timestep values in the original dataset and iε 1 c 1 parameter c is also used to generate new interpolated position x i and y i values as seen in table 3 we empirically find that c 2 is the optimal value i e using an interpolated dataset that is 27 times the size of the original dataset yields the smallest mses larger values of c results in similar or worse performance either due to performance saturation or skewed balance between the supervised and interpolated datasets 4 2 lstm the mse values obtained for the different lstm models are given in table 4 the multi output model performs better than the single task model for all the three output variables as it helps in modeling the interdependency among the variables additionally the physics informed model trained on the supervised dataset achieves less mse loss highlighting the importance of the supervision by the governing equations a steep decrease in the loss while predicting the water production rate is observed when physics is incorporated into the loss function the model performance is further improved for all the three output variables as it is trained jointly with the interpolated space time datapoints the qualitative comparison of the data driven and physics informed models for prediction of gas saturation s g and pressure p variables is illustrated in fig 9 we observe that the relative error for both variables decreases significantly when the model is trained jointly with interpolated points fig 10 qualitatively compares the evolution of the water production rate q w predicted using data driven and physics informed multi output lstm models showing that the physics informed model predictions are considerably more accurate the variations in the gas saturation field with increasing timesteps and the corresponding relative errors are plotted in fig 11 the relative error is quite low and remains stable across all timesteps for both the gas saturation and pressure predictions as shown in fig 11 b and c 5 conclusions we compare data driven and physics informed deep learning models mlp and lstm to predict a carbon storage site response the evolution of pressure and co 2 saturation distributions together with water production rate knowing the site porosity and permeability as well as gas injection rate the mlp is a stateless model while lstm carries over a state and uses input history the lstm model while almost taking twice as long for training performs slightly better than mlp model for pressure and gas saturation fields single output and multi output data driven models perform similarly with multi output models performing slightly better our main finding is that physics informed models deep learning models that incorporate a set of simplified flow equations in their loss functions deliver significantly more accurate predictions moreover training on an interpolated dataset additional data points obtained by time and space interpolations further improves the physics informed model performances here the models are trained validated and tested on a small synthetic toy dataset we will explore the feasibility of our proposed approach on a larger and more realistic dataset in future studies one concern is the longer training time associated with physics informed models such concerns can be addressed by strategies such as optimizing the data loading process pre fetching data use of multiple gpus feature reduction and network pruning which were not needed for the small dataset we use for this study furthermore with large datasets it is possible to create a separate validation set to avoid cross validation in addition we emphasize that while the training time is longer the testing time is largely unaffected therefore depending on the application the advantages of having a generalizable and accurate models may outweigh the added training costs the presented modeling approach combined with numerical reservoir simulations can be integrated in co 2 storage management to accurately and quickly estimate the critical site response to co 2 injection even when limited training data a small number of simulation runs is available declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was completed as part of the science informed machine learning to accelerate real time decision making for carbon storage smart cs initiative edx netl doe gov smart support for this initiative was provided by the u s department of energy s doe office of fossil energy s carbon storage research program through the national energy technology laboratory netl the authors wish to acknowledge mark mckoy netl carbon storage technology manager darin damiani doe office of fossil energy carbon storage program manager and mark ackiewicz doe office of fossil energy director division of carbon capture and storage research and development for programmatic guidance direction and support the authors also wish to acknowledge the anonymous reviewers for their insightful comments which helped improve the manuscript the synthetic dataset used in this study is available for download doi https doi org 10 5281 zenodo 4617269 the codes can be found at https github com sumedha29 co2 sequestration git appendix a permeability porosity realizations fig a 1 the a permeability log scale and b porosity distribution over 25 25 field data corresponds to p50 geological conditions the 1st timestep fig a 1 fig a 2 the a permeability log scale and b porosity distribution over 25 25 field data corresponds to p90 geological conditions the 1st timestep fig a 2 appendix b gas saturation and pressure visualization fig b 1 the gas saturation and pressure distribution over 25 25 field data corresponds to p10 p50 and p90 realizations fig b 1 appendix c water production rate visualization fig c 1 the water production rate distribution across the 72 timesteps data corresponds to p10 p50 and p90 realizations fig c 1 
1428,this study applies innovative methods to characterize and quantify the magnitude of groundwater flow in a fractured and variably cemented sandstone aquifer to inform an in situ remediation strategy for trichloroethene tce contamination a modified active distributed temperature sensing a dts approach in which fiber optic cables were permanently grouted in the borehole was used to quantify groundwater flow rates two additional tracer tests were conducted 1 fluorescein tracer injection followed by rock coring and sampling for visual mapping and porewater analysis and 2 deployment of passive flux meters in conventional monitoring wells to evaluate groundwater velocity and mass flux distributions forced gradient injection of fluorescein tracer suggests a dual porosity flow system wherein higher rates of groundwater flow occur within discrete features including highly permeable bedding planes and fractures with slower flow occurring within the rock matrix tracer was observed and detected in the unfractured matrix porewater 1 5 m away from the injection well beyond this distance 6 m radially away from the injection hole tracer was primarily detected within and adjacent to high transmissivity fractures serving as preferential flow paths the darcy flux calculated using active distributed temperature sensing a dts shows depth discrete values ranging from 7 to 60 cm day with average and median values of 23 and 17 cm day respectively passive flux meters pfms deployed in three conventional monitoring wells with slotted screens and sand filter packs showed groundwater flux values ranging from 2 to 11 cm day with an overall average of 4 cm day and are likely biased low due to spreading in the sand pack the study results were used to inform an in situ remediation system design including the proposed injection well spacing and the amendment delivery approach in addition the results were used to build confidence in the viability of delivering an oxidant to the rock matrix via advective processes this is important because 1 the matrix is where the majority of the tce mass occurs and 2 it provides insights on processes that directly affect remedial performance expectations given advective delivery to preferential pathways and the matrix overcomes diffusion only conditions keywords ambient groundwater flow rates poorly cemented sandstone preferential flow active distributed temperature sensing passive flux meter fluorescein tracer injection experiment dual permeability 1 introduction many urban centers overlie sedimentary rock aquifers and rely upon them for their municipal water supply sedimentary rocks often form highly transmissive aquifers with excellent natural water quality but can be susceptible to contamination due to their proximity to surface and high groundwater velocity through fractures contaminant migration rates through these aquifers can be slowed relative to average groundwater velocities due to transverse advection and diffusion into the lower permeability matrix zones between fractures these processes are known to retard plume front migration and delay the arrival of dissolved contaminants to receptors supply wells and surface water but to some extent is site specific nas 2015 a lower permeability matrix leads to persistent contamination that is difficult to flush by advective methods e g pump and treat which predominately flush groundwater from fractures this is due to lower permeability in the matrix in which diffusion often dominates transport as a result they represent some of the most difficult aquifer types to remediate nrc 2013 kueper et al 2014 due to slow rates of back diffusion from the matrix to the fracture consideration of methods to facilitate in situ contaminant destruction or degradations is required hence delivery of amendments in both preferential flow pathways and in the lower permeability matrix zones where the majority of contaminant mass typically resides is desired it is critical to identify the distribution of contaminants relative to the position of various flow pathways in the bedrock and determine the rate of groundwater flow and contaminant transport to design remediation delivery of amendments and estimate timeframes for monitoring and completion suthersan et al 2016 characterizing and acknowledging the aquifer heterogeneity is necessary for the implementation of advanced amendment delivery methods cho et al 2019 in variably cemented sandstone aquifers identifying these flow pathways can be challenging because flow can occur both within fractures and within less permeable poorly cemented intervals in the rock matrix since the bulk of contaminant mass typically resides in the rock matrix due to its larger porosity and mass storage capacity it is important for the amendments to easily penetrate the matrix to enhance remediation effectiveness this can be achieved through diffusion of the amendments into the matrix from closely spaced fractures or from advection into the matrix if there is sufficient permeability and gradient this study applies innovative methods in a fractured and variably cemented sandstone aquifer to identify the nature of the groundwater flow in both discrete fracture zones and matrix and quantify the magnitude and variability of groundwater flow to inform an in situ remediation strategy for decades old tce contamination the nature and extent of this tce plume has been well defined in previous investigations using continuous wireline coring high frequency rock core sampling and porewater contaminant analysis and multilevel groundwater monitoring systems however the nature and magnitude of groundwater flow was not well understood and is critical information for successful application of an in situ remediation approach characterizing groundwater flow in bedrock aquifers is challenging because flow is dominated by small sparsely distributed and variably transmissive fractures berkowitz 2002 neuman 2005 nrc 2013 nas 2015 or in the case of poorly cemented sandstones within both fractures and variably cemented sediment matrix characterizing fracture distribution extent and their interconnectivity can be critical to remediation system design parker et al 2018 historically hydraulically active fractures were inferred by visual inspection of core and geophysical logs or open hole fluid logging however recently many new approaches have been used with higher sensitivity to identify active flow zones in bedrock boreholes under both open and sealed conditions parker et al 2012 for examples active heat has been used as a tracer to inform water flow within a borehole by trolling temperature sensors inside an open or sealed borehole condition pehme et al 2010 2013 or by using fiber optic distributed temperature sensing methods in a variety of configurations summarized by bense et al 2016 borehole flow metering under ambient and pumped conditions provide the position transmissivity and interconnectivity of fractures e g paillet 1993 williams and paillet 2002 however it is advantageous to characterize flow under natural gradient conditions without the influence of hydraulic cross connection from an open borehole or a long screen monitoring well intersecting multiple hydrogeological units pehme et al 2010 parker et al 2018 several established and emerging methods can measure ambient flow under natural gradient conditions by isolating sections of an open bedrock borehole examples include the in well point velocity probe iwpvp that provides groundwater velocity at a centimeter scale osorno et al 2018 and tracer dilution experiments that can be performed in test intervals isolated by straddle packers at a centimeter to meter scale jamin et al 2015 maldaner et al 2018 passive flux meters are another technology that relies on a suite of tracers with variable transport properties that can be deployed in conventional monitoring wells with intervals isolated by rubber disks to estimate depth discrete groundwater and contaminant mass flux annable et al 2005 klammer et al 2016 or between packers in open rock boreholes in addition boreholes have been temporarily sealed with impermeable and flexible borehole liners to allow wireline trolling of high resolution temperature sensors inside the static water column under ambient and actively heated conditions to identify depth discrete hydraulically active flow locations pehme et al 2013 2014 advancements in fiber optic distributed temperature sensing a dts have allowed estimation of groundwater flow under natural gradient conditions when combined with direct push methods to directly install the fiber optic cables in unconsolidated sediments liu et al 2013 bakker et al 2015 or by deploying cables in temporary sealed bedrock boreholes using borehole liners coleman et al 2015 maldaner et al 2019 munn et al 2020 in poorly cemented bedrock or in unconsolidated overburden deposits several of the methods above may not be suitable or practicable direct push and borehole liner methods may not be feasible since the rock is too competent for direct push methods and too unstable for the borehole to remain open during the installation and removal of borehole liners this provides challenges for most of the methods mentioned above therefore in this study a modified approach was applied and tested in which fiber optic cables attached to blank pvc well casing were permanently grouted in place in the borehole to provide complementary datasets for comparison two tracer tests were conducted 1 fluorescein tracer injection followed by rock coring and sampling for porewater analysis to determine the tracer distribution and 2 deployment of the passive flux meter in conventional monitoring wells to evaluate the in situ groundwater velocity and mass flux distributions at different depths this study aims to identify the position and variability of flow pathways in a poorly cemented fractured sandstone using different methods for comparison to estimate groundwater flow rates that can later inform the design of an in situ remediation system 2 study site the study area is a former industrial facility that operated from 1965 to 2009 in southern france as shown in fig 1 volatile organic compounds vocs primarily trichloroethene tce have been identified in two separate areas referred to as the northern and southern areas the southern area plume is being addressed via a groundwater pumping and treatment system see extraction wells ew 1 and ew 2 on fig 1 the northern area was subjected to high resolution investigations fig 1b including continuous wireline coring and high frequency rock core sampling for voc analysis and installation of conventional and continuous multichannel tubing cmt multilevel systems einarson and cherry 2002 these higher resolution characterization and monitoring datasets led to an improved understanding of tce mass distributions in the plume above and below the water table with rock core tce concentrations of up to 456 μg kg and groundwater concentrations of up to 1000 μg l in the shallow units located 10 15 m below ground surface bgs fig 1c the lithostratigraphic units identified at the study site are presented in fig 1c at the ground surface a 2 m granular fill and or clayey sand layer overlies an approximately 2 m thick silt and clay interval that overlies the pliocene aged sandstone units of the astien formation at the study site the astien formation has been subdivided into shallow intermediate deep and very deep layers shallow and intermediate portions are generally unconsolidated or poorly cemented sandstone with gravely lenses and limited calcareous cementation the deep and very deep portions are moderate to highly cemented and are typically described as bedrock in the northern area the depth to groundwater is generally 10 m bgs and groundwater flows in a west southwest direction there is visual evidence of preferential flow paths from detailed inspection of core logs in the unconsolidated shallow aquifer and these features become more prominent and frequent within the increasingly competent intermediate and deep astien formation units 3 methods multiple field methods were applied including injection of a conservative tracer fluorescein under forced gradient conditions that is typical of in situ remediation fluid injections active heat tracer tests using fiber optic cables with distributed temperature sensing a dts using a modified borehole deployment technique and passive flux meter pfm measurements in conventional monitoring wells under natural gradient conditions these are presented in more detail below 3 1 tracer injection experiment a fluorescein tracer injection was performed using a total of 117 m3 of tracer solution with concentration of 100 000 μg l the solution was injected into monitoring well pz 89s screened from 11 to 14 m bgs at an average flow rate of 1 4 l min for 53 days by gravity using a hydraulic head difference of around 10 m periodic groundwater samples for field screening and laboratory analysis of fluorescein were performed at nearby conventional and multi level monitoring wells following the 53 day injection period five 14 6 cm outer diameter boreholes b604 b606 b607 b609 b610 were drilled using a pq wireline coring with diamond bit at distances ranging from 1 5 to 5 9 m from the injection well fig 1b and c each core run 8 5 cm diameter and 1 5 m long was retrieved inside a plastic liner divided in half into two 0 75 m long pieces capped and frozen on site shortly after collection using dry ice in a large insulated container fig 2a after at least 2 h the frozen cores were scored lengthwise on both sides to a depth of approximately 2 cm using a circular saw with a masonry blade in a wooden guide and then split in half using chisels and a mallet fig 2b and c scoring and manually splitting the core rather than cutting all the way through provided an interior less disturbed surface that more clearly portrayed the rock texture and sediment structures for geologic logging that were less visible on the cut surface fig 2d after splitting the cores were left to partially thaw before they were photographed under ambient and ultraviolet uv light for fluorescein tracer observations the cores were covered with a black tarp during the thawing period to prevent degradation of the fluorescein dye by exposure to sunlight thawing the core was important to avoid the formation of ice crystals from moist air condensing and freezing on the core surface that masked the fluorescein and sediment structures to detect the presence of fluorescein at concentrations below visual detection core samples were collected for porewater fluorescein laboratory analysis at an average sample frequency of four samples per meter targeting zones in and around zones of visual fluorescein detection samples were comprised of an average of 13 g of the rock sediments added to 40 ml glass vials with 20 ml of water as an extractant in the lab the samples were shaken centrifuged and fluorescein concentrations were analyzed using an agilent cary eclipse fluorescence spectrophotometer with a method detection limit mdl of 0 3 μg l the resulting fluorescein concentration in the extractant mv 1 was converted to porewater concentration mv 1 using the following equation 1 c aq m t ρ b wet ϕr where m t is the total mass of fluorescein per unit mass of rock mm 1 which is calculated from the extract concentration mass of rock sample and volume of extractant ρ b wet is the wet bulk rock density mv 1 ϕ is the rock matrix porosity and r the retardation factor a fixed value of 2 69 g cm3 and 0 38 were applied for the wet bulk density and matrix porosity determined from physical property measurements on 15 core samples respectively table 1 a retardation factor of 1 was assumed for fluorescein sabatini and austin 1991 3 2 heat tracer experiments 3 2 1 the active distributed temperature sensing a dts method fiber optic a dts tests record nearly continuous in time the in situ thermal response of the aquifer materials to an infinite line heating source fig 3 variations in the heat transfer rates from the fiber optic cable with integrated heating wires into the formation are attributed to differences in the rock thermal properties and active groundwater flow zones where the a dts calculated apparent thermal conductivity is significantly enhanced over the effective rock thermal conductivity baseline determined from lab measurements of several saturated rock core samples representative of geologic variability correspond to zones of active groundwater flow and the relative magnitude of enhancement corresponds to the magnitude of flow maldaner et al 2019 thus from the continuous a dts data and rock baseline thermal conductivity plots one can infer the position and relative magnitude of active groundwater flow at discrete depths along the full length of the borehole further described below heat tracer experiments using the a dts method in sealed bedrock boreholes to characterize depth discrete hydraulically active groundwater flow features was originally developed by coleman et al 2015 and later improved to allow estimation of groundwater flow rates in discrete fractures by maldaner et al 2019 the method has been demonstrated to be sensitive to changes in fracture flow due to changes in hydraulic gradients in a dolostone aquifer munn et al 2020 this method involves installing a composite fiber optic cable containing optical fibers and heating wires into a borehole temporarily sealing the borehole with a flexible fabric liner cherry et al 2007 keller et al 2014 and conducting a thermal response test by heating the cable and continuously measuring the temperature across distributed intervals 12 6 cm along the full length of the cable using a distributed temperature sensor dts at the surface active groundwater flow causes enhanced heat dissipation and the magnitude and position of this flow can be measured with the dts unit for this investigation the approach was modified for cable deployment in the poorly cemented sandstone where flexible liners were not suitable due to the unstable boreholes therefore instead of directly deploying the cable in a borehole sealed with a liner that pushes the cable against the borehole wall the composite fiber optic cable was attached along the outside surface of a schedule 40 pvc pipe 89 mm od using nylon cable ties spaced 1 5 m apart fig 3 the pvc pipe was lowered in the borehole that was kept open using drilling mud and then it was permanently grouted in place using a bentonite and cement mixture inside the pipe and annular space assuming the pvc pipe is centered in the borehole the fiber optic cable is positioned approximately 5 cm from the borehole wall for the numerical modeling used for flow rate estimation in this study the pvc pipe is assumed to be centered however if this position deviates along the borehole length such that the cable is closer or farther from the borehole wall the modelled relationship may overestimate or underestimate the volumetric flow respectively quantification of the error associated with these geometry changes is underway at the surface the optical fibers were connected to a silixa ultima s dts unit with a 1 8 km maximum range and maximum spatial temporal and temperature resolutions of 29 cm 1 s and 0 01 c respectively the ultima s dts unit provides a sampling resolution of 12 6 cm approximately half of the spatial resolution of the dts unit the two copper conductors were connected to a custom power controller that utilized a silicon controlled rectifier control concepts microfusion the natural background temperature of the borehole was recorded for 30 min before heating the composite cable at 15 w m for 24 h data collected using a dts requires calibration to account for optical attenuation along the fiber and to ensure an accurate absolute temperature output the dts data were collected using the internal double ended calibration routine to account for linear attenuation and an external well mixed calibration bath with 10 m of unheated cable and two pt100 temperature sensors are used for the offset correction smolen and van der spek 2003 provided an overview of dts measurements and calibration routines measurements along the entire cable length were collected every 2 s and later averaged to 180 s readings to achieve a temperature resolution of approximately 0 03 c the final data are reported as temperature differences c above background recorded before heating 3 2 2 apparent thermal conductivity in situ an a dts test can be approximated as a continuous line source problem that allows the estimation of apparent thermal conductivity λa w mk along the borehole wall using an analytical solution presented by carslaw jaeger 1959 p 261 this approach assumes radial heat flow from a continuous and constant line source of power q h w m surrounded by a homogeneous infinite medium using this geometry λa can be estimated using 2 λ a q h 4 π 1 m where 3 m t t 2 t t 1 ln t 2 ln t 1 where m is the slope of temperature t k versus log time t s and is obtained from a linear regression through all temperature measurements at the heat source during the heating portion of the test while the borehole construction and materials introduce some physical and thermal heterogeneities this influence is primarily constrained to the early portions of the heating data to reduce this effect the first 5 h of heating were not included in the analysis and the regression is passed through all the data points between 5 and 24 h this was repeated for each depth interval every 0 126 m and thus a near spatially continuous profile of apparent thermal conductivity can be calculated from an a dts test if the flow is negligible because of low permeability and or insignificant hydraulic gradient heat dissipates from the cable only by conduction and λ a becomes equal to the effective rock thermal conductivity λr w mk in zones with active groundwater flow the λ a will be enhanced above the baseline λ r value by convection processes in addition to conduction 3 2 3 effective rock thermal conductivity the effective thermal conductivity of the saturated rock matrix represents the heat transport flux under a no groundwater flow condition to establish the baseline rock thermal properties the water saturated effective rock thermal conductivity λr was measured on 15 samples from borehole b616 fig 1a from depths between 8 1 and 29 3 m bgs two samples from the grout used to cement the boreholes with the fiber optic cables were sampled for effective thermal conductivity measurements in the lab the measurements were made at the l institut national de la recherche scientifique inrs in quebec city qc canada using a decagon devices kd2 pro thermal properties analyzer and the rk 1 rock sensor kit needle attachment the measurement process consists of temporary removing the plastic seal at the top of the field core samples added at the time of sampling to retain full water saturation drilling a 5 32 in diameter hole using a makita bhr241 hammer drill and inserting the rk 1 probe into the hole with arctic alumina thermal grease the thermal conductivity was measured on each sample four times and standards were used between each sample to ensure accurate readings finally the four measurements were averaged to provide a single value for each sample the thermal conductivity of the cement grout was measured using the same technique and the competent nature of the material allowed additional thermal conductivity testing techniques to be performed using a tcs thermal conductivity scanner 3 2 4 groundwater flow estimation from a dts tests in zones with groundwater flow the apparent thermal conductivity is greater than the effective thermal conductivity baseline for the borehole and surrounding rock the apparent enhancement of the heat transfer rate w calculated from the apparent thermal conductivity w mk is proportional to the groundwater flow rate l day as demonstrated using numerical modeling by maldaner et al 2019 in a permanently grouted borehole the cable is not in direct contact with the borehole wall but rather several materials exist around the fiber optic cable including the pvc pipe the grout and the surrounding rock formation this cable positioning and additional materials decreases the sensitivity and consequently increases the uncertainty of the a dts flow values compared to the more typical installation in temporary sealed bedrock borehole deployment technique reported by maldaner et al 2019 where the cable is installed in direct contact with the rock formation by an inflated borehole liner empirical relationships have been developed for a dts tests using numerical heat transport modeling for the materials and geometry conditions to determine the relationship between the apparent rate of convective heat transport qh conv w and the volumetric flow rate through fractures in a rock with low matrix permeability qflow l day maldaner et al 2019 this allows groundwater flow rates to be estimated from a dts data provided enough information is known about the study site to establish a rock effective thermal conductivity baseline the numerical approach outlined in maldaner et al 2019 was modified to recreate the cable and borehole geometry of this study this was conducted using the finite element numerical model heatflow smoker to represent three dimensional groundwater flow and heat transport in a discretely fractured porous medium molson et al 1992 the full 3 d domain has dimensions of 3 3 2 m with a 0 146 m diameter vertical borehole which is intersected by horizontal planar and continuous fractures the borehole is located at the center of the domain which also includes discretization of the pvc casing with 10 mm thick wall composite fiber optic cables and grouting material fig 4 physical and thermal parameters used to populate the numerical model are presented in table 1 thermal conductivity values for the grout and rock were measured in the lab and the remainder of the values were based on pre existing field or lab measurements or literature values the hydraulic gradient was fixed at 0 01 and the initial and boundary temperatures were set to 18 c which represented the background groundwater temperature at the site an a dts test was simulated using the numerical model and the apparent convective rate of heat transfer qh conv w for each scenario was calculated the scenarios were created by varying the number of fractures in the interval from 1 to 4 fractures and varying the aperture of each fracture from 50 to 500 μm producing 24 different flow rates and corresponding apparent convective rates of heat transport these two properties for each scenario can be plotted against one another and an empirical relationship established thus if one can calculate the apparent rate of convective heat transfer from a field a dts test they can estimate the groundwater flow rate using this relationship due to the multiple model runs required for the range of cable positions in the borehole this paper relies on the centralized condition only but with excellent controls on the rock and grout thermal conductivities to inform the test conditions these estimates of flow are considered approximate and evaluated against other quantitative methods sufficient for the purposes of the study for finding depth discrete preferential pathways and delivery of remediation fluids more robust evaluation of flow uncertainty is considered beyond the scope and objectives of this paper 3 3 groundwater flow estimation from passive flux meter pfm another approach to measure groundwater flow at the site was applied using pfms the pfm is a permeable cylindrical pack of sorbent containing tracers that are placed along a monitoring well screen for quantitation of groundwater and solute fluxes annable et al 2005 basu et al 2006 the pfm sorbent consists of granular activated carbon impregnated with multiple water soluble tracers that desorb at varying rates with groundwater flow through the pfm the tracer mass is used to estimate the average groundwater flux during the deployment period in addition the organic contaminants flowing through the pfm sorb to the activated carbon and the total mass is used to estimate the contaminant flux a more detailed summary of the method is presented in haluska et al 2019 for this study the pfm deployments occurred approximately 2 months after the fluorescein experiment and the a dts test the pfms were segmented into 10 30 cm sections to provide high spatial resolution of mass flux within the 3 to 4 m long well screen intervals rubber disks serving as baffles separate these sections to minimize potential vertical flow inside the pfm and within the well screen in total 10 sections were defined for wells pz 59s pz 60s and 23 sections for well pz 89s fig 1a and c after retrieval the samples of each section were submitted for laboratory analysis of vocs and suite of alcohol tracers as described by annable et al 2005 4 results and discussion 4 1 preferential flow pathways at the end of the 53 day fluorescein tracer injection period continuous core was retrieved from five boreholes b604 b606 b607 b609 b610 drilled downgradient from the injection well pz 89s fig 1b fluorescein was not observed along the external edge of the cores indicating minimal cross contamination during core drilling or during retrieval and handling at the surface before each core was frozen the core photos taken under uv light clearly show positions with presence of the fluorescein tracer in both the rock matrix and along preferential pathways fig 5 the continuous presence of fluorescein in the core samples from 10 to 15 m bgs in borehole b604 located 1 5 m away from the injection well pz 89s screened at the same elevation indicate evidence of flow in both matrix and along preferential pathways matrix flow seems to occur primarily in intervals with poor cementation which is evidenced by the lack of fluorescein in intervals of harder cementation fig 5a the presence of fluorescein in the matrix is less evident with increasing distance from the injection well deeper in borehole b604 some intervals also showed presence of fluorescein with a strong detection at 18 5 m bgs where fluorescein was also visually observed under uv light these depths are well below the injection depth in pz 89s suggesting hydraulic connectivity through preferential pathways to these depths or possibly vertical migration through the borehole from hydraulic cross connection in general the core sample porewater fluorescein analyses agreed with the visual evidence but fluorescein was detected in porewater samples in intervals where fluorescein was not visually apparent fig 6 suggesting deeper penetration of fluorescein into the aquifer matrix than was apparent based on visual observation the profiles presenting fluorescein concentration in porewater show that for distances 4 5 m the tracer is only detected within and near preferential pathways in four of the boreholes fluorescein was detected in the interval from 10 5 12 m bgs indicating connected preferential flow pathways in this interval the tracer visible at these features present evidence of advection and diffusion into the rock matrix on either side of the preferential pathways surface thus flow through preferential pathways appears to allow more rapid transport and a farther travel distance than the aquifer matrix at the time of sampling four core holes were sampled and analyzed for tce in the rock core porewater fig 6 a description of the rock core sampling and analysis approach can be found in goldstein et al 2004 and in parker et al 2012 borehole b504 located 2 9 m away from the injection well pz 89s was cored before the fluorescein injection experiment boreholes b604 b606 and b607 were cored after the injection experiment and located 1 5 4 4 and 5 9 m away from the injection well respectively based on borehole b504 data representing the conditions before the tracer injection most of the tce mass was stored between 10 and 17 m bgs after the injection tce was not detected within this interval in the borehole closest to the injection well b604 1 5 m away where relatively uniform delivery of fluorescein was observed also the boreholes that are further away b606 and b607 4 4 and 5 9 m respectively have measurable tce within the 10 17 m interval however each has thin zones within this interval where the tce concentrations are below detection these thin intervals correspond with the intervals of relatively elevated fluorescein concentrations fig 6 the presence of fluorescein and the lack of tce in borehole b604 suggests that the injection of the fluorescein tracer may have displaced the matrix porewater containing tce from these intervals this flushing effect is observed in both the matrix and preferential flow paths near the injection well and only near preferential pathways farther away 4 5 m from the injection well the displacement of tce might have been caused by the enhanced hydraulic gradients and groundwater velocities during the injection period relative to the ambient gradient conditions 4 2 groundwater flow rates from a dts test 4 2 1 rock baseline thermal conductivity the rock thermal conductivity baseline provides constraint of the no flow thermal conditions of the aquifer materials the results of the laboratory effective rock thermal conductivity measurements in 15 samples from borehole b616 show reasonably consistent values with depth with minimum and maximum of 1 62 and 2 41 w mk respectively average of 2 06 w mk and a standard deviation of 0 19 w mk the low range of effective rock thermal conductivity values becomes evident when plotted as profile with different lithological units identified fig 7 the cement and bentonite mix grout used to permanently install the fiber optical cable in borehole b504 provided an effective thermal conductivity of 1 08 w mk lower than the surrounding rock values the bulk effective thermal conductivity of all materials surrounding the cable such as the standing pipe plastic the injected grout and the formation sediments controls the heat dissipation from the composite fiber optic cable therefore the low thermal conductivity of the materials surrounding the fiber optic cable in this type of deployment decreases the sensitivity to the thermal signal created by the enhanced heat dissipation due to groundwater flow surrounding the borehole in comparison to maldaner et al 2019 for this study the fiber optic cable was permanently grouted in the borehole therefore the effective bulk thermal conductivity value representing a no groundwater flow condition of 1 74 w mk was estimated using a numerical modeling scenario including all the different thermal properties and the geometry of the deployment this included the materials surrounding the cable such as pvc standpipe grout and sediments and a no flow condition established by setting the hydraulic gradient to zero fig 4 estimating the effective bulk thermal conductivity for the deployment is important because it is assumed that any value of apparent thermal conductivity measured above this threshold will be considered due to groundwater flow 4 2 2 relationship between in situ apparent thermal conductivity and groundwater flow the approach to estimate groundwater flow from a dts tests is based on the empirical relationship between apparent convective rate of heat transfer and groundwater flow rates as proposed by maldaner et al 2019 the relationship is obtained from site specific numerical modeling by calculating values of apparent convective rate of heat transfer for each groundwater flow scenario imposed to the model the relationship is then applied to the apparent convective rate of heat transfer values obtained from a dts tests obtained at the study site in total 24 modeling scenarios using a range of groundwater flow rates provide an empirical relationship between the apparent convective rate of heat transport qh conv w and groundwater flow rate through the fractures qflow l day fig 8 a linear regression through all the data points was used to establish the empirical relationship 4 q flow 86 16 q h conv w f where 5 q h conv q h total 1 λ r λ a λ a λ r and w f is a transverse fracture width of interest m which for eq 4 is equal to 1 m thus to compare a dts flow estimates to those obtained using a borehole dilution system the flow value needs to be scaled to the effective cross section area for flow q h total is the power output and is calculated by taking the line source power output w m times interval height m e g the dts sampling resolution 12 6 cm thus if one knows the power output from the heating cable the apparent thermal conductivity from the a dts measurements and the rock thermal conductivity from lab measurements a volumetric flow rate q flow can be estimated for a cross sectional flow area which in this case is calculated using a 1 m wide fracture times the interval height the darcy velocity can then be estimated by dividing q flow by the interval height so the results could be compared with the passive flux meter pfm velocity estimates it is important to note that this empirical relationship is somewhat site specific in that it was developed using the borehole geometry the specific thermal properties of those materials and the heating output and duration to match the field experiments the constant in eq 4 is larger than the relationship presented by maldaner et al 2019 for the fractured dolostone in guelph canada this is caused mainly by the cable deployment differences between the installation in this study and that using a flexible borehole liner in this study the cable is set back from the borehole wall approximately 5 cm and encased in a low effective thermal conductivity cement bentonite grout 1 08 w mk and also by the lower thermal conductivity of the sandstone at the study site in contrast with the dolostone 2 06 w mk vs 4 0 w mk respectively 4 2 3 field a dts test and apparent thermal conductivity profile temperature evolution was monitored continuously during the 24 h a dts test in borehole b604 and temperature difference above ambient was calculated by subtracting the background temperature fig 7 the background temperature decreases from 20 to 17 c from the top to the bottom of the borehole a temperature increase near 13 m bgs can be observed due to the warm tracer solution injected in well pz 89s screened from 10 2 14 8 m bgs during the a dts test the temperature inside the heated fiber optic cable increases at variable rates at different depths along the borehole with maximum final temperature differences over ambient of 11 22 c fig 7 the variable temperature differences is caused by a combination factors including degree of water saturation that occurs at the top of the borehole variation of the rock thermal properties with depth and heterogeneous groundwater flow along the tested profile one way to interpret the rate of temperature increase during a dts tests is by calculating the apparent thermal conductivity profile which is proportional to the rate of temperature change maldaner et al 2019 for the current deployment the estimated baseline no flow effective thermal conductivity is estimated to be around 1 74 w mk based on the a dts apparent thermal conductivity profile 7 intervals a to g are highlighted in borehole b604 that represent enhancements above this baseline fig 7 interval a shows higher temperature differences of 20 c above background and apparent thermal conductivity values below the baseline caused by the unsaturated hydraulic conditions interval b presents temperature difference values ranging from 16 to 18 c with all apparent thermal conductivity values above the baseline indicating presence of groundwater flow evidence of flow through preferential pathways occurs at depths where the thermal conductivity profile spikes such as at 14 0 15 2 and 17 0 m bgs at this same depth interval interval b the results from the fluorescein tracer pore water analysis in corehole b604 fig 6 demonstrate flow in the rock matrix and the uv core pictures show the tracer along preferential flow paths corroborating the a dts results below 20 m bgs the apparent thermal conductivity profile behavior changes with evidence of stronger heat dissipation only at depth discrete intervals see intervals c e and f in fig 7 interval d presents apparent thermal conductivity values equal or below the baseline indicating limited groundwater flow based on the physical characteristics of the rock such as the poorly cemented nature of the matrix particularly in the upper half of the sequence there is likely some component of flow through the matrix as well suggesting a dual porosity dual permeability system with some degree of flow through both preferential pathways and matrix the results from the fluorescein tracer tests support the a dts results interpretation and reinforce that the adapted a dts method to poorly cemented formations using grouted fiber optic cables can provide meaningful data in an efficient way 4 2 4 groundwater flow from in situ a dts test based on the a dts apparent thermal conductivity profile obtained in borehole b604 and the relationship obtained between the rate of heat dissipation and groundwater flow eqs 4 and 5 the flow rates q flow estimated from a dts apparent thermal conductivity vary from 2 to 24 l day with average and median values of 11 and 7 l day respectively the darcy flux estimated by dividing the flow rate values by the height of the integrated interval and unit width ranged from 7 to 60 cm day with average and median values of 23 and 17 cm day respectively the absolute flow rate from a dts tests requires application of an empirical relationship developed from numerical model scenarios of groundwater flow and heat transport eq 4 this modeling effort requires simplifications or idealities relating to the borehole deployment geometry and flow conditions deviation of real world conditions from these idealities results in some uncertainty in the flow estimates for example the numerical model assumes the cable is affixed to the pvc pipe and the pipe is centered in the borehole if the actual cable is in fact closer to the borehole wall at certain depths the empirical relationship developed from numerical modeling would overestimate flow despite these simplifications the relationship between the rate of heat dissipation and groundwater flow presented by maldaner et al 2019 and the a dts method is currently the only method that provides a full profile of groundwater flow rates and velocities under natural gradient conditions if a dts measurements are performed over time the method can provide a temporal dataset of groundwater flow rate changes that could be related to recharge events or changes in boundary conditions such as pumping of nearby wells this application of the method to temporal changes was assessed by a sensitivity test where the hydraulic condition of the field site was changed and fully captured by the a dts method munn et al 2020 such data would provide a robust means to refine and test conceptual site models 4 3 groundwater velocity and mass flux from passive flux meter pfm passive flux meters pfm were deployed in three conventional monitoring wells pz 59s pz 60s and pz 90s fig 1a pz 90s is located 3 m away from the fluorescein tracer injection well and the deployment of the pfms occurred 2 months after the end of the tracer injection the estimated groundwater fluxes from the pfms range from 2 to 11 cm day with an overall average of 4 cm day fig 9 it is assumed that these darcy fluxes correspond to horizontal flow in the formation under natural gradient conditions monitoring well pz 59s shows a relatively uniform flux distribution 2 4 cm day along the screened interval with slightly slower fluxes at the center of the profile and close to the contact between the upper sandy unit and the lower silty sand unit pz 60s presents a groundwater flux in the sandy unit around 2 cm day and it increases with depth to 4 8 cm day at the contact with the silty sand unit with the highest values centered around 12 7 m bgs in the upper portion of silty sand unit in general the highest fluxes are observed in pz 90s 4 6 cm day the darcy fluxes calculated from the a dts data along the same interval shows a relatively uniform value 16 cm day within the upper 3 m 10 13 m bgs and an increase in flux up to 25 cm day in the silty sand unit fig 9 the higher a dts fluxes of 16 cm day compared with the average pfm velocity of 4 cm day could be the result of actual flow differences between locations i e lateral spatial variability temporal variability and or due to uncertainties specific to both methods specifically it is worth noting the nature of sand packs in conventional wells where the pfms were deployed could be a major contributor to lower darcy flux values with this technique the geometry and permeability of typical sand packs in conventional wells will homogenize flow over the depth of the sand pack and vertically blend horizontal preferential flow paths slowing down depth discrete flow in higher flow intervals and resulting in a vertically homogeneous and dampened velocity profile underestimation of groundwater velocities using pfm was observed in a groundwater surface water discharge study when compared to point velocity probes ottosen et al 2020 alternatively the variation in the a dts flow estimates resulting from variation in cable positioning in the borehole contributes some uncertainty not yet quantified both methods are complementary in that they provide a sense of the position nature and relative magnitude of flow contaminant mass flux provides a useful means to assess contaminant migration and risk to offsite receptors as well as provide horizons to focus remediation efforts the tce mass fluxes estimated from the pfm results provide information about the vertical contaminant distribution and transport rates which is variable among the three wells where pfms were deployed fig 9 tce was detected in the extracts from pfm intervals in pz 59s 7 94 μg l and pz 60s 4 162 μg l while only at the upper portion 10 7 11 7 m bgs of pz 90s 1 11 μg l in well pz 59s the bulk of the tce mass is distributed from the upper sand unit down to the contact with the silty sand unit the higher tce concentration at 12 25 m bgs corresponds to an interval with lower darcy velocity therefore the tce flux is not as high as at 11 m bgs 0 05 mg m2 day in well pz 60s most of the tce mass is in the lower silty sand unit that corresponds to the interval with the highest darcy flux resulting in largest tce mass flux 0 17 mg m2 day among all three wells the pfm results from pz 90s show low tce mass flux 0 002 mg m2 day in comparison to the other wells since this well is located near the fluorescein tracer injection well and the pfms were deployed after the tracer experiment the results suggest that the injected tracer fluid was able to displace the matrix porewater due to lower but appreciable matrix permeability at least under forced gradient conditions the tce porewater concentrations in borehole b604 also located near the injection well are mostly non detect supporting the hypothesis that tce mass was largely removed from this portion of the aquifer by the fluorescein tracer injection process fig 6 4 4 site conceptual model and implications on the remediation strategy variable groundwater flow rates through different pathways are identified in this study from multiple methods including visual inspection of continuous core porewater analysis in rock core samples a dts tests and passive flux meters at 1 5 m from the injection well fluorescein was visually observed in numerous discrete intervals and in the rock matrix and confirmed with porewater lab analysis these results suggest advective flow through preferential pathways and slower advective flow rates in the rock matrix slightly further from the injection well at 4 5 6 m fluorescein was only observed in a few discrete intervals indicating groundwater radiated farther away at a higher velocity through discrete preferential pathways with higher permeability than through the rock matrix these preferential pathways were also identified in the a dts results as zones of enhanced heat dissipation thus groundwater flow at the site is consistent with a dual porosity dual permeability system with slower advective groundwater flow within the rock matrix and faster flow within preferential pathways fluorescein was effectively delivered through preferential pathways to distances of up to 6 m from the injection well within less than a 1 month period however within the less permeable zones i e matrix this distance was about 3 5 m during the same timeframe based on these results a 3 5 m travel distance of amendments is the conservative estimate for designing an in situ remediation injection well gallery therefore a 7 m spacing of injection wells is recommended these results support that the injection of amendments will likely result in a fast wide and quasi uniform distribution due to preferential flow in the depth discrete features and reasonable rock matrix permeability since in situ chemical oxidation isco relies upon contact of amendment with the vocs to be successful it is a critical finding that the slower advection in the rock matrix can occur in a timeframe during injection that makes isco a cost effective remedial option nevertheless it would be prudent to design the amendment injection phases with enough time between them to allow the variable advection with transverse diffusion to enhance delivery into the lower permeability zones it will be important from a performance monitoring standpoint to have a monitoring approach that provides sufficient spatial resolution and temporal frequency to distinguish between delivery through preferential flow pathways and variable rates of advection and diffusion into the rock matrix that can evaluate variable delivery rates an important question for evaluating the potential effectiveness of an in situ remediation method is whether untreated portions of the aquifer could represent an on going source of contamination due to high amounts of contaminant storage no measurable tce mass discharge was observed in any of the pfm segments from well pz 90s suggesting that the potential for back diffusion might be minimal at this site when effective delivery of voc free fluids to the aquifer is accomplished 5 conclusions a combination of tracer experiments was performed under both natural and forced gradient conditions at an industrial site with tce contamination to inform in situ remediation strategies fluorescein tracer injection followed by high resolution coring and subsampling for porewater concentrations showed preferential groundwater flow along discrete features but some tracer penetration in the rock matrix by slower advective flow because boreholes installed in the poorly cemented sandstone aquifer were unstable it was not possible to perform a dts testing using the traditional deployment method using a flexible borehole liner therefore a novel approach to deploy the fiber optic cable for a dts testing was developed wherein the cable was attached to the outside of pvc casing lowered into the borehole and permanently grouted in place the a dts heat tracer experiment showed hydraulic variability at different depths under natural gradient conditions suggested enhanced flow through preferential pathways and secondary flow through the rock matrix these results were compared to flow velocities from in well passive flux meters with reasonable agreement and are most consistent with a dual porosity dual permeability system the observation that preferential pathways are laterally and vertically connected and that the tce can be relatively quickly removed from the high permeability layers improves the understanding of the groundwater flow and transport site conceptual model the tracer was able to move farther and faster through preferential pathways and more slowly through the permeable matrix this study informs the remediation injection well spacing of 7 m based on extent of the tracer in the laterally connected preferential pathways and in the rock matrix it also provides insights on delivery of remediation amendments to the contaminated portion of the aquifer by allowing time between injection periods for amendments to penetrate the rock matrix by minor advection and diffusion processes from the preferential pathways the data from this study provided the means to develop an evidence based remediation approach that informed design and spacing of future injection wells built confidence that in situ remediation could be effective despite the observed groundwater flow path heterogeneity and managed expectations of stakeholders on performance outcomes and timeframes for completion declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we appreciate the constructive comments from two anonymous reviewers field and logistical support was provided by vincent durand melanie caperan and lucas flavien antea france and paula pryor and erica bosse sanborn head associates inc and data analysis support from sean murphy sanborn head associates professor jasmin raymond and mafalda miranda inrs quebec city canada provided access and support with the laboratory thermal conductivity measurements wayne noble g360 institute for groundwater research guelph canada lead the laboratory fluorescein measurements on core samples funding for this study was provided by the study site owner 
1428,this study applies innovative methods to characterize and quantify the magnitude of groundwater flow in a fractured and variably cemented sandstone aquifer to inform an in situ remediation strategy for trichloroethene tce contamination a modified active distributed temperature sensing a dts approach in which fiber optic cables were permanently grouted in the borehole was used to quantify groundwater flow rates two additional tracer tests were conducted 1 fluorescein tracer injection followed by rock coring and sampling for visual mapping and porewater analysis and 2 deployment of passive flux meters in conventional monitoring wells to evaluate groundwater velocity and mass flux distributions forced gradient injection of fluorescein tracer suggests a dual porosity flow system wherein higher rates of groundwater flow occur within discrete features including highly permeable bedding planes and fractures with slower flow occurring within the rock matrix tracer was observed and detected in the unfractured matrix porewater 1 5 m away from the injection well beyond this distance 6 m radially away from the injection hole tracer was primarily detected within and adjacent to high transmissivity fractures serving as preferential flow paths the darcy flux calculated using active distributed temperature sensing a dts shows depth discrete values ranging from 7 to 60 cm day with average and median values of 23 and 17 cm day respectively passive flux meters pfms deployed in three conventional monitoring wells with slotted screens and sand filter packs showed groundwater flux values ranging from 2 to 11 cm day with an overall average of 4 cm day and are likely biased low due to spreading in the sand pack the study results were used to inform an in situ remediation system design including the proposed injection well spacing and the amendment delivery approach in addition the results were used to build confidence in the viability of delivering an oxidant to the rock matrix via advective processes this is important because 1 the matrix is where the majority of the tce mass occurs and 2 it provides insights on processes that directly affect remedial performance expectations given advective delivery to preferential pathways and the matrix overcomes diffusion only conditions keywords ambient groundwater flow rates poorly cemented sandstone preferential flow active distributed temperature sensing passive flux meter fluorescein tracer injection experiment dual permeability 1 introduction many urban centers overlie sedimentary rock aquifers and rely upon them for their municipal water supply sedimentary rocks often form highly transmissive aquifers with excellent natural water quality but can be susceptible to contamination due to their proximity to surface and high groundwater velocity through fractures contaminant migration rates through these aquifers can be slowed relative to average groundwater velocities due to transverse advection and diffusion into the lower permeability matrix zones between fractures these processes are known to retard plume front migration and delay the arrival of dissolved contaminants to receptors supply wells and surface water but to some extent is site specific nas 2015 a lower permeability matrix leads to persistent contamination that is difficult to flush by advective methods e g pump and treat which predominately flush groundwater from fractures this is due to lower permeability in the matrix in which diffusion often dominates transport as a result they represent some of the most difficult aquifer types to remediate nrc 2013 kueper et al 2014 due to slow rates of back diffusion from the matrix to the fracture consideration of methods to facilitate in situ contaminant destruction or degradations is required hence delivery of amendments in both preferential flow pathways and in the lower permeability matrix zones where the majority of contaminant mass typically resides is desired it is critical to identify the distribution of contaminants relative to the position of various flow pathways in the bedrock and determine the rate of groundwater flow and contaminant transport to design remediation delivery of amendments and estimate timeframes for monitoring and completion suthersan et al 2016 characterizing and acknowledging the aquifer heterogeneity is necessary for the implementation of advanced amendment delivery methods cho et al 2019 in variably cemented sandstone aquifers identifying these flow pathways can be challenging because flow can occur both within fractures and within less permeable poorly cemented intervals in the rock matrix since the bulk of contaminant mass typically resides in the rock matrix due to its larger porosity and mass storage capacity it is important for the amendments to easily penetrate the matrix to enhance remediation effectiveness this can be achieved through diffusion of the amendments into the matrix from closely spaced fractures or from advection into the matrix if there is sufficient permeability and gradient this study applies innovative methods in a fractured and variably cemented sandstone aquifer to identify the nature of the groundwater flow in both discrete fracture zones and matrix and quantify the magnitude and variability of groundwater flow to inform an in situ remediation strategy for decades old tce contamination the nature and extent of this tce plume has been well defined in previous investigations using continuous wireline coring high frequency rock core sampling and porewater contaminant analysis and multilevel groundwater monitoring systems however the nature and magnitude of groundwater flow was not well understood and is critical information for successful application of an in situ remediation approach characterizing groundwater flow in bedrock aquifers is challenging because flow is dominated by small sparsely distributed and variably transmissive fractures berkowitz 2002 neuman 2005 nrc 2013 nas 2015 or in the case of poorly cemented sandstones within both fractures and variably cemented sediment matrix characterizing fracture distribution extent and their interconnectivity can be critical to remediation system design parker et al 2018 historically hydraulically active fractures were inferred by visual inspection of core and geophysical logs or open hole fluid logging however recently many new approaches have been used with higher sensitivity to identify active flow zones in bedrock boreholes under both open and sealed conditions parker et al 2012 for examples active heat has been used as a tracer to inform water flow within a borehole by trolling temperature sensors inside an open or sealed borehole condition pehme et al 2010 2013 or by using fiber optic distributed temperature sensing methods in a variety of configurations summarized by bense et al 2016 borehole flow metering under ambient and pumped conditions provide the position transmissivity and interconnectivity of fractures e g paillet 1993 williams and paillet 2002 however it is advantageous to characterize flow under natural gradient conditions without the influence of hydraulic cross connection from an open borehole or a long screen monitoring well intersecting multiple hydrogeological units pehme et al 2010 parker et al 2018 several established and emerging methods can measure ambient flow under natural gradient conditions by isolating sections of an open bedrock borehole examples include the in well point velocity probe iwpvp that provides groundwater velocity at a centimeter scale osorno et al 2018 and tracer dilution experiments that can be performed in test intervals isolated by straddle packers at a centimeter to meter scale jamin et al 2015 maldaner et al 2018 passive flux meters are another technology that relies on a suite of tracers with variable transport properties that can be deployed in conventional monitoring wells with intervals isolated by rubber disks to estimate depth discrete groundwater and contaminant mass flux annable et al 2005 klammer et al 2016 or between packers in open rock boreholes in addition boreholes have been temporarily sealed with impermeable and flexible borehole liners to allow wireline trolling of high resolution temperature sensors inside the static water column under ambient and actively heated conditions to identify depth discrete hydraulically active flow locations pehme et al 2013 2014 advancements in fiber optic distributed temperature sensing a dts have allowed estimation of groundwater flow under natural gradient conditions when combined with direct push methods to directly install the fiber optic cables in unconsolidated sediments liu et al 2013 bakker et al 2015 or by deploying cables in temporary sealed bedrock boreholes using borehole liners coleman et al 2015 maldaner et al 2019 munn et al 2020 in poorly cemented bedrock or in unconsolidated overburden deposits several of the methods above may not be suitable or practicable direct push and borehole liner methods may not be feasible since the rock is too competent for direct push methods and too unstable for the borehole to remain open during the installation and removal of borehole liners this provides challenges for most of the methods mentioned above therefore in this study a modified approach was applied and tested in which fiber optic cables attached to blank pvc well casing were permanently grouted in place in the borehole to provide complementary datasets for comparison two tracer tests were conducted 1 fluorescein tracer injection followed by rock coring and sampling for porewater analysis to determine the tracer distribution and 2 deployment of the passive flux meter in conventional monitoring wells to evaluate the in situ groundwater velocity and mass flux distributions at different depths this study aims to identify the position and variability of flow pathways in a poorly cemented fractured sandstone using different methods for comparison to estimate groundwater flow rates that can later inform the design of an in situ remediation system 2 study site the study area is a former industrial facility that operated from 1965 to 2009 in southern france as shown in fig 1 volatile organic compounds vocs primarily trichloroethene tce have been identified in two separate areas referred to as the northern and southern areas the southern area plume is being addressed via a groundwater pumping and treatment system see extraction wells ew 1 and ew 2 on fig 1 the northern area was subjected to high resolution investigations fig 1b including continuous wireline coring and high frequency rock core sampling for voc analysis and installation of conventional and continuous multichannel tubing cmt multilevel systems einarson and cherry 2002 these higher resolution characterization and monitoring datasets led to an improved understanding of tce mass distributions in the plume above and below the water table with rock core tce concentrations of up to 456 μg kg and groundwater concentrations of up to 1000 μg l in the shallow units located 10 15 m below ground surface bgs fig 1c the lithostratigraphic units identified at the study site are presented in fig 1c at the ground surface a 2 m granular fill and or clayey sand layer overlies an approximately 2 m thick silt and clay interval that overlies the pliocene aged sandstone units of the astien formation at the study site the astien formation has been subdivided into shallow intermediate deep and very deep layers shallow and intermediate portions are generally unconsolidated or poorly cemented sandstone with gravely lenses and limited calcareous cementation the deep and very deep portions are moderate to highly cemented and are typically described as bedrock in the northern area the depth to groundwater is generally 10 m bgs and groundwater flows in a west southwest direction there is visual evidence of preferential flow paths from detailed inspection of core logs in the unconsolidated shallow aquifer and these features become more prominent and frequent within the increasingly competent intermediate and deep astien formation units 3 methods multiple field methods were applied including injection of a conservative tracer fluorescein under forced gradient conditions that is typical of in situ remediation fluid injections active heat tracer tests using fiber optic cables with distributed temperature sensing a dts using a modified borehole deployment technique and passive flux meter pfm measurements in conventional monitoring wells under natural gradient conditions these are presented in more detail below 3 1 tracer injection experiment a fluorescein tracer injection was performed using a total of 117 m3 of tracer solution with concentration of 100 000 μg l the solution was injected into monitoring well pz 89s screened from 11 to 14 m bgs at an average flow rate of 1 4 l min for 53 days by gravity using a hydraulic head difference of around 10 m periodic groundwater samples for field screening and laboratory analysis of fluorescein were performed at nearby conventional and multi level monitoring wells following the 53 day injection period five 14 6 cm outer diameter boreholes b604 b606 b607 b609 b610 were drilled using a pq wireline coring with diamond bit at distances ranging from 1 5 to 5 9 m from the injection well fig 1b and c each core run 8 5 cm diameter and 1 5 m long was retrieved inside a plastic liner divided in half into two 0 75 m long pieces capped and frozen on site shortly after collection using dry ice in a large insulated container fig 2a after at least 2 h the frozen cores were scored lengthwise on both sides to a depth of approximately 2 cm using a circular saw with a masonry blade in a wooden guide and then split in half using chisels and a mallet fig 2b and c scoring and manually splitting the core rather than cutting all the way through provided an interior less disturbed surface that more clearly portrayed the rock texture and sediment structures for geologic logging that were less visible on the cut surface fig 2d after splitting the cores were left to partially thaw before they were photographed under ambient and ultraviolet uv light for fluorescein tracer observations the cores were covered with a black tarp during the thawing period to prevent degradation of the fluorescein dye by exposure to sunlight thawing the core was important to avoid the formation of ice crystals from moist air condensing and freezing on the core surface that masked the fluorescein and sediment structures to detect the presence of fluorescein at concentrations below visual detection core samples were collected for porewater fluorescein laboratory analysis at an average sample frequency of four samples per meter targeting zones in and around zones of visual fluorescein detection samples were comprised of an average of 13 g of the rock sediments added to 40 ml glass vials with 20 ml of water as an extractant in the lab the samples were shaken centrifuged and fluorescein concentrations were analyzed using an agilent cary eclipse fluorescence spectrophotometer with a method detection limit mdl of 0 3 μg l the resulting fluorescein concentration in the extractant mv 1 was converted to porewater concentration mv 1 using the following equation 1 c aq m t ρ b wet ϕr where m t is the total mass of fluorescein per unit mass of rock mm 1 which is calculated from the extract concentration mass of rock sample and volume of extractant ρ b wet is the wet bulk rock density mv 1 ϕ is the rock matrix porosity and r the retardation factor a fixed value of 2 69 g cm3 and 0 38 were applied for the wet bulk density and matrix porosity determined from physical property measurements on 15 core samples respectively table 1 a retardation factor of 1 was assumed for fluorescein sabatini and austin 1991 3 2 heat tracer experiments 3 2 1 the active distributed temperature sensing a dts method fiber optic a dts tests record nearly continuous in time the in situ thermal response of the aquifer materials to an infinite line heating source fig 3 variations in the heat transfer rates from the fiber optic cable with integrated heating wires into the formation are attributed to differences in the rock thermal properties and active groundwater flow zones where the a dts calculated apparent thermal conductivity is significantly enhanced over the effective rock thermal conductivity baseline determined from lab measurements of several saturated rock core samples representative of geologic variability correspond to zones of active groundwater flow and the relative magnitude of enhancement corresponds to the magnitude of flow maldaner et al 2019 thus from the continuous a dts data and rock baseline thermal conductivity plots one can infer the position and relative magnitude of active groundwater flow at discrete depths along the full length of the borehole further described below heat tracer experiments using the a dts method in sealed bedrock boreholes to characterize depth discrete hydraulically active groundwater flow features was originally developed by coleman et al 2015 and later improved to allow estimation of groundwater flow rates in discrete fractures by maldaner et al 2019 the method has been demonstrated to be sensitive to changes in fracture flow due to changes in hydraulic gradients in a dolostone aquifer munn et al 2020 this method involves installing a composite fiber optic cable containing optical fibers and heating wires into a borehole temporarily sealing the borehole with a flexible fabric liner cherry et al 2007 keller et al 2014 and conducting a thermal response test by heating the cable and continuously measuring the temperature across distributed intervals 12 6 cm along the full length of the cable using a distributed temperature sensor dts at the surface active groundwater flow causes enhanced heat dissipation and the magnitude and position of this flow can be measured with the dts unit for this investigation the approach was modified for cable deployment in the poorly cemented sandstone where flexible liners were not suitable due to the unstable boreholes therefore instead of directly deploying the cable in a borehole sealed with a liner that pushes the cable against the borehole wall the composite fiber optic cable was attached along the outside surface of a schedule 40 pvc pipe 89 mm od using nylon cable ties spaced 1 5 m apart fig 3 the pvc pipe was lowered in the borehole that was kept open using drilling mud and then it was permanently grouted in place using a bentonite and cement mixture inside the pipe and annular space assuming the pvc pipe is centered in the borehole the fiber optic cable is positioned approximately 5 cm from the borehole wall for the numerical modeling used for flow rate estimation in this study the pvc pipe is assumed to be centered however if this position deviates along the borehole length such that the cable is closer or farther from the borehole wall the modelled relationship may overestimate or underestimate the volumetric flow respectively quantification of the error associated with these geometry changes is underway at the surface the optical fibers were connected to a silixa ultima s dts unit with a 1 8 km maximum range and maximum spatial temporal and temperature resolutions of 29 cm 1 s and 0 01 c respectively the ultima s dts unit provides a sampling resolution of 12 6 cm approximately half of the spatial resolution of the dts unit the two copper conductors were connected to a custom power controller that utilized a silicon controlled rectifier control concepts microfusion the natural background temperature of the borehole was recorded for 30 min before heating the composite cable at 15 w m for 24 h data collected using a dts requires calibration to account for optical attenuation along the fiber and to ensure an accurate absolute temperature output the dts data were collected using the internal double ended calibration routine to account for linear attenuation and an external well mixed calibration bath with 10 m of unheated cable and two pt100 temperature sensors are used for the offset correction smolen and van der spek 2003 provided an overview of dts measurements and calibration routines measurements along the entire cable length were collected every 2 s and later averaged to 180 s readings to achieve a temperature resolution of approximately 0 03 c the final data are reported as temperature differences c above background recorded before heating 3 2 2 apparent thermal conductivity in situ an a dts test can be approximated as a continuous line source problem that allows the estimation of apparent thermal conductivity λa w mk along the borehole wall using an analytical solution presented by carslaw jaeger 1959 p 261 this approach assumes radial heat flow from a continuous and constant line source of power q h w m surrounded by a homogeneous infinite medium using this geometry λa can be estimated using 2 λ a q h 4 π 1 m where 3 m t t 2 t t 1 ln t 2 ln t 1 where m is the slope of temperature t k versus log time t s and is obtained from a linear regression through all temperature measurements at the heat source during the heating portion of the test while the borehole construction and materials introduce some physical and thermal heterogeneities this influence is primarily constrained to the early portions of the heating data to reduce this effect the first 5 h of heating were not included in the analysis and the regression is passed through all the data points between 5 and 24 h this was repeated for each depth interval every 0 126 m and thus a near spatially continuous profile of apparent thermal conductivity can be calculated from an a dts test if the flow is negligible because of low permeability and or insignificant hydraulic gradient heat dissipates from the cable only by conduction and λ a becomes equal to the effective rock thermal conductivity λr w mk in zones with active groundwater flow the λ a will be enhanced above the baseline λ r value by convection processes in addition to conduction 3 2 3 effective rock thermal conductivity the effective thermal conductivity of the saturated rock matrix represents the heat transport flux under a no groundwater flow condition to establish the baseline rock thermal properties the water saturated effective rock thermal conductivity λr was measured on 15 samples from borehole b616 fig 1a from depths between 8 1 and 29 3 m bgs two samples from the grout used to cement the boreholes with the fiber optic cables were sampled for effective thermal conductivity measurements in the lab the measurements were made at the l institut national de la recherche scientifique inrs in quebec city qc canada using a decagon devices kd2 pro thermal properties analyzer and the rk 1 rock sensor kit needle attachment the measurement process consists of temporary removing the plastic seal at the top of the field core samples added at the time of sampling to retain full water saturation drilling a 5 32 in diameter hole using a makita bhr241 hammer drill and inserting the rk 1 probe into the hole with arctic alumina thermal grease the thermal conductivity was measured on each sample four times and standards were used between each sample to ensure accurate readings finally the four measurements were averaged to provide a single value for each sample the thermal conductivity of the cement grout was measured using the same technique and the competent nature of the material allowed additional thermal conductivity testing techniques to be performed using a tcs thermal conductivity scanner 3 2 4 groundwater flow estimation from a dts tests in zones with groundwater flow the apparent thermal conductivity is greater than the effective thermal conductivity baseline for the borehole and surrounding rock the apparent enhancement of the heat transfer rate w calculated from the apparent thermal conductivity w mk is proportional to the groundwater flow rate l day as demonstrated using numerical modeling by maldaner et al 2019 in a permanently grouted borehole the cable is not in direct contact with the borehole wall but rather several materials exist around the fiber optic cable including the pvc pipe the grout and the surrounding rock formation this cable positioning and additional materials decreases the sensitivity and consequently increases the uncertainty of the a dts flow values compared to the more typical installation in temporary sealed bedrock borehole deployment technique reported by maldaner et al 2019 where the cable is installed in direct contact with the rock formation by an inflated borehole liner empirical relationships have been developed for a dts tests using numerical heat transport modeling for the materials and geometry conditions to determine the relationship between the apparent rate of convective heat transport qh conv w and the volumetric flow rate through fractures in a rock with low matrix permeability qflow l day maldaner et al 2019 this allows groundwater flow rates to be estimated from a dts data provided enough information is known about the study site to establish a rock effective thermal conductivity baseline the numerical approach outlined in maldaner et al 2019 was modified to recreate the cable and borehole geometry of this study this was conducted using the finite element numerical model heatflow smoker to represent three dimensional groundwater flow and heat transport in a discretely fractured porous medium molson et al 1992 the full 3 d domain has dimensions of 3 3 2 m with a 0 146 m diameter vertical borehole which is intersected by horizontal planar and continuous fractures the borehole is located at the center of the domain which also includes discretization of the pvc casing with 10 mm thick wall composite fiber optic cables and grouting material fig 4 physical and thermal parameters used to populate the numerical model are presented in table 1 thermal conductivity values for the grout and rock were measured in the lab and the remainder of the values were based on pre existing field or lab measurements or literature values the hydraulic gradient was fixed at 0 01 and the initial and boundary temperatures were set to 18 c which represented the background groundwater temperature at the site an a dts test was simulated using the numerical model and the apparent convective rate of heat transfer qh conv w for each scenario was calculated the scenarios were created by varying the number of fractures in the interval from 1 to 4 fractures and varying the aperture of each fracture from 50 to 500 μm producing 24 different flow rates and corresponding apparent convective rates of heat transport these two properties for each scenario can be plotted against one another and an empirical relationship established thus if one can calculate the apparent rate of convective heat transfer from a field a dts test they can estimate the groundwater flow rate using this relationship due to the multiple model runs required for the range of cable positions in the borehole this paper relies on the centralized condition only but with excellent controls on the rock and grout thermal conductivities to inform the test conditions these estimates of flow are considered approximate and evaluated against other quantitative methods sufficient for the purposes of the study for finding depth discrete preferential pathways and delivery of remediation fluids more robust evaluation of flow uncertainty is considered beyond the scope and objectives of this paper 3 3 groundwater flow estimation from passive flux meter pfm another approach to measure groundwater flow at the site was applied using pfms the pfm is a permeable cylindrical pack of sorbent containing tracers that are placed along a monitoring well screen for quantitation of groundwater and solute fluxes annable et al 2005 basu et al 2006 the pfm sorbent consists of granular activated carbon impregnated with multiple water soluble tracers that desorb at varying rates with groundwater flow through the pfm the tracer mass is used to estimate the average groundwater flux during the deployment period in addition the organic contaminants flowing through the pfm sorb to the activated carbon and the total mass is used to estimate the contaminant flux a more detailed summary of the method is presented in haluska et al 2019 for this study the pfm deployments occurred approximately 2 months after the fluorescein experiment and the a dts test the pfms were segmented into 10 30 cm sections to provide high spatial resolution of mass flux within the 3 to 4 m long well screen intervals rubber disks serving as baffles separate these sections to minimize potential vertical flow inside the pfm and within the well screen in total 10 sections were defined for wells pz 59s pz 60s and 23 sections for well pz 89s fig 1a and c after retrieval the samples of each section were submitted for laboratory analysis of vocs and suite of alcohol tracers as described by annable et al 2005 4 results and discussion 4 1 preferential flow pathways at the end of the 53 day fluorescein tracer injection period continuous core was retrieved from five boreholes b604 b606 b607 b609 b610 drilled downgradient from the injection well pz 89s fig 1b fluorescein was not observed along the external edge of the cores indicating minimal cross contamination during core drilling or during retrieval and handling at the surface before each core was frozen the core photos taken under uv light clearly show positions with presence of the fluorescein tracer in both the rock matrix and along preferential pathways fig 5 the continuous presence of fluorescein in the core samples from 10 to 15 m bgs in borehole b604 located 1 5 m away from the injection well pz 89s screened at the same elevation indicate evidence of flow in both matrix and along preferential pathways matrix flow seems to occur primarily in intervals with poor cementation which is evidenced by the lack of fluorescein in intervals of harder cementation fig 5a the presence of fluorescein in the matrix is less evident with increasing distance from the injection well deeper in borehole b604 some intervals also showed presence of fluorescein with a strong detection at 18 5 m bgs where fluorescein was also visually observed under uv light these depths are well below the injection depth in pz 89s suggesting hydraulic connectivity through preferential pathways to these depths or possibly vertical migration through the borehole from hydraulic cross connection in general the core sample porewater fluorescein analyses agreed with the visual evidence but fluorescein was detected in porewater samples in intervals where fluorescein was not visually apparent fig 6 suggesting deeper penetration of fluorescein into the aquifer matrix than was apparent based on visual observation the profiles presenting fluorescein concentration in porewater show that for distances 4 5 m the tracer is only detected within and near preferential pathways in four of the boreholes fluorescein was detected in the interval from 10 5 12 m bgs indicating connected preferential flow pathways in this interval the tracer visible at these features present evidence of advection and diffusion into the rock matrix on either side of the preferential pathways surface thus flow through preferential pathways appears to allow more rapid transport and a farther travel distance than the aquifer matrix at the time of sampling four core holes were sampled and analyzed for tce in the rock core porewater fig 6 a description of the rock core sampling and analysis approach can be found in goldstein et al 2004 and in parker et al 2012 borehole b504 located 2 9 m away from the injection well pz 89s was cored before the fluorescein injection experiment boreholes b604 b606 and b607 were cored after the injection experiment and located 1 5 4 4 and 5 9 m away from the injection well respectively based on borehole b504 data representing the conditions before the tracer injection most of the tce mass was stored between 10 and 17 m bgs after the injection tce was not detected within this interval in the borehole closest to the injection well b604 1 5 m away where relatively uniform delivery of fluorescein was observed also the boreholes that are further away b606 and b607 4 4 and 5 9 m respectively have measurable tce within the 10 17 m interval however each has thin zones within this interval where the tce concentrations are below detection these thin intervals correspond with the intervals of relatively elevated fluorescein concentrations fig 6 the presence of fluorescein and the lack of tce in borehole b604 suggests that the injection of the fluorescein tracer may have displaced the matrix porewater containing tce from these intervals this flushing effect is observed in both the matrix and preferential flow paths near the injection well and only near preferential pathways farther away 4 5 m from the injection well the displacement of tce might have been caused by the enhanced hydraulic gradients and groundwater velocities during the injection period relative to the ambient gradient conditions 4 2 groundwater flow rates from a dts test 4 2 1 rock baseline thermal conductivity the rock thermal conductivity baseline provides constraint of the no flow thermal conditions of the aquifer materials the results of the laboratory effective rock thermal conductivity measurements in 15 samples from borehole b616 show reasonably consistent values with depth with minimum and maximum of 1 62 and 2 41 w mk respectively average of 2 06 w mk and a standard deviation of 0 19 w mk the low range of effective rock thermal conductivity values becomes evident when plotted as profile with different lithological units identified fig 7 the cement and bentonite mix grout used to permanently install the fiber optical cable in borehole b504 provided an effective thermal conductivity of 1 08 w mk lower than the surrounding rock values the bulk effective thermal conductivity of all materials surrounding the cable such as the standing pipe plastic the injected grout and the formation sediments controls the heat dissipation from the composite fiber optic cable therefore the low thermal conductivity of the materials surrounding the fiber optic cable in this type of deployment decreases the sensitivity to the thermal signal created by the enhanced heat dissipation due to groundwater flow surrounding the borehole in comparison to maldaner et al 2019 for this study the fiber optic cable was permanently grouted in the borehole therefore the effective bulk thermal conductivity value representing a no groundwater flow condition of 1 74 w mk was estimated using a numerical modeling scenario including all the different thermal properties and the geometry of the deployment this included the materials surrounding the cable such as pvc standpipe grout and sediments and a no flow condition established by setting the hydraulic gradient to zero fig 4 estimating the effective bulk thermal conductivity for the deployment is important because it is assumed that any value of apparent thermal conductivity measured above this threshold will be considered due to groundwater flow 4 2 2 relationship between in situ apparent thermal conductivity and groundwater flow the approach to estimate groundwater flow from a dts tests is based on the empirical relationship between apparent convective rate of heat transfer and groundwater flow rates as proposed by maldaner et al 2019 the relationship is obtained from site specific numerical modeling by calculating values of apparent convective rate of heat transfer for each groundwater flow scenario imposed to the model the relationship is then applied to the apparent convective rate of heat transfer values obtained from a dts tests obtained at the study site in total 24 modeling scenarios using a range of groundwater flow rates provide an empirical relationship between the apparent convective rate of heat transport qh conv w and groundwater flow rate through the fractures qflow l day fig 8 a linear regression through all the data points was used to establish the empirical relationship 4 q flow 86 16 q h conv w f where 5 q h conv q h total 1 λ r λ a λ a λ r and w f is a transverse fracture width of interest m which for eq 4 is equal to 1 m thus to compare a dts flow estimates to those obtained using a borehole dilution system the flow value needs to be scaled to the effective cross section area for flow q h total is the power output and is calculated by taking the line source power output w m times interval height m e g the dts sampling resolution 12 6 cm thus if one knows the power output from the heating cable the apparent thermal conductivity from the a dts measurements and the rock thermal conductivity from lab measurements a volumetric flow rate q flow can be estimated for a cross sectional flow area which in this case is calculated using a 1 m wide fracture times the interval height the darcy velocity can then be estimated by dividing q flow by the interval height so the results could be compared with the passive flux meter pfm velocity estimates it is important to note that this empirical relationship is somewhat site specific in that it was developed using the borehole geometry the specific thermal properties of those materials and the heating output and duration to match the field experiments the constant in eq 4 is larger than the relationship presented by maldaner et al 2019 for the fractured dolostone in guelph canada this is caused mainly by the cable deployment differences between the installation in this study and that using a flexible borehole liner in this study the cable is set back from the borehole wall approximately 5 cm and encased in a low effective thermal conductivity cement bentonite grout 1 08 w mk and also by the lower thermal conductivity of the sandstone at the study site in contrast with the dolostone 2 06 w mk vs 4 0 w mk respectively 4 2 3 field a dts test and apparent thermal conductivity profile temperature evolution was monitored continuously during the 24 h a dts test in borehole b604 and temperature difference above ambient was calculated by subtracting the background temperature fig 7 the background temperature decreases from 20 to 17 c from the top to the bottom of the borehole a temperature increase near 13 m bgs can be observed due to the warm tracer solution injected in well pz 89s screened from 10 2 14 8 m bgs during the a dts test the temperature inside the heated fiber optic cable increases at variable rates at different depths along the borehole with maximum final temperature differences over ambient of 11 22 c fig 7 the variable temperature differences is caused by a combination factors including degree of water saturation that occurs at the top of the borehole variation of the rock thermal properties with depth and heterogeneous groundwater flow along the tested profile one way to interpret the rate of temperature increase during a dts tests is by calculating the apparent thermal conductivity profile which is proportional to the rate of temperature change maldaner et al 2019 for the current deployment the estimated baseline no flow effective thermal conductivity is estimated to be around 1 74 w mk based on the a dts apparent thermal conductivity profile 7 intervals a to g are highlighted in borehole b604 that represent enhancements above this baseline fig 7 interval a shows higher temperature differences of 20 c above background and apparent thermal conductivity values below the baseline caused by the unsaturated hydraulic conditions interval b presents temperature difference values ranging from 16 to 18 c with all apparent thermal conductivity values above the baseline indicating presence of groundwater flow evidence of flow through preferential pathways occurs at depths where the thermal conductivity profile spikes such as at 14 0 15 2 and 17 0 m bgs at this same depth interval interval b the results from the fluorescein tracer pore water analysis in corehole b604 fig 6 demonstrate flow in the rock matrix and the uv core pictures show the tracer along preferential flow paths corroborating the a dts results below 20 m bgs the apparent thermal conductivity profile behavior changes with evidence of stronger heat dissipation only at depth discrete intervals see intervals c e and f in fig 7 interval d presents apparent thermal conductivity values equal or below the baseline indicating limited groundwater flow based on the physical characteristics of the rock such as the poorly cemented nature of the matrix particularly in the upper half of the sequence there is likely some component of flow through the matrix as well suggesting a dual porosity dual permeability system with some degree of flow through both preferential pathways and matrix the results from the fluorescein tracer tests support the a dts results interpretation and reinforce that the adapted a dts method to poorly cemented formations using grouted fiber optic cables can provide meaningful data in an efficient way 4 2 4 groundwater flow from in situ a dts test based on the a dts apparent thermal conductivity profile obtained in borehole b604 and the relationship obtained between the rate of heat dissipation and groundwater flow eqs 4 and 5 the flow rates q flow estimated from a dts apparent thermal conductivity vary from 2 to 24 l day with average and median values of 11 and 7 l day respectively the darcy flux estimated by dividing the flow rate values by the height of the integrated interval and unit width ranged from 7 to 60 cm day with average and median values of 23 and 17 cm day respectively the absolute flow rate from a dts tests requires application of an empirical relationship developed from numerical model scenarios of groundwater flow and heat transport eq 4 this modeling effort requires simplifications or idealities relating to the borehole deployment geometry and flow conditions deviation of real world conditions from these idealities results in some uncertainty in the flow estimates for example the numerical model assumes the cable is affixed to the pvc pipe and the pipe is centered in the borehole if the actual cable is in fact closer to the borehole wall at certain depths the empirical relationship developed from numerical modeling would overestimate flow despite these simplifications the relationship between the rate of heat dissipation and groundwater flow presented by maldaner et al 2019 and the a dts method is currently the only method that provides a full profile of groundwater flow rates and velocities under natural gradient conditions if a dts measurements are performed over time the method can provide a temporal dataset of groundwater flow rate changes that could be related to recharge events or changes in boundary conditions such as pumping of nearby wells this application of the method to temporal changes was assessed by a sensitivity test where the hydraulic condition of the field site was changed and fully captured by the a dts method munn et al 2020 such data would provide a robust means to refine and test conceptual site models 4 3 groundwater velocity and mass flux from passive flux meter pfm passive flux meters pfm were deployed in three conventional monitoring wells pz 59s pz 60s and pz 90s fig 1a pz 90s is located 3 m away from the fluorescein tracer injection well and the deployment of the pfms occurred 2 months after the end of the tracer injection the estimated groundwater fluxes from the pfms range from 2 to 11 cm day with an overall average of 4 cm day fig 9 it is assumed that these darcy fluxes correspond to horizontal flow in the formation under natural gradient conditions monitoring well pz 59s shows a relatively uniform flux distribution 2 4 cm day along the screened interval with slightly slower fluxes at the center of the profile and close to the contact between the upper sandy unit and the lower silty sand unit pz 60s presents a groundwater flux in the sandy unit around 2 cm day and it increases with depth to 4 8 cm day at the contact with the silty sand unit with the highest values centered around 12 7 m bgs in the upper portion of silty sand unit in general the highest fluxes are observed in pz 90s 4 6 cm day the darcy fluxes calculated from the a dts data along the same interval shows a relatively uniform value 16 cm day within the upper 3 m 10 13 m bgs and an increase in flux up to 25 cm day in the silty sand unit fig 9 the higher a dts fluxes of 16 cm day compared with the average pfm velocity of 4 cm day could be the result of actual flow differences between locations i e lateral spatial variability temporal variability and or due to uncertainties specific to both methods specifically it is worth noting the nature of sand packs in conventional wells where the pfms were deployed could be a major contributor to lower darcy flux values with this technique the geometry and permeability of typical sand packs in conventional wells will homogenize flow over the depth of the sand pack and vertically blend horizontal preferential flow paths slowing down depth discrete flow in higher flow intervals and resulting in a vertically homogeneous and dampened velocity profile underestimation of groundwater velocities using pfm was observed in a groundwater surface water discharge study when compared to point velocity probes ottosen et al 2020 alternatively the variation in the a dts flow estimates resulting from variation in cable positioning in the borehole contributes some uncertainty not yet quantified both methods are complementary in that they provide a sense of the position nature and relative magnitude of flow contaminant mass flux provides a useful means to assess contaminant migration and risk to offsite receptors as well as provide horizons to focus remediation efforts the tce mass fluxes estimated from the pfm results provide information about the vertical contaminant distribution and transport rates which is variable among the three wells where pfms were deployed fig 9 tce was detected in the extracts from pfm intervals in pz 59s 7 94 μg l and pz 60s 4 162 μg l while only at the upper portion 10 7 11 7 m bgs of pz 90s 1 11 μg l in well pz 59s the bulk of the tce mass is distributed from the upper sand unit down to the contact with the silty sand unit the higher tce concentration at 12 25 m bgs corresponds to an interval with lower darcy velocity therefore the tce flux is not as high as at 11 m bgs 0 05 mg m2 day in well pz 60s most of the tce mass is in the lower silty sand unit that corresponds to the interval with the highest darcy flux resulting in largest tce mass flux 0 17 mg m2 day among all three wells the pfm results from pz 90s show low tce mass flux 0 002 mg m2 day in comparison to the other wells since this well is located near the fluorescein tracer injection well and the pfms were deployed after the tracer experiment the results suggest that the injected tracer fluid was able to displace the matrix porewater due to lower but appreciable matrix permeability at least under forced gradient conditions the tce porewater concentrations in borehole b604 also located near the injection well are mostly non detect supporting the hypothesis that tce mass was largely removed from this portion of the aquifer by the fluorescein tracer injection process fig 6 4 4 site conceptual model and implications on the remediation strategy variable groundwater flow rates through different pathways are identified in this study from multiple methods including visual inspection of continuous core porewater analysis in rock core samples a dts tests and passive flux meters at 1 5 m from the injection well fluorescein was visually observed in numerous discrete intervals and in the rock matrix and confirmed with porewater lab analysis these results suggest advective flow through preferential pathways and slower advective flow rates in the rock matrix slightly further from the injection well at 4 5 6 m fluorescein was only observed in a few discrete intervals indicating groundwater radiated farther away at a higher velocity through discrete preferential pathways with higher permeability than through the rock matrix these preferential pathways were also identified in the a dts results as zones of enhanced heat dissipation thus groundwater flow at the site is consistent with a dual porosity dual permeability system with slower advective groundwater flow within the rock matrix and faster flow within preferential pathways fluorescein was effectively delivered through preferential pathways to distances of up to 6 m from the injection well within less than a 1 month period however within the less permeable zones i e matrix this distance was about 3 5 m during the same timeframe based on these results a 3 5 m travel distance of amendments is the conservative estimate for designing an in situ remediation injection well gallery therefore a 7 m spacing of injection wells is recommended these results support that the injection of amendments will likely result in a fast wide and quasi uniform distribution due to preferential flow in the depth discrete features and reasonable rock matrix permeability since in situ chemical oxidation isco relies upon contact of amendment with the vocs to be successful it is a critical finding that the slower advection in the rock matrix can occur in a timeframe during injection that makes isco a cost effective remedial option nevertheless it would be prudent to design the amendment injection phases with enough time between them to allow the variable advection with transverse diffusion to enhance delivery into the lower permeability zones it will be important from a performance monitoring standpoint to have a monitoring approach that provides sufficient spatial resolution and temporal frequency to distinguish between delivery through preferential flow pathways and variable rates of advection and diffusion into the rock matrix that can evaluate variable delivery rates an important question for evaluating the potential effectiveness of an in situ remediation method is whether untreated portions of the aquifer could represent an on going source of contamination due to high amounts of contaminant storage no measurable tce mass discharge was observed in any of the pfm segments from well pz 90s suggesting that the potential for back diffusion might be minimal at this site when effective delivery of voc free fluids to the aquifer is accomplished 5 conclusions a combination of tracer experiments was performed under both natural and forced gradient conditions at an industrial site with tce contamination to inform in situ remediation strategies fluorescein tracer injection followed by high resolution coring and subsampling for porewater concentrations showed preferential groundwater flow along discrete features but some tracer penetration in the rock matrix by slower advective flow because boreholes installed in the poorly cemented sandstone aquifer were unstable it was not possible to perform a dts testing using the traditional deployment method using a flexible borehole liner therefore a novel approach to deploy the fiber optic cable for a dts testing was developed wherein the cable was attached to the outside of pvc casing lowered into the borehole and permanently grouted in place the a dts heat tracer experiment showed hydraulic variability at different depths under natural gradient conditions suggested enhanced flow through preferential pathways and secondary flow through the rock matrix these results were compared to flow velocities from in well passive flux meters with reasonable agreement and are most consistent with a dual porosity dual permeability system the observation that preferential pathways are laterally and vertically connected and that the tce can be relatively quickly removed from the high permeability layers improves the understanding of the groundwater flow and transport site conceptual model the tracer was able to move farther and faster through preferential pathways and more slowly through the permeable matrix this study informs the remediation injection well spacing of 7 m based on extent of the tracer in the laterally connected preferential pathways and in the rock matrix it also provides insights on delivery of remediation amendments to the contaminated portion of the aquifer by allowing time between injection periods for amendments to penetrate the rock matrix by minor advection and diffusion processes from the preferential pathways the data from this study provided the means to develop an evidence based remediation approach that informed design and spacing of future injection wells built confidence that in situ remediation could be effective despite the observed groundwater flow path heterogeneity and managed expectations of stakeholders on performance outcomes and timeframes for completion declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we appreciate the constructive comments from two anonymous reviewers field and logistical support was provided by vincent durand melanie caperan and lucas flavien antea france and paula pryor and erica bosse sanborn head associates inc and data analysis support from sean murphy sanborn head associates professor jasmin raymond and mafalda miranda inrs quebec city canada provided access and support with the laboratory thermal conductivity measurements wayne noble g360 institute for groundwater research guelph canada lead the laboratory fluorescein measurements on core samples funding for this study was provided by the study site owner 
1429,accurate calculation of the longitudinal dispersion coefficient k x of pollution is essential in modeling river pollution status various equations are presented to calculate the k x using experimental analytical and mathematical methods although machine learning models are more reliable than experimental equations in the presence of uncertainties missing data they have not been widely used in predicting k x in this study the k x of the river was predicted using machine learning methods including least square support vector machine ls svm adaptive neuro fuzzy inference system anfis and anfis optimized by harris hawk optimization anfis hho and the results were compared with that of the experimental methods several scenarios were designed by different combinations of input variables such as the average depth of the flow h average flow velocity u and shear velocity u the results showed that machine learning models had a more efficient performance to predict k x than experimental equations the anfis hho with a scenario containing all the input variables performed better than the other two models with root mean square error mean absolute percentage error and coefficient of determination of 17 0 0 22 and 0 97 respectively furthermore the hho algorithm slightly increased the prediction performance of the anfis the discrepancy ratio dr evaluation criteria showed that experimental equations overestimated the values of k x while the machine learning models resulted in higher precision also the results of taylor s diagram showed the acceptable performance of the anfis hho model compared to other models given the promising results of the present study it is expected that the proposed approach can be efficiently used for similar environmental modeling problems keywords dispersion coefficient water quality modeling streamflow machine learning abbreviations acor ant colony optimization algorithm ade advection dispersion equation anfis adaptive neuro fuzzy inference system ann artificial neural network ba bee algorithm bn bayesian network cs cuckoo search de differential evolutionary dr discrepancy ratio epr evolutionary polynomial regression fm fuzzy model ga genetic algorithm gep gene expression programming gmdh group method of data handling gp genetic programming hho harris hawks optimization ica imperialist competitive algorithm ls svm least squares support vector machine m5 model tree mape mean absolute percentage error mars multivariate adaptive regression spline max maximum min minimum mt model tree nf neuro fuzzy pomggp pareto optimal multigene genetic programming pso particle swarm optimization rmse root mean square error sd standard deviation svm support vector machine woa whale optimization algorithm nomenclature a cross sectional area of the flow b regression bias b water surface width c cross sectional concentration e error e indicates the escaping energy of the prey e0 randomly changes inside the interval 1 1 in the hho g acceleration due to gravity h the average depth of the flow j rabbit represents the random jump in the hho k x longitudinal dispersion coefficient lb upper bound n denotes the total number of hawks n number of samples p the consequent model parameters anfis q the consequent model parameters anfis r 1 r 2 r 3 r 4 random numbers between 0 and 1 in the hho r2 coefficient of determination t weight t the maximum number of iterations in the hho u average flow velocity u shear velocity ub upper bound w transpose operator respectively x input variable anfis x t 1 the position vector of hawks in the next iteration x o observed value x p predicted value anfis x rabbit t the position of rabbit y input variable β equal to 1 0 in triangular channels β is a default constant set to 1 5 in the hho γ the regulation term for the error δx t difference between the position vector of the rabbit and the current location in iteration t σ the channel sinuosity φ x the nonlinear mapping of inputs to a high dimensional feature space 1 introduction in recent years the protection of rivers has been considered by national and international organizations responsible for quality control and protection of water resources the importance of river protection reveals in regions where large cities and industries are located near the rivers and rivers are the main supplier of the water needs tayfur and singh 2005 increasing the level of pollution in surface waters necessitates mixing and reduction processes in natural rivers one of the most important and efficient river environmental management methods is to improve the self cleaning ability of the river pourabadei and kashefipour 2007 currently agricultural and industrial wastewater entrance to natural rivers has become a common management practice in environmental engineering because of its oxidization and organic matter removal capabilities to control the quality of surface water resources pollutants entrance to natural rivers and open streams is conducted using costly methods this requires accurate knowledge about the pollutant transfer to the rivers and the possibility of transmission and mixing and self cleaning of pollutants by river flow pourabadei and kashefipour 2007 the process of pollutant transfer can be seen in three stages in the first stage a pollutant is diluted due to its initial movement in the channel in the second stage the pollutants are mixed because of the turbulent transfer processes throughout the river section in the third stage after completing the cross section longitudinal dispersion tends to clear the longitudinal changes in pollutant concentrations french 1986 the longitudinal dispersion coefficient k x of pollution is an essential variable in modeling the pollution status of rivers accurate calculation of k x is required in several applied hydraulic problems such as river engineering environmental engineering river mouth problems and risk assessment of injection of dangerous pollutants into rivers sedighnezhad et al 2007 seo and bake 2004 various equations have been proposed to calculate the k x using experimental analytical and mathematical methods k x can be easily determined when actual field data are available experimental equations are used in rivers where the characteristics of pollution dispersion are unclear kashefipur and falconer 2002 analytical and mathematical methods have high computational complexities and are often time consuming experimental methods are of the research methods used to test hypotheses they aim to investigate the effect of specific stimuli methods or environmental conditions on a group of subjects one of the characteristics of the experimental methods is that they provide results by manipulating the variables and conditions obtained for the group selected by random assignments in general these methods result in significant errors in the prediction of k x in this regard the researchers have presented relationships that depend on the river s hydraulic parameters namely flow velocity river shear velocity flow depth and river width these relationships are valid in a specific hydraulic condition and do not provide reliable results for outlier values azamathulla and wu 2011 table 1 summarizes the available experimental equations for the calculation of k x based on the average depth of the flow h average flow velocity u shear velocity u and water surface width b elder 1959 introduced the most straightforward equation which relates the k x to h and u later researchers have developed equations that use more parameters such as u and b deng et al 2001 introduced a new equation in which k x depends not only on the geometric and hydraulic characteristics of the flow but also on the transverse dispersion coefficient ε t the latter also depends on the hydraulic and geometric parameters of the flow machine learning models have gathered considerable attention due to not requiring the physical information of the channels and their physical structure researchers have extensively used these models in recent years due to the lack of difficulties that occur in numerical models and not having the limitations and high costs of experimental models artificial neural network ann adaptive neuro fuzzy inference system anfis least square support vector machine ls svm and bayesian networks bn are among these models these models have been applied for the assessment of sediment transport demonstrating acceptable results azamathulla et al 2012 azamathulla et al 2009 afan et al 2015 kumar et al 2016 mount and stott 2008 milan et al 2018 najafzadeh and oliveto 2020 saberi movahed et al 2020 najafzadeh and ghaemi 2019 najafzadeh and etemad shahidi 2016 balf et al 2018 in recent years researchers have used machine learning based methods to predict k x in a leading study tayfur and singh 2005 predicted k x using data of 71 samples from 29 rivers in the united states using ann and showed that ann had an acceptable ability to estimate the amount of k x riahi madvar et al 2009 used the anfis approach to predict k x based on 73 data samples of which 70 of the data were used for training and the rest for the test error evaluation criteria showed that anfis had better performance than experimental models and could be combined with mathematical models from 2009 to 2016 besides ann and anfis other models such as svm and gep were used to predict k x table 2 for the first time najafzadeh and tafarojnoruz 2016 used the nf gmdh pso hybrid model and the mt ann de and ga models to predict k x they used 233 data samples of which 75 of the data were selected randomly for training and the remaining data for the test the models performance was acceptable and the nf gmdh pso hybrid model was capable of predicting k x with the highest performance using the ability of evolutionary algorithms some researchers have developed empirical relationships in this field tayfur 2009 sahay and dutta 2009 sahay 2013 in the field of evolutionary algorithms alizadeh et al 2017a 2017b 2017c used the pso algorithm to derive new equations to predict k x in natural rivers based on their study pso could improve the performance of predictive equations by finding the optimal values of the coefficients in another study memarzadeh et al 2020 used the woa evolutionary algorithm to find the optimal coefficients and showed that the algorithm improved the performance of predictive equations ls svm models have also been used in various studies including land temperature prediction water quality satellite images and sensor development showing an excellent performance chauchard et al 2004 zheng et al 2008 leong et al 2019 najafzadeh and ghaemi 2019 zhou et al 2020 compared with the classical svm method ls svm has less computation complexity leading to higher accuracy and lower consuming time in a study kong et al 2008 employed ls svm and wavelet transform to predict daily river flow their results indicated the appropriate accuracy of the ls svm model in flow prediction najafzadeh and ghaemi 2019 compared the ls svm and mars models with ann and anfis to predict water quality indicators they used 200 data sets considering nine input variables and concluded that ls svm and mars performed better than the other models anfis is another model useful for data with uncertainties its relatively low accuracy in the modeling and being occasionally trapped in the local minima asefpour vakilian and massah 2016 najafzadeh et al 2016 necessitate the use of advanced optimization methods such as particle swarm optimization pso and differential evolution de to optimize the coefficients of the anfis model and therefore increase its performance ebtehaj et al 2019 used the pso algorithm to train an anfis model to simulate sediment transport in open channels the results indicated the acceptable performance of the anfis pso hybrid model compared to the anfis model azad et al 2018 used the anfis model and the ga pso acor and de evolutionary algorithms to simulate the quality parameters of the gorganrood river iran their results showed that the de algorithm is more accurate than the other evolutionary algorithms in another study they used these algorithms to model rainfall runoff in isfahan iran azad et al 2019 they showed that the anfis acor method resulted in the best performance with r2 rmse and si of 0 92 2 73 and 0 26 respectively yang et al 2019 used anfis ga and anfis pso hybrid models to predict landslides the anfis ga and anfis pso models could predict ground vibration with acceptable accuracy yang et al 2019 seifi and riahi madvar 2018 used 505 data divided into training 60 and test 40 samples to predict k x they used the ann and anfis models along with ga evolutionary algorithm to improve the performance of them the results showed that ga remarkably improved the performance of anfis so that anfis ga predicted the value of k x more accurately than other models proposed by heidari et al 2019 the harris hawks optimization hho is one of the most recently algorithms available for optimization problems in this research hho is used to improve the training capability of anfis in predicting k x in natural streams amount the literature review on the application of machine learning in predicting the value of k x shows that it is possible to increase the prediction performance with advanced machine learning models ls svm is one of the models that has shown promising results in various studies and therefore its use in predicting k x can be efficient along with models such as anfis also due to the poor performance of anfis especially for the test data in some cases evolutionary optimization algorithms can be used to improve its results in this study an attempt has been made to use one of the most advanced evolutionary algorithms to improve the results of machine learning algorithms since machine learning models are not sensitive to the nature of the input data it has been tried in this study to create various scenarios by different combinations of input variables i e b h u u b h u u β and σ to determine the most appropriate scenario for estimating k x moreover the most suitable machine learning model is selected based on rmse mape r2 and taylor s diagram the selected models along with the selected input scenario are compared with the results of some experimental equations 2 materials and methods 2 1 advection dispersion equation ade k x is an essential factor in the prediction of the concentration which was introduced by taylor 1954 in a one dimensional 1d environment eq 1 1 c t u c x k x 2 c x 2 where c is cross sectional concentration t is time and x is the longitudinal direction throughout the flow fisher 1967 developed eq 2 to calculate the k x for pollutant transfer tayfur and singh 2005 2 k x 1 a 0 b h u 0 y 1 ε t h 0 y h u dydydy where a is the cross sectional area of the flow h is the local depth of the flow u is the deviation of the speed at depth from the average speed and y is the coordinates in the lateral direction eq 2 is the basis of many experimental methods for determining k x the most important of which are presented in table 1 fisher 1967 proposed a simpler equation eq 3 for taylor s method 3 k x 0 011 u 2 b 2 h u fisher et al 1979 presented eq 4 to calculate ε t for the wide and direct rivers with the uniform flow and constant depth in width kashefipur and falconer 2002 4 ε t 0 15 h u 2 2 dataset data from 29 rivers in the united states including 71 data samples were extracted from deng et al 2001 they were used to analyze the experimental equations and construct the machine learning models table 3 summarizes the statistical characteristics of the dataset used in this study it is observed that the k x of the rivers ranged from 1 90 to 892 m2 s while its average value was ca 107 m2 s β indicates the channel shape introduced by deng et al 2001 5 β ln b h β is equal to 1 0 in triangular channels otherwise it has either a parabolic shape β 2 having a flatbed region with two curving banks 2 β 5 or a rectangular shape β 5 deng et al 2001 σ is the channel sinuosity which is defined as the ratio of the channel length to the valley length chang 1988 the sinuosity of the streams and rivers varies from 1 08 to 2 54 2 3 least squares support vector machine ls svm suykens and vandewalle 1999 introduced ls svm which is very similar to the classical svm but has lower computation and time complexity and higher performance given a set of training data such as x k y k k 1 n whose input and output data include x k r n and y k r respectively eq 6 shows the nonlinear regression function in the initial weighting suykens and vandewalle 1999 6 y x w t φ x b where t b and w are weight regression bias and transpose operator respectively φ x is the nonlinear mapping of inputs to a high dimensional feature space this nonlinear regression can be solved using an optimization process eq 7 7 min j w e 1 2 w 2 w 1 2 γ k 1 n e k 2 with the constraint 8 y k w t φ x b e k k 1 n and γ is the regulation term for the error e γ controls the approximation function so the larger the γ value the higher the error is solving this equation using the lagrangian form of the main objective function we have 9 l w b e a j w e i 1 n α i w t φ x k b e k y k where α i is the lagrangian coefficient based on the karush kuhn tucker condition the ls svm model is written for the approximation function as eq 10 mellit et al 2013 10 y x k 1 n α k k x x k b where k x x k is called kernel function in this study the gaussian kernel function is used eq 6 mellit et al 2013 11 k x x k exp x x k 2 σ 2 2 4 adaptive neuro fuzzy inference system anfis the anfis model was developed by combining a fuzzy inference system fis and ann jang 1993 anfis is a fuzzy rule based network that uses adaptive systems to facilitate the learning and adaptation process ozgan et al 2009 the main purpose of the anfis is to optimize the fis parameters by using input output data sets through a learning algorithm in this structure the nodes in the first and last layers represent the input and output data while the nodes in the hidden layers are identified as membership functions and rules the sugeno model is widely used in this structure because of its interpretability high computational capability and adaptability for two inputs x 1 x 2 and one output y of the sugeno type anfis structure the rules are defined as eqs 12 and 13 12 rule 1 if x 1 is a 1 and x 2 is b 1 then f 1 p 1 x 1 q 1 x 2 r 1 13 rule 2 if x 1 is a 2 and x 2 is b 2 then f 2 p 2 x 1 q 2 x 2 r 2 where a and b are the fuzzy sets p q and r are the consequent model parameters that are determined in the training stage anfis architecture includes five layers fig 1 in the first layer the input data passes through different membership functions and the membership degree of input nodes to different fuzzy intervals is determined using membership functions in the second layer which contains the rule nodes fuzzy values are multiplied by each node and the result is the weight of the rules the nodes of the third layer normalize the weight of the rules the resultant nodes create the fuzzy based rule outputs the fifth layer consists of a single node that calculates the total output of the system this layer transforms the results of each fuzzy rule into a non fuzzy output using a defuzzification process 2 5 development of the anfis using harris hawks optimization neuron based methods suffer from several drawbacks such as trapping in local minima and slow convergence of training especially for wide search spaces asefpour vakilian and massah 2018 therefore there is a need to use hybrid methods that use optimization techniques to optimize the parameters of the anfis in this study the hho evolutionary algorithm was used along with the anfis model to improve the anfis model according to the literature the hho algorithm has its unique features that can significantly improve the traditional anfis model the relationships of hybrid anfis hho used in this study to predict the kx is depicted in fig 2 firstly scenarios with different variables were given to the model as input and then the type of the fuzzy function and the anfis structure is determined the anfis is improved with evolutionary algorithms to achieve better results in this structure the objective function is to minimize the error of the predicted values finally the amount of k x is predicted by the optimized model like many other evolutionary algorithms hho is a nature inspired and population based algorithm which is based on rabbit hunting by harris hawks heidari et al 2019 in the hho method the harris hawks are the candidate solutions fig 3a they perch randomly on some locations and wait to detect prey based on two strategies their position is mathematically expressed as eq 14 14 x t 1 x rand t r 1 x rand t 2 r 2 x t q 0 5 x rabbit t x m t r 3 lb r 4 ub lb q 0 5 where x t 1 is the position vector of hawks in the next iteration of t x rabbit t is the position of rabbit x t is the current position vector of hawks r 1 r 2 r 3 r 4 and q are random numbers between 0 and 1 which are updated in each iteration lb and ub are the lower and upper bounds of variables x rand t is a randomly selected hawk from the current population and x m is the average position of the current population of hawks the average position of hawks is obtained using eq 15 15 x m t 1 n i 1 n x i t where x i t indicates the location of each hawk in iteration t and n denotes the total number of hawks the energy of prey decreases considerably during the escape the energy of prey is modeled using eq 16 16 e 2 e 0 1 t t where e indicates the escaping energy of the prey t is the maximum number of iterations and e 0 is the initial energy e 0 randomly changes inside the interval 1 1 at each iteration the hawks intensify the besiege process to catch the exhausted prey effortlessly the e parameter is utilized to model this strategy and enable the hho to switch between soft and hard besiege processes in this regard when e 0 5 the soft besiege happens and when e 0 5 the hard besiege occurs fig 3b if r 0 5 and e 0 5 the rabbit still has enough energy and tries to escape by some random misleading jumps but finally it cannot during these attempts the harris hawks encircle it softly to make the rabbit more exhausted and then perform the surprise pounce this behavior is modeled by eqs 17 and 18 17 x t 1 δ x t e j x rabbit t x t 18 δ x t x rabbit t x t where δx t is the difference between the position vector of the rabbit and the current location in iteration t r 5 is a random number between 0 and 1 and j rabbit represents the random jump strength of the rabbit throughout the escaping procedure if r 0 5 and e 0 5 the prey is exhausted and it has low escaping energy besides harris hawks hardly encircle the prey to perform the surprise pounce finally fig 3a in this situation the current positions are updated using eq 19 19 x t 1 x rabbit t e δ x t 2 6 performance evaluation criteria the dataset was randomly divided into two groups 70 of the data for the training of the models and the remaining for the test root mean square error rmse mean absolute percentage error mape and coefficient of determination r2 were used to evaluate the scenarios and machine learning methods 20 rmse i 1 n x o x p 2 n 21 mape 100 n i 1 n x o x p x o 22 r 2 1 i 1 n x p x o 2 i 1 n x o x o 2 where x o is the observed measured value x p is the predicted value and n is the number of samples the lower rmse mape and higher r2 values present the better performance of the model 3 results and discussion in this section firstly the results of the machine learning models are described and analyzed and then the results of the machine learning models are compared with that of the experimental equations since several variables are effective in the prediction of k x 10 scenarios were defined with different combinations of input variables according to table 4 the complete scenario included all the input variables i e b h u u b h u u β and σ each scenario was used separately to train the machines and the performances of the machines were compared to obtain the most efficient scenario 3 1 results of the ls svm model table 5 shows the optimum values of the ls svm parameters the gaussian kernel in the ls svm method has two parameters namely σ2 and γ the optimum value of which was obtained equal to 5 365 and 136 03 respectively according to table 6 the scenarios that included more input variables had better accuracy than the scenarios with three or four input variables except scenario 8 which included only three input variables of b h and u therefore in some cases where only the values of b h and u are available k x can be predicted with appropriate performance scenario 1 which includes all the input parameters except σ is the best scenario to predict the value of k x using this scenario the values of rmse mape and r2 for the test data were obtained equal to 24 6 0 42 and 0 96 respectively the complete scenario also resulted in an acceptable performance however in this scenario despite its good accuracy on the training data the prediction of the test data was conducted with lower performance compared to scenario 1 the trend of k x changes for the measured and predicted values of the test data shows that using the ls svm model scenario 1 could efficiently predict the k x behavior fig 4 as can be seen in fig 4 the measured values are well predicted by the ls svm model furthermore the measured and predicted values are very close to each other based on the line fitted to the data 3 2 results of the anfis and anfis hho models the appropriate structure of the anfis model and the optimal values for its parameters are brought in table 7 according to the table the gaussian membership function was selected as the most appropriate fuzzy membership function since the anfis uses the sugeno type method the linear function was selected as the best output function of the model the optimal structure and parameter values of the hho algorithm can be seen in table 8 achieving the appropriate values for each parameter requires implementing the model with a wide range of values which ends with determining the appropriate values of the parameter the population for hho was 30 while the maximum number of iterations was obtained to be 1500 table 9 shows the values of the performance evaluation criteria for the anfis and anfis hho models the anfis model predicted the training data with acceptable performance while exerted poor results for the test data it can be said that the training algorithms of the anfis are trapped in local optimal minima and as a result irrational predictive errors are observed for the test data for this purpose the hho algorithm was used to optimize anfis parameters to solve this problem and improve the results for most of the scenarios a large difference was observed between the measured and predicted data obtained by anfis however in the anfis hho model the prediction performance of the training and test data are relatively similar one of the essential points of using machine learning algorithms that should always be assessed is the slight difference between the prediction accuracy of training and test data which was not observed in the anfis model the complete scenario which included all the input parameters resulted in the best results in both models using this scenario the values of rmse mape and r2 of the anfis model for the test data were 73 4 2 53 and 0 87 respectively these values for the anfis hho model were 23 63 0 38 and 0 94 respectively the results indicate that the use of the hho algorithm has significantly improved the predictive performance of the anfis model the trend of k x changes for the measured and predicted values of the test data is depicted in figs 5 and 6 for the anfis and anfis hho models respectively the figures show that the complete scenario was capable of efficient prediction of k x behavior fig 5 shows that although k x always has a positive value negative values are predicted for k x using the anfis model which is one of the limitations of the anfis model however in fig 6 despite the presence of multiple peak data the anfis hho model has detected these values correctly with relatively acceptable performance furthermore the measured and predicted values are very close to each other based on the line fitted to the data 3 3 the comparison of the machine learning models and experimental equations some experimental models for the calculation of k x that were proposed by previous studies are compared with machine learning algorithms in this section table 10 shows the evaluation criteria of the models including rmse mape and r2 according to the table the machine learning models resulted in a better performance than the experimental equations among the experimental models the equations introduced by sahay and dutta 2009 and zeng and huai 2014 had a relatively better performance compared to other experimental models rmse mape and r2 for sahay and dutta 2009 equation were equal to 283 0 85 and 0 43 respectively while these values were equal to 163 3 45 and 0 4 respectively for the equation of zeng and huai 2014 in contrast all the machine learning models used in this study were very accurate among them the anfis hho model resulted in the highest performance using this model the values of the rmse mape and r2 were equal to 17 0 0 22 and 0 97 respectively it can be seen that there is a significant difference between the performance of the experimental and machine learning models fig 7 shows the measured and predicted data obtained by the experimental equations and machine learning models as can be seen unacceptable prediction results are obtained using the experimental equations in these equations the difference between the measured and predicted values and compared to the regression fitted line is sometimes large according to the figure the most suitable match is achieved by the machine learning models and among them the anfis hho model it can be concluded that the experimental equations are not capable of predicting the k x and the relationships between the input variables and the output are more complex than a simple linear model therefore machine learning models should be used to predict the k x values of the rivers one of the most suitable methods to compare the performance of several predictive models is to use taylor s diagram taylor s diagrams of the experimental and machine learning models are depicted in fig 8 a and b respectively the x and y axes indicate the standard deviation of the data the quarter circle arc shows the value of the correlation coefficient of arbitrary data and the observation data which varies from 0 to 1 the measured data lies on the x axis and a predicted data close to the x axis indicates a strong correlation with the measured data the green arcs indicate the root mean square deviation rmsd according to fig 8 a the results of all experimental equations had a correlation coefficient between 0 6 and 0 7 while according to fig 8 b the correlation coefficient is more than 0 95 for the machine learning models the highest correlation coefficient was obtained for the anfis hho model which was equal to 0 99 among the experimental models the highest standard deviation of data was observed for tavakollizadeh and kashefipur 2007 equation which was ca 3500 while for other experimental equations it was less than 1800 this coefficient was much lower in machine learning models ca 170 the lowest value of this coefficient was obtained for the anfis hho model furthermore the rmsd values for the experimental equations were very large in the range of 500 3500 indicating a significant difference between the data predicted by the machine learning models and the experimental equations in total the results show that the anfis hho method had better efficiency compared to the other two methods furthermore the discrepancy ratio dr kashefipur and falconer 2002 was used in this study to evaluate the performance of the models eq 23 23 dr log k xp k xm where k xm and k xp indicate the measured and predicted values for the k x of the river respectively if the value of the ratio is zero k xp k xm dr 0 there is no difference between the measured and predicted values if the ratio is positive k xp k xm dr 0 the model has overestimated the values and if the ratio is negative k xp k xm dr 0 the values are underestimated by the model according to fig 9 the dr of the ls svm model was in a range between 0 3 to 0 3 in other words 45 of the data was slightly overestimated while 45 of the remaining was underestimated the anfis and anfis hho models had similar behavior to the ls svm model the dr values higher than zero for most of the experimental equations show that these models have been accompanied by an overestimation for example 50 of the data predicted by the equation of zeng and huai 2014 had a dr value between 0 3 and 1 which indicates that in most cases it resulted in an overestimation no dr values higher than 1 or lower than 1 was observed using this equation finally according to fig 9 it can be said that all three models of ls svm anfis and anfis hho have resulted in predicted data in a balanced range the converging trend of a model to the minimum rmse is essential for model training according to fig 10 this trend was different for the studied models the hho algorithms had an initial rmse of ca 85 m and then converged rapidly to the optimum point after a small number of iterations finally after 600 to 1500 iterations all the algorithms have reached a particular error and maximum convergence has been obtained it is observed that after convergence the rmse of the hho algorithm was 13 8 which was higher than that of the anfis hho model after convergence the measured and predicted values of the experimental equations and machine learning models used in the present study are brought in fig 11 a and b respectively according to fig 11 a in the steps where the river s kx values have a short peak the experimental equations resulted in a significant overestimation the equation of tavakollizadeh and kashefipur 2007 resulted in an irrational prediction in step 38 which has decreased its performance significantly it can be said that the experimental equations are not able to correctly calculate the k x values of the outlier samples since they usually face remarkable errors for these samples however as shown in fig 11 b the machine learning models have been able to correctly identify the values of k x while the anfis hho model has had the most compatibility among them therefore it can be claimed that the anfis hho model is the best model for the prediction of k x values 3 4 discussion the results showed acceptable performance of ls svm and anfis hho models according to the results obtained from the error evaluation criteria rmse mape r2 and taylor s diagram the anfis hho model was proposed although both models had similar results the number of optimized parameters in the ls svm model is less than that of anfis hho and therefore the ls svm model is easier to use than the anfis hho hybrid model dr values also showed the similar performance of both prediction models because both models overestimated or underestimated the output with 0 40 to 0 45 errors which was very small compared to the anfis model and experimental equations in general it can be said that evolutionary algorithms had a high ability to improve machine learning models for better prediction results the results of this study were in along with seifi and riahi madvar 2019 which used algorithms for optimizing ann anfis and gmdh to provide better results than classical models another approach considered in this study and was much less considered in previous studies was the number of input variables to predict k x and their combination to achieve the most appropriate accuracy for this purpose several scenarios were developed in this study which were dimensional and non dimensional combinations of variables the results showed that all input variables were required to have proper accuracy in the anfis model and its hybrid model but when using ls sm the presence of all input parameters except σ was sufficient to achieve the appropriate accuracy furthermore when the non dimensional parameters were not considered as input parameters the accuracy of the results was somewhat reduced therefore combining both dimensional and non dimensional input variables is recommended to have proper prediction results in predicting k x values at peaks the hybrid model was able to estimate the values correctly in almost all data while in the other two models especially anfis these values were associated with significant errors fig 6 nevertheless in this study for the first time a combination of various dimensional and non dimensional input variables was considered to evaluate their effects 4 conclusion before the emergence of machine learning models experimental equations were used to predict the k x of the river however recently various researchers have been able to increase the accuracy of k x predictions by using machine learning models in this study several advanced machine learning models were developed to predict the k x of the river three models i e ls svm anfis and anfis hho were used to predict the value of k x furthermore the results of some of the well known experimental equations proposed by the previous studies were compared with the results of machine learning models the river data based on deng et al 2002 were used to evaluate the performance of models and experimental equations the results of this study can be summarized as follows 1 machine learning models require more input variables for efficient prediction of k x 2 although anfis exerted an acceptable performance in the prediction of the training data its results were poor in predicting the test data which indicates this model is trapped in the local optimal minima during the training 3 the performance of the machine learning models was much better than that of the experimental equations which proves the necessity of using machine learning models in this study 4 performance evaluation criteria and taylor s diagram showed that the best model for the prediction of the k x values is anfis hho furthermore the anfis hho hybrid model performed better than the anfis model which shows that using the evolutionary optimization algorithms can improve the anfis model s performance in predictions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
1429,accurate calculation of the longitudinal dispersion coefficient k x of pollution is essential in modeling river pollution status various equations are presented to calculate the k x using experimental analytical and mathematical methods although machine learning models are more reliable than experimental equations in the presence of uncertainties missing data they have not been widely used in predicting k x in this study the k x of the river was predicted using machine learning methods including least square support vector machine ls svm adaptive neuro fuzzy inference system anfis and anfis optimized by harris hawk optimization anfis hho and the results were compared with that of the experimental methods several scenarios were designed by different combinations of input variables such as the average depth of the flow h average flow velocity u and shear velocity u the results showed that machine learning models had a more efficient performance to predict k x than experimental equations the anfis hho with a scenario containing all the input variables performed better than the other two models with root mean square error mean absolute percentage error and coefficient of determination of 17 0 0 22 and 0 97 respectively furthermore the hho algorithm slightly increased the prediction performance of the anfis the discrepancy ratio dr evaluation criteria showed that experimental equations overestimated the values of k x while the machine learning models resulted in higher precision also the results of taylor s diagram showed the acceptable performance of the anfis hho model compared to other models given the promising results of the present study it is expected that the proposed approach can be efficiently used for similar environmental modeling problems keywords dispersion coefficient water quality modeling streamflow machine learning abbreviations acor ant colony optimization algorithm ade advection dispersion equation anfis adaptive neuro fuzzy inference system ann artificial neural network ba bee algorithm bn bayesian network cs cuckoo search de differential evolutionary dr discrepancy ratio epr evolutionary polynomial regression fm fuzzy model ga genetic algorithm gep gene expression programming gmdh group method of data handling gp genetic programming hho harris hawks optimization ica imperialist competitive algorithm ls svm least squares support vector machine m5 model tree mape mean absolute percentage error mars multivariate adaptive regression spline max maximum min minimum mt model tree nf neuro fuzzy pomggp pareto optimal multigene genetic programming pso particle swarm optimization rmse root mean square error sd standard deviation svm support vector machine woa whale optimization algorithm nomenclature a cross sectional area of the flow b regression bias b water surface width c cross sectional concentration e error e indicates the escaping energy of the prey e0 randomly changes inside the interval 1 1 in the hho g acceleration due to gravity h the average depth of the flow j rabbit represents the random jump in the hho k x longitudinal dispersion coefficient lb upper bound n denotes the total number of hawks n number of samples p the consequent model parameters anfis q the consequent model parameters anfis r 1 r 2 r 3 r 4 random numbers between 0 and 1 in the hho r2 coefficient of determination t weight t the maximum number of iterations in the hho u average flow velocity u shear velocity ub upper bound w transpose operator respectively x input variable anfis x t 1 the position vector of hawks in the next iteration x o observed value x p predicted value anfis x rabbit t the position of rabbit y input variable β equal to 1 0 in triangular channels β is a default constant set to 1 5 in the hho γ the regulation term for the error δx t difference between the position vector of the rabbit and the current location in iteration t σ the channel sinuosity φ x the nonlinear mapping of inputs to a high dimensional feature space 1 introduction in recent years the protection of rivers has been considered by national and international organizations responsible for quality control and protection of water resources the importance of river protection reveals in regions where large cities and industries are located near the rivers and rivers are the main supplier of the water needs tayfur and singh 2005 increasing the level of pollution in surface waters necessitates mixing and reduction processes in natural rivers one of the most important and efficient river environmental management methods is to improve the self cleaning ability of the river pourabadei and kashefipour 2007 currently agricultural and industrial wastewater entrance to natural rivers has become a common management practice in environmental engineering because of its oxidization and organic matter removal capabilities to control the quality of surface water resources pollutants entrance to natural rivers and open streams is conducted using costly methods this requires accurate knowledge about the pollutant transfer to the rivers and the possibility of transmission and mixing and self cleaning of pollutants by river flow pourabadei and kashefipour 2007 the process of pollutant transfer can be seen in three stages in the first stage a pollutant is diluted due to its initial movement in the channel in the second stage the pollutants are mixed because of the turbulent transfer processes throughout the river section in the third stage after completing the cross section longitudinal dispersion tends to clear the longitudinal changes in pollutant concentrations french 1986 the longitudinal dispersion coefficient k x of pollution is an essential variable in modeling the pollution status of rivers accurate calculation of k x is required in several applied hydraulic problems such as river engineering environmental engineering river mouth problems and risk assessment of injection of dangerous pollutants into rivers sedighnezhad et al 2007 seo and bake 2004 various equations have been proposed to calculate the k x using experimental analytical and mathematical methods k x can be easily determined when actual field data are available experimental equations are used in rivers where the characteristics of pollution dispersion are unclear kashefipur and falconer 2002 analytical and mathematical methods have high computational complexities and are often time consuming experimental methods are of the research methods used to test hypotheses they aim to investigate the effect of specific stimuli methods or environmental conditions on a group of subjects one of the characteristics of the experimental methods is that they provide results by manipulating the variables and conditions obtained for the group selected by random assignments in general these methods result in significant errors in the prediction of k x in this regard the researchers have presented relationships that depend on the river s hydraulic parameters namely flow velocity river shear velocity flow depth and river width these relationships are valid in a specific hydraulic condition and do not provide reliable results for outlier values azamathulla and wu 2011 table 1 summarizes the available experimental equations for the calculation of k x based on the average depth of the flow h average flow velocity u shear velocity u and water surface width b elder 1959 introduced the most straightforward equation which relates the k x to h and u later researchers have developed equations that use more parameters such as u and b deng et al 2001 introduced a new equation in which k x depends not only on the geometric and hydraulic characteristics of the flow but also on the transverse dispersion coefficient ε t the latter also depends on the hydraulic and geometric parameters of the flow machine learning models have gathered considerable attention due to not requiring the physical information of the channels and their physical structure researchers have extensively used these models in recent years due to the lack of difficulties that occur in numerical models and not having the limitations and high costs of experimental models artificial neural network ann adaptive neuro fuzzy inference system anfis least square support vector machine ls svm and bayesian networks bn are among these models these models have been applied for the assessment of sediment transport demonstrating acceptable results azamathulla et al 2012 azamathulla et al 2009 afan et al 2015 kumar et al 2016 mount and stott 2008 milan et al 2018 najafzadeh and oliveto 2020 saberi movahed et al 2020 najafzadeh and ghaemi 2019 najafzadeh and etemad shahidi 2016 balf et al 2018 in recent years researchers have used machine learning based methods to predict k x in a leading study tayfur and singh 2005 predicted k x using data of 71 samples from 29 rivers in the united states using ann and showed that ann had an acceptable ability to estimate the amount of k x riahi madvar et al 2009 used the anfis approach to predict k x based on 73 data samples of which 70 of the data were used for training and the rest for the test error evaluation criteria showed that anfis had better performance than experimental models and could be combined with mathematical models from 2009 to 2016 besides ann and anfis other models such as svm and gep were used to predict k x table 2 for the first time najafzadeh and tafarojnoruz 2016 used the nf gmdh pso hybrid model and the mt ann de and ga models to predict k x they used 233 data samples of which 75 of the data were selected randomly for training and the remaining data for the test the models performance was acceptable and the nf gmdh pso hybrid model was capable of predicting k x with the highest performance using the ability of evolutionary algorithms some researchers have developed empirical relationships in this field tayfur 2009 sahay and dutta 2009 sahay 2013 in the field of evolutionary algorithms alizadeh et al 2017a 2017b 2017c used the pso algorithm to derive new equations to predict k x in natural rivers based on their study pso could improve the performance of predictive equations by finding the optimal values of the coefficients in another study memarzadeh et al 2020 used the woa evolutionary algorithm to find the optimal coefficients and showed that the algorithm improved the performance of predictive equations ls svm models have also been used in various studies including land temperature prediction water quality satellite images and sensor development showing an excellent performance chauchard et al 2004 zheng et al 2008 leong et al 2019 najafzadeh and ghaemi 2019 zhou et al 2020 compared with the classical svm method ls svm has less computation complexity leading to higher accuracy and lower consuming time in a study kong et al 2008 employed ls svm and wavelet transform to predict daily river flow their results indicated the appropriate accuracy of the ls svm model in flow prediction najafzadeh and ghaemi 2019 compared the ls svm and mars models with ann and anfis to predict water quality indicators they used 200 data sets considering nine input variables and concluded that ls svm and mars performed better than the other models anfis is another model useful for data with uncertainties its relatively low accuracy in the modeling and being occasionally trapped in the local minima asefpour vakilian and massah 2016 najafzadeh et al 2016 necessitate the use of advanced optimization methods such as particle swarm optimization pso and differential evolution de to optimize the coefficients of the anfis model and therefore increase its performance ebtehaj et al 2019 used the pso algorithm to train an anfis model to simulate sediment transport in open channels the results indicated the acceptable performance of the anfis pso hybrid model compared to the anfis model azad et al 2018 used the anfis model and the ga pso acor and de evolutionary algorithms to simulate the quality parameters of the gorganrood river iran their results showed that the de algorithm is more accurate than the other evolutionary algorithms in another study they used these algorithms to model rainfall runoff in isfahan iran azad et al 2019 they showed that the anfis acor method resulted in the best performance with r2 rmse and si of 0 92 2 73 and 0 26 respectively yang et al 2019 used anfis ga and anfis pso hybrid models to predict landslides the anfis ga and anfis pso models could predict ground vibration with acceptable accuracy yang et al 2019 seifi and riahi madvar 2018 used 505 data divided into training 60 and test 40 samples to predict k x they used the ann and anfis models along with ga evolutionary algorithm to improve the performance of them the results showed that ga remarkably improved the performance of anfis so that anfis ga predicted the value of k x more accurately than other models proposed by heidari et al 2019 the harris hawks optimization hho is one of the most recently algorithms available for optimization problems in this research hho is used to improve the training capability of anfis in predicting k x in natural streams amount the literature review on the application of machine learning in predicting the value of k x shows that it is possible to increase the prediction performance with advanced machine learning models ls svm is one of the models that has shown promising results in various studies and therefore its use in predicting k x can be efficient along with models such as anfis also due to the poor performance of anfis especially for the test data in some cases evolutionary optimization algorithms can be used to improve its results in this study an attempt has been made to use one of the most advanced evolutionary algorithms to improve the results of machine learning algorithms since machine learning models are not sensitive to the nature of the input data it has been tried in this study to create various scenarios by different combinations of input variables i e b h u u b h u u β and σ to determine the most appropriate scenario for estimating k x moreover the most suitable machine learning model is selected based on rmse mape r2 and taylor s diagram the selected models along with the selected input scenario are compared with the results of some experimental equations 2 materials and methods 2 1 advection dispersion equation ade k x is an essential factor in the prediction of the concentration which was introduced by taylor 1954 in a one dimensional 1d environment eq 1 1 c t u c x k x 2 c x 2 where c is cross sectional concentration t is time and x is the longitudinal direction throughout the flow fisher 1967 developed eq 2 to calculate the k x for pollutant transfer tayfur and singh 2005 2 k x 1 a 0 b h u 0 y 1 ε t h 0 y h u dydydy where a is the cross sectional area of the flow h is the local depth of the flow u is the deviation of the speed at depth from the average speed and y is the coordinates in the lateral direction eq 2 is the basis of many experimental methods for determining k x the most important of which are presented in table 1 fisher 1967 proposed a simpler equation eq 3 for taylor s method 3 k x 0 011 u 2 b 2 h u fisher et al 1979 presented eq 4 to calculate ε t for the wide and direct rivers with the uniform flow and constant depth in width kashefipur and falconer 2002 4 ε t 0 15 h u 2 2 dataset data from 29 rivers in the united states including 71 data samples were extracted from deng et al 2001 they were used to analyze the experimental equations and construct the machine learning models table 3 summarizes the statistical characteristics of the dataset used in this study it is observed that the k x of the rivers ranged from 1 90 to 892 m2 s while its average value was ca 107 m2 s β indicates the channel shape introduced by deng et al 2001 5 β ln b h β is equal to 1 0 in triangular channels otherwise it has either a parabolic shape β 2 having a flatbed region with two curving banks 2 β 5 or a rectangular shape β 5 deng et al 2001 σ is the channel sinuosity which is defined as the ratio of the channel length to the valley length chang 1988 the sinuosity of the streams and rivers varies from 1 08 to 2 54 2 3 least squares support vector machine ls svm suykens and vandewalle 1999 introduced ls svm which is very similar to the classical svm but has lower computation and time complexity and higher performance given a set of training data such as x k y k k 1 n whose input and output data include x k r n and y k r respectively eq 6 shows the nonlinear regression function in the initial weighting suykens and vandewalle 1999 6 y x w t φ x b where t b and w are weight regression bias and transpose operator respectively φ x is the nonlinear mapping of inputs to a high dimensional feature space this nonlinear regression can be solved using an optimization process eq 7 7 min j w e 1 2 w 2 w 1 2 γ k 1 n e k 2 with the constraint 8 y k w t φ x b e k k 1 n and γ is the regulation term for the error e γ controls the approximation function so the larger the γ value the higher the error is solving this equation using the lagrangian form of the main objective function we have 9 l w b e a j w e i 1 n α i w t φ x k b e k y k where α i is the lagrangian coefficient based on the karush kuhn tucker condition the ls svm model is written for the approximation function as eq 10 mellit et al 2013 10 y x k 1 n α k k x x k b where k x x k is called kernel function in this study the gaussian kernel function is used eq 6 mellit et al 2013 11 k x x k exp x x k 2 σ 2 2 4 adaptive neuro fuzzy inference system anfis the anfis model was developed by combining a fuzzy inference system fis and ann jang 1993 anfis is a fuzzy rule based network that uses adaptive systems to facilitate the learning and adaptation process ozgan et al 2009 the main purpose of the anfis is to optimize the fis parameters by using input output data sets through a learning algorithm in this structure the nodes in the first and last layers represent the input and output data while the nodes in the hidden layers are identified as membership functions and rules the sugeno model is widely used in this structure because of its interpretability high computational capability and adaptability for two inputs x 1 x 2 and one output y of the sugeno type anfis structure the rules are defined as eqs 12 and 13 12 rule 1 if x 1 is a 1 and x 2 is b 1 then f 1 p 1 x 1 q 1 x 2 r 1 13 rule 2 if x 1 is a 2 and x 2 is b 2 then f 2 p 2 x 1 q 2 x 2 r 2 where a and b are the fuzzy sets p q and r are the consequent model parameters that are determined in the training stage anfis architecture includes five layers fig 1 in the first layer the input data passes through different membership functions and the membership degree of input nodes to different fuzzy intervals is determined using membership functions in the second layer which contains the rule nodes fuzzy values are multiplied by each node and the result is the weight of the rules the nodes of the third layer normalize the weight of the rules the resultant nodes create the fuzzy based rule outputs the fifth layer consists of a single node that calculates the total output of the system this layer transforms the results of each fuzzy rule into a non fuzzy output using a defuzzification process 2 5 development of the anfis using harris hawks optimization neuron based methods suffer from several drawbacks such as trapping in local minima and slow convergence of training especially for wide search spaces asefpour vakilian and massah 2018 therefore there is a need to use hybrid methods that use optimization techniques to optimize the parameters of the anfis in this study the hho evolutionary algorithm was used along with the anfis model to improve the anfis model according to the literature the hho algorithm has its unique features that can significantly improve the traditional anfis model the relationships of hybrid anfis hho used in this study to predict the kx is depicted in fig 2 firstly scenarios with different variables were given to the model as input and then the type of the fuzzy function and the anfis structure is determined the anfis is improved with evolutionary algorithms to achieve better results in this structure the objective function is to minimize the error of the predicted values finally the amount of k x is predicted by the optimized model like many other evolutionary algorithms hho is a nature inspired and population based algorithm which is based on rabbit hunting by harris hawks heidari et al 2019 in the hho method the harris hawks are the candidate solutions fig 3a they perch randomly on some locations and wait to detect prey based on two strategies their position is mathematically expressed as eq 14 14 x t 1 x rand t r 1 x rand t 2 r 2 x t q 0 5 x rabbit t x m t r 3 lb r 4 ub lb q 0 5 where x t 1 is the position vector of hawks in the next iteration of t x rabbit t is the position of rabbit x t is the current position vector of hawks r 1 r 2 r 3 r 4 and q are random numbers between 0 and 1 which are updated in each iteration lb and ub are the lower and upper bounds of variables x rand t is a randomly selected hawk from the current population and x m is the average position of the current population of hawks the average position of hawks is obtained using eq 15 15 x m t 1 n i 1 n x i t where x i t indicates the location of each hawk in iteration t and n denotes the total number of hawks the energy of prey decreases considerably during the escape the energy of prey is modeled using eq 16 16 e 2 e 0 1 t t where e indicates the escaping energy of the prey t is the maximum number of iterations and e 0 is the initial energy e 0 randomly changes inside the interval 1 1 at each iteration the hawks intensify the besiege process to catch the exhausted prey effortlessly the e parameter is utilized to model this strategy and enable the hho to switch between soft and hard besiege processes in this regard when e 0 5 the soft besiege happens and when e 0 5 the hard besiege occurs fig 3b if r 0 5 and e 0 5 the rabbit still has enough energy and tries to escape by some random misleading jumps but finally it cannot during these attempts the harris hawks encircle it softly to make the rabbit more exhausted and then perform the surprise pounce this behavior is modeled by eqs 17 and 18 17 x t 1 δ x t e j x rabbit t x t 18 δ x t x rabbit t x t where δx t is the difference between the position vector of the rabbit and the current location in iteration t r 5 is a random number between 0 and 1 and j rabbit represents the random jump strength of the rabbit throughout the escaping procedure if r 0 5 and e 0 5 the prey is exhausted and it has low escaping energy besides harris hawks hardly encircle the prey to perform the surprise pounce finally fig 3a in this situation the current positions are updated using eq 19 19 x t 1 x rabbit t e δ x t 2 6 performance evaluation criteria the dataset was randomly divided into two groups 70 of the data for the training of the models and the remaining for the test root mean square error rmse mean absolute percentage error mape and coefficient of determination r2 were used to evaluate the scenarios and machine learning methods 20 rmse i 1 n x o x p 2 n 21 mape 100 n i 1 n x o x p x o 22 r 2 1 i 1 n x p x o 2 i 1 n x o x o 2 where x o is the observed measured value x p is the predicted value and n is the number of samples the lower rmse mape and higher r2 values present the better performance of the model 3 results and discussion in this section firstly the results of the machine learning models are described and analyzed and then the results of the machine learning models are compared with that of the experimental equations since several variables are effective in the prediction of k x 10 scenarios were defined with different combinations of input variables according to table 4 the complete scenario included all the input variables i e b h u u b h u u β and σ each scenario was used separately to train the machines and the performances of the machines were compared to obtain the most efficient scenario 3 1 results of the ls svm model table 5 shows the optimum values of the ls svm parameters the gaussian kernel in the ls svm method has two parameters namely σ2 and γ the optimum value of which was obtained equal to 5 365 and 136 03 respectively according to table 6 the scenarios that included more input variables had better accuracy than the scenarios with three or four input variables except scenario 8 which included only three input variables of b h and u therefore in some cases where only the values of b h and u are available k x can be predicted with appropriate performance scenario 1 which includes all the input parameters except σ is the best scenario to predict the value of k x using this scenario the values of rmse mape and r2 for the test data were obtained equal to 24 6 0 42 and 0 96 respectively the complete scenario also resulted in an acceptable performance however in this scenario despite its good accuracy on the training data the prediction of the test data was conducted with lower performance compared to scenario 1 the trend of k x changes for the measured and predicted values of the test data shows that using the ls svm model scenario 1 could efficiently predict the k x behavior fig 4 as can be seen in fig 4 the measured values are well predicted by the ls svm model furthermore the measured and predicted values are very close to each other based on the line fitted to the data 3 2 results of the anfis and anfis hho models the appropriate structure of the anfis model and the optimal values for its parameters are brought in table 7 according to the table the gaussian membership function was selected as the most appropriate fuzzy membership function since the anfis uses the sugeno type method the linear function was selected as the best output function of the model the optimal structure and parameter values of the hho algorithm can be seen in table 8 achieving the appropriate values for each parameter requires implementing the model with a wide range of values which ends with determining the appropriate values of the parameter the population for hho was 30 while the maximum number of iterations was obtained to be 1500 table 9 shows the values of the performance evaluation criteria for the anfis and anfis hho models the anfis model predicted the training data with acceptable performance while exerted poor results for the test data it can be said that the training algorithms of the anfis are trapped in local optimal minima and as a result irrational predictive errors are observed for the test data for this purpose the hho algorithm was used to optimize anfis parameters to solve this problem and improve the results for most of the scenarios a large difference was observed between the measured and predicted data obtained by anfis however in the anfis hho model the prediction performance of the training and test data are relatively similar one of the essential points of using machine learning algorithms that should always be assessed is the slight difference between the prediction accuracy of training and test data which was not observed in the anfis model the complete scenario which included all the input parameters resulted in the best results in both models using this scenario the values of rmse mape and r2 of the anfis model for the test data were 73 4 2 53 and 0 87 respectively these values for the anfis hho model were 23 63 0 38 and 0 94 respectively the results indicate that the use of the hho algorithm has significantly improved the predictive performance of the anfis model the trend of k x changes for the measured and predicted values of the test data is depicted in figs 5 and 6 for the anfis and anfis hho models respectively the figures show that the complete scenario was capable of efficient prediction of k x behavior fig 5 shows that although k x always has a positive value negative values are predicted for k x using the anfis model which is one of the limitations of the anfis model however in fig 6 despite the presence of multiple peak data the anfis hho model has detected these values correctly with relatively acceptable performance furthermore the measured and predicted values are very close to each other based on the line fitted to the data 3 3 the comparison of the machine learning models and experimental equations some experimental models for the calculation of k x that were proposed by previous studies are compared with machine learning algorithms in this section table 10 shows the evaluation criteria of the models including rmse mape and r2 according to the table the machine learning models resulted in a better performance than the experimental equations among the experimental models the equations introduced by sahay and dutta 2009 and zeng and huai 2014 had a relatively better performance compared to other experimental models rmse mape and r2 for sahay and dutta 2009 equation were equal to 283 0 85 and 0 43 respectively while these values were equal to 163 3 45 and 0 4 respectively for the equation of zeng and huai 2014 in contrast all the machine learning models used in this study were very accurate among them the anfis hho model resulted in the highest performance using this model the values of the rmse mape and r2 were equal to 17 0 0 22 and 0 97 respectively it can be seen that there is a significant difference between the performance of the experimental and machine learning models fig 7 shows the measured and predicted data obtained by the experimental equations and machine learning models as can be seen unacceptable prediction results are obtained using the experimental equations in these equations the difference between the measured and predicted values and compared to the regression fitted line is sometimes large according to the figure the most suitable match is achieved by the machine learning models and among them the anfis hho model it can be concluded that the experimental equations are not capable of predicting the k x and the relationships between the input variables and the output are more complex than a simple linear model therefore machine learning models should be used to predict the k x values of the rivers one of the most suitable methods to compare the performance of several predictive models is to use taylor s diagram taylor s diagrams of the experimental and machine learning models are depicted in fig 8 a and b respectively the x and y axes indicate the standard deviation of the data the quarter circle arc shows the value of the correlation coefficient of arbitrary data and the observation data which varies from 0 to 1 the measured data lies on the x axis and a predicted data close to the x axis indicates a strong correlation with the measured data the green arcs indicate the root mean square deviation rmsd according to fig 8 a the results of all experimental equations had a correlation coefficient between 0 6 and 0 7 while according to fig 8 b the correlation coefficient is more than 0 95 for the machine learning models the highest correlation coefficient was obtained for the anfis hho model which was equal to 0 99 among the experimental models the highest standard deviation of data was observed for tavakollizadeh and kashefipur 2007 equation which was ca 3500 while for other experimental equations it was less than 1800 this coefficient was much lower in machine learning models ca 170 the lowest value of this coefficient was obtained for the anfis hho model furthermore the rmsd values for the experimental equations were very large in the range of 500 3500 indicating a significant difference between the data predicted by the machine learning models and the experimental equations in total the results show that the anfis hho method had better efficiency compared to the other two methods furthermore the discrepancy ratio dr kashefipur and falconer 2002 was used in this study to evaluate the performance of the models eq 23 23 dr log k xp k xm where k xm and k xp indicate the measured and predicted values for the k x of the river respectively if the value of the ratio is zero k xp k xm dr 0 there is no difference between the measured and predicted values if the ratio is positive k xp k xm dr 0 the model has overestimated the values and if the ratio is negative k xp k xm dr 0 the values are underestimated by the model according to fig 9 the dr of the ls svm model was in a range between 0 3 to 0 3 in other words 45 of the data was slightly overestimated while 45 of the remaining was underestimated the anfis and anfis hho models had similar behavior to the ls svm model the dr values higher than zero for most of the experimental equations show that these models have been accompanied by an overestimation for example 50 of the data predicted by the equation of zeng and huai 2014 had a dr value between 0 3 and 1 which indicates that in most cases it resulted in an overestimation no dr values higher than 1 or lower than 1 was observed using this equation finally according to fig 9 it can be said that all three models of ls svm anfis and anfis hho have resulted in predicted data in a balanced range the converging trend of a model to the minimum rmse is essential for model training according to fig 10 this trend was different for the studied models the hho algorithms had an initial rmse of ca 85 m and then converged rapidly to the optimum point after a small number of iterations finally after 600 to 1500 iterations all the algorithms have reached a particular error and maximum convergence has been obtained it is observed that after convergence the rmse of the hho algorithm was 13 8 which was higher than that of the anfis hho model after convergence the measured and predicted values of the experimental equations and machine learning models used in the present study are brought in fig 11 a and b respectively according to fig 11 a in the steps where the river s kx values have a short peak the experimental equations resulted in a significant overestimation the equation of tavakollizadeh and kashefipur 2007 resulted in an irrational prediction in step 38 which has decreased its performance significantly it can be said that the experimental equations are not able to correctly calculate the k x values of the outlier samples since they usually face remarkable errors for these samples however as shown in fig 11 b the machine learning models have been able to correctly identify the values of k x while the anfis hho model has had the most compatibility among them therefore it can be claimed that the anfis hho model is the best model for the prediction of k x values 3 4 discussion the results showed acceptable performance of ls svm and anfis hho models according to the results obtained from the error evaluation criteria rmse mape r2 and taylor s diagram the anfis hho model was proposed although both models had similar results the number of optimized parameters in the ls svm model is less than that of anfis hho and therefore the ls svm model is easier to use than the anfis hho hybrid model dr values also showed the similar performance of both prediction models because both models overestimated or underestimated the output with 0 40 to 0 45 errors which was very small compared to the anfis model and experimental equations in general it can be said that evolutionary algorithms had a high ability to improve machine learning models for better prediction results the results of this study were in along with seifi and riahi madvar 2019 which used algorithms for optimizing ann anfis and gmdh to provide better results than classical models another approach considered in this study and was much less considered in previous studies was the number of input variables to predict k x and their combination to achieve the most appropriate accuracy for this purpose several scenarios were developed in this study which were dimensional and non dimensional combinations of variables the results showed that all input variables were required to have proper accuracy in the anfis model and its hybrid model but when using ls sm the presence of all input parameters except σ was sufficient to achieve the appropriate accuracy furthermore when the non dimensional parameters were not considered as input parameters the accuracy of the results was somewhat reduced therefore combining both dimensional and non dimensional input variables is recommended to have proper prediction results in predicting k x values at peaks the hybrid model was able to estimate the values correctly in almost all data while in the other two models especially anfis these values were associated with significant errors fig 6 nevertheless in this study for the first time a combination of various dimensional and non dimensional input variables was considered to evaluate their effects 4 conclusion before the emergence of machine learning models experimental equations were used to predict the k x of the river however recently various researchers have been able to increase the accuracy of k x predictions by using machine learning models in this study several advanced machine learning models were developed to predict the k x of the river three models i e ls svm anfis and anfis hho were used to predict the value of k x furthermore the results of some of the well known experimental equations proposed by the previous studies were compared with the results of machine learning models the river data based on deng et al 2002 were used to evaluate the performance of models and experimental equations the results of this study can be summarized as follows 1 machine learning models require more input variables for efficient prediction of k x 2 although anfis exerted an acceptable performance in the prediction of the training data its results were poor in predicting the test data which indicates this model is trapped in the local optimal minima during the training 3 the performance of the machine learning models was much better than that of the experimental equations which proves the necessity of using machine learning models in this study 4 performance evaluation criteria and taylor s diagram showed that the best model for the prediction of the k x values is anfis hho furthermore the anfis hho hybrid model performed better than the anfis model which shows that using the evolutionary optimization algorithms can improve the anfis model s performance in predictions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
