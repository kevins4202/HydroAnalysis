index,text
410,this article studies the individual contribution of each term in the navier stokes darcy brinkman equation to the fluid linear momentum balance and the consequences of opting for the darcy or brinkman equations in 3d reactive flow simulations of a vuggy carbonate a two scale continuum model was used to simulate the acidification of a carbonate sample using the darcy and brinkman equations rock heterogeneity is considered in the initial porosity and permeability fields which are calculated directly from micro ct images simulations showed that the darcy equation predicts the acid breakthrough earlier in most cases the convective acceleration term in the brinkman equation plays an important role in describing the fluid momentum balance at high injection velocities and this is a clear evidence against the use of the darcy equation to model reactive flow in such conditions keywords digital rock physics carbonate dissolution reactive flow two scale continuum model brinkman equation darcy equation micro ct 1 introduction reinjection of co2 is currently carried out by oil industry as a tertiary recovery method with the advantage of avoiding emissions to the atmosphere nevertheless when in contact with a carbonate reservoir co2 may cause adverse effects such as carbonate dissolution wormhole formation and collapse of the injection well klokov et al 2018 peng et al 2015 bickle et al 2017 qajar and arns 2016 ahmadi et al 2015 to avoid such problems it is important to understand the rock dissolution processes caused by the co2 injection for which computational simulation has emerged as an essential tool mehmani et al 2020 hao et al 2019 youssef and awotunde 2019 golfier et al 2002 khan et al 2017 hayat et al 2016a 2016b accurate estimates of the velocity field inside pore systems are the key factor in a computational reactive flow simulation since it directly affects the transport of chemical species and other kinetic calculations darcy navier stokes and navier stokes darcy also called brinkman equations have been used to model the flow field inside porous media oliveira et al 2019 molins et al 2019 kim et al 2018 singh et al 2018 huber et al 2014 the darcy equation has been widely used in studies at different scales from plugs to reservoir simulations srinivasan and nakshatrala 2012 maheshwari et al 2014 ratnakar et al 2013 jiang 2011 it ignores acceleration terms and fluid fluid viscous interactions using only one effective medium parameter the hydraulic permeability to account the effect of pore structure in the overall velocity field neuman 1977 used an averaging procedure to obtain the darcy equation directly from the navier stokes equation neglecting the terms of fluid acceleration for an anisotropic porous medium saturated by an incompressible homogeneous newtonian fluid flowing at low reynolds number later whitaker 1986 formally derived the darcy equation without using constitutive assumptions due to these simplifications darcy s equation is not a valid approximation under certain conditions such as alterations in the measured permeability due to changes in the injection pressure or by changing the injecting fluid itself ziabasharhagh et al 2008 steenkamer et al 1995 jackson and james 1986 the navier stokes equation on the other hand requires a detailed description of the pore space geometry turning the mesh generation into a major challenge chen et al 2018 deng and peters 2018 al khulaifi et al 2018 the brinkman equation is a combination of linear momentum and mass conservation for the fluid in large pores and flow channels and darcy s equation for regions with unresolved pores it is constructed in a way that in a simulation cell representing free flow regions such as inside vugs and wormholes the darcy term tends to zero and navier stokes components govern the flow in contrast in simulation cells representing sub resolution porous media the navier stokes terms apart from the pressure gradient become irrelevant resulting in darcy s equation basirat et al 2015 some studies compared the darcy and brinkman equations for reactive flow simulations showing more accurate results when the brinkman equation is used sheremet and trifonova 2014 marušić paloka et al 2012 especially in cases where high conductive paths such as fractures and vugs in pore system simulations are present in the rock hao et al 2019 liu and liu 2016 the brinkman equation has been extensively applied to reactive flow simulations morales and showalter 2017 galvis et al 2015 fei et al 2020 tumuluri and amaranath 2018 nasser el dine and saad 2018 srinivasan and rajagopal 2014 remarkably when the sub resolution porosity plays an important role on the overall fluid flow liu and mostaghimi 2018 showed the effect of microporosity in carbonate samples by comparing computational simulations with experimental results they reported substantial underestimation of the reactant penetration on porous medium when microporosity was neglected soulaine et al 2016 showed the strong impact on the permeability estimates caused by microporosity mesh refinement another important aspect in reactive flow simulations was studied by williamson et al 2019 using 2d and 3d numerical experiments they showed the importance of error estimates to create a new adaptive strategy for mesh refinement despite the extensive research area involving the brinkman equation most of the studies neglect the acceleration terms and assume low fluid velocities in simulations therefore the main motivation for this work is to fill a clear gap in the literature regarding a quantitative study on the individual contribution of each term present in brinkman s equation we consider this knowledge crucial to the general fluid flow science and particularly for the understanding of reactive transport in porous media with multiscale features which in turn plays an essential role for oil recovery techniques such as water alternating gas wag injection and co2 reinjection we quantified the magnitudes of the five components in brinkman s equation for different regions in the computational mesh such as inside a wormhole and in the unresolved porous media the paper is divided in two parts first we established whether reactive flow simulations using the brinkman and darcy s equations are equivalent in a vuggy carbonate the influence of fluid velocity dissolution rate constant and permeability assigned to pores was considered in the simulations in the second part we investigated the effects of fluid fluid viscous interactions in free flow regions for an imposed constant flow rate the pressure drop decreases due to the continuous rock solubilization potentially masking the fluid fluid viscous effects eventually present thus its quantification had to be made via computational simulation at low injection velocities local and convective accelerations are expected to be small at high velocities we showed that convective acceleration became significant to describe the flow finally we accounted for the simultaneous effects of viscous fluid fluid interactions in large pores vugs and developing wormholes together with the computation of terms proportional to the local and convective accelerations we consider this part the main contribution of this work 2 numerical methods 2 1 mathematical modeling in our previous work ferreira et al 2020 we modified the two scale continuum model developed by panga et al 2005 to simulate reactive flow in vuggy carbonates we used the brinkman equation to account for momentum conservation and implemented this model using the software openfoam open source field operation and manipulation weller et al 1998 openfoam 2020 in the first part of this study we investigated whether the brinkman and darcy equations perform differently in reactive flow simulations for this purpose in addition to the solver used in our previous work we implemented a second one replacing the brinkman by darcy equation to differentiate them the former will be referred to as solver b brinkman while the latter will be solver d darcy let u u x u y u z be the velocity vector in m s 1 darcy s equation used in solver d is 1 u k p μ brinkman equation used in solver b is 2 ρ u t ρ u u ϵ ϵ p μ 2 u ϵ μ k u where p is the pressure kg m 1 s 2 μ is the viscosity kg m 1 s 1 ρ is the fluid density kg m 3 t is the time s ϵ is the porosity and k is the absolute permeability m2 we considered an isotropic porous medium so that the intrinsic and apparent permeabilities are equivalent scheidegger 1974 bear 1988 gravitational effects were not considered in the simulations besides the darcy and brinkman equations other equations that compose the models at the darcy and pore scales are common to both solvers and are briefly presented in the next section a detailed description of the model was presented by ferreira et al 2020 2 1 1 equations for the darcy scale in addition to eqs 1 and 2 according to the solver the darcy scale model is composed of the following equations ferreira et al 2020 continuity equation 3 ϵ t u 0 acid transport 4 ϵ c f l t u c f l ϵ d e c f l a v r kinetics 5 r k c c f l c f l 1 k s k c r f 6 r f 1 ϵ 1 ϵ 10 20 porosity update 7 ϵ t r a v α ρ s where cfl is the solution acid concentration mol m 3 d e is the effective dispersion tensor m2 s 1 av is the interfacial area per volume m 1 r is the reaction rate mol m 2 s 1 kc is the local mass transfer coefficient m s 1 ks is the reaction rate constant at the surface m s 1 rf is the reaction factor inside free flow regions such as vugs ϵ 1 and rf is zero meaning that no reaction occurs in these regions outside these regions ϵ 1 rf 1 and the reaction is taken into account lastly α is the dissolving power of the acid defined as the mass of dissolved rock per amount of reacted acid kg mol 1 and ρs is the rock density kg m 3 2 1 2 equations for the pore scale the equations for the pore scale model are used to update permeability pore radius and interfacial area as dissolution occurs as well as the coefficients for mass transfer and dispersion as follows ferreira et al 2020 8 k t k o ϵ t ϵ o ϵ t 1 ϵ o ϵ o 1 ϵ t 2 β 9 r p t r p o k t ϵ o k o ϵ t 10 a v t a v o ϵ t r p o ϵ o r p t 11 2 k c r p d m sh sh b r e p 1 2 sc 1 3 12 r e p 2 ρ u r p μ 13 d e d e x d e t 14 d x d e x d m α 0 s λ x p e p 15 d t d e t d m α 0 s λ t p e p 16 p e p u d h ϵ d m where superscripts t and o represent the variable at the new time and old time steps respectively rp is the mean pore radius m β is an adjusting parameter sh is the sherwood number sh is the asymptotic sherwood number for the pore equal to 3 66 for spherical pores b is a constant b 0 7 rep is the reynolds number in the pore dm is the molecular diffusivity of the acid m2 s 1 sc is the schmidt number 1000 for liquids panga et al 2005 dex and det are the longitudinal and transverse terms of the dispersion tensor α 0s λx and λt are constants related to the porous media structure λx 0 5 and λt 0 1 for a pack of spheres dh is the pore hydraulic diameter dh 2rp for cylindrical pores and pep is the péclet number on the pore eqs 8 10 are semiempirical relations used to estimate the new values of permeability pore radius and interfacial area respectively due to porosity changes ratnakar et al 2013 panga et al 2005 kalia and balakotaiah 2007 2009 when β 1 eq 8 reduces to the kozeny carman model k ϵ 3 1 ϵ 2 eq 11 is an approximation to the sherwood number used to calculate the local mass transfer coefficient kc eqs 14 and 15 are derived from random walk models to estimate the effective dispersion tensor components finally eqs 12 and 16 estimate the dimensionless numbers of reynolds and péclet on the pore respectively 2 2 simulation reactive flow experiments using the carbonate indiana limestone with co2 rich brines and also the dolostone outcrop silurian dolomite with hcl both outcrops from kocurek 2018 were performed by ferreira et al 2020 in this work we used the parameters obtained by those authors with hcl since the total injection time to be simulated in this case was considerably smaller compared to the experiment with co2 1 h for the silurian with hcl versus 30 hours of injection for indiana limestone with co2 the selected plug had the following characteristics diameter 3 83 10 2 m length 3 7 10 2 m ϵ 11 8 k 1 7 10 2 d and was composed of 97 9 dolomite a microtomography micro ct image of this plug was acquired in an x ray scanner phoenix vtomex 140 kv 250 ma resolution 40 µm voxel before the acidification experiment this image was used to calculate the initial porosity and permeability fields as well as for the mesh generation following the same methods from our previous work ferreira et al 2020 the original micro ct image is available for download at the digital rocks portal doi 10 17612 v09y aw80 ferreira 2020 2 2 1 mesh generation since the original micro ct image dimensions 1300 1300 1560 voxels were too large to be handled by the solvers it was resampled to 379 µm voxel 101 101 115 voxels by using the lanczos resampling kernel this resampled image was used to generate the simulation mesh porosity and permeability fields an in house software reactivecenpesmesh was used to construct the simulation mesh by transforming the micro ct voxels directly into cubic cells 2 2 2 porosity distribution we estimated porosity at each voxel in the resampled micro ct image based on the grayscale range variations the sample is composed of 97 dolomite and was considered pure using the following steps 1 the grayscale level of the pores was assigned to porosity 100 gspore 2 the grayscale level of the solid phase was related to a background porosity bp gssolid 3 porosity was calculated directly in the micro ct voxels according to the following equation 17 ϵ v o x e l 100 b p g s v o x e l g s s o l i d g s p o r e g s s o l i d b p the deviation between the global porosity of the plug calculated by this methodology and that experimentally measured is 2 2 2 3 initial permeability distribution we considered the rock samples as being isotropic two methodologies were developed in our previous work ferreira et al 2020 to calculate the initial permeability distribution they are briefly described below methodology p k is estimated for each point of the mesh porosity values in each voxel are used as input in the winland equation kolodzie 1980 18 log r 35 0 732 0 588 log k 0 864 log ϵ where r35 is the pore aperture that corresponds to 35 of mercury saturation we performed a mercury injection capillary pressure test micp with a sample of the silurian dolomite outcrop to obtain the required capillary curve the curve is available at ferreira et al 2020 methodology s k is estimated for regions of similar permeabilities considering regions of similar grayscale values the resampled micro ct image of the plug is segmented in four phases pores high k phase more permeable medium k phase intermediary permeability and low k phase less permeable a sample of the same outcrop representative of the region high k was imaged at 4 µm voxel a direct numerical simulation dns was performed directly in this micro ct image voxels by using a stokes solver the permeability obtained 1 d was assigned to high k region the mean porosity of the medium k phase was calculated and used in winland correlation eq 18 to estimate k resulting in 3 5 10 2 d swanson correlation swanson 1981 was used to estimate k in the low k phase this correlation calculated a permeability between 0 22 and 1 10 3 d and the value 1 10 3 d was adopted for the low k phase permeability fig 1 presents the original micro ct image from the plug the resampled image and the calculated porosity field the differences between fig 1 a and b are small confirming that the resampling process maintained the rock heterogeneity the porosity field c reveals a highly heterogeneous sample fig 2 a shows the segmented image where a more permeable region is easily seen near the plug outlet upper part as well as on the left side of the plug fig 2 b and c correspond to the permeability fields estimated by the methodologies p and s respectively fig 2 b and c show smaller permeability gradients for methodology p which occurred because this methodology used the porosity at each cell to estimate the respective permeability the scale range from fig 2 b and c was used to highlight the permeability gradients the permeability range is larger and regions with permeability greater than 0 1 d are in white and can not be distinguished in these images free flow regions represent only 0 002 of this sample fig 2 a since this is the most critical region to differentiate the brinkman and darcy equations we increased the number of segmented pores in the original porosity field and generated two additional porosity fields modified 1 and modified 2 in which the free flow regions represent 2 7 and 13 2 respectively the permeability fields were then recalculated for the new porosity fields using the two previously described methodologies the resulting porosity fields are shown in fig 3 besides the standard mesh with 101 101 115 cells we generated two additional porosity and permeability fields maintaining the same porous zones as in the field modified 1 and using methodology p with different sizes 76 76 86 cells 510 µm voxel and 154 154 175 cells 250 µm voxel to evaluate how the chosen mesh size affects the solvers results 2 2 4 simulation cases table 1 summarizes the parameters adopted in all simulations where uref is the reference injection velocity and poutlet is the pressure at the sample outlet ferreira et al 2020 a layer of cells filled with fluid ϵ 1 is added to the inlet and outlet of each simulation mesh so that the following boundary conditions hold constant and uniform injection velocity at the inlet constant and uniform pressure at the outlet and lateral impermeable boundaries as shown in fig 4 in all figures the flow direction is upward simulations performed to evaluate the effects of mesh size section 3 1 are presented in table 2 in each case we adopted the porosity field modified 1 which was used to calculate the permeability field according to methodology p and ks 3 10 5 m s 1 a permeability equal to 10 d was assigned to the free flow cells k pore table 3 presents the cases simulated with solvers b and d to investigate whether the brinkman and the darcy equations are equivalent for modeling reactive flow simulations section 3 2 in section 3 3 simulations with solver b were used to calculate the contribution of each term in the brinkman equation for the fluid linear momentum distribution inside the porous medium and in free flow regions since the permeability fields were calculated via two methodologies p and s and simulations were performed with two solvers b and d each case from table 3 generated four simulations identified by the letters that represent the solver and methodology plus the case order number 3 results and discussion 3 1 effect of mesh size on simulation reactive flow simulations were performed for the three mesh sizes described in table 2 considering the total injection of 11 7 pore volumes pv of reactive brine into the mesh at a flow rate q 1 cm3 min 1 u i n j u r e f 1 45 10 5 m s 1 figs 5 and 6 show the evolution of sample permeability and three dimensional renderings of the segmented wormholes respectively from fig 5 we see that mesh size has little influence on the simulated permeability evolution curves for solver b on the other hand mesh refinement did impact the results for solver d suggesting that the darcy equation requires a finer mesh for convergence compared to the brinkman equation fig 6 shows that increasing the mesh size did not significantly affect the wormhole structures developed by acidification these results suggest that a mesh with 101 101 115 cells is adequate to avoid mesh size related artifacts in the simulations this mesh size was adopted in the next simulations 3 2 brinkman versus darcy in reactive flow simulations for the original porosity field did not reveal significant differences between solvers b and d especially with methodology p as shown in fig 7 this was expected since the main differences between the brinkman and darcy equations appear on the free flow regions and these represent only 0 002 of original porosity field we adopted two results as references for measuring the relative difference between the two solvers the accumulated injected pore volume pv at the acid breakthrough and the permeability curve shapes table 4 summarizes the ratio between the injected pore volumes at acid breakthrough predicted by solvers b and d pvb pvd the effects of free flow regions on simulations are clearly seen in table 4 where bigger differences were verified for simulations using the porosity field modified 2 the small differences observed in simulation cases 1 to 3 indicate that for reduced proportions of free flow regions the darcy and brinkman equations give similar results in most cases the difference was slightly larger for methodology s the one with higher gradients in the permeability field this gradient affected more markedly solver d resulting in bigger differences between simulations with both solvers besides solver d systematically predicted smaller volumes injected before acid breakthrough than solver b the cases where only kpore changed 1 and 2 as well as cases 4 and 5 indicate that kpore has a similar impact on simulations performed with solvers b and d for other cases see supplementary material since we only simulated the effect of kpore for porosity fields original and modified 1 free flow regions 0 002 and 2 7 respectively the effect of this parameter for higher proportions of free flow regions is a topic for future studies the impact of the dissolution rate constant ks on the simulation results depends on whether darcy or brinkman equation is being solved fig 8 displays the permeability curves for varying ks using the porosity fields modified 1 a and modified 2 b fig 8 shows that a higher value for the dissolution rate accelerated the formation of wormholes for both porosity fields however the difference between the darcy and brinkman solvers was accentuated by the increase of ks in cases 5 and 6 modified 1 but decreased for cases 7 and 8 modified 2 since solver b considers accelerations in the fluid and viscous effects increasing the proportion of free flow regions in the mesh impact differently each solver and this might be related to ks the same behavior was also noticed in table 4 comparing cases 2 and 3 original 5 and 6 modified 1 7 and 8 modified 2 one can see that the volume ratio between simulations with solvers b and d increased for simulations using porosity field original decreased for cases using the modified 2 field and displayed both behaviors for field modified 1 the difference may be significant up to 10 for cases bs 6 ds 6 these results demonstrate that higher proportions of free flow regions in the sample reduces the impact of ks in the solvers the curves and final porosity fields for case 16 modified 2 k p o r e 1000 d u i n j 100 uref ks 3 10 5 m s 1 using methodology s are displayed in figs 9 and 10 respectively see supplementary material for methodology p fig 9 shows that the permeability curves changed significantly between solvers solver d predicted a faster permeability increase early in the simulation and lower increase after a while with this both solvers predicted a similar plug permeability at the last time step simulated this might be the effect of higher accelerations in the fluid which is neglected by the darcy law at higher injection velocities dissolution occurred uniformly along a path inside the plug fig 10 indicating that the dissolution process changed from wormholing the wormhole formation at the inlet growing by dissolution at its tip until it reaches the sample outlet menke et al 2016 to preferential path formation wormhole formation by rock dissolution at a preferential path menke et al 2016 in table 4 we used the ratio between the injected volumes at acid breakthrough to quantify the solvers differences however it is difficult to determine the acid breakthrough exact moment at high injection velocities and therefore we adopted a different metric in these cases observing fig 9 it shows that the difference between solvers predictions is higher when the sample permeability reached 1 d and we considered this moment to compare the solvers as presented in table 5 for fields original and modified 1 the free flow regions contribution is small and the ratios from table 5 are similar to those observed for cases in which u i n j u r e f table 4 however for case 16 free flow regions 13 2 the volumes predicted by solvers b and d differ in more than 50 this is a strong evidence that brinkman s equation should be used for simulations with highly vuggy porous systems these results agree with the observations of marušić paloka et al 2012 who compared the darcy and the brinkman equations for simulations in a thin fracture and concluded that the brinkman equation should be used in such problems for cases 1 to 6 and at low injection velocities both solvers predicted similar pore systems for a given initial porosity and permeability fields however significant differences were observed in cases using higher injection velocities and porosity field modified 2 to illustrate this fig 11 compares the pore system predicted by each solver when the velocity porosity and permeability fields are changed the segmented pore systems for other cases have been made available in supplementary material fig 11 shows two types of differences one in the main wormhole a and another in the development of a secondary wormhole b the flow pattern that generated these differences also affected the respective permeability evolution curves since further developed secondary wormholes indicate a more distributed flow inside the sample the differences observed in the pore systems ratify the divergence of predictions for the two solvers in samples with higher amounts of segmented pores the model adopted in this work is an extension of that used by panga et al 2005 who considered a 2d model created an initial porosity field by adding random fluctuations to a mean porosity value and used the darcy equation to solve for the velocity field they were able to reproduce diverse dissolution patterns by varying the injection velocity although only a qualitative adjustment was reached for the accumulated volume of fluid injected at the acid breakthrough liu and liu 2016 used a modified version of the continuum model developed by panga et al to study acidification of highly heterogeneous carbonates using viscoelastic surfactant based self diverting acids they showed the importance of the heterogeneity to the wormhole formation path for 2d cases the improvements implemented in this work especially the use of a 3d model and the methodologies to generate porosity and permeability fields that express with high fidelity the rock heterogeneity allowed us to analyze more realistically the permeability curves besides we could inspect the shape and region of the plug where the wormhole developed which is a significant improvement compared to previous works which only reproduce the dissolution patterns sheremet and trifonova 2014 evaluated the darcy and the brinkman extended darcy model in natural convection simulations inside a vertical cylinder and observed that the darcy equation predicted overrated values for the average nusselt number in comparison with the brinkman extended darcy model in our case we observed that the darcy equation predicted smaller injected pore volumes before the acid breakthrough compared to the brinkman equation 3 3 calculation of the brinkman terms the brinkman terms were computed for cases bs 5 bs 14 and bs 15 at the last simulation time step accumulated injections of 12 12 and 50 pv respectively in two regions of interest in the porous medium far from the wormhole and inside the wormhole path fig 12 shows where these two regions were cut from the plug for case bs 15 region 1 presented in fig 12 a was extracted far from the plug walls inlet and outlet and consists of approximately 50 cells with mean porosity equal to 22 the extraction location was the same for the three cases studied the plug inlet and outlet were also avoided when extracting region 2 fig 12 b from the region shown in this figure we considered only the cells with porosity equal to 1 thus the final number of cells in region 2 was approximately 300 since the wormhole path changes with the injection velocity we could not use the same location for the three cases however the same procedure was used in the other two cases keeping a similar number of cells the value of each term of the brinkman equation for region 1 is presented in table 6 table 6 shows that within the porous medium the terms ϵ p and ϵ μ k u are of the same order of magnitude and the only ones relevant to the simulation in all directions the high pressure gradients result from the low permeability in the porous medium the darcy term ϵ μ k u on the other hand represents the viscous interactions between the fluid and the porous walls which together with the viscous fluid fluid interactions μ 2 u correspond to the flow head loss the relatively low permeability values associated with the porous medium reflect the interaction between the fluid and pore walls justifying its high values the local and convective accelerations as well as the term associated with viscous fluid fluid interactions are five or more orders of magnitude smaller than the pressure gradient the local acceleration term results from the rock dissolution responsible for new spaces to be occupied by the fluid unless an extremely intense dissolution process occurs local accelerations are expected to be small as observed in all cases presented in table 6 even in case bs 15 with injection velocity 100 times higher than that one in case bs 5 we observed small values for this parameter notice that for cases bs 5 and bs 14 this term increased five orders of magnitude in the flow direction the terms ρ u u ϵ and μ 2 u are strongly dependent on fluid velocity and since region 1 was extracted far from the wormhole its corresponding fluid velocity was small these results are in full agreement with the literature since the brinkman equation should reduce to darcy equation in the porous zones gulbransen et al 2009 since the simulated plug is cylindrical there are only two important directions to characterize the flow axial and transverse as confirmed by the similar results obtained for x and y directions in case bs 15 the last column in table 6 represents the sum of all terms since this sum is theoretically zero it is in fact a measure of the errors associated with the terms the error is much smaller than ϵ p and ϵ μ k u in all cases and directions although the values for the acceleration terms ρ u t and ρ u u ϵ are smaller than the error for directions x and z they are at least five orders of magnitude smaller than the pressure gradient the corresponding values for y direction in case bs 15 confirms that the acceleration terms contribution to the momentum balance is insignificant for region 1 table 7 presents the brinkman terms for the wormhole region table 7 shows that the contributions of terms ρ u t ρ u u ϵ and μ 2 u are significantly higher inside the wormhole path while ϵ μ k u become irrelevant since the flow occurs mainly at the channel dissolution processes are concentrated in the wormhole walls gradually widening the channel this explains the high increase observed in the local acceleration term compared to the results for the porous medium table 6 however this increase was insufficient to make this contribution significant it represents approximately 0 5 of ϵ p it also shows that for high velocity regions or at very high dissolution regimes such as in the vicinity of co2 injection wells at oilfield projects the relevance of this term should be evaluated contribution from viscous effects represented between 15 and 83 of that observed for ϵ p z direction these values indicate that inside the wormhole path at low velocities most of the momentum variation is explained by the pressure gradient and viscous effects the darcy term contribution was approximately 7 orders of magnitude smaller than that of the pressure gradient as expected since inside the wormhole and far from its walls there is no viscous fluid solid interaction and thus this term must be very small convective acceleration results from pore diameter variations along the flow path its contribution inside the wormhole path increased with the injection velocity representing 16 3 85 6 and 83 5 of that one observed for ϵ p for cases bs 5 bs 14 and bs 15 respectively z direction table 7 to investigate the reasons for this significant increase we consider a longitudinal cross section aligned to the wormhole as presented in fig 13 as previously discussed for higher injection velocities we observed a change in the dissolution process from wormholing to preferential path formation fig 13 shows a well developed wormhole in case bs 5 it was not possible to show the wormhole from the plug s inlet to outlet in a single plane cases bs 14 and bs 15 however exhibit a preferential path still dissolving to form the wormhole pronounced variations in the wormhole diameter are observed especially for case bs 15 when compared to case bs 5 the velocity increase and the change in the dissolution process are the main causes for the significant differences verified in the convective acceleration contributions observed for cases bs 14 and bs 15 since the darcy equation does not consider fluid accelerations results for case 15 uinj 1 45 10 3 m s 1 are strong evidence that this equation does not adequately describe flow for high injection velocities data presented in tables 6 and 7 indicate that in simulations of reactive flow in vuggy carbonates as well as in fractured reservoirs the brinkman equation is preferable to model the flow in full agreement with the results from the literature srinivasan and nakshatrala 2012 jiménez islas et al 1999 4 conclusions in this work we analyzed the consequences of opting for the darcy or navier stokes darcy brinkman equation to solve for the velocity in a two scale reactive transport model we compared the equations by simulating the dissolution of a 3d natural rock sample previously imaged by microtomography rock heterogeneity was accounted for in the initial porosity and permeability fields which were obtained directly for the micro ct image in the first part of the study we observed that the reactive transport model that employed the darcy equation darcy solver systematically predicted less pore volumes to acid breakthrough pvbt than the model where brinkman equation was used brinkman solver in simulation cases with small proportions of free flow regions and using a low injection velocity both models predicted a similar evolution of permeability and final wormhole structure however results of the darcy solver proved to be more sensitive to the increase in the proportion of free flow regions reflected in a faster increase of permeability and more significant change in the final wormhole structures as a consequence we observed large differences between the solvers when applied to images with a large proportion of free flow regions the injected volumes predicted by the brinkman solver was 53 higher than that predicted by the darcy solver these results suggest that for highly heterogeneous samples where free flow regions are more abundant 13 2 in our case the simplifications assumed by the darcy equation are not appropriate and the brinkman equation should be used instead to have a quantitative assessment of the importance of each term in the brinkman equation to reactive flow simulations we evaluated them in two regions inside the wormhole and in a region where only sub resolution porosity is present simulations showed that inside the porous medium the terms associated to pressure gradient and viscous fluid solid interactions ϵ p and ϵ μ k u respectively are of the same order of magnitude while the local and convective accelerations ρ u t and ρ u u ϵ respectively and the term associated with viscous fluid fluid effects μ 2 u are smaller by at least five orders of magnitude as expected inside the wormhole ρ u t ρ u u ϵ and μ 2 u contributions to momentum balance were significantly higher while the one from the darcy term ϵ μ k u became irrelevant this term accounts for viscous fluid solid interactions and its magnitude was approximately seven orders smaller than the one from pressure gradient reflecting a typical behavior for the brinkman equation inside free flow regions even though the contribution of the local acceleration term increased significantly inside the wormhole path this term represents only 0 5 of ϵ p for high velocity regions or at very high dissolution regimes such as in the vicinity of co2 injection wells the relevance of this term should be evaluated an interesting finding is the importance of the term μ 2 u compared to ρ u u ϵ as injection velocity is increased at low injection velocity u i n j 1 45 10 5 m s 1 μ 2 u represented up to 83 of the pressure gradient indicating that these are the most important terms in representing the momentum balance inside the wormhole in this regime however when the injection velocity was multiplied by 10 ρ u u ϵ becomes dominant over μ 2 u representing up to 86 of ϵ p further investigations proved that this significant increase occurred primarily due to the increase in uinj but also due to a change in the dissolution process responsible for significant variations in the growing wormhole diameter these elevated convective accelerations are strong evidence against using the darcy equation to model reactive flow with high injection velocities our results also showed that this equation should be avoided when the sample has considerable proportions of free flow regions such as vugs and fractures credit authorship contribution statement leandro de paulo ferreira methodology software formal analysis investigation writing original draft thomas david serafini de oliveira software formal analysis writing review editing rodrigo surmas conceptualization writing review editing funding acquisition mônica antunes pereira da silva supervision writing review editing ricardo pires peçanha supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we gratefully acknowledge the petrophysics group from petrobras research center rio de janeiro brazil for the permanent support l p f wishes special thanks to maria aparecida do espírito santo for her inestimable help to the tomography laboratory group for providing the images and support to rodolfo a victor for technical discussions and to jovani favero from wikki brasil for the help with openfoam the original and resampled micro ct images as well as segmentation results porosity and permeability files have been made available for download at the digital rocks portal doi 10 17612 v09y aw80 ferreira 2020 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103696 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
410,this article studies the individual contribution of each term in the navier stokes darcy brinkman equation to the fluid linear momentum balance and the consequences of opting for the darcy or brinkman equations in 3d reactive flow simulations of a vuggy carbonate a two scale continuum model was used to simulate the acidification of a carbonate sample using the darcy and brinkman equations rock heterogeneity is considered in the initial porosity and permeability fields which are calculated directly from micro ct images simulations showed that the darcy equation predicts the acid breakthrough earlier in most cases the convective acceleration term in the brinkman equation plays an important role in describing the fluid momentum balance at high injection velocities and this is a clear evidence against the use of the darcy equation to model reactive flow in such conditions keywords digital rock physics carbonate dissolution reactive flow two scale continuum model brinkman equation darcy equation micro ct 1 introduction reinjection of co2 is currently carried out by oil industry as a tertiary recovery method with the advantage of avoiding emissions to the atmosphere nevertheless when in contact with a carbonate reservoir co2 may cause adverse effects such as carbonate dissolution wormhole formation and collapse of the injection well klokov et al 2018 peng et al 2015 bickle et al 2017 qajar and arns 2016 ahmadi et al 2015 to avoid such problems it is important to understand the rock dissolution processes caused by the co2 injection for which computational simulation has emerged as an essential tool mehmani et al 2020 hao et al 2019 youssef and awotunde 2019 golfier et al 2002 khan et al 2017 hayat et al 2016a 2016b accurate estimates of the velocity field inside pore systems are the key factor in a computational reactive flow simulation since it directly affects the transport of chemical species and other kinetic calculations darcy navier stokes and navier stokes darcy also called brinkman equations have been used to model the flow field inside porous media oliveira et al 2019 molins et al 2019 kim et al 2018 singh et al 2018 huber et al 2014 the darcy equation has been widely used in studies at different scales from plugs to reservoir simulations srinivasan and nakshatrala 2012 maheshwari et al 2014 ratnakar et al 2013 jiang 2011 it ignores acceleration terms and fluid fluid viscous interactions using only one effective medium parameter the hydraulic permeability to account the effect of pore structure in the overall velocity field neuman 1977 used an averaging procedure to obtain the darcy equation directly from the navier stokes equation neglecting the terms of fluid acceleration for an anisotropic porous medium saturated by an incompressible homogeneous newtonian fluid flowing at low reynolds number later whitaker 1986 formally derived the darcy equation without using constitutive assumptions due to these simplifications darcy s equation is not a valid approximation under certain conditions such as alterations in the measured permeability due to changes in the injection pressure or by changing the injecting fluid itself ziabasharhagh et al 2008 steenkamer et al 1995 jackson and james 1986 the navier stokes equation on the other hand requires a detailed description of the pore space geometry turning the mesh generation into a major challenge chen et al 2018 deng and peters 2018 al khulaifi et al 2018 the brinkman equation is a combination of linear momentum and mass conservation for the fluid in large pores and flow channels and darcy s equation for regions with unresolved pores it is constructed in a way that in a simulation cell representing free flow regions such as inside vugs and wormholes the darcy term tends to zero and navier stokes components govern the flow in contrast in simulation cells representing sub resolution porous media the navier stokes terms apart from the pressure gradient become irrelevant resulting in darcy s equation basirat et al 2015 some studies compared the darcy and brinkman equations for reactive flow simulations showing more accurate results when the brinkman equation is used sheremet and trifonova 2014 marušić paloka et al 2012 especially in cases where high conductive paths such as fractures and vugs in pore system simulations are present in the rock hao et al 2019 liu and liu 2016 the brinkman equation has been extensively applied to reactive flow simulations morales and showalter 2017 galvis et al 2015 fei et al 2020 tumuluri and amaranath 2018 nasser el dine and saad 2018 srinivasan and rajagopal 2014 remarkably when the sub resolution porosity plays an important role on the overall fluid flow liu and mostaghimi 2018 showed the effect of microporosity in carbonate samples by comparing computational simulations with experimental results they reported substantial underestimation of the reactant penetration on porous medium when microporosity was neglected soulaine et al 2016 showed the strong impact on the permeability estimates caused by microporosity mesh refinement another important aspect in reactive flow simulations was studied by williamson et al 2019 using 2d and 3d numerical experiments they showed the importance of error estimates to create a new adaptive strategy for mesh refinement despite the extensive research area involving the brinkman equation most of the studies neglect the acceleration terms and assume low fluid velocities in simulations therefore the main motivation for this work is to fill a clear gap in the literature regarding a quantitative study on the individual contribution of each term present in brinkman s equation we consider this knowledge crucial to the general fluid flow science and particularly for the understanding of reactive transport in porous media with multiscale features which in turn plays an essential role for oil recovery techniques such as water alternating gas wag injection and co2 reinjection we quantified the magnitudes of the five components in brinkman s equation for different regions in the computational mesh such as inside a wormhole and in the unresolved porous media the paper is divided in two parts first we established whether reactive flow simulations using the brinkman and darcy s equations are equivalent in a vuggy carbonate the influence of fluid velocity dissolution rate constant and permeability assigned to pores was considered in the simulations in the second part we investigated the effects of fluid fluid viscous interactions in free flow regions for an imposed constant flow rate the pressure drop decreases due to the continuous rock solubilization potentially masking the fluid fluid viscous effects eventually present thus its quantification had to be made via computational simulation at low injection velocities local and convective accelerations are expected to be small at high velocities we showed that convective acceleration became significant to describe the flow finally we accounted for the simultaneous effects of viscous fluid fluid interactions in large pores vugs and developing wormholes together with the computation of terms proportional to the local and convective accelerations we consider this part the main contribution of this work 2 numerical methods 2 1 mathematical modeling in our previous work ferreira et al 2020 we modified the two scale continuum model developed by panga et al 2005 to simulate reactive flow in vuggy carbonates we used the brinkman equation to account for momentum conservation and implemented this model using the software openfoam open source field operation and manipulation weller et al 1998 openfoam 2020 in the first part of this study we investigated whether the brinkman and darcy equations perform differently in reactive flow simulations for this purpose in addition to the solver used in our previous work we implemented a second one replacing the brinkman by darcy equation to differentiate them the former will be referred to as solver b brinkman while the latter will be solver d darcy let u u x u y u z be the velocity vector in m s 1 darcy s equation used in solver d is 1 u k p μ brinkman equation used in solver b is 2 ρ u t ρ u u ϵ ϵ p μ 2 u ϵ μ k u where p is the pressure kg m 1 s 2 μ is the viscosity kg m 1 s 1 ρ is the fluid density kg m 3 t is the time s ϵ is the porosity and k is the absolute permeability m2 we considered an isotropic porous medium so that the intrinsic and apparent permeabilities are equivalent scheidegger 1974 bear 1988 gravitational effects were not considered in the simulations besides the darcy and brinkman equations other equations that compose the models at the darcy and pore scales are common to both solvers and are briefly presented in the next section a detailed description of the model was presented by ferreira et al 2020 2 1 1 equations for the darcy scale in addition to eqs 1 and 2 according to the solver the darcy scale model is composed of the following equations ferreira et al 2020 continuity equation 3 ϵ t u 0 acid transport 4 ϵ c f l t u c f l ϵ d e c f l a v r kinetics 5 r k c c f l c f l 1 k s k c r f 6 r f 1 ϵ 1 ϵ 10 20 porosity update 7 ϵ t r a v α ρ s where cfl is the solution acid concentration mol m 3 d e is the effective dispersion tensor m2 s 1 av is the interfacial area per volume m 1 r is the reaction rate mol m 2 s 1 kc is the local mass transfer coefficient m s 1 ks is the reaction rate constant at the surface m s 1 rf is the reaction factor inside free flow regions such as vugs ϵ 1 and rf is zero meaning that no reaction occurs in these regions outside these regions ϵ 1 rf 1 and the reaction is taken into account lastly α is the dissolving power of the acid defined as the mass of dissolved rock per amount of reacted acid kg mol 1 and ρs is the rock density kg m 3 2 1 2 equations for the pore scale the equations for the pore scale model are used to update permeability pore radius and interfacial area as dissolution occurs as well as the coefficients for mass transfer and dispersion as follows ferreira et al 2020 8 k t k o ϵ t ϵ o ϵ t 1 ϵ o ϵ o 1 ϵ t 2 β 9 r p t r p o k t ϵ o k o ϵ t 10 a v t a v o ϵ t r p o ϵ o r p t 11 2 k c r p d m sh sh b r e p 1 2 sc 1 3 12 r e p 2 ρ u r p μ 13 d e d e x d e t 14 d x d e x d m α 0 s λ x p e p 15 d t d e t d m α 0 s λ t p e p 16 p e p u d h ϵ d m where superscripts t and o represent the variable at the new time and old time steps respectively rp is the mean pore radius m β is an adjusting parameter sh is the sherwood number sh is the asymptotic sherwood number for the pore equal to 3 66 for spherical pores b is a constant b 0 7 rep is the reynolds number in the pore dm is the molecular diffusivity of the acid m2 s 1 sc is the schmidt number 1000 for liquids panga et al 2005 dex and det are the longitudinal and transverse terms of the dispersion tensor α 0s λx and λt are constants related to the porous media structure λx 0 5 and λt 0 1 for a pack of spheres dh is the pore hydraulic diameter dh 2rp for cylindrical pores and pep is the péclet number on the pore eqs 8 10 are semiempirical relations used to estimate the new values of permeability pore radius and interfacial area respectively due to porosity changes ratnakar et al 2013 panga et al 2005 kalia and balakotaiah 2007 2009 when β 1 eq 8 reduces to the kozeny carman model k ϵ 3 1 ϵ 2 eq 11 is an approximation to the sherwood number used to calculate the local mass transfer coefficient kc eqs 14 and 15 are derived from random walk models to estimate the effective dispersion tensor components finally eqs 12 and 16 estimate the dimensionless numbers of reynolds and péclet on the pore respectively 2 2 simulation reactive flow experiments using the carbonate indiana limestone with co2 rich brines and also the dolostone outcrop silurian dolomite with hcl both outcrops from kocurek 2018 were performed by ferreira et al 2020 in this work we used the parameters obtained by those authors with hcl since the total injection time to be simulated in this case was considerably smaller compared to the experiment with co2 1 h for the silurian with hcl versus 30 hours of injection for indiana limestone with co2 the selected plug had the following characteristics diameter 3 83 10 2 m length 3 7 10 2 m ϵ 11 8 k 1 7 10 2 d and was composed of 97 9 dolomite a microtomography micro ct image of this plug was acquired in an x ray scanner phoenix vtomex 140 kv 250 ma resolution 40 µm voxel before the acidification experiment this image was used to calculate the initial porosity and permeability fields as well as for the mesh generation following the same methods from our previous work ferreira et al 2020 the original micro ct image is available for download at the digital rocks portal doi 10 17612 v09y aw80 ferreira 2020 2 2 1 mesh generation since the original micro ct image dimensions 1300 1300 1560 voxels were too large to be handled by the solvers it was resampled to 379 µm voxel 101 101 115 voxels by using the lanczos resampling kernel this resampled image was used to generate the simulation mesh porosity and permeability fields an in house software reactivecenpesmesh was used to construct the simulation mesh by transforming the micro ct voxels directly into cubic cells 2 2 2 porosity distribution we estimated porosity at each voxel in the resampled micro ct image based on the grayscale range variations the sample is composed of 97 dolomite and was considered pure using the following steps 1 the grayscale level of the pores was assigned to porosity 100 gspore 2 the grayscale level of the solid phase was related to a background porosity bp gssolid 3 porosity was calculated directly in the micro ct voxels according to the following equation 17 ϵ v o x e l 100 b p g s v o x e l g s s o l i d g s p o r e g s s o l i d b p the deviation between the global porosity of the plug calculated by this methodology and that experimentally measured is 2 2 2 3 initial permeability distribution we considered the rock samples as being isotropic two methodologies were developed in our previous work ferreira et al 2020 to calculate the initial permeability distribution they are briefly described below methodology p k is estimated for each point of the mesh porosity values in each voxel are used as input in the winland equation kolodzie 1980 18 log r 35 0 732 0 588 log k 0 864 log ϵ where r35 is the pore aperture that corresponds to 35 of mercury saturation we performed a mercury injection capillary pressure test micp with a sample of the silurian dolomite outcrop to obtain the required capillary curve the curve is available at ferreira et al 2020 methodology s k is estimated for regions of similar permeabilities considering regions of similar grayscale values the resampled micro ct image of the plug is segmented in four phases pores high k phase more permeable medium k phase intermediary permeability and low k phase less permeable a sample of the same outcrop representative of the region high k was imaged at 4 µm voxel a direct numerical simulation dns was performed directly in this micro ct image voxels by using a stokes solver the permeability obtained 1 d was assigned to high k region the mean porosity of the medium k phase was calculated and used in winland correlation eq 18 to estimate k resulting in 3 5 10 2 d swanson correlation swanson 1981 was used to estimate k in the low k phase this correlation calculated a permeability between 0 22 and 1 10 3 d and the value 1 10 3 d was adopted for the low k phase permeability fig 1 presents the original micro ct image from the plug the resampled image and the calculated porosity field the differences between fig 1 a and b are small confirming that the resampling process maintained the rock heterogeneity the porosity field c reveals a highly heterogeneous sample fig 2 a shows the segmented image where a more permeable region is easily seen near the plug outlet upper part as well as on the left side of the plug fig 2 b and c correspond to the permeability fields estimated by the methodologies p and s respectively fig 2 b and c show smaller permeability gradients for methodology p which occurred because this methodology used the porosity at each cell to estimate the respective permeability the scale range from fig 2 b and c was used to highlight the permeability gradients the permeability range is larger and regions with permeability greater than 0 1 d are in white and can not be distinguished in these images free flow regions represent only 0 002 of this sample fig 2 a since this is the most critical region to differentiate the brinkman and darcy equations we increased the number of segmented pores in the original porosity field and generated two additional porosity fields modified 1 and modified 2 in which the free flow regions represent 2 7 and 13 2 respectively the permeability fields were then recalculated for the new porosity fields using the two previously described methodologies the resulting porosity fields are shown in fig 3 besides the standard mesh with 101 101 115 cells we generated two additional porosity and permeability fields maintaining the same porous zones as in the field modified 1 and using methodology p with different sizes 76 76 86 cells 510 µm voxel and 154 154 175 cells 250 µm voxel to evaluate how the chosen mesh size affects the solvers results 2 2 4 simulation cases table 1 summarizes the parameters adopted in all simulations where uref is the reference injection velocity and poutlet is the pressure at the sample outlet ferreira et al 2020 a layer of cells filled with fluid ϵ 1 is added to the inlet and outlet of each simulation mesh so that the following boundary conditions hold constant and uniform injection velocity at the inlet constant and uniform pressure at the outlet and lateral impermeable boundaries as shown in fig 4 in all figures the flow direction is upward simulations performed to evaluate the effects of mesh size section 3 1 are presented in table 2 in each case we adopted the porosity field modified 1 which was used to calculate the permeability field according to methodology p and ks 3 10 5 m s 1 a permeability equal to 10 d was assigned to the free flow cells k pore table 3 presents the cases simulated with solvers b and d to investigate whether the brinkman and the darcy equations are equivalent for modeling reactive flow simulations section 3 2 in section 3 3 simulations with solver b were used to calculate the contribution of each term in the brinkman equation for the fluid linear momentum distribution inside the porous medium and in free flow regions since the permeability fields were calculated via two methodologies p and s and simulations were performed with two solvers b and d each case from table 3 generated four simulations identified by the letters that represent the solver and methodology plus the case order number 3 results and discussion 3 1 effect of mesh size on simulation reactive flow simulations were performed for the three mesh sizes described in table 2 considering the total injection of 11 7 pore volumes pv of reactive brine into the mesh at a flow rate q 1 cm3 min 1 u i n j u r e f 1 45 10 5 m s 1 figs 5 and 6 show the evolution of sample permeability and three dimensional renderings of the segmented wormholes respectively from fig 5 we see that mesh size has little influence on the simulated permeability evolution curves for solver b on the other hand mesh refinement did impact the results for solver d suggesting that the darcy equation requires a finer mesh for convergence compared to the brinkman equation fig 6 shows that increasing the mesh size did not significantly affect the wormhole structures developed by acidification these results suggest that a mesh with 101 101 115 cells is adequate to avoid mesh size related artifacts in the simulations this mesh size was adopted in the next simulations 3 2 brinkman versus darcy in reactive flow simulations for the original porosity field did not reveal significant differences between solvers b and d especially with methodology p as shown in fig 7 this was expected since the main differences between the brinkman and darcy equations appear on the free flow regions and these represent only 0 002 of original porosity field we adopted two results as references for measuring the relative difference between the two solvers the accumulated injected pore volume pv at the acid breakthrough and the permeability curve shapes table 4 summarizes the ratio between the injected pore volumes at acid breakthrough predicted by solvers b and d pvb pvd the effects of free flow regions on simulations are clearly seen in table 4 where bigger differences were verified for simulations using the porosity field modified 2 the small differences observed in simulation cases 1 to 3 indicate that for reduced proportions of free flow regions the darcy and brinkman equations give similar results in most cases the difference was slightly larger for methodology s the one with higher gradients in the permeability field this gradient affected more markedly solver d resulting in bigger differences between simulations with both solvers besides solver d systematically predicted smaller volumes injected before acid breakthrough than solver b the cases where only kpore changed 1 and 2 as well as cases 4 and 5 indicate that kpore has a similar impact on simulations performed with solvers b and d for other cases see supplementary material since we only simulated the effect of kpore for porosity fields original and modified 1 free flow regions 0 002 and 2 7 respectively the effect of this parameter for higher proportions of free flow regions is a topic for future studies the impact of the dissolution rate constant ks on the simulation results depends on whether darcy or brinkman equation is being solved fig 8 displays the permeability curves for varying ks using the porosity fields modified 1 a and modified 2 b fig 8 shows that a higher value for the dissolution rate accelerated the formation of wormholes for both porosity fields however the difference between the darcy and brinkman solvers was accentuated by the increase of ks in cases 5 and 6 modified 1 but decreased for cases 7 and 8 modified 2 since solver b considers accelerations in the fluid and viscous effects increasing the proportion of free flow regions in the mesh impact differently each solver and this might be related to ks the same behavior was also noticed in table 4 comparing cases 2 and 3 original 5 and 6 modified 1 7 and 8 modified 2 one can see that the volume ratio between simulations with solvers b and d increased for simulations using porosity field original decreased for cases using the modified 2 field and displayed both behaviors for field modified 1 the difference may be significant up to 10 for cases bs 6 ds 6 these results demonstrate that higher proportions of free flow regions in the sample reduces the impact of ks in the solvers the curves and final porosity fields for case 16 modified 2 k p o r e 1000 d u i n j 100 uref ks 3 10 5 m s 1 using methodology s are displayed in figs 9 and 10 respectively see supplementary material for methodology p fig 9 shows that the permeability curves changed significantly between solvers solver d predicted a faster permeability increase early in the simulation and lower increase after a while with this both solvers predicted a similar plug permeability at the last time step simulated this might be the effect of higher accelerations in the fluid which is neglected by the darcy law at higher injection velocities dissolution occurred uniformly along a path inside the plug fig 10 indicating that the dissolution process changed from wormholing the wormhole formation at the inlet growing by dissolution at its tip until it reaches the sample outlet menke et al 2016 to preferential path formation wormhole formation by rock dissolution at a preferential path menke et al 2016 in table 4 we used the ratio between the injected volumes at acid breakthrough to quantify the solvers differences however it is difficult to determine the acid breakthrough exact moment at high injection velocities and therefore we adopted a different metric in these cases observing fig 9 it shows that the difference between solvers predictions is higher when the sample permeability reached 1 d and we considered this moment to compare the solvers as presented in table 5 for fields original and modified 1 the free flow regions contribution is small and the ratios from table 5 are similar to those observed for cases in which u i n j u r e f table 4 however for case 16 free flow regions 13 2 the volumes predicted by solvers b and d differ in more than 50 this is a strong evidence that brinkman s equation should be used for simulations with highly vuggy porous systems these results agree with the observations of marušić paloka et al 2012 who compared the darcy and the brinkman equations for simulations in a thin fracture and concluded that the brinkman equation should be used in such problems for cases 1 to 6 and at low injection velocities both solvers predicted similar pore systems for a given initial porosity and permeability fields however significant differences were observed in cases using higher injection velocities and porosity field modified 2 to illustrate this fig 11 compares the pore system predicted by each solver when the velocity porosity and permeability fields are changed the segmented pore systems for other cases have been made available in supplementary material fig 11 shows two types of differences one in the main wormhole a and another in the development of a secondary wormhole b the flow pattern that generated these differences also affected the respective permeability evolution curves since further developed secondary wormholes indicate a more distributed flow inside the sample the differences observed in the pore systems ratify the divergence of predictions for the two solvers in samples with higher amounts of segmented pores the model adopted in this work is an extension of that used by panga et al 2005 who considered a 2d model created an initial porosity field by adding random fluctuations to a mean porosity value and used the darcy equation to solve for the velocity field they were able to reproduce diverse dissolution patterns by varying the injection velocity although only a qualitative adjustment was reached for the accumulated volume of fluid injected at the acid breakthrough liu and liu 2016 used a modified version of the continuum model developed by panga et al to study acidification of highly heterogeneous carbonates using viscoelastic surfactant based self diverting acids they showed the importance of the heterogeneity to the wormhole formation path for 2d cases the improvements implemented in this work especially the use of a 3d model and the methodologies to generate porosity and permeability fields that express with high fidelity the rock heterogeneity allowed us to analyze more realistically the permeability curves besides we could inspect the shape and region of the plug where the wormhole developed which is a significant improvement compared to previous works which only reproduce the dissolution patterns sheremet and trifonova 2014 evaluated the darcy and the brinkman extended darcy model in natural convection simulations inside a vertical cylinder and observed that the darcy equation predicted overrated values for the average nusselt number in comparison with the brinkman extended darcy model in our case we observed that the darcy equation predicted smaller injected pore volumes before the acid breakthrough compared to the brinkman equation 3 3 calculation of the brinkman terms the brinkman terms were computed for cases bs 5 bs 14 and bs 15 at the last simulation time step accumulated injections of 12 12 and 50 pv respectively in two regions of interest in the porous medium far from the wormhole and inside the wormhole path fig 12 shows where these two regions were cut from the plug for case bs 15 region 1 presented in fig 12 a was extracted far from the plug walls inlet and outlet and consists of approximately 50 cells with mean porosity equal to 22 the extraction location was the same for the three cases studied the plug inlet and outlet were also avoided when extracting region 2 fig 12 b from the region shown in this figure we considered only the cells with porosity equal to 1 thus the final number of cells in region 2 was approximately 300 since the wormhole path changes with the injection velocity we could not use the same location for the three cases however the same procedure was used in the other two cases keeping a similar number of cells the value of each term of the brinkman equation for region 1 is presented in table 6 table 6 shows that within the porous medium the terms ϵ p and ϵ μ k u are of the same order of magnitude and the only ones relevant to the simulation in all directions the high pressure gradients result from the low permeability in the porous medium the darcy term ϵ μ k u on the other hand represents the viscous interactions between the fluid and the porous walls which together with the viscous fluid fluid interactions μ 2 u correspond to the flow head loss the relatively low permeability values associated with the porous medium reflect the interaction between the fluid and pore walls justifying its high values the local and convective accelerations as well as the term associated with viscous fluid fluid interactions are five or more orders of magnitude smaller than the pressure gradient the local acceleration term results from the rock dissolution responsible for new spaces to be occupied by the fluid unless an extremely intense dissolution process occurs local accelerations are expected to be small as observed in all cases presented in table 6 even in case bs 15 with injection velocity 100 times higher than that one in case bs 5 we observed small values for this parameter notice that for cases bs 5 and bs 14 this term increased five orders of magnitude in the flow direction the terms ρ u u ϵ and μ 2 u are strongly dependent on fluid velocity and since region 1 was extracted far from the wormhole its corresponding fluid velocity was small these results are in full agreement with the literature since the brinkman equation should reduce to darcy equation in the porous zones gulbransen et al 2009 since the simulated plug is cylindrical there are only two important directions to characterize the flow axial and transverse as confirmed by the similar results obtained for x and y directions in case bs 15 the last column in table 6 represents the sum of all terms since this sum is theoretically zero it is in fact a measure of the errors associated with the terms the error is much smaller than ϵ p and ϵ μ k u in all cases and directions although the values for the acceleration terms ρ u t and ρ u u ϵ are smaller than the error for directions x and z they are at least five orders of magnitude smaller than the pressure gradient the corresponding values for y direction in case bs 15 confirms that the acceleration terms contribution to the momentum balance is insignificant for region 1 table 7 presents the brinkman terms for the wormhole region table 7 shows that the contributions of terms ρ u t ρ u u ϵ and μ 2 u are significantly higher inside the wormhole path while ϵ μ k u become irrelevant since the flow occurs mainly at the channel dissolution processes are concentrated in the wormhole walls gradually widening the channel this explains the high increase observed in the local acceleration term compared to the results for the porous medium table 6 however this increase was insufficient to make this contribution significant it represents approximately 0 5 of ϵ p it also shows that for high velocity regions or at very high dissolution regimes such as in the vicinity of co2 injection wells at oilfield projects the relevance of this term should be evaluated contribution from viscous effects represented between 15 and 83 of that observed for ϵ p z direction these values indicate that inside the wormhole path at low velocities most of the momentum variation is explained by the pressure gradient and viscous effects the darcy term contribution was approximately 7 orders of magnitude smaller than that of the pressure gradient as expected since inside the wormhole and far from its walls there is no viscous fluid solid interaction and thus this term must be very small convective acceleration results from pore diameter variations along the flow path its contribution inside the wormhole path increased with the injection velocity representing 16 3 85 6 and 83 5 of that one observed for ϵ p for cases bs 5 bs 14 and bs 15 respectively z direction table 7 to investigate the reasons for this significant increase we consider a longitudinal cross section aligned to the wormhole as presented in fig 13 as previously discussed for higher injection velocities we observed a change in the dissolution process from wormholing to preferential path formation fig 13 shows a well developed wormhole in case bs 5 it was not possible to show the wormhole from the plug s inlet to outlet in a single plane cases bs 14 and bs 15 however exhibit a preferential path still dissolving to form the wormhole pronounced variations in the wormhole diameter are observed especially for case bs 15 when compared to case bs 5 the velocity increase and the change in the dissolution process are the main causes for the significant differences verified in the convective acceleration contributions observed for cases bs 14 and bs 15 since the darcy equation does not consider fluid accelerations results for case 15 uinj 1 45 10 3 m s 1 are strong evidence that this equation does not adequately describe flow for high injection velocities data presented in tables 6 and 7 indicate that in simulations of reactive flow in vuggy carbonates as well as in fractured reservoirs the brinkman equation is preferable to model the flow in full agreement with the results from the literature srinivasan and nakshatrala 2012 jiménez islas et al 1999 4 conclusions in this work we analyzed the consequences of opting for the darcy or navier stokes darcy brinkman equation to solve for the velocity in a two scale reactive transport model we compared the equations by simulating the dissolution of a 3d natural rock sample previously imaged by microtomography rock heterogeneity was accounted for in the initial porosity and permeability fields which were obtained directly for the micro ct image in the first part of the study we observed that the reactive transport model that employed the darcy equation darcy solver systematically predicted less pore volumes to acid breakthrough pvbt than the model where brinkman equation was used brinkman solver in simulation cases with small proportions of free flow regions and using a low injection velocity both models predicted a similar evolution of permeability and final wormhole structure however results of the darcy solver proved to be more sensitive to the increase in the proportion of free flow regions reflected in a faster increase of permeability and more significant change in the final wormhole structures as a consequence we observed large differences between the solvers when applied to images with a large proportion of free flow regions the injected volumes predicted by the brinkman solver was 53 higher than that predicted by the darcy solver these results suggest that for highly heterogeneous samples where free flow regions are more abundant 13 2 in our case the simplifications assumed by the darcy equation are not appropriate and the brinkman equation should be used instead to have a quantitative assessment of the importance of each term in the brinkman equation to reactive flow simulations we evaluated them in two regions inside the wormhole and in a region where only sub resolution porosity is present simulations showed that inside the porous medium the terms associated to pressure gradient and viscous fluid solid interactions ϵ p and ϵ μ k u respectively are of the same order of magnitude while the local and convective accelerations ρ u t and ρ u u ϵ respectively and the term associated with viscous fluid fluid effects μ 2 u are smaller by at least five orders of magnitude as expected inside the wormhole ρ u t ρ u u ϵ and μ 2 u contributions to momentum balance were significantly higher while the one from the darcy term ϵ μ k u became irrelevant this term accounts for viscous fluid solid interactions and its magnitude was approximately seven orders smaller than the one from pressure gradient reflecting a typical behavior for the brinkman equation inside free flow regions even though the contribution of the local acceleration term increased significantly inside the wormhole path this term represents only 0 5 of ϵ p for high velocity regions or at very high dissolution regimes such as in the vicinity of co2 injection wells the relevance of this term should be evaluated an interesting finding is the importance of the term μ 2 u compared to ρ u u ϵ as injection velocity is increased at low injection velocity u i n j 1 45 10 5 m s 1 μ 2 u represented up to 83 of the pressure gradient indicating that these are the most important terms in representing the momentum balance inside the wormhole in this regime however when the injection velocity was multiplied by 10 ρ u u ϵ becomes dominant over μ 2 u representing up to 86 of ϵ p further investigations proved that this significant increase occurred primarily due to the increase in uinj but also due to a change in the dissolution process responsible for significant variations in the growing wormhole diameter these elevated convective accelerations are strong evidence against using the darcy equation to model reactive flow with high injection velocities our results also showed that this equation should be avoided when the sample has considerable proportions of free flow regions such as vugs and fractures credit authorship contribution statement leandro de paulo ferreira methodology software formal analysis investigation writing original draft thomas david serafini de oliveira software formal analysis writing review editing rodrigo surmas conceptualization writing review editing funding acquisition mônica antunes pereira da silva supervision writing review editing ricardo pires peçanha supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we gratefully acknowledge the petrophysics group from petrobras research center rio de janeiro brazil for the permanent support l p f wishes special thanks to maria aparecida do espírito santo for her inestimable help to the tomography laboratory group for providing the images and support to rodolfo a victor for technical discussions and to jovani favero from wikki brasil for the help with openfoam the original and resampled micro ct images as well as segmentation results porosity and permeability files have been made available for download at the digital rocks portal doi 10 17612 v09y aw80 ferreira 2020 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103696 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
411,the impact of phases distribution on mixing and reaction is hardly assessable experimentally we use a multiple point statistical method which belongs to the family of machine learning algorithms to generate simulations of phases distributions from data out of laboratory experiments the simulations honour the saturation of the laboratory experiments resemble the statistical distributions of several geometric descriptors and respect the physics imposed by capillary forces the simulated phases distributions are used to compute solute transport the breakthrough curves reveal that different phases distributions lead to broad ranges of early arrival times and long term tailings as saturation decreases for a given saturation a similar long term scaling of mixing area interface length and corresponding reactivity is observed regardless of phases distribution however phases distribution has a clear impact on the final values before breakthrough of area of mixing interface length and mass of reaction product keywords phase saturation phases distribution solute mixing and reactions pore scale multiple point statistics simulation 1 introduction the proper understanding of solute spreading dispersion mixing and reaction is key to the success of natural and engineered remediation of pollutants in the subsurface the characterization of dispersion is important to predict the current or future spatial extent of a contaminant plume however dispersion does not provide any information about the mixing of the solute i e the distribution of solute concentration within the plume which controls chemical reaction processes fluhler et al 1996 dentz et al 2011 de barros et al 2012 chiogna et al 2012 de anna et al 2014 in the unsaturated zone between the soil surface and the groundwater level all three mechanisms dispersion mixing and reaction depend on saturation i e the fraction of pore volume occupied by water for instance an increase in dispersion is observed as saturation decreases due to the development of high and low velocity regions respectively preferential flow paths and stagnation zones de gennes 1983 however an unexpected decrease of dispersion below a certain threshold so called critical saturation has also been observed toride et al 2003 raoof and hassanizadeh 2013 above the critical saturation the development of preferential flow paths favours faster travel times leading to shorter times for mixing and reaction vanderborght et al 2001 ursino et al 2001 persson et al 2005 gouet kaplan and berkowitz 2011 kapetas et al 2014 in addition flow channelling may also increase concentration gradients thus enhancing diffusive mass transfer and reaction rates jiménez martínez et al 2015 2017 the impact of saturation on transport processes and in particular on dispersion has been widely studied at the field scale through displacement experiments in columns using both glass beads or natural soils de smedt and wierenga 1984 maraqa et al 1997 matsubayashi et al 1997 haga et al 1999 padilla et al 1999 sato et al 2003 nutzmann et al 2002 toride et al 2003 bunsri et al 2008 more recently two dimensional experiments down to pore scale observations have been carried out in heterogeneous media e g karadimitriu et al 2016 jiménez martínez et al 2015 2017 such experiments are costly and time consuming which together with the difficulties in obtaining equivalent degrees of heterogeneity for a given saturation and for different saturations hinders the analysis of the impact of phases distribution on mixing and reaction this problem can be tackled numerically and is known as image reconstruction in the context of porous media a number of methods have been developed to reconstruct aquifer or sample architecture from partial data sets e g the optimization based method yeong et al 1998 pilot points based methods alcolea et al 2006 2008 the phase recovery method hasanabadi et al 2016 the gaussian random fields method roberts 1997 the superdimension method rozman and utz 2001 cross correlation based simulation tahmasebi and sahimi 2013 supervised learning tahmasebi 2018 and multiple point statistics hajizadeh et al 2011 comunian et al 2012 mariethoz and renard 2010 multiple point statistical mps methods generate equally likely conditional or unconditional to data simulations of the patterns captured from a training data set tds hereinafter usually an image representing a conceptual model or an analogue to what is being simulated mps methods belong to the broad family of machine learning techniques in fact it has been recently demonstrated that 1 the traditional mps methods can be enhanced via deep learning and 2 that the capabilities of mps methods for reproducing reconstructing sophisticated geometries of small scale features and connectivity of complex 3d media is virtually unlimited and only bounded by cpu issues feng et al 2018 in this work we address numerically the effect of phases distribution on mixing and reaction by generating mps equally like simulations of phases distribution that inherit the spatial patterns of a tds obtained from a laboratory experiment to that end we use the mps method recently devised by straubhaar et al 2020 three different two dimensional saturation degrees obtained from previous experiments jiménez martínez et al 2017 were used after prior merely geometric evaluation of the reliability of the computed simulations steady state creeping flow and conservative transport were simulated numerically and derived magnitudes e g breakthrough curves and reaction rates amongst others were calculated the comparison of the sets of outputs corresponding to different saturations allowed us to confirm numerically what is already known experimentally about the impact of saturation on solute dispersion mixing and chemical reactions i e that lower saturation enhances all three mechanisms jiménez martínez et al 2015 2017 jougnot et al 2018 this is an independent confirmation of the goodness of the suggested approach that motivates further analyses of the impact of phases distribution on mixing and reaction for a given saturation to that end we assume a fast homogeneous irreversible reaction e g de simoni et al 2005 2007 willmann et al 2010 and compute the effective reactivity and the total mass of reaction product from local concentration gradients this manuscript is organized as follows section 2 summarizes the experimental data sets i e the phases distributions for three given saturation degrees used as tds the numerical model adopted for solving creeping flow and conservative solute transport and the computation of mixing and reaction from the numerically solved concentration fields in section 3 we succinctly describe the mps method used to generate equally likely phases distributions from a given training data set in section 4 we present and discuss the results the paper ends with concluding remarks about the importance of phases distribution on reaction and mixing 2 methodology the proposed methodology consists of three main steps described in detail in dedicated sub sections step 1 laboratory experiment under controlled saturation conditions the main outcome of the experiment is a high resolution image depicting the steady state i e final spatial distribution of air clusters and solid obstacles the image is the so called training data set tds step 2 generation of equally likely mps simulations inheriting the statistical patterns and mimicking the aforementioned image a set of geometric and statistical coherence checks is made to warrant that simulated phases distributions analogue to the given tds step 3 flow and solute transport simulation and evaluation of derived outcomes including breakthrough curves geometry of the mixing zone area and fluid fluid interface length reactivity and mass of reaction product to address the impact of phases distributions on dispersion mixing and reaction 2 1 laboratory experiment the two dimensional water wet porous medium under study 132 mm length and 87 mm width is made of a total of 4421 irregularly distributed circular obstacles with mean diameter d 0 83 0 22 mm these define an average pore size λ 1 85 mm and an average pore throat a 1 17 mm which yield a final porosity ϕ 0 71 and permeability κ 7 8 10 3 mm2 three different wetting phase saturations s w ratio of the combined surface of wetting clusters to that of the pore space 0 83 0 77 and 0 71 were experimentally obtained by simultaneously injecting two immiscible phases i e air and water see jiménez martínez et al 2017 the dimensions of the saturation images used as tds are 3292 2182 pixels which yield a resolution of 0 04 mm per pixel the images consist of binary data in which air clusters have zero value and water areas are flagged with one the solid obstacles grains are always at the same location and are considered separately the static bulk saturations obtained experimentally are homogenous in both longitudinal and transverse directions the size distribution of the non wetting phase air clusters was previously analysed jiménez martínez et al 2017 the gyrational radius of the air bubbles also termed here air clusters indistinctly was used as measure the obtained distributions were in a good agreement with previous findings tallasktad et al 2009 showing that desaturation i e increase in the air content gives rise to a broader distribution of the air bubble sizes 2 2 multiple point statistics at pore scale simulations of phases distributions the multiple point statistics mps algorithm deesse straubhaar et al 2020 was used to generate a set of stochastic simulations of the phases distributions for each saturation value by considering the corresponding tds the simulations are generated on a grid with the same dimensions as the tds the areas covered by the solid obstacles are masked at all simulations because their location and size remain constant in time since the geometry of the air and water phases is affected by surface tension processes at the contacts with the solid obstacles the mps algorithm needs to account for the position of the solid surface this is accomplished by computing a distance to the surface of the solid obstacles and using it as secondary variable during the mps simulation process this distance is given together with the experimental data in the tds and is used as conditioning data note also that for a better control of the proportion of air in the simulations some isolated air pixels are randomly placed in the simulation grid in order to nucleate some air clusters before running the mps simulation the mps simulation process is described in detail in mariethoz et al 2010 all pixels defining the simulation grid except those defining the solid obstacles are successively populated in a random order for each pixel the spatial patterns constituted by the locations and values of the binary variable and the distance to the solid obstacles for the already simulated pixels closest to the current location are retrieved next the tds is randomly scanned until the algorithm finds an acceptable match between the aforementioned pattern of conditioning data in the simulation grid and in the tds for both variables the value at the central pixel of the pattern is then copied from the tds and pasted on the simulation grid as the simulation progresses the density of the informed pixels on the grid increases which results in a smooth transition from wide to narrow patterns hence large and small scale patterns are borrowed from the tds and each simulation shares the spatial statistics of the tds the three main parameters of the algorithm the maximum number of neighbours the maximum scanned fraction of the tds and the acceptance threshold for accepting matching patterns have been adjusted by trial and error to obtain enough variability between simulations and an adequate reproduction of the geometry of air clusters this aspect is discussed in detail below in this study the geometric and statistical coherence between the simulations and the tds is guaranteed by comparing the saturation degree and a number of morphological descriptors of the air phase distribution and air clusters such as 1 the statistical distribution pdf of the radii pores occupied by air 2 the area and perimeter of the air clusters 3 the major and minor axes lengths of a statistically equivalent ellipse fitting the air clusters i e a shape comparison to an equivalent ellipse with the same normalized second central moments as the air cluster and 4 the orientation of the major axis of those ellipses with respect to the main flow direction global similarity and dissimilarity measures are also calculated the similarity is measured by the geometric connectivity of the air phase a standard 8 connectivity measure for air clusters was used in which air pixels are connected if their edges or corners touch each other two adjoining air pixels are part of the same object if they are connected along the horizontal vertical or diagonal direction cheng et al 2009 the dissimilarity between the tds and the simulations is measured by simply subtracting the binary images and counting the pixels whose absolute difference is 1 a global connectivity measure consisting of the proportion of water pixels that connect the inlet and the outlet of the domain is computed for each simulation i e isolated water pixels clusters are ignored in this case since connectivity plays a key role in flow and transport processes these measures for the simulations are expected to be similar to that of the tds moreover the proportion of mismatching pixels between the simulation and the tds is computed this global measure of dissimilarity reports on the variability of the set of simulations compared to the tds 2 3 fluid flow and solute transport modelling mixing and reaction a finite element model developed with comsol multiphysics was used to simulate fluid flow and solute transport through the porous medium solid obstacles and the non wetting phase air were considered immobile and incompressible the latter assumption is valid due to the low flow rates used and the rheology of the wetting phase which result in capillary forces stronger than viscous forces this prevents deformation and the displacement of air bubbles the size of the finite elements is variable and always smaller than the pixel size 0 04 mm to alleviate numerical instabilities in addition the mesh was refined at the interfaces between phases and thus depends on the simulation or tds i e the laboratory experiment under analysis on average more than 600 000 thousand triangular and quadrilateral finite elements define each mesh numerical instabilities are further alleviated by means of a refine temporal discretization defined by a geometric progression with common ratio 1 02 and starting time increment 0 23 s overall 600 time steps were used for solving a time span of 10 000 s for each saturation degree a steady state velocity field is assumed for simplicity to that end the set of navier stokes equations representing creeping flow with very low reynolds number and viscous effects more important than inertial effects is solved at the wetting phase water as follows 1 ρ w u t u u p μ w 2 u 1 3 u f 2 ρ w t u ρ w 0 where u m s 1 is fluid velocity p kg m 1 s 2 is fluid pressure ρ w kg m 3 and μ w kg m 1 s 1 are water density and dynamic viscosity respectively and f kg m 2 s 2 is the volumetric force term in the momentum equation values used in this study are ρ w 1 099 kg m 3 and μ w 0 0372 kg m 1 s 1 the volumetric force term f was set to zero for simplicity for the particular case of creeping flow both advective and gravity terms can be neglected under steady state conditions and considering an incompressible fluid the continuity eq 2 can be rewritten as u 0 therefore the resulting creeping flow formulation is 3 p μ w 2 u f 0 the partial differential eq 3 is constrained by boundary conditions representing constant flow rate q 5 54 10 4 m3 s 1 and constant pressure p 0 kg m 1 s 2 at the inlet and outlet of the domain respectively no slip conditions were considered at the liquid gas and liquid solid interfaces setting to zero the flow velocity along them this assumption simplifies the workflow and reduces the computational effort while its impact on transport processes is negligible guédon et al 2019 triadis et al 2019 advection and diffusion processes were considered for the simulation of solute transport 4 c t d c u c where c mol m 3 is solute concentration and d m2 s 1 is molecular diffusion d 10 9 m2 s 1 in this study a constant concentration c 1 mol m 3 was injected at the inlet the mean fluid flow velocities u and computed dimensionless numbers to characterize flow and transport i e reynolds number r e ρ w u a μ w and péclet number p e u a 2 2 d λ respectively for each saturation are summarized in table 1 in this work we evaluate the relative importance of dispersion mixing and reaction to that end we analyse the geometry of the mixing zone and the reactivity within the geometry of the mixing zone ω m where 0 c 1 is characterized by its area sm m2 defined as ω m x y 0 02 c x y 0 98 mol m 3 to get rid of spurious numerical effects and by the length σ m of its centre line γ defined as the set of locations where c 0 5 mol m 3 γ can be interpreted as the interface between the resident and injected solutions i e the centre line of a diffuse interface reactions are often consequence of the miscibility between two solutions in particular mixing driven reactions take place when the characteristic reaction time scale tr s is smaller than the characteristic advective time t a λ u also in s in that case the damköhler number da ta tr 1 is large and local reaction rates r mol m 3 s 1 can be computed from the measured concentration fields de simoni et al 2005 2007 willmann et al 2010 5 r 2 k c 2 4 k 3 2 d c 2 where k mol2 m 6 is the equilibrium constant of the reaction k 10 2 mol2 m 6 in this study the upscaled reactivity termed here global reaction rate r mol s 1 is computed as the integral of the local reaction rates r over the mixing zone r ω m d x d y r the integral of r over time is the total mass of reaction product mt mol jiménez martínez et al 2015 3 results and discussion 3 1 geometrical coherence a total of 200 mps equally likely simulations per saturation were generated that honour the saturation of the corresponding tds with a tolerance 0 02 figure s1 supplementary material the simulations resemble the corresponding tds well because multiple point statistical patterns are properly inherited figure s2 supplementary material indeed the locations of air clusters are different at all simulations and different to those in the tds the simulations are dissimilar from the tds as measured by the fraction of wet pixels with different value e g air in the simulation but water in the tds or vice versa note that the location of the solid obstacles is the same at the tds and the simulations see figure s2 supplementary material as expected the differences between the tds and the simulations increase with decreasing saturation because the air clusters are more prominent however the connectivity of the air phase in the tds and the simulations is still similar which corroborates the overall resemblance of the spatial patterns contained in the tds additionally the connectivity of the air phase decreases with increasing saturation see figure s3 supplementary material fig 1 a displays the distribution of radii of saturated pores for a saturation s w 0 83 as observed the similarity between the distributions attained with the tds and with the simulations is striking all distributions are centred around a mean pore radius 0 55 mm i e the non wetting phase air does not occupy the largest pores the average pore size λ 1 85 mm this is due to the desaturation of the experimental porous medium caused by the simultaneous injection of both phases before reaching a final static bulk saturation jiménez martínez et al 2017 the cumulative distribution functions cdf of area and perimeter of the simulated air clusters reproduce well those of the tds fig 1b c the cdfs of the major and minor axes lengths of an area equivalent ellipse fitting the simulated air clusters also reproduce the corresponding ones of the tds although in the first case simulated major lengths are slightly above the experimental observations fig 1d e the comparison between the cdfs of orientation inclination with respect to the main flow direction from left to right of air clusters indicates that the simulated air clusters mimic the experimental orientations with deviations smaller than 30 fig 1f the same analysis has been performed for saturations s w 0 77 and 0 71 and leads to identical qualitative conclusions figures s4 and s5 supplementary material with these analyses it is ascertained that the simulations analogue to the training data sets because the simulated phases distributions 1 mimic the statistics of several morphological descriptors of the tds with minimal deviations explained by the random nature of the simulation process and 2 resemble the physics of multiphase flow processes in unsaturated media in the sense that the simulated distributions of saturated pore radii are almost identical to those of the tds in short mps allows to extract the most information out of a costly hardly repeatable and time consuming laboratory experiment which enables the analysis of the impact of phases distribution on mixing and reaction evaluated next 3 2 impact of phases distribution on mixing we randomly selected a subset of 10 simulations for each tds and numerically solved flow and solute transport see section 2 3 fig 2 displays the spatial distribution of solute concentration for each tds and two simulations the visual inspection of the tds and simulation outputs for a given saturation already reveals the impact of phases distribution on solute transport e g different spreading and development of distinct fingering patterns this impact is best evaluated quantitatively by means of solute mixing and chemical reaction descriptors a first measure of the impact of phase distribution on solute transport is given by the breakthrough curves btcs fig 3 which report on solute spreading the enhanced development of a fingering pattern causes earlier arrival times under unsaturated conditions through preferential flow paths but more pronounced tailing due to the existence of low velocity and even stagnation regions guédon et al 2019 than in the saturated case blue lines in fig 3 under identical pe conditions the development of fingers under unsaturated conditions drives the so called anomalous transport or non fickian solute dispersion bromly and hinz 2004 cortis and berkowitz 2004 zoia et al 2010 guillon et al 2013 whose effect in tailing is similar to that caused by aquifer heterogeneity carrera et al 1998 sanchez vila and carrera 2004 alcolea et al 2008 silva et al 2009 as observed the tailing in the simulated btcs is more pronounced than that in the corresponding tds regardless of saturation we attribute this disturbing finding to small statistical differences between the tds and the simulations mainly in the orientation and major equivalent length of air clusters fig 1d and f simulations are indeed noisier than the high resolution and smooth tds thus they may contain a number of small air clusters leading to enhanced contact surfaces between mobile and immobile phases as saturation decreases the larger control of phases distribution i e the location of the air clusters on fingers development causes a general larger variability in the late time behaviour of the btcs and therefore in solute spreading however neither solute spreading nor the btcs report on chemicals reactions within the system because reactivity depends on local fluctuations of solute concentration i e on solute mixing spreading and mixing are coupled i e spreading enhances mixing and mixing smooths out concentration contrasts at close locations the calculated concentration fields are used to compute the temporal evolution of the area of the mixing zone sm fig 4 in the fully saturated cases ran under the same pe as the corresponding unsaturated case an initial increase of the area of mixing is observed followed by a fickian scaling sm t 1 2 the initial increase results from the pseudo uniform development of small fingers figure s6 supplementary material when early fingers merge by the action of molecular diffusion mixing follows approximately a fickian scaling le borgne et al 2013 2015 in the unsaturated cases an initial increase is also observed although more pronounced due to the development of more fingers than in the saturated case followed by a temporal scaling larger than fickian this late time effect is explained by enhanced fingering and a limited impact of molecular diffusion caused by the presence of air clusters jiménez martínez et al 2015 2017 the late times scaling increases as saturation decreases fig 4 in other words mixing is enhanced as saturation decreases because the impact of heterogeneity introduced by the air clusters is larger see also figure s5 supplementary material note that at long term very small variability in the scaling is observed for the tds and the corresponding simulations regardless of saturation this could make one think that phase distribution controls only the early time behaviour of the mixing area but not its final trend while this is true in terms of late time scaling the final value of area of mixing largely depends on phases distribution as discussed below a second descriptor of solute mixing is the length of the interface between the resident and the injected solutions i e the centre line of a diffusive interface γ fig 5 at early times of injection increases sharply regardless of saturation due to invasion of the mixing front as observed in the experiments carried out by de anna et al 2014 and jiménez martínez et al 2015 amongst others under unsaturated conditions the variability of the entry time is larger as saturation decreases because the amount and spatial distribution of air clusters near the inlet plays an important role instead under saturated conditions experimental observations indicate that stabilizes at a plateau caused by the merging of fingers due to molecular diffusion jiménez martínez et al 2015 although a trend towards a plateau is observed this was not the case in our simulations because the model length along the main flow direction is small and pe is large instead under unsaturated conditions experimental observations reveal that increases faster than linear due to enhanced fingering and does not reach a plateau until late times of system homogenization de barros et al 2012 in fact our simulations show both extremes and demonstrate the large impact of saturation on solute mixing contrary to the area of mixing presented above fig 4 which largely depends on the type of experiment under analysis the length of the interface between resident and injected solution displays a very large variability regardless of saturation the variability in the temporal evolution of the interface length increases with decreasing saturation this is explained by a larger control of the spatial distribution of air clusters on the deformation of the interface 3 3 impact of phases distribution on mixing induced reactions concentration gradients within solute plumes control diffusive mass transfer and local reaction rates the global reaction rate r computed as the integral of the local reaction rates over the mixing zone is significantly impacted by saturation fig 6 a to c under fully saturated conditions and after an initial increase r decreases following a fickian or diffusive decay r t 1 2 this indicates that after the initial deformation of the invasive front the coalescence of small fingers causes mass transfer to scale as a molecular diffusion process under unsaturated conditions r increases initially in a similar manner and then decreases slower than under fully saturated conditions or even keeps on increasing depending on saturation as expected r increases with decreasing saturation jiménez martínez et al 2015 the higher reaction rates observed at late times under unsaturated conditions translate directly into a larger mass of the reaction product mp than in the fully saturated counterparts fig 6 d to f the joint impact of saturation and phases distribution on mixing and reaction is best observed in fig 7 which displays the box and whisker plots of the final value of the analysed descriptors prior to breakthrough including the area of the mixing zone the interface length and the total mass of reaction product saturation controls the topology of the system which is dominated by the number and extent of the air clusters instead phases distribution relates to the way the air clusters are distributed over the modelled domain both concepts are linked through entropy which measures the degree of disorder or randomness of the system it has been demonstrated that entropy increases as saturation decreases however entropy is not only controlled by saturation but also by phases distribution i e similar entropies may be obtained for different saturations jiménez martínez and negre 2017 these authors also show that an increase of entropy also implies an enhanced mixing capacity while the final prior to breakthrough area of mixing increases down to a saturation of s w 0 77 this trend is inverted at the lowest saturation s w 0 71 in the case of the final value of the interface length a general increase is observed as saturation decreases and a larger variability is also observed the total mass in mol of the reaction product m t t 0 t bt m p d t produced before breakthrough t bt increases with decreasing saturation although a general positive correlation exists between interface length and area of mixing these results evidence the larger control of the interface length on the total mass of reaction product for the lowest saturation s w 0 71 the presence of more and larger air clusters enhances the stretching and folding of the invasive front le borgne et al 2013 2015 i e the creation of concentration gradients even for a smaller area of mixing than in under higher saturations for low saturations while the creation of interface is enhanced the mixing can be volume limited i e the presence of air clusters inhibits the growth of the mixing zone by molecular diffusion as stated before for entropy a similar total mass of reaction product may be obtained under different saturations fig 7 4 concluding remarks this work presents a novel methodology that combines a multiple point statistical method and transport simulations for the comprehensive analysis of the impact of saturation and phases distribution on solute dispersion mixing and reaction in porous media for a given saturation the simulated phases distributions resemble the spatial patterns observed in the corresponding training data set i e an experimental image as indicated by several geometrical and physical descriptors in other words simulations are analogues to experiments hardly repeatable in the laboratory this enables further analyses a large impact of phases distribution on early arrival times and long term tailings has been observed in the breakthrough curves regardless of saturation with increasing variability as saturation decreases the phases distribution at the inlet of the domain largely controls the early time evolution of the area of mixing and particularly of the interface length which shows a larger variability and is controlled by the fingering pattern developed at early times of invasion of the solute front the late time behaviour has been analysed both in absolute and relative terms final value before breakthrough and temporal scaling for a given saturation small differences in the late time temporal scaling of the area of mixing and interface length have been observed regardless of phases distribution the impact of saturation is revealed by the different late time scaling which increases in both cases as saturation decreases thus depicting a more pronounced non fickian behaviour the joint impact of saturation and phases distribution is clearly observable in the final values of the area of mixing and interface length both generally increase as saturation decreases an exception being the area of the mixing zone under the lowest saturation in this case mixing is inhibited by the limited accessibility of the injected solute to the resident liquid which is hindered by the numerous isolated water clusters a larger variability is observed in the final values of the interface length indicating a larger control of phases distribution as saturation decreases the temporal evolution of the global reaction rate and the mass of reaction product and correspondingly the total mass of reaction product results from the interplay between mixing area and interface length thus the behaviour at early times is the same one described above by observing these magnitudes we demonstrate a larger control of the interface length the presence of air promotes the formation of interface length by stretching and folding the invasive front thus enhancing the creation of concentration gradients and therefore of mass reaction product in spite of the increasing of the late time temporal scaling of global reaction rate and mass of reaction product with decreasing saturation the heterogeneity introduced by phases distribution yields similar magnitudes of the total mass of reaction product for different saturations in a nutshell phases distribution controls the total mass of reaction product while its late time scaling is controlled by saturation much remains to be done both at pore and continuum scales for instance at continuum scale the knowledge of the actual saturation distribution in unsaturated soils and the actual spatial distribution of hydraulic conductivity in aquifers is essential to reduce the uncertainty of the predictions the total mass of reaction product the methodology presented here is general and allows further analyses with minimal changes in the model set up this allows to analyse numerically what is costly hardly repeatable and time consuming in the laboratory this work is a step forward in the modelling of the joint impact of phases distribution and saturation in solute dispersion mixing and reaction in unsaturated porous media credit authorship contribution statement joaquín jiménez martínez conceptualization methodology writing review editing andrés alcolea conceptualization methodology writing review editing julien a straubhaar methodology writing original draft philippe renard methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements jjm gratefully acknowledges the financial support from the swiss national science foundation snf grant nr 200021 178986 we thank the three anonymous reviewers whose valuable comments and suggestions help to improve the manuscript we also acknowledge andrés valencia and almudena sánchez for the constructive discussions supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103697 appendix supplementary materials image application 1 image application 2 
411,the impact of phases distribution on mixing and reaction is hardly assessable experimentally we use a multiple point statistical method which belongs to the family of machine learning algorithms to generate simulations of phases distributions from data out of laboratory experiments the simulations honour the saturation of the laboratory experiments resemble the statistical distributions of several geometric descriptors and respect the physics imposed by capillary forces the simulated phases distributions are used to compute solute transport the breakthrough curves reveal that different phases distributions lead to broad ranges of early arrival times and long term tailings as saturation decreases for a given saturation a similar long term scaling of mixing area interface length and corresponding reactivity is observed regardless of phases distribution however phases distribution has a clear impact on the final values before breakthrough of area of mixing interface length and mass of reaction product keywords phase saturation phases distribution solute mixing and reactions pore scale multiple point statistics simulation 1 introduction the proper understanding of solute spreading dispersion mixing and reaction is key to the success of natural and engineered remediation of pollutants in the subsurface the characterization of dispersion is important to predict the current or future spatial extent of a contaminant plume however dispersion does not provide any information about the mixing of the solute i e the distribution of solute concentration within the plume which controls chemical reaction processes fluhler et al 1996 dentz et al 2011 de barros et al 2012 chiogna et al 2012 de anna et al 2014 in the unsaturated zone between the soil surface and the groundwater level all three mechanisms dispersion mixing and reaction depend on saturation i e the fraction of pore volume occupied by water for instance an increase in dispersion is observed as saturation decreases due to the development of high and low velocity regions respectively preferential flow paths and stagnation zones de gennes 1983 however an unexpected decrease of dispersion below a certain threshold so called critical saturation has also been observed toride et al 2003 raoof and hassanizadeh 2013 above the critical saturation the development of preferential flow paths favours faster travel times leading to shorter times for mixing and reaction vanderborght et al 2001 ursino et al 2001 persson et al 2005 gouet kaplan and berkowitz 2011 kapetas et al 2014 in addition flow channelling may also increase concentration gradients thus enhancing diffusive mass transfer and reaction rates jiménez martínez et al 2015 2017 the impact of saturation on transport processes and in particular on dispersion has been widely studied at the field scale through displacement experiments in columns using both glass beads or natural soils de smedt and wierenga 1984 maraqa et al 1997 matsubayashi et al 1997 haga et al 1999 padilla et al 1999 sato et al 2003 nutzmann et al 2002 toride et al 2003 bunsri et al 2008 more recently two dimensional experiments down to pore scale observations have been carried out in heterogeneous media e g karadimitriu et al 2016 jiménez martínez et al 2015 2017 such experiments are costly and time consuming which together with the difficulties in obtaining equivalent degrees of heterogeneity for a given saturation and for different saturations hinders the analysis of the impact of phases distribution on mixing and reaction this problem can be tackled numerically and is known as image reconstruction in the context of porous media a number of methods have been developed to reconstruct aquifer or sample architecture from partial data sets e g the optimization based method yeong et al 1998 pilot points based methods alcolea et al 2006 2008 the phase recovery method hasanabadi et al 2016 the gaussian random fields method roberts 1997 the superdimension method rozman and utz 2001 cross correlation based simulation tahmasebi and sahimi 2013 supervised learning tahmasebi 2018 and multiple point statistics hajizadeh et al 2011 comunian et al 2012 mariethoz and renard 2010 multiple point statistical mps methods generate equally likely conditional or unconditional to data simulations of the patterns captured from a training data set tds hereinafter usually an image representing a conceptual model or an analogue to what is being simulated mps methods belong to the broad family of machine learning techniques in fact it has been recently demonstrated that 1 the traditional mps methods can be enhanced via deep learning and 2 that the capabilities of mps methods for reproducing reconstructing sophisticated geometries of small scale features and connectivity of complex 3d media is virtually unlimited and only bounded by cpu issues feng et al 2018 in this work we address numerically the effect of phases distribution on mixing and reaction by generating mps equally like simulations of phases distribution that inherit the spatial patterns of a tds obtained from a laboratory experiment to that end we use the mps method recently devised by straubhaar et al 2020 three different two dimensional saturation degrees obtained from previous experiments jiménez martínez et al 2017 were used after prior merely geometric evaluation of the reliability of the computed simulations steady state creeping flow and conservative transport were simulated numerically and derived magnitudes e g breakthrough curves and reaction rates amongst others were calculated the comparison of the sets of outputs corresponding to different saturations allowed us to confirm numerically what is already known experimentally about the impact of saturation on solute dispersion mixing and chemical reactions i e that lower saturation enhances all three mechanisms jiménez martínez et al 2015 2017 jougnot et al 2018 this is an independent confirmation of the goodness of the suggested approach that motivates further analyses of the impact of phases distribution on mixing and reaction for a given saturation to that end we assume a fast homogeneous irreversible reaction e g de simoni et al 2005 2007 willmann et al 2010 and compute the effective reactivity and the total mass of reaction product from local concentration gradients this manuscript is organized as follows section 2 summarizes the experimental data sets i e the phases distributions for three given saturation degrees used as tds the numerical model adopted for solving creeping flow and conservative solute transport and the computation of mixing and reaction from the numerically solved concentration fields in section 3 we succinctly describe the mps method used to generate equally likely phases distributions from a given training data set in section 4 we present and discuss the results the paper ends with concluding remarks about the importance of phases distribution on reaction and mixing 2 methodology the proposed methodology consists of three main steps described in detail in dedicated sub sections step 1 laboratory experiment under controlled saturation conditions the main outcome of the experiment is a high resolution image depicting the steady state i e final spatial distribution of air clusters and solid obstacles the image is the so called training data set tds step 2 generation of equally likely mps simulations inheriting the statistical patterns and mimicking the aforementioned image a set of geometric and statistical coherence checks is made to warrant that simulated phases distributions analogue to the given tds step 3 flow and solute transport simulation and evaluation of derived outcomes including breakthrough curves geometry of the mixing zone area and fluid fluid interface length reactivity and mass of reaction product to address the impact of phases distributions on dispersion mixing and reaction 2 1 laboratory experiment the two dimensional water wet porous medium under study 132 mm length and 87 mm width is made of a total of 4421 irregularly distributed circular obstacles with mean diameter d 0 83 0 22 mm these define an average pore size λ 1 85 mm and an average pore throat a 1 17 mm which yield a final porosity ϕ 0 71 and permeability κ 7 8 10 3 mm2 three different wetting phase saturations s w ratio of the combined surface of wetting clusters to that of the pore space 0 83 0 77 and 0 71 were experimentally obtained by simultaneously injecting two immiscible phases i e air and water see jiménez martínez et al 2017 the dimensions of the saturation images used as tds are 3292 2182 pixels which yield a resolution of 0 04 mm per pixel the images consist of binary data in which air clusters have zero value and water areas are flagged with one the solid obstacles grains are always at the same location and are considered separately the static bulk saturations obtained experimentally are homogenous in both longitudinal and transverse directions the size distribution of the non wetting phase air clusters was previously analysed jiménez martínez et al 2017 the gyrational radius of the air bubbles also termed here air clusters indistinctly was used as measure the obtained distributions were in a good agreement with previous findings tallasktad et al 2009 showing that desaturation i e increase in the air content gives rise to a broader distribution of the air bubble sizes 2 2 multiple point statistics at pore scale simulations of phases distributions the multiple point statistics mps algorithm deesse straubhaar et al 2020 was used to generate a set of stochastic simulations of the phases distributions for each saturation value by considering the corresponding tds the simulations are generated on a grid with the same dimensions as the tds the areas covered by the solid obstacles are masked at all simulations because their location and size remain constant in time since the geometry of the air and water phases is affected by surface tension processes at the contacts with the solid obstacles the mps algorithm needs to account for the position of the solid surface this is accomplished by computing a distance to the surface of the solid obstacles and using it as secondary variable during the mps simulation process this distance is given together with the experimental data in the tds and is used as conditioning data note also that for a better control of the proportion of air in the simulations some isolated air pixels are randomly placed in the simulation grid in order to nucleate some air clusters before running the mps simulation the mps simulation process is described in detail in mariethoz et al 2010 all pixels defining the simulation grid except those defining the solid obstacles are successively populated in a random order for each pixel the spatial patterns constituted by the locations and values of the binary variable and the distance to the solid obstacles for the already simulated pixels closest to the current location are retrieved next the tds is randomly scanned until the algorithm finds an acceptable match between the aforementioned pattern of conditioning data in the simulation grid and in the tds for both variables the value at the central pixel of the pattern is then copied from the tds and pasted on the simulation grid as the simulation progresses the density of the informed pixels on the grid increases which results in a smooth transition from wide to narrow patterns hence large and small scale patterns are borrowed from the tds and each simulation shares the spatial statistics of the tds the three main parameters of the algorithm the maximum number of neighbours the maximum scanned fraction of the tds and the acceptance threshold for accepting matching patterns have been adjusted by trial and error to obtain enough variability between simulations and an adequate reproduction of the geometry of air clusters this aspect is discussed in detail below in this study the geometric and statistical coherence between the simulations and the tds is guaranteed by comparing the saturation degree and a number of morphological descriptors of the air phase distribution and air clusters such as 1 the statistical distribution pdf of the radii pores occupied by air 2 the area and perimeter of the air clusters 3 the major and minor axes lengths of a statistically equivalent ellipse fitting the air clusters i e a shape comparison to an equivalent ellipse with the same normalized second central moments as the air cluster and 4 the orientation of the major axis of those ellipses with respect to the main flow direction global similarity and dissimilarity measures are also calculated the similarity is measured by the geometric connectivity of the air phase a standard 8 connectivity measure for air clusters was used in which air pixels are connected if their edges or corners touch each other two adjoining air pixels are part of the same object if they are connected along the horizontal vertical or diagonal direction cheng et al 2009 the dissimilarity between the tds and the simulations is measured by simply subtracting the binary images and counting the pixels whose absolute difference is 1 a global connectivity measure consisting of the proportion of water pixels that connect the inlet and the outlet of the domain is computed for each simulation i e isolated water pixels clusters are ignored in this case since connectivity plays a key role in flow and transport processes these measures for the simulations are expected to be similar to that of the tds moreover the proportion of mismatching pixels between the simulation and the tds is computed this global measure of dissimilarity reports on the variability of the set of simulations compared to the tds 2 3 fluid flow and solute transport modelling mixing and reaction a finite element model developed with comsol multiphysics was used to simulate fluid flow and solute transport through the porous medium solid obstacles and the non wetting phase air were considered immobile and incompressible the latter assumption is valid due to the low flow rates used and the rheology of the wetting phase which result in capillary forces stronger than viscous forces this prevents deformation and the displacement of air bubbles the size of the finite elements is variable and always smaller than the pixel size 0 04 mm to alleviate numerical instabilities in addition the mesh was refined at the interfaces between phases and thus depends on the simulation or tds i e the laboratory experiment under analysis on average more than 600 000 thousand triangular and quadrilateral finite elements define each mesh numerical instabilities are further alleviated by means of a refine temporal discretization defined by a geometric progression with common ratio 1 02 and starting time increment 0 23 s overall 600 time steps were used for solving a time span of 10 000 s for each saturation degree a steady state velocity field is assumed for simplicity to that end the set of navier stokes equations representing creeping flow with very low reynolds number and viscous effects more important than inertial effects is solved at the wetting phase water as follows 1 ρ w u t u u p μ w 2 u 1 3 u f 2 ρ w t u ρ w 0 where u m s 1 is fluid velocity p kg m 1 s 2 is fluid pressure ρ w kg m 3 and μ w kg m 1 s 1 are water density and dynamic viscosity respectively and f kg m 2 s 2 is the volumetric force term in the momentum equation values used in this study are ρ w 1 099 kg m 3 and μ w 0 0372 kg m 1 s 1 the volumetric force term f was set to zero for simplicity for the particular case of creeping flow both advective and gravity terms can be neglected under steady state conditions and considering an incompressible fluid the continuity eq 2 can be rewritten as u 0 therefore the resulting creeping flow formulation is 3 p μ w 2 u f 0 the partial differential eq 3 is constrained by boundary conditions representing constant flow rate q 5 54 10 4 m3 s 1 and constant pressure p 0 kg m 1 s 2 at the inlet and outlet of the domain respectively no slip conditions were considered at the liquid gas and liquid solid interfaces setting to zero the flow velocity along them this assumption simplifies the workflow and reduces the computational effort while its impact on transport processes is negligible guédon et al 2019 triadis et al 2019 advection and diffusion processes were considered for the simulation of solute transport 4 c t d c u c where c mol m 3 is solute concentration and d m2 s 1 is molecular diffusion d 10 9 m2 s 1 in this study a constant concentration c 1 mol m 3 was injected at the inlet the mean fluid flow velocities u and computed dimensionless numbers to characterize flow and transport i e reynolds number r e ρ w u a μ w and péclet number p e u a 2 2 d λ respectively for each saturation are summarized in table 1 in this work we evaluate the relative importance of dispersion mixing and reaction to that end we analyse the geometry of the mixing zone and the reactivity within the geometry of the mixing zone ω m where 0 c 1 is characterized by its area sm m2 defined as ω m x y 0 02 c x y 0 98 mol m 3 to get rid of spurious numerical effects and by the length σ m of its centre line γ defined as the set of locations where c 0 5 mol m 3 γ can be interpreted as the interface between the resident and injected solutions i e the centre line of a diffuse interface reactions are often consequence of the miscibility between two solutions in particular mixing driven reactions take place when the characteristic reaction time scale tr s is smaller than the characteristic advective time t a λ u also in s in that case the damköhler number da ta tr 1 is large and local reaction rates r mol m 3 s 1 can be computed from the measured concentration fields de simoni et al 2005 2007 willmann et al 2010 5 r 2 k c 2 4 k 3 2 d c 2 where k mol2 m 6 is the equilibrium constant of the reaction k 10 2 mol2 m 6 in this study the upscaled reactivity termed here global reaction rate r mol s 1 is computed as the integral of the local reaction rates r over the mixing zone r ω m d x d y r the integral of r over time is the total mass of reaction product mt mol jiménez martínez et al 2015 3 results and discussion 3 1 geometrical coherence a total of 200 mps equally likely simulations per saturation were generated that honour the saturation of the corresponding tds with a tolerance 0 02 figure s1 supplementary material the simulations resemble the corresponding tds well because multiple point statistical patterns are properly inherited figure s2 supplementary material indeed the locations of air clusters are different at all simulations and different to those in the tds the simulations are dissimilar from the tds as measured by the fraction of wet pixels with different value e g air in the simulation but water in the tds or vice versa note that the location of the solid obstacles is the same at the tds and the simulations see figure s2 supplementary material as expected the differences between the tds and the simulations increase with decreasing saturation because the air clusters are more prominent however the connectivity of the air phase in the tds and the simulations is still similar which corroborates the overall resemblance of the spatial patterns contained in the tds additionally the connectivity of the air phase decreases with increasing saturation see figure s3 supplementary material fig 1 a displays the distribution of radii of saturated pores for a saturation s w 0 83 as observed the similarity between the distributions attained with the tds and with the simulations is striking all distributions are centred around a mean pore radius 0 55 mm i e the non wetting phase air does not occupy the largest pores the average pore size λ 1 85 mm this is due to the desaturation of the experimental porous medium caused by the simultaneous injection of both phases before reaching a final static bulk saturation jiménez martínez et al 2017 the cumulative distribution functions cdf of area and perimeter of the simulated air clusters reproduce well those of the tds fig 1b c the cdfs of the major and minor axes lengths of an area equivalent ellipse fitting the simulated air clusters also reproduce the corresponding ones of the tds although in the first case simulated major lengths are slightly above the experimental observations fig 1d e the comparison between the cdfs of orientation inclination with respect to the main flow direction from left to right of air clusters indicates that the simulated air clusters mimic the experimental orientations with deviations smaller than 30 fig 1f the same analysis has been performed for saturations s w 0 77 and 0 71 and leads to identical qualitative conclusions figures s4 and s5 supplementary material with these analyses it is ascertained that the simulations analogue to the training data sets because the simulated phases distributions 1 mimic the statistics of several morphological descriptors of the tds with minimal deviations explained by the random nature of the simulation process and 2 resemble the physics of multiphase flow processes in unsaturated media in the sense that the simulated distributions of saturated pore radii are almost identical to those of the tds in short mps allows to extract the most information out of a costly hardly repeatable and time consuming laboratory experiment which enables the analysis of the impact of phases distribution on mixing and reaction evaluated next 3 2 impact of phases distribution on mixing we randomly selected a subset of 10 simulations for each tds and numerically solved flow and solute transport see section 2 3 fig 2 displays the spatial distribution of solute concentration for each tds and two simulations the visual inspection of the tds and simulation outputs for a given saturation already reveals the impact of phases distribution on solute transport e g different spreading and development of distinct fingering patterns this impact is best evaluated quantitatively by means of solute mixing and chemical reaction descriptors a first measure of the impact of phase distribution on solute transport is given by the breakthrough curves btcs fig 3 which report on solute spreading the enhanced development of a fingering pattern causes earlier arrival times under unsaturated conditions through preferential flow paths but more pronounced tailing due to the existence of low velocity and even stagnation regions guédon et al 2019 than in the saturated case blue lines in fig 3 under identical pe conditions the development of fingers under unsaturated conditions drives the so called anomalous transport or non fickian solute dispersion bromly and hinz 2004 cortis and berkowitz 2004 zoia et al 2010 guillon et al 2013 whose effect in tailing is similar to that caused by aquifer heterogeneity carrera et al 1998 sanchez vila and carrera 2004 alcolea et al 2008 silva et al 2009 as observed the tailing in the simulated btcs is more pronounced than that in the corresponding tds regardless of saturation we attribute this disturbing finding to small statistical differences between the tds and the simulations mainly in the orientation and major equivalent length of air clusters fig 1d and f simulations are indeed noisier than the high resolution and smooth tds thus they may contain a number of small air clusters leading to enhanced contact surfaces between mobile and immobile phases as saturation decreases the larger control of phases distribution i e the location of the air clusters on fingers development causes a general larger variability in the late time behaviour of the btcs and therefore in solute spreading however neither solute spreading nor the btcs report on chemicals reactions within the system because reactivity depends on local fluctuations of solute concentration i e on solute mixing spreading and mixing are coupled i e spreading enhances mixing and mixing smooths out concentration contrasts at close locations the calculated concentration fields are used to compute the temporal evolution of the area of the mixing zone sm fig 4 in the fully saturated cases ran under the same pe as the corresponding unsaturated case an initial increase of the area of mixing is observed followed by a fickian scaling sm t 1 2 the initial increase results from the pseudo uniform development of small fingers figure s6 supplementary material when early fingers merge by the action of molecular diffusion mixing follows approximately a fickian scaling le borgne et al 2013 2015 in the unsaturated cases an initial increase is also observed although more pronounced due to the development of more fingers than in the saturated case followed by a temporal scaling larger than fickian this late time effect is explained by enhanced fingering and a limited impact of molecular diffusion caused by the presence of air clusters jiménez martínez et al 2015 2017 the late times scaling increases as saturation decreases fig 4 in other words mixing is enhanced as saturation decreases because the impact of heterogeneity introduced by the air clusters is larger see also figure s5 supplementary material note that at long term very small variability in the scaling is observed for the tds and the corresponding simulations regardless of saturation this could make one think that phase distribution controls only the early time behaviour of the mixing area but not its final trend while this is true in terms of late time scaling the final value of area of mixing largely depends on phases distribution as discussed below a second descriptor of solute mixing is the length of the interface between the resident and the injected solutions i e the centre line of a diffusive interface γ fig 5 at early times of injection increases sharply regardless of saturation due to invasion of the mixing front as observed in the experiments carried out by de anna et al 2014 and jiménez martínez et al 2015 amongst others under unsaturated conditions the variability of the entry time is larger as saturation decreases because the amount and spatial distribution of air clusters near the inlet plays an important role instead under saturated conditions experimental observations indicate that stabilizes at a plateau caused by the merging of fingers due to molecular diffusion jiménez martínez et al 2015 although a trend towards a plateau is observed this was not the case in our simulations because the model length along the main flow direction is small and pe is large instead under unsaturated conditions experimental observations reveal that increases faster than linear due to enhanced fingering and does not reach a plateau until late times of system homogenization de barros et al 2012 in fact our simulations show both extremes and demonstrate the large impact of saturation on solute mixing contrary to the area of mixing presented above fig 4 which largely depends on the type of experiment under analysis the length of the interface between resident and injected solution displays a very large variability regardless of saturation the variability in the temporal evolution of the interface length increases with decreasing saturation this is explained by a larger control of the spatial distribution of air clusters on the deformation of the interface 3 3 impact of phases distribution on mixing induced reactions concentration gradients within solute plumes control diffusive mass transfer and local reaction rates the global reaction rate r computed as the integral of the local reaction rates over the mixing zone is significantly impacted by saturation fig 6 a to c under fully saturated conditions and after an initial increase r decreases following a fickian or diffusive decay r t 1 2 this indicates that after the initial deformation of the invasive front the coalescence of small fingers causes mass transfer to scale as a molecular diffusion process under unsaturated conditions r increases initially in a similar manner and then decreases slower than under fully saturated conditions or even keeps on increasing depending on saturation as expected r increases with decreasing saturation jiménez martínez et al 2015 the higher reaction rates observed at late times under unsaturated conditions translate directly into a larger mass of the reaction product mp than in the fully saturated counterparts fig 6 d to f the joint impact of saturation and phases distribution on mixing and reaction is best observed in fig 7 which displays the box and whisker plots of the final value of the analysed descriptors prior to breakthrough including the area of the mixing zone the interface length and the total mass of reaction product saturation controls the topology of the system which is dominated by the number and extent of the air clusters instead phases distribution relates to the way the air clusters are distributed over the modelled domain both concepts are linked through entropy which measures the degree of disorder or randomness of the system it has been demonstrated that entropy increases as saturation decreases however entropy is not only controlled by saturation but also by phases distribution i e similar entropies may be obtained for different saturations jiménez martínez and negre 2017 these authors also show that an increase of entropy also implies an enhanced mixing capacity while the final prior to breakthrough area of mixing increases down to a saturation of s w 0 77 this trend is inverted at the lowest saturation s w 0 71 in the case of the final value of the interface length a general increase is observed as saturation decreases and a larger variability is also observed the total mass in mol of the reaction product m t t 0 t bt m p d t produced before breakthrough t bt increases with decreasing saturation although a general positive correlation exists between interface length and area of mixing these results evidence the larger control of the interface length on the total mass of reaction product for the lowest saturation s w 0 71 the presence of more and larger air clusters enhances the stretching and folding of the invasive front le borgne et al 2013 2015 i e the creation of concentration gradients even for a smaller area of mixing than in under higher saturations for low saturations while the creation of interface is enhanced the mixing can be volume limited i e the presence of air clusters inhibits the growth of the mixing zone by molecular diffusion as stated before for entropy a similar total mass of reaction product may be obtained under different saturations fig 7 4 concluding remarks this work presents a novel methodology that combines a multiple point statistical method and transport simulations for the comprehensive analysis of the impact of saturation and phases distribution on solute dispersion mixing and reaction in porous media for a given saturation the simulated phases distributions resemble the spatial patterns observed in the corresponding training data set i e an experimental image as indicated by several geometrical and physical descriptors in other words simulations are analogues to experiments hardly repeatable in the laboratory this enables further analyses a large impact of phases distribution on early arrival times and long term tailings has been observed in the breakthrough curves regardless of saturation with increasing variability as saturation decreases the phases distribution at the inlet of the domain largely controls the early time evolution of the area of mixing and particularly of the interface length which shows a larger variability and is controlled by the fingering pattern developed at early times of invasion of the solute front the late time behaviour has been analysed both in absolute and relative terms final value before breakthrough and temporal scaling for a given saturation small differences in the late time temporal scaling of the area of mixing and interface length have been observed regardless of phases distribution the impact of saturation is revealed by the different late time scaling which increases in both cases as saturation decreases thus depicting a more pronounced non fickian behaviour the joint impact of saturation and phases distribution is clearly observable in the final values of the area of mixing and interface length both generally increase as saturation decreases an exception being the area of the mixing zone under the lowest saturation in this case mixing is inhibited by the limited accessibility of the injected solute to the resident liquid which is hindered by the numerous isolated water clusters a larger variability is observed in the final values of the interface length indicating a larger control of phases distribution as saturation decreases the temporal evolution of the global reaction rate and the mass of reaction product and correspondingly the total mass of reaction product results from the interplay between mixing area and interface length thus the behaviour at early times is the same one described above by observing these magnitudes we demonstrate a larger control of the interface length the presence of air promotes the formation of interface length by stretching and folding the invasive front thus enhancing the creation of concentration gradients and therefore of mass reaction product in spite of the increasing of the late time temporal scaling of global reaction rate and mass of reaction product with decreasing saturation the heterogeneity introduced by phases distribution yields similar magnitudes of the total mass of reaction product for different saturations in a nutshell phases distribution controls the total mass of reaction product while its late time scaling is controlled by saturation much remains to be done both at pore and continuum scales for instance at continuum scale the knowledge of the actual saturation distribution in unsaturated soils and the actual spatial distribution of hydraulic conductivity in aquifers is essential to reduce the uncertainty of the predictions the total mass of reaction product the methodology presented here is general and allows further analyses with minimal changes in the model set up this allows to analyse numerically what is costly hardly repeatable and time consuming in the laboratory this work is a step forward in the modelling of the joint impact of phases distribution and saturation in solute dispersion mixing and reaction in unsaturated porous media credit authorship contribution statement joaquín jiménez martínez conceptualization methodology writing review editing andrés alcolea conceptualization methodology writing review editing julien a straubhaar methodology writing original draft philippe renard methodology writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements jjm gratefully acknowledges the financial support from the swiss national science foundation snf grant nr 200021 178986 we thank the three anonymous reviewers whose valuable comments and suggestions help to improve the manuscript we also acknowledge andrés valencia and almudena sánchez for the constructive discussions supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103697 appendix supplementary materials image application 1 image application 2 
412,in this study we have developed a combined lattice boltzmann smoothed profile method to explore coupled mechanisms governing transport of colloids and their retention in porous media we have considered flow in a constricted tube and included hydrodynamic gravity buoyancy van der waals and electrostatic forces to simulate colloid transport and aggregation a major advantage of this complete formulation is that it does not require any common assumptions which neglect the effects of inter particle forces e g dilute suspension or clean bed filtration and pore structure changes due to colloid retention the results show an increase in colloid aggregation and surface coverage as pore velocity decreases however the pore void fraction and its conductivity show a reduction with decreased velocity in the presence of a secondary energy minimum rolling of colloids on the grain surface is demonstrated to be the major mechanism that prevents pore clogging details of these observations are provided and a comprehensive sensitivity analysis of model parameters is performed and discussed keywords colloid transport agglomeration hydrodynamic effect colloid size effect lattice boltzmann method 1 introduction understanding colloid transport processes is essential for predicting transport of colloidal contaminants and microorganisms such as toxic nanoparticles and viruses colloids may act as pollutants or may carry other contaminants deep into the subsurface roy et al 2018 bakshi et al 2015 gavrilescu 2014 sen 2011 several mechanisms influence colloid filtration a major mechanism is straining which refers to colloid removal by a spectrum of physical process including size exclusion bridging across pore spaces or the retention of colloids in low velocity regions of porous media such as crevice sites and dead end pores this mechanism is affected by the colloid to collector diameter pore size distribution van der waals electric double layer and hydrodynamic forces torkzaban et al 2008 bradford et al 2007 bradford et al 2006 bradford et al 2002 when the colloid size is larger than the pore throat size size exclusion takes place which may completely clog the pore space bradford and torkzaban 2013 babakhani 2019 for smaller colloids with size comparable to the pore throat size the bridging mechanism may occur when several particles simultaneously arrive at a throat location this mechanism is affected by colloid concentration hydrodynamic forces the ratio of particle size to the throat size the pore size distribution and it is shown to be the mechanism responsible for permeability reduction in porous media ramachandran et al 2000 bacchin et al 2014 torkzaban et al 2015 when particles are much smaller than the pore size surface deposition is primarily influenced by adhesive forces and mass transfer of particles to the surface which occurs by interception gravitational sedimentation and brownian motion yang and balhoff 2017 yao et al 1971 many studies have reported results from column experiments to understand and simulate transport and removal mechanisms of colloids microorganisms and nanoparticles results have shown that many factors influence colloid transport and retention including solution ionic strength is bradford and torkzaban 2013 jin et al 2017 chen et al 2017 french et al 2009 zevi et al 2009 ph french et al 2009 fujita and kobayashi 2016 zhang et al 2010 electrolyte valence and type french et al 2009 zhang et al 2010 particle and pore surface zeta potential ζ saleh et al 2008 dunphy guzman et al 2006 fluid velocity zhang et al 2018 perez et al 2020 bennacer et al 2017 zhang et al 2015 johnson and tong 2006 suspension concentration wang et al 2012 bradford et al 2009 coating materials micić et al 2017 morales et al 2011 colloid and grains size and shape mcnew et al 2017 syngouna and chrysikopoulos 2012 pelley and tufenkji 2008 grain size distribution ahfir et al 2017 hammadi et al 2017 chalk et al 2012 gravity chrysikopoulos and syngouna 2014 kim and whittle 2006 surface roughness xinqiang et al 2019 henry and minier 2018 bradford et al 2017 torkzaban and bradford 2016 and physical and chemical heterogeneities bradford et al 2013 li and ma 2019 li et al 2017 bradford and torkzaban 2013 shen et al 2013 considerable amounts of retained colloids can be released by increasing the flow velocity decreasing the solution is increasing the ph when adsorbed divalent cations are exchanged for monovalent cations after flow interruptions and following water drainage and imbibition cycles bradford and torkzaban 2013 torkzaban et al 2008 seetha et al 2014 for example scouring of colloids and co existing aggregates by hydrodynamic forces can contribute significantly to release and mobilization of colloids to deeper depths chaumeil and crapper 2014 ahfir et al 2017 the macroscopic advection dispersion equation with one site or two site kinetics is commonly used to simulate measured breakthrough curves katzourakis and chrysikopoulos 2019 schijven et al 2013 simunek et al 2005 schijven and hassanizadeh 2000 however breakthrough curves and profiles of retained colloids typically exhibit time e g plateau region increases or decreases with time and depth dependent e g hyper exponential or non monotonic distributions with depth retention behavior that can depend on physical parameters such as grain size water content flow rate and chemical properties such as solution is and ph torkzaban et al 2008 a fundamental understanding and ability to predict the controlling mechanisms and factors that influence colloid transport retention and release is hampered by the complexity coupling and the number of processes that occur at the column scale to overcome this challenge several studies have employed eulerian or lagrangian approaches to numerically simulate colloid transport retention and release at the pore scale seetha et al 2014 seetha et al 2015 raoof and hassanizadeh 2010 raoof et al 2010 however the full complexity and coupling of various factors have not been considered in these works for example previous pore scale simulations have made simplifying assumptions such as dilute suspension clean bed filtration and irreversible attachment seetha et al 2014 seetha et al 2015 raoof and hassanizadeh 2010 raoof et al 2010 dilute suspensions imply that interactions among particles can be neglected clean bed filtration neglects the influence of attached particles on pore structure flow streamlines and particle transport whereas irreversible attachment disregards particle release and remobilization it is important to develop pore scale simulation approaches that are not constrained by these simplifications in order to assess the validity and impact of these assumptions on colloid transport and fate the interaction energy between two charged surfaces is commonly calculated using theory by derjaguin landau verwey overbeek dlvo which considers the combined effects of van der waals and electric double layer interactions derjaguin and landau 1941 verwey and overbeek 1948 the net interaction can result in conditions with an entirely attractive or a totally repulsive or an energy profile in which a primary and a secondary minimum exist for surfaces with opposite charges particle deposition is favorable because both van der waals and electric double layer interactions are attractive fig 1 a in this case a deep primary energy minimum pem is formed at very close distances between the two surfaces such that attached particles do not detach from the surface e g irreversible attachment when the two surfaces are similarly charged the electric double layer interaction is repulsive and the van der waals interaction is attractive an energy barrier against deposition can exist under these electrostatically unfavorable conditions in this case particle attachment in a pem can only occur if the energy barrier is sufficiently small for particles to diffuse over it however particles may reversibly attach in a secondary energy minimum sem which is developed at distances exterior to the energy barrier fig 1b messina et al 2015 p 25 early trajectory analysis applications that have studied particle retention surfaces have been found to be unrealistic because deposited particles can continue to roll over the surface bai and tien 1997 das et al 1994 sharma et al 1992 hubbe 1984 although several valuable experimental observations and numerical models exist which include different transport and adsorption parameters there is still a gap due to the lack of mechanistic studies that provide insights on parameters influencing colloid fate in porous media this study aims at filling this research gap by mechanistically simulating colloid transport and retention at the pore scale we have developed fully coupled numerical models to perform several simulations under both favorable and unfavorable conditions that explicitly included detailed physical processes with no assumptions of dilute suspensions and clean bed conditions the effect of fluid flow on the movement of particles as well as the effect of particle motion and rotation on fluid flow was simulated by including buoyancy gravity forces and hydrodynamic effects for both shear and normal stresses e g a two way coupling between fluid flow and particle transport equations the interactions between particles as well as particle surface interactions were considered and calculated using dlvo theory the presence of aggregates was considered on deposition processes whereas classical filtration models assume homogeneous pore space and largely ignore colloid aggregation moreover retained particles that interact with the sem can roll over the surface to the outlet be immobilized or detach to the bulk flow under unfavorable conditions we consider the mentioned mechanisms and perform a large number of simulations over 160 to explore the effects of flow velocity colloid size and pore structure evolution on colloid transport retention aggregation and release the effects of these parameters on colloid behavior is quantified using dynamically changing particle agglomerates particle particle and particle grain surface interactions available surface area pore hydraulic conductivity and void fraction results from this study provide a clear image of mechanisms controlling colloids transport and fate in the pore space of a porous medium 2 methods and parameters 2 1 lattice boltzmann method the developed model uses d2q9 lattice boltzmann method lbm to solve mass balance and momentum conservation equations for the steady state flow of an incompressible newtonian fluid at low reynolds numbers this model uses the discretized form of the boltzmann equation with an external force term and applies the bhatnagar gross krook bgk collision approximation as 1 f α x e α δ t t δ t f α x t 1 τ f α x t f α e q x t 3 ω α ρ e α f c 2 where f α and f α e q are the distribution and equilibrium distribution functions respectively the equilibrium distribution function can be written as 2 f α e q ω α ρ 1 3 e α u c 2 9 2 e α u 2 c 4 3 2 u u c 2 where c x and t are lattice speed lattice coordinate and time respectively the weight coefficients ωα and the discrete velocity vectors e α in each of the nine α directions in the d2q9 model are described as 3 e α 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 α 0 α 1 2 3 4 α 5 6 7 8 4 ω α 4 9 1 9 1 36 α 0 α 1 2 3 4 α 5 6 7 8 the dimensionless relaxation time τ is defined as τ ν c s 2 δ t 0 5 τ controls the relaxation time scale of the viscous stress in the numerical formulation which in its physical representation relates to the fluid kinematic viscosity ν and the speed of sound in the lattice defined as c s 2 c 2 3 f considers the external body forces exerted on the fluid which in this study simulates the effect of particles on fluid flow in the discretized velocity space the macroscopic fluid density ρ and velocity u can be defined as 5 ρ x t α 0 8 f α x t 6 ρ x t u x t α 0 8 e α f α x t by using the chapman enskog procedure the incompressible navier stokes equations can be obtained from eq 1 details of the lbm and derivation of navier stokes equations can be found in luo 1993 succi 2001 guo and shu 2013 2 2 smoothed profile method in the developed model we have applied a smoothed profile method spm to represent the individual particles the spm represents the solid particles using a profile function ϕ which is equal to one within the particle and approaches zero within the fluid phase we have considered round particles and eq 7 provides the profile which uses the particle radius rp the center position of the particle r p and the interface thickness ξ to provide the domain occupied by a given particle p 7 φ p x t s r p x r p t s l p 0 l p ξ 2 1 2 s i n π l p ξ 1 l p ξ 2 1 l p ξ 2 the calculated total profile function φ x t p 1 n p φ p x t is used to determine particle regions based on all n particles present within the pore space afterwards the particles velocity 8 φ x t u p x t p 1 n p φ p x t u c p t ω p x r p t at time t and position x u p x t is calculated by assuming rigid motion of particles as where u c p and ω p are the translational and the angular velocities of particles respectively in this study particles dynamically flow through the fluid filled pore space we apply fh function to obtain the fluid solid interaction forces and add this function to the lbm formula i e in form of a body force f in eq 1 the fh function is written as 9 f h φ x t f p x t φ x t u p x t u x t where u x t is the fluid velocity at time t and position x and ϕfp represents the fluid solid interaction forces acting on the solid phases the momentum conservation law can be used to obtain the integrated hydrodynamic force f p h and torque t p h exerted on each individual solid particle as 10 f p h p ρ φ x t u x t u p x t d p 11 t p h p x r p ρ φ x t u x t u p x t d p details of the spm can be found in jafari et al 2011 nakayama and yamamoto 2005 2 3 equations of motion and force components for particles to calculate a particle s translational velocity u c p and position r p we have included hydrodynamic fh gravitational fg particle surface f p s e d l f p s v d w and particle particle f p p e d l f p p v d w forces in eq 17 chaumeil and crapper 2014 derjaguin and landau 1941 verwey and overbeek 1948 hogg et al 1966 the angular velocity of a particle ω p is updated using eq 18 in which tp is the total external torque exerted on a particle and ip is the particle moment of inertia for particle sizes considered in this study i e 1 3 and 10 µm particle diffusion is negligible and it is not considered in transport equations table 1 provides a summary of equations employed in this study we have calculated the particle surface interactions assuming a sphere plate geometry and assumed that the curved pore surface is microscopically smooth i e while the surface is curved there is no roughness on the surface initially particle and pore surfaces are chemically homogeneous and uniformly charged we should note that these conditions are the initial settings and during simulations retention of particles with different sizes and charges on the pore surface alters the homogeneity of the pore a large number of simulations for colloid transport were performed for various solution is pore and particle surface zeta potentials ζ particles sizes dp and average fluid velocities u to obtain systematic results we have chosen a set of three values for each of these parameters presented in table 1 average fluid velocities u are related to steady state flows before particles were injected the fluid velocity field u was dynamically calculated i e in each time step after particles entered the pore space using coupled formulas for fluid flow and particle motion this allowed the effects of fluid hydrodynamic forces on particle movement and the effect of particles on fluid flow to be captured with local velocity variations the selected range of parameters resulted in 162 different simulations to cover a range of favorable and unfavorable conditions several simulations were run simultaneously on a workstation pc with 32 cores and 128 gb memory this approach was found to be more time efficient than running each simulation on multiple cores the computational time for each simulation was on average around nineteen days after which a new set of simulations was run until all 162 simulations were completed in describing results of the simulations unless otherwise stated particles were retained in the sem zone of other particles to form agglomerates which are shown by orange color particles in figures or in the sem zone of the grain surface under unfavorable conditions which are indicated by red color particles in figures strong particle attachment in pem takes place when there is no energy barrier under favorable conditions which are shown by white color particles in figures ρ p 1055 kg m3 mp kg and vp m3 are density mass and volume of particles respectively kb 1 38 10 23 j k is the boltzmann constant t 298 k is temperature e 1 6 10 19 c is electron charge ε0 8 85 10 12 c2 jm is vacuum dielectric permittivity ε r 78 54 is dielectric constant of the media ha 1 5 10 21 j is the hamaker constant dij m is the center to center distance between two particles h m is the separation distance z is the valence of each ion species in the electrolyte and κ 2 103 nae 2 is ε0ε r kbt 1 2 m 1 is the reciprocal debye length for a monovalent electrolyte where na 6 02 1023 is avogadro s number 2 4 torque analysis to calculate the torque when particles enter into the sem of the grain surface a contact area with a lever arm of ix frdp 8k 1 3 was calculated where fr is the sum of forces providing torques to prevent rolling johnson et al 1971 and k is the composite young s modulus for which a value of 4 014 109 nm 2 was chosen in this study we calculate torques at the two ends of the contact area which is represented by a line in 2d simulations to determine whether the trapped particles can roll forward backward or they remain immobile on the sinusoidal pore surface torkzaban et al 2007 when a particle is moving in the bulk flow its rotation is around its center however when it is retained within the grain sem it begins rolling around the edge of its contact line pore scale simulations have shown that the secondary minimum plays an important role in retention of both small and large size colloids in the absence of diffusion i e for particle sizes larger than 1 µm the contribution of sem in particle retention increases when the interaction energy barrier increases and favorability for attachment in the pem of the surface is reduced seetha et al 2014 for much smaller particles that diffusion is a major transport mechanism the sem retention role is reduced and diffusive release of particles may occur 3 geometry and boundary conditions in this study we have considered a sinusoidal pore with a length of 200 µm and an opening of 50 µm at the inlet and outlet which is reduced to 20 µm in the middle of the pore this pore structure represents a typical pore present in glass beads or sand packs between pairs of rounded grains the chosen pore size falls in the range of medium sand packs and is within the common range of pore size distributions for sandstone and carbonate rocks the importance of the sinusoidal shape is that it captures the presence of diverging and converging velocities and streamlines in porous media a curve boundary bounce back method was applied to simulate the pore surfaces bouzidi et al 2001 at the pore inlet boundary a parabolic velocity profile was implemented and a constant pressure was assigned at the pore outlet these conditions were chosen to obtain a mean steady state flow velocity along the pore equal to 1 5 and 10 m d before injection of any particles the particle injection height was selected to allow particles to enter randomly along the pore inlet face to resemble colloid trajectories in porous media the rate of colloid injection was continued and chosen such that the surface area of entering colloids would be equal to 1188 µm2 per injected fluid pore volume shown by pv in the text and figures for example the particle injection rates were equal to 168 60 and 15 particles per injected fluid pv in simulations using 3 5 and 10 µm particles respectively when the bulk velocity was 10 m d these rates were equal to 2 108 9 108 and 27 108 particles per milliliter of injected fluid respectively this approach allowed us to provide a well defined basis for comparison of results from different simulations the initial velocity of particles at the inlet was chosen to be equal to the fluid velocity at that location the constructed numerical grid included 400 100 cells in each principal direction we chose to only simulate 2d geometries because of the considerable computational time that was required to solve the coupled equations 4 results and discussion 4 1 hydrodynamic effect the flowing water creates a hydrodynamic force on moving and attached colloids our results have shown that lower velocities generate forces which are relatively weak and may not be able to overcome adhesive forces even for particles retained within the sem zone of other particles or the pore surface therefore pore clogging was more frequent in these simulations due to lower velocity values as all the colloids are similarly charged the condition for aggregation is unfavorable and due to colloid colloid sem interactions however the retention of colloids on the grain surface can occur within the sem zone under unfavorable conditions or within the pem zone under favorable conditions once colloids are attached on the pore surface under favorable conditions then condition may reverse from favorable to unfavorable and sem interactions between approaching and already attached colloids may result in multilayer deposition fig 2 a and b examine the attachment and clogging behavior of 5 and 3 µm sized particles at several velocities under favorable conditions when an intermediate is of 0 05 m was considered pore clogging was observed at a fluid velocity of 1 m d for 5 µm particles when ζ 17 5 45 56 and 60 mv and for 3 µm particles when ζ 17 5 mv conversely colloids formed a single attached layer on the grain surface that delayed pore clogging when higher velocities of 5 and 10 m d were applied e g colloids did not form multi layers that were needed to clog the pore approaching particles moving in the bulk solution can generally attach within the sem zone of deposited particles and form multilayer deposition during this process the pore size available to flow decreases and generates larger shear forces which are more effective in mobilizing particles and agglomerates the increased shear forces therefore hamper strong pore clogging this effect is shown in fig 2c where the increased shear force resulted in separation of retained particles and remobilization of aggregates the non uniform shape of the pore generates hydrodynamic forces which are stronger at the location of the pore throat and can remobilize retained particles we describe this effect using fig 2d this figure shows a particle the red particle in the blue box which is rolling over the surface to reach the pore constriction the increased shear force detaches this particle from the grain surface and makes it rotate around its own center while still experiencing dlvo interactions with the surface shown as the white particle in the blue box ultimately this particle is completely released from the surface and enters the bulk flow shown as the light blue particle in the blue box the velocity field may change due to particle retention and pore shape and this can deform clusters of aggregated colloids the generated velocities may break a cluster of aggregated colloids into smaller groups depending on the relative strength of the shear force to the depth of the sem in fig 2e two agglomerates are shown in blue and red boxes each aggregate remains intact until passing through the throat but then they disaggregate due to increased fluid velocity and shear force that can overcome weak sem interactions among these particles at low is of 0 001 m the velocity field begins to diverge after passing the pore throat and hydrodynamic forces decrease particles and agglomerates become less mobile due to this decrease in force in this situation approaching mobile colloids and aggregates with higher velocities can collide with less mobile agglomerates after passing through the narrow pore throat the outcome of this collision depends on the acquired momentum of the aggregate and it may begin to move faster fig 3 a b show that agglomerates become less mobile after passing through the throat location marked by red boxes in figures and then they start to move faster once approaching mobile colloids marked by blue boxes collide with them the coupling between fluid flow and colloid transport generates transient changes in the velocity field in particular clogging builds up fluid pressure and increases fluid velocity among agglomerated particles to maintain the fluid flow prescribed by the inlet boundary condition if the generated force is not large enough to break the cluster and remobilize retained particles agglomerates begin to clog the pore as shown in fig 3c however if the increase in shear flow is enough to break up the agglomerates the free pore space recovers and remobilization relaxes the pressure field and lowers the fluid velocity fig 3d shows examples of pressure gradient fluctuations caused by pore clogging and subsequent rupture of agglomerates similar observations were made by dunphy guzman et al 2006 they found that shear forces increased within narrow channels when nanoparticles started to clog but that aggregates can break apart and reform in this section we provided some physical insights in how particles interact with each other and the pore surface at the pore scale the effect of these interactions on particle agglomeration pore surface coverage conductivity and void fraction is discussed in sections 4 1 1 and 4 1 2 under favorable and unfavorable conditions respectively 4 1 1 effects of velocity on colloid transport and change of pore properties favorable conditions in this section we will explore how flow velocity influences colloid transport agglomeration grain surface coverage pore conductivity and pore void fraction the size and stability of an aggregate is influenced by flow velocity we define particle coordination number to describe the connectivity of colloid members within an aggregate the particle coordination number for any colloid is the number of particles that are attached to that colloid the average coordination number was calculated from this information for each aggregate and for the whole pore the normalized grain surface coverage was calculated as the ratio of occupied grain surface area by deposited particles to the total grain surface in this study grain surface area that was occupied by a retained colloid was calculated by projecting the colloid diameter on the grain surface our results show that the average coordination number i e connectivity among colloid members of aggregates decreases as the flow velocity and hydrodynamic force increases because aggregates are ruptured into smaller clusters fig 4 a the generated clusters can often flow deeper into the pore space due to their smaller size and this influences the arrangement of the retained colloids on the grain surface the increased hydrodynamic force lowers the grain surface coverage fig 4b and increases the void fraction and conductivity of the pore fig 4c d these observations agree with findings from li et al 2017 column experiments in ko and elimelech 2000 showed that larger flow velocities create a greater distance between attached particles this space is called the shadow zone and colloids do not deposit within this space ko and elimelech 2000 as flow velocity decreases shadow zones grow smaller and their effect on retention of other particles and change of grain surface coverage becomes negligible our simulations showed the same general trend in grain surface coverage however slight deviations from this trend are probable because interactions between colloids and fluid flow are complex and dynamic for example in fig 4b plots f and h the simulations with flow velocity of 10 m d showed a higher surface coverage than the simulations with a lower velocity of 5 m d for the simulation shown in fig 4b f with a velocity of 5 m d we observed that an agglomerate near the inlet changed the flow field such that fewer particles were carried towards the grain surface and attached in this case the grain surface coverage was lower at velocity of 5 m d than 10 m d until the aggregate started to move and the relaxed fluid flow allowed more attachment fig 4b h shows that the pore space was clogged for all three velocities when the is was 0 3 m however several remobilization events happened for the 3 µm agglomerates before complete pore clogging remobilization happened when an increase in the velocity to 10 m d made more particles detach and move further along the pore space this increased velocity ruptured aggregates into individual or small size clusters which deposit on the grain surface in a single layer pattern and increase the surface coverage compared to a lower velocity of 5 m d when particle size was increased from 3 to 5 µm the observed surface coverage for most combinations of parameters was lower for u 10 m d compared to u 5 m d the exceptions to this trend were the simulations with is 0 3 m for which pore clogging took place close to the pore inlet before the grain surface could contact many colloids therefore for larger particles fast clogging close to the pore inlet and blockage of flow through the pore can prevent an increase in the grain surface coverage for the whole pore the 5 and 10 µm particles showed less remobilization events in comparison to 3 µm particles mainly because they formed stronger attractive particle particle forces these results agree with findings of ahfir et al 2017 who showed that under lower flow velocities the hydrodynamic forces were not sufficient to prevent deposition or to mobilize attached particles ahfir et al 2017 according to their study while attachment happened to colloids of different sizes larger colloids attached mainly close to the inlet of the sample however larger particles could travel further when the flow velocity was increased and this resulted in a smoother profile of adsorbed mass along the sample ahfir et al 2017 4 1 2 effects of velocity on colloid transport and change of pore properties unfavorable conditions the connectivity among the aggregated colloids under unfavorable condition is shown in fig 5 a for 3 µm colloids simulations using the lower velocity of u 1 m d provided the highest particle coordination number the particle coordination number shows more fluctuations under low is 0 001 m because retention and remobilization take place several times the coordination number becomes larger at a higher is because of a deeper sem in comparison with favorable conditions the coordination numbers under flow velocities of 5 and 10 m d have closer values to the coordination numbers related to velocity of 1 m d under unfavorable conditions this is because under this condition the second layer of retained particles in sem distance of the surface rolling particles can remain connected to them while these particles are rolling on the pore surface however under favorable conditions the first layer of particles is strongly attached to the surface and the second layer particles in their sem distance have to be separated from them to continue their path toward the outlet an important transport mechanism under unfavorable condition is the rolling of retained particles over the surface which enables them to move forward without detaching from the surface particles and agglomerates move faster when the applied velocity and hydrodynamic force increases they can collide and form new aggregates with larger coordination numbers during movement while simulations using 3 and 5 µm particles showed similar behaviors 10 µm particles showed larger fluctuations because hydrodynamic forces and sem interactions with the grain surface and other particles were stronger surface coverage is highly affected by the formation of agglomerates when conditions are not favorable for creation of large agglomerates transport happens in the form of individual colloids or small agglomerates which can deposit on grain surfaces especially at lower flow velocities this occurred under low is 0 001 m condition and when the is 0 05 m for fluid injection of less than 2 pv or high values of zeta potential about 60 mv because the surface coverage increased as the flow velocity decreased fig 5b plots a b c f and d pv 2 e pv 2 fig 5b also shows that for moderate to high is values 0 05 and 0 3 m the surface coverage raised considerably when the velocity increased from 5 to 10 m d fig 5b plots d e h i pv 2 in contrast surface coverage was higher for lower flow velocities under favorable conditions due to the reduction of the shadow zones behind strongly attached particles under unfavorable conditions the shadow zone can change as particles roll over the grain surface and the distance among rolling particles will change until they leave the channel as velocity increased to 10 m d some large agglomerates moved faster toward the outlet the blocked area behind them grew smaller and the surface coverage increased the conductivity and the void fraction of the pore space are influenced by particle agglomeration the presence of smaller and mobile agglomerates under higher flow velocities help the pore void fraction and conductivity to have large values the conductivity is not sensitive to the flow velocity under low is 0 001 m conditions fig 5c however larger agglomerates are formed under larger is values 0 05 m or 0 3 m and the pore conductivity becomes lower and larger variations in the local velocity field are observed in this case the generated force of the increased velocity remobilizes particles and agglomerates and the pore conductivity shown in fig 5c and void fraction fig 5d can fluctuate or rise over time torkzaban et al suggested that hydrodynamic bridging was the main cause of permeability reductions torkzaban et al 2015 they have showed that an increase in the flow velocity can break a fraction of colloid bridges and increase the permeability recall that the pore conductivity was diminished as a result of clogging under favorable conditions in contrast unfavorable conditions were very effective in maintaining the pore conductivity due to rolling of particles over the grain surface except for the simulations with is 0 3 m and ζ 17 5 mv shown in fig 5c plot g where the combination of high is and low zeta potential resulted in pore clogging fig 5d shows the change of pore void fraction with pv the observed behavior corresponds with the dynamics of grain surface coverage which is discussed before and is shown in fig 5b higher values of grain surface coverage indicate an increase in colloid retention which lowers the void fraction sharp reductions in the value of surface coverage corresponds with fluctuations of pore conductivity and pore void fraction shown by the red box in plot i of fig 5b d and are related to previously attached large size agglomerates that move out of the pore fig 5e 4 2 colloid size effect larger size colloids create stronger dlvo forces which are developed at larger distances from the grain surface and are more sensitive to is and zeta potential changes fig 6 a b this relation makes 10 µm size colloids to be retained more easily compared to the 5 µm or the 3 µm size colloids our simulations show that under favorable conditions the 10 µm colloids clog the pore space in a short time on the order of 1 pv whereas the 3 µm size colloids produced much less clogging deposition of these large particles changes the pore structure and results in filtration of the approaching particles due to stronger dlvo interactions detachment of large size colloids and their agglomerates is unlikely unless a considerably higher flow rate is applied fig 6c shows that a pore clogged with 5 µm size colloids did not able to re open during the simulation time the flow and chemistry conditions applied in this simulation are the same as those applied in fig 3d except that a smaller colloid size of 3 µm was employed fig 3d shows re opening events for the pore due to the smaller colloid size and weaker dlvo interactions yang and balhoff have shown that colloid bridging becomes the controlling retention mechanism when the particle to pore size ratio is 1 7 yang and balhoff 2017 under unfavorable conditions the average coordination number for 10 µm particles fig 6d shows stronger fluctuations in comparison with smaller 3 µm particles fig 6e when the is 0 05 and 0 3 m there are two reasons for such observations first the larger agglomerates need to considerably deform to pass through the narrow throat which may change the coordination number of each particle second as the colloid size increases there may be less particles available in the pore to make large agglomerates if these agglomerates are defragmented while moving the coordination number for a larger fraction of available particles changes and the fluctuations in agglomerates connectivity increases 4 3 pore structure effect the constricted pore shape used in this study has initially converging and diverging sections to provide a non uniform flow field in the beginning of the simulations the curved pore surface is also microscopically smooth i e with no roughness on the curved surfaces and chemically homogeneous however throughout the simulations deposition of colloids with different sizes and charges make the pore surface increasingly heterogeneous both physically and chemically the evolved pore structures influence the size and form of aggregates we have observed that generally aggregates become more elongated upon approaching the pore constriction and afterwards then may re form into rounded clusters shown in fig 7 a the attached colloids or aggregates can significantly change the fluid streamlines fig 7b shows that the 10 µm particles has squeezed the fluid into a few remaining narrow spaces where flow velocity increases fig 7c shows how flow streamlines are deviated into a new path due to the presence of an agglomerate marked in the figure using a box as the pore space available for flow shrinks the deviated streamlines have larger velocity magnitudes and can mobilize colloids present in their newly established path the non uniform pore shape and particle attachments causes variable shear forces to act on particles or agglomerates in different locations of the pore space fig 7d shows that the initial deposition of 10 µm particles at the pore constriction marked by numbers 1 2 and 3 created a partial bottleneck for other particles where the streamlines directed colloids into the center of the pore i e away from the grain surface therefore this simulation showed very late pore clogging in comparison with other simulations with 10 µm particles our simulations have shown the effect of clogging location on surface coverage in fig 7e the grain surface coverage remains lower as clogging occurs at a distance closer to the pore inlet shown by blue boxes in comparison with fig 7f this is because the clogging prevents accessibility of mobile colloids to downstream regions 5 summary and conclusions a wide range of experimental and numerical studies have explored colloid retention and release in porous media to determine controlling mechanisms however there is great uncertainty in characterizing these mechanisms at the column scale because of the complexity and coupling of many processes and factors to overcome this limitation a model has been developed to simulate colloid transport retention release and permeability alterations within a single pore our novel approach considers the interlink between different processes that were neglected in previous studies including the influence of bulk and retained particles on the flow field and particle particle interactions the effects of hydrodynamic forces solution is zeta potentials colloid size and pore structure on colloids transport and retention under both favorable and unfavorable conditions were subsequently investigated the results show that particle particle interactions can create aggregates that rupture deform attach and remobilize in the presence of various hydrodynamic forces solution is and surface charge conditions aggregates caused complete pore clogging under favorable conditions at the same time attachment increased the shear force by lowering the pore space available for flow which resulted in colloid remobilizations and rupture of aggregates the re opening of the pore space results in sharp increases in pore hydraulic conductivity and its void fraction our results have shown that the flowing colloids and agglomerates can produce the required momentum to remobilize stagnant agglomerates which are often formed ahead of a pore throat where streamlines diverge and the flow velocity decreases simulations under unfavorable conditions showed that the rolling of particles on the grain surface hinders pore clogging and considerably affects the shadow zone behind trapped particles observed differences in surface coverage and particle coordination number for favorable and unfavorable conditions were attributed to colloid rolling when hydrodynamic forces were sufficiently strong to mobilize the agglomerates the pore void fraction and conductivity increased whereas the coordination number and fluid pressure gradient decreased these findings are in agreement with previous studies based on the dlvo theory however our detailed direct transient simulations over a range of fluid velocities showed how the combined effects of is zeta potential colloid size and pore structure alterations determine the particle deposition behavior moreover we have shown and discussed how the complex and deformed flow can result in colloid transport behaviors which deviate from the expected general trends the observed mechanisms and their coupling provide a detail understanding that can be used to help explain and correctly model experimental observations at larger scales e g breakthrough curves and retention profiles in column experiments for example the underlying causes for hyper exponential and non monotonic retention profiles and ripening processes furthermore this information can be used to derive correlation equations for parameters such as retention release rate coefficients insight gained from the 162 two dimensional simulations in this work can also be used in identify specific conditions and factors that warrant additional research in 3d simulations but that are much more computationally intensive author statement all persons who meet authorship criteria are listed as authors and all authors certify that they have participated sufficiently in the work to take public responsibility for the content including participation in the concept design analysis writing or revision of the manuscript furthermore each author certifies that this material or similar material has not been and will not be submitted to or published in any other publication before its appearance in the journal of petroleum science and engineering declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
412,in this study we have developed a combined lattice boltzmann smoothed profile method to explore coupled mechanisms governing transport of colloids and their retention in porous media we have considered flow in a constricted tube and included hydrodynamic gravity buoyancy van der waals and electrostatic forces to simulate colloid transport and aggregation a major advantage of this complete formulation is that it does not require any common assumptions which neglect the effects of inter particle forces e g dilute suspension or clean bed filtration and pore structure changes due to colloid retention the results show an increase in colloid aggregation and surface coverage as pore velocity decreases however the pore void fraction and its conductivity show a reduction with decreased velocity in the presence of a secondary energy minimum rolling of colloids on the grain surface is demonstrated to be the major mechanism that prevents pore clogging details of these observations are provided and a comprehensive sensitivity analysis of model parameters is performed and discussed keywords colloid transport agglomeration hydrodynamic effect colloid size effect lattice boltzmann method 1 introduction understanding colloid transport processes is essential for predicting transport of colloidal contaminants and microorganisms such as toxic nanoparticles and viruses colloids may act as pollutants or may carry other contaminants deep into the subsurface roy et al 2018 bakshi et al 2015 gavrilescu 2014 sen 2011 several mechanisms influence colloid filtration a major mechanism is straining which refers to colloid removal by a spectrum of physical process including size exclusion bridging across pore spaces or the retention of colloids in low velocity regions of porous media such as crevice sites and dead end pores this mechanism is affected by the colloid to collector diameter pore size distribution van der waals electric double layer and hydrodynamic forces torkzaban et al 2008 bradford et al 2007 bradford et al 2006 bradford et al 2002 when the colloid size is larger than the pore throat size size exclusion takes place which may completely clog the pore space bradford and torkzaban 2013 babakhani 2019 for smaller colloids with size comparable to the pore throat size the bridging mechanism may occur when several particles simultaneously arrive at a throat location this mechanism is affected by colloid concentration hydrodynamic forces the ratio of particle size to the throat size the pore size distribution and it is shown to be the mechanism responsible for permeability reduction in porous media ramachandran et al 2000 bacchin et al 2014 torkzaban et al 2015 when particles are much smaller than the pore size surface deposition is primarily influenced by adhesive forces and mass transfer of particles to the surface which occurs by interception gravitational sedimentation and brownian motion yang and balhoff 2017 yao et al 1971 many studies have reported results from column experiments to understand and simulate transport and removal mechanisms of colloids microorganisms and nanoparticles results have shown that many factors influence colloid transport and retention including solution ionic strength is bradford and torkzaban 2013 jin et al 2017 chen et al 2017 french et al 2009 zevi et al 2009 ph french et al 2009 fujita and kobayashi 2016 zhang et al 2010 electrolyte valence and type french et al 2009 zhang et al 2010 particle and pore surface zeta potential ζ saleh et al 2008 dunphy guzman et al 2006 fluid velocity zhang et al 2018 perez et al 2020 bennacer et al 2017 zhang et al 2015 johnson and tong 2006 suspension concentration wang et al 2012 bradford et al 2009 coating materials micić et al 2017 morales et al 2011 colloid and grains size and shape mcnew et al 2017 syngouna and chrysikopoulos 2012 pelley and tufenkji 2008 grain size distribution ahfir et al 2017 hammadi et al 2017 chalk et al 2012 gravity chrysikopoulos and syngouna 2014 kim and whittle 2006 surface roughness xinqiang et al 2019 henry and minier 2018 bradford et al 2017 torkzaban and bradford 2016 and physical and chemical heterogeneities bradford et al 2013 li and ma 2019 li et al 2017 bradford and torkzaban 2013 shen et al 2013 considerable amounts of retained colloids can be released by increasing the flow velocity decreasing the solution is increasing the ph when adsorbed divalent cations are exchanged for monovalent cations after flow interruptions and following water drainage and imbibition cycles bradford and torkzaban 2013 torkzaban et al 2008 seetha et al 2014 for example scouring of colloids and co existing aggregates by hydrodynamic forces can contribute significantly to release and mobilization of colloids to deeper depths chaumeil and crapper 2014 ahfir et al 2017 the macroscopic advection dispersion equation with one site or two site kinetics is commonly used to simulate measured breakthrough curves katzourakis and chrysikopoulos 2019 schijven et al 2013 simunek et al 2005 schijven and hassanizadeh 2000 however breakthrough curves and profiles of retained colloids typically exhibit time e g plateau region increases or decreases with time and depth dependent e g hyper exponential or non monotonic distributions with depth retention behavior that can depend on physical parameters such as grain size water content flow rate and chemical properties such as solution is and ph torkzaban et al 2008 a fundamental understanding and ability to predict the controlling mechanisms and factors that influence colloid transport retention and release is hampered by the complexity coupling and the number of processes that occur at the column scale to overcome this challenge several studies have employed eulerian or lagrangian approaches to numerically simulate colloid transport retention and release at the pore scale seetha et al 2014 seetha et al 2015 raoof and hassanizadeh 2010 raoof et al 2010 however the full complexity and coupling of various factors have not been considered in these works for example previous pore scale simulations have made simplifying assumptions such as dilute suspension clean bed filtration and irreversible attachment seetha et al 2014 seetha et al 2015 raoof and hassanizadeh 2010 raoof et al 2010 dilute suspensions imply that interactions among particles can be neglected clean bed filtration neglects the influence of attached particles on pore structure flow streamlines and particle transport whereas irreversible attachment disregards particle release and remobilization it is important to develop pore scale simulation approaches that are not constrained by these simplifications in order to assess the validity and impact of these assumptions on colloid transport and fate the interaction energy between two charged surfaces is commonly calculated using theory by derjaguin landau verwey overbeek dlvo which considers the combined effects of van der waals and electric double layer interactions derjaguin and landau 1941 verwey and overbeek 1948 the net interaction can result in conditions with an entirely attractive or a totally repulsive or an energy profile in which a primary and a secondary minimum exist for surfaces with opposite charges particle deposition is favorable because both van der waals and electric double layer interactions are attractive fig 1 a in this case a deep primary energy minimum pem is formed at very close distances between the two surfaces such that attached particles do not detach from the surface e g irreversible attachment when the two surfaces are similarly charged the electric double layer interaction is repulsive and the van der waals interaction is attractive an energy barrier against deposition can exist under these electrostatically unfavorable conditions in this case particle attachment in a pem can only occur if the energy barrier is sufficiently small for particles to diffuse over it however particles may reversibly attach in a secondary energy minimum sem which is developed at distances exterior to the energy barrier fig 1b messina et al 2015 p 25 early trajectory analysis applications that have studied particle retention surfaces have been found to be unrealistic because deposited particles can continue to roll over the surface bai and tien 1997 das et al 1994 sharma et al 1992 hubbe 1984 although several valuable experimental observations and numerical models exist which include different transport and adsorption parameters there is still a gap due to the lack of mechanistic studies that provide insights on parameters influencing colloid fate in porous media this study aims at filling this research gap by mechanistically simulating colloid transport and retention at the pore scale we have developed fully coupled numerical models to perform several simulations under both favorable and unfavorable conditions that explicitly included detailed physical processes with no assumptions of dilute suspensions and clean bed conditions the effect of fluid flow on the movement of particles as well as the effect of particle motion and rotation on fluid flow was simulated by including buoyancy gravity forces and hydrodynamic effects for both shear and normal stresses e g a two way coupling between fluid flow and particle transport equations the interactions between particles as well as particle surface interactions were considered and calculated using dlvo theory the presence of aggregates was considered on deposition processes whereas classical filtration models assume homogeneous pore space and largely ignore colloid aggregation moreover retained particles that interact with the sem can roll over the surface to the outlet be immobilized or detach to the bulk flow under unfavorable conditions we consider the mentioned mechanisms and perform a large number of simulations over 160 to explore the effects of flow velocity colloid size and pore structure evolution on colloid transport retention aggregation and release the effects of these parameters on colloid behavior is quantified using dynamically changing particle agglomerates particle particle and particle grain surface interactions available surface area pore hydraulic conductivity and void fraction results from this study provide a clear image of mechanisms controlling colloids transport and fate in the pore space of a porous medium 2 methods and parameters 2 1 lattice boltzmann method the developed model uses d2q9 lattice boltzmann method lbm to solve mass balance and momentum conservation equations for the steady state flow of an incompressible newtonian fluid at low reynolds numbers this model uses the discretized form of the boltzmann equation with an external force term and applies the bhatnagar gross krook bgk collision approximation as 1 f α x e α δ t t δ t f α x t 1 τ f α x t f α e q x t 3 ω α ρ e α f c 2 where f α and f α e q are the distribution and equilibrium distribution functions respectively the equilibrium distribution function can be written as 2 f α e q ω α ρ 1 3 e α u c 2 9 2 e α u 2 c 4 3 2 u u c 2 where c x and t are lattice speed lattice coordinate and time respectively the weight coefficients ωα and the discrete velocity vectors e α in each of the nine α directions in the d2q9 model are described as 3 e α 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 α 0 α 1 2 3 4 α 5 6 7 8 4 ω α 4 9 1 9 1 36 α 0 α 1 2 3 4 α 5 6 7 8 the dimensionless relaxation time τ is defined as τ ν c s 2 δ t 0 5 τ controls the relaxation time scale of the viscous stress in the numerical formulation which in its physical representation relates to the fluid kinematic viscosity ν and the speed of sound in the lattice defined as c s 2 c 2 3 f considers the external body forces exerted on the fluid which in this study simulates the effect of particles on fluid flow in the discretized velocity space the macroscopic fluid density ρ and velocity u can be defined as 5 ρ x t α 0 8 f α x t 6 ρ x t u x t α 0 8 e α f α x t by using the chapman enskog procedure the incompressible navier stokes equations can be obtained from eq 1 details of the lbm and derivation of navier stokes equations can be found in luo 1993 succi 2001 guo and shu 2013 2 2 smoothed profile method in the developed model we have applied a smoothed profile method spm to represent the individual particles the spm represents the solid particles using a profile function ϕ which is equal to one within the particle and approaches zero within the fluid phase we have considered round particles and eq 7 provides the profile which uses the particle radius rp the center position of the particle r p and the interface thickness ξ to provide the domain occupied by a given particle p 7 φ p x t s r p x r p t s l p 0 l p ξ 2 1 2 s i n π l p ξ 1 l p ξ 2 1 l p ξ 2 the calculated total profile function φ x t p 1 n p φ p x t is used to determine particle regions based on all n particles present within the pore space afterwards the particles velocity 8 φ x t u p x t p 1 n p φ p x t u c p t ω p x r p t at time t and position x u p x t is calculated by assuming rigid motion of particles as where u c p and ω p are the translational and the angular velocities of particles respectively in this study particles dynamically flow through the fluid filled pore space we apply fh function to obtain the fluid solid interaction forces and add this function to the lbm formula i e in form of a body force f in eq 1 the fh function is written as 9 f h φ x t f p x t φ x t u p x t u x t where u x t is the fluid velocity at time t and position x and ϕfp represents the fluid solid interaction forces acting on the solid phases the momentum conservation law can be used to obtain the integrated hydrodynamic force f p h and torque t p h exerted on each individual solid particle as 10 f p h p ρ φ x t u x t u p x t d p 11 t p h p x r p ρ φ x t u x t u p x t d p details of the spm can be found in jafari et al 2011 nakayama and yamamoto 2005 2 3 equations of motion and force components for particles to calculate a particle s translational velocity u c p and position r p we have included hydrodynamic fh gravitational fg particle surface f p s e d l f p s v d w and particle particle f p p e d l f p p v d w forces in eq 17 chaumeil and crapper 2014 derjaguin and landau 1941 verwey and overbeek 1948 hogg et al 1966 the angular velocity of a particle ω p is updated using eq 18 in which tp is the total external torque exerted on a particle and ip is the particle moment of inertia for particle sizes considered in this study i e 1 3 and 10 µm particle diffusion is negligible and it is not considered in transport equations table 1 provides a summary of equations employed in this study we have calculated the particle surface interactions assuming a sphere plate geometry and assumed that the curved pore surface is microscopically smooth i e while the surface is curved there is no roughness on the surface initially particle and pore surfaces are chemically homogeneous and uniformly charged we should note that these conditions are the initial settings and during simulations retention of particles with different sizes and charges on the pore surface alters the homogeneity of the pore a large number of simulations for colloid transport were performed for various solution is pore and particle surface zeta potentials ζ particles sizes dp and average fluid velocities u to obtain systematic results we have chosen a set of three values for each of these parameters presented in table 1 average fluid velocities u are related to steady state flows before particles were injected the fluid velocity field u was dynamically calculated i e in each time step after particles entered the pore space using coupled formulas for fluid flow and particle motion this allowed the effects of fluid hydrodynamic forces on particle movement and the effect of particles on fluid flow to be captured with local velocity variations the selected range of parameters resulted in 162 different simulations to cover a range of favorable and unfavorable conditions several simulations were run simultaneously on a workstation pc with 32 cores and 128 gb memory this approach was found to be more time efficient than running each simulation on multiple cores the computational time for each simulation was on average around nineteen days after which a new set of simulations was run until all 162 simulations were completed in describing results of the simulations unless otherwise stated particles were retained in the sem zone of other particles to form agglomerates which are shown by orange color particles in figures or in the sem zone of the grain surface under unfavorable conditions which are indicated by red color particles in figures strong particle attachment in pem takes place when there is no energy barrier under favorable conditions which are shown by white color particles in figures ρ p 1055 kg m3 mp kg and vp m3 are density mass and volume of particles respectively kb 1 38 10 23 j k is the boltzmann constant t 298 k is temperature e 1 6 10 19 c is electron charge ε0 8 85 10 12 c2 jm is vacuum dielectric permittivity ε r 78 54 is dielectric constant of the media ha 1 5 10 21 j is the hamaker constant dij m is the center to center distance between two particles h m is the separation distance z is the valence of each ion species in the electrolyte and κ 2 103 nae 2 is ε0ε r kbt 1 2 m 1 is the reciprocal debye length for a monovalent electrolyte where na 6 02 1023 is avogadro s number 2 4 torque analysis to calculate the torque when particles enter into the sem of the grain surface a contact area with a lever arm of ix frdp 8k 1 3 was calculated where fr is the sum of forces providing torques to prevent rolling johnson et al 1971 and k is the composite young s modulus for which a value of 4 014 109 nm 2 was chosen in this study we calculate torques at the two ends of the contact area which is represented by a line in 2d simulations to determine whether the trapped particles can roll forward backward or they remain immobile on the sinusoidal pore surface torkzaban et al 2007 when a particle is moving in the bulk flow its rotation is around its center however when it is retained within the grain sem it begins rolling around the edge of its contact line pore scale simulations have shown that the secondary minimum plays an important role in retention of both small and large size colloids in the absence of diffusion i e for particle sizes larger than 1 µm the contribution of sem in particle retention increases when the interaction energy barrier increases and favorability for attachment in the pem of the surface is reduced seetha et al 2014 for much smaller particles that diffusion is a major transport mechanism the sem retention role is reduced and diffusive release of particles may occur 3 geometry and boundary conditions in this study we have considered a sinusoidal pore with a length of 200 µm and an opening of 50 µm at the inlet and outlet which is reduced to 20 µm in the middle of the pore this pore structure represents a typical pore present in glass beads or sand packs between pairs of rounded grains the chosen pore size falls in the range of medium sand packs and is within the common range of pore size distributions for sandstone and carbonate rocks the importance of the sinusoidal shape is that it captures the presence of diverging and converging velocities and streamlines in porous media a curve boundary bounce back method was applied to simulate the pore surfaces bouzidi et al 2001 at the pore inlet boundary a parabolic velocity profile was implemented and a constant pressure was assigned at the pore outlet these conditions were chosen to obtain a mean steady state flow velocity along the pore equal to 1 5 and 10 m d before injection of any particles the particle injection height was selected to allow particles to enter randomly along the pore inlet face to resemble colloid trajectories in porous media the rate of colloid injection was continued and chosen such that the surface area of entering colloids would be equal to 1188 µm2 per injected fluid pore volume shown by pv in the text and figures for example the particle injection rates were equal to 168 60 and 15 particles per injected fluid pv in simulations using 3 5 and 10 µm particles respectively when the bulk velocity was 10 m d these rates were equal to 2 108 9 108 and 27 108 particles per milliliter of injected fluid respectively this approach allowed us to provide a well defined basis for comparison of results from different simulations the initial velocity of particles at the inlet was chosen to be equal to the fluid velocity at that location the constructed numerical grid included 400 100 cells in each principal direction we chose to only simulate 2d geometries because of the considerable computational time that was required to solve the coupled equations 4 results and discussion 4 1 hydrodynamic effect the flowing water creates a hydrodynamic force on moving and attached colloids our results have shown that lower velocities generate forces which are relatively weak and may not be able to overcome adhesive forces even for particles retained within the sem zone of other particles or the pore surface therefore pore clogging was more frequent in these simulations due to lower velocity values as all the colloids are similarly charged the condition for aggregation is unfavorable and due to colloid colloid sem interactions however the retention of colloids on the grain surface can occur within the sem zone under unfavorable conditions or within the pem zone under favorable conditions once colloids are attached on the pore surface under favorable conditions then condition may reverse from favorable to unfavorable and sem interactions between approaching and already attached colloids may result in multilayer deposition fig 2 a and b examine the attachment and clogging behavior of 5 and 3 µm sized particles at several velocities under favorable conditions when an intermediate is of 0 05 m was considered pore clogging was observed at a fluid velocity of 1 m d for 5 µm particles when ζ 17 5 45 56 and 60 mv and for 3 µm particles when ζ 17 5 mv conversely colloids formed a single attached layer on the grain surface that delayed pore clogging when higher velocities of 5 and 10 m d were applied e g colloids did not form multi layers that were needed to clog the pore approaching particles moving in the bulk solution can generally attach within the sem zone of deposited particles and form multilayer deposition during this process the pore size available to flow decreases and generates larger shear forces which are more effective in mobilizing particles and agglomerates the increased shear forces therefore hamper strong pore clogging this effect is shown in fig 2c where the increased shear force resulted in separation of retained particles and remobilization of aggregates the non uniform shape of the pore generates hydrodynamic forces which are stronger at the location of the pore throat and can remobilize retained particles we describe this effect using fig 2d this figure shows a particle the red particle in the blue box which is rolling over the surface to reach the pore constriction the increased shear force detaches this particle from the grain surface and makes it rotate around its own center while still experiencing dlvo interactions with the surface shown as the white particle in the blue box ultimately this particle is completely released from the surface and enters the bulk flow shown as the light blue particle in the blue box the velocity field may change due to particle retention and pore shape and this can deform clusters of aggregated colloids the generated velocities may break a cluster of aggregated colloids into smaller groups depending on the relative strength of the shear force to the depth of the sem in fig 2e two agglomerates are shown in blue and red boxes each aggregate remains intact until passing through the throat but then they disaggregate due to increased fluid velocity and shear force that can overcome weak sem interactions among these particles at low is of 0 001 m the velocity field begins to diverge after passing the pore throat and hydrodynamic forces decrease particles and agglomerates become less mobile due to this decrease in force in this situation approaching mobile colloids and aggregates with higher velocities can collide with less mobile agglomerates after passing through the narrow pore throat the outcome of this collision depends on the acquired momentum of the aggregate and it may begin to move faster fig 3 a b show that agglomerates become less mobile after passing through the throat location marked by red boxes in figures and then they start to move faster once approaching mobile colloids marked by blue boxes collide with them the coupling between fluid flow and colloid transport generates transient changes in the velocity field in particular clogging builds up fluid pressure and increases fluid velocity among agglomerated particles to maintain the fluid flow prescribed by the inlet boundary condition if the generated force is not large enough to break the cluster and remobilize retained particles agglomerates begin to clog the pore as shown in fig 3c however if the increase in shear flow is enough to break up the agglomerates the free pore space recovers and remobilization relaxes the pressure field and lowers the fluid velocity fig 3d shows examples of pressure gradient fluctuations caused by pore clogging and subsequent rupture of agglomerates similar observations were made by dunphy guzman et al 2006 they found that shear forces increased within narrow channels when nanoparticles started to clog but that aggregates can break apart and reform in this section we provided some physical insights in how particles interact with each other and the pore surface at the pore scale the effect of these interactions on particle agglomeration pore surface coverage conductivity and void fraction is discussed in sections 4 1 1 and 4 1 2 under favorable and unfavorable conditions respectively 4 1 1 effects of velocity on colloid transport and change of pore properties favorable conditions in this section we will explore how flow velocity influences colloid transport agglomeration grain surface coverage pore conductivity and pore void fraction the size and stability of an aggregate is influenced by flow velocity we define particle coordination number to describe the connectivity of colloid members within an aggregate the particle coordination number for any colloid is the number of particles that are attached to that colloid the average coordination number was calculated from this information for each aggregate and for the whole pore the normalized grain surface coverage was calculated as the ratio of occupied grain surface area by deposited particles to the total grain surface in this study grain surface area that was occupied by a retained colloid was calculated by projecting the colloid diameter on the grain surface our results show that the average coordination number i e connectivity among colloid members of aggregates decreases as the flow velocity and hydrodynamic force increases because aggregates are ruptured into smaller clusters fig 4 a the generated clusters can often flow deeper into the pore space due to their smaller size and this influences the arrangement of the retained colloids on the grain surface the increased hydrodynamic force lowers the grain surface coverage fig 4b and increases the void fraction and conductivity of the pore fig 4c d these observations agree with findings from li et al 2017 column experiments in ko and elimelech 2000 showed that larger flow velocities create a greater distance between attached particles this space is called the shadow zone and colloids do not deposit within this space ko and elimelech 2000 as flow velocity decreases shadow zones grow smaller and their effect on retention of other particles and change of grain surface coverage becomes negligible our simulations showed the same general trend in grain surface coverage however slight deviations from this trend are probable because interactions between colloids and fluid flow are complex and dynamic for example in fig 4b plots f and h the simulations with flow velocity of 10 m d showed a higher surface coverage than the simulations with a lower velocity of 5 m d for the simulation shown in fig 4b f with a velocity of 5 m d we observed that an agglomerate near the inlet changed the flow field such that fewer particles were carried towards the grain surface and attached in this case the grain surface coverage was lower at velocity of 5 m d than 10 m d until the aggregate started to move and the relaxed fluid flow allowed more attachment fig 4b h shows that the pore space was clogged for all three velocities when the is was 0 3 m however several remobilization events happened for the 3 µm agglomerates before complete pore clogging remobilization happened when an increase in the velocity to 10 m d made more particles detach and move further along the pore space this increased velocity ruptured aggregates into individual or small size clusters which deposit on the grain surface in a single layer pattern and increase the surface coverage compared to a lower velocity of 5 m d when particle size was increased from 3 to 5 µm the observed surface coverage for most combinations of parameters was lower for u 10 m d compared to u 5 m d the exceptions to this trend were the simulations with is 0 3 m for which pore clogging took place close to the pore inlet before the grain surface could contact many colloids therefore for larger particles fast clogging close to the pore inlet and blockage of flow through the pore can prevent an increase in the grain surface coverage for the whole pore the 5 and 10 µm particles showed less remobilization events in comparison to 3 µm particles mainly because they formed stronger attractive particle particle forces these results agree with findings of ahfir et al 2017 who showed that under lower flow velocities the hydrodynamic forces were not sufficient to prevent deposition or to mobilize attached particles ahfir et al 2017 according to their study while attachment happened to colloids of different sizes larger colloids attached mainly close to the inlet of the sample however larger particles could travel further when the flow velocity was increased and this resulted in a smoother profile of adsorbed mass along the sample ahfir et al 2017 4 1 2 effects of velocity on colloid transport and change of pore properties unfavorable conditions the connectivity among the aggregated colloids under unfavorable condition is shown in fig 5 a for 3 µm colloids simulations using the lower velocity of u 1 m d provided the highest particle coordination number the particle coordination number shows more fluctuations under low is 0 001 m because retention and remobilization take place several times the coordination number becomes larger at a higher is because of a deeper sem in comparison with favorable conditions the coordination numbers under flow velocities of 5 and 10 m d have closer values to the coordination numbers related to velocity of 1 m d under unfavorable conditions this is because under this condition the second layer of retained particles in sem distance of the surface rolling particles can remain connected to them while these particles are rolling on the pore surface however under favorable conditions the first layer of particles is strongly attached to the surface and the second layer particles in their sem distance have to be separated from them to continue their path toward the outlet an important transport mechanism under unfavorable condition is the rolling of retained particles over the surface which enables them to move forward without detaching from the surface particles and agglomerates move faster when the applied velocity and hydrodynamic force increases they can collide and form new aggregates with larger coordination numbers during movement while simulations using 3 and 5 µm particles showed similar behaviors 10 µm particles showed larger fluctuations because hydrodynamic forces and sem interactions with the grain surface and other particles were stronger surface coverage is highly affected by the formation of agglomerates when conditions are not favorable for creation of large agglomerates transport happens in the form of individual colloids or small agglomerates which can deposit on grain surfaces especially at lower flow velocities this occurred under low is 0 001 m condition and when the is 0 05 m for fluid injection of less than 2 pv or high values of zeta potential about 60 mv because the surface coverage increased as the flow velocity decreased fig 5b plots a b c f and d pv 2 e pv 2 fig 5b also shows that for moderate to high is values 0 05 and 0 3 m the surface coverage raised considerably when the velocity increased from 5 to 10 m d fig 5b plots d e h i pv 2 in contrast surface coverage was higher for lower flow velocities under favorable conditions due to the reduction of the shadow zones behind strongly attached particles under unfavorable conditions the shadow zone can change as particles roll over the grain surface and the distance among rolling particles will change until they leave the channel as velocity increased to 10 m d some large agglomerates moved faster toward the outlet the blocked area behind them grew smaller and the surface coverage increased the conductivity and the void fraction of the pore space are influenced by particle agglomeration the presence of smaller and mobile agglomerates under higher flow velocities help the pore void fraction and conductivity to have large values the conductivity is not sensitive to the flow velocity under low is 0 001 m conditions fig 5c however larger agglomerates are formed under larger is values 0 05 m or 0 3 m and the pore conductivity becomes lower and larger variations in the local velocity field are observed in this case the generated force of the increased velocity remobilizes particles and agglomerates and the pore conductivity shown in fig 5c and void fraction fig 5d can fluctuate or rise over time torkzaban et al suggested that hydrodynamic bridging was the main cause of permeability reductions torkzaban et al 2015 they have showed that an increase in the flow velocity can break a fraction of colloid bridges and increase the permeability recall that the pore conductivity was diminished as a result of clogging under favorable conditions in contrast unfavorable conditions were very effective in maintaining the pore conductivity due to rolling of particles over the grain surface except for the simulations with is 0 3 m and ζ 17 5 mv shown in fig 5c plot g where the combination of high is and low zeta potential resulted in pore clogging fig 5d shows the change of pore void fraction with pv the observed behavior corresponds with the dynamics of grain surface coverage which is discussed before and is shown in fig 5b higher values of grain surface coverage indicate an increase in colloid retention which lowers the void fraction sharp reductions in the value of surface coverage corresponds with fluctuations of pore conductivity and pore void fraction shown by the red box in plot i of fig 5b d and are related to previously attached large size agglomerates that move out of the pore fig 5e 4 2 colloid size effect larger size colloids create stronger dlvo forces which are developed at larger distances from the grain surface and are more sensitive to is and zeta potential changes fig 6 a b this relation makes 10 µm size colloids to be retained more easily compared to the 5 µm or the 3 µm size colloids our simulations show that under favorable conditions the 10 µm colloids clog the pore space in a short time on the order of 1 pv whereas the 3 µm size colloids produced much less clogging deposition of these large particles changes the pore structure and results in filtration of the approaching particles due to stronger dlvo interactions detachment of large size colloids and their agglomerates is unlikely unless a considerably higher flow rate is applied fig 6c shows that a pore clogged with 5 µm size colloids did not able to re open during the simulation time the flow and chemistry conditions applied in this simulation are the same as those applied in fig 3d except that a smaller colloid size of 3 µm was employed fig 3d shows re opening events for the pore due to the smaller colloid size and weaker dlvo interactions yang and balhoff have shown that colloid bridging becomes the controlling retention mechanism when the particle to pore size ratio is 1 7 yang and balhoff 2017 under unfavorable conditions the average coordination number for 10 µm particles fig 6d shows stronger fluctuations in comparison with smaller 3 µm particles fig 6e when the is 0 05 and 0 3 m there are two reasons for such observations first the larger agglomerates need to considerably deform to pass through the narrow throat which may change the coordination number of each particle second as the colloid size increases there may be less particles available in the pore to make large agglomerates if these agglomerates are defragmented while moving the coordination number for a larger fraction of available particles changes and the fluctuations in agglomerates connectivity increases 4 3 pore structure effect the constricted pore shape used in this study has initially converging and diverging sections to provide a non uniform flow field in the beginning of the simulations the curved pore surface is also microscopically smooth i e with no roughness on the curved surfaces and chemically homogeneous however throughout the simulations deposition of colloids with different sizes and charges make the pore surface increasingly heterogeneous both physically and chemically the evolved pore structures influence the size and form of aggregates we have observed that generally aggregates become more elongated upon approaching the pore constriction and afterwards then may re form into rounded clusters shown in fig 7 a the attached colloids or aggregates can significantly change the fluid streamlines fig 7b shows that the 10 µm particles has squeezed the fluid into a few remaining narrow spaces where flow velocity increases fig 7c shows how flow streamlines are deviated into a new path due to the presence of an agglomerate marked in the figure using a box as the pore space available for flow shrinks the deviated streamlines have larger velocity magnitudes and can mobilize colloids present in their newly established path the non uniform pore shape and particle attachments causes variable shear forces to act on particles or agglomerates in different locations of the pore space fig 7d shows that the initial deposition of 10 µm particles at the pore constriction marked by numbers 1 2 and 3 created a partial bottleneck for other particles where the streamlines directed colloids into the center of the pore i e away from the grain surface therefore this simulation showed very late pore clogging in comparison with other simulations with 10 µm particles our simulations have shown the effect of clogging location on surface coverage in fig 7e the grain surface coverage remains lower as clogging occurs at a distance closer to the pore inlet shown by blue boxes in comparison with fig 7f this is because the clogging prevents accessibility of mobile colloids to downstream regions 5 summary and conclusions a wide range of experimental and numerical studies have explored colloid retention and release in porous media to determine controlling mechanisms however there is great uncertainty in characterizing these mechanisms at the column scale because of the complexity and coupling of many processes and factors to overcome this limitation a model has been developed to simulate colloid transport retention release and permeability alterations within a single pore our novel approach considers the interlink between different processes that were neglected in previous studies including the influence of bulk and retained particles on the flow field and particle particle interactions the effects of hydrodynamic forces solution is zeta potentials colloid size and pore structure on colloids transport and retention under both favorable and unfavorable conditions were subsequently investigated the results show that particle particle interactions can create aggregates that rupture deform attach and remobilize in the presence of various hydrodynamic forces solution is and surface charge conditions aggregates caused complete pore clogging under favorable conditions at the same time attachment increased the shear force by lowering the pore space available for flow which resulted in colloid remobilizations and rupture of aggregates the re opening of the pore space results in sharp increases in pore hydraulic conductivity and its void fraction our results have shown that the flowing colloids and agglomerates can produce the required momentum to remobilize stagnant agglomerates which are often formed ahead of a pore throat where streamlines diverge and the flow velocity decreases simulations under unfavorable conditions showed that the rolling of particles on the grain surface hinders pore clogging and considerably affects the shadow zone behind trapped particles observed differences in surface coverage and particle coordination number for favorable and unfavorable conditions were attributed to colloid rolling when hydrodynamic forces were sufficiently strong to mobilize the agglomerates the pore void fraction and conductivity increased whereas the coordination number and fluid pressure gradient decreased these findings are in agreement with previous studies based on the dlvo theory however our detailed direct transient simulations over a range of fluid velocities showed how the combined effects of is zeta potential colloid size and pore structure alterations determine the particle deposition behavior moreover we have shown and discussed how the complex and deformed flow can result in colloid transport behaviors which deviate from the expected general trends the observed mechanisms and their coupling provide a detail understanding that can be used to help explain and correctly model experimental observations at larger scales e g breakthrough curves and retention profiles in column experiments for example the underlying causes for hyper exponential and non monotonic retention profiles and ripening processes furthermore this information can be used to derive correlation equations for parameters such as retention release rate coefficients insight gained from the 162 two dimensional simulations in this work can also be used in identify specific conditions and factors that warrant additional research in 3d simulations but that are much more computationally intensive author statement all persons who meet authorship criteria are listed as authors and all authors certify that they have participated sufficiently in the work to take public responsibility for the content including participation in the concept design analysis writing or revision of the manuscript furthermore each author certifies that this material or similar material has not been and will not be submitted to or published in any other publication before its appearance in the journal of petroleum science and engineering declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
413,classic extreme value theory provides asymptotic distributions of block maxima bm y or peaks over threshold pot however as bm and pot are relatively small subsets of the values assumed by the parent process z alternative approaches have been proposed to make inferences on extremes by using intermediate values and non asymptotic models in this study we investigate the finite sample theory of extremes based on order statistics and present a set of results enabling the analysis of the properties of non asymptotic distributions of bm in finite size blocks of data under the assumption that the parent process z has stationary temporal dependence in particular we suggest the beta binomial distribution f β b as a suitable approximation of the marginal distribution of order statistics and bm under dependence thus generalizing the theoretical results available under independence we demonstrate the usefulness of the f β b distribution in three conceptual applications of hydrological interest firstly we review the so called complete time series analysis cta framework showing that the differences between fy and fz are due to the inherent theoretical nature of the processes y and z and the different probabilistic failure scenarios described by fy and fz secondly we provide a theoretical rule to select the number of the largest maxima lm and over threshold exceedances ot required to approximate the desired portion of the upper tail of fz with specified accuracy finally we discuss how the f β b distribution offers an interpretation and generalization of the so called metastatistical extreme value mev framework and its simplified version smev avoiding the use of high dimensional joint distributions and preliminary data thresholding and declustering all methodological results are validated by monte carlo simulations involving widely used stochastic processes with persistence real world stream flow data are also analyzed as proof of concept keywords order statistics block maxima persistent processes beta binomial distribution return period metastatistical extreme value mev todorovic distributions 1 introduction since the pioneering works of hazen 1914 and fuller 1914 on water supply management and flood protection design the study of hydrological extremes has been the focus of many theoretical and applied studies from a theoretical standpoint an entire branch of statistics called extreme value theory evt has been developed to characterize the probability of extremes fisher and tippett 1928 von mises 1936 gnedenko 1943 jenkinson 1955 balkema and de haan 1974 pickands iii 1975 leadbetter 1983 smith 1984 davison and smith 1990 beirlant et al 2006 the application of evt to hydro climatic analyses has become a prominent topic after the work of gumbel 1958 who provided the link between evt results and the empirical basis of hydrological frequency curves see e g coles 2001 salvadori et al 2007 for an overview in the context on hydro climatic applications evt describes the extremal behavior of observed phenomena by asymptotic probability distributions which are valid for a large number n of observations i e n resembling the samples of independent and identically distributed i id random variables whose parent distribution should belong to one of the three domains of attraction identified by evt under the assumption that the limit distribution of extreme values is non degenerate of course hydro climatic extremes hardly ever meet such oversimplifying assumptions indeed i systematic hydro climatic records rarely span more than 100 200 years ii extreme events are rare by definition and their number is commonly less than few tens if the focus is on really extreme values iii hydro climatic phenomena often result from combinations of heterogeneous processes such as frontal and convective meteorological systems extra tropical cyclones heavy rainfall rapid snow melt or monsoons driving precipitation and flood events e g morrison and smith 2002 smith et al 2011 2018 and iv hydro climatic processes such as stream flow rainfall and temperature at various temporal scales exhibit short long or mixed short long term serial correlation e g iliopoulou et al 2018 kantelhardt et al 2006 labat et al 2011 lombardo et al 2017 markonis et al 2018 papalexiou et al 2011 serinaldi 2010 serinaldi et al 2018 serinaldi and kilsby 2018 wang et al 2007 serinaldi and lombardo 2020 serinaldi kilsby 2016 and references therein in this respect focusing on sub samples such as block maxima bm or over threshold ot values can only apparently help fulfilling the required assumptions in real world analyses in fact bm and ot sub sampling procedures i decrease the available samples size ii do not remove possible heterogeneity of the generating mechanism which prevents or slows down convergence toward a domain of attraction and iii do not remove the possible effect of correlation characterizing non extreme values on the extremes even if annual maxima am and ot samples are formed in such a way to appear approximately uncorrelated iliopoulou and koutsoyiannis 2019 koutsoyiannis 2004 the need to overcome these limitations led to consider alternative modeling approaches such as sub pre asymptotic methods that allow for a more efficient use of the available data using for instance all the data forming over threshold clusters instead of cluster maxima only thus reducing the estimation variance with the same aim i e retaining as many observations as possible to infer the distribution of the largest values there has been a renewed research interest in non asymptotic distributions of bm in finite size samples including both extreme and intermediate observations e g de michele 2019 de michele and avanzi 2018 hosseini et al 2019 lombardo et al 2019 marani and ignaccolo 2015 marra et al 2018 2019 todorovic and zelenhasic 1970 volpi et al 2019 zorzetto et al 2016 zorzetto and marani 2020 in sections 1 1 and 1 2 we summarize the main results in asymptotic pre asymptotic and non asymptotic analysis of extreme values focusing on how these approaches deal with the aforementioned serial correlation effects and lack of distributional identity 1 1 overview of evt approaches to non homogeneity and serial dependence concerning the lack of distributional identity leadbetter et al 1983 p 289 distinguish two main types of variation with time of the distribution parameters when modeling processes such as rainfall or wave height i deterministic variations corresponding to patterns repeating from one period of time to the next e g seasonality and ii random fluctuations with their own distributional properties the latter case corresponds to observations coming from mixed or compound distributions which can provide a more realistic description of hydro climatic records reflecting the complexity heterogeneity of mechanisms driving the target hydro climatic process of interest barth et al 2019 koutsoyiannis 2004 porporato et al 2006 rossi et al 1984 rulfová et al 2016 for the aforementioned types of variation evt provides different theoretical results and therefore different limit distributions see e g examples in leadbetter et al 1983 pp 290 297 as far as the effect of correlation is concerned under the assumption that the limit distribution is non degenerate leadbetter 1983 showed that serially correlated and independent processes share the same asymptotic extreme value distributions when the correlated process fulfills the so called d condition which controls the long range dependence in the process at extreme levels for gaussian sequences with autocorrelation ρτ at lag τ the d condition is satisfied as soon as ρτ logτ 0 as τ berman 1964 which is however weaker than the geometric decay assumed by autoregressive models beirlant et al 2006 pp 373 374 the validity of evt limit distributions under serial correlation also holds for weaker versions of the d conditions such as the asymptotic independence of maxima aim proposed by o brien 1987 which admits a class of periodic markov chains see also beirlant et al 2006 p 374 similar conditions can be established for pot or cluster maxima as well e g leadbetter 1991 informally these conditions ensure that for large enough lags any dependence is sufficiently negligible so as to have no effect on the limit laws for extremes fawcett and walshaw 2016 however such asymptotic independence conditions are not valid for instance for strongly correlated processes in these cases one can obtain quite arbitrary asymptotic distributions for the maximum leadbetter et al 1983 p 66 leadbetter et al 1983 ch 6 provide examples of gaussian processes in which an asymptotic distribution for the maximum exists but is not of extreme value type when the dependence decay is so slow that d does not hold moreover the slow decay of the correlations not only changes the limiting distribution of extremes but also destroys the asymptotic independence between extreme values in disjoint intervals leadbetter et al 1983 p 133 this behavior is not so unusual for instance in daily stream flow records exhibiting long range dependence and therefore clustering of threshold exeedances in time and sequences of high low annual maxima i e flood rich and flood poor periods see e g serinaldi kilsby 2016 and references therein even when the d condition holds true limit distributions under dependence are not identical to those of the corresponding independent processes with the same marginal distribution albeit they share the same domain of attraction this fact implies very practical consequences indeed dealing with generally short hydro climatic variables one year blocks do not always ensure fulfilling asymptotic conditions and bm can still be influenced by underlying dependence as they are not necessarily the most true extreme values e g eichner et al 2011 bogachev and bunde 2012 volpi et al 2015 serinaldi and kilsby 2016 on the other hand intra cluster serial correlation emerges when using moderate thresholds to increase the sample size of ot exceedances and reduce estimation uncertainty of extreme value distribution parameters the problem of dealing with pre sub asymptotic conditions and possible effect of serial correlation has been studied in evt introducing for instance the concepts of extremal index leadbetter et al 1983 or sub asymptotic extremal index ledford and tawn 2003 which rescale classical limit distributions fitted on sub asymptotic values in order to obtain the actual asymptotic distribution of the extreme values of the process under study see also ancona navarrete and tawn 2000 beirlant et al 2006 fawcett and walshaw 2007 2008 2016 and references therein 1 2 non asymptotic approaches to the distributions of bm in finite size samples conceptually the non asymptotic distributions of bm precede the limit distributions provided by evt as the latter are the asymptotic version of the former however evt is much more widespread than the theory concerning finite sample bm as i evt is fairly general ii it does not require to know the distribution function of the parent process too precisely leadbetter et al 1983 p 4 iii it is more advanced as discussed above and iv it is relatively easy to apply at least in several every day practical applications among the non asymptotic methods in this study we focus on the so called complete time series analysis cta volpi et al 2019 and a framework denoted as metastatistical extreme value mev marani and ignaccolo 2015 cta consists of estimating the probability of extreme values by using the distribution of the entire data set including all the available records the same approach was previously applied by papalexiou and koutsoyiannis 2013 and papalexiou et al 2018 without any re labeling earlier marani and ignaccolo 2015 introduced a framework denoted as metastatistical extreme value mev which is a compound version of the standard distribution of bm in finite size blocks resulting from the theory of order statistics for independent random variables marra et al 2019 proposed a simplified version of mev smev accounting for intra annual parameter s variations but removing inter annual fluctuations both mev and smev are valid under independence and have been applied to rainfall and stream flow data fulfilling this assumption after pre processing the data by declustering if required e g hosseini et al 2019 marra et al 2018 miniussi et al 2020 as better explained below mev is strictly related to the todorovic framework tf todorovic 1970 the general tf todorovic 1970 eqs 3 3 and 3 4 involves the high dimensional multivariate joint distribution of the parent process in finite size blocks to account for serial dependence to deal with tractable joint distributions lombardo et al 2019 specialized tf for markovian dependence structures and negative binomial block sizes this choice allows the derivation of a closed form distribution of maxima as first order markov processes are fully characterized by a low dimensional bivariate joint distribution as better discussed in the following sections all these methods attempt to account for the effects of serial correlation and lack of distributional homogeneity to some extent 1 3 aim and structure of this study denoting the marginal distribution of the variable z describing a parent process of interest e g rainfall or stream flow as fz and the block size as m most of the literature assumes the standard distribution of bm f z m for independent and identically distributed i id random variables as starting point in more detail classical evt deals with the asymptotic version of f z m while standard non asymptotic methods deal directly with it or its compound versions e g mev however to the best of our knowledge a general version of the distribution of bm for serially correlated identically distributed sc id random variables has not been considered in the literature in this study we suggest a possible version of the univariate distribution of order statistics under sc id f r and discuss its key role in three conceptual applications of practical interest in more detail 1 we review cta providing the theoretical explanation of the relationship and differences between cta and bm distributions 2 we disclose the different probabilistic scenarios described by cta and bm distributions and how bm distributions can be handled to approximate the desired portion of upper tail of the parent distribution with desired accuracy 3 we review mev and smev and therefore indirectly tf we show how f r allows for the interpretation and generalization of mev and smev frameworks overcoming the problem of estimating the multidimensional distribution of the parent process and enabling the non asymptotic analysis and modeling of bm of processes with stationary serial correlation structure this paper is organized as follows section 2 introduces the distribution of order statistics f r and block maxima fy under temporal dependence we show that such distributions can be conveniently parametrized in terms of parent distribution fz and the average of the autocorrelation matrix of the parent process thus avoiding the use of high dimensional joint distributions in section 3 we use the distributions of order statistics under i id and sc id to interpret the theoretical differences between fy and fz section 4 discusses theoretical rules for choosing the number of the largest maxima lm e g leadbetter et al 1983 ch 5 and ot exceedances such that fy can approximate a given portion of the upper tail of fz with desired accuracy in section 5 we use f r to interpret and generalize mev and smev while section 6 presents some proofs of concept based on real world stream flow data section 7 summarizes the main findings of this study 2 order matters the distribution of order statistics and block maxima under temporal dependence 2 1 overview of standard results for the i id case to introduce the distribution of order statistics for a correlated process we firstly recall some basic results for the case of independent and identically distributed i id random variables when a sequence of m random variables z 1 z m with the same cumulative distribution function cdf fz z is sorted in ascending order of magnitude and then written as z 1 z m we call z r or z r m the rth order statistic r 1 m with distribution function f r z depending on fz z david and nagaraja 2004 p 1 recalling the derivation of the expression of f r z in terms of fz z helps understand its extension to the case of serially correlated identically distributed sc id random variables for given z we can define a binary process x such that 1 x i i z z i 1 if z i z 0 otherwise where i is the indicator function it follows that the random variable s i 1 m x i represents the number of variables zi exceeding z therefore the expression of f r z can be derived from the equivalence of the two events z r z and s m r in fact if the rth order statistic is less than or equal to z then the number of zi exceeding z is surely smaller than or equal to m r i e p z r z p s m r and vice versa mood et al 1974 pp 251 252 since s has a binomial distribution with parameters m number of trials and fz z rate of occurrence under i id assumption for z it follows that 2 f r z p z r z i 0 m r p s i i 0 m r m i f z m i z 1 f z z i f b m r m 1 f z z f β f z z r m r 1 the last form in eq 2 results from the relation between binomial sums and the regularized incomplete beta function gibbons and chakraborti 2003 pp 40 42 3 f β w α β 1 b α β 0 w t α 1 1 t β 1 d t where b α β is the complete beta function see also arnold et al 1992 pp 12 13 the cdfs in eq 2 provide the marginal distributions useful in many applications such as the definition of confidence intervals of quantiles e g hutson 1999 serinaldi 2009a and the study of the maximum y z m and the minimum z 1 of a random sample z 1 z m e g kottegoda and rosso 2008 pp 406 409 in particular the cdf of block maxima bm y in random samples of finite size m is 4 f y z f m z i 0 m m m i f z m i z 1 f z z i f z m z f b 0 m 1 f z z f β f z z m 1 2 2 order statistics under sc id conditions results in section 2 1 rely on the duality between the parent process zi and the corresponding counting process s describing the number of exceedances of a given threshold z focusing on the process s f r can be represented by a binomial distribution f b which is only valid in the i id case the extension to sc id case requires a distribution equivalent to f b enabling the description of the sum s of a correlated binary process xi corresponding to a correlated parent process zi even though the general distribution of s under sc id is unknown its mean and variance are known as discussed later therefore we propose to approximate distribution of s with a so called beta binomial distribution which allows for an explicit parametrization in terms of fz and autocorrelation function acf of the process z and includes f b as a special case under i id some preliminary remarks help better understand the rationale of using the beta binomial model in the present context in principle the derivation of the exact distribution of s under sc id should rely on the joint distribution of correlated binary process xi which provides a complete description of the process itself such a distribution is multinomial and can be specified using a representation first suggested by bahadur 1961 in the bahadur representation the joint probability of m correlated binary variables is uniquely determined by m marginal probabilities pi i 1 m and the i 2 m m i 2 m m 1 correlation coefficients of all orders i e second and higher see also kupper and haseman 1978 lipsitz et al 1995 zaigraev and kaniovski 2013 the bahadur representation allows for defining the joint probability distribution of any vector of correlated binary variables at the price of using a large number of parameters to overcome this difficulty bahadur proposed truncating the distribution to second order correlations also known as correlated binomial cb model kupper and haseman 1978 paul 1985 this is equivalent to assuming that all higher order correlations are negligible zaigraev and kaniovski 2013 however this approximation i does not guarantee that the probability mass function is always positive even if it always sums up to one and ii it yields a valid distribution only for a range of second order correlation values whose limits become closer to zero as m increases see e g kupper and haseman 1978 paul 1985 proposed a generalized version of the cb model called beta correlated binomial βcb distribution this generalization relies on the concept of compound distributions allowing the rate of occurrence p of the cb model to vary according to a beta distribution however similarly to cb the βcb model is still valid for a limited range of correlation values whose bounds tend to zero as m increases thus making the model not suitable for practical applications with e g m 365 annual blocks of daily data based on the foregoing remarks the complete joint distribution might not be a practical option because of the curse of dimensionality and high parametrization on the other hand extensions of the classical binomial model accounting for modulation of second order moments appear a more viable option in this respect the concept of compound distributions can help find an approximate distribution that is suitable for our purposes since hydro climatic processes are generally positively correlated the required binomial extension should also be valid for at least the range of correlation values 0 1 a widely used model fulfilling these requirements is the beta binomial f β b distribution this distribution has a long history skellam 1948 it can arise in a number of ways moran 1968 hisakado et al 2006 and is also known as the pólya or negative hypergeometric distribution griffiths 1973 and has been applied in several fields for various purposes nicola and goyal 1990 hughes and madden 1993 ahn and chen 1995 tsai et al 2003 serinaldi et al 2018 even though it has received little attention in hydro climatology despite its very attractive properties see e g serinaldi and kilsby 2018 referring to the references above for further details we introduce the rationale and main properties of f β b useful for the present discussion f β b is a popular model especially in toxicological or infection studies where the effects of a chemical agent or disease are often recorded as the number of the affected individuals within an experimental unit e g a litter or a household a common characteristic of this type of data is the so called litter effect i e the tendency for individuals from the same unit to respond more alike than individuals from different units such greater alikeness which is denoted as intra unit or intra cluster correlation may arise for instance from unmeasurable litter effects or from covariates common to the experimental unit that are omitted or are inaccurately measured such as genetic factors and or differences in surrounding environment haseman and kupper 1979 prentice 1986 the resulting count data usually exhibit over dispersion compared to binomial or poisson samples due to aforementioned intra cluster correlation i e litter effects in this context litter effects are often accounted for by using mixture distributions supposing that the binary variates within an experimental unit are independent estimators of a latent response rate p in other words under this type of models the intra cluster or intra litter responses are conditionally independent but are unconditionally dependent haseman and kupper 1979 intra cluster correlation enters upon allowing p to vary according to some distribution thus mimicking litter effects on p prentice 1986 we stress that the mixture distributions of counting processes which are fully known do not coincide with the actual unknown distribution of s under sc id but the former can approximate the latter preserving some properties such as mean and variance within the class of discrete mixture distributions f β b is a convenient compound distribution that arises by assuming the rate of occurrence p of an ordinary binomial distribution to be a random variable following a beta distribution fβ eq 3 recalling the duality between the events z r z and s m r such that p z r z p s m r for a correlated stationary process zi the cdf of z r corresponding to eq 2 can be approximated by f β b skellam 1948 5 f r z p s m r i 0 m r 0 1 f b i w f β w α z β z d w i 0 m r m i b i α z m i β z b α z β z where 6 α z 1 ρ β b z ρ β b z 1 f z z β z 1 ρ β b z ρ β b z f z z and f z z 1 α z α z β z and ρ β b z is known as the intra class or intra cluster correlation see appendix a 7 ρ β b z 1 α z β z 1 j l ρ l j z m m 1 where ρ l j z corr x j z x l z denotes the pairwise correlation of two randomly chosen trials separated by a time lag l j the indices j and l refer to two different time steps in a temporal process evolving in m time steps the mean and variance of f β b are given by the formulas ahn and chen 1995 8 μ β b e z m 1 f z z and 9 σ β b 2 var z m f z z 1 f z z 1 m 1 ρ β b recalling that μ b m 1 f z z and σ b 2 m f z z 1 f z z eqs 8 and 9 indicate that f β b and f b have the same mean while f β b allows for further modulation of the variance precisely as σ β b 2 0 by definition it follows that ρ β b 1 m 1 1 thus confirming the capability of f β b to cover the entire range of positive correlation values as well as a subset of negative values which however becomes very small for block sizes of our interest e g m 365 we stress that the terms ρ l j refer to the binary process xi resulting from the dichotomization procedure in eq 1 which in turn depends on z as well even though this dichotomization does not preserve linear correlation the terms of the autocorrelation function acf of the process xi are related to those of the parent process zi with arbitrary marginal distribution fz bivariate joint distribution g 2 and bivariate copula c 2 by emrich and piedmonte 1991 ahn and chen 1995 10 ρ l j p x j 1 x l 1 p 2 p 1 p p z j z z l z p 2 p 1 p 1 2 f z z g 2 z z ξ p 2 p 1 p 1 2 1 p c 2 1 p 1 p ξ p 2 p 1 p where p 1 f z z and ξ is a generic parameter quantifying the overall degree of dependence between the pairs zj zl as a particular case a meta gaussian dependence structure copula is a common assumption in time series analysis and modeling papalexiou 2018 papalexiou and serinaldi 2020 as popular time series models such as autogressive ar models and their extension or mandelbrot s fractional gaussian noise fgn rely on this assumption in these cases ρ l j can be computed from the correlation values of an auxiliary standard gaussian process wi which is related to the parent process zi through the normal quantile transformation nqt w i φ 1 f z z i where φ denotes the standard gaussian cdf since ranking and percentage based dichotomization are invariant to monotonic transformations such as nqt gibbons and chakraborti 2003 p 189 eq 1 yields the same xi process when it is applied to zi with threshold equal to z or to wi with threshold w φ 1 f z z working with the process wi corresponding to zi and using the symmetry of the gaussian distributions allow the easy calculation of the correlation coefficients ρ l j from those of the gaussian process by the relationship emrich and piedmonte 1991 serinaldi and lombardo 2017a 11 ρ l j φ 2 φ 1 p φ 1 p corr w j w l p 2 p 1 p where φ2 denotes the bivariate gaussian cdf of wj wl obviously eq 11 is a special case of eq 10 emphasizing the dependence of ρ β b on fz z and the acf of the process zi or wi denoted as ρ the distribution of bm in finite size blocks under sc id can be described by eq 5 in the form 12 f y z f m z b α z m β z b α z β z f β b 0 m 1 f z z ρ β b f z z ρ which yields eq 4 as a particular case for ρ β b 0 we validate the capability of f β b of reproducing the distribution of the bm y in blocks of size m 365 mimicking annual maxima of daily time series for four stationary processes fractional gaussian noise fgn which is also known as hurst kolmogorov process and has gaussian dependence structure first order autoregressive ar 1 process with gaussian dependence structure ar 1 process with bivariate clayton dependence structure linking consecutive values and standard gaussian marginal distributions clayton ar 1 see appendix b ar 1 process with bivariate gumbel dependence structure linking consecutive values and standard gaussian marginal distributions gumbel ar 1 see appendix b the autocorrelation functions acfs of the fgn and ar 1 processes are reported in appendix b along with the expressions of the clayton and gumbel copulas in all cases we assume standard gaussian marginal distributions to better assess the impact of dependence structure and tail dependence in fact the gaussian and clayton copulas are upper tail independent while the gumbel copula which is an extreme value copula exhibits upper tail dependence e g salvadori et al 2007 pp 236 238 and 254 255 for the processes with multivariate gaussian distribution e g fgn and ar 1 under sc id conditions the exact distribution of y is no longer f z m eq 4 but the 365 dimensional joint gaussian distribution φ365 z of z 1 z 365 with correlation matrix σ i e 13 f y z p z 1 z z 2 z z 365 z φ 365 z σ on the other hand to the best of our knowledge explicit expressions for the acf and 365 dimensional joint distribution describing all mutual lagged correlations of clayton ar 1 and gumbel ar 1 processes are not readily available to better visualize the behavior of the upper tail of fy fig 1 compares the survival functions 1 f y obtained from eq 5 and the empirical counterpart 1 f n y 1 n 1 i y i y corresponding to 1000 annual maxima extracted from time series of size 365 1000 along with the survival function derived from eq 13 for fgn and ar 1 we considered fgn processes with parameter values h 0 6 0 7 0 8 0 9 ar 1 with ρ 1 0 2 0 5 0 8 0 95 and clayton ar 1 and gumbel ar 1 processes with parameters ξ corresponding to lag 1 kendall correlation coefficient τ 1 0 2 0 5 0 8 0 9 see appendix b this set of parameters allows a validation of the f β b distribution in eq 12 for the entire range of positive correlation values as all processes have zero mean the diagrams in the figures are shifted horizontally by one unit for better visualization fig 1 a and b show that f β b provides results indistinguishable from φ365 using a simple univariate distribution instead of a high dimensional joint distribution which requires numerical integration and can be prone to accuracy problems this can explain some discrepancies emerging in the body of the distributions for the highest values of the parameters h and ρ 1 leaving aside sampling fluctuations the empirical distributions fn confirm that both methods faithfully reproduce the expected distributions on y whereby f β b has the advantage to be univariate and computationally inexpensive and free from possible inaccuracy due to numerical solution of high dimensional integrals the advantage of using f β b is even more evident when dealing with the clayton ar 1 and gumbel ar 1 processes for which the exact 365 dimensional joint distribution is not available in explicit form in these cases ρ l j is computed by eq 10 with parameter ξ τ l j see eqs b 4 and b 6 fig 1c and d show that f β b provides an accurate approximation for low to middle values of τ 1 and all values of probability of practical interest i e p y z 0 2 corresponding to return periods t 5 years while some discrepancy emerges for high values of τ 1 and gumbel copula however this is the expected effect of the upper tail dependence which yields extreme values more correlated than those of tail independent models therefore tail dependence further inflates information redundancy of bm meaning that longer time series are required to explore the state space since f β b accounts for second order properties via ρ l j see eqs 10 and 11 some loss of information concerning higher order properties is expected nonetheless results in fig 1c and d show that the lack of accuracy is limited and it is an acceptable cost considering the simplicity of the approach the greatly reduced computational cost and more importantly the unavailability of viable forms of the exact high dimensional distributions 3 facets of return period based on probabilities as a first conceptual application in this section we show how f β b plays a key role in the interpretation of different definitions of return period provided by volpi et al 2019 in the context of cta thus highlighting the theoretical relationships and differences between the distribution of bm fy and that of the parent process fz 3 1 setting the stage referring to the literature for the formal derivation of the expressions of return period t for independent non independent identically non identically distributed random processes in a univariate multivariate framework chow et al 1988 fernández and salas 1999 douglas et al 2002 cooley 2013 salas and obeysekera 2014 serinaldi 2015 volpi et al 2015 salvadori et al 2016 we only recall that t is the average inter arrival or waiting time of safety critical events e g threshold exceedances in a stationary context t is written as 14 t μ p μ p e μ 1 f where μ 0 denotes the average inter arrival time between two observations of a discrete time process of interest e g zi p p e is the probability to observe a critical unsafe event e and f indicates the distribution function quantifying the probability of the uncritical safe complementary event e in classical univariate setting t is usually estimated by analyzing the process of bm or ot values y of the parent random process z which can be for instance the daily stream flow process in this case the critical event can be defined as e y y f fy and p p y y 1 f y y being the expected value of a highly skewed variable such as the inter arrival time bunde et al 2007 bogachev and bunde 2012 serinaldi and kilsby 2016 t is generally insufficient in statistical sense to describe the distribution inter arrival time serinaldi 2015 volpi et al 2015 in the same way as the mean is not sufficient to characterize a gaussian distribution without introducing the variance this makes t prone to misinterpretation strathie et al 2017 and ill posed comparisons in the description of the rareness of an event serinaldi 2015 2016 cta uses all observations of the parent process z e g daily data when available to estimate t attempting to avoid the sub sampling effect related to the selection of a limited number of bm or ot values as mentioned in section 1 1 evt provides models for fy that approximate fz only asymptotically in the very upper tail thus implicitly admitting discrepancies out of the range of convergence on the other hand such discrepancies are accepted in front of the advantage to avoid massive data collection which is often not possible at reasonable quality level and cost denoting t z and t y the return periods resulting from cta and bm analysis respectively volpi et al 2019 observed that t z t y and concluded that this inequality is a consequence of data decimation i e loss of information due to discarding observations different from bm they showed that the serial dependence of the parent process increases the uncertainty in the estimates of extreme quantiles and also concluded that am leads to an overestimation of the return period of the parent process for small to moderate return period values converging to cta estimates for large events however talking about over under estimation is strictly correct if two or more estimators quantify the same target statistics in this respect volpi et al 2019 recognized that cta and bm are inherently different processes that give subtly different information on the same underlying continuous process specifically cta describes the marginal behaviour of the whole parent process sampled in discrete time at a given temporal resolution while am describes the statistical behavior of its extremes thus the research question is what is the true nature of the difference between t z and t y in section 3 2 we show that such a difference is related to the different probabilistic hazard scenarios described by the probabilities pz and py appearing in the expressions of t z and t y this finding has fundamental impact on the interpretation of t values resulting from bm ot or cta as it clarifies that talking about over under estimation is misleading and discrepancies are unavoidable theoretical differences resulting from different failure scenarios described by pz and py 3 2 defining return period in different probabilistic scenarios 3 2 1 the i id case to allow a direct comparison with volpi et al 2019 we assume that bm are e g annual maxima am according to eq 14 the return period of am t y can be written as 15 t y 1 p y 1 p y c 1 1 f y c 1 1 f z c m where c denotes a generic threshold value μ 1 as the average inter arrival time between two am is one year and m is the number of observations of the parent process z sampled at a constant time interval for example m 365 for daily stream flow series removing leap years on the other hand cta based t z expressed in years reads as 16 t z 1 p z 1 m p z c 1 m 1 f z c as 1 m years is the inter arrival time between two observations zi and z i 1 of the parent process z in this case μ coincides with the sampling interval expressed in years or a generic measurement unit of m size blocks such as weeks if m 7 days months if m 30 days etc for example μ 1 365 when the parent process is sampled at daily scale note that in ot analysis m is a random variable as it is the expected value of the inter arrival time between ot exceedances focusing on the denominators of the rightmost terms of eqs 15 and 16 we have 17 p y 1 f z c m 1 i 1 m f z i c 1 p z 1 c p z 2 c p z m c 1 p z 1 c z 2 c z m c 1 g m c where the symbol stands for and and denotes logical conjunction while gm is a m dimensional joint distribution the equalities in the middle of eq 17 hold only under independence as the product i 1 m f z i c implies lack of interaction among events on the other hand 18 p z m 1 f z c i 1 m 1 f z i c p z 1 c p z 2 c p z m c p z 1 c z 2 c z m c where the symbol stands for xor and denotes exclusive disjunction therefore pz describes the probability of the union of mutually exclusive events in fact the expression of pz lacks the terms describing the probabilities of possible joint events i e two or more exceedances in other words py is the probability of observing at least an exceedance i e one or more in m independent experiments while pz is the probability of exceeding a given value in each specific trial on an m step time basis without the possibility to observe additional events in the m trials as they are mutually exclusive the explicit relationship between py and pz is easy to obtain for m 2 3 and for a generic m by induction see appendix c firstly we discuss the cases m 2 3 as they allow graphical visualization geometrical interpretation and better understanding of the meaning and difference of py and pz for m 2 from eqs 17 and 18 we obtain 19 p z p y 2 1 f z 1 f z 2 1 f z 2 while for m 3 20 p z p y 3 1 f z 1 f z 3 2 1 f z 3 3 1 f z 2 f z eq 19 shows that the difference between pz and py is equal to the probability of observing exceedances in both blocks for m 3 see appendix c we have a similar term corresponding to exceedances of the threshold c in all blocks i e 2 1 f z 3 along with an additional term corresponding to the exceedances in two blocks out of three i e 3 1 f z 2 f z which are not included in the definition of pz as this refers to the probability of mutually exclusive events for m 2 3 figs 2 and 3 provide a visual representation of the terms of eqs 19 and 20 respectively eqs 19 and 20 also explain why pz and py tend to match for extreme events i e for small values of 1 f z the terms quantifying the difference between pz and py are the 2nd and 3rd powers of the exceedance probability 1 f z while pz is 1st power and py is 0 order as it does not depend on 1 f z therefore for extreme events i e for fz 1 the terms on the right side of eqs 19 and 20 tend to zero more rapidly than pz and py thus resulting in the convergence of the values of pz and py and thus t z and t y for a generic block size m we have 21 p z p y i 2 m i 1 m i 1 f z i f z m i i 2 m i 1 f b i m 1 f z where f b is the binomial probability mass function describing the probability of observing i events in m trials with rate of occurrence 1 f z corresponding to the cdf f b in eq 2 the terms of the summation in eq 21 describe the probabilities of the combinations of events i e possible multiple exceedances in m trials that distinguish the two probabilistic scenarios represented by pz and py for example i 2 gives the probability of observing exactly two exceedances in m trials or time steps as shown in eq 19 3 2 2 the sc id case under sc id conditions the meaning of py and pz does not change as the former is the probability of observing at least an exceedance in m dependent trials while pz is still the probability of the union of m mutually exclusive events zi c i 1 m the difference of py and pz is still represented by the probability of observing more than one exceedance in m time steps i e the joint probability of a count process s corresponding to the number of ot exceedances in m trials as discussed in section 2 2 a tractable form of such a joint distribution is not available while constraints on the degree of correlation affecting some of its approximations prevent the application of these approximations in the cases of general interest on the other hand f β b eq 5 generalizes f b eq 2 and provides an approximation of the required joint distribution that preserves second order properties and in particular pairwise correlations in the entire range of positive values of the average of the acf i e ρ β b 0 1 therefore f β b is a valuable modeling option for applications involving hydro climatic processes that are generally characterized by positive serial correlation and positive average of the m m correlation matrix under these assumptions a generalization of eq 21 for correlated processes results from replacing f b with f β b thus obtaining 22 p z p y i 2 m i 1 m i b i α z m i β z b α z β z i 2 m i 1 f β b i m 1 f z ρ β b f z ρ we checked the accuracy of eq 22 for an ar 1 process with ρ 1 0 9 and fgn with h 0 9 i e for challenging persistent processes eq 21 for i id was also validated for completeness fig 4 reports return periods vs return levels for easier comparison with volpi et al 2019 and it shows how t z approaches to t y by progressively subtracting each of the terms of the summations in eq 21 for i id and eq 22 for ar 1 and fgn they describe the probability of the various multiple failure exceedance scenarios in m 365 blocks which mimic the case of daily series fig 4a refers to the i id case eq 21 while fig 4b and c show the output of eq 22 for the sc id cases the t y curves corresponding to the distributions fy obtained by the joint distribution via 1 φ 365 are also shown for the sake of comparison fig 4 shows that the differences between t z and t y under i id and sc id are theoretically explained in terms of difference of failure scenarios and are an inherent property resulting from the probabilistic description of such scenarios focusing on t 1 i e on the range of t where both t z and t y are defined volpi et al 2019 noted that the discrepancies between t z and t y increase as the processes exhibit stronger persistence thus affecting higher return periods however our analysis shows that such discrepancies i e the departures of t y from t z for low middle values of t are independent of sample size which indeed does not appear in eqs 21 and 22 and their derivation therefore such differences in the low middle range of t values cannot be reduced or eliminated even if large data sets are or become available on the other hand the numerical convergence for very extreme values low pz and py justifies as expected the use of asymptotic results from classical evt however talking about over under estimation of t z vs t y especially outside the range of validity of asymptotic convergence may be theoretically ungrounded as both t z and t y correctly quantify the probability associated to the variables and failure scenarios they refer to we also note that a superficial use of the term return period often conceals the actual meaning of underlying probabilities and type of events e g univariate conditional or joint thus leading to potentially incorrect conclusions e g serinaldi 2015 in this respect the foregoing analysis could not have been possible without moving from t z and t y to pz and py this further stresses the advantages of complementing surrogate indices such as return period with their underlying probabilities for a better understanding of the failure scenarios under study as well as a more transparent communication of the actual probability of failure in hydro climatic risk assessment 4 recovering the upper tail of fz the role of the kth largest maxima based on the discussion in section 3 2 we consider a second conceptual application of f b and f β b recalling that p y 1 f y and p z m 1 f z eqs 21 and 22 describe the relationship between py and pz or similarly between t y and t z or fy and fz therefore fy can result from rescaled fz by subtracting the terms of the summation denoting the probability of the events with r exceedances in m size blocks i e f y m f z 1 m δ where δ denotes the summations in the right side of eqs 21 and 22 however eq 21 and 22 can also be used conversely to move from fy to fz by adding progressively the summation terms in this respect it should be noted that such terms depend on fz therefore in real world applications we cannot move fy to fz without additional information on the parent process z nonetheless eq 21 allows for a conceptual analysis revealing the theoretical basis of some empirically based recommendations concerning the number of lm or threshold exceedances required to make py close to pz in a given portion of the upper tail of fz corresponding for instance to small return periods i e in a region where asymptotic convergence is not yet in play in fact for r increasing from two to m the sum p y δ i e 1 f z m δ becomes closer and closer to pz i e m 1 f z for example for r 2 we add the probability corresponding to the event of observing two exceedances in m trials this means considering two lm in m trials for r 3 eq 21 and 22 yields the probability of observing up to three exceedances in m trials thus meaning that three lm are accounted for in other words as expected adding more and more lm allows the better approximation of the upper tail of fz therefore in principle for a fixed value t it is possible to select a minimum number k of lm required to approximate the desired portion of the upper tail of fz with specified accuracy i e yielding p z p y ε for values of p z 1 t and arbitrarily small ε or similarly t z t y ε for values of t z t and arbitrarily small ε this concept is illustrated considering three processes i id ar 1 with ρ 1 0 9 and fgn with h 0 9 m 365 sample size 1000 m and fz 364 365 363 365 corresponding to t 1 0 5 years for example let us focus on return level plots in fig 5 a and assume t 1 year as a reference value fig 5a shows that there is a discrepancy between the curves t z and t y for t 1 year in order to fill this gap let us add the first summation term in eq 21 up to py the resulting t curve labeled as k 2 in fig 5a is closer to the t z curve for t 1 as it corresponds to the return level curve of two lm for k 3 i e considering the distribution of three lm the resulting t curve labeled as k 3 in fig 5a matches the t z curve for t 1 year i e above the point in fig 5a therefore for the gaussian i id process we should consider at least three lm to obtain an accurate reproduction of the upper tail of the parent distribution for fz 364 365 or likewise t z 1 year fig 5 a also shows the empirical cdfs fn of k lm and ot exceedances selected from the simulated series of course samples of ot exceedances are not identical to k lm samples however their distributions are very similar in the upper tail of interest for t z 1 year where they are required to match fz or t z by the way it is not surprising that k 3 corresponds to the rate of ot values commonly suggested in the literature to perform extreme value analysis according empirical arguments and or statistical tests e g lang et al 1999 durocher et al 2018 for t 0 5 years fig 5b shows that we need at least k 5 lm or ot values to accurately retrieve the desired portion of the upper tail of fz i e fz 363 365 or t z 0 5 years under sc id conditions ar 1 and fgn processes serial dependence introduces information redundancy meaning that we need more observations to approximate the fz or t z curve in the range of interest for example comparing fig 5a c and e and fig 5b d and f where each grey curve denotes an additional term of the summations in eqs 21 and 22 we can see that more terms are needed under sc id to approximate the t z curve for t z 1 year and t z 0 5 years in more detail for the ar 1 process with ρ 1 0 9 we need k 12 15 lm for t 1 0 5 years respectively for the fgn process with h 0 9 we need k 30 40 lm for t 1 0 5 years respectively bearing in mind that lm and ot exceedances rely on different selection methods the foregoing analysis provides a criterion to evaluate the number of lm or ot exceedances required to reproduce a desired portion of the upper tail of the parent distribution when the focus is on moderate values of exceedance probability in particular the effect of serial correlation can strongly increase such a number as discussed in section 1 1 these effects have been widely studied in evt however our analysis provides a different finite size perspective that enables a suitable visualization and practical guidelines we stress again that the above analysis requires the knowledge of the parent process this can appear contradictory as one of the main advantages of using bm or lm or ot exceedances and evt is to avoid a detailed knowledge of the parent process however as discussed above assumptions on the parent process are required in evt as well for example if the parent process is assumed to be long range persistent the convergence to the evt asymptotic distributions is no longer guaranteed therefore the aim of the above analysis is to provide a procedure to assess the degree of accuracy of bm or lm distributions in reproducing a given portion of the upper tail of the parent distribution under different assumptions in other words while single bm can be sufficient to faithfully represent fz for e g t z 2 years under parent i id processes they might be not enough if the underlying process is persistent in the latter case discrepancies like those shown in fig 5 cannot be reduced by increasing the sample size but only increasing the number of lm or lowering the threshold thus including more information from the intermediate order statistics 5 f β b c compound f β b distributions explaining and generalizing mev under serial dependence 5 1 mev and its relationship with todorovic distributions a matter of compound distributions marani and ignaccolo 2015 proposed the so called metastatistical extreme value mev framework to model the distribution of block maxima y exploiting the distribution of the parent process z in finite size blocks in more detail denoting the parameter s of the parent distribution fz as θ the mev approach considers θ θ and the number of observations l l in blocks of finite size m as random variables with joint probability density function g l θ focusing on annual maxima this assumption accounts for the inter annual fluctuations e g koutsoyiannis 2004 note that a fluctuating number of observations in blocks with fixed size e g m 365 days refers to particular processes such as non zero daily rainfall or over threshold discharge records where the number of observations can change in every m size block under independence the mev cdf is therefore the unconditional probability distribution function of y resulting from marginalizing the distribution of y conditional on l l and θ θ i e p y z l l θ θ f y z l θ f z l z θ over g l θ 23 f y z l 0 ω θ f z l z θ g l θ d θ e f z l z θ e f b 0 l 1 f z z θ e f β f z z θ l 1 where ω θ is the state space of parameters θ and the latter equalities result from the identities f z l z θ f b 0 l 1 f z z θ f β f z z θ l 1 in eq 4 the mev cdf belongs to the well known class of compound distributions e g dubey 1970 van montfort and van putten 2002 that are in turn special cases of doubly stochastic processes i e processes in which both the parent random variables zi and parameters are stochastic processes e g tjøstheim 1986 thayakaran and ramesh 2017 compound distributions appeared in the literature under various names and contexts for example they have been re named as superstatistics in physics and hydrology beck 2001 de michele and avanzi 2018 porporato et al 2006 or as predictive distributions in bayesian inference renard et al 2013 the rationale of integrating over the parameter space was also applied without introducing any specific re labeling allamano et al 2011 botto et al 2014 in particular eq 23 highlights that mev is a compound f b or equivalently a compound fβ i e the expectation of the standard distributions of maxima for finite size blocks under independence unlike the bayesian context where g l θ is usually the empirical posterior distribution resulting from simulations via monte carlo markov chain mcmc algorithms in the mev approach g l θ is the sample distribution of the values of lj and θ j j 1 n y estimated in ny blocks of one year e g 365 days or 365 24 h therefore the theoretical mean can be approximated by the sample mean yielding 24 f y z e f z l z θ 1 n y j 1 n y f z l j z θ j 1 n y j 1 n y f b 0 l j 1 f z z θ j 1 n y j 1 n y f β f z z θ j l j 1 as mentioned in section 1 mev is strictly related to todorovic framework tf todorovic 1970 which reads as follows 25 f y z l 0 p i 0 l z i z l l l 0 p z 1 z z 2 z z l z l l p l l l 0 g l z θ g l e g l z θ where gl is the l dimensional joint distribution of z under independence g l f z l and tf corresponds to a simplified mev version with constant parameters θ i e standard f b under independence or the same mev is a version of tf with fluctuating parameters θ under independence on the other hand replacing f z l with a more general gl in eq 23 mev can be seen as a version of tf with fluctuating parameters θ under dependence or the same the expectation of tf in other words both tf and mev are compound distributions tf is the compound version of a general l dimensional joint distribution gl which is valid under dependence and includes f z l as special case and accounts for inter block fluctuations of l but not of θ mev is the compound version of f z l z θ f b 0 l 1 f z z θ which is valid only under independence and accounts for inter block fluctuations of l and θ a more general distribution of bm should combine the properties of tf and mev thus reading as the compound distribution of gl accounting for inter block fluctuations of l and θ this distribution is valid under independence and dependence like tf but accounts for inter block fluctuations of all parameters like mev it can be considered an extension of tf or mev by introducing very minor changes in these models although one can be tempted to call this distribution as extended tf or extended mev we think that it should be simply denoted as compound distribution of bm to highlight its meaning and rationale and avoid possible misunderstandings as well as the proliferation of uninformative names and acronyms denoting the same thing balazs et al 2007 nonetheless such a compound distribution involves an l dimensional multivariate distribution gl that makes its use rather unpractical especially when dealing with hydro climatic variables characterized by complex joint distributions with l 365 for example however as shown in section 5 2 using the generalized fy in eq 12 overcomes the problem by replacing the l dimensional gl with a one dimensional distribution this approach greatly simplifies the calculations avoiding to solve high dimensional integrals the cost is some loss of information as fy in eq 12 preserves only the serial correlation function i e second order joint moments thus missing higher dimensional correlation properties 5 2 introducing compound distributions f β b c for bm of correlated processes according to the parametrization in eq 23 under independence mev is a compound f b therefore a generalization is straightforward and consists in replacing f z l i e f b in eq 4 by f β b eq 12 under the assumptions discussed in section 2 2 and then integrating over the parameter space 26 f y z f β b c z l 0 ω ρ ω θ f β b 0 l 1 f z z θ ρ β b f z z θ ρ g l ρ θ d ρ d θ e f β b 0 l 1 f z z θ ρ β b f z z θ ρ 1 n y j 1 n y f β b 0 l j 1 f z z θ j ρ β b f z z θ j ρ j where ρ is correlation matrix of the parent process zi or wi introduced in section 2 2 of course eq 26 can be simplified assuming for instance that some parameter is constant for example we can assume that ρ does not change from year to year thus resulting in the expression 27 f β b c z l 0 ω θ f β b 0 l 1 f z z θ ρ β b f z z θ ρ g l θ d θ 1 n y j 1 n y f β b 0 l j 1 f z z θ j ρ β b f z z θ j ρ we numerically validated f β b c for a set of processes with lognormal marginals and ar 1 correlation structure we used lognormal marginals with location parameter μ ln 0 5 and scale parameter σ ln 0 2 1 2 4 corresponding to different distribution shapes i e weakly skewed bell shaped moderately skewed bell shaped and strongly skewed j shaped respectively fig s1 we considered three values of the ar 1 parameter ρ 1 0 3 0 6 0 9 and three different percentages of zeros p 0 0 0 0 3 0 7 to mimic zero inflated processes such as daily rainfall or stream flows of non perennial rivers this setting yields 27 different combinations that cover a wide range of distribution shapes degree of serial correlation and degree of zero inflation intermittency of practical interest lognormal ar 1 sequences have been simulated using the method described by papalexiou 2018 while zero inflation was obtained multiplying the simulated lognormal series by binary sequences with ar 1 correlation structure and ρ 1 0 5 serinaldi and lombardo 2017a 2017b thus introducing the required percentage of zeros in each m size block for the cases p 0 0 in order to generate series from processes with proper inter block fluctuations of the parameters we used a two stage procedure for each of the foregoing 27 combinations at the first stage we generated an auxiliary synthetic series of size 1000 365 mimicking 1000 years of daily records then we selected the 1000 blocks of size 365 and estimated all parameters of the parent lognormal process for each block this procedure yields 1000 values for each parameter of the parent lognormal process i e μ ln 1 μ ln 1000 σ ln 1 σ ln 1000 etc that describe their sampling distribution when the estimation is performed on 365 size blocks at the second stage we generated reference time series to be used in bm analysis by simulating lognormal processes with parameters changing every 365 size block in other words we used a set of parameters μ ln i σ ln i to generate a first sequence of 365 values another set μ ln j σ ln j for the subsequent 365 values and so on up to 1000 365 the resulting reference series follow processes with parameters fluctuating over 365 size blocks according to their sampling distributions results of the nine combinations of parameters corresponding to σ ln 1 2 moderate skewness are reported in fig 6 by quantile quantile q q plots comparing f β b c quantiles mev quantiles and simulated values according to the definitions in eqs 24 and 26 f β b c and mev are obtained as the averages of the bm distributions estimated over the 1000 365 size blocks of the simulated series results for σ ln 0 2 4 i e weakly and strongly skewed parent distributions are reported in figs s2 and s3 q q plots are shown both in log log scale to emphasize the behavior in the body of the distributions and in linear scale inset panels to emphasize the actual magnitude of differences for weak correlation fig 6a c show that f β b c and mev match as expected while fig 6d and g illustrate the increasing discrepancies between f β b c and mev as the degree of correlation increases for fixed correlation values zero inflation reduces the differences between f β b c and mev see fig 6d f and g i in this respect we note that the block size in fig 6a d and g i e the left column of panels is 365 while the average number of non zero observations for each block is l 365 0 7 255 5 in the middle column of panels i e fig 6b e and h and l 365 0 3 105 5 in the right column i e fig 6c f and i as l decreases the acf terms contributing to ρ are less and less and the simulated samples appear less and less correlated as the number of occurrences l is not enough to reveal the actual intensity and nature of the autocorrelation structure of the generating process therefore ceteris paribus the difference between compound bm distributions under independence mev and serial dependence f β b c decreases as l decreases actually this dichotomy is artificial as mev is a special case of f β b c when ρ 0 similar interpretation applies for weakly and strongly skewed distributions in figs s2 and s3 the distribution shape interacts with the effect of serial correlation the more less the skewness the more less compound distributions of bm under independence depart from those under serial dependence we stress that the foregoing analysis aims to reveal general theoretical behaviors and properties in a variety of cases i e distribution shapes degree of correlation and percentage of zeros comprising a broad range of real situations however in real world analysis the actual effectiveness advantage of using a more general model depends on several factors such as data availability data quality and accuracy required according to the aim of the study project in this respect the advantage of accounting for serial dependence should be evaluated case by case as obvious and f β b c is devised as a tool enabling this evaluation 5 3 reviewing simplified mev still a matter of compound distributions marra et al 2019 relaxed the assumption of identical distribution within each year or block thus assuming that the observations can correspond to different processes some examples are rainfall storms corresponding to frontal and convective meteorological systems or floods resulting from snowmelt and heavy rainfall following marra et al 2019 let us consider s types of processes z i with distributions f z i i 1 s with parameters θ i j at the jth year if the ith type of process is sampled l i j times during the jth year so that l j i 1 s l i j the mev cdf can be written as 28 f y z l 1 0 l s 0 ω θ 1 ω θ s i 1 s f z i l i z θ i g l 1 l s θ 1 θ s d θ 1 d θ s e i 1 s f z i l i z θ i 1 n y j 1 n y i 1 s f z i l i j z θ i j neglecting the inter annual variability of the parameters of f z i and the number of annual occurrences li marra et al 2019 proposed a simplified version of mev denoted as smev that reads as follows 29 f y z i 1 s f z i l i z θ i in order to introduce temporal correlation eqs 28 and 29 need to be rewritten in a suitable form highlighting the true nature of smev representation when a target process z e g rainfall results from the superposition of s processes z i by total probability theorem its distribution at jth year is a mixed distribution of the form 30 f z z π i j θ i j i 1 s π i j f z i z θ i j where π i j are weighting factors such that i 1 s π i j 1 the π i j factors can be estimated by the relative frequencies of occurrence of each process z i in a block of observations i e π i j l i j l j from eq 30 and recalling that f z l f b 0 l 1 f z z f β f z z l 1 see eq 4 eqs 28 and 29 become 31 f y z l 1 0 l s 0 ω θ 1 ω θ s f z l z π i θ i g l 1 l s θ 1 θ s d θ 1 d θ s e f z l z π i θ i 1 n y j 1 n y f z l j z π i j θ i j 1 n y j 1 n y f b 0 l j 1 i 1 s l i j l j f z i z θ i j 1 n y j 1 n y f β i 1 s l i j l j f z i z θ i j l j 1 and 32 f y z f z l z π i θ i f b 0 l 1 i 1 s l i l f z i z θ i f β i 1 s l i l f z i z θ i l 1 when the components f z i belong to the same family the mixed distribution in eq 30 is itself a form of compound distribution resulting from the weighted average of the distributions f z i defined over s classes of parameters with probability π i j l i j l j comparing eq 29 smev to eq 32 we have 33 smev i 1 s f z i l i z θ i i 1 s l i l f z i z θ i l f b 0 l 1 f z z π i θ i meaning that smev is nothing but the standard distribution of maxima in l size blocks under i id for a process with intra block mixed distribution therefore re naming the distributions in eqs 29 and 32 as smev might be inappropriate as they are standard f b distributions of order stastistics which are valid under i id for whatever parent distribution fz discrete continuous discrete continuous mixed etc moreover smev does not involve any compounding procedure to handle inter block variability which is the element characterizing mev we also note that the weighted average in eq 30 becomes an integral when the intra annual intra block variability is described by a continuous function e g a sinusoidal function as in allamano et al 2011 in other words highlighting that the distributions of order statistics are f b or fβ eqs 31 and 32 clarify the role of the parent distribution fz thus showing that it can incorporate whatever discrete or continuous intra annual pattern corresponding for instance to the alternation of s driving processes or smoothly varying seasonal fluctuations based on the type of support discrete or continuous the average intra annual distribution results from simple weighted averages or integration in other words the description of both intra block and inter block variability relies on the same rationale which is formalized by compound mixed distributions resulting from integration or simple weighted averaging eqs 31 and 32 allow a generalization for the case of serial dependence indeed recalling the discussion in section 2 2 and replacing f b with f β b a version of eq 28 under serial dependence is exactly eq 26 with intra block parent distribution given by the mixture f z j in eq 30 that is 34 f y z 1 n y j 1 n y f β b 0 l j 1 f z z π i j θ i j ρ β b f z z π i j θ i j ρ j while smev in eq 29 takes the form 35 f y z f β b 0 l 1 f z z π i θ i ρ β b f z z π i θ i ρ we do not assign any specific name label to the distribution in eq 35 in fact analogous to the identity smev f b under independence eq 35 is simply the f β b distribution of finite size bm under serial dependence for a process with intra block mixed distribution and is valid irrespective of the nature mixed or not of the parent distribution as for mev in section 5 2 f β b is numerically validated by simulating from known processes as proof of concept we used a mixture of two weibull distributions with cdf f wei z 1 exp z λ i κ i i 1 2 and parameters λ 1 11 7 κ 1 0 90 λ 2 4 11 κ 1 0 70 and fixed number of observations per block l 1 30 5 and l 2 17 9 these distributions were used by marra et al 2019 in their smev analysis and describe the typical observed conditions of daily rainfall corresponding to the two main intra annual synoptic weather systems driving precipitation over israel therefore the resulting mixed distribution describes the probability of a mixture of two intra annual processes z 1 and z 2 we considered the independent case to check the capability of f β b to reproduce correctly its special form f b smev along with a case involving ar 1 process with mixed weibull marginal distribution and gaussian copula with ρ 1 0 9 we stress that such a numerical example serves as an illustration of the correctness of the foregoing equations in presence of possible correlation keeping the other settings unchanged and it is not related to the data analysis discussed by marra et al 2019 analytical results for f b smev and f β b are compared with the numerical results obtained by monte carlo simulations in particular fig 7 compares analytical survival functions and the average of the empirical survival functions computed on 200 synthetic series of 1000 block maxima resulting from sequences of size 1000 365 drawn from the mixed weibull parent processes fig 7 confirms that f β b correctly describes the distribution of bm of a mixed distribution under serial dependence ρ 0 and independence ρ 0 in the latter case f β b becomes f b smev 6 proofs of concept on real world stream flow data 6 1 data for illustrative purposes we analyzed four daily stream flow time series listed in table 1 these flow records are extracted from the hydro climatic data network hcdn 2009 lins 2012 which is composed of 743 gauge stations maintained by the u s geological survey usgs hcdn 2009 includes quality controlled time series from stations that were screened to exclude sites where human or other activities affect the natural flow and with length sufficiently long for analysis of patterns in stream flow over time hcdn 2009 is specifically drawn to provide a stream flow data set suitable for analyzing hydrologic variations and trends in a climatic context lins 2012 a complete list of hcdn 2009 stations along with basic attributes can be found at the web site http water usgs gov osw hcdn 2009 while the data set is freely available at http waterdata usgs gov nwis sw 6 2 selecting the number of stream flow lm to approximate f z with specified accuracy the concepts presented in sections 3 and 4 are applied to study the daily stream flow records of the piscataquis river table 1 which is the longest time series in the hcdn 2009 database with 112 years of records with no missing values similar to volpi et al 2019 we only used the empirical cdfs data are transformed to normality by nqt i e φ 1 f n z the acf is estimated on transformed data after removing the seasonal components of mean and standard deviation to eliminate the inflating effect of the seasonal fluctuations of the marginal distribution on the acf see serinaldi and kilsby 2016 for further details this procedure does not remove intrinsic seasonal patterns of the acf not related to the fluctuation of the marginal distributions therefore empirical acf and fn z are used to estimate ρ β b and the distribution of am is computed by eq 12 based on the same reasoning used in section 4 the terms of the summation in eq 22 are then progressively added to fy in order to better approximate the portion of the upper tail of fz corresponding to t z greater than one and 0 5 years fig 8 reports the results in terms of return level plots i e t values versus discharges similar to fig 5 fig 8 shows that the theoretical t curve or cdf of am well reproduces the empirical t curve or cdf some bias is expected because the observed am are unavoidably identical to the upper quantiles of the empirical cdf of the parent z while the theoretical fy approaches to fz only asymptotically by the way uncertainty related to relatively small sample size should also be considered the t curve of am i e lm with k 1 departs from that of the parent process y for t 1 year while it cannot represent sub annual t values such as 0 5 years however increasing the number of lm for each block the t curves of lm i e gray curves approach to that of the parent process i e the target point in fig 8 the figure shows that k 7 and 10 lm or ot exceedances per year are needed to guarantee an accurate approximation of fz for t z 1 and 0 5 years respectively choosing smaller values for the number of ot exceedances is possible as the ot distribution follows the shape of fz in its entire range over the threshold corresponding to an average of k exceedances per block on the other hand if we use smaller k values the shape of the distribution of k lm introduces a departure from fz starting above the target t i e the point in fig 8 therefore the k lm value required to approximate the desired part of the upper tail of fz by the distribution of lm can be conservative if used to identify the number of ot exceedances needed to accomplish the same task in other words a slightly smaller average number of ot exceedances per year can be sufficient to approximate the desired part of the upper tail of fz however this aspect requires further investigation that goes beyond the aim of this study 6 3 analysis of stream flow annual maxima via f β b c for the sake of illustration f β b c has been tested on the stream flow records of the big creek wintering river and rio pueblo de taos table 1 these time series have been selected to fulfill some criteria firstly standard mev has been applied to data that are known to be approximately independent or weakly dependent such as rainfall at daily time scale e g zorzetto et al 2016 zorzetto and marani 2020 when independence is not a tenable assumption as for sub daily rainfall data are usually pre processed to select independent events observations e g hosseini et al 2019 marra et al 2018 miniussi et al 2020 on the other hand there is evidence that the marginal distribution of daily rainfall is well modeled by generalized gamma and burr xii distributions papalexiou and koutsoyiannis 2016 which encompass the weibull distribution as special case the latter has been widely used in rainfall modeling herr and krzysztofowicz 2005 wilson and toumi 2005 serinaldi 2009b and is the standard choice in mev superstatistical analysis applied to rainfall de michele 2019 de michele and avanzi 2018 marani and ignaccolo 2015 marra et al 2018 2019 zorzetto et al 2016 zorzetto and marani 2019 2020 dealing with stream flow serial dependence is usually stronger than that of rainfall the number of annual non zero observations is commonly constant and higher than that of non zero rainfall even in non perennial rivers and the identification of a unique general marginal distribution can be problematic because of the prominent effect of the seasonality and the complex filtering transfer and buffering processes characterizing hydrographic basins e g blum et al 2017 and references therein based on these remarks we selected three stream flow series referring to relatively small basins that are expected to fast react to rainfall impulses thus preserving some properties of the main driving process two of them big creek and wintering river are also intermittent thus showing varying number of non zero observation on an annual basis these properties make compound distributions suitable for the data at hand the aim of this analysis is to show the capability of f β b c to reproduce the empirical distribution of the am using all observations of the parent process and explicitly accounting for serial correlation without discarding any observation by e g over threshold selection and or declustering to fulfill the independence hypothesis required by standard evt methods or mev an empirical comparison of these approaches goes beyond the aim of this methodological study focusing on the big creek fig 9 a c show part of the time series from 2003 to 2013 included the average acf estimated on an annual basis and its 90 confidence intervals and the q q plot of the modeled f β b c annual maxima versus observed values and values resulting from f β b c with ρ β b 0 i e f b c or mev f β b c quantiles for a fixed probability are computed by a zero cross finding algorithm fig 9c shows that maxima in finite size blocks under serial dependence tend to be less extreme than those under independence conditions confirming the theoretical results reported in figs 6 and 7 in fact for persistent processes much more observations are required to cover their complete state space because of information redundancy and the corresponding reduced effective sample size similar remarks apply for the wintering river and rio pueblo de taos fig 9d i obviously neglecting serial dependence and applying f b c without pre processing data yield very different results as mentioned in section 5 2 the magnitude of such differences depend on the characteristics of the process at hand in the present case they results from the combination of very skewed marginal distributions and high persistence see acf in fig 9b e h and lag 1 and lag 2 acf values in table 1 these differences are consistent with those discussed in section 5 2 for theoretical lognormal ar 1 processes with similar properties 7 discussion and conclusions since extreme events are rare by definition the application of asymptotic extreme value theory evt generally relies on relatively small samples of block maxima bm or values over high thresholds ot therefore efforts have been made in the past to develop methodologies enabling the use of more information by including additional intermediate values or all available observations while it can be questioned whether intermediate values can provide direct information on extremes allowing for improvements of estimation accuracy they surely convey information about the underlying generating process and particularly on the possible presence of serial dependence which is known to affect finite size properties causing bias and variance inflation as discussed in section 1 1 the effects of serial correlation are well known and affect also clusters of extremes defined as exceedances of a given threshold therefore they have been studied rather extensively in classical asymptotic evt on the other hand non asymptotic models involving the largest and intermediate observations have generally been presented and applied under the assumption of independence although this assumption is even less tenable when dealing with the entire sequence of records especially for hydro climatic processes sampled at daily or sub daily time scales in fact when independence is not a realistic assumption the application of non asymptotic models requires the data to be pre processed by over threshold selection and or declustering similarly to evt models in this study we attempted to contribute in this respect by introducing a rather general univariate distribution of finite size order statistics under stationary serial correlation over m size blocks of observations whereby the corresponding m m correlation matrix has positive average this distribution is known in the literature as beta binomial f β b and specialized as the classical binomial f b distribution of order statistics under independence as the order statistics are the starting point of every asymptotic and non asymptotic extreme value model f β b plays a fundamental role for further developments in a variety of conceptual applications for example since bm are the largest order statistics f β b can be used to approximate the true m dimensional joint distribution required to compute the probability of bm preserving the second order joint moments i e the serial correlation function however f β b can be used in a variety of applications we discussed three of these potential applications firstly we showed how f β b can help providing theoretical explanation of the relationship and differences between the distribution of bm and that of the parent generating process in particular f β b allowed a deeper theoretical study of the differences between the return periods resulting from the analysis of bm and those of the entire process previously discussed by volpi et al 2019 we showed that such discrepancies are not due to sampling uncertainty but are intrinsic and explained by the different nature of the bm and parent processes along with the different failure scenarios described by their probability distributions these results further stress the importance of reasoning in terms of probability to draw correct interpretation of derived variables such as the return period secondly using f β b and f b and reasoning in terms of probabilistic scenarios provide a simple and clear explanation of the convergence of the upper tail of the bm distribution to the upper tail of the parent distribution this fact and the corresponding probabilistic formulation enables the derivation of some rules yielding the number of the largest maxima lm or ot values required to approximate the parent distribution with the desired level of accuracy for example these rules provide a theoretical support to the popular rule of thumb of using 3 ot values under independence on the other hand they also stress the requirement of a larger number of lm or ot values depending on the degree or extent of serial dependence as third conceptual application our theoretical results also shed light on existing non asymptotic models for extremes in particular reasoning in terms of f β b and f b reveals that the so called metastatistical extreme value mev distributions are compound f b accounting for inter block variability while the so called simplified mev smev is a standard f b for processes with mixed parent distribution accounting for intra block variability moreover interpreting mev and smev in terms of distributions of order statistics allows for a straightforward generalization incorporating the effect of serial correlation as discussed in section 5 1 in this context the most general non asymptotic model for bm is a compound m dimensional joint distribution that accounts for the serial correlation of the observations by a complete mutivariate distribution and for possible inter block fluctuations by compounding averaging over the parameter space existing methods such as mev so called todorovic distributions or the models by lombardo et al 2019 are special cases of such a general model however since such a joint distribution has usually high dimensionality e g up to 365 for annual blocks of daily observations and low tractability for practical implementation some simplifications are required in this respect lombardo et al 2019 specialized the todorovic distributions reducing the dimensionality by focusing on the bivariate case corresponding to first order markov processes on the other hand the compound version of f β b distribution f β b c proposed in this study allows the modeling of processes with more persistent serial correlation structures similar to the above mentioned exact m dimensional joint distribution and accounts for the inter block fluctuations of all parameters similar to mev however while preserving information concerning the second order joint moments i e the linear autocorrelation function f β b c unavoidably misses the information of higher order joint moments characterizing the joint distribution in other words tractability reduction of dimensionality and extension to strongly persistent processes is paid by accepting to focus on the autocorrelation rather than on the entire multivariate distribution this loss of information is not a true limit for many practical applications and it opens the door to the analysis of a variety of persistent processes such as stream flows without pre processing data based on the above remarks we analyzed river discharge time series characterized by non negligible serial dependence as a proof of concept of the theoretical results results confirm that the number of lm or ot values required to approximate the upper tail largest quantiles of the parent distribution increases when dealing with persistent processes due to information redundancy and reduced effective sample size we stress that such a better approximation is related to the increase of the number of lm per block on the other hand this improvement cannot be obtained by preserving the number of lm per block and increasing the sample size because the discrepancies between the lm and parent distributions are intrinsic and independent of sample size analyses based on f β b c show that such a model can reproduce the empirical distributions of bm of strongly persistent stream flow processes starting from the entire sequences of observations and without the need of pre processing the data in any way finally in this methodological study we showed only few conceptual examples of potential applications of the distributions of order statistics as well as the importance of interpreting the existing techniques in the consistent and unified framework of order statistics theory and compound distributions to avoid misleading conclusions clearly additional applications are possible and several problems deserve further investigation for example f β b can be used to improve existing estimation procedures based on order statistics that are currently available only under the assumption of independence makkonen and tikanmäki 2019 using models incorporating observations of the entire process also raises the problem of estimating a realistic parent marginal distribution in fact the latter cannot be described by standard distributions commonly applied in hydro climatic analysis because of the properties of the parent process such as seasonality and correlation itself more advanced models such as generalized linear additive models can be explored to accomplish this task credit authorship contribution statement francesco serinaldi conceptualization methodology software formal analysis writing original draft writing review editing visualization federico lombardo conceptualization methodology writing review editing chris g kilsby conceptualization writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements francesco serinaldi and chris g kilsby acknowledge the support from the willis research network federico lombardo is grateful to the italian national fire and rescue service for the continuous support the authors thank an eponymous reviewer dr marco marani università degli studi di padova and duke university and two anonymous reviewers for their critical remarks that helped substantially improve content and presentation of the original manuscript the analyses were performed in r r development core team 2019 appendix a derivation of eqs 6 and 7 let xi i 1 2 m be a sequence of correlated binary random variables taking the value 1 with probability p and the value 0 with probability 1 p and let e denote the expectation of a random variable the correlation ρij between xi and xj is defined as a 1 ρ i j e x i x j e x i e x j e x i 1 e x i e x j 1 e x j and the average correlation is i j ρ i j m m 1 as mentioned in section 2 2 compound distributions are a viable tool to accont for correlation with the foregoing settings and recalling that s i 1 m x i the beta binomial probability mass function f β b takes the form a 2 f β b p s s 0 1 f b i w f β w α β d w m s b s α m s β b α β the mean μ β b and variance σ β b 2 are a 3 μ β b e s m p σ β b 2 var s m p 1 p 1 m γ 1 γ where a 4 p α α β 1 p β α β γ 1 α β the parameter γ is a measure of the fluctuation of the rate of occurrence it is called as correlation level and γ 0 for case of pure binomial distribution hisakado et al 2006 our aim is to derive analytically the identity in eq 7 thus showing that the correlation ρij of a process with fixed p can be expressed in terms of α and β and therefore the known compound distribution of the sum of mixing independent binary variables with fluctuating rate of occurrence can serve to approximate the unknown distribution of the sum of serially correlated binary variables exploiting the identity of their mean and variance since the correlated variables xi have the same mean e x i e x p and variance var x i var x p 1 p we have a 5 e s m e x and a 6 var s m var x i j cov x i x j m var x i j e x i x j e x 2 m var x i j e x i x j m m 1 e x 2 from eqs a 3 a 5 and a 6 it follows that a 7 i j e x i x j m m 1 var s m var x m m 1 e x 2 σ β b 2 m p 1 p m m 1 p 2 γ 1 γ p 1 p p 2 using eqs a 1 a 4 and a 7 the average correlation becomes a 8 i j ρ i j m m 1 1 m m 1 i j e x i x j e x i e x j e x i 1 e x i e x j 1 e x j 1 m m 1 i j e x i x j p 2 p 1 p p 1 p 1 p 1 p i j e x i x j m m 1 1 p 1 p i j p 2 m m 1 1 p 1 p γ 1 γ p 1 p p 2 p 1 p γ 1 γ 1 α β 1 ρ β b which yields eq 7 using this result and recalling that p 1 f z the equalities in eq 6 readily follow from the first two equalities in eq a 4 appendix b dependence structures denoting the lag time as δ the fractional gaussian noise fgn also known as hurst kolmogorov process e g koutsoyiannis 2010 is characterized by the following acf b 1 ρ x δ 1 2 δ 1 2 h 2 δ 2 h δ 1 2 h which exhibits a power law decay ρ x δ δ 2 h 2 for 0 5 h 1 the process is positively correlated and exhibits long range dependence while it reduces to white noise for h 0 5 the discrete time ar 1 process is characterized by exponentially decaying acf of the form b 2 ρ x δ exp γ δ ρ 1 δ where 1 γ is the correlation radius and ρ 1 exp γ is the lag one autocorrelation coefficient the bivariate gumbel or gumbel hougaard copula has standard expression e g salvadori et al 2007 pp 236 237 b 3 c u v ξ e ln u ξ ln v ξ 1 ξ where u v 0 1 2 and ξ 1 is a dependence parameter related to the kendall correlation coefficient τ by the relationship b 4 ξ 1 1 τ the gumbel copula belongs to the class of extreme value copulas and its upper tail dependence coefficient is given by λ u 2 2 1 ξ the bivariate clayton copula has standard expression e g salvadori et al 2007 pp 237 240 b 5 c u v ξ max u ξ v ξ 1 0 1 ξ where u v 0 1 2 and ξ 1 is a dependence parameter related to the kendall τ by the relationship b 6 ξ 2 τ 1 τ the upper tail dependence coefficient of clayton copulas is given by λ u 0 the gumbel ar 1 and clayton ar 1 processes are simulated by using the conditional distribution of u i 1 given u i u i e g salvadori et al 2007 pp 209 210 b 7 c u i u i 1 p u i 1 u i 1 u i u i u i c u i u i 1 therefore a possible algorithm is as follows 1 generate independent variables u 1 and t from a standard uniform distribution 2 set u i 1 c u i 1 t where c u i 1 denotes the inverse of the conditional distribution in eq b 7 3 iterate steps 1 and 2 up to the desired step m 4 apply the quantile function f z 1 u i to obtain a sequence with the desired marginal distribution fz as closed form analytical expressions of the acf of gumbel ar 1 and clayton ar 1 processes are not available acf terms required for the analysis reported in section 2 2 are numerically derived by taking the average of the empirical acfs computed on sequences simulated from these processes appendix c derivation of eqs 19 21 for m 2 let us set f z c f z and g c g for ease of notation and recall that p z 1 c z 2 c 1 p z 1 c p z 2 c p z 1 c z 2 c 1 2 f z g under independence p z 1 c z 2 c p z 1 c p z 2 c and 1 2 f z g 1 2 f z f z 2 1 f z 2 according to de morgan s laws the disjunction of the negations is the negation of a conjunction then we have c 1 p z 1 c p z 2 c p z 1 c p z 2 c 1 p z 1 c p z 2 c 1 f z 1 f z 1 f z 2 1 f z 2 2 1 f z 1 f z 2 1 f z 2 p z 1 f z 2 p y for m 3 c 2 i 1 3 p z i c 2 i 1 3 p z i c p z 1 c p z 2 c p z 3 c p z 2 c p z 3 c p z 1 c p z 3 c p z 1 c p z 2 c 1 p z 1 c p z 2 c p z 3 c 3 1 f z 2 1 f z 3 3 1 f z 2 f z 1 f z 3 p z 2 1 f z 3 3 1 f z 2 f z p y for a generic m we obtain by induction c 3 p z p y 1 1 f z 2 for block size 2 2 1 f z 3 3 1 f z 2 f z for block size 3 3 1 f z 4 8 1 f z 3 f z 6 1 f z 2 f z 2 for block size 4 m 1 1 f z m m 2 m m 1 1 f z m 1 f z m 3 m m 2 1 f z m 2 f z 2 m 2 1 f z 2 f z m 2 for block size m the latter line in eq c 3 can be rewritten in a compact form as in eq 21 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103686 appendix d supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
413,classic extreme value theory provides asymptotic distributions of block maxima bm y or peaks over threshold pot however as bm and pot are relatively small subsets of the values assumed by the parent process z alternative approaches have been proposed to make inferences on extremes by using intermediate values and non asymptotic models in this study we investigate the finite sample theory of extremes based on order statistics and present a set of results enabling the analysis of the properties of non asymptotic distributions of bm in finite size blocks of data under the assumption that the parent process z has stationary temporal dependence in particular we suggest the beta binomial distribution f β b as a suitable approximation of the marginal distribution of order statistics and bm under dependence thus generalizing the theoretical results available under independence we demonstrate the usefulness of the f β b distribution in three conceptual applications of hydrological interest firstly we review the so called complete time series analysis cta framework showing that the differences between fy and fz are due to the inherent theoretical nature of the processes y and z and the different probabilistic failure scenarios described by fy and fz secondly we provide a theoretical rule to select the number of the largest maxima lm and over threshold exceedances ot required to approximate the desired portion of the upper tail of fz with specified accuracy finally we discuss how the f β b distribution offers an interpretation and generalization of the so called metastatistical extreme value mev framework and its simplified version smev avoiding the use of high dimensional joint distributions and preliminary data thresholding and declustering all methodological results are validated by monte carlo simulations involving widely used stochastic processes with persistence real world stream flow data are also analyzed as proof of concept keywords order statistics block maxima persistent processes beta binomial distribution return period metastatistical extreme value mev todorovic distributions 1 introduction since the pioneering works of hazen 1914 and fuller 1914 on water supply management and flood protection design the study of hydrological extremes has been the focus of many theoretical and applied studies from a theoretical standpoint an entire branch of statistics called extreme value theory evt has been developed to characterize the probability of extremes fisher and tippett 1928 von mises 1936 gnedenko 1943 jenkinson 1955 balkema and de haan 1974 pickands iii 1975 leadbetter 1983 smith 1984 davison and smith 1990 beirlant et al 2006 the application of evt to hydro climatic analyses has become a prominent topic after the work of gumbel 1958 who provided the link between evt results and the empirical basis of hydrological frequency curves see e g coles 2001 salvadori et al 2007 for an overview in the context on hydro climatic applications evt describes the extremal behavior of observed phenomena by asymptotic probability distributions which are valid for a large number n of observations i e n resembling the samples of independent and identically distributed i id random variables whose parent distribution should belong to one of the three domains of attraction identified by evt under the assumption that the limit distribution of extreme values is non degenerate of course hydro climatic extremes hardly ever meet such oversimplifying assumptions indeed i systematic hydro climatic records rarely span more than 100 200 years ii extreme events are rare by definition and their number is commonly less than few tens if the focus is on really extreme values iii hydro climatic phenomena often result from combinations of heterogeneous processes such as frontal and convective meteorological systems extra tropical cyclones heavy rainfall rapid snow melt or monsoons driving precipitation and flood events e g morrison and smith 2002 smith et al 2011 2018 and iv hydro climatic processes such as stream flow rainfall and temperature at various temporal scales exhibit short long or mixed short long term serial correlation e g iliopoulou et al 2018 kantelhardt et al 2006 labat et al 2011 lombardo et al 2017 markonis et al 2018 papalexiou et al 2011 serinaldi 2010 serinaldi et al 2018 serinaldi and kilsby 2018 wang et al 2007 serinaldi and lombardo 2020 serinaldi kilsby 2016 and references therein in this respect focusing on sub samples such as block maxima bm or over threshold ot values can only apparently help fulfilling the required assumptions in real world analyses in fact bm and ot sub sampling procedures i decrease the available samples size ii do not remove possible heterogeneity of the generating mechanism which prevents or slows down convergence toward a domain of attraction and iii do not remove the possible effect of correlation characterizing non extreme values on the extremes even if annual maxima am and ot samples are formed in such a way to appear approximately uncorrelated iliopoulou and koutsoyiannis 2019 koutsoyiannis 2004 the need to overcome these limitations led to consider alternative modeling approaches such as sub pre asymptotic methods that allow for a more efficient use of the available data using for instance all the data forming over threshold clusters instead of cluster maxima only thus reducing the estimation variance with the same aim i e retaining as many observations as possible to infer the distribution of the largest values there has been a renewed research interest in non asymptotic distributions of bm in finite size samples including both extreme and intermediate observations e g de michele 2019 de michele and avanzi 2018 hosseini et al 2019 lombardo et al 2019 marani and ignaccolo 2015 marra et al 2018 2019 todorovic and zelenhasic 1970 volpi et al 2019 zorzetto et al 2016 zorzetto and marani 2020 in sections 1 1 and 1 2 we summarize the main results in asymptotic pre asymptotic and non asymptotic analysis of extreme values focusing on how these approaches deal with the aforementioned serial correlation effects and lack of distributional identity 1 1 overview of evt approaches to non homogeneity and serial dependence concerning the lack of distributional identity leadbetter et al 1983 p 289 distinguish two main types of variation with time of the distribution parameters when modeling processes such as rainfall or wave height i deterministic variations corresponding to patterns repeating from one period of time to the next e g seasonality and ii random fluctuations with their own distributional properties the latter case corresponds to observations coming from mixed or compound distributions which can provide a more realistic description of hydro climatic records reflecting the complexity heterogeneity of mechanisms driving the target hydro climatic process of interest barth et al 2019 koutsoyiannis 2004 porporato et al 2006 rossi et al 1984 rulfová et al 2016 for the aforementioned types of variation evt provides different theoretical results and therefore different limit distributions see e g examples in leadbetter et al 1983 pp 290 297 as far as the effect of correlation is concerned under the assumption that the limit distribution is non degenerate leadbetter 1983 showed that serially correlated and independent processes share the same asymptotic extreme value distributions when the correlated process fulfills the so called d condition which controls the long range dependence in the process at extreme levels for gaussian sequences with autocorrelation ρτ at lag τ the d condition is satisfied as soon as ρτ logτ 0 as τ berman 1964 which is however weaker than the geometric decay assumed by autoregressive models beirlant et al 2006 pp 373 374 the validity of evt limit distributions under serial correlation also holds for weaker versions of the d conditions such as the asymptotic independence of maxima aim proposed by o brien 1987 which admits a class of periodic markov chains see also beirlant et al 2006 p 374 similar conditions can be established for pot or cluster maxima as well e g leadbetter 1991 informally these conditions ensure that for large enough lags any dependence is sufficiently negligible so as to have no effect on the limit laws for extremes fawcett and walshaw 2016 however such asymptotic independence conditions are not valid for instance for strongly correlated processes in these cases one can obtain quite arbitrary asymptotic distributions for the maximum leadbetter et al 1983 p 66 leadbetter et al 1983 ch 6 provide examples of gaussian processes in which an asymptotic distribution for the maximum exists but is not of extreme value type when the dependence decay is so slow that d does not hold moreover the slow decay of the correlations not only changes the limiting distribution of extremes but also destroys the asymptotic independence between extreme values in disjoint intervals leadbetter et al 1983 p 133 this behavior is not so unusual for instance in daily stream flow records exhibiting long range dependence and therefore clustering of threshold exeedances in time and sequences of high low annual maxima i e flood rich and flood poor periods see e g serinaldi kilsby 2016 and references therein even when the d condition holds true limit distributions under dependence are not identical to those of the corresponding independent processes with the same marginal distribution albeit they share the same domain of attraction this fact implies very practical consequences indeed dealing with generally short hydro climatic variables one year blocks do not always ensure fulfilling asymptotic conditions and bm can still be influenced by underlying dependence as they are not necessarily the most true extreme values e g eichner et al 2011 bogachev and bunde 2012 volpi et al 2015 serinaldi and kilsby 2016 on the other hand intra cluster serial correlation emerges when using moderate thresholds to increase the sample size of ot exceedances and reduce estimation uncertainty of extreme value distribution parameters the problem of dealing with pre sub asymptotic conditions and possible effect of serial correlation has been studied in evt introducing for instance the concepts of extremal index leadbetter et al 1983 or sub asymptotic extremal index ledford and tawn 2003 which rescale classical limit distributions fitted on sub asymptotic values in order to obtain the actual asymptotic distribution of the extreme values of the process under study see also ancona navarrete and tawn 2000 beirlant et al 2006 fawcett and walshaw 2007 2008 2016 and references therein 1 2 non asymptotic approaches to the distributions of bm in finite size samples conceptually the non asymptotic distributions of bm precede the limit distributions provided by evt as the latter are the asymptotic version of the former however evt is much more widespread than the theory concerning finite sample bm as i evt is fairly general ii it does not require to know the distribution function of the parent process too precisely leadbetter et al 1983 p 4 iii it is more advanced as discussed above and iv it is relatively easy to apply at least in several every day practical applications among the non asymptotic methods in this study we focus on the so called complete time series analysis cta volpi et al 2019 and a framework denoted as metastatistical extreme value mev marani and ignaccolo 2015 cta consists of estimating the probability of extreme values by using the distribution of the entire data set including all the available records the same approach was previously applied by papalexiou and koutsoyiannis 2013 and papalexiou et al 2018 without any re labeling earlier marani and ignaccolo 2015 introduced a framework denoted as metastatistical extreme value mev which is a compound version of the standard distribution of bm in finite size blocks resulting from the theory of order statistics for independent random variables marra et al 2019 proposed a simplified version of mev smev accounting for intra annual parameter s variations but removing inter annual fluctuations both mev and smev are valid under independence and have been applied to rainfall and stream flow data fulfilling this assumption after pre processing the data by declustering if required e g hosseini et al 2019 marra et al 2018 miniussi et al 2020 as better explained below mev is strictly related to the todorovic framework tf todorovic 1970 the general tf todorovic 1970 eqs 3 3 and 3 4 involves the high dimensional multivariate joint distribution of the parent process in finite size blocks to account for serial dependence to deal with tractable joint distributions lombardo et al 2019 specialized tf for markovian dependence structures and negative binomial block sizes this choice allows the derivation of a closed form distribution of maxima as first order markov processes are fully characterized by a low dimensional bivariate joint distribution as better discussed in the following sections all these methods attempt to account for the effects of serial correlation and lack of distributional homogeneity to some extent 1 3 aim and structure of this study denoting the marginal distribution of the variable z describing a parent process of interest e g rainfall or stream flow as fz and the block size as m most of the literature assumes the standard distribution of bm f z m for independent and identically distributed i id random variables as starting point in more detail classical evt deals with the asymptotic version of f z m while standard non asymptotic methods deal directly with it or its compound versions e g mev however to the best of our knowledge a general version of the distribution of bm for serially correlated identically distributed sc id random variables has not been considered in the literature in this study we suggest a possible version of the univariate distribution of order statistics under sc id f r and discuss its key role in three conceptual applications of practical interest in more detail 1 we review cta providing the theoretical explanation of the relationship and differences between cta and bm distributions 2 we disclose the different probabilistic scenarios described by cta and bm distributions and how bm distributions can be handled to approximate the desired portion of upper tail of the parent distribution with desired accuracy 3 we review mev and smev and therefore indirectly tf we show how f r allows for the interpretation and generalization of mev and smev frameworks overcoming the problem of estimating the multidimensional distribution of the parent process and enabling the non asymptotic analysis and modeling of bm of processes with stationary serial correlation structure this paper is organized as follows section 2 introduces the distribution of order statistics f r and block maxima fy under temporal dependence we show that such distributions can be conveniently parametrized in terms of parent distribution fz and the average of the autocorrelation matrix of the parent process thus avoiding the use of high dimensional joint distributions in section 3 we use the distributions of order statistics under i id and sc id to interpret the theoretical differences between fy and fz section 4 discusses theoretical rules for choosing the number of the largest maxima lm e g leadbetter et al 1983 ch 5 and ot exceedances such that fy can approximate a given portion of the upper tail of fz with desired accuracy in section 5 we use f r to interpret and generalize mev and smev while section 6 presents some proofs of concept based on real world stream flow data section 7 summarizes the main findings of this study 2 order matters the distribution of order statistics and block maxima under temporal dependence 2 1 overview of standard results for the i id case to introduce the distribution of order statistics for a correlated process we firstly recall some basic results for the case of independent and identically distributed i id random variables when a sequence of m random variables z 1 z m with the same cumulative distribution function cdf fz z is sorted in ascending order of magnitude and then written as z 1 z m we call z r or z r m the rth order statistic r 1 m with distribution function f r z depending on fz z david and nagaraja 2004 p 1 recalling the derivation of the expression of f r z in terms of fz z helps understand its extension to the case of serially correlated identically distributed sc id random variables for given z we can define a binary process x such that 1 x i i z z i 1 if z i z 0 otherwise where i is the indicator function it follows that the random variable s i 1 m x i represents the number of variables zi exceeding z therefore the expression of f r z can be derived from the equivalence of the two events z r z and s m r in fact if the rth order statistic is less than or equal to z then the number of zi exceeding z is surely smaller than or equal to m r i e p z r z p s m r and vice versa mood et al 1974 pp 251 252 since s has a binomial distribution with parameters m number of trials and fz z rate of occurrence under i id assumption for z it follows that 2 f r z p z r z i 0 m r p s i i 0 m r m i f z m i z 1 f z z i f b m r m 1 f z z f β f z z r m r 1 the last form in eq 2 results from the relation between binomial sums and the regularized incomplete beta function gibbons and chakraborti 2003 pp 40 42 3 f β w α β 1 b α β 0 w t α 1 1 t β 1 d t where b α β is the complete beta function see also arnold et al 1992 pp 12 13 the cdfs in eq 2 provide the marginal distributions useful in many applications such as the definition of confidence intervals of quantiles e g hutson 1999 serinaldi 2009a and the study of the maximum y z m and the minimum z 1 of a random sample z 1 z m e g kottegoda and rosso 2008 pp 406 409 in particular the cdf of block maxima bm y in random samples of finite size m is 4 f y z f m z i 0 m m m i f z m i z 1 f z z i f z m z f b 0 m 1 f z z f β f z z m 1 2 2 order statistics under sc id conditions results in section 2 1 rely on the duality between the parent process zi and the corresponding counting process s describing the number of exceedances of a given threshold z focusing on the process s f r can be represented by a binomial distribution f b which is only valid in the i id case the extension to sc id case requires a distribution equivalent to f b enabling the description of the sum s of a correlated binary process xi corresponding to a correlated parent process zi even though the general distribution of s under sc id is unknown its mean and variance are known as discussed later therefore we propose to approximate distribution of s with a so called beta binomial distribution which allows for an explicit parametrization in terms of fz and autocorrelation function acf of the process z and includes f b as a special case under i id some preliminary remarks help better understand the rationale of using the beta binomial model in the present context in principle the derivation of the exact distribution of s under sc id should rely on the joint distribution of correlated binary process xi which provides a complete description of the process itself such a distribution is multinomial and can be specified using a representation first suggested by bahadur 1961 in the bahadur representation the joint probability of m correlated binary variables is uniquely determined by m marginal probabilities pi i 1 m and the i 2 m m i 2 m m 1 correlation coefficients of all orders i e second and higher see also kupper and haseman 1978 lipsitz et al 1995 zaigraev and kaniovski 2013 the bahadur representation allows for defining the joint probability distribution of any vector of correlated binary variables at the price of using a large number of parameters to overcome this difficulty bahadur proposed truncating the distribution to second order correlations also known as correlated binomial cb model kupper and haseman 1978 paul 1985 this is equivalent to assuming that all higher order correlations are negligible zaigraev and kaniovski 2013 however this approximation i does not guarantee that the probability mass function is always positive even if it always sums up to one and ii it yields a valid distribution only for a range of second order correlation values whose limits become closer to zero as m increases see e g kupper and haseman 1978 paul 1985 proposed a generalized version of the cb model called beta correlated binomial βcb distribution this generalization relies on the concept of compound distributions allowing the rate of occurrence p of the cb model to vary according to a beta distribution however similarly to cb the βcb model is still valid for a limited range of correlation values whose bounds tend to zero as m increases thus making the model not suitable for practical applications with e g m 365 annual blocks of daily data based on the foregoing remarks the complete joint distribution might not be a practical option because of the curse of dimensionality and high parametrization on the other hand extensions of the classical binomial model accounting for modulation of second order moments appear a more viable option in this respect the concept of compound distributions can help find an approximate distribution that is suitable for our purposes since hydro climatic processes are generally positively correlated the required binomial extension should also be valid for at least the range of correlation values 0 1 a widely used model fulfilling these requirements is the beta binomial f β b distribution this distribution has a long history skellam 1948 it can arise in a number of ways moran 1968 hisakado et al 2006 and is also known as the pólya or negative hypergeometric distribution griffiths 1973 and has been applied in several fields for various purposes nicola and goyal 1990 hughes and madden 1993 ahn and chen 1995 tsai et al 2003 serinaldi et al 2018 even though it has received little attention in hydro climatology despite its very attractive properties see e g serinaldi and kilsby 2018 referring to the references above for further details we introduce the rationale and main properties of f β b useful for the present discussion f β b is a popular model especially in toxicological or infection studies where the effects of a chemical agent or disease are often recorded as the number of the affected individuals within an experimental unit e g a litter or a household a common characteristic of this type of data is the so called litter effect i e the tendency for individuals from the same unit to respond more alike than individuals from different units such greater alikeness which is denoted as intra unit or intra cluster correlation may arise for instance from unmeasurable litter effects or from covariates common to the experimental unit that are omitted or are inaccurately measured such as genetic factors and or differences in surrounding environment haseman and kupper 1979 prentice 1986 the resulting count data usually exhibit over dispersion compared to binomial or poisson samples due to aforementioned intra cluster correlation i e litter effects in this context litter effects are often accounted for by using mixture distributions supposing that the binary variates within an experimental unit are independent estimators of a latent response rate p in other words under this type of models the intra cluster or intra litter responses are conditionally independent but are unconditionally dependent haseman and kupper 1979 intra cluster correlation enters upon allowing p to vary according to some distribution thus mimicking litter effects on p prentice 1986 we stress that the mixture distributions of counting processes which are fully known do not coincide with the actual unknown distribution of s under sc id but the former can approximate the latter preserving some properties such as mean and variance within the class of discrete mixture distributions f β b is a convenient compound distribution that arises by assuming the rate of occurrence p of an ordinary binomial distribution to be a random variable following a beta distribution fβ eq 3 recalling the duality between the events z r z and s m r such that p z r z p s m r for a correlated stationary process zi the cdf of z r corresponding to eq 2 can be approximated by f β b skellam 1948 5 f r z p s m r i 0 m r 0 1 f b i w f β w α z β z d w i 0 m r m i b i α z m i β z b α z β z where 6 α z 1 ρ β b z ρ β b z 1 f z z β z 1 ρ β b z ρ β b z f z z and f z z 1 α z α z β z and ρ β b z is known as the intra class or intra cluster correlation see appendix a 7 ρ β b z 1 α z β z 1 j l ρ l j z m m 1 where ρ l j z corr x j z x l z denotes the pairwise correlation of two randomly chosen trials separated by a time lag l j the indices j and l refer to two different time steps in a temporal process evolving in m time steps the mean and variance of f β b are given by the formulas ahn and chen 1995 8 μ β b e z m 1 f z z and 9 σ β b 2 var z m f z z 1 f z z 1 m 1 ρ β b recalling that μ b m 1 f z z and σ b 2 m f z z 1 f z z eqs 8 and 9 indicate that f β b and f b have the same mean while f β b allows for further modulation of the variance precisely as σ β b 2 0 by definition it follows that ρ β b 1 m 1 1 thus confirming the capability of f β b to cover the entire range of positive correlation values as well as a subset of negative values which however becomes very small for block sizes of our interest e g m 365 we stress that the terms ρ l j refer to the binary process xi resulting from the dichotomization procedure in eq 1 which in turn depends on z as well even though this dichotomization does not preserve linear correlation the terms of the autocorrelation function acf of the process xi are related to those of the parent process zi with arbitrary marginal distribution fz bivariate joint distribution g 2 and bivariate copula c 2 by emrich and piedmonte 1991 ahn and chen 1995 10 ρ l j p x j 1 x l 1 p 2 p 1 p p z j z z l z p 2 p 1 p 1 2 f z z g 2 z z ξ p 2 p 1 p 1 2 1 p c 2 1 p 1 p ξ p 2 p 1 p where p 1 f z z and ξ is a generic parameter quantifying the overall degree of dependence between the pairs zj zl as a particular case a meta gaussian dependence structure copula is a common assumption in time series analysis and modeling papalexiou 2018 papalexiou and serinaldi 2020 as popular time series models such as autogressive ar models and their extension or mandelbrot s fractional gaussian noise fgn rely on this assumption in these cases ρ l j can be computed from the correlation values of an auxiliary standard gaussian process wi which is related to the parent process zi through the normal quantile transformation nqt w i φ 1 f z z i where φ denotes the standard gaussian cdf since ranking and percentage based dichotomization are invariant to monotonic transformations such as nqt gibbons and chakraborti 2003 p 189 eq 1 yields the same xi process when it is applied to zi with threshold equal to z or to wi with threshold w φ 1 f z z working with the process wi corresponding to zi and using the symmetry of the gaussian distributions allow the easy calculation of the correlation coefficients ρ l j from those of the gaussian process by the relationship emrich and piedmonte 1991 serinaldi and lombardo 2017a 11 ρ l j φ 2 φ 1 p φ 1 p corr w j w l p 2 p 1 p where φ2 denotes the bivariate gaussian cdf of wj wl obviously eq 11 is a special case of eq 10 emphasizing the dependence of ρ β b on fz z and the acf of the process zi or wi denoted as ρ the distribution of bm in finite size blocks under sc id can be described by eq 5 in the form 12 f y z f m z b α z m β z b α z β z f β b 0 m 1 f z z ρ β b f z z ρ which yields eq 4 as a particular case for ρ β b 0 we validate the capability of f β b of reproducing the distribution of the bm y in blocks of size m 365 mimicking annual maxima of daily time series for four stationary processes fractional gaussian noise fgn which is also known as hurst kolmogorov process and has gaussian dependence structure first order autoregressive ar 1 process with gaussian dependence structure ar 1 process with bivariate clayton dependence structure linking consecutive values and standard gaussian marginal distributions clayton ar 1 see appendix b ar 1 process with bivariate gumbel dependence structure linking consecutive values and standard gaussian marginal distributions gumbel ar 1 see appendix b the autocorrelation functions acfs of the fgn and ar 1 processes are reported in appendix b along with the expressions of the clayton and gumbel copulas in all cases we assume standard gaussian marginal distributions to better assess the impact of dependence structure and tail dependence in fact the gaussian and clayton copulas are upper tail independent while the gumbel copula which is an extreme value copula exhibits upper tail dependence e g salvadori et al 2007 pp 236 238 and 254 255 for the processes with multivariate gaussian distribution e g fgn and ar 1 under sc id conditions the exact distribution of y is no longer f z m eq 4 but the 365 dimensional joint gaussian distribution φ365 z of z 1 z 365 with correlation matrix σ i e 13 f y z p z 1 z z 2 z z 365 z φ 365 z σ on the other hand to the best of our knowledge explicit expressions for the acf and 365 dimensional joint distribution describing all mutual lagged correlations of clayton ar 1 and gumbel ar 1 processes are not readily available to better visualize the behavior of the upper tail of fy fig 1 compares the survival functions 1 f y obtained from eq 5 and the empirical counterpart 1 f n y 1 n 1 i y i y corresponding to 1000 annual maxima extracted from time series of size 365 1000 along with the survival function derived from eq 13 for fgn and ar 1 we considered fgn processes with parameter values h 0 6 0 7 0 8 0 9 ar 1 with ρ 1 0 2 0 5 0 8 0 95 and clayton ar 1 and gumbel ar 1 processes with parameters ξ corresponding to lag 1 kendall correlation coefficient τ 1 0 2 0 5 0 8 0 9 see appendix b this set of parameters allows a validation of the f β b distribution in eq 12 for the entire range of positive correlation values as all processes have zero mean the diagrams in the figures are shifted horizontally by one unit for better visualization fig 1 a and b show that f β b provides results indistinguishable from φ365 using a simple univariate distribution instead of a high dimensional joint distribution which requires numerical integration and can be prone to accuracy problems this can explain some discrepancies emerging in the body of the distributions for the highest values of the parameters h and ρ 1 leaving aside sampling fluctuations the empirical distributions fn confirm that both methods faithfully reproduce the expected distributions on y whereby f β b has the advantage to be univariate and computationally inexpensive and free from possible inaccuracy due to numerical solution of high dimensional integrals the advantage of using f β b is even more evident when dealing with the clayton ar 1 and gumbel ar 1 processes for which the exact 365 dimensional joint distribution is not available in explicit form in these cases ρ l j is computed by eq 10 with parameter ξ τ l j see eqs b 4 and b 6 fig 1c and d show that f β b provides an accurate approximation for low to middle values of τ 1 and all values of probability of practical interest i e p y z 0 2 corresponding to return periods t 5 years while some discrepancy emerges for high values of τ 1 and gumbel copula however this is the expected effect of the upper tail dependence which yields extreme values more correlated than those of tail independent models therefore tail dependence further inflates information redundancy of bm meaning that longer time series are required to explore the state space since f β b accounts for second order properties via ρ l j see eqs 10 and 11 some loss of information concerning higher order properties is expected nonetheless results in fig 1c and d show that the lack of accuracy is limited and it is an acceptable cost considering the simplicity of the approach the greatly reduced computational cost and more importantly the unavailability of viable forms of the exact high dimensional distributions 3 facets of return period based on probabilities as a first conceptual application in this section we show how f β b plays a key role in the interpretation of different definitions of return period provided by volpi et al 2019 in the context of cta thus highlighting the theoretical relationships and differences between the distribution of bm fy and that of the parent process fz 3 1 setting the stage referring to the literature for the formal derivation of the expressions of return period t for independent non independent identically non identically distributed random processes in a univariate multivariate framework chow et al 1988 fernández and salas 1999 douglas et al 2002 cooley 2013 salas and obeysekera 2014 serinaldi 2015 volpi et al 2015 salvadori et al 2016 we only recall that t is the average inter arrival or waiting time of safety critical events e g threshold exceedances in a stationary context t is written as 14 t μ p μ p e μ 1 f where μ 0 denotes the average inter arrival time between two observations of a discrete time process of interest e g zi p p e is the probability to observe a critical unsafe event e and f indicates the distribution function quantifying the probability of the uncritical safe complementary event e in classical univariate setting t is usually estimated by analyzing the process of bm or ot values y of the parent random process z which can be for instance the daily stream flow process in this case the critical event can be defined as e y y f fy and p p y y 1 f y y being the expected value of a highly skewed variable such as the inter arrival time bunde et al 2007 bogachev and bunde 2012 serinaldi and kilsby 2016 t is generally insufficient in statistical sense to describe the distribution inter arrival time serinaldi 2015 volpi et al 2015 in the same way as the mean is not sufficient to characterize a gaussian distribution without introducing the variance this makes t prone to misinterpretation strathie et al 2017 and ill posed comparisons in the description of the rareness of an event serinaldi 2015 2016 cta uses all observations of the parent process z e g daily data when available to estimate t attempting to avoid the sub sampling effect related to the selection of a limited number of bm or ot values as mentioned in section 1 1 evt provides models for fy that approximate fz only asymptotically in the very upper tail thus implicitly admitting discrepancies out of the range of convergence on the other hand such discrepancies are accepted in front of the advantage to avoid massive data collection which is often not possible at reasonable quality level and cost denoting t z and t y the return periods resulting from cta and bm analysis respectively volpi et al 2019 observed that t z t y and concluded that this inequality is a consequence of data decimation i e loss of information due to discarding observations different from bm they showed that the serial dependence of the parent process increases the uncertainty in the estimates of extreme quantiles and also concluded that am leads to an overestimation of the return period of the parent process for small to moderate return period values converging to cta estimates for large events however talking about over under estimation is strictly correct if two or more estimators quantify the same target statistics in this respect volpi et al 2019 recognized that cta and bm are inherently different processes that give subtly different information on the same underlying continuous process specifically cta describes the marginal behaviour of the whole parent process sampled in discrete time at a given temporal resolution while am describes the statistical behavior of its extremes thus the research question is what is the true nature of the difference between t z and t y in section 3 2 we show that such a difference is related to the different probabilistic hazard scenarios described by the probabilities pz and py appearing in the expressions of t z and t y this finding has fundamental impact on the interpretation of t values resulting from bm ot or cta as it clarifies that talking about over under estimation is misleading and discrepancies are unavoidable theoretical differences resulting from different failure scenarios described by pz and py 3 2 defining return period in different probabilistic scenarios 3 2 1 the i id case to allow a direct comparison with volpi et al 2019 we assume that bm are e g annual maxima am according to eq 14 the return period of am t y can be written as 15 t y 1 p y 1 p y c 1 1 f y c 1 1 f z c m where c denotes a generic threshold value μ 1 as the average inter arrival time between two am is one year and m is the number of observations of the parent process z sampled at a constant time interval for example m 365 for daily stream flow series removing leap years on the other hand cta based t z expressed in years reads as 16 t z 1 p z 1 m p z c 1 m 1 f z c as 1 m years is the inter arrival time between two observations zi and z i 1 of the parent process z in this case μ coincides with the sampling interval expressed in years or a generic measurement unit of m size blocks such as weeks if m 7 days months if m 30 days etc for example μ 1 365 when the parent process is sampled at daily scale note that in ot analysis m is a random variable as it is the expected value of the inter arrival time between ot exceedances focusing on the denominators of the rightmost terms of eqs 15 and 16 we have 17 p y 1 f z c m 1 i 1 m f z i c 1 p z 1 c p z 2 c p z m c 1 p z 1 c z 2 c z m c 1 g m c where the symbol stands for and and denotes logical conjunction while gm is a m dimensional joint distribution the equalities in the middle of eq 17 hold only under independence as the product i 1 m f z i c implies lack of interaction among events on the other hand 18 p z m 1 f z c i 1 m 1 f z i c p z 1 c p z 2 c p z m c p z 1 c z 2 c z m c where the symbol stands for xor and denotes exclusive disjunction therefore pz describes the probability of the union of mutually exclusive events in fact the expression of pz lacks the terms describing the probabilities of possible joint events i e two or more exceedances in other words py is the probability of observing at least an exceedance i e one or more in m independent experiments while pz is the probability of exceeding a given value in each specific trial on an m step time basis without the possibility to observe additional events in the m trials as they are mutually exclusive the explicit relationship between py and pz is easy to obtain for m 2 3 and for a generic m by induction see appendix c firstly we discuss the cases m 2 3 as they allow graphical visualization geometrical interpretation and better understanding of the meaning and difference of py and pz for m 2 from eqs 17 and 18 we obtain 19 p z p y 2 1 f z 1 f z 2 1 f z 2 while for m 3 20 p z p y 3 1 f z 1 f z 3 2 1 f z 3 3 1 f z 2 f z eq 19 shows that the difference between pz and py is equal to the probability of observing exceedances in both blocks for m 3 see appendix c we have a similar term corresponding to exceedances of the threshold c in all blocks i e 2 1 f z 3 along with an additional term corresponding to the exceedances in two blocks out of three i e 3 1 f z 2 f z which are not included in the definition of pz as this refers to the probability of mutually exclusive events for m 2 3 figs 2 and 3 provide a visual representation of the terms of eqs 19 and 20 respectively eqs 19 and 20 also explain why pz and py tend to match for extreme events i e for small values of 1 f z the terms quantifying the difference between pz and py are the 2nd and 3rd powers of the exceedance probability 1 f z while pz is 1st power and py is 0 order as it does not depend on 1 f z therefore for extreme events i e for fz 1 the terms on the right side of eqs 19 and 20 tend to zero more rapidly than pz and py thus resulting in the convergence of the values of pz and py and thus t z and t y for a generic block size m we have 21 p z p y i 2 m i 1 m i 1 f z i f z m i i 2 m i 1 f b i m 1 f z where f b is the binomial probability mass function describing the probability of observing i events in m trials with rate of occurrence 1 f z corresponding to the cdf f b in eq 2 the terms of the summation in eq 21 describe the probabilities of the combinations of events i e possible multiple exceedances in m trials that distinguish the two probabilistic scenarios represented by pz and py for example i 2 gives the probability of observing exactly two exceedances in m trials or time steps as shown in eq 19 3 2 2 the sc id case under sc id conditions the meaning of py and pz does not change as the former is the probability of observing at least an exceedance in m dependent trials while pz is still the probability of the union of m mutually exclusive events zi c i 1 m the difference of py and pz is still represented by the probability of observing more than one exceedance in m time steps i e the joint probability of a count process s corresponding to the number of ot exceedances in m trials as discussed in section 2 2 a tractable form of such a joint distribution is not available while constraints on the degree of correlation affecting some of its approximations prevent the application of these approximations in the cases of general interest on the other hand f β b eq 5 generalizes f b eq 2 and provides an approximation of the required joint distribution that preserves second order properties and in particular pairwise correlations in the entire range of positive values of the average of the acf i e ρ β b 0 1 therefore f β b is a valuable modeling option for applications involving hydro climatic processes that are generally characterized by positive serial correlation and positive average of the m m correlation matrix under these assumptions a generalization of eq 21 for correlated processes results from replacing f b with f β b thus obtaining 22 p z p y i 2 m i 1 m i b i α z m i β z b α z β z i 2 m i 1 f β b i m 1 f z ρ β b f z ρ we checked the accuracy of eq 22 for an ar 1 process with ρ 1 0 9 and fgn with h 0 9 i e for challenging persistent processes eq 21 for i id was also validated for completeness fig 4 reports return periods vs return levels for easier comparison with volpi et al 2019 and it shows how t z approaches to t y by progressively subtracting each of the terms of the summations in eq 21 for i id and eq 22 for ar 1 and fgn they describe the probability of the various multiple failure exceedance scenarios in m 365 blocks which mimic the case of daily series fig 4a refers to the i id case eq 21 while fig 4b and c show the output of eq 22 for the sc id cases the t y curves corresponding to the distributions fy obtained by the joint distribution via 1 φ 365 are also shown for the sake of comparison fig 4 shows that the differences between t z and t y under i id and sc id are theoretically explained in terms of difference of failure scenarios and are an inherent property resulting from the probabilistic description of such scenarios focusing on t 1 i e on the range of t where both t z and t y are defined volpi et al 2019 noted that the discrepancies between t z and t y increase as the processes exhibit stronger persistence thus affecting higher return periods however our analysis shows that such discrepancies i e the departures of t y from t z for low middle values of t are independent of sample size which indeed does not appear in eqs 21 and 22 and their derivation therefore such differences in the low middle range of t values cannot be reduced or eliminated even if large data sets are or become available on the other hand the numerical convergence for very extreme values low pz and py justifies as expected the use of asymptotic results from classical evt however talking about over under estimation of t z vs t y especially outside the range of validity of asymptotic convergence may be theoretically ungrounded as both t z and t y correctly quantify the probability associated to the variables and failure scenarios they refer to we also note that a superficial use of the term return period often conceals the actual meaning of underlying probabilities and type of events e g univariate conditional or joint thus leading to potentially incorrect conclusions e g serinaldi 2015 in this respect the foregoing analysis could not have been possible without moving from t z and t y to pz and py this further stresses the advantages of complementing surrogate indices such as return period with their underlying probabilities for a better understanding of the failure scenarios under study as well as a more transparent communication of the actual probability of failure in hydro climatic risk assessment 4 recovering the upper tail of fz the role of the kth largest maxima based on the discussion in section 3 2 we consider a second conceptual application of f b and f β b recalling that p y 1 f y and p z m 1 f z eqs 21 and 22 describe the relationship between py and pz or similarly between t y and t z or fy and fz therefore fy can result from rescaled fz by subtracting the terms of the summation denoting the probability of the events with r exceedances in m size blocks i e f y m f z 1 m δ where δ denotes the summations in the right side of eqs 21 and 22 however eq 21 and 22 can also be used conversely to move from fy to fz by adding progressively the summation terms in this respect it should be noted that such terms depend on fz therefore in real world applications we cannot move fy to fz without additional information on the parent process z nonetheless eq 21 allows for a conceptual analysis revealing the theoretical basis of some empirically based recommendations concerning the number of lm or threshold exceedances required to make py close to pz in a given portion of the upper tail of fz corresponding for instance to small return periods i e in a region where asymptotic convergence is not yet in play in fact for r increasing from two to m the sum p y δ i e 1 f z m δ becomes closer and closer to pz i e m 1 f z for example for r 2 we add the probability corresponding to the event of observing two exceedances in m trials this means considering two lm in m trials for r 3 eq 21 and 22 yields the probability of observing up to three exceedances in m trials thus meaning that three lm are accounted for in other words as expected adding more and more lm allows the better approximation of the upper tail of fz therefore in principle for a fixed value t it is possible to select a minimum number k of lm required to approximate the desired portion of the upper tail of fz with specified accuracy i e yielding p z p y ε for values of p z 1 t and arbitrarily small ε or similarly t z t y ε for values of t z t and arbitrarily small ε this concept is illustrated considering three processes i id ar 1 with ρ 1 0 9 and fgn with h 0 9 m 365 sample size 1000 m and fz 364 365 363 365 corresponding to t 1 0 5 years for example let us focus on return level plots in fig 5 a and assume t 1 year as a reference value fig 5a shows that there is a discrepancy between the curves t z and t y for t 1 year in order to fill this gap let us add the first summation term in eq 21 up to py the resulting t curve labeled as k 2 in fig 5a is closer to the t z curve for t 1 as it corresponds to the return level curve of two lm for k 3 i e considering the distribution of three lm the resulting t curve labeled as k 3 in fig 5a matches the t z curve for t 1 year i e above the point in fig 5a therefore for the gaussian i id process we should consider at least three lm to obtain an accurate reproduction of the upper tail of the parent distribution for fz 364 365 or likewise t z 1 year fig 5 a also shows the empirical cdfs fn of k lm and ot exceedances selected from the simulated series of course samples of ot exceedances are not identical to k lm samples however their distributions are very similar in the upper tail of interest for t z 1 year where they are required to match fz or t z by the way it is not surprising that k 3 corresponds to the rate of ot values commonly suggested in the literature to perform extreme value analysis according empirical arguments and or statistical tests e g lang et al 1999 durocher et al 2018 for t 0 5 years fig 5b shows that we need at least k 5 lm or ot values to accurately retrieve the desired portion of the upper tail of fz i e fz 363 365 or t z 0 5 years under sc id conditions ar 1 and fgn processes serial dependence introduces information redundancy meaning that we need more observations to approximate the fz or t z curve in the range of interest for example comparing fig 5a c and e and fig 5b d and f where each grey curve denotes an additional term of the summations in eqs 21 and 22 we can see that more terms are needed under sc id to approximate the t z curve for t z 1 year and t z 0 5 years in more detail for the ar 1 process with ρ 1 0 9 we need k 12 15 lm for t 1 0 5 years respectively for the fgn process with h 0 9 we need k 30 40 lm for t 1 0 5 years respectively bearing in mind that lm and ot exceedances rely on different selection methods the foregoing analysis provides a criterion to evaluate the number of lm or ot exceedances required to reproduce a desired portion of the upper tail of the parent distribution when the focus is on moderate values of exceedance probability in particular the effect of serial correlation can strongly increase such a number as discussed in section 1 1 these effects have been widely studied in evt however our analysis provides a different finite size perspective that enables a suitable visualization and practical guidelines we stress again that the above analysis requires the knowledge of the parent process this can appear contradictory as one of the main advantages of using bm or lm or ot exceedances and evt is to avoid a detailed knowledge of the parent process however as discussed above assumptions on the parent process are required in evt as well for example if the parent process is assumed to be long range persistent the convergence to the evt asymptotic distributions is no longer guaranteed therefore the aim of the above analysis is to provide a procedure to assess the degree of accuracy of bm or lm distributions in reproducing a given portion of the upper tail of the parent distribution under different assumptions in other words while single bm can be sufficient to faithfully represent fz for e g t z 2 years under parent i id processes they might be not enough if the underlying process is persistent in the latter case discrepancies like those shown in fig 5 cannot be reduced by increasing the sample size but only increasing the number of lm or lowering the threshold thus including more information from the intermediate order statistics 5 f β b c compound f β b distributions explaining and generalizing mev under serial dependence 5 1 mev and its relationship with todorovic distributions a matter of compound distributions marani and ignaccolo 2015 proposed the so called metastatistical extreme value mev framework to model the distribution of block maxima y exploiting the distribution of the parent process z in finite size blocks in more detail denoting the parameter s of the parent distribution fz as θ the mev approach considers θ θ and the number of observations l l in blocks of finite size m as random variables with joint probability density function g l θ focusing on annual maxima this assumption accounts for the inter annual fluctuations e g koutsoyiannis 2004 note that a fluctuating number of observations in blocks with fixed size e g m 365 days refers to particular processes such as non zero daily rainfall or over threshold discharge records where the number of observations can change in every m size block under independence the mev cdf is therefore the unconditional probability distribution function of y resulting from marginalizing the distribution of y conditional on l l and θ θ i e p y z l l θ θ f y z l θ f z l z θ over g l θ 23 f y z l 0 ω θ f z l z θ g l θ d θ e f z l z θ e f b 0 l 1 f z z θ e f β f z z θ l 1 where ω θ is the state space of parameters θ and the latter equalities result from the identities f z l z θ f b 0 l 1 f z z θ f β f z z θ l 1 in eq 4 the mev cdf belongs to the well known class of compound distributions e g dubey 1970 van montfort and van putten 2002 that are in turn special cases of doubly stochastic processes i e processes in which both the parent random variables zi and parameters are stochastic processes e g tjøstheim 1986 thayakaran and ramesh 2017 compound distributions appeared in the literature under various names and contexts for example they have been re named as superstatistics in physics and hydrology beck 2001 de michele and avanzi 2018 porporato et al 2006 or as predictive distributions in bayesian inference renard et al 2013 the rationale of integrating over the parameter space was also applied without introducing any specific re labeling allamano et al 2011 botto et al 2014 in particular eq 23 highlights that mev is a compound f b or equivalently a compound fβ i e the expectation of the standard distributions of maxima for finite size blocks under independence unlike the bayesian context where g l θ is usually the empirical posterior distribution resulting from simulations via monte carlo markov chain mcmc algorithms in the mev approach g l θ is the sample distribution of the values of lj and θ j j 1 n y estimated in ny blocks of one year e g 365 days or 365 24 h therefore the theoretical mean can be approximated by the sample mean yielding 24 f y z e f z l z θ 1 n y j 1 n y f z l j z θ j 1 n y j 1 n y f b 0 l j 1 f z z θ j 1 n y j 1 n y f β f z z θ j l j 1 as mentioned in section 1 mev is strictly related to todorovic framework tf todorovic 1970 which reads as follows 25 f y z l 0 p i 0 l z i z l l l 0 p z 1 z z 2 z z l z l l p l l l 0 g l z θ g l e g l z θ where gl is the l dimensional joint distribution of z under independence g l f z l and tf corresponds to a simplified mev version with constant parameters θ i e standard f b under independence or the same mev is a version of tf with fluctuating parameters θ under independence on the other hand replacing f z l with a more general gl in eq 23 mev can be seen as a version of tf with fluctuating parameters θ under dependence or the same the expectation of tf in other words both tf and mev are compound distributions tf is the compound version of a general l dimensional joint distribution gl which is valid under dependence and includes f z l as special case and accounts for inter block fluctuations of l but not of θ mev is the compound version of f z l z θ f b 0 l 1 f z z θ which is valid only under independence and accounts for inter block fluctuations of l and θ a more general distribution of bm should combine the properties of tf and mev thus reading as the compound distribution of gl accounting for inter block fluctuations of l and θ this distribution is valid under independence and dependence like tf but accounts for inter block fluctuations of all parameters like mev it can be considered an extension of tf or mev by introducing very minor changes in these models although one can be tempted to call this distribution as extended tf or extended mev we think that it should be simply denoted as compound distribution of bm to highlight its meaning and rationale and avoid possible misunderstandings as well as the proliferation of uninformative names and acronyms denoting the same thing balazs et al 2007 nonetheless such a compound distribution involves an l dimensional multivariate distribution gl that makes its use rather unpractical especially when dealing with hydro climatic variables characterized by complex joint distributions with l 365 for example however as shown in section 5 2 using the generalized fy in eq 12 overcomes the problem by replacing the l dimensional gl with a one dimensional distribution this approach greatly simplifies the calculations avoiding to solve high dimensional integrals the cost is some loss of information as fy in eq 12 preserves only the serial correlation function i e second order joint moments thus missing higher dimensional correlation properties 5 2 introducing compound distributions f β b c for bm of correlated processes according to the parametrization in eq 23 under independence mev is a compound f b therefore a generalization is straightforward and consists in replacing f z l i e f b in eq 4 by f β b eq 12 under the assumptions discussed in section 2 2 and then integrating over the parameter space 26 f y z f β b c z l 0 ω ρ ω θ f β b 0 l 1 f z z θ ρ β b f z z θ ρ g l ρ θ d ρ d θ e f β b 0 l 1 f z z θ ρ β b f z z θ ρ 1 n y j 1 n y f β b 0 l j 1 f z z θ j ρ β b f z z θ j ρ j where ρ is correlation matrix of the parent process zi or wi introduced in section 2 2 of course eq 26 can be simplified assuming for instance that some parameter is constant for example we can assume that ρ does not change from year to year thus resulting in the expression 27 f β b c z l 0 ω θ f β b 0 l 1 f z z θ ρ β b f z z θ ρ g l θ d θ 1 n y j 1 n y f β b 0 l j 1 f z z θ j ρ β b f z z θ j ρ we numerically validated f β b c for a set of processes with lognormal marginals and ar 1 correlation structure we used lognormal marginals with location parameter μ ln 0 5 and scale parameter σ ln 0 2 1 2 4 corresponding to different distribution shapes i e weakly skewed bell shaped moderately skewed bell shaped and strongly skewed j shaped respectively fig s1 we considered three values of the ar 1 parameter ρ 1 0 3 0 6 0 9 and three different percentages of zeros p 0 0 0 0 3 0 7 to mimic zero inflated processes such as daily rainfall or stream flows of non perennial rivers this setting yields 27 different combinations that cover a wide range of distribution shapes degree of serial correlation and degree of zero inflation intermittency of practical interest lognormal ar 1 sequences have been simulated using the method described by papalexiou 2018 while zero inflation was obtained multiplying the simulated lognormal series by binary sequences with ar 1 correlation structure and ρ 1 0 5 serinaldi and lombardo 2017a 2017b thus introducing the required percentage of zeros in each m size block for the cases p 0 0 in order to generate series from processes with proper inter block fluctuations of the parameters we used a two stage procedure for each of the foregoing 27 combinations at the first stage we generated an auxiliary synthetic series of size 1000 365 mimicking 1000 years of daily records then we selected the 1000 blocks of size 365 and estimated all parameters of the parent lognormal process for each block this procedure yields 1000 values for each parameter of the parent lognormal process i e μ ln 1 μ ln 1000 σ ln 1 σ ln 1000 etc that describe their sampling distribution when the estimation is performed on 365 size blocks at the second stage we generated reference time series to be used in bm analysis by simulating lognormal processes with parameters changing every 365 size block in other words we used a set of parameters μ ln i σ ln i to generate a first sequence of 365 values another set μ ln j σ ln j for the subsequent 365 values and so on up to 1000 365 the resulting reference series follow processes with parameters fluctuating over 365 size blocks according to their sampling distributions results of the nine combinations of parameters corresponding to σ ln 1 2 moderate skewness are reported in fig 6 by quantile quantile q q plots comparing f β b c quantiles mev quantiles and simulated values according to the definitions in eqs 24 and 26 f β b c and mev are obtained as the averages of the bm distributions estimated over the 1000 365 size blocks of the simulated series results for σ ln 0 2 4 i e weakly and strongly skewed parent distributions are reported in figs s2 and s3 q q plots are shown both in log log scale to emphasize the behavior in the body of the distributions and in linear scale inset panels to emphasize the actual magnitude of differences for weak correlation fig 6a c show that f β b c and mev match as expected while fig 6d and g illustrate the increasing discrepancies between f β b c and mev as the degree of correlation increases for fixed correlation values zero inflation reduces the differences between f β b c and mev see fig 6d f and g i in this respect we note that the block size in fig 6a d and g i e the left column of panels is 365 while the average number of non zero observations for each block is l 365 0 7 255 5 in the middle column of panels i e fig 6b e and h and l 365 0 3 105 5 in the right column i e fig 6c f and i as l decreases the acf terms contributing to ρ are less and less and the simulated samples appear less and less correlated as the number of occurrences l is not enough to reveal the actual intensity and nature of the autocorrelation structure of the generating process therefore ceteris paribus the difference between compound bm distributions under independence mev and serial dependence f β b c decreases as l decreases actually this dichotomy is artificial as mev is a special case of f β b c when ρ 0 similar interpretation applies for weakly and strongly skewed distributions in figs s2 and s3 the distribution shape interacts with the effect of serial correlation the more less the skewness the more less compound distributions of bm under independence depart from those under serial dependence we stress that the foregoing analysis aims to reveal general theoretical behaviors and properties in a variety of cases i e distribution shapes degree of correlation and percentage of zeros comprising a broad range of real situations however in real world analysis the actual effectiveness advantage of using a more general model depends on several factors such as data availability data quality and accuracy required according to the aim of the study project in this respect the advantage of accounting for serial dependence should be evaluated case by case as obvious and f β b c is devised as a tool enabling this evaluation 5 3 reviewing simplified mev still a matter of compound distributions marra et al 2019 relaxed the assumption of identical distribution within each year or block thus assuming that the observations can correspond to different processes some examples are rainfall storms corresponding to frontal and convective meteorological systems or floods resulting from snowmelt and heavy rainfall following marra et al 2019 let us consider s types of processes z i with distributions f z i i 1 s with parameters θ i j at the jth year if the ith type of process is sampled l i j times during the jth year so that l j i 1 s l i j the mev cdf can be written as 28 f y z l 1 0 l s 0 ω θ 1 ω θ s i 1 s f z i l i z θ i g l 1 l s θ 1 θ s d θ 1 d θ s e i 1 s f z i l i z θ i 1 n y j 1 n y i 1 s f z i l i j z θ i j neglecting the inter annual variability of the parameters of f z i and the number of annual occurrences li marra et al 2019 proposed a simplified version of mev denoted as smev that reads as follows 29 f y z i 1 s f z i l i z θ i in order to introduce temporal correlation eqs 28 and 29 need to be rewritten in a suitable form highlighting the true nature of smev representation when a target process z e g rainfall results from the superposition of s processes z i by total probability theorem its distribution at jth year is a mixed distribution of the form 30 f z z π i j θ i j i 1 s π i j f z i z θ i j where π i j are weighting factors such that i 1 s π i j 1 the π i j factors can be estimated by the relative frequencies of occurrence of each process z i in a block of observations i e π i j l i j l j from eq 30 and recalling that f z l f b 0 l 1 f z z f β f z z l 1 see eq 4 eqs 28 and 29 become 31 f y z l 1 0 l s 0 ω θ 1 ω θ s f z l z π i θ i g l 1 l s θ 1 θ s d θ 1 d θ s e f z l z π i θ i 1 n y j 1 n y f z l j z π i j θ i j 1 n y j 1 n y f b 0 l j 1 i 1 s l i j l j f z i z θ i j 1 n y j 1 n y f β i 1 s l i j l j f z i z θ i j l j 1 and 32 f y z f z l z π i θ i f b 0 l 1 i 1 s l i l f z i z θ i f β i 1 s l i l f z i z θ i l 1 when the components f z i belong to the same family the mixed distribution in eq 30 is itself a form of compound distribution resulting from the weighted average of the distributions f z i defined over s classes of parameters with probability π i j l i j l j comparing eq 29 smev to eq 32 we have 33 smev i 1 s f z i l i z θ i i 1 s l i l f z i z θ i l f b 0 l 1 f z z π i θ i meaning that smev is nothing but the standard distribution of maxima in l size blocks under i id for a process with intra block mixed distribution therefore re naming the distributions in eqs 29 and 32 as smev might be inappropriate as they are standard f b distributions of order stastistics which are valid under i id for whatever parent distribution fz discrete continuous discrete continuous mixed etc moreover smev does not involve any compounding procedure to handle inter block variability which is the element characterizing mev we also note that the weighted average in eq 30 becomes an integral when the intra annual intra block variability is described by a continuous function e g a sinusoidal function as in allamano et al 2011 in other words highlighting that the distributions of order statistics are f b or fβ eqs 31 and 32 clarify the role of the parent distribution fz thus showing that it can incorporate whatever discrete or continuous intra annual pattern corresponding for instance to the alternation of s driving processes or smoothly varying seasonal fluctuations based on the type of support discrete or continuous the average intra annual distribution results from simple weighted averages or integration in other words the description of both intra block and inter block variability relies on the same rationale which is formalized by compound mixed distributions resulting from integration or simple weighted averaging eqs 31 and 32 allow a generalization for the case of serial dependence indeed recalling the discussion in section 2 2 and replacing f b with f β b a version of eq 28 under serial dependence is exactly eq 26 with intra block parent distribution given by the mixture f z j in eq 30 that is 34 f y z 1 n y j 1 n y f β b 0 l j 1 f z z π i j θ i j ρ β b f z z π i j θ i j ρ j while smev in eq 29 takes the form 35 f y z f β b 0 l 1 f z z π i θ i ρ β b f z z π i θ i ρ we do not assign any specific name label to the distribution in eq 35 in fact analogous to the identity smev f b under independence eq 35 is simply the f β b distribution of finite size bm under serial dependence for a process with intra block mixed distribution and is valid irrespective of the nature mixed or not of the parent distribution as for mev in section 5 2 f β b is numerically validated by simulating from known processes as proof of concept we used a mixture of two weibull distributions with cdf f wei z 1 exp z λ i κ i i 1 2 and parameters λ 1 11 7 κ 1 0 90 λ 2 4 11 κ 1 0 70 and fixed number of observations per block l 1 30 5 and l 2 17 9 these distributions were used by marra et al 2019 in their smev analysis and describe the typical observed conditions of daily rainfall corresponding to the two main intra annual synoptic weather systems driving precipitation over israel therefore the resulting mixed distribution describes the probability of a mixture of two intra annual processes z 1 and z 2 we considered the independent case to check the capability of f β b to reproduce correctly its special form f b smev along with a case involving ar 1 process with mixed weibull marginal distribution and gaussian copula with ρ 1 0 9 we stress that such a numerical example serves as an illustration of the correctness of the foregoing equations in presence of possible correlation keeping the other settings unchanged and it is not related to the data analysis discussed by marra et al 2019 analytical results for f b smev and f β b are compared with the numerical results obtained by monte carlo simulations in particular fig 7 compares analytical survival functions and the average of the empirical survival functions computed on 200 synthetic series of 1000 block maxima resulting from sequences of size 1000 365 drawn from the mixed weibull parent processes fig 7 confirms that f β b correctly describes the distribution of bm of a mixed distribution under serial dependence ρ 0 and independence ρ 0 in the latter case f β b becomes f b smev 6 proofs of concept on real world stream flow data 6 1 data for illustrative purposes we analyzed four daily stream flow time series listed in table 1 these flow records are extracted from the hydro climatic data network hcdn 2009 lins 2012 which is composed of 743 gauge stations maintained by the u s geological survey usgs hcdn 2009 includes quality controlled time series from stations that were screened to exclude sites where human or other activities affect the natural flow and with length sufficiently long for analysis of patterns in stream flow over time hcdn 2009 is specifically drawn to provide a stream flow data set suitable for analyzing hydrologic variations and trends in a climatic context lins 2012 a complete list of hcdn 2009 stations along with basic attributes can be found at the web site http water usgs gov osw hcdn 2009 while the data set is freely available at http waterdata usgs gov nwis sw 6 2 selecting the number of stream flow lm to approximate f z with specified accuracy the concepts presented in sections 3 and 4 are applied to study the daily stream flow records of the piscataquis river table 1 which is the longest time series in the hcdn 2009 database with 112 years of records with no missing values similar to volpi et al 2019 we only used the empirical cdfs data are transformed to normality by nqt i e φ 1 f n z the acf is estimated on transformed data after removing the seasonal components of mean and standard deviation to eliminate the inflating effect of the seasonal fluctuations of the marginal distribution on the acf see serinaldi and kilsby 2016 for further details this procedure does not remove intrinsic seasonal patterns of the acf not related to the fluctuation of the marginal distributions therefore empirical acf and fn z are used to estimate ρ β b and the distribution of am is computed by eq 12 based on the same reasoning used in section 4 the terms of the summation in eq 22 are then progressively added to fy in order to better approximate the portion of the upper tail of fz corresponding to t z greater than one and 0 5 years fig 8 reports the results in terms of return level plots i e t values versus discharges similar to fig 5 fig 8 shows that the theoretical t curve or cdf of am well reproduces the empirical t curve or cdf some bias is expected because the observed am are unavoidably identical to the upper quantiles of the empirical cdf of the parent z while the theoretical fy approaches to fz only asymptotically by the way uncertainty related to relatively small sample size should also be considered the t curve of am i e lm with k 1 departs from that of the parent process y for t 1 year while it cannot represent sub annual t values such as 0 5 years however increasing the number of lm for each block the t curves of lm i e gray curves approach to that of the parent process i e the target point in fig 8 the figure shows that k 7 and 10 lm or ot exceedances per year are needed to guarantee an accurate approximation of fz for t z 1 and 0 5 years respectively choosing smaller values for the number of ot exceedances is possible as the ot distribution follows the shape of fz in its entire range over the threshold corresponding to an average of k exceedances per block on the other hand if we use smaller k values the shape of the distribution of k lm introduces a departure from fz starting above the target t i e the point in fig 8 therefore the k lm value required to approximate the desired part of the upper tail of fz by the distribution of lm can be conservative if used to identify the number of ot exceedances needed to accomplish the same task in other words a slightly smaller average number of ot exceedances per year can be sufficient to approximate the desired part of the upper tail of fz however this aspect requires further investigation that goes beyond the aim of this study 6 3 analysis of stream flow annual maxima via f β b c for the sake of illustration f β b c has been tested on the stream flow records of the big creek wintering river and rio pueblo de taos table 1 these time series have been selected to fulfill some criteria firstly standard mev has been applied to data that are known to be approximately independent or weakly dependent such as rainfall at daily time scale e g zorzetto et al 2016 zorzetto and marani 2020 when independence is not a tenable assumption as for sub daily rainfall data are usually pre processed to select independent events observations e g hosseini et al 2019 marra et al 2018 miniussi et al 2020 on the other hand there is evidence that the marginal distribution of daily rainfall is well modeled by generalized gamma and burr xii distributions papalexiou and koutsoyiannis 2016 which encompass the weibull distribution as special case the latter has been widely used in rainfall modeling herr and krzysztofowicz 2005 wilson and toumi 2005 serinaldi 2009b and is the standard choice in mev superstatistical analysis applied to rainfall de michele 2019 de michele and avanzi 2018 marani and ignaccolo 2015 marra et al 2018 2019 zorzetto et al 2016 zorzetto and marani 2019 2020 dealing with stream flow serial dependence is usually stronger than that of rainfall the number of annual non zero observations is commonly constant and higher than that of non zero rainfall even in non perennial rivers and the identification of a unique general marginal distribution can be problematic because of the prominent effect of the seasonality and the complex filtering transfer and buffering processes characterizing hydrographic basins e g blum et al 2017 and references therein based on these remarks we selected three stream flow series referring to relatively small basins that are expected to fast react to rainfall impulses thus preserving some properties of the main driving process two of them big creek and wintering river are also intermittent thus showing varying number of non zero observation on an annual basis these properties make compound distributions suitable for the data at hand the aim of this analysis is to show the capability of f β b c to reproduce the empirical distribution of the am using all observations of the parent process and explicitly accounting for serial correlation without discarding any observation by e g over threshold selection and or declustering to fulfill the independence hypothesis required by standard evt methods or mev an empirical comparison of these approaches goes beyond the aim of this methodological study focusing on the big creek fig 9 a c show part of the time series from 2003 to 2013 included the average acf estimated on an annual basis and its 90 confidence intervals and the q q plot of the modeled f β b c annual maxima versus observed values and values resulting from f β b c with ρ β b 0 i e f b c or mev f β b c quantiles for a fixed probability are computed by a zero cross finding algorithm fig 9c shows that maxima in finite size blocks under serial dependence tend to be less extreme than those under independence conditions confirming the theoretical results reported in figs 6 and 7 in fact for persistent processes much more observations are required to cover their complete state space because of information redundancy and the corresponding reduced effective sample size similar remarks apply for the wintering river and rio pueblo de taos fig 9d i obviously neglecting serial dependence and applying f b c without pre processing data yield very different results as mentioned in section 5 2 the magnitude of such differences depend on the characteristics of the process at hand in the present case they results from the combination of very skewed marginal distributions and high persistence see acf in fig 9b e h and lag 1 and lag 2 acf values in table 1 these differences are consistent with those discussed in section 5 2 for theoretical lognormal ar 1 processes with similar properties 7 discussion and conclusions since extreme events are rare by definition the application of asymptotic extreme value theory evt generally relies on relatively small samples of block maxima bm or values over high thresholds ot therefore efforts have been made in the past to develop methodologies enabling the use of more information by including additional intermediate values or all available observations while it can be questioned whether intermediate values can provide direct information on extremes allowing for improvements of estimation accuracy they surely convey information about the underlying generating process and particularly on the possible presence of serial dependence which is known to affect finite size properties causing bias and variance inflation as discussed in section 1 1 the effects of serial correlation are well known and affect also clusters of extremes defined as exceedances of a given threshold therefore they have been studied rather extensively in classical asymptotic evt on the other hand non asymptotic models involving the largest and intermediate observations have generally been presented and applied under the assumption of independence although this assumption is even less tenable when dealing with the entire sequence of records especially for hydro climatic processes sampled at daily or sub daily time scales in fact when independence is not a realistic assumption the application of non asymptotic models requires the data to be pre processed by over threshold selection and or declustering similarly to evt models in this study we attempted to contribute in this respect by introducing a rather general univariate distribution of finite size order statistics under stationary serial correlation over m size blocks of observations whereby the corresponding m m correlation matrix has positive average this distribution is known in the literature as beta binomial f β b and specialized as the classical binomial f b distribution of order statistics under independence as the order statistics are the starting point of every asymptotic and non asymptotic extreme value model f β b plays a fundamental role for further developments in a variety of conceptual applications for example since bm are the largest order statistics f β b can be used to approximate the true m dimensional joint distribution required to compute the probability of bm preserving the second order joint moments i e the serial correlation function however f β b can be used in a variety of applications we discussed three of these potential applications firstly we showed how f β b can help providing theoretical explanation of the relationship and differences between the distribution of bm and that of the parent generating process in particular f β b allowed a deeper theoretical study of the differences between the return periods resulting from the analysis of bm and those of the entire process previously discussed by volpi et al 2019 we showed that such discrepancies are not due to sampling uncertainty but are intrinsic and explained by the different nature of the bm and parent processes along with the different failure scenarios described by their probability distributions these results further stress the importance of reasoning in terms of probability to draw correct interpretation of derived variables such as the return period secondly using f β b and f b and reasoning in terms of probabilistic scenarios provide a simple and clear explanation of the convergence of the upper tail of the bm distribution to the upper tail of the parent distribution this fact and the corresponding probabilistic formulation enables the derivation of some rules yielding the number of the largest maxima lm or ot values required to approximate the parent distribution with the desired level of accuracy for example these rules provide a theoretical support to the popular rule of thumb of using 3 ot values under independence on the other hand they also stress the requirement of a larger number of lm or ot values depending on the degree or extent of serial dependence as third conceptual application our theoretical results also shed light on existing non asymptotic models for extremes in particular reasoning in terms of f β b and f b reveals that the so called metastatistical extreme value mev distributions are compound f b accounting for inter block variability while the so called simplified mev smev is a standard f b for processes with mixed parent distribution accounting for intra block variability moreover interpreting mev and smev in terms of distributions of order statistics allows for a straightforward generalization incorporating the effect of serial correlation as discussed in section 5 1 in this context the most general non asymptotic model for bm is a compound m dimensional joint distribution that accounts for the serial correlation of the observations by a complete mutivariate distribution and for possible inter block fluctuations by compounding averaging over the parameter space existing methods such as mev so called todorovic distributions or the models by lombardo et al 2019 are special cases of such a general model however since such a joint distribution has usually high dimensionality e g up to 365 for annual blocks of daily observations and low tractability for practical implementation some simplifications are required in this respect lombardo et al 2019 specialized the todorovic distributions reducing the dimensionality by focusing on the bivariate case corresponding to first order markov processes on the other hand the compound version of f β b distribution f β b c proposed in this study allows the modeling of processes with more persistent serial correlation structures similar to the above mentioned exact m dimensional joint distribution and accounts for the inter block fluctuations of all parameters similar to mev however while preserving information concerning the second order joint moments i e the linear autocorrelation function f β b c unavoidably misses the information of higher order joint moments characterizing the joint distribution in other words tractability reduction of dimensionality and extension to strongly persistent processes is paid by accepting to focus on the autocorrelation rather than on the entire multivariate distribution this loss of information is not a true limit for many practical applications and it opens the door to the analysis of a variety of persistent processes such as stream flows without pre processing data based on the above remarks we analyzed river discharge time series characterized by non negligible serial dependence as a proof of concept of the theoretical results results confirm that the number of lm or ot values required to approximate the upper tail largest quantiles of the parent distribution increases when dealing with persistent processes due to information redundancy and reduced effective sample size we stress that such a better approximation is related to the increase of the number of lm per block on the other hand this improvement cannot be obtained by preserving the number of lm per block and increasing the sample size because the discrepancies between the lm and parent distributions are intrinsic and independent of sample size analyses based on f β b c show that such a model can reproduce the empirical distributions of bm of strongly persistent stream flow processes starting from the entire sequences of observations and without the need of pre processing the data in any way finally in this methodological study we showed only few conceptual examples of potential applications of the distributions of order statistics as well as the importance of interpreting the existing techniques in the consistent and unified framework of order statistics theory and compound distributions to avoid misleading conclusions clearly additional applications are possible and several problems deserve further investigation for example f β b can be used to improve existing estimation procedures based on order statistics that are currently available only under the assumption of independence makkonen and tikanmäki 2019 using models incorporating observations of the entire process also raises the problem of estimating a realistic parent marginal distribution in fact the latter cannot be described by standard distributions commonly applied in hydro climatic analysis because of the properties of the parent process such as seasonality and correlation itself more advanced models such as generalized linear additive models can be explored to accomplish this task credit authorship contribution statement francesco serinaldi conceptualization methodology software formal analysis writing original draft writing review editing visualization federico lombardo conceptualization methodology writing review editing chris g kilsby conceptualization writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements francesco serinaldi and chris g kilsby acknowledge the support from the willis research network federico lombardo is grateful to the italian national fire and rescue service for the continuous support the authors thank an eponymous reviewer dr marco marani università degli studi di padova and duke university and two anonymous reviewers for their critical remarks that helped substantially improve content and presentation of the original manuscript the analyses were performed in r r development core team 2019 appendix a derivation of eqs 6 and 7 let xi i 1 2 m be a sequence of correlated binary random variables taking the value 1 with probability p and the value 0 with probability 1 p and let e denote the expectation of a random variable the correlation ρij between xi and xj is defined as a 1 ρ i j e x i x j e x i e x j e x i 1 e x i e x j 1 e x j and the average correlation is i j ρ i j m m 1 as mentioned in section 2 2 compound distributions are a viable tool to accont for correlation with the foregoing settings and recalling that s i 1 m x i the beta binomial probability mass function f β b takes the form a 2 f β b p s s 0 1 f b i w f β w α β d w m s b s α m s β b α β the mean μ β b and variance σ β b 2 are a 3 μ β b e s m p σ β b 2 var s m p 1 p 1 m γ 1 γ where a 4 p α α β 1 p β α β γ 1 α β the parameter γ is a measure of the fluctuation of the rate of occurrence it is called as correlation level and γ 0 for case of pure binomial distribution hisakado et al 2006 our aim is to derive analytically the identity in eq 7 thus showing that the correlation ρij of a process with fixed p can be expressed in terms of α and β and therefore the known compound distribution of the sum of mixing independent binary variables with fluctuating rate of occurrence can serve to approximate the unknown distribution of the sum of serially correlated binary variables exploiting the identity of their mean and variance since the correlated variables xi have the same mean e x i e x p and variance var x i var x p 1 p we have a 5 e s m e x and a 6 var s m var x i j cov x i x j m var x i j e x i x j e x 2 m var x i j e x i x j m m 1 e x 2 from eqs a 3 a 5 and a 6 it follows that a 7 i j e x i x j m m 1 var s m var x m m 1 e x 2 σ β b 2 m p 1 p m m 1 p 2 γ 1 γ p 1 p p 2 using eqs a 1 a 4 and a 7 the average correlation becomes a 8 i j ρ i j m m 1 1 m m 1 i j e x i x j e x i e x j e x i 1 e x i e x j 1 e x j 1 m m 1 i j e x i x j p 2 p 1 p p 1 p 1 p 1 p i j e x i x j m m 1 1 p 1 p i j p 2 m m 1 1 p 1 p γ 1 γ p 1 p p 2 p 1 p γ 1 γ 1 α β 1 ρ β b which yields eq 7 using this result and recalling that p 1 f z the equalities in eq 6 readily follow from the first two equalities in eq a 4 appendix b dependence structures denoting the lag time as δ the fractional gaussian noise fgn also known as hurst kolmogorov process e g koutsoyiannis 2010 is characterized by the following acf b 1 ρ x δ 1 2 δ 1 2 h 2 δ 2 h δ 1 2 h which exhibits a power law decay ρ x δ δ 2 h 2 for 0 5 h 1 the process is positively correlated and exhibits long range dependence while it reduces to white noise for h 0 5 the discrete time ar 1 process is characterized by exponentially decaying acf of the form b 2 ρ x δ exp γ δ ρ 1 δ where 1 γ is the correlation radius and ρ 1 exp γ is the lag one autocorrelation coefficient the bivariate gumbel or gumbel hougaard copula has standard expression e g salvadori et al 2007 pp 236 237 b 3 c u v ξ e ln u ξ ln v ξ 1 ξ where u v 0 1 2 and ξ 1 is a dependence parameter related to the kendall correlation coefficient τ by the relationship b 4 ξ 1 1 τ the gumbel copula belongs to the class of extreme value copulas and its upper tail dependence coefficient is given by λ u 2 2 1 ξ the bivariate clayton copula has standard expression e g salvadori et al 2007 pp 237 240 b 5 c u v ξ max u ξ v ξ 1 0 1 ξ where u v 0 1 2 and ξ 1 is a dependence parameter related to the kendall τ by the relationship b 6 ξ 2 τ 1 τ the upper tail dependence coefficient of clayton copulas is given by λ u 0 the gumbel ar 1 and clayton ar 1 processes are simulated by using the conditional distribution of u i 1 given u i u i e g salvadori et al 2007 pp 209 210 b 7 c u i u i 1 p u i 1 u i 1 u i u i u i c u i u i 1 therefore a possible algorithm is as follows 1 generate independent variables u 1 and t from a standard uniform distribution 2 set u i 1 c u i 1 t where c u i 1 denotes the inverse of the conditional distribution in eq b 7 3 iterate steps 1 and 2 up to the desired step m 4 apply the quantile function f z 1 u i to obtain a sequence with the desired marginal distribution fz as closed form analytical expressions of the acf of gumbel ar 1 and clayton ar 1 processes are not available acf terms required for the analysis reported in section 2 2 are numerically derived by taking the average of the empirical acfs computed on sequences simulated from these processes appendix c derivation of eqs 19 21 for m 2 let us set f z c f z and g c g for ease of notation and recall that p z 1 c z 2 c 1 p z 1 c p z 2 c p z 1 c z 2 c 1 2 f z g under independence p z 1 c z 2 c p z 1 c p z 2 c and 1 2 f z g 1 2 f z f z 2 1 f z 2 according to de morgan s laws the disjunction of the negations is the negation of a conjunction then we have c 1 p z 1 c p z 2 c p z 1 c p z 2 c 1 p z 1 c p z 2 c 1 f z 1 f z 1 f z 2 1 f z 2 2 1 f z 1 f z 2 1 f z 2 p z 1 f z 2 p y for m 3 c 2 i 1 3 p z i c 2 i 1 3 p z i c p z 1 c p z 2 c p z 3 c p z 2 c p z 3 c p z 1 c p z 3 c p z 1 c p z 2 c 1 p z 1 c p z 2 c p z 3 c 3 1 f z 2 1 f z 3 3 1 f z 2 f z 1 f z 3 p z 2 1 f z 3 3 1 f z 2 f z p y for a generic m we obtain by induction c 3 p z p y 1 1 f z 2 for block size 2 2 1 f z 3 3 1 f z 2 f z for block size 3 3 1 f z 4 8 1 f z 3 f z 6 1 f z 2 f z 2 for block size 4 m 1 1 f z m m 2 m m 1 1 f z m 1 f z m 3 m m 2 1 f z m 2 f z 2 m 2 1 f z 2 f z m 2 for block size m the latter line in eq c 3 can be rewritten in a compact form as in eq 21 supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103686 appendix d supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 supplementary data s2 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s2 
414,groundwater being a vital component of the natural water resource system needs continuous monitoring and dynamic management strategies that said we require computationally inexpensive groundwater flow models for repetitive solutions with desirable accuracy under budgetary limitation s natural aquifer systems inherit strong heterogeneity at local scales in this work we have proposed ordinary kriging based sequential algorithm for generating replicates of randomly distributed heterogeneous hydraulic conductivity field monte carlo method based algorithm conditioned by field values from sampled locations in an irregular unstructured grid system finite volume method based groundwater models often encounter difficulties with the representation of point source sink terms operating within the domain in this paper we have proposed an irregular unstructured grid finite volume discretization technique for overcoming the singularity of point source sink term to yield a consistent output with different grid dimensions furthermore full system groundwater models often come with a substantial computational burden hence reduction in model order cuts down the computational expenses in terms of cpu time and usage to a significant level we have also put forth a model order reduction methodology for three different illustrative pumping tests the proposed framework for the model order reduction projects the governing groundwater flow equation onto a set of identified patterns or orthonormal basis functions applying the galerkin projection method to compute a vector of time dependent coefficients we have performed pattern identification by singular value decomposition svd of snapshots of full system model simulation data at selected time instants within the pumping test time domain the numerical results of the proposed reduced order models show a good approximation of the full system models at a comparatively lesser computational time the accuracy and efficiency of the models attempt to ensure their potential applicability for identifying groundwater dynamics keywords random heterogeneity finite volume method singular point source sink reduced order model proper orthogonal decomposition 1 introduction groundwater management framework requires the repetitive use of groundwater flow models for designing a sustainable policy with time scientists have developed several mathematical models to estimate the groundwater dynamics of different aquifer systems finite difference fd methods based models such as modflow mcdonald and harbaugh 1988 harbaugh et al 2000 harbaugh 2005 have wide applications in groundwater modeling as fd models work on a simple rectangular grid system the discretization of governing equations is very straightforward this makes the fd scheme popular among practitioners however the fd scheme fails to describe precisely the boundaries of domains with complex geometry which significantly affects the accuracy of model prediction near the boundaries although grid refinement can be a remedy for the incurred loss in accuracy mehl and hill 2002 it comes at the cost of increased computational expenses an improved version of the fd scheme the integrated finite difference ifd method also known as the control volume finite difference cvfd method has been used as well to analyze fluid flow in porous media narasimhan and witherspoon 1976 modflow usg panday et al 2013 a cvfd based unstructured grid version of modflow has been developed to solve tightly coupled multiple hydrological flow processes other numerical methods like finite element fe method reddy 2006 boundary element be method kobayashi and nishimura 1992 finite volume fv method leveque 2002 mazumder 2016 and different mesh free methods liu and gu 2005 have proved their relevance in modeling groundwater flow over time another attractive numerical method for groundwater modeling is the fe method the fe based commercial computer models like feflow diersch 2014 and femwater lin et al 1997 are also available for simulation of saturated unsaturated subsurface flow and transport nevertheless the accuracy of the fe method suffers due to its non conservative nature nowadays the fv method is gaining acceptance among emerging numerical methods because it is highly conservative moreover the fv method is also applicable to domains with complex geometries the fv method integrates the flow governing equations over the control volume of any shape and conserves the mass momentum and the energy entering and exiting a system fv models for groundwater flow applications have been developed for different regular and irregular unstructured grid systems loudyi et al 2006 dotlić et al 2016 in groundwater modeling a well is treated as a singular point source or sink moreover a well encountered in groundwater hydrology be it of recharging or extraction type is of vanishingly small radius in the order of 0 1 0 2 metres bear 1979 pinder and celia 2006 the drawdown inside such a small diameter well can be calculated neglecting the water derived from the storage inside the well papadopulos and cooper 1967 in numerical modeling a well is specified at the centroid of an element when the governing partial differential equation is discretized on a regular structured or unstructured grid using fd and cvfd schemes the problem arises during simulation of real life situations because the circumference of a well where the pressure gradient is maximum is practically very small compared to the area of the element containing it peaceman method defines the well block pressure in terms of the pressure in the neighbouring elements it is depicted to be numerically equal to the actual pressure at an effective radius of 0 2δx for regular square grid peaceman 1977 and 0 14 δ x 2 δ y 2 1 2 for regular rectangular grid peaceman 1983 systems however local grid refinement around a well can be considered to bring down the effective radius very close to the actual value on the other hand finer spatial discretization imposes several restrictions on temporal discretization to maintain stability of the numerical scheme this eventually increases the computational expenses turning it into an impractical attempt furthermore when irregular unstructured grid systems are considered the above considerations do not function as grid dimensions vary for each element thereby separate well models become a necessity different well models for standard fem control volume fem and mixed fem have been developed by chen and zhang 2009 the well model derived for control volume fem has been applied for cvfd scheme in modflow usg panday et al 2013 which is approximately equivalent to peaceman method applied for structured grids in previous versions of modflow regardless bringing down the effective well radius close to the actual radius value still remains an unanswered question the application of any groundwater flow model requires the identification of aquifer parameters such as the hydraulic conductivity field and the storage coefficients the primary means of aquifer characterization are on field pumping tests and numerical simulations as pumping tests are complex and expensive alternative economical methods based on particle size distribution rogiers et al 2012 and electrical resistivity tomography ert data yu and wu 2006 have been used to estimate field hydraulic conductivity one of the significant challenges faced in modeling groundwater flow through porous media is the mathematical replication of parameter heterogeneity inherent to transport media previously to avoid complexities the concept of equivalent porous medium was prevalent where the effects of heterogeneity were lumped into a single effective parameter which represented the medium yeh 1986 has modeled the field heterogeneity by dividing the flow regime into several sub regions where a constant hydraulic conductivity characterizes each region kriging is an important tool used in groundwater hydrology for distributing field information throughout the domain from limited data points the kriging estimates are highly influenced by the uncertainty of the semivariogram as it is determined on the basis of available sampled data the uncertainty of the model semivariogram can be quantified using random fields which is very essential for stochastic modeling lin and chen 2005 xu et al 2017 has shown the successful application of kriging based interpolation technique to determine spatial distribution of hydraulic conductivity obtained from resistivity and grain size data at sampled locations in reality aquifer parameters not only vary among different layers the variation within a particular layer is also of much significance the heterogeneity of a hydraulic conductivity field is stochastically best described by a log normal probability density function freeze 1975 a stochastic model of porous media considers hydraulic conductivity as a random variable greenkorn and kessler 1969 and the intrinsic heterogeneity as a space random function srf correlated in space and time bellin and rubin 1996 monte carlo method based sequential gaussian simulation is considered an efficient algorithm for the generation of random fields application of the monte carlo method to such srf field generation simplifies the intricacies associated with the replication of spatial variability of field heterogeneity however a significant limitation of the monte carlo method is that it converges slowly as o 1 n where n is the number of independent monte carlo realizations in order to obtain nearly accurate results we require a large number of monte carlo replicates of the random field which eventually increases the computation time of the model many effective commercial softwares are available for random field generation based on sequential gaussian simulation random surface generation rsg is a moving average method based software used for generating gaussian random surfaces to account for the topographic height variations over a surface bergström et al 2007 similarly random finite element method rfem is a fem based geotechnical modeling software which generates gaussian random fields for introducing random behavior of geologic formations smith et al 2013 on the other hand exhibiting the characteristics of a hydraulic conductivity field requires the generated field realization to be conditioned by field measurements conditional simulation of heterogeneous porous formations based on measured hydraulic conductivity or transmissivity data at few points of the formation have been successfully attempted delhomme 1979 dagan 1982 clifton and neuman 1982 tsai 2006 tbsim a computer program for conditional simulation of gaussian random fields emery and lantuéjoul 2006 is also available for simulating random fields conditioned by available data at selected locations by far stanford geostatistical modeling software sgems remy et al 2009 is the most productive conditional gaussian random field generator used to generate random fields replicating the properties of heterogeneous porous media although the aquifer is intrinsically heterogeneous in continuum approach to flow through porous media the parameters are considered to be homogeneous within a small volume known as representative elementary volume rev bear 1979 pinder and celia 2006 this implies that natural heterogeneous porous media is homogeneous at microscopic scale hence accurate mathematical formulations should consider a suitable rev for the conditioning data while generating fields that characterize natural geologic formations the accuracy of a groundwater model highly depends on the discretization of the spatial and the temporal domain finer the discretization more accurate are the model predictions this increases the computational expenses making it an inefficient one in the case of high dimensional models therefore the focus should be on the development of a model that optimizes both the efficiency parameters accuracy and computation time scientists of various genre have acclaimed the model order reduction methodology based on data driven pattern identification techniques in different fields of scientific study over the past few decades sirovich 1987 park and cho 1996 park et al 1999 haasdonk and ohlberger 2011 hasenauer et al 2012 dehghan and abbaszadeh 2018 abbaszadeh and dehghan 2020 the method projects the governing equation onto a reduced sub space of identified patterns thereby cutting down the number of algebraic equations to be solved for each temporal iteration vermeulen et al 2004 made the first attempt towards low dimensional modeling of groundwater flow systems since then model reduction technique has been applied to modeling of groundwater flow through both confined pasetto et al 2011 2013 boyce and yeh 2014 and unconfined aquifers boyce et al 2015 stanko et al 2016 groundwater contamination problems ilati and dehghan 2016 kani and elsheikh 2019 and groundwater optimization and management studies mcphee and yeh 2008 baú 2012 in reduced order modeling snapshot selection is the key to pattern recognition hence the temporal distribution of snapshots for groundwater flow systems siade et al 2010 should be chosen wisely the applications of model order reduction for characterizing aquifer dynamics are limited to fd and fe methods till date as the fv method is a highly useful tool for pde discretization reducing the degrees of freedom involved in the classical approach will help in minimizing the computational complexities in this paper we have presented an fv based computationally inexpensive mathematical model for evaluating the dynamics of groundwater flow through a heterogeneous confined aquifer subjected to singular point source sink in the first step we have developed a fast effective and accurate algorithm for generating spatially correlated and randomly distributed heterogeneous hydraulic conductivity field based on available field values from sampled locations by integrating the concept of rev into standard sequential gaussian simulation technique we have developed the field for an irregular unstructured grid system to facilitate the application of advanced numerical tools secondly we have presented an fv formulation to estimate the groundwater response through the generated random heterogeneous field subjected to singularity of point source sink in the proposed methodology we have considered the actual radius of the well which is independent of the grid dimensions we have carried out a separate study of the proposed fv based full system model through a homogeneous confined aquifer to compare the performance of the model with modflow simulation results finally we have performed pod based reduced order modeling to minimize the computational expenses in terms of cpu time and usage acquired by the proposed fv based full system model 2 random heterogeneous field generation technique in this section we have introduced an ordinary kriging based sequential gaussian simulation technique to generate a random hydraulic conductivity field in an irregular unstructured grid system ordinary kriging is a geostatistical method for interpolating a variable value at any desired location within the domain based on available neighborhood data goovaerts 1997 to integrate the influence of homogeneity at the scale of rev we have introduced a set of area coefficients along with the set of kriging coefficients used in usual ordinary kriging method as a result we have a new non bias condition which includes both the area coefficients and the kriging coefficients 2 1 basis points in this approach we have considered a set of basis points whose values have been used for conditioning the estimated values we have assumed a physical domain ω with field hydraulic conductivity values k α i available at n 1 sampled locations acting as the primary basis points initially we have assigned an influence zone for each sampled location over which we have assumed the corresponding field hydraulic conductivity value to be constant we have adopted voronoi tessellation method for the above zonation procedure the voronoi polygon area corresponding to ith sampled location is a α i i 1 n 1 furthermore we have overlaid an irregular unstructured grid system with n 2 elements on the domain ω the area of the jth discretized element is denoted by a β j j 1 n 2 which is considered to be the rev for the hydraulic conductivity value k β j estimation at the centroid of the element the estimates of hydraulic conductivity for these n 2 elements are determined based on the available field values at n 1 basis points as conditioning data assuming hydraulic conductivity to vary log normally freeze 1975 we have defined two variables z α i and z β j as 1 z α i ln k α i i 1 n 1 2 z β j ln k β j j 1 n 2 2 2 search neighborhood here we have followed an a priori determined random sequential arrangement of the elements for the generation of each monte carlo replicate of the hydraulic conductivity field such an approach enhances randomness within the generated field we have considered two different categories of conditioning data i available hydraulic conductivity values from primary basis points ii values from the secondary set of basis points that include elements with previously generated hydraulic conductivity estimates unavailable for initial estimates hence we have considered two different sized search neighborhoods for selecting the above two categories of conditioning data fig 1 we have approximated an initial search radius r 1 for selecting the primary conditioning data as isaaks and srivastava 1989 3 r 1 i 1 n 1 a α i n 1 we have incremented the search radius by ϵ r as long as a pre defined number of conditioning data are not selected however we have considered the search radius for the second category of conditioning data to be constant for the entire procedure we have assumed the characteristic length used for irregular unstructured grid generation as the equivalent search radius r 2 for the secondary basis points by this approach we have attempted to optimize the search neighborhood for computational efficiency without sacrificing the accuracy of the estimates 2 3 conditional mean and variance let us assume that the neighborhood encloses m 1 primary basis points with corresponding logarithmic values of field hydraulic conductivity z α r where r 1 m 1 and m 2 secondary basis points with previously generated conditional estimates z β s where s 1 m 2 for the kth element we have generated the conditional estimate of hydraulic conductivity for the kth element from a standard random generator which generates random values following normal distribution with conditional mean mc and conditional variance σc 2 as target statistics bellin and rubin 1996 we have calculated the conditional mean mc as 4 m c m u c r 1 m 1 ϕ α r λ α r z α r m u c α s 1 m 2 ϕ β s λ β s z β s m u c β where muc α muc β and muc respectively are area weighted unconditional means based on primary data secondary data and their combination available within the neighborhood and can be represented as the following 5 m u c α r 1 m 1 z α r a α r r 1 m 1 a α r 6 m u c β s 1 m 2 z β s a β s s 1 m 2 a β s 7 m u c r 1 m 1 z α r a α r s 1 m 2 z β s a β s r 1 m 1 a α r s 1 m 2 a β s we have calculated the conditional variance σc 2 as 8 σ c 2 σ u c 2 r 1 m 1 ϕ α r λ α r γ z α r z β k s 1 m 2 ϕ β s λ β s γ z β s z β k where σuc 2 and m respectively are area weighted unconditional variance and mean calculated based on all available primary data over the entire domain and can be expressed as the following 9 σ u c 2 i 1 n 1 a α i z α i m 2 i 1 n 1 a α i 10 m i 1 n 1 a α i z α i i 1 n 1 a α i 2 4 area weighting coefficients we have introduced a set of area weighted coefficients ϕ α r and ϕ β s which are calculated as 11 ϕ α r a α r r 1 m 1 a α r r 1 m 1 12 ϕ β s a β s s 1 m 2 a β s s 1 m 2 2 5 semivariogram model a continuous function has to be fitted to the experimental semivariogram goovaerts 1997 to calculate the covariance or semivariogram values for any lag distance h the best fit function also known as the model semivariogram is used for the kriging method we have selected an unbounded semivariogram with power law dependence of variance γ on lag distance h 13 γ h c h ω we can consider a porous medium as a distribution of interconnected channels with random obstructions at different length scales between them fractal geometry is an emerging mathematical tool for studying the behavior of irregular geometric objects and has been successfully applied to porous geological formations to determine its fractal nature adler and thovert 1993 moreover the application of fractal geometry at the micro scale level has also simplified the problems of spatial heterogeneity characterization of porous media and transport phenomenon through the same sahimi and yortsos 1990 a self similar fractal field requires the correlation of the hydraulic conductivity values over greater lengths and this unbounded power law semivariogram model 13 stands out as the appropriate choice furthermore for ω 1 the field shows smooth variation and looks highly realistic 2 6 determination of kriging coefficients we can express the error variance for conditional estimation of hydraulic conductivity for the kth element as 14 σ e r r o r 2 v a r z β k z β k v a r z β k v a r z β k 2 c o v z β k z β k r 1 m 1 s 1 m 1 ϕ α r λ α r ϕ α s λ α s c z z α r z α s r 1 m 1 s 1 m 2 ϕ α r λ α r ϕ β s λ β s c z z α r z β s r 1 m 2 s 1 m 1 ϕ β r λ β r ϕ α s λ α s c z z β r z α s r 1 m 2 s 1 m 2 ϕ β r λ β r ϕ β s λ β s c z z β r z β s c z 0 2 r 1 m 1 ϕ α r λ α r c z z α r z β k 2 s 1 m 2 ϕ β s λ β s c z z β s z β k ordinary kriging produces estimates with minimum estimation error variance for constraining the minimization problem we have defined the non bias condition comprising the kriging and area coefficients for both the primary and secondary data as the following 15 r 1 m 1 ϕ α r λ α r s 1 m 2 ϕ β s λ β s 1 here we have introduced a lagrange multiplier μ for converting the constrained minimization problem into an unconstrained one and have defined a new function for error variance as 16 l σ e r r o r 2 2 μ r 1 m 1 ϕ α r λ α r s 1 m 2 ϕ β s λ β s 1 the minimization of the new error variance function yields a set of m 1 m 2 linear algebraic equations the set of first m 1 equations obtained from the condition l λ α r 0 is as follows 17 s 1 m 1 ϕ α s λ α s γ z α p z α s s 1 m 2 ϕ β s λ β s γ z α p z β s μ γ z α p z β k for p 1 m 1 the next set of m 2 equations obtained from the condition l λ β r 0 is as follows 18 s 1 m 1 ϕ α s λ α s γ z β q z α s s 1 m 2 ϕ β s λ β s γ z β q z β s μ γ z β q z β k for q 1 m 2 the ordinary kriging coefficients and the lagrange multiplier μ have been calculated by simultaneously solving the set of m 1 m 2 equations 17 and 18 and the non bias condition 15 as the spatial configuration of the conditioning data for any element is not constant for an irregular unstructured grid system we need to compute the ordinary kriging coefficients repeatedly for every element 3 governing equation the transient saturated groundwater flow through a heterogeneous and isotropic confined aquifer with extraction is governed by bear 1979 19 s s s a x t t k s a x t w s i n s x t δ x x i t 0 x ω t 0 t f i n a l s a x t h 0 z a x t we have considered the extraction well to be fully penetrating to ensure horizontal flow and constant extraction rate throughout the time domain as we have ensured the flow to be horizontal we have defined depth averaged drawdown in the governing equation eq 19 thereby reducing the flow in two dimensional space the governing equation is subjected to the following initial and boundary conditions initial condition 20 s a x 0 s a 0 x dirichlet boundary condition 21 s a x t s a d x t x γ d ω neumann boundary condition 22 k s a x t n q n x t x γ n ω where k k x 0 0 k y 4 finite volume discretization the cvfd scheme used in modflow usg panday et al 2013 has a geometric constraint that the line joining the centroids of the two adjacent elements has to perpendicularly bisect the common face narasimhan and witherspoon 1976 this geometric requirement is satisfied by grids composed of equilateral triangles rectangles or other regular higher order polygons and unstructured grids formed by voronoi tessellation while dealing with real life problems the grids generated do not always conform to the cvfd criteria and subsequent error creeps into the solution in order to reduce the error the ghost node correction gnc package is implemented in modflow usg which eventually increases the computation time however the fv method completely overcomes this potential source of error arising due to the geometry of the discretized elements by considering a tangential flux term a tangential flux is generated whenever a line joining the centroids of two adjacent elements is not a perpendicular bisector of their common face hence we have preferred this approach because of its flexibility and mass conservative nature in this section we have illustrated an fv discretization approach for the governing partial differential equation of confined groundwater flow in this approach we have considered the singular point source sink terms separately for their respective operating nodes the integration of 19 without the point source sink term over the volume of an element vβ and time step δt and subsequent application of gauss divergence theorem yields 23 t t δ t v β s s s a t dv dt t t δ t a f k s a n da dt t t δ t v β w s dv dt discretization of eq 23 for a triangular element in an irregular unstructured grid produces the following 24 s a β i s a i 0 k 1 s a i 0 k δ t f 1 3 t f s a f n f l f w s a β i b where s s s b t f k f b we have used the superscript for representing the time level of the temporal discretization and the subscript 0 to designate the element centered values of a variable 4 1 gradient approximatio the gradient term sa f at the face f can be decomposed into two components from the point of intersection of the line joining the centroids of the parent and the adjacent neighbor element one normally outward to the face and the other tangentially along the face fig 2 25 s a f s a f n f n f s a f t f t f a dot product of eq 25 with the vector if and subsequent rearrangement of the terms yields the following 26 s a f n f s a f i f δ n f s a f t f δ t f δ n f after performing the dot products of the gradient term sa f with if and t f in eq 26 the final approximation of the gradient term becomes 27 s a f n f s a f 0 s a i 0 δ n f s a f 1 s a f 2 l f δ n f δ t f we have used the subscripts 1 and 2 for implying the values at the two nodes of the face f that distinguish the nodal values from the element centered values designated by the subscript 0 4 2 face centered approximation of hydraulic conductivity the fv formulation of groundwater flow in an irregular unstructured grid system requires an interpolation of the face centered hydraulic conductivity from adjacent element centered values we have performed inverse distance weighted interpolation for determining the face centered hydraulic conductivity because it is second order accurate and has certain advantages over other methods mazumder 2016 we can write the interpolation equation as the following 28 k f w f k i 0 1 w f k f 0 where 29 w f 1 d 1 1 d 1 1 d 2 4 3 interpolation of element centered values to nodal values post processing of the fv algorithm needs an interpolation of nodal values from the calculated element centered values we have computed the nodal values using area weighted interpolation as 30 s a f n i 1 n p w n i n s a i 0 where 31 w n i n a β i i 1 n p a β i 4 4 discretization for all internal elements we have deduced the fv discretized form of the governing equation for all internal elements as 32 s a β i s a i 0 k 1 s a i 0 k δ t f 1 3 t f s a f 0 s a i 0 δ n f s a f 1 s a f 2 l f δ n f δ t f l f w s a β i b f 1 3 t f l f δ n f s a f 0 s a i 0 f 1 3 t f δ t f δ n f s a f 1 s a f 2 t a n g e n t i a l f l u x w s a β i b in the equation above 32 we cannot calculate the tangential flux term directly therefore further approximation is needed interpolating the drawdown at each node from the drawdowns of all the associated elements by eq 30 we have expanded the tangential flux term as 33 f 1 3 t f δ t f δ n f s a f 1 s a f 2 t 2 δ t 2 δ n 2 t 3 δ t 3 δ n 3 l 1 1 n e 1 s a l 1 0 w n l 1 1 s a i 1 t 3 δ t 3 δ n 3 t 1 δ t 1 δ n 1 l 2 1 n e 2 s a l 2 0 w n l 2 2 s a i 2 t 1 δ t 1 δ n 1 t 2 δ t 2 δ n 2 l 3 1 n e 3 s a l 3 0 w n l 3 3 s a i 3 applying θ scheme for temporal discretization we can write the final approximation of eq 32 as 34 a i s a i 0 k 1 f 1 3 b i f s a f 0 k 1 m 1 3 d i l m l m 1 n e m s a l m 0 k 1 w n l m m f i where a i s a β i θ δ t f 1 3 t f l f δ n f b i f θ δ t t f l f δ n f for f 1 2 3 d i l 1 θ δ t t 2 δ t 2 δ n 2 t 3 δ t 3 δ n 3 d i l 2 θ δ t t 3 δ t 3 δ n 3 t 1 δ t 1 δ n 1 d i l 3 θ δ t t 1 δ t 1 δ n 1 t 2 δ t 2 δ n 2 f i s a β i θ 1 1 θ a i s a i 0 k 1 1 θ f 1 3 b i f s a f 0 k m 1 3 d i l m l m 1 n e m s a l m 0 k w n l m m w s a β i b δ t 4 5 discretization for extraction well node in this work we have presented a generalized fv scheme for confined groundwater flow with singular point source sink in an irregular unstructured grid system here we have specified the wells at the nodes in the grid system an important aspect considered in this formulation is the selection of actual well radius for the calculation of drawdown at the well node and not the effective radius calculated by any well model this ensures that the well radius is independent of the grid dimension unlike in modflow usg where it is dependent on grid dimensions a linear aquifer loss coefficient which accounts for the head loss in the well node due to the differences in actual and effective well radius has been applied for multi node wells in modflow usg however single node wells simulated by the basic well wel package lacks this correction hence the selection of actual well radius rules out the issues of grid convergence that may arise with changing grid dimensions assuming the flow to be radial in the neighbourhood of a well the drawdown at a well is calculated by solving the continuity equation at that well node for every time step the radially inward flow from the centroids of all the elements associated with the well node are equated with the extraction rate we have calculated the inward flux through the arc subtended by the well for each element associated with the well node fig 3 as thiem 1906 35 f i φ i t i 0 s a w s a i 0 ln r i r w we can present the continuity equation at the extraction well node as follows 36 i 1 n p f i q p 0 on substituting eq 35 in eq 36 and rearranging the terms we get 37 i 1 n p φ i t i 0 ln r i r w s a w k 1 i 1 n p φ i t i 0 ln r i r w s a i 0 k 1 q p 0 4 6 discretization for elements associated with the extraction well node the elements associated with the extraction well node have an additional flux term directed radially towards the node the final discretized form after applying the θ scheme for temporal averaging is as the following 38 a i p s a i 0 k 1 f 1 3 b i f p s a f 0 k 1 c i p s a w k 1 m 1 3 d i l m p l m 1 n e m s a l m 0 k 1 w n l m m f i p where a i p a i θ δ t φ i t i 0 ln r i r w c i p θ δ t φ i t i 0 ln r i r w f i p f i 1 1 θ c i p s a w k however the coefficients b i f p d i l 1 p d i l 2 p and d i l 3 p are respectively equal to b i f d i l 1 d i l 2 and d i l 3 from eq 34 4 7 boundary conditions in groundwater flow problems we come across three types of boundary conditions dirichlet or specified head boundary condition neumann or specified flux boundary condition and cauchy boundary condition in the dirichlet boundary the hydraulic head is either constant or specified as a function of space and time for each dirichlet boundary element we need to specify the heads for the two nodes lying on the boundary however for a neumann boundary element the normal flux through the face s coinciding with the boundary is are specified an impermeable boundary is a particular case of neumann boundary condition where the specified normal flux through the boundary face is zero moreover the cauchy boundary condition can be considered as an imposition of both dirichlet and neumann conditions on the boundary elements the fv discretization equations for the elements associated with both dirichlet and neumann boundaries are presented in the supplementary information appendix sa1 5 reduced order modeling model order reduction is a computationally efficient technique used for solving any full scale model in this section we have presented a reduced order groundwater flow model applying the standard pod formulation since fv method is highly conservative in nature application of pod to the proposed fv formulation of groundwater flow equation through heterogeneous porous media is expected to yield extremely satisfactory results the reduced order model approximates the state variable as the product of an orthogonal matrix p x and a time dependent coefficient vector rn t as 39 s a x t p x r n t 5 1 snapshot selection model order reduction methodology starts with a collection of scenarios known as snapshots that tend to describe the dynamics of the system with time a snapshot matrix stores the solutions of a full system groundwater model at some pre defined time instants we require a careful study of the nature of the governing equation and the evolution of its solution with time for determining the snapshot time set for groundwater flow problems we have selected the snapshot time set by the following exponential function 40 t s i 0 i 1 1 tanh t s 1 u i otherwise where u i i 1 n t s 1 the snapshot matrix ssnap has been formed from the solutions of eq 19 for different time instants given by the time set t s the required number of sets of snapshots depends on the number of linearly independent constant or variable forcing agent extraction well operative within the domain if multiple forcing agents are present a single set of snapshots has to be collected separately for each of them each set should have the solutions of the model with one forcing agent operative at a constant rate while others are remaining completely inoperative we have represented the complete snapshot matrix as s snap j s a t s 1 s a t s 2 s a t s 3 s a t s n t s j 1 2 3 n s e t 41 s snap s snap 1 s snap 2 s snap 3 s snap n s e t 5 2 formation of the pod basis for orthonormalization of the above snapshot matrix we have performed singular value decomposition svd of ssnap as 42 s snap u σ v t after svd the matrix u containing the left singular vectors of ssnap represents the orthogonal matrix p x from eq 39 also known as the pod basis accordingly we can call the left singular vectors as the pod basis vectors among all pod basis vectors only a few contributes significantly to maximum information regarding system dynamics we have chosen the basis vectors corresponding to the singular values satisfying the following relationship for the construction of the final pod basis 43 i 1 n p σ i i 1 r a n k s snap σ i 100 99 99 5 3 galerkin projection we have denoted the matrix form of the discretized governing eq 24 as 44 a s a f we have split the above equation into two parts whereby we have separated the extraction well nodes from the elements we can write the partitioned equation as a e a p t a p a p s a e s a p f e f p 45 a e s a e a p t s a p f e 46 a p s a e a p s a p f p the eq 45 corresponds to the drawdowns at the elements we have solved this equation by projecting it onto a reduced sub space of pod basis via galerkin projection however we have calculated the drawdown at the extraction well nodes by solving eq 46 explicitly for each time step in order to initiate the iteration we have assumed the full system solution at a very early time step in the range of 10 5 as the initial guess vector the galerkin projection of eq 45 has been performed by substituting eq 39 to form the following a e p r n f e a p t s a p p t a e p r n p t f e a p t s a p 47 r n p t a p 1 p t f e a p t s a p the resulting vector rn has been substituted in eq 39 to obtain the reduced order solution at the element centroids we have then substituted the solution vector sae in eq 46 to estimate the drawdown at the extraction well locations at the end of each time step 6 numerical tests 6 1 tc1 random hydraulic conductivity field generation in order to demonstrate the applicability of the heterogeneous field generation algorithm proposed in section 2 we have utilized a two dimensional synthetic square shaped confined aquifer with sides 3200 m and depth 50 m tsai 2006 we have considered the specific storage coefficient of the aquifer to be 10 4 m in order to condition the estimates of hydraulic conductivity we have obtained field values from 75 sampled locations within the aquifer fig 4 shows the 75 sample locations with respective field hydraulic conductivity values and their corresponding zones formed after voronoi tessellation we have computed the experimental semivariogram with these measured field conductivities and have fitted a power law model semivariogram eq 13 with parameters c 10 4 and ω 1 2462 we have then discretized the aquifer into 2398 nodes with 5690 triangular elements we have evaluated the estimates of hydraulic conductivity for these triangular elements by algorithm 1 with the following input parameters n c min 5 m 1 max 5 m 2 max 5 ϵ r 100 m and r 2 70 m for each field replicate the initial estimates have entirely been conditioned by primary basis data searched over large neighborhoods due to the unavailability of secondary basis data such estimates are thus bound to be very rough ones however the random sequence adopted for the estimation of each field realization ensures smoothening of these rough estimates when a large number of replicates are generated the effects of local integration over discretization have been insignificant as the correlation length for the unbounded power law semivariogram is very large compared to the characteristic length used for grid generation ababou 1988 we have displayed the contour diagram of the mean log hydraulic conductivity field averaged over 104 monte carlo simulations in fig 5 a the contour plot of estimation error variance fig 5b shows minimum variance around the central region of the aquifer where the primary conditioning data was available in abundance the maximum error variance is in the range of 0 05 to 0 07 and is observed along the left boundary and near the bottom right boundary where the density of available primary basis points was the least 6 2 tc2 transient groundwater flow model with a single extraction well in a homogeneous confined aquifer we have tested the fv formulation of the full system groundwater model and the proposed reduced order model on the synthetic confined aquifer described in tc1 we have assumed the aquifer to be homogeneous with a constant value of hydraulic conductivity 50 m day throughout the entire domain we have considered zero dirichlet boundary conditions on all the boundaries of the confined aquifer an extraction well extracting at a constant rate of 104 m 3 day is located at the center of the aquifer we have discretized the aquifer into 2851 nodes with 5516 triangular elements we have performed a pumping test of 15 days duration we have assumed a small diameter well of radius 0 1 m for all the test problems we have observed the system to achieve steady state conditions after 5 days of extraction from the drawdowns recorded figure sf2b at three different locations within the aquifer figure sf2a we have compared the performance of our proposed fv based full system model fsm with the results of modflow usg simulations for tc2 we have carried out the simulations on a square grid system in modflow usg using different grid dimensions we have used the well wel package for carrying out the simulations we have observed that the drawdown at the well location is inconsistent with changing grid dimensions this can be attributed to the fact that the effective well radius considered in the calculation changes with varying grid dimensions we have applied grid refinement around the well using modflow lgr so that the effective well radius approaches toward the actual well radius however the grid refinement operates at the expense of cpu computation time the results of our proposed fv based fsm closely agrees with modflow usg when the effective well radius is almost equal to the actual well radius fig 6 claims that our proposed fv based fsm offers better grid convergence than modflow usg using the well wel package the drawdown calculated at the well location for different grid dimensions using modflow usg and proposed fv based fsm are tabulated in table 1 along with the respective cpu computation times next we have taken 10 snapshots calculated at various time instances by eq 40 for the reduced order model rom we have computed the snapshots at an increased extraction rate of 5 104 m 3 day for obtaining a significant response from every part of the aquifer this has helped us in profoundly identifying the patterns of the system response the pod basis computed from the snapshot matrix comprises 9 vectors therefore for every time step the rom needs to solve 9 equations as compared to 5516 by the fsm as a result we can ensure a significant reduction in computation time and cpu memory usage the rom replicates the fsm with a maximum absolute error of 4 2 10 5 m from the entire domain the other error statistic parameter values tabulated in table 2 also determine the accuracy of the rom and justify its applicability as an alternative for the fsm we have shown the comparison of drawdown contours calculated by the fsm and the rom after 15 days of constant extraction in fig 7 while discretizing the governing equation for all the test problems we have adopted the crank nicholson scheme θ 0 5 for temporal averaging 6 3 tc3 transient groundwater flow model with a single extraction well in a heterogeneous confined aquifer in tc3 we have solved the problem in tc2 assuming the confined aquifer to be heterogeneous we have generated a randomly distributed heterogeneous hydraulic conductivity field based on the field values from 75 sampled locations tc1 following algorithm 1 we have performed the pumping test for 30 days we have observed the system to attain steady state conditions approximately within 10 days from the commencement of the pumping test figure sf2c hence we have captured 20 snapshots of the fsm within that interval for pod basis calculation here again we have calculated the snapshots at an enhanced extraction rate of 5 104 m 3 day we have computed a pod basis of 12 vectors from the snapshot matrix we have presented in fig 8 the comparison of drawdown contours at the end of the pumping test for the fsm and the rom the results imply that the accuracy of the rom reduces in replicating the dynamics of the aquifer due to the incorporation of random heterogeneity the maximum absolute error of estimation has been reduced to 4 2 10 4 m in comparison to tc2 we have observed the absolute estimation error to be more in the top right corner and bottom left corner of the field compared to the other parts analysing the hydraulic conductivity field we can infer that the estimation error over the domain is higher in the zones of low hydraulic conductivity fig 10a however the plot of absolute nodal error distribution in fig 10b shows that the absolute error for more than 90 of the domain has been less than 10 4 m hence we can consider the rom to be capable of reproducing the fsm for a randomly distributed heterogeneous confined aquifer 6 4 tc4 transient groundwater flow model with multiple extraction wells in a heterogeneous confined aquifer in tc4 we have intensified the complexity of the problem by introducing multiple extraction wells and neumann boundary in the synthetic confined aquifer illustrated in tc1 we have considered zero dirichlet boundary condition on the left boundary of the aquifer while the other three boundaries are assumed to be impervious we have assumed the depth of the aquifer to be 100 m three extraction wells located at 1650 1250 1050 1950 and 2250 1950 figure sf3a have been operated at a constant rate of 5 103 m 3 day throughout the duration of the 90 days pumping test we have discretized the aquifer into 2884 nodes with 5582 triangular elements and we have generated a randomly distributed heterogeneous hydraulic conductivity field following algorithm 1 similar to the one conducted in tc3 in order to determine the approximate steady state time we have compared the drawdowns at 6 locations within the domain figure sf3a we have conducted 3 separate runs of the fsm one extraction well being operated at a time while the others wells remaining inoperative from figures sf3b sf3c and sf3d we have estimated that the system attains steady state conditions approximately after 75 days of constant extraction the snapshot selection strategy in this case has been different from the previous two cases as multiple extraction wells are operating simultaneously here we need to record the response of the system separately for each time invariant and linearly independent forcing agent we have captured 75 snapshots of the system dynamics separately for each extraction well considering it to be extracting at an enhanced rate of 5 104 m 3 day while others are inoperative during that time period we have combined the 3 sets of snapshots to form the final snapshot matrix consisting of 225 drawdown vectors singular value decomposition of the final snapshot matrix identifies 20 principal modes to be dominant that constitute the pod basis in fig 9 we have displayed the comparison of drawdown contours for the fsm and the rom after 90 days of constant extraction we have observed that the accuracy of rom is reducing with the increase in complexity of the boundary conditions as the maximum absolute error has increased to 3 6 10 3 m we have discovered the accuracy of the rom to be significantly high near the dirichlet boundary which reduces gradually while moving towards the impervious boundaries fig 10c in tc4 the estimation errors are dominant near the neumann boundaries whereas in tc3 the low hydraulic conductivity zones primarily account for the errors in estimation analyzing the estimation errors for tc2 tc3 and tc4 we can comment that the accuracy of the rom is affected more by the neumann boundaries than by the heterogeneity of the conductivity field the plot of absolute nodal error distribution for tc4 fig 10d reveals that approximately more than 60 of the domain exhibits estimation error less than 3 10 3 m thereby ensuring the application of the proposed rom for potential replication of the fsm for multiple well and complex boundary test problems 7 summary and conclusions in this research work we have presented an algorithm for generating spatially distributed random hydraulic conductivity fields on an irregular unstructured grid system based on field values measured from sampled locations within the domain to define aquifers with strong local heterogeneity we have also presented an irregular unstructured grid fv formulation for modeling groundwater flow through such randomly heterogeneous confined aquifers with special treatment of singular point source sink terms furthermore we have developed a model order reduction methodology based on global pod basis functions for cutting down the computational expenses associated with such full system groundwater models the field generation algorithm is not only capable of producing a picture of overall heterogeneity of the domain but also incorporates randomness at a micro scale level random hydraulic conductivity value for each element to define the effects of local heterogeneity the algorithm generates similar replicates of the heterogeneous field for finer spatial discretization thereby fulfilling the grid convergence criteria figure sf1 we have observed the results of the fv based fsm to overcome the issues of grid convergence faced by modflow usg using the standard well wel package the fsm is fast and accurate and also shows promising convergence results with decreasing grid dimensions for all the test cases figures sf4 sf5 sf6 the proposed rom reproduces the fsm with the desired accuracy for the considered test problems and also shows efficient grid convergence figure sf7 the comparison of the results of the fsm and the rom suggests that our proposed rom estimates the drawdowns very accurately in regions of large drawdowns if the order of calculated responses for a certain considered forcing agent is small a difficulty arises in pattern identification technique this can be overcome by considering an increased value of the forcing agent and compute a parameter independent pod basis for the rom however careful observation reveals that the rom solutions are most accurate near the extraction well nodes where the system is highly responsive we have detected somewhat lesser accuracy in the zones of low responses i e the low conductivity regions and also near the boundaries especially the neumann boundaries the key benefit of the proposed rom lies in its ability to reduce the cpu computation time application of pod reduces the high dimensional solution space to a low dimensional sub space consisting of 9 11 and 20 modes for tc2 tc3 and tc4 respectively that preserve 99 99 of the total energy fig 11 compares the energy percentage of the dominant modes for the three test cases for tc2 and tc3 we have achieved approximately 485 and 456 times reduction in computation time respectively with respect to the fsm computation time reduction is much more significant for problems with complex boundary conditions this has been evident in tc4 where we have achieved a greater time reduction of approximately 610 times through the rom however computation time reduction has increased significantly while reproducing the previous problems with finer spatial discretization table st1 besides we have also accomplished a significant reduction of cpu storage as we have solved the governing equation in a reduced sub space with the same set of pod basis for every time iteration the primary objective of this study is to verify the proposed methodologies of random hydraulic conductivity field generation and computationally inexpensive groundwater modeling on theoretical aquifer systems the results confirm that the above methodologies are likely to be applied for natural aquifer systems on catchment scale groundwater dynamics of a catchment comprising a confined aquifer can be characterized applying the proposed methodologies to begin with the field hydraulic conductivity values need to be measured through field tests from priorly designated sample locations over the catchment next a mean hydraulic conductivity field for the catchment can be generated using algorithm 1 on a regular or an irregular unstructured grid system depending on the catchment geometry finally with proper information about the catchment boundaries and available hydrological data the proposed rom can simulate the groundwater head distribution over the catchment in conclusion the performance evaluation of the proposed fv based full system groundwater model and corresponding reduced order model prove their potential applicability at estimating groundwater dynamics for both homogeneous and heterogeneous confined aquifer systems subjected to variable boundary conditions and multiple forcing agents we plan on extending the methodology to solve flow problems involving non linearity and unfurl the applicability of the proposed methods to solve groundwater flow problems through unconfined and coastal aquifers notations a stiffness matrix af surface area of the element boundary l 2 aα aβ voronoi polygon area corresponding to sampled locations and area of an element of the irregular unstructured grid respectively l 2 b depth of the confined aquifer l cz covariance function c power law constant d 1 d 2 distance of the center of an element face respectively from the centroid of the parent element and the neighbor element adjacent to that face l f force vector h 0 static hydraulic head l if vector directed from the centroid of the parent element to the centroid of the neighbor element adjacent to the face f k hydraulic conductivity tensor kf face centered hydraulic conductivity of the fth face of the element l t 1 kx ky hydraulic conductivity in x and y directions respectively l t 1 kα kβ field hydraulic conductivity at sampled locations and estimated hydraulic conductivity for irregular unstructured grid elements respectively l t 1 l estimation error variance function lf length of the face f of an element l mc number of monte carlo realizations m mean of the sampled field hydraulic conductivity values mc muc conditional and unconditional means respectively mucα mucβ mean of the primary and secondary basis values respectively within the defined respective neighborhood of an element m 1 m 2 number of primary and secondary basis points respectively within the defined neighborhood of an element m 1 max m 2 max maximum number of primary and secondary basis points to be considered within the defined neighborhood of an element respectively nc min minimum number of conditioning values to be considered for an element nr a random integer ns specific volumetric point source sink t 1 ne 1 ne 2 ne 3 number of elements associated with first second and third node of an element respectively np number of elements associated with any node n p number of principal components nset number of sets of snapshots n t s number of snapshots in each set n normal vector at the boundary n f unit vector in the outward normal direction from the point of intersection of the line joining the centroids of the parent and the adjacent neighbor element on the face f n 1 n 2 number of sampled locations and number of elements in the irregular unstructured grid respectively p pod basis matrix qp volumetric extraction rate of the extraction well l 3 t 1 qn a known function r distance of the extraction well node from the centroid of the element associated to it l rn time dependent coefficient vector rw radius of the extraction well l s storage coefficient ss specific storage of the confined aquifer l 1 ssnap snapshot matrix sa drawdown l s a estimated drawdown vector sa d sa 0 known functions tf face centered transmissivity of the fth face of the element l 2 t 1 tfinal final extraction time t s approximate steady state time t time coordinate t f unit vector in the tangential direction along face f from the point of intersection of the line joining the centroids of the parent and the adjacent neighbor element t s snapshot time set u v matrix of left and right singular vectors respectively ws specific volumetric source or sink t 1 wf wn element to face inverse distance weighted interpolation function and element to node area weighted interpolation function respectively x vector of space coordinates in the euclidean space l zα zβ natural logarithmic value of field hydraulic conductivity at sampled locations and estimated logarithmic value of hydraulic conductivity for irregular unstructured grid elements respectively l t 1 za hydraulic head l γ d γ n dirichlet and neumann boundaries respectively γ model semivariogram δ dirac delta function δn f δt f distance between the centroids of the parent element and neighbor element adjacent to the face f in the normal and tangential directions to the face respectively l ϵ r incremental value of r 1 for each iteration l θ degree of implicitness λα λβ kriging coefficient corresponding to primary and secondary basis values respectively μ lagrange multiplier σ diagonal matrix with the singular values as the diagonal elements σ singular value σc 2 σuc 2 conditional and unconditional variances respectively σerror 2 estimation error variance ϕα ϕβ area weighting coefficient corresponding to primary and secondary basis values respectively ω physical domain ω power law exponent φ angle subtended in radians with the extraction well node by the element associated to it f inward flux from the associated element to the extraction well node l 3 t 1 credit authorship contribution statement saumava dey conceptualization methodology validation writing original draft anirban dhar supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103703 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
414,groundwater being a vital component of the natural water resource system needs continuous monitoring and dynamic management strategies that said we require computationally inexpensive groundwater flow models for repetitive solutions with desirable accuracy under budgetary limitation s natural aquifer systems inherit strong heterogeneity at local scales in this work we have proposed ordinary kriging based sequential algorithm for generating replicates of randomly distributed heterogeneous hydraulic conductivity field monte carlo method based algorithm conditioned by field values from sampled locations in an irregular unstructured grid system finite volume method based groundwater models often encounter difficulties with the representation of point source sink terms operating within the domain in this paper we have proposed an irregular unstructured grid finite volume discretization technique for overcoming the singularity of point source sink term to yield a consistent output with different grid dimensions furthermore full system groundwater models often come with a substantial computational burden hence reduction in model order cuts down the computational expenses in terms of cpu time and usage to a significant level we have also put forth a model order reduction methodology for three different illustrative pumping tests the proposed framework for the model order reduction projects the governing groundwater flow equation onto a set of identified patterns or orthonormal basis functions applying the galerkin projection method to compute a vector of time dependent coefficients we have performed pattern identification by singular value decomposition svd of snapshots of full system model simulation data at selected time instants within the pumping test time domain the numerical results of the proposed reduced order models show a good approximation of the full system models at a comparatively lesser computational time the accuracy and efficiency of the models attempt to ensure their potential applicability for identifying groundwater dynamics keywords random heterogeneity finite volume method singular point source sink reduced order model proper orthogonal decomposition 1 introduction groundwater management framework requires the repetitive use of groundwater flow models for designing a sustainable policy with time scientists have developed several mathematical models to estimate the groundwater dynamics of different aquifer systems finite difference fd methods based models such as modflow mcdonald and harbaugh 1988 harbaugh et al 2000 harbaugh 2005 have wide applications in groundwater modeling as fd models work on a simple rectangular grid system the discretization of governing equations is very straightforward this makes the fd scheme popular among practitioners however the fd scheme fails to describe precisely the boundaries of domains with complex geometry which significantly affects the accuracy of model prediction near the boundaries although grid refinement can be a remedy for the incurred loss in accuracy mehl and hill 2002 it comes at the cost of increased computational expenses an improved version of the fd scheme the integrated finite difference ifd method also known as the control volume finite difference cvfd method has been used as well to analyze fluid flow in porous media narasimhan and witherspoon 1976 modflow usg panday et al 2013 a cvfd based unstructured grid version of modflow has been developed to solve tightly coupled multiple hydrological flow processes other numerical methods like finite element fe method reddy 2006 boundary element be method kobayashi and nishimura 1992 finite volume fv method leveque 2002 mazumder 2016 and different mesh free methods liu and gu 2005 have proved their relevance in modeling groundwater flow over time another attractive numerical method for groundwater modeling is the fe method the fe based commercial computer models like feflow diersch 2014 and femwater lin et al 1997 are also available for simulation of saturated unsaturated subsurface flow and transport nevertheless the accuracy of the fe method suffers due to its non conservative nature nowadays the fv method is gaining acceptance among emerging numerical methods because it is highly conservative moreover the fv method is also applicable to domains with complex geometries the fv method integrates the flow governing equations over the control volume of any shape and conserves the mass momentum and the energy entering and exiting a system fv models for groundwater flow applications have been developed for different regular and irregular unstructured grid systems loudyi et al 2006 dotlić et al 2016 in groundwater modeling a well is treated as a singular point source or sink moreover a well encountered in groundwater hydrology be it of recharging or extraction type is of vanishingly small radius in the order of 0 1 0 2 metres bear 1979 pinder and celia 2006 the drawdown inside such a small diameter well can be calculated neglecting the water derived from the storage inside the well papadopulos and cooper 1967 in numerical modeling a well is specified at the centroid of an element when the governing partial differential equation is discretized on a regular structured or unstructured grid using fd and cvfd schemes the problem arises during simulation of real life situations because the circumference of a well where the pressure gradient is maximum is practically very small compared to the area of the element containing it peaceman method defines the well block pressure in terms of the pressure in the neighbouring elements it is depicted to be numerically equal to the actual pressure at an effective radius of 0 2δx for regular square grid peaceman 1977 and 0 14 δ x 2 δ y 2 1 2 for regular rectangular grid peaceman 1983 systems however local grid refinement around a well can be considered to bring down the effective radius very close to the actual value on the other hand finer spatial discretization imposes several restrictions on temporal discretization to maintain stability of the numerical scheme this eventually increases the computational expenses turning it into an impractical attempt furthermore when irregular unstructured grid systems are considered the above considerations do not function as grid dimensions vary for each element thereby separate well models become a necessity different well models for standard fem control volume fem and mixed fem have been developed by chen and zhang 2009 the well model derived for control volume fem has been applied for cvfd scheme in modflow usg panday et al 2013 which is approximately equivalent to peaceman method applied for structured grids in previous versions of modflow regardless bringing down the effective well radius close to the actual radius value still remains an unanswered question the application of any groundwater flow model requires the identification of aquifer parameters such as the hydraulic conductivity field and the storage coefficients the primary means of aquifer characterization are on field pumping tests and numerical simulations as pumping tests are complex and expensive alternative economical methods based on particle size distribution rogiers et al 2012 and electrical resistivity tomography ert data yu and wu 2006 have been used to estimate field hydraulic conductivity one of the significant challenges faced in modeling groundwater flow through porous media is the mathematical replication of parameter heterogeneity inherent to transport media previously to avoid complexities the concept of equivalent porous medium was prevalent where the effects of heterogeneity were lumped into a single effective parameter which represented the medium yeh 1986 has modeled the field heterogeneity by dividing the flow regime into several sub regions where a constant hydraulic conductivity characterizes each region kriging is an important tool used in groundwater hydrology for distributing field information throughout the domain from limited data points the kriging estimates are highly influenced by the uncertainty of the semivariogram as it is determined on the basis of available sampled data the uncertainty of the model semivariogram can be quantified using random fields which is very essential for stochastic modeling lin and chen 2005 xu et al 2017 has shown the successful application of kriging based interpolation technique to determine spatial distribution of hydraulic conductivity obtained from resistivity and grain size data at sampled locations in reality aquifer parameters not only vary among different layers the variation within a particular layer is also of much significance the heterogeneity of a hydraulic conductivity field is stochastically best described by a log normal probability density function freeze 1975 a stochastic model of porous media considers hydraulic conductivity as a random variable greenkorn and kessler 1969 and the intrinsic heterogeneity as a space random function srf correlated in space and time bellin and rubin 1996 monte carlo method based sequential gaussian simulation is considered an efficient algorithm for the generation of random fields application of the monte carlo method to such srf field generation simplifies the intricacies associated with the replication of spatial variability of field heterogeneity however a significant limitation of the monte carlo method is that it converges slowly as o 1 n where n is the number of independent monte carlo realizations in order to obtain nearly accurate results we require a large number of monte carlo replicates of the random field which eventually increases the computation time of the model many effective commercial softwares are available for random field generation based on sequential gaussian simulation random surface generation rsg is a moving average method based software used for generating gaussian random surfaces to account for the topographic height variations over a surface bergström et al 2007 similarly random finite element method rfem is a fem based geotechnical modeling software which generates gaussian random fields for introducing random behavior of geologic formations smith et al 2013 on the other hand exhibiting the characteristics of a hydraulic conductivity field requires the generated field realization to be conditioned by field measurements conditional simulation of heterogeneous porous formations based on measured hydraulic conductivity or transmissivity data at few points of the formation have been successfully attempted delhomme 1979 dagan 1982 clifton and neuman 1982 tsai 2006 tbsim a computer program for conditional simulation of gaussian random fields emery and lantuéjoul 2006 is also available for simulating random fields conditioned by available data at selected locations by far stanford geostatistical modeling software sgems remy et al 2009 is the most productive conditional gaussian random field generator used to generate random fields replicating the properties of heterogeneous porous media although the aquifer is intrinsically heterogeneous in continuum approach to flow through porous media the parameters are considered to be homogeneous within a small volume known as representative elementary volume rev bear 1979 pinder and celia 2006 this implies that natural heterogeneous porous media is homogeneous at microscopic scale hence accurate mathematical formulations should consider a suitable rev for the conditioning data while generating fields that characterize natural geologic formations the accuracy of a groundwater model highly depends on the discretization of the spatial and the temporal domain finer the discretization more accurate are the model predictions this increases the computational expenses making it an inefficient one in the case of high dimensional models therefore the focus should be on the development of a model that optimizes both the efficiency parameters accuracy and computation time scientists of various genre have acclaimed the model order reduction methodology based on data driven pattern identification techniques in different fields of scientific study over the past few decades sirovich 1987 park and cho 1996 park et al 1999 haasdonk and ohlberger 2011 hasenauer et al 2012 dehghan and abbaszadeh 2018 abbaszadeh and dehghan 2020 the method projects the governing equation onto a reduced sub space of identified patterns thereby cutting down the number of algebraic equations to be solved for each temporal iteration vermeulen et al 2004 made the first attempt towards low dimensional modeling of groundwater flow systems since then model reduction technique has been applied to modeling of groundwater flow through both confined pasetto et al 2011 2013 boyce and yeh 2014 and unconfined aquifers boyce et al 2015 stanko et al 2016 groundwater contamination problems ilati and dehghan 2016 kani and elsheikh 2019 and groundwater optimization and management studies mcphee and yeh 2008 baú 2012 in reduced order modeling snapshot selection is the key to pattern recognition hence the temporal distribution of snapshots for groundwater flow systems siade et al 2010 should be chosen wisely the applications of model order reduction for characterizing aquifer dynamics are limited to fd and fe methods till date as the fv method is a highly useful tool for pde discretization reducing the degrees of freedom involved in the classical approach will help in minimizing the computational complexities in this paper we have presented an fv based computationally inexpensive mathematical model for evaluating the dynamics of groundwater flow through a heterogeneous confined aquifer subjected to singular point source sink in the first step we have developed a fast effective and accurate algorithm for generating spatially correlated and randomly distributed heterogeneous hydraulic conductivity field based on available field values from sampled locations by integrating the concept of rev into standard sequential gaussian simulation technique we have developed the field for an irregular unstructured grid system to facilitate the application of advanced numerical tools secondly we have presented an fv formulation to estimate the groundwater response through the generated random heterogeneous field subjected to singularity of point source sink in the proposed methodology we have considered the actual radius of the well which is independent of the grid dimensions we have carried out a separate study of the proposed fv based full system model through a homogeneous confined aquifer to compare the performance of the model with modflow simulation results finally we have performed pod based reduced order modeling to minimize the computational expenses in terms of cpu time and usage acquired by the proposed fv based full system model 2 random heterogeneous field generation technique in this section we have introduced an ordinary kriging based sequential gaussian simulation technique to generate a random hydraulic conductivity field in an irregular unstructured grid system ordinary kriging is a geostatistical method for interpolating a variable value at any desired location within the domain based on available neighborhood data goovaerts 1997 to integrate the influence of homogeneity at the scale of rev we have introduced a set of area coefficients along with the set of kriging coefficients used in usual ordinary kriging method as a result we have a new non bias condition which includes both the area coefficients and the kriging coefficients 2 1 basis points in this approach we have considered a set of basis points whose values have been used for conditioning the estimated values we have assumed a physical domain ω with field hydraulic conductivity values k α i available at n 1 sampled locations acting as the primary basis points initially we have assigned an influence zone for each sampled location over which we have assumed the corresponding field hydraulic conductivity value to be constant we have adopted voronoi tessellation method for the above zonation procedure the voronoi polygon area corresponding to ith sampled location is a α i i 1 n 1 furthermore we have overlaid an irregular unstructured grid system with n 2 elements on the domain ω the area of the jth discretized element is denoted by a β j j 1 n 2 which is considered to be the rev for the hydraulic conductivity value k β j estimation at the centroid of the element the estimates of hydraulic conductivity for these n 2 elements are determined based on the available field values at n 1 basis points as conditioning data assuming hydraulic conductivity to vary log normally freeze 1975 we have defined two variables z α i and z β j as 1 z α i ln k α i i 1 n 1 2 z β j ln k β j j 1 n 2 2 2 search neighborhood here we have followed an a priori determined random sequential arrangement of the elements for the generation of each monte carlo replicate of the hydraulic conductivity field such an approach enhances randomness within the generated field we have considered two different categories of conditioning data i available hydraulic conductivity values from primary basis points ii values from the secondary set of basis points that include elements with previously generated hydraulic conductivity estimates unavailable for initial estimates hence we have considered two different sized search neighborhoods for selecting the above two categories of conditioning data fig 1 we have approximated an initial search radius r 1 for selecting the primary conditioning data as isaaks and srivastava 1989 3 r 1 i 1 n 1 a α i n 1 we have incremented the search radius by ϵ r as long as a pre defined number of conditioning data are not selected however we have considered the search radius for the second category of conditioning data to be constant for the entire procedure we have assumed the characteristic length used for irregular unstructured grid generation as the equivalent search radius r 2 for the secondary basis points by this approach we have attempted to optimize the search neighborhood for computational efficiency without sacrificing the accuracy of the estimates 2 3 conditional mean and variance let us assume that the neighborhood encloses m 1 primary basis points with corresponding logarithmic values of field hydraulic conductivity z α r where r 1 m 1 and m 2 secondary basis points with previously generated conditional estimates z β s where s 1 m 2 for the kth element we have generated the conditional estimate of hydraulic conductivity for the kth element from a standard random generator which generates random values following normal distribution with conditional mean mc and conditional variance σc 2 as target statistics bellin and rubin 1996 we have calculated the conditional mean mc as 4 m c m u c r 1 m 1 ϕ α r λ α r z α r m u c α s 1 m 2 ϕ β s λ β s z β s m u c β where muc α muc β and muc respectively are area weighted unconditional means based on primary data secondary data and their combination available within the neighborhood and can be represented as the following 5 m u c α r 1 m 1 z α r a α r r 1 m 1 a α r 6 m u c β s 1 m 2 z β s a β s s 1 m 2 a β s 7 m u c r 1 m 1 z α r a α r s 1 m 2 z β s a β s r 1 m 1 a α r s 1 m 2 a β s we have calculated the conditional variance σc 2 as 8 σ c 2 σ u c 2 r 1 m 1 ϕ α r λ α r γ z α r z β k s 1 m 2 ϕ β s λ β s γ z β s z β k where σuc 2 and m respectively are area weighted unconditional variance and mean calculated based on all available primary data over the entire domain and can be expressed as the following 9 σ u c 2 i 1 n 1 a α i z α i m 2 i 1 n 1 a α i 10 m i 1 n 1 a α i z α i i 1 n 1 a α i 2 4 area weighting coefficients we have introduced a set of area weighted coefficients ϕ α r and ϕ β s which are calculated as 11 ϕ α r a α r r 1 m 1 a α r r 1 m 1 12 ϕ β s a β s s 1 m 2 a β s s 1 m 2 2 5 semivariogram model a continuous function has to be fitted to the experimental semivariogram goovaerts 1997 to calculate the covariance or semivariogram values for any lag distance h the best fit function also known as the model semivariogram is used for the kriging method we have selected an unbounded semivariogram with power law dependence of variance γ on lag distance h 13 γ h c h ω we can consider a porous medium as a distribution of interconnected channels with random obstructions at different length scales between them fractal geometry is an emerging mathematical tool for studying the behavior of irregular geometric objects and has been successfully applied to porous geological formations to determine its fractal nature adler and thovert 1993 moreover the application of fractal geometry at the micro scale level has also simplified the problems of spatial heterogeneity characterization of porous media and transport phenomenon through the same sahimi and yortsos 1990 a self similar fractal field requires the correlation of the hydraulic conductivity values over greater lengths and this unbounded power law semivariogram model 13 stands out as the appropriate choice furthermore for ω 1 the field shows smooth variation and looks highly realistic 2 6 determination of kriging coefficients we can express the error variance for conditional estimation of hydraulic conductivity for the kth element as 14 σ e r r o r 2 v a r z β k z β k v a r z β k v a r z β k 2 c o v z β k z β k r 1 m 1 s 1 m 1 ϕ α r λ α r ϕ α s λ α s c z z α r z α s r 1 m 1 s 1 m 2 ϕ α r λ α r ϕ β s λ β s c z z α r z β s r 1 m 2 s 1 m 1 ϕ β r λ β r ϕ α s λ α s c z z β r z α s r 1 m 2 s 1 m 2 ϕ β r λ β r ϕ β s λ β s c z z β r z β s c z 0 2 r 1 m 1 ϕ α r λ α r c z z α r z β k 2 s 1 m 2 ϕ β s λ β s c z z β s z β k ordinary kriging produces estimates with minimum estimation error variance for constraining the minimization problem we have defined the non bias condition comprising the kriging and area coefficients for both the primary and secondary data as the following 15 r 1 m 1 ϕ α r λ α r s 1 m 2 ϕ β s λ β s 1 here we have introduced a lagrange multiplier μ for converting the constrained minimization problem into an unconstrained one and have defined a new function for error variance as 16 l σ e r r o r 2 2 μ r 1 m 1 ϕ α r λ α r s 1 m 2 ϕ β s λ β s 1 the minimization of the new error variance function yields a set of m 1 m 2 linear algebraic equations the set of first m 1 equations obtained from the condition l λ α r 0 is as follows 17 s 1 m 1 ϕ α s λ α s γ z α p z α s s 1 m 2 ϕ β s λ β s γ z α p z β s μ γ z α p z β k for p 1 m 1 the next set of m 2 equations obtained from the condition l λ β r 0 is as follows 18 s 1 m 1 ϕ α s λ α s γ z β q z α s s 1 m 2 ϕ β s λ β s γ z β q z β s μ γ z β q z β k for q 1 m 2 the ordinary kriging coefficients and the lagrange multiplier μ have been calculated by simultaneously solving the set of m 1 m 2 equations 17 and 18 and the non bias condition 15 as the spatial configuration of the conditioning data for any element is not constant for an irregular unstructured grid system we need to compute the ordinary kriging coefficients repeatedly for every element 3 governing equation the transient saturated groundwater flow through a heterogeneous and isotropic confined aquifer with extraction is governed by bear 1979 19 s s s a x t t k s a x t w s i n s x t δ x x i t 0 x ω t 0 t f i n a l s a x t h 0 z a x t we have considered the extraction well to be fully penetrating to ensure horizontal flow and constant extraction rate throughout the time domain as we have ensured the flow to be horizontal we have defined depth averaged drawdown in the governing equation eq 19 thereby reducing the flow in two dimensional space the governing equation is subjected to the following initial and boundary conditions initial condition 20 s a x 0 s a 0 x dirichlet boundary condition 21 s a x t s a d x t x γ d ω neumann boundary condition 22 k s a x t n q n x t x γ n ω where k k x 0 0 k y 4 finite volume discretization the cvfd scheme used in modflow usg panday et al 2013 has a geometric constraint that the line joining the centroids of the two adjacent elements has to perpendicularly bisect the common face narasimhan and witherspoon 1976 this geometric requirement is satisfied by grids composed of equilateral triangles rectangles or other regular higher order polygons and unstructured grids formed by voronoi tessellation while dealing with real life problems the grids generated do not always conform to the cvfd criteria and subsequent error creeps into the solution in order to reduce the error the ghost node correction gnc package is implemented in modflow usg which eventually increases the computation time however the fv method completely overcomes this potential source of error arising due to the geometry of the discretized elements by considering a tangential flux term a tangential flux is generated whenever a line joining the centroids of two adjacent elements is not a perpendicular bisector of their common face hence we have preferred this approach because of its flexibility and mass conservative nature in this section we have illustrated an fv discretization approach for the governing partial differential equation of confined groundwater flow in this approach we have considered the singular point source sink terms separately for their respective operating nodes the integration of 19 without the point source sink term over the volume of an element vβ and time step δt and subsequent application of gauss divergence theorem yields 23 t t δ t v β s s s a t dv dt t t δ t a f k s a n da dt t t δ t v β w s dv dt discretization of eq 23 for a triangular element in an irregular unstructured grid produces the following 24 s a β i s a i 0 k 1 s a i 0 k δ t f 1 3 t f s a f n f l f w s a β i b where s s s b t f k f b we have used the superscript for representing the time level of the temporal discretization and the subscript 0 to designate the element centered values of a variable 4 1 gradient approximatio the gradient term sa f at the face f can be decomposed into two components from the point of intersection of the line joining the centroids of the parent and the adjacent neighbor element one normally outward to the face and the other tangentially along the face fig 2 25 s a f s a f n f n f s a f t f t f a dot product of eq 25 with the vector if and subsequent rearrangement of the terms yields the following 26 s a f n f s a f i f δ n f s a f t f δ t f δ n f after performing the dot products of the gradient term sa f with if and t f in eq 26 the final approximation of the gradient term becomes 27 s a f n f s a f 0 s a i 0 δ n f s a f 1 s a f 2 l f δ n f δ t f we have used the subscripts 1 and 2 for implying the values at the two nodes of the face f that distinguish the nodal values from the element centered values designated by the subscript 0 4 2 face centered approximation of hydraulic conductivity the fv formulation of groundwater flow in an irregular unstructured grid system requires an interpolation of the face centered hydraulic conductivity from adjacent element centered values we have performed inverse distance weighted interpolation for determining the face centered hydraulic conductivity because it is second order accurate and has certain advantages over other methods mazumder 2016 we can write the interpolation equation as the following 28 k f w f k i 0 1 w f k f 0 where 29 w f 1 d 1 1 d 1 1 d 2 4 3 interpolation of element centered values to nodal values post processing of the fv algorithm needs an interpolation of nodal values from the calculated element centered values we have computed the nodal values using area weighted interpolation as 30 s a f n i 1 n p w n i n s a i 0 where 31 w n i n a β i i 1 n p a β i 4 4 discretization for all internal elements we have deduced the fv discretized form of the governing equation for all internal elements as 32 s a β i s a i 0 k 1 s a i 0 k δ t f 1 3 t f s a f 0 s a i 0 δ n f s a f 1 s a f 2 l f δ n f δ t f l f w s a β i b f 1 3 t f l f δ n f s a f 0 s a i 0 f 1 3 t f δ t f δ n f s a f 1 s a f 2 t a n g e n t i a l f l u x w s a β i b in the equation above 32 we cannot calculate the tangential flux term directly therefore further approximation is needed interpolating the drawdown at each node from the drawdowns of all the associated elements by eq 30 we have expanded the tangential flux term as 33 f 1 3 t f δ t f δ n f s a f 1 s a f 2 t 2 δ t 2 δ n 2 t 3 δ t 3 δ n 3 l 1 1 n e 1 s a l 1 0 w n l 1 1 s a i 1 t 3 δ t 3 δ n 3 t 1 δ t 1 δ n 1 l 2 1 n e 2 s a l 2 0 w n l 2 2 s a i 2 t 1 δ t 1 δ n 1 t 2 δ t 2 δ n 2 l 3 1 n e 3 s a l 3 0 w n l 3 3 s a i 3 applying θ scheme for temporal discretization we can write the final approximation of eq 32 as 34 a i s a i 0 k 1 f 1 3 b i f s a f 0 k 1 m 1 3 d i l m l m 1 n e m s a l m 0 k 1 w n l m m f i where a i s a β i θ δ t f 1 3 t f l f δ n f b i f θ δ t t f l f δ n f for f 1 2 3 d i l 1 θ δ t t 2 δ t 2 δ n 2 t 3 δ t 3 δ n 3 d i l 2 θ δ t t 3 δ t 3 δ n 3 t 1 δ t 1 δ n 1 d i l 3 θ δ t t 1 δ t 1 δ n 1 t 2 δ t 2 δ n 2 f i s a β i θ 1 1 θ a i s a i 0 k 1 1 θ f 1 3 b i f s a f 0 k m 1 3 d i l m l m 1 n e m s a l m 0 k w n l m m w s a β i b δ t 4 5 discretization for extraction well node in this work we have presented a generalized fv scheme for confined groundwater flow with singular point source sink in an irregular unstructured grid system here we have specified the wells at the nodes in the grid system an important aspect considered in this formulation is the selection of actual well radius for the calculation of drawdown at the well node and not the effective radius calculated by any well model this ensures that the well radius is independent of the grid dimension unlike in modflow usg where it is dependent on grid dimensions a linear aquifer loss coefficient which accounts for the head loss in the well node due to the differences in actual and effective well radius has been applied for multi node wells in modflow usg however single node wells simulated by the basic well wel package lacks this correction hence the selection of actual well radius rules out the issues of grid convergence that may arise with changing grid dimensions assuming the flow to be radial in the neighbourhood of a well the drawdown at a well is calculated by solving the continuity equation at that well node for every time step the radially inward flow from the centroids of all the elements associated with the well node are equated with the extraction rate we have calculated the inward flux through the arc subtended by the well for each element associated with the well node fig 3 as thiem 1906 35 f i φ i t i 0 s a w s a i 0 ln r i r w we can present the continuity equation at the extraction well node as follows 36 i 1 n p f i q p 0 on substituting eq 35 in eq 36 and rearranging the terms we get 37 i 1 n p φ i t i 0 ln r i r w s a w k 1 i 1 n p φ i t i 0 ln r i r w s a i 0 k 1 q p 0 4 6 discretization for elements associated with the extraction well node the elements associated with the extraction well node have an additional flux term directed radially towards the node the final discretized form after applying the θ scheme for temporal averaging is as the following 38 a i p s a i 0 k 1 f 1 3 b i f p s a f 0 k 1 c i p s a w k 1 m 1 3 d i l m p l m 1 n e m s a l m 0 k 1 w n l m m f i p where a i p a i θ δ t φ i t i 0 ln r i r w c i p θ δ t φ i t i 0 ln r i r w f i p f i 1 1 θ c i p s a w k however the coefficients b i f p d i l 1 p d i l 2 p and d i l 3 p are respectively equal to b i f d i l 1 d i l 2 and d i l 3 from eq 34 4 7 boundary conditions in groundwater flow problems we come across three types of boundary conditions dirichlet or specified head boundary condition neumann or specified flux boundary condition and cauchy boundary condition in the dirichlet boundary the hydraulic head is either constant or specified as a function of space and time for each dirichlet boundary element we need to specify the heads for the two nodes lying on the boundary however for a neumann boundary element the normal flux through the face s coinciding with the boundary is are specified an impermeable boundary is a particular case of neumann boundary condition where the specified normal flux through the boundary face is zero moreover the cauchy boundary condition can be considered as an imposition of both dirichlet and neumann conditions on the boundary elements the fv discretization equations for the elements associated with both dirichlet and neumann boundaries are presented in the supplementary information appendix sa1 5 reduced order modeling model order reduction is a computationally efficient technique used for solving any full scale model in this section we have presented a reduced order groundwater flow model applying the standard pod formulation since fv method is highly conservative in nature application of pod to the proposed fv formulation of groundwater flow equation through heterogeneous porous media is expected to yield extremely satisfactory results the reduced order model approximates the state variable as the product of an orthogonal matrix p x and a time dependent coefficient vector rn t as 39 s a x t p x r n t 5 1 snapshot selection model order reduction methodology starts with a collection of scenarios known as snapshots that tend to describe the dynamics of the system with time a snapshot matrix stores the solutions of a full system groundwater model at some pre defined time instants we require a careful study of the nature of the governing equation and the evolution of its solution with time for determining the snapshot time set for groundwater flow problems we have selected the snapshot time set by the following exponential function 40 t s i 0 i 1 1 tanh t s 1 u i otherwise where u i i 1 n t s 1 the snapshot matrix ssnap has been formed from the solutions of eq 19 for different time instants given by the time set t s the required number of sets of snapshots depends on the number of linearly independent constant or variable forcing agent extraction well operative within the domain if multiple forcing agents are present a single set of snapshots has to be collected separately for each of them each set should have the solutions of the model with one forcing agent operative at a constant rate while others are remaining completely inoperative we have represented the complete snapshot matrix as s snap j s a t s 1 s a t s 2 s a t s 3 s a t s n t s j 1 2 3 n s e t 41 s snap s snap 1 s snap 2 s snap 3 s snap n s e t 5 2 formation of the pod basis for orthonormalization of the above snapshot matrix we have performed singular value decomposition svd of ssnap as 42 s snap u σ v t after svd the matrix u containing the left singular vectors of ssnap represents the orthogonal matrix p x from eq 39 also known as the pod basis accordingly we can call the left singular vectors as the pod basis vectors among all pod basis vectors only a few contributes significantly to maximum information regarding system dynamics we have chosen the basis vectors corresponding to the singular values satisfying the following relationship for the construction of the final pod basis 43 i 1 n p σ i i 1 r a n k s snap σ i 100 99 99 5 3 galerkin projection we have denoted the matrix form of the discretized governing eq 24 as 44 a s a f we have split the above equation into two parts whereby we have separated the extraction well nodes from the elements we can write the partitioned equation as a e a p t a p a p s a e s a p f e f p 45 a e s a e a p t s a p f e 46 a p s a e a p s a p f p the eq 45 corresponds to the drawdowns at the elements we have solved this equation by projecting it onto a reduced sub space of pod basis via galerkin projection however we have calculated the drawdown at the extraction well nodes by solving eq 46 explicitly for each time step in order to initiate the iteration we have assumed the full system solution at a very early time step in the range of 10 5 as the initial guess vector the galerkin projection of eq 45 has been performed by substituting eq 39 to form the following a e p r n f e a p t s a p p t a e p r n p t f e a p t s a p 47 r n p t a p 1 p t f e a p t s a p the resulting vector rn has been substituted in eq 39 to obtain the reduced order solution at the element centroids we have then substituted the solution vector sae in eq 46 to estimate the drawdown at the extraction well locations at the end of each time step 6 numerical tests 6 1 tc1 random hydraulic conductivity field generation in order to demonstrate the applicability of the heterogeneous field generation algorithm proposed in section 2 we have utilized a two dimensional synthetic square shaped confined aquifer with sides 3200 m and depth 50 m tsai 2006 we have considered the specific storage coefficient of the aquifer to be 10 4 m in order to condition the estimates of hydraulic conductivity we have obtained field values from 75 sampled locations within the aquifer fig 4 shows the 75 sample locations with respective field hydraulic conductivity values and their corresponding zones formed after voronoi tessellation we have computed the experimental semivariogram with these measured field conductivities and have fitted a power law model semivariogram eq 13 with parameters c 10 4 and ω 1 2462 we have then discretized the aquifer into 2398 nodes with 5690 triangular elements we have evaluated the estimates of hydraulic conductivity for these triangular elements by algorithm 1 with the following input parameters n c min 5 m 1 max 5 m 2 max 5 ϵ r 100 m and r 2 70 m for each field replicate the initial estimates have entirely been conditioned by primary basis data searched over large neighborhoods due to the unavailability of secondary basis data such estimates are thus bound to be very rough ones however the random sequence adopted for the estimation of each field realization ensures smoothening of these rough estimates when a large number of replicates are generated the effects of local integration over discretization have been insignificant as the correlation length for the unbounded power law semivariogram is very large compared to the characteristic length used for grid generation ababou 1988 we have displayed the contour diagram of the mean log hydraulic conductivity field averaged over 104 monte carlo simulations in fig 5 a the contour plot of estimation error variance fig 5b shows minimum variance around the central region of the aquifer where the primary conditioning data was available in abundance the maximum error variance is in the range of 0 05 to 0 07 and is observed along the left boundary and near the bottom right boundary where the density of available primary basis points was the least 6 2 tc2 transient groundwater flow model with a single extraction well in a homogeneous confined aquifer we have tested the fv formulation of the full system groundwater model and the proposed reduced order model on the synthetic confined aquifer described in tc1 we have assumed the aquifer to be homogeneous with a constant value of hydraulic conductivity 50 m day throughout the entire domain we have considered zero dirichlet boundary conditions on all the boundaries of the confined aquifer an extraction well extracting at a constant rate of 104 m 3 day is located at the center of the aquifer we have discretized the aquifer into 2851 nodes with 5516 triangular elements we have performed a pumping test of 15 days duration we have assumed a small diameter well of radius 0 1 m for all the test problems we have observed the system to achieve steady state conditions after 5 days of extraction from the drawdowns recorded figure sf2b at three different locations within the aquifer figure sf2a we have compared the performance of our proposed fv based full system model fsm with the results of modflow usg simulations for tc2 we have carried out the simulations on a square grid system in modflow usg using different grid dimensions we have used the well wel package for carrying out the simulations we have observed that the drawdown at the well location is inconsistent with changing grid dimensions this can be attributed to the fact that the effective well radius considered in the calculation changes with varying grid dimensions we have applied grid refinement around the well using modflow lgr so that the effective well radius approaches toward the actual well radius however the grid refinement operates at the expense of cpu computation time the results of our proposed fv based fsm closely agrees with modflow usg when the effective well radius is almost equal to the actual well radius fig 6 claims that our proposed fv based fsm offers better grid convergence than modflow usg using the well wel package the drawdown calculated at the well location for different grid dimensions using modflow usg and proposed fv based fsm are tabulated in table 1 along with the respective cpu computation times next we have taken 10 snapshots calculated at various time instances by eq 40 for the reduced order model rom we have computed the snapshots at an increased extraction rate of 5 104 m 3 day for obtaining a significant response from every part of the aquifer this has helped us in profoundly identifying the patterns of the system response the pod basis computed from the snapshot matrix comprises 9 vectors therefore for every time step the rom needs to solve 9 equations as compared to 5516 by the fsm as a result we can ensure a significant reduction in computation time and cpu memory usage the rom replicates the fsm with a maximum absolute error of 4 2 10 5 m from the entire domain the other error statistic parameter values tabulated in table 2 also determine the accuracy of the rom and justify its applicability as an alternative for the fsm we have shown the comparison of drawdown contours calculated by the fsm and the rom after 15 days of constant extraction in fig 7 while discretizing the governing equation for all the test problems we have adopted the crank nicholson scheme θ 0 5 for temporal averaging 6 3 tc3 transient groundwater flow model with a single extraction well in a heterogeneous confined aquifer in tc3 we have solved the problem in tc2 assuming the confined aquifer to be heterogeneous we have generated a randomly distributed heterogeneous hydraulic conductivity field based on the field values from 75 sampled locations tc1 following algorithm 1 we have performed the pumping test for 30 days we have observed the system to attain steady state conditions approximately within 10 days from the commencement of the pumping test figure sf2c hence we have captured 20 snapshots of the fsm within that interval for pod basis calculation here again we have calculated the snapshots at an enhanced extraction rate of 5 104 m 3 day we have computed a pod basis of 12 vectors from the snapshot matrix we have presented in fig 8 the comparison of drawdown contours at the end of the pumping test for the fsm and the rom the results imply that the accuracy of the rom reduces in replicating the dynamics of the aquifer due to the incorporation of random heterogeneity the maximum absolute error of estimation has been reduced to 4 2 10 4 m in comparison to tc2 we have observed the absolute estimation error to be more in the top right corner and bottom left corner of the field compared to the other parts analysing the hydraulic conductivity field we can infer that the estimation error over the domain is higher in the zones of low hydraulic conductivity fig 10a however the plot of absolute nodal error distribution in fig 10b shows that the absolute error for more than 90 of the domain has been less than 10 4 m hence we can consider the rom to be capable of reproducing the fsm for a randomly distributed heterogeneous confined aquifer 6 4 tc4 transient groundwater flow model with multiple extraction wells in a heterogeneous confined aquifer in tc4 we have intensified the complexity of the problem by introducing multiple extraction wells and neumann boundary in the synthetic confined aquifer illustrated in tc1 we have considered zero dirichlet boundary condition on the left boundary of the aquifer while the other three boundaries are assumed to be impervious we have assumed the depth of the aquifer to be 100 m three extraction wells located at 1650 1250 1050 1950 and 2250 1950 figure sf3a have been operated at a constant rate of 5 103 m 3 day throughout the duration of the 90 days pumping test we have discretized the aquifer into 2884 nodes with 5582 triangular elements and we have generated a randomly distributed heterogeneous hydraulic conductivity field following algorithm 1 similar to the one conducted in tc3 in order to determine the approximate steady state time we have compared the drawdowns at 6 locations within the domain figure sf3a we have conducted 3 separate runs of the fsm one extraction well being operated at a time while the others wells remaining inoperative from figures sf3b sf3c and sf3d we have estimated that the system attains steady state conditions approximately after 75 days of constant extraction the snapshot selection strategy in this case has been different from the previous two cases as multiple extraction wells are operating simultaneously here we need to record the response of the system separately for each time invariant and linearly independent forcing agent we have captured 75 snapshots of the system dynamics separately for each extraction well considering it to be extracting at an enhanced rate of 5 104 m 3 day while others are inoperative during that time period we have combined the 3 sets of snapshots to form the final snapshot matrix consisting of 225 drawdown vectors singular value decomposition of the final snapshot matrix identifies 20 principal modes to be dominant that constitute the pod basis in fig 9 we have displayed the comparison of drawdown contours for the fsm and the rom after 90 days of constant extraction we have observed that the accuracy of rom is reducing with the increase in complexity of the boundary conditions as the maximum absolute error has increased to 3 6 10 3 m we have discovered the accuracy of the rom to be significantly high near the dirichlet boundary which reduces gradually while moving towards the impervious boundaries fig 10c in tc4 the estimation errors are dominant near the neumann boundaries whereas in tc3 the low hydraulic conductivity zones primarily account for the errors in estimation analyzing the estimation errors for tc2 tc3 and tc4 we can comment that the accuracy of the rom is affected more by the neumann boundaries than by the heterogeneity of the conductivity field the plot of absolute nodal error distribution for tc4 fig 10d reveals that approximately more than 60 of the domain exhibits estimation error less than 3 10 3 m thereby ensuring the application of the proposed rom for potential replication of the fsm for multiple well and complex boundary test problems 7 summary and conclusions in this research work we have presented an algorithm for generating spatially distributed random hydraulic conductivity fields on an irregular unstructured grid system based on field values measured from sampled locations within the domain to define aquifers with strong local heterogeneity we have also presented an irregular unstructured grid fv formulation for modeling groundwater flow through such randomly heterogeneous confined aquifers with special treatment of singular point source sink terms furthermore we have developed a model order reduction methodology based on global pod basis functions for cutting down the computational expenses associated with such full system groundwater models the field generation algorithm is not only capable of producing a picture of overall heterogeneity of the domain but also incorporates randomness at a micro scale level random hydraulic conductivity value for each element to define the effects of local heterogeneity the algorithm generates similar replicates of the heterogeneous field for finer spatial discretization thereby fulfilling the grid convergence criteria figure sf1 we have observed the results of the fv based fsm to overcome the issues of grid convergence faced by modflow usg using the standard well wel package the fsm is fast and accurate and also shows promising convergence results with decreasing grid dimensions for all the test cases figures sf4 sf5 sf6 the proposed rom reproduces the fsm with the desired accuracy for the considered test problems and also shows efficient grid convergence figure sf7 the comparison of the results of the fsm and the rom suggests that our proposed rom estimates the drawdowns very accurately in regions of large drawdowns if the order of calculated responses for a certain considered forcing agent is small a difficulty arises in pattern identification technique this can be overcome by considering an increased value of the forcing agent and compute a parameter independent pod basis for the rom however careful observation reveals that the rom solutions are most accurate near the extraction well nodes where the system is highly responsive we have detected somewhat lesser accuracy in the zones of low responses i e the low conductivity regions and also near the boundaries especially the neumann boundaries the key benefit of the proposed rom lies in its ability to reduce the cpu computation time application of pod reduces the high dimensional solution space to a low dimensional sub space consisting of 9 11 and 20 modes for tc2 tc3 and tc4 respectively that preserve 99 99 of the total energy fig 11 compares the energy percentage of the dominant modes for the three test cases for tc2 and tc3 we have achieved approximately 485 and 456 times reduction in computation time respectively with respect to the fsm computation time reduction is much more significant for problems with complex boundary conditions this has been evident in tc4 where we have achieved a greater time reduction of approximately 610 times through the rom however computation time reduction has increased significantly while reproducing the previous problems with finer spatial discretization table st1 besides we have also accomplished a significant reduction of cpu storage as we have solved the governing equation in a reduced sub space with the same set of pod basis for every time iteration the primary objective of this study is to verify the proposed methodologies of random hydraulic conductivity field generation and computationally inexpensive groundwater modeling on theoretical aquifer systems the results confirm that the above methodologies are likely to be applied for natural aquifer systems on catchment scale groundwater dynamics of a catchment comprising a confined aquifer can be characterized applying the proposed methodologies to begin with the field hydraulic conductivity values need to be measured through field tests from priorly designated sample locations over the catchment next a mean hydraulic conductivity field for the catchment can be generated using algorithm 1 on a regular or an irregular unstructured grid system depending on the catchment geometry finally with proper information about the catchment boundaries and available hydrological data the proposed rom can simulate the groundwater head distribution over the catchment in conclusion the performance evaluation of the proposed fv based full system groundwater model and corresponding reduced order model prove their potential applicability at estimating groundwater dynamics for both homogeneous and heterogeneous confined aquifer systems subjected to variable boundary conditions and multiple forcing agents we plan on extending the methodology to solve flow problems involving non linearity and unfurl the applicability of the proposed methods to solve groundwater flow problems through unconfined and coastal aquifers notations a stiffness matrix af surface area of the element boundary l 2 aα aβ voronoi polygon area corresponding to sampled locations and area of an element of the irregular unstructured grid respectively l 2 b depth of the confined aquifer l cz covariance function c power law constant d 1 d 2 distance of the center of an element face respectively from the centroid of the parent element and the neighbor element adjacent to that face l f force vector h 0 static hydraulic head l if vector directed from the centroid of the parent element to the centroid of the neighbor element adjacent to the face f k hydraulic conductivity tensor kf face centered hydraulic conductivity of the fth face of the element l t 1 kx ky hydraulic conductivity in x and y directions respectively l t 1 kα kβ field hydraulic conductivity at sampled locations and estimated hydraulic conductivity for irregular unstructured grid elements respectively l t 1 l estimation error variance function lf length of the face f of an element l mc number of monte carlo realizations m mean of the sampled field hydraulic conductivity values mc muc conditional and unconditional means respectively mucα mucβ mean of the primary and secondary basis values respectively within the defined respective neighborhood of an element m 1 m 2 number of primary and secondary basis points respectively within the defined neighborhood of an element m 1 max m 2 max maximum number of primary and secondary basis points to be considered within the defined neighborhood of an element respectively nc min minimum number of conditioning values to be considered for an element nr a random integer ns specific volumetric point source sink t 1 ne 1 ne 2 ne 3 number of elements associated with first second and third node of an element respectively np number of elements associated with any node n p number of principal components nset number of sets of snapshots n t s number of snapshots in each set n normal vector at the boundary n f unit vector in the outward normal direction from the point of intersection of the line joining the centroids of the parent and the adjacent neighbor element on the face f n 1 n 2 number of sampled locations and number of elements in the irregular unstructured grid respectively p pod basis matrix qp volumetric extraction rate of the extraction well l 3 t 1 qn a known function r distance of the extraction well node from the centroid of the element associated to it l rn time dependent coefficient vector rw radius of the extraction well l s storage coefficient ss specific storage of the confined aquifer l 1 ssnap snapshot matrix sa drawdown l s a estimated drawdown vector sa d sa 0 known functions tf face centered transmissivity of the fth face of the element l 2 t 1 tfinal final extraction time t s approximate steady state time t time coordinate t f unit vector in the tangential direction along face f from the point of intersection of the line joining the centroids of the parent and the adjacent neighbor element t s snapshot time set u v matrix of left and right singular vectors respectively ws specific volumetric source or sink t 1 wf wn element to face inverse distance weighted interpolation function and element to node area weighted interpolation function respectively x vector of space coordinates in the euclidean space l zα zβ natural logarithmic value of field hydraulic conductivity at sampled locations and estimated logarithmic value of hydraulic conductivity for irregular unstructured grid elements respectively l t 1 za hydraulic head l γ d γ n dirichlet and neumann boundaries respectively γ model semivariogram δ dirac delta function δn f δt f distance between the centroids of the parent element and neighbor element adjacent to the face f in the normal and tangential directions to the face respectively l ϵ r incremental value of r 1 for each iteration l θ degree of implicitness λα λβ kriging coefficient corresponding to primary and secondary basis values respectively μ lagrange multiplier σ diagonal matrix with the singular values as the diagonal elements σ singular value σc 2 σuc 2 conditional and unconditional variances respectively σerror 2 estimation error variance ϕα ϕβ area weighting coefficient corresponding to primary and secondary basis values respectively ω physical domain ω power law exponent φ angle subtended in radians with the extraction well node by the element associated to it f inward flux from the associated element to the extraction well node l 3 t 1 credit authorship contribution statement saumava dey conceptualization methodology validation writing original draft anirban dhar supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary material supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103703 appendix a supplementary materials supplementary data s1 supplementary raw research data this is open data under the cc by license http creativecommons org licenses by 4 0 supplementary data s1 
