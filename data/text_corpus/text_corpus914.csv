index,text
4570,food security is important for human well being worldwide however changing climate population growth and shrinking land resources are threatening food security in many regions of the world jiangsu province china is one such region it is a major food producing region of the country but is witnessing rapid population growth and urbanization that is putting pressure on agricultural water and land resources and threatening food security of the region this paper interprets the nexus between regional water availability and food security in jiangsu province under different climate change and socio economic scenarios of population growth and land resource availability climate change scenarios are generated based on historical data and global climate model gcm products socio economic scenarios are generated based on population growth and crop planted area projections the uptake of water and nutrients are considered as two dominant biophysical processes of crop growth and food production complementing it is human agency including human labor irrigation and land preparation machinery which are the factors behind water and nutrient use efficiencies of crops grown two dominant crops are considered rice and wheat that contribute to 61 4 of total crops produced in the province results show that adaptation by human agency is necessary to ensure that food supply meets at least the demand of the province under all climate change and socio economic scenarios under relatively favorable scenarios labor could replace land preparing machinery since the level of food production can be easily maintained with abundant water and land availability mechanization in agricultural production significantly increases food production under unfavorable conditions since it improves water and nutrient use efficiencies and leads to higher crop yields this demonstrates that human agency plays an important role in securing food under stressful scenarios of drier climate population growth and contraction of agricultural lands keywords climate change food security scenario analysis water and nutrient use efficiencies trade off between human labor and machinery in agriculture 1 introduction maintaining sufficient food supply is key to a healthy population and social stability springmann et al 2016 kaiser 2011 this can either be realized through trade or through high and stable level of food produced locally the latter is especially important under changing climate and evolving socio economic conditions turral et al 2011 such as rapid population growth mccarthy et al 2018 and shrinking agricultural lands hou et al 2019 qiu et al 2020 this is because trade will likely be disrupted more often offering less reliable means of securing food for local population cardwell 2014 under changing climate local food production is expected to be affected by changing water availability and impact food security and agricultural employment hertel and rosch 2010 rosemberg 2010 siwar et al 2013 food security i e when food supply of a region is at least able to meet its own demand is affected directly by such changing agro ecological conditions and crop yields as well as indirectly by inequitable distribution of incomes schmidhuber and tubiello 2007 changing socio economic conditions garibaldi and pérez méndez 2019 such as shrinking agricultural land resources for food crops are also expected to reduce overall food production van vliet et al 2017 wang 2019 this exasperates food insecurity with rising demand for food due to population growth avery et al 2019 mondal and sanaul 2019 jiangsu province china is one such region that exemplifies the pressures on food security as one of the major regions of crop production in china gu and guo 2011 the province produces 37 million tons of food crops bsc 2019 and supports the enormous food demand of the country it is also one of the regions which is under water stress li and li 2012 xu et al 2011 and witnessing land and population growth pressures zhang et al 2004 qian et al 2008 zhu and ou 2020 with agricultural land shrinking in the process of urbanization people are shifting from rural agriculture to modern industries leading to rural to urban migration lyu et al 2019 the province is likely to face food insecurity in the future and adaptation strategies are urgently needed xu and ding 2015 often not enough adaptation to bio physical impacts high cost of measures short term merit but long term negative adaptations and lack of feasible adaptive strategies hinder adequate response to climate and socioeconomic changes warner and geest 2013 this highlights the need to unravel possible means to adapt under diverse future scenarios and secure sufficient food challinor et al 2010 which move away from more expensive hard interventions such as supply oriented measures to soft interventions examples of the latter include how water and land resources are governed and used in crop production medeiros and sivapalan 2020 li and sivapalan 2020 kakinuma et al 2014 this paper uniquely views humans as agents of change that improve water and nutrient use efficiencies and inquires to what extent food security can be ensured for jiangsu province since most food crops are farmed labor is an indispensable part of such human agency achille et al 2015 the agency also includes machineries for irrigation and land preparation which improves the efficiency of water and nutrients uptakes for food crop production febrina et al 2013 ma et al 2020 huang et al 2018 the human agency can adapt crop production to changing conditions and secure food crane et al 2011 olesen et al 2011 leisnham et al 2013 preston et al 2015 gomez zavaglia et al 2020 however no studies yet exist that have modelled human agency in context of crop production and assessed the effects of its adaptation to changing environment on food security the aim of the paper is to assess the extent to which food security can be ensured by adapting human agency under changing conditions of water and land availability in jiangsu province the paper is organized into five sections section 2 describes the methodology used for generating climate change and socio economic scenarios modeling crop production evaluating food security and maximizing it by adapting human agency together with the main data sources used section 3 presents the results of optimized food security under different climate and socio economic scenarios section 4 first discusses the improvements in crop water and nutrient use efficiencies that are brought about by adapting human agency it then discusses the trade offs between labor and machinery employed to optimize food security under different climate change and socio economic scenarios section 5 then summarizes the main conclusions 2 methods and materials fig 1 illustrates the overall methodology a crop model which combines bio physical mechanisms with human agency lyu et al 2020 is applied climate change brought about by greenhouse gas emissions is assumed to effect crop yields due to changes in precipitation the human agency including labor irrigation machinery power and land preparing machinery power per unit area determines the water and nutrient use efficiencies during crop growth the socio economic conditions are assumed to be dominated by population growth and food crop plant area and affect crop production and the ratio of food supply to food demand i e food self sufficiency rate a key indicator of food security the human agency adapts to changing climate and socio economic conditions by improving the water and nutrient use efficiencies of food crops so that higher yields are achieved the food self sufficiency rate within jiangsu province is then determined as the ratio of food supply and food demanded for given population and planted area scenarios here food supply is the product of yield and planted area and food demand is determined by the dietary demand of the population of the province finally it is assumed that the objective of adaptation by human agency is to jointly maximize the magnitude and stability i e lower variance of food self sufficiency rate fsr for a given climate change and socioeconomic scenario over the next 30 years till 2050 the human agency adapts in order to identify non dominated sets of higher and stabler lower variance fsrs here by non dominated sets it is meant that there are no other sets that dominate this set in terms of either having higher or stabler fsr 2 1 study area as shown in fig 2 jiangsu province is located in the southeastern coast of china the province is in a transition zone between subtropical and warm temperate climate with annual precipitation around 1000 mm year three of the main rivers of china run through it yi shu si huaihe and yangzi including the taihu lake river network benefiting from its abundant river systems and water resources jiangsu is one of the main exporters of food crops to other provinces in china li et al 2009 it is able to supply food not only for its own residents but also to other provinces across the country there are eight crop monitoring stations providing crop locations and related information of the growing seasons six stations for wheat fengxian ganyu xuyi huaiyin yangzhou kunshan and three stations for rice ganyu dantu gaochun are considered 2 2 stochastic climate scenario generation representative concentration pathways rcps ipcc 2019 have been applied as emission scenarios for climate backgrounds to generate regional precipitation and temperature time series with uncertainty lobell et al 2006 regional precipitation time series have been produced with a multi model climate generator called simgen greene et al 2012 2015 greene 2012 the simgen climate generator incorporates nonlinear climate change trends inferred using an ensemble of global climate models from the coupled model intercomparison project cmip5 taylor et al 2012 meehl and hibbard 2007 hibbard et al 2007 hurrell et al 2011 under a given rcp condition simgen first uses a selected number of global climate models gcms to simulate historical precipitation data at the stations within the study area as shown in fig 2 and evaluates the performance of each gcm based on its correlation with the historical precipitation time series greene et al 2012 eyring 2013 aloysius et al 2016 gcms with correlation coefficients higher than 0 50 are selected for generating climate scenario time series for future time steps the frequency distributions of temperature change c and fractional change of precipitation with per c change of temperature together with the cumulative frequency distribution function cdf of the selected gcms for rcps 8 5 and 2 6 are shown in fig 3 a b for the study area a combination of a selected gcm corresponding to a percentile on the frequency distribution with a rcp used by simgen then produces corresponding precipitation and temperature time series with stochastic effects here 100 runs each of 2 3 combinations of two rcps 2 6 8 5 and three gcm percentiles 10 50 95 are used to generate climate change scenarios for more details on simgen readers are referred to greene 2012 rcp2 6 represents a pathway where the radiation forcing reaches to about 3 w m2 before 2100 and then declines the corresponding greenhouse gas emission concentration path emission concentration pathway ecp assumes constant emissions after 2100 rcp8 5 represents a pathway in which the radiation forcing reaches greater than 8 5 w m2 and continues to rise after 2100 the corresponding ecp assumes constant greenhouse gas emission after 2100 and constant greenhouse gas concentration after year 2250 precipitation time series have been generated for the six wheat crop stations and three rice crop stations see fig 2 for each combination of rcp and gcm percentile the generated climate scenarios have four dimensions p t i j k where t is the time step 50 years from 2001 to 2050 in total with climate scenarios applied since 2018 i denotes crop type 1 for wheat and 2 for rice j represents crop monitoring station j 1 6 for wheat j 1 3 for rice k indexes a stochastic run of simgen with given rcp and gcm percentile 100 runs in total 2 3 generation of options for adaptation by human agency labor capita irrigation machinery power and land preparing machinery power per unit area are treated as human agency it improves the efficiencies of water and nutrient uptake thereby improving crop yields in order to generate realistic options for adaptation by human agency appropriate data generating processes that describe temporal evolution of human agency are first identified these are based on growth rate time series from 2002 to 2017 of labor force g l irrigation machinery power g mi and land preparing machinery power g ml autoregressive integrated moving average model kotu and deshpande 2018 arima 1 0 0 is applied to the time series of g l g mi and g ml as it is found to be most appropriate model of the past time series being arima 1 0 0 the lag coefficients of the models i e τ l τ mi and τ ml for respective time series are sufficient to describe the time series in order to stochastically simulate the time series 2000 tuples of arima coefficients τ l τ mi and τ ml within the range of 0 9999 0 9999 are randomly sampled for a given climate scenario the generated coefficient tuples are then expressed as τ l r τ mi r τ ml r r 1 2000 with 2000 samples of coefficient tuples time series of g l g mi and g ml are stochastically generated and 2000 human agency time series of human labor force irrigation machinery power and land preparing machinery power per area are thus obtained 2 4 crop production simulation as shown in fig 1 a crop production model is used that combines both bio physical factors and human agency in simulating crop yields lyu et al 2020 have demonstrated its utility in simulating wheat and rice production in jiangsu province china the crop production model treats normalized difference vegetation index ndvi as resulting from the joint effect of water and nutrient uptakes on plant greenness therefore the effect of water uptake represented by transpiration t on ndvi is first filtered out and the remaining variance of ndvi is then assumed to approximate the effect of uptake of nutrients n the yield uptake relationship is then defined in the form of a production function y λ x w α x n β where y is crop yield x w is water uptake given by η w p x n is nutrient uptake given by η n f α and β are corresponding elasticities and λ is a scaling factor this production function represents the biophysical responses of crop yields to water and nutrient uptakes lyu et al 2020 the parameters λ α β therefore do not assess economic or technological aspects of human agency the human agency determines the water and nutrient use efficiencies η w and η n respectively that translate available water p and applied nutrients f to water and nutrient uptakes x w and x n respectively the relationship between water or nutrient use efficiency and human agency is estimated based on the following equations η w j λ h j δ j w 1a b η n j θ h j θ j n here j refers to a crop monitoring station h j represent station specific human activities but its effect on efficiencies λ θ are general across all the stations fixed station specific effects are quantified by δ i θ i and w n represent the residuals accounting for the variances of efficiencies not explained by h human agency such as labor used in crop production l c irrigation machinery power m i and land preparing machinery power m l per unit area are considered in the set of independent variables h all combinations of joint and individual effects such as l c m i m l l c m i m i m l l c m i l c m i and m l are first regressed and only those effects that were statistically significant are selected in the final model in the calibration of eq 1 station specific observed values of η w and η n were calculated as η w t p and η n n f where t and p are transpiration and precipitation fluxes respectively integrated over the crop growing seasons n is the nutrient proxy and f is fertilizer use per area which is the nutrient resource for croplands see supplementary materials for the estimated parameters of the equations climate change scenarios impose its effects on crop growth via precipitation p kawuma menya 2011 kukal and irmak 2018 makowski et al 2020 the simulated crop yields i e crop production per unit planted area under each climate scenario i e a combination of a rcp and a gcm percentile q for either wheat or rice is represented by variable y t j p q r where t is time step 50 years from 2001 to 2050 with climate scenarios applied since 2018 j represents a crop monitoring station j 1 6 for wheat j 1 3 for rice r denotes human agency scenario r 1 2000 and p represents a stochastic run of simgen under each climate scenario p 1 100 2 5 socio economic scenarios for a given level of crop yield as determined by the human agency factors under a climate change scenario socio economic conditions linked to population and plant area finally determine the level of food self sufficiency within the study area as shown in fig 4 three scenarios of population low mid high have been simulated based on provincial population prediction datasets bureau of statistics of jiangsu 2002 2012 and the observed time series of population within the province bureau of statistics of jiangsu 2019 the crop plant area scenarios are based on the planted area dataset in the statistical yearbook of jiangsu bureau of statistics of jiangsu 2018 and the cost per unit area dataset in the china rural statistical yearbook national bureau of statistics 2002 2018 future crop planted area time series have been simulated based on relationships between two food crops wheat rice and six cash crops used as benchmark since these crops compete over finite land area available and the decisions to grow which crops are affected by the costs of growing those crops chen et al 2016 zhao and yan 2019 it is assumed that farmers are cost minimizers the farmers decide on how much area is allocated to food crops relative to cash crops based on minimizing costs chen 2019 mo et al 2020 corresponding efficiency conditions imply linear relationships between areas under food crops relative to cash crops and costs of cash crops relative to food crops following steps outline the steps taken to unravel the linear relationships first the time series of the total planted areas of the eight selected crops are observed to vary linearly in time a linear forecasting model r 0 95 p value 10 3 as shown in fig 5 a is used to estimate past trend based on historical data from 2011 to 2018 and to generate trend based scenarios of total planted area for the future the ratios of food crop planted areas with the six cash crops c planted areas are then estimated based on linear regressions with the ratios of cash crop average cost per unit area with the food crops cost per unit area as the independent variables a v a c f 1 y c y v 2a b a r a c f 2 y c y r where a v and a r are the planted areas of wheat v and rice r respectively y v y r and y c are the costs per unit areas of wheat rice and cash crops respectively and f 1 and f 2 are linear functions fig 5b and 5c show the regression results for wheat r 0 84 p value 10 4 and for rice r 0 92 p value 10 7 it shows that the cash crops within the province have been gradually replaced by food crops because the cost per unit area of cash crops have been increasing relative to that of food crops finally the slope of the trend line for total planted area estimated based on historical data above is used to generate scenarios for future areas planted under food crops according to the statistical yearbook of jiangsu in 2018 the area planted under wheat and rice in jiangsu was 4618 68 kha 103 ha whereas the area under the six cash crops was 274 93 kha i e 5 of area under food crops this means that food crops have already dominated the cash crops in the province and may not significantly increase in the future therefore the future scenarios of area under food crops only considered stable or declining trends i e constant or negative slopes of the linear forecasting models for wheat and rice for it to be realistic random errors were added based on the residuals between observed and linear model of the historic data four scenarios from low to high slopes are created as shown in fig 6 the lowest slope scenario is based on the slope displayed in fig 5a the other three use scaled slopes which are 75 50 and 25 of the slope in the lowest slope scenario as shown in fig 6 the four crop plant area scenarios from low to high were named as 0al 1am1 2am2 and 3ah a means area l means low m means medium and h means high 2 6 food security indicator self sufficiency ratio food self sufficiency rate ψ is defined as the ratio of food crop production to food crop demand of the province the food crop production per capita is calculated as follows 3 y t m n p q r a v t n 6 j 1 6 y v t j p q r a r t n 3 j 1 3 y r t j p q r ϕ t m where y t m n p q r is the food crop production per capita at time step t for human agency scenario r with precipitation time series p for each climate scenario q there are k 1 100 precipitation time series with stochastic effects of climate under plant area scenario n and population scenario m a v t n and a r t n are the plant areas of wheat v and rice r at time t under plant area scenario n ϕ t m is the population at time step t under population scenario m j represent the agricultural meteorological monitoring stations for wheat j 1 6 for rice j 1 3 note that the numerator of equation 3 is the sum of wheat and rice production levels averaged over the six and three corresponding stations respectively the calculation of self sufficiency ratio ψ t m n p q r is defined as 4 ψ t m n p q r y t m n p q r d where y t m n p q r is the food crop production per capita d is the demand per capita for wheat and rice the total food crop demand was assumed as 400 kg capita wang et al 2013 no shift in diet is considered that may lead to changes either in the total demand for food crops per capita or in the demand for wheat relative to rice considering that the total production of wheat and rice in 2018 accounted for about 88 7 of all food crops bsc 2019 a factor of 0 90 is used to estimate total d for wheat and rice as 360 kg capita 2 7 food security under each of the six climate change scenarios two rcps and three gcm percentiles 100 precipitation time series are stochastically generated for each such generation 2000 human agency options are applied that are randomly sampled according to the arima model to obtain corresponding crop yields for rice and wheat then 12 socio economic scenarios i e three population scenarios and four crop planted area scenarios are used to estimate the food sufficiency ratio within jiangsu province china for a given climate scenario q population scenario m and crop planted area scenario n a collection of food self sufficiency rates ψ t m n p q r are obtained note here that r 1 2000 denotes the human agency options i e combination of labor irrigation and land preparing machinery power per unit area of cropland and p 1 100 denotes the 100 precipitation time series with stochastic effects under the given climate scenario q simplifying ψ t m n p q r to ψ t p r a two dimensional food security indicator is estimated that considers the magnitude and variance of food sufficiency ratio over time in order to estimate the average magnitude of food sufficiency average of food sufficiency ratio is first estimated over the 100 stochastic precipitation time series 5 ψ t r 1 100 p 1 100 ψ t p r the magnitude and variance of food self sufficiency rate are then obtained by the equations below respectively 6a ψ ì r 1 50 t 1 50 ψ t r 6b σ ψ r 1 50 1 t 1 50 ψ t r 1 50 t 1 50 ψ t r 2 these two quantities provide the two dimensions of food security which are how large and how stable food sufficiency is over time the two quantities can also be thought of as two objectives to be optimized by adapting human agency under different climate and socioeconomic scenarios e g in the form 7a b min ψ ì r σ ψ r given the nature of the objective function being multi objective non dominated sets of ψ ì r σ ψ r are sought the human agency parameter tuples τ l r τ mi r τ ml r corresponding to non dominated sets are identified as the adaptation by human agency to secure food non dominated sets are such that there are no other ways human agency can adapt that will result in both larger magnitude of food self sufficiency ratio as well as stabler i e with lower variance ratio these therefore describe how the time series of human agency should evolve over time in order to optimize food security for the region 2 8 data sources the data sources of all the datasets are shown below in table 1 3 results 3 1 food secure non dominated sets fig 7 a and b show the non dominated sets pareto frontier of ψ ì r σ ψ r for two climate scenarios which correspond to food secure options identified from amongst the simulated adaptation options by human agency i e from 2000 random samples of tuples τ l r τ mi r τ ml r the impact of crop plant area contraction scenarios on food security is most significant fig 7a and b display the food security scenarios including non dominated sets for the least optimistic climate scenario rcp8 5 p10 and the most optimistic climate scenario rcp2 6 p95 rcp 8 5 is generally taken as the basis for worst case climate change scenario since it assumes that the emission of green house gases will continue to rise throughout the 21st century on the other hand rcp 2 6 assumes the most stringent limitations on future green house gas emissions the temperature rise under rcp 8 5 is generally higher than that under rcp 2 6 as shown in fig 3a b and leads to less precipitation in each of the figures the three rows correspond to the three population scenarios named as 1popl 2popm 3poph the definitions of these population scenarios are listed in table 2 the four columns of fig 7a and b correspond to the four crop planted area a scenarios namely 0al 1am1 2am2 and 3ah see fig 6 here l means low standing for the most negative growth rate i e contraction rates of 33 93 kha year after 2018 of planted area m1 and m2 correspond to relatively mild planted area contraction rates after 2018 i e 75 and 50 of low scenario rates respectively h means high with a relatively stable growth rate of planted area after 2018 which is 25 of the value in the low scenario both the figures confirm that the food secure pareto frontier moves towards higher level of average food sufficiency ratios when population growth rate is lower or planted area contracts slower this is intuitive because faster population growth puts food security under stress while more available land for crops leads to more production of food thereby increasing food self sufficiency moreover the pareto frontier rotates clockwise as higher levels of food self sufficiency ψ ì are achieved this means that food self sufficiency is more variable over time at higher levels of average food self sufficiency indicating that the tradeoff between the two objectives i e min ψ ì r and min σ ψ r increases with higher levels of average food self sufficiency rate the pattern of the effects of climate scenarios on food self sufficiency rate is similar to those of socio economic scenarios the food secure pareto frontier moves towards higher level of food sufficiency in the most optimistic scenario rcp2 6 p95 but with higher variability than in the case of rcp8 5 p10 3 2 pareto optimal food self sufficiency time series fig 8 a and b show the median values of average food self sufficiency ratios for non dominated human agency sets and for dominated sets in gray sets for the two scenarios rcp8 5 p10 and rcp2 6 p95 the time series are from 2018 to 2050 which are shown along with the historical values available from 2001 to 2017 the 3poph 0al scenario is the worst socioeconomic scenario for food security for both the climate scenarios the worst scenario is the least optimistic climate scenario with highest population growth rate and rapidly declining crop planted area under the scenario of rapidly declining crop planted area the average food self sufficiency rate drops below 1 0 when human agency doesn t adapt indicating heightened risk of food insecurity however with adaptation by human agency the food self sufficiency rate is maintained above 1 0 this means that human agency has the ability to ensure food security even under least optimistic scenarios of the future under the most optimistic socioeconomic scenario of 1popl 3ah shown in fig 8b the average food self sufficiency rate keeps rising and finally reaches a value above 1 2 the most optimistic scenario is the most optimistic climate scenario with slowest growth in population and no contraction of available cropland with food self sufficiency rate higher than 1 0 the crop production within the province can satisfy the food demand of the province and outside also note that the difference between the dominated and non dominated solutions is not as high as in the least optimistic scenario meaning that adaptation by human agency plays a critical role when dealing with less optimistic future scenarios for the scenarios in between average food self sufficiency can be maintained between 1 0 and 1 2 when human agency adapts to changing conditions adaptation by human agency is important even under more optimistic scenarios since without it food self sufficiency can fall below 1 0 corresponding to the dominated food sufficiency time series the median levels of food self sufficiency for non dominated solutions red lines in fig 8a and b are always higher than that of dominated solutions gray line again the gap between the non dominated and the dominated time series is more significant under less optimistic scenarios i e with higher temperature less precipitation less crop plant area and more stress from population growth the subplot 3poph 0pal in fig 8a shows that the gap of food self sufficiency between non dominated and dominated solutions can exceed by 10 under the least optimistic climate and socioeconomic scenario under the scenarios of e g lower pressure on cropland area and from population growth from 0al to 3ah the gap between non dominated and dominated solutions narrows and is between 5 and 10 this indicates the importance of adaptation by human agency under more stressful climate and socioeconomic conditions e g of drought or fast pace urbanization human agency which is a combination of labor irrigation and land preparation machinery can effectively ensure food security within jiangsu province under possible future water or land resources stresses 4 discussion 4 1 improving water and nutrient use efficiencies by adapting human agency modern technologies in agriculture such as irrigation and land preparation machineries can bring significant improvements in the water and nutrient use efficiencies of crops water saving irrigation technology has been applied to 2637 47 2767 23 kha from 2017 to 2018 bureau of statistics of jiangsu 2019 which is about 34 9 36 8 of total agricultural cropland within the province across china latest technologies such as water fertilizer integrated irrigation system based on internet of things iot has also been designed and proposed shi et al 2017 hao et al 2020 also land preparing machinery are better in preparing croplands for higher nutrient use efficiency of food crops than human labor fig 9 shows the average level of water and nutrient use efficiencies in log space under two extreme scenarios most optimistic and least optimistic climate and socioeconomic scenarios the non dominated efficiencies are higher in general under unfavorable conditions more trade off between the two in wheat production compared to rice is due to how sensitive crop specific efficiencies are related to human agency the water use efficiency of wheat is sensitive to the human agency under non dominated cases while that of rice is not however the nutrient use efficiency of both wheat and rice can be significantly improved with adapting human agency i e corresponding to non dominated cases the difference between non dominated and dominated efficiencies under favorable conditions is insignificant which again emphasizes that human agency matters when conditions are unfavorable there is more scope for improving efficiencies when conditions are unfavorable due to poor water and land supply and high food demand 4 2 trade offs between labor and machinery used fig 10 a and b plot labor l c against land preparing machinery power m l for two climate scenarios rcp 8 5 p10 and rcp 2 6 p95 the rows of each figure denote population growth rates three levels from low to high whereas the columns represent crop plant area contraction rates four levels from low to high modern machinery appears to be the main agency that delivers higher food self sufficiency under all circumstances under unfavorable socioeconomic conditions i e with higher population growth and sharper contraction of available land resources for crop cultivation agricultural land preparing machinery plays more important role to ensure nutrient and water use efficiency in order to increase the production of food crop ensuring a higher and stabler supply of food the effect of labor on food sufficiency is relatively low this indicates that agricultural mechanization would ensure food security in jiangsu province under the unfavorable scenario of rapid urbanization agricultural lands will shrink in the process of urbanization this will shift people from rural agriculture to modern industries leading to rural to urban migration lyu et al 2019 agricultural mechanization can however replace the demand of shrinking human labor while ensuring same or higher levels of food production thereby ensuring food security in the region under the scenarios of less stressed socioeconomic conditions i e lower population growth or lower contraction of crop planted area the need for agricultural machinery which can rapidly improve crop unit yields and thus result in higher food self sufficiency rate would not be that urgent compared to the unfavorable case more labor can be hired to relieve under employment in rural agriculture areas similarly in context of climate scenarios agricultural labor demand would slightly rise in more optimistic climate scenarios since the urgency to use agricultural machinery is eased to a certain extent when the climate is less optimistic e g rcp8 5 p10 agricultural machinery is important agency that should be adapted to improve food crop production capacity and ensure high and stable food self sufficiency 5 conclusion this study investigated how food security can be ensured within jiangsu province china under different climate and socioeconomic scenarios by adapting human agency the human agency comprises of crop production labor irrigation machinery power and land preparing machinery climate scenarios included six combinations of two rcps rcp 2 6 and rcp 8 5 and three percentiles 10 50 95 of a distribution of gcms most representative of the past climate conditions of the province the socioeconomic scenarios considered combinations of three population growth rates and four rates of crop plant area growth into the future two crops rice and wheat were considered the predicted time series of food self sufficiency rate were evaluated and trade offs between human power and land preparing machinery power were analyzed to reveal the critical role played by human agency in adapting to different climate and socio economic conditions the results demonstrated that adapting human agency led to improved water and nutrient use efficiencies of crop production especially in least optimistic climate and socioeconomic scenarios the jiangsu province can be self sufficient in food under all considered climate and socioeconomic scenarios considered when options are available for human agency to adapt the gap between adaption and non adaptation solutions was found to be larger under more challenging scenarios of lesser precipitation higher population growth or stronger contraction of crop plant area this suggests that human adaptation can significantly improve food security within jiangsu province especially when there are higher stresses of water or land resources insecurity under lower water or land resources stress conditions labor could replace land preparing machinery since the level of food production can be easily maintained with abundant water and land availability on the other hand when climate change negatively affects the precipitation or when population rises more rapidly machinery such as water saving irrigation or even water fertilizer integrated irrigation systems together with land preparing machinery instead of human labor could lead to higher levels of water and nutrient use efficiencies these are much needed to secure food under adverse conditions the applied crop model lyu et al 2020 ignores seeds and pesticides inputs to crop production as reported in the literature ignoring these inputs can lead to over estimation of production levels zida et al 2011 similarly only precipitation and temperature effects of climate change were considered and not those of co2 fertilization this may lead to under estimation of production levels under adverse climate change scenarios rashid et al 2019 we used historical 18 years agro meteorological stations data here crop yields were not limited by availability of seeds and fertilizers therefore it would not be possible to assess the effects of these inputs on crop yields and production however assessing the positive feedbacks between co2 concentration and crop yields is possible we defer this improvement in crop model for future research 6 declarations the authors declare that there is no financial or personal interest or belief that could affect their objectivity credit authorship contribution statement haoyang lyu conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization zengchuan dong supervision conceptualization saket pande supervision conceptualization validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126344 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4570,food security is important for human well being worldwide however changing climate population growth and shrinking land resources are threatening food security in many regions of the world jiangsu province china is one such region it is a major food producing region of the country but is witnessing rapid population growth and urbanization that is putting pressure on agricultural water and land resources and threatening food security of the region this paper interprets the nexus between regional water availability and food security in jiangsu province under different climate change and socio economic scenarios of population growth and land resource availability climate change scenarios are generated based on historical data and global climate model gcm products socio economic scenarios are generated based on population growth and crop planted area projections the uptake of water and nutrients are considered as two dominant biophysical processes of crop growth and food production complementing it is human agency including human labor irrigation and land preparation machinery which are the factors behind water and nutrient use efficiencies of crops grown two dominant crops are considered rice and wheat that contribute to 61 4 of total crops produced in the province results show that adaptation by human agency is necessary to ensure that food supply meets at least the demand of the province under all climate change and socio economic scenarios under relatively favorable scenarios labor could replace land preparing machinery since the level of food production can be easily maintained with abundant water and land availability mechanization in agricultural production significantly increases food production under unfavorable conditions since it improves water and nutrient use efficiencies and leads to higher crop yields this demonstrates that human agency plays an important role in securing food under stressful scenarios of drier climate population growth and contraction of agricultural lands keywords climate change food security scenario analysis water and nutrient use efficiencies trade off between human labor and machinery in agriculture 1 introduction maintaining sufficient food supply is key to a healthy population and social stability springmann et al 2016 kaiser 2011 this can either be realized through trade or through high and stable level of food produced locally the latter is especially important under changing climate and evolving socio economic conditions turral et al 2011 such as rapid population growth mccarthy et al 2018 and shrinking agricultural lands hou et al 2019 qiu et al 2020 this is because trade will likely be disrupted more often offering less reliable means of securing food for local population cardwell 2014 under changing climate local food production is expected to be affected by changing water availability and impact food security and agricultural employment hertel and rosch 2010 rosemberg 2010 siwar et al 2013 food security i e when food supply of a region is at least able to meet its own demand is affected directly by such changing agro ecological conditions and crop yields as well as indirectly by inequitable distribution of incomes schmidhuber and tubiello 2007 changing socio economic conditions garibaldi and pérez méndez 2019 such as shrinking agricultural land resources for food crops are also expected to reduce overall food production van vliet et al 2017 wang 2019 this exasperates food insecurity with rising demand for food due to population growth avery et al 2019 mondal and sanaul 2019 jiangsu province china is one such region that exemplifies the pressures on food security as one of the major regions of crop production in china gu and guo 2011 the province produces 37 million tons of food crops bsc 2019 and supports the enormous food demand of the country it is also one of the regions which is under water stress li and li 2012 xu et al 2011 and witnessing land and population growth pressures zhang et al 2004 qian et al 2008 zhu and ou 2020 with agricultural land shrinking in the process of urbanization people are shifting from rural agriculture to modern industries leading to rural to urban migration lyu et al 2019 the province is likely to face food insecurity in the future and adaptation strategies are urgently needed xu and ding 2015 often not enough adaptation to bio physical impacts high cost of measures short term merit but long term negative adaptations and lack of feasible adaptive strategies hinder adequate response to climate and socioeconomic changes warner and geest 2013 this highlights the need to unravel possible means to adapt under diverse future scenarios and secure sufficient food challinor et al 2010 which move away from more expensive hard interventions such as supply oriented measures to soft interventions examples of the latter include how water and land resources are governed and used in crop production medeiros and sivapalan 2020 li and sivapalan 2020 kakinuma et al 2014 this paper uniquely views humans as agents of change that improve water and nutrient use efficiencies and inquires to what extent food security can be ensured for jiangsu province since most food crops are farmed labor is an indispensable part of such human agency achille et al 2015 the agency also includes machineries for irrigation and land preparation which improves the efficiency of water and nutrients uptakes for food crop production febrina et al 2013 ma et al 2020 huang et al 2018 the human agency can adapt crop production to changing conditions and secure food crane et al 2011 olesen et al 2011 leisnham et al 2013 preston et al 2015 gomez zavaglia et al 2020 however no studies yet exist that have modelled human agency in context of crop production and assessed the effects of its adaptation to changing environment on food security the aim of the paper is to assess the extent to which food security can be ensured by adapting human agency under changing conditions of water and land availability in jiangsu province the paper is organized into five sections section 2 describes the methodology used for generating climate change and socio economic scenarios modeling crop production evaluating food security and maximizing it by adapting human agency together with the main data sources used section 3 presents the results of optimized food security under different climate and socio economic scenarios section 4 first discusses the improvements in crop water and nutrient use efficiencies that are brought about by adapting human agency it then discusses the trade offs between labor and machinery employed to optimize food security under different climate change and socio economic scenarios section 5 then summarizes the main conclusions 2 methods and materials fig 1 illustrates the overall methodology a crop model which combines bio physical mechanisms with human agency lyu et al 2020 is applied climate change brought about by greenhouse gas emissions is assumed to effect crop yields due to changes in precipitation the human agency including labor irrigation machinery power and land preparing machinery power per unit area determines the water and nutrient use efficiencies during crop growth the socio economic conditions are assumed to be dominated by population growth and food crop plant area and affect crop production and the ratio of food supply to food demand i e food self sufficiency rate a key indicator of food security the human agency adapts to changing climate and socio economic conditions by improving the water and nutrient use efficiencies of food crops so that higher yields are achieved the food self sufficiency rate within jiangsu province is then determined as the ratio of food supply and food demanded for given population and planted area scenarios here food supply is the product of yield and planted area and food demand is determined by the dietary demand of the population of the province finally it is assumed that the objective of adaptation by human agency is to jointly maximize the magnitude and stability i e lower variance of food self sufficiency rate fsr for a given climate change and socioeconomic scenario over the next 30 years till 2050 the human agency adapts in order to identify non dominated sets of higher and stabler lower variance fsrs here by non dominated sets it is meant that there are no other sets that dominate this set in terms of either having higher or stabler fsr 2 1 study area as shown in fig 2 jiangsu province is located in the southeastern coast of china the province is in a transition zone between subtropical and warm temperate climate with annual precipitation around 1000 mm year three of the main rivers of china run through it yi shu si huaihe and yangzi including the taihu lake river network benefiting from its abundant river systems and water resources jiangsu is one of the main exporters of food crops to other provinces in china li et al 2009 it is able to supply food not only for its own residents but also to other provinces across the country there are eight crop monitoring stations providing crop locations and related information of the growing seasons six stations for wheat fengxian ganyu xuyi huaiyin yangzhou kunshan and three stations for rice ganyu dantu gaochun are considered 2 2 stochastic climate scenario generation representative concentration pathways rcps ipcc 2019 have been applied as emission scenarios for climate backgrounds to generate regional precipitation and temperature time series with uncertainty lobell et al 2006 regional precipitation time series have been produced with a multi model climate generator called simgen greene et al 2012 2015 greene 2012 the simgen climate generator incorporates nonlinear climate change trends inferred using an ensemble of global climate models from the coupled model intercomparison project cmip5 taylor et al 2012 meehl and hibbard 2007 hibbard et al 2007 hurrell et al 2011 under a given rcp condition simgen first uses a selected number of global climate models gcms to simulate historical precipitation data at the stations within the study area as shown in fig 2 and evaluates the performance of each gcm based on its correlation with the historical precipitation time series greene et al 2012 eyring 2013 aloysius et al 2016 gcms with correlation coefficients higher than 0 50 are selected for generating climate scenario time series for future time steps the frequency distributions of temperature change c and fractional change of precipitation with per c change of temperature together with the cumulative frequency distribution function cdf of the selected gcms for rcps 8 5 and 2 6 are shown in fig 3 a b for the study area a combination of a selected gcm corresponding to a percentile on the frequency distribution with a rcp used by simgen then produces corresponding precipitation and temperature time series with stochastic effects here 100 runs each of 2 3 combinations of two rcps 2 6 8 5 and three gcm percentiles 10 50 95 are used to generate climate change scenarios for more details on simgen readers are referred to greene 2012 rcp2 6 represents a pathway where the radiation forcing reaches to about 3 w m2 before 2100 and then declines the corresponding greenhouse gas emission concentration path emission concentration pathway ecp assumes constant emissions after 2100 rcp8 5 represents a pathway in which the radiation forcing reaches greater than 8 5 w m2 and continues to rise after 2100 the corresponding ecp assumes constant greenhouse gas emission after 2100 and constant greenhouse gas concentration after year 2250 precipitation time series have been generated for the six wheat crop stations and three rice crop stations see fig 2 for each combination of rcp and gcm percentile the generated climate scenarios have four dimensions p t i j k where t is the time step 50 years from 2001 to 2050 in total with climate scenarios applied since 2018 i denotes crop type 1 for wheat and 2 for rice j represents crop monitoring station j 1 6 for wheat j 1 3 for rice k indexes a stochastic run of simgen with given rcp and gcm percentile 100 runs in total 2 3 generation of options for adaptation by human agency labor capita irrigation machinery power and land preparing machinery power per unit area are treated as human agency it improves the efficiencies of water and nutrient uptake thereby improving crop yields in order to generate realistic options for adaptation by human agency appropriate data generating processes that describe temporal evolution of human agency are first identified these are based on growth rate time series from 2002 to 2017 of labor force g l irrigation machinery power g mi and land preparing machinery power g ml autoregressive integrated moving average model kotu and deshpande 2018 arima 1 0 0 is applied to the time series of g l g mi and g ml as it is found to be most appropriate model of the past time series being arima 1 0 0 the lag coefficients of the models i e τ l τ mi and τ ml for respective time series are sufficient to describe the time series in order to stochastically simulate the time series 2000 tuples of arima coefficients τ l τ mi and τ ml within the range of 0 9999 0 9999 are randomly sampled for a given climate scenario the generated coefficient tuples are then expressed as τ l r τ mi r τ ml r r 1 2000 with 2000 samples of coefficient tuples time series of g l g mi and g ml are stochastically generated and 2000 human agency time series of human labor force irrigation machinery power and land preparing machinery power per area are thus obtained 2 4 crop production simulation as shown in fig 1 a crop production model is used that combines both bio physical factors and human agency in simulating crop yields lyu et al 2020 have demonstrated its utility in simulating wheat and rice production in jiangsu province china the crop production model treats normalized difference vegetation index ndvi as resulting from the joint effect of water and nutrient uptakes on plant greenness therefore the effect of water uptake represented by transpiration t on ndvi is first filtered out and the remaining variance of ndvi is then assumed to approximate the effect of uptake of nutrients n the yield uptake relationship is then defined in the form of a production function y λ x w α x n β where y is crop yield x w is water uptake given by η w p x n is nutrient uptake given by η n f α and β are corresponding elasticities and λ is a scaling factor this production function represents the biophysical responses of crop yields to water and nutrient uptakes lyu et al 2020 the parameters λ α β therefore do not assess economic or technological aspects of human agency the human agency determines the water and nutrient use efficiencies η w and η n respectively that translate available water p and applied nutrients f to water and nutrient uptakes x w and x n respectively the relationship between water or nutrient use efficiency and human agency is estimated based on the following equations η w j λ h j δ j w 1a b η n j θ h j θ j n here j refers to a crop monitoring station h j represent station specific human activities but its effect on efficiencies λ θ are general across all the stations fixed station specific effects are quantified by δ i θ i and w n represent the residuals accounting for the variances of efficiencies not explained by h human agency such as labor used in crop production l c irrigation machinery power m i and land preparing machinery power m l per unit area are considered in the set of independent variables h all combinations of joint and individual effects such as l c m i m l l c m i m i m l l c m i l c m i and m l are first regressed and only those effects that were statistically significant are selected in the final model in the calibration of eq 1 station specific observed values of η w and η n were calculated as η w t p and η n n f where t and p are transpiration and precipitation fluxes respectively integrated over the crop growing seasons n is the nutrient proxy and f is fertilizer use per area which is the nutrient resource for croplands see supplementary materials for the estimated parameters of the equations climate change scenarios impose its effects on crop growth via precipitation p kawuma menya 2011 kukal and irmak 2018 makowski et al 2020 the simulated crop yields i e crop production per unit planted area under each climate scenario i e a combination of a rcp and a gcm percentile q for either wheat or rice is represented by variable y t j p q r where t is time step 50 years from 2001 to 2050 with climate scenarios applied since 2018 j represents a crop monitoring station j 1 6 for wheat j 1 3 for rice r denotes human agency scenario r 1 2000 and p represents a stochastic run of simgen under each climate scenario p 1 100 2 5 socio economic scenarios for a given level of crop yield as determined by the human agency factors under a climate change scenario socio economic conditions linked to population and plant area finally determine the level of food self sufficiency within the study area as shown in fig 4 three scenarios of population low mid high have been simulated based on provincial population prediction datasets bureau of statistics of jiangsu 2002 2012 and the observed time series of population within the province bureau of statistics of jiangsu 2019 the crop plant area scenarios are based on the planted area dataset in the statistical yearbook of jiangsu bureau of statistics of jiangsu 2018 and the cost per unit area dataset in the china rural statistical yearbook national bureau of statistics 2002 2018 future crop planted area time series have been simulated based on relationships between two food crops wheat rice and six cash crops used as benchmark since these crops compete over finite land area available and the decisions to grow which crops are affected by the costs of growing those crops chen et al 2016 zhao and yan 2019 it is assumed that farmers are cost minimizers the farmers decide on how much area is allocated to food crops relative to cash crops based on minimizing costs chen 2019 mo et al 2020 corresponding efficiency conditions imply linear relationships between areas under food crops relative to cash crops and costs of cash crops relative to food crops following steps outline the steps taken to unravel the linear relationships first the time series of the total planted areas of the eight selected crops are observed to vary linearly in time a linear forecasting model r 0 95 p value 10 3 as shown in fig 5 a is used to estimate past trend based on historical data from 2011 to 2018 and to generate trend based scenarios of total planted area for the future the ratios of food crop planted areas with the six cash crops c planted areas are then estimated based on linear regressions with the ratios of cash crop average cost per unit area with the food crops cost per unit area as the independent variables a v a c f 1 y c y v 2a b a r a c f 2 y c y r where a v and a r are the planted areas of wheat v and rice r respectively y v y r and y c are the costs per unit areas of wheat rice and cash crops respectively and f 1 and f 2 are linear functions fig 5b and 5c show the regression results for wheat r 0 84 p value 10 4 and for rice r 0 92 p value 10 7 it shows that the cash crops within the province have been gradually replaced by food crops because the cost per unit area of cash crops have been increasing relative to that of food crops finally the slope of the trend line for total planted area estimated based on historical data above is used to generate scenarios for future areas planted under food crops according to the statistical yearbook of jiangsu in 2018 the area planted under wheat and rice in jiangsu was 4618 68 kha 103 ha whereas the area under the six cash crops was 274 93 kha i e 5 of area under food crops this means that food crops have already dominated the cash crops in the province and may not significantly increase in the future therefore the future scenarios of area under food crops only considered stable or declining trends i e constant or negative slopes of the linear forecasting models for wheat and rice for it to be realistic random errors were added based on the residuals between observed and linear model of the historic data four scenarios from low to high slopes are created as shown in fig 6 the lowest slope scenario is based on the slope displayed in fig 5a the other three use scaled slopes which are 75 50 and 25 of the slope in the lowest slope scenario as shown in fig 6 the four crop plant area scenarios from low to high were named as 0al 1am1 2am2 and 3ah a means area l means low m means medium and h means high 2 6 food security indicator self sufficiency ratio food self sufficiency rate ψ is defined as the ratio of food crop production to food crop demand of the province the food crop production per capita is calculated as follows 3 y t m n p q r a v t n 6 j 1 6 y v t j p q r a r t n 3 j 1 3 y r t j p q r ϕ t m where y t m n p q r is the food crop production per capita at time step t for human agency scenario r with precipitation time series p for each climate scenario q there are k 1 100 precipitation time series with stochastic effects of climate under plant area scenario n and population scenario m a v t n and a r t n are the plant areas of wheat v and rice r at time t under plant area scenario n ϕ t m is the population at time step t under population scenario m j represent the agricultural meteorological monitoring stations for wheat j 1 6 for rice j 1 3 note that the numerator of equation 3 is the sum of wheat and rice production levels averaged over the six and three corresponding stations respectively the calculation of self sufficiency ratio ψ t m n p q r is defined as 4 ψ t m n p q r y t m n p q r d where y t m n p q r is the food crop production per capita d is the demand per capita for wheat and rice the total food crop demand was assumed as 400 kg capita wang et al 2013 no shift in diet is considered that may lead to changes either in the total demand for food crops per capita or in the demand for wheat relative to rice considering that the total production of wheat and rice in 2018 accounted for about 88 7 of all food crops bsc 2019 a factor of 0 90 is used to estimate total d for wheat and rice as 360 kg capita 2 7 food security under each of the six climate change scenarios two rcps and three gcm percentiles 100 precipitation time series are stochastically generated for each such generation 2000 human agency options are applied that are randomly sampled according to the arima model to obtain corresponding crop yields for rice and wheat then 12 socio economic scenarios i e three population scenarios and four crop planted area scenarios are used to estimate the food sufficiency ratio within jiangsu province china for a given climate scenario q population scenario m and crop planted area scenario n a collection of food self sufficiency rates ψ t m n p q r are obtained note here that r 1 2000 denotes the human agency options i e combination of labor irrigation and land preparing machinery power per unit area of cropland and p 1 100 denotes the 100 precipitation time series with stochastic effects under the given climate scenario q simplifying ψ t m n p q r to ψ t p r a two dimensional food security indicator is estimated that considers the magnitude and variance of food sufficiency ratio over time in order to estimate the average magnitude of food sufficiency average of food sufficiency ratio is first estimated over the 100 stochastic precipitation time series 5 ψ t r 1 100 p 1 100 ψ t p r the magnitude and variance of food self sufficiency rate are then obtained by the equations below respectively 6a ψ ì r 1 50 t 1 50 ψ t r 6b σ ψ r 1 50 1 t 1 50 ψ t r 1 50 t 1 50 ψ t r 2 these two quantities provide the two dimensions of food security which are how large and how stable food sufficiency is over time the two quantities can also be thought of as two objectives to be optimized by adapting human agency under different climate and socioeconomic scenarios e g in the form 7a b min ψ ì r σ ψ r given the nature of the objective function being multi objective non dominated sets of ψ ì r σ ψ r are sought the human agency parameter tuples τ l r τ mi r τ ml r corresponding to non dominated sets are identified as the adaptation by human agency to secure food non dominated sets are such that there are no other ways human agency can adapt that will result in both larger magnitude of food self sufficiency ratio as well as stabler i e with lower variance ratio these therefore describe how the time series of human agency should evolve over time in order to optimize food security for the region 2 8 data sources the data sources of all the datasets are shown below in table 1 3 results 3 1 food secure non dominated sets fig 7 a and b show the non dominated sets pareto frontier of ψ ì r σ ψ r for two climate scenarios which correspond to food secure options identified from amongst the simulated adaptation options by human agency i e from 2000 random samples of tuples τ l r τ mi r τ ml r the impact of crop plant area contraction scenarios on food security is most significant fig 7a and b display the food security scenarios including non dominated sets for the least optimistic climate scenario rcp8 5 p10 and the most optimistic climate scenario rcp2 6 p95 rcp 8 5 is generally taken as the basis for worst case climate change scenario since it assumes that the emission of green house gases will continue to rise throughout the 21st century on the other hand rcp 2 6 assumes the most stringent limitations on future green house gas emissions the temperature rise under rcp 8 5 is generally higher than that under rcp 2 6 as shown in fig 3a b and leads to less precipitation in each of the figures the three rows correspond to the three population scenarios named as 1popl 2popm 3poph the definitions of these population scenarios are listed in table 2 the four columns of fig 7a and b correspond to the four crop planted area a scenarios namely 0al 1am1 2am2 and 3ah see fig 6 here l means low standing for the most negative growth rate i e contraction rates of 33 93 kha year after 2018 of planted area m1 and m2 correspond to relatively mild planted area contraction rates after 2018 i e 75 and 50 of low scenario rates respectively h means high with a relatively stable growth rate of planted area after 2018 which is 25 of the value in the low scenario both the figures confirm that the food secure pareto frontier moves towards higher level of average food sufficiency ratios when population growth rate is lower or planted area contracts slower this is intuitive because faster population growth puts food security under stress while more available land for crops leads to more production of food thereby increasing food self sufficiency moreover the pareto frontier rotates clockwise as higher levels of food self sufficiency ψ ì are achieved this means that food self sufficiency is more variable over time at higher levels of average food self sufficiency indicating that the tradeoff between the two objectives i e min ψ ì r and min σ ψ r increases with higher levels of average food self sufficiency rate the pattern of the effects of climate scenarios on food self sufficiency rate is similar to those of socio economic scenarios the food secure pareto frontier moves towards higher level of food sufficiency in the most optimistic scenario rcp2 6 p95 but with higher variability than in the case of rcp8 5 p10 3 2 pareto optimal food self sufficiency time series fig 8 a and b show the median values of average food self sufficiency ratios for non dominated human agency sets and for dominated sets in gray sets for the two scenarios rcp8 5 p10 and rcp2 6 p95 the time series are from 2018 to 2050 which are shown along with the historical values available from 2001 to 2017 the 3poph 0al scenario is the worst socioeconomic scenario for food security for both the climate scenarios the worst scenario is the least optimistic climate scenario with highest population growth rate and rapidly declining crop planted area under the scenario of rapidly declining crop planted area the average food self sufficiency rate drops below 1 0 when human agency doesn t adapt indicating heightened risk of food insecurity however with adaptation by human agency the food self sufficiency rate is maintained above 1 0 this means that human agency has the ability to ensure food security even under least optimistic scenarios of the future under the most optimistic socioeconomic scenario of 1popl 3ah shown in fig 8b the average food self sufficiency rate keeps rising and finally reaches a value above 1 2 the most optimistic scenario is the most optimistic climate scenario with slowest growth in population and no contraction of available cropland with food self sufficiency rate higher than 1 0 the crop production within the province can satisfy the food demand of the province and outside also note that the difference between the dominated and non dominated solutions is not as high as in the least optimistic scenario meaning that adaptation by human agency plays a critical role when dealing with less optimistic future scenarios for the scenarios in between average food self sufficiency can be maintained between 1 0 and 1 2 when human agency adapts to changing conditions adaptation by human agency is important even under more optimistic scenarios since without it food self sufficiency can fall below 1 0 corresponding to the dominated food sufficiency time series the median levels of food self sufficiency for non dominated solutions red lines in fig 8a and b are always higher than that of dominated solutions gray line again the gap between the non dominated and the dominated time series is more significant under less optimistic scenarios i e with higher temperature less precipitation less crop plant area and more stress from population growth the subplot 3poph 0pal in fig 8a shows that the gap of food self sufficiency between non dominated and dominated solutions can exceed by 10 under the least optimistic climate and socioeconomic scenario under the scenarios of e g lower pressure on cropland area and from population growth from 0al to 3ah the gap between non dominated and dominated solutions narrows and is between 5 and 10 this indicates the importance of adaptation by human agency under more stressful climate and socioeconomic conditions e g of drought or fast pace urbanization human agency which is a combination of labor irrigation and land preparation machinery can effectively ensure food security within jiangsu province under possible future water or land resources stresses 4 discussion 4 1 improving water and nutrient use efficiencies by adapting human agency modern technologies in agriculture such as irrigation and land preparation machineries can bring significant improvements in the water and nutrient use efficiencies of crops water saving irrigation technology has been applied to 2637 47 2767 23 kha from 2017 to 2018 bureau of statistics of jiangsu 2019 which is about 34 9 36 8 of total agricultural cropland within the province across china latest technologies such as water fertilizer integrated irrigation system based on internet of things iot has also been designed and proposed shi et al 2017 hao et al 2020 also land preparing machinery are better in preparing croplands for higher nutrient use efficiency of food crops than human labor fig 9 shows the average level of water and nutrient use efficiencies in log space under two extreme scenarios most optimistic and least optimistic climate and socioeconomic scenarios the non dominated efficiencies are higher in general under unfavorable conditions more trade off between the two in wheat production compared to rice is due to how sensitive crop specific efficiencies are related to human agency the water use efficiency of wheat is sensitive to the human agency under non dominated cases while that of rice is not however the nutrient use efficiency of both wheat and rice can be significantly improved with adapting human agency i e corresponding to non dominated cases the difference between non dominated and dominated efficiencies under favorable conditions is insignificant which again emphasizes that human agency matters when conditions are unfavorable there is more scope for improving efficiencies when conditions are unfavorable due to poor water and land supply and high food demand 4 2 trade offs between labor and machinery used fig 10 a and b plot labor l c against land preparing machinery power m l for two climate scenarios rcp 8 5 p10 and rcp 2 6 p95 the rows of each figure denote population growth rates three levels from low to high whereas the columns represent crop plant area contraction rates four levels from low to high modern machinery appears to be the main agency that delivers higher food self sufficiency under all circumstances under unfavorable socioeconomic conditions i e with higher population growth and sharper contraction of available land resources for crop cultivation agricultural land preparing machinery plays more important role to ensure nutrient and water use efficiency in order to increase the production of food crop ensuring a higher and stabler supply of food the effect of labor on food sufficiency is relatively low this indicates that agricultural mechanization would ensure food security in jiangsu province under the unfavorable scenario of rapid urbanization agricultural lands will shrink in the process of urbanization this will shift people from rural agriculture to modern industries leading to rural to urban migration lyu et al 2019 agricultural mechanization can however replace the demand of shrinking human labor while ensuring same or higher levels of food production thereby ensuring food security in the region under the scenarios of less stressed socioeconomic conditions i e lower population growth or lower contraction of crop planted area the need for agricultural machinery which can rapidly improve crop unit yields and thus result in higher food self sufficiency rate would not be that urgent compared to the unfavorable case more labor can be hired to relieve under employment in rural agriculture areas similarly in context of climate scenarios agricultural labor demand would slightly rise in more optimistic climate scenarios since the urgency to use agricultural machinery is eased to a certain extent when the climate is less optimistic e g rcp8 5 p10 agricultural machinery is important agency that should be adapted to improve food crop production capacity and ensure high and stable food self sufficiency 5 conclusion this study investigated how food security can be ensured within jiangsu province china under different climate and socioeconomic scenarios by adapting human agency the human agency comprises of crop production labor irrigation machinery power and land preparing machinery climate scenarios included six combinations of two rcps rcp 2 6 and rcp 8 5 and three percentiles 10 50 95 of a distribution of gcms most representative of the past climate conditions of the province the socioeconomic scenarios considered combinations of three population growth rates and four rates of crop plant area growth into the future two crops rice and wheat were considered the predicted time series of food self sufficiency rate were evaluated and trade offs between human power and land preparing machinery power were analyzed to reveal the critical role played by human agency in adapting to different climate and socio economic conditions the results demonstrated that adapting human agency led to improved water and nutrient use efficiencies of crop production especially in least optimistic climate and socioeconomic scenarios the jiangsu province can be self sufficient in food under all considered climate and socioeconomic scenarios considered when options are available for human agency to adapt the gap between adaption and non adaptation solutions was found to be larger under more challenging scenarios of lesser precipitation higher population growth or stronger contraction of crop plant area this suggests that human adaptation can significantly improve food security within jiangsu province especially when there are higher stresses of water or land resources insecurity under lower water or land resources stress conditions labor could replace land preparing machinery since the level of food production can be easily maintained with abundant water and land availability on the other hand when climate change negatively affects the precipitation or when population rises more rapidly machinery such as water saving irrigation or even water fertilizer integrated irrigation systems together with land preparing machinery instead of human labor could lead to higher levels of water and nutrient use efficiencies these are much needed to secure food under adverse conditions the applied crop model lyu et al 2020 ignores seeds and pesticides inputs to crop production as reported in the literature ignoring these inputs can lead to over estimation of production levels zida et al 2011 similarly only precipitation and temperature effects of climate change were considered and not those of co2 fertilization this may lead to under estimation of production levels under adverse climate change scenarios rashid et al 2019 we used historical 18 years agro meteorological stations data here crop yields were not limited by availability of seeds and fertilizers therefore it would not be possible to assess the effects of these inputs on crop yields and production however assessing the positive feedbacks between co2 concentration and crop yields is possible we defer this improvement in crop model for future research 6 declarations the authors declare that there is no financial or personal interest or belief that could affect their objectivity credit authorship contribution statement haoyang lyu conceptualization methodology software validation formal analysis investigation data curation writing original draft writing review editing visualization zengchuan dong supervision conceptualization saket pande supervision conceptualization validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126344 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4571,springs are an indispensable source of freshwater for mountain communities in the indian himalayan region ihr owing to the synergistic impact of anthropogenic and climatic factors numerous perennial springs and streams in the region are either becoming ephemeral or drying out thus impacting the local people water scarcity poverty and limited scope of alternate livelihoods further reduce the communities resilience our focus is to assess the potential of reviving drying springs with the help of hydro geological studies in water scarce villages the methodology involved high resolution data monitoring of springs and first order streams in two headwater micro watersheds namely shiv gadera and haraita in the rural himalayas of uttarakhand india with unalike topography and geology to understand the hydro geological processes and assess the flow regimes and aquifer storage dynamics we applied water balance correlation flow duration master recession curves analysis and geological studies the univariate and bivariate analysis shows that shiv gadera has a better system memory indicating a larger storage capacity than haraita the spring hydrograph responses also append that shiv gadera has better storage and has a homogenous aquifer feed the water balance however is in positive storage only during the rainy months in both the sites the hydro geological characterization from hydrograph analysis recession analysis and field surveys shows that shiv gadera has intricate flow networks and slow flow velocities while haraita is characteristic of transmissive fractured rocks the spring flows in shiv gadera are observed to be perennial and more groundwater contributes to spring discharges while haraita exhibits intermittent to ephemeral nature the recession curves also indicate uniform geology a distinctive feed from recharge area and slow emptying of the aquifer while haraita exhibits shallow storage and quick responses to storms spring flows in shiv gadera show better stability than haraita as indicated by q10 q90 and q50 q90 measurements these inferences qualify shiv gadera as having a better chance of responding to management and treatments thus a better potential for revival the combination of hydrologic time series analysis and geological characterization used in this study could be a valuable approach for assessing spring revival in the ihr and has a potential for implementation across other parts of the himalayas keywords springshed recession curves time series analysis water balance spring aquifers himalayas list of terms and definitions sl no term definition 1 amphibolites it is a coarse grained metamorphic rock composed of amphibole minerals formed by regional metamorphism in convergent plate boundaries 2 bedding planes it is the discrete boundary surface parallel to the stratum separating two rock beds groundwater flow is facilitated by joints fractures in bedding planes 3 biophysical of or relating to humans and its relationship with its physical environment which includes attributes associated with the role that hydrologic regime geomorphology biodiversity climate and community plays in securing a socio ecological system s capacity to sustain essential ecosystem services and their relationships with social demand for management services water governance land use and development 4 central crystalline a continuous lithotectonic unit spanning from kumaun in the east to kashmir in the west a term used to refer to crystalline rocks of the himalayas the rock mass shows progressive regional metamorphism with mineral assemblages of pelites meta calcareous and basic rocks 5 fracture spring system it refers to a concerted flow of water from bedding planes joints cleavage faults and other breaks in consolidated hard or low permeability rock groundwater movement is mainly through fractures and may tap shallow as well as deep aquifers such spring systems occur when these fractures intersect the land surface 6 interventions the act of designing and executing measures or practices to preserve or restore spring ecosystems considering a broad approach integrating the management of forests soil and water systems governance and stakeholder participation 7 mechanistic mechanistic understanding is the viewpoint that states the behavioural responses of complex systems such as montane springs are determined strictly by the interactions of the individual factors or components mechanistic description of a system can be obtained from an analysis of observational time series and interpreting physically meaningful terms from monitoring exercises and experimentation carried out in natural systems 8 nappe a large coherent sheet like rock body tectonic unit that has moved a distance several times its thickness and over 5 km along a sub horizontal floor from its original position nappes form when a rock mass is forced over another at a low angle fault plane 9 one umbrella approach it refers to the successful management and development practices on one site being executed in multiple locations with a view that the particular successful practice conforms to all ecosystems and yield similar outcomes 10 preferential pathways it is the movement of water by preferred flow channels at an accelerated speed in a fraction of geologic media the controlling factors are the degree of fracture connectivity and the distribution of conductivities among fractures and sparsely by orientation and elevation of fracture walls 1 introduction himalayan mountain communities have historically been dependent on springs as the primary water source for meeting their domestic and agricultural needs valdiya and bartarya 1989 vashisht and sharma 2007 a total of roughly five million springs serve over two hundred million inhabitants in india sikdar 2019 in terms of food livelihood and energy naik et al 2002 according to niti aayog 2018 a government of india think tank report states that 60 of the five million springs across india are located in the indian himalayan region ihr and nearly 50 of them are either drying up or becoming seasonal amidst climate change anthropogenic stressors and lack of scientific watershed management an acute decline of discharge in several himalayan springs has been observed in the last two decades agarwal et al 2012 a comprehensive study mahamuni and kulkarni 2012 of the urban himalayan region discerned that 8000 villages face acute water scarcity issues valdiya and bartarya 1989 investigated 35 years of spring discharge data of the kumaon himalayas they reported a decline in spring discharge in 40 of studied villages of which over 2 had gone dry springs of mid himalayas of nepal are also drying up due to the coupled impact of biophysical and socio economic factors icimod 2015 moreover a survey conducted in sikkim revealed that all the springs in the state have declined by half a dreadful situation for a himalayan state almost entirely reliant on springs tambe et al 2011 springs are a multi component entity including a watershed aquifer and an outlet each component having distinct characteristics however the problems related to springs are often addressed as a demand supply approach and the aspects of ecological degradation watershed characteristics geology and groundwater flow regime remain unaddressed hence there is an urgent need to enhance a holistic understanding of spring systems in the context of these aspects considering the growing water crisis in the ihr himalayan non government organizations ngos and the sikkim government realized the importance of a paradigm shift in interventions from a supply side approach and partnered with local communities to map and protect spring sources kulkarni et al 2015 quite a few intervention programs have been implemented in the himalayas following a one umbrella management approach agarwal et al 2012 sharma and shakya 2006 whereas site specific springshed management plan is the need of the hour springsheds as defined by the florida geological survey 2003 struhs et al 2003 are those areas within ground and surface water basins that contribute to the discharge of springs thus a springshed which is administratively bifurcated into two regions maybe spanning over a shared aquifer hence local community participation is essential to be considered in a springshed development plan for the sustainability of himalayan springs several interventions and management approaches have been convened in the himalayas garg et al 2012 singh et al 2014 tambe et al 2012 reported up to 230 increase in spring discharge attributed to field interventions in sikkim and inferred that recharge area identification and building local capacity are crucial factors in springshed development it has also been observed in many cases that a successful intervention practice implemented at a particular site is often replicated without considering the variations in hydroclimatic and geological settings such practices may not yield the expected results for spring rejuvenation according to chinnasamy and prathapar 2016 understanding himalayan spring hydro geology is below par and sparsely investigated bruijnzeel and bremmer 1989 emphasized the need for an improved understanding of himalayan hydrological processes to develop better management plans as current knowledge is inadequate and may not solve the escalating water scarcity problems regardless of the emergent nature and subsequent consequences of this crisis increasing water demands along with ecological degradation and rapid urbanization shall continually affect spring flow rates natural springs and their sustainable development in the ihr are given less due importance at both policy and practice levels even though these play a pivotal role in water security this situation is primarily because of major gaps between data and understanding be it hydrological or socio economic data concerning community dependence on springs and their role in nurturing socio cultural services bridging the gap is essential to learn about the existing interlinkages between the biophysical attributes lithology and spring flow responses this shall be pertinent in scaling out springshed development methods and innovative management strategies for a long term water resources management plan assessing the current scenario water demand and availability must be done well in advance sharma and shakya 2006 scientific understanding of water resource systems responses to ever changing trends requires knowledge of the effects of present conditions and projected future responses mccarthy et al 2002 besides the local community needs to be sensitized and involved in cooperative action to ensure equity and sustainability of the plans developed for water security planning commission india 2007 hence extensive field research to attain a new mechanistic understanding of how a spring system works is necessary there is a vast scope of knowledge in the sustainable management of himalayan spring systems primarily due to a lack of detailed understanding of hydro geological processes within the system like subsurface water movement and spring flow continuum aquifer recharge processes and rainfall response variabilities in different hydro geological settings investigation of underlying processes requires field monitoring techniques and the monitored data e g spring flow time series combined with rainfall data and field geologic survey this gives insights into the drivers of hydrological processes controlling groundwater flow and recharge mechanism the objectives of the study are to i explore the usefulness of time series analysis for a mechanistic understanding of springshed scale hydrological processes ii determine the hydro geology of springsheds and understand water flow processes iii assess the spring flow characteristics using flow duration curves and master recession analysis and iv estimate the potential of spring aquifer recharge the study shall improve the conceptual understanding of himalayan spring systems and aid in water security planning and design the study hypothesizes that working at a springshed scale will result in a holistic approach to manage water resources as each of the two selected sites are hydrologically definedgeographic areas and unique in physiography ecology water quality and land use further highly fractured and weathered springshed systems are unfavorable to aquifer storage in the context of the prevailing hydroclimatic scenario this is because the rate of discharge decline or increment is externally controlled by recharge variability and spring flow stability this can be mainly attributed to the storage capacity and the extent of flow systems that feed it subsequently an aquifer system will respond to the designed treatment initiatives based on the geology s transmissive nature and its storage potential overall this study aims to present the situational assessment of existing hydro geological processes taking the case of two micro watersheds of uttarakhand for developing a springshed management strategy that envisions to attain water security in the rural indian himalayas by integrating hydro geological studies and community participation the paper is organized as follows the details of the study area instrumentation data collection and methods of analysis are described in the next section the results and interpretations of the study are presented in section3 which is followed by section4 where we summarize the main inferences conclude the analysis and acknowledge our supporters 2 materials and methodology two pilot micro watersheds shiv gadera and haraita were selected within the sahigad and pundoliraul watersheds in uttarakhand state india fig 2 firstly in a two part research approach weather stations were set up for hydro meteorological data collection and monitoring at sub hourly scales secondly a parallel hydro geological field assessment to layout conceptual springshed maps and understand the geological influence on the hydrological outputs was conducted a detailed geological mapping of the study area including the determination of the lithological and structural framework of the area as well as measuring the dominant orientation of bedrock fractures and foliation present in the rocks was done a combination of topographical information and site investigations making extensive use of rock exposures present along roads and the stream as well as any other exposed outcrops was used geological literature and other historical data were also compiled to study the impact on the springs parshall flumes and hs flumes gauged the stream and spring flows respectively in both the micro watersheds further description of the methodological approach and research framework of the study can be found in fig 1 this framework can well be suitable for any other springshed system 2 1 study area 2 1 1 general description two micro watersheds shiv gadera and haraita selected for the study are located in the almora and pauri garhwal districts of uttarakhand state india respectively fig 2 appendix f geographically these districts are located in two different regions of uttarakhand i e kumaon and garhwal and are classified as water scarce regions with a high dependency on springs for drinking domestic and irrigation water demands the sahigad watershed lies in the headwater of kosi river which is a springfed river and has shown a decline in discharge aronsson and piculell 2011 it is used as a major water supply source for many areas in almora flow data of the river shows that its average low flow decreased steadily from 995 l per second lps in 1994 to 196 lps in 2004 rawat 2013 recharging springs will not only increase the water availability for the villagers but could also help revive small streams that feed the kosi river shiv gadera is the headwater micro watershed where instruments have been installed for hydrological monitoring fig 3 the second watershed is pundoliraul which is one of the most water scarce blocks of the district the selected springs and a stream for instrumentation are in dashmeri village this site was chosen as it forms a headwater micro watershed haraita required for this study fig 4 the micro watershed hosts several springs most of whose discharge reduces mainly during the summer season in the western himalayan region it is quite a common phenomenon to find habitation nearby springs and these habitations are majorly affected during the summers piped water supply is available in the concerned villages but it is inadequate and irregular especially during summers as it is also spring based which are gradually drying up springs are the major sources of drinking domestic and irrigation water in both the selected micro watersheds but due to climate variations and changes in land use these are becoming critical in terms of their discharge unlike other parts of the world eg in italy and florida usa dragoni et al 2013 united states department of agriculture 2012 there is no pumping schemes in these watersheds to utilize the springs for water supply 2 1 2 geology 2 1 2 1 hydro geological setup of the study area shiv gadera almora three major lithotectonic divisions have been postulated within the lesser kumaon himalaya each characterized by distinctive lithology and structures the most dominant rock formation of the lesser kumaon himalaya form part of the central crystallines thrusted synformally southward they occur from south to north as follows heim and gansser 1939 i the outer krol nappe is comprising of pre tertiary mild metamorphosed sediments confined in the north by south almora thrust and the main boundary fault in the south ii the almora nappe is comprising of metamorphics that are intimately associated with granitic rocks this nappe is represented by two klippe the almora crystallines in the central part and baijnath and askot crystallines in the northeast iii the two inner krol nappes comprises mildly metamorphosed sediments bordered in the south by the north almora thrust and main central thrust in the north the regional structural setting of the study area is controlled by tectonics compressional in nature leading to himalayan orogeny joshi and tiwari 2009 the process has transformed sandstone to low grade quartzite further crushing the rock and giving a crumbly appearance the shear zone has also developed during different phases of himalayan orogeny valdiya 1980 the earlier two episodes were represented by tight to isoclinal reclined folds having similar geometry and orientation and the later deformations were of open folds oriented at right angles to each other chamyal 1991 the nw dipping fractures have developed during the second episode of deformation as a consequence of being distributed uniformly throughout the region highly fragile zones are observed at the ridges while the central portion is relatively less deformed chamyal 1991 in the central portion of watershed high undulations were observed on the eastern side of the map beds are trending ne sw dipping towards south east while the bedding planes are near horizontal especially near the ridge to gentle ranging from 20 to 30 quartzite is the dominant lithology in the study area and is characteristic of low primary porosity but considerable secondary porosity the monitored spring shiv dhara is a fractured spring and it is perennial the villagers use it throughout the year even though they have a pipeline supply in their village the maintenance of this spring is done by the water user group of this spring the average discharge of the spring measured in april 2018 was 1 2 lpm 2 1 2 2 hydro geological setup of the study area haraita pauri garhwal all the rural households inhabiting haraita micro watershed are dependent on spring water for their household needs the aquifer systems of haraita micro watershed are sustained by primary and secondary porosities of rock units schist which has undergone weathering process with quartzite interband forms the major portion of the study area although both have very little primary porosity schist possesses poor primary porosity and permeability owing to this the presence of joints and fractures becomes crucial for the development of secondary porosity in these rocks the joints fractures and cavities thus provide conduits for transmission and storage of water within the rocks although their distribution varies according to the rock type hydrologically the study area is categorized into two zones based on permeability compact and soft lithology zones the soft zone comprises overburdened soil they form a suitable aquifer system for springs and originates several depression type perennial springs in addition this zone is underlined by water holding rock strata compact zone provides another unconfined aquifer system which is majorly comprised of quartzite and schists rocks in this zone are hard and compact possessing very little primary porosity but have high secondary porosity viz fractures joints cavities springs in these zones are dominantly fractured type seasonal springs 2 1 2 3 methodology for hydro geological studies regional geology and stratigraphy were studied on the ground and literature regarding the study area has been consulted toposheets survey of india of the study area were collected for plotting the geological data and locating the springs outcrops were studied to gather information about the various rock types and trends of openings which may be in the form of bedding planes foliation planes fractures and faults the direction and attitude of rock beds and geological structures were measured using a brunton which further helped in determining the recharge area of the concerned spring as different rock types their attitude openings and the various structural features govern the accumulation and movement of groundwater the dip and strike of different types of rocks form the basis of geological mapping to identify the underlying geological conditions and to interpret the type of spring or aquifer spring locations were marked and discharge rate was measured the point of the emergence of the spring helps in the classification of the spring and also gives an idea of the geologic formation which acts as the aquifer storing and transmitting groundwater to it the dip and strike of the rocks and slopes of the given region were measured the lithological and structural folds faults and fractures characteristics of the rocks were marked and oriented photographs and samples were taken the foliation types based on schistosity were specified by qualitative comparison of the images with a series of reference photos that have been classified beforehand in the pilot study the rock type identification was followed by the specification of the lithology by image petrology the rock types were identified by visual methods the major characteristics of phyllites are crinkled having wavy appearance with foliations while the schists were identified based on schistosity all the lithologs were recorded and later fed into a spreadsheet program post field work lithological and hydro geological cross section maps were prepared for better understanding and visualization laying out the springshed with its underground structural makeup as conceptual diagrams facilitates a better process understanding of the aquifer mechanisms google earth pro was used for visualizing the location and distribution of data auto cad and corel draw were used to collate all data for deciphering relationships between lithology and groundwater with emphasis on the orientation of features to create the cross sections aquifers and potential recharge areas can be easily depicted in conceptual cross section maps 2 1 2 4 geological assessment of shiv dhara springshed almora the rock type of springshed is quartzite which is striking along n 60 240 and towards n 150 with the dip amount of 20 along with this there are two major sets of fractures present in the area trending ne sw nw se in the central portion three sets of fractures are dipping towards ne sw and nw with moderate dip amounts ranging from 45 55 the nw trending fracture is observed throughout the mapped area a highly compressed landslide prone zone where rocks are extensively fractured known as the shear zone is also observed this is an important factor concerning the movement of groundwater because of the anomalous porosity and permeability developed in the rock along this zone the vertical fracture allows quick infiltration during deformation bedding planes become undulating and develop openings the land use pattern in the recharge area of this spring is covered with community forest the conceptual cross section of the potential recharge area of the spring is shown in fig 5 2 1 2 5 geological assessment of haraita springshed pauri garhwal from the field analysis it is concluded that the springs in the haraita are fractured types the major fracture sets supporting the groundwater are trending 292 45 n22 e 050 75 n40 w and 130 60 s40 w respectively in hard lithology zones fig 6 though trends also change as per local geology hydro geologically the region hosts two main aquifer systems alluvium aquifer system hosts springs at the base towards west separated by thick schist and a weathered quartzite intercalated layer while a highly fractured but closely spaced flaky rock system forms the second aquifer system the area is dominated by schist of low grade metamorphism and possesses characters such as fine grained with shiny luster moderately compact yet highly cleaved in nature the strike shows undulating nature along ne sw and therefore the direction also varies from nw sw and w towards the north intercalated quartzite beds trend n70 n250 towards n340 2 2 experimental setup and field data collection the study sites are instrumented with automatic weather stations aws hs and parshall flumes and other hydrological instruments tabulated in appendix b various environmental sensors installed at aws enabled real time measurement of weather parameters including precipitation relative humidity atmospheric pressure solar radiation flux wind speed and direction the location of all the gauging stations employed in the study areas is described in appendix a continuous water depth data are converted into discharge values using the flume discharge equation the details of the monitoring observatories are tabulated in table 1 appendix a b and the nomenclature of the observatory setup detailed in table 2 2 3 hydrological studies 2 3 1 water balance we utilized the weather parameters recorded by aws for water balance wb analysis of both the micro watersheds the wb components viz rainfall grass reference potential evapotranspiration stream discharge were calculated on a daily basis for shiv gadera almora and haraita pauri garhwal springsheds respectively with no irrigation the water balance equation is deduced in the form 1 δ s p et ref r where δ s is the change in the soil water storage p and r denote the precipitation and runoff respectively et ref is the reference evapotranspiration for grass surface during the computation interval all the wb components are presented as equivalent water depth per unit time i e mm d 1 2 3 2 univariate and bivariate analysis the autocorrelation univariate analysis has been performed to find out the linear dependency of spring and stream discharge values on its preceding time series and to characterize the system s memory such an analysis provides insights into the short and long term influences of an event as the correlograms describe the response of a system to an event the memory effect corresponds to the duration of the time lag starting from initial zero to the point where the correlogram r xx k reaches the value of 0 2 mayaud et al 2014 the autocorrelation function is obtained by normalizing the covariance of the univariate series x i having mean μ x and variance σ x 2 as 2 r xx k c xx k c xx 0 c xx k σ x 2 3 c xx k 1 n t 1 n k x i μ x x i k μ x where k denotes the time lag varying from 0 to m i e length of the time series in our analysis the value of m has been taken as 120 days 1 3 rd of the whole observation period to avoid stability problems mangin 1984 auto correlation reveals the inertia of the system and offers ancillary data on the storage potential of the system and the degree of fractures to analyse the magnitude and time lag of our system s response to a given input we cross correlated rainfall with discharge observations as a cross correlogram will indicate the degree of linear interdependence of the rainfall and spring stream discharge series as a time function the cross correlation function for k 0 is obtained by normalizing the covariance of the bivariate series x i and y i having mean μ x and μ y and variance σ x 2 and σ y 2 respectively larocque et al 1998 as 4 r xy k c xy k c xy 0 c xy k σ x σ y 5 c xy k 1 n t 1 n k x i μ x y i k μ y for k 0 x and y positions are interchanged in eq 4 and eq 5 the delay is defined as the time lag between maximum amplitude of input rainfall and maximum r xx k univariate and bivariate analysis autocorrelation and cross correlation respectively of the discharge and rainfall time series is a complementary analytical technique to study the functioning and hydrodynamic behavior of spring systems long term analysis of the correlograms provides information on spring aquifer functioning unlike single event analysis where we get the spring reaction to a single recharge event mayaud et al 2014 2 3 3 master recession curves analysis the main purpose of master recession curves mrcs method is to quantify the effects of individual recession events to indicate the nature of sub surface processes as discrete recession segments of a hydrograph do not provide much information on aquifer systems due to high variability in storage and recharge fluxes posavec et al 2006 the mrc s provide information on the hydro geological properties and dynamics of the underlying aquifer systems storativity transmissivity and physical characteristics of the recharge area posavec et al 2010 such inferences eventually help in recharge area management mainly attributed to the assessment of aquifer systems the use of mrcs is widely accepted in policymaking and sustainable management of water resources kumar and sen 2018 rivera ramirez et al 2002 two approaches for generating mrcs are employed in our study i matching strip method posavec et al 2006 which formulates an objective automated technique of mrc separation and ii a newly developed mrctoolsv3 0 spreadsheet tool posavec et al 2010 of excel visual basic for applications vbas utilizing trigonometry laws for overlapping individual recession segments the presented mrcs are the best fits yielding better results in terms of high r2 value amongst both the approaches applied viz matching strip method using multiple linear nonlinear regression based method exponential regression model and extracted with respect to q90 flow and trigonometry based mrctoolsv3 0 spreadsheet tool 2 3 4 flow duration analysis we generated flow duration curves fdc to study the relationship between the magnitude and frequency of spring and streamflows during our monitoring period these curves quantify the flow characteristics without considering the sequence of its occurrence and give a frequency distribution of outflows both in time and magnitude searcy 1959 it also provides a feasible platform to compare the flow characteristics of two or more springsheds a comprehensive graphical view of discharge variability at a particular site can be obtained 2 4 community engagement and participation plan local communities were involved in participatory exercises for assessing the usage of spring water and its recharge area the historical transect of the concerned springs further helped in understanding the anthropogenic and natural factors leading to the depletion of spring discharge resource mapping exercise helped in understanding the land usage and ownership of the recharge area awareness campaigns were organized in each village of the concerned micro watersheds in the form of street plays puppet shows and village meetings to generate public interest and support for spring revival this was followed by the formation of village level institutions spring water user groups and their capacity building for operation and maintenance appendix d the planning for spring treatment was done considering the topography soil type land use and land ownership of the identified recharge area along with the water and biomass needs in consultation with the local communities the feasibility of such springshed treatment plans is based on hydro geological assessments due consideration has been given to the traditional practices of spring recharge existing in the region a cadre of para workers mostly women has been developed and trained in spring discharge rainfall and water quality measurements household surveys were conducted to understand the seasonal consumption pattern from the springs for the concerned villages and further to compare it with the prescribed norms fig 7 c shows the annual domestic water consumption for villages dependent on the monitored springs 3 results and discussion 3 1 assessment of micro watershed water yields monthly water balance assessment of both the study sites is performed and compared for a total of 14 months as shown in fig 7 a b both micro watersheds exhibit a seasonal monsoon climate with positive water storage primarily during the monsoon season i e from july september although the number of rainy days is similar for shiv gadera and haraita micro watersheds i e 156 days and 145 days respectively appendix c the amount of total rainfall is almost double in the latter 999879 m3 in haraita compared to 583984 m3 in shiv gadera appendix c less rainfall combined with the higher vegetation cover in shiv gadera micro watershed figs 3 and 4 results in about a two fold increase in the reference evapotranspiration with an average of 6 28 mm d 1 as compared to 2 99 mm d 1 in haraita micro watershed during the study period table 3 this trend of et ref has a negative impact on the aquifer limits as explained in the forthcoming sections despite receiving ample rainfall compared to the country s average annual rainfall i e 1200 mm both the micro watersheds seem unable to continue the above average water storage conditions this behavior can most likely be explained by the prevailing steep terrain degree of fractures in the underlying aquifer systems and highly heterogeneous rainfall 60 and 70 of which occurred during the three months of monsoon season only for both sites respectively a persistent depletion in storage is also observed for the non monsoon months in both the sites fig 7 a b 3 2 assessment of domestic water consumption the seasonal domestic water consumption is shown in fig 7 c kaurali and dashmeri villages are dependent on shiv gadera and haraita spring systems respectively the general trend exhibits more water consumption during summers with the onset of the dry season followed by monsoon and winter seasons in both villages summer season water consumption is lower for dashmeri as compared to kaurali this can be attributed to the presence of three spring systems in haraita of which nauli dhara and jethuna tok are perennial springs on the contrary in shiv gadera the dependency of the village is only on one spring shiv dhara which ultimately leads to higher usage in both the watersheds the water consumption is below 55 lpcd which is the drinking water norms under the national rural drinking water program nrdwp india thus signifying that there is no overexploitation of the water resources in the region or the low consumption might also be due to less availability of water interestingly in the summers the water consumption from springs is more than that from the pipeline water supply as the supply from the latter decreases drastically during summers this might be another reason why the monsoon and winter consumption are less therefore the behavior and the impact of the existing hydro geological conditions on the natural flow rates need to be explicitly investigated particularly for attaining drinking water security the rural communities depend on springs for their drinking domestic and minor irrigation needs for this the naturally overflowing water is used without the use of a pumping system this is because the mountain springs have a small aquifer system and their discharge varies as per the season that is why monsoon fed irrigation is practiced here only after fulfilling the drinking and domestic needs the surplus overflowing water is used for minor irrigation 3 3 spring hydrograph analysis a preliminary assessment of springshed characteristics was done by analyzing spring hydrographs the shape or retardation response of rainfall inputs is closely related to the extent of recharge area intensity of rain evaluation of recharge and storage capacity and assessment of average transmissive properties of aquifer structure kresic and bonacci 2010 the discharge observations for the springsheds are shown in table 3 spring discharges from shiv dhara are perennial with and an average flow of 50 lpm while the spring flows in haraita micro watershed show intermittent flow behavior thus characterizing the primary hydro geological features of the underlying aquifers the springs nauli dhara bichola pani and jethuna tok show significant differences in their average flow rates and decrease across the transect fig 8 d the hydrograph responses indicated that both the springshed systems are highly controlled by precipitation input and the permeability matrix of the aquifer shiv gadera has better storage capacity and homogeneity as the hydrograph responses show a persistent and gradual increase and decrease as compared to the hydrograph of haraita springs fig 8 c and d such an analysis aids in discerning the nature of aquifer feed to the spring system and its flow drainage operation memon 1995 the response of newly infiltrated water on spring flow rate is dependent on the porosity of the rock matrix and the groundwater levels if we consider the case of nauli dhara the initial response of an increase in discharge from 21 lpm to 175 5 lpm 10th july 21st july 19 is due to the pressure propagation through large fractures and conduits and it is not the outflow of the newly infiltrated water such reactions are characteristic of transmissive fracture rock kresic and bonacci 2010 the flow rate stabilizes to 84 8 lpm on 26th july 19 and then starts rising gradually as a response to the rainfall events in june august 2019 after the initial response and recharge events a shift is observed in the recession level from 84 8 lpm to a higher hydrograph level at 187 lpm 25 days after stabilizing the new water upon reaching the spring contributes a fraction of the total flow rate with a certain delay but analysis of spring discharge of bichola pani shows that the spring is drained through a well developed network of fractures and conduits and hence it takes a longer time to dissipate the initial response and it stabilizes at 25 7 lpm after 40 days of nauli dhara attaining stability responding to the same rainfall events analysis of shiv dhara spring discharge shows that after reaching the seasonal spring peak discharge of 85 6 lpm on 27th aug 19 the recession is gradual august through november 2019 the spring maintains an average flow rate of 68 98 lpm during this period groundwater levels and antecedent moisture conditions are most likely high in unsaturated zones and evapotranspiration losses with a median value of 160 7 mm 1 05 mm d 1 is much less than the average of 6 28 mm d 1 for the whole period so the newly infiltrated water raises an already high hydraulic head and the groundwater is easily infiltrated into the aquifer matrix kresic and stevanovic 2010 also a gradual terrain slope and homogenous underlying geology play a key role in maintaining a perennial continuum of shiv dhara spring antecedent storage conditions majorly influence the proportion of rainfall inputs in the system that drains as spring flows and the lag in output responses a sharply peaked hydrograph is observed for haraita spring indicating high fractures and impermeable strata as such hydrograph signatures are characteristic of small storage and rapid discharge whereas the shiv dhara spring exhibits a comparatively flatter wider and delayed response kresic 2006 nauli dhara responds significantly better to rainfall inputs than bichola pani and jethuna tok in haraita and thus proves to be a reliable source for the locals this behavior is observed primarily due to reason that the bedding planes and the rock lineaments actively feed the spring in conjunction during precipitation phases major flows occur during the monsoons and the springs in haraita exhibit intermittent and ephemeral nature whereas shiv dhara is perennial 3 4 response delays and significance the autocorrelation function acf for shiv gadera shows a gradual decline up to 0 5 and 0 4 for the spring and the stream respectively even after 120 days fig 8 g and 8 h the auto correlation for the discharge of both shiv dhara and shiv gadera diminishes very slowly damped with prolonged memory effect during the entire 120 days of time lag this damped response is potentially explained by a larger storage capacity within the shiv gadera micro watershed behrens et al 1992 the aquifer has stored water and contributes to stream and spring continually for a prolonged period in contrast for haraita springs there is a sharp decline in the auto correlogram during the initial 50 to 70 lag days thus showing less memory effect as compared to shiv gadera a shorter memory effect in the haraita micro watershed is an indication that the discharge is an independent variable exhibiting quasi randomness the memory effect of the aquifer system is observed as 50 60 70 days for nauli dhara bichola pani jethuna tok respectively and around 30 days only for the stream as illustrated in fig 8 g and 8 h the acf declines slowly with a higher memory effect for shiv gadera indicating a larger storage capacity of the underlying aquifer than haraita a slow decline over a longer period i e acf 0 2 indicates a strong linear inter relationship behavior influenced by rock matrix storage as slow flow pathways within a matrix require a long time to fill and drain the pores whereas a drop to zero indicates that it is uncorrelated meaning limited storage effect on water level variation an increased memory effect in shiv gadera indicates that the underlying aquifer system is influenced by an event for a more extended time which implies that the system is having considerable storativity a shorter memory effect suggests more developed fractures or an extensive network of flow paths or conduits and an extensive memory indicates a poorly drained network of conduits a gradually decreasing trend in auto correlogram indicates the presence of small fissures through which water flows at much lower velocities as exhibited by shiv gadera almora in contrast a well developed fracture system has little memory and decreases steeply and quickly as shown by haraita pauri garhwal an asymmetrical cross correlation function indicates a high dependency of the springshed systems output i e discharge on system input i e rainfall for both the study sites as shown in fig 8 i j the mean response time represents the lag time of the peak cross correlation coefficient for the time series data over a monitoring period the peak of the function is at a time lag of zero days with a value of 0 63 for haraita and 0 55 for shiv gadera the cross correlogram exhibits a variable impulse response to rainfall for all of the hydrological flow gauging stations with a response time of 15 25 30 days and diminished peaks just ahead of 50 days lag for stream shiv gadera whereas shiv dhara spring has peaks at 25 30 40 and 50 days which are not so pronounced as compared to the stream after 50 days dampening of the impulse response is observed for both the flow gauges this time delay exhibited by rainfall pulse response highlights the significant reduction in input pulse signals during its propagation through the system higher amplitudes in the peaks in shiv gadera as compared to those of shiv dhara signify that the rainfall has a quicker and vital response to the stream discharge the influence of rainfall on the spring discharge follows the order nauli dhara jethuna tok bichola pani in haraita micro watershed for individual rainfall peaks the cross correlation function r xy k increases the most for the stream and verifies that stream discharge is predominantly controlled by rainfall and that the aquifer storage is contributing very little this observation can also be ascertained by the fact that haraita micro watershed has steeper terrain and more barren agricultural land attributing to the lesser evapotranspiration rates delay or transfer speed corresponds to the time lag to maximum r xy k delay in the peaks of the cross correlogram from the rainfall events accounts for the time of propagation of the rainfall impulse to exhibit a response in the outlet a shorter delay indicates faster transfer of the input rainfall influence on the output discharge and a lower signal transfer speed indicates a low degree of fractures an absence of preferential pathways in the aquifer system can be inferred for shiv gadera a low degree of maximum r xy k values show that the input is highly changed throughout the output a comparatively lower value for haraita indicates a complex recharge system post monsoon period exhibits high antecedent moisture conditions helping the input pressure pulse to travel quicker and appearing in the output amplification a highly fractured system like haraita transmits such pressure pulses directly and swiftly to the outlet and thus prevents the aquifer from leveraging the input for recharge but during low flows the highly intricate pores and fissure network channel de saturates thus enabling a gradual and homogenous pulse transmission for deeper infiltration into the saturated zone since the rainfall is not having a user defined pattern the cross correlogram is the signature of the system s impulse response a gradual decrease in cross correlation function for shiv gadera as compared to haraita represents a slower emptying rate of the aquifer and hence a large storage capacity regulating the input flow and propounds the idea that the aquifer storage of haraita is unable to attenuate the flood pulse of the storm event to the same extent as in shiv gadera in shiv gadera amplification in signals can be seen when there is a delay in spring flow due to the release of stored water it also indicates the large storage capacity of the aquifer and this high storage potential can be explained by the presence of minute fissures that store water and release gradually post peak flows when highly transmissive channels are de saturated 3 5 assemblage of flow recession time series and interpretation the mrcs generated for all the sites are presented in fig 9 the coefficient of determination r2 is also presented for comparison with the visuals of the goodness of fit of the selected regression models mrc showed a fairly good fit with the exponential method for both the springsheds with a comparatively lower value of recession coefficient α d 1 calculated for spring in shiv gadera almora 0 038 than in haraita pauri garhwal 0 109 0 088 0 081 respectively shiv gadera s geology can be characterized as having pervasive fracturing which is rather interconnected with low permeability matrices a condition that enables the gradual release of water over time and as a consequence slow emptying of the aquifer feed tarafdar 2013 the low value is a translation of diffused fracture system low permeability matrix and medium to low extent of joint openings on the contrary haraita s hydro geology is characterized by well interconnected joints the shallow extent of recharge area and rapid emptying of the reservoirs feeding the springs amit et al 2002 the higher value of α in this case indicates a small or localized recharge area in the case of shiv dhara and shiv gadera almora the exponential regression and trigonometry based approach generated a narrower mrc envelope respectively and hence a high coefficient of determination of the overlapped recession segments can be seen the responses of spring shiv dhara exhibits a high r2 value of 0 98 the predictability of the shiv dhara s flow can be complemented by its perennial nature and its innate ability to maintain a constant range of flows in the lean season the stream shiv gadera fits better with the trigonometric approach r2 0 98 than the exponential regression fit r2 0 86 as illustrated in appendix e this further supports our inference from correlograms of uniform underlying geology and distinctive feed from the recharge area on the contrary springs in haraita pauri nauli dhara bichola pani and jethuna tok display a good fit of the composite recession curves with the mrc generated with r2 values 0 94 0 96 and 0 95 respectively as shown in fig 9 c 9 e all the springs showed fairly good fits with the exponential regression method a steep upper section of the mrc s in haraita reflects the shallow storage that quickly responds to storm events but exhausts gradually thereafter bonacci 1993 a difference in the initial reservoir volumes can also be observed for the springs in haraita all three springs nauli dhara bichola pani and jethuna tok have a wide spread which means a stochastic dynamic feeding process is underlain wider scattered recession segments account for the stochastic nature of hydrodynamic processes in the aquifer system thus indicating the dominance of highly fractured formations aiding spring recharges at large spatial scales and their respective precipitation inputs vegetation cover land use pattern results of haraita spring clusters show that the aquifer feeding mechanism is complex and induced by a combination of pores micro fractures and conduits the steeper shape of the mrc indicates conditions of short residence time in the aquifer moreover the highly variable slopes of the individual recession segments represent the different rates of recession during different time intervals of the given time series which in turn induces the reduced prediction potential and reliability and impedes the estimation of the characteristic aquifer parameters the variable slopes of recession limbs indicate a complex spatial extent of the recharge area owing to the highly heterogeneous geological strata having different intrinsic properties and flow paths giacopetti et al 2016 similar slopes of recession limbs in shiv dhara however represent the homogeneous spatial hydro geology with a distinct recharge area consequently having almost the same effects from different rainfall events hydro geological survey of haraita micro watershed reveals that the spring feeds are through fracture and bedding planes of its characteristic quartzitic phyllite strata and the presence of preferential pathways can be observed spring responses integrate geological and hydrological signatures at large spatiotemporal scales and hence spring hydrograph recession proves to be an important indirect source of hydro geologic information 3 6 frequency distribution of flow duration and hydrological significance fig 10 represents the frequency distribution of flows in shiv gadera and haraita micro watersheds fdc is an integrated response for various factors that affect flows during the monitoring period a steep curve throughout depicts a highly variable flow largely from quick flow pathways whereas a flatter curve indicates the presence of storage as the storage tries to equalize the flow searcy 1959 in haraita a steep slope of flow distribution for the springs was observed indicating a dependency on rainfall and infiltration process whereas a flattened curve for springflows was characteristic of shiv gadera the breakpoints in the fdcs may be a result of intrinsic dynamics of the corresponding springshed as rainfall infiltrates the pressure pulse gets modified in accordance to the feedback it receives from its surrounding which may be in the form of changes in microscale hydro geology decrease in effective porosity of the aquifer or transition through preferential flow paths spring jethuna tok has a comparatively flatter curve indicating storage the persistent steep slope in the fdc of stream in haraita indicates a highly variable stream flows which may be attributed to quick flow channels the steep slope indicates a fast response to rainfall input and is also evident from the incidents of disruption in instrumentation during high flows the slope at the lower end of fdc describes the storage characteristics of the springsheds a flat slope determines large storage and steep slopes indicate negligible storage a gradual slope for the stream shiv gadera with a flatter tail end portion indicates base flows a flat slope at the upper ends of all the springs may be inferred as draining from deeper aquifers indicating a progressive emptying of the aquifer due to ineffective recharge a matter of grave water security concern the low flow distributions are inherently driven by springsheds geology so the designs for recharge structures or formulation of treatment measures must be based on low flows 15 50 exceedance fdc s are a valuable medium for exploring springshed hydro geology during low flows because the distribution of low flows is governed chiefly by geology the lower end of an fdc provides effective means of studying the geological implications on springshed hydrology at the time scale of the monitoring duration total spring flows were present for almost 70 80 and 100 of the times for bichola pani jethuna tok and nauli dhara respectively and present 100 of the time for shiv dhara to measure the spring variability the ratio q10 q90 given by netopil was employed the q10 q90 value of shiv dhara is 2 3 and nauli dhara is 54 2 which falls in the extraordinarily balanced and extraordinarily unbalanced category alfaro and wallace 1994 respectively the low flow variability measured as q50 q90 indicates high variability for nauli dhara spring 4 5 and low variability for shiv dhara at 1 37 tarafdar 2013 comparison between the springsheds depicts stable nature of shiv gadera than haraita as a flat slope indicates the slow response of the springshed to storm events whereas haraita responds fast also confirmed by local people dependent on the springs the impact of a successful water security plan depends largely on the assessment of lean and surplus period of water availability the optimum design capacity of storage structures in the vicinity of springs may be based on design low flow values i e the flow within the 10 50 exceedance probability for storage of excess water during the unutilized period tarafdar 2013 the storage structure can be aided with screens an overflow chamber and a chlorinator for maintaining quality results of fdc showed that steeper volume changes occur majorly during higher flows i e 60 exceedance which is influenced by the degree of interception and evapotranspiration from a springshed management perspective vegetation coverage shall alter rates of interception and evapotranspiration thus having lower flows following any rainfall event interventions involving managing land use and landcover for water yield shall concern changes in the upper section of the fdc thus fdcs complement the mrcs and provide information on water availability during lean and peak flows and help formulate springshed treatment measures accordingly 4 conclusions and recommendations this study utilized a combination of high resolution hydrologic time series analysis and geological characterization to assess the spring flows and characterize the spring aquifers in the rural himalayas of india two pilot sites were instrumented for the experimental study and geological investigations to understand the underlain hydro geological process this approach could be useful for assessing the spring revival potential in the ihr and make informed springshed management decisions the approach can also be implemented across other parts of the himalayas the major findings can be summarized below i in both the micro watersheds shiv gadera and haraita the intensity and duration of rainfall have a strong influence on spring discharge however the variations in spring response can be attributed to differences in the type of springs geology terrain slope and land use patterns a continuum of rainfall runoff responses was observed at both sites ii shiv gadera is characteristic of predictable flow responses homogeneous geology and indicates a distinctive feed from the recharge area in contrast haraita exhibits variable flow dynamics and a complex spatial extent of recharge area feed thus highlighting the need for the adaptation of the site specific springshed management practices iii the presence of intricate flow networks and low flow velocities aid in aquifer storage in shiv gadera and strong peaks in the hydrograph in haraita indicate the presence of a well developed fracture system so treatment measures must consider the geology and terrain characteristics iv gradual fdc of spring and stream flows for shiv gadera indicates perennial flow whereas haraita springshed exhibits intermittent to ephemeral flows these variable behaviors indicate how local water management and user groups can formulate management plans and regulatory protocols v the fdc results suggest more groundwater contribution to springs discharge in shiv gadera compared to haraita hence we infer that better and sustained spring discharge can be achieved by employing the recharge intervention measures in shiv gadera vi slow emptying of the aquifer can be inferred from gradual and prolonged damping of lag responses in shiv gadera in contrast an asymmetrical cross correlation indicates variability in flow responses and complex spring dynamics hence springshed treatment should be based on the storage potential and transmissive nature of the springshed vii community participation can play a crucial role in the equitable and sustainable use of water as well as in recharge area protection by planning and implementing sanitary protocols way forward the research work indicates some critical aspects of water security in mountain regions 1 identification of spring type and potential recharge area mapping based on hydro geological studies 2 demystification of hydro geological knowledge for community awareness and participation 3 to garner community participation and bolster the sustainability of the program design 4 achieve active participation of the community at all stages to better the long term efficacy of treatment measures 5 assessment of socio cultural capabilities of the communities and leverage science as well as local knowledge in program design 6 train and empower groups individuals in data collection monitoring and local governance of the spring systems in fig 11 we illustrate the proposed springshed assessment approach in the context of water security which can be implemented across the himalayas the full impact of intervention work is observed after at least three water years the detailed implementation of planned activities is beyond the scope of the current study and isotopic studies may complement hydro geological analysis and inferences in the future the study thus highlights that assessing and understanding the underlying geology and hydrological processes of himalayan springs is of paramount significance to scientifically plan for their rejuvenation towards addressing growing water security concerns credit authorship contribution statement bhargabnanda dass conceptualization methodology writing original draft writing review editing abhishek data curation software sumit sen conceptualization supervision investigation writing review editing funding acquisition vargish bamola methodology conceptualization anita sharma project administration writing review editing debashish sen writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge funding from the ministry of environment forest and climate change moefcc under its national mission for himalayan studies nmhs program project id and title nmhs 2017 18 mg19 03 water security through community based springshed development in the ihr and also acknowledge department of hydrology indian institute of technology roorkee roorkee india where the hydrological experiments and data analysis were conducted and the manuscript was prepared the authors are grateful to prof kristijan posavec university of zagreb croatia for his inputs in methodology we would also like to acknowledge the technical support by manik goel iitr and manoj sharma psi and the local field support by maya verma for almora and dharmendra singh for pauri garhwal the contents of this work are solely the responsibility of the authors and do not necessarily represent the official views of the funding agencies appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126354 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4571,springs are an indispensable source of freshwater for mountain communities in the indian himalayan region ihr owing to the synergistic impact of anthropogenic and climatic factors numerous perennial springs and streams in the region are either becoming ephemeral or drying out thus impacting the local people water scarcity poverty and limited scope of alternate livelihoods further reduce the communities resilience our focus is to assess the potential of reviving drying springs with the help of hydro geological studies in water scarce villages the methodology involved high resolution data monitoring of springs and first order streams in two headwater micro watersheds namely shiv gadera and haraita in the rural himalayas of uttarakhand india with unalike topography and geology to understand the hydro geological processes and assess the flow regimes and aquifer storage dynamics we applied water balance correlation flow duration master recession curves analysis and geological studies the univariate and bivariate analysis shows that shiv gadera has a better system memory indicating a larger storage capacity than haraita the spring hydrograph responses also append that shiv gadera has better storage and has a homogenous aquifer feed the water balance however is in positive storage only during the rainy months in both the sites the hydro geological characterization from hydrograph analysis recession analysis and field surveys shows that shiv gadera has intricate flow networks and slow flow velocities while haraita is characteristic of transmissive fractured rocks the spring flows in shiv gadera are observed to be perennial and more groundwater contributes to spring discharges while haraita exhibits intermittent to ephemeral nature the recession curves also indicate uniform geology a distinctive feed from recharge area and slow emptying of the aquifer while haraita exhibits shallow storage and quick responses to storms spring flows in shiv gadera show better stability than haraita as indicated by q10 q90 and q50 q90 measurements these inferences qualify shiv gadera as having a better chance of responding to management and treatments thus a better potential for revival the combination of hydrologic time series analysis and geological characterization used in this study could be a valuable approach for assessing spring revival in the ihr and has a potential for implementation across other parts of the himalayas keywords springshed recession curves time series analysis water balance spring aquifers himalayas list of terms and definitions sl no term definition 1 amphibolites it is a coarse grained metamorphic rock composed of amphibole minerals formed by regional metamorphism in convergent plate boundaries 2 bedding planes it is the discrete boundary surface parallel to the stratum separating two rock beds groundwater flow is facilitated by joints fractures in bedding planes 3 biophysical of or relating to humans and its relationship with its physical environment which includes attributes associated with the role that hydrologic regime geomorphology biodiversity climate and community plays in securing a socio ecological system s capacity to sustain essential ecosystem services and their relationships with social demand for management services water governance land use and development 4 central crystalline a continuous lithotectonic unit spanning from kumaun in the east to kashmir in the west a term used to refer to crystalline rocks of the himalayas the rock mass shows progressive regional metamorphism with mineral assemblages of pelites meta calcareous and basic rocks 5 fracture spring system it refers to a concerted flow of water from bedding planes joints cleavage faults and other breaks in consolidated hard or low permeability rock groundwater movement is mainly through fractures and may tap shallow as well as deep aquifers such spring systems occur when these fractures intersect the land surface 6 interventions the act of designing and executing measures or practices to preserve or restore spring ecosystems considering a broad approach integrating the management of forests soil and water systems governance and stakeholder participation 7 mechanistic mechanistic understanding is the viewpoint that states the behavioural responses of complex systems such as montane springs are determined strictly by the interactions of the individual factors or components mechanistic description of a system can be obtained from an analysis of observational time series and interpreting physically meaningful terms from monitoring exercises and experimentation carried out in natural systems 8 nappe a large coherent sheet like rock body tectonic unit that has moved a distance several times its thickness and over 5 km along a sub horizontal floor from its original position nappes form when a rock mass is forced over another at a low angle fault plane 9 one umbrella approach it refers to the successful management and development practices on one site being executed in multiple locations with a view that the particular successful practice conforms to all ecosystems and yield similar outcomes 10 preferential pathways it is the movement of water by preferred flow channels at an accelerated speed in a fraction of geologic media the controlling factors are the degree of fracture connectivity and the distribution of conductivities among fractures and sparsely by orientation and elevation of fracture walls 1 introduction himalayan mountain communities have historically been dependent on springs as the primary water source for meeting their domestic and agricultural needs valdiya and bartarya 1989 vashisht and sharma 2007 a total of roughly five million springs serve over two hundred million inhabitants in india sikdar 2019 in terms of food livelihood and energy naik et al 2002 according to niti aayog 2018 a government of india think tank report states that 60 of the five million springs across india are located in the indian himalayan region ihr and nearly 50 of them are either drying up or becoming seasonal amidst climate change anthropogenic stressors and lack of scientific watershed management an acute decline of discharge in several himalayan springs has been observed in the last two decades agarwal et al 2012 a comprehensive study mahamuni and kulkarni 2012 of the urban himalayan region discerned that 8000 villages face acute water scarcity issues valdiya and bartarya 1989 investigated 35 years of spring discharge data of the kumaon himalayas they reported a decline in spring discharge in 40 of studied villages of which over 2 had gone dry springs of mid himalayas of nepal are also drying up due to the coupled impact of biophysical and socio economic factors icimod 2015 moreover a survey conducted in sikkim revealed that all the springs in the state have declined by half a dreadful situation for a himalayan state almost entirely reliant on springs tambe et al 2011 springs are a multi component entity including a watershed aquifer and an outlet each component having distinct characteristics however the problems related to springs are often addressed as a demand supply approach and the aspects of ecological degradation watershed characteristics geology and groundwater flow regime remain unaddressed hence there is an urgent need to enhance a holistic understanding of spring systems in the context of these aspects considering the growing water crisis in the ihr himalayan non government organizations ngos and the sikkim government realized the importance of a paradigm shift in interventions from a supply side approach and partnered with local communities to map and protect spring sources kulkarni et al 2015 quite a few intervention programs have been implemented in the himalayas following a one umbrella management approach agarwal et al 2012 sharma and shakya 2006 whereas site specific springshed management plan is the need of the hour springsheds as defined by the florida geological survey 2003 struhs et al 2003 are those areas within ground and surface water basins that contribute to the discharge of springs thus a springshed which is administratively bifurcated into two regions maybe spanning over a shared aquifer hence local community participation is essential to be considered in a springshed development plan for the sustainability of himalayan springs several interventions and management approaches have been convened in the himalayas garg et al 2012 singh et al 2014 tambe et al 2012 reported up to 230 increase in spring discharge attributed to field interventions in sikkim and inferred that recharge area identification and building local capacity are crucial factors in springshed development it has also been observed in many cases that a successful intervention practice implemented at a particular site is often replicated without considering the variations in hydroclimatic and geological settings such practices may not yield the expected results for spring rejuvenation according to chinnasamy and prathapar 2016 understanding himalayan spring hydro geology is below par and sparsely investigated bruijnzeel and bremmer 1989 emphasized the need for an improved understanding of himalayan hydrological processes to develop better management plans as current knowledge is inadequate and may not solve the escalating water scarcity problems regardless of the emergent nature and subsequent consequences of this crisis increasing water demands along with ecological degradation and rapid urbanization shall continually affect spring flow rates natural springs and their sustainable development in the ihr are given less due importance at both policy and practice levels even though these play a pivotal role in water security this situation is primarily because of major gaps between data and understanding be it hydrological or socio economic data concerning community dependence on springs and their role in nurturing socio cultural services bridging the gap is essential to learn about the existing interlinkages between the biophysical attributes lithology and spring flow responses this shall be pertinent in scaling out springshed development methods and innovative management strategies for a long term water resources management plan assessing the current scenario water demand and availability must be done well in advance sharma and shakya 2006 scientific understanding of water resource systems responses to ever changing trends requires knowledge of the effects of present conditions and projected future responses mccarthy et al 2002 besides the local community needs to be sensitized and involved in cooperative action to ensure equity and sustainability of the plans developed for water security planning commission india 2007 hence extensive field research to attain a new mechanistic understanding of how a spring system works is necessary there is a vast scope of knowledge in the sustainable management of himalayan spring systems primarily due to a lack of detailed understanding of hydro geological processes within the system like subsurface water movement and spring flow continuum aquifer recharge processes and rainfall response variabilities in different hydro geological settings investigation of underlying processes requires field monitoring techniques and the monitored data e g spring flow time series combined with rainfall data and field geologic survey this gives insights into the drivers of hydrological processes controlling groundwater flow and recharge mechanism the objectives of the study are to i explore the usefulness of time series analysis for a mechanistic understanding of springshed scale hydrological processes ii determine the hydro geology of springsheds and understand water flow processes iii assess the spring flow characteristics using flow duration curves and master recession analysis and iv estimate the potential of spring aquifer recharge the study shall improve the conceptual understanding of himalayan spring systems and aid in water security planning and design the study hypothesizes that working at a springshed scale will result in a holistic approach to manage water resources as each of the two selected sites are hydrologically definedgeographic areas and unique in physiography ecology water quality and land use further highly fractured and weathered springshed systems are unfavorable to aquifer storage in the context of the prevailing hydroclimatic scenario this is because the rate of discharge decline or increment is externally controlled by recharge variability and spring flow stability this can be mainly attributed to the storage capacity and the extent of flow systems that feed it subsequently an aquifer system will respond to the designed treatment initiatives based on the geology s transmissive nature and its storage potential overall this study aims to present the situational assessment of existing hydro geological processes taking the case of two micro watersheds of uttarakhand for developing a springshed management strategy that envisions to attain water security in the rural indian himalayas by integrating hydro geological studies and community participation the paper is organized as follows the details of the study area instrumentation data collection and methods of analysis are described in the next section the results and interpretations of the study are presented in section3 which is followed by section4 where we summarize the main inferences conclude the analysis and acknowledge our supporters 2 materials and methodology two pilot micro watersheds shiv gadera and haraita were selected within the sahigad and pundoliraul watersheds in uttarakhand state india fig 2 firstly in a two part research approach weather stations were set up for hydro meteorological data collection and monitoring at sub hourly scales secondly a parallel hydro geological field assessment to layout conceptual springshed maps and understand the geological influence on the hydrological outputs was conducted a detailed geological mapping of the study area including the determination of the lithological and structural framework of the area as well as measuring the dominant orientation of bedrock fractures and foliation present in the rocks was done a combination of topographical information and site investigations making extensive use of rock exposures present along roads and the stream as well as any other exposed outcrops was used geological literature and other historical data were also compiled to study the impact on the springs parshall flumes and hs flumes gauged the stream and spring flows respectively in both the micro watersheds further description of the methodological approach and research framework of the study can be found in fig 1 this framework can well be suitable for any other springshed system 2 1 study area 2 1 1 general description two micro watersheds shiv gadera and haraita selected for the study are located in the almora and pauri garhwal districts of uttarakhand state india respectively fig 2 appendix f geographically these districts are located in two different regions of uttarakhand i e kumaon and garhwal and are classified as water scarce regions with a high dependency on springs for drinking domestic and irrigation water demands the sahigad watershed lies in the headwater of kosi river which is a springfed river and has shown a decline in discharge aronsson and piculell 2011 it is used as a major water supply source for many areas in almora flow data of the river shows that its average low flow decreased steadily from 995 l per second lps in 1994 to 196 lps in 2004 rawat 2013 recharging springs will not only increase the water availability for the villagers but could also help revive small streams that feed the kosi river shiv gadera is the headwater micro watershed where instruments have been installed for hydrological monitoring fig 3 the second watershed is pundoliraul which is one of the most water scarce blocks of the district the selected springs and a stream for instrumentation are in dashmeri village this site was chosen as it forms a headwater micro watershed haraita required for this study fig 4 the micro watershed hosts several springs most of whose discharge reduces mainly during the summer season in the western himalayan region it is quite a common phenomenon to find habitation nearby springs and these habitations are majorly affected during the summers piped water supply is available in the concerned villages but it is inadequate and irregular especially during summers as it is also spring based which are gradually drying up springs are the major sources of drinking domestic and irrigation water in both the selected micro watersheds but due to climate variations and changes in land use these are becoming critical in terms of their discharge unlike other parts of the world eg in italy and florida usa dragoni et al 2013 united states department of agriculture 2012 there is no pumping schemes in these watersheds to utilize the springs for water supply 2 1 2 geology 2 1 2 1 hydro geological setup of the study area shiv gadera almora three major lithotectonic divisions have been postulated within the lesser kumaon himalaya each characterized by distinctive lithology and structures the most dominant rock formation of the lesser kumaon himalaya form part of the central crystallines thrusted synformally southward they occur from south to north as follows heim and gansser 1939 i the outer krol nappe is comprising of pre tertiary mild metamorphosed sediments confined in the north by south almora thrust and the main boundary fault in the south ii the almora nappe is comprising of metamorphics that are intimately associated with granitic rocks this nappe is represented by two klippe the almora crystallines in the central part and baijnath and askot crystallines in the northeast iii the two inner krol nappes comprises mildly metamorphosed sediments bordered in the south by the north almora thrust and main central thrust in the north the regional structural setting of the study area is controlled by tectonics compressional in nature leading to himalayan orogeny joshi and tiwari 2009 the process has transformed sandstone to low grade quartzite further crushing the rock and giving a crumbly appearance the shear zone has also developed during different phases of himalayan orogeny valdiya 1980 the earlier two episodes were represented by tight to isoclinal reclined folds having similar geometry and orientation and the later deformations were of open folds oriented at right angles to each other chamyal 1991 the nw dipping fractures have developed during the second episode of deformation as a consequence of being distributed uniformly throughout the region highly fragile zones are observed at the ridges while the central portion is relatively less deformed chamyal 1991 in the central portion of watershed high undulations were observed on the eastern side of the map beds are trending ne sw dipping towards south east while the bedding planes are near horizontal especially near the ridge to gentle ranging from 20 to 30 quartzite is the dominant lithology in the study area and is characteristic of low primary porosity but considerable secondary porosity the monitored spring shiv dhara is a fractured spring and it is perennial the villagers use it throughout the year even though they have a pipeline supply in their village the maintenance of this spring is done by the water user group of this spring the average discharge of the spring measured in april 2018 was 1 2 lpm 2 1 2 2 hydro geological setup of the study area haraita pauri garhwal all the rural households inhabiting haraita micro watershed are dependent on spring water for their household needs the aquifer systems of haraita micro watershed are sustained by primary and secondary porosities of rock units schist which has undergone weathering process with quartzite interband forms the major portion of the study area although both have very little primary porosity schist possesses poor primary porosity and permeability owing to this the presence of joints and fractures becomes crucial for the development of secondary porosity in these rocks the joints fractures and cavities thus provide conduits for transmission and storage of water within the rocks although their distribution varies according to the rock type hydrologically the study area is categorized into two zones based on permeability compact and soft lithology zones the soft zone comprises overburdened soil they form a suitable aquifer system for springs and originates several depression type perennial springs in addition this zone is underlined by water holding rock strata compact zone provides another unconfined aquifer system which is majorly comprised of quartzite and schists rocks in this zone are hard and compact possessing very little primary porosity but have high secondary porosity viz fractures joints cavities springs in these zones are dominantly fractured type seasonal springs 2 1 2 3 methodology for hydro geological studies regional geology and stratigraphy were studied on the ground and literature regarding the study area has been consulted toposheets survey of india of the study area were collected for plotting the geological data and locating the springs outcrops were studied to gather information about the various rock types and trends of openings which may be in the form of bedding planes foliation planes fractures and faults the direction and attitude of rock beds and geological structures were measured using a brunton which further helped in determining the recharge area of the concerned spring as different rock types their attitude openings and the various structural features govern the accumulation and movement of groundwater the dip and strike of different types of rocks form the basis of geological mapping to identify the underlying geological conditions and to interpret the type of spring or aquifer spring locations were marked and discharge rate was measured the point of the emergence of the spring helps in the classification of the spring and also gives an idea of the geologic formation which acts as the aquifer storing and transmitting groundwater to it the dip and strike of the rocks and slopes of the given region were measured the lithological and structural folds faults and fractures characteristics of the rocks were marked and oriented photographs and samples were taken the foliation types based on schistosity were specified by qualitative comparison of the images with a series of reference photos that have been classified beforehand in the pilot study the rock type identification was followed by the specification of the lithology by image petrology the rock types were identified by visual methods the major characteristics of phyllites are crinkled having wavy appearance with foliations while the schists were identified based on schistosity all the lithologs were recorded and later fed into a spreadsheet program post field work lithological and hydro geological cross section maps were prepared for better understanding and visualization laying out the springshed with its underground structural makeup as conceptual diagrams facilitates a better process understanding of the aquifer mechanisms google earth pro was used for visualizing the location and distribution of data auto cad and corel draw were used to collate all data for deciphering relationships between lithology and groundwater with emphasis on the orientation of features to create the cross sections aquifers and potential recharge areas can be easily depicted in conceptual cross section maps 2 1 2 4 geological assessment of shiv dhara springshed almora the rock type of springshed is quartzite which is striking along n 60 240 and towards n 150 with the dip amount of 20 along with this there are two major sets of fractures present in the area trending ne sw nw se in the central portion three sets of fractures are dipping towards ne sw and nw with moderate dip amounts ranging from 45 55 the nw trending fracture is observed throughout the mapped area a highly compressed landslide prone zone where rocks are extensively fractured known as the shear zone is also observed this is an important factor concerning the movement of groundwater because of the anomalous porosity and permeability developed in the rock along this zone the vertical fracture allows quick infiltration during deformation bedding planes become undulating and develop openings the land use pattern in the recharge area of this spring is covered with community forest the conceptual cross section of the potential recharge area of the spring is shown in fig 5 2 1 2 5 geological assessment of haraita springshed pauri garhwal from the field analysis it is concluded that the springs in the haraita are fractured types the major fracture sets supporting the groundwater are trending 292 45 n22 e 050 75 n40 w and 130 60 s40 w respectively in hard lithology zones fig 6 though trends also change as per local geology hydro geologically the region hosts two main aquifer systems alluvium aquifer system hosts springs at the base towards west separated by thick schist and a weathered quartzite intercalated layer while a highly fractured but closely spaced flaky rock system forms the second aquifer system the area is dominated by schist of low grade metamorphism and possesses characters such as fine grained with shiny luster moderately compact yet highly cleaved in nature the strike shows undulating nature along ne sw and therefore the direction also varies from nw sw and w towards the north intercalated quartzite beds trend n70 n250 towards n340 2 2 experimental setup and field data collection the study sites are instrumented with automatic weather stations aws hs and parshall flumes and other hydrological instruments tabulated in appendix b various environmental sensors installed at aws enabled real time measurement of weather parameters including precipitation relative humidity atmospheric pressure solar radiation flux wind speed and direction the location of all the gauging stations employed in the study areas is described in appendix a continuous water depth data are converted into discharge values using the flume discharge equation the details of the monitoring observatories are tabulated in table 1 appendix a b and the nomenclature of the observatory setup detailed in table 2 2 3 hydrological studies 2 3 1 water balance we utilized the weather parameters recorded by aws for water balance wb analysis of both the micro watersheds the wb components viz rainfall grass reference potential evapotranspiration stream discharge were calculated on a daily basis for shiv gadera almora and haraita pauri garhwal springsheds respectively with no irrigation the water balance equation is deduced in the form 1 δ s p et ref r where δ s is the change in the soil water storage p and r denote the precipitation and runoff respectively et ref is the reference evapotranspiration for grass surface during the computation interval all the wb components are presented as equivalent water depth per unit time i e mm d 1 2 3 2 univariate and bivariate analysis the autocorrelation univariate analysis has been performed to find out the linear dependency of spring and stream discharge values on its preceding time series and to characterize the system s memory such an analysis provides insights into the short and long term influences of an event as the correlograms describe the response of a system to an event the memory effect corresponds to the duration of the time lag starting from initial zero to the point where the correlogram r xx k reaches the value of 0 2 mayaud et al 2014 the autocorrelation function is obtained by normalizing the covariance of the univariate series x i having mean μ x and variance σ x 2 as 2 r xx k c xx k c xx 0 c xx k σ x 2 3 c xx k 1 n t 1 n k x i μ x x i k μ x where k denotes the time lag varying from 0 to m i e length of the time series in our analysis the value of m has been taken as 120 days 1 3 rd of the whole observation period to avoid stability problems mangin 1984 auto correlation reveals the inertia of the system and offers ancillary data on the storage potential of the system and the degree of fractures to analyse the magnitude and time lag of our system s response to a given input we cross correlated rainfall with discharge observations as a cross correlogram will indicate the degree of linear interdependence of the rainfall and spring stream discharge series as a time function the cross correlation function for k 0 is obtained by normalizing the covariance of the bivariate series x i and y i having mean μ x and μ y and variance σ x 2 and σ y 2 respectively larocque et al 1998 as 4 r xy k c xy k c xy 0 c xy k σ x σ y 5 c xy k 1 n t 1 n k x i μ x y i k μ y for k 0 x and y positions are interchanged in eq 4 and eq 5 the delay is defined as the time lag between maximum amplitude of input rainfall and maximum r xx k univariate and bivariate analysis autocorrelation and cross correlation respectively of the discharge and rainfall time series is a complementary analytical technique to study the functioning and hydrodynamic behavior of spring systems long term analysis of the correlograms provides information on spring aquifer functioning unlike single event analysis where we get the spring reaction to a single recharge event mayaud et al 2014 2 3 3 master recession curves analysis the main purpose of master recession curves mrcs method is to quantify the effects of individual recession events to indicate the nature of sub surface processes as discrete recession segments of a hydrograph do not provide much information on aquifer systems due to high variability in storage and recharge fluxes posavec et al 2006 the mrc s provide information on the hydro geological properties and dynamics of the underlying aquifer systems storativity transmissivity and physical characteristics of the recharge area posavec et al 2010 such inferences eventually help in recharge area management mainly attributed to the assessment of aquifer systems the use of mrcs is widely accepted in policymaking and sustainable management of water resources kumar and sen 2018 rivera ramirez et al 2002 two approaches for generating mrcs are employed in our study i matching strip method posavec et al 2006 which formulates an objective automated technique of mrc separation and ii a newly developed mrctoolsv3 0 spreadsheet tool posavec et al 2010 of excel visual basic for applications vbas utilizing trigonometry laws for overlapping individual recession segments the presented mrcs are the best fits yielding better results in terms of high r2 value amongst both the approaches applied viz matching strip method using multiple linear nonlinear regression based method exponential regression model and extracted with respect to q90 flow and trigonometry based mrctoolsv3 0 spreadsheet tool 2 3 4 flow duration analysis we generated flow duration curves fdc to study the relationship between the magnitude and frequency of spring and streamflows during our monitoring period these curves quantify the flow characteristics without considering the sequence of its occurrence and give a frequency distribution of outflows both in time and magnitude searcy 1959 it also provides a feasible platform to compare the flow characteristics of two or more springsheds a comprehensive graphical view of discharge variability at a particular site can be obtained 2 4 community engagement and participation plan local communities were involved in participatory exercises for assessing the usage of spring water and its recharge area the historical transect of the concerned springs further helped in understanding the anthropogenic and natural factors leading to the depletion of spring discharge resource mapping exercise helped in understanding the land usage and ownership of the recharge area awareness campaigns were organized in each village of the concerned micro watersheds in the form of street plays puppet shows and village meetings to generate public interest and support for spring revival this was followed by the formation of village level institutions spring water user groups and their capacity building for operation and maintenance appendix d the planning for spring treatment was done considering the topography soil type land use and land ownership of the identified recharge area along with the water and biomass needs in consultation with the local communities the feasibility of such springshed treatment plans is based on hydro geological assessments due consideration has been given to the traditional practices of spring recharge existing in the region a cadre of para workers mostly women has been developed and trained in spring discharge rainfall and water quality measurements household surveys were conducted to understand the seasonal consumption pattern from the springs for the concerned villages and further to compare it with the prescribed norms fig 7 c shows the annual domestic water consumption for villages dependent on the monitored springs 3 results and discussion 3 1 assessment of micro watershed water yields monthly water balance assessment of both the study sites is performed and compared for a total of 14 months as shown in fig 7 a b both micro watersheds exhibit a seasonal monsoon climate with positive water storage primarily during the monsoon season i e from july september although the number of rainy days is similar for shiv gadera and haraita micro watersheds i e 156 days and 145 days respectively appendix c the amount of total rainfall is almost double in the latter 999879 m3 in haraita compared to 583984 m3 in shiv gadera appendix c less rainfall combined with the higher vegetation cover in shiv gadera micro watershed figs 3 and 4 results in about a two fold increase in the reference evapotranspiration with an average of 6 28 mm d 1 as compared to 2 99 mm d 1 in haraita micro watershed during the study period table 3 this trend of et ref has a negative impact on the aquifer limits as explained in the forthcoming sections despite receiving ample rainfall compared to the country s average annual rainfall i e 1200 mm both the micro watersheds seem unable to continue the above average water storage conditions this behavior can most likely be explained by the prevailing steep terrain degree of fractures in the underlying aquifer systems and highly heterogeneous rainfall 60 and 70 of which occurred during the three months of monsoon season only for both sites respectively a persistent depletion in storage is also observed for the non monsoon months in both the sites fig 7 a b 3 2 assessment of domestic water consumption the seasonal domestic water consumption is shown in fig 7 c kaurali and dashmeri villages are dependent on shiv gadera and haraita spring systems respectively the general trend exhibits more water consumption during summers with the onset of the dry season followed by monsoon and winter seasons in both villages summer season water consumption is lower for dashmeri as compared to kaurali this can be attributed to the presence of three spring systems in haraita of which nauli dhara and jethuna tok are perennial springs on the contrary in shiv gadera the dependency of the village is only on one spring shiv dhara which ultimately leads to higher usage in both the watersheds the water consumption is below 55 lpcd which is the drinking water norms under the national rural drinking water program nrdwp india thus signifying that there is no overexploitation of the water resources in the region or the low consumption might also be due to less availability of water interestingly in the summers the water consumption from springs is more than that from the pipeline water supply as the supply from the latter decreases drastically during summers this might be another reason why the monsoon and winter consumption are less therefore the behavior and the impact of the existing hydro geological conditions on the natural flow rates need to be explicitly investigated particularly for attaining drinking water security the rural communities depend on springs for their drinking domestic and minor irrigation needs for this the naturally overflowing water is used without the use of a pumping system this is because the mountain springs have a small aquifer system and their discharge varies as per the season that is why monsoon fed irrigation is practiced here only after fulfilling the drinking and domestic needs the surplus overflowing water is used for minor irrigation 3 3 spring hydrograph analysis a preliminary assessment of springshed characteristics was done by analyzing spring hydrographs the shape or retardation response of rainfall inputs is closely related to the extent of recharge area intensity of rain evaluation of recharge and storage capacity and assessment of average transmissive properties of aquifer structure kresic and bonacci 2010 the discharge observations for the springsheds are shown in table 3 spring discharges from shiv dhara are perennial with and an average flow of 50 lpm while the spring flows in haraita micro watershed show intermittent flow behavior thus characterizing the primary hydro geological features of the underlying aquifers the springs nauli dhara bichola pani and jethuna tok show significant differences in their average flow rates and decrease across the transect fig 8 d the hydrograph responses indicated that both the springshed systems are highly controlled by precipitation input and the permeability matrix of the aquifer shiv gadera has better storage capacity and homogeneity as the hydrograph responses show a persistent and gradual increase and decrease as compared to the hydrograph of haraita springs fig 8 c and d such an analysis aids in discerning the nature of aquifer feed to the spring system and its flow drainage operation memon 1995 the response of newly infiltrated water on spring flow rate is dependent on the porosity of the rock matrix and the groundwater levels if we consider the case of nauli dhara the initial response of an increase in discharge from 21 lpm to 175 5 lpm 10th july 21st july 19 is due to the pressure propagation through large fractures and conduits and it is not the outflow of the newly infiltrated water such reactions are characteristic of transmissive fracture rock kresic and bonacci 2010 the flow rate stabilizes to 84 8 lpm on 26th july 19 and then starts rising gradually as a response to the rainfall events in june august 2019 after the initial response and recharge events a shift is observed in the recession level from 84 8 lpm to a higher hydrograph level at 187 lpm 25 days after stabilizing the new water upon reaching the spring contributes a fraction of the total flow rate with a certain delay but analysis of spring discharge of bichola pani shows that the spring is drained through a well developed network of fractures and conduits and hence it takes a longer time to dissipate the initial response and it stabilizes at 25 7 lpm after 40 days of nauli dhara attaining stability responding to the same rainfall events analysis of shiv dhara spring discharge shows that after reaching the seasonal spring peak discharge of 85 6 lpm on 27th aug 19 the recession is gradual august through november 2019 the spring maintains an average flow rate of 68 98 lpm during this period groundwater levels and antecedent moisture conditions are most likely high in unsaturated zones and evapotranspiration losses with a median value of 160 7 mm 1 05 mm d 1 is much less than the average of 6 28 mm d 1 for the whole period so the newly infiltrated water raises an already high hydraulic head and the groundwater is easily infiltrated into the aquifer matrix kresic and stevanovic 2010 also a gradual terrain slope and homogenous underlying geology play a key role in maintaining a perennial continuum of shiv dhara spring antecedent storage conditions majorly influence the proportion of rainfall inputs in the system that drains as spring flows and the lag in output responses a sharply peaked hydrograph is observed for haraita spring indicating high fractures and impermeable strata as such hydrograph signatures are characteristic of small storage and rapid discharge whereas the shiv dhara spring exhibits a comparatively flatter wider and delayed response kresic 2006 nauli dhara responds significantly better to rainfall inputs than bichola pani and jethuna tok in haraita and thus proves to be a reliable source for the locals this behavior is observed primarily due to reason that the bedding planes and the rock lineaments actively feed the spring in conjunction during precipitation phases major flows occur during the monsoons and the springs in haraita exhibit intermittent and ephemeral nature whereas shiv dhara is perennial 3 4 response delays and significance the autocorrelation function acf for shiv gadera shows a gradual decline up to 0 5 and 0 4 for the spring and the stream respectively even after 120 days fig 8 g and 8 h the auto correlation for the discharge of both shiv dhara and shiv gadera diminishes very slowly damped with prolonged memory effect during the entire 120 days of time lag this damped response is potentially explained by a larger storage capacity within the shiv gadera micro watershed behrens et al 1992 the aquifer has stored water and contributes to stream and spring continually for a prolonged period in contrast for haraita springs there is a sharp decline in the auto correlogram during the initial 50 to 70 lag days thus showing less memory effect as compared to shiv gadera a shorter memory effect in the haraita micro watershed is an indication that the discharge is an independent variable exhibiting quasi randomness the memory effect of the aquifer system is observed as 50 60 70 days for nauli dhara bichola pani jethuna tok respectively and around 30 days only for the stream as illustrated in fig 8 g and 8 h the acf declines slowly with a higher memory effect for shiv gadera indicating a larger storage capacity of the underlying aquifer than haraita a slow decline over a longer period i e acf 0 2 indicates a strong linear inter relationship behavior influenced by rock matrix storage as slow flow pathways within a matrix require a long time to fill and drain the pores whereas a drop to zero indicates that it is uncorrelated meaning limited storage effect on water level variation an increased memory effect in shiv gadera indicates that the underlying aquifer system is influenced by an event for a more extended time which implies that the system is having considerable storativity a shorter memory effect suggests more developed fractures or an extensive network of flow paths or conduits and an extensive memory indicates a poorly drained network of conduits a gradually decreasing trend in auto correlogram indicates the presence of small fissures through which water flows at much lower velocities as exhibited by shiv gadera almora in contrast a well developed fracture system has little memory and decreases steeply and quickly as shown by haraita pauri garhwal an asymmetrical cross correlation function indicates a high dependency of the springshed systems output i e discharge on system input i e rainfall for both the study sites as shown in fig 8 i j the mean response time represents the lag time of the peak cross correlation coefficient for the time series data over a monitoring period the peak of the function is at a time lag of zero days with a value of 0 63 for haraita and 0 55 for shiv gadera the cross correlogram exhibits a variable impulse response to rainfall for all of the hydrological flow gauging stations with a response time of 15 25 30 days and diminished peaks just ahead of 50 days lag for stream shiv gadera whereas shiv dhara spring has peaks at 25 30 40 and 50 days which are not so pronounced as compared to the stream after 50 days dampening of the impulse response is observed for both the flow gauges this time delay exhibited by rainfall pulse response highlights the significant reduction in input pulse signals during its propagation through the system higher amplitudes in the peaks in shiv gadera as compared to those of shiv dhara signify that the rainfall has a quicker and vital response to the stream discharge the influence of rainfall on the spring discharge follows the order nauli dhara jethuna tok bichola pani in haraita micro watershed for individual rainfall peaks the cross correlation function r xy k increases the most for the stream and verifies that stream discharge is predominantly controlled by rainfall and that the aquifer storage is contributing very little this observation can also be ascertained by the fact that haraita micro watershed has steeper terrain and more barren agricultural land attributing to the lesser evapotranspiration rates delay or transfer speed corresponds to the time lag to maximum r xy k delay in the peaks of the cross correlogram from the rainfall events accounts for the time of propagation of the rainfall impulse to exhibit a response in the outlet a shorter delay indicates faster transfer of the input rainfall influence on the output discharge and a lower signal transfer speed indicates a low degree of fractures an absence of preferential pathways in the aquifer system can be inferred for shiv gadera a low degree of maximum r xy k values show that the input is highly changed throughout the output a comparatively lower value for haraita indicates a complex recharge system post monsoon period exhibits high antecedent moisture conditions helping the input pressure pulse to travel quicker and appearing in the output amplification a highly fractured system like haraita transmits such pressure pulses directly and swiftly to the outlet and thus prevents the aquifer from leveraging the input for recharge but during low flows the highly intricate pores and fissure network channel de saturates thus enabling a gradual and homogenous pulse transmission for deeper infiltration into the saturated zone since the rainfall is not having a user defined pattern the cross correlogram is the signature of the system s impulse response a gradual decrease in cross correlation function for shiv gadera as compared to haraita represents a slower emptying rate of the aquifer and hence a large storage capacity regulating the input flow and propounds the idea that the aquifer storage of haraita is unable to attenuate the flood pulse of the storm event to the same extent as in shiv gadera in shiv gadera amplification in signals can be seen when there is a delay in spring flow due to the release of stored water it also indicates the large storage capacity of the aquifer and this high storage potential can be explained by the presence of minute fissures that store water and release gradually post peak flows when highly transmissive channels are de saturated 3 5 assemblage of flow recession time series and interpretation the mrcs generated for all the sites are presented in fig 9 the coefficient of determination r2 is also presented for comparison with the visuals of the goodness of fit of the selected regression models mrc showed a fairly good fit with the exponential method for both the springsheds with a comparatively lower value of recession coefficient α d 1 calculated for spring in shiv gadera almora 0 038 than in haraita pauri garhwal 0 109 0 088 0 081 respectively shiv gadera s geology can be characterized as having pervasive fracturing which is rather interconnected with low permeability matrices a condition that enables the gradual release of water over time and as a consequence slow emptying of the aquifer feed tarafdar 2013 the low value is a translation of diffused fracture system low permeability matrix and medium to low extent of joint openings on the contrary haraita s hydro geology is characterized by well interconnected joints the shallow extent of recharge area and rapid emptying of the reservoirs feeding the springs amit et al 2002 the higher value of α in this case indicates a small or localized recharge area in the case of shiv dhara and shiv gadera almora the exponential regression and trigonometry based approach generated a narrower mrc envelope respectively and hence a high coefficient of determination of the overlapped recession segments can be seen the responses of spring shiv dhara exhibits a high r2 value of 0 98 the predictability of the shiv dhara s flow can be complemented by its perennial nature and its innate ability to maintain a constant range of flows in the lean season the stream shiv gadera fits better with the trigonometric approach r2 0 98 than the exponential regression fit r2 0 86 as illustrated in appendix e this further supports our inference from correlograms of uniform underlying geology and distinctive feed from the recharge area on the contrary springs in haraita pauri nauli dhara bichola pani and jethuna tok display a good fit of the composite recession curves with the mrc generated with r2 values 0 94 0 96 and 0 95 respectively as shown in fig 9 c 9 e all the springs showed fairly good fits with the exponential regression method a steep upper section of the mrc s in haraita reflects the shallow storage that quickly responds to storm events but exhausts gradually thereafter bonacci 1993 a difference in the initial reservoir volumes can also be observed for the springs in haraita all three springs nauli dhara bichola pani and jethuna tok have a wide spread which means a stochastic dynamic feeding process is underlain wider scattered recession segments account for the stochastic nature of hydrodynamic processes in the aquifer system thus indicating the dominance of highly fractured formations aiding spring recharges at large spatial scales and their respective precipitation inputs vegetation cover land use pattern results of haraita spring clusters show that the aquifer feeding mechanism is complex and induced by a combination of pores micro fractures and conduits the steeper shape of the mrc indicates conditions of short residence time in the aquifer moreover the highly variable slopes of the individual recession segments represent the different rates of recession during different time intervals of the given time series which in turn induces the reduced prediction potential and reliability and impedes the estimation of the characteristic aquifer parameters the variable slopes of recession limbs indicate a complex spatial extent of the recharge area owing to the highly heterogeneous geological strata having different intrinsic properties and flow paths giacopetti et al 2016 similar slopes of recession limbs in shiv dhara however represent the homogeneous spatial hydro geology with a distinct recharge area consequently having almost the same effects from different rainfall events hydro geological survey of haraita micro watershed reveals that the spring feeds are through fracture and bedding planes of its characteristic quartzitic phyllite strata and the presence of preferential pathways can be observed spring responses integrate geological and hydrological signatures at large spatiotemporal scales and hence spring hydrograph recession proves to be an important indirect source of hydro geologic information 3 6 frequency distribution of flow duration and hydrological significance fig 10 represents the frequency distribution of flows in shiv gadera and haraita micro watersheds fdc is an integrated response for various factors that affect flows during the monitoring period a steep curve throughout depicts a highly variable flow largely from quick flow pathways whereas a flatter curve indicates the presence of storage as the storage tries to equalize the flow searcy 1959 in haraita a steep slope of flow distribution for the springs was observed indicating a dependency on rainfall and infiltration process whereas a flattened curve for springflows was characteristic of shiv gadera the breakpoints in the fdcs may be a result of intrinsic dynamics of the corresponding springshed as rainfall infiltrates the pressure pulse gets modified in accordance to the feedback it receives from its surrounding which may be in the form of changes in microscale hydro geology decrease in effective porosity of the aquifer or transition through preferential flow paths spring jethuna tok has a comparatively flatter curve indicating storage the persistent steep slope in the fdc of stream in haraita indicates a highly variable stream flows which may be attributed to quick flow channels the steep slope indicates a fast response to rainfall input and is also evident from the incidents of disruption in instrumentation during high flows the slope at the lower end of fdc describes the storage characteristics of the springsheds a flat slope determines large storage and steep slopes indicate negligible storage a gradual slope for the stream shiv gadera with a flatter tail end portion indicates base flows a flat slope at the upper ends of all the springs may be inferred as draining from deeper aquifers indicating a progressive emptying of the aquifer due to ineffective recharge a matter of grave water security concern the low flow distributions are inherently driven by springsheds geology so the designs for recharge structures or formulation of treatment measures must be based on low flows 15 50 exceedance fdc s are a valuable medium for exploring springshed hydro geology during low flows because the distribution of low flows is governed chiefly by geology the lower end of an fdc provides effective means of studying the geological implications on springshed hydrology at the time scale of the monitoring duration total spring flows were present for almost 70 80 and 100 of the times for bichola pani jethuna tok and nauli dhara respectively and present 100 of the time for shiv dhara to measure the spring variability the ratio q10 q90 given by netopil was employed the q10 q90 value of shiv dhara is 2 3 and nauli dhara is 54 2 which falls in the extraordinarily balanced and extraordinarily unbalanced category alfaro and wallace 1994 respectively the low flow variability measured as q50 q90 indicates high variability for nauli dhara spring 4 5 and low variability for shiv dhara at 1 37 tarafdar 2013 comparison between the springsheds depicts stable nature of shiv gadera than haraita as a flat slope indicates the slow response of the springshed to storm events whereas haraita responds fast also confirmed by local people dependent on the springs the impact of a successful water security plan depends largely on the assessment of lean and surplus period of water availability the optimum design capacity of storage structures in the vicinity of springs may be based on design low flow values i e the flow within the 10 50 exceedance probability for storage of excess water during the unutilized period tarafdar 2013 the storage structure can be aided with screens an overflow chamber and a chlorinator for maintaining quality results of fdc showed that steeper volume changes occur majorly during higher flows i e 60 exceedance which is influenced by the degree of interception and evapotranspiration from a springshed management perspective vegetation coverage shall alter rates of interception and evapotranspiration thus having lower flows following any rainfall event interventions involving managing land use and landcover for water yield shall concern changes in the upper section of the fdc thus fdcs complement the mrcs and provide information on water availability during lean and peak flows and help formulate springshed treatment measures accordingly 4 conclusions and recommendations this study utilized a combination of high resolution hydrologic time series analysis and geological characterization to assess the spring flows and characterize the spring aquifers in the rural himalayas of india two pilot sites were instrumented for the experimental study and geological investigations to understand the underlain hydro geological process this approach could be useful for assessing the spring revival potential in the ihr and make informed springshed management decisions the approach can also be implemented across other parts of the himalayas the major findings can be summarized below i in both the micro watersheds shiv gadera and haraita the intensity and duration of rainfall have a strong influence on spring discharge however the variations in spring response can be attributed to differences in the type of springs geology terrain slope and land use patterns a continuum of rainfall runoff responses was observed at both sites ii shiv gadera is characteristic of predictable flow responses homogeneous geology and indicates a distinctive feed from the recharge area in contrast haraita exhibits variable flow dynamics and a complex spatial extent of recharge area feed thus highlighting the need for the adaptation of the site specific springshed management practices iii the presence of intricate flow networks and low flow velocities aid in aquifer storage in shiv gadera and strong peaks in the hydrograph in haraita indicate the presence of a well developed fracture system so treatment measures must consider the geology and terrain characteristics iv gradual fdc of spring and stream flows for shiv gadera indicates perennial flow whereas haraita springshed exhibits intermittent to ephemeral flows these variable behaviors indicate how local water management and user groups can formulate management plans and regulatory protocols v the fdc results suggest more groundwater contribution to springs discharge in shiv gadera compared to haraita hence we infer that better and sustained spring discharge can be achieved by employing the recharge intervention measures in shiv gadera vi slow emptying of the aquifer can be inferred from gradual and prolonged damping of lag responses in shiv gadera in contrast an asymmetrical cross correlation indicates variability in flow responses and complex spring dynamics hence springshed treatment should be based on the storage potential and transmissive nature of the springshed vii community participation can play a crucial role in the equitable and sustainable use of water as well as in recharge area protection by planning and implementing sanitary protocols way forward the research work indicates some critical aspects of water security in mountain regions 1 identification of spring type and potential recharge area mapping based on hydro geological studies 2 demystification of hydro geological knowledge for community awareness and participation 3 to garner community participation and bolster the sustainability of the program design 4 achieve active participation of the community at all stages to better the long term efficacy of treatment measures 5 assessment of socio cultural capabilities of the communities and leverage science as well as local knowledge in program design 6 train and empower groups individuals in data collection monitoring and local governance of the spring systems in fig 11 we illustrate the proposed springshed assessment approach in the context of water security which can be implemented across the himalayas the full impact of intervention work is observed after at least three water years the detailed implementation of planned activities is beyond the scope of the current study and isotopic studies may complement hydro geological analysis and inferences in the future the study thus highlights that assessing and understanding the underlying geology and hydrological processes of himalayan springs is of paramount significance to scientifically plan for their rejuvenation towards addressing growing water security concerns credit authorship contribution statement bhargabnanda dass conceptualization methodology writing original draft writing review editing abhishek data curation software sumit sen conceptualization supervision investigation writing review editing funding acquisition vargish bamola methodology conceptualization anita sharma project administration writing review editing debashish sen writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors acknowledge funding from the ministry of environment forest and climate change moefcc under its national mission for himalayan studies nmhs program project id and title nmhs 2017 18 mg19 03 water security through community based springshed development in the ihr and also acknowledge department of hydrology indian institute of technology roorkee roorkee india where the hydrological experiments and data analysis were conducted and the manuscript was prepared the authors are grateful to prof kristijan posavec university of zagreb croatia for his inputs in methodology we would also like to acknowledge the technical support by manik goel iitr and manoj sharma psi and the local field support by maya verma for almora and dharmendra singh for pauri garhwal the contents of this work are solely the responsibility of the authors and do not necessarily represent the official views of the funding agencies appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126354 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4572,submarine groundwater discharge from a coastal watershed a 2 d cross section view of subsurface processes reveals local scale temporal dynamics b 2 d plan view of surface processes reveals spatial dynamics at the catchments scale and c 3 d view of coupled surface subsurface processes captures spatiotemporal dynamics at the coastline segment scale fig 2 gis data collected for coupled surface subsurface hydrologic modeling a shows the elevation and location of model domain in greece shown in green b depicts the river network and major faults for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 hydrological processes associated with the pihm for fresh sgd estimation the triangular prisms represent the spatial domain decomposition and blue lines represent river channels hydrological processes are shown for each triangular prism white lines indicate no flow boundaries dark blue lines indicate coastal boundaries for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 4 comparison of simulated and observed hydrological variables panel a shows mean et from 2007 figure 4 comparison of simulated and observed hydrological variables panel a shows mean et from 2007 7 1 to 2010 6 30 obtained from modis data panel b shows mean et from 2007 7 1 to 2010 6 30 obtained from model simulation panel c shows the variation in 8 day averaged et from modis black dots and results from the model simulation red dots in panel d the observed results black lines and modeled streamflow red lines are shown together for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 5 locations and magnitude of fresh sgd and river discharge panel a shows the location of karst faults gray triangles rivers light blue and shorelines dark blue panels b and c describe the spatial variation in the magnitudes of simulated fresh sgd open circles and streamflow blue dots along the north and south shorelines respectively locations of top 5 local maxima are labeled by numbers and identified on the shorelines black dashed line denotes the average fresh sgd of the north and south shorelines respectively for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 6 daily fresh sgd along the a north and b the south shorelines black line indicates the mean value of fresh sgd at 5 locations shown in fig 5 the gray area indicates first and third quartiles fig 7 spatial pattern of fresh sgd in wet and dry season along the a north and b the south shorelines fig 8 cumulative fresh sgd flux distributions for the north blue and south red shorelines a daily values on each computational unit b spatial mean through coastlines and c temporal mean through simulation periods for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 9 sgd along the coasts of ms as determined by a point measurements of velociy table 4 b point measurements estimated fluxes black boxplot table 3 and c the 228ra mass balance method black boxplot table 3 plotted together with results from this study 3 year average red boxplot for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 10 comparison of fresh sgd values and spatial resolution from different studies table 1 hotspots of discharge to the sea hotspots surface water runoff m3 day river slope m m r1 1 07e 08 1 20e 02 r2 3 40e 07 9 10e 03 r3 2 11e 07 6 10e 03 r4 7 71e 07 6 50e 03 r5 4 24e 06 8 00e 03 r6 1 06e 08 1 00e 02 r7 1 75e 08 8 60e 03 r8 6 09e 07 1 08e 02 r9 1 72e 07 1 50e 02 r10 1 10e 07 2 40e 03 r11 7 55e 07 5 00e 02 hotspots groundwater fresh sgd m3 m day k m day g1 7 85e 03 14 9 g2 5 05e 03 8 9 g3 1 22e 04 10 3 g4 7 05e 03 7 8 g5 4 99e 03 13 9 g6 1 46e 04 10 3 g7 1 31e 05 13 9 g8 3 20e 04 7 8 g9 1 26e 04 8 2 g10 1 25e 04 8 9 table 2 the water budget and fresh sgd to the north and south shorelines shoreline p et streamflow fresh sgd surface runoff to the sea north m3 year 8 40e 08 4 49e 08 3 50e 08 5 20e 07 3 20e 04 northw m3 year m2 1 07e 00 5 72e 01 4 46e 01 6 62e 02 4 07e 05 northl m3 year m 4 23e 02 0 26 1 09e 02 7 47e 02 south m3 year 7 20e 08 2 10e 08 3 40e 08 1 76e 08 8 00e 03 southw m3 year m2 2 02e 00 5 89e 01 9 54e 01 5 06e 01 2 25e 05 southl m3 year m 5 00e 03 0 22 1 92e 03 6 42e 02 indicates results from zhou et al 2019 indicates results from luijendijk et al 2020 table 3 shore normalized sgd estimates for different sites of the ms study site shore length km sgd 106 m3 km 1 yr 1 reference maro cerro gordo spain 16 00 0 25 montiel et al 2018 balearic islands spain 0 28 0 54 garcia solsona et al 2010a alcalfar spain 0 40 0 40 garcia solsona et al 2010a 2010b romàntica spain 0 15 0 40 tovar sánchez et al 2014 santanyí spain 0 07 1 40 tovar sánchez et al 2014 dor beach israel 0 10 1 80 weinstein et al 2007 dor beach israel 0 10 2 60 swarzenski et al 2006 palma beach spain 4 40 4 60 rodellas et al 2014 donnalucatta italy 0 04 6 00 taniguchi et al 2006 peníscola spain 3 00 6 30 rodellas et al 2012 la palme lagoon france 6 00 7 90 stieglitz et al 2013 marina lagoon egypt 11 00 8 00 el gamal et al 2012 el maestrat spain 45 00 8 30 mejías et al 2012 stoupa greece 2 00 11 00 pavlidou et al 2014 lesina lagoon italy 25 00 13 00 rapaglia et al 2012 badum spain 2 50 19 00 garcia solsona et al 2010a 2010b sa nau spain 0 08 21 00 tovar sánchez et al 2014 gulf of lyon france 300 00 29 00 ollivier et al 2008 donnalucatta italy 0 04 39 00 burnett and dulaiova 2006 south venice lag italy 15 00 40 00 gattacceca et al 2011 venice lagoon italy 80 00 160 00 rapaglia et al 2010 donnalucatta italy 0 20 370 00 moore 2006 vlora bay albania 22 00 2 00 polemio et al 2011 vlora bay albania 16 00 2 76 polemio et al 2011 maestrazgo spain 40 00 0 21 mejías et al 2012 dor beach israel 0 10 1 80 weinstein et al 2007 formosa portugal 3 60 1 31 leote et al 2008 maro cliff spain 1 10 294 65 montiel et al 2018 cantarrijan beach spain 0 70 166 86 montiel et al 2018 white mountains region greece 0 57 2 60 this study indicates the isotope mass balance method indicates the water budget method indicates seepage meter estimates table 4 seepage meter estimated flux velocity for sites of the ms study site sgd cm d reference es cargol spain 15 0 basterretxea et al 2010 portocolom spain 8 7 basterretxea et al 2010 soller spain 5 8 basterretxea et al 2010 santa ponca spain 3 4 basterretxea et al 2010 balearic islands spain 2 5 garcia solsona et al 2010a maro cliff spain 19 0 montiel et al 2018 maro cliff spain 32 0 montiel et al 2018 maro cliff spain 37 0 montiel et al 2018 maro cliff spain 25 0 montiel et al 2018 cantarrijan beach spain 32 0 montiel et al 2018 cantarrijan beach spain 13 0 montiel et al 2018 cantarrijan beach spain 26 0 montiel et al 2018 cantarrijan beach spain 20 0 montiel et al 2018 research papers capturing hotspots of fresh submarine groundwater discharge using a coupled surface subsurface model xuan yu conceptualization methodology writing original draft a b zexuan xu conceptualization methodology c daniel moraetis investigation data curation writing review editing d nikolaos p nikolaidis supervision writing review editing e franklin w schwartz writing review editing f yu zhang software writing review editing g lele shu data curation h i christopher j duffy supervision writing review editing j bingjun liu writing review editing a b a center for water resources and environment school of civil engineering sun yat sen university guangzhou 510275 china center for water resources and environment school of civil engineering sun yat sen university guangzhou 510275 china center for water resources and environment school of civil engineering sun yat sen university guangzhou 510275 china b southern marine science and engineering guangdong laboratory zhuhai zhuhai 519082 china southern marine science and engineering guangdong laboratory zhuhai zhuhai 519082 china southern marine science and engineering guangdong laboratory zhuhai zhuhai 519082 china c climate and ecosystem sciences division lawrence berkeley national laboratory berkeley ca 94720 usa climate and ecosystem sciences division lawrence berkeley national laboratory berkeley ca 94720 usa climate and ecosystem sciences division lawrence berkeley national laboratory berkeley ca 94720 usa d department of applied physics and astronomy university of sharjah sharjah 27272 uae department of applied physics and astronomy university of sharjah sharjah 27272 uae department of applied physics and astronomy university of sharjah sharjah 27272 uae e school of environmental engineering technical university of crete university campus 73100 chania greece school of environmental engineering technical university of crete university campus 73100 chania greece school of environmental engineering technical university of crete university campus 73100 chania greece f school of earth sciences the ohio state university columbus oh 43210 usa school of earth sciences the ohio state university columbus oh 43210 usa school of earth sciences the ohio state university columbus oh 43210 usa g earth and environmental sciences division los alamos national laboratory los alamos nm 87545 usa earth and environmental sciences division los alamos national laboratory los alamos nm 87545 usa earth and environmental sciences division los alamos national laboratory los alamos nm 87545 usa h key laboratory of land surface process and climate change in cold and arid regions chinese academy of sciences lanzhou 730000 china key laboratory of land surface process and climate change in cold and arid regions chinese academy of sciences lanzhou 730000 china key laboratory of land surface process and climate change in cold and arid regions chinese academy of sciences lanzhou 730000 china i northwest institute of eco environment and resources chinese academy of sciences lanzhou 730000 china northwest institute of eco environment and resources chinese academy of sciences lanzhou 730000 china northwest institute of eco environment and resources chinese academy of sciences lanzhou 730000 china j department of civil and environmental engineering the pennsylvania state university university park pa 16802 usa department of civil and environmental engineering the pennsylvania state university university park pa 16802 usa department of civil and environmental engineering the pennsylvania state university university park pa 16802 usa corresponding author this manuscript was handled by jiri simunek editor in chief with the assistance of yonghong hao associate editor submarine groundwater discharge sgd contributes to the physical and chemical characters of coastal waters by discharging nutrients and contaminants significantly impacting regional marine ecosystems and contributing to ocean chemical budgets however such groundwater discharge varies dramatically across scales and is often not comparable due to different model assumptions and field designs we used a hydrologic model with integration of fundamental surface and subsurface processes to simulate the coastline level fresh sgd for the crete island in the mediterranean sea the modeled hydrological processes suggested that fresh sgd substantially contributes to water flow entering the mediterranean sea 2 3 108 m3 yr amounting to 31 of river discharge and 14 of precipitation spatially fresh sgd varied from 2 4 m3 yr m to 13 4 104 m3 yr m with an average of 2 6 103 m3 yr m the local maxima were commonly associated with river mouths reflecting larger hydraulic gradients and higher permeable structures temporally fresh sgd was impacted by episodic precipitation in a delayed and prolonged pattern we found that fresh sgd variability at the coastline segment level was compared to point measurements and fresh sgd magnitudes summered up to the catchment level were consistent with global products our results suggest the coupled surface subsurface hydrologic modeling approach is a promising strategy to quantify and partition large scale water budgets down to point observations that typically do not capture the full range of fresh sgd dynamics keywords submarine groundwater discharge river runoff surface water groundwater interaction coupled surface subsurface model pihm 1 introduction submarine groundwater discharge sgd is the flow of water on continental margins from the seabed to the coastal ocean comprising terrestrial water mixed with sea water that has infiltrated coastal aquifers burnett et al 2006 sgd continuously delivers groundwater to adjacent coastal surface waters carrying higher concentrations of nutrients and other land derived contaminants than river runoff e g dai et al 2021a mayfield et al 2021 sawyer et al 2016a slomp and van cappellen 2004 sgd may significantly impact regional marine ecosystems e g bishop et al 2015 kim et al 2017 liu et al 2017 2021 moore 2010 moraetis et al 2010 rocha et al 2016 santos et al 2021 shoji and tominaga 2018 wang et al 2014 2015 2018 wu et al 2013 and contribute to the chemical budgets of oceans at a global scale e g kwon et al 2014 cho and kim 2016 cho et al 2018 however the quantities of inflow and chemical composition of sgd are not well described for many coastal systems due to technical constraints in making necessary measurements in space and time the large uncertainties associated with indirect methods of characterization and the interdisciplinary barrier between marine science and hydrogeology taniguchi et al 2002 burnett et al 2006 2001 taniguchi et al 2019 duque et al 2020a numerical modeling of density dependent groundwater flow and mass transport provides an approach in quantifying sgd locally one strategy involves modeling a 2d cross section to determine fresh and salt water flows perpendicular to the seashore fig 1 a given specific inland and seafloor boundary conditions such a model provides salinity distributions and fluxes at ocean margin freshwater discharge areas as a function of different hydrogeological settings smith 2004 this approach facilitates estimates of how the magnitude of sgd can vary as a function of inland boundaries yu et al 2017 2019a 2019b michael et al 2005 tides abarca et al 2013 greskowiak 2014 heiss and michael 2014 li et al 2009 prieto and destouni 2005 robinson et al 2007a b xia and li 2012 waves robinson et al 2014 xin et al 2014 2015 and groundwater abstraction yu and michael 2019 stein et al 2019 however estimation of sgd by variable density simulation with a number of cross sections along coastlines can be rather tedious e g kreyns et al 2020 studies for large scale sgd estimation usually setup several base case of 2 d cross sections and then interpolate the results along coastlines luijendijk et al 2020 michael et al 2013 such method can effectively explain temporal dynamics of sgd along with point measurements by seepages meters duque et al 2020b while cross section methods cannot capture lateral re distribution of fluxes where rivers dissect the coastline zhang et al 2016 robinson et al 2018 alternatively sgd can be estimated separately as fresh and saline components since the amount fresh sgd is constrained by water budgets of coastal catchments saline sgd estimation has been extensively studied by isotopic tracer method such as radium isotopes moore 2003 1996 and then fresh sgd can be calculated from the water balance lee and kim 2007 douglas et al 2020 fresh sgd can also be estimated by modeling groundwater flow from catchment draining to the coast jarsjö et al 2008 developed a hydrologic model to estimate fresh sgd by separating surface runoff and groundwater recharge based on topography land cover vegetation and soil texture simulated flows from two swedish coastal catchments showed that 80 of the outflow to the ocean occurred as streamflow with the remaining 20 occurring as sgd along the coast however the spatial variability of fresh sgd is strongly dependent on coastline topography and the scale of variability introduced by streams and rivers destouni et al 2008 as well as geological heterogeneity russoniello et al 2013 michael et al 2016 such variability leads to large uncertainties in modeling surface runoff and groundwater discharge across space and time zhou et al 2018 further simplification on watershed geometry enables a reasonable estimation method of fresh sgd at the catchment level considering the water budget of a watershed if the watershed drains to a river gray in fig 1b we can assume no fresh sgd is created and the recharge eventually discharge to river which can be monitored sawyer et al 2016a if the watershed drains to coasts white in fig 1b neglecting surface runoff net imbalance between injection and withdrawal the net recharge groundwater should be equal to fresh sgd sawyer et al 2016a calculated continental scale water budgets for catchments draining to coasts and found that quantities of fresh sgd depend on both the geometry of drainage networks and climate knights et al 2017 applied this water budget method to estimate fresh groundwater discharge along the united states coastlines of great lakes zhou et al 2019 explored global scale fresh sgd using this water budget method and found that significant fresh sgd is exported along tropic coasts and tectonically active margins such water budget analyses essentially simplify groundwater processes to enable large scale and computationally efficient estimation of fresh sgd which can make use of abundant spatial and temporal data sets that provide the foundation for spatial dynamics understanding at catchment level zhou et al 2018 hajati et al 2019 developed a regional lumped transient water balance model to estimate fresh sgd of each catchment along the coast of java island the model demonstrated different seasonality of fresh sgd which is determined by aquifer and soil properties befus et al 2017 developed 3 d groundwater flow models for coastal regions of the eastern u s and gulf of mexico they found that for half of coastal catchments sgd included components that originated with recharge in catchments further inland due to cross watershed groundwater flow fig 1c this method can explicitly simulate fresh sgd contributions spatially due to heterogeneous subsurface properties but requires intensive geological data and parameterization at this point in time possibilities exist for the development of new methods for estimating sgd which further develop strengths of existing modeling approaches and minimize limitations zhou et al 2018 field oriented measurements of sgd demonstrated significant spatial and temporal heterogeneity seepage meters are the most common method providing point measurements at high temporal and high spatial resolution duque et al 2020b russoniello et al 2013 showed that fresh sgd varied spatially at both meter scales and 100 m scales due to natural geologic heterogeneity and the existence of paleovalleys montiel et al 2018 found that sgd in southern spain exhibited both strong seasonal variability and large spatial heterogeneity related to local hydrogeological settings in particular the extensive subsurface connectivity with fractures conduits and caves are potential hotspots of fresh sgd fleury et al 2007 xu et al 2016 modeled fresh sgd is often represented as a simple mean annual discharge value along a coast estimated by steady state simulations as a result many modeled fresh sgd results have been found to be less than field based estimates sawyer et al 2016a befus et al 2017 zhou et al 2018 current monitoring data of submarine groundwater discharge is rather limited in capturing the spatial patterns and complex temporal dynamics sawyer et al 2016b and point measurements may cause biased results due to observation time and locations moosdorf et al 2015 perhaps resolving hydrological processes in transient simulations can explain the discrepancy between modeled fresh sgd and field based estimates zhou et al 2018 conceptually fresh sgd within the coastal water cycle is primarily controlled by a variety of coupled surface subsurface hydrological processes befus et al 2017 fig 1c for example the amount of inland groundwater which outflows to the seabed i e fresh sgd is regulated by several hydrological processes such as recharge runoff at inland mountainous regions surface runoff is generated as horton overland flow horton 1945 dunne overland flow dunne and black 1970a 1970b or subsurface stormflow according to the hydrologic setting mirus and loague 2013 and antecedent conditions qu and duffy 2007 surface runoff flows to nearby surface water channels according to topographic gradients from ridges to valleys as determined by the terrain and geometry of the catchment land cover soil type and channel network some fraction of precipitation infiltrates soil zones with excess water flowing downward to recharge groundwater flow systems that eventually discharge in nearby rivers i e as streamflow or the seabed i e as fresh sgd these patterns of groundwater flow are determined by features of the hydrogeological setting e g karst conduits xu et al 2015 heterogeneity in hydraulic conductivity montiel et al 2018 the transient characteristics of coupled surface subsurface processes drive the exchange of water between groundwater and streams details of these interactions are important because they determine whether previously recharged groundwater drains into the stream as runoff or into the sea as fresh sgd along each coastline segment for this reason it is essential to include coupled surface subsurface hydrologic processes to characterize spatial and temporal dynamics of sgd at coastline segment level the main goal of this study is to reveal hotspots of fresh sgd at coastline segment level by a coupled surface subsurface model to this end we used a coupled surface subsurface hydrologic model driven by site specific data that for example include high resolution digital elevations land cover soil texture and features of the hydrogeological setting the model was calibrated and validated by available streamflow and evapotranspiration data and then the spatial variability of sgd estimations was compared against field based estimations at local level and global products at catchment level this study is an important step in identifying the hydrologic features that cause the apparent disparity between field and model based estimates of fresh sgd 2 materials and methods we used a coupled surface subsurface model at a mediterranean island fig 2 to explore how complexity in the climatologic and hydrogeologic settings naturally produce temporal and spatial variability in land surface hydrologic processes contributing to fresh sgd at the coastline segment level this section includes brief descriptions of the modeling approach application and analysis methods 2 1 modeling approach the computational approach involves a coupled surface subsurface hydrologic model penn state integrated hydrologic model pihm to perform the integrated simulation of surface subsurface hydrologic processes pihm kumar 2009 qu and duffy 2007 is a comprehensive hydrologic model that simulates water budget fluxes for interception throughfall infiltration recharge evapotranspiration overland flow unsaturated soil water processes groundwater flow and channel routing in a fully coupled manner evapotranspiration is calculated using the penman monteith approach adapted from noah lsm chen and dudhia 2001 overland flow is described in a simplified form of 2 d using st venant equations qu and duffy 2007 pihm uses a diffusive wave approximation for overland flow and streamflow the model conceptualizes the subsurface in terms of unsaturated and saturated layers fig 3d and assumes that flow in the unsaturated layer is one dimensional in the vertical direction recharge and 2 d in the layer of saturation groundwater flow recharge is calculated by richard s equation based on the difference of hydraulic heads between the unsaturated and saturated layers duffy 2004 groundwater flow is evaluated using a volume averaged version of darcy s law duffy 2004 interception and snowmelt are simulated with a bucket model and a temperature index model respectively horizontally the simulation domain is represented as unstructured delaunay triangles fig 3a the governing equation for each process is discretized on the triangles from canopy to bedrock forming partial differential equations pdes pihm incorporates a semi discrete finite volume formulation for solving the system of coupled pdes resulting in a system of ordinary differential equations odes representing all processes within each triangle the system of odes is solved using the cvode implicit solver cohen and hindmarsh 1996 in brief the pihm modeling approach provides a quasi 3d characterization of a watershed at each computational grid i e triangular prism state variables of surface water unsaturated storage and groundwater depth are solved according to lateral fluxes between each computational grid and vertical fluxes across ground surface and water table fig 3b in river channels the fluxes between river bank and river are calculated at both surface and subsurface layers fig 3c detailed descriptions of the modeling theory and mathematical formulation can be found in the associated publications kumar 2009 qu 2005 qu and duffy 2007 in this study a new seaside boundary condition adopted from zhang et al 2018 2019 in pihm wetland model was applied to simulate the surface and subsurface water exchange between fresh water from terrestrial landscapes and seawater from the ocean fig 3e this seaside boundary condition differs from the boundary conditions used in previous studies chen et al 2015 kumar et al 2013 liu and kumar 2016 shi et al 2013 yu et al 2015a 2019a 2019b yu et al 2015b zhang et al 2017a 2017b in which a no flow subsurface boundary condition along the coastline and critical depth surface flow boundary i e free fall over the weir at the outlet were applied specifically along the coastal boundary of the simulation domain surface runoff qsw m2 s is calculated based on the hydraulic gradient between the surface water height near the coast and the instant sea level namely 1 q sw s surf 5 3 s surf z h sea l n s t 1 2 where ssurf is the surface water depth m z is the land surface elevation m hsea is the instantaneous sea level m elevation on the boundary l is the distance between the center of the surface triangle to the ocean m ns is manning s roughness and t is the surface slope of the triangular element note that the mix of surface freshwater and saltwater and saltwater intrusion through surface infiltration during each tidal cycle is not simulated in this study due to 1 a focus on the large scale fresh sgd along the coastal aquifer and 2 an adequate capability of the subsurface head estimation in the subsurface our model simplified seawater intrusion processes as the pressure difference between the fresh water in the coastal aquifer and the saltwater from the ocean we assume i a dynamic sharp interface between the fresh and saltwater while ignoring the dispersion between the interface the blue dashed line in fig 3f and ii dupuit type horizontal flow gupta 1985 shamir and dagan 1971 ferguson and gleeson 2012 zhang et al 2018 this subsurface saltwater intrusion scheme has been widely used in saltwater intrusion studies with good predictive capabilities in understanding coastal subsurface freshwater and saltwater interaction e g shamir and dagan 1971 ferguson and gleeson 2012 zhang et al 2018 zhang et al 2019 according to zhang et al 2018 the following equations tracks the motion of the interface based on the conservation of the mass of freshwater and saltwater in coastal aquifer 2 q freshsgd k s sat s salt z b x 3 q salt k σ f s sat σ s s salt x where qfreshsgd and qsalt are the fresh groundwater flow m2 s respectively a positive value of the fluxes indicates a freshwater saltwater outflow from a model cell to adjacent cells or ocean boundary conversely a negative value means an inflow from adjacent cells or ocean boundary thus this form can dynamically track the fresh and salty groundwater flow at the land ocean interface ssat and ssalt are the groundwater and saltwater storage m respectively zb is the bedrock elevation m k is the hydraulic conductivity m day σf and σs are the density of fresh and salt water kg m3 respectively in this study σf 1 000 kg m3 and σs 1 027 5 kg m3 rodellas et al 2015 2 2 application and model setup the study area white mountains region wmr is located in the western portion of the island of crete in the mediterranean sea ms the wmr consists of the white mountains lefka ori and the surrounding coastal plains with an area of 1142 km2 fig 2 located at the western margin of the island of crete the fifth largest island in the ms our area of interest includes two e w oriented coastlines the north shoreline is 123 km long with a drainage area of 786 km2 the topography is characterized by steep mountain slopes with broad low lying flood plains connecting the shore and uplands the average slope is 17 degree the south shoreline is 36 km long with an associated drainage area of 356 km2 the topography across this area is mountainous with steep slopes averaging 27 degrees the wmr was selected because the region had been studied previously and there are basic data describing various features of the physical setting more importantly the presence of karst and differences in coastal geometry for the two study watersheds provide unique patterns of spatial and temporal variability in fresh sgd which highlight the need for coupled surface subsurface modeling approach more details of wmr are given in text s1 nikolaidis et al 2013 the model domain was discretized as an unstructured mesh of 7848 triangular prisms with each prism started from ground elevation to 20 m below river elements conform to edges of these triangular prisms fig 3 bhatt et al 2014 the various hydrologic processes incorporated in the model are illustrated in fig 3 we used topography land use soil and geologic data to parametrize each prism fig 4 table s2 output from the model facilitates the calculation of groundwater fluxes along the shoreline as fresh sgd surface runoff directly discharging into the ms at the shoreline is termed unmonitored runoff which was also calculated the initial condition for the transient simulation was obtained by spinning up the model with data from the two previous years 2005 7 1 2007 6 30 we began with a uniform water table depth of 10 m on 2005 7 1 and forced the model using the observed meteorological data text s1 the initial conditions provided a smooth water table surface from just below the land surface to 20 m the system proved to be so responsive that this period of spin up provided an appropriate set of initial conditions 2 3 calibration and validation pihm simulations were performed over a three year period 2007 7 1 2010 6 30 streamflow was calibrated using observed daily streamflow data at stylos spring fig 2b and modis remotely sensed et dataset mod16 running et al 2017 we calibrated two groups separately event and seasonal scale groups according to the method proposed by yu et al 2013 the event scale parameters were optimized using observed streamflow data from 2008 1 5 to 2008 3 4 a period in spring with largest flows the calibration was automatically achieved by the evolutionary method cma es hansen et al 2003 the seasonal scale parameters were adjusted based on et from 2007 7 1 to 2008 6 30 the simulation results for the last two years were used for validation we used the relative error e pearson product moment correlation coefficient r and nash sutcliffe coefficient of efficiency nse nash and sutcliffe 1970 to evaluate the model performance table s3 simulated 8 day average et running et al 2017 was in good agreement with modis data spatially fig 4a and b except in areas to northwest figure s3 average et from the simulation was 0 563 m yr which was comparable with the modis et value 0 589 m yr indicating reliable partitioning of the water budget fig 4c simulated streamflow results are shown in fig 4d the dynamics of streamflow variation between observed and modeled results were in reasonable agreement and were considered acceptable 2 4 fresh sgd comparisons we compared our fresh sgd estimates against model based fresh sgd at global scale zhou et al 2019 luijendijk et al 2020 and field estimated total sgd we focused on the spatial variability of fresh sgd between these estimates since large uncertainties may exist due to normalization of different methods moosdorf et al 2015 we used a simple method to estimate total sgd from pihm modeled fresh sgd using the relation prieto and destouni 2011 4 sg d total 1 1 s g d fresh 470 m 3 y r m 3 results 3 1 spatial patterns of fresh sgd the magnitude of fresh sgd along the modeled coastlines during the simulation period was 2 3 108 m3 yr amounting to 33 of modeled river discharge i e 6 9 108 m3 yr 14 of precipitation i e 1 6 109 m3 yr the average shore length of each modeling edge was 568 m we normalized fresh sgd to shore length and obtained 2 6 103 m3 yr m for all the coastlines the maximum fresh sgd was 1 34 105 m3 yr m while the minimum fresh sgd was only 2 4 m3 yr m fig 5 a previous study pnue pam plan bleu 2004 estimated fresh groundwater discharge from annual climate data and found that fresh groundwater discharge to ms was 46 of river discharge which was slightly higher than our methods where a much lower resolution and a rough estimation method were applied the spatial patterns of fresh sgd along both coastlines showed significant variability with the maxima in the vicinity of river mouths and locations of karst fault intersection with the coast spatial distributions of fresh sgd were plotted as a function of distance along the coast west to east for the north and south shorelines with reference to the most important discharge location of groundwater flow river alluvium and karst fig 5b and c the top 5 local maxima of fresh sgd fluxes along the north shoreline were 1 22 0 79 0 71 0 6 51 and 0 50 104 m3 yr m locations g1 g3 g4 and g5 were close to river mouths fig 5 locations g2 and g5 were at karst faults the top 5 local maxima of fresh sgd fluxes along the south shoreline were 13 1 3 20 1 46 1 26 and 1 25 104 m3 yr m locations g7 and g8 were close to river mouths fig 5 location g7 and g9 were at karst faults location g6 and g10 were close to small rivers fig 2b represented by topography long stretches of coastline in between are characterized by much lower fresh sgd most of them are below the average value 0 07 104 m3 yr m for the north shoreline and 0 77 104 m3 yr m for the south shoreline indicated by the black dashed lines in fig 5 fresh sgd near rivers r6 r8 r9 and r11 were below average these rivers had steep slopes near the mouths table 1 groundwater were forced to recharge to the rivers and leave the catchment as streamflow the water budgets of the north and south shorelines controlled the actual magnitudes of localized fresh sgd differently though locations of hotspots tended to be close to riverbeds in a similar pattern table 2 lists modeled water budgets for 2007 7 1 2010 6 30 of the north and south parts of wmr total water budgets suggested more precipitation more et and less fresh sgd in the northward draining watersheds normalized variable by drainage area northw and southw in table 2 suggested that less precipitation similar et and less fresh sgd in the north part normalized variable by coastline length northl and southl in table 2 suggested that fresh sgd to the south shoreline was more than one order magnitude higher than the north to the south 1 km of the shoreline on average drains 9 9 km2 whereas to the north 1 km of shoreline drains 6 3 km2 the hydraulic gradients along the south coastline are also on average greater than the gradients in the north coastline which results in larger magnitude of fresh sgd model results also indicated that unmonitored runoff i e surface runoff to the sea was negligible in wmr compared to river runoff 3 2 temporal dynamics of fresh sgd daily fresh sgd was affected by episodic precipitation fig 6 the response time are different between the north and south shorelines in the north part of the domain a maximum daily average rainfall rate 0 22 m d occurred on 2010 1 12 fig 6a the peak of fresh sgd occurred the following day i e the sgd response was delayed by only 1 d in the south a maximum daily average rainfall event of 0 42 m d took place on 2010 1 12 fig 6b the peak in fresh sgd occurred on 2010 1 31 i e with a response time of 19 d seasonal hydrologic conditions controled the hotspots of fresh sgd for the typical mediterranean climate 94 of the precipitation occurs during the wet season winter and spring along the north shoreline 98 9 of the annual fresh sgd was produced during the wet season whereas 91 3 of the annual fresh sgd was produced during the wet season along the south shoreline wet season showed most fresh sgd and the hotspots included both karst aquifers and flat riverbeds fig 7 while in dry season karst aquifers didn t generate high fresh sgd only flat riverbeds were still fresh sgd hotspots mean values of fresh sgd through space and time significantly reduced its variability the distributions or relative frequency of fresh sgd computed from daily time series from 2007 7 1 to 2010 6 30 at each computational unit were similar between the north shoreline and the south shoreline fig 7 a mean values through coastlines reduced the maximum fresh sgd of both shorelines and increased the minimum fresh sgd of north shoreline more significantly than the south shoreline fig 7b mean values through simulation periods also reduced the variability of fresh sgd and resulted different patterns between these two shorelines fig 7c 3 3 comparison of spatial variability with local estimates total sgd along the shorelines of our model domain ranged from 4 7 102 to 1 5 105 m3 yr m with a mean of 3 3 103 m3 yr m fig 9 previous local studies using radium isotopes methods estimated total sgd ranging from 4 102 to 3 7 105 m3 yr m where shoreline length ranged from 0 04 to 300 km burnett and dulaiova 2006 el gamal et al 2012 garcia solsona et al 2010a 2010b gattacceca et al 2011 mejías et al 2012 montiel et al 2018 moore 2006 ollivier et al 2008 pavlidou et al 2014 rapaglia et al 2010 2012 rodellas et al 2012 2014 stieglitz et al 2013 swarzenski et al 2006 taniguchi et al 2006 tovar sánchez et al 2014 weinstein et al 2007 point measurements by seepage meters indicated that total sgd ranged from to 2 1 102 to 3 0 105 m3 yr m fig 9 a basin wide estimation of total sgd along ms ranged from 6 103 to 1 105 m3 yr m rodellas et al 2015 thus our estimated total sgd was in good agreement with local studies conducted along the ms using 228ra mass balance methods and seepage meter measurements table 3 and 4 according to the range but was greatly lower according to the median fig 9 3 4 comparison of magnitude with catchment level estimates global estimation of fresh sgd has much coarser resolution with significantly reduced spatial variability comparing to our results both luijendijk et al 2020 and zhou et al 2019 estimated global fresh sgd distribution using coastal catchments as the computational unit for our study area the coastline lengths of each catchment was 5 7 km to 23 km in luijendijk et al 2020 and 1 2 km to 79 km fig 10 after summary at catchment scale the magnitudes of our estimation showed similar spatial distribution to global fresh sgd products table 2 4 discussions this study highlights the need to consider the fully coupled effects of hydrological processes in determining fresh sgd hotspots at the coastline segment level the spatial and temporal characteristics revealed by coupled surface subsurface processes are potentially useful in analyzing systems at scales up to continental by catchment water budgets and down to points measurements by seepage meters 4 1 spatiotemporal dynamics of fresh sgd the work presented here shows that significant fresh sgd flows at riverbeds after river floods the 10 hotspots g1 g10 fig 5 witnessed 38 of total fresh sgd along the coasts and 8 of them were close to riverbeds with 35 of total fresh sgd the temporal dynamics suggested that 92 of fresh sgd was in wet season such mechanism is reasonable since surface processes controls the recharges to surficial aquifers and then discharges to nearshore coasts responses of fresh sgd to different drive mechanisms have been revealed by cross sectional modeling studies xin et al 2014 2015 yu et al 2017 our simulated time lags between peaks of precipitation and fresh sgd ranges from 1 to 19 days which is comparable to previous results ranging from 3 to 41 days yu et al 2017 since we used constant sea level boundary condition our time lags may be underestimated without the effects of waves and tides xin et al 2014 2015 luckily it is more practical to install field measurements nearshore than offshore hotspots captured here can be validated by nearshore field installation along these coastlines though current field estimates fig 9 were not located in our study area we also note that in regional groundwater dominated systems temporal patterns may be less impacted by surface processes due to deep groundwater recharge from confined aquifers el gamal et al 2012 guo and li 2015 future work should address how to conceptualize subsurface aquifers for hydrologic models along karstic aquifers in highly tectonized and deformed rocks fresh sgd estimation studies should pay more attention on riverbeds our study shows that areas close to flat riverbeds and karst aquifers are potential fresh sgd hotspots it is not surprising that high fresh sgd flow at karst aquifers while fresh sgd around riverbeds is much dynamic revealed by two way coupled surface subsurface approach figure s4 text s2 spatial riverbed geometry has been overlooked in most global identification studies befus et al 2017 zhou et al 2018 sawyer et al 2016a luijendijk et al 2020 these global fresh sgd datasets show no difference between river mouth and rest of the coast figure s5 the mean values of fresh sgd along the coastline and at the riverbed showed no significant difference in majority of these continents table s4 our results highlight the importance of considering river flow dynamics when making global fresh sgd estimation across temporal and spatial scales both synthetic and site specific studies have also demonstrated that complex groundwater surface interaction increase groundwater discharge rate at coastal zones e g sawyer et al 2015 kolker et al 2013 glaser et al 2021 hydrological fluxes across riverbeds are complex due to both natural flow dynamics and human activities sawyer et al 2016b grill et al 2019 more field studies of fresh sgd around river mouths are encouraged across different climate and hydrogeological settings improved global fresh sgd estimation method is expected with consideration on the impact of flowing rivers since 63 of the world s rivers 1 000 km no longer free flowing grill et al 2019 4 2 from point measurements to coastline segments increase resolution of model based fresh sgd to coastline segments provides a promising opportunity to resolve the discrepancy between modeled and field based fresh sgd the coupled surface subsurface modeling method could estimate fresh sgd at the coastline segment scale our example showed fresh sgd at such high resolution i e 0 3 km to 1 km could capture the spatial variability of field observations and obtain similar magnitudes of fresh sgd fig 9 model based daily or even higher temporal resolution on fresh sgd can provide field work guide for seepages meters spatiotemporal continues fresh sgd estimation by coupled surface subsurface approach provides valuable information for monitoring plans of seepage meters duque et al 2020b combinations between seepage meters and coupled surface subsurface modeling methods may obtain an integrated understanding of interpolation between measurement events and reduce biased results due to selection on measurement locations and seasons moosdorf et al 2015 zhou et al 2018 4 3 from catchments to coastline segments fresh sgd reduces the spatial variability by averaging along the coastline both water budget method zhou et al 2019 and cross section interpolation method luijendijk et al 2020 estimated fresh sgd at variable spatial resolution due to geometry of coastal watersheds fig 10 comparison between two catchment level products showed relation between spatial resolution and variability of fresh sgd high spatial variability of fresh sgd was reduced due to summary at catchment level using the catchment scale fresh sgd as a constraint to obtain higher resolution at coastline segment level will lead more useful information for coastal management fresh sgd estimate at coastline segment level are more informative to understand how land use change impacts since land use types have a dominant control of chemical composition of sgd bishop et al 2015 watershed hydrologists has developed and applied coupled surface subsurface models at many inland watersheds e g chen et al 2015 yu et al 2015a cross sectional aquifers e g dai et al 2021b heiss et al 2015 yu et al 2016 and continental scales e g condon and maxwell 2015 sutanudjaja et al 2014 it is feasible to setup coupled hydrologic models along coastlines to reveal the spatial distribution and temporal responses at the coastline segment level 4 4 simplifications and limitations many other factors may affect the magnitude and timing of fresh sgd one major concern is the representation of subsurface a uniform 20 meter depth is not enough for this geological complex region moraetis et al 2010 the conceptualization of pihm is to integrate groundwater and unsaturated zone as two state for rainfall storage runoff processes in complex topography geology soil and climate variability duffy 1996 such assumption enables wide application of pihm since thickness from ground surface to bedrock is usually difficult to conceptualize in watershed models condon et al 2020 shi et al 2015 this one layer groundwater flow assumption ignores regional groundwater flow and may underestimate the fresh sgd befus et al 2017 moreover the geology complexity especially with the presence of unmapped faults or even large scale folds with preferential flow along fold hinges may have underestimated fresh sgd rates lilli et al 2020 and supplementary information therein as well as time lags for freshwater to transport from the recharge area to the sea nevertheless our findings showed contrasting spatial difference of fresh sgd distribution which should be careful addresses when we compare field based estimates with the results of water budget methods it is worth to investigate the impact of subsurface conceptualization rapp et al 2020 on fresh sgd estimation in future studies simplification of seaside boundary may introduce uncertainty in fresh sgd the assumption of sharp interface on the sea side boundary may underestimate saline sgd since density driven seawater circulation through heterogeneous aquifers can significantly enhance fresh saline groundwater mixing michael et al 2016 the mechanism has less impact on fresh sgd because the amount fresh discharge is constrained by the water budget sensitivity of streamflow and sgd to seaside boundary should be further studied e g pool et al 2011 the representation of karst was simplified to achieve operational parameterization additional field surveys are ongoing to improve performance of calibrated model parameters and understanding on karst conduits which is critical for this system e g bakalowicz 2015 lilli et al 2020 the improved model performance will affect the results of the estimated fresh sgd but it does not affect general conclusions on spatial and temporal dynamics of fresh sgd 5 conclusions this study describes a coupled surface subsurface modeling approach that was applied in the estimation of fresh sgd at coastline segment level the potential of this approach was demonstrated through an illustrative application in a mediterranean island what is particularly noteworthy is the hydrologic control provided by permeable karst and river mouth that potentially focuses groundwater discharge to discrete locations also the episodic characteristic of the discharge reflects near surface process control on the temporal dynamic of fresh sgd the spatial and temporal variability of fresh sgd should be carefully interpreted because the distributions are highly skewed to the authors knowledge the fresh sgd has not yet been investigated by coupled surface subsurface flow models at the watershed scale our modeling results suggested that surface water groundwater interaction cross riverbeds controls the spatial and temporal dynamics of fresh sgd at coastline segment level our illustration suggests a promising and cost effective method for modeling fresh sgd comparable to seepage meter results and to catchment water budget estimates credit authorship contribution statement xuan yu conceptualization methodology writing original draft zexuan xu conceptualization methodology daniel moraetis investigation data curation writing review editing nikolaos p nikolaidis supervision writing review editing frank w schwartz writing review editing yu zhang software writing review editing lele shu data curation christopher duffy supervision writing review editing bingjun liu writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement all data for this study can be obtained from the corresponding author yuxuan7 mail sysu edu cn the authors thank eliot atekwana from university of delaware for discussion and anonymous reviewers for their valuable comments on delineating the strength of the paper this work was initiated by the soiltrec soil transformations in european catchments european commission 7th framework programme as a large integrating project grant agreement no 244118 and the igcp 715 a new karst modelling approach along different tectonic contacts by unesco and iugs the authors acknowledge the national natural science foundation of china grant no 51879289 and no 91547108 the national key research and development program of china 2017yfc0405900 and the guangdong provincial department of science and technology 2019zt08g090 for supporting this work appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126356 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4572,submarine groundwater discharge from a coastal watershed a 2 d cross section view of subsurface processes reveals local scale temporal dynamics b 2 d plan view of surface processes reveals spatial dynamics at the catchments scale and c 3 d view of coupled surface subsurface processes captures spatiotemporal dynamics at the coastline segment scale fig 2 gis data collected for coupled surface subsurface hydrologic modeling a shows the elevation and location of model domain in greece shown in green b depicts the river network and major faults for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 3 hydrological processes associated with the pihm for fresh sgd estimation the triangular prisms represent the spatial domain decomposition and blue lines represent river channels hydrological processes are shown for each triangular prism white lines indicate no flow boundaries dark blue lines indicate coastal boundaries for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 4 comparison of simulated and observed hydrological variables panel a shows mean et from 2007 figure 4 comparison of simulated and observed hydrological variables panel a shows mean et from 2007 7 1 to 2010 6 30 obtained from modis data panel b shows mean et from 2007 7 1 to 2010 6 30 obtained from model simulation panel c shows the variation in 8 day averaged et from modis black dots and results from the model simulation red dots in panel d the observed results black lines and modeled streamflow red lines are shown together for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 5 locations and magnitude of fresh sgd and river discharge panel a shows the location of karst faults gray triangles rivers light blue and shorelines dark blue panels b and c describe the spatial variation in the magnitudes of simulated fresh sgd open circles and streamflow blue dots along the north and south shorelines respectively locations of top 5 local maxima are labeled by numbers and identified on the shorelines black dashed line denotes the average fresh sgd of the north and south shorelines respectively for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 6 daily fresh sgd along the a north and b the south shorelines black line indicates the mean value of fresh sgd at 5 locations shown in fig 5 the gray area indicates first and third quartiles fig 7 spatial pattern of fresh sgd in wet and dry season along the a north and b the south shorelines fig 8 cumulative fresh sgd flux distributions for the north blue and south red shorelines a daily values on each computational unit b spatial mean through coastlines and c temporal mean through simulation periods for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 9 sgd along the coasts of ms as determined by a point measurements of velociy table 4 b point measurements estimated fluxes black boxplot table 3 and c the 228ra mass balance method black boxplot table 3 plotted together with results from this study 3 year average red boxplot for interpretation of the references to colour in this figure legend the reader is referred to the web version of this article fig 10 comparison of fresh sgd values and spatial resolution from different studies table 1 hotspots of discharge to the sea hotspots surface water runoff m3 day river slope m m r1 1 07e 08 1 20e 02 r2 3 40e 07 9 10e 03 r3 2 11e 07 6 10e 03 r4 7 71e 07 6 50e 03 r5 4 24e 06 8 00e 03 r6 1 06e 08 1 00e 02 r7 1 75e 08 8 60e 03 r8 6 09e 07 1 08e 02 r9 1 72e 07 1 50e 02 r10 1 10e 07 2 40e 03 r11 7 55e 07 5 00e 02 hotspots groundwater fresh sgd m3 m day k m day g1 7 85e 03 14 9 g2 5 05e 03 8 9 g3 1 22e 04 10 3 g4 7 05e 03 7 8 g5 4 99e 03 13 9 g6 1 46e 04 10 3 g7 1 31e 05 13 9 g8 3 20e 04 7 8 g9 1 26e 04 8 2 g10 1 25e 04 8 9 table 2 the water budget and fresh sgd to the north and south shorelines shoreline p et streamflow fresh sgd surface runoff to the sea north m3 year 8 40e 08 4 49e 08 3 50e 08 5 20e 07 3 20e 04 northw m3 year m2 1 07e 00 5 72e 01 4 46e 01 6 62e 02 4 07e 05 northl m3 year m 4 23e 02 0 26 1 09e 02 7 47e 02 south m3 year 7 20e 08 2 10e 08 3 40e 08 1 76e 08 8 00e 03 southw m3 year m2 2 02e 00 5 89e 01 9 54e 01 5 06e 01 2 25e 05 southl m3 year m 5 00e 03 0 22 1 92e 03 6 42e 02 indicates results from zhou et al 2019 indicates results from luijendijk et al 2020 table 3 shore normalized sgd estimates for different sites of the ms study site shore length km sgd 106 m3 km 1 yr 1 reference maro cerro gordo spain 16 00 0 25 montiel et al 2018 balearic islands spain 0 28 0 54 garcia solsona et al 2010a alcalfar spain 0 40 0 40 garcia solsona et al 2010a 2010b romàntica spain 0 15 0 40 tovar sánchez et al 2014 santanyí spain 0 07 1 40 tovar sánchez et al 2014 dor beach israel 0 10 1 80 weinstein et al 2007 dor beach israel 0 10 2 60 swarzenski et al 2006 palma beach spain 4 40 4 60 rodellas et al 2014 donnalucatta italy 0 04 6 00 taniguchi et al 2006 peníscola spain 3 00 6 30 rodellas et al 2012 la palme lagoon france 6 00 7 90 stieglitz et al 2013 marina lagoon egypt 11 00 8 00 el gamal et al 2012 el maestrat spain 45 00 8 30 mejías et al 2012 stoupa greece 2 00 11 00 pavlidou et al 2014 lesina lagoon italy 25 00 13 00 rapaglia et al 2012 badum spain 2 50 19 00 garcia solsona et al 2010a 2010b sa nau spain 0 08 21 00 tovar sánchez et al 2014 gulf of lyon france 300 00 29 00 ollivier et al 2008 donnalucatta italy 0 04 39 00 burnett and dulaiova 2006 south venice lag italy 15 00 40 00 gattacceca et al 2011 venice lagoon italy 80 00 160 00 rapaglia et al 2010 donnalucatta italy 0 20 370 00 moore 2006 vlora bay albania 22 00 2 00 polemio et al 2011 vlora bay albania 16 00 2 76 polemio et al 2011 maestrazgo spain 40 00 0 21 mejías et al 2012 dor beach israel 0 10 1 80 weinstein et al 2007 formosa portugal 3 60 1 31 leote et al 2008 maro cliff spain 1 10 294 65 montiel et al 2018 cantarrijan beach spain 0 70 166 86 montiel et al 2018 white mountains region greece 0 57 2 60 this study indicates the isotope mass balance method indicates the water budget method indicates seepage meter estimates table 4 seepage meter estimated flux velocity for sites of the ms study site sgd cm d reference es cargol spain 15 0 basterretxea et al 2010 portocolom spain 8 7 basterretxea et al 2010 soller spain 5 8 basterretxea et al 2010 santa ponca spain 3 4 basterretxea et al 2010 balearic islands spain 2 5 garcia solsona et al 2010a maro cliff spain 19 0 montiel et al 2018 maro cliff spain 32 0 montiel et al 2018 maro cliff spain 37 0 montiel et al 2018 maro cliff spain 25 0 montiel et al 2018 cantarrijan beach spain 32 0 montiel et al 2018 cantarrijan beach spain 13 0 montiel et al 2018 cantarrijan beach spain 26 0 montiel et al 2018 cantarrijan beach spain 20 0 montiel et al 2018 research papers capturing hotspots of fresh submarine groundwater discharge using a coupled surface subsurface model xuan yu conceptualization methodology writing original draft a b zexuan xu conceptualization methodology c daniel moraetis investigation data curation writing review editing d nikolaos p nikolaidis supervision writing review editing e franklin w schwartz writing review editing f yu zhang software writing review editing g lele shu data curation h i christopher j duffy supervision writing review editing j bingjun liu writing review editing a b a center for water resources and environment school of civil engineering sun yat sen university guangzhou 510275 china center for water resources and environment school of civil engineering sun yat sen university guangzhou 510275 china center for water resources and environment school of civil engineering sun yat sen university guangzhou 510275 china b southern marine science and engineering guangdong laboratory zhuhai zhuhai 519082 china southern marine science and engineering guangdong laboratory zhuhai zhuhai 519082 china southern marine science and engineering guangdong laboratory zhuhai zhuhai 519082 china c climate and ecosystem sciences division lawrence berkeley national laboratory berkeley ca 94720 usa climate and ecosystem sciences division lawrence berkeley national laboratory berkeley ca 94720 usa climate and ecosystem sciences division lawrence berkeley national laboratory berkeley ca 94720 usa d department of applied physics and astronomy university of sharjah sharjah 27272 uae department of applied physics and astronomy university of sharjah sharjah 27272 uae department of applied physics and astronomy university of sharjah sharjah 27272 uae e school of environmental engineering technical university of crete university campus 73100 chania greece school of environmental engineering technical university of crete university campus 73100 chania greece school of environmental engineering technical university of crete university campus 73100 chania greece f school of earth sciences the ohio state university columbus oh 43210 usa school of earth sciences the ohio state university columbus oh 43210 usa school of earth sciences the ohio state university columbus oh 43210 usa g earth and environmental sciences division los alamos national laboratory los alamos nm 87545 usa earth and environmental sciences division los alamos national laboratory los alamos nm 87545 usa earth and environmental sciences division los alamos national laboratory los alamos nm 87545 usa h key laboratory of land surface process and climate change in cold and arid regions chinese academy of sciences lanzhou 730000 china key laboratory of land surface process and climate change in cold and arid regions chinese academy of sciences lanzhou 730000 china key laboratory of land surface process and climate change in cold and arid regions chinese academy of sciences lanzhou 730000 china i northwest institute of eco environment and resources chinese academy of sciences lanzhou 730000 china northwest institute of eco environment and resources chinese academy of sciences lanzhou 730000 china northwest institute of eco environment and resources chinese academy of sciences lanzhou 730000 china j department of civil and environmental engineering the pennsylvania state university university park pa 16802 usa department of civil and environmental engineering the pennsylvania state university university park pa 16802 usa department of civil and environmental engineering the pennsylvania state university university park pa 16802 usa corresponding author this manuscript was handled by jiri simunek editor in chief with the assistance of yonghong hao associate editor submarine groundwater discharge sgd contributes to the physical and chemical characters of coastal waters by discharging nutrients and contaminants significantly impacting regional marine ecosystems and contributing to ocean chemical budgets however such groundwater discharge varies dramatically across scales and is often not comparable due to different model assumptions and field designs we used a hydrologic model with integration of fundamental surface and subsurface processes to simulate the coastline level fresh sgd for the crete island in the mediterranean sea the modeled hydrological processes suggested that fresh sgd substantially contributes to water flow entering the mediterranean sea 2 3 108 m3 yr amounting to 31 of river discharge and 14 of precipitation spatially fresh sgd varied from 2 4 m3 yr m to 13 4 104 m3 yr m with an average of 2 6 103 m3 yr m the local maxima were commonly associated with river mouths reflecting larger hydraulic gradients and higher permeable structures temporally fresh sgd was impacted by episodic precipitation in a delayed and prolonged pattern we found that fresh sgd variability at the coastline segment level was compared to point measurements and fresh sgd magnitudes summered up to the catchment level were consistent with global products our results suggest the coupled surface subsurface hydrologic modeling approach is a promising strategy to quantify and partition large scale water budgets down to point observations that typically do not capture the full range of fresh sgd dynamics keywords submarine groundwater discharge river runoff surface water groundwater interaction coupled surface subsurface model pihm 1 introduction submarine groundwater discharge sgd is the flow of water on continental margins from the seabed to the coastal ocean comprising terrestrial water mixed with sea water that has infiltrated coastal aquifers burnett et al 2006 sgd continuously delivers groundwater to adjacent coastal surface waters carrying higher concentrations of nutrients and other land derived contaminants than river runoff e g dai et al 2021a mayfield et al 2021 sawyer et al 2016a slomp and van cappellen 2004 sgd may significantly impact regional marine ecosystems e g bishop et al 2015 kim et al 2017 liu et al 2017 2021 moore 2010 moraetis et al 2010 rocha et al 2016 santos et al 2021 shoji and tominaga 2018 wang et al 2014 2015 2018 wu et al 2013 and contribute to the chemical budgets of oceans at a global scale e g kwon et al 2014 cho and kim 2016 cho et al 2018 however the quantities of inflow and chemical composition of sgd are not well described for many coastal systems due to technical constraints in making necessary measurements in space and time the large uncertainties associated with indirect methods of characterization and the interdisciplinary barrier between marine science and hydrogeology taniguchi et al 2002 burnett et al 2006 2001 taniguchi et al 2019 duque et al 2020a numerical modeling of density dependent groundwater flow and mass transport provides an approach in quantifying sgd locally one strategy involves modeling a 2d cross section to determine fresh and salt water flows perpendicular to the seashore fig 1 a given specific inland and seafloor boundary conditions such a model provides salinity distributions and fluxes at ocean margin freshwater discharge areas as a function of different hydrogeological settings smith 2004 this approach facilitates estimates of how the magnitude of sgd can vary as a function of inland boundaries yu et al 2017 2019a 2019b michael et al 2005 tides abarca et al 2013 greskowiak 2014 heiss and michael 2014 li et al 2009 prieto and destouni 2005 robinson et al 2007a b xia and li 2012 waves robinson et al 2014 xin et al 2014 2015 and groundwater abstraction yu and michael 2019 stein et al 2019 however estimation of sgd by variable density simulation with a number of cross sections along coastlines can be rather tedious e g kreyns et al 2020 studies for large scale sgd estimation usually setup several base case of 2 d cross sections and then interpolate the results along coastlines luijendijk et al 2020 michael et al 2013 such method can effectively explain temporal dynamics of sgd along with point measurements by seepages meters duque et al 2020b while cross section methods cannot capture lateral re distribution of fluxes where rivers dissect the coastline zhang et al 2016 robinson et al 2018 alternatively sgd can be estimated separately as fresh and saline components since the amount fresh sgd is constrained by water budgets of coastal catchments saline sgd estimation has been extensively studied by isotopic tracer method such as radium isotopes moore 2003 1996 and then fresh sgd can be calculated from the water balance lee and kim 2007 douglas et al 2020 fresh sgd can also be estimated by modeling groundwater flow from catchment draining to the coast jarsjö et al 2008 developed a hydrologic model to estimate fresh sgd by separating surface runoff and groundwater recharge based on topography land cover vegetation and soil texture simulated flows from two swedish coastal catchments showed that 80 of the outflow to the ocean occurred as streamflow with the remaining 20 occurring as sgd along the coast however the spatial variability of fresh sgd is strongly dependent on coastline topography and the scale of variability introduced by streams and rivers destouni et al 2008 as well as geological heterogeneity russoniello et al 2013 michael et al 2016 such variability leads to large uncertainties in modeling surface runoff and groundwater discharge across space and time zhou et al 2018 further simplification on watershed geometry enables a reasonable estimation method of fresh sgd at the catchment level considering the water budget of a watershed if the watershed drains to a river gray in fig 1b we can assume no fresh sgd is created and the recharge eventually discharge to river which can be monitored sawyer et al 2016a if the watershed drains to coasts white in fig 1b neglecting surface runoff net imbalance between injection and withdrawal the net recharge groundwater should be equal to fresh sgd sawyer et al 2016a calculated continental scale water budgets for catchments draining to coasts and found that quantities of fresh sgd depend on both the geometry of drainage networks and climate knights et al 2017 applied this water budget method to estimate fresh groundwater discharge along the united states coastlines of great lakes zhou et al 2019 explored global scale fresh sgd using this water budget method and found that significant fresh sgd is exported along tropic coasts and tectonically active margins such water budget analyses essentially simplify groundwater processes to enable large scale and computationally efficient estimation of fresh sgd which can make use of abundant spatial and temporal data sets that provide the foundation for spatial dynamics understanding at catchment level zhou et al 2018 hajati et al 2019 developed a regional lumped transient water balance model to estimate fresh sgd of each catchment along the coast of java island the model demonstrated different seasonality of fresh sgd which is determined by aquifer and soil properties befus et al 2017 developed 3 d groundwater flow models for coastal regions of the eastern u s and gulf of mexico they found that for half of coastal catchments sgd included components that originated with recharge in catchments further inland due to cross watershed groundwater flow fig 1c this method can explicitly simulate fresh sgd contributions spatially due to heterogeneous subsurface properties but requires intensive geological data and parameterization at this point in time possibilities exist for the development of new methods for estimating sgd which further develop strengths of existing modeling approaches and minimize limitations zhou et al 2018 field oriented measurements of sgd demonstrated significant spatial and temporal heterogeneity seepage meters are the most common method providing point measurements at high temporal and high spatial resolution duque et al 2020b russoniello et al 2013 showed that fresh sgd varied spatially at both meter scales and 100 m scales due to natural geologic heterogeneity and the existence of paleovalleys montiel et al 2018 found that sgd in southern spain exhibited both strong seasonal variability and large spatial heterogeneity related to local hydrogeological settings in particular the extensive subsurface connectivity with fractures conduits and caves are potential hotspots of fresh sgd fleury et al 2007 xu et al 2016 modeled fresh sgd is often represented as a simple mean annual discharge value along a coast estimated by steady state simulations as a result many modeled fresh sgd results have been found to be less than field based estimates sawyer et al 2016a befus et al 2017 zhou et al 2018 current monitoring data of submarine groundwater discharge is rather limited in capturing the spatial patterns and complex temporal dynamics sawyer et al 2016b and point measurements may cause biased results due to observation time and locations moosdorf et al 2015 perhaps resolving hydrological processes in transient simulations can explain the discrepancy between modeled fresh sgd and field based estimates zhou et al 2018 conceptually fresh sgd within the coastal water cycle is primarily controlled by a variety of coupled surface subsurface hydrological processes befus et al 2017 fig 1c for example the amount of inland groundwater which outflows to the seabed i e fresh sgd is regulated by several hydrological processes such as recharge runoff at inland mountainous regions surface runoff is generated as horton overland flow horton 1945 dunne overland flow dunne and black 1970a 1970b or subsurface stormflow according to the hydrologic setting mirus and loague 2013 and antecedent conditions qu and duffy 2007 surface runoff flows to nearby surface water channels according to topographic gradients from ridges to valleys as determined by the terrain and geometry of the catchment land cover soil type and channel network some fraction of precipitation infiltrates soil zones with excess water flowing downward to recharge groundwater flow systems that eventually discharge in nearby rivers i e as streamflow or the seabed i e as fresh sgd these patterns of groundwater flow are determined by features of the hydrogeological setting e g karst conduits xu et al 2015 heterogeneity in hydraulic conductivity montiel et al 2018 the transient characteristics of coupled surface subsurface processes drive the exchange of water between groundwater and streams details of these interactions are important because they determine whether previously recharged groundwater drains into the stream as runoff or into the sea as fresh sgd along each coastline segment for this reason it is essential to include coupled surface subsurface hydrologic processes to characterize spatial and temporal dynamics of sgd at coastline segment level the main goal of this study is to reveal hotspots of fresh sgd at coastline segment level by a coupled surface subsurface model to this end we used a coupled surface subsurface hydrologic model driven by site specific data that for example include high resolution digital elevations land cover soil texture and features of the hydrogeological setting the model was calibrated and validated by available streamflow and evapotranspiration data and then the spatial variability of sgd estimations was compared against field based estimations at local level and global products at catchment level this study is an important step in identifying the hydrologic features that cause the apparent disparity between field and model based estimates of fresh sgd 2 materials and methods we used a coupled surface subsurface model at a mediterranean island fig 2 to explore how complexity in the climatologic and hydrogeologic settings naturally produce temporal and spatial variability in land surface hydrologic processes contributing to fresh sgd at the coastline segment level this section includes brief descriptions of the modeling approach application and analysis methods 2 1 modeling approach the computational approach involves a coupled surface subsurface hydrologic model penn state integrated hydrologic model pihm to perform the integrated simulation of surface subsurface hydrologic processes pihm kumar 2009 qu and duffy 2007 is a comprehensive hydrologic model that simulates water budget fluxes for interception throughfall infiltration recharge evapotranspiration overland flow unsaturated soil water processes groundwater flow and channel routing in a fully coupled manner evapotranspiration is calculated using the penman monteith approach adapted from noah lsm chen and dudhia 2001 overland flow is described in a simplified form of 2 d using st venant equations qu and duffy 2007 pihm uses a diffusive wave approximation for overland flow and streamflow the model conceptualizes the subsurface in terms of unsaturated and saturated layers fig 3d and assumes that flow in the unsaturated layer is one dimensional in the vertical direction recharge and 2 d in the layer of saturation groundwater flow recharge is calculated by richard s equation based on the difference of hydraulic heads between the unsaturated and saturated layers duffy 2004 groundwater flow is evaluated using a volume averaged version of darcy s law duffy 2004 interception and snowmelt are simulated with a bucket model and a temperature index model respectively horizontally the simulation domain is represented as unstructured delaunay triangles fig 3a the governing equation for each process is discretized on the triangles from canopy to bedrock forming partial differential equations pdes pihm incorporates a semi discrete finite volume formulation for solving the system of coupled pdes resulting in a system of ordinary differential equations odes representing all processes within each triangle the system of odes is solved using the cvode implicit solver cohen and hindmarsh 1996 in brief the pihm modeling approach provides a quasi 3d characterization of a watershed at each computational grid i e triangular prism state variables of surface water unsaturated storage and groundwater depth are solved according to lateral fluxes between each computational grid and vertical fluxes across ground surface and water table fig 3b in river channels the fluxes between river bank and river are calculated at both surface and subsurface layers fig 3c detailed descriptions of the modeling theory and mathematical formulation can be found in the associated publications kumar 2009 qu 2005 qu and duffy 2007 in this study a new seaside boundary condition adopted from zhang et al 2018 2019 in pihm wetland model was applied to simulate the surface and subsurface water exchange between fresh water from terrestrial landscapes and seawater from the ocean fig 3e this seaside boundary condition differs from the boundary conditions used in previous studies chen et al 2015 kumar et al 2013 liu and kumar 2016 shi et al 2013 yu et al 2015a 2019a 2019b yu et al 2015b zhang et al 2017a 2017b in which a no flow subsurface boundary condition along the coastline and critical depth surface flow boundary i e free fall over the weir at the outlet were applied specifically along the coastal boundary of the simulation domain surface runoff qsw m2 s is calculated based on the hydraulic gradient between the surface water height near the coast and the instant sea level namely 1 q sw s surf 5 3 s surf z h sea l n s t 1 2 where ssurf is the surface water depth m z is the land surface elevation m hsea is the instantaneous sea level m elevation on the boundary l is the distance between the center of the surface triangle to the ocean m ns is manning s roughness and t is the surface slope of the triangular element note that the mix of surface freshwater and saltwater and saltwater intrusion through surface infiltration during each tidal cycle is not simulated in this study due to 1 a focus on the large scale fresh sgd along the coastal aquifer and 2 an adequate capability of the subsurface head estimation in the subsurface our model simplified seawater intrusion processes as the pressure difference between the fresh water in the coastal aquifer and the saltwater from the ocean we assume i a dynamic sharp interface between the fresh and saltwater while ignoring the dispersion between the interface the blue dashed line in fig 3f and ii dupuit type horizontal flow gupta 1985 shamir and dagan 1971 ferguson and gleeson 2012 zhang et al 2018 this subsurface saltwater intrusion scheme has been widely used in saltwater intrusion studies with good predictive capabilities in understanding coastal subsurface freshwater and saltwater interaction e g shamir and dagan 1971 ferguson and gleeson 2012 zhang et al 2018 zhang et al 2019 according to zhang et al 2018 the following equations tracks the motion of the interface based on the conservation of the mass of freshwater and saltwater in coastal aquifer 2 q freshsgd k s sat s salt z b x 3 q salt k σ f s sat σ s s salt x where qfreshsgd and qsalt are the fresh groundwater flow m2 s respectively a positive value of the fluxes indicates a freshwater saltwater outflow from a model cell to adjacent cells or ocean boundary conversely a negative value means an inflow from adjacent cells or ocean boundary thus this form can dynamically track the fresh and salty groundwater flow at the land ocean interface ssat and ssalt are the groundwater and saltwater storage m respectively zb is the bedrock elevation m k is the hydraulic conductivity m day σf and σs are the density of fresh and salt water kg m3 respectively in this study σf 1 000 kg m3 and σs 1 027 5 kg m3 rodellas et al 2015 2 2 application and model setup the study area white mountains region wmr is located in the western portion of the island of crete in the mediterranean sea ms the wmr consists of the white mountains lefka ori and the surrounding coastal plains with an area of 1142 km2 fig 2 located at the western margin of the island of crete the fifth largest island in the ms our area of interest includes two e w oriented coastlines the north shoreline is 123 km long with a drainage area of 786 km2 the topography is characterized by steep mountain slopes with broad low lying flood plains connecting the shore and uplands the average slope is 17 degree the south shoreline is 36 km long with an associated drainage area of 356 km2 the topography across this area is mountainous with steep slopes averaging 27 degrees the wmr was selected because the region had been studied previously and there are basic data describing various features of the physical setting more importantly the presence of karst and differences in coastal geometry for the two study watersheds provide unique patterns of spatial and temporal variability in fresh sgd which highlight the need for coupled surface subsurface modeling approach more details of wmr are given in text s1 nikolaidis et al 2013 the model domain was discretized as an unstructured mesh of 7848 triangular prisms with each prism started from ground elevation to 20 m below river elements conform to edges of these triangular prisms fig 3 bhatt et al 2014 the various hydrologic processes incorporated in the model are illustrated in fig 3 we used topography land use soil and geologic data to parametrize each prism fig 4 table s2 output from the model facilitates the calculation of groundwater fluxes along the shoreline as fresh sgd surface runoff directly discharging into the ms at the shoreline is termed unmonitored runoff which was also calculated the initial condition for the transient simulation was obtained by spinning up the model with data from the two previous years 2005 7 1 2007 6 30 we began with a uniform water table depth of 10 m on 2005 7 1 and forced the model using the observed meteorological data text s1 the initial conditions provided a smooth water table surface from just below the land surface to 20 m the system proved to be so responsive that this period of spin up provided an appropriate set of initial conditions 2 3 calibration and validation pihm simulations were performed over a three year period 2007 7 1 2010 6 30 streamflow was calibrated using observed daily streamflow data at stylos spring fig 2b and modis remotely sensed et dataset mod16 running et al 2017 we calibrated two groups separately event and seasonal scale groups according to the method proposed by yu et al 2013 the event scale parameters were optimized using observed streamflow data from 2008 1 5 to 2008 3 4 a period in spring with largest flows the calibration was automatically achieved by the evolutionary method cma es hansen et al 2003 the seasonal scale parameters were adjusted based on et from 2007 7 1 to 2008 6 30 the simulation results for the last two years were used for validation we used the relative error e pearson product moment correlation coefficient r and nash sutcliffe coefficient of efficiency nse nash and sutcliffe 1970 to evaluate the model performance table s3 simulated 8 day average et running et al 2017 was in good agreement with modis data spatially fig 4a and b except in areas to northwest figure s3 average et from the simulation was 0 563 m yr which was comparable with the modis et value 0 589 m yr indicating reliable partitioning of the water budget fig 4c simulated streamflow results are shown in fig 4d the dynamics of streamflow variation between observed and modeled results were in reasonable agreement and were considered acceptable 2 4 fresh sgd comparisons we compared our fresh sgd estimates against model based fresh sgd at global scale zhou et al 2019 luijendijk et al 2020 and field estimated total sgd we focused on the spatial variability of fresh sgd between these estimates since large uncertainties may exist due to normalization of different methods moosdorf et al 2015 we used a simple method to estimate total sgd from pihm modeled fresh sgd using the relation prieto and destouni 2011 4 sg d total 1 1 s g d fresh 470 m 3 y r m 3 results 3 1 spatial patterns of fresh sgd the magnitude of fresh sgd along the modeled coastlines during the simulation period was 2 3 108 m3 yr amounting to 33 of modeled river discharge i e 6 9 108 m3 yr 14 of precipitation i e 1 6 109 m3 yr the average shore length of each modeling edge was 568 m we normalized fresh sgd to shore length and obtained 2 6 103 m3 yr m for all the coastlines the maximum fresh sgd was 1 34 105 m3 yr m while the minimum fresh sgd was only 2 4 m3 yr m fig 5 a previous study pnue pam plan bleu 2004 estimated fresh groundwater discharge from annual climate data and found that fresh groundwater discharge to ms was 46 of river discharge which was slightly higher than our methods where a much lower resolution and a rough estimation method were applied the spatial patterns of fresh sgd along both coastlines showed significant variability with the maxima in the vicinity of river mouths and locations of karst fault intersection with the coast spatial distributions of fresh sgd were plotted as a function of distance along the coast west to east for the north and south shorelines with reference to the most important discharge location of groundwater flow river alluvium and karst fig 5b and c the top 5 local maxima of fresh sgd fluxes along the north shoreline were 1 22 0 79 0 71 0 6 51 and 0 50 104 m3 yr m locations g1 g3 g4 and g5 were close to river mouths fig 5 locations g2 and g5 were at karst faults the top 5 local maxima of fresh sgd fluxes along the south shoreline were 13 1 3 20 1 46 1 26 and 1 25 104 m3 yr m locations g7 and g8 were close to river mouths fig 5 location g7 and g9 were at karst faults location g6 and g10 were close to small rivers fig 2b represented by topography long stretches of coastline in between are characterized by much lower fresh sgd most of them are below the average value 0 07 104 m3 yr m for the north shoreline and 0 77 104 m3 yr m for the south shoreline indicated by the black dashed lines in fig 5 fresh sgd near rivers r6 r8 r9 and r11 were below average these rivers had steep slopes near the mouths table 1 groundwater were forced to recharge to the rivers and leave the catchment as streamflow the water budgets of the north and south shorelines controlled the actual magnitudes of localized fresh sgd differently though locations of hotspots tended to be close to riverbeds in a similar pattern table 2 lists modeled water budgets for 2007 7 1 2010 6 30 of the north and south parts of wmr total water budgets suggested more precipitation more et and less fresh sgd in the northward draining watersheds normalized variable by drainage area northw and southw in table 2 suggested that less precipitation similar et and less fresh sgd in the north part normalized variable by coastline length northl and southl in table 2 suggested that fresh sgd to the south shoreline was more than one order magnitude higher than the north to the south 1 km of the shoreline on average drains 9 9 km2 whereas to the north 1 km of shoreline drains 6 3 km2 the hydraulic gradients along the south coastline are also on average greater than the gradients in the north coastline which results in larger magnitude of fresh sgd model results also indicated that unmonitored runoff i e surface runoff to the sea was negligible in wmr compared to river runoff 3 2 temporal dynamics of fresh sgd daily fresh sgd was affected by episodic precipitation fig 6 the response time are different between the north and south shorelines in the north part of the domain a maximum daily average rainfall rate 0 22 m d occurred on 2010 1 12 fig 6a the peak of fresh sgd occurred the following day i e the sgd response was delayed by only 1 d in the south a maximum daily average rainfall event of 0 42 m d took place on 2010 1 12 fig 6b the peak in fresh sgd occurred on 2010 1 31 i e with a response time of 19 d seasonal hydrologic conditions controled the hotspots of fresh sgd for the typical mediterranean climate 94 of the precipitation occurs during the wet season winter and spring along the north shoreline 98 9 of the annual fresh sgd was produced during the wet season whereas 91 3 of the annual fresh sgd was produced during the wet season along the south shoreline wet season showed most fresh sgd and the hotspots included both karst aquifers and flat riverbeds fig 7 while in dry season karst aquifers didn t generate high fresh sgd only flat riverbeds were still fresh sgd hotspots mean values of fresh sgd through space and time significantly reduced its variability the distributions or relative frequency of fresh sgd computed from daily time series from 2007 7 1 to 2010 6 30 at each computational unit were similar between the north shoreline and the south shoreline fig 7 a mean values through coastlines reduced the maximum fresh sgd of both shorelines and increased the minimum fresh sgd of north shoreline more significantly than the south shoreline fig 7b mean values through simulation periods also reduced the variability of fresh sgd and resulted different patterns between these two shorelines fig 7c 3 3 comparison of spatial variability with local estimates total sgd along the shorelines of our model domain ranged from 4 7 102 to 1 5 105 m3 yr m with a mean of 3 3 103 m3 yr m fig 9 previous local studies using radium isotopes methods estimated total sgd ranging from 4 102 to 3 7 105 m3 yr m where shoreline length ranged from 0 04 to 300 km burnett and dulaiova 2006 el gamal et al 2012 garcia solsona et al 2010a 2010b gattacceca et al 2011 mejías et al 2012 montiel et al 2018 moore 2006 ollivier et al 2008 pavlidou et al 2014 rapaglia et al 2010 2012 rodellas et al 2012 2014 stieglitz et al 2013 swarzenski et al 2006 taniguchi et al 2006 tovar sánchez et al 2014 weinstein et al 2007 point measurements by seepage meters indicated that total sgd ranged from to 2 1 102 to 3 0 105 m3 yr m fig 9 a basin wide estimation of total sgd along ms ranged from 6 103 to 1 105 m3 yr m rodellas et al 2015 thus our estimated total sgd was in good agreement with local studies conducted along the ms using 228ra mass balance methods and seepage meter measurements table 3 and 4 according to the range but was greatly lower according to the median fig 9 3 4 comparison of magnitude with catchment level estimates global estimation of fresh sgd has much coarser resolution with significantly reduced spatial variability comparing to our results both luijendijk et al 2020 and zhou et al 2019 estimated global fresh sgd distribution using coastal catchments as the computational unit for our study area the coastline lengths of each catchment was 5 7 km to 23 km in luijendijk et al 2020 and 1 2 km to 79 km fig 10 after summary at catchment scale the magnitudes of our estimation showed similar spatial distribution to global fresh sgd products table 2 4 discussions this study highlights the need to consider the fully coupled effects of hydrological processes in determining fresh sgd hotspots at the coastline segment level the spatial and temporal characteristics revealed by coupled surface subsurface processes are potentially useful in analyzing systems at scales up to continental by catchment water budgets and down to points measurements by seepage meters 4 1 spatiotemporal dynamics of fresh sgd the work presented here shows that significant fresh sgd flows at riverbeds after river floods the 10 hotspots g1 g10 fig 5 witnessed 38 of total fresh sgd along the coasts and 8 of them were close to riverbeds with 35 of total fresh sgd the temporal dynamics suggested that 92 of fresh sgd was in wet season such mechanism is reasonable since surface processes controls the recharges to surficial aquifers and then discharges to nearshore coasts responses of fresh sgd to different drive mechanisms have been revealed by cross sectional modeling studies xin et al 2014 2015 yu et al 2017 our simulated time lags between peaks of precipitation and fresh sgd ranges from 1 to 19 days which is comparable to previous results ranging from 3 to 41 days yu et al 2017 since we used constant sea level boundary condition our time lags may be underestimated without the effects of waves and tides xin et al 2014 2015 luckily it is more practical to install field measurements nearshore than offshore hotspots captured here can be validated by nearshore field installation along these coastlines though current field estimates fig 9 were not located in our study area we also note that in regional groundwater dominated systems temporal patterns may be less impacted by surface processes due to deep groundwater recharge from confined aquifers el gamal et al 2012 guo and li 2015 future work should address how to conceptualize subsurface aquifers for hydrologic models along karstic aquifers in highly tectonized and deformed rocks fresh sgd estimation studies should pay more attention on riverbeds our study shows that areas close to flat riverbeds and karst aquifers are potential fresh sgd hotspots it is not surprising that high fresh sgd flow at karst aquifers while fresh sgd around riverbeds is much dynamic revealed by two way coupled surface subsurface approach figure s4 text s2 spatial riverbed geometry has been overlooked in most global identification studies befus et al 2017 zhou et al 2018 sawyer et al 2016a luijendijk et al 2020 these global fresh sgd datasets show no difference between river mouth and rest of the coast figure s5 the mean values of fresh sgd along the coastline and at the riverbed showed no significant difference in majority of these continents table s4 our results highlight the importance of considering river flow dynamics when making global fresh sgd estimation across temporal and spatial scales both synthetic and site specific studies have also demonstrated that complex groundwater surface interaction increase groundwater discharge rate at coastal zones e g sawyer et al 2015 kolker et al 2013 glaser et al 2021 hydrological fluxes across riverbeds are complex due to both natural flow dynamics and human activities sawyer et al 2016b grill et al 2019 more field studies of fresh sgd around river mouths are encouraged across different climate and hydrogeological settings improved global fresh sgd estimation method is expected with consideration on the impact of flowing rivers since 63 of the world s rivers 1 000 km no longer free flowing grill et al 2019 4 2 from point measurements to coastline segments increase resolution of model based fresh sgd to coastline segments provides a promising opportunity to resolve the discrepancy between modeled and field based fresh sgd the coupled surface subsurface modeling method could estimate fresh sgd at the coastline segment scale our example showed fresh sgd at such high resolution i e 0 3 km to 1 km could capture the spatial variability of field observations and obtain similar magnitudes of fresh sgd fig 9 model based daily or even higher temporal resolution on fresh sgd can provide field work guide for seepages meters spatiotemporal continues fresh sgd estimation by coupled surface subsurface approach provides valuable information for monitoring plans of seepage meters duque et al 2020b combinations between seepage meters and coupled surface subsurface modeling methods may obtain an integrated understanding of interpolation between measurement events and reduce biased results due to selection on measurement locations and seasons moosdorf et al 2015 zhou et al 2018 4 3 from catchments to coastline segments fresh sgd reduces the spatial variability by averaging along the coastline both water budget method zhou et al 2019 and cross section interpolation method luijendijk et al 2020 estimated fresh sgd at variable spatial resolution due to geometry of coastal watersheds fig 10 comparison between two catchment level products showed relation between spatial resolution and variability of fresh sgd high spatial variability of fresh sgd was reduced due to summary at catchment level using the catchment scale fresh sgd as a constraint to obtain higher resolution at coastline segment level will lead more useful information for coastal management fresh sgd estimate at coastline segment level are more informative to understand how land use change impacts since land use types have a dominant control of chemical composition of sgd bishop et al 2015 watershed hydrologists has developed and applied coupled surface subsurface models at many inland watersheds e g chen et al 2015 yu et al 2015a cross sectional aquifers e g dai et al 2021b heiss et al 2015 yu et al 2016 and continental scales e g condon and maxwell 2015 sutanudjaja et al 2014 it is feasible to setup coupled hydrologic models along coastlines to reveal the spatial distribution and temporal responses at the coastline segment level 4 4 simplifications and limitations many other factors may affect the magnitude and timing of fresh sgd one major concern is the representation of subsurface a uniform 20 meter depth is not enough for this geological complex region moraetis et al 2010 the conceptualization of pihm is to integrate groundwater and unsaturated zone as two state for rainfall storage runoff processes in complex topography geology soil and climate variability duffy 1996 such assumption enables wide application of pihm since thickness from ground surface to bedrock is usually difficult to conceptualize in watershed models condon et al 2020 shi et al 2015 this one layer groundwater flow assumption ignores regional groundwater flow and may underestimate the fresh sgd befus et al 2017 moreover the geology complexity especially with the presence of unmapped faults or even large scale folds with preferential flow along fold hinges may have underestimated fresh sgd rates lilli et al 2020 and supplementary information therein as well as time lags for freshwater to transport from the recharge area to the sea nevertheless our findings showed contrasting spatial difference of fresh sgd distribution which should be careful addresses when we compare field based estimates with the results of water budget methods it is worth to investigate the impact of subsurface conceptualization rapp et al 2020 on fresh sgd estimation in future studies simplification of seaside boundary may introduce uncertainty in fresh sgd the assumption of sharp interface on the sea side boundary may underestimate saline sgd since density driven seawater circulation through heterogeneous aquifers can significantly enhance fresh saline groundwater mixing michael et al 2016 the mechanism has less impact on fresh sgd because the amount fresh discharge is constrained by the water budget sensitivity of streamflow and sgd to seaside boundary should be further studied e g pool et al 2011 the representation of karst was simplified to achieve operational parameterization additional field surveys are ongoing to improve performance of calibrated model parameters and understanding on karst conduits which is critical for this system e g bakalowicz 2015 lilli et al 2020 the improved model performance will affect the results of the estimated fresh sgd but it does not affect general conclusions on spatial and temporal dynamics of fresh sgd 5 conclusions this study describes a coupled surface subsurface modeling approach that was applied in the estimation of fresh sgd at coastline segment level the potential of this approach was demonstrated through an illustrative application in a mediterranean island what is particularly noteworthy is the hydrologic control provided by permeable karst and river mouth that potentially focuses groundwater discharge to discrete locations also the episodic characteristic of the discharge reflects near surface process control on the temporal dynamic of fresh sgd the spatial and temporal variability of fresh sgd should be carefully interpreted because the distributions are highly skewed to the authors knowledge the fresh sgd has not yet been investigated by coupled surface subsurface flow models at the watershed scale our modeling results suggested that surface water groundwater interaction cross riverbeds controls the spatial and temporal dynamics of fresh sgd at coastline segment level our illustration suggests a promising and cost effective method for modeling fresh sgd comparable to seepage meter results and to catchment water budget estimates credit authorship contribution statement xuan yu conceptualization methodology writing original draft zexuan xu conceptualization methodology daniel moraetis investigation data curation writing review editing nikolaos p nikolaidis supervision writing review editing frank w schwartz writing review editing yu zhang software writing review editing lele shu data curation christopher duffy supervision writing review editing bingjun liu writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement all data for this study can be obtained from the corresponding author yuxuan7 mail sysu edu cn the authors thank eliot atekwana from university of delaware for discussion and anonymous reviewers for their valuable comments on delineating the strength of the paper this work was initiated by the soiltrec soil transformations in european catchments european commission 7th framework programme as a large integrating project grant agreement no 244118 and the igcp 715 a new karst modelling approach along different tectonic contacts by unesco and iugs the authors acknowledge the national natural science foundation of china grant no 51879289 and no 91547108 the national key research and development program of china 2017yfc0405900 and the guangdong provincial department of science and technology 2019zt08g090 for supporting this work appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126356 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
4573,runoff and sediment yield predictions using rainfall runoff modeling systems play a significant role in developing sustainable rangeland and water resource management strategies to characterize the behavior and predictive uncertainty of the kineros2 physically based distributed hydrologic model we assessed model parameters importance at the event scale for small nested semi arid subwatersheds in southeastern arizona using the variogram analysis of response surfaces vars methodology a two pronged approach using time aggregate and time variant parameter importance analysis was adopted to improve understanding of the control and behavior of models the time aggregate analysis looks at several signature responses including runoff volume sediment yield peak runoff runoff duration time to peak lag time and recession duration to investigate the influence of parameter and input on the model predictions the time variant analysis looks at the dynamical influence of parameters on the simulation of flow and sediment rates at every simulation time step using the different forcing inputs this investigation was able to address simpson s paradox type issues where the analysis across the different objective functions and full data set vs its subsets i e different events and or time steps could yield inconsistent and potentially misleading results the results indicated the uncertainties in the flow responses are primarily due to the saturated hydraulic conductivity the manning s coefficient the soil capillary coefficient and the cohesion in sediment and flow related responses the level of influence of k2 parameters depends on the type of the model response surface the rainfall and the watershed size keywords walnut gulch kineros2 global sensitivity uncertainty parameter importance response surfaces vars rainfall intensity 1 introduction advanced hydrologic modeling tools play an important role in developing sustainable rangeland and water resource management systems including the implementation of real time flood forecast and warning systems creutin and borga 2003 kitanidis and bras 1980a 1980b and assessments of climate change adaptation strategies in the semiarid southwestern us the highly nonlinear nature of the rainfall runoff relationship yatheendradas et al 2008a 2008b goodrich et al 2000 1997 pilgrim et al 1988 makes it difficult to comprehensively understand the sources of modeling uncertainty in this region precipitation is extremely localized and summertime convective thunderstorms are exceptionally intense roeske et al 1989 keefer et al 2015 resulting in significant variability of watershed responses ranging from flash flood disasters https www weather gov hazstat to extreme droughts seager et al 2007 ipcc 2013 cook et al 2014 zhao and dai 2015 feng et al 2014 the application of hydrologic models requires analysis of outputs relevant to a given modeling objective for the evaluation of model performance the spatially distributed kineros2 kinematic runoff and erosion modeling system smith et al 1995a 1995b semmens et al 2005 is well suited to arid and semi arid watersheds goodrich et al 2012 providing a physically based representation of highly variable semiarid rainfall and of the consequent infiltration and runoff processes at high spatiotemporal resolution the kineros2 also referred to as k2 model has been widely applied to a number of watershed related problems across the world to understand processes in arid and semi arid landscapes these includes erosion and sediment load prediction smith et al 1995a 1995b silva et al 2007 elliot et al 2009 gupta et al 2018 for predicting runoff and flooding schaffner et al 2010 nedkov and burkhard 2012 broxton et al 2014 assessing impacts of urban and green infrastructure yang et al 2019 kennedy et al 2013 korgaonkar et al 2018 predicting the impacts of wildfire and changes in land use on hydrology tajbakhsh et al 2018 sidman et al 2015 etc it has also been part of several studies on evaluation of hydrologic model structure and uncertainties e g duru and hjelmfelt 1994 yatheendradas et al 2008 korgaonkar et al 2020 goodrich et al 1994 in this paper we assess the relative time aggregate and time variant importance of all the k2 parameters on watershed outputs as realistic as k2 and its representation of the hydrology of the southwest arid environment is its results can only be as good as the quality of the input and parameter estimates to explore how realistic the model results are we must understand the relative influence of uncertainties in forcing inputs initial conditions and model parameters on model output sensitivities to understand the relative influence of parameters on the dynamics of k2 model behavior in semi arid region we conducted a multi response based sensitivity analysis sa of k2 under different scenarios of input and modeling objective at a watershed scale similar to the extent of localized monsoon rainfall events in addition to helping elucidate the relative influence of each parameter in the model sa also helps the modeler to prepare for model parameterization and to direct research priorities by establishing which parameters contribute the most to uncertainty in the model response yatheendradas et al 2008a 2008b razavi and gupta 2015 wei et al 2007 saltelli and campolongo 2000 breshears et al 1992 this exercise can also aid in revealing if the processes in the watershed are correctly represented in the model as discussed in razavi and gupta 2015 2016a b several sa approaches such as the morris method morris 1991 campolongo et al 2007 sobol method sobol 1993 saltelli et al 2008 pawn method pianosi and wagener 2015 delsa method rakovec et al 2014 and moment based method dell oca et al 2017 etc can provide identical sensitivity rankings for situations having very different parameter sensitivity properties in this work we implemented the variogram analysis of response surfaces vars methodology razavi and gupta 2016a 2016b to assess the importance of k2 parameters and their dynamics with respect to different rainfall properties and size of contributing areas other time variant sensitivity analysis based on moris methods sobol methods and others eg wagener et al 2003 reusser et al 2011 reusser and zehe 2011 pianosi and wagener 2016 guse et al 2016 wang et al 2021 etc were applied in watersheds with continuous flow different drainage areas and provided valuable insights in understanding models the study was conducted on three small 0 34 4 6 ha lucky hills subwatersheds within the usda agricultural research service ars walnut gulch experimental watershed wgew arizona walnut gulch is also part of the long term agro ecosystems research ltar https ltar ars usda gov network this comprises a unique assessment of model parameter importance and an in depth look at the factors that influence parameter importance unlike other sa analysis tools vars accounts for the spatial correlation in model response as parameters are varied is more efficient cost effective and has been reported to provide more reliable stable estimates in the face of sampling variability gupta and razavi 2018 we compare the results of the vars method to that of the sobol sobol 1993 saltelli et al 2008 and morris morris 1991 campolongo et al 2007 methods which are included in the vars computations as by products under the global sensitivity analysis gsa framework where all the input factors were varied simultaneously we applied the vars tool over the entire range of the parameter spaces the analysis included investigation of the strength of influence of k2 parameters on 14 different types of model response surfaces generated from k2 simulation outputs forced by six different rainfall events the 14 response surfaces were derived from runoff and sediment yield outputs directly or by computing objective functions based on the model outputs the direct model output responses are categorized as performance metric free gupta and razavi 2018 and includes information derived from the model such as flow rate peak flow rate flow duration time to peak time to start of runoff recession time average sediment rate mass of sediment per unit time peak sediment rate and total sediment mass we also explored the influence of the parameters on selected performance metric based objective functions responses that represent goodness of model fit to the observations this includes the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 bias observation model prediction and kling gupta efficiency kge kling and gupta 2009 analysis of parameter importance using traditional approaches which usually involves goodness of fit responses surfaces as consistent and accurate indications of the sensitivity of model outputs to parameter perturbations is conceptually flawed gupta and razavi 2018 in this study we examined the hypothesis of independence between parameter importance and model forcing inputs in semi arid regions this work s novelty lies in implementing a time variant parameter importance analysis in semi arid systems using an event scale modeling approach on ephemeral headwater watersheds to understand what controls the physically distributed k2 model behaviors in relation to various response surfaces model outputs to various forcing input properties in addition our study provides insight into and that explains the internal model functioning time variant sa in an event based setting is novel as the previous works only covered continuous hydrologic models the event based simulation experiments on small watersheds with spatially uniform forcing input allowed us to understand model behavior and controls with respect to several modeling objectives as opposed to conventional parameter sensitivity analysis the majority of previous time variant parameter importance studies are on objective functions but here we also directly investigated the sensitivity of different model responses to parameters independent of observations to our knowledge this extensive analyses at this scope has not been undertaken in the past the study focuses on small nested watersheds where rainfall is assumed to be spatially uniform in large watersheds especially where catchment size is greater than the typical storms in semi arid region a comprehensive look at the impacts of spatial extent and storm location on model outputs is required the uniform rainfall assumption minimizes the impacts of temporal and spatial variability of semi arid rainfall on model behavior and control whose scope increases significantly with the watershed drainage area the work also included a comprehensive assessment of factors affecting parameter importance such as the purpose of the modeling activity and watershed size the objectives of this work were i to understand and learn model behavior control of multi response surface based assessment of semi arid systems using a metric free gsa methodology in the context of time aggregate and time variant model responses and ii to evaluate the impacts of rainfall properties with high temporal variability on the relative importance of model parameters in semi arid watersheds the latter included the effects of rainfall perturbation on parameter importance and the nature of the impacts of extreme events the event driven modeling capabilities of k2 at a high temporal resolution 1 min for semi arid ephemeral headwater processes provided a unique opportunity to answer questions related to the sources of model uncertainties due to forcing input parameters watershed size and modeling objectives 2 data and methods 2 1 study site the study was conducted in the lucky hills subwatersheds within the wgew fig 1 lucky hills is a very small 4 6 ha set of nested experimental watersheds within wgew four watershed areas were used in the study including the largest watershed lh 104 subwatersheds lh 106 and lh 102 with contributing areas of 0 34 ha and 1 3 ha respectively and the intervening area represented by the contributing area below stations lh 102 and lh 106 in fig 1 of 2 9 ha lucky hills has elevations ranging between 1354 and 1374 masl and surface slopes averaging 6 7 mean annual temperature is 17 6 deg c with a mean annual rainfall of 324 mm soils in the study watersheds are sandy loam ustochreptic calciorthid with a shrub dominated cover e g king et al 2008 skirvin et al 2008 lucky hills has been densely instrumented since 1961 canfield and goodrich 2003 and was part of the global change and terrestrial ecosystems soil erosion network gcte sen ritchie et al 2005 currently runoff is measured with two supercritical santa rita flumes and one h flume stone et al 2008 runoff instrumentation is located at the outlets of the largest watershed and the two subwatersheds two weighing type recording rain gauges with a precision of 0 25 mm and 1 minute time step after the year 2000 are used to measure rainfall data required for k2 modeling of lucky hills are curated and accessed through the southwest watershed research center data access project swrc dap database usda ars nichols and anson 2008 2 2 rainfall data data from six runoff producing rainfall events were selected for the analysis event data were selected from summer rainfall with a dry initial condition defined as a minimum of 24 h without rain for which the observed pre storm moisture content values showed 6 7 vmc the hyetograph and hydrographs of the selected events are illustrated in fig 2 the hyetographs in fig 2a consist of the average of event rainfall records from two the rain gauges rg83 and rg384 fig 1 which are about 250 m apart at 1 minute time steps the recordings from both rain gauges were correlated at 0 94 0 98 with a total mean difference of less than 0 4 mm for all selected events these data are also included in the swrc dap database https www tucson ars ag gov dap nichols and anson 2008 2 3 modeling using k2 k2 semmens et al 2005 www tucson ars ag gov agwa kineros is an event based physically distributed model developed to simulate runoff and sediment discharge in southwestern arid environments k2 simulates entire hydrographs and sedigraphs for a single rainfall event goodrich et al 2012 at sub hourly time steps k2 conceptualizes watersheds as a collection of spatially distributed rectangular overland flow model elements planar or curvilinear in such a way that hydrologically distinct portions of the watershed such as soil slope impervious area etc can be represented the model simulates interception and the dynamics of infiltration and infiltration excess runoff the infiltration component uses the parlange three parameter model parlange et al 1982 smith and parlange 1978 which is applied on a surface that can exhibit micro topographic variation goodrich et al 2012 and log normally distributed saturated hydraulic conductivity values smith and goodrich 2000 flow routing is based on a finite difference solution of the one dimensional kinematic wave equations woolhiser et al 1990 over a cascade of overland flow model elements and channels the erosion and or deposition component is computed based on raindrop energy splash erosion hydraulic erosion and transport capacity and considers multiple particle size classes e g semmens et al 2008 the automated geospatial watershed assessment tool agwa miller et al 2007 www tucson ars ag gov agwa was used for initial parameterization and execution of the model in this study we investigated seven of the model parameters affecting infiltration and runoff including the saturated hydraulic conductivity ksat manning s roughness coefficient n the coefficient of variability of ksat cv the capillary drive coefficient g intercepted depth in hydraulic erosion coefficient c and sediment splash coefficient s we limited the number of parameters to seven treating the channel and contributing areas with the same multipliers the channel parameters were not treated separately because of the shortness and small size of the channels and very limited channel transmission losses goodrich et al 1997 feasible initial estimates for the k2 parameter values table 1 were obtained through agwa parametrization using gis data layers such as a 1 m dem ssurgo soils and nlcd land use for walnut gulch see table 1 for agwa based database parameter range considering the dry antecedent conditions the initial soil moisture values were set constant to 0 2 for all events the initial parameter values for each element were scaled up and down by global multipliers that ranged from 0 to 2 2 4 model responses in this study ensembles of response surfaces were generated by running the model using parameter sets created by applying random multiplier values to each parameter response surfaces are either direct model outputs or transformations of the outputs to information necessary for a particular modeling objective e g peak flow rate for each randomly generated parameter set we used two time series response surfaces the simulated runoff and sediment rates and 14 computed response surfaces each summarizing the simulation period see table 2 to evaluate the relative importance of the k2 parameters eleven of the response surfaces in table 2 are performance metric free responses which were extracted from the model outputs regardless of observation data the remaining three are performance metric based responses which are measures of the closeness between the model output and the observations we included only performance metric free response surfaces for sediment to limit the scope of the study in the evaluation of the strengths and weaknesses of gsa using time aggregate and time variant responses in addition to the understanding and accurate representation of watershed processes these response surfaces could be used to represent several engineering and management aspects of hydrologic studies such as flood forecasting accuracies lead time to flood early warning systems watershed and water resource management reservoir filling and emptying strategies etc 2 5 vars indices the vars framework razavi and gupta 2016a b enables robust and efficient global sensitivity testing of model responses based on the latin hypercube and a star based sampling strategy known as star vars e g razavi and gupta 2016b star sampling consists vertices star centers that define subsets of the parameter space 10 of the parameter ranges used in this study from which parameters are randomly sampled across the full range of parameter space these randomly generated sets of parameters were used to run the hydrologic model and generate the response surfaces from the model outputs the response surfaces could be time variant y t or time aggregated a single value y for each simulation the vars global sensitivity of a response surface y with respect to a model parameter θ is computed by its variogram γ h and covariogram c h functions 1 γ h 1 2 v y θ h y θ 2 c h 1 2 cov y θ h y θ where h θ a θ b is the length vector h h i h n between any two points a and b in the parameter factor space at locations θ a a n d θ b directional variograms γ h and covariograms c h provide sensitivity information computed at each time step of the simulation period in the time variant analysis y varies with simulation time or an aggregate value in the time aggregate sensitivity analysis these variogram based sensitivity indices are also integrated to provide integrated summary indices or ivars integrated variogram across a range of scales for particular scale range of the ith factor h i 3 γ h i 0 h i γ h i d h i in this analysis we reported the computed ivars values as the parameter importance sensitivity index values specifically we used the ivars50 h 50 factor range values which is the most comprehensive vars based global sensitivity index as it captures the full range of parameter perturbation range razavi et al 2019 for the details of the theoretical and mathematical formulation of vars methodology readers are referred to razavi and gupta 2015 and razavi and gupta 2016a b because of the close theoretical connection between vars directional variograms as h i 0 and the expected value of the square of the ratios of changes in output to changes in inputs vars sa is closely associated to the morris based sa similarly the variogram and covariogram functions are closely related to the total order effect sobol variance based sa as h i becomes large because of this close relationship between vars and the morris and sobol methods the vars methodology provides reliable estimates of the sobol and morris sensitivity rankings as by products at no extra computational expense razavi and gupta 2016a 4a s k i y θ 1 1 k y θ 1 npts k y θ n 1 k y θ n npts k 4b s i k t y t θ 1 1 k y t θ 1 npts k y t θ n 1 k y t θ n npts k in this analysis we first randomly generated sets of the k2 parameter multipliers using progressive latin hypercube and star sampling strategies razavi et al 2019 to extract sensitivity information across the full extent of the parameter space θ 1 θ n pts second we ran k2 for each set of parameters θ n and for each of the six selected rainfall events we then extracted two time variant response surfaces y t θ flow rate and sediment rate and the 14 computed responses represented by y θ as time aggregate simulation outputs for each watershed and for each rainfall event the time aggregate parameter sensitivity indices s i k that are usually the ivars50 were computed equation 4a for each parameter and the 14 response surfaces representing parameter importance cross the entire simulation third we applied the vars procedure to build and analyze the dynamic time variant global sensitivity matrix gsm equation 4b where the sensitivity indices were computed for each parameter θ i i 1 n across the parameter space 1 n pts for each of the simulation periods t 0 t here the sensitivity indices for each parameter s i k are computed at every time step as s i t k over the simulation period representing the time variant analysis where k i and t represent the different response surfaces sediment rates and flow rates k2 model parameters θ and the simulation time respectively further the results of these model runs were used to generate the sensitivity indices of the 14 computed responses to the parameters we also calibrated k2 independent of the vars framework based on the model response surfaces model outputs and the available observations sedigraphs and hydrographs of each event using standard hydrologic goodness of fit indices such as nash efficiency nse kling gupta efficiency keg pearson correlation r root mean square errors rmse and bias without application of optimization algorithms we then selected parameter sets that provided best goodness of fit as discussed earlier the relative parameter importance for the overall simulation s i k time aggregate and at each simulation time step time variant as s i t k is computed via directional variograms γ h covariograms c h and ivars γ h i then the uncertainties in the sensitivity indices generated for each of the response surfaces spaces were evaluated using the bootstrapping technique described in efron 1979 razavi and gupta 2016b sheikholeslami et al 2018 the time variant metric or time series of parameter importance metric at every simulation time step are computed for each of the time variant response surfaces it comprises useful information for understanding model process representations the effects of variability in system inputs and parameter controls corresponding to the simulation period for details of the analysis on the dynamic time variant vars algorithm readers are encouraged to see gupta and razavi 2018 the time aggregate metric shows the summary sensitivity metric at every simulation time step eq 4 or the relative measure of the computed metric normalized by the sum of all the parameter sensitivity indices eq 5 it is calculated for each time aggregate response surface and time variant response surfaces as an average metric representing the overall simulation period the time aggregate analysis supports conventional parameterization approaches during model calibration here we present the analysis and interpretation of both conventional aggregate output response surfaces and the dynamic time variant vars outputs the interpretations are based on values of the ivars γ h and also of the percent sensitivity across the h distance vectors where the latter is defined as the value of γ h i for each parameter divided by the sum of γ h i for all the parameters multiplied by 100 5 s k i s k i i 1 n θ s k i 100 relative sensitivity is normalized by the sum of the sensitivity indices of all the parameters sensitivity for each time step 6 s i k t s i k t i 1 n s i k t log sensitivity 7 l o g s i k t log 10 s i k t to derive error weighted sensitivity indices the product of mean square error mse and the sensitivity indices across all time steps and parameter sets n pts was used the mse at a time step provides an insight into the model response to dynamic changes in the parameter values as a measure of the variance of the response surfaces and its bias w r t observations z t weighting the sensitivity indices by mse at any given time shows the relative sensitivity when the time variant model response would be significant relative to simulation duration 7 s i k t m s e t 1 n pts t 1 i n pts z t k y t θ i k 2 s i k t 3 results and discussion 3 1 time aggregate gsa in fig 3 we show the relative importance of each of the k2 parameters to each of the responses along with 90 confidence intervals of the parameter space clearly the degree of importance of each parameter depends on the type of the response investigated further we find a significant difference in the level and type of parameter importance for the different categories of performance based and performance metrics free responses the time related model outputs column 2 fig 3 such as the time leading up to runoff generation the time to peak and the lag time are affected by all of the flow related parameters this is expected because these responses occur over a small part of the simulation period in other flow related responses including flow duration the number of important parameters decreases to three parameters and four in sediment related outputs in general this exercise showed that the saturated hydraulic conductivity ksat manning s coefficient n the capillary coefficient g and the hydraulic erosion coefficient c play the most significant roles in the model response for the flow time component responses such as duration time to peak lag time and recession time manning s coefficient n appears to be the most dominant parameter when using the bias nse and kge performance metrics the saturated hydraulic conductivity was found to be most important with the g value and n also having a significant impact in the performance metric free flow rate related responses the manning s coefficient is the most important parameter though less so for peak flow rate when examining the performance metric free sediment yield related responses the hydraulic conductivity soil surface roughness and hydraulic erosion coefficient play a significant role fig 3 also shows that the ranges of the 90 confidence uncertainty intervals vary from one response to another with the full vars trial of 100 samples for each parameter the narrow confidence bands of some responses such as bias and kge provide evidence for robustness against sampling variability it is evident that the level of robustness also varies by parameter even for the same response see flow duration maximum sediment rate etc clearly parameter importance can depend on the type of metric and the response investigated as illustrated by fig 4 where the parameter rankings vary significantly except for the sediment related responses in the latter the rankings do not change but the magnitude of sensitivity shows noticeable change one sees the same for the two performance based metrics bias and kge the difference in the percent sensitivity values and the ranking between duration and recession time were comparable for the dominant parameters with little variation in the two insensitive parameters cv of ksat and the intercepted depth this small variation is attributable to the similarity between the flow duration and the recession time the flow duration minus the time to peak which is very small in the southwest arid environment because of the more typical short rainfall durations the analysis also reveals significant variability in the sensitivity of flow rate and sediment responses the variability is minimal in the responses time to peak lag time and time to start which share two properties in common 1 all the parameters play a significant role and 2 the range of time over which these responses are active is very small from an application perspective this exercise illustrates that parameter optimization should take advantage of the knowledge of which parameters are more important for what types of model outputs associated with the modeling objective in almost all applications ksat n and g parameters for flow and c for sediment can be assumed to be important in the time related response surfaces except in time to start the parameter n showed dominance compared to other parameters the importance of intercepted depth in in the sparsely vegetated southwest remains minimal in the k2 application for small headwater watersheds this was true for response surfaces such as the maximum flow time to peak lag time and start time which occur in the early stage of the simulation period the minimum in importance is attributed to the sparse vegetation cover and the type of vegetation grasses and shrubs in the semi arid southwest in the case of areas with a significant vegetation cover as noted in langbein and schumm 1958 the influence of in on runoff and erosion cannot be ignored in the sediment response surfaces n was also the dominant parameter with the second dominant parameter being the hydraulic erosion coefficient c in general the importance of ksat was apparent in the performance metric free response surfaces the variability in the sensitivity across the different types of model response surfaces reflects the inconsistencies between modeling objectives the use of conventional approaches to identify parameter importance without considering the modeling objective may lead to potentially misleading results 3 2 time variant gsa analysis for different model responses response surfaces in the time variant gsa the integrated sensitivity metrics for flow rate and sediment rate were calculated for each simulation time step 1 min and parameter values across the entire space fig 5 shows the relative sensitivity indices of k2 parameters to simulated flow rate during the event on sept 12 2013 on lh 104 the top panel fig 5a shows the rainfall rate average of two rain gauges observed streamflow and the range of simulated runoff fig 5b presents the percent sensitivity index which was computed by normalizing each index by the sum of the integrated sensitivity indices from all of the parameters for each time step the percent sensitivity provides a very intuitive sense of parameter importance at any given time but fails to show the time at which a given parameter is more important the logarithmic transformed sensitivity index fig 5c shows the time varying sensitivity which differ from each other in several orders of magnitude the metrics in fig 5b and 5c can be used to understand the relative importance of all the parameters during each event simulated by the model fig 5d plots the integrated sensitivity index showing when the variance and bias of the response surface was the strongest during the simulation this index mainly highlights the time when most of the infiltration and routing processes are active the effect of less important parameters and rainfall beyond 60 min is shown to be very insignificant in fig 5e the sensitivity index is a product of the integrated index and mse mean square error it illustrates a shorter time window where the sensitivity and uncertainty of the processes is the strongest the metrics in 5d and 5e for event based modeling exercises that include parameter identification and calibration illustrate the high likelihood of obtaining parameter values that create a good fit in the short window of time when the parameters are active the metrics in 5d and 5e can also be used to compare parameter importance during different rainfall inputs each index fig 5b e has its own strengths and limitations in the information they provide to modelers in regards to not only the most important parameters but also when they are important for example fig 5e showed a narrower time of strong parameter importance by incorporating time where the large deviation from the observations occurred this index minimizes the effects of dynamics in the rising and recession tails of the hydrograph with very small sensitivity values fig 6 plots the observed hyetograph hydrograph and sedigraph fig 6a and the corresponding sensitivity indices of the simulated runoff fig 6b and sediment yield fig 6c to parameters for lh 104 from the event of july 25 2010 in both 6b and 6c the time varying changes in parameter importance illustrate the integrated effects of the model algorithms and drivers rainfall surface topography soil and land cover properties the importance increases with rainfall intensity and decreases as rainfall subsides however the importance of the parameters does not go to zero even after the rainfall has stopped the four pie charts in subplots 6b and 6c show the importance of each parameter in percent the relative importance of ksat red seems to increase over time for flow rate while the relative importance of manning s n green decreases then increases over time and the capillary drive coefficient black decreases over time in the simulated sediment yield fig 6c most trajectories of parameter importance showed variation across the simulation period though ksat red exhibited the same increasing trajectory as for flow rate the routing parameter n is the dominant parameter in both runoff and sediment response surfaces during active runoff generation processes the two large pie charts in fig 6b and 6c represent relative time aggregate parameter importance values that show significant differences from the dynamic values across the simulation time steps 3 3 effects of rainfall intensity and watershed size on parameter importance we compared the impacts of rainfall in terms of depth intensity and duration on the parameter importance analysis the sensitivity indices computed for each of the k2 parameters for all the storms fig 2a were compared fig 7 a e across each simulation period the sensitivity index time series were in direct responses to the period when intense rain and runoff generation occurred in the watershed the level of parameter importance varies with the rainfall inputs fig 7 the sensitivity differs significantly between the parameters as evidenced by the scales of the y axis fig 7 and by the comparisons discussed in figs 5 and 6 the magnitude of the sensitivity indices at a given time is a function of the prior rainfall and current rainfall rate which demonstrates the importance of the rainfall rate distribution this makes a direct comparison between the different rainfall inputs very difficult because of the substantial variation in model response over time which depends not only on the amount but also the distribution of the rainfall a direct time series comparison such as fig 7 requires caution however in order to compare the impact of the rainfall on parameter importance we aggregated the parameter importance indices of each of the events as averages over the simulations fig 8 compares the aggregate sensitivity indices in response to the different rainfall inputs for the different subwatersheds of lucky hills as a function of contributing area the aggregated log transformed summary sensitivity index for each of the parameters shows variations as a function of watershed size and the rainfall depth we considered four sizes of contributing area the two internal gauging stations at lh 106 and lh 102 the outlet at lh 104 and the intervening area between the internal gauging stations and the outlet the level of parameter importance increased with increasing rainfall intensity and depth parameter importance also showed a steady increase with size fig 8 the effects of watershed size on parameter importance analysis are limited to small hillslope scale sizes for which the spatial uniformity assumption holds in the semi arid environment storms with high spatial variability of rainfall located on a smaller portion of the watershed can cause runoff while other part of the watershed received no rain are relatively common syed et al 2002 the analysis in relatively larger watershed sizes requires a broader scope because of the immense variability of rainfall in space and time making the relationship between watershed processes and the rainfall more complicated for the most part the importance of all k2 parameters increased with total rainfall depths the ranking of parameter importance by event across all sizes from most important to least important was consistently events 6 4 5 3 and 2 this shows that parameter importance variation is dependent on not only the depth of rainfall but also the combined effects of both rainfall intensity and depth event 1 07 14 2014 with the least intense rainfall and minimal generated runoff showed a clear difference from the rest of the events these analyses provide not only the dynamics and extents of parameter importance but also assist in explaning inconsistencies in the time aggregate sa relative to the modeling objective in order to compare the temporal patterns of sensitivity response to rainfall intensities we perturbed scaled up and down event 2 which has a symmetrical distribution before and after the peak see the hyetograph of fig 2 id 2 we used scaling factors of 0 5 0 6 0 7 0 8 0 9 1 1 1 2 1 3 1 4 1 5 2 3 4 and 5 see the ensembles of the scaled rainfall intensities in fig 9 c for analysis of the sensitivity of the model parameters the use of similar rainfall distributions and durations in this exercise shows the influence of rainfall depth intensity on parameter importance at any given time during the simulation period the symmetrical scaling of the input rainfall resulted in corresponding impacts on parameter importance at a given time example of the impacts of increasing rainfall intensities that resulted in corresponding changes in the magnitudes of the parameter importance indices is illustrated in fig 9a and the period duration of significant parameter influence also increased to the left and right in response to a longer duration flow with increased rainfall depth and intensity similarly the scaled down rainfall resulted in reduced sensitivity and a shorter duration of parameter influence it is also important to note the small sensitivity values of in and cv across all ranges of rainfall indicating their inconsequential effect in the calibration and validation processes the sensitivity values of in and cv are an order of magnitude less than the sensitivity of other k2 parameters in fig 9b we plotted the changes in parameter importance to the changes in scaling factors which shows a power function relationship between the change in sensitivity of n manning s coefficient and the change in rainfall the ksat the capillary coefficient g and the interception coefficient in showed a linear relationship for small rainfall changes but became unresponsive as the rainfall scaling increased these changes in the way parameters control the hydrologic processes reveals how the dominant processes were altered with substantial changes in rainfall input this exercise demonstrates that in arid climates with very intense rain and especially extreme events resulting from current trends of climate change the role of parameters controlling the catchment hydrologic response diminishes while the routing parameters hydraulic control mannings n become more dominant see fig 9b the importance of other k2 parameters showed a decreasing trend as the rainfall intensities increased twofold the changes in sensitivity indices due to smaller changes in rainfall see the first 50 fig 9c reflected an almost linear relationship between the change in precipitation intensity and the difference in the magnitude of parameter importance 3 4 implications for model parametrization once the parameter importance investigations were conducted we applied the resulting sensitivity outputs to the model parametrization strategy and tested the advantage of only using the most sensitive parameters in model calibration in the calibration of all 7 seven parameter multipliers we used a total of 6400 monte carlo simulations generated using the progressive latin hypercube framework plhs sheikholeslami and razavi 2017 to optimize each parameter with respect to observations based on widely used goodness of fit metrics in fig 10 we compare the resulting calibrated model performance for various numbers of monte carlo simulations 1300 20 3 1700 26 5 2200 34 3 2900 34 3 3700 57 8 and 6400 100 using only the four most critical k2 parameters the comparison of the cumulative calibrated runoff and sediment rates fig 10a using only four of the k2 parameters compared to the model calibrated for the full range of parameters showed very little to no gain with the full calibration using sediment and flow rate model outputs the box plot fig 10b showed that the identified parameter ranges were consistent and within the acceptable range for the study sites this demonstrates that the vars procedure is more comprehensive and robust for parameter screening and model calibrations parameter sensitivity analysis has been widely and successfully used for parameter screening in model calibration e g morris 1991 campolongo et al 2000 bárdossy 2007 and makler pick et al 2011 in fig 11 the performance of the models calibrated using the four most sensitive parameters illustrate the efficiency robustness and effectiveness of vars e g gupta and razavi 2018 sheikholeslami et al 2018 the very small coefficient close to zero of the linear fit line blue and r2 close to zero indicated that there was very little difference between using a subset versus the entire set of monte carlo simulationswith the four most sensitive parameters for calibration even the smallest sets of monte carlo simulations showed very comparable performance to the fully calibrated model showing the robustness and efficiency of vars parameter importance analysis and the embedded parameter sampling strategy in addition to demonstrating the advantage of using only the most sensitive parameters the approach significantly reduces the time and computing resource requirements in large simulation exercises as this method produces equivalent model performance with a smaller subset of monte carlo simulations 4 conclusions in this paper we explored the dynamics of earth systems model behavior through application of general sensitivity analysis gsa using various forms of model responses under different conditions that influence the event based watershed responses the conventional approaches in global parameter importance analysis which usually use performance metric response surfaces in dynamical environmental systems offer an incomplete explanation of factors controlling model behavior gupta and razavi 2018 argued that these approaches be termed as parameter identifiability analyses rather than the parameter importance problem to fully understand the dynamics of model behavior within the k2 model structure we used the new time variant gsa analysis i e vars and evaluation of different response surface scenarios that provide additional interpretable information from model outputs the relative importance of each k2 parameter identified using the vars methodology was found to be intuitively consistent with the type of response investigated the study revealed that the magnitude and rank of parameter importance varies depending on the type of model response surface usually defined by the modeling objective and the rainfall intensities in flow rate and sediment related response surfaces the vars sensitivity indices exhibited considerable variability among k2 parameters with ksat n and g parameters showing the dominant impact in contrast the time based response surfaces especially the time to peak and start time showed minimum variation with all parameters of noticeable importance this illustrates that in model calibration and model parameter identification exercises it is important to consider which behaviors are the most important type for the modeling objective in question parameter importance analysis using the spectrum of model response surfaces used in this study provided additional useful insights as to what factors are important for affecting model behavior those explanations and characterizations related to model behavior controls and systems functioning response revealed in this study could not have been undertaken without a detailed took at time variant sensitivity comparisons of parameters of events based models on different response surfaces under varying forcing inputs in general the coefficient of variation of the conductivity cv the interception in and splash s parameters are the least sensitive parameters in k2 with an insignificant level of importance in this study comparison of the variance based total order sobol to and derivative based morris sensitivity indices showed identical ranking to the vars indices however there were differences in the relative importance between the parameters as given by the magnitudes of vars indices this is in line with the reporting by razavi and gupta 2016a and razavi and gupta 2016b in the detailed comparison of vars and the two sensitivity analyses tools providing significant insights in the strengths and limitations of those methods razavi and gupta 2015 also mentioned the different sa methods might lead to different results as they use fundamentally different philosophies and equations the time variant approach which illustrates when in time the model parameters control the hydrologic processes and how inputs influence the model outputs is not only different from the time aggregate analysis but also provides additional insight into why when physically based models do not perform as well as expected the time variant gsa produced the relative parameter importance and ranking that are robust leading to a better understanding of model behaviors the vars approach also showed significant flexibility in applying and evaluating the impacts of a range of input forcings on model behaviors and functions represented by the different response surfaces evaluation of other time variant gsa methods using theoretical models showed effectiveness and superior perfornce of vars methodology e g becker 2020 puy et al 2020 but comparison under different hydrologic scenarios and models requires extensive research the variation in the relative importance is affected by the rainfall input and continues to the end of the simulation the relative importance of the parameters also varies with the distribution of the rainfall intensity understanding and interpreting parameter importance during the simulation requires the choice of a sensitivity metric that best suits a given interest the application of time variant sensitivity analysis for understanding model behaviors can be expanded to a continuous models which are usually characterized by significant rainfall variability over the simulation period and area conducting a time variant sensitivity analysis for a response surface of interest provides a structured approach to untangle the dynamic influence of parameters on the simulation of flow and sediment rates of a given event the differences between analysis of the continuous model vs its subsets i e different events and or time steps are significant which can be explained by simpson s paradox the use of time aggregate sa accompanied by time variant sa accounts for the dynamics and the inconsistencies in the various sa outputs comparison of parameter importance during simulations with different rainfall intensities is difficult because of the sensitivity of the parameters to the temproral rainfall distribution parameter importance varies during the simulation as a function of prior rainfall input and the rainfall at present additionally high quality high temporal resolution observations as used in this case study are not widely available and are typically applied on larger scale watersheds where the assumption of spatially uniform forcing used here is problematic across lareger areas the high spatial heterogeneity of rainfall resulting from compact air masses s further complicates the model behavior controls in watersheds larger than the localized convective semi arid rainfall rainfall variability becomes so significant that it requires a more in depth look at its influence from the parameter importance point of view and its complex effect interms of spatial variability in activating hydrologic processes based on the spatial distibution of the rainfall the complexity can also increase with respect to parameter spatial consistency and identifiability problems consequently the time variant sensitivity and importance is not widely tested or characterized under different scenarios and modeling structures revealing potential weaknesses in physical models more broadly this reveals the limitations of our current observation networks in the understanding and representation of physical processes and parameters within our models and offers opportunities to explore unexplained uncertainty and poor performance of physically based models like kineros2 parameter sensitivity analysis with perturbed rainfall intensities can be viewed in one sense as a way of looking into impacts of climate change inputs resulting in the likelihood of future flood events for example the ever increasing influence of manning s coefficient fig 10 on watershed response with increasing rainfall when the importance of parameters related to infiltration storage and abstraction decreased or did not change with exceptionally high rainfall see fig 10 indicates the shift in the dominance of sets of parameters with the extent of rainfall inputs fixing insensitive parameters and calibrating the most important parameters in k2 for arid regions proved to be an excellent strategy by reducing the time and computing resources needed when a large number of monte carlo simulations are used credit authorship contribution statement menberu b meles conceptualization methodology visualization investigation software writing review editing dave c goodrich methodology writing review editing hoshin v gupta methodology software writing review editing i shea burns software writing review editing carl l unkrich software writing review editing saman razavi software writing review editing d phillip guertin writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments funding and support were provided by the u s department of agriculture ars and a contribution from the long term agroecosystem research ltar network thanks to the many dedicated usda ars southwest watershed research center staff in tombstone and tucson arizona who made possible the collection of high quality rainfall and runoff records in wgew the vision and commitment of all ars scientists and administrators to construct manage and operate the experimental walnut gulch watershed for the long term are to be commended the data used in this study are available in dap databased https www tucson ars ag gov dap the authors declared no conflict of interest 
4573,runoff and sediment yield predictions using rainfall runoff modeling systems play a significant role in developing sustainable rangeland and water resource management strategies to characterize the behavior and predictive uncertainty of the kineros2 physically based distributed hydrologic model we assessed model parameters importance at the event scale for small nested semi arid subwatersheds in southeastern arizona using the variogram analysis of response surfaces vars methodology a two pronged approach using time aggregate and time variant parameter importance analysis was adopted to improve understanding of the control and behavior of models the time aggregate analysis looks at several signature responses including runoff volume sediment yield peak runoff runoff duration time to peak lag time and recession duration to investigate the influence of parameter and input on the model predictions the time variant analysis looks at the dynamical influence of parameters on the simulation of flow and sediment rates at every simulation time step using the different forcing inputs this investigation was able to address simpson s paradox type issues where the analysis across the different objective functions and full data set vs its subsets i e different events and or time steps could yield inconsistent and potentially misleading results the results indicated the uncertainties in the flow responses are primarily due to the saturated hydraulic conductivity the manning s coefficient the soil capillary coefficient and the cohesion in sediment and flow related responses the level of influence of k2 parameters depends on the type of the model response surface the rainfall and the watershed size keywords walnut gulch kineros2 global sensitivity uncertainty parameter importance response surfaces vars rainfall intensity 1 introduction advanced hydrologic modeling tools play an important role in developing sustainable rangeland and water resource management systems including the implementation of real time flood forecast and warning systems creutin and borga 2003 kitanidis and bras 1980a 1980b and assessments of climate change adaptation strategies in the semiarid southwestern us the highly nonlinear nature of the rainfall runoff relationship yatheendradas et al 2008a 2008b goodrich et al 2000 1997 pilgrim et al 1988 makes it difficult to comprehensively understand the sources of modeling uncertainty in this region precipitation is extremely localized and summertime convective thunderstorms are exceptionally intense roeske et al 1989 keefer et al 2015 resulting in significant variability of watershed responses ranging from flash flood disasters https www weather gov hazstat to extreme droughts seager et al 2007 ipcc 2013 cook et al 2014 zhao and dai 2015 feng et al 2014 the application of hydrologic models requires analysis of outputs relevant to a given modeling objective for the evaluation of model performance the spatially distributed kineros2 kinematic runoff and erosion modeling system smith et al 1995a 1995b semmens et al 2005 is well suited to arid and semi arid watersheds goodrich et al 2012 providing a physically based representation of highly variable semiarid rainfall and of the consequent infiltration and runoff processes at high spatiotemporal resolution the kineros2 also referred to as k2 model has been widely applied to a number of watershed related problems across the world to understand processes in arid and semi arid landscapes these includes erosion and sediment load prediction smith et al 1995a 1995b silva et al 2007 elliot et al 2009 gupta et al 2018 for predicting runoff and flooding schaffner et al 2010 nedkov and burkhard 2012 broxton et al 2014 assessing impacts of urban and green infrastructure yang et al 2019 kennedy et al 2013 korgaonkar et al 2018 predicting the impacts of wildfire and changes in land use on hydrology tajbakhsh et al 2018 sidman et al 2015 etc it has also been part of several studies on evaluation of hydrologic model structure and uncertainties e g duru and hjelmfelt 1994 yatheendradas et al 2008 korgaonkar et al 2020 goodrich et al 1994 in this paper we assess the relative time aggregate and time variant importance of all the k2 parameters on watershed outputs as realistic as k2 and its representation of the hydrology of the southwest arid environment is its results can only be as good as the quality of the input and parameter estimates to explore how realistic the model results are we must understand the relative influence of uncertainties in forcing inputs initial conditions and model parameters on model output sensitivities to understand the relative influence of parameters on the dynamics of k2 model behavior in semi arid region we conducted a multi response based sensitivity analysis sa of k2 under different scenarios of input and modeling objective at a watershed scale similar to the extent of localized monsoon rainfall events in addition to helping elucidate the relative influence of each parameter in the model sa also helps the modeler to prepare for model parameterization and to direct research priorities by establishing which parameters contribute the most to uncertainty in the model response yatheendradas et al 2008a 2008b razavi and gupta 2015 wei et al 2007 saltelli and campolongo 2000 breshears et al 1992 this exercise can also aid in revealing if the processes in the watershed are correctly represented in the model as discussed in razavi and gupta 2015 2016a b several sa approaches such as the morris method morris 1991 campolongo et al 2007 sobol method sobol 1993 saltelli et al 2008 pawn method pianosi and wagener 2015 delsa method rakovec et al 2014 and moment based method dell oca et al 2017 etc can provide identical sensitivity rankings for situations having very different parameter sensitivity properties in this work we implemented the variogram analysis of response surfaces vars methodology razavi and gupta 2016a 2016b to assess the importance of k2 parameters and their dynamics with respect to different rainfall properties and size of contributing areas other time variant sensitivity analysis based on moris methods sobol methods and others eg wagener et al 2003 reusser et al 2011 reusser and zehe 2011 pianosi and wagener 2016 guse et al 2016 wang et al 2021 etc were applied in watersheds with continuous flow different drainage areas and provided valuable insights in understanding models the study was conducted on three small 0 34 4 6 ha lucky hills subwatersheds within the usda agricultural research service ars walnut gulch experimental watershed wgew arizona walnut gulch is also part of the long term agro ecosystems research ltar https ltar ars usda gov network this comprises a unique assessment of model parameter importance and an in depth look at the factors that influence parameter importance unlike other sa analysis tools vars accounts for the spatial correlation in model response as parameters are varied is more efficient cost effective and has been reported to provide more reliable stable estimates in the face of sampling variability gupta and razavi 2018 we compare the results of the vars method to that of the sobol sobol 1993 saltelli et al 2008 and morris morris 1991 campolongo et al 2007 methods which are included in the vars computations as by products under the global sensitivity analysis gsa framework where all the input factors were varied simultaneously we applied the vars tool over the entire range of the parameter spaces the analysis included investigation of the strength of influence of k2 parameters on 14 different types of model response surfaces generated from k2 simulation outputs forced by six different rainfall events the 14 response surfaces were derived from runoff and sediment yield outputs directly or by computing objective functions based on the model outputs the direct model output responses are categorized as performance metric free gupta and razavi 2018 and includes information derived from the model such as flow rate peak flow rate flow duration time to peak time to start of runoff recession time average sediment rate mass of sediment per unit time peak sediment rate and total sediment mass we also explored the influence of the parameters on selected performance metric based objective functions responses that represent goodness of model fit to the observations this includes the nash sutcliffe efficiency coefficient nse nash and sutcliffe 1970 bias observation model prediction and kling gupta efficiency kge kling and gupta 2009 analysis of parameter importance using traditional approaches which usually involves goodness of fit responses surfaces as consistent and accurate indications of the sensitivity of model outputs to parameter perturbations is conceptually flawed gupta and razavi 2018 in this study we examined the hypothesis of independence between parameter importance and model forcing inputs in semi arid regions this work s novelty lies in implementing a time variant parameter importance analysis in semi arid systems using an event scale modeling approach on ephemeral headwater watersheds to understand what controls the physically distributed k2 model behaviors in relation to various response surfaces model outputs to various forcing input properties in addition our study provides insight into and that explains the internal model functioning time variant sa in an event based setting is novel as the previous works only covered continuous hydrologic models the event based simulation experiments on small watersheds with spatially uniform forcing input allowed us to understand model behavior and controls with respect to several modeling objectives as opposed to conventional parameter sensitivity analysis the majority of previous time variant parameter importance studies are on objective functions but here we also directly investigated the sensitivity of different model responses to parameters independent of observations to our knowledge this extensive analyses at this scope has not been undertaken in the past the study focuses on small nested watersheds where rainfall is assumed to be spatially uniform in large watersheds especially where catchment size is greater than the typical storms in semi arid region a comprehensive look at the impacts of spatial extent and storm location on model outputs is required the uniform rainfall assumption minimizes the impacts of temporal and spatial variability of semi arid rainfall on model behavior and control whose scope increases significantly with the watershed drainage area the work also included a comprehensive assessment of factors affecting parameter importance such as the purpose of the modeling activity and watershed size the objectives of this work were i to understand and learn model behavior control of multi response surface based assessment of semi arid systems using a metric free gsa methodology in the context of time aggregate and time variant model responses and ii to evaluate the impacts of rainfall properties with high temporal variability on the relative importance of model parameters in semi arid watersheds the latter included the effects of rainfall perturbation on parameter importance and the nature of the impacts of extreme events the event driven modeling capabilities of k2 at a high temporal resolution 1 min for semi arid ephemeral headwater processes provided a unique opportunity to answer questions related to the sources of model uncertainties due to forcing input parameters watershed size and modeling objectives 2 data and methods 2 1 study site the study was conducted in the lucky hills subwatersheds within the wgew fig 1 lucky hills is a very small 4 6 ha set of nested experimental watersheds within wgew four watershed areas were used in the study including the largest watershed lh 104 subwatersheds lh 106 and lh 102 with contributing areas of 0 34 ha and 1 3 ha respectively and the intervening area represented by the contributing area below stations lh 102 and lh 106 in fig 1 of 2 9 ha lucky hills has elevations ranging between 1354 and 1374 masl and surface slopes averaging 6 7 mean annual temperature is 17 6 deg c with a mean annual rainfall of 324 mm soils in the study watersheds are sandy loam ustochreptic calciorthid with a shrub dominated cover e g king et al 2008 skirvin et al 2008 lucky hills has been densely instrumented since 1961 canfield and goodrich 2003 and was part of the global change and terrestrial ecosystems soil erosion network gcte sen ritchie et al 2005 currently runoff is measured with two supercritical santa rita flumes and one h flume stone et al 2008 runoff instrumentation is located at the outlets of the largest watershed and the two subwatersheds two weighing type recording rain gauges with a precision of 0 25 mm and 1 minute time step after the year 2000 are used to measure rainfall data required for k2 modeling of lucky hills are curated and accessed through the southwest watershed research center data access project swrc dap database usda ars nichols and anson 2008 2 2 rainfall data data from six runoff producing rainfall events were selected for the analysis event data were selected from summer rainfall with a dry initial condition defined as a minimum of 24 h without rain for which the observed pre storm moisture content values showed 6 7 vmc the hyetograph and hydrographs of the selected events are illustrated in fig 2 the hyetographs in fig 2a consist of the average of event rainfall records from two the rain gauges rg83 and rg384 fig 1 which are about 250 m apart at 1 minute time steps the recordings from both rain gauges were correlated at 0 94 0 98 with a total mean difference of less than 0 4 mm for all selected events these data are also included in the swrc dap database https www tucson ars ag gov dap nichols and anson 2008 2 3 modeling using k2 k2 semmens et al 2005 www tucson ars ag gov agwa kineros is an event based physically distributed model developed to simulate runoff and sediment discharge in southwestern arid environments k2 simulates entire hydrographs and sedigraphs for a single rainfall event goodrich et al 2012 at sub hourly time steps k2 conceptualizes watersheds as a collection of spatially distributed rectangular overland flow model elements planar or curvilinear in such a way that hydrologically distinct portions of the watershed such as soil slope impervious area etc can be represented the model simulates interception and the dynamics of infiltration and infiltration excess runoff the infiltration component uses the parlange three parameter model parlange et al 1982 smith and parlange 1978 which is applied on a surface that can exhibit micro topographic variation goodrich et al 2012 and log normally distributed saturated hydraulic conductivity values smith and goodrich 2000 flow routing is based on a finite difference solution of the one dimensional kinematic wave equations woolhiser et al 1990 over a cascade of overland flow model elements and channels the erosion and or deposition component is computed based on raindrop energy splash erosion hydraulic erosion and transport capacity and considers multiple particle size classes e g semmens et al 2008 the automated geospatial watershed assessment tool agwa miller et al 2007 www tucson ars ag gov agwa was used for initial parameterization and execution of the model in this study we investigated seven of the model parameters affecting infiltration and runoff including the saturated hydraulic conductivity ksat manning s roughness coefficient n the coefficient of variability of ksat cv the capillary drive coefficient g intercepted depth in hydraulic erosion coefficient c and sediment splash coefficient s we limited the number of parameters to seven treating the channel and contributing areas with the same multipliers the channel parameters were not treated separately because of the shortness and small size of the channels and very limited channel transmission losses goodrich et al 1997 feasible initial estimates for the k2 parameter values table 1 were obtained through agwa parametrization using gis data layers such as a 1 m dem ssurgo soils and nlcd land use for walnut gulch see table 1 for agwa based database parameter range considering the dry antecedent conditions the initial soil moisture values were set constant to 0 2 for all events the initial parameter values for each element were scaled up and down by global multipliers that ranged from 0 to 2 2 4 model responses in this study ensembles of response surfaces were generated by running the model using parameter sets created by applying random multiplier values to each parameter response surfaces are either direct model outputs or transformations of the outputs to information necessary for a particular modeling objective e g peak flow rate for each randomly generated parameter set we used two time series response surfaces the simulated runoff and sediment rates and 14 computed response surfaces each summarizing the simulation period see table 2 to evaluate the relative importance of the k2 parameters eleven of the response surfaces in table 2 are performance metric free responses which were extracted from the model outputs regardless of observation data the remaining three are performance metric based responses which are measures of the closeness between the model output and the observations we included only performance metric free response surfaces for sediment to limit the scope of the study in the evaluation of the strengths and weaknesses of gsa using time aggregate and time variant responses in addition to the understanding and accurate representation of watershed processes these response surfaces could be used to represent several engineering and management aspects of hydrologic studies such as flood forecasting accuracies lead time to flood early warning systems watershed and water resource management reservoir filling and emptying strategies etc 2 5 vars indices the vars framework razavi and gupta 2016a b enables robust and efficient global sensitivity testing of model responses based on the latin hypercube and a star based sampling strategy known as star vars e g razavi and gupta 2016b star sampling consists vertices star centers that define subsets of the parameter space 10 of the parameter ranges used in this study from which parameters are randomly sampled across the full range of parameter space these randomly generated sets of parameters were used to run the hydrologic model and generate the response surfaces from the model outputs the response surfaces could be time variant y t or time aggregated a single value y for each simulation the vars global sensitivity of a response surface y with respect to a model parameter θ is computed by its variogram γ h and covariogram c h functions 1 γ h 1 2 v y θ h y θ 2 c h 1 2 cov y θ h y θ where h θ a θ b is the length vector h h i h n between any two points a and b in the parameter factor space at locations θ a a n d θ b directional variograms γ h and covariograms c h provide sensitivity information computed at each time step of the simulation period in the time variant analysis y varies with simulation time or an aggregate value in the time aggregate sensitivity analysis these variogram based sensitivity indices are also integrated to provide integrated summary indices or ivars integrated variogram across a range of scales for particular scale range of the ith factor h i 3 γ h i 0 h i γ h i d h i in this analysis we reported the computed ivars values as the parameter importance sensitivity index values specifically we used the ivars50 h 50 factor range values which is the most comprehensive vars based global sensitivity index as it captures the full range of parameter perturbation range razavi et al 2019 for the details of the theoretical and mathematical formulation of vars methodology readers are referred to razavi and gupta 2015 and razavi and gupta 2016a b because of the close theoretical connection between vars directional variograms as h i 0 and the expected value of the square of the ratios of changes in output to changes in inputs vars sa is closely associated to the morris based sa similarly the variogram and covariogram functions are closely related to the total order effect sobol variance based sa as h i becomes large because of this close relationship between vars and the morris and sobol methods the vars methodology provides reliable estimates of the sobol and morris sensitivity rankings as by products at no extra computational expense razavi and gupta 2016a 4a s k i y θ 1 1 k y θ 1 npts k y θ n 1 k y θ n npts k 4b s i k t y t θ 1 1 k y t θ 1 npts k y t θ n 1 k y t θ n npts k in this analysis we first randomly generated sets of the k2 parameter multipliers using progressive latin hypercube and star sampling strategies razavi et al 2019 to extract sensitivity information across the full extent of the parameter space θ 1 θ n pts second we ran k2 for each set of parameters θ n and for each of the six selected rainfall events we then extracted two time variant response surfaces y t θ flow rate and sediment rate and the 14 computed responses represented by y θ as time aggregate simulation outputs for each watershed and for each rainfall event the time aggregate parameter sensitivity indices s i k that are usually the ivars50 were computed equation 4a for each parameter and the 14 response surfaces representing parameter importance cross the entire simulation third we applied the vars procedure to build and analyze the dynamic time variant global sensitivity matrix gsm equation 4b where the sensitivity indices were computed for each parameter θ i i 1 n across the parameter space 1 n pts for each of the simulation periods t 0 t here the sensitivity indices for each parameter s i k are computed at every time step as s i t k over the simulation period representing the time variant analysis where k i and t represent the different response surfaces sediment rates and flow rates k2 model parameters θ and the simulation time respectively further the results of these model runs were used to generate the sensitivity indices of the 14 computed responses to the parameters we also calibrated k2 independent of the vars framework based on the model response surfaces model outputs and the available observations sedigraphs and hydrographs of each event using standard hydrologic goodness of fit indices such as nash efficiency nse kling gupta efficiency keg pearson correlation r root mean square errors rmse and bias without application of optimization algorithms we then selected parameter sets that provided best goodness of fit as discussed earlier the relative parameter importance for the overall simulation s i k time aggregate and at each simulation time step time variant as s i t k is computed via directional variograms γ h covariograms c h and ivars γ h i then the uncertainties in the sensitivity indices generated for each of the response surfaces spaces were evaluated using the bootstrapping technique described in efron 1979 razavi and gupta 2016b sheikholeslami et al 2018 the time variant metric or time series of parameter importance metric at every simulation time step are computed for each of the time variant response surfaces it comprises useful information for understanding model process representations the effects of variability in system inputs and parameter controls corresponding to the simulation period for details of the analysis on the dynamic time variant vars algorithm readers are encouraged to see gupta and razavi 2018 the time aggregate metric shows the summary sensitivity metric at every simulation time step eq 4 or the relative measure of the computed metric normalized by the sum of all the parameter sensitivity indices eq 5 it is calculated for each time aggregate response surface and time variant response surfaces as an average metric representing the overall simulation period the time aggregate analysis supports conventional parameterization approaches during model calibration here we present the analysis and interpretation of both conventional aggregate output response surfaces and the dynamic time variant vars outputs the interpretations are based on values of the ivars γ h and also of the percent sensitivity across the h distance vectors where the latter is defined as the value of γ h i for each parameter divided by the sum of γ h i for all the parameters multiplied by 100 5 s k i s k i i 1 n θ s k i 100 relative sensitivity is normalized by the sum of the sensitivity indices of all the parameters sensitivity for each time step 6 s i k t s i k t i 1 n s i k t log sensitivity 7 l o g s i k t log 10 s i k t to derive error weighted sensitivity indices the product of mean square error mse and the sensitivity indices across all time steps and parameter sets n pts was used the mse at a time step provides an insight into the model response to dynamic changes in the parameter values as a measure of the variance of the response surfaces and its bias w r t observations z t weighting the sensitivity indices by mse at any given time shows the relative sensitivity when the time variant model response would be significant relative to simulation duration 7 s i k t m s e t 1 n pts t 1 i n pts z t k y t θ i k 2 s i k t 3 results and discussion 3 1 time aggregate gsa in fig 3 we show the relative importance of each of the k2 parameters to each of the responses along with 90 confidence intervals of the parameter space clearly the degree of importance of each parameter depends on the type of the response investigated further we find a significant difference in the level and type of parameter importance for the different categories of performance based and performance metrics free responses the time related model outputs column 2 fig 3 such as the time leading up to runoff generation the time to peak and the lag time are affected by all of the flow related parameters this is expected because these responses occur over a small part of the simulation period in other flow related responses including flow duration the number of important parameters decreases to three parameters and four in sediment related outputs in general this exercise showed that the saturated hydraulic conductivity ksat manning s coefficient n the capillary coefficient g and the hydraulic erosion coefficient c play the most significant roles in the model response for the flow time component responses such as duration time to peak lag time and recession time manning s coefficient n appears to be the most dominant parameter when using the bias nse and kge performance metrics the saturated hydraulic conductivity was found to be most important with the g value and n also having a significant impact in the performance metric free flow rate related responses the manning s coefficient is the most important parameter though less so for peak flow rate when examining the performance metric free sediment yield related responses the hydraulic conductivity soil surface roughness and hydraulic erosion coefficient play a significant role fig 3 also shows that the ranges of the 90 confidence uncertainty intervals vary from one response to another with the full vars trial of 100 samples for each parameter the narrow confidence bands of some responses such as bias and kge provide evidence for robustness against sampling variability it is evident that the level of robustness also varies by parameter even for the same response see flow duration maximum sediment rate etc clearly parameter importance can depend on the type of metric and the response investigated as illustrated by fig 4 where the parameter rankings vary significantly except for the sediment related responses in the latter the rankings do not change but the magnitude of sensitivity shows noticeable change one sees the same for the two performance based metrics bias and kge the difference in the percent sensitivity values and the ranking between duration and recession time were comparable for the dominant parameters with little variation in the two insensitive parameters cv of ksat and the intercepted depth this small variation is attributable to the similarity between the flow duration and the recession time the flow duration minus the time to peak which is very small in the southwest arid environment because of the more typical short rainfall durations the analysis also reveals significant variability in the sensitivity of flow rate and sediment responses the variability is minimal in the responses time to peak lag time and time to start which share two properties in common 1 all the parameters play a significant role and 2 the range of time over which these responses are active is very small from an application perspective this exercise illustrates that parameter optimization should take advantage of the knowledge of which parameters are more important for what types of model outputs associated with the modeling objective in almost all applications ksat n and g parameters for flow and c for sediment can be assumed to be important in the time related response surfaces except in time to start the parameter n showed dominance compared to other parameters the importance of intercepted depth in in the sparsely vegetated southwest remains minimal in the k2 application for small headwater watersheds this was true for response surfaces such as the maximum flow time to peak lag time and start time which occur in the early stage of the simulation period the minimum in importance is attributed to the sparse vegetation cover and the type of vegetation grasses and shrubs in the semi arid southwest in the case of areas with a significant vegetation cover as noted in langbein and schumm 1958 the influence of in on runoff and erosion cannot be ignored in the sediment response surfaces n was also the dominant parameter with the second dominant parameter being the hydraulic erosion coefficient c in general the importance of ksat was apparent in the performance metric free response surfaces the variability in the sensitivity across the different types of model response surfaces reflects the inconsistencies between modeling objectives the use of conventional approaches to identify parameter importance without considering the modeling objective may lead to potentially misleading results 3 2 time variant gsa analysis for different model responses response surfaces in the time variant gsa the integrated sensitivity metrics for flow rate and sediment rate were calculated for each simulation time step 1 min and parameter values across the entire space fig 5 shows the relative sensitivity indices of k2 parameters to simulated flow rate during the event on sept 12 2013 on lh 104 the top panel fig 5a shows the rainfall rate average of two rain gauges observed streamflow and the range of simulated runoff fig 5b presents the percent sensitivity index which was computed by normalizing each index by the sum of the integrated sensitivity indices from all of the parameters for each time step the percent sensitivity provides a very intuitive sense of parameter importance at any given time but fails to show the time at which a given parameter is more important the logarithmic transformed sensitivity index fig 5c shows the time varying sensitivity which differ from each other in several orders of magnitude the metrics in fig 5b and 5c can be used to understand the relative importance of all the parameters during each event simulated by the model fig 5d plots the integrated sensitivity index showing when the variance and bias of the response surface was the strongest during the simulation this index mainly highlights the time when most of the infiltration and routing processes are active the effect of less important parameters and rainfall beyond 60 min is shown to be very insignificant in fig 5e the sensitivity index is a product of the integrated index and mse mean square error it illustrates a shorter time window where the sensitivity and uncertainty of the processes is the strongest the metrics in 5d and 5e for event based modeling exercises that include parameter identification and calibration illustrate the high likelihood of obtaining parameter values that create a good fit in the short window of time when the parameters are active the metrics in 5d and 5e can also be used to compare parameter importance during different rainfall inputs each index fig 5b e has its own strengths and limitations in the information they provide to modelers in regards to not only the most important parameters but also when they are important for example fig 5e showed a narrower time of strong parameter importance by incorporating time where the large deviation from the observations occurred this index minimizes the effects of dynamics in the rising and recession tails of the hydrograph with very small sensitivity values fig 6 plots the observed hyetograph hydrograph and sedigraph fig 6a and the corresponding sensitivity indices of the simulated runoff fig 6b and sediment yield fig 6c to parameters for lh 104 from the event of july 25 2010 in both 6b and 6c the time varying changes in parameter importance illustrate the integrated effects of the model algorithms and drivers rainfall surface topography soil and land cover properties the importance increases with rainfall intensity and decreases as rainfall subsides however the importance of the parameters does not go to zero even after the rainfall has stopped the four pie charts in subplots 6b and 6c show the importance of each parameter in percent the relative importance of ksat red seems to increase over time for flow rate while the relative importance of manning s n green decreases then increases over time and the capillary drive coefficient black decreases over time in the simulated sediment yield fig 6c most trajectories of parameter importance showed variation across the simulation period though ksat red exhibited the same increasing trajectory as for flow rate the routing parameter n is the dominant parameter in both runoff and sediment response surfaces during active runoff generation processes the two large pie charts in fig 6b and 6c represent relative time aggregate parameter importance values that show significant differences from the dynamic values across the simulation time steps 3 3 effects of rainfall intensity and watershed size on parameter importance we compared the impacts of rainfall in terms of depth intensity and duration on the parameter importance analysis the sensitivity indices computed for each of the k2 parameters for all the storms fig 2a were compared fig 7 a e across each simulation period the sensitivity index time series were in direct responses to the period when intense rain and runoff generation occurred in the watershed the level of parameter importance varies with the rainfall inputs fig 7 the sensitivity differs significantly between the parameters as evidenced by the scales of the y axis fig 7 and by the comparisons discussed in figs 5 and 6 the magnitude of the sensitivity indices at a given time is a function of the prior rainfall and current rainfall rate which demonstrates the importance of the rainfall rate distribution this makes a direct comparison between the different rainfall inputs very difficult because of the substantial variation in model response over time which depends not only on the amount but also the distribution of the rainfall a direct time series comparison such as fig 7 requires caution however in order to compare the impact of the rainfall on parameter importance we aggregated the parameter importance indices of each of the events as averages over the simulations fig 8 compares the aggregate sensitivity indices in response to the different rainfall inputs for the different subwatersheds of lucky hills as a function of contributing area the aggregated log transformed summary sensitivity index for each of the parameters shows variations as a function of watershed size and the rainfall depth we considered four sizes of contributing area the two internal gauging stations at lh 106 and lh 102 the outlet at lh 104 and the intervening area between the internal gauging stations and the outlet the level of parameter importance increased with increasing rainfall intensity and depth parameter importance also showed a steady increase with size fig 8 the effects of watershed size on parameter importance analysis are limited to small hillslope scale sizes for which the spatial uniformity assumption holds in the semi arid environment storms with high spatial variability of rainfall located on a smaller portion of the watershed can cause runoff while other part of the watershed received no rain are relatively common syed et al 2002 the analysis in relatively larger watershed sizes requires a broader scope because of the immense variability of rainfall in space and time making the relationship between watershed processes and the rainfall more complicated for the most part the importance of all k2 parameters increased with total rainfall depths the ranking of parameter importance by event across all sizes from most important to least important was consistently events 6 4 5 3 and 2 this shows that parameter importance variation is dependent on not only the depth of rainfall but also the combined effects of both rainfall intensity and depth event 1 07 14 2014 with the least intense rainfall and minimal generated runoff showed a clear difference from the rest of the events these analyses provide not only the dynamics and extents of parameter importance but also assist in explaning inconsistencies in the time aggregate sa relative to the modeling objective in order to compare the temporal patterns of sensitivity response to rainfall intensities we perturbed scaled up and down event 2 which has a symmetrical distribution before and after the peak see the hyetograph of fig 2 id 2 we used scaling factors of 0 5 0 6 0 7 0 8 0 9 1 1 1 2 1 3 1 4 1 5 2 3 4 and 5 see the ensembles of the scaled rainfall intensities in fig 9 c for analysis of the sensitivity of the model parameters the use of similar rainfall distributions and durations in this exercise shows the influence of rainfall depth intensity on parameter importance at any given time during the simulation period the symmetrical scaling of the input rainfall resulted in corresponding impacts on parameter importance at a given time example of the impacts of increasing rainfall intensities that resulted in corresponding changes in the magnitudes of the parameter importance indices is illustrated in fig 9a and the period duration of significant parameter influence also increased to the left and right in response to a longer duration flow with increased rainfall depth and intensity similarly the scaled down rainfall resulted in reduced sensitivity and a shorter duration of parameter influence it is also important to note the small sensitivity values of in and cv across all ranges of rainfall indicating their inconsequential effect in the calibration and validation processes the sensitivity values of in and cv are an order of magnitude less than the sensitivity of other k2 parameters in fig 9b we plotted the changes in parameter importance to the changes in scaling factors which shows a power function relationship between the change in sensitivity of n manning s coefficient and the change in rainfall the ksat the capillary coefficient g and the interception coefficient in showed a linear relationship for small rainfall changes but became unresponsive as the rainfall scaling increased these changes in the way parameters control the hydrologic processes reveals how the dominant processes were altered with substantial changes in rainfall input this exercise demonstrates that in arid climates with very intense rain and especially extreme events resulting from current trends of climate change the role of parameters controlling the catchment hydrologic response diminishes while the routing parameters hydraulic control mannings n become more dominant see fig 9b the importance of other k2 parameters showed a decreasing trend as the rainfall intensities increased twofold the changes in sensitivity indices due to smaller changes in rainfall see the first 50 fig 9c reflected an almost linear relationship between the change in precipitation intensity and the difference in the magnitude of parameter importance 3 4 implications for model parametrization once the parameter importance investigations were conducted we applied the resulting sensitivity outputs to the model parametrization strategy and tested the advantage of only using the most sensitive parameters in model calibration in the calibration of all 7 seven parameter multipliers we used a total of 6400 monte carlo simulations generated using the progressive latin hypercube framework plhs sheikholeslami and razavi 2017 to optimize each parameter with respect to observations based on widely used goodness of fit metrics in fig 10 we compare the resulting calibrated model performance for various numbers of monte carlo simulations 1300 20 3 1700 26 5 2200 34 3 2900 34 3 3700 57 8 and 6400 100 using only the four most critical k2 parameters the comparison of the cumulative calibrated runoff and sediment rates fig 10a using only four of the k2 parameters compared to the model calibrated for the full range of parameters showed very little to no gain with the full calibration using sediment and flow rate model outputs the box plot fig 10b showed that the identified parameter ranges were consistent and within the acceptable range for the study sites this demonstrates that the vars procedure is more comprehensive and robust for parameter screening and model calibrations parameter sensitivity analysis has been widely and successfully used for parameter screening in model calibration e g morris 1991 campolongo et al 2000 bárdossy 2007 and makler pick et al 2011 in fig 11 the performance of the models calibrated using the four most sensitive parameters illustrate the efficiency robustness and effectiveness of vars e g gupta and razavi 2018 sheikholeslami et al 2018 the very small coefficient close to zero of the linear fit line blue and r2 close to zero indicated that there was very little difference between using a subset versus the entire set of monte carlo simulationswith the four most sensitive parameters for calibration even the smallest sets of monte carlo simulations showed very comparable performance to the fully calibrated model showing the robustness and efficiency of vars parameter importance analysis and the embedded parameter sampling strategy in addition to demonstrating the advantage of using only the most sensitive parameters the approach significantly reduces the time and computing resource requirements in large simulation exercises as this method produces equivalent model performance with a smaller subset of monte carlo simulations 4 conclusions in this paper we explored the dynamics of earth systems model behavior through application of general sensitivity analysis gsa using various forms of model responses under different conditions that influence the event based watershed responses the conventional approaches in global parameter importance analysis which usually use performance metric response surfaces in dynamical environmental systems offer an incomplete explanation of factors controlling model behavior gupta and razavi 2018 argued that these approaches be termed as parameter identifiability analyses rather than the parameter importance problem to fully understand the dynamics of model behavior within the k2 model structure we used the new time variant gsa analysis i e vars and evaluation of different response surface scenarios that provide additional interpretable information from model outputs the relative importance of each k2 parameter identified using the vars methodology was found to be intuitively consistent with the type of response investigated the study revealed that the magnitude and rank of parameter importance varies depending on the type of model response surface usually defined by the modeling objective and the rainfall intensities in flow rate and sediment related response surfaces the vars sensitivity indices exhibited considerable variability among k2 parameters with ksat n and g parameters showing the dominant impact in contrast the time based response surfaces especially the time to peak and start time showed minimum variation with all parameters of noticeable importance this illustrates that in model calibration and model parameter identification exercises it is important to consider which behaviors are the most important type for the modeling objective in question parameter importance analysis using the spectrum of model response surfaces used in this study provided additional useful insights as to what factors are important for affecting model behavior those explanations and characterizations related to model behavior controls and systems functioning response revealed in this study could not have been undertaken without a detailed took at time variant sensitivity comparisons of parameters of events based models on different response surfaces under varying forcing inputs in general the coefficient of variation of the conductivity cv the interception in and splash s parameters are the least sensitive parameters in k2 with an insignificant level of importance in this study comparison of the variance based total order sobol to and derivative based morris sensitivity indices showed identical ranking to the vars indices however there were differences in the relative importance between the parameters as given by the magnitudes of vars indices this is in line with the reporting by razavi and gupta 2016a and razavi and gupta 2016b in the detailed comparison of vars and the two sensitivity analyses tools providing significant insights in the strengths and limitations of those methods razavi and gupta 2015 also mentioned the different sa methods might lead to different results as they use fundamentally different philosophies and equations the time variant approach which illustrates when in time the model parameters control the hydrologic processes and how inputs influence the model outputs is not only different from the time aggregate analysis but also provides additional insight into why when physically based models do not perform as well as expected the time variant gsa produced the relative parameter importance and ranking that are robust leading to a better understanding of model behaviors the vars approach also showed significant flexibility in applying and evaluating the impacts of a range of input forcings on model behaviors and functions represented by the different response surfaces evaluation of other time variant gsa methods using theoretical models showed effectiveness and superior perfornce of vars methodology e g becker 2020 puy et al 2020 but comparison under different hydrologic scenarios and models requires extensive research the variation in the relative importance is affected by the rainfall input and continues to the end of the simulation the relative importance of the parameters also varies with the distribution of the rainfall intensity understanding and interpreting parameter importance during the simulation requires the choice of a sensitivity metric that best suits a given interest the application of time variant sensitivity analysis for understanding model behaviors can be expanded to a continuous models which are usually characterized by significant rainfall variability over the simulation period and area conducting a time variant sensitivity analysis for a response surface of interest provides a structured approach to untangle the dynamic influence of parameters on the simulation of flow and sediment rates of a given event the differences between analysis of the continuous model vs its subsets i e different events and or time steps are significant which can be explained by simpson s paradox the use of time aggregate sa accompanied by time variant sa accounts for the dynamics and the inconsistencies in the various sa outputs comparison of parameter importance during simulations with different rainfall intensities is difficult because of the sensitivity of the parameters to the temproral rainfall distribution parameter importance varies during the simulation as a function of prior rainfall input and the rainfall at present additionally high quality high temporal resolution observations as used in this case study are not widely available and are typically applied on larger scale watersheds where the assumption of spatially uniform forcing used here is problematic across lareger areas the high spatial heterogeneity of rainfall resulting from compact air masses s further complicates the model behavior controls in watersheds larger than the localized convective semi arid rainfall rainfall variability becomes so significant that it requires a more in depth look at its influence from the parameter importance point of view and its complex effect interms of spatial variability in activating hydrologic processes based on the spatial distibution of the rainfall the complexity can also increase with respect to parameter spatial consistency and identifiability problems consequently the time variant sensitivity and importance is not widely tested or characterized under different scenarios and modeling structures revealing potential weaknesses in physical models more broadly this reveals the limitations of our current observation networks in the understanding and representation of physical processes and parameters within our models and offers opportunities to explore unexplained uncertainty and poor performance of physically based models like kineros2 parameter sensitivity analysis with perturbed rainfall intensities can be viewed in one sense as a way of looking into impacts of climate change inputs resulting in the likelihood of future flood events for example the ever increasing influence of manning s coefficient fig 10 on watershed response with increasing rainfall when the importance of parameters related to infiltration storage and abstraction decreased or did not change with exceptionally high rainfall see fig 10 indicates the shift in the dominance of sets of parameters with the extent of rainfall inputs fixing insensitive parameters and calibrating the most important parameters in k2 for arid regions proved to be an excellent strategy by reducing the time and computing resources needed when a large number of monte carlo simulations are used credit authorship contribution statement menberu b meles conceptualization methodology visualization investigation software writing review editing dave c goodrich methodology writing review editing hoshin v gupta methodology software writing review editing i shea burns software writing review editing carl l unkrich software writing review editing saman razavi software writing review editing d phillip guertin writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments funding and support were provided by the u s department of agriculture ars and a contribution from the long term agroecosystem research ltar network thanks to the many dedicated usda ars southwest watershed research center staff in tombstone and tucson arizona who made possible the collection of high quality rainfall and runoff records in wgew the vision and commitment of all ars scientists and administrators to construct manage and operate the experimental walnut gulch watershed for the long term are to be commended the data used in this study are available in dap databased https www tucson ars ag gov dap the authors declared no conflict of interest 
4574,data assimilation plays an essential role in real time forecasting but demands repetitive model evaluations given ensembles to address this computational challenge a novel robust and efficient approach to surrogate data assimilation is presented it replaces the internal processes of the ensemble kalman filter enkf with polynomial chaos expansion pce theory eight types of surrogate filters which can be characterized according to their different surrogate structures building systems and assimilating targets are proposed and validated to compensate for the potential shortcomings of the existing sequential experimental design sed an advanced optimization scheme named sequential experimental design polynomial degree sed pd is also advised its dual optimization system resolves the issue of sed by which the value of the polynomial degree had to be selected ad hoc or by trial and error its multiple stopping criteria ensure convergence even when an accuracy metric does not monotonically decrease over iterations a comprehensive investigation into how to configure a surrogate filter indicates that the new partial replacing part of original filters and invariant valid for entire time periods approaches are preferred in terms of accuracy and efficiency which helps directly reduce the number of dimensions and bridge the gap between hindcasting and real time forecasting of the eight filters the dual invariant partial filter performs best with equivalent accuracy to dual enkf and about 500 times greater computational efficiency ultimately this proposed surrogate filter will be a promising alternative tool for performing computationally intensive data assimilation in high dimensional problems keywords surrogate filter data assimilation polynomial chaos expansion ensemble kalman filter real time forecasting sequential experimental design polynomial degree 1 introduction making accurate and timely predictions of floods in real time is a major task in hydrology moradkhani and sorooshian 2008 however it suffers from inherent difficulties due to epistemic and aleatoric uncertainties associated with future conditions of rainfall forcing initial and boundary conditions and model parameters beven 1989 ajami et al 2007 kim et al 2016a 2016b beven et al 2018 dwelle et al 2019 as the development of in situ or remote sensing techniques over several decades makes it possible to collect real time observation data assimilation da has proven to be one of the most effective ways to improve the performance and quantify the uncertainty of real time predictions liu et al 2012 the central idea of da is to find a way to reduce the bias of hydrological model states and or parameters sequentially by incorporating real time observations into pre forecasted results evensen 1994 clark et al 2008 moradkhani and sorooshian 2008 at present da techniques are becoming more and more sophisticated from simple rule based direct insertion to advanced smoothing and sequential techniques liu et al 2012 despite the effectiveness of data assimilation the computational burden required to perform model evaluations in real time remains an obstacle liu et al 2012 houtekamer and zhang 2016 bannister 2017 loos et al 2020 since da includes the process of predicting and updating states and model outputs the number of model evaluations should be carried out multiple times compared to predicting only once when da is not applied if a model takes a lot of computation time this problem can become even more critical examples are when running hydrological models coupled with the multi dimensional governing equations of navier stokes marshall et al 1997 giraldo and restelli 2008 tossavainen et al 2011 saint venant kim et al 2012a 2012b richards maxwell et al 2007 kollet et al 2010 and hairsine rose kim et al 2013 kim and ivanov 2014 on atmosphere surface subsurface and surface erosion respectively their cpu runtimes required for a 1 day simulation generally reach up to the order of days furthermore most da techniques use ensemble representations for the covariances of forecast e g streamflow and analysis error of model states and or parameters maintaining a larger set of ensembles for initial states model noises and perturbed observations helps reduce sampling errors that can occur when the state and parameter variables are non gaussian and non linear evensen 2003 li and xiu 2008 liu et al 2012 slivinski and snyder 2016 bannister 2017 the size of the ensemble can be at least o 10 2 to more than o 10 8 houtekamer and zhang 2016 resulting in a higher computational barrier this is indeed not desirable in situations such as flood forecasting where real time decisions are needed the use of surrogate models could be a solution to cope with this concern which has attracted attention recently and used widely in many research areas to mimic nonlinear dynamic models laloy et al 2013 dwelle et al 2019 tran et al 2020 zhang et al 2020 this surrogate model performs thousands of simulations in seconds resulting in improved computational efficiency that dramatically reduce cpu runtime razavi et al 2012 asher et al 2015 mohanty 2015 the most common methods used to build surrogate models include genetic programming support vector machines svm artificial neural networks ann gaussian process emulation gpe also called kriging and polynomial chaos expansion pce simpson et al 2001 rajabi 2019 in particular pce has shown its merit and attractiveness in recent studies dwelle et al 2019 rajabi 2019 tran et al 2020 wang et al 2020 and it turns out to be more effective than the other data driven methods razavi et al 2012 rajabi 2019 torre et al 2019 for example pce performs better than the data driven models in terms of accuracy e g ann or svm when applied to small training sets and minimal configurations torre et al 2019 another merit of using pce occurs when predicting extreme events beyond the boundaries of training data flood and kartam 1994 minns and hall 1996 tokar and johnson 1999 rare events can be captured more completely because pce is built based on high fidelity samples supervised by physical models schöbi et al 2017 dubreuil et al 2018 tran et al 2020 third pce can be fitted very fast regardless of the size of training data unlike gpe and svm that are prone to computational demands for large training sets razavi et al 2012 last pce can facilitate global sensitivity analysis by performing only simple arithmetic on the coefficients of the already constructed pce instead of implementing additional model evaluations sudret 2008 dwelle et al 2019 due to its advantages pce has been used extensively in many types of hydrological problems from simple to complex e g sochala and le maître 2013 sargsyan et al 2014 wang et al 2017 dwelle et al 2019 tran and kim 2019 tran et al 2020 in the literature conventional ways of constructing pce are to build a single pce that can mimic the entire model process for each computational time step however these are problematic when tackling a high dimensional problem with a large number of uncertain parameters states its pce construction may be challenging due to the exponential increase in the number of pce coefficients blatman and sudret 2010 sargsyan et al 2014 konakli and sudret 2016 dwelle et al 2019 tran et al 2020 if one provides necessary design sampling points to have substantial and sufficient search space for all the dimensions that points for the model evaluation could be overly large advanced techniques such as the fractional factorial design and analysis wang et al 2015 the least angle regression blatman and sudret 2011 and the bayesian compressive sensing sargsyan et al 2014 have been able to solve some of the high dimensional 80 dimensions problems by calculating coefficients only for the most sensitive pce terms that have significant impacts on the model response but dealing with a larger dimension is still intricate additionally when making a real time prediction the conventional approach requires building a new pce at every time step prior to forecasting wang et al 2018 hu et al 2019 tran et al 2020 from the context of real time flood predictions that should be provided within a very short time usually less than an hour generating pce every time is a huge burden therefore finding alternative ways to reduce the dimension or to avoid the recurring pce construction is the right direction another issue of pce construction is that to mimic the original model and yield a reliable outcome for a wide range of conditions pce should be trained through as many training sets called experimental design x as possible schöbi et al 2017 choosing a suitable size for the experimental design is also a challenge razavi et al 2012 in order to circumvent this problem blatman and sudret 2010 proposed a sequential experimental design sed scheme to limit the size of the experimental design when constructing the pce minimizing its building time specifically the size of the experimental design n one of two important parameters is increased until a given statistic for computing the error between the surrogate and original models reaches a target value this scheme allowed us to successfully determine the size of x however the order of the polynomial p the other parameter that directly affects the performance of the pce dwelle et al 2019 tran and kim 2019 was not considered in that sed scheme the value of the polynomial degree had to be selected ad hoc or by trial and error additionally the sed scheme uses only a single convergence criterion for a relative error e g leave one out cross validation error ε loo and sets a small target value e g 10 5 to define acceptance level however its inherent assumption that the relative error should decrease monotonically as n or p increases is not always satisfied hu and youn 2010 sargsyan et al 2014 diaz et al 2018 dwelle et al 2019 torre et al 2019 the criterion proposed by the sed scheme may not reach a small target for problems where the error does not decrease continuously and thus infinite iterations may occur we need to investigate whether this criterion is appropriate for flood simulations and how to modify the scheme if it is not in this study we present a robust surrogate data assimilation approach based on polynomial chaos expansion theory this approach includes novel solutions to significantly reduce the computational cost of data assimilation and to effectively determine the optimal the size of the experimental design and the order of the polynomial of pce construction it is organized as follows eight filters replacing the ensemble kalman filter are developed and necessary modifications to the sed scheme are presented in section 2 from the synthetic and real experimental setups in section 3 the performance of the proposed surrogate filters is evaluated in section 4 discussions and conclusions drawn from comprehensive analyses continue in sections 5 and 6 respectively 2 methodology 2 1 single and dual ensemble kalman filters since the ensemble kalman filter enkf has become the most broadly used da technique in many discipline due to its ease of implementation in solving diverse da conundrums weerts and el serafy 2006 clark et al 2008 liu et al 2012 pathiraja et al 2018 tran et al 2020 enkf was chosen as an original filter to be substituted in this study both single and dual enkfs were used to perform the experiments both filters have in common that they update model states at each time step the main difference is whether these filters update model parameters because the internal structure and principles of enkfs have already been described in detail in the literature this study will briefly address the key equations that are necessary to describe the surrogate filter we will propose later for more details readers are referred to moradkhani et al 2005 or section s 1 in the supplementary material regarding a nonlinear deterministic or statistical model on discrete time domains a transition equation for its state x is described by 1 x t i f x t 1 i θ t 1 i u t 1 i w t 1 i i 1 n da where x t i is the i th ensemble state predicted at time t and x t 1 i is the i th state updated at time t 1 the size of x t is n da n s with n da ensemble members and n s model states θ t 1 i is the i th ensemble parameter updated at time t 1 and θ t has a size of n da n p where n p is the number of model parameters u t 1 i is the i th ensemble forcing at time t 1 which is generated following a log normal distribution with the mean equal to the actual forcing u t 1 and covariance e t 1 u at time t 1 in this study e t 1 u is assumed by using a relative error in forcing re u and u t 1 i e e t 1 u re u u t 1 the size of u t 1 i is n da n i with n i forcings propagator f for computing the model states can be any hydrological model w t 1 i representing the model structure uncertainty is the i th model error at time t 1 assuming that model parameters also follow a random walk the i th ensemble parameters at time t are treated by adding gaussian noise τ t 1 i with covariance e t 1 θ to θ t 1 i moradkhani et al 2005 2 θ t i θ t 1 i τ t 1 i τ t 1 i n 0 e t 1 θ where e t 1 θ is assumed by multiplying the relative error in parameters re θ and the variance of ensemble parameter distribution at time t 1 θ t 1 the i th prediction model output at time t y t i is the function of the model states parameters and forcings 3 y t i h x t i θ t i u t i where h is a propagator for computing the model outputs streamflow in this study and can also be a hydrological model that includes nonlinear relationships the i th ensemble parameters at time t θ t i are corrected by using the kalman gain k t θ and the i th observations at time t y t obs i 4 θ t i θ t i k t θ y t obs i y t i where details of how to evaluate the kalman gain k t θ are provided in section s 1 of the supplementary material y t obs i is a perturbed observation due to measurement noise following a normal distribution with mean equal to the actual observation y t obs at each time t and a predefined or assumed covariance e t obs that is computed based on a relative error in observation re obs and observation y t obs i e e t obs re obs y t obs with these updated ensemble parameters θ t i the prediction is updated once more with an equation similar to eq 3 5 y t i h x t i θ t i u t i finally the i th ensemble model states that at time t x t i are corrected by using the kalman gain k t x and perturbed observations 6 x t i x t i k t x y t obs i y t i where details of how to evaluate the kalman gain k t x are also illustrated in section s 1 of the supplementary material the equations above from eqs 1 6 all correspond to the dual enkf for the single enkf all the equations are identical except for eqs 2 4 and 5 the noise parameter in eq 2 is disregarded eq 4 is assumed as θ t i θ t i and eq 5 is then simplified to y t i y t i combining the above six equations the final form of enkfs can be expressed as 7 x t i y t i e n k f x t 1 i θ t 1 i u t 1 i u t i y t obs i 8 x t i θ t i y t i d u a l e n k f x t 1 i θ t 1 i u t 1 i u t i y t obs i 2 2 eight surrogate solutions to ensemble kalman filters here we present eight surrogate filters based on polynomial chaos expansion pce theory that can be substituted for enkfs the proposed filters expect to achieve high accuracy at low computational cost and inherit the same fundamental assumptions as the enkf implementations the differences among the eight filters will be described below and in fig 1 2 2 1 different surrogate structures whole vs partial surrogate filters the first criterion for distinguishing among the eight surrogate filters is to determine what to replace in the existing enkf system one possibility is to construct a single surrogate that can mimic the entire enkf process given all the input variables on the right side of eqs 7 and 8 the output variable on the left side is computed through the surrogate filters this is similar to the conventional approach hereafter called surrogate whole filter suwf the other new approach is to configure multiple surrogates each of which mimics a specific process in the enkfs theoretically it is possible to distinguish all the processes of enkfs and construct surrogates for all of them but two independent surrogates are only built for two of the processes in this study these processes were chosen because they are the most unfavorable in terms of computational efficiency but have a great impact on accuracy li and xiu 2009 the processes are those computing ensemble states and streamflow forwarded in time through the propagators f and h in eqs 1 3 and 5 regarding the enkf processes other than these two the same applies as with the existing enkfs this is hereafter called the surrogate partial filter supf 2 2 2 different building systems variant vs invariant surrogate filters the second criterion is whether or not the pce employed to create the surrogate filters changes over time one conventional type of pce is a time variant pce vapce which is continuously reconstructed based on new information about forcings and streamflow at all forecasting steps of data assimilation fan et al 2016 wang et al 2017 2018 dwelle et al 2019 hu et al 2019 tran and kim 2019 the collection of the training set is much more straightforward than in the other type because precipitation forcing and streamflow are known during the assimilation process that is u t 1 u t and y t obs are real data tran et al 2020 we will refer to the surrogate filters created using the time variant pce as variant surrogate filters vasufs i e vasuwf and vasupf the other type of pce is built only once over the calibration period and is used later for the forecasting period tran et al 2020 this time invariant pce hereafter referred to as inpce has the advantage of maximizing applicability and efficiency because it does not need to be re built during real time forecasting one notes that inpce should be made to better represent the behavior of the original model under a wide range of conditions trained for a limited dataset from the past the pce model has shown excellent performance with other events similar to the calibration sets however for events that differ from those in the training series it is challenging to construct a surrogate model that mimics the original model tran et al 2020 this issue can be addressed by training with as much data as possible but attaining large amounts of data is still far away for some ungauged domains we therefore propose a new procedure of collecting training sets to build an invariant pce that does not require measurement data in this study we assume that all input variables of a filter model in eqs 7 and 8 i e model states model parameters rainfall measurements and observed discharges are uncertain and vary within a particular range instead of arranging them in a deterministic way their input values are randomly generated through a sampling process the latin hypercube lhs sampling technique mckay et al 1979 is used in this work this procedure makes the invariant pce suitable for as many input conditions as possible further details on how to collect the experimental design in building the invariant pce will be described in section 3 3 we will refer to the surrogate filters created by the invariant pce as invariant surrogate filters insufs i e insuwf and insupf such a differentiating criterion is related to the amount of information needed to generate a pce that is whether to select training information for just a single time step or all periods it thus involves setting the extent to which the generated pce can replace the original model in other words a pce generated using a wider range of training data can mimic the results of the original filter in a wider range of simulation conditions a more detailed comparison and discussion on this subject can be found in tran et al 2020 2 2 3 different assimilating targets single vs dual surrogate filters the last criterion is based on the goal of data assimilation whether to update only state vectors like single enkf in eq 7 or to update model parameters as well as the state vectors like dual enkf in eq 8 surrogate filters that replace single and dual enkf can be called single surrogate filters sufs i e insuwf insupf vasuwf and vasupf and dual surrogate filters dual sufs i e dual insuwf dual insupf dual vasuwf and dual vasupf respectively the mathematical denotations of these eight surrogate filters are presented in appendix a for clarity this includes the denotations for both surrogate filters and their corresponding pces the latter specifically consists of 4 variant pces vapce1 vapce2 vapce3 and vapce4 and 4 invariant pces inpce1 inpce2 inpce3 and inpce4 2 3 polynomial chaos expansion pce to develop the surrogate filters explained in section 2 2 and handle the computational burden mentioned above a pce that expresses stochastic quantities as a convergent polynomial series of random input variables is used wiener 1938 ghanem and spanos 1991 let us consider a filter model m that will be supplanted by a surrogate m pce given inputs x t i and outputs y t i of m shown in eqs a 2 a 4 a 6 a 7 a 10 a 12 a 14 and a 15 the relationship between x t i and y t i is described as 9 y t i m x t i m pce x t i α n n x ε α ψ α x t i i 1 n da where the numbers of inputs x t i and outputs y t i each member of the pce outputs is called a quantity of interest qoi in eq 9 are n x and n y respectively which vary depending on the aforementioned pces specifically the values of n x are n s n p 2 n i 1 n s n p 2 n i 1 n s n p n i and n s n p n i for pce1 pce2 pce3 and pce4 respectively regardless of whether the pces are variant or invariant whereas the corresponding values of n y are n s 1 n s n p 1 n s and 1 for the 4 pces respectively then one attempts to approximate m with m pce represented by a suitable polynomial expansion the expansion consists of polynomial basis terms ψ α x t i that are multivariate orthogonal polynomials over the distribution of input x t i ε α are deterministic polynomial expansion coefficients for multi indices α α 1 α n x that are introduced to simplify notations and represent the orders of polynomial terms three widely used methods to estimate pce coefficients ε α are gaussian quadrature smolyak 1963 bayesian compressive sensing sargsyan et al 2014 and sparse regression berveiller et al 2006 blatman and sudret 2008 the latter method which has been suggested in previous studies e g blatman and sudret 2011 wang et al 2015 meng and li 2018 is employed in this study for more information about this method we refer the reader to blatman and sudret 2008 a brief overview for determining pce coefficients is described in section s 2 of the supplementary material 2 4 optimization of pce hyper parameters the constructed pce includes two hyper parameters the size of training data set called experimental design x n and the degree of polynomials p it is important to set the values of the hyper parameters prior to estimating the pce coefficients which directly affects the ability to capture the behavior of the original filter blatman and sudret 2010 however such a determination is not straightforward and often has been decided by trial and error hu and youn 2010 laloy et al 2013 sochala and le maître 2013 wang et al 2017 dwelle et al 2019 tran and kim 2019 to address this problem we propose a procedural version in which the ultimate values of n and p are identified by continuously increasing their values until any convergence criteria are met this method is the extension of the sequential experimental design blatman and sudret 2010 2 4 1 sequential experimental design polynomial degree scheme in the original sequential experimental design sed scheme suggested by blatman and sudret 2010 the enrichment of experimental design x is stopped when an accuracy metric reaches a target error that is a single stopping criterion was employed because some studies do not meet its intrinsic assumption that the accuracy metric decreases monotonically hu and youn 2010 sargsyan et al 2014 diaz et al 2018 dwelle et al 2019 torre et al 2019 this study extends the existing scheme so that multiple stopping convergence criteria can be satisfied sequentially by enriching both n and p in the so called sequential experimental design polynomial degree sed pd scheme specifically this sed pd consists of two subsequent iterative cycles to determine the optimum values of n and p in which the sub loop of p is influenced by the iteration of n enrichment a stepwise description of the sed pd scheme is provided as follows and an associated flowchart is sketched in fig 2 1 the first step is to initialize the size n of the experimental design with a feasible number if one chooses an initial value of n that is too small it will take a long time to converge conversely an initial value that is too large may not converge at all therefore selecting an appropriate number for the initial value of n is an important task in general determining the optimal size of the experimental design depends largely on the complexity of the original model as well as on the computational budget available razavi et al 2012 the relevant literature has not reported a well established rule of thumb for the initialization of n to build the pce blatman and sudret 2010 schöbi et al 2017 diaz et al 2018 dubreuil et al 2018 dwelle et al 2019 torre et al 2019 here we attempt to appraise an approximate order of an initial value for n regarding the four variant pces i e vapce1 2 3 and 4 in eqs a 2 a 4 a 6 and a 7 n can be expressed in the order of the number of ensemble members n pce i e initial n n pce because these pces reconstructed in each computational time have a single time step the number of time steps n t 1 regarding the other invariant pces i e inpce1 2 3 and 4 the smallest starting value could be the product of the number of time steps n t and the number of ensemble members n pce i e initial n n t n pce such a number indicates that an original filter model needs to be computed over the number of ensemble members of the input variables per each time step 2 given n the experimental design x is sampled using the lhs technique and the corresponding response y is computed from eq s 29 3 the other hyper parameter the polynomial degree p needs to be initialized as well unlike the initialization of n the starting value of p can be chosen to be 1 without much effort 4 given the values of n and p a candidate surrogate for each qoi m pce q o i is constructed from eq s 29 5 to quantify the difference between the results of the original and surrogate filters judge the degree of convergence and evaluate the performance of the latter filters a statistic is introduced and will be computed for each qoi for each iteration following the study by blatman and sudret 2010 an accuracy metric for each qoi ε loo q o i is defined as 10 ε loo q o i 1 n k 1 n m q o i x k m pce q o i x k 1 h k 2 where h k is the k th diagonal term of the matrix f f t f 1 f t and the information matrix f is defined in eq s 32 this leave one out cross validation error metric ε loo q o i is designed to quantify how exactly the surrogate model behaves compared to the original model by computing a deviation between these model outputs and to detect an overfitting phenomenon more easily blatman and sudret 2010 6 the inner iterative cycle refers to steps 4 through 6 fig 2 and aims to determine an optimal p given a value of n if the convergence stopping criteria for p are not satisfied the inner loop is executed again i e l p increased by one for the new p increased by one such iterations continue until convergence criteria based on the accuracy metric are met the details for the criteria will be described in the next section 7 once the inner loop is finished the second bigger iterative cycle begins comprising steps 2 through 7 this outer loop includes the former inner loop determining optimal values of both hyper parameters for the fixed value of p determined in the first loop a similar decision is made as to whether other criteria for n are met if they are not the iterative algorithm goes back to step 2 with the new n increased by n i e l n increased by one new samples with size n are added to the existing samples of the experimental design then steps 2 through 7 are repeated until these criteria for n are satisfied note that each time a new n is chosen and the outer loop executes p is newly determined within the inner loop eventually both criteria must be satisfied to complete the sed pd algorithm optimal values of n and p are determined for each qoi 2 4 2 convergence stopping criteria a set of multiple convergence stopping criteria based on the error metric have been proposed to stop the loop iterations of the sed pd scheme this is similar to an optimization problem that can maximize the accuracy of the pce while minimizing the computational cost required for pce construction following the successive procedure of sed pd convergence criteria are applied twice to the selections of n and p respectively four criteria are proposed to ensure stopping the enrichment of p and n fig 3 the increase of p or n is stopped if any of the following four convergence criteria are satisfied 1 one can stop if the ε loo q o i value reaches a sufficiently small target error it is acceptable that the difference between two comparing models is negligible the threshold error ε th lower targeted in this study is set to 10 5 similar to the previous study blatman and sudret 2011 the optimal values are specifically determined by selecting the values of p and n at the moment when ε loo q o i l at iteration l l l p l n see fig 3 is smaller than the lower threshold the corresponding mathematical expression is 11 s t o p i f ε loo q o i l ε th lower 2 the first criterion is valid only with the expectation that the error decreases monotonically however due to the complexity of the model which is affected by many sources of uncertainty the first criterion may not be met within a finite number of iterations besides an excessive increase in the number of n and p does not mean that they always provide a better surrogate model which can lead to an increase in ε loo q o i called over fitting such a phenomenon can be avoided by addition of another criterion that is one can stop if the ε loo q o i increases in three consecutive iterations and ε loo q o i l 2 is smaller than ε th upper 12 s t o p i f ε loo q o i l 2 ε loo q o i l 1 ε loo q o i l a n d ε loo q o i l 2 ε th upper where ε loo q o i l 2 ε loo q o i l 1 and ε loo q o i l are the error estimates computed at the successive iterations of l 2 l 1 and l respectively to avoid instances where the iterations stop very early or the optimal ε loo q o i value is still large we also introduced another threshold ε th upper as a safeguard in this study the value of ε th upper is set to be 10 1 the optimal values are then determined as the p or n values at the iteration when ε loo q o i is the smallest for example in fig 3 p or n value at l 2 is selected 3 another possible case where the scheme will not converge is when the error is not small and rarely decreases by calculating the degree of reduction i e slope one can take into account divergence in such a case this can be stopped if the slope in eq 13 calculated using the errors estimated in three consecutive iteration steps is insignificant thus the third stopping criterion is 13 s t o p i f ε loo q o i l ε loo q o i l 1 ε loo q o i l 2 ε loo q o i l 1 ε th slope a n d ε loo q o i l 1 ε th upper where 0 05 is used as the value of ε th slope as in prior studies echard et al 2011 schöbi et al 2017 dubreuil et al 2018 like the second criterion the value of ε loo q o i is restricted to be smaller than ε th upper the p or n value is determined at the iteration when ε loo q o i is the smallest for example p or n values at l 1 are selected in fig 3 4 the fourth and final criterion is given in case that divergence or overflow can still occur even though the above three safety measures have been implemented according to the computational power employed the p and n values should be limited to avoid infinite iterations of the sed pd when the above three criteria do not work that is the fourth stopping criterion is 14 s t o p i f p p max o r i f n n max where a maximum degree of polynomials p max of 15 is used in this study the maximum number of experimental design n max is set to be p max 1 n x analogous to the total number of model evaluations when using the gaussian quadrature method sudret 2008 the p or n value is determined at the iteration when ε loo q o i is the smallest for example p or n values at l 1 not l max are selected in fig 3 3 experimental configurations all experiments were carried out in the vu gia watershed in central vietnam fig 4 the area of this watershed is 1679 8 km2 and it is characterized by a large difference in elevation ranging from about 30 m to 2100 m with mainly mountainous and hilly terrain the catchment is heavily influenced by the tropical monsoon climate with heavy rains occurring mainly from september to december greater than 2000 mm year not only because of the large amount of rain but also because of the topographic features this region has experienced severe floods and significant damage reported by the united nations development programme undp 1999 3 1 flood events and a hydrological model three flood events from the rainy season in 2016 were selected for verification and application of the surrogate filters precipitation data was observed at the thanh my and kham duc stations and discharge data at the outlet of the watershed at the thanh my station fig 4a all the hourly data available in this domain were taken into account and the data are provided by the vietnam national centre for hydro meteorological fig 4b the areal average of rainfall used for a hydrological model was computed through the thiessen method while the potential evapotranspiration was not considered due to its insignificant effects on flooding data assimilation experiments were performed by employing the nedbør afstrømnings model nam nielsen and hansen 1973 which is a conceptual lumped rainfall runoff model containing nine adjustable parameters and five model states given these parameters and states the model can simulate three pathways of flow i e overland intermediate and groundwater and control the amounts of water stored in the surface zone lower zone and routing components a description and feasible range of the parameters and states are listed in table 1 for a more detailed description of nam see o brien et al 2013 and dhi 2014 and for a summary see tran and kim 2019 and tran et al 2020 3 2 modeling procedure for the variant pce construction building the variant pces should be performed in real time for the present forcings at each time step the first task is to initialize the state vector and specify the parameters of the hydrological model zero initial states are assumed and parameters are sampled from the posterior distributions estimated by the generalized likelihood uncertainty estimation glue beven and freer 2001 for more details see section s 3 in supplementary material since a much smaller number of training samples e g 50 can make the pce successfully tran and kim 2019 the initial n of the experimental design x is given as the number of ensembles n pce of 10 in this type of construction real time forcings and observations are employed for the enkf assimilations then the sed pd scheme stops iterating if criteria for n are met otherwise it continues the iterations with the n increased by n 10 note that to construct the variant pces stochastically varying rainfall and discharge are not essential real data for the three events is directly employed four variant pces are built at each time step that is 51 50 and 34 variant pces are built for the first second and third flood events respectively 3 3 modeling procedure for the invariant pce construction the first task to constructing invariant pces is also to initialize the state vector and specify the parameters of the nam model this study initializes the ensemble of the states with zero and specifies the ensemble of the parameters with samples chosen randomly from the uniform prior distribution these ensembles start with the initial n n t n pce 100 100 10 000 a number of n filter evaluations are followed for rainfall forcings and streamflow observations as described in section 2 2 2 stochastic inputs of rainfall and discharge are preferred to build the invariant pces we generated the stochastic samples under the assumption that these two input variables followed a uniform distribution over bounded intervals the lower bounds of the possible ranges for observed rainfall and discharge were set to be zero while the upper bounds were subject to the domain in this study values of 50 mm hour and 7000 m3 s were employed for the upper bounds of rainfall and streamflow respectively these values were determined from the maximum hourly rainfall in data available since 2015 and an extreme corresponding to a 100 year return period the latter flood frequency analysis was made by applying the pearson type iii distribution to annual flood peaks for data from 1976 to 2016 then according to the sed pd scheme additional n filter evaluations are included if criteria for n are not met the n for the second next iteration becomes n n n 100 10 100 10 12 100 this size continues to grow until the criteria are satisfied note that each of the invariant pces is unique and can be applied to any event including the three events given 3 4 synthetic and real data assimilation experiments the first of three events was used as a synthetic experiment the objective of which is to judge the performance of certain data assimilation techniques whether evaluating the convergence of the parameters quantifying the parameter range adequately and minimizing the predictive uncertainty moradkhani 2008 serving as a control run this synthetic experimental dataset was generated through a free run using observed rainfall event 1 pre specified also referred to as true parameters in table 1 and discharges computed from the former two other flood events i e 2 and 3 were utilized for application of the proposed filters to real time flood forecasting in which the performance of the eight surrogate filters are compared and validated with the single and dual ensemble kalman filters all data assimilation experiments were performed with n da of 500 which was considered to be a rational ensemble size to adequately represent the uncertainty bounds moradkhani et al 2012 kim and ivanov 2015 kim et al 2015 tran and kim 2019 tran et al 2020 the initialization of the states given the ensemble size was simply set to be zero the specification of the parameters for the same size was performed by using the posterior distribution by glue for the real data experiment and by using the prior uniform distribution for the range given in table 1 for the synthetic experiment to achieve the most reliable ensemble prediction over the entire forecasting period it is necessary to assume noise for quantities that contain uncertainty in the data assimilation framework renard et al 2010 dechant and moradkhani 2012 in this study 500 perturbations were applied to the precipitation and streamflow observations in both synthetic and real data experiments to account for uncertainties similarly to previous da studies dechant and moradkhani 2012 moradkhani et al 2012 abbaszadeh et al 2019 specifically we assume a log normal error distribution with a relative error re u of 25 for precipitation the streamflow observation error is assumed to be normally distributed with a relative error re obs of 15 at each time step it is also assumed that the model parameters follow a random walk by adding a small amount of noise following a normal distribution with a relative error re θ of 1 in eq 2 3 5 evaluation measures for accuracy and efficiency to evaluate the accuracy and predictability of the proposed surrogate filters both deterministic and probabilistic measures were selected for deterministic metrics the nash sutcliffe efficiency nse in eq s 34 widely used to assess the goodness of fit of a model is computed for each ensemble member over the entire computational time t peak error pe which is often used to verify the ability to accurately predict flood peaks is computed by eq s 35 the ensemble forecasting results also can be evaluated through probabilistic measures the brier score bs which is a commonly used scoring rule for measuring the accuracy of probabilistic predictions brier 1950 is defined as the mean squared error of the probabilistic forecasts over the verification sample 15 bs 1 t t 1 t p t f p t obs 2 where p f is the forecast probabilities among n da ensemble reached a predefined flow threshold p t obs is the observed probability 1 if the event occurred and 0 if it did not which is obtained from the comparison of y t obs and the threshold in this study this threshold value is selected as the proportional rate of 90 of the observation peak the continuously ranked probability score crps measures the proximity of the forecast distribution and the measurement distribution at a single time step gneiting and raftery 2007 in this study the temporal mean of crps crps is used for comparison 16 crps 1 t t 1 t f y t f y t obs 2 d y where f y t and f y t obs are the empirical cumulative distribution of n da ensemble predictions y t i and the actual observation y t obs at time t respectively the value of crps is non negative and has a value of zero if two distributions are identical since a reliable forecast with an excessively high dispersion is not desired the spread can be considered this parameter is equal to the square root of the average ensemble variance over the evaluation period fortin et al 2014 liu et al 2019 and is non negative with the best value of zero it has the same unit as streamflow 17 spread 1 t t 1 t 1 n da 1 i 1 n da y t i y t obs 2 regarding the modeling efficiency runtime at each time step rt t and cumulative runtime rt cum t are established as 18 rt t rt build t rt run t n da 19 rt cum t t 1 t rt t where rt build t is the runtime needed for building a filter at each time step of the assimilation rt run t is the runtime to perform the filter for assimilation at each time step for one ensemble member the runtime rt build t consists of the time rt x t required to configure the experimental design x i e model evaluations and the time rt opt t required to determine the optimal hyper parameters and coefficients of pce the latter runtime is the summation of rt opt t q o i m for each qoi because a filter is made after pce construction over each qoi in contrast the former runtime chooses the largest time among all rt x t q o i m because the pce is built by recycling all the previously performed model evaluations i e it shares the experimental design with the largest n of all qois that is rt build t for the variant filters rt build t va is written as 20 rt build t rt build t va m a x rt x t q o i m m 1 n y f i l t e r m 1 n y f i l t e r rt opt t q o i m where m is an index for the number of pce outputs of the filter n y f i l t e r n y f i l t e r for suwf dual suwf supf and dual supf are n s 1 n s n p 1 n s 1 and n s 1 respectively regardless of whether the filters are variant or invariant surrogate filters note that because the variant surrogate filters need to re build at every time step of the assimilation rt build t va is subject to the time step t on the other hand rt build t for the invariant filters rt build in does not need the subscript t and is independent of time because their construction could be done before forecasting thus rt build in is similarly expressed as 21 rt build t rt build in m a x rt x q o i m m 1 n y f i l t e r m 1 n y f i l t e r rt opt q o i m 4 results 4 1 optimization of the pce hyper parameters hyper parameters n and p must be predetermined to construct pce for each qoi but their optimal values to maximize the performance of constructing pce are unknown here we present the results of the sed pd scheme which can be a guideline for other studies the results are shown in fig 5 including the convergence criteria used for stopping the scheme and the number of iterations needed for optimizing n and p table 2 presents the optimal values of n and p the error ε loo q o i at stopping and the building time these results are subject to vary depending on the surrogate solutions proposed but are significantly different between the variant and invariant pces the sed pd adopts four criteria for attaining the optimal values of n and p for the selection of p the second 57 in magenta or the first 28 in yellow stopping criterion is used for the variant pces that is over fitting predominantly happens or ε loo q o i smaller than the threshold of 10 5 exists the number of iterations l p is smaller and varies from 1 to 5 specifically 1 25 3 29 4 20 and 5 12 see fig 5 in contrast the third 87 in green in fig 5 or fourth 13 in cyan criterion is frequently used to construct the invariant pces that is the optimal p p opt q o i is largely determined when the consecutive values of ε loo q o i remain unchanged or the degree of polynomials reaches its maximum value of 15 this implies that it is difficult for the value of ε loo q o i to reach its ideal predefined value ε th lower the number of iterations l p to optimize p is generally greater than 5 with the most commonly identified numbers of iterations being 5 72 7 16 and 15 29 these results confirm that finding an optimal p when constructing vapces requires fewer iterations and is much faster than in making inpces for determining the optimal n of each qoi n opt q o i a similar approach using four criteria was made in building vapces the most commonly used criteria were 1 67 2 19 and 3 15 and the numbers of iterations l n required were only 1 48 or 3 30 these results indicate that the values of ε loo q o i easily reach the desired values so the l n is lower in contrast in constructing inpces the criteria used were 2 78 and 3 22 and the values of l n were mostly from 3 to 8 but ranged up to 23 in summary the results of the optimization of n and p demonstrate that it is much easier to identify appropriate n and p values in constructing vapces than inpces table 2 reports the values of n opt q o i p opt q o i ε loo q o i rt x q o i and rt opt q o i in constructing eight pces for each qoi the n opt q o i and p opt q o i values of the variant pces are smaller than 100 and 3 respectively and their ε loo q o i values are mostly smaller than 10 4 conversely the n opt q o i and p opt q o i values of the invariant pces are greater than 10 000 and 5 respectively and their ε loo q o i values are greater than 10 3 pces generated based on more sampling data i e larger n opt q o i and more complex models i e higher p opt q o i do not necessarily provide better results i e smaller errors furthermore the differences in the time required to implement the sed pd are evident the build times of the invariant filters are significantly greater than those of the variant filters by factors of approximately 2962 3027 263 and 263 times in the comparisons of insuwf versus vasuwf dual insuwf versus dual vasuwf insupf versus vasupf and dual insupf versus dual vasupf respectively see table 2 these results indicate that a more universal invariant pce built with enormous margins of all uncertain variables takes significantly more time than a specific variant pce in which all forcings and observations are confirmed in real time 4 2 data assimilation of the synthetic experiment synthetic experiments are often employed to examine whether parameters converge satisfactorily whether the range of parameters is adequately quantified and whether predictive uncertainty is minimized moradkhani 2008 first we ensured that the model parameters updated from dual data assimilation can converge to the predefined parameter values for event 1 fig 6 shows the time evolution of posterior distributions of nine parameters for five dual filters the most easily identifiable parameters are cqof and ck12 while the rest of the parameters could not reduce the large uncertainty range over time as also inferred from the results of glue and sensitivity analysis in section s 3 all dual filters except for dual insuwf successfully provided the posterior distribution of these parameters that almost converged to the predefined values at the end stage of assimilation compared to the tendency of dual enkf to converge to the predefined parameters the dual variant filters dual vasuwf and dual vasupf can accurately update the posterior parameters in terms of convergence speed and degree on the other hand the dual invariant partial filter dual insupf provides a slightly different converging tendency wherein the magnitude of the uncertainty of ck12 is larger than dual enkf and the convergence is slower specifically the mean value of ensemble members of ck12 black line in fig 6 converges to its predefined value at about 20 h in dual enkf as well as both dual variant filters but it takes an additional 7 h in dual insupf the other dual invariant whole filter dual insuwf completely fails to estimate the parameter posterior distribution because the influential parameters converge to a lesser extent and the identified posterior distributions do not converge to the predefined values fig 6d ensemble streamflow predictions and their error measures were compared for ten filters in the synthetic experiment over event 1 in fig 7 1 deterministic and stochastic error measure values in fig 7b d indicate that all surrogate filters are functioning properly to improve the accuracy of streamflow predictions the results of nse pe bs crps and spread when using da are significantly better than those without da 2 the single and dual surrogate filters were compared clearly demonstrating the effect of simultaneously updating the states and parameters on the accuracy all dual filters except for dual insuwf produce superior results to single filters and provide almost the same results as the original dual enkf for example the performance of four dual filters increases by at least about 8 65 48 68 and 51 for the ensemble median of nse nse the ensemble median of pe pe bs crps and spread respectively the interquartile uncertainty range of nse is also reduced to 0 02 0 07 in dual filters from 0 03 to 0 39 in single filters and that of pe is reduced to 2 10 in dual filters from 10 to 30 in single filters 3 dual insuwf showed no performance improvement for nse and pe compared to insuwf while there were improvements of about 36 and 22 for crps and spread respectively dual insuwf is less accurate than dual enkf while insuwf has more accurate prediction performance than enkf in summary the analyses above in the synthetic experiment indicate that all of the four single filters insuwf insupf vasuwf and vasupf worked similarly to the original single filter enkf in terms of accuracy for streamflow forecasting furthermore three of the four dual filters dual insupf dual vasuwf and dual vasupf showed equivalent performance to the original dual filter dual enkf in terms of increased accuracy and parameter posterior estimation however dual insuwf failed to converge to predefined parameters during the assimilation process nor did it improve predictive performance 4 3 data assimilation of the real experiment in this section two data assimilation experiments using real rainfall and streamflow observations were conducted to further examine the performance of proposed filters in a real time forecasting framework the forecasting results over events 2 and 3 are reported from figs 8 11 in general the results of the real data assimilation experiment have equivalent conclusions to those of the synthetic experiment qualitative inspections for observation consistency and uncertainty interval from figs 8 and 9 reveal that all surrogate filters provided similar results to enkfs and dual filters are more accurate and have narrower uncertain ranges than single filters since it is evident that streamflow predictions were improved by using data assimilation we omitted the comparison for the absence of da and showed the comparison between filters regarding the reliability of surrogate filters three paired comparisons were performed based on three standards of surrogate filter construction described in section 2 2 whole versus partial variant versus invariant and single versus dual such comparisons can be done easily with the help of a relative difference metric δ between the values of the evaluation metrics m e t r i c including nse pe bs crps and spread this difference metric is defined in the unit of percentage as 22 δ m e t r i c s u f s 1 m e t r i c i d e a l m e t r i c s u f s 2 m e t r i c i d e a l m e t r i c s u f s 1 m e t r i c i d e a l 100 where s u f s 1 denotes the former group filters i e whole variant and single filters while s u f s 2 denotes the latter filters i e partial invariant and dual filters m e t r i c i d e a l represents the ideal perfect values of the metrics of nse pe bs crps and spread that is 1 0 0 0 and 0 respectively the positive or negative values of δ indicate that the prediction results of the latter group filters are more or less accurate than those computed by the former filters the results of δ for the three paired comparisons are illustrated in fig 10 and also reported in table s 1 first the results of δ between whole and partial filters are mostly negative revealing that whole filters outperform partial filters by up to 203 117 115 41 and 44 for nse pe bs crps and spread respectively over both events 2 and 3 the only exception for this tendency can be found in dual insuwf which does not show an obvious superiority over dual insupf as an example for event 2 nse crps and spread of dual insuwf are inferior i e positive δ values to those of dual insupf by about 31 19 and 29 respectively while pe and bs are improved i e negative δ values by about 34 and 59 respectively fig 10 regarding the second paired comparisons of building systems between variant and invariant filters three out of four invariant filters have better performance than the corresponding variant filters fig 10 in particular the values of δ for all metrics have positive values ranging up to 60 45 27 79 and 37 for nse pe bs crps and spread respectively conversely for the forecasting results of the remaining invariant filter dual insuwf i e blue in fig 10 it is hard to conclude which building systems are superior the performance results are mixed depending on the metrics e g results of pe are 68 worse than those in dual vasuwf while those of crps are 27 better for event 3 third convincing evidence was found that dual filters outperform single filters as also seen in section 4 2 the dual updates of parameter and state significantly enhance the forecasting results and narrow their uncertainty spreads quantitatively the difference metric results of dual filters are improved by up to 9 48 34 54 and 50 over event 2 for nse pe bs crps and spread respectively for event 3 these improvements are more substantial with improvements of up to 38 69 90 56 and 52 respectively fig 10 in summary the dual vasuwf and dual insupf filters have proven to be superior to the others in providing accurate forecasting results followed by dual vasupf with prediction results closest to the above two filters the above comparisons were made for prediction results for short lead times lt of 1 h as predictions for greater lead times are usually in demand additional analysis was performed to examine whether the surrogate filters can provide reliable and accurate streamflow predictions for larger lead times of 1 6 h as expected the forecasting performance for ten filters decreases with the lead time decreasing for all metrics such a tendency is clearly shown in fig s 2 where the evaluation metrics at each lead time are compared with those at the lead time of 1 h for ten filters specifically in event 2 the ranges of degradation of nse pe bs crps and spread at a lead time of 6 h compared to those at lead time of 1 h are 181 1430 0 469 0 853 51 154 and 46 152 respectively in event 3 these ranges are 235 1206 105 395 115 585 51 203 and 66 196 interestingly some filters all single filters and dual insuwf have much worse predictability with respect to lead time while all dual filters except for dual insuwf are not as good but better than the former filters in order to compare the degree of performance deterioration for lead time among 10 filters another relative difference metric γ is computed as 23 γ m e t r i c b e s t m e t r i c i d e a l m e t r i c s u f s l t m e t r i c i d e a l m e t r i c b e s t m e t r i c i d e a l 100 where m e t r i c s u f s l t denotes the evaluation metric of a surrogate filter at a lead time lt that is varied from 1 to 6 h m e t r i c b e s t represents the best of the 60 values corresponding to 10 filters 6 different lead times closest to the m e t r i c i d e a l the negative values of γ indicate the degree of performance deterioration as compared to the best value compared to the best performance of nse its performance degradation at the longest lead time of 6 h stretches from 293 714 and 626 in dual vasuwf dual vasupf and dual insupf respectively up to 1724 in dual insuwf such a degradation is highest in nse and then in bs and pe fig 11 another interesting phenomenon is that the performance between the 10 filters is not very different for a lead time of 1 h but the performance difference between the filters increases significantly as the lead time increases for example the performance differences of γ at 1 h lead time are about 216 233 146 115 and 126 for nse pe bs crps and spread respectively at a lead time of 6 h the differences extend up to 1724 606 853 343 and 288 fig 11a filters that perform well at longer lead times are dual vasuwf dual insupf and dual vasupf which means that filters that performed better at a lead time of 1 h outperform other surrogate filters at longer lead times 4 4 evaluation of the superiority of computational performance to enkf fig 12 demonstrates the superiority of sufs to enkfs in terms of efficiency by computing the cumulative and instantaneous runtime rt cum t and rt t of ten filters for event 2 from fig 12a displaying the cumulative runtime versus time for n da of 500 it can be seen that the calculation speed of insufs is much faster than that of enkfs whereas the speed of vasufs is slightly faster for example at the end of forecasting t 50 the best filter dual insupf is about 500 times more efficient than dual enkf since the building time rt build t of both of these two filters is equal to zero the difference of 500 times is the same as the difference in the running time rt run t of the two filters i e about 4 6 10 4 and 0 23 secs see the slope of eq 18 written in the legend of fig 12b comparing the runtime of vasufs to enkfs is the case when the additional runtime required for building the filters rt build t offsets the efficiency of the runtime in running the filters rt run t when n da is small the efficiency improvement of dual vasupf and dual vasuwf to dual enkf is relatively low e g only 4 and 6 times faster for n da 500 but as n da gets larger this improvement becomes much greater e g 65 and 100 times faster for n da 10 000 5 discussion 5 1 is a partial surrogate approach more promising the primitive rationale of the partial approach was to individually replace the time consuming processes e g eqs 1 3 and 5 in the original filter model the rest of the enkf processes eqs 4 and 6 which take less time but play an important role remain the same since kalman gain k in that partial filter was directly calculated and reflected in updating the parameters and states it was possible to present more accurate results than the conventional whole approach that blackboxed this process thus a remarkable question to be addressed is how to select the process to be replaced among processes included in original filters models when designing a surrogate filter model considering the trade off between the time taken to execute the process and its physical importance a flexible surrogate model design will be possible what are the central advantages of the partial approach in terms of efficiency other than the aforementioned accuracy improvement the partial approach can effectively reduce the number of dimensions of the pce input in this study the total number of dimensions n x was n s n p n u in the partial filter while n s n p 2 n u n obs the number of observations in the whole approach the number of dimensions is reduced by n u n obs from 17 whole to 15 partial although the decrease in the number of dimensions 2 may seem small its contribution from the perspective of pce coefficients is by no means small that is the number of pce coefficients decreases significantly from 26 334 to 15 504 40 reduction estimated by the n x and a common p of 5 from eq s 27 thus resulting in the smaller size of experimental design e g from 90 000 to 40 000 for building dual insufs see table 2 if forcings and observations with different values for space are considered i e if n u and n obs are not equal to 1 such a reduction effect by the partial approach will be even greater how can the partial approach be extended to a fully distributed model with much larger dimensions rather than a lumped model in this case the total number of dimensions is as large as the total dimensions of the lumped model multiplied by the number of computational cells n cell that is n x n s n p 2 n u n obs n cell in the whole approach note that such a number is incredibly too high a pragmatic solution by the partial approach is to create independent surrogate pces as many as n cell it is enabled if each cell is treated as a separate process and thus is superseded with an independent pce this ultimately has the effect of turning the problem of generating one pce with the entire dimension into a problem of generating several n cell pces with dimensions of n x n cell even more productive solution is enabled by combining this partial approach with karhunen loève kl decomposition karhunen 1946 where it can lump cells with high correlation between model outputs in space or time into one group once the spatially correlated groups are identified the partial approach is then employed to construct a pce for that group cells surely results simulated by the constructed pce can be pertained only to the portion of domain determined previously 5 2 is building a universal pce achievable and consequential a well known characteristic and challenge of data driven models is that they cannot be applied to domains outside the scope of trained data basically data driven models have only one unique model suitable for each training data space likewise pce also has one optimal model for each data set experimental design if new data needs to be taken into account for future forecasting as with most studies in the past sargsyan et al 2014 bazargan et al 2015 wang et al 2018 dwelle et al 2019 hu et al 2019 tran and kim 2019 zhang et al 2020 it is natural to create a new pce model like the time variant approach however this approach cannot be applied when measurement or forecasted data is scarce and even if the data is sufficient there is a very critical disadvantage that a time consuming operation must be repeated whenever data is altered one of the goals of this study was to determine whether a universal invariant pce that could be applied to a wide range of rainfall events could be generated it is apparent that the higher the degree of generalization of rainfall events represented by the experimental design the more the pce can be applied to various conditions an effortless way to expand the scope of the data space i e the invariant approach was proposed and verified based on the results of the synthetic and real experiments a universal surrogate filter using the invariant approach dual insupf is the most efficient filter and one of the three surrogate filters that provide the most reliable predictability these results confirm that a single universal pce could be constructed across a wide range of random data space e g for rainfall and streamflow and applied to new input space this idea of using a random input generator allows for creating as many hypothetical events as possible that can happen in that region this does not require any specific historical event data so it has the advantage of being easily applied even if there is no historical data what are the practical implications of the universal invariant filter while many studies have highlighted the benefits of pce in saving computational costs most studies have been limited to hindcasting based on historical data e g focusing on uncertainty quantification or sensitivity analysis wu et al 2014 meng and li 2018 miller et al 2018 dwelle et al 2019 to the best of our knowledge no surrogate model or filter was applied to real time flood forecasting because there is a downside of having insufficient time to rebuild a new pce at each computation step for inputs provided in real time therefore the idea of making a unique surrogate filter during non flood season can bridge the gap between hindcasting and real time forecasting 5 3 is an advanced sed pd necessary in constructing pce in this study we propose a sed pd scheme an advanced version of sed introduced by blatman and sudret 2010 that was employed to determine the optimal values of n and p in estimating pce coefficients as a result of investigating the accuracy errors below and in the literature hu and youn 2010 sargsyan et al 2014 diaz et al 2018 dwelle et al 2019 torre et al 2019 we found that it is inappropriate to apply the sed originally developed for finite element problems directly to hydrologic problems of interest here we underscore the limitations of sed and the necessities of sed pd fig 13 clearly shows the difference between the hypothetical results obtained using sed and those from sed pd in terms of evolution of the error over runtime the results of sed were derived specifically for the vapce1 and inpce1 constructions of qoi y the p values were fixed from 1 to 7 and the maximum iterations for n l n m a x were limited to 1000 and 100 for vapce1 and inpce1 respectively there was a single stopping criterion the first criterion where the lower threshold ε th lower is 10 5 interestingly in both vapce1 and inpce1 ε loo q o i could not reach to the threshold value which implies that one cannot create any pce that satisfies the desired condition within a limited time when using sed apparently such an optimization using sed should be amended three possibilities are discussed for why sed pd is necessary in optimizing the hyper parameters n and p first the use of a single criterion cannot guarantee convergence if the target error is not reached errors computed are no longer reduced even if a large number of iterations e g up to 1000 and 100 of l n m a x equivalently 10 000 and 1 188 100 of n for vapce1 and inpce1 in fig 13a and c have been implemented compared to the sed pd case sed has not been able to obtain the desired convergence even after spending an enormous amount of time or has to invest an almost infinite amount of time until convergence see sed vs sed pd comparisons when stopping iterations rt build t 50 va q o i y are infinite vs 7 92 secs for vapce1 in fig 13a and rt build in q o i y are infinite vs 2 81 103 secs for inpce1 in fig 13c on the other hand sed pd can determine the optimal n and p quickly through the four criteria proposed ensuring system convergence and computational stability the second possibility is related to whether or not to include the optimization process of the p value in sed since the optimal value of p is unknown a common way to reveal an acceptable n value in sed is to start from p 1 and increase the value by 1 until the optimal n is determined as in fig 13a and c or if one can assume an appropriate p value the optimal n for that random p value can be determined since the optimal p value that causes the smallest error can vary from case to case for example optimal p is determined as 6 when l n 2 for vapce1 and as 5 when l n 2 for inpce1 see the cyan empty circles in fig 13b and d sed always requires additional analysis of similar form to fig 13a and c however in sed pd dual optimizations for both p and n are adopted such that the optimal value of p is automatically identified at each iteration l n like the blue empty circles in fig 13b and d such a dual optimization system ultimately improves the existing approach of sed by which the p value had to be selected ad hoc or by trial and error note that the performance of sed is highly influenced by the pce types and the lower threshold ε th lower see fig 13 in particular the success or failure of the sed optimization process depends on the latter threshold value therefore one might wonder how the optimization result will change if a larger value is chosen for ε th lower of sed in this regard fig 14 demonstrates the effects of the lower threshold ε th lower on the runtime for building the pce the larger the threshold value the sooner sed can stop and the higher the probability of attaining an optimal n value the empty red squares in fig 14 indicate that there is no probability to get its optimum that satisfies the criterion within the maximum number of iterations given p in order to avoid sed failure a feasible threshold greater than the minimum value of ε loo q o i say about 1 5 10 4 for vapce1 and about 5 5 10 2 for inpce1 must be selected in advance then a question arises of how to pre determine the value of ε th lower for each pce construction a practical and general answer to this question is to perform an additional analysis similar to fig 14 that uses trial and error with different thresholds this analysis is however unnecessary in sed pd 5 4 is the surrogate filter broadly applicable to geophysical science surrogate filter approaches proposed can be applied to various geophysical fields that require data assimilation to improve the accuracy and efficiency of real time predictions all da techniques generally consist of prediction step predicting the values of current state variables given information at the previous time step and update analysis step updating the predictands by calculating the error between the predicted values and the currently observed values although the da techniques differ in how they calculate and analyze the error in detail the fact that states parameters and forcings are transited to the predictions through a propagator e g eqs 1 3 and 5 is identical since the partial filter proposed replaces these equations it can be applied seamlessly to other da techniques without much modification obviously the whole filter can be generated only with evaluation results of the original filter so there is no limitation in applying it to other da applications moreover these approaches are all based on any geophysical model that should be used for the prediction and update thus the more complex governing equations the model contains the more the computational effect using the surrogate filter will be maximized 6 summary and conclusion the main objectives of this study were 1 to present a robust and efficient data assimilation technique in the framework of hydrologic flood forecasting embracing the merits of the ensemble kalman filter enkf and polynomial chaos expansion pce in order to produce reliable streamflow predictions with significantly reduced runtime 2 to underscore the advantages of the novel partial and invariant approaches in making a surrogate filter by investigating the accuracy and efficiency of the eight surrogate filters categorized according to different surrogate structures whole and partial building systems variant and invariant and assimilating targets single and dual 3 to propose an advanced dual optimization system with multiple stopping criteria named sequential experimental design polynomial degree sed pd that simultaneously determines the hyper parameters of n and p necessary for the pce construction the following are the principal results and conclusions of this study the sed pd scheme has evolved into a dual optimizing system and requires four stopping criteria dealing with two issues that originally occurred in sed during pce construction in particular the inherent assumption of sed that its accuracy error should decrease monotonically with iterations is not always satisfied thus the multiple criteria were needed to ensure convergence of the optimization process and avoid the possibility of infinite iterations additionally the exclusion of polynomial degree from the optimization process leads to a practical issue wherein the value of polynomial degree had to be selected ad hoc or by trial and error the dual optimization system proposed resolves this existing issue of sed a comprehensive investigation into how to configure a surrogate filter has been carried out conventionally the whole replacing entire processes of the original filter and variant requiring reconstruction at each time step approaches have been employed however we have confirmed that this traditional approach deteriorates forecasting performance in terms of accuracy and efficiency a novel partial replacing part of the original filter and invariant valid for whole time periods approach is proposed for the filter construction which outperforms the conventional approach the partial approach can directly reduce the number of dimensions by turning the problem of generating one pce with the entire dimension into a problem of generating several pces with a reduced dimension the invariant approach making a unique surrogate filter during non flood season can bridge the gap between hindcasting and real time forecasting specific results from the synthetic and real data assimilation experiments are 1 dual sufs except for dual insuwf successfully mimic the convergence characteristics of dual enkf in updating model parameters 2 the comparing results of eight surrogate filters show that dual vasuwf dual vasupf and dual insupf illustrate the most superior performance equivalent to that of dual enkf 3 these three filters perform relatively well at longer lead times as well although forecasting performance decreases with lead time for all filters regarding efficiency the use of surrogate filters dramatically improves the computational performance in particular dual vasuwf dual vasupf and dual insupf are about 6 4 and 500 times faster than dual enkf respectively when comparing the cumulative runtime rt cum t over event 2 with the ensemble size of 500 this efficiency gain is more pronounced when original filters being replaced are time consuming or larger ensemble sizes are employed since the calculation speed of the generated pce is related to the time of the arithmetic operation level it is always fast regardless of how complicated and time consuming the original filter is based on in depth analyses the dual invariant partial filter i e dual insupf is the best one being superior in terms of usefulness effectiveness and robustness as an enkf replacement although no application has yet been made to more comprehensive experiments beyond the scope of configurations of this study the proposed surrogate filter will be a promising alternative tool for performing computationally intensive data assimilation in high dimensional problems ultimately it not only provides equivalently accurate forecasting results in real time but also significantly reduces the computational burden of larger ensemble predictions credit authorship contribution statement vinh ngoc tran conceptualization methodology formal analysis investigation visualization writing original draft jongho kim conceptualization validation writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the 2021 research fund of university of ulsan we acknowledge the uncertainty quantification group uqlab of eth zurich for sharing open source algorithms appendix a denotation of eight surrogate filters the eight surrogate filters proposed fig 1 consist of 2 2 2 subcases whole or partial variant or invariant single or dual denotation of the filters are described below the single variant surrogate whole filter vasuwf has the same mathematical form as eq 7 the entire set of processes of the enkf is replaced with a first variant pce named vapce1 where va suwf vapce 1 a 1 x t i y t i va suwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 2 x t i y t i va pce 1 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the dual variant surrogate whole filter dual vasuwf has the same mathematical form as eq 8 the entire set of processes of the dual enkf is replaced with a second variant pce vapce2 where dual vasuwf va pce2 a 3 x t i θ t i y t i dual va suwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 4 x t i θ t i y t i va pce 2 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the single variant surrogate partial filter vasupf has the same mathematical form as eq 7 however the process of computing x t i in the latter enkf is replaced with a third variant pce vapce3 and the process of computing y t i is replaced with a fourth variant pce vapce4 where vasupf includes vapce3 and vapce4 a 5 x t i y t i va supf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 6 x t i va pce3 x t 1 i θ t 1 i u t 1 i w t 1 i i 1 n da a 7 y t i va pce4 x t i θ t i u t i i 1 n da the dual variant surrogate partial filter dual vasupf has the same mathematical form as eq 8 however the process of computing x t i in the latter dual enkf is replaced with the third variant pce vapce3 as shown in eq a 6 and the two processes of computing y t i are replaced with the same fourth variant pce vapce4 as in eq a 7 a 8 x t i θ t i y t i dual va su p f x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da another four invariant filters are set up similarly to vasufs except for using the time invariant pce inpce the fifth filter single invariant surrogate whole filter insuwf also has the same mathematical form as eq 7 the entire set of processes of the enkf is replaced with an first invariant pce named inpce1 where in suwf in pce1 a 9 x t i y t i insuwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 10 x t i y t i in pce1 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the dual invariant surrogate whole filter dual insuwf has the same mathematical form as eq 8 the entire set of processes of the dual enkf is replaced with an second invariant pce inpce2 where dual insuwf in pce2 a 11 x t i θ t i y t i dual in suwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 12 x t i θ t i y t i in pce2 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the single invariant surrogate partial filter insupf has the same mathematical form as eq 7 however the process of computing x t i in the enkf is replaced with an third invariant pce inpce3 and the process of computing y t i is replaced with an fourth invariant pce inpce4 a 13 x t i y t i in supf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 14 x t i in pce3 x t 1 i θ t 1 i u t 1 i w t 1 i i 1 n da a 15 y t i i n pce4 x t i θ t i u t i i 1 n da the dual invariant surrogate partial filter dual insupf has the same mathematical form as eq 8 however the process of computing x t i in the dual enkf is replaced with a third invariant pce inpce3 as in eq a 14 and the two processes of computing y t i are replaced with the same fourth invariant pce inpce4 as in eq a 15 a 16 x t i θ t i y t i dual in supf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126367 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
4574,data assimilation plays an essential role in real time forecasting but demands repetitive model evaluations given ensembles to address this computational challenge a novel robust and efficient approach to surrogate data assimilation is presented it replaces the internal processes of the ensemble kalman filter enkf with polynomial chaos expansion pce theory eight types of surrogate filters which can be characterized according to their different surrogate structures building systems and assimilating targets are proposed and validated to compensate for the potential shortcomings of the existing sequential experimental design sed an advanced optimization scheme named sequential experimental design polynomial degree sed pd is also advised its dual optimization system resolves the issue of sed by which the value of the polynomial degree had to be selected ad hoc or by trial and error its multiple stopping criteria ensure convergence even when an accuracy metric does not monotonically decrease over iterations a comprehensive investigation into how to configure a surrogate filter indicates that the new partial replacing part of original filters and invariant valid for entire time periods approaches are preferred in terms of accuracy and efficiency which helps directly reduce the number of dimensions and bridge the gap between hindcasting and real time forecasting of the eight filters the dual invariant partial filter performs best with equivalent accuracy to dual enkf and about 500 times greater computational efficiency ultimately this proposed surrogate filter will be a promising alternative tool for performing computationally intensive data assimilation in high dimensional problems keywords surrogate filter data assimilation polynomial chaos expansion ensemble kalman filter real time forecasting sequential experimental design polynomial degree 1 introduction making accurate and timely predictions of floods in real time is a major task in hydrology moradkhani and sorooshian 2008 however it suffers from inherent difficulties due to epistemic and aleatoric uncertainties associated with future conditions of rainfall forcing initial and boundary conditions and model parameters beven 1989 ajami et al 2007 kim et al 2016a 2016b beven et al 2018 dwelle et al 2019 as the development of in situ or remote sensing techniques over several decades makes it possible to collect real time observation data assimilation da has proven to be one of the most effective ways to improve the performance and quantify the uncertainty of real time predictions liu et al 2012 the central idea of da is to find a way to reduce the bias of hydrological model states and or parameters sequentially by incorporating real time observations into pre forecasted results evensen 1994 clark et al 2008 moradkhani and sorooshian 2008 at present da techniques are becoming more and more sophisticated from simple rule based direct insertion to advanced smoothing and sequential techniques liu et al 2012 despite the effectiveness of data assimilation the computational burden required to perform model evaluations in real time remains an obstacle liu et al 2012 houtekamer and zhang 2016 bannister 2017 loos et al 2020 since da includes the process of predicting and updating states and model outputs the number of model evaluations should be carried out multiple times compared to predicting only once when da is not applied if a model takes a lot of computation time this problem can become even more critical examples are when running hydrological models coupled with the multi dimensional governing equations of navier stokes marshall et al 1997 giraldo and restelli 2008 tossavainen et al 2011 saint venant kim et al 2012a 2012b richards maxwell et al 2007 kollet et al 2010 and hairsine rose kim et al 2013 kim and ivanov 2014 on atmosphere surface subsurface and surface erosion respectively their cpu runtimes required for a 1 day simulation generally reach up to the order of days furthermore most da techniques use ensemble representations for the covariances of forecast e g streamflow and analysis error of model states and or parameters maintaining a larger set of ensembles for initial states model noises and perturbed observations helps reduce sampling errors that can occur when the state and parameter variables are non gaussian and non linear evensen 2003 li and xiu 2008 liu et al 2012 slivinski and snyder 2016 bannister 2017 the size of the ensemble can be at least o 10 2 to more than o 10 8 houtekamer and zhang 2016 resulting in a higher computational barrier this is indeed not desirable in situations such as flood forecasting where real time decisions are needed the use of surrogate models could be a solution to cope with this concern which has attracted attention recently and used widely in many research areas to mimic nonlinear dynamic models laloy et al 2013 dwelle et al 2019 tran et al 2020 zhang et al 2020 this surrogate model performs thousands of simulations in seconds resulting in improved computational efficiency that dramatically reduce cpu runtime razavi et al 2012 asher et al 2015 mohanty 2015 the most common methods used to build surrogate models include genetic programming support vector machines svm artificial neural networks ann gaussian process emulation gpe also called kriging and polynomial chaos expansion pce simpson et al 2001 rajabi 2019 in particular pce has shown its merit and attractiveness in recent studies dwelle et al 2019 rajabi 2019 tran et al 2020 wang et al 2020 and it turns out to be more effective than the other data driven methods razavi et al 2012 rajabi 2019 torre et al 2019 for example pce performs better than the data driven models in terms of accuracy e g ann or svm when applied to small training sets and minimal configurations torre et al 2019 another merit of using pce occurs when predicting extreme events beyond the boundaries of training data flood and kartam 1994 minns and hall 1996 tokar and johnson 1999 rare events can be captured more completely because pce is built based on high fidelity samples supervised by physical models schöbi et al 2017 dubreuil et al 2018 tran et al 2020 third pce can be fitted very fast regardless of the size of training data unlike gpe and svm that are prone to computational demands for large training sets razavi et al 2012 last pce can facilitate global sensitivity analysis by performing only simple arithmetic on the coefficients of the already constructed pce instead of implementing additional model evaluations sudret 2008 dwelle et al 2019 due to its advantages pce has been used extensively in many types of hydrological problems from simple to complex e g sochala and le maître 2013 sargsyan et al 2014 wang et al 2017 dwelle et al 2019 tran and kim 2019 tran et al 2020 in the literature conventional ways of constructing pce are to build a single pce that can mimic the entire model process for each computational time step however these are problematic when tackling a high dimensional problem with a large number of uncertain parameters states its pce construction may be challenging due to the exponential increase in the number of pce coefficients blatman and sudret 2010 sargsyan et al 2014 konakli and sudret 2016 dwelle et al 2019 tran et al 2020 if one provides necessary design sampling points to have substantial and sufficient search space for all the dimensions that points for the model evaluation could be overly large advanced techniques such as the fractional factorial design and analysis wang et al 2015 the least angle regression blatman and sudret 2011 and the bayesian compressive sensing sargsyan et al 2014 have been able to solve some of the high dimensional 80 dimensions problems by calculating coefficients only for the most sensitive pce terms that have significant impacts on the model response but dealing with a larger dimension is still intricate additionally when making a real time prediction the conventional approach requires building a new pce at every time step prior to forecasting wang et al 2018 hu et al 2019 tran et al 2020 from the context of real time flood predictions that should be provided within a very short time usually less than an hour generating pce every time is a huge burden therefore finding alternative ways to reduce the dimension or to avoid the recurring pce construction is the right direction another issue of pce construction is that to mimic the original model and yield a reliable outcome for a wide range of conditions pce should be trained through as many training sets called experimental design x as possible schöbi et al 2017 choosing a suitable size for the experimental design is also a challenge razavi et al 2012 in order to circumvent this problem blatman and sudret 2010 proposed a sequential experimental design sed scheme to limit the size of the experimental design when constructing the pce minimizing its building time specifically the size of the experimental design n one of two important parameters is increased until a given statistic for computing the error between the surrogate and original models reaches a target value this scheme allowed us to successfully determine the size of x however the order of the polynomial p the other parameter that directly affects the performance of the pce dwelle et al 2019 tran and kim 2019 was not considered in that sed scheme the value of the polynomial degree had to be selected ad hoc or by trial and error additionally the sed scheme uses only a single convergence criterion for a relative error e g leave one out cross validation error ε loo and sets a small target value e g 10 5 to define acceptance level however its inherent assumption that the relative error should decrease monotonically as n or p increases is not always satisfied hu and youn 2010 sargsyan et al 2014 diaz et al 2018 dwelle et al 2019 torre et al 2019 the criterion proposed by the sed scheme may not reach a small target for problems where the error does not decrease continuously and thus infinite iterations may occur we need to investigate whether this criterion is appropriate for flood simulations and how to modify the scheme if it is not in this study we present a robust surrogate data assimilation approach based on polynomial chaos expansion theory this approach includes novel solutions to significantly reduce the computational cost of data assimilation and to effectively determine the optimal the size of the experimental design and the order of the polynomial of pce construction it is organized as follows eight filters replacing the ensemble kalman filter are developed and necessary modifications to the sed scheme are presented in section 2 from the synthetic and real experimental setups in section 3 the performance of the proposed surrogate filters is evaluated in section 4 discussions and conclusions drawn from comprehensive analyses continue in sections 5 and 6 respectively 2 methodology 2 1 single and dual ensemble kalman filters since the ensemble kalman filter enkf has become the most broadly used da technique in many discipline due to its ease of implementation in solving diverse da conundrums weerts and el serafy 2006 clark et al 2008 liu et al 2012 pathiraja et al 2018 tran et al 2020 enkf was chosen as an original filter to be substituted in this study both single and dual enkfs were used to perform the experiments both filters have in common that they update model states at each time step the main difference is whether these filters update model parameters because the internal structure and principles of enkfs have already been described in detail in the literature this study will briefly address the key equations that are necessary to describe the surrogate filter we will propose later for more details readers are referred to moradkhani et al 2005 or section s 1 in the supplementary material regarding a nonlinear deterministic or statistical model on discrete time domains a transition equation for its state x is described by 1 x t i f x t 1 i θ t 1 i u t 1 i w t 1 i i 1 n da where x t i is the i th ensemble state predicted at time t and x t 1 i is the i th state updated at time t 1 the size of x t is n da n s with n da ensemble members and n s model states θ t 1 i is the i th ensemble parameter updated at time t 1 and θ t has a size of n da n p where n p is the number of model parameters u t 1 i is the i th ensemble forcing at time t 1 which is generated following a log normal distribution with the mean equal to the actual forcing u t 1 and covariance e t 1 u at time t 1 in this study e t 1 u is assumed by using a relative error in forcing re u and u t 1 i e e t 1 u re u u t 1 the size of u t 1 i is n da n i with n i forcings propagator f for computing the model states can be any hydrological model w t 1 i representing the model structure uncertainty is the i th model error at time t 1 assuming that model parameters also follow a random walk the i th ensemble parameters at time t are treated by adding gaussian noise τ t 1 i with covariance e t 1 θ to θ t 1 i moradkhani et al 2005 2 θ t i θ t 1 i τ t 1 i τ t 1 i n 0 e t 1 θ where e t 1 θ is assumed by multiplying the relative error in parameters re θ and the variance of ensemble parameter distribution at time t 1 θ t 1 the i th prediction model output at time t y t i is the function of the model states parameters and forcings 3 y t i h x t i θ t i u t i where h is a propagator for computing the model outputs streamflow in this study and can also be a hydrological model that includes nonlinear relationships the i th ensemble parameters at time t θ t i are corrected by using the kalman gain k t θ and the i th observations at time t y t obs i 4 θ t i θ t i k t θ y t obs i y t i where details of how to evaluate the kalman gain k t θ are provided in section s 1 of the supplementary material y t obs i is a perturbed observation due to measurement noise following a normal distribution with mean equal to the actual observation y t obs at each time t and a predefined or assumed covariance e t obs that is computed based on a relative error in observation re obs and observation y t obs i e e t obs re obs y t obs with these updated ensemble parameters θ t i the prediction is updated once more with an equation similar to eq 3 5 y t i h x t i θ t i u t i finally the i th ensemble model states that at time t x t i are corrected by using the kalman gain k t x and perturbed observations 6 x t i x t i k t x y t obs i y t i where details of how to evaluate the kalman gain k t x are also illustrated in section s 1 of the supplementary material the equations above from eqs 1 6 all correspond to the dual enkf for the single enkf all the equations are identical except for eqs 2 4 and 5 the noise parameter in eq 2 is disregarded eq 4 is assumed as θ t i θ t i and eq 5 is then simplified to y t i y t i combining the above six equations the final form of enkfs can be expressed as 7 x t i y t i e n k f x t 1 i θ t 1 i u t 1 i u t i y t obs i 8 x t i θ t i y t i d u a l e n k f x t 1 i θ t 1 i u t 1 i u t i y t obs i 2 2 eight surrogate solutions to ensemble kalman filters here we present eight surrogate filters based on polynomial chaos expansion pce theory that can be substituted for enkfs the proposed filters expect to achieve high accuracy at low computational cost and inherit the same fundamental assumptions as the enkf implementations the differences among the eight filters will be described below and in fig 1 2 2 1 different surrogate structures whole vs partial surrogate filters the first criterion for distinguishing among the eight surrogate filters is to determine what to replace in the existing enkf system one possibility is to construct a single surrogate that can mimic the entire enkf process given all the input variables on the right side of eqs 7 and 8 the output variable on the left side is computed through the surrogate filters this is similar to the conventional approach hereafter called surrogate whole filter suwf the other new approach is to configure multiple surrogates each of which mimics a specific process in the enkfs theoretically it is possible to distinguish all the processes of enkfs and construct surrogates for all of them but two independent surrogates are only built for two of the processes in this study these processes were chosen because they are the most unfavorable in terms of computational efficiency but have a great impact on accuracy li and xiu 2009 the processes are those computing ensemble states and streamflow forwarded in time through the propagators f and h in eqs 1 3 and 5 regarding the enkf processes other than these two the same applies as with the existing enkfs this is hereafter called the surrogate partial filter supf 2 2 2 different building systems variant vs invariant surrogate filters the second criterion is whether or not the pce employed to create the surrogate filters changes over time one conventional type of pce is a time variant pce vapce which is continuously reconstructed based on new information about forcings and streamflow at all forecasting steps of data assimilation fan et al 2016 wang et al 2017 2018 dwelle et al 2019 hu et al 2019 tran and kim 2019 the collection of the training set is much more straightforward than in the other type because precipitation forcing and streamflow are known during the assimilation process that is u t 1 u t and y t obs are real data tran et al 2020 we will refer to the surrogate filters created using the time variant pce as variant surrogate filters vasufs i e vasuwf and vasupf the other type of pce is built only once over the calibration period and is used later for the forecasting period tran et al 2020 this time invariant pce hereafter referred to as inpce has the advantage of maximizing applicability and efficiency because it does not need to be re built during real time forecasting one notes that inpce should be made to better represent the behavior of the original model under a wide range of conditions trained for a limited dataset from the past the pce model has shown excellent performance with other events similar to the calibration sets however for events that differ from those in the training series it is challenging to construct a surrogate model that mimics the original model tran et al 2020 this issue can be addressed by training with as much data as possible but attaining large amounts of data is still far away for some ungauged domains we therefore propose a new procedure of collecting training sets to build an invariant pce that does not require measurement data in this study we assume that all input variables of a filter model in eqs 7 and 8 i e model states model parameters rainfall measurements and observed discharges are uncertain and vary within a particular range instead of arranging them in a deterministic way their input values are randomly generated through a sampling process the latin hypercube lhs sampling technique mckay et al 1979 is used in this work this procedure makes the invariant pce suitable for as many input conditions as possible further details on how to collect the experimental design in building the invariant pce will be described in section 3 3 we will refer to the surrogate filters created by the invariant pce as invariant surrogate filters insufs i e insuwf and insupf such a differentiating criterion is related to the amount of information needed to generate a pce that is whether to select training information for just a single time step or all periods it thus involves setting the extent to which the generated pce can replace the original model in other words a pce generated using a wider range of training data can mimic the results of the original filter in a wider range of simulation conditions a more detailed comparison and discussion on this subject can be found in tran et al 2020 2 2 3 different assimilating targets single vs dual surrogate filters the last criterion is based on the goal of data assimilation whether to update only state vectors like single enkf in eq 7 or to update model parameters as well as the state vectors like dual enkf in eq 8 surrogate filters that replace single and dual enkf can be called single surrogate filters sufs i e insuwf insupf vasuwf and vasupf and dual surrogate filters dual sufs i e dual insuwf dual insupf dual vasuwf and dual vasupf respectively the mathematical denotations of these eight surrogate filters are presented in appendix a for clarity this includes the denotations for both surrogate filters and their corresponding pces the latter specifically consists of 4 variant pces vapce1 vapce2 vapce3 and vapce4 and 4 invariant pces inpce1 inpce2 inpce3 and inpce4 2 3 polynomial chaos expansion pce to develop the surrogate filters explained in section 2 2 and handle the computational burden mentioned above a pce that expresses stochastic quantities as a convergent polynomial series of random input variables is used wiener 1938 ghanem and spanos 1991 let us consider a filter model m that will be supplanted by a surrogate m pce given inputs x t i and outputs y t i of m shown in eqs a 2 a 4 a 6 a 7 a 10 a 12 a 14 and a 15 the relationship between x t i and y t i is described as 9 y t i m x t i m pce x t i α n n x ε α ψ α x t i i 1 n da where the numbers of inputs x t i and outputs y t i each member of the pce outputs is called a quantity of interest qoi in eq 9 are n x and n y respectively which vary depending on the aforementioned pces specifically the values of n x are n s n p 2 n i 1 n s n p 2 n i 1 n s n p n i and n s n p n i for pce1 pce2 pce3 and pce4 respectively regardless of whether the pces are variant or invariant whereas the corresponding values of n y are n s 1 n s n p 1 n s and 1 for the 4 pces respectively then one attempts to approximate m with m pce represented by a suitable polynomial expansion the expansion consists of polynomial basis terms ψ α x t i that are multivariate orthogonal polynomials over the distribution of input x t i ε α are deterministic polynomial expansion coefficients for multi indices α α 1 α n x that are introduced to simplify notations and represent the orders of polynomial terms three widely used methods to estimate pce coefficients ε α are gaussian quadrature smolyak 1963 bayesian compressive sensing sargsyan et al 2014 and sparse regression berveiller et al 2006 blatman and sudret 2008 the latter method which has been suggested in previous studies e g blatman and sudret 2011 wang et al 2015 meng and li 2018 is employed in this study for more information about this method we refer the reader to blatman and sudret 2008 a brief overview for determining pce coefficients is described in section s 2 of the supplementary material 2 4 optimization of pce hyper parameters the constructed pce includes two hyper parameters the size of training data set called experimental design x n and the degree of polynomials p it is important to set the values of the hyper parameters prior to estimating the pce coefficients which directly affects the ability to capture the behavior of the original filter blatman and sudret 2010 however such a determination is not straightforward and often has been decided by trial and error hu and youn 2010 laloy et al 2013 sochala and le maître 2013 wang et al 2017 dwelle et al 2019 tran and kim 2019 to address this problem we propose a procedural version in which the ultimate values of n and p are identified by continuously increasing their values until any convergence criteria are met this method is the extension of the sequential experimental design blatman and sudret 2010 2 4 1 sequential experimental design polynomial degree scheme in the original sequential experimental design sed scheme suggested by blatman and sudret 2010 the enrichment of experimental design x is stopped when an accuracy metric reaches a target error that is a single stopping criterion was employed because some studies do not meet its intrinsic assumption that the accuracy metric decreases monotonically hu and youn 2010 sargsyan et al 2014 diaz et al 2018 dwelle et al 2019 torre et al 2019 this study extends the existing scheme so that multiple stopping convergence criteria can be satisfied sequentially by enriching both n and p in the so called sequential experimental design polynomial degree sed pd scheme specifically this sed pd consists of two subsequent iterative cycles to determine the optimum values of n and p in which the sub loop of p is influenced by the iteration of n enrichment a stepwise description of the sed pd scheme is provided as follows and an associated flowchart is sketched in fig 2 1 the first step is to initialize the size n of the experimental design with a feasible number if one chooses an initial value of n that is too small it will take a long time to converge conversely an initial value that is too large may not converge at all therefore selecting an appropriate number for the initial value of n is an important task in general determining the optimal size of the experimental design depends largely on the complexity of the original model as well as on the computational budget available razavi et al 2012 the relevant literature has not reported a well established rule of thumb for the initialization of n to build the pce blatman and sudret 2010 schöbi et al 2017 diaz et al 2018 dubreuil et al 2018 dwelle et al 2019 torre et al 2019 here we attempt to appraise an approximate order of an initial value for n regarding the four variant pces i e vapce1 2 3 and 4 in eqs a 2 a 4 a 6 and a 7 n can be expressed in the order of the number of ensemble members n pce i e initial n n pce because these pces reconstructed in each computational time have a single time step the number of time steps n t 1 regarding the other invariant pces i e inpce1 2 3 and 4 the smallest starting value could be the product of the number of time steps n t and the number of ensemble members n pce i e initial n n t n pce such a number indicates that an original filter model needs to be computed over the number of ensemble members of the input variables per each time step 2 given n the experimental design x is sampled using the lhs technique and the corresponding response y is computed from eq s 29 3 the other hyper parameter the polynomial degree p needs to be initialized as well unlike the initialization of n the starting value of p can be chosen to be 1 without much effort 4 given the values of n and p a candidate surrogate for each qoi m pce q o i is constructed from eq s 29 5 to quantify the difference between the results of the original and surrogate filters judge the degree of convergence and evaluate the performance of the latter filters a statistic is introduced and will be computed for each qoi for each iteration following the study by blatman and sudret 2010 an accuracy metric for each qoi ε loo q o i is defined as 10 ε loo q o i 1 n k 1 n m q o i x k m pce q o i x k 1 h k 2 where h k is the k th diagonal term of the matrix f f t f 1 f t and the information matrix f is defined in eq s 32 this leave one out cross validation error metric ε loo q o i is designed to quantify how exactly the surrogate model behaves compared to the original model by computing a deviation between these model outputs and to detect an overfitting phenomenon more easily blatman and sudret 2010 6 the inner iterative cycle refers to steps 4 through 6 fig 2 and aims to determine an optimal p given a value of n if the convergence stopping criteria for p are not satisfied the inner loop is executed again i e l p increased by one for the new p increased by one such iterations continue until convergence criteria based on the accuracy metric are met the details for the criteria will be described in the next section 7 once the inner loop is finished the second bigger iterative cycle begins comprising steps 2 through 7 this outer loop includes the former inner loop determining optimal values of both hyper parameters for the fixed value of p determined in the first loop a similar decision is made as to whether other criteria for n are met if they are not the iterative algorithm goes back to step 2 with the new n increased by n i e l n increased by one new samples with size n are added to the existing samples of the experimental design then steps 2 through 7 are repeated until these criteria for n are satisfied note that each time a new n is chosen and the outer loop executes p is newly determined within the inner loop eventually both criteria must be satisfied to complete the sed pd algorithm optimal values of n and p are determined for each qoi 2 4 2 convergence stopping criteria a set of multiple convergence stopping criteria based on the error metric have been proposed to stop the loop iterations of the sed pd scheme this is similar to an optimization problem that can maximize the accuracy of the pce while minimizing the computational cost required for pce construction following the successive procedure of sed pd convergence criteria are applied twice to the selections of n and p respectively four criteria are proposed to ensure stopping the enrichment of p and n fig 3 the increase of p or n is stopped if any of the following four convergence criteria are satisfied 1 one can stop if the ε loo q o i value reaches a sufficiently small target error it is acceptable that the difference between two comparing models is negligible the threshold error ε th lower targeted in this study is set to 10 5 similar to the previous study blatman and sudret 2011 the optimal values are specifically determined by selecting the values of p and n at the moment when ε loo q o i l at iteration l l l p l n see fig 3 is smaller than the lower threshold the corresponding mathematical expression is 11 s t o p i f ε loo q o i l ε th lower 2 the first criterion is valid only with the expectation that the error decreases monotonically however due to the complexity of the model which is affected by many sources of uncertainty the first criterion may not be met within a finite number of iterations besides an excessive increase in the number of n and p does not mean that they always provide a better surrogate model which can lead to an increase in ε loo q o i called over fitting such a phenomenon can be avoided by addition of another criterion that is one can stop if the ε loo q o i increases in three consecutive iterations and ε loo q o i l 2 is smaller than ε th upper 12 s t o p i f ε loo q o i l 2 ε loo q o i l 1 ε loo q o i l a n d ε loo q o i l 2 ε th upper where ε loo q o i l 2 ε loo q o i l 1 and ε loo q o i l are the error estimates computed at the successive iterations of l 2 l 1 and l respectively to avoid instances where the iterations stop very early or the optimal ε loo q o i value is still large we also introduced another threshold ε th upper as a safeguard in this study the value of ε th upper is set to be 10 1 the optimal values are then determined as the p or n values at the iteration when ε loo q o i is the smallest for example in fig 3 p or n value at l 2 is selected 3 another possible case where the scheme will not converge is when the error is not small and rarely decreases by calculating the degree of reduction i e slope one can take into account divergence in such a case this can be stopped if the slope in eq 13 calculated using the errors estimated in three consecutive iteration steps is insignificant thus the third stopping criterion is 13 s t o p i f ε loo q o i l ε loo q o i l 1 ε loo q o i l 2 ε loo q o i l 1 ε th slope a n d ε loo q o i l 1 ε th upper where 0 05 is used as the value of ε th slope as in prior studies echard et al 2011 schöbi et al 2017 dubreuil et al 2018 like the second criterion the value of ε loo q o i is restricted to be smaller than ε th upper the p or n value is determined at the iteration when ε loo q o i is the smallest for example p or n values at l 1 are selected in fig 3 4 the fourth and final criterion is given in case that divergence or overflow can still occur even though the above three safety measures have been implemented according to the computational power employed the p and n values should be limited to avoid infinite iterations of the sed pd when the above three criteria do not work that is the fourth stopping criterion is 14 s t o p i f p p max o r i f n n max where a maximum degree of polynomials p max of 15 is used in this study the maximum number of experimental design n max is set to be p max 1 n x analogous to the total number of model evaluations when using the gaussian quadrature method sudret 2008 the p or n value is determined at the iteration when ε loo q o i is the smallest for example p or n values at l 1 not l max are selected in fig 3 3 experimental configurations all experiments were carried out in the vu gia watershed in central vietnam fig 4 the area of this watershed is 1679 8 km2 and it is characterized by a large difference in elevation ranging from about 30 m to 2100 m with mainly mountainous and hilly terrain the catchment is heavily influenced by the tropical monsoon climate with heavy rains occurring mainly from september to december greater than 2000 mm year not only because of the large amount of rain but also because of the topographic features this region has experienced severe floods and significant damage reported by the united nations development programme undp 1999 3 1 flood events and a hydrological model three flood events from the rainy season in 2016 were selected for verification and application of the surrogate filters precipitation data was observed at the thanh my and kham duc stations and discharge data at the outlet of the watershed at the thanh my station fig 4a all the hourly data available in this domain were taken into account and the data are provided by the vietnam national centre for hydro meteorological fig 4b the areal average of rainfall used for a hydrological model was computed through the thiessen method while the potential evapotranspiration was not considered due to its insignificant effects on flooding data assimilation experiments were performed by employing the nedbør afstrømnings model nam nielsen and hansen 1973 which is a conceptual lumped rainfall runoff model containing nine adjustable parameters and five model states given these parameters and states the model can simulate three pathways of flow i e overland intermediate and groundwater and control the amounts of water stored in the surface zone lower zone and routing components a description and feasible range of the parameters and states are listed in table 1 for a more detailed description of nam see o brien et al 2013 and dhi 2014 and for a summary see tran and kim 2019 and tran et al 2020 3 2 modeling procedure for the variant pce construction building the variant pces should be performed in real time for the present forcings at each time step the first task is to initialize the state vector and specify the parameters of the hydrological model zero initial states are assumed and parameters are sampled from the posterior distributions estimated by the generalized likelihood uncertainty estimation glue beven and freer 2001 for more details see section s 3 in supplementary material since a much smaller number of training samples e g 50 can make the pce successfully tran and kim 2019 the initial n of the experimental design x is given as the number of ensembles n pce of 10 in this type of construction real time forcings and observations are employed for the enkf assimilations then the sed pd scheme stops iterating if criteria for n are met otherwise it continues the iterations with the n increased by n 10 note that to construct the variant pces stochastically varying rainfall and discharge are not essential real data for the three events is directly employed four variant pces are built at each time step that is 51 50 and 34 variant pces are built for the first second and third flood events respectively 3 3 modeling procedure for the invariant pce construction the first task to constructing invariant pces is also to initialize the state vector and specify the parameters of the nam model this study initializes the ensemble of the states with zero and specifies the ensemble of the parameters with samples chosen randomly from the uniform prior distribution these ensembles start with the initial n n t n pce 100 100 10 000 a number of n filter evaluations are followed for rainfall forcings and streamflow observations as described in section 2 2 2 stochastic inputs of rainfall and discharge are preferred to build the invariant pces we generated the stochastic samples under the assumption that these two input variables followed a uniform distribution over bounded intervals the lower bounds of the possible ranges for observed rainfall and discharge were set to be zero while the upper bounds were subject to the domain in this study values of 50 mm hour and 7000 m3 s were employed for the upper bounds of rainfall and streamflow respectively these values were determined from the maximum hourly rainfall in data available since 2015 and an extreme corresponding to a 100 year return period the latter flood frequency analysis was made by applying the pearson type iii distribution to annual flood peaks for data from 1976 to 2016 then according to the sed pd scheme additional n filter evaluations are included if criteria for n are not met the n for the second next iteration becomes n n n 100 10 100 10 12 100 this size continues to grow until the criteria are satisfied note that each of the invariant pces is unique and can be applied to any event including the three events given 3 4 synthetic and real data assimilation experiments the first of three events was used as a synthetic experiment the objective of which is to judge the performance of certain data assimilation techniques whether evaluating the convergence of the parameters quantifying the parameter range adequately and minimizing the predictive uncertainty moradkhani 2008 serving as a control run this synthetic experimental dataset was generated through a free run using observed rainfall event 1 pre specified also referred to as true parameters in table 1 and discharges computed from the former two other flood events i e 2 and 3 were utilized for application of the proposed filters to real time flood forecasting in which the performance of the eight surrogate filters are compared and validated with the single and dual ensemble kalman filters all data assimilation experiments were performed with n da of 500 which was considered to be a rational ensemble size to adequately represent the uncertainty bounds moradkhani et al 2012 kim and ivanov 2015 kim et al 2015 tran and kim 2019 tran et al 2020 the initialization of the states given the ensemble size was simply set to be zero the specification of the parameters for the same size was performed by using the posterior distribution by glue for the real data experiment and by using the prior uniform distribution for the range given in table 1 for the synthetic experiment to achieve the most reliable ensemble prediction over the entire forecasting period it is necessary to assume noise for quantities that contain uncertainty in the data assimilation framework renard et al 2010 dechant and moradkhani 2012 in this study 500 perturbations were applied to the precipitation and streamflow observations in both synthetic and real data experiments to account for uncertainties similarly to previous da studies dechant and moradkhani 2012 moradkhani et al 2012 abbaszadeh et al 2019 specifically we assume a log normal error distribution with a relative error re u of 25 for precipitation the streamflow observation error is assumed to be normally distributed with a relative error re obs of 15 at each time step it is also assumed that the model parameters follow a random walk by adding a small amount of noise following a normal distribution with a relative error re θ of 1 in eq 2 3 5 evaluation measures for accuracy and efficiency to evaluate the accuracy and predictability of the proposed surrogate filters both deterministic and probabilistic measures were selected for deterministic metrics the nash sutcliffe efficiency nse in eq s 34 widely used to assess the goodness of fit of a model is computed for each ensemble member over the entire computational time t peak error pe which is often used to verify the ability to accurately predict flood peaks is computed by eq s 35 the ensemble forecasting results also can be evaluated through probabilistic measures the brier score bs which is a commonly used scoring rule for measuring the accuracy of probabilistic predictions brier 1950 is defined as the mean squared error of the probabilistic forecasts over the verification sample 15 bs 1 t t 1 t p t f p t obs 2 where p f is the forecast probabilities among n da ensemble reached a predefined flow threshold p t obs is the observed probability 1 if the event occurred and 0 if it did not which is obtained from the comparison of y t obs and the threshold in this study this threshold value is selected as the proportional rate of 90 of the observation peak the continuously ranked probability score crps measures the proximity of the forecast distribution and the measurement distribution at a single time step gneiting and raftery 2007 in this study the temporal mean of crps crps is used for comparison 16 crps 1 t t 1 t f y t f y t obs 2 d y where f y t and f y t obs are the empirical cumulative distribution of n da ensemble predictions y t i and the actual observation y t obs at time t respectively the value of crps is non negative and has a value of zero if two distributions are identical since a reliable forecast with an excessively high dispersion is not desired the spread can be considered this parameter is equal to the square root of the average ensemble variance over the evaluation period fortin et al 2014 liu et al 2019 and is non negative with the best value of zero it has the same unit as streamflow 17 spread 1 t t 1 t 1 n da 1 i 1 n da y t i y t obs 2 regarding the modeling efficiency runtime at each time step rt t and cumulative runtime rt cum t are established as 18 rt t rt build t rt run t n da 19 rt cum t t 1 t rt t where rt build t is the runtime needed for building a filter at each time step of the assimilation rt run t is the runtime to perform the filter for assimilation at each time step for one ensemble member the runtime rt build t consists of the time rt x t required to configure the experimental design x i e model evaluations and the time rt opt t required to determine the optimal hyper parameters and coefficients of pce the latter runtime is the summation of rt opt t q o i m for each qoi because a filter is made after pce construction over each qoi in contrast the former runtime chooses the largest time among all rt x t q o i m because the pce is built by recycling all the previously performed model evaluations i e it shares the experimental design with the largest n of all qois that is rt build t for the variant filters rt build t va is written as 20 rt build t rt build t va m a x rt x t q o i m m 1 n y f i l t e r m 1 n y f i l t e r rt opt t q o i m where m is an index for the number of pce outputs of the filter n y f i l t e r n y f i l t e r for suwf dual suwf supf and dual supf are n s 1 n s n p 1 n s 1 and n s 1 respectively regardless of whether the filters are variant or invariant surrogate filters note that because the variant surrogate filters need to re build at every time step of the assimilation rt build t va is subject to the time step t on the other hand rt build t for the invariant filters rt build in does not need the subscript t and is independent of time because their construction could be done before forecasting thus rt build in is similarly expressed as 21 rt build t rt build in m a x rt x q o i m m 1 n y f i l t e r m 1 n y f i l t e r rt opt q o i m 4 results 4 1 optimization of the pce hyper parameters hyper parameters n and p must be predetermined to construct pce for each qoi but their optimal values to maximize the performance of constructing pce are unknown here we present the results of the sed pd scheme which can be a guideline for other studies the results are shown in fig 5 including the convergence criteria used for stopping the scheme and the number of iterations needed for optimizing n and p table 2 presents the optimal values of n and p the error ε loo q o i at stopping and the building time these results are subject to vary depending on the surrogate solutions proposed but are significantly different between the variant and invariant pces the sed pd adopts four criteria for attaining the optimal values of n and p for the selection of p the second 57 in magenta or the first 28 in yellow stopping criterion is used for the variant pces that is over fitting predominantly happens or ε loo q o i smaller than the threshold of 10 5 exists the number of iterations l p is smaller and varies from 1 to 5 specifically 1 25 3 29 4 20 and 5 12 see fig 5 in contrast the third 87 in green in fig 5 or fourth 13 in cyan criterion is frequently used to construct the invariant pces that is the optimal p p opt q o i is largely determined when the consecutive values of ε loo q o i remain unchanged or the degree of polynomials reaches its maximum value of 15 this implies that it is difficult for the value of ε loo q o i to reach its ideal predefined value ε th lower the number of iterations l p to optimize p is generally greater than 5 with the most commonly identified numbers of iterations being 5 72 7 16 and 15 29 these results confirm that finding an optimal p when constructing vapces requires fewer iterations and is much faster than in making inpces for determining the optimal n of each qoi n opt q o i a similar approach using four criteria was made in building vapces the most commonly used criteria were 1 67 2 19 and 3 15 and the numbers of iterations l n required were only 1 48 or 3 30 these results indicate that the values of ε loo q o i easily reach the desired values so the l n is lower in contrast in constructing inpces the criteria used were 2 78 and 3 22 and the values of l n were mostly from 3 to 8 but ranged up to 23 in summary the results of the optimization of n and p demonstrate that it is much easier to identify appropriate n and p values in constructing vapces than inpces table 2 reports the values of n opt q o i p opt q o i ε loo q o i rt x q o i and rt opt q o i in constructing eight pces for each qoi the n opt q o i and p opt q o i values of the variant pces are smaller than 100 and 3 respectively and their ε loo q o i values are mostly smaller than 10 4 conversely the n opt q o i and p opt q o i values of the invariant pces are greater than 10 000 and 5 respectively and their ε loo q o i values are greater than 10 3 pces generated based on more sampling data i e larger n opt q o i and more complex models i e higher p opt q o i do not necessarily provide better results i e smaller errors furthermore the differences in the time required to implement the sed pd are evident the build times of the invariant filters are significantly greater than those of the variant filters by factors of approximately 2962 3027 263 and 263 times in the comparisons of insuwf versus vasuwf dual insuwf versus dual vasuwf insupf versus vasupf and dual insupf versus dual vasupf respectively see table 2 these results indicate that a more universal invariant pce built with enormous margins of all uncertain variables takes significantly more time than a specific variant pce in which all forcings and observations are confirmed in real time 4 2 data assimilation of the synthetic experiment synthetic experiments are often employed to examine whether parameters converge satisfactorily whether the range of parameters is adequately quantified and whether predictive uncertainty is minimized moradkhani 2008 first we ensured that the model parameters updated from dual data assimilation can converge to the predefined parameter values for event 1 fig 6 shows the time evolution of posterior distributions of nine parameters for five dual filters the most easily identifiable parameters are cqof and ck12 while the rest of the parameters could not reduce the large uncertainty range over time as also inferred from the results of glue and sensitivity analysis in section s 3 all dual filters except for dual insuwf successfully provided the posterior distribution of these parameters that almost converged to the predefined values at the end stage of assimilation compared to the tendency of dual enkf to converge to the predefined parameters the dual variant filters dual vasuwf and dual vasupf can accurately update the posterior parameters in terms of convergence speed and degree on the other hand the dual invariant partial filter dual insupf provides a slightly different converging tendency wherein the magnitude of the uncertainty of ck12 is larger than dual enkf and the convergence is slower specifically the mean value of ensemble members of ck12 black line in fig 6 converges to its predefined value at about 20 h in dual enkf as well as both dual variant filters but it takes an additional 7 h in dual insupf the other dual invariant whole filter dual insuwf completely fails to estimate the parameter posterior distribution because the influential parameters converge to a lesser extent and the identified posterior distributions do not converge to the predefined values fig 6d ensemble streamflow predictions and their error measures were compared for ten filters in the synthetic experiment over event 1 in fig 7 1 deterministic and stochastic error measure values in fig 7b d indicate that all surrogate filters are functioning properly to improve the accuracy of streamflow predictions the results of nse pe bs crps and spread when using da are significantly better than those without da 2 the single and dual surrogate filters were compared clearly demonstrating the effect of simultaneously updating the states and parameters on the accuracy all dual filters except for dual insuwf produce superior results to single filters and provide almost the same results as the original dual enkf for example the performance of four dual filters increases by at least about 8 65 48 68 and 51 for the ensemble median of nse nse the ensemble median of pe pe bs crps and spread respectively the interquartile uncertainty range of nse is also reduced to 0 02 0 07 in dual filters from 0 03 to 0 39 in single filters and that of pe is reduced to 2 10 in dual filters from 10 to 30 in single filters 3 dual insuwf showed no performance improvement for nse and pe compared to insuwf while there were improvements of about 36 and 22 for crps and spread respectively dual insuwf is less accurate than dual enkf while insuwf has more accurate prediction performance than enkf in summary the analyses above in the synthetic experiment indicate that all of the four single filters insuwf insupf vasuwf and vasupf worked similarly to the original single filter enkf in terms of accuracy for streamflow forecasting furthermore three of the four dual filters dual insupf dual vasuwf and dual vasupf showed equivalent performance to the original dual filter dual enkf in terms of increased accuracy and parameter posterior estimation however dual insuwf failed to converge to predefined parameters during the assimilation process nor did it improve predictive performance 4 3 data assimilation of the real experiment in this section two data assimilation experiments using real rainfall and streamflow observations were conducted to further examine the performance of proposed filters in a real time forecasting framework the forecasting results over events 2 and 3 are reported from figs 8 11 in general the results of the real data assimilation experiment have equivalent conclusions to those of the synthetic experiment qualitative inspections for observation consistency and uncertainty interval from figs 8 and 9 reveal that all surrogate filters provided similar results to enkfs and dual filters are more accurate and have narrower uncertain ranges than single filters since it is evident that streamflow predictions were improved by using data assimilation we omitted the comparison for the absence of da and showed the comparison between filters regarding the reliability of surrogate filters three paired comparisons were performed based on three standards of surrogate filter construction described in section 2 2 whole versus partial variant versus invariant and single versus dual such comparisons can be done easily with the help of a relative difference metric δ between the values of the evaluation metrics m e t r i c including nse pe bs crps and spread this difference metric is defined in the unit of percentage as 22 δ m e t r i c s u f s 1 m e t r i c i d e a l m e t r i c s u f s 2 m e t r i c i d e a l m e t r i c s u f s 1 m e t r i c i d e a l 100 where s u f s 1 denotes the former group filters i e whole variant and single filters while s u f s 2 denotes the latter filters i e partial invariant and dual filters m e t r i c i d e a l represents the ideal perfect values of the metrics of nse pe bs crps and spread that is 1 0 0 0 and 0 respectively the positive or negative values of δ indicate that the prediction results of the latter group filters are more or less accurate than those computed by the former filters the results of δ for the three paired comparisons are illustrated in fig 10 and also reported in table s 1 first the results of δ between whole and partial filters are mostly negative revealing that whole filters outperform partial filters by up to 203 117 115 41 and 44 for nse pe bs crps and spread respectively over both events 2 and 3 the only exception for this tendency can be found in dual insuwf which does not show an obvious superiority over dual insupf as an example for event 2 nse crps and spread of dual insuwf are inferior i e positive δ values to those of dual insupf by about 31 19 and 29 respectively while pe and bs are improved i e negative δ values by about 34 and 59 respectively fig 10 regarding the second paired comparisons of building systems between variant and invariant filters three out of four invariant filters have better performance than the corresponding variant filters fig 10 in particular the values of δ for all metrics have positive values ranging up to 60 45 27 79 and 37 for nse pe bs crps and spread respectively conversely for the forecasting results of the remaining invariant filter dual insuwf i e blue in fig 10 it is hard to conclude which building systems are superior the performance results are mixed depending on the metrics e g results of pe are 68 worse than those in dual vasuwf while those of crps are 27 better for event 3 third convincing evidence was found that dual filters outperform single filters as also seen in section 4 2 the dual updates of parameter and state significantly enhance the forecasting results and narrow their uncertainty spreads quantitatively the difference metric results of dual filters are improved by up to 9 48 34 54 and 50 over event 2 for nse pe bs crps and spread respectively for event 3 these improvements are more substantial with improvements of up to 38 69 90 56 and 52 respectively fig 10 in summary the dual vasuwf and dual insupf filters have proven to be superior to the others in providing accurate forecasting results followed by dual vasupf with prediction results closest to the above two filters the above comparisons were made for prediction results for short lead times lt of 1 h as predictions for greater lead times are usually in demand additional analysis was performed to examine whether the surrogate filters can provide reliable and accurate streamflow predictions for larger lead times of 1 6 h as expected the forecasting performance for ten filters decreases with the lead time decreasing for all metrics such a tendency is clearly shown in fig s 2 where the evaluation metrics at each lead time are compared with those at the lead time of 1 h for ten filters specifically in event 2 the ranges of degradation of nse pe bs crps and spread at a lead time of 6 h compared to those at lead time of 1 h are 181 1430 0 469 0 853 51 154 and 46 152 respectively in event 3 these ranges are 235 1206 105 395 115 585 51 203 and 66 196 interestingly some filters all single filters and dual insuwf have much worse predictability with respect to lead time while all dual filters except for dual insuwf are not as good but better than the former filters in order to compare the degree of performance deterioration for lead time among 10 filters another relative difference metric γ is computed as 23 γ m e t r i c b e s t m e t r i c i d e a l m e t r i c s u f s l t m e t r i c i d e a l m e t r i c b e s t m e t r i c i d e a l 100 where m e t r i c s u f s l t denotes the evaluation metric of a surrogate filter at a lead time lt that is varied from 1 to 6 h m e t r i c b e s t represents the best of the 60 values corresponding to 10 filters 6 different lead times closest to the m e t r i c i d e a l the negative values of γ indicate the degree of performance deterioration as compared to the best value compared to the best performance of nse its performance degradation at the longest lead time of 6 h stretches from 293 714 and 626 in dual vasuwf dual vasupf and dual insupf respectively up to 1724 in dual insuwf such a degradation is highest in nse and then in bs and pe fig 11 another interesting phenomenon is that the performance between the 10 filters is not very different for a lead time of 1 h but the performance difference between the filters increases significantly as the lead time increases for example the performance differences of γ at 1 h lead time are about 216 233 146 115 and 126 for nse pe bs crps and spread respectively at a lead time of 6 h the differences extend up to 1724 606 853 343 and 288 fig 11a filters that perform well at longer lead times are dual vasuwf dual insupf and dual vasupf which means that filters that performed better at a lead time of 1 h outperform other surrogate filters at longer lead times 4 4 evaluation of the superiority of computational performance to enkf fig 12 demonstrates the superiority of sufs to enkfs in terms of efficiency by computing the cumulative and instantaneous runtime rt cum t and rt t of ten filters for event 2 from fig 12a displaying the cumulative runtime versus time for n da of 500 it can be seen that the calculation speed of insufs is much faster than that of enkfs whereas the speed of vasufs is slightly faster for example at the end of forecasting t 50 the best filter dual insupf is about 500 times more efficient than dual enkf since the building time rt build t of both of these two filters is equal to zero the difference of 500 times is the same as the difference in the running time rt run t of the two filters i e about 4 6 10 4 and 0 23 secs see the slope of eq 18 written in the legend of fig 12b comparing the runtime of vasufs to enkfs is the case when the additional runtime required for building the filters rt build t offsets the efficiency of the runtime in running the filters rt run t when n da is small the efficiency improvement of dual vasupf and dual vasuwf to dual enkf is relatively low e g only 4 and 6 times faster for n da 500 but as n da gets larger this improvement becomes much greater e g 65 and 100 times faster for n da 10 000 5 discussion 5 1 is a partial surrogate approach more promising the primitive rationale of the partial approach was to individually replace the time consuming processes e g eqs 1 3 and 5 in the original filter model the rest of the enkf processes eqs 4 and 6 which take less time but play an important role remain the same since kalman gain k in that partial filter was directly calculated and reflected in updating the parameters and states it was possible to present more accurate results than the conventional whole approach that blackboxed this process thus a remarkable question to be addressed is how to select the process to be replaced among processes included in original filters models when designing a surrogate filter model considering the trade off between the time taken to execute the process and its physical importance a flexible surrogate model design will be possible what are the central advantages of the partial approach in terms of efficiency other than the aforementioned accuracy improvement the partial approach can effectively reduce the number of dimensions of the pce input in this study the total number of dimensions n x was n s n p n u in the partial filter while n s n p 2 n u n obs the number of observations in the whole approach the number of dimensions is reduced by n u n obs from 17 whole to 15 partial although the decrease in the number of dimensions 2 may seem small its contribution from the perspective of pce coefficients is by no means small that is the number of pce coefficients decreases significantly from 26 334 to 15 504 40 reduction estimated by the n x and a common p of 5 from eq s 27 thus resulting in the smaller size of experimental design e g from 90 000 to 40 000 for building dual insufs see table 2 if forcings and observations with different values for space are considered i e if n u and n obs are not equal to 1 such a reduction effect by the partial approach will be even greater how can the partial approach be extended to a fully distributed model with much larger dimensions rather than a lumped model in this case the total number of dimensions is as large as the total dimensions of the lumped model multiplied by the number of computational cells n cell that is n x n s n p 2 n u n obs n cell in the whole approach note that such a number is incredibly too high a pragmatic solution by the partial approach is to create independent surrogate pces as many as n cell it is enabled if each cell is treated as a separate process and thus is superseded with an independent pce this ultimately has the effect of turning the problem of generating one pce with the entire dimension into a problem of generating several n cell pces with dimensions of n x n cell even more productive solution is enabled by combining this partial approach with karhunen loève kl decomposition karhunen 1946 where it can lump cells with high correlation between model outputs in space or time into one group once the spatially correlated groups are identified the partial approach is then employed to construct a pce for that group cells surely results simulated by the constructed pce can be pertained only to the portion of domain determined previously 5 2 is building a universal pce achievable and consequential a well known characteristic and challenge of data driven models is that they cannot be applied to domains outside the scope of trained data basically data driven models have only one unique model suitable for each training data space likewise pce also has one optimal model for each data set experimental design if new data needs to be taken into account for future forecasting as with most studies in the past sargsyan et al 2014 bazargan et al 2015 wang et al 2018 dwelle et al 2019 hu et al 2019 tran and kim 2019 zhang et al 2020 it is natural to create a new pce model like the time variant approach however this approach cannot be applied when measurement or forecasted data is scarce and even if the data is sufficient there is a very critical disadvantage that a time consuming operation must be repeated whenever data is altered one of the goals of this study was to determine whether a universal invariant pce that could be applied to a wide range of rainfall events could be generated it is apparent that the higher the degree of generalization of rainfall events represented by the experimental design the more the pce can be applied to various conditions an effortless way to expand the scope of the data space i e the invariant approach was proposed and verified based on the results of the synthetic and real experiments a universal surrogate filter using the invariant approach dual insupf is the most efficient filter and one of the three surrogate filters that provide the most reliable predictability these results confirm that a single universal pce could be constructed across a wide range of random data space e g for rainfall and streamflow and applied to new input space this idea of using a random input generator allows for creating as many hypothetical events as possible that can happen in that region this does not require any specific historical event data so it has the advantage of being easily applied even if there is no historical data what are the practical implications of the universal invariant filter while many studies have highlighted the benefits of pce in saving computational costs most studies have been limited to hindcasting based on historical data e g focusing on uncertainty quantification or sensitivity analysis wu et al 2014 meng and li 2018 miller et al 2018 dwelle et al 2019 to the best of our knowledge no surrogate model or filter was applied to real time flood forecasting because there is a downside of having insufficient time to rebuild a new pce at each computation step for inputs provided in real time therefore the idea of making a unique surrogate filter during non flood season can bridge the gap between hindcasting and real time forecasting 5 3 is an advanced sed pd necessary in constructing pce in this study we propose a sed pd scheme an advanced version of sed introduced by blatman and sudret 2010 that was employed to determine the optimal values of n and p in estimating pce coefficients as a result of investigating the accuracy errors below and in the literature hu and youn 2010 sargsyan et al 2014 diaz et al 2018 dwelle et al 2019 torre et al 2019 we found that it is inappropriate to apply the sed originally developed for finite element problems directly to hydrologic problems of interest here we underscore the limitations of sed and the necessities of sed pd fig 13 clearly shows the difference between the hypothetical results obtained using sed and those from sed pd in terms of evolution of the error over runtime the results of sed were derived specifically for the vapce1 and inpce1 constructions of qoi y the p values were fixed from 1 to 7 and the maximum iterations for n l n m a x were limited to 1000 and 100 for vapce1 and inpce1 respectively there was a single stopping criterion the first criterion where the lower threshold ε th lower is 10 5 interestingly in both vapce1 and inpce1 ε loo q o i could not reach to the threshold value which implies that one cannot create any pce that satisfies the desired condition within a limited time when using sed apparently such an optimization using sed should be amended three possibilities are discussed for why sed pd is necessary in optimizing the hyper parameters n and p first the use of a single criterion cannot guarantee convergence if the target error is not reached errors computed are no longer reduced even if a large number of iterations e g up to 1000 and 100 of l n m a x equivalently 10 000 and 1 188 100 of n for vapce1 and inpce1 in fig 13a and c have been implemented compared to the sed pd case sed has not been able to obtain the desired convergence even after spending an enormous amount of time or has to invest an almost infinite amount of time until convergence see sed vs sed pd comparisons when stopping iterations rt build t 50 va q o i y are infinite vs 7 92 secs for vapce1 in fig 13a and rt build in q o i y are infinite vs 2 81 103 secs for inpce1 in fig 13c on the other hand sed pd can determine the optimal n and p quickly through the four criteria proposed ensuring system convergence and computational stability the second possibility is related to whether or not to include the optimization process of the p value in sed since the optimal value of p is unknown a common way to reveal an acceptable n value in sed is to start from p 1 and increase the value by 1 until the optimal n is determined as in fig 13a and c or if one can assume an appropriate p value the optimal n for that random p value can be determined since the optimal p value that causes the smallest error can vary from case to case for example optimal p is determined as 6 when l n 2 for vapce1 and as 5 when l n 2 for inpce1 see the cyan empty circles in fig 13b and d sed always requires additional analysis of similar form to fig 13a and c however in sed pd dual optimizations for both p and n are adopted such that the optimal value of p is automatically identified at each iteration l n like the blue empty circles in fig 13b and d such a dual optimization system ultimately improves the existing approach of sed by which the p value had to be selected ad hoc or by trial and error note that the performance of sed is highly influenced by the pce types and the lower threshold ε th lower see fig 13 in particular the success or failure of the sed optimization process depends on the latter threshold value therefore one might wonder how the optimization result will change if a larger value is chosen for ε th lower of sed in this regard fig 14 demonstrates the effects of the lower threshold ε th lower on the runtime for building the pce the larger the threshold value the sooner sed can stop and the higher the probability of attaining an optimal n value the empty red squares in fig 14 indicate that there is no probability to get its optimum that satisfies the criterion within the maximum number of iterations given p in order to avoid sed failure a feasible threshold greater than the minimum value of ε loo q o i say about 1 5 10 4 for vapce1 and about 5 5 10 2 for inpce1 must be selected in advance then a question arises of how to pre determine the value of ε th lower for each pce construction a practical and general answer to this question is to perform an additional analysis similar to fig 14 that uses trial and error with different thresholds this analysis is however unnecessary in sed pd 5 4 is the surrogate filter broadly applicable to geophysical science surrogate filter approaches proposed can be applied to various geophysical fields that require data assimilation to improve the accuracy and efficiency of real time predictions all da techniques generally consist of prediction step predicting the values of current state variables given information at the previous time step and update analysis step updating the predictands by calculating the error between the predicted values and the currently observed values although the da techniques differ in how they calculate and analyze the error in detail the fact that states parameters and forcings are transited to the predictions through a propagator e g eqs 1 3 and 5 is identical since the partial filter proposed replaces these equations it can be applied seamlessly to other da techniques without much modification obviously the whole filter can be generated only with evaluation results of the original filter so there is no limitation in applying it to other da applications moreover these approaches are all based on any geophysical model that should be used for the prediction and update thus the more complex governing equations the model contains the more the computational effect using the surrogate filter will be maximized 6 summary and conclusion the main objectives of this study were 1 to present a robust and efficient data assimilation technique in the framework of hydrologic flood forecasting embracing the merits of the ensemble kalman filter enkf and polynomial chaos expansion pce in order to produce reliable streamflow predictions with significantly reduced runtime 2 to underscore the advantages of the novel partial and invariant approaches in making a surrogate filter by investigating the accuracy and efficiency of the eight surrogate filters categorized according to different surrogate structures whole and partial building systems variant and invariant and assimilating targets single and dual 3 to propose an advanced dual optimization system with multiple stopping criteria named sequential experimental design polynomial degree sed pd that simultaneously determines the hyper parameters of n and p necessary for the pce construction the following are the principal results and conclusions of this study the sed pd scheme has evolved into a dual optimizing system and requires four stopping criteria dealing with two issues that originally occurred in sed during pce construction in particular the inherent assumption of sed that its accuracy error should decrease monotonically with iterations is not always satisfied thus the multiple criteria were needed to ensure convergence of the optimization process and avoid the possibility of infinite iterations additionally the exclusion of polynomial degree from the optimization process leads to a practical issue wherein the value of polynomial degree had to be selected ad hoc or by trial and error the dual optimization system proposed resolves this existing issue of sed a comprehensive investigation into how to configure a surrogate filter has been carried out conventionally the whole replacing entire processes of the original filter and variant requiring reconstruction at each time step approaches have been employed however we have confirmed that this traditional approach deteriorates forecasting performance in terms of accuracy and efficiency a novel partial replacing part of the original filter and invariant valid for whole time periods approach is proposed for the filter construction which outperforms the conventional approach the partial approach can directly reduce the number of dimensions by turning the problem of generating one pce with the entire dimension into a problem of generating several pces with a reduced dimension the invariant approach making a unique surrogate filter during non flood season can bridge the gap between hindcasting and real time forecasting specific results from the synthetic and real data assimilation experiments are 1 dual sufs except for dual insuwf successfully mimic the convergence characteristics of dual enkf in updating model parameters 2 the comparing results of eight surrogate filters show that dual vasuwf dual vasupf and dual insupf illustrate the most superior performance equivalent to that of dual enkf 3 these three filters perform relatively well at longer lead times as well although forecasting performance decreases with lead time for all filters regarding efficiency the use of surrogate filters dramatically improves the computational performance in particular dual vasuwf dual vasupf and dual insupf are about 6 4 and 500 times faster than dual enkf respectively when comparing the cumulative runtime rt cum t over event 2 with the ensemble size of 500 this efficiency gain is more pronounced when original filters being replaced are time consuming or larger ensemble sizes are employed since the calculation speed of the generated pce is related to the time of the arithmetic operation level it is always fast regardless of how complicated and time consuming the original filter is based on in depth analyses the dual invariant partial filter i e dual insupf is the best one being superior in terms of usefulness effectiveness and robustness as an enkf replacement although no application has yet been made to more comprehensive experiments beyond the scope of configurations of this study the proposed surrogate filter will be a promising alternative tool for performing computationally intensive data assimilation in high dimensional problems ultimately it not only provides equivalently accurate forecasting results in real time but also significantly reduces the computational burden of larger ensemble predictions credit authorship contribution statement vinh ngoc tran conceptualization methodology formal analysis investigation visualization writing original draft jongho kim conceptualization validation writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this work was supported by the 2021 research fund of university of ulsan we acknowledge the uncertainty quantification group uqlab of eth zurich for sharing open source algorithms appendix a denotation of eight surrogate filters the eight surrogate filters proposed fig 1 consist of 2 2 2 subcases whole or partial variant or invariant single or dual denotation of the filters are described below the single variant surrogate whole filter vasuwf has the same mathematical form as eq 7 the entire set of processes of the enkf is replaced with a first variant pce named vapce1 where va suwf vapce 1 a 1 x t i y t i va suwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 2 x t i y t i va pce 1 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the dual variant surrogate whole filter dual vasuwf has the same mathematical form as eq 8 the entire set of processes of the dual enkf is replaced with a second variant pce vapce2 where dual vasuwf va pce2 a 3 x t i θ t i y t i dual va suwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 4 x t i θ t i y t i va pce 2 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the single variant surrogate partial filter vasupf has the same mathematical form as eq 7 however the process of computing x t i in the latter enkf is replaced with a third variant pce vapce3 and the process of computing y t i is replaced with a fourth variant pce vapce4 where vasupf includes vapce3 and vapce4 a 5 x t i y t i va supf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 6 x t i va pce3 x t 1 i θ t 1 i u t 1 i w t 1 i i 1 n da a 7 y t i va pce4 x t i θ t i u t i i 1 n da the dual variant surrogate partial filter dual vasupf has the same mathematical form as eq 8 however the process of computing x t i in the latter dual enkf is replaced with the third variant pce vapce3 as shown in eq a 6 and the two processes of computing y t i are replaced with the same fourth variant pce vapce4 as in eq a 7 a 8 x t i θ t i y t i dual va su p f x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da another four invariant filters are set up similarly to vasufs except for using the time invariant pce inpce the fifth filter single invariant surrogate whole filter insuwf also has the same mathematical form as eq 7 the entire set of processes of the enkf is replaced with an first invariant pce named inpce1 where in suwf in pce1 a 9 x t i y t i insuwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 10 x t i y t i in pce1 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the dual invariant surrogate whole filter dual insuwf has the same mathematical form as eq 8 the entire set of processes of the dual enkf is replaced with an second invariant pce inpce2 where dual insuwf in pce2 a 11 x t i θ t i y t i dual in suwf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 12 x t i θ t i y t i in pce2 x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da the single invariant surrogate partial filter insupf has the same mathematical form as eq 7 however the process of computing x t i in the enkf is replaced with an third invariant pce inpce3 and the process of computing y t i is replaced with an fourth invariant pce inpce4 a 13 x t i y t i in supf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da a 14 x t i in pce3 x t 1 i θ t 1 i u t 1 i w t 1 i i 1 n da a 15 y t i i n pce4 x t i θ t i u t i i 1 n da the dual invariant surrogate partial filter dual insupf has the same mathematical form as eq 8 however the process of computing x t i in the dual enkf is replaced with a third invariant pce inpce3 as in eq a 14 and the two processes of computing y t i are replaced with the same fourth invariant pce inpce4 as in eq a 15 a 16 x t i θ t i y t i dual in supf x t 1 i θ t 1 i u t 1 i u t i y t obs i i 1 n da appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 126367 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
