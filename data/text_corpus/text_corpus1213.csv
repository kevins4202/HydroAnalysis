index,text
6065,the predictions made using rainfall runoff models are inherently uncertain and it is important to recognize and account for this uncertainty especially in urban watersheds due to the high flood risk in these areas recent studies on hydrological model uncertainty mostly refer to the identification of model parameter uncertainty however such studies are somewhat limited using the bootstrap approach a nonparametric method which makes less prior assumptions on the model structure and thus is more flexible hence a residual based bootstrap approach associated with the sce ua global optimization algorithm is demonstrated in this study for the analysis of calibrated parameter uncertainty and its subsequent effect on the model simulation of an urban specific rainfall runoff model urban storage function usf model under two different data scenarios of individual event based and whole data based scenarios initially the parameter uncertainty was expressed by estimating the confidence interval ci of the usf model parameters obtained from bootstrapping and then the parameters from the highest to the lowest uncertainties were derived by utilizing two newly proposed parameter uncertainty indices which can make the best use of ci moreover investigations on the effect of calibrated parameter uncertainty on model simulations revealed that the model was able to bracket most of the observations within the prediction range of considered scenarios this further indicates that the residual based bootstrap approach along with the sce ua method reasonably well predicted the uncertainty range of the usf model for a better understanding of simulation uncertainty we defined and demonstrated two model simulation uncertainty indices and these indices could be useful in future studies to analyze the simulation uncertainty of different rainfall runoff models in the watersheds worldwide keywords model parameter uncertainty urban storage function model residual based bootstrap method model parameter uncertainty indices model simulation uncertainty indices 1 introduction in urban watersheds the urban areas occupy most of the basin from upstream to downstream and are under constant development in terms of buildings roads other infrastructures etc kawamura 2018 there is no specific definition of urban watersheds quantitatively in terms of the threshold urban area however according to kjeldsen 2010 and salavati et al 2016 the watersheds with an urban area percentage greater than 15 can be considered as urban watersheds the modeling of urban watershed processes is complicated due to the increasing complexities of the urban hydrologic system that can be attributed to urbanization rapid population growth model scale etc mcpherson and schneider 1974 urbanization is a radical form of land use change and will replace the natural land use with impervious surfaces and storm drainage system kjeldsen 2010 this further inhibits the natural infiltration capacity and reduces the lag time the other hydrological impacts of urbanization can be listed as the increase of low return period floods more than the high return period floods increase in drainage density and channel cross sectional area flashiness of storm flow etc graf 1977 hollis 1975 these changes alter the runoff process significantly and accelerate the rainfall runoff transformation process which could lead to higher and rapid flood flows hollis 1975 salavati et al 2016 in addition the urban watersheds face constant and drastic changes in terms of frequent occurrence of high intensity rainfall due to the heat island phenomena bornstein and lin 2000 leakage from the water distribution system increased flood and inundation risk suriya and mudgal 2012 increase in human settlement and associated activities removal of vegetation and natural storage etc amaguchi et al 2012 wmo 2008 in contrast to urban watersheds the percentage impervious areas as well as the installed sewer system density is either very low or absent in rural watersheds and will undergo slow and steady changes of hydrologic and hydraulic characteristics they will retain a significant amount of rainfall due to the presence of natural land use hollis 1975 sheng and wilson 2009 and will substantially decrease the peak discharge and increases the flood duration sheng and wilson 2009 further oudin et al 2018 analyzed the effect of distance of urban areas from the catchment outlet on runoff response and the results revealed that the location of urban areas has a secondary effect compared with the percentage impervious surfaces hence the corresponding flood risk will be moderate in rural watersheds although it includes urban areas at the outlet due to the relatively low population and settlements it accommodates therefore it is very important to detect urban flood flows compared to those in rural areas as they are associated with increased risks and costs mason et al 2012 for this purpose the rainfall runoff models are important tools and they play a central role in urban watersheds padiyedath et al 2018a however the predictions made using rainfall runoff models are inherently uncertain the uncertainties in the modeling mainly arise from parameter uncertainties measurement errors associated with the input data and from model structure errors arising from the aggregation of spatially distributed watershed processes into a relatively simple runoff model sivakumar and berndtsson 2010 the models which are not parameterized properly or lack input data of reasonable quality could provide an inaccurate representation of the actual hydrological processes shrestha 2009 generally the effectiveness of a model in providing a good prediction of the hydrological processes is mainly determined by its parameter values jeremiah et al 2012 therefore the model parameter uncertainty has received a prime recognition over other sources of uncertainties in the field of hydrological modeling and recent studies on hydrological model uncertainties mostly refer to the identification of parameter uncertainty uhlenbrook et al 1999 or parameter calibration ajami et al 2004 and their impacts on the model simulation results freer et al 1996 traditionally model parameters have been quantified from watershed properties or theoretically analyzed by comparing with similar models li et al 2010 however since the introduction of computer intensive statistics the parameters are being estimated by calibrating the models against observed data even though it increases the efforts and costs taken for the data measurements required for calibration and validation however this calibrated parameters are influenced by factors such as quantity and quality of input data model error correlation between the parameters etc duan et al 1992 which will lead the parameter estimates to deviate from their underlying true values ebtehaj et al 2010 thus leading to a great level of uncertainty of parameters and cannot fully characterize the actual processes different quantity and quality of input data used for calibration may provide quite different optimum parameter sets and the resulting parameter distributions would reflect the uncertainty in the parameter estimates and the interaction between the individual parameters beven 1993 generally the hydrologists calibrate their models with all the available data e g vaze and teng 2011 to get the more robust parameter set however several studies analyzed the effect of input data quantity on parameter uncertainty by calibrating the model for different sub periods of all available data kleme≈° 1986 proposed a framework to evaluate the model transposability over time by calibrating the model for a selected sub period and validating in another period different from that used for parameter calibration later jakeman et al 1993 investigated the parameter fluctuations and associated uncertainties in model predictions for variable climatic conditions by calibrating a lumped rainfall runoff model for sub periods recently vaze et al 2010 analyzed the transposability of four rainfall runoff models to a changing climatic scenario different from those used for parameter calibration and they found that the model performance was affected by the calibrated parameters subsequently poulin et al 2011 studied the effects of model structure and parameter equifinality on the model simulation uncertainty in a climate change impact perspective soon after merz et al 2011 examined the parameter time stability of a conceptual model by calibrating the model in different sub periods moreover coron et al 2012 also analyzed the parameter time variability of three hydrological models using the split sample test and its effect on the model simulation thereafter brigode et al 2013 investigated the dependence of the optimal parameter set on the climate characteristics of the calibration period and the results revealed that the dependence can contribute variability in streamflow projections however the calibrated parameters often have no measurable reference in nature bellprat 2013 therefore the major concern which arises is that what confidence bounds can be placed on the calibrated parameters for a given period where the different sources of uncertainty is mainly arising from observational with different input data quality and model parameterization errors and how do these uncertainties affect the hydrologic simulations ebtehaj et al 2010 this parameter uncertainty further contributes to model simulation uncertainties but to what extent is unknown hence its quantitative evaluation is critical in reducing the uncertainty of these simulations recent researchers have paid more attention to these uncertainties and many uncertainty analysis techniques have been developed and applied to different catchments in the past decades yang et al 2008 most of these techniques rely on either parametric methods or bayesian methods selle and hannah 2010 yang et al 2008 the most traditional parametric methods used for the assessment of model parameter uncertainty are the linear analysis first order approximation by providing a rough confidence interval ci of parameters kuczera 1988 nonlinear constrained maximization or minimization etc gallagher and doherty 2007 however in the parametric method the structure of the model is specified a priori and the number and nature of the parameters are generally fixed in advance and there is a little flexibility sivakumar 2017 since the advances in computer technology the monte carlo approaches with a bayesian inference have become popular due to their ability to handle nonlinearity and interdependency of parameters in complex hydrological models li et al 2010 the other methods based on bayesian approaches are generalized likelihood uncertainty estimation glue beven and binley 1992 hornberger and spear 1981 sequential uncertainty fitting algorithm sufi abbaspour et al 1997 abbaspour et al 1999 etc still the bayesian technique requires the form specification of the error distribution for response variables selle and hannah 2010 hence the nonparametric methods have the advantage that they make less prior assumptions on error structures and thus are potentially more flexible the bootstrap method a nonparametric technique has been developed by efron 1979 for random resampling of the original data set to develop replicate data sets from which the underlying distribution of the statistics of interest such as mean variation correlation etc can be estimated sivakumar 2017 this resampling technique has applications in diverse fields like hydrology groundwater hydrology air pollution modeling toxicology etc dixon 2006 where it has been successfully used in hydrological modeling to design storms from exceedance series to develop artificial neural network ann model to estimate the sampling variability of reconstructed runoff etc jeong and kim 2005 sun et al 2013 zucchini and adamson 1989 by utilizing non time series data however the outcome from the rainfall runoff models is the time series hydrograph and hence the time series application of the bootstrap method becomes necessary sophisticated approaches have been developed for this purpose and has been extensively used for the trend analysis of temperature and streamflow time series generation of synthetic streamflow sequences that are used in simulation studies forecasting of low flow frequency uncertainty assessment of water quality trends etc hirsch et al 2015 lall and sharma 1996 √∂n√∂z and bayazit 2012 sonali and nagesh kumar 2013 srinivas and srinivasan 2005 tasker and dunne 1997 however use of the bootstrap technique for model parameter uncertainty analysis by employing the time series data appears to be quite narrow until recently and very limited studies have been conducted to quantify the calibrated parameter uncertainty of rainfall runoff models using this technique ebtehaj et al 2010 introduced a nonparametric block bootstrapping approach coupled with global optimization to estimate the parameter uncertainty resulting from uncertainty in the forcing data and evaluate its impacts on the resulting streamflow simulations later selle and hannah 2010 demonstrated a model based bootstrap and compared the results with the block bootstrap approach for the parameter uncertainty of abc hydrological model and a conceptual salt load model the bootstrap approach also seems to have been used for the analysis of parameter uncertainty of swat model li et al 2010 zhang et al 2014 further brigode et al 2014 brigode et al 2015 analyzed the effect of different rainfall runoff calibration periods and information contained in the calibration period on extreme flood estimations using the block bootstrap method the uncertainty studies conducted using the swat model for different catchments reported that the parameter uncertainty and its effect on model simulation uncertainty vary from catchment to catchment even for the same model li et al 2010 zhang et al 2014 therefore there is a need to carry out such studies in different types of watersheds worldwide under varying agro climatic conditions with different rainfall runoff models in light of the aforementioned discussions it is apparent that very few studies have been conducted for model parameter uncertainty analysis using the bootstrap method among these none of the studies have been carried out in urban watersheds particularly using the urban storage function usf model takasaki et al 2009 a relatively new storage function sf model specially developed for urban watersheds where combined sewer systems are in use hence an attempt has been made to explore the use of bootstrap resampling to evaluate the uncertainty of optimal parameter estimates that arise due to uncertainties in the input data using a case study in the upper kanda river basin a typical small to medium sized urban watershed in tokyo japan previous studies on model parameter uncertainty analysis using bootstrap approach were conducted using all the available data instead of individual flood events since the hydrologists were mainly interested in the estimation of catchment hydrological variables such as peak flow flood volume etc with utmost accuracy and reliability the flood runoff analysis in urban watersheds is generally event based due to the relevance of flash flood peak estimation and short time of concentration therefore the bootstrap approach was applied in this study to both the individual flood events and the whole events in order to demonstrate the impact of different available data scenarios on the uncertainty behavior of calibrated parameters additionally two types of new indices have been proposed for the detailed analysis of uncertainty involved in the model parameters and model simulations 2 methodology 2 1 usf model the usf model is an sf model hoshi and yamaoka 1982 kimura 1961 prasad 1967 developed for the urban watersheds by incorporating the outflow from the basin to the treatment plant through the combined sewer system the model is based on the relationship between rainfall over the basin and runoff at the outlet point and is governed by the following equation padiyedath et al 2018a takasaki et al 2009 1 s k 1 q q r p 1 k 2 d dt q q r p 2 where s is the watershed storage mm q is the river discharge mm min q r is the storm drainage from the basin through the combined sewer system mm min t is the time min and k 1 k 2 p 1 p 2 are the model parameters combining the above expression of storage with the following continuity equation yields the nonlinear expression of the usf model 2 ds dt r i e o q q r q l where r is the rainfall mm min i is the urban specific and groundwater inflows from other basins mm min e is the evapotranspiration mm min o is the water intake from the basin for intended purposes such as water supply agricultural needs etc mm min and q l is the groundwater related loss mm min groundwater related loss q l was defined by considering the infiltration hole height z and is given by the following equation padiyedath et al 2018a takasaki et al 2009 3 q l k 3 s z s z 0 s z where k 3 and z are the parameters the expression for storm drainage q r from the combined sewer system discharged out of the basin was developed by assuming a linear relationship between total discharge q q r and the storm drainage q r immediately after the rainfall the q r is defined padiyedath et al 2018a takasaki et al 2009 as follows 4 q r Œ± q q r q 0 Œ± q q r q 0 q r m a x q r m a x Œ± q q r q 0 q r m a x where Œ± is the slope of the linear relationship between total discharge q q r and the drainage q r and q 0 is the initial river discharge just before the rain starts the maximum volume of q r cannot exceed the sewer maximum carrying capacity q rmax substituting eqs 1 and 3 into 2 leads to a second order ordinary differential equation ode and can be numerically solved after transforming into a first order ode the river discharge q was obtained as the solution after subtracting q r which was calculated using eq 4 from the total discharge overall the usf model is a seven parameter model with parameters k 1 k 2 k 3 p 1 p 2 z and Œ± used in the rainfall runoff modeling for a detailed description of the usf model see takasaki et al 2009 and padiyedath et al 2018a 2 2 model calibration and validation the shuffled complex evolution university of arizona sce ua method proposed by duan et al 1992 was used to calibrate the usf model it is a well known global optimization strategy developed for the effective and efficient calibration of the watershed models by optimizing a single objective function for up to 16 parameters duan et al 1992 green and van griensven 2008 this method combines a simplex method with the concept of controlled random search for the competitive evolution of the population with complex shuffling the algorithmic parameters of sce ua method were selected as per the recommendations of duan et al 1993 in the first step of the method it generates an initial population as the first generation by random sampling from the feasible parameter space which was defined by setting the lower and upper search range for p number of parameters to be optimized from the second generation onwards this population is partitioned into several complexes each of which is permitted to evolve independently size of the population produced in each generation was decided based on the number of parameters in the target model the number of complexes c was set equal to 20 and the number of populations in each complex r 2 p 1 the objective function to be minimized using the sce ua method was selected as the root mean squared error rmse between the observed and simulated discharge common use in hydrological modeling and simplicity were the reasons for the selection of rmse as the objective function ebtehaj et al 2010 wmo 1992 the calibrated parameters are functionally dependent on the length and properties of the calibration data objective function used for calibration etc and these factors subsequently affect the model simulations the seven parameters of usf model are shown in table 1 with their descriptions and search range used in the sce ua parameter optimization method padiyedath et al 2018a takasaki et al 2009 a narrow search range will constrain the parameters and the calibrated parameters will not reflect the actual watershed characteristics therefore a wide search range was defined instead of a narrow one by considering the possible physical minimum and maximum parameter values the model calibration was conducted using three data scenarios i whole data based scenario where all the available events were used for the model calibration ii individual event based scenario where individual flood events were used iii leave one out scenario where leaving out each flood event at a time from the all available events and calibrating on the remaining events the model performance during calibration was analyzed by simulating the flood events using the whole data based and individual event based parameters the performance of a model derived from the calibration data set is insufficient evidence for its satisfactory performance since no simulation model is intended merely to show how well it fits the data used for its development thus the data used for model validation should be different as those used for calibration but must represent a situation similar to that for which the data are to be generated kleme≈° 1986 therefore to test the operational performance of the model we have used the calibrated parameters from the individual event based scenario and the leave one out scenario the available flood events are split into two segments in which the first segment consists of one flood event at a time and the second segment is comprised of the remaining flood events the calibrated parameters of the individual event based and leave one out scenarios from the second segment are used to validate the model on the first segment for example event 1 forms the first segment and the second segment is composed of the remaining flood events events 2 5 the calibrated parameters of individual events 2 5 four parameter sets and the whole events except 1 one parameter set are used to validate the event 1 this calibration was repeated by leaving out the subsequent flood event one at a time from the available events 2 3 residual based bootstrap method the classical idea behind the bootstrap method is the resampling and extraction of m samples from the original data with an unknown distribution having a size of n this method makes no assumptions concerning the distribution of data or model being used the m bootstrap samples can provide the best knowledge regarding the underlying true distribution of the sample however the use of bootstrap for time series data was limited because the classical bootstrap technique assumes that the data set is independent and identically distributed iid efron 1982 which means each data of the data set will be mutually independent and selected from the same population generally the time series data sets are highly dependent in nature and it is quite unreasonable to perform classical bootstrapping as it destroys the original dependency structure of the time series in order to overcome the problem of dependence of time series the bootstrap method can be extended either as a block bootstrap davison and hinkley 1997 k√ºnsch 1989 in which the time series is divided into different blocks and these blocks are resampled instead of the individual data value or as a model based bootstrap lahiri 2003 selle and hannah 2010 which adopts a specific time series form of dependence in selle and hannah 2010 they considered a first order autoregressive model to consider the dependence of model error rather than assuming it is independent however a modification of this approach which can be simpler to apply in practice is to construct the bootstrap samples as fitted values plus residuals where the residuals are sampled with replacement from the observed distribution of residuals this method is known as the resampling of residuals shalizi 2016 shao and tu 1995 hereafter residual based bootstrap the residual based bootstrap approach was used to generate sample estimates of the hydrologic model parameters corresponding to the calibrated data set and to quantify the associated uncertainties in this method first we calibrate the model and then simulate by resampling residuals to that estimate and adding them back to the fitted values shalizi 2016 this surrogate data set is then re analyzed like a new data set by repeating the procedure m times bootstrapped time series are generated and the hydrologic model is then calibrated using each bootstrapped time series to arrive at bootstrapped estimates of the calibrated parameter sets these estimates are further used for the confidence interval analysis of the model parameter estimators however the residual based bootstrap method is usually based on some model assumptions although it requires no theoretical formula for the quantity to be estimated and is less model dependent than the traditional approach shao and tu 1995 the general assumptions for performing the residual based bootstrap are given as 1 the residuals are independent of each other 2 the residuals are identically distributed 3 the residuals are homoscedastic 4 the residuals are a good approximation of the observed data and model structure error 5 the residuals are randomly selected from their population with equal probability the procedure for the residual based bootstrap explained by stine 1985 and others shalizi 2016 shao and tu 1995 is described as follows consider the original data set x n q n where x n is the input data q n is the observed discharge data and n is the data length the observed discharge can be written as a function q n f x Œ∏ Œµ n where x x 1 x n Œ∏ is the parameter vector Œ∏ 1 Œ∏ p with p being the number of model parameters and Œµ n is the model residuals initially the model was calibrated using the sce ua method to obtain the calibrated parameter vector Œ∏ which was further used along with the input data to compute the model calibrated discharge data q n f x Œ∏ which can be demonstrated as q n f x Œ∏ Œµ n thereafter the model residuals can be expressed using the following equation 5 Œµ n q n q n q n f x Œ∏ the model residuals Œµ n were assumed to be iid for all n which is one of the assumptions made for the bootstrapping stine 1985 julian and gardner 2014 examined the effect of land cover on runoff patterns and the results revealed that increases in urbanization caused a decrease in long term hydrologic memory in urban watersheds the impervious surfaces decrease water storage which is the predominant factor that affecting long term hydrologic memory and the runoff became flashier julian and gardner 2014 this flash flood decreases the watershed hydrologic memory therefore the resulting model residuals of urban watersheds can be assumed to hold low memory due to the quick runoff response resulted from the increased percent of impervious surfaces the detailed residual based bootstrapping procedure is outlined as follows 1 bootstrap resampling of the residual time series Œµ n with replacement to form new bootstrapped residual series Œµ j n where j 1 m 2 add the new bootstrapped residual series Œµ j n to the calibrated discharge data q n to form the bootstrapped discharge series as q j n q n Œµ j n this bootstrapped discharge series will form the replication of the observed discharge series 3 calibrate the bootstrapped discharge series q j n with input data set x and obtain the j th bootstrapped parameter vector Œ∏ j using sce ua method and the associated simulated discharge series q j n f x Œ∏ j by this way the model can be re fitted to each bootstrapped discharge series q j n yielding bootstrap estimates of model parameters 4 derive the ordered bootstrap estimates Œ∏ j Œ∏ j 1 Œ∏ j p obtained after the bootstrap resampling method then the 95 ci for Œ∏ j was estimated from the ordered bootstrap samples the essential idea of this bootstrap approach is that the pseudo replicate samples bootstrap samples drawn at random with replacement from the data can be used to furnish information about the uncertainty of quantities estimated from the data selle and hannah 2010 the precision of a bootstrap estimate depends on the number of times the original data set is randomly resampled i e how many bootstrap replicates the bootstrap estimate converges to a consistent range of values as the number of resamples become large by the law of large numbers meyer et al 1986 efron and tibshirani 1993 suggested that the number of bootstrap samples should be at least 1000 therefore all the computations performed in this study were based on 1000 bootstrap replicates m 1000 from which the confidence intervals for the original corresponding parameter estimates can be calculated this method has asymptotic convergence properties which means that by increasing the number of simulated bootstrapped time series estimation error will be reduced ebtehaj et al 2010 the whole data based and individual event based scenarios described in section 2 2 were used to perform the residual based bootstrapping in order to identify the parameter fluctuation under the varying conditions of available data scenarios 2 4 model parameter uncertainty quantification the performance of hydrological models is significantly affected by the calibrated parameter uncertainty the parameter uncertainty is generally expressed by estimating the ci of the parameters however the ci gives the uncertainty range of each parameter from which it is difficult to identify the parameter with the highest and least uncertainty due to the different ranges of parameter values therefore it is necessary to propose certain indices which can interpret the ci of parameters with different ranges and clearly differentiate them based on their contribution to the uncertainty therefore in addition to the statistical estimators of the mean Œ∏ median Œ∏ 50 and the coefficient of variation cv of the m parameter sets from bootstrapping method two indices were proposed for assessing the uncertainty of model parameters model parameter uncertainty indices which can elucidate the ci in a better way here the indices are considering the individual parameters rather than the parameter vector in order to derive the parameters from the highest to the lowest uncertainty selle and hannah 2010 the first parameter uncertainty index pu i 1 utilizes the width of the ci and hence the parameter with a small index value will be less uncertain as compared with other parameters the second parameter uncertainty index pu i 2 compares the median value from the confidence region with the calibrated parameter vector Œ∏ and it should be minimum for the stability of the parameters the model parameter uncertainty indices are given as 6 pu i 1 i Œ∏ 97 5 i Œ∏ 2 5 i Œ∏ i 100 7 pu i 2 i Œ∏ i Œ∏ 50 i Œ∏ i 100 where Œ∏ 97 5 is the 97 5th percentile Œ∏ 2 5 is the 2 5th percentile and Œ∏ 50 is the 50th percentile median for the i th parameter obtained from bootstrapping Œ∏ is the calibrated parameter 2 5 model simulation uncertainty the model simulation uncertainty is referred to as the uncertainty of simulated discharge q j which occurs due to the calibrated parameter uncertainty and is illustrated as the 95 ci of simulated discharge series by the model this 95 ci should envelope most of the observations and at the same time it is desirable to have a narrow envelope swain and patra 2017 p factor is a statistical term used for the assessment of model simulation uncertainty and is calculated as the percentage of original discharge data at each time step that lies within the 95 ci yang et al 2008 the value of the p factor ranges between 0 and 100 and the goodness of model simulation uncertainty is judged based on the closeness of p factor to 100 i e all observations bracketed within the 95 ci the p factor is computed as follows 8 p factor n n 100 where n is the number of original observed discharge values at each time step that are bracketed within the 95 ci in addition to the p factor two other indices have been proposed for assessing the uncertainty of model simulated discharge model simulation uncertainty indices by utilizing the 95 ci similar to the model parameter uncertainty indices the model simulation uncertainty indices sui are given below 9 su i 1 1 n t 1 n q 97 5 t q 2 5 t q t 100 10 su i 2 1 n t 1 n q t q 50 t q t 100 where q 97 5 t q 2 5 t and q 50 t are the 97 5 2 5 and 50 levels of the cumulative distribution of the model simulated discharge series respectively q t is the observed discharge data 2 6 rainfall spatial variability usually the characteristics of rainfall events are spatially distributed and different from others even for the same watershed due to the effect of several meteorological factors which will result in the different parameter values moreover there will be an interaction between the spatial variability in rainfall and the spatial storage distribution which controls the discharge the discharge response at the outlet point to an averaged input will differ significantly from that to a distributed input shah et al 1996 high spatial variability of rainfall in the basin can affect the runoff prediction capability of usf model since it uses the average basin rainfall therefore further analysis was carried out to have a clear understanding about the extent of spatial variability of rainfall in the watershed by computing the percentage variation of total rainfall obtained from each rain gauge with respect to the mean rainfall from all the gauges the percentage variation can be computed using the following formula 11 v a r i a t i o n i t r i tr tr where t r i is the total rainfall from gauge i mm and tr is the mean rainfall from all the gauges mm 3 study area and data used the urban watershed of the upper kanda river basin having an area of 7 7 km2 at koyo bridge as shown in fig 1 was selected for the study the basin lies between latitudes 35 70 n and 35 64 n and longitudes 139 56 e and 139 64 e in tokyo japan with an urbanization rate of 97 since 2003 tmg 2016 the river originates from the inokashira pond and joins the zenpukuji river and flows east ando and takahasi 1997 the drainage pattern follows the combined sewer system and 100 of the population is connected to the sewer the urban landscape gis delineation was used to precisely estimate the impervious area percentage as 68 koga et al 2016 that significantly reduced the water retention capacity of the basin the computed time of concentration of surface runoff from the upstream reaches to the watershed outlet was about 30 min the reduced time of concentration indicated that the river discharge will occur immediately after the rainfall within a short period and it is desirable to use the hydrological data at very short time intervals for the rainfall runoff analysis therefore rainfall and water level data at one minute intervals were collected from the bureau of construction tokyo metropolitan government tmg during 2003 2006 for the present study the average rainfall of the basin was determined using the thiessen polygon method from the eight rain gauges scattered over the basin as shown in fig 1 five target events whose 60 minute maximum rainfall r60 was greater than 30 mm and were capable of producing flash floods were selected from the data table 2 shows the characteristics of the five selected rainfall events the inflow component i in the continuity equation was fixed at 0 0012 mm min based on the annual report of the bureau of construction tmg the water intake o from the basin and evapotranspiration e were set at 0 as there was no intake from the target basin and the evapotranspiration during heavy rainfall is insignificant padiyedath et al 2018b the maximum storm drainage q r m a x was estimated as 0 033 mm min using manning s equation 4 results and discussion 4 1 model calibration and performance the sce ua optimization method was applied for calibrating the usf model in the target watershed with rmse as the objective function for the considered data scenarios discussed in section 2 2 in the whole data based scenario all the selected events were considered for model calibration and a single set of parameters was derived from all the events on the other hand in the individual event based scenario each event was considered for model calibration the leave one out scenario leaves out one flood event at a time and calibrating on the remaining events the convergence of parameters was checked and the parameters were found to converge before the 50th generation in each sce ua application run thereafter the best parameter set Œ∏ among the population at the 50th generation with a minimum rmse value was used for the further simulations fig 2 shows the calibrated model parameters using the considered data scenarios in which the whole data based parameters are represented by a black line and the individual event based and leave one out parameters are depicted by the blue circles and red triangles respectively it is clear from fig 2 a and g that the individual event based parameters k 1 and Œ± are identical in all the events and are similar to the whole data based parameter values also the parameters k 2 and p 1 as shown in fig 2 b and d respectively have similar values in the data scenarios even though they exhibit slight variations between events however the remaining individual event based parameters k 3 p 2 and z are varying significantly between events and are similar to the whole data based parameters only during certain events the parameters k 3 and z represent the loss to the groundwater takasaki et al 2009 the z values close to zero indicate a high rate of recession and higher z values represent a higher river flow at the outlet point instead of contributing to the groundwater the higher value of z in event 1 can be attributed to its meteorological factor which is an intensive localized storm as shown in table 1 parameter p 2 portrays the change in storage during the rising and recession limbs of a hydrograph based on the type of rainfall event hoshi and yamaoka 1982 the higher p 2 values exhibited during events 1 and 3 as shown in fig 2 e may be possibly due to differences in meteorological factors from other events the leave one out parameters at each event number represent the calibrated parameters from the flood events except that particular event for example the parameters at event number 1 in fig 2 show the calibrated parameters from all the flood events except event 1 the leave one out parameters exhibit close resemblance with the whole data based parameters except for leaving out event 1 the results confirm that the parameters k 3 p 2 and z will have a prominent effect on the estimation of discharge due to their high variability also the meteorological factors can significantly affect parameter values during the model calibration however the considered data sets are not sufficient to generalize the above discussions despite providing a brief description of parameter uncertainty therefore to have an elaborative idea of calibrated parameter uncertainty the bootstrap approach was employed for generating samples which could be further utilized for conducting the uncertainty analysis thereafter the model performance on estimating discharge using the whole data based and individual event based parameters was analyzed table 3 presents the detailed performance evaluation using the statistical indicators of rmse nash sutcliffe efficiency nse nash and sutcliffe 1970 percentage error in peak pep and percentage error in volume pev padiyedath et al 2018a additionally fig 3 provides a visual representation of the hydrograph reproduced by the model for both the data scenarios it is apparent from table 3 that the model with individual event based parameters has lower values of rmse and higher values of nse in all the events as compared to the whole data based parameters it is evident from the table that the pep values estimated by the model using the individual event based parameters were very low close to zero compared to that from the whole data based parameters even though the model exhibited a higher pep value during event 1 and was not greater than 10 during any of the events fig 3 also shows that the model was able to reproduce the peak discharge with utmost accuracy using the individual event based parameters on the other hand the model with whole data based parameters exhibited remarkable anomaly in the reproduction of peak values especially in events 4 and 5 likewise the pep usf model shows the best performance in pev values using the individual event based parameters as shown in table 3 which is close to zero as compared to that of the whole data based parameters the results further confirmed that the difference between the values of statistical indicators shown in table 3 for the considered data scenarios is quite large and significantly greater for events 4 and 5 it can also be envisaged from fig 3 that the calibrated discharge using the individual event based parameters by usf model nearly overlaps with the observed river discharge and reproduces the shape of the observed hydrograph with only slight variations on the contrary the model with whole data based parameters deviated significantly while reproducing the shape of the hydrograph therefore the results indicate that the individual event based parameters can exactly reproduce the shape of the observed hydrograph as well as the peak discharge by significantly reducing the rmse by 50 compared to that of the whole data based parameters during the calibration hence it is necessary to consider the calibration based on individual flood events for the parameter uncertainty analysis rather than considering the whole data based calibration alone 4 2 model validation the model validation on independent sub events was carried out to assess the operational performance of the usf model fig 4 a1 a5 shows the reproduced hydrographs during the validation using the leave one out parameters as well as the individual event based parameters it is clear from fig 4 a1 a5 that the simulated discharge using the calibrated parameters of individual event based scenario has highly deviated from the observed discharge except event 3 on the other hand simulated discharge using the parameters of leave one out scenario and event 3 was close to the observed discharge during validation however it is not easy to clearly portray the difference between the simulated discharge hydrographs of these cases from fig 4 a1 a5 hence we evaluated the performance further using the same performance evaluation criteria of rmse nse pep and pev that used during the calibration and is shown in fig 4 b1 b5 the left y axis of fig 4 b represents rmse and nse while the right y axis depicts the pep and pev values it can be envisaged from the figure that the parameters from event 3 and the leave one out scenario consistently generated the lowest rmse and highest nse for reproducing the hydrographs in validation the remaining individual event based parameters exhibited low performance in terms of rmse and nse during validation on the selected sub events in the same way the pep and pev values were also close to zero in the case of event 3 and the leave one out scenario parameters and the rest of the cases exhibited varying values of pev and pev the validation based on event 3 and leave one out scenario performed equally in terms of rmse and other performance evaluation criteria similar to that exhibited in calibration table 3 the calibration of usf model over specific flood events and validation on independent flood events revealed that the model with leave one out parameters has consistent performance compared with the individual event based parameters this leave one out parameters represent the robust parameter set of the model and can be implemented for operational use in the context of flood simulation however there arises a question that which calibration approach is the most performant subject to validation based on the above discussions it is recommended that the model should be calibrated with all the available flood event data to get a more robust parameter set for the flood simulation vaze et al 2010 studied the effect of calibration periods on model simulation and their study revealed that the model calibration on a portion of the record with conditions similar to those of the future period to simulate can provide a more reasonable set of parameters this result was supported by de vos et al 2010 who suggested clustering time series according to climate similarities during calibration therefore the usf model could be calibrated using the available flood events since usf is a flood event based model for the flood simulation in urban watersheds with combined sewer system these calibration techniques will provide a minimum standard for operational validation of the model however it needs more such calibrations at different sub periods including more flood events to arrive at a conclusion moreover moore et al 2007 suggest that in many situations it is hard for the lumped conceptual models to outperform in operational use for flood simulation therefore it is recommended that further work is undertaken on alternative formulations which will describe the operational adequacy of the model 4 3 model parameter uncertainty analysis the calibration parameter uncertainty analysis was conducted using the five available flood events under the whole data based and individual event based scenarios the computed model residual series eq 5 was used to perform the resampling process for 1000 times by employing the residual based bootstrap approach then associated bootstrapped discharge series were generated by adding 1000 bootstrapped residual series to the calibrated discharge series as described in section 2 3 these bootstrapped discharge series q j t were used to obtain the j th bootstrapped parameter vector Œ∏ j of the usf model for both the whole data based and individual event based scenarios fig 5 shows the scatter plots of the bootstrapped parameter vectors with their 95 ci in grey shading the search range shown in table 1 is illustrated as the left y axis and the percentage contribution of 95 ci to the search range is depicted on the right y axis of fig 5 it is apparent from fig 5 a1 f1 that the k 1 values lie close to the lower limit of the search range and converged to a reduced range between 20 and 70 in all the cases the 95 ci of parameter k 1 have a comparable width in all the cases and constitute about 1 5 of the search range which is quite narrow the scatter plot of parameter k 2 was narrow as well as close to the lower search range with values clustered around 500 2000 as shown in fig 5 a2 f2 similarly the 95 ci of k 2 was also narrow for the whole data based parameter and was quite similar to the values of events 1 and 3 as compared to this pattern the ci was relatively wide during the rest of the events the parameter k 3 has a widespread pattern as compared to parameters k 1 and k 2 as shown in fig 5 a3 f3 the 95 ci of k 3 was wide and its contribution to the search range was high except for event 3 and the whole data based scenario there is a well spread pattern for parameter p 1 from 0 1 to 1 within the search range whereas most of the p 2 values accumulated near the lower search range between 0 1 and 0 7 as shown in fig 5 a4 f4 and a5 f5 respectively the 95 ci of these parameters are wide as compared to k 1 and k 2 with a high percentage contribution to the search range it is evident from fig 5 a6 f6 that most of the z values are gathered near the lower limit of the search range and the 95 ci is relatively wide parameter Œ± demonstrated a very widespread pattern with values close to the upper search range as depicted in fig 5 a7 f7 the 95 ci of Œ± was wide in all the scenarios and constituted about 25 50 of the search range it can be envisaged from fig 5 that the scatter plot of whole data based parameters is similar to the parameter pattern exhibited in event 3 which further indicate that the events with a large number of observations have domination on the whole data based model calibration even though a wide search range was considered certain parameters converged to a very narrow range on the other hand some parameters showed a widespread pattern from the lower to the upper limit of the search range this could be a reflection of the equifinality concept beven and freer 2001 and reconsideration of this search range could enhance the performance of the model in cases where parameter values accumulate on the search range boundaries additionally a larger number of bootstrap resamples can lead to a narrow 95 ci due to the convergence of parameters as observed in the study of selle and hannah 2010 fig 6 shows the statistical representation of fig 5 in terms of the box whisker plot of 1000 bootstrapped parameter vectors for both the data scenarios in which the bottom and the top lines of the boxes show the 25th and 75th percentiles respectively and the line passing through the box represents the median Œ∏ 50 the whiskers extend to the 2 5th and the 97 5th percentiles and the highest and lowest observations are plotted as asterisks additionally fig 6 represents the mean Œ∏ as the blue square and cv values at the top of the bootstrapped parameter vectors along with the calibrated parameter values Œ∏ as the red circle detailed descriptions of the plot are given in the figure caption it is clear from fig 6 a and b that the bootstrap estimates of Œ∏ 50 and Œ∏ of parameters k 1 and k 2 have similar values and are very close to the calibrated Œ∏ values in all the events however the parameter k 3 exhibited differences in the Œ∏ values during event 1 as depicted in fig 6 c it is apparent from fig 6 d that the Œ∏ 50 and Œ∏ values of p 1 are similar except for event 4 whereas the Œ∏ and Œ∏ values are identical except for events 4 and 5 on the other hand the Œ∏ 50 Œ∏ and Œ∏ values of parameter p 2 were close enough except for event 5 as shown in fig 6 e similar to the parameter p 2 the Œ∏ 50 Œ∏ and Œ∏ values of parameter z in fig 6 f were identical except in event 1 subsequently the Œ∏ values of Œ± exhibited minor discrepancy only in event 5 as compared to the Œ∏ 50 and Œ∏ values as illustrated in fig 6 g overall the Œ∏ values were in accordance with the Œ∏ 50 and Œ∏ values in most of the cases even though the Œ∏ values show minor deviations the cv values also varied between scenarios as shown in fig 6 during the whole data based analysis the highest cv value of around 133 was observed for parameter z and the least cv value was noted for parameter k 2 further the parameters were ordered based on their cv values as follows z Œ± k 3 p 1 p 2 k 1 k 2 however for the individual event based analysis during event 1 the highest cv value was exhibited by the parameter k 3 which was followed by parameter z the order of parameters based on cv values are k 3 z p 1 Œ± p 2 k 2 k 1 the same order for event 2 was p 2 k 3 z p 1 k 2 Œ± k 1 during events 3 and 4 based on the cv values the parameter z had the highest uncertainty on the contrary parameters p 2 and z had very high cv values as compared to other parameters during event 5 therefore the results reveal that the parameter with the highest and lowest uncertainty varies from case to case however z and k 1 were the parameters with the highest and lowest uncertainty respectively based on their cv values in most of the cases selle and hannah 2010 identified the parameter with the highest uncertainty of a conceptual salt load model using the cv value as the only index however in this study two proposed indices were computed in addition to the cv for objectively assessing the parameter uncertainty in order to have a clear understanding of the 95 ci as well as the median values of the parameters as shown in fig 7 in this figure the pu i 1 and pu i 2 index values of parameter z for the whole data based scenario is represented at the figure boundaries with their values since the Œ∏ value of parameter z was very close to zero in the whole data based scenario as shown in fig 2 f the calculated pu i 1 and pu i 2 values of z were very high and represented at the boundaries it is evident from fig 7 a that the parameter z has the highest value of pu i 1 during events 3 and 4 and also in the whole data based case which further indicates that z had the highest uncertainty in most of the considered scenarios based on pu i 1 this higher pu i 1 value of z can be interpreted as to its wide 95 ci and calibrated parameter values close to zero during these scenarios however the parameter p 2 demonstrated a higher value of pu i 1 during events 2 and 5 which could also be attributed to its very wide 95 ci as compared to other parameters as shown in fig 5 c5 and f5 while parameter p 1 has got the highest pu i 1 value during event 1 the parameters k 2 and k 1 demonstrated the lowest uncertainty from the cases whose 95 ci was very narrow as compared to the rest of the parameters the remaining parameters showed a different order of pu i 1 values in the considered scenarios based on their 95 ci width and the calibrated parameter values the high uncertainty in terms of pu i 2 was exhibited by the parameter z in all the cases except for event 3 as illustrated in fig 7 b during event 3 all the parameters exhibited a small magnitude of uncertainty and were comparable to each other even though the pu i 1 portrayed z as the most uncertain parameter in event 3 which can be further interpreted as the very similar median and calibrated values of parameters also for a narrow ci the median and calibrated parameter values will come closer and further the pu i 2 values will approach zero the parameter z exhibited negative pu i 2 values with a high magnitude in the whole data based scenario and event 4 which was significantly high in the whole data based scenario these high magnitude negative pu i 2 values indicate that the bootstrap median values are much higher than the calibrated parameters the results revealed that the difference in both the calculated indices pu i 1 and pu i 2 is because both represent different aspects of uncertainty analysis the parameter z represents the infiltration hole height in the usf model takasaki et al 2009 which depends upon parameters like basin storage and rainfall intensity and will vary greatly from event to event with the highest uncertainty additionally the optimum value of z estimated from the model calibration is close to zero with a very wide range of bootstrapped parameter values as shown in fig 5 a6 f6 which also makes it the most uncertain parameter the parameter with higher uncertainty after z varied from case to case however based on the pu i 1 and pu i 2 values p 1 p 2 Œ± k 3 and k 2 had higher uncertainty values after parameter z for most of the cases the 95 ci of these parameters are relatively wide which can be transformed into higher index values the parameter k 1 exhibited the least uncertainty one of the reasons for this could be the fact that parameter k 1 describes features of the watershed sugiyama et al 1997 and there is a very low chance of a change in watershed features within a short span this further indicated that parameter k 1 remains reasonably stable under varying input data scenarios besides the equifinality concept can also derive parameter uncertainty by generating non unique parameter sets during the calibration process and there will be a lot of different parameter combinations that lead to multiple optimal solutions beven and freer 2001 yang et al 2008 however this parameter uncertainty can be overcome to some extent by using global searching techniques during calibration 4 4 model simulation uncertainty the uncertainty in model simulation due to the calibrated parameter uncertainty was estimated by computing the 95 ci of the 1000 simulated discharge series generated by the bootstrapped parameters from the whole data based and the individual event based scenarios fig 8 shows the 95 ci of simulated discharge uncertainty range for each event from both the whole data based and the individual event based scenarios during calibration it is desirable to have a narrow range and fig 8 a1 b1 shows that the uncertainty range from the whole data based parameters at the peak flows of event 1 is wider than the range simulated from the individual event based parameters however the width of the uncertainty range at low flows was almost identical for event 1 from both the scenarios fig 8 a2 b2 shows that the uncertainty range was unable to capture the observed values during the flood peak of the whole data based scenario whereas the uncertainty range of individual event based scenario was able to bracket a large amount of the observed values including the flood peaks the uncertainty range of the whole data based scenario illustrated in fig 8 a3 b3 included the highest flood peak value with a wide uncertainty range on the other hand the uncertainty range of the individual event based scenario was very narrow and was close to the observed peak flows and hence was not able to capture the flood peaks during events 4 and 5 from the whole data based parameters most of the flood peak values were falling inside the uncertainty range even though the low flows were not well captured as shown in fig 8 a4 and a5 concurrently the uncertainty range of the individual event based scenario was able to capture almost all the flows except the peak value during events 4 and 5 as shown in fig 8 b4 and b5 overall the whole data based scenario captured the observed discharge with a very wide uncertainty range whereas the individual event based scenario bracketed observations within a very narrow uncertainty range during calibration also as can be seen from fig 8 that the uncertainty range is very narrow at the low flows for both the scenarios hence it can be concluded that the model simulates peak discharge with higher uncertainty as compared to low flows high uncertainty in the model simulation during flood peaks can be attributed to the influence of low flows as they may have dominated the parameter estimation process due to their greater numbers as compared to the peak flow gallagher and doherty 2007 however it is essential to estimate flood peaks with lesser uncertainty as compared to the low flows due to the high risk factor associated with them it is possible to do so by calibrating the model parameters using a specific objective function which can initiate the type of simulation that the model is required to make in order to portray the differences in the model simulation uncertainty during calibration a detailed uncertainty analysis was further conducted using the p factor and the two proposed model simulation uncertainty indices su i 1 and su i 2 fig 9 shows the model simulation uncertainty for the whole data based and the individual event based scenarios using the p factor su i 1 and su i 2 the p factor value as defined by eq 8 close to 100 represents the capability of the model to reasonably capture almost all the observed discharge values within the uncertainty range similarly the values of su i 1 and su i 2 close to zero indicate low uncertainty of the model in simulating the discharge it is clear from fig 9 a that the obtained value of p factor is higher for events 1 2 and 5 in the individual event based scenario and the whole data based scenario showed higher values of p factor during events 3 and 4 even though the p factor of individual event based analysis is lower than the whole data based analysis in events 3 and 4 the difference between the values is quite small the individual event based scenario captured an almost equal number of observations with a very narrow uncertainty range especially at the peak flows in event 3 compared with the whole data based scenario that resulted in an almost equal p factor the high uncertainty of parameter z during event 4 in terms of parameter uncertainty indices as shown in fig 7 could be a reason for the low p factor exhibited by the individual event based scenario in event 4 subsequently values of the proposed index su i 1 derived from the individual event based analysis were less than the values derived from whole data based analysis in all the events except for event 1 as shown in fig 9 b during event 1 the su i 1 value of both the scenarios was similar and the whole data based scenario received the least value the results revealed that the width of the uncertainty range is narrow relative to the observed discharge values in the individual event based analysis as compared to the whole data based analysis the individual event based values of su i 2 were also close to zero in all the events except for event 4 as illustrated in fig 9 c the su i 2 values were negative for events 4 and 5 in the whole data based scenario which indicates that the observed discharge values were lesser than the median values and lied in the lower confidence region in the same way values from the individual event based analysis were mostly positive except for events 1 and 3 and were found in the upper confidence region overall considering all the indices the simulation uncertainty was lower during the individual event based analysis as compared to the whole data based analysis 4 5 rainfall spatial variability the results revealed that the model simulation uncertainty varies from event to event as well as from the considered data scenarios this can be ascribed to the difference in parameter values in each event and the whole data based scenario resulted from the spatial variability in rainfall therefore further analysis was carried out to have a clear understanding of the extent of spatial variability of rainfall in the watershed fig 10 shows the percentage variation of total rainfall obtained from each rain gauge with respect to the mean rainfall from all the gauges it is clear from fig 10 that during event 1 the variation of two gauges are around 30 whereas the same in event 2 for one gauge is about 40 these high percentage variation values of rainfall exhibited by several rain gauges indicate that there is a relatively high spatial variability in rainfall during events 1 and 2 however all the gauges showed relatively low variability except one gauge during event 3 which resulted in an overall low spatial variability in this event moving to events 4 and 5 almost all the gauges portrayed high percentage variation values ranging from 60 to 60 and exhibited the highest spatial variability this high spatial variability exhibited by the rain gauges in each event can be attributed to their completely different rainfall pattern and this could be a cause of the high uncertainty in simulations during the whole data based scenario the model parameters were averaged spatially as well as temporally over the watershed without considering the spatial variability of rainfall as well as the meteorological factors that caused the rainfall events and the estimated model parameters will be different from the true watershed parameters chaubey et al 1999 this could be a possible reason for the high simulation uncertainty exhibited by the model in the whole data based scenario however during the individual event based scenario the catchment properties are only spatially averaged not temporally this will lead to a reduced simulation uncertainty in the event based scenario compared with the whole data based scenario at the same time lumping up of the complex spatially varying catchment properties such as rainfall inflow etc in a model will induce considerable errors associated with the spatially averaged input data cooley 2004 and further affect the model simulation uncertainty in both the data scenarios notwithstanding the problems associated with the spatial averaging of the watershed processes the usf model was able to simulate the discharge with reasonable accuracy in the individual event based and the whole data based scenarios using the bootstrap approach associated with the sce ua method therefore the bootstrap approach will contribute to the development of parsimonious hydrologic models selle and hannah 2010 with reliable estimates of parameter uncertainty in this study we found that the range of simulation uncertainty due to the parameters is relatively small apart from parameter uncertainty input data measurement errors from all sources and model structure errors also cause model simulation uncertainty sivakumar and berndtsson 2010 however it is not practicable to define the extent to which the other sources of uncertainties will affect the model simulation uncertainty based on our present study 5 conclusions the residual based bootstrap technique was utilized to analyze the calibration parameter uncertainty of the usf model to assess its impact on the model simulation in the upper kanda river basin an urban watershed in tokyo the bootstrap approach was applied to the individual flood events for the first time due to the relevance of flood runoff analysis in urban watersheds along with the available whole data in order to demonstrate the impact of different available data scenarios on the calibration uncertainty behavior of the parameters the 95 ci of certain parameters converged to a very narrow range as compared to the search range while some parameters showed a wider confidence range from the lower to the upper limit of the search range in both the scenarios further the parameter uncertainty was scrupulously analyzed and the parameters with the highest and the lowest uncertainty were identified by utilizing two newly proposed indices that are based on the width of the confidence interval and the median value although the order of the model parameters assigned during the uncertainty analysis based on the proposed indices differs the significant parameters yielded was the same hence the proposed indices could be useful in future studies to derive the parameters from the highest to the lowest uncertainty additionally the effect of parameter uncertainty on the model simulation was investigated by computing the 95 ci of 1000 simulated discharge series generated from the bootstrapped parameters and by utilizing the p factor and two other proposed indices for assessing the model simulation uncertainty the results revealed that the simulation uncertainty is low in the individual event based analysis compared with the whole data based analysis based on all the considered indices also the uncertainty range was wider at the peak flows and hence the model simulated peak discharge values had higher uncertainty than low flows as a conclusion the parameter uncertainty and its effect on model simulation uncertainty were successfully evaluated and the characteristics of an urban specific rainfall runoff model usf model were explained in detail using the bootstrap approach the residual based bootstrap approach used in this study assumed an independent and identically distributed model residual series however this assumption does not seem to be appropriate after looking at the autocorrelation plot of residuals the residuals demonstrated a short term persistence although the residual autocorrelation function decayed exponentially and was statistically insignificant beyond a lag of 6 min one solution to tackle this issue is the use of block bootstrap resampling of the residual with sufficiently long blocks to preserve the time dependence of the residuals another possibility is the use of the autoregressive component to reconstruct auto correlated bootstrap residuals selle and hannah 2010 have already carried out such an improvement and obtained comparable results from both bootstrap approaches it is also important to conduct comparative studies between the bootstrap and other techniques for parameter uncertainty analysis which will reveal the strength and weaknesses of the bootstrap approach the violation of the assumptions made during uncertainty analysis by the bootstrap method may lead to the inadequate characterization of simulation uncertainty therefore it is desirable to validate the simulation uncertainty using observations which will further provide some empirical evidence that the bootstrap method provides a good estimation of parameter and simulation uncertainties further the parameter variance obtained from this uncertainty analysis can be used in the data assimilation approaches for the real time prediction of flood and will give confidence to the hydrologist who uses the model in an operational context however this study primarily focused on the residual based bootstrap approach for the calibration parameter uncertainty analysis and its subsequent effect on model simulation uncertainty we will carry out further research on the aforementioned areas by considering the residual correlation and heteroscedasticity declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this study was carried out as a part of the research project entitled study on guerrilla rainstorm flood and water pollution in megacity urban watersheds countermeasures against megacity urban water related disasters bipolarized by climate change supported by tokyo metropolitan government japan represented by prof akira kawamura appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124195 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6065,the predictions made using rainfall runoff models are inherently uncertain and it is important to recognize and account for this uncertainty especially in urban watersheds due to the high flood risk in these areas recent studies on hydrological model uncertainty mostly refer to the identification of model parameter uncertainty however such studies are somewhat limited using the bootstrap approach a nonparametric method which makes less prior assumptions on the model structure and thus is more flexible hence a residual based bootstrap approach associated with the sce ua global optimization algorithm is demonstrated in this study for the analysis of calibrated parameter uncertainty and its subsequent effect on the model simulation of an urban specific rainfall runoff model urban storage function usf model under two different data scenarios of individual event based and whole data based scenarios initially the parameter uncertainty was expressed by estimating the confidence interval ci of the usf model parameters obtained from bootstrapping and then the parameters from the highest to the lowest uncertainties were derived by utilizing two newly proposed parameter uncertainty indices which can make the best use of ci moreover investigations on the effect of calibrated parameter uncertainty on model simulations revealed that the model was able to bracket most of the observations within the prediction range of considered scenarios this further indicates that the residual based bootstrap approach along with the sce ua method reasonably well predicted the uncertainty range of the usf model for a better understanding of simulation uncertainty we defined and demonstrated two model simulation uncertainty indices and these indices could be useful in future studies to analyze the simulation uncertainty of different rainfall runoff models in the watersheds worldwide keywords model parameter uncertainty urban storage function model residual based bootstrap method model parameter uncertainty indices model simulation uncertainty indices 1 introduction in urban watersheds the urban areas occupy most of the basin from upstream to downstream and are under constant development in terms of buildings roads other infrastructures etc kawamura 2018 there is no specific definition of urban watersheds quantitatively in terms of the threshold urban area however according to kjeldsen 2010 and salavati et al 2016 the watersheds with an urban area percentage greater than 15 can be considered as urban watersheds the modeling of urban watershed processes is complicated due to the increasing complexities of the urban hydrologic system that can be attributed to urbanization rapid population growth model scale etc mcpherson and schneider 1974 urbanization is a radical form of land use change and will replace the natural land use with impervious surfaces and storm drainage system kjeldsen 2010 this further inhibits the natural infiltration capacity and reduces the lag time the other hydrological impacts of urbanization can be listed as the increase of low return period floods more than the high return period floods increase in drainage density and channel cross sectional area flashiness of storm flow etc graf 1977 hollis 1975 these changes alter the runoff process significantly and accelerate the rainfall runoff transformation process which could lead to higher and rapid flood flows hollis 1975 salavati et al 2016 in addition the urban watersheds face constant and drastic changes in terms of frequent occurrence of high intensity rainfall due to the heat island phenomena bornstein and lin 2000 leakage from the water distribution system increased flood and inundation risk suriya and mudgal 2012 increase in human settlement and associated activities removal of vegetation and natural storage etc amaguchi et al 2012 wmo 2008 in contrast to urban watersheds the percentage impervious areas as well as the installed sewer system density is either very low or absent in rural watersheds and will undergo slow and steady changes of hydrologic and hydraulic characteristics they will retain a significant amount of rainfall due to the presence of natural land use hollis 1975 sheng and wilson 2009 and will substantially decrease the peak discharge and increases the flood duration sheng and wilson 2009 further oudin et al 2018 analyzed the effect of distance of urban areas from the catchment outlet on runoff response and the results revealed that the location of urban areas has a secondary effect compared with the percentage impervious surfaces hence the corresponding flood risk will be moderate in rural watersheds although it includes urban areas at the outlet due to the relatively low population and settlements it accommodates therefore it is very important to detect urban flood flows compared to those in rural areas as they are associated with increased risks and costs mason et al 2012 for this purpose the rainfall runoff models are important tools and they play a central role in urban watersheds padiyedath et al 2018a however the predictions made using rainfall runoff models are inherently uncertain the uncertainties in the modeling mainly arise from parameter uncertainties measurement errors associated with the input data and from model structure errors arising from the aggregation of spatially distributed watershed processes into a relatively simple runoff model sivakumar and berndtsson 2010 the models which are not parameterized properly or lack input data of reasonable quality could provide an inaccurate representation of the actual hydrological processes shrestha 2009 generally the effectiveness of a model in providing a good prediction of the hydrological processes is mainly determined by its parameter values jeremiah et al 2012 therefore the model parameter uncertainty has received a prime recognition over other sources of uncertainties in the field of hydrological modeling and recent studies on hydrological model uncertainties mostly refer to the identification of parameter uncertainty uhlenbrook et al 1999 or parameter calibration ajami et al 2004 and their impacts on the model simulation results freer et al 1996 traditionally model parameters have been quantified from watershed properties or theoretically analyzed by comparing with similar models li et al 2010 however since the introduction of computer intensive statistics the parameters are being estimated by calibrating the models against observed data even though it increases the efforts and costs taken for the data measurements required for calibration and validation however this calibrated parameters are influenced by factors such as quantity and quality of input data model error correlation between the parameters etc duan et al 1992 which will lead the parameter estimates to deviate from their underlying true values ebtehaj et al 2010 thus leading to a great level of uncertainty of parameters and cannot fully characterize the actual processes different quantity and quality of input data used for calibration may provide quite different optimum parameter sets and the resulting parameter distributions would reflect the uncertainty in the parameter estimates and the interaction between the individual parameters beven 1993 generally the hydrologists calibrate their models with all the available data e g vaze and teng 2011 to get the more robust parameter set however several studies analyzed the effect of input data quantity on parameter uncertainty by calibrating the model for different sub periods of all available data kleme≈° 1986 proposed a framework to evaluate the model transposability over time by calibrating the model for a selected sub period and validating in another period different from that used for parameter calibration later jakeman et al 1993 investigated the parameter fluctuations and associated uncertainties in model predictions for variable climatic conditions by calibrating a lumped rainfall runoff model for sub periods recently vaze et al 2010 analyzed the transposability of four rainfall runoff models to a changing climatic scenario different from those used for parameter calibration and they found that the model performance was affected by the calibrated parameters subsequently poulin et al 2011 studied the effects of model structure and parameter equifinality on the model simulation uncertainty in a climate change impact perspective soon after merz et al 2011 examined the parameter time stability of a conceptual model by calibrating the model in different sub periods moreover coron et al 2012 also analyzed the parameter time variability of three hydrological models using the split sample test and its effect on the model simulation thereafter brigode et al 2013 investigated the dependence of the optimal parameter set on the climate characteristics of the calibration period and the results revealed that the dependence can contribute variability in streamflow projections however the calibrated parameters often have no measurable reference in nature bellprat 2013 therefore the major concern which arises is that what confidence bounds can be placed on the calibrated parameters for a given period where the different sources of uncertainty is mainly arising from observational with different input data quality and model parameterization errors and how do these uncertainties affect the hydrologic simulations ebtehaj et al 2010 this parameter uncertainty further contributes to model simulation uncertainties but to what extent is unknown hence its quantitative evaluation is critical in reducing the uncertainty of these simulations recent researchers have paid more attention to these uncertainties and many uncertainty analysis techniques have been developed and applied to different catchments in the past decades yang et al 2008 most of these techniques rely on either parametric methods or bayesian methods selle and hannah 2010 yang et al 2008 the most traditional parametric methods used for the assessment of model parameter uncertainty are the linear analysis first order approximation by providing a rough confidence interval ci of parameters kuczera 1988 nonlinear constrained maximization or minimization etc gallagher and doherty 2007 however in the parametric method the structure of the model is specified a priori and the number and nature of the parameters are generally fixed in advance and there is a little flexibility sivakumar 2017 since the advances in computer technology the monte carlo approaches with a bayesian inference have become popular due to their ability to handle nonlinearity and interdependency of parameters in complex hydrological models li et al 2010 the other methods based on bayesian approaches are generalized likelihood uncertainty estimation glue beven and binley 1992 hornberger and spear 1981 sequential uncertainty fitting algorithm sufi abbaspour et al 1997 abbaspour et al 1999 etc still the bayesian technique requires the form specification of the error distribution for response variables selle and hannah 2010 hence the nonparametric methods have the advantage that they make less prior assumptions on error structures and thus are potentially more flexible the bootstrap method a nonparametric technique has been developed by efron 1979 for random resampling of the original data set to develop replicate data sets from which the underlying distribution of the statistics of interest such as mean variation correlation etc can be estimated sivakumar 2017 this resampling technique has applications in diverse fields like hydrology groundwater hydrology air pollution modeling toxicology etc dixon 2006 where it has been successfully used in hydrological modeling to design storms from exceedance series to develop artificial neural network ann model to estimate the sampling variability of reconstructed runoff etc jeong and kim 2005 sun et al 2013 zucchini and adamson 1989 by utilizing non time series data however the outcome from the rainfall runoff models is the time series hydrograph and hence the time series application of the bootstrap method becomes necessary sophisticated approaches have been developed for this purpose and has been extensively used for the trend analysis of temperature and streamflow time series generation of synthetic streamflow sequences that are used in simulation studies forecasting of low flow frequency uncertainty assessment of water quality trends etc hirsch et al 2015 lall and sharma 1996 √∂n√∂z and bayazit 2012 sonali and nagesh kumar 2013 srinivas and srinivasan 2005 tasker and dunne 1997 however use of the bootstrap technique for model parameter uncertainty analysis by employing the time series data appears to be quite narrow until recently and very limited studies have been conducted to quantify the calibrated parameter uncertainty of rainfall runoff models using this technique ebtehaj et al 2010 introduced a nonparametric block bootstrapping approach coupled with global optimization to estimate the parameter uncertainty resulting from uncertainty in the forcing data and evaluate its impacts on the resulting streamflow simulations later selle and hannah 2010 demonstrated a model based bootstrap and compared the results with the block bootstrap approach for the parameter uncertainty of abc hydrological model and a conceptual salt load model the bootstrap approach also seems to have been used for the analysis of parameter uncertainty of swat model li et al 2010 zhang et al 2014 further brigode et al 2014 brigode et al 2015 analyzed the effect of different rainfall runoff calibration periods and information contained in the calibration period on extreme flood estimations using the block bootstrap method the uncertainty studies conducted using the swat model for different catchments reported that the parameter uncertainty and its effect on model simulation uncertainty vary from catchment to catchment even for the same model li et al 2010 zhang et al 2014 therefore there is a need to carry out such studies in different types of watersheds worldwide under varying agro climatic conditions with different rainfall runoff models in light of the aforementioned discussions it is apparent that very few studies have been conducted for model parameter uncertainty analysis using the bootstrap method among these none of the studies have been carried out in urban watersheds particularly using the urban storage function usf model takasaki et al 2009 a relatively new storage function sf model specially developed for urban watersheds where combined sewer systems are in use hence an attempt has been made to explore the use of bootstrap resampling to evaluate the uncertainty of optimal parameter estimates that arise due to uncertainties in the input data using a case study in the upper kanda river basin a typical small to medium sized urban watershed in tokyo japan previous studies on model parameter uncertainty analysis using bootstrap approach were conducted using all the available data instead of individual flood events since the hydrologists were mainly interested in the estimation of catchment hydrological variables such as peak flow flood volume etc with utmost accuracy and reliability the flood runoff analysis in urban watersheds is generally event based due to the relevance of flash flood peak estimation and short time of concentration therefore the bootstrap approach was applied in this study to both the individual flood events and the whole events in order to demonstrate the impact of different available data scenarios on the uncertainty behavior of calibrated parameters additionally two types of new indices have been proposed for the detailed analysis of uncertainty involved in the model parameters and model simulations 2 methodology 2 1 usf model the usf model is an sf model hoshi and yamaoka 1982 kimura 1961 prasad 1967 developed for the urban watersheds by incorporating the outflow from the basin to the treatment plant through the combined sewer system the model is based on the relationship between rainfall over the basin and runoff at the outlet point and is governed by the following equation padiyedath et al 2018a takasaki et al 2009 1 s k 1 q q r p 1 k 2 d dt q q r p 2 where s is the watershed storage mm q is the river discharge mm min q r is the storm drainage from the basin through the combined sewer system mm min t is the time min and k 1 k 2 p 1 p 2 are the model parameters combining the above expression of storage with the following continuity equation yields the nonlinear expression of the usf model 2 ds dt r i e o q q r q l where r is the rainfall mm min i is the urban specific and groundwater inflows from other basins mm min e is the evapotranspiration mm min o is the water intake from the basin for intended purposes such as water supply agricultural needs etc mm min and q l is the groundwater related loss mm min groundwater related loss q l was defined by considering the infiltration hole height z and is given by the following equation padiyedath et al 2018a takasaki et al 2009 3 q l k 3 s z s z 0 s z where k 3 and z are the parameters the expression for storm drainage q r from the combined sewer system discharged out of the basin was developed by assuming a linear relationship between total discharge q q r and the storm drainage q r immediately after the rainfall the q r is defined padiyedath et al 2018a takasaki et al 2009 as follows 4 q r Œ± q q r q 0 Œ± q q r q 0 q r m a x q r m a x Œ± q q r q 0 q r m a x where Œ± is the slope of the linear relationship between total discharge q q r and the drainage q r and q 0 is the initial river discharge just before the rain starts the maximum volume of q r cannot exceed the sewer maximum carrying capacity q rmax substituting eqs 1 and 3 into 2 leads to a second order ordinary differential equation ode and can be numerically solved after transforming into a first order ode the river discharge q was obtained as the solution after subtracting q r which was calculated using eq 4 from the total discharge overall the usf model is a seven parameter model with parameters k 1 k 2 k 3 p 1 p 2 z and Œ± used in the rainfall runoff modeling for a detailed description of the usf model see takasaki et al 2009 and padiyedath et al 2018a 2 2 model calibration and validation the shuffled complex evolution university of arizona sce ua method proposed by duan et al 1992 was used to calibrate the usf model it is a well known global optimization strategy developed for the effective and efficient calibration of the watershed models by optimizing a single objective function for up to 16 parameters duan et al 1992 green and van griensven 2008 this method combines a simplex method with the concept of controlled random search for the competitive evolution of the population with complex shuffling the algorithmic parameters of sce ua method were selected as per the recommendations of duan et al 1993 in the first step of the method it generates an initial population as the first generation by random sampling from the feasible parameter space which was defined by setting the lower and upper search range for p number of parameters to be optimized from the second generation onwards this population is partitioned into several complexes each of which is permitted to evolve independently size of the population produced in each generation was decided based on the number of parameters in the target model the number of complexes c was set equal to 20 and the number of populations in each complex r 2 p 1 the objective function to be minimized using the sce ua method was selected as the root mean squared error rmse between the observed and simulated discharge common use in hydrological modeling and simplicity were the reasons for the selection of rmse as the objective function ebtehaj et al 2010 wmo 1992 the calibrated parameters are functionally dependent on the length and properties of the calibration data objective function used for calibration etc and these factors subsequently affect the model simulations the seven parameters of usf model are shown in table 1 with their descriptions and search range used in the sce ua parameter optimization method padiyedath et al 2018a takasaki et al 2009 a narrow search range will constrain the parameters and the calibrated parameters will not reflect the actual watershed characteristics therefore a wide search range was defined instead of a narrow one by considering the possible physical minimum and maximum parameter values the model calibration was conducted using three data scenarios i whole data based scenario where all the available events were used for the model calibration ii individual event based scenario where individual flood events were used iii leave one out scenario where leaving out each flood event at a time from the all available events and calibrating on the remaining events the model performance during calibration was analyzed by simulating the flood events using the whole data based and individual event based parameters the performance of a model derived from the calibration data set is insufficient evidence for its satisfactory performance since no simulation model is intended merely to show how well it fits the data used for its development thus the data used for model validation should be different as those used for calibration but must represent a situation similar to that for which the data are to be generated kleme≈° 1986 therefore to test the operational performance of the model we have used the calibrated parameters from the individual event based scenario and the leave one out scenario the available flood events are split into two segments in which the first segment consists of one flood event at a time and the second segment is comprised of the remaining flood events the calibrated parameters of the individual event based and leave one out scenarios from the second segment are used to validate the model on the first segment for example event 1 forms the first segment and the second segment is composed of the remaining flood events events 2 5 the calibrated parameters of individual events 2 5 four parameter sets and the whole events except 1 one parameter set are used to validate the event 1 this calibration was repeated by leaving out the subsequent flood event one at a time from the available events 2 3 residual based bootstrap method the classical idea behind the bootstrap method is the resampling and extraction of m samples from the original data with an unknown distribution having a size of n this method makes no assumptions concerning the distribution of data or model being used the m bootstrap samples can provide the best knowledge regarding the underlying true distribution of the sample however the use of bootstrap for time series data was limited because the classical bootstrap technique assumes that the data set is independent and identically distributed iid efron 1982 which means each data of the data set will be mutually independent and selected from the same population generally the time series data sets are highly dependent in nature and it is quite unreasonable to perform classical bootstrapping as it destroys the original dependency structure of the time series in order to overcome the problem of dependence of time series the bootstrap method can be extended either as a block bootstrap davison and hinkley 1997 k√ºnsch 1989 in which the time series is divided into different blocks and these blocks are resampled instead of the individual data value or as a model based bootstrap lahiri 2003 selle and hannah 2010 which adopts a specific time series form of dependence in selle and hannah 2010 they considered a first order autoregressive model to consider the dependence of model error rather than assuming it is independent however a modification of this approach which can be simpler to apply in practice is to construct the bootstrap samples as fitted values plus residuals where the residuals are sampled with replacement from the observed distribution of residuals this method is known as the resampling of residuals shalizi 2016 shao and tu 1995 hereafter residual based bootstrap the residual based bootstrap approach was used to generate sample estimates of the hydrologic model parameters corresponding to the calibrated data set and to quantify the associated uncertainties in this method first we calibrate the model and then simulate by resampling residuals to that estimate and adding them back to the fitted values shalizi 2016 this surrogate data set is then re analyzed like a new data set by repeating the procedure m times bootstrapped time series are generated and the hydrologic model is then calibrated using each bootstrapped time series to arrive at bootstrapped estimates of the calibrated parameter sets these estimates are further used for the confidence interval analysis of the model parameter estimators however the residual based bootstrap method is usually based on some model assumptions although it requires no theoretical formula for the quantity to be estimated and is less model dependent than the traditional approach shao and tu 1995 the general assumptions for performing the residual based bootstrap are given as 1 the residuals are independent of each other 2 the residuals are identically distributed 3 the residuals are homoscedastic 4 the residuals are a good approximation of the observed data and model structure error 5 the residuals are randomly selected from their population with equal probability the procedure for the residual based bootstrap explained by stine 1985 and others shalizi 2016 shao and tu 1995 is described as follows consider the original data set x n q n where x n is the input data q n is the observed discharge data and n is the data length the observed discharge can be written as a function q n f x Œ∏ Œµ n where x x 1 x n Œ∏ is the parameter vector Œ∏ 1 Œ∏ p with p being the number of model parameters and Œµ n is the model residuals initially the model was calibrated using the sce ua method to obtain the calibrated parameter vector Œ∏ which was further used along with the input data to compute the model calibrated discharge data q n f x Œ∏ which can be demonstrated as q n f x Œ∏ Œµ n thereafter the model residuals can be expressed using the following equation 5 Œµ n q n q n q n f x Œ∏ the model residuals Œµ n were assumed to be iid for all n which is one of the assumptions made for the bootstrapping stine 1985 julian and gardner 2014 examined the effect of land cover on runoff patterns and the results revealed that increases in urbanization caused a decrease in long term hydrologic memory in urban watersheds the impervious surfaces decrease water storage which is the predominant factor that affecting long term hydrologic memory and the runoff became flashier julian and gardner 2014 this flash flood decreases the watershed hydrologic memory therefore the resulting model residuals of urban watersheds can be assumed to hold low memory due to the quick runoff response resulted from the increased percent of impervious surfaces the detailed residual based bootstrapping procedure is outlined as follows 1 bootstrap resampling of the residual time series Œµ n with replacement to form new bootstrapped residual series Œµ j n where j 1 m 2 add the new bootstrapped residual series Œµ j n to the calibrated discharge data q n to form the bootstrapped discharge series as q j n q n Œµ j n this bootstrapped discharge series will form the replication of the observed discharge series 3 calibrate the bootstrapped discharge series q j n with input data set x and obtain the j th bootstrapped parameter vector Œ∏ j using sce ua method and the associated simulated discharge series q j n f x Œ∏ j by this way the model can be re fitted to each bootstrapped discharge series q j n yielding bootstrap estimates of model parameters 4 derive the ordered bootstrap estimates Œ∏ j Œ∏ j 1 Œ∏ j p obtained after the bootstrap resampling method then the 95 ci for Œ∏ j was estimated from the ordered bootstrap samples the essential idea of this bootstrap approach is that the pseudo replicate samples bootstrap samples drawn at random with replacement from the data can be used to furnish information about the uncertainty of quantities estimated from the data selle and hannah 2010 the precision of a bootstrap estimate depends on the number of times the original data set is randomly resampled i e how many bootstrap replicates the bootstrap estimate converges to a consistent range of values as the number of resamples become large by the law of large numbers meyer et al 1986 efron and tibshirani 1993 suggested that the number of bootstrap samples should be at least 1000 therefore all the computations performed in this study were based on 1000 bootstrap replicates m 1000 from which the confidence intervals for the original corresponding parameter estimates can be calculated this method has asymptotic convergence properties which means that by increasing the number of simulated bootstrapped time series estimation error will be reduced ebtehaj et al 2010 the whole data based and individual event based scenarios described in section 2 2 were used to perform the residual based bootstrapping in order to identify the parameter fluctuation under the varying conditions of available data scenarios 2 4 model parameter uncertainty quantification the performance of hydrological models is significantly affected by the calibrated parameter uncertainty the parameter uncertainty is generally expressed by estimating the ci of the parameters however the ci gives the uncertainty range of each parameter from which it is difficult to identify the parameter with the highest and least uncertainty due to the different ranges of parameter values therefore it is necessary to propose certain indices which can interpret the ci of parameters with different ranges and clearly differentiate them based on their contribution to the uncertainty therefore in addition to the statistical estimators of the mean Œ∏ median Œ∏ 50 and the coefficient of variation cv of the m parameter sets from bootstrapping method two indices were proposed for assessing the uncertainty of model parameters model parameter uncertainty indices which can elucidate the ci in a better way here the indices are considering the individual parameters rather than the parameter vector in order to derive the parameters from the highest to the lowest uncertainty selle and hannah 2010 the first parameter uncertainty index pu i 1 utilizes the width of the ci and hence the parameter with a small index value will be less uncertain as compared with other parameters the second parameter uncertainty index pu i 2 compares the median value from the confidence region with the calibrated parameter vector Œ∏ and it should be minimum for the stability of the parameters the model parameter uncertainty indices are given as 6 pu i 1 i Œ∏ 97 5 i Œ∏ 2 5 i Œ∏ i 100 7 pu i 2 i Œ∏ i Œ∏ 50 i Œ∏ i 100 where Œ∏ 97 5 is the 97 5th percentile Œ∏ 2 5 is the 2 5th percentile and Œ∏ 50 is the 50th percentile median for the i th parameter obtained from bootstrapping Œ∏ is the calibrated parameter 2 5 model simulation uncertainty the model simulation uncertainty is referred to as the uncertainty of simulated discharge q j which occurs due to the calibrated parameter uncertainty and is illustrated as the 95 ci of simulated discharge series by the model this 95 ci should envelope most of the observations and at the same time it is desirable to have a narrow envelope swain and patra 2017 p factor is a statistical term used for the assessment of model simulation uncertainty and is calculated as the percentage of original discharge data at each time step that lies within the 95 ci yang et al 2008 the value of the p factor ranges between 0 and 100 and the goodness of model simulation uncertainty is judged based on the closeness of p factor to 100 i e all observations bracketed within the 95 ci the p factor is computed as follows 8 p factor n n 100 where n is the number of original observed discharge values at each time step that are bracketed within the 95 ci in addition to the p factor two other indices have been proposed for assessing the uncertainty of model simulated discharge model simulation uncertainty indices by utilizing the 95 ci similar to the model parameter uncertainty indices the model simulation uncertainty indices sui are given below 9 su i 1 1 n t 1 n q 97 5 t q 2 5 t q t 100 10 su i 2 1 n t 1 n q t q 50 t q t 100 where q 97 5 t q 2 5 t and q 50 t are the 97 5 2 5 and 50 levels of the cumulative distribution of the model simulated discharge series respectively q t is the observed discharge data 2 6 rainfall spatial variability usually the characteristics of rainfall events are spatially distributed and different from others even for the same watershed due to the effect of several meteorological factors which will result in the different parameter values moreover there will be an interaction between the spatial variability in rainfall and the spatial storage distribution which controls the discharge the discharge response at the outlet point to an averaged input will differ significantly from that to a distributed input shah et al 1996 high spatial variability of rainfall in the basin can affect the runoff prediction capability of usf model since it uses the average basin rainfall therefore further analysis was carried out to have a clear understanding about the extent of spatial variability of rainfall in the watershed by computing the percentage variation of total rainfall obtained from each rain gauge with respect to the mean rainfall from all the gauges the percentage variation can be computed using the following formula 11 v a r i a t i o n i t r i tr tr where t r i is the total rainfall from gauge i mm and tr is the mean rainfall from all the gauges mm 3 study area and data used the urban watershed of the upper kanda river basin having an area of 7 7 km2 at koyo bridge as shown in fig 1 was selected for the study the basin lies between latitudes 35 70 n and 35 64 n and longitudes 139 56 e and 139 64 e in tokyo japan with an urbanization rate of 97 since 2003 tmg 2016 the river originates from the inokashira pond and joins the zenpukuji river and flows east ando and takahasi 1997 the drainage pattern follows the combined sewer system and 100 of the population is connected to the sewer the urban landscape gis delineation was used to precisely estimate the impervious area percentage as 68 koga et al 2016 that significantly reduced the water retention capacity of the basin the computed time of concentration of surface runoff from the upstream reaches to the watershed outlet was about 30 min the reduced time of concentration indicated that the river discharge will occur immediately after the rainfall within a short period and it is desirable to use the hydrological data at very short time intervals for the rainfall runoff analysis therefore rainfall and water level data at one minute intervals were collected from the bureau of construction tokyo metropolitan government tmg during 2003 2006 for the present study the average rainfall of the basin was determined using the thiessen polygon method from the eight rain gauges scattered over the basin as shown in fig 1 five target events whose 60 minute maximum rainfall r60 was greater than 30 mm and were capable of producing flash floods were selected from the data table 2 shows the characteristics of the five selected rainfall events the inflow component i in the continuity equation was fixed at 0 0012 mm min based on the annual report of the bureau of construction tmg the water intake o from the basin and evapotranspiration e were set at 0 as there was no intake from the target basin and the evapotranspiration during heavy rainfall is insignificant padiyedath et al 2018b the maximum storm drainage q r m a x was estimated as 0 033 mm min using manning s equation 4 results and discussion 4 1 model calibration and performance the sce ua optimization method was applied for calibrating the usf model in the target watershed with rmse as the objective function for the considered data scenarios discussed in section 2 2 in the whole data based scenario all the selected events were considered for model calibration and a single set of parameters was derived from all the events on the other hand in the individual event based scenario each event was considered for model calibration the leave one out scenario leaves out one flood event at a time and calibrating on the remaining events the convergence of parameters was checked and the parameters were found to converge before the 50th generation in each sce ua application run thereafter the best parameter set Œ∏ among the population at the 50th generation with a minimum rmse value was used for the further simulations fig 2 shows the calibrated model parameters using the considered data scenarios in which the whole data based parameters are represented by a black line and the individual event based and leave one out parameters are depicted by the blue circles and red triangles respectively it is clear from fig 2 a and g that the individual event based parameters k 1 and Œ± are identical in all the events and are similar to the whole data based parameter values also the parameters k 2 and p 1 as shown in fig 2 b and d respectively have similar values in the data scenarios even though they exhibit slight variations between events however the remaining individual event based parameters k 3 p 2 and z are varying significantly between events and are similar to the whole data based parameters only during certain events the parameters k 3 and z represent the loss to the groundwater takasaki et al 2009 the z values close to zero indicate a high rate of recession and higher z values represent a higher river flow at the outlet point instead of contributing to the groundwater the higher value of z in event 1 can be attributed to its meteorological factor which is an intensive localized storm as shown in table 1 parameter p 2 portrays the change in storage during the rising and recession limbs of a hydrograph based on the type of rainfall event hoshi and yamaoka 1982 the higher p 2 values exhibited during events 1 and 3 as shown in fig 2 e may be possibly due to differences in meteorological factors from other events the leave one out parameters at each event number represent the calibrated parameters from the flood events except that particular event for example the parameters at event number 1 in fig 2 show the calibrated parameters from all the flood events except event 1 the leave one out parameters exhibit close resemblance with the whole data based parameters except for leaving out event 1 the results confirm that the parameters k 3 p 2 and z will have a prominent effect on the estimation of discharge due to their high variability also the meteorological factors can significantly affect parameter values during the model calibration however the considered data sets are not sufficient to generalize the above discussions despite providing a brief description of parameter uncertainty therefore to have an elaborative idea of calibrated parameter uncertainty the bootstrap approach was employed for generating samples which could be further utilized for conducting the uncertainty analysis thereafter the model performance on estimating discharge using the whole data based and individual event based parameters was analyzed table 3 presents the detailed performance evaluation using the statistical indicators of rmse nash sutcliffe efficiency nse nash and sutcliffe 1970 percentage error in peak pep and percentage error in volume pev padiyedath et al 2018a additionally fig 3 provides a visual representation of the hydrograph reproduced by the model for both the data scenarios it is apparent from table 3 that the model with individual event based parameters has lower values of rmse and higher values of nse in all the events as compared to the whole data based parameters it is evident from the table that the pep values estimated by the model using the individual event based parameters were very low close to zero compared to that from the whole data based parameters even though the model exhibited a higher pep value during event 1 and was not greater than 10 during any of the events fig 3 also shows that the model was able to reproduce the peak discharge with utmost accuracy using the individual event based parameters on the other hand the model with whole data based parameters exhibited remarkable anomaly in the reproduction of peak values especially in events 4 and 5 likewise the pep usf model shows the best performance in pev values using the individual event based parameters as shown in table 3 which is close to zero as compared to that of the whole data based parameters the results further confirmed that the difference between the values of statistical indicators shown in table 3 for the considered data scenarios is quite large and significantly greater for events 4 and 5 it can also be envisaged from fig 3 that the calibrated discharge using the individual event based parameters by usf model nearly overlaps with the observed river discharge and reproduces the shape of the observed hydrograph with only slight variations on the contrary the model with whole data based parameters deviated significantly while reproducing the shape of the hydrograph therefore the results indicate that the individual event based parameters can exactly reproduce the shape of the observed hydrograph as well as the peak discharge by significantly reducing the rmse by 50 compared to that of the whole data based parameters during the calibration hence it is necessary to consider the calibration based on individual flood events for the parameter uncertainty analysis rather than considering the whole data based calibration alone 4 2 model validation the model validation on independent sub events was carried out to assess the operational performance of the usf model fig 4 a1 a5 shows the reproduced hydrographs during the validation using the leave one out parameters as well as the individual event based parameters it is clear from fig 4 a1 a5 that the simulated discharge using the calibrated parameters of individual event based scenario has highly deviated from the observed discharge except event 3 on the other hand simulated discharge using the parameters of leave one out scenario and event 3 was close to the observed discharge during validation however it is not easy to clearly portray the difference between the simulated discharge hydrographs of these cases from fig 4 a1 a5 hence we evaluated the performance further using the same performance evaluation criteria of rmse nse pep and pev that used during the calibration and is shown in fig 4 b1 b5 the left y axis of fig 4 b represents rmse and nse while the right y axis depicts the pep and pev values it can be envisaged from the figure that the parameters from event 3 and the leave one out scenario consistently generated the lowest rmse and highest nse for reproducing the hydrographs in validation the remaining individual event based parameters exhibited low performance in terms of rmse and nse during validation on the selected sub events in the same way the pep and pev values were also close to zero in the case of event 3 and the leave one out scenario parameters and the rest of the cases exhibited varying values of pev and pev the validation based on event 3 and leave one out scenario performed equally in terms of rmse and other performance evaluation criteria similar to that exhibited in calibration table 3 the calibration of usf model over specific flood events and validation on independent flood events revealed that the model with leave one out parameters has consistent performance compared with the individual event based parameters this leave one out parameters represent the robust parameter set of the model and can be implemented for operational use in the context of flood simulation however there arises a question that which calibration approach is the most performant subject to validation based on the above discussions it is recommended that the model should be calibrated with all the available flood event data to get a more robust parameter set for the flood simulation vaze et al 2010 studied the effect of calibration periods on model simulation and their study revealed that the model calibration on a portion of the record with conditions similar to those of the future period to simulate can provide a more reasonable set of parameters this result was supported by de vos et al 2010 who suggested clustering time series according to climate similarities during calibration therefore the usf model could be calibrated using the available flood events since usf is a flood event based model for the flood simulation in urban watersheds with combined sewer system these calibration techniques will provide a minimum standard for operational validation of the model however it needs more such calibrations at different sub periods including more flood events to arrive at a conclusion moreover moore et al 2007 suggest that in many situations it is hard for the lumped conceptual models to outperform in operational use for flood simulation therefore it is recommended that further work is undertaken on alternative formulations which will describe the operational adequacy of the model 4 3 model parameter uncertainty analysis the calibration parameter uncertainty analysis was conducted using the five available flood events under the whole data based and individual event based scenarios the computed model residual series eq 5 was used to perform the resampling process for 1000 times by employing the residual based bootstrap approach then associated bootstrapped discharge series were generated by adding 1000 bootstrapped residual series to the calibrated discharge series as described in section 2 3 these bootstrapped discharge series q j t were used to obtain the j th bootstrapped parameter vector Œ∏ j of the usf model for both the whole data based and individual event based scenarios fig 5 shows the scatter plots of the bootstrapped parameter vectors with their 95 ci in grey shading the search range shown in table 1 is illustrated as the left y axis and the percentage contribution of 95 ci to the search range is depicted on the right y axis of fig 5 it is apparent from fig 5 a1 f1 that the k 1 values lie close to the lower limit of the search range and converged to a reduced range between 20 and 70 in all the cases the 95 ci of parameter k 1 have a comparable width in all the cases and constitute about 1 5 of the search range which is quite narrow the scatter plot of parameter k 2 was narrow as well as close to the lower search range with values clustered around 500 2000 as shown in fig 5 a2 f2 similarly the 95 ci of k 2 was also narrow for the whole data based parameter and was quite similar to the values of events 1 and 3 as compared to this pattern the ci was relatively wide during the rest of the events the parameter k 3 has a widespread pattern as compared to parameters k 1 and k 2 as shown in fig 5 a3 f3 the 95 ci of k 3 was wide and its contribution to the search range was high except for event 3 and the whole data based scenario there is a well spread pattern for parameter p 1 from 0 1 to 1 within the search range whereas most of the p 2 values accumulated near the lower search range between 0 1 and 0 7 as shown in fig 5 a4 f4 and a5 f5 respectively the 95 ci of these parameters are wide as compared to k 1 and k 2 with a high percentage contribution to the search range it is evident from fig 5 a6 f6 that most of the z values are gathered near the lower limit of the search range and the 95 ci is relatively wide parameter Œ± demonstrated a very widespread pattern with values close to the upper search range as depicted in fig 5 a7 f7 the 95 ci of Œ± was wide in all the scenarios and constituted about 25 50 of the search range it can be envisaged from fig 5 that the scatter plot of whole data based parameters is similar to the parameter pattern exhibited in event 3 which further indicate that the events with a large number of observations have domination on the whole data based model calibration even though a wide search range was considered certain parameters converged to a very narrow range on the other hand some parameters showed a widespread pattern from the lower to the upper limit of the search range this could be a reflection of the equifinality concept beven and freer 2001 and reconsideration of this search range could enhance the performance of the model in cases where parameter values accumulate on the search range boundaries additionally a larger number of bootstrap resamples can lead to a narrow 95 ci due to the convergence of parameters as observed in the study of selle and hannah 2010 fig 6 shows the statistical representation of fig 5 in terms of the box whisker plot of 1000 bootstrapped parameter vectors for both the data scenarios in which the bottom and the top lines of the boxes show the 25th and 75th percentiles respectively and the line passing through the box represents the median Œ∏ 50 the whiskers extend to the 2 5th and the 97 5th percentiles and the highest and lowest observations are plotted as asterisks additionally fig 6 represents the mean Œ∏ as the blue square and cv values at the top of the bootstrapped parameter vectors along with the calibrated parameter values Œ∏ as the red circle detailed descriptions of the plot are given in the figure caption it is clear from fig 6 a and b that the bootstrap estimates of Œ∏ 50 and Œ∏ of parameters k 1 and k 2 have similar values and are very close to the calibrated Œ∏ values in all the events however the parameter k 3 exhibited differences in the Œ∏ values during event 1 as depicted in fig 6 c it is apparent from fig 6 d that the Œ∏ 50 and Œ∏ values of p 1 are similar except for event 4 whereas the Œ∏ and Œ∏ values are identical except for events 4 and 5 on the other hand the Œ∏ 50 Œ∏ and Œ∏ values of parameter p 2 were close enough except for event 5 as shown in fig 6 e similar to the parameter p 2 the Œ∏ 50 Œ∏ and Œ∏ values of parameter z in fig 6 f were identical except in event 1 subsequently the Œ∏ values of Œ± exhibited minor discrepancy only in event 5 as compared to the Œ∏ 50 and Œ∏ values as illustrated in fig 6 g overall the Œ∏ values were in accordance with the Œ∏ 50 and Œ∏ values in most of the cases even though the Œ∏ values show minor deviations the cv values also varied between scenarios as shown in fig 6 during the whole data based analysis the highest cv value of around 133 was observed for parameter z and the least cv value was noted for parameter k 2 further the parameters were ordered based on their cv values as follows z Œ± k 3 p 1 p 2 k 1 k 2 however for the individual event based analysis during event 1 the highest cv value was exhibited by the parameter k 3 which was followed by parameter z the order of parameters based on cv values are k 3 z p 1 Œ± p 2 k 2 k 1 the same order for event 2 was p 2 k 3 z p 1 k 2 Œ± k 1 during events 3 and 4 based on the cv values the parameter z had the highest uncertainty on the contrary parameters p 2 and z had very high cv values as compared to other parameters during event 5 therefore the results reveal that the parameter with the highest and lowest uncertainty varies from case to case however z and k 1 were the parameters with the highest and lowest uncertainty respectively based on their cv values in most of the cases selle and hannah 2010 identified the parameter with the highest uncertainty of a conceptual salt load model using the cv value as the only index however in this study two proposed indices were computed in addition to the cv for objectively assessing the parameter uncertainty in order to have a clear understanding of the 95 ci as well as the median values of the parameters as shown in fig 7 in this figure the pu i 1 and pu i 2 index values of parameter z for the whole data based scenario is represented at the figure boundaries with their values since the Œ∏ value of parameter z was very close to zero in the whole data based scenario as shown in fig 2 f the calculated pu i 1 and pu i 2 values of z were very high and represented at the boundaries it is evident from fig 7 a that the parameter z has the highest value of pu i 1 during events 3 and 4 and also in the whole data based case which further indicates that z had the highest uncertainty in most of the considered scenarios based on pu i 1 this higher pu i 1 value of z can be interpreted as to its wide 95 ci and calibrated parameter values close to zero during these scenarios however the parameter p 2 demonstrated a higher value of pu i 1 during events 2 and 5 which could also be attributed to its very wide 95 ci as compared to other parameters as shown in fig 5 c5 and f5 while parameter p 1 has got the highest pu i 1 value during event 1 the parameters k 2 and k 1 demonstrated the lowest uncertainty from the cases whose 95 ci was very narrow as compared to the rest of the parameters the remaining parameters showed a different order of pu i 1 values in the considered scenarios based on their 95 ci width and the calibrated parameter values the high uncertainty in terms of pu i 2 was exhibited by the parameter z in all the cases except for event 3 as illustrated in fig 7 b during event 3 all the parameters exhibited a small magnitude of uncertainty and were comparable to each other even though the pu i 1 portrayed z as the most uncertain parameter in event 3 which can be further interpreted as the very similar median and calibrated values of parameters also for a narrow ci the median and calibrated parameter values will come closer and further the pu i 2 values will approach zero the parameter z exhibited negative pu i 2 values with a high magnitude in the whole data based scenario and event 4 which was significantly high in the whole data based scenario these high magnitude negative pu i 2 values indicate that the bootstrap median values are much higher than the calibrated parameters the results revealed that the difference in both the calculated indices pu i 1 and pu i 2 is because both represent different aspects of uncertainty analysis the parameter z represents the infiltration hole height in the usf model takasaki et al 2009 which depends upon parameters like basin storage and rainfall intensity and will vary greatly from event to event with the highest uncertainty additionally the optimum value of z estimated from the model calibration is close to zero with a very wide range of bootstrapped parameter values as shown in fig 5 a6 f6 which also makes it the most uncertain parameter the parameter with higher uncertainty after z varied from case to case however based on the pu i 1 and pu i 2 values p 1 p 2 Œ± k 3 and k 2 had higher uncertainty values after parameter z for most of the cases the 95 ci of these parameters are relatively wide which can be transformed into higher index values the parameter k 1 exhibited the least uncertainty one of the reasons for this could be the fact that parameter k 1 describes features of the watershed sugiyama et al 1997 and there is a very low chance of a change in watershed features within a short span this further indicated that parameter k 1 remains reasonably stable under varying input data scenarios besides the equifinality concept can also derive parameter uncertainty by generating non unique parameter sets during the calibration process and there will be a lot of different parameter combinations that lead to multiple optimal solutions beven and freer 2001 yang et al 2008 however this parameter uncertainty can be overcome to some extent by using global searching techniques during calibration 4 4 model simulation uncertainty the uncertainty in model simulation due to the calibrated parameter uncertainty was estimated by computing the 95 ci of the 1000 simulated discharge series generated by the bootstrapped parameters from the whole data based and the individual event based scenarios fig 8 shows the 95 ci of simulated discharge uncertainty range for each event from both the whole data based and the individual event based scenarios during calibration it is desirable to have a narrow range and fig 8 a1 b1 shows that the uncertainty range from the whole data based parameters at the peak flows of event 1 is wider than the range simulated from the individual event based parameters however the width of the uncertainty range at low flows was almost identical for event 1 from both the scenarios fig 8 a2 b2 shows that the uncertainty range was unable to capture the observed values during the flood peak of the whole data based scenario whereas the uncertainty range of individual event based scenario was able to bracket a large amount of the observed values including the flood peaks the uncertainty range of the whole data based scenario illustrated in fig 8 a3 b3 included the highest flood peak value with a wide uncertainty range on the other hand the uncertainty range of the individual event based scenario was very narrow and was close to the observed peak flows and hence was not able to capture the flood peaks during events 4 and 5 from the whole data based parameters most of the flood peak values were falling inside the uncertainty range even though the low flows were not well captured as shown in fig 8 a4 and a5 concurrently the uncertainty range of the individual event based scenario was able to capture almost all the flows except the peak value during events 4 and 5 as shown in fig 8 b4 and b5 overall the whole data based scenario captured the observed discharge with a very wide uncertainty range whereas the individual event based scenario bracketed observations within a very narrow uncertainty range during calibration also as can be seen from fig 8 that the uncertainty range is very narrow at the low flows for both the scenarios hence it can be concluded that the model simulates peak discharge with higher uncertainty as compared to low flows high uncertainty in the model simulation during flood peaks can be attributed to the influence of low flows as they may have dominated the parameter estimation process due to their greater numbers as compared to the peak flow gallagher and doherty 2007 however it is essential to estimate flood peaks with lesser uncertainty as compared to the low flows due to the high risk factor associated with them it is possible to do so by calibrating the model parameters using a specific objective function which can initiate the type of simulation that the model is required to make in order to portray the differences in the model simulation uncertainty during calibration a detailed uncertainty analysis was further conducted using the p factor and the two proposed model simulation uncertainty indices su i 1 and su i 2 fig 9 shows the model simulation uncertainty for the whole data based and the individual event based scenarios using the p factor su i 1 and su i 2 the p factor value as defined by eq 8 close to 100 represents the capability of the model to reasonably capture almost all the observed discharge values within the uncertainty range similarly the values of su i 1 and su i 2 close to zero indicate low uncertainty of the model in simulating the discharge it is clear from fig 9 a that the obtained value of p factor is higher for events 1 2 and 5 in the individual event based scenario and the whole data based scenario showed higher values of p factor during events 3 and 4 even though the p factor of individual event based analysis is lower than the whole data based analysis in events 3 and 4 the difference between the values is quite small the individual event based scenario captured an almost equal number of observations with a very narrow uncertainty range especially at the peak flows in event 3 compared with the whole data based scenario that resulted in an almost equal p factor the high uncertainty of parameter z during event 4 in terms of parameter uncertainty indices as shown in fig 7 could be a reason for the low p factor exhibited by the individual event based scenario in event 4 subsequently values of the proposed index su i 1 derived from the individual event based analysis were less than the values derived from whole data based analysis in all the events except for event 1 as shown in fig 9 b during event 1 the su i 1 value of both the scenarios was similar and the whole data based scenario received the least value the results revealed that the width of the uncertainty range is narrow relative to the observed discharge values in the individual event based analysis as compared to the whole data based analysis the individual event based values of su i 2 were also close to zero in all the events except for event 4 as illustrated in fig 9 c the su i 2 values were negative for events 4 and 5 in the whole data based scenario which indicates that the observed discharge values were lesser than the median values and lied in the lower confidence region in the same way values from the individual event based analysis were mostly positive except for events 1 and 3 and were found in the upper confidence region overall considering all the indices the simulation uncertainty was lower during the individual event based analysis as compared to the whole data based analysis 4 5 rainfall spatial variability the results revealed that the model simulation uncertainty varies from event to event as well as from the considered data scenarios this can be ascribed to the difference in parameter values in each event and the whole data based scenario resulted from the spatial variability in rainfall therefore further analysis was carried out to have a clear understanding of the extent of spatial variability of rainfall in the watershed fig 10 shows the percentage variation of total rainfall obtained from each rain gauge with respect to the mean rainfall from all the gauges it is clear from fig 10 that during event 1 the variation of two gauges are around 30 whereas the same in event 2 for one gauge is about 40 these high percentage variation values of rainfall exhibited by several rain gauges indicate that there is a relatively high spatial variability in rainfall during events 1 and 2 however all the gauges showed relatively low variability except one gauge during event 3 which resulted in an overall low spatial variability in this event moving to events 4 and 5 almost all the gauges portrayed high percentage variation values ranging from 60 to 60 and exhibited the highest spatial variability this high spatial variability exhibited by the rain gauges in each event can be attributed to their completely different rainfall pattern and this could be a cause of the high uncertainty in simulations during the whole data based scenario the model parameters were averaged spatially as well as temporally over the watershed without considering the spatial variability of rainfall as well as the meteorological factors that caused the rainfall events and the estimated model parameters will be different from the true watershed parameters chaubey et al 1999 this could be a possible reason for the high simulation uncertainty exhibited by the model in the whole data based scenario however during the individual event based scenario the catchment properties are only spatially averaged not temporally this will lead to a reduced simulation uncertainty in the event based scenario compared with the whole data based scenario at the same time lumping up of the complex spatially varying catchment properties such as rainfall inflow etc in a model will induce considerable errors associated with the spatially averaged input data cooley 2004 and further affect the model simulation uncertainty in both the data scenarios notwithstanding the problems associated with the spatial averaging of the watershed processes the usf model was able to simulate the discharge with reasonable accuracy in the individual event based and the whole data based scenarios using the bootstrap approach associated with the sce ua method therefore the bootstrap approach will contribute to the development of parsimonious hydrologic models selle and hannah 2010 with reliable estimates of parameter uncertainty in this study we found that the range of simulation uncertainty due to the parameters is relatively small apart from parameter uncertainty input data measurement errors from all sources and model structure errors also cause model simulation uncertainty sivakumar and berndtsson 2010 however it is not practicable to define the extent to which the other sources of uncertainties will affect the model simulation uncertainty based on our present study 5 conclusions the residual based bootstrap technique was utilized to analyze the calibration parameter uncertainty of the usf model to assess its impact on the model simulation in the upper kanda river basin an urban watershed in tokyo the bootstrap approach was applied to the individual flood events for the first time due to the relevance of flood runoff analysis in urban watersheds along with the available whole data in order to demonstrate the impact of different available data scenarios on the calibration uncertainty behavior of the parameters the 95 ci of certain parameters converged to a very narrow range as compared to the search range while some parameters showed a wider confidence range from the lower to the upper limit of the search range in both the scenarios further the parameter uncertainty was scrupulously analyzed and the parameters with the highest and the lowest uncertainty were identified by utilizing two newly proposed indices that are based on the width of the confidence interval and the median value although the order of the model parameters assigned during the uncertainty analysis based on the proposed indices differs the significant parameters yielded was the same hence the proposed indices could be useful in future studies to derive the parameters from the highest to the lowest uncertainty additionally the effect of parameter uncertainty on the model simulation was investigated by computing the 95 ci of 1000 simulated discharge series generated from the bootstrapped parameters and by utilizing the p factor and two other proposed indices for assessing the model simulation uncertainty the results revealed that the simulation uncertainty is low in the individual event based analysis compared with the whole data based analysis based on all the considered indices also the uncertainty range was wider at the peak flows and hence the model simulated peak discharge values had higher uncertainty than low flows as a conclusion the parameter uncertainty and its effect on model simulation uncertainty were successfully evaluated and the characteristics of an urban specific rainfall runoff model usf model were explained in detail using the bootstrap approach the residual based bootstrap approach used in this study assumed an independent and identically distributed model residual series however this assumption does not seem to be appropriate after looking at the autocorrelation plot of residuals the residuals demonstrated a short term persistence although the residual autocorrelation function decayed exponentially and was statistically insignificant beyond a lag of 6 min one solution to tackle this issue is the use of block bootstrap resampling of the residual with sufficiently long blocks to preserve the time dependence of the residuals another possibility is the use of the autoregressive component to reconstruct auto correlated bootstrap residuals selle and hannah 2010 have already carried out such an improvement and obtained comparable results from both bootstrap approaches it is also important to conduct comparative studies between the bootstrap and other techniques for parameter uncertainty analysis which will reveal the strength and weaknesses of the bootstrap approach the violation of the assumptions made during uncertainty analysis by the bootstrap method may lead to the inadequate characterization of simulation uncertainty therefore it is desirable to validate the simulation uncertainty using observations which will further provide some empirical evidence that the bootstrap method provides a good estimation of parameter and simulation uncertainties further the parameter variance obtained from this uncertainty analysis can be used in the data assimilation approaches for the real time prediction of flood and will give confidence to the hydrologist who uses the model in an operational context however this study primarily focused on the residual based bootstrap approach for the calibration parameter uncertainty analysis and its subsequent effect on model simulation uncertainty we will carry out further research on the aforementioned areas by considering the residual correlation and heteroscedasticity declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment this study was carried out as a part of the research project entitled study on guerrilla rainstorm flood and water pollution in megacity urban watersheds countermeasures against megacity urban water related disasters bipolarized by climate change supported by tokyo metropolitan government japan represented by prof akira kawamura appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124195 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
6066,understanding the interaction of the groundwater seepage flow and sediment transport along permeable boundaries is essential for managing soil beds and bank erosion a significant bank failure may occur due to sediment transport under the boiling condition in the present study an experiment is conducted to investigate the effects of injection or upward seepage on the critical shear stress of a cohesionless soil bed subjected to surface flow the upward seepage force acting on the soil bed particles may reduce the virtual weight of the particles in turn it may also reduce the critical shear stress acting on the particles a theoretical analysis examines how the upward seepage force acts to modify the critical shear stress for the sediment entrainment due to the increase in the hydraulic gradient of the seepage flow a force analysis reveals that the ratio of the critical shear stress with seepage to that without seepage is dependent on the ratio of the hydraulic gradient of seepage to its value at the quicksand condition a test apparatus was built and the effects of injection on the critical shear stress of cohesionless soil bed particles were measured an acrylic channel with a rectangular cross section was prepared and a section of a cohesionless soil bed subjected to an upward seepage flow was installed at the bottom of the channel the experiment demonstrates that the induced seepage affects the dynamics of the channel flow even though the magnitude of the seepage flow velocity is significantly smaller than that of the free surface water flow the test results show that the dimensionless critical shear stress of the cohesionless soil bed particles decreases slightly as the hydraulic gradient of the seepage flow is increased when critical shear stress is determined at the upstream edge of the seepage zone furthermore the dimensionless critical shear stress decreases sharply with the increment of the hydraulic gradient of the seepage flow when critical shear stress is determined in the seepage zone however it does not decrease in either case as was theoretically assumed even when the hydraulic gradient approaches to the critical hydraulic gradient or the quicksand condition keywords cohesionless soil critical shear stress injection seepage flow bed shear stress hydraulic gradient 1 introduction permeable boundaries are often found in natural rivers banks irrigation and drainage channels and earthen dams in the form of sand particles and gravel depending on the adjacent groundwater table the seepage water can enter or exit to these structures when the groundwater table is higher than that of the free surface water in the open channel or stream the water will seep up to the open channel this process of the flowing of water towards the stream is known as upward seepage or injection on the other hand the reverse process is known as downward seepage or suction the seepage flow rates are much smaller than the open channel flow rates thus seepage is commonly ignored by river engineers in the analysis of water and environmental issues however these small flows can induce mass transfer and momentum transfer which have a significant influence on the flow characteristics incipient motion and sediment transport behavior of a channel if the injection effect is significant enough the sand particles on the bed may boil consequently this will lead to significant bank failure and a rapid change in the form of the bed cao et al 2016 the sediment transport process is a very complicated subject that requires a comprehensive understanding of the interaction between water and the geological boundary conditions aberle et al 2012 lu et al 2008 cao et al 2016 ballio and tait 2012 this complexity often leads to unpredicted sediment transport rates for this reason understanding the combined interaction of the seepage flow and the sediment transport is essential for managing erosion the upward seepage effect on any streamflow may alter the hydrodynamic condition of the channel flow which has significant impact on incipient motion of bed particles in general the seepage effect on the sediment particle movement subjected to surface flow may be divided into three categories namely the seepage effects on the streamwise velocity distribution and bed shear stress the incipient motion and the sediment transport rate liu and chiew 2012 1 1 effects of seepage on vertical velocity profile thus far changes in the surface flow velocity profile due to the seepage flow in the permeable bed have been investigated and modifications have been added to the logarithmic law such that it considers the seepage velocity on the bed simpson 1970 and schlichting 1979 theoretically proposed a logarithmic law by taking into account the effects of injection and suction cheng and chiew 1998b krogstad and kourakine 2000 and dey and nath 2010 conducted measurements of the velocity profile near the permeable bed with injection and suction they discussed the seepage effect on the velocity profile and modified the logarithmic law with their measurements cheng and chiew 1998a b 1999 found that injection decreases the velocity and the bed shear stress near the bed and increases them near the water surface whereas rao et al 1994 found that both injection and suction can increase or decrease bed shear stresses the reason may be due to the use of a different variable i e the seepage intensity parameter which is not directly related to the seepage velocity liu and chiew 2012 krogstad and kourakine 2000 stated that the modification of the near bed flow configuration is responsible for the reduction in shear stress due to the injection effect the lower velocities near the bed are displaced further away from the boundary during injection on the other hand the higher velocities persist closer to the bed surface during suction as the lower momentum flow near the boundary is removed from the main flow kavcar and wright 2009 1 2 effects of seepage on incipient motion of bed particles the threshold conditions between erosion and sedimentation of a single particle are usually referred to as incipient motion the minimum amount of shear stress exerted by stream currents required to initiate bed particle motion is also known as the critical shear stress of bed particles the incipient motion has been studied widely by many researchers in the absence of seepage flow helland hansen et al 1935 kramer 1935 shields 1936 yalin 1977 the shields diagram is the most widely used criterion for incipient motion of sediment with particular property in the absence of seepage flow when seepage flow happens in the bed it introduces extra force to the bed particles which affects the incipient motion condition of sediment kavcar and wright 2009 proposed a modified shields parameter to account for the effect of seepage flow into or out to the bed particles different analytical and experimental models have been conducted by numerous researchers to investigate the seepage effects on the incipient motion dey and zanke 2004 studied analytically the upward seepage effects on the critical shear stress of bed particles they confirmed that the upward seepage decreases the critical shear stress of bed particles xie et al 2009 analytically showed that the critical shields number decreases with an increase in the hydraulic gradient of upward seepage flow cheng and chiew 1999 performed analytical and experimental investigations on the effect of upward seepage on the threshold of sediment transport they derived an equation to calculate the critical shear velocity with seepage in terms of the injection velocity they also showed that the critical shear velocity is reduced in the presence of upward seepage or injection liu and chiew 2012 ali et al 2003 showed from their experimental results that the injection decreases the critical shear stress of bed particles kavcar and wright 2009 experimentally concluded that the injection or positive upwards bed seepage tends to reduce the bed shear stress required for incipient motion of bed sediments while downwards seepage into the bed increases the required bed shear stress they also concluded that the hydraulic gradient through the bed is the most relevant parameter related to bed seepage influencing cohesionless sediment stability hydraulic gradients greater than 0 1 are required to have a noticeable effect on bed stability contrarily rao and sitaram 1999 empirically found that the suction reduces the stability of particles and it can even initiate their movement whereas injection increases the stability of bed particles it does not aid initiating their movement the rate of bed erosion is reduced or even stopped by the increased injection rates while increased with the increased rates of suction however their conclusion cannot be generalized because they did not allow for a change in seepage velocities hence it is valid only for a specific condition anurag and bimlesh 2018 evaluated the double averaged turbulence characteristics of the sand bed channel subjected to the downward seepage through permeable bed they found that the downward seepage increases the turbulent kinetic energy and turbulent intensities causing the bed particles to move rapidly 1 3 effects of seepage on sediment transport the sediment transportability of the channel depends on the balance between the gravitational forces acting to keep particles on the bed and the drag forces acting to either suspend them in the flow or push them along the downstream since both forms of seepage either upward or downward add additional force they may have an impact on the sediment transport rate of a channel on the other hand seepage affects both the bed shear stress and the critical shear velocity thus it is also likely to have a substantial influence on the sediment transport rate oldenziel and brink 1974 richardson et al 1985 and francalanci 2006 stated that downward seepage decreases the sediment transport rate whereas upward seepage increases it however other researchers have presented an exactly opposite conclusion stating that downward seepage decreases the stability of the bed particles while upward seepage decreases the mobility of the particles on a transporting bed willetts and drossos 1975 maclean and willetts 1986 maclean 1991 rao and sitaram 1999 ali et al 2003 lu and chiew 2007 rao et al 2011 sreenivasulu et al 2010 liu and chiew 2012 anurag and bimlesh 2018 vishal and bimlesh 2017 applied downward seepage to parabolic channels based on tractive force theory in order to determine its effect on the longitudinal and cross sectional profiles they observed that sediment transport in the threshold channels increased when downward seepage was applied generally the movement of sediment particles represented by the sediment transport rate is governed by the excess net force between the driving and resistance forces acting on the sediment particles liu and chiew 2012 on the other hand the sediment transport rate could also be expressed as a function of the difference between the acting shear velocity at the bed and the critical shear velocity called the shear velocity excess aguirre pe et al 2003 the shear velocity signifies the driving force acting on the bed particles whereas critical shear velocity represents the resistant force when sand particles are just about to move if the shear velocity excess increases the difference between the driving force and resistance force becomes larger and the sediment particles will move faster and vice versa liu and chiew 2012 liu and chiew 2014 experimentally showed that an increase in the injection velocity causes a reduction in the shear velocity excess leading to a reduction in the bedload transport rate they also derived empirical equation for predicting the bedload transport rate in the presence of upward seepage the above literature review reveals that different researchers hold very different views on injection effects on velocity profile incipient motion and sediment transport rate in open channel flow some opined that injection increases incipient motion and sediment transport rate changes velocity profile while the others found an exact opposite results the results reported so far have not been conclusive enough to qualitatively understand these complex effects and they can be contradictory to one another hence there appears a necessity to undertake further investigations the purpose of the present study is to determine the incipient motion of particles in a cohesionless soil bed subjected to upward seepage flow with different hydraulic gradients the rest of this paper is organized as follows the conceptual relationship between the critical shear stress and the hydraulic gradient of the seepage flow which is strongly related to the seepage force is presented in the next section then the testing apparatus and the procedures are explained the test results are discussed in the subsequent section which is followed by the conclusions 2 derivation for dimensionless critical shear stress the critical shear stress in the absence of a seepage flow is non dimensionalized as follows it is also known as the shields number yalin 1977 1 œÑ c œÑ c œÅ s œÅ w d g where œÑc œÑc œÅs œÅw d and g denote the dimensionless critical shear stress the critical shear stress with the dimension of stress the grain density the water density the diameter of the cohesionless soil particles and the gravitational acceleration respectively the dimensionless critical shear stress of eq 1 implies the ratio of the horizontal force to the vertical force exerted onto a particle on the bed because the horizontal and vertical forces are proportional to œÑcd2 and œÅs œÅw d3g respectively when the permeable bed experiences injection the following magnitude of seepage force f acts additionally on each particle of the bed material in the upward direction namely 2 f œÅ w g i 1 n where i and n denote the hydraulic gradient and porosity respectively it can be assumed that the ratio of the horizontal force to the vertical force on the incipient motion of the particles is maintained even when the bed is subjected to the upward seepage flow because the ratio corresponds to the friction coefficient of the particles or the tangent of the angle of repose the following relation can be derived under this assumption 3 œÑ cs œÅ s œÅ w d g f d œÑ c œÅ s œÅ w d g where œÑcs denotes the critical shear stress under the upward seepage flow substituting eq 2 into eq 3 eq 3 is reduced to the following relation 4 œÑ cs œÑ c œÑ cs œÑ c 1 i i c where ic is the well known critical hydraulic gradient and œÑ cs is the dimensionless critical shear stress of œÑcs given as below 5 i c 1 n œÅ s œÅ w 1 œÑ cs œÑ cs œÅ s œÅ w d g cheng and chiew 1999 and liu and chiew 2012 also derived eq 4 from the balance of the forces exerted onto a sediment particle assuming a horizontal plane bed consisting of uniform cohesionless sediment particles and approximating sediment particles as spheres for simplicity eq 2 means that the seepage force is proportional to the hydraulic gradient hence the seepage force at the surface of a sand bed is related to how the hydraulic gradient changes at the surface according to martin and aral 1971 the soil grains on the surface of the bed experience a seepage force that is roughly half as large as the soil grains located at a depth greater than several pore sizes lobkovsky et al 2004 thus it is assumed that a factor of c 0 5 reduces the seepage force given by eq 2 martin and aral 1971 first revealed experimentally that c approximately has the value of 0 5 and lobkovsky et al 2004 also applied c 0 5 to their experiment therefore eq 4 can be modified into following form when the particle motion on the bed surface is considered 6 œÑ cs œÑ c œÑ cs œÑ c 1 c i i c eq 4 is shown by the solid line in fig 1 it is seen that the dimensionless critical shear stress during the seepage flow decreases linearly as the hydraulic gradient increases and it becomes zero when the critical hydraulic gradient is reached eq 6 is shown by the dashed line in fig 1 it is seen that the dimensionless critical shear stress during the seepage flow decreases linearly as the hydraulic gradient becomes greater and it does not vanish even when the critical hydraulic gradient is reached 3 materials and methods 3 1 permeability test determining the critical hydraulic gradient is very important for designing the experiment presented in the next subsection the critical hydraulic gradient can easily be determined from the relationship between the hydraulic gradient and the seepage flow velocity internal erosion or sand boiling may occur if the seepage flow velocity is allowed to increase the hydraulic conductivity k and the critical injection velocity vcr for the sand material used in this study were determined for subsequent analyses the standard permeability test based on the method stipulated in astm 2006 was used to evaluate the hydraulic conductivity and the critical injection velocity fujisawa et al 2013 also used the same method to evaluate these variables the minimum hydraulic gradient at which the sign of internal erosion occurs corresponds to the critical hydraulic gradient the relationship between the hydraulic gradient and the seepage flow velocity of the experimental sand particles is plotted in fig 2 the fig 2 shows that when the injection or seepage flow velocity vi exceeds 0 174 cm s a distinct gradient change is noticed invalidating the linearity approximation of darcy s law thus this point can be defined as the critical injection velocity at which boiling begins to occur from fig 2 the corresponding hydraulic gradient can be read at 0 75 it is known as the critical hydraulic gradient for the experimental sand particles although the theoretical critical hydraulic gradient for these experimental sand particles was found to be around 0 899 using terzaghi s classical formula of the first equality in eq 5 it has been observed thus far both in the field and in the laboratory that seepage erosion can initiate at gradients lower than those determined by terzaghi s classical approach richards and reddy 2007 skempton and brogan 1994 fleshman and rice 2013 huang et al 2017 the linear relationship between the hydraulic gradient and the seepage flow velocity as predicted by darcy s law is observed when vi vcr the slope of the straight line fitted to the experimental data before the slope change yields hydraulic conductivity k 0 206 cm s at a temperature of 15 c the reynolds number re vid ŒΩ varied 0 24 0 89 before boiling happened and the range of re 1 satisfied the linearity of the darcy s law 3 2 experiment setup 3 2 1 test material black silica sand particles with a mean diameter of 0 58 mm as shown in fig 3 and a grain density of 2 64 g cm3 were used as the test material which also has been used for the above mentioned permeability test the sand was packed in the seepage box as sediment the physical properties of the test material and the results of the permeability test are summarized in table 1 3 2 2 experimental facilities a laboratory examination of the seepage effects was carried out in an acrylic glass sided re circulating close conduit channel whose dimensions were 10 cm in width 5 cm in depth and 300 cm in length an adjustable seepage box 10 10 cm of the same material was attached to the bottom of the channel as the seepage zone or the test section the test apparatus for the experiment is shown in fig 4 the flow rate in the conduit was controlled using a valve and monitored using an electromagnetic flow meter a transparent sand trap 10 cm in width and 13 cm in depth in the form of a hopper was placed 14 5 cm downstream of the seepage zone to collect the transported sand particles during the experiment the same method has been applied by many other researchers sumer et al 2003 pagliara et al 2011 cao et al 2016 the sand trap was used to directly measure the bed load transport rate by collecting the entrained sand within a specified duration the structure of the test apparatus was similar to the efa erosion function apparatus of briaud et al 2001 although it did not include the water tank generating the seepage flow and the deposition box 3 2 3 seepage box the seepage box was located 201 5 cm downstream of the conduit in order to obtain a uniform surface flow the sand in the seepage box was placed on top of a filter net which in turn overlaid a perforated plastic plate and a thin gravel layer the gravel layer was introduced to ensure a controlled and uniform seepage flow in other words the layer reduces the possibility of pre boiling in the vicinity of the seepage box wall seepage was then introduced into the seepage box using a hosepipe which was connected to the water tank this water tank was continually supplied with water to maintain different hydraulic gradients throughout the seepage zone the head difference for the different hydraulic gradients was read from the piezometers attached to the seepage box the flow rate into the seepage box was monitored using another electromagnetic flow meter 3 2 4 piv data acquisition and shear velocity the vertical velocity profile of the flow in the channel was measured at the upstream edge of the seepage zone the smooth bed and at the seepage zone the sand bed using the particle image velocimetry piv method adrian 1991 shown in fig 5 nylon particles 10 ¬µm in size were used as the tracer material and illuminated by a vertical laser sheet side view images of the flow focusing on the upstream edge of the sand bed and the sand bed itself were acquired using a camera then 100 consecutive images were captured and processed to compute the ensemble average velocity fields the regions of 0 10 mm length in sand bed and 30 40 mm length in the upstream edge of the sand bed as shown in fig 5 a were selected to extract data for making vertical velocity profiles the shear velocity was calculated by the newton raphson iterative method for curve fitting of the measured velocity profile to the logarithmic law and the modified logarithmic law on the smooth bed and the sand bed of the channel respectively as shown in fig 6 a d when a seepage flow occurs in a permeable sand bed it invalidates the usual logarithmic law for an impermeable bed schlichting 1979 proposed the modified logarithmic law considering both injection and suction in a permeable sand bed the logarithmic law and the modified logarithmic law are given as follows 7 u 1 k ln y a s 8 u 1 k ln y a s v s 4 u 1 k ln y a s 2 9 u u u y u y ŒΩ where u u y vs ŒΩ k and as denote the horizontal flow velocity the shear velocity the vertical coordinate with its origin at the bed the seepage velocity the kinematic viscosity of water the von k√°rm√°n constant k 0 41 and the integral constant for a smooth bed as 5 29 shear velocity u appearing in eqs 7 and 8 is related to bed shear stress œÑ as follows 10 œÑ œÅ w u 2 the shear velocity at different hydraulic gradients is summarized in table 2 this table comprises both measured and estimated values for different experimental cases the temperature of the water the sedimentation rate the shear velocity the seepage velocity and the hydraulic conductivity at different hydraulic gradients are measured in this experiment on the other hand the changes in porosity at each hydraulic gradient are estimated using the kozeny donat equation ichikawa et al 2012 as it is difficult to measure the porosity of sand that may change during experimentation the calculated shear velocity in the smooth bed from the curve fitting to the logarithmic law given by eq 7 can be used to estimate the bed shear stress in the sand bed a detailed explanation of this is presented in the results and discussions section 3 3 test procedure a series of tests was carried out which followed successive operating stages the surface flow velocity was changed for each hydraulic gradient and the corresponding velocity vector image was recorded using the particle image velocimetry piv method for subsequent analysis each test usually took 7 8 h depending on the imposed hydraulic gradient and the required velocity vector image the test procedure was continued until the critical hydraulic gradient was reached details of the test procedure are given as follows 1 the sediment box was installed at the bottom of the channel after being filled with cohesionless sand particles 2 the water flow into the main channel was started and kept at a slow enough rate so as not to move the sediment particles the temperature of the flowing water was recorded 3 the water tank connected to the sediment box was lifted up to the height that would enable the realization of the predetermined hydraulic gradients of 0 00 0 15 0 25 0 35 0 45 0 55 0 65 and 0 75 for each series of tests 4 the motion of the sediment particles started as the flow rate in the main channel was increased then side view images were acquired focusing on target zones using piv for subsequent analysis of vertical velocity vector profiles of the channel flow 5 open the transparent sand trap valve to collect the wet sand particles which were trapped for 30 60 min then the wet sand particles were put in oven dried at 120 c for 24 hour by measuring the weight of the dried sand particles the sediment transport rate of the transported sand particles was obtained for each test series 6 the 3rd to 5th steps of the above procedure were repeated changing the hydraulic gradient and the flow rate in the channel to order to obtain six or seven pieces of data for each test series with a predetermined value of hydraulic gradient in this way the critical shear stress at the different hydraulic gradients were determined the height of the bed surface in the sediment box could be adjusted along a shaft by rotating a screw attached at its bottom although the sediment transport rate in the experiment was fairly small as shown in the next section because all the tests were focused on the incipient motion of the bed particles the bed degradation due to erosion was controlled a few times throughout the experiment by rotating the screw slowly by hand 4 results and discussions 4 1 shear velocity on sand bed the roughness of the sand bed which is divided into hydraulically smooth hydraulically rough and transitional incompletely rough has a significant influence on the estimation of the shear velocity or the shear stress of the bed a thin layer must exist very close to the boundary in all turbulent flows where the viscous shear stress overcomes the turbulent shear stress the flow becomes laminar in a layer of thickness Œ¥ near the wall known as a viscous sublayer for turbulent flows the thickness of viscous sublayer Œ¥ can be expressed as 11 Œ¥ 11 6 ŒΩ u where ŒΩ and u denote the kinematic viscosity of water and the shear velocity of the flow respectively the grain shear reynolds number denoted by re which is proportional to the ratio of grain diameter d to the thickness of viscous sublayer has the following form 12 r e u d ŒΩ d Œ¥ eqs 11 and 12 are used for determining whether the turbulent flows are hydraulically smooth d Œ¥ 3 or re 4 rough 6Œ¥ d or 70 re or in transition between smooth and rough Œ¥ 3 d 6Œ¥ or 4 re 7 0 julien 1998 the shear velocity at the upstream edge the smooth bed of the seepage zone in the experiment is calculated from eq 7 and the values for Œ¥ and re are 6 93 10 4 m 8 44 10 4 m and 7 96 9 71 respectively the flow of water in the experiment lies in the transition range which is close to the hydraulically smooth range hence the shear velocity or the bed shear stress at the upstream edge can be a reasonable estimate of that on the seepage zone if seepage does not occur since the bed shear stress generally decreases when the upward seepage flow comes onto the bed the bed shear stress estimated at the upstream edge may well become higher than that on the seepage zone with upward seepage on the other hand eq 8 is applied to the flows on a smooth bed with injection or suction this equation is also used to determine the shear velocity on the seepage zone from the flow velocity profile on the sand bed however as mentioned above the sand bed of the seepage zone is not entirely hydraulically smooth therefore the shear velocity estimated by eq 8 can be slightly smaller than the actual or true one on the seepage zone the sand bed both eqs 7 and 8 are used to estimate the shear velocity on the seepage zone in the experiment it should be noted from the above discussion that the shear velocity at the upstream edge calculated by eq 7 is regarded as the maximum estimate when there is injection whereas the shear velocity from the flow velocity profile on the sand bed calculated by eq 8 is regarded as the minimum estimate 4 2 vertical velocity profile it is useful to investigate the effect of injection on vertical velocity profiles as mentioned in the previous section the vertical velocity profile measurements were conducted at the upstream of the sediment box and in the seepage zone with upward seepage flows through the sand bed the vertical velocity profiles of typical experiments underlined in table 2 are shown in fig 7 although the measured velocity profiles in both zones do not change significantly however a closer investigation in fig 7 shows that the some of measured velocity profiles near the bed are displaced further away from the boundary in the seepage zone than that of the upstream edge of the seepage zone during injection kavcar and wright 2009 also found that the lower velocities near the bed are displaced further away from the boundary during injection the velocity profile especially at i 0 75 displaces more in the seepage zone resulting higher flow velocity values than the upstream edge of seepage zone this may happen due to larger hydraulic gradient 4 3 shear velocity at incipient motion the results of the relationship between the sediment transport rate of the sand particles and the shear velocity calculated by curve fitting to the logarithmic law eq 7 and to the modified logarithmic law eq 8 under the various hydraulic gradients of 0 00 0 15 0 25 0 35 0 45 0 55 0 65 and 0 75 shown in figs 8 and 9 respectively are described both figures show that the changes in the sediment transport rate over the shear velocity were small even when the hydraulic gradients were increased the value of the shear velocity which induces the incipient motion also known as the critical shear velocity of the sediment particles can be obtained as the x intercept of the approximate lines of higher sediment rates and the corresponding shear velocities the values of shear velocity for each hydraulic gradient are placed in a limited range as shown in table 2 therefore the bedload transport equation can be linearized for sufficiently accurate estimation in the neighborhood of critical shear velocity or critical shear stress letting u cs be the value of the x intercept the critical shear stress under the seepage flow is calculated as 13 œÑ cs œÅ w u c s 2 where u cs denotes the critical shear velocity under the upward seepage flow the value next to the vertical dashed line in figs 8 and 9 corresponds to the critical shear velocity or shear velocity at incipient motion if the bed shear stress value is used instead of the shear velocity value for plotting figs 8 and 9 the dimensionless critical shear stress estimation will be varied negligibly on the other hand the shear velocity is directly related to the viscous sublayer estimation discussed in the previous subsection as a result the shear velocity value is used in this experiment to estimate the dimensionless critical shear stress the dimensionless critical shear stress is then estimated using second equality of eq 5 cheng and chiew 1999 suggested that some subjectivity should be expected and that a certain amount of scattering in the experimental data is unavoidable if the incipient motion of the bed particles is visually recognized the subjectivity involved with a visual judgment of the incipient motion can be avoided in this research by using the above mentioned method to determine the critical shear stress correlation and ordinary regression analyses were conducted to examine the relationship between the shear velocity and the sediment transport rate prediction as can be seen in figs 8 and 9 each of the r squared values for the different hydraulic gradients is positively and significantly correlated the r squared values show a good agreement between the fitted model and the measurement the sediment transport rate is incrementally dependent on the shear velocity the shear velocity varies in a short range for different hydraulic gradients when considering the upstream edge of the seepage zone as shown in fig 8 therefore the approximate lines seen in the figure may well cross each other and the values of the critical shear stress for the different hydraulic gradients do not vary significantly the upward seepage adds additional hydrodynamic force which initiates the movement of sand particles as a result it reduces the critical shear velocity in other words critical shear stress the critical shear stress can be determined from eq 13 it is seen from figs 8 and 9 that the critical shear velocity or critical shear stress get reduced as the hydraulic gradient increased this phenomenon is also found from the analytical results reported in dey and zanke 2004 cheng and chiew 1999 the experimental results reported in cheng and chiew 1999 ali et al 2003 kavcar and wright 2009 liu and chiew 2012 also confirm that the upward seepage reduces the critical shear stress on the other hand rao and sitaram 1999 found that upward seepage increases the stability of the bed which means the increment of critical shear stress this result contradicts to the present observation but their result can not be generalized because the empirical equations proposed by them does not allow for a change in seepage velocities liu and chiew 2012 4 4 dimensionless critical shear stress the relationship between the dimensionless critical shear stress values of the sand particles and the hydraulic gradients of 0 00 0 15 0 25 0 35 0 45 0 55 0 65 and 0 75 is shown in fig 10 the linear fit lines through the rectangular points and the circular points denote the experimental results of the dimensionless critical shear stress with hydraulic gradients in the seepage zone and in the upstream edge of the seepage zone respectively as shown in fig 10 the calculated values for the dimensionless critical shear stress vary in the range of 0 0358 œÑ c 0 0284 when considering the upstream edge of the seepage zone on the other hand the values for the dimensionless critical shear stress vary in the range of 0 0334 œÑ c 0 0128 when considering the seepage zone the values in both cases are validated with shield s diagram shields 1936 when an upward seepage flow does not occur a good agreement is found where the value of œÑ c for coarse granular material d 0 5 mm is 0 033 at 20 c julien 1998 in both cases the dimensionless critical shear stress decreases with the increment of hydraulic gradient which is also confirmed by xie et al 2009 the decreasing trend of dimensionless critical shear stress also adheres to results found by cheng and chiew 1999 liu and chiew 2012 it is seen from fig 10 that the dimensionless critical shear stress does not decrease with an increase in the hydraulic gradient as much as expected by eq 6 the solid gray line in fig 10 corresponds to eq 6 the following reason for the discrepancy between the value of the dimensionless critical shear stress at the upstream edge of the seepage zone and eq 6 can be considered the bed shear stress was determined by the approach velocity profile at the upstream edge of the seepage zone where the channel bottom is not permeable the injection into the permeable sediment bed might significantly decrease the bed shear stress on it on the contrary the following reason for the discrepancy between the value of the dimensionless critical shear stress in the seepage zone and eq 6 can be considered the injection decreases the effective weight of the particles thus promoting bed sediment mobility cao et al 2016 consequently the dimensionless critical shear stress decreases with an increase in the hydraulic gradient the value of dimensionless critical shear stress in the seepage zone decreases significantly shown in fig 10 when hydraulic gradient is more than 0 1 kavcar and wright 2009 also concluded that hydraulic gradients of bed seepage greater than 0 1 are required to have a noticeable effect on non cohesive sediment bed stability 4 5 limitations and further research one of the limitations of present study is the spatial scale resolution of the flume where the length of the flume is 300 cm the length of the experimental flume is smaller than that of other researcher s experiments liu and chiew 2012 lu et al 2008 the size of the seepage zone 10 cm 10 cm is also smaller than that of the other researchers liu and chiew 2012 lu et al 2008 on the other hand uniform seepage flow conditions can never be achieved for a large sized seepage zone based on the laboratory observations we analyzed macroscopically the variation of critical shear stress with the hydraulic gradient of the seepage flow the microscopic investigation of critical shear stress with the hydraulic gradient can be a potential way of further research 5 conclusions a theoretical analysis and experimental study were conducted to investigate the critical shear stress of sand particles under injection since the upward seepage force causes a decrease in the virtual weight of the bed material the conventional concept of dimensionless critical shear stress has shown that theoretically the induced upward hydraulic gradient brings about a decrease in the critical shear stress linearly and that this force does not diminish even at the quicksand condition this is due to a reduction in the seepage force on the bed surface but the reduction is only half of that occurring in the bed located at a depth greater than several pore sizes martin and aral 1971 force analyses also revealed that the ratio of the critical shear stress with seepage to that without seepage is dependent on the ratio of the hydraulic gradient of seepage to its value at the quicksand condition in the experiments a water channel was constructed to be 10 cm in width 5 cm in depth and 300 cm in length a section of the channel was made as a sediment bed with cohesionless sand particles subjected to upward seepage flow and installed at the bottom of the channel by changing the flow rate in the channel the critical shear stress under different hydraulic gradients was determined at the upstream edge of the seepage zone and in the seepage zone the experimental results revealed that the dimensionless critical shear stress acting on the cohesionless sand particles decreased slightly as the hydraulic gradient of the seepage flow was increased when critical shear stress was determined at the upstream edge of the seepage zone the linear fit line of the experiment was seen to lie above the line calculated by eq 6 moreover the dimensionless critical shear stress acting on the cohesionless sand particles decreased sharply as the hydraulic gradient of the seepage flow was increased when critical shear stress was determined in the seepage zone the linear fit line was seen to lie below the line calculated by eq 6 it is assumed that the critical shear stress calculated in the upstream edge of the seepage zone was seen as a kind of maximum force on the other hand the critical shear stress calculated in the seepage zone was seen as a kind of minimum force finally it can be concluded that the dimensionless critical shear stress acting on these experimental cohesionless sand particles fell between these minimum and maximum forces declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by jsps kakenhi grant in aid for scientific research b grant number 17h03889 the first author would like to express his gratitude to the mext scholarship provided by the japanese government the authors also would like to thank all the anonymous reviewers for their valuable comments and suggestions appendix notations as integral constant for smooth bed d diameter of cohesionless soil particle f seepage force g gravitational acceleration i hydraulic gradient ic critical hydraulic gradient k hydraulic conductivity n porosity re reynolds number re grain shear reynolds number u horizontal flow velocity u shear velocity u cs critical shear velocity under upward seepage flow vi injection velocity vcr critical injection velocity vs seepage velocity y vertical coordinate with its origin at the bed œÅw water density œÅs grain density ŒΩ kinematic viscosity of water œÑc critical shear stress with dimension of stress œÑ c dimensionless critical shear stress œÑcs critical shear stress under upward seepage flow œÑ cs dimensionless critical shear stress under upward seepage flow Œ¥ viscous sublayer thickness k von k√°rm√°n constant 
6066,understanding the interaction of the groundwater seepage flow and sediment transport along permeable boundaries is essential for managing soil beds and bank erosion a significant bank failure may occur due to sediment transport under the boiling condition in the present study an experiment is conducted to investigate the effects of injection or upward seepage on the critical shear stress of a cohesionless soil bed subjected to surface flow the upward seepage force acting on the soil bed particles may reduce the virtual weight of the particles in turn it may also reduce the critical shear stress acting on the particles a theoretical analysis examines how the upward seepage force acts to modify the critical shear stress for the sediment entrainment due to the increase in the hydraulic gradient of the seepage flow a force analysis reveals that the ratio of the critical shear stress with seepage to that without seepage is dependent on the ratio of the hydraulic gradient of seepage to its value at the quicksand condition a test apparatus was built and the effects of injection on the critical shear stress of cohesionless soil bed particles were measured an acrylic channel with a rectangular cross section was prepared and a section of a cohesionless soil bed subjected to an upward seepage flow was installed at the bottom of the channel the experiment demonstrates that the induced seepage affects the dynamics of the channel flow even though the magnitude of the seepage flow velocity is significantly smaller than that of the free surface water flow the test results show that the dimensionless critical shear stress of the cohesionless soil bed particles decreases slightly as the hydraulic gradient of the seepage flow is increased when critical shear stress is determined at the upstream edge of the seepage zone furthermore the dimensionless critical shear stress decreases sharply with the increment of the hydraulic gradient of the seepage flow when critical shear stress is determined in the seepage zone however it does not decrease in either case as was theoretically assumed even when the hydraulic gradient approaches to the critical hydraulic gradient or the quicksand condition keywords cohesionless soil critical shear stress injection seepage flow bed shear stress hydraulic gradient 1 introduction permeable boundaries are often found in natural rivers banks irrigation and drainage channels and earthen dams in the form of sand particles and gravel depending on the adjacent groundwater table the seepage water can enter or exit to these structures when the groundwater table is higher than that of the free surface water in the open channel or stream the water will seep up to the open channel this process of the flowing of water towards the stream is known as upward seepage or injection on the other hand the reverse process is known as downward seepage or suction the seepage flow rates are much smaller than the open channel flow rates thus seepage is commonly ignored by river engineers in the analysis of water and environmental issues however these small flows can induce mass transfer and momentum transfer which have a significant influence on the flow characteristics incipient motion and sediment transport behavior of a channel if the injection effect is significant enough the sand particles on the bed may boil consequently this will lead to significant bank failure and a rapid change in the form of the bed cao et al 2016 the sediment transport process is a very complicated subject that requires a comprehensive understanding of the interaction between water and the geological boundary conditions aberle et al 2012 lu et al 2008 cao et al 2016 ballio and tait 2012 this complexity often leads to unpredicted sediment transport rates for this reason understanding the combined interaction of the seepage flow and the sediment transport is essential for managing erosion the upward seepage effect on any streamflow may alter the hydrodynamic condition of the channel flow which has significant impact on incipient motion of bed particles in general the seepage effect on the sediment particle movement subjected to surface flow may be divided into three categories namely the seepage effects on the streamwise velocity distribution and bed shear stress the incipient motion and the sediment transport rate liu and chiew 2012 1 1 effects of seepage on vertical velocity profile thus far changes in the surface flow velocity profile due to the seepage flow in the permeable bed have been investigated and modifications have been added to the logarithmic law such that it considers the seepage velocity on the bed simpson 1970 and schlichting 1979 theoretically proposed a logarithmic law by taking into account the effects of injection and suction cheng and chiew 1998b krogstad and kourakine 2000 and dey and nath 2010 conducted measurements of the velocity profile near the permeable bed with injection and suction they discussed the seepage effect on the velocity profile and modified the logarithmic law with their measurements cheng and chiew 1998a b 1999 found that injection decreases the velocity and the bed shear stress near the bed and increases them near the water surface whereas rao et al 1994 found that both injection and suction can increase or decrease bed shear stresses the reason may be due to the use of a different variable i e the seepage intensity parameter which is not directly related to the seepage velocity liu and chiew 2012 krogstad and kourakine 2000 stated that the modification of the near bed flow configuration is responsible for the reduction in shear stress due to the injection effect the lower velocities near the bed are displaced further away from the boundary during injection on the other hand the higher velocities persist closer to the bed surface during suction as the lower momentum flow near the boundary is removed from the main flow kavcar and wright 2009 1 2 effects of seepage on incipient motion of bed particles the threshold conditions between erosion and sedimentation of a single particle are usually referred to as incipient motion the minimum amount of shear stress exerted by stream currents required to initiate bed particle motion is also known as the critical shear stress of bed particles the incipient motion has been studied widely by many researchers in the absence of seepage flow helland hansen et al 1935 kramer 1935 shields 1936 yalin 1977 the shields diagram is the most widely used criterion for incipient motion of sediment with particular property in the absence of seepage flow when seepage flow happens in the bed it introduces extra force to the bed particles which affects the incipient motion condition of sediment kavcar and wright 2009 proposed a modified shields parameter to account for the effect of seepage flow into or out to the bed particles different analytical and experimental models have been conducted by numerous researchers to investigate the seepage effects on the incipient motion dey and zanke 2004 studied analytically the upward seepage effects on the critical shear stress of bed particles they confirmed that the upward seepage decreases the critical shear stress of bed particles xie et al 2009 analytically showed that the critical shields number decreases with an increase in the hydraulic gradient of upward seepage flow cheng and chiew 1999 performed analytical and experimental investigations on the effect of upward seepage on the threshold of sediment transport they derived an equation to calculate the critical shear velocity with seepage in terms of the injection velocity they also showed that the critical shear velocity is reduced in the presence of upward seepage or injection liu and chiew 2012 ali et al 2003 showed from their experimental results that the injection decreases the critical shear stress of bed particles kavcar and wright 2009 experimentally concluded that the injection or positive upwards bed seepage tends to reduce the bed shear stress required for incipient motion of bed sediments while downwards seepage into the bed increases the required bed shear stress they also concluded that the hydraulic gradient through the bed is the most relevant parameter related to bed seepage influencing cohesionless sediment stability hydraulic gradients greater than 0 1 are required to have a noticeable effect on bed stability contrarily rao and sitaram 1999 empirically found that the suction reduces the stability of particles and it can even initiate their movement whereas injection increases the stability of bed particles it does not aid initiating their movement the rate of bed erosion is reduced or even stopped by the increased injection rates while increased with the increased rates of suction however their conclusion cannot be generalized because they did not allow for a change in seepage velocities hence it is valid only for a specific condition anurag and bimlesh 2018 evaluated the double averaged turbulence characteristics of the sand bed channel subjected to the downward seepage through permeable bed they found that the downward seepage increases the turbulent kinetic energy and turbulent intensities causing the bed particles to move rapidly 1 3 effects of seepage on sediment transport the sediment transportability of the channel depends on the balance between the gravitational forces acting to keep particles on the bed and the drag forces acting to either suspend them in the flow or push them along the downstream since both forms of seepage either upward or downward add additional force they may have an impact on the sediment transport rate of a channel on the other hand seepage affects both the bed shear stress and the critical shear velocity thus it is also likely to have a substantial influence on the sediment transport rate oldenziel and brink 1974 richardson et al 1985 and francalanci 2006 stated that downward seepage decreases the sediment transport rate whereas upward seepage increases it however other researchers have presented an exactly opposite conclusion stating that downward seepage decreases the stability of the bed particles while upward seepage decreases the mobility of the particles on a transporting bed willetts and drossos 1975 maclean and willetts 1986 maclean 1991 rao and sitaram 1999 ali et al 2003 lu and chiew 2007 rao et al 2011 sreenivasulu et al 2010 liu and chiew 2012 anurag and bimlesh 2018 vishal and bimlesh 2017 applied downward seepage to parabolic channels based on tractive force theory in order to determine its effect on the longitudinal and cross sectional profiles they observed that sediment transport in the threshold channels increased when downward seepage was applied generally the movement of sediment particles represented by the sediment transport rate is governed by the excess net force between the driving and resistance forces acting on the sediment particles liu and chiew 2012 on the other hand the sediment transport rate could also be expressed as a function of the difference between the acting shear velocity at the bed and the critical shear velocity called the shear velocity excess aguirre pe et al 2003 the shear velocity signifies the driving force acting on the bed particles whereas critical shear velocity represents the resistant force when sand particles are just about to move if the shear velocity excess increases the difference between the driving force and resistance force becomes larger and the sediment particles will move faster and vice versa liu and chiew 2012 liu and chiew 2014 experimentally showed that an increase in the injection velocity causes a reduction in the shear velocity excess leading to a reduction in the bedload transport rate they also derived empirical equation for predicting the bedload transport rate in the presence of upward seepage the above literature review reveals that different researchers hold very different views on injection effects on velocity profile incipient motion and sediment transport rate in open channel flow some opined that injection increases incipient motion and sediment transport rate changes velocity profile while the others found an exact opposite results the results reported so far have not been conclusive enough to qualitatively understand these complex effects and they can be contradictory to one another hence there appears a necessity to undertake further investigations the purpose of the present study is to determine the incipient motion of particles in a cohesionless soil bed subjected to upward seepage flow with different hydraulic gradients the rest of this paper is organized as follows the conceptual relationship between the critical shear stress and the hydraulic gradient of the seepage flow which is strongly related to the seepage force is presented in the next section then the testing apparatus and the procedures are explained the test results are discussed in the subsequent section which is followed by the conclusions 2 derivation for dimensionless critical shear stress the critical shear stress in the absence of a seepage flow is non dimensionalized as follows it is also known as the shields number yalin 1977 1 œÑ c œÑ c œÅ s œÅ w d g where œÑc œÑc œÅs œÅw d and g denote the dimensionless critical shear stress the critical shear stress with the dimension of stress the grain density the water density the diameter of the cohesionless soil particles and the gravitational acceleration respectively the dimensionless critical shear stress of eq 1 implies the ratio of the horizontal force to the vertical force exerted onto a particle on the bed because the horizontal and vertical forces are proportional to œÑcd2 and œÅs œÅw d3g respectively when the permeable bed experiences injection the following magnitude of seepage force f acts additionally on each particle of the bed material in the upward direction namely 2 f œÅ w g i 1 n where i and n denote the hydraulic gradient and porosity respectively it can be assumed that the ratio of the horizontal force to the vertical force on the incipient motion of the particles is maintained even when the bed is subjected to the upward seepage flow because the ratio corresponds to the friction coefficient of the particles or the tangent of the angle of repose the following relation can be derived under this assumption 3 œÑ cs œÅ s œÅ w d g f d œÑ c œÅ s œÅ w d g where œÑcs denotes the critical shear stress under the upward seepage flow substituting eq 2 into eq 3 eq 3 is reduced to the following relation 4 œÑ cs œÑ c œÑ cs œÑ c 1 i i c where ic is the well known critical hydraulic gradient and œÑ cs is the dimensionless critical shear stress of œÑcs given as below 5 i c 1 n œÅ s œÅ w 1 œÑ cs œÑ cs œÅ s œÅ w d g cheng and chiew 1999 and liu and chiew 2012 also derived eq 4 from the balance of the forces exerted onto a sediment particle assuming a horizontal plane bed consisting of uniform cohesionless sediment particles and approximating sediment particles as spheres for simplicity eq 2 means that the seepage force is proportional to the hydraulic gradient hence the seepage force at the surface of a sand bed is related to how the hydraulic gradient changes at the surface according to martin and aral 1971 the soil grains on the surface of the bed experience a seepage force that is roughly half as large as the soil grains located at a depth greater than several pore sizes lobkovsky et al 2004 thus it is assumed that a factor of c 0 5 reduces the seepage force given by eq 2 martin and aral 1971 first revealed experimentally that c approximately has the value of 0 5 and lobkovsky et al 2004 also applied c 0 5 to their experiment therefore eq 4 can be modified into following form when the particle motion on the bed surface is considered 6 œÑ cs œÑ c œÑ cs œÑ c 1 c i i c eq 4 is shown by the solid line in fig 1 it is seen that the dimensionless critical shear stress during the seepage flow decreases linearly as the hydraulic gradient increases and it becomes zero when the critical hydraulic gradient is reached eq 6 is shown by the dashed line in fig 1 it is seen that the dimensionless critical shear stress during the seepage flow decreases linearly as the hydraulic gradient becomes greater and it does not vanish even when the critical hydraulic gradient is reached 3 materials and methods 3 1 permeability test determining the critical hydraulic gradient is very important for designing the experiment presented in the next subsection the critical hydraulic gradient can easily be determined from the relationship between the hydraulic gradient and the seepage flow velocity internal erosion or sand boiling may occur if the seepage flow velocity is allowed to increase the hydraulic conductivity k and the critical injection velocity vcr for the sand material used in this study were determined for subsequent analyses the standard permeability test based on the method stipulated in astm 2006 was used to evaluate the hydraulic conductivity and the critical injection velocity fujisawa et al 2013 also used the same method to evaluate these variables the minimum hydraulic gradient at which the sign of internal erosion occurs corresponds to the critical hydraulic gradient the relationship between the hydraulic gradient and the seepage flow velocity of the experimental sand particles is plotted in fig 2 the fig 2 shows that when the injection or seepage flow velocity vi exceeds 0 174 cm s a distinct gradient change is noticed invalidating the linearity approximation of darcy s law thus this point can be defined as the critical injection velocity at which boiling begins to occur from fig 2 the corresponding hydraulic gradient can be read at 0 75 it is known as the critical hydraulic gradient for the experimental sand particles although the theoretical critical hydraulic gradient for these experimental sand particles was found to be around 0 899 using terzaghi s classical formula of the first equality in eq 5 it has been observed thus far both in the field and in the laboratory that seepage erosion can initiate at gradients lower than those determined by terzaghi s classical approach richards and reddy 2007 skempton and brogan 1994 fleshman and rice 2013 huang et al 2017 the linear relationship between the hydraulic gradient and the seepage flow velocity as predicted by darcy s law is observed when vi vcr the slope of the straight line fitted to the experimental data before the slope change yields hydraulic conductivity k 0 206 cm s at a temperature of 15 c the reynolds number re vid ŒΩ varied 0 24 0 89 before boiling happened and the range of re 1 satisfied the linearity of the darcy s law 3 2 experiment setup 3 2 1 test material black silica sand particles with a mean diameter of 0 58 mm as shown in fig 3 and a grain density of 2 64 g cm3 were used as the test material which also has been used for the above mentioned permeability test the sand was packed in the seepage box as sediment the physical properties of the test material and the results of the permeability test are summarized in table 1 3 2 2 experimental facilities a laboratory examination of the seepage effects was carried out in an acrylic glass sided re circulating close conduit channel whose dimensions were 10 cm in width 5 cm in depth and 300 cm in length an adjustable seepage box 10 10 cm of the same material was attached to the bottom of the channel as the seepage zone or the test section the test apparatus for the experiment is shown in fig 4 the flow rate in the conduit was controlled using a valve and monitored using an electromagnetic flow meter a transparent sand trap 10 cm in width and 13 cm in depth in the form of a hopper was placed 14 5 cm downstream of the seepage zone to collect the transported sand particles during the experiment the same method has been applied by many other researchers sumer et al 2003 pagliara et al 2011 cao et al 2016 the sand trap was used to directly measure the bed load transport rate by collecting the entrained sand within a specified duration the structure of the test apparatus was similar to the efa erosion function apparatus of briaud et al 2001 although it did not include the water tank generating the seepage flow and the deposition box 3 2 3 seepage box the seepage box was located 201 5 cm downstream of the conduit in order to obtain a uniform surface flow the sand in the seepage box was placed on top of a filter net which in turn overlaid a perforated plastic plate and a thin gravel layer the gravel layer was introduced to ensure a controlled and uniform seepage flow in other words the layer reduces the possibility of pre boiling in the vicinity of the seepage box wall seepage was then introduced into the seepage box using a hosepipe which was connected to the water tank this water tank was continually supplied with water to maintain different hydraulic gradients throughout the seepage zone the head difference for the different hydraulic gradients was read from the piezometers attached to the seepage box the flow rate into the seepage box was monitored using another electromagnetic flow meter 3 2 4 piv data acquisition and shear velocity the vertical velocity profile of the flow in the channel was measured at the upstream edge of the seepage zone the smooth bed and at the seepage zone the sand bed using the particle image velocimetry piv method adrian 1991 shown in fig 5 nylon particles 10 ¬µm in size were used as the tracer material and illuminated by a vertical laser sheet side view images of the flow focusing on the upstream edge of the sand bed and the sand bed itself were acquired using a camera then 100 consecutive images were captured and processed to compute the ensemble average velocity fields the regions of 0 10 mm length in sand bed and 30 40 mm length in the upstream edge of the sand bed as shown in fig 5 a were selected to extract data for making vertical velocity profiles the shear velocity was calculated by the newton raphson iterative method for curve fitting of the measured velocity profile to the logarithmic law and the modified logarithmic law on the smooth bed and the sand bed of the channel respectively as shown in fig 6 a d when a seepage flow occurs in a permeable sand bed it invalidates the usual logarithmic law for an impermeable bed schlichting 1979 proposed the modified logarithmic law considering both injection and suction in a permeable sand bed the logarithmic law and the modified logarithmic law are given as follows 7 u 1 k ln y a s 8 u 1 k ln y a s v s 4 u 1 k ln y a s 2 9 u u u y u y ŒΩ where u u y vs ŒΩ k and as denote the horizontal flow velocity the shear velocity the vertical coordinate with its origin at the bed the seepage velocity the kinematic viscosity of water the von k√°rm√°n constant k 0 41 and the integral constant for a smooth bed as 5 29 shear velocity u appearing in eqs 7 and 8 is related to bed shear stress œÑ as follows 10 œÑ œÅ w u 2 the shear velocity at different hydraulic gradients is summarized in table 2 this table comprises both measured and estimated values for different experimental cases the temperature of the water the sedimentation rate the shear velocity the seepage velocity and the hydraulic conductivity at different hydraulic gradients are measured in this experiment on the other hand the changes in porosity at each hydraulic gradient are estimated using the kozeny donat equation ichikawa et al 2012 as it is difficult to measure the porosity of sand that may change during experimentation the calculated shear velocity in the smooth bed from the curve fitting to the logarithmic law given by eq 7 can be used to estimate the bed shear stress in the sand bed a detailed explanation of this is presented in the results and discussions section 3 3 test procedure a series of tests was carried out which followed successive operating stages the surface flow velocity was changed for each hydraulic gradient and the corresponding velocity vector image was recorded using the particle image velocimetry piv method for subsequent analysis each test usually took 7 8 h depending on the imposed hydraulic gradient and the required velocity vector image the test procedure was continued until the critical hydraulic gradient was reached details of the test procedure are given as follows 1 the sediment box was installed at the bottom of the channel after being filled with cohesionless sand particles 2 the water flow into the main channel was started and kept at a slow enough rate so as not to move the sediment particles the temperature of the flowing water was recorded 3 the water tank connected to the sediment box was lifted up to the height that would enable the realization of the predetermined hydraulic gradients of 0 00 0 15 0 25 0 35 0 45 0 55 0 65 and 0 75 for each series of tests 4 the motion of the sediment particles started as the flow rate in the main channel was increased then side view images were acquired focusing on target zones using piv for subsequent analysis of vertical velocity vector profiles of the channel flow 5 open the transparent sand trap valve to collect the wet sand particles which were trapped for 30 60 min then the wet sand particles were put in oven dried at 120 c for 24 hour by measuring the weight of the dried sand particles the sediment transport rate of the transported sand particles was obtained for each test series 6 the 3rd to 5th steps of the above procedure were repeated changing the hydraulic gradient and the flow rate in the channel to order to obtain six or seven pieces of data for each test series with a predetermined value of hydraulic gradient in this way the critical shear stress at the different hydraulic gradients were determined the height of the bed surface in the sediment box could be adjusted along a shaft by rotating a screw attached at its bottom although the sediment transport rate in the experiment was fairly small as shown in the next section because all the tests were focused on the incipient motion of the bed particles the bed degradation due to erosion was controlled a few times throughout the experiment by rotating the screw slowly by hand 4 results and discussions 4 1 shear velocity on sand bed the roughness of the sand bed which is divided into hydraulically smooth hydraulically rough and transitional incompletely rough has a significant influence on the estimation of the shear velocity or the shear stress of the bed a thin layer must exist very close to the boundary in all turbulent flows where the viscous shear stress overcomes the turbulent shear stress the flow becomes laminar in a layer of thickness Œ¥ near the wall known as a viscous sublayer for turbulent flows the thickness of viscous sublayer Œ¥ can be expressed as 11 Œ¥ 11 6 ŒΩ u where ŒΩ and u denote the kinematic viscosity of water and the shear velocity of the flow respectively the grain shear reynolds number denoted by re which is proportional to the ratio of grain diameter d to the thickness of viscous sublayer has the following form 12 r e u d ŒΩ d Œ¥ eqs 11 and 12 are used for determining whether the turbulent flows are hydraulically smooth d Œ¥ 3 or re 4 rough 6Œ¥ d or 70 re or in transition between smooth and rough Œ¥ 3 d 6Œ¥ or 4 re 7 0 julien 1998 the shear velocity at the upstream edge the smooth bed of the seepage zone in the experiment is calculated from eq 7 and the values for Œ¥ and re are 6 93 10 4 m 8 44 10 4 m and 7 96 9 71 respectively the flow of water in the experiment lies in the transition range which is close to the hydraulically smooth range hence the shear velocity or the bed shear stress at the upstream edge can be a reasonable estimate of that on the seepage zone if seepage does not occur since the bed shear stress generally decreases when the upward seepage flow comes onto the bed the bed shear stress estimated at the upstream edge may well become higher than that on the seepage zone with upward seepage on the other hand eq 8 is applied to the flows on a smooth bed with injection or suction this equation is also used to determine the shear velocity on the seepage zone from the flow velocity profile on the sand bed however as mentioned above the sand bed of the seepage zone is not entirely hydraulically smooth therefore the shear velocity estimated by eq 8 can be slightly smaller than the actual or true one on the seepage zone the sand bed both eqs 7 and 8 are used to estimate the shear velocity on the seepage zone in the experiment it should be noted from the above discussion that the shear velocity at the upstream edge calculated by eq 7 is regarded as the maximum estimate when there is injection whereas the shear velocity from the flow velocity profile on the sand bed calculated by eq 8 is regarded as the minimum estimate 4 2 vertical velocity profile it is useful to investigate the effect of injection on vertical velocity profiles as mentioned in the previous section the vertical velocity profile measurements were conducted at the upstream of the sediment box and in the seepage zone with upward seepage flows through the sand bed the vertical velocity profiles of typical experiments underlined in table 2 are shown in fig 7 although the measured velocity profiles in both zones do not change significantly however a closer investigation in fig 7 shows that the some of measured velocity profiles near the bed are displaced further away from the boundary in the seepage zone than that of the upstream edge of the seepage zone during injection kavcar and wright 2009 also found that the lower velocities near the bed are displaced further away from the boundary during injection the velocity profile especially at i 0 75 displaces more in the seepage zone resulting higher flow velocity values than the upstream edge of seepage zone this may happen due to larger hydraulic gradient 4 3 shear velocity at incipient motion the results of the relationship between the sediment transport rate of the sand particles and the shear velocity calculated by curve fitting to the logarithmic law eq 7 and to the modified logarithmic law eq 8 under the various hydraulic gradients of 0 00 0 15 0 25 0 35 0 45 0 55 0 65 and 0 75 shown in figs 8 and 9 respectively are described both figures show that the changes in the sediment transport rate over the shear velocity were small even when the hydraulic gradients were increased the value of the shear velocity which induces the incipient motion also known as the critical shear velocity of the sediment particles can be obtained as the x intercept of the approximate lines of higher sediment rates and the corresponding shear velocities the values of shear velocity for each hydraulic gradient are placed in a limited range as shown in table 2 therefore the bedload transport equation can be linearized for sufficiently accurate estimation in the neighborhood of critical shear velocity or critical shear stress letting u cs be the value of the x intercept the critical shear stress under the seepage flow is calculated as 13 œÑ cs œÅ w u c s 2 where u cs denotes the critical shear velocity under the upward seepage flow the value next to the vertical dashed line in figs 8 and 9 corresponds to the critical shear velocity or shear velocity at incipient motion if the bed shear stress value is used instead of the shear velocity value for plotting figs 8 and 9 the dimensionless critical shear stress estimation will be varied negligibly on the other hand the shear velocity is directly related to the viscous sublayer estimation discussed in the previous subsection as a result the shear velocity value is used in this experiment to estimate the dimensionless critical shear stress the dimensionless critical shear stress is then estimated using second equality of eq 5 cheng and chiew 1999 suggested that some subjectivity should be expected and that a certain amount of scattering in the experimental data is unavoidable if the incipient motion of the bed particles is visually recognized the subjectivity involved with a visual judgment of the incipient motion can be avoided in this research by using the above mentioned method to determine the critical shear stress correlation and ordinary regression analyses were conducted to examine the relationship between the shear velocity and the sediment transport rate prediction as can be seen in figs 8 and 9 each of the r squared values for the different hydraulic gradients is positively and significantly correlated the r squared values show a good agreement between the fitted model and the measurement the sediment transport rate is incrementally dependent on the shear velocity the shear velocity varies in a short range for different hydraulic gradients when considering the upstream edge of the seepage zone as shown in fig 8 therefore the approximate lines seen in the figure may well cross each other and the values of the critical shear stress for the different hydraulic gradients do not vary significantly the upward seepage adds additional hydrodynamic force which initiates the movement of sand particles as a result it reduces the critical shear velocity in other words critical shear stress the critical shear stress can be determined from eq 13 it is seen from figs 8 and 9 that the critical shear velocity or critical shear stress get reduced as the hydraulic gradient increased this phenomenon is also found from the analytical results reported in dey and zanke 2004 cheng and chiew 1999 the experimental results reported in cheng and chiew 1999 ali et al 2003 kavcar and wright 2009 liu and chiew 2012 also confirm that the upward seepage reduces the critical shear stress on the other hand rao and sitaram 1999 found that upward seepage increases the stability of the bed which means the increment of critical shear stress this result contradicts to the present observation but their result can not be generalized because the empirical equations proposed by them does not allow for a change in seepage velocities liu and chiew 2012 4 4 dimensionless critical shear stress the relationship between the dimensionless critical shear stress values of the sand particles and the hydraulic gradients of 0 00 0 15 0 25 0 35 0 45 0 55 0 65 and 0 75 is shown in fig 10 the linear fit lines through the rectangular points and the circular points denote the experimental results of the dimensionless critical shear stress with hydraulic gradients in the seepage zone and in the upstream edge of the seepage zone respectively as shown in fig 10 the calculated values for the dimensionless critical shear stress vary in the range of 0 0358 œÑ c 0 0284 when considering the upstream edge of the seepage zone on the other hand the values for the dimensionless critical shear stress vary in the range of 0 0334 œÑ c 0 0128 when considering the seepage zone the values in both cases are validated with shield s diagram shields 1936 when an upward seepage flow does not occur a good agreement is found where the value of œÑ c for coarse granular material d 0 5 mm is 0 033 at 20 c julien 1998 in both cases the dimensionless critical shear stress decreases with the increment of hydraulic gradient which is also confirmed by xie et al 2009 the decreasing trend of dimensionless critical shear stress also adheres to results found by cheng and chiew 1999 liu and chiew 2012 it is seen from fig 10 that the dimensionless critical shear stress does not decrease with an increase in the hydraulic gradient as much as expected by eq 6 the solid gray line in fig 10 corresponds to eq 6 the following reason for the discrepancy between the value of the dimensionless critical shear stress at the upstream edge of the seepage zone and eq 6 can be considered the bed shear stress was determined by the approach velocity profile at the upstream edge of the seepage zone where the channel bottom is not permeable the injection into the permeable sediment bed might significantly decrease the bed shear stress on it on the contrary the following reason for the discrepancy between the value of the dimensionless critical shear stress in the seepage zone and eq 6 can be considered the injection decreases the effective weight of the particles thus promoting bed sediment mobility cao et al 2016 consequently the dimensionless critical shear stress decreases with an increase in the hydraulic gradient the value of dimensionless critical shear stress in the seepage zone decreases significantly shown in fig 10 when hydraulic gradient is more than 0 1 kavcar and wright 2009 also concluded that hydraulic gradients of bed seepage greater than 0 1 are required to have a noticeable effect on non cohesive sediment bed stability 4 5 limitations and further research one of the limitations of present study is the spatial scale resolution of the flume where the length of the flume is 300 cm the length of the experimental flume is smaller than that of other researcher s experiments liu and chiew 2012 lu et al 2008 the size of the seepage zone 10 cm 10 cm is also smaller than that of the other researchers liu and chiew 2012 lu et al 2008 on the other hand uniform seepage flow conditions can never be achieved for a large sized seepage zone based on the laboratory observations we analyzed macroscopically the variation of critical shear stress with the hydraulic gradient of the seepage flow the microscopic investigation of critical shear stress with the hydraulic gradient can be a potential way of further research 5 conclusions a theoretical analysis and experimental study were conducted to investigate the critical shear stress of sand particles under injection since the upward seepage force causes a decrease in the virtual weight of the bed material the conventional concept of dimensionless critical shear stress has shown that theoretically the induced upward hydraulic gradient brings about a decrease in the critical shear stress linearly and that this force does not diminish even at the quicksand condition this is due to a reduction in the seepage force on the bed surface but the reduction is only half of that occurring in the bed located at a depth greater than several pore sizes martin and aral 1971 force analyses also revealed that the ratio of the critical shear stress with seepage to that without seepage is dependent on the ratio of the hydraulic gradient of seepage to its value at the quicksand condition in the experiments a water channel was constructed to be 10 cm in width 5 cm in depth and 300 cm in length a section of the channel was made as a sediment bed with cohesionless sand particles subjected to upward seepage flow and installed at the bottom of the channel by changing the flow rate in the channel the critical shear stress under different hydraulic gradients was determined at the upstream edge of the seepage zone and in the seepage zone the experimental results revealed that the dimensionless critical shear stress acting on the cohesionless sand particles decreased slightly as the hydraulic gradient of the seepage flow was increased when critical shear stress was determined at the upstream edge of the seepage zone the linear fit line of the experiment was seen to lie above the line calculated by eq 6 moreover the dimensionless critical shear stress acting on the cohesionless sand particles decreased sharply as the hydraulic gradient of the seepage flow was increased when critical shear stress was determined in the seepage zone the linear fit line was seen to lie below the line calculated by eq 6 it is assumed that the critical shear stress calculated in the upstream edge of the seepage zone was seen as a kind of maximum force on the other hand the critical shear stress calculated in the seepage zone was seen as a kind of minimum force finally it can be concluded that the dimensionless critical shear stress acting on these experimental cohesionless sand particles fell between these minimum and maximum forces declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by jsps kakenhi grant in aid for scientific research b grant number 17h03889 the first author would like to express his gratitude to the mext scholarship provided by the japanese government the authors also would like to thank all the anonymous reviewers for their valuable comments and suggestions appendix notations as integral constant for smooth bed d diameter of cohesionless soil particle f seepage force g gravitational acceleration i hydraulic gradient ic critical hydraulic gradient k hydraulic conductivity n porosity re reynolds number re grain shear reynolds number u horizontal flow velocity u shear velocity u cs critical shear velocity under upward seepage flow vi injection velocity vcr critical injection velocity vs seepage velocity y vertical coordinate with its origin at the bed œÅw water density œÅs grain density ŒΩ kinematic viscosity of water œÑc critical shear stress with dimension of stress œÑ c dimensionless critical shear stress œÑcs critical shear stress under upward seepage flow œÑ cs dimensionless critical shear stress under upward seepage flow Œ¥ viscous sublayer thickness k von k√°rm√°n constant 
6067,low lying coastal cities are vulnerable to flooding under the combined impact of storm tide and heavy rainfall while storm tide or heavy rainfall alone is able to directly cause widespread flooding in coastal areas often heavy rainfall and storm tide happen concurrently and the severity of flooding is greatly exacerbated current methods for understanding flood risk and mapping floodplains normally does not clearly communicate either the individual or combined impact of these two flooding mechanisms flood mitigation strategies typically target either rainfall driven flooding e g stormwater controls or tidally driven flooding e g flood walls and tide gates thus better understanding and communicating the individual and combined flood risk resulting from these two mechanisms can be important to improving flood resilience to address this need this study presents tools and methods for floodplain mapping in coastal urban environments were rainfall and storm tide driven flooding can be better understood and communicated the approaches are demonstrated for a watershed in norfolk va usa as a case study system using a 1d pipe 2d overland flow hydrodynamic model built for the watershed storm tide and heavy rainfall events with return periods varying from 1 to 100 year were designed based on historical observations and combined into a series of compound storm scenarios then these compound storm scenarios were simulated using the hydrodynamic model for simulating flow through both the land surface and underground pipe network systems results show how the capacity of the drainage system and therefore flood risk reduction is sensitive to storm tide levels even for less extreme events with a 1 year return period the model also provides new insights into the role of stormwater infrastructure in exacerbating flooding risk within communities during high sea level conditions results demonstrate how dividing the floodplain into different regions based on the dominant flooding mechanism rainfall vs storm tide makes it possible to better target mitigation strategies to improve flood resilience to this end a transition zone index tzi is presented to help decision makers identify the change from rainfall driven to tide driven flooding for locations within a watershed finally we demonstrate how different flood mitigation strategies can be tested using this modeling approach to better understand their impact on increasing flood resilience within the system for portions of the floodplain impacted by rainfall driven and tidal driven flooding keywords coastal city urban hydrology coastal flood mapping storm tide heavy rainfall 2d hydrodynamic modeling flood resilience 1 introduction in the context of sea level rise and climate change flooding is one of the most challenging issues facing coastal cities today hallegatte et al 2013 woodruff et al 2013 coastal cities form a vital component of national and global economies however coastal cities and their economies are increasingly vulnerable to extreme storm events hanson et al 2011 as a consequence of extreme storm events flooding impacts on these low lying densely populated and highly developed regions can be devastating gallien et al 2014 wahl et al 2015 karamouz et al 2017 sadler et al 2017 bilskie and hagen 2018 in coastal cities flooding is primary caused by two processes surface runoff due to inland heavy rainfall and tidal flooding from extreme high tide dawson et al 2008 archetti et al 2011 xu et al 2014 wahl et al 2015 heavy rainfall is more likely to cause severe flooding in urban areas with poorly functioning or insufficient stormwater infrastructure upadhyaya et al 2014 yazdanfar and sharma 2015 in coastal cities rainfall driven stormwater collected by drainage system is designed to drain into the sea either by gravity fed flow or pumping however during extreme high tide events the drainage capabilities are greatly reduced with a worse situation of backward flow additionally extreme high tide alone is able to directly cause widespread coastal flooding xu et al 2014 castrucci and tahvildari 2018 thus if heavy precipitation and extreme high tide happen concurrently the severity of flood can be greatly exacerbated zheng et al 2013 xu et al 2014 wahl et al 2015 karamouz et al 2015 2017 wu et al 2018 the extreme high tide discussed in this study is in the form of storm tide which is the total observed seawater level during a storm resulting from the combination of storm surge and the astronomical tide prior studies have used statistical methods to explore the interdependence between storm tide and heavy rainfall and their combined impact on flood risk zheng et al 2013 xu et al 2014 wahl et al 2015 batten et al 2017 wu et al 2018 zheng et al 2013 investigated the presence of the dependence between extreme rainfall and storm surge on australian coastline using available rainfall and tide level observations they found a statistically significant dependence with regional and seasonal variations for the majority of studied locations wahl et al 2015 studied the likelihood of concurrent storm tide and heavy rainfall for major coastal cities in the contiguous united states it was found that the probability of combined storms is higher for the atlantic gulf coast relative to the pacific coast meanwhile in many of the focused cities the number of compound events has increased greatly over the past century and this trend may continue under the changing environment xu et al 2014 and batten et al 2017 estimated the joint probability of storm tide and extreme rainfall in their study areas and proposed design guidance for future flooding preparedness specifically batten et al 2017 who worked on the same region coastal of virginia usa as the current study showed that over 50 of the rainfall events happened when sea water level was higher than mean daily high tide while statistical approaches are important for understanding risk they are not able to identify specific areas within a coastal community vulnerable to flooding nor are they able to quantify how modifications to the built environment in the form of infrastructure improvements can mitigate flooding risk physical models of the system are needed for these challenges coupled one dimension 1d pipe and two dimension 2d overland flood models are an efficient way to simulate urban flooding and have been widely used for assessing urban flood risk leandro et al 2009 seyoum et al 2012 russo et al 2015 fan et al 2017 martins et al 2018 in prior studies 1d models ray et al 2011 lian et al 2013 bacopoulos et al 2017 karamouz et al 2017 or 2d models karamouz et al 2017 silva araya et al 2018 have been used to investigate the combined impact of storm tide and extreme rainfall but the combination of 2d 1d modeling approaches to simulate both overland flow and flow through stormwater drainage systems for coastal watersheds is novel coastal regions are usually located in low relief terrains with flat or mild slopes and a large amount of storage potential especially in coastal cities with complex topography and a large number of artificial structures routing water in such regions is not as straightforward as in high gradient regions since water does not always stay within river channels in confined channels 1d models are able to generate good estimation of flooding as long as the water remains in the channels mark et al 2004 leandro et al 2009 however for extreme storm events in urban environment stormwater flow can easily overtops the curbs in the streets and the direction of the flow may change dramatically in such conditions a 2d model is a more reliable tool for urban flood simulation however even though 2d models were used in karamouz et al 2017 and silva araya et al 2018 the underground drainage system was not considered in both studies underground drainage system is a key component of stormwater management infrastructure in coastal cities and its efficiency could be greatly influenced by the downstream tidal boundary conditions archetti et al 2011 therefore in order to simulate coastal city flooding in a realistic manner flood models need to be capable of simulating the dynamics of flow on ground surface and pipe flow in underground drainage system as well as the interaction between them an effective way is to use a 1d pipe and 2d overland coupled model several commercial or open source 1d 2d modeling system are available such as the two dimensional unsteady flow tuflow model syme 2001 mike 21 carr and smith 2007 xp swmm leandro et al 2016 and wu et al 2017 such modeling systems can support coastal flood mapping with the consideration of the individual and combined flood risk resulting from storm tide and heavy rainfall and it can be important to improving flood resilience by testing the impact of different potential mitigation strategies in prior studies geospatial information and hydrodynamic models have been used for understanding flood risk and mapping coastal floodplains wang et al 2002 karamouz et al 2015 karamouz et al 2017 fema 2018 however these methods normally do not clearly communicate the mechanisms of flooding for specific locations in other words it is not clear if the flooding is caused by the individual or combined impact of storm tide and heavy rainfall this is problem in part because flood mitigation strategies typically target either rainfall driven flooding e g stormwater controls or tidally driven flooding e g flood walls and tide gates to access flood risk across coastal landscapes bilskie and hagen 2018 proposed a methodology to delineate coastal floodplains into three flood zones tidal zone hydrological zone and transition zone according to different driving forces of flooding the transition zone is defined as an area susceptible the interaction between tidal and rainfall driven flooding application of this method to a flooding event in southeast louisiana shows that the excess rainfall and storm surge interact nonlinearly and their compound effect is smaller than their superposition bilskie and hagen 2018 their study area was primarily located in a rural area with no effect from underground stormwater drainage systems the transition zone identified from their study is primarily located in a region relatively close to the shoreline where the tide has a significant impact on flooding however in urban environments the interaction between rainfall driven flooding and tidal flooding exists on both the land surface and subsurface through stormwater pipeline drainage systems thus the influence of storm tide is not limited to the near shoreline region but regions further inland as well the objective of the study is to develop methodologies to enhance the understanding of coastal city flood risk under compound storm events and demonstrate how flood mitigation strategies for improving flood resilience current methods for understanding flood risk and mapping do not clearly communicate either the individual or combined impact of different flood mechanisms in coastal cities flood mitigation strategies typically target either rainfall driven flooding e g stormwater controls or tidally driven flooding e g flood walls and tide gates the methodology developed in this study can help to better understand and communicate the individual and combined flood risk resulting from these two mechanisms a high resolution coupled 1d pipe 2d overland hydrodynamic model was built using the tuflow modeling system for a watershed within the hague community of norfolk va usa tuflow solves the full 2d depth averaged momentum and continuity equations for shallow water free surface flow and incorporates the full functionality of the estry one dimensional 1d hydrodynamic network syme 2001 this modeling system takes both rainfall and storm tide level as inputs and outputs detailed flooding simulations on both land surface and underground pipeline system which allows for the assessment of flood risk and the evaluation of the contribution of flooding from individual or combined factors the coastal floodplain mapping method proposed in bilskie and hagen 2018 was extended for coastal urban watershed based 2d 1d flood model simulations the spatial extent of flood regions dominated by different flood mechanisms can be identified we also introduce an index to represent the likelihood of a region being susceptible to the combined impact of storm tide and heavy rainfall the index is to help decision makers identify the change from rainfall driven to tidally driven flooding for locations within a watershed the mapping strategy also assists in understanding how flood mitigation approaches reduce flooding risk resulting from rainfall and storm tide drivers the results make it possible to better target mitigation strategies to improve flood resilience as a demonstration two flood mitigation methods are tested in this study the methodologies developed in this study can aid city planners and stormwater engineers in other coastal communities to understand and improve flood resilience by targeting both rainfall and storm tide driven flooding the remainder of the paper is organized as follows the methodology section provides background information about the study domain and explains the urban flood model and design the storm scenarios used in the study it also includes a description of how flood zones were determined within the floodplain mapping analysis and introduces the concept of a transition zone index tzi the results and discussion section explains the model evaluation how the lag between the peak storm tide and rainfall was determined in the modeling scenarios and flood risk determined by the model the influence of storm tide on the underground stormwater drainage system is also explored followed by the coastal floodplain mapping results and a brief exploration of how flood mitigation strategies could reduce the floodplain for the study watershed the paper concludes with key findings along with possible future research to further advance the approach 2 methodology 2 1 study area norfolk virginia usa is the second most populous city in virginia and the home of world s largest naval base norfolk is a highly urbanized and relatively flat community with nearly all areas below elevation 4 5 m north american vertical datum of 1988 nadv 88 the relative low elevations and tidal connections to the chesapeake bay place a significant percentage of the city at risk of tidal flooding the tidal flooding risk is more serious under the threat of sea level rise slr and land subsidence li et al 2013 sadler et al 2017 the study domain is located in the hague community of the norfolk va fig 1 the waterbody in the southwest is the receiving body of water from the study domain which subsequently feeds into the elizabeth river there is no hydraulic structures such as tide gage exist between the domain outfall and the elizabeth river the domain outfall is tidally influenced and subjected to storm surges the sources of spatial datasets used in this study are provided in table 1 the study domain has a total area of 3 7 km2 including total waterbody area of 0 1 km2 and land area of 3 6 km2 in which 0 7 km2 is building area ground surface elevation of the study domain varies from 0 3 m to 4 2 m with an average of 2 6 m navd88 in this study the tide level data was collected from the sewells point station station id 8638610 which is 9 7 km away from the domain tidal boundary this tide gauge has the longest tide level record dating back to 1927 in virginia there is no official rain gauge located inside the study domain rainfall data was obtained from two weather stations run by the u s national weather services nws and two other weather stations run by the hampton roads sanitation district hrsd fig 1 on average the nws and hrsd stations are about 9 km and 3 km away from the study domain center respectively the two nws weather stations have hourly rainfall data available since 1948 and 1973 respectively the hrsd stations were installed in january 2016 for hurricane events simulated the study the nws rainfall record was used as rainfall input for hurricanes earlier than 2016 and the hrsd rainfall record was used for hurricanes after 2016 2 2 the urban flood model the study domain is located in a highly urbanized area with complex flow patterns and paths the interaction between overland flow and pipe flow significantly increases the complexity of flood modeling to overcome these difficulties a 1d pipe 2d overland hydrodynamic flood model was built using the tuflow model tuflow was chosen due to its capability to represent surface flow on a 2d domain as well as fluvial and pipe network via its 1d functionality and the dynamically link between the two the tuflow high performance computing hpc engine allows to execute the model on multiple gpu units which would significantly speed up model simulations the domain boundary was selected from the basin boundaries provided by the city of norfolk and adjusted based on a high resolution lidar digital elevation model dem and the underground drainage system there is no rainfall driven flow in the form of overland or pipe flow entering into the study domain from adjacent watersheds therefore all rainfall driven flooding is generated inside the domain the outlet of the domain connects to the elizabeth river which is a portion of the chesapeake bay wave speed of tide is currently not considered in this study so the tide level at swells point was considered to be the same as the outlet of the study watershed the topography of the 2d domain was defined using a 1 m 1 m lidar dem building outlines and road centerlines collected from the virginia geographic information network vgin as shown in table 1 a land cover dataset with 1 m spatial resolution was obtained from vgin to define the overland roughness the manning s roughness coefficients for overland flow from mccuen 1998 were assigned to the 2d domain based on the land cover types as shown in table 2 for a small watershed flooding is primarily from short duration extreme storm events bryndal et al 2017 at the same time the current study area has an imperviousness ratio of 57 and shallow groundwater level thus infiltration is expected to have minor influence on flooding caused by extreme storm events therefore infiltration was not considered in the current version of the urban flood model which presumes saturated conditions within the watershed prior to the model simulation period tuflow solves the full 2d depth averaged momentum and continuity equations for shallow water free surface flow and incorporates the full functionality of the estry one dimensional 1d hydrodynamic network syme 2001 in tuflow inlets and grates are represented as pits which allow modelers to specify a depth discharge relationship between ponding depth at pits and flow rate entering drainage system the depth discharge relationship controlled by the type and dimension of inlet defines the flow rate of overland stormwater entering into the pipeline system the urban drainage design manuals from federal highway administration 2009 and state departments of transportation e g vdot 2017 provide methods to calculate the draining capacity corresponding to the type and dimensional of different inlets in this study the depth discharge curves were determined for different types of inlets based on the vdot drainage manual 2017 the manning s roughness coefficients were assigned to different types of pipelines as shown in table 2 2 3 designing of combined storm events this study focuses on storm tide and heavy rainfall occurring with hurricanes on the virginia coastline a summary of the hurricane history of central and eastern virginia is provided by the national weather service nws 2016 flood risk as a consequence of storm tide and heavy rainfall with the return periods varying from 1 to 100 year are simulated and investigated in this study thus hurricanes resulted in both storm tide and rainfall with recurrence intervals less than one year for coastal virginia were filtered out from the list of hurricanes analyzed in this section historical hurricanes with rainfall and tide peak recurrence intervals greater than one year are listed in table 3 hourly rainfall data were collected from the nws weather station 013 737 due to it having the longest record in the study region the sewells points station was installed in 1927 to collect tide level data thus only hurricanes happened after 1927 are listed in table 3 for the 15 hurricanes with an available rainfall record the total amount of rainfall varies from 16 8 mm to 289 9 mm the minimal and maximum tide peaks are 0 55 m and 1 95 m navd88 respectively the rainfall durations of the 15 hurricanes vary from 8 to 77 h with the median of 22 h ten out of the 15 hurricanes have rainfall durations between 16 and 30 h therefore because rainfall events happening during hurricanes in the virginia coastal region have average durations of about 22 h a 24 hour duration was selected as the design rainfall events in this study 2 3 1 designing of storm tide events the annual exceedance probability curves of extreme tide levels for the sewells points station were generated by the u s national oceanic and atmospheric administration noaa https tidesandcurrents noaa gov est curves shtml stnid 8638610 the annual exceedance probability curves of extreme tide levels with 95 confidence intervals are included in the report the curves were calculated from the annual highest tide levels after the mean sea level trend was removed the tide levels with different return periods along with the 95 confidence intervals are obtained from the noaa report as shown in table 4 the tide level was converted from the mean higher high water mhhw datum to navd88 to be consistent with the urban flood model settings the tide level time series observed during historical hurricanes are taken as the references for designing storm tide events tide peak levels were selected as an indicator to choose historical hurricanes as reference to design storm tide events for storm tides with certain return periods in table 4 the matched hurricane events in table 3 have tide peak levels that are close to the storm tide peaks and fall in between the 95 confidence intervals the tide level observations of the matched hurricanes would be taken as the designed storm tide events take the 50 year storm tide event as an example according to table 4 the 50 year tide has a peak of 1 87 m navd88 with 95 confidence intervals from 1 64 m to 2 33 m in the table 3 hurricane isabel 2003 had a tide level peak of 1 91 m which is closest to the 50 year tide among all these hurricanes at the same time the tide peak level of hurricane isabel 2003 falls in between the 95 confidence interval of the 50 year tide therefore hurricane isabel 2003 was selected as the 50 year storm tide event in this study and its tide level observation was used to design the 50 year storm tide event designed storm tide events with return periods of 1 10 50 and 100 years are presented in fig 2 2 3 2 designing of heavy rainfall events in this study the rainfall intensity durationfrequency idf curves were obtained from the noaa atlas 14 precipitation frequency estimates bonnin et al 2006 the noaa atlas 14 contains precipitation frequency estimates with associated confidence intervals for the united states and it is provided through a web site https hdsc nws noaa gov hdsc pfds pfds map cont html the 24 hour rainfall intensities with the 90 confidence intervals for different return periods were obtained from the noaa atlas 14 and are shown in table 5 the rainfall distribution used for rainfall design storms was obtained from a natural resources conservation service nrcs study merkel et al 2015 in merkel s study 2015 four types of rainfall distributions were developed from data in the noaa atlas 14 a map showing a multistate area with groups of regional precipitation distributions was presented along with tables containing 24 hour precipitation distributions in merkel s study 2015 the current study domain is located in the region of type c precipitation distribution the precipitation distribution is non dimensional between values 0 to 1 0 designed rainfall events were generated by multiplying the type c precipitation distributions with the corresponding 24 hour rainfall intensities from the noaa atlas 14 the synthetic rainfall events with different return periods are presented in fig 3 a series of compound storm scenarios were created by combining different synthetic storm tide and heavy rainfall events the combined impact of storm tide and heavy rainfall are investigated according to the urban flood model simulation for these storm scenarios flood simulations on both 2d land area and 1d pipelines were generated as outputs 2 4 determine flood zones according to bilskie and hagen 2018 the coastal floodplain can be separated into three different flood zones hydrological zone tidal zone and transition zone based on the driving forces of flooding in the tidal zone storm tide is the primary factor of flooding and rainfall has negligible impacts the tidal zone is usually located near a shoreline the hydrological zone normally located inland is dominated by rainfall driven flooding with only minor impacts from storm tide the transition zone is where significant interactions exist between rainfall driven and tidal flooding these three flood zones for a specific combined storm event are determined by the maximum water level simulations from three designed storm scenarios in simulation i the storm tide is the only input i e no rainfall input simulation ii consists of heavy rainfall input with a normal tide normal tide means an average astronomical tide that cannot cause flooding in the study domain and its maximum tide level is lower than all drainage pipeline outlets simulation iii consists of both storm tide and heavy rainfall thus flooding in simulations i and ii is driven by storm tide and rainfall respectively and it is driven by the combined effect of storm tide and rainfall in simulation iii in the tidal zone rainfall has negligible impacts on flooding thus the maximum water level simulation from simulation iii would have minor differences compared to simulation i even with the existing of rainfall impact therefore the tidal zone is defined as the area where the maximum water level simulations from simulations i and iii have a difference equal to or smaller than 0 01 m in the hydrological zone storm tide has minor impacts on flooding therefore the maximum water level simulations from simulation ii and iii would be fairly close in the hydrological zone in the current study the hydrological zone is identified as the area where the maximum water level simulations from simulation ii and iii have a difference equal to or smaller than 0 01 m the transition zone is normally located in between the hydrological and tidal zones in the transition zone both the maximum water level simulations from simulation i and ii are smaller than simulation iii with a difference greater than 0 01 m the spatial extent of the transition zone varies with the change of storm tide and heavy rainfall combinations thus simply mapping this zone does not fully describe this complex interaction between storm tide and heavy rainfall in general a greater tide peak or rainfall intensity would lead to a larger transition zone for compound storms with higher tide peaks the tidal zone and transition zone is more likely to extend further inland meanwhile the increase of rainfall intensity would shrink the spatial extent of the tidal zone to quantify this interaction we defined the transition zone index tzi as 1 tzi m n where m is the number of simulations with transition zones sharing a same location and n is the total number of simulations tzi can be computed for any watershed based on the simulations from all the compound storm scenarios as demonstrated in this study a high tzi locates an area in the watershed where flooding is the product of interactions between storm tide and heavy rainfall the higher the tzi the stronger the interaction between these two primarily mechanisms for coastal flooding tzi helps to identify regions in the watershed that would be impacted by flood mitigation approaches that target either storm tide driven flooding or rainfall driven flooding 3 results and discussion 3 1 sensitivity analysis the results of a sensitivity analysis of the model mesh resolution and energy loss for the 1d pipe model are presented as demonstrated in prior studies 1d 2d hydrodynamic models can be sensitive to many parameters including model mesh resolution energy loss between pipe and overland flow exchange dem resolution and manning s roughness coefficients adeogun et al 2015 glock et al 2019 exploring the sensitivity of all these parameters is extremely challenging given the computational demands of the model 2d hydrodynamic modeling is known to have significant computational demands papanicolaou et al 2011 morsy et al 2018 for our modeling work a personal computer windows 10 pro 64 bit operating system was used equipped with an intel i7 8700 cpu 32 gb ram and 2 nvidia geforce gtx 1080ti gpus with a 5 m uniform cartesian grid the urban flood model run using the a gpu solver took approximately 2 5 h to complete a simulation of a storm event lasting 143 h given the practical limitations imposed by this simulation runtime the sensitivity analysis for this study considered just two important properties of the model mesh resolution and energy loss coefficients of the 1d pipeline the manning s roughness coefficients for both land and pipe were chosen based on the recommendation in mccuen 1998 as shown in table 2 and held constant in the simulations the highest resolution lidar data available from the city of norfolk va was used as the dem the simulations of hurricane irene 2011 were taken as examples in the model sensitivity analysis the urban flood model can be simulated with mesh resolution no greater than 1 m which is the spatial resolution of the dem three mesh resolutions 10 m 5 m and 2 m were tested and compared as shown in table 6 generally the mesh resolution can significantly influence both the simulation results and the time theoretically the higher resolution mesh is more likely to provide an accurate better representation of street level flood simulation however the computational cost increases dramatically as the mesh resolution increases for example the computational time increased about 5 times as the mesh resolution changed from 5 m to 2 m compared to the 2 m mesh the results from 5 m mesh have a relatively small difference approximately 0 4 for maximum flood volume and 10 for maximum flood area the difference in maximum flood area was primarily in regions with a shallow flood depth of less than 0 2ft the 10 m mesh resolution showed a greater error compared to the 5 m resolution without a significant runtime savings therefore considering the model accuracy and computational cost the 5 m mesh resolution was chosen for this study the energy loss is associated with the contraction and expansion of flow into and out of a structure in the urban flood model the initial pipeline entrance contraction and exit expansion energy loss is predefined then the urban flood model is able to automatically adjust the entrance and exit energy loss according to the approach and departure velocities in the upstream and downstream pipes details of the energy loss adjustment technique are referenced to tuflow manual 2016 and tullis and robinson 2008 different combinations of entrance and exit loss varying from 0 0 to 1 0 were defined to explore their impacts on the model results as shown in table 7 the maximum flood volume and area happened when entrance and exit losses are both equal to 1 0 the minimum flood volume and area occurred on the condition that entrance and exit losses are 0 5 and 0 0 respectively however the difference between results on these two conditions is fairly small 0 5 on maximum flood volume and 0 4 on maximum flood area therefore it can be assumed that the urban flood model results important to this study area and volume of flooding are not sensitive to the initial energy loss of pipelines therefore the entrance and exit losses were set to 0 5 and 1 0 for the rest of the study 3 2 model evaluation observations of the depth extent and duration of flooding in urban coastal landscapes are very rare however such data are essential to evaluate the performance of urban flood models smith et al 2012 data sources such as photographs taken of flooded areas newspaper reports and personal interviews flood information collected from social media and crow sourced drone footage can be converted to inundation information for model evaluation smith et al 2012 middleton et al 2014 fohringer et al 2015 loftis et al 2017 however these data sources are often sparse and not available for the current study domain in the current study the data source used for flood model evaluation is a crowdsourced flood report dataset from the city of norfolk va this record includes flooded street locations in norfolk starting from hurricane nicole on 30 september 2010 sadler et al 2018 in the flood report record only the date and location of reports were stored instead of the precise time and flood depth therefore the maximum inundation maps on the date when flood locations were reported were compared with the flood report locations as an indication of model performance during a storm event stormwater may cause ponding on the most parts of the study domain ponding depth is selected as the indicator for inundation area mapping in this study the inundation maps shown in this paper only include area with ponding depth greater than 0 1 m this value was selected to distinguish between dry land and flooded locations during storm events it is assumed that the impact of flood is negligible for flood management purpose when the water depth is smaller than 0 1 m the model performance was evaluated on hurricanes irene 2011 hermine 2016 and matthew 2016 fig 4 if simulated ponding exists in a 20 m buffer of a flood reported location this flood report was assumed to validate the model simulation all flood reported locations of hurricanes irene and matthew are consistent with the inundated areas from the simulations during hurricane hermine 25 flood locations were reported and 22 88 locations matched with the flood model simulation the remaining three flood locations are about 250 m away from the shoreline as shown in fig 4 b the ponding depth at these three locations varies from 0 05 m to 0 09 m which is lower than the cutoff depth selected for inundation area mapping the crowdsourced flood report dataset contains unique and valuable street level flood information but there are still limitations of this dataset as can be expected when using crowd sourced data the flood report dataset has an unknown amount of subjectivity and bias because the flood locations are reported by individuals sadler et al 2018 nonetheless using the best available information it is reasonable to suggest that the urban flood model has predictive skill at simulating flooded roads for three different extreme weather events 3 3 time lag between storm tide and rainfall the storm scenarios were created by combining the synthetic rainfall and storm tide events however we needed a method to match the time axis of rainfall and storm tide events usually there is a time lag between storm tide and rainfall events and the time lag has a significant impact on flood risk zheng et al 2013 in this section we show how the time lag between the tide peak and rainfall peak influence flood risk in the study domain time lag is defined as 2 t lag t tidepeak t rainfallpeak where t tidepeak is the time of tide peak and the t rainfallpeak is the time of rainfall peak in this analysis the 10 year rainfall is selected as an intermediate rainfall intensity the 1 and 10 year storm tides were chosen to represent a short duration less than 6 h and a long duration greater than 6 h storm tide respectively for each combination of storm tide and heavy rainfall 17 synthetic storm scenarios with time lags varying from 8 to 8 h were created and simulated the maximum inundation areas mia in percentage of the total land area and the maximum flood volumes mfv on land are shown in fig 5 the tide levels at the time of rainfall peak for each scenario are provided on the upper row of fig 5 for both the 1 year tide and 10 year tide cases the mias appear when tide peaks and rainfall peaks happen simultaneously i e time lags equal to zero the mfvs occur when rainfall peaks are one hour ahead of tide peaks time lags equal to one from fig 5 we found that both mia and mfv have positive correlations with tide levels at the time of rainfall peaks when the absolute values of time lag are greater than 4 h rainfall peaks happen at low tide periods and both mia and mfv are relatively small for scenarios with absolute values of time lag less than 4 h the mia and mfv increase rapidly with the increase of tide levels at rainfall peaks using mia and mfv as indicators it the worst flooding appears to happens when the time lags are between 1 to 2 h in the current study the compound storms with simultaneous storm tide and rainfall are chosen to represent the worst case scenarios where the worst case scenarios are determined by using the mia as the indicator of flood severity 3 4 flood risk the flood ponding depth at the time of maximum inundation area for each storm scenario is presented in fig 6 among all storm scenarios the maximum ponding depth of 1 49 m appeared during the compound storm of 100 year rainfall and 100 year tide for storm scenarios with fixed rainfall intensity for example 1 year rainfall the inundation area and ponding depth near the shoreline increase rapidly as the storm tide return period increases several inland flood prone areas are isolated from overland tidal flooding however for a specific rainfall intensity both the inundation area and ponding depth in these areas experience a significant increase as the storm tide return period increases flooding in these flood prone areas are greatly influenced by the impact of storm tide on underground pipeline system which will be discussed in detail in the section 3 5 mias and mfvs for different compound storm scenarios are provided in fig 7 the storm scenario with the 1 year rainfall and 1 year storm tide would flood 12 7 of the land area with a mfv of about 76 000 m 3 the storm scenario with the 100 year rainfall and 100 year storm tide according to the model would cause mia of 38 9 and mfv of about 457 000 m 3 from fig 7 the results show that mia is more sensitive to the change of rainfall return period compared to tide return period for example under the 1 year storm tide condition mia increases from 12 7 for 1 year rainfall to 32 1 for 100 year rainfall in contrast for the 1 year rainfall event mia increases from 12 6 to 22 7 for 1 and 100 year storm tides respectively from fig 7 mfv is susceptible to the change of both rainfall intensity and storm tide severity the simulations from certain storm scenarios have a similar amount of mias or mfvs but different spatial extents for example the difference between mias for the storm scenario with the 10 year rainfall and 1 year tide and the storm scenario with the 1 year rainfall and 50 year tide is only 0 7 however fig 7 shows that these two scenarios while having a similar mia have large differences in the spatial extent of inundated areas as expected the flooded area of the event with a 1 year rainfall and 50 year tide is primarily concentrated near the shoreline while the event with 10 year rainfall and 1 year tide has flooded areas more inland with relatively shallow ponding depths 3 5 influence of storm tide on underground drainage system the study domain has a complex drainage system which plays a key role in the stormwater management model results and local knowledge of the drainage system both suggest that the efficiency of the drainage system is highly sensitive to the tide levels at the outfalls during storm tide events the pipeline outfalls can be partly or even fully submerged in a submerged state both the head difference between upstream and downstream pipes and the capacity of the system are reduced which slows the draining of stormwater through the system in the study domain the ground elevation of several roads and streets near the shoreline is higher than surrounding areas these connected roads and streets form a barrier impeding overland tidal flooding entering into inland regions the area in between the shoreline and these elevated roads and streets is defined as the shoreline floodplain inside the shoreline floodplain inundation is the combined consequence of overland tidal flooding local rainfall driven flooding and surcharge flow from the underground pipeline system the inland region is free from overland tidal flooding thus the inundation in the inland region is a consequence of local rainfall driven flooding and surcharge flow from underground pipelines therefore in the inland region the flood severity for a fixed rainfall event is determined by the efficiency of the underground pipeline system which is highly sensitive to the tide levels at outfalls to explore the relationship between tide level and the efficiency of the drainage system the flood severity in the inland region is analyzed under the impact of different storm tide events in this section the compound storm scenarios with 1 year rainfall and storm tide varying from normal tide to 100 year tide were simulated and analyzed normal tide means an average astronomical tide that cannot cause flooding in the study domain and its maximum tide level is lower than all drainage pipeline outlets as shown in fig 8 the maximum extent of the shoreline floodplain for these compound storm scenarios are covered by the shoreline floodplain mask and the inland region is outside the mask the focus pipes connect the inland region with the shoreline floodplain the time series of total discharge in the focus pipes and the total amount of flood volume in the inland region for the simulated compound storm scenarios are present in fig 9 from fig 9 a there is no backward flow through the focus pipes under the normal tide and 1 year storm tide conditions before hour 12 the total discharge time series have nearly identical trends under these two conditions however the peak of total discharge under the 1 year storm tide condition is about 10 lower than the normal tide condition meanwhile from fig 9 b the maximum inland flood volume for the 1 year storm tide is about 5 higher than the normal tide the pipeline outlets elevation is higher than the normal tide peak but lower than the 1 year storm tide peak therefore the 1 year storm tide has a blockage effect on the drainage system and would slow down the draining of inland stormwater when the recurrence intervals of storm tide are equal to or higher than 10 years backward flow would occur at the beginning period of the storms this means these storm tide events are able to reach to the pipelines in the inland region under the 10 year tide condition the total volume of backward flow through the focus pipes is 37 000 m 3 this volume would occupy a large portion of the storage space of pipeline system and slow down the draining of runoff from the inland region the blockage effect results in the peak of total discharge under the 10 year tide condition decreased by 22 compared to the normal tide condition and the maximum inland flood volume increased by 34 the total volumes of backward flow are 310 000 m 3 and 210 000 m 3 under the 50 and 100 year storm tide conditions respectively in the current paper designed storm tides are selected based on the peak water levels for example the 100 year tide is 0 04 m higher than the 50 year tide however the duration of the 50 year tide is about 5 h longer than the 100 year tide which is the reason that the 50 year tide caused greater volume of backward flow the water head near the peaks of 50 and 100 year storm tide events are higher than several flood prone areas in the inland region thus in the simulation a portion of the backward flow would exit the pipeline system and cause inundation in these areas from fig 9 b the maximum flood volumes under the 50 and 100 year tide conditions have more than 70 increase compared to the normal tide condition therefore the surcharge flow on top of the blockage effect on pipeline system greatly exacerbate the flooding in inland region 3 6 coastal floodplain mapping the coastal floodplain mapping method is demonstrated by three simulations generated from the 50 year rainfall and 50 year storm tide in simulation i the 50 year tide is the only input i e no rainfall simulation ii consists of 50 year rain and normal tide simulation iii consists of 50 year rainfall and 50 year tide for the focused transect in fig 1 the maximum water level simulations for these three simulations along with the land surface elevation profile are presented in fig 10 in the tidal zone the maximum water levels from simulations i and iii have a difference less than 0 01 m which means the impact from rainfall is negligible in the hydrological zone the difference between maximum water level simulations from simulations ii and iii is less than 0 01 m this indicates that storm tide has minor impact in the hydrological zone and rainfall is the dominating factor the transition zone is normally located between the tidal zone and hydrological zone in transition zone the maximum water level from simulation iii is higher than both simulations i and ii for simulation iii the spatial extent of different flood zones are identified as shown in fig 11 the total inundation area is 1 17 k m 2 which is about 32 5 of the land area the inundation area includes 7 of the tidal zone 43 of the hydrological zone and 50 of the transition zone the tidal zone is located in a narrow region near the shoreline the hydrological zone is primarily distributed in inland region the transition zone as originally proposed by bilskie and hagen 2018 is located relatively close to the shoreline however in this study and in contrast to the bilskie and hagen 2018 study due to the existing of pipeline system the transition zone can reach to much further inland areas this is because the strong interaction between rainfall driven and tidal flooding exists for both the ground surface and underground drainage systems based on the simulations from the 16 compound storm scenarios in this study the transition zone index tzi was computed and presented in fig 12 generally high tzi locates flood prone areas where strong interaction exists between storm tide and heavy rainfall these regions are prone to rainfall driven flooding due to the relatively low elevation comparing to surround areas meanwhile storm tide would slow down the draining of stormwater from these regions and in extreme conditions pipe flow can become surcharge flow and exacerbate flooding severity the high tzi areas are normally located in the middle region between shoreline and inland area the inland region has zero or relatively small tzi which means rainfall is the dominating factor of flooding thus in the inland region stormwater control measures e g detention pond or rain garden are effective flood mitigation strategies in the near shoreline region storm tide is the primary driving factor of flooding because of the small tzi therefore tide control measures e g tide gates or flood walls can be effective to reduce flood risk for the high tzi areas both stormwater and tide control measures can potentially help to reduce the flood risk and the efficiency and mechanisms can be evaluated and explored using the 1d pipe 2d overland flood model 3 7 flood mitigation strategies in order to demonstrate how the model can be used to aid decision makers when decided between strategies for improving flood resilience within a system two mitigation strategies were explored for the case study watershed in both cases the tzi maps help decisions makers to anticipate regions within the watershed that will be improved based on the mitigation strategy selected the first strategy is to install flap gates at certain locations within the drainage system to block backflow from high tide this strategy is aimed at improving flood resilience for areas in the tidal zone with a low tzi value the second strategy is to increase the useable capacity of a detention pond within the watershed to increase its capability for flood control this strategy is targeted areas in the hydrological zone with low tzi value could be impacted by either of these two mitigation strategies in complex ways the ponding depth reduction ratio is defined as the criteria for quantifying the improved resilience of the flood mitigation methods the ponding depth reduction ratio is defined as 3 pondingdepthreductionratio mp d modified m p d original mp d original 100 where the mp d modified is the maximum ponding depth simulation from the urban flood model including flood mitigation method and the mp d original is the maximum ponding depth simulation from the original version of the urban flood model with no flood reduction measure two methods of using flap gates are discussed in this section the first method version i is to install flap gates at the 17 outfalls of the drainage system however during extreme high tide overland tidal flooding can reach to near shoreline region to inundate several pits and manholes and sea water would enter into the drainage system through these pits and manholes the region inundated by overland tidal flooding is defined as the tidal floodplain to further reduce the volume of backward flow from tide the second method version ii is to install flap gates at all pipes covered by the 100 year tidal floodplain the version i and ii methods were tested on storm scenarios with 1 year rainfall combined with 10 or 100 year storm tide events the maximum ponding depths were simulated from the urban flood models with and without flap gates the ponding depth reduction ratio were calculated as shown in fig 13 overall the reduction of maximum ponding depth can be observed from the simulation in several flood prone regions after flap gates are installed also flap gates have greater influence for a more extreme storm tide event under the combined impact of the 1 year rainfall and 10 year tide event the version i method is able to reduce the ponding depth by 2 to 5 for several flood prone areas and 5 to 15 in a small portion of these flood prone area under the same event the version ii method generates large area with a reduction ratio between 5 and 15 for the storm scenarios with 100 year tide the ponding depth reduction appear more expansive compared with the 10 year tide however the reduction ratio from the version i method is limited to the range of 2 to 15 and the majority of that is between 2 and 5 for the version ii method the maximum ponding depth shows a significant reduction in the upstream flood prone area in this case a large area experiences a ponding depth reduction ratio between 5 and 30 and several areas have a reduction ratio greater than 30 the detention pond in the study domain is a permanent pool of standing water that provides long term water quality enhancement of stormwater runoff stormwater can also be temporarily stored in the detention pond for downstream flood control the detention pond has a total capacity of about 24 000 m3 and a bed elevation of 1 83 m navd88 the detention pond has a normal water level of about 0 35 m navd88 and detention storage of about 15 600 m3 the flood control ability of the detention pond is determined by its usable capacity at the beginning of storm events to enlarge the usable capacity stormwater control structures can be installed to lower the water level in advance of a forecasted storm for example if the water level is lowered to 1m navd88 the detention pond would gain 7000 m3 extra usable capacity for flood control two initial water level iwl scenarios were tested in this section for the first scenario iwl i the iwl was lowered to 1m above navd88 the second scenario iwl ii had an iwl of 1 83 m the bed elevation meaning the detention pond is dry under the iwl ii condition the iwl ii is tested and discussed to represent a best case scenario for flood risk reduction the storm scenarios with the joint occurrences of 1 and 10 year rainfall with 1 year tide are selected to analyze the efficiency of flood mitigation when the detention pond is in iwl i and ii conditions the ponding depth reduction ratios between the maximum ponding depth simulations with lowered iwls and normal water level of the detention pond are calculated and presented in fig 14 generally lowering the detention pond iwl only influences the flooding in local regions near the pond and the ponding depth reduction ratios on iwl i and ii conditions are very similar for both tested storm scenarios this is because the usable capacities of the detention pond have relatively small difference about 2 000 m3 between iwl i and ii conditions with a 1 year rainfall event the detention pond does not reach to its full capacity under both iwl conditions and the maximum ponding depths in the region downstream the pond decrease by 2 to 15 for a 10 year rainfall event the detention pond does exceed bankfull levels and the maximum ponding depths in the downstream region near the pond decrease by 5 to 15 and a portion of this region has more than a 15 ponding depth reduction ratio a 2 to 15 reduction ratio occurs in the further downstream the most significant flood mitigation appears on the southeastern portion of the detention pond drainage area due to increased capacity to store rainfall runoff generated from this area 4 conclusions an overarching objective of this study was to develop methodologies to enhance the understanding of flood risk within coastal urban watersheds the methodology developed in this study is to better understand and communicate the individual and combined flood risk resulting from heavy rainfall and storm tide to this end we modeled how overland flooding in an urban watershed with stormwater drainage infrastructure is affected by storm tide and rainfall events with varying return periods the study area is located in norfolk va usa a city prone to recurrent flooding challenge the 1 to 100 year storm tide events were designed based on storm tides that happened during historical hurricanes impacting the virginia coastline a series of rainfall events with return periods varying from 1 to 100 year were designed based on the noaa atlas 14 precipitation frequency estimates bonnin et al 2006 these design storm tide and rainfall events were combined to a series of compound storm scenarios a coupled 1d pipe 2d overland hydrodynamic model was built for the study watershed using the tuflow model the model outputs included detailed flooding information on both land surface and underground pipeline system which allows to assess flood risk and understand the contribution of flooding from individual or combined factors floodplain maps and a new transition zone index tzi were created to communicate regions of the watershed under risk of flooding due to tide and rainfall driven mechanisms the 1d pipe 2d overland flood model and floodplain visualizations are a powerful tool to evaluate the efficiency of different flood mitigation strategies as a demonstrated for two flood mitigation methods results show how the capacity of stormwater drainage system is highly sensitive to storm tide levels based on model simulations event with a 1 year tide is able to partially submerge the pipeline outlets and has an impact on the pipeline capacity storm tide events with return periods greater than or equal to 10 years would significantly reduce the drainage capacity extreme storm tide events for example a 50 and 100 year tide would cause flooding within the watershed due to the backing up and day lighting of sea water traveling through stormwater drainage infrastructure even for smaller tide events model simulations show that rainfall driven flooding combined with reduced capacity of the drainage infrastructure caused by tailwater conditions can cause significant flooding in inland regions due to the low gradient of the stormwater drainage infrastructure which is common in many coastal urban areas this interaction between rainfall driven flow and sea water flow traveling through the pipe system can influence flooding far into the watershed this study provides a methodology that can be repeated for other coastal urban watersheds to better understand the influence of storm tide and rainfall driven flooding through floodplain maps the coastal floodplain mapping method proposed in bilskie and hagen s study 2018 was applied to the urban watershed in the current study in bilskie and hagen s study 2018 the study area is located in a rural area and the interaction between rainfall driving and tidal flooding is primarily within the region close to the shoreline however in this study we extended on past work to include the stormwater drainage system showing that the transition zone can reach much further inland due to the underground stormwater drainage system the transition zone index tzi was defined to represent the likelihood of a location under the impact of strong interaction between tidal and rainfall driven flooding in areas with low tzi flood risk is primarily caused by individual factors therefore flood mitigation measures targeting to individual flood mechanisms can be effective ways to reduce flood risk in these parts of the watershed for the high tzi areas both stormwater and tide control measures can potentially assist to reduce the flood risk and the efficiency and mechanisms can be evaluated and explored using the 1d pipe 2d overland flood model lastly the flood model and floodplain visualization is a powerful tool to evaluate the efficiency of different flood mitigation strategies as a demonstration two flood mitigation methods were tested in this study one targeting rainfall driven flooding and the second targeting tidal driven flooding the model simulations show how both methods would be able to reduce the flood risk for certain flood prone regions of the watershed because the floodplain map helps to visualize regions of the watershed where tide rainfall or a combination of these two mechanisms cause flooding it is easier to see how mitigation strategies improve flood resilience this methodology can be of a significant value to cities and communities as they work to improve resilience for a host of services that can be impacted by flood risk the presented model will be used in a future study to explore several aspects of compound storm tide and rainfall driven flooding in this study only tide level data is considered at the boundary as the tide input while tidal flow velocity may have a significant effect on tidal flooding and the function of drainage system future research should focus on coupling a hydrodynamic storm surge model with the inland hydrodynamic model to account for these processes furthermore this study is focused on present sea level however climate change impacts include increases in rainfall intensity and relative sea level rise rslr which could substantially increase the severity of flood risk in the study area future assessments using this model will aim to quantify the impacts of changing climatic conditions on flooding risk declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national science foundation under the award number 1735587 the authors wish to acknowledge the bmt for the tuflow hpc license and kindly help on model building and problem solving we would also like to acknowledge the university of virginia advance research computing services for providing the gpus computing resource nt acknowledges support from the department of transportation through mid atlantic transportation sustainability university transportation center mats utc appendix a the watershed is urbanized and flow has complex patterns and paths through building areas these buildings dissipate energy by forcing the flow to change its direction and speed in prior studies the buildings in the 2d model domain have been represented by increasing the roughness coefficient blocking out of buildings applying energy loss coefficient in building areas and setting the buildings as porous elements hunter et al 2008 syme 2008 chen et al 2012 in this study one assumption is that no water would enter into buildings during simulations therefore the method of blocking out of buildings is the only satisfactory option based on this assumption as shown in fig a1 the areas inside building outlines are deactivated from the 2d domain to make sure no stormwater from rainfall lost by deactivating the buildings areas a building representation method is proposed in this study including three major steps i deactivate areas inside building outlines from the 2d domain ii build polygons that includes groups of buildings and iii apply the rainfall falling on the building areas to the buffered polygon around each group of buildings the building roofs are designed to drain rain water rapidly and completely the assumption behind the building representation method is that rain water can drain out of building roofs without any loss of rain water and no delay time from transferring the water from precipitation to ground this method is reasonable for the study domain where most of its buildings are residential houses with relatively small roof areas 
6067,low lying coastal cities are vulnerable to flooding under the combined impact of storm tide and heavy rainfall while storm tide or heavy rainfall alone is able to directly cause widespread flooding in coastal areas often heavy rainfall and storm tide happen concurrently and the severity of flooding is greatly exacerbated current methods for understanding flood risk and mapping floodplains normally does not clearly communicate either the individual or combined impact of these two flooding mechanisms flood mitigation strategies typically target either rainfall driven flooding e g stormwater controls or tidally driven flooding e g flood walls and tide gates thus better understanding and communicating the individual and combined flood risk resulting from these two mechanisms can be important to improving flood resilience to address this need this study presents tools and methods for floodplain mapping in coastal urban environments were rainfall and storm tide driven flooding can be better understood and communicated the approaches are demonstrated for a watershed in norfolk va usa as a case study system using a 1d pipe 2d overland flow hydrodynamic model built for the watershed storm tide and heavy rainfall events with return periods varying from 1 to 100 year were designed based on historical observations and combined into a series of compound storm scenarios then these compound storm scenarios were simulated using the hydrodynamic model for simulating flow through both the land surface and underground pipe network systems results show how the capacity of the drainage system and therefore flood risk reduction is sensitive to storm tide levels even for less extreme events with a 1 year return period the model also provides new insights into the role of stormwater infrastructure in exacerbating flooding risk within communities during high sea level conditions results demonstrate how dividing the floodplain into different regions based on the dominant flooding mechanism rainfall vs storm tide makes it possible to better target mitigation strategies to improve flood resilience to this end a transition zone index tzi is presented to help decision makers identify the change from rainfall driven to tide driven flooding for locations within a watershed finally we demonstrate how different flood mitigation strategies can be tested using this modeling approach to better understand their impact on increasing flood resilience within the system for portions of the floodplain impacted by rainfall driven and tidal driven flooding keywords coastal city urban hydrology coastal flood mapping storm tide heavy rainfall 2d hydrodynamic modeling flood resilience 1 introduction in the context of sea level rise and climate change flooding is one of the most challenging issues facing coastal cities today hallegatte et al 2013 woodruff et al 2013 coastal cities form a vital component of national and global economies however coastal cities and their economies are increasingly vulnerable to extreme storm events hanson et al 2011 as a consequence of extreme storm events flooding impacts on these low lying densely populated and highly developed regions can be devastating gallien et al 2014 wahl et al 2015 karamouz et al 2017 sadler et al 2017 bilskie and hagen 2018 in coastal cities flooding is primary caused by two processes surface runoff due to inland heavy rainfall and tidal flooding from extreme high tide dawson et al 2008 archetti et al 2011 xu et al 2014 wahl et al 2015 heavy rainfall is more likely to cause severe flooding in urban areas with poorly functioning or insufficient stormwater infrastructure upadhyaya et al 2014 yazdanfar and sharma 2015 in coastal cities rainfall driven stormwater collected by drainage system is designed to drain into the sea either by gravity fed flow or pumping however during extreme high tide events the drainage capabilities are greatly reduced with a worse situation of backward flow additionally extreme high tide alone is able to directly cause widespread coastal flooding xu et al 2014 castrucci and tahvildari 2018 thus if heavy precipitation and extreme high tide happen concurrently the severity of flood can be greatly exacerbated zheng et al 2013 xu et al 2014 wahl et al 2015 karamouz et al 2015 2017 wu et al 2018 the extreme high tide discussed in this study is in the form of storm tide which is the total observed seawater level during a storm resulting from the combination of storm surge and the astronomical tide prior studies have used statistical methods to explore the interdependence between storm tide and heavy rainfall and their combined impact on flood risk zheng et al 2013 xu et al 2014 wahl et al 2015 batten et al 2017 wu et al 2018 zheng et al 2013 investigated the presence of the dependence between extreme rainfall and storm surge on australian coastline using available rainfall and tide level observations they found a statistically significant dependence with regional and seasonal variations for the majority of studied locations wahl et al 2015 studied the likelihood of concurrent storm tide and heavy rainfall for major coastal cities in the contiguous united states it was found that the probability of combined storms is higher for the atlantic gulf coast relative to the pacific coast meanwhile in many of the focused cities the number of compound events has increased greatly over the past century and this trend may continue under the changing environment xu et al 2014 and batten et al 2017 estimated the joint probability of storm tide and extreme rainfall in their study areas and proposed design guidance for future flooding preparedness specifically batten et al 2017 who worked on the same region coastal of virginia usa as the current study showed that over 50 of the rainfall events happened when sea water level was higher than mean daily high tide while statistical approaches are important for understanding risk they are not able to identify specific areas within a coastal community vulnerable to flooding nor are they able to quantify how modifications to the built environment in the form of infrastructure improvements can mitigate flooding risk physical models of the system are needed for these challenges coupled one dimension 1d pipe and two dimension 2d overland flood models are an efficient way to simulate urban flooding and have been widely used for assessing urban flood risk leandro et al 2009 seyoum et al 2012 russo et al 2015 fan et al 2017 martins et al 2018 in prior studies 1d models ray et al 2011 lian et al 2013 bacopoulos et al 2017 karamouz et al 2017 or 2d models karamouz et al 2017 silva araya et al 2018 have been used to investigate the combined impact of storm tide and extreme rainfall but the combination of 2d 1d modeling approaches to simulate both overland flow and flow through stormwater drainage systems for coastal watersheds is novel coastal regions are usually located in low relief terrains with flat or mild slopes and a large amount of storage potential especially in coastal cities with complex topography and a large number of artificial structures routing water in such regions is not as straightforward as in high gradient regions since water does not always stay within river channels in confined channels 1d models are able to generate good estimation of flooding as long as the water remains in the channels mark et al 2004 leandro et al 2009 however for extreme storm events in urban environment stormwater flow can easily overtops the curbs in the streets and the direction of the flow may change dramatically in such conditions a 2d model is a more reliable tool for urban flood simulation however even though 2d models were used in karamouz et al 2017 and silva araya et al 2018 the underground drainage system was not considered in both studies underground drainage system is a key component of stormwater management infrastructure in coastal cities and its efficiency could be greatly influenced by the downstream tidal boundary conditions archetti et al 2011 therefore in order to simulate coastal city flooding in a realistic manner flood models need to be capable of simulating the dynamics of flow on ground surface and pipe flow in underground drainage system as well as the interaction between them an effective way is to use a 1d pipe and 2d overland coupled model several commercial or open source 1d 2d modeling system are available such as the two dimensional unsteady flow tuflow model syme 2001 mike 21 carr and smith 2007 xp swmm leandro et al 2016 and wu et al 2017 such modeling systems can support coastal flood mapping with the consideration of the individual and combined flood risk resulting from storm tide and heavy rainfall and it can be important to improving flood resilience by testing the impact of different potential mitigation strategies in prior studies geospatial information and hydrodynamic models have been used for understanding flood risk and mapping coastal floodplains wang et al 2002 karamouz et al 2015 karamouz et al 2017 fema 2018 however these methods normally do not clearly communicate the mechanisms of flooding for specific locations in other words it is not clear if the flooding is caused by the individual or combined impact of storm tide and heavy rainfall this is problem in part because flood mitigation strategies typically target either rainfall driven flooding e g stormwater controls or tidally driven flooding e g flood walls and tide gates to access flood risk across coastal landscapes bilskie and hagen 2018 proposed a methodology to delineate coastal floodplains into three flood zones tidal zone hydrological zone and transition zone according to different driving forces of flooding the transition zone is defined as an area susceptible the interaction between tidal and rainfall driven flooding application of this method to a flooding event in southeast louisiana shows that the excess rainfall and storm surge interact nonlinearly and their compound effect is smaller than their superposition bilskie and hagen 2018 their study area was primarily located in a rural area with no effect from underground stormwater drainage systems the transition zone identified from their study is primarily located in a region relatively close to the shoreline where the tide has a significant impact on flooding however in urban environments the interaction between rainfall driven flooding and tidal flooding exists on both the land surface and subsurface through stormwater pipeline drainage systems thus the influence of storm tide is not limited to the near shoreline region but regions further inland as well the objective of the study is to develop methodologies to enhance the understanding of coastal city flood risk under compound storm events and demonstrate how flood mitigation strategies for improving flood resilience current methods for understanding flood risk and mapping do not clearly communicate either the individual or combined impact of different flood mechanisms in coastal cities flood mitigation strategies typically target either rainfall driven flooding e g stormwater controls or tidally driven flooding e g flood walls and tide gates the methodology developed in this study can help to better understand and communicate the individual and combined flood risk resulting from these two mechanisms a high resolution coupled 1d pipe 2d overland hydrodynamic model was built using the tuflow modeling system for a watershed within the hague community of norfolk va usa tuflow solves the full 2d depth averaged momentum and continuity equations for shallow water free surface flow and incorporates the full functionality of the estry one dimensional 1d hydrodynamic network syme 2001 this modeling system takes both rainfall and storm tide level as inputs and outputs detailed flooding simulations on both land surface and underground pipeline system which allows for the assessment of flood risk and the evaluation of the contribution of flooding from individual or combined factors the coastal floodplain mapping method proposed in bilskie and hagen 2018 was extended for coastal urban watershed based 2d 1d flood model simulations the spatial extent of flood regions dominated by different flood mechanisms can be identified we also introduce an index to represent the likelihood of a region being susceptible to the combined impact of storm tide and heavy rainfall the index is to help decision makers identify the change from rainfall driven to tidally driven flooding for locations within a watershed the mapping strategy also assists in understanding how flood mitigation approaches reduce flooding risk resulting from rainfall and storm tide drivers the results make it possible to better target mitigation strategies to improve flood resilience as a demonstration two flood mitigation methods are tested in this study the methodologies developed in this study can aid city planners and stormwater engineers in other coastal communities to understand and improve flood resilience by targeting both rainfall and storm tide driven flooding the remainder of the paper is organized as follows the methodology section provides background information about the study domain and explains the urban flood model and design the storm scenarios used in the study it also includes a description of how flood zones were determined within the floodplain mapping analysis and introduces the concept of a transition zone index tzi the results and discussion section explains the model evaluation how the lag between the peak storm tide and rainfall was determined in the modeling scenarios and flood risk determined by the model the influence of storm tide on the underground stormwater drainage system is also explored followed by the coastal floodplain mapping results and a brief exploration of how flood mitigation strategies could reduce the floodplain for the study watershed the paper concludes with key findings along with possible future research to further advance the approach 2 methodology 2 1 study area norfolk virginia usa is the second most populous city in virginia and the home of world s largest naval base norfolk is a highly urbanized and relatively flat community with nearly all areas below elevation 4 5 m north american vertical datum of 1988 nadv 88 the relative low elevations and tidal connections to the chesapeake bay place a significant percentage of the city at risk of tidal flooding the tidal flooding risk is more serious under the threat of sea level rise slr and land subsidence li et al 2013 sadler et al 2017 the study domain is located in the hague community of the norfolk va fig 1 the waterbody in the southwest is the receiving body of water from the study domain which subsequently feeds into the elizabeth river there is no hydraulic structures such as tide gage exist between the domain outfall and the elizabeth river the domain outfall is tidally influenced and subjected to storm surges the sources of spatial datasets used in this study are provided in table 1 the study domain has a total area of 3 7 km2 including total waterbody area of 0 1 km2 and land area of 3 6 km2 in which 0 7 km2 is building area ground surface elevation of the study domain varies from 0 3 m to 4 2 m with an average of 2 6 m navd88 in this study the tide level data was collected from the sewells point station station id 8638610 which is 9 7 km away from the domain tidal boundary this tide gauge has the longest tide level record dating back to 1927 in virginia there is no official rain gauge located inside the study domain rainfall data was obtained from two weather stations run by the u s national weather services nws and two other weather stations run by the hampton roads sanitation district hrsd fig 1 on average the nws and hrsd stations are about 9 km and 3 km away from the study domain center respectively the two nws weather stations have hourly rainfall data available since 1948 and 1973 respectively the hrsd stations were installed in january 2016 for hurricane events simulated the study the nws rainfall record was used as rainfall input for hurricanes earlier than 2016 and the hrsd rainfall record was used for hurricanes after 2016 2 2 the urban flood model the study domain is located in a highly urbanized area with complex flow patterns and paths the interaction between overland flow and pipe flow significantly increases the complexity of flood modeling to overcome these difficulties a 1d pipe 2d overland hydrodynamic flood model was built using the tuflow model tuflow was chosen due to its capability to represent surface flow on a 2d domain as well as fluvial and pipe network via its 1d functionality and the dynamically link between the two the tuflow high performance computing hpc engine allows to execute the model on multiple gpu units which would significantly speed up model simulations the domain boundary was selected from the basin boundaries provided by the city of norfolk and adjusted based on a high resolution lidar digital elevation model dem and the underground drainage system there is no rainfall driven flow in the form of overland or pipe flow entering into the study domain from adjacent watersheds therefore all rainfall driven flooding is generated inside the domain the outlet of the domain connects to the elizabeth river which is a portion of the chesapeake bay wave speed of tide is currently not considered in this study so the tide level at swells point was considered to be the same as the outlet of the study watershed the topography of the 2d domain was defined using a 1 m 1 m lidar dem building outlines and road centerlines collected from the virginia geographic information network vgin as shown in table 1 a land cover dataset with 1 m spatial resolution was obtained from vgin to define the overland roughness the manning s roughness coefficients for overland flow from mccuen 1998 were assigned to the 2d domain based on the land cover types as shown in table 2 for a small watershed flooding is primarily from short duration extreme storm events bryndal et al 2017 at the same time the current study area has an imperviousness ratio of 57 and shallow groundwater level thus infiltration is expected to have minor influence on flooding caused by extreme storm events therefore infiltration was not considered in the current version of the urban flood model which presumes saturated conditions within the watershed prior to the model simulation period tuflow solves the full 2d depth averaged momentum and continuity equations for shallow water free surface flow and incorporates the full functionality of the estry one dimensional 1d hydrodynamic network syme 2001 in tuflow inlets and grates are represented as pits which allow modelers to specify a depth discharge relationship between ponding depth at pits and flow rate entering drainage system the depth discharge relationship controlled by the type and dimension of inlet defines the flow rate of overland stormwater entering into the pipeline system the urban drainage design manuals from federal highway administration 2009 and state departments of transportation e g vdot 2017 provide methods to calculate the draining capacity corresponding to the type and dimensional of different inlets in this study the depth discharge curves were determined for different types of inlets based on the vdot drainage manual 2017 the manning s roughness coefficients were assigned to different types of pipelines as shown in table 2 2 3 designing of combined storm events this study focuses on storm tide and heavy rainfall occurring with hurricanes on the virginia coastline a summary of the hurricane history of central and eastern virginia is provided by the national weather service nws 2016 flood risk as a consequence of storm tide and heavy rainfall with the return periods varying from 1 to 100 year are simulated and investigated in this study thus hurricanes resulted in both storm tide and rainfall with recurrence intervals less than one year for coastal virginia were filtered out from the list of hurricanes analyzed in this section historical hurricanes with rainfall and tide peak recurrence intervals greater than one year are listed in table 3 hourly rainfall data were collected from the nws weather station 013 737 due to it having the longest record in the study region the sewells points station was installed in 1927 to collect tide level data thus only hurricanes happened after 1927 are listed in table 3 for the 15 hurricanes with an available rainfall record the total amount of rainfall varies from 16 8 mm to 289 9 mm the minimal and maximum tide peaks are 0 55 m and 1 95 m navd88 respectively the rainfall durations of the 15 hurricanes vary from 8 to 77 h with the median of 22 h ten out of the 15 hurricanes have rainfall durations between 16 and 30 h therefore because rainfall events happening during hurricanes in the virginia coastal region have average durations of about 22 h a 24 hour duration was selected as the design rainfall events in this study 2 3 1 designing of storm tide events the annual exceedance probability curves of extreme tide levels for the sewells points station were generated by the u s national oceanic and atmospheric administration noaa https tidesandcurrents noaa gov est curves shtml stnid 8638610 the annual exceedance probability curves of extreme tide levels with 95 confidence intervals are included in the report the curves were calculated from the annual highest tide levels after the mean sea level trend was removed the tide levels with different return periods along with the 95 confidence intervals are obtained from the noaa report as shown in table 4 the tide level was converted from the mean higher high water mhhw datum to navd88 to be consistent with the urban flood model settings the tide level time series observed during historical hurricanes are taken as the references for designing storm tide events tide peak levels were selected as an indicator to choose historical hurricanes as reference to design storm tide events for storm tides with certain return periods in table 4 the matched hurricane events in table 3 have tide peak levels that are close to the storm tide peaks and fall in between the 95 confidence intervals the tide level observations of the matched hurricanes would be taken as the designed storm tide events take the 50 year storm tide event as an example according to table 4 the 50 year tide has a peak of 1 87 m navd88 with 95 confidence intervals from 1 64 m to 2 33 m in the table 3 hurricane isabel 2003 had a tide level peak of 1 91 m which is closest to the 50 year tide among all these hurricanes at the same time the tide peak level of hurricane isabel 2003 falls in between the 95 confidence interval of the 50 year tide therefore hurricane isabel 2003 was selected as the 50 year storm tide event in this study and its tide level observation was used to design the 50 year storm tide event designed storm tide events with return periods of 1 10 50 and 100 years are presented in fig 2 2 3 2 designing of heavy rainfall events in this study the rainfall intensity durationfrequency idf curves were obtained from the noaa atlas 14 precipitation frequency estimates bonnin et al 2006 the noaa atlas 14 contains precipitation frequency estimates with associated confidence intervals for the united states and it is provided through a web site https hdsc nws noaa gov hdsc pfds pfds map cont html the 24 hour rainfall intensities with the 90 confidence intervals for different return periods were obtained from the noaa atlas 14 and are shown in table 5 the rainfall distribution used for rainfall design storms was obtained from a natural resources conservation service nrcs study merkel et al 2015 in merkel s study 2015 four types of rainfall distributions were developed from data in the noaa atlas 14 a map showing a multistate area with groups of regional precipitation distributions was presented along with tables containing 24 hour precipitation distributions in merkel s study 2015 the current study domain is located in the region of type c precipitation distribution the precipitation distribution is non dimensional between values 0 to 1 0 designed rainfall events were generated by multiplying the type c precipitation distributions with the corresponding 24 hour rainfall intensities from the noaa atlas 14 the synthetic rainfall events with different return periods are presented in fig 3 a series of compound storm scenarios were created by combining different synthetic storm tide and heavy rainfall events the combined impact of storm tide and heavy rainfall are investigated according to the urban flood model simulation for these storm scenarios flood simulations on both 2d land area and 1d pipelines were generated as outputs 2 4 determine flood zones according to bilskie and hagen 2018 the coastal floodplain can be separated into three different flood zones hydrological zone tidal zone and transition zone based on the driving forces of flooding in the tidal zone storm tide is the primary factor of flooding and rainfall has negligible impacts the tidal zone is usually located near a shoreline the hydrological zone normally located inland is dominated by rainfall driven flooding with only minor impacts from storm tide the transition zone is where significant interactions exist between rainfall driven and tidal flooding these three flood zones for a specific combined storm event are determined by the maximum water level simulations from three designed storm scenarios in simulation i the storm tide is the only input i e no rainfall input simulation ii consists of heavy rainfall input with a normal tide normal tide means an average astronomical tide that cannot cause flooding in the study domain and its maximum tide level is lower than all drainage pipeline outlets simulation iii consists of both storm tide and heavy rainfall thus flooding in simulations i and ii is driven by storm tide and rainfall respectively and it is driven by the combined effect of storm tide and rainfall in simulation iii in the tidal zone rainfall has negligible impacts on flooding thus the maximum water level simulation from simulation iii would have minor differences compared to simulation i even with the existing of rainfall impact therefore the tidal zone is defined as the area where the maximum water level simulations from simulations i and iii have a difference equal to or smaller than 0 01 m in the hydrological zone storm tide has minor impacts on flooding therefore the maximum water level simulations from simulation ii and iii would be fairly close in the hydrological zone in the current study the hydrological zone is identified as the area where the maximum water level simulations from simulation ii and iii have a difference equal to or smaller than 0 01 m the transition zone is normally located in between the hydrological and tidal zones in the transition zone both the maximum water level simulations from simulation i and ii are smaller than simulation iii with a difference greater than 0 01 m the spatial extent of the transition zone varies with the change of storm tide and heavy rainfall combinations thus simply mapping this zone does not fully describe this complex interaction between storm tide and heavy rainfall in general a greater tide peak or rainfall intensity would lead to a larger transition zone for compound storms with higher tide peaks the tidal zone and transition zone is more likely to extend further inland meanwhile the increase of rainfall intensity would shrink the spatial extent of the tidal zone to quantify this interaction we defined the transition zone index tzi as 1 tzi m n where m is the number of simulations with transition zones sharing a same location and n is the total number of simulations tzi can be computed for any watershed based on the simulations from all the compound storm scenarios as demonstrated in this study a high tzi locates an area in the watershed where flooding is the product of interactions between storm tide and heavy rainfall the higher the tzi the stronger the interaction between these two primarily mechanisms for coastal flooding tzi helps to identify regions in the watershed that would be impacted by flood mitigation approaches that target either storm tide driven flooding or rainfall driven flooding 3 results and discussion 3 1 sensitivity analysis the results of a sensitivity analysis of the model mesh resolution and energy loss for the 1d pipe model are presented as demonstrated in prior studies 1d 2d hydrodynamic models can be sensitive to many parameters including model mesh resolution energy loss between pipe and overland flow exchange dem resolution and manning s roughness coefficients adeogun et al 2015 glock et al 2019 exploring the sensitivity of all these parameters is extremely challenging given the computational demands of the model 2d hydrodynamic modeling is known to have significant computational demands papanicolaou et al 2011 morsy et al 2018 for our modeling work a personal computer windows 10 pro 64 bit operating system was used equipped with an intel i7 8700 cpu 32 gb ram and 2 nvidia geforce gtx 1080ti gpus with a 5 m uniform cartesian grid the urban flood model run using the a gpu solver took approximately 2 5 h to complete a simulation of a storm event lasting 143 h given the practical limitations imposed by this simulation runtime the sensitivity analysis for this study considered just two important properties of the model mesh resolution and energy loss coefficients of the 1d pipeline the manning s roughness coefficients for both land and pipe were chosen based on the recommendation in mccuen 1998 as shown in table 2 and held constant in the simulations the highest resolution lidar data available from the city of norfolk va was used as the dem the simulations of hurricane irene 2011 were taken as examples in the model sensitivity analysis the urban flood model can be simulated with mesh resolution no greater than 1 m which is the spatial resolution of the dem three mesh resolutions 10 m 5 m and 2 m were tested and compared as shown in table 6 generally the mesh resolution can significantly influence both the simulation results and the time theoretically the higher resolution mesh is more likely to provide an accurate better representation of street level flood simulation however the computational cost increases dramatically as the mesh resolution increases for example the computational time increased about 5 times as the mesh resolution changed from 5 m to 2 m compared to the 2 m mesh the results from 5 m mesh have a relatively small difference approximately 0 4 for maximum flood volume and 10 for maximum flood area the difference in maximum flood area was primarily in regions with a shallow flood depth of less than 0 2ft the 10 m mesh resolution showed a greater error compared to the 5 m resolution without a significant runtime savings therefore considering the model accuracy and computational cost the 5 m mesh resolution was chosen for this study the energy loss is associated with the contraction and expansion of flow into and out of a structure in the urban flood model the initial pipeline entrance contraction and exit expansion energy loss is predefined then the urban flood model is able to automatically adjust the entrance and exit energy loss according to the approach and departure velocities in the upstream and downstream pipes details of the energy loss adjustment technique are referenced to tuflow manual 2016 and tullis and robinson 2008 different combinations of entrance and exit loss varying from 0 0 to 1 0 were defined to explore their impacts on the model results as shown in table 7 the maximum flood volume and area happened when entrance and exit losses are both equal to 1 0 the minimum flood volume and area occurred on the condition that entrance and exit losses are 0 5 and 0 0 respectively however the difference between results on these two conditions is fairly small 0 5 on maximum flood volume and 0 4 on maximum flood area therefore it can be assumed that the urban flood model results important to this study area and volume of flooding are not sensitive to the initial energy loss of pipelines therefore the entrance and exit losses were set to 0 5 and 1 0 for the rest of the study 3 2 model evaluation observations of the depth extent and duration of flooding in urban coastal landscapes are very rare however such data are essential to evaluate the performance of urban flood models smith et al 2012 data sources such as photographs taken of flooded areas newspaper reports and personal interviews flood information collected from social media and crow sourced drone footage can be converted to inundation information for model evaluation smith et al 2012 middleton et al 2014 fohringer et al 2015 loftis et al 2017 however these data sources are often sparse and not available for the current study domain in the current study the data source used for flood model evaluation is a crowdsourced flood report dataset from the city of norfolk va this record includes flooded street locations in norfolk starting from hurricane nicole on 30 september 2010 sadler et al 2018 in the flood report record only the date and location of reports were stored instead of the precise time and flood depth therefore the maximum inundation maps on the date when flood locations were reported were compared with the flood report locations as an indication of model performance during a storm event stormwater may cause ponding on the most parts of the study domain ponding depth is selected as the indicator for inundation area mapping in this study the inundation maps shown in this paper only include area with ponding depth greater than 0 1 m this value was selected to distinguish between dry land and flooded locations during storm events it is assumed that the impact of flood is negligible for flood management purpose when the water depth is smaller than 0 1 m the model performance was evaluated on hurricanes irene 2011 hermine 2016 and matthew 2016 fig 4 if simulated ponding exists in a 20 m buffer of a flood reported location this flood report was assumed to validate the model simulation all flood reported locations of hurricanes irene and matthew are consistent with the inundated areas from the simulations during hurricane hermine 25 flood locations were reported and 22 88 locations matched with the flood model simulation the remaining three flood locations are about 250 m away from the shoreline as shown in fig 4 b the ponding depth at these three locations varies from 0 05 m to 0 09 m which is lower than the cutoff depth selected for inundation area mapping the crowdsourced flood report dataset contains unique and valuable street level flood information but there are still limitations of this dataset as can be expected when using crowd sourced data the flood report dataset has an unknown amount of subjectivity and bias because the flood locations are reported by individuals sadler et al 2018 nonetheless using the best available information it is reasonable to suggest that the urban flood model has predictive skill at simulating flooded roads for three different extreme weather events 3 3 time lag between storm tide and rainfall the storm scenarios were created by combining the synthetic rainfall and storm tide events however we needed a method to match the time axis of rainfall and storm tide events usually there is a time lag between storm tide and rainfall events and the time lag has a significant impact on flood risk zheng et al 2013 in this section we show how the time lag between the tide peak and rainfall peak influence flood risk in the study domain time lag is defined as 2 t lag t tidepeak t rainfallpeak where t tidepeak is the time of tide peak and the t rainfallpeak is the time of rainfall peak in this analysis the 10 year rainfall is selected as an intermediate rainfall intensity the 1 and 10 year storm tides were chosen to represent a short duration less than 6 h and a long duration greater than 6 h storm tide respectively for each combination of storm tide and heavy rainfall 17 synthetic storm scenarios with time lags varying from 8 to 8 h were created and simulated the maximum inundation areas mia in percentage of the total land area and the maximum flood volumes mfv on land are shown in fig 5 the tide levels at the time of rainfall peak for each scenario are provided on the upper row of fig 5 for both the 1 year tide and 10 year tide cases the mias appear when tide peaks and rainfall peaks happen simultaneously i e time lags equal to zero the mfvs occur when rainfall peaks are one hour ahead of tide peaks time lags equal to one from fig 5 we found that both mia and mfv have positive correlations with tide levels at the time of rainfall peaks when the absolute values of time lag are greater than 4 h rainfall peaks happen at low tide periods and both mia and mfv are relatively small for scenarios with absolute values of time lag less than 4 h the mia and mfv increase rapidly with the increase of tide levels at rainfall peaks using mia and mfv as indicators it the worst flooding appears to happens when the time lags are between 1 to 2 h in the current study the compound storms with simultaneous storm tide and rainfall are chosen to represent the worst case scenarios where the worst case scenarios are determined by using the mia as the indicator of flood severity 3 4 flood risk the flood ponding depth at the time of maximum inundation area for each storm scenario is presented in fig 6 among all storm scenarios the maximum ponding depth of 1 49 m appeared during the compound storm of 100 year rainfall and 100 year tide for storm scenarios with fixed rainfall intensity for example 1 year rainfall the inundation area and ponding depth near the shoreline increase rapidly as the storm tide return period increases several inland flood prone areas are isolated from overland tidal flooding however for a specific rainfall intensity both the inundation area and ponding depth in these areas experience a significant increase as the storm tide return period increases flooding in these flood prone areas are greatly influenced by the impact of storm tide on underground pipeline system which will be discussed in detail in the section 3 5 mias and mfvs for different compound storm scenarios are provided in fig 7 the storm scenario with the 1 year rainfall and 1 year storm tide would flood 12 7 of the land area with a mfv of about 76 000 m 3 the storm scenario with the 100 year rainfall and 100 year storm tide according to the model would cause mia of 38 9 and mfv of about 457 000 m 3 from fig 7 the results show that mia is more sensitive to the change of rainfall return period compared to tide return period for example under the 1 year storm tide condition mia increases from 12 7 for 1 year rainfall to 32 1 for 100 year rainfall in contrast for the 1 year rainfall event mia increases from 12 6 to 22 7 for 1 and 100 year storm tides respectively from fig 7 mfv is susceptible to the change of both rainfall intensity and storm tide severity the simulations from certain storm scenarios have a similar amount of mias or mfvs but different spatial extents for example the difference between mias for the storm scenario with the 10 year rainfall and 1 year tide and the storm scenario with the 1 year rainfall and 50 year tide is only 0 7 however fig 7 shows that these two scenarios while having a similar mia have large differences in the spatial extent of inundated areas as expected the flooded area of the event with a 1 year rainfall and 50 year tide is primarily concentrated near the shoreline while the event with 10 year rainfall and 1 year tide has flooded areas more inland with relatively shallow ponding depths 3 5 influence of storm tide on underground drainage system the study domain has a complex drainage system which plays a key role in the stormwater management model results and local knowledge of the drainage system both suggest that the efficiency of the drainage system is highly sensitive to the tide levels at the outfalls during storm tide events the pipeline outfalls can be partly or even fully submerged in a submerged state both the head difference between upstream and downstream pipes and the capacity of the system are reduced which slows the draining of stormwater through the system in the study domain the ground elevation of several roads and streets near the shoreline is higher than surrounding areas these connected roads and streets form a barrier impeding overland tidal flooding entering into inland regions the area in between the shoreline and these elevated roads and streets is defined as the shoreline floodplain inside the shoreline floodplain inundation is the combined consequence of overland tidal flooding local rainfall driven flooding and surcharge flow from the underground pipeline system the inland region is free from overland tidal flooding thus the inundation in the inland region is a consequence of local rainfall driven flooding and surcharge flow from underground pipelines therefore in the inland region the flood severity for a fixed rainfall event is determined by the efficiency of the underground pipeline system which is highly sensitive to the tide levels at outfalls to explore the relationship between tide level and the efficiency of the drainage system the flood severity in the inland region is analyzed under the impact of different storm tide events in this section the compound storm scenarios with 1 year rainfall and storm tide varying from normal tide to 100 year tide were simulated and analyzed normal tide means an average astronomical tide that cannot cause flooding in the study domain and its maximum tide level is lower than all drainage pipeline outlets as shown in fig 8 the maximum extent of the shoreline floodplain for these compound storm scenarios are covered by the shoreline floodplain mask and the inland region is outside the mask the focus pipes connect the inland region with the shoreline floodplain the time series of total discharge in the focus pipes and the total amount of flood volume in the inland region for the simulated compound storm scenarios are present in fig 9 from fig 9 a there is no backward flow through the focus pipes under the normal tide and 1 year storm tide conditions before hour 12 the total discharge time series have nearly identical trends under these two conditions however the peak of total discharge under the 1 year storm tide condition is about 10 lower than the normal tide condition meanwhile from fig 9 b the maximum inland flood volume for the 1 year storm tide is about 5 higher than the normal tide the pipeline outlets elevation is higher than the normal tide peak but lower than the 1 year storm tide peak therefore the 1 year storm tide has a blockage effect on the drainage system and would slow down the draining of inland stormwater when the recurrence intervals of storm tide are equal to or higher than 10 years backward flow would occur at the beginning period of the storms this means these storm tide events are able to reach to the pipelines in the inland region under the 10 year tide condition the total volume of backward flow through the focus pipes is 37 000 m 3 this volume would occupy a large portion of the storage space of pipeline system and slow down the draining of runoff from the inland region the blockage effect results in the peak of total discharge under the 10 year tide condition decreased by 22 compared to the normal tide condition and the maximum inland flood volume increased by 34 the total volumes of backward flow are 310 000 m 3 and 210 000 m 3 under the 50 and 100 year storm tide conditions respectively in the current paper designed storm tides are selected based on the peak water levels for example the 100 year tide is 0 04 m higher than the 50 year tide however the duration of the 50 year tide is about 5 h longer than the 100 year tide which is the reason that the 50 year tide caused greater volume of backward flow the water head near the peaks of 50 and 100 year storm tide events are higher than several flood prone areas in the inland region thus in the simulation a portion of the backward flow would exit the pipeline system and cause inundation in these areas from fig 9 b the maximum flood volumes under the 50 and 100 year tide conditions have more than 70 increase compared to the normal tide condition therefore the surcharge flow on top of the blockage effect on pipeline system greatly exacerbate the flooding in inland region 3 6 coastal floodplain mapping the coastal floodplain mapping method is demonstrated by three simulations generated from the 50 year rainfall and 50 year storm tide in simulation i the 50 year tide is the only input i e no rainfall simulation ii consists of 50 year rain and normal tide simulation iii consists of 50 year rainfall and 50 year tide for the focused transect in fig 1 the maximum water level simulations for these three simulations along with the land surface elevation profile are presented in fig 10 in the tidal zone the maximum water levels from simulations i and iii have a difference less than 0 01 m which means the impact from rainfall is negligible in the hydrological zone the difference between maximum water level simulations from simulations ii and iii is less than 0 01 m this indicates that storm tide has minor impact in the hydrological zone and rainfall is the dominating factor the transition zone is normally located between the tidal zone and hydrological zone in transition zone the maximum water level from simulation iii is higher than both simulations i and ii for simulation iii the spatial extent of different flood zones are identified as shown in fig 11 the total inundation area is 1 17 k m 2 which is about 32 5 of the land area the inundation area includes 7 of the tidal zone 43 of the hydrological zone and 50 of the transition zone the tidal zone is located in a narrow region near the shoreline the hydrological zone is primarily distributed in inland region the transition zone as originally proposed by bilskie and hagen 2018 is located relatively close to the shoreline however in this study and in contrast to the bilskie and hagen 2018 study due to the existing of pipeline system the transition zone can reach to much further inland areas this is because the strong interaction between rainfall driven and tidal flooding exists for both the ground surface and underground drainage systems based on the simulations from the 16 compound storm scenarios in this study the transition zone index tzi was computed and presented in fig 12 generally high tzi locates flood prone areas where strong interaction exists between storm tide and heavy rainfall these regions are prone to rainfall driven flooding due to the relatively low elevation comparing to surround areas meanwhile storm tide would slow down the draining of stormwater from these regions and in extreme conditions pipe flow can become surcharge flow and exacerbate flooding severity the high tzi areas are normally located in the middle region between shoreline and inland area the inland region has zero or relatively small tzi which means rainfall is the dominating factor of flooding thus in the inland region stormwater control measures e g detention pond or rain garden are effective flood mitigation strategies in the near shoreline region storm tide is the primary driving factor of flooding because of the small tzi therefore tide control measures e g tide gates or flood walls can be effective to reduce flood risk for the high tzi areas both stormwater and tide control measures can potentially help to reduce the flood risk and the efficiency and mechanisms can be evaluated and explored using the 1d pipe 2d overland flood model 3 7 flood mitigation strategies in order to demonstrate how the model can be used to aid decision makers when decided between strategies for improving flood resilience within a system two mitigation strategies were explored for the case study watershed in both cases the tzi maps help decisions makers to anticipate regions within the watershed that will be improved based on the mitigation strategy selected the first strategy is to install flap gates at certain locations within the drainage system to block backflow from high tide this strategy is aimed at improving flood resilience for areas in the tidal zone with a low tzi value the second strategy is to increase the useable capacity of a detention pond within the watershed to increase its capability for flood control this strategy is targeted areas in the hydrological zone with low tzi value could be impacted by either of these two mitigation strategies in complex ways the ponding depth reduction ratio is defined as the criteria for quantifying the improved resilience of the flood mitigation methods the ponding depth reduction ratio is defined as 3 pondingdepthreductionratio mp d modified m p d original mp d original 100 where the mp d modified is the maximum ponding depth simulation from the urban flood model including flood mitigation method and the mp d original is the maximum ponding depth simulation from the original version of the urban flood model with no flood reduction measure two methods of using flap gates are discussed in this section the first method version i is to install flap gates at the 17 outfalls of the drainage system however during extreme high tide overland tidal flooding can reach to near shoreline region to inundate several pits and manholes and sea water would enter into the drainage system through these pits and manholes the region inundated by overland tidal flooding is defined as the tidal floodplain to further reduce the volume of backward flow from tide the second method version ii is to install flap gates at all pipes covered by the 100 year tidal floodplain the version i and ii methods were tested on storm scenarios with 1 year rainfall combined with 10 or 100 year storm tide events the maximum ponding depths were simulated from the urban flood models with and without flap gates the ponding depth reduction ratio were calculated as shown in fig 13 overall the reduction of maximum ponding depth can be observed from the simulation in several flood prone regions after flap gates are installed also flap gates have greater influence for a more extreme storm tide event under the combined impact of the 1 year rainfall and 10 year tide event the version i method is able to reduce the ponding depth by 2 to 5 for several flood prone areas and 5 to 15 in a small portion of these flood prone area under the same event the version ii method generates large area with a reduction ratio between 5 and 15 for the storm scenarios with 100 year tide the ponding depth reduction appear more expansive compared with the 10 year tide however the reduction ratio from the version i method is limited to the range of 2 to 15 and the majority of that is between 2 and 5 for the version ii method the maximum ponding depth shows a significant reduction in the upstream flood prone area in this case a large area experiences a ponding depth reduction ratio between 5 and 30 and several areas have a reduction ratio greater than 30 the detention pond in the study domain is a permanent pool of standing water that provides long term water quality enhancement of stormwater runoff stormwater can also be temporarily stored in the detention pond for downstream flood control the detention pond has a total capacity of about 24 000 m3 and a bed elevation of 1 83 m navd88 the detention pond has a normal water level of about 0 35 m navd88 and detention storage of about 15 600 m3 the flood control ability of the detention pond is determined by its usable capacity at the beginning of storm events to enlarge the usable capacity stormwater control structures can be installed to lower the water level in advance of a forecasted storm for example if the water level is lowered to 1m navd88 the detention pond would gain 7000 m3 extra usable capacity for flood control two initial water level iwl scenarios were tested in this section for the first scenario iwl i the iwl was lowered to 1m above navd88 the second scenario iwl ii had an iwl of 1 83 m the bed elevation meaning the detention pond is dry under the iwl ii condition the iwl ii is tested and discussed to represent a best case scenario for flood risk reduction the storm scenarios with the joint occurrences of 1 and 10 year rainfall with 1 year tide are selected to analyze the efficiency of flood mitigation when the detention pond is in iwl i and ii conditions the ponding depth reduction ratios between the maximum ponding depth simulations with lowered iwls and normal water level of the detention pond are calculated and presented in fig 14 generally lowering the detention pond iwl only influences the flooding in local regions near the pond and the ponding depth reduction ratios on iwl i and ii conditions are very similar for both tested storm scenarios this is because the usable capacities of the detention pond have relatively small difference about 2 000 m3 between iwl i and ii conditions with a 1 year rainfall event the detention pond does not reach to its full capacity under both iwl conditions and the maximum ponding depths in the region downstream the pond decrease by 2 to 15 for a 10 year rainfall event the detention pond does exceed bankfull levels and the maximum ponding depths in the downstream region near the pond decrease by 5 to 15 and a portion of this region has more than a 15 ponding depth reduction ratio a 2 to 15 reduction ratio occurs in the further downstream the most significant flood mitigation appears on the southeastern portion of the detention pond drainage area due to increased capacity to store rainfall runoff generated from this area 4 conclusions an overarching objective of this study was to develop methodologies to enhance the understanding of flood risk within coastal urban watersheds the methodology developed in this study is to better understand and communicate the individual and combined flood risk resulting from heavy rainfall and storm tide to this end we modeled how overland flooding in an urban watershed with stormwater drainage infrastructure is affected by storm tide and rainfall events with varying return periods the study area is located in norfolk va usa a city prone to recurrent flooding challenge the 1 to 100 year storm tide events were designed based on storm tides that happened during historical hurricanes impacting the virginia coastline a series of rainfall events with return periods varying from 1 to 100 year were designed based on the noaa atlas 14 precipitation frequency estimates bonnin et al 2006 these design storm tide and rainfall events were combined to a series of compound storm scenarios a coupled 1d pipe 2d overland hydrodynamic model was built for the study watershed using the tuflow model the model outputs included detailed flooding information on both land surface and underground pipeline system which allows to assess flood risk and understand the contribution of flooding from individual or combined factors floodplain maps and a new transition zone index tzi were created to communicate regions of the watershed under risk of flooding due to tide and rainfall driven mechanisms the 1d pipe 2d overland flood model and floodplain visualizations are a powerful tool to evaluate the efficiency of different flood mitigation strategies as a demonstrated for two flood mitigation methods results show how the capacity of stormwater drainage system is highly sensitive to storm tide levels based on model simulations event with a 1 year tide is able to partially submerge the pipeline outlets and has an impact on the pipeline capacity storm tide events with return periods greater than or equal to 10 years would significantly reduce the drainage capacity extreme storm tide events for example a 50 and 100 year tide would cause flooding within the watershed due to the backing up and day lighting of sea water traveling through stormwater drainage infrastructure even for smaller tide events model simulations show that rainfall driven flooding combined with reduced capacity of the drainage infrastructure caused by tailwater conditions can cause significant flooding in inland regions due to the low gradient of the stormwater drainage infrastructure which is common in many coastal urban areas this interaction between rainfall driven flow and sea water flow traveling through the pipe system can influence flooding far into the watershed this study provides a methodology that can be repeated for other coastal urban watersheds to better understand the influence of storm tide and rainfall driven flooding through floodplain maps the coastal floodplain mapping method proposed in bilskie and hagen s study 2018 was applied to the urban watershed in the current study in bilskie and hagen s study 2018 the study area is located in a rural area and the interaction between rainfall driving and tidal flooding is primarily within the region close to the shoreline however in this study we extended on past work to include the stormwater drainage system showing that the transition zone can reach much further inland due to the underground stormwater drainage system the transition zone index tzi was defined to represent the likelihood of a location under the impact of strong interaction between tidal and rainfall driven flooding in areas with low tzi flood risk is primarily caused by individual factors therefore flood mitigation measures targeting to individual flood mechanisms can be effective ways to reduce flood risk in these parts of the watershed for the high tzi areas both stormwater and tide control measures can potentially assist to reduce the flood risk and the efficiency and mechanisms can be evaluated and explored using the 1d pipe 2d overland flood model lastly the flood model and floodplain visualization is a powerful tool to evaluate the efficiency of different flood mitigation strategies as a demonstration two flood mitigation methods were tested in this study one targeting rainfall driven flooding and the second targeting tidal driven flooding the model simulations show how both methods would be able to reduce the flood risk for certain flood prone regions of the watershed because the floodplain map helps to visualize regions of the watershed where tide rainfall or a combination of these two mechanisms cause flooding it is easier to see how mitigation strategies improve flood resilience this methodology can be of a significant value to cities and communities as they work to improve resilience for a host of services that can be impacted by flood risk the presented model will be used in a future study to explore several aspects of compound storm tide and rainfall driven flooding in this study only tide level data is considered at the boundary as the tide input while tidal flow velocity may have a significant effect on tidal flooding and the function of drainage system future research should focus on coupling a hydrodynamic storm surge model with the inland hydrodynamic model to account for these processes furthermore this study is focused on present sea level however climate change impacts include increases in rainfall intensity and relative sea level rise rslr which could substantially increase the severity of flood risk in the study area future assessments using this model will aim to quantify the impacts of changing climatic conditions on flooding risk declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national science foundation under the award number 1735587 the authors wish to acknowledge the bmt for the tuflow hpc license and kindly help on model building and problem solving we would also like to acknowledge the university of virginia advance research computing services for providing the gpus computing resource nt acknowledges support from the department of transportation through mid atlantic transportation sustainability university transportation center mats utc appendix a the watershed is urbanized and flow has complex patterns and paths through building areas these buildings dissipate energy by forcing the flow to change its direction and speed in prior studies the buildings in the 2d model domain have been represented by increasing the roughness coefficient blocking out of buildings applying energy loss coefficient in building areas and setting the buildings as porous elements hunter et al 2008 syme 2008 chen et al 2012 in this study one assumption is that no water would enter into buildings during simulations therefore the method of blocking out of buildings is the only satisfactory option based on this assumption as shown in fig a1 the areas inside building outlines are deactivated from the 2d domain to make sure no stormwater from rainfall lost by deactivating the buildings areas a building representation method is proposed in this study including three major steps i deactivate areas inside building outlines from the 2d domain ii build polygons that includes groups of buildings and iii apply the rainfall falling on the building areas to the buffered polygon around each group of buildings the building roofs are designed to drain rain water rapidly and completely the assumption behind the building representation method is that rain water can drain out of building roofs without any loss of rain water and no delay time from transferring the water from precipitation to ground this method is reasonable for the study domain where most of its buildings are residential houses with relatively small roof areas 
6068,nowadays preparing long term data is one of the main concerns of researchers in many countries many hydro climatological studies have reported that at least 30 year data are required for such studies unfortunately it is impossible to provide 30 year data in many countries even developed countries even the recording the precipitation data in many of the regions varies from one station to another station there are also regions which cannot be ignored due to data for less than 30 years the objective of this research was to evaluate the sensitivity of the seven different precipitation based drought indices including the china z index czi the modified china z index mczi percent of normal precipitation index pnpi deciles index di the z score index zsi effective drought index edi and standardized precipitation index spi to different lengths of record at monthly seasonal and annual time scales in this research monthly seasonal and annual precipitation data of 8 meteorological stations representing eight different climate classes in iran were used for a 55 year period 1960 2014 for each of the monthly seasonal and annual time scales the lengths of record 55 50 45 40 35 and 30 years were extracted from the main period 1960 2014 which each of these lengths was lengths ending to 2014 first the correlation coefficient of the indices was obtained for all lengths of record then match and non match of the indices obtained from the longer lengths of record with the values obtained from shorter lengths of record were investigated for all three time scales finally the unique drought and flood years of stations were compared for the time scales the results revealed that better time stability was seen in the effective drought index edi and z score index zsi compared to other indices in the monthly time scale it means that the sensitivity of these two indices to different lengths of record was less percentage of normal precipitation index pnpi in two seasonal and annual scales also shows the lowest sensitivity was seen among the studied indices however deciles index di and the modified china z index mczi were two indices which had the highest sensitivity to different lengths of record among other indices it means that these two indices have more sensitivity to lengths of record studied and they should be used carefully keywords drought length of a record correlation coefficient match and non match sensitivity 1 introduction water related natural disasters pose major impediments to achieving human security and sustainable socio economic development wwap 2012 droughts are one of the most complicated and at the same time the most unknown water related natural disasters that humans grapple with hagman 1984 this phenomenon has the greatest effect on human activities compared to other natural hazards wilhite 1987 kogan 1997 salami 2004 the drought s effects are basically non structural their spatial extension is wide and the extent of their damage is much greater compared to other water related natural disasters these non structural effects of droughts have been a major obstacle to the development of timely reliable and accurate estimates of the severity of droughts so that setting up and preparing any drought preparedness plan in many countries have become difficult chopra 2006 nearly all regions of the world with various climates have suffered from drought however its effects and frequencies are more vivid in arid and semiarid regimes specifying the characteristics of droughts and wetness in these regions can be considered as one of the essential needs of planners for water resources management the vast country of iran is located in one of these arid and semi arid regions of the world which great changes in the rate of precipitation its high severity and distribution and temperature fluctuations are considered as its characteristics during recent years precipitation anomalies have been increased in various regions in iran due to the factors that are predominantly related to global climatic change the increase in precipitation anomalies has caused changes in the temporal spatial properties of iran s droughts mahmoudi et al 2019 daneshmand and mahmoudi 2017 the results of these changes have been extravagant damages imposed onto the various economic social and bioenvironmental sectors in this territory hence specifying a set of appropriate and accurate indices which can be used to quantify and evaluate the severity and the breadth of drought in the country has special importance several indices have been defined in various regions of the world to monitor the droughts which base of all of them is climatic and environmental data including palmer drought severity index pdsi palmer 1965 deciles index di gibbs and maher 1967 crop moisture index cmi palmer 1968 bhalme mooley drought index bmdi bhalme and mooley 1980 surface water supply index swsi shafer and dezman 1982 standardized precipitation index spi mckee et al 1993 effective drought index edi byun and wilhite 1999 and reclamination drought index rdi tsakiris et al 2007 during the several past decades the increase in the number of various indices of drought monitoring has led to an increase in the comparative studies of them as well the comparative study of several various indices provides the researchers with the possibility of comparing them thereby to become able to choose the best index for monitoring the study region s droughts to specify the accuracy relationship and integration of the relevant indices in respect to a special goal as well amongst the most important studies performed in this regard the researches by mahmoudi et al 2019 dogan et al 2012 morid et al 2006 and wu et al 2001 can be pointed out in line with selecting the best index for monitoring iran s droughts mahmoudi et al 2019 compared seven drought precipitation based indices in comparative research for various climates in iran and concluded that the effective drought index edi and standardized precipitation index spi have had better performances than the other indices these results were exactly the same as the findings attained by morid et al 2006 in the designing of the drought monitoring system in tehran province in iran wu et al 2001 as well concluded in a comparison of three indices namely standardized precipitation index spi china z index and z score index in various temporal scales for the arid and humid climates in china that all three indices have had identical results for all of the various temporal scales palmer s drought severity index pdsi was developed in 1965 by palmer the index has been used for 30 years as an appropriate tool for monitoring the droughts amongst the variables used in this index temperature precipitation runoff evaporation and transpiration as well as soil moisture can be pointed out as an optimal executive index for monitoring systems the index is faced with a lot of problems like the complexity of the calculations doubts in the accuracy of the proposed water balance model non clarity of the temporal span and unclearness of its physical and statistical nature due to its need for a lot of information as pointed out by kao and govindaraju 2010 however colorado state university researchers offered a new probability index called as standardized precipitation index spi for better and accurate monitoring under the conditions of drought and wetness periods mckee et al 1993 1995 the standardized precipitation index spi is calculable for different time intervals and it has high importance for providing early warning and helping to assess the drought severity this index is also an appropriate tool in analyzing the precipitation data and has been considered by many researchers and it is widely used for monitoring and zoning regional and local droughts around the world such as iran karimpour et al 2009 raziei et al 2009 negaresh et al 2010 shahabfar and eitzinger 2013 safari shad et al 2013 akbari et al 2015 the mediterranean paulo and pereira 2007 lana et al 2001 turkey keskin 2009 touchan et al 2005 komuscu 1999 the united states guttman 1999 hayes et al 1999 keyantash et al 2002 and other parts of the world ntale and gan 2003 pandey et al 2008 patel et al 2007 roudier and mahe 2010 considering the advantages of this index which some of them were mentioned above this index has several unique limitations and disadvantages which they should be considered when using it one of these limitations is the sensitivity of this index to the probability distributions used in it since this index analyzes precipitation for monitoring droughts through gamma distribution and this distribution might not be appropriate for all regions or stations investigated blain 2011a a few studies have been carried out so far on the selection of the best probability distribution for this index blain 2011b in brazil angelidis et al 2012 in portugal ntale and gan 2003 in east africa another disadvantage of the standardized precipitation index spi is this index sensitivity to the lengths of the record used which very limited number studies are seen in this regard mirabbasi et al 2013 one of the most important studies conducted in this regard is the study of wu et al 2005 in this research they showed that the percentage related to non matches when the time scale of the data is longer the differences would be more significant for some stations another result of this research is the match of spi values for unique drought and flood years in short and long term scales besides spi values obtained from longer lengths of record are correlated with spi values obtained from shorter lengths of record for all time scales in the studied periods now it has been observed in a review of the subjective literature s resources of the present study that there are many strong and weak points of the various drought indices especially standardized precipitation index spi taken into account by many of the researches in such fields as hydrology geography meteorology climatology and agriculture but in between one of the weak points to which less attention has been paid is the sensitivity of the various drought indices to the length of the various temporal periods although wu et al 2005 have considered it for standard precipitation index spi there is a need for being that much sensitive to the other indices as well thus the present study sought to investigate the sensitivity of spi in addition to the sensitivities of other drought indices like zsi pn di mczi czi and edi to different lengths of record 2 study area and data given the specific geographical position and topography characteristics of each region of iran different climates govern it so that based on the classification performed by masoodian 2012 iran can be divided into eight climatic regions fig 1 in this research one station representing that climate region was selected fig 1 in this research monthly seasonal and annual precipitation data of the studied stations were used for a 55 year period 1960 2014 the names geographical coordinates mean annual temperatures total means of the annual precipitation establishment years and types of the used station have been presented in table 1 the lengths of record 55 50 45 40 35 and 30 years were extracted from the main period 1960 2014 for each of the monthly seasonal and annual time scales it should be stated that each of these lengths was the lengths ending in 2014 the reason that the minimum length of the studied lengths was selected to be 30 years was that it is the most appropriate length of the record to calculate the spi at best state of continuous lengths with minimum 30 years of data mckee et al 1993 3 methodology the model and method used in this research were derived from the research carried out by wu et al 2005 they examined the impact lengths of record of data on calculation of standardized precipitation index spi in this research drought indices were calculated for the mentioned time scales for all selected lengths of record dip software was used to calculate these indices this software was offered by morid et al in 2007 drought monitoring the indices used in the research are introduced in brief 3 1 standardized precipitation index spi this index was provided by mckee et al 1993 and widely used throughout the world this index is based only on the precipitation variable and it is an appropriate tool to realize the drought phenomena in different regions the first step in calculating the spi index is determining the probability distribution function based on the studies conducted by mckee et al 1995 guttman 1999 ntale and gan 2003 and wu et al 2007 the most appropriate probability distribution function for fit to precipitation data is gamma family functions which are defined as follows 1 g x 1 b a Œ≥ a x a 1 e x b in the equation above Œ± 0 is shape parameter Œ≤ 0 is scale parameter x is precipitation amount and Œ≥ Œ± is gamma function the parameters of gamma probability density function are estimated using the maximum likelihood method for each station and for each time scale so 2 Œ± 1 4 a 1 1 4 a 3 b x Œ± a ln x ln x n where n is the number of precipitation observations then calculated parameters are used to find the precipitation cumulative probability for the considered time scale for each of the stations assuming t x Œ≤ the cumulative probability is transformed into the incomplete gamma function 3 g x 0 x y x d x 1 b Œ± Œ≥ Œ± 0 x x Œ± 1 e x b d x when the gamma function is not defined for x 0 and precipitation distribution is zero the cumulative probability is calculated as follows 4 h x q 1 q g x in the equation above the precipitation probability is zero while m is the number of zeros in precipitation time series q is estimated in m n and h x is transformed into the normal variable z with the following approximation 5 z s p i t c 0 c 1 c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 h x 0 5 6 z s p i t c 0 c 1 c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 5 h x 1 0 where 7 t ln 1 h x 2 0 h x 0 5 8 t ln 1 1 0 h x 2 0 5 h x 1 0 and d 1 d 2 d 3 c 0 c 1 c 2 are constant coefficients as follows d 1 1 432788 c 0 2 515517 d 2 0 189269 c 1 0 802853 d 3 0 001308 c 2 0 010328 when the equation of probability of current precipitation data was obtained the spot probability of each of the observed precipitation data is calculated and used to calculate the standard normal probability density function which has the mean of zero and one unit standard deviation these values indicate the spi value for each precipitation data as spi values are fitted with same normal distribution it can be expected that approximately 68 of the times to be placed in values with one unit of standard deviation 95 of the times to be placed with two deviations and 99 of the times to be placed with three standard deviations of mean spi values are classified in table 2 3 2 percent of normal precipitation index pnpi percent of normal precipitation index pnpi is one of the simplest indices for detecting the droughts this index was first presented by wileke et al 1994 the basic concept of this index is the ratio of actual precipitation to its normal value in a specified time period expressed as a percentage and can be calculated for different time scales weekly monthly seasonal and annual the actual value of this index for the studied length of record and station is calculated using the following formula 9 p n p i p i p 100 where pnpi pi and p are the percent of normal precipitation index precipitation of the considered year and mean long term precipitation respectively the point which should not be forgotten in using this index is that this index can be used when the mean precipitation is matched with precipitation median or the precipitation distribution is normal if this condition does not govern precipitation time series its results might result in false interpretations however using this index is simple and has high flexibility for other calculations moreover the results of this index show the deviation from mean well and easily it is considered one advantage of pnpi index table 2 shows the drought classification based on this index 3 3 deciles index di this index was for the first time used in 1967 by gibbs and maher for the investigation of the historical droughts in australia in this index the long term monthly seasonal or annual precipitation values of the studied stations are arranged in ascending or descending order so that their cumulative frequency distribution to be formed then they are divided into groups of normal distribution each of these groups is called a decile the first decile is the amount of precipitation which is less than 10 of the precipitations the second decile shows the amount of precipitation which is less than 20 of the precipitation the fifth decile or median is the amount of precipitation which does not exceed 50 of the precipitations table 2 shows the classification of this index the point which should be remembered in using this index is that if the precipitation data do not follow the normal distribution the data should be normalized using one of the normalization methods one of the methods used in normalizing the data is box cox transformation in this research these transformations were used for stations where their distribution did not follow the normal distribution 3 4 z score index zsi index is calculated very simple it has been used in many drought studies such as tsakiris and vangelis 2004 patel et al 2007 morid et al 2006 the zsi index does not require transforming the fit data for distributions such as gamma or pearson type iii as used in spi and czi this index is obtained from the following equation 10 zsi x ij x œÉ i in the equation above x ij i s the precipitation of month j for length i and œÉi and x are the standard deviation of precipitation and mean in each time scale respectively table 2 shows the classification of this index 3 5 the china z index czi and the modified china z index mczi the czi index was widely used in 1995 by the national climate center of china the czi index is calculated based on the third wilson hilferty third root transformation wilson and hilferty 1931 assuming that the data follow the pearson type iii distribution the czi index is calculated as follows 11 œÉ 1 n i 1 n x i x 2 12 c s i 1 n x i x 3 n œÉ 3 13 czi 6 c s c s 2 z s c o r e 1 1 3 6 c s c s 6 in the equations above œÉ is the standard deviation n is the number of observations and cs is the coefficient of skewness xi and x are calculated exactly as xi and x are calculated in z score index the modified czi index mczi is calculated as czi is calculated while the median is used instead of the mean table 2 shows the severity of drought related to this index 3 6 effective drought index edi this index was developed by byun and wilhite in 1999 to detect and determine the start time and end time of droughts effective drought index edi in its original form is calculated based on daily data akhtari et al 2009 kalamaras et al 2010 kim and byun 2009 kim et al 2009 morid et al 2006 roudier and mahe 2010 unlike other drought indices however its principles can be generalized to monthly precipitation data as morid et al 2007 developed this index for monthly scale thus the monthly time scale developed by morid et al 2007 was used in the current research to calculate edi there are many steps which described later in brief the main concept in this index is effective precipitation ep effective precipitation is the sum of daily precipitation values with a time dependent reducing function which is calculated using the following equation 14 ep n 1 i m 1 n p m n in which i is the duration of summation and pm is precipitation up to m 1 days before in the next step of calculating this index the deviation of the ep of mep is calculated this deviation is calculated by calculating the dep which its equation is presented below in fact mep is the mean of ep for each calendar day which it is climatic characteristics in one place and time dep ep mep calculation of the precipitation needed for a return to normal daily conditions prn is another step of the calculation obtained using eq 12 16 prn dep n 1 j 1 n finally the edi which is the standardized form of prn is calculated according to the following equation 17 edi prn st prn in the equation above st prn represents the standard deviation of prn table 2 shows the classification of different degrees of drought in all the indices studied in this research after calculating the indices the pearson correlation coefficient and spearman rank correlation coefficient kendall and stuart 1977 measuring the power of the linear relationship between the pair of values of the indexes extracted from different lengths of record were calculated for all stations in time scales ranks of values of indices in a specified time period are an important index for the severity of drought and wetness events the rank of each single index value is specified based on its row in the list of ranks then pearson and spearman correlation coefficients are calculated between the pair of values of indices which ranks are used for it as the base for measuring the strength of the relationship between the two index values it should be noted that the numerical correlation coefficients are numbers between zero and one as the correlation value is close to number one the correlation between the two variables would be higher and as it is closer to zero the correlation would be lower the correlation equals to one means linear and 100 relationship correlation can be positive or negative in the second step match and non match between the occurrence severities obtained from the long and short lengths for each station are investigated in three 5time scales in the third step the values of indices obtained from different lengths of record in the unique years of the severe drought and flood in the recorded data were compared 4 results and discussion seven drought indices of di spi pnpi zsi mczi czi and edi were used in this research first the lengths of record of 55 50 45 40 35 and 30 years were extracted at monthly seasonal and annual time scales then the sensitivity of lengths of record was investigated in several steps the correlation coefficient of these indices and then the match and non match of the indices obtained from the longer lengths of record with values obtained from shorter lengths were determined and studied for each of three time scales finally unique drought and flood years of stations were compared for the mentioned time scales 4 1 comparing the correlation coefficients pearson correlation coefficient and spearman correlation coefficient rank were obtained for all studied stations for all lengths in monthly seasonal and annual time scales which 2 cases from each time scale were included in the paper as the results of the two correlation coefficients were very close and similar the results of the spearman correlation coefficient were included in the paper the results of the correlation coefficient obtained at monthly time scales suggested that edi index had the highest correlation coefficient among the indices as the length of record increases in this index the correlation coefficient between lengths of the record increases table 3 b in this scale the mczi index and then di index have the lowest correlation coefficient among the indices so that a weak correlation was found between them in some lengths of record table 3a in other indices the correlation coefficient between the lengths of record was obtained very strong and high for example the relationship between the length of records in the spi zsi and pnpi indices was above 0 90 it should be noted that the results obtained in the spi index are completely similar to the results of wu et al 2001 and confirm the results of their work in the seasonal time scale the edi index was removed since it can be calculated only on a daily and monthly scale the results of the correlation coefficient between the indices were similar to the monthly scale but the results of the correlation coefficient in the di index were reduced significantly so that weak relationship was observed between them in some of the lengths of record table 3c in this scale the highest correlation coefficient among the indices was related to the pnpi index which correlation coefficient between the lengths of the records was higher than 0 9 in all of the studied stations table 3d the correlation coefficient was obtained in annual scale at all stations the correlation coefficient was obtained very strong in all indices except for di index in this index the relationship between lengths of record was reduced and in some lengths the relationship was not found between the lengths of record table 3e in other indices such as zsi index the correlation coefficient between all lengths of record was obtained higher than 0 9 table 3f the mczi index was not calculated in this scale 4 2 comparison of match and non match in the studied indices investigating the match and non match of different classes of drought and wetness from the long term 1960 2014 and short term 1985 2014 was derived from the main length this match and non match are determined as follows if one class of classes of occurrence of droughts derived from long term lengths of record matches with short term lengths of record it is called match otherwise it is called non match hence percentage of non match is obtained by dividing the number of non matches into the sum of the number of matches and non matches moreover to show level of non match the number of frequencies in which difference of match was more than one class was also counted for example this case occurs when the value of the index obtained from the long term length of record is classified within the close to normal class and the value of corresponding index extracted from the short term length of record was classified into severe drought or very severe drought class in first the percentage of non match was generally obtained for all indices fig 2 findings revealed that the lowest non match in all stations except for abadan and babolsar stations was related to edi index so that this value in isfahan and abadan stations was 3 6 and 3 9 percent less than that in other indices additionally the highest non match in all stations except isfahan station was related to the mczi index in the range between 34 2 bandar abbas station and 47 2 abadan station following this index di index had the highest non match in the monthly time scale non match in the mczi and di indexes had difference more than one class the highest percentage of non match occurred in di index 21 9 at zahedan station and it occurred in the mczi index 40 at abadan station which this difference between the long term and the short term was one class table 4 the important point on the edi index is that the percentage of non match in this index in all stations except gorgan station was not more than one class the highest percentage of non match between short term and long term length in this index was 10 3 in the abadan station in the seasonal time scale as with the second stage edi index analysis section was removed in this scale the indices of zsi spi mczi and czi were calculated as moving mean the results obtained in this scale showed that the two indices of mczi and di had the highest non match between the two long and short term lengths so that the non match for the mczi index was more than 50 in sanandaj and abadan stations moreover this value has been repeated for two stations of zahedan and gorgan in the di index the lowest non match among the indices was in two indices of pnpi and spi at different stations at the stations of zahedan abadan and gorgan spi index had the lowest non match and at stations of babolsar isfahan khorramabad and sanandaj pnpi index had the lowest non match the important point observed in this scale was that in all indices the non match was more than 23 at the gorgan station in all indices fig 3 one of its reasons is the precipitation regime of this station which precipitation fluctuations of the station is not uniform the geographical position of this city is so that it is placed in the wet and dry region border in the seasonal time scale the difference of classes between the two mczi and di indices between long term and short term lengths was seen more than one class for example at abadan station non match in both indices of the three classes was different while this difference was up to two classes for other indices this difference of classes in spi index at all stations was one class except for sanandaj gorgan and zahedan stations as the distance of classes increases from one class to another class the distance between classes is reduced table 5 fig 4 shows total percentage of non match at the annual time scale at the studied stations in this scale the mczi index was removed from the sum of indices the highest percentage of non match among the indices belonged to di index at khoramabad station the percentage of non match in this index reached to more than 50 at stations of abadan bandar abbas and khoramabad the percentage of non match for the pnpi index was obtained zero at gorgan station as with other two scales the percentage of non match was increased for all studied indices which its value for all indices was more than 30 table 6 shows the difference of drought and wetness classes at the annual scale as seen the difference of classes in the pnpi index was not observed for many of stations such as abadan babolsar bandar abbas and khoramabad the highest difference of classes as with seasonal time scales is in the di index after the pnpi index the zsi index has the lowest difference in its classes no difference was seen in classes of this index even in abadan stations other indices like the spi index at all stations except for sanandaj station have one difference class the non match in the czi index is evident both in one and two difference classes in the studied stations 4 3 comparing values of different indices in unique years in order to examine the match and non match of the studied indices one very wet year and one very dry year were selected among the studied years in order to examine the length of record match and find the strength of the droughts and witnesses for this purpose the year 2005 was determined as the wet year and the year 2007 was selected as the drought year these years were recognized before by nooshirvani 2014 as shown in fig 5 the edi index has the best match among all lengths this index could easily identify the drought year of 2007 and the severe wet year of 2005 the indices of spi zsi and czi had relatively similar performance these indices as with edi index could not show drought and wetness of the considered years the performance mczi index is very different with that of other indices so that none of the lengths of record match with each other 5 conclusion nowadays preparing the long term data is one of the main concerns of researchers in many countries many studies have reported that at least 30 year data are required for a scientific research unfortunately it is impossible to provide 30 year data in many countries even developed countries even the recording the precipitation data in many of the regions varies from one station to another station there are also regions which cannot be ignored due to data less than 30 years this research tried to evaluate the sensitivity of precipitation lengths of record in different indices to introduce an index so that the lengths of record to have the lowest impact on its values and can cover this weakness of data shortage weakness it should be noted that this research has been conducted regardless of other shortcomings of the indices it means that only one aspect has been considered in the paper at a monthly scale the edi index showed better time stability compared to other indices in this index the values derived from the lengths of record did not differ significantly as the lengths of record increases the accuracy of index increases and the effect on the classes is reduced this index is very appropriate at these time scale for places and regions where they have no longer lengths of record the pnpi index at annual and seasonal scale at most of the stations had the lowest non match among the studied indices even at several stations no non match was seen among lengths of record in this index the zsi index is one of the indices which non match in this index is less compared to other indices this index has the lowest non match after the edi index at monthly time scale and after the pnpi index in the seasonal time scale this index at the annual scale both after the pnpi index and along with the czi index is among the indices showed the better match the czi index has shown better match compared to spi index the spi index showed appropriate performance but the results are not reliable non match at studied time scales was not equal for different stations at stations of gorgan khorramabad and sanandaj non match increases are from monthly time scale to seasonal time scale and from seasonal time scale to annual time scale however non match at stations such as zahedan babolsar isfahan reduces from monthly time scale to seasonal time scale and increases from seasonal time scale to annual time scale one of the most important non match at different stations is the probability distribution gamma used in spi index which is equal for all studied stations to solve this problem probability distribution should be obtained for each station and examine the length of record the highest non match among the studied indices was seen in two mczi and di indices very low time stability was seen in these indices at studied time scale these indices were severely sensitive to lengths of record and they should be used with caution in the studies declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124181 these data include google maps of the most important areas described in this article appendix a supplementary data the following are the supplementary data to this article the following kml file contain the google maps of the most important areas described in this article map 
6068,nowadays preparing long term data is one of the main concerns of researchers in many countries many hydro climatological studies have reported that at least 30 year data are required for such studies unfortunately it is impossible to provide 30 year data in many countries even developed countries even the recording the precipitation data in many of the regions varies from one station to another station there are also regions which cannot be ignored due to data for less than 30 years the objective of this research was to evaluate the sensitivity of the seven different precipitation based drought indices including the china z index czi the modified china z index mczi percent of normal precipitation index pnpi deciles index di the z score index zsi effective drought index edi and standardized precipitation index spi to different lengths of record at monthly seasonal and annual time scales in this research monthly seasonal and annual precipitation data of 8 meteorological stations representing eight different climate classes in iran were used for a 55 year period 1960 2014 for each of the monthly seasonal and annual time scales the lengths of record 55 50 45 40 35 and 30 years were extracted from the main period 1960 2014 which each of these lengths was lengths ending to 2014 first the correlation coefficient of the indices was obtained for all lengths of record then match and non match of the indices obtained from the longer lengths of record with the values obtained from shorter lengths of record were investigated for all three time scales finally the unique drought and flood years of stations were compared for the time scales the results revealed that better time stability was seen in the effective drought index edi and z score index zsi compared to other indices in the monthly time scale it means that the sensitivity of these two indices to different lengths of record was less percentage of normal precipitation index pnpi in two seasonal and annual scales also shows the lowest sensitivity was seen among the studied indices however deciles index di and the modified china z index mczi were two indices which had the highest sensitivity to different lengths of record among other indices it means that these two indices have more sensitivity to lengths of record studied and they should be used carefully keywords drought length of a record correlation coefficient match and non match sensitivity 1 introduction water related natural disasters pose major impediments to achieving human security and sustainable socio economic development wwap 2012 droughts are one of the most complicated and at the same time the most unknown water related natural disasters that humans grapple with hagman 1984 this phenomenon has the greatest effect on human activities compared to other natural hazards wilhite 1987 kogan 1997 salami 2004 the drought s effects are basically non structural their spatial extension is wide and the extent of their damage is much greater compared to other water related natural disasters these non structural effects of droughts have been a major obstacle to the development of timely reliable and accurate estimates of the severity of droughts so that setting up and preparing any drought preparedness plan in many countries have become difficult chopra 2006 nearly all regions of the world with various climates have suffered from drought however its effects and frequencies are more vivid in arid and semiarid regimes specifying the characteristics of droughts and wetness in these regions can be considered as one of the essential needs of planners for water resources management the vast country of iran is located in one of these arid and semi arid regions of the world which great changes in the rate of precipitation its high severity and distribution and temperature fluctuations are considered as its characteristics during recent years precipitation anomalies have been increased in various regions in iran due to the factors that are predominantly related to global climatic change the increase in precipitation anomalies has caused changes in the temporal spatial properties of iran s droughts mahmoudi et al 2019 daneshmand and mahmoudi 2017 the results of these changes have been extravagant damages imposed onto the various economic social and bioenvironmental sectors in this territory hence specifying a set of appropriate and accurate indices which can be used to quantify and evaluate the severity and the breadth of drought in the country has special importance several indices have been defined in various regions of the world to monitor the droughts which base of all of them is climatic and environmental data including palmer drought severity index pdsi palmer 1965 deciles index di gibbs and maher 1967 crop moisture index cmi palmer 1968 bhalme mooley drought index bmdi bhalme and mooley 1980 surface water supply index swsi shafer and dezman 1982 standardized precipitation index spi mckee et al 1993 effective drought index edi byun and wilhite 1999 and reclamination drought index rdi tsakiris et al 2007 during the several past decades the increase in the number of various indices of drought monitoring has led to an increase in the comparative studies of them as well the comparative study of several various indices provides the researchers with the possibility of comparing them thereby to become able to choose the best index for monitoring the study region s droughts to specify the accuracy relationship and integration of the relevant indices in respect to a special goal as well amongst the most important studies performed in this regard the researches by mahmoudi et al 2019 dogan et al 2012 morid et al 2006 and wu et al 2001 can be pointed out in line with selecting the best index for monitoring iran s droughts mahmoudi et al 2019 compared seven drought precipitation based indices in comparative research for various climates in iran and concluded that the effective drought index edi and standardized precipitation index spi have had better performances than the other indices these results were exactly the same as the findings attained by morid et al 2006 in the designing of the drought monitoring system in tehran province in iran wu et al 2001 as well concluded in a comparison of three indices namely standardized precipitation index spi china z index and z score index in various temporal scales for the arid and humid climates in china that all three indices have had identical results for all of the various temporal scales palmer s drought severity index pdsi was developed in 1965 by palmer the index has been used for 30 years as an appropriate tool for monitoring the droughts amongst the variables used in this index temperature precipitation runoff evaporation and transpiration as well as soil moisture can be pointed out as an optimal executive index for monitoring systems the index is faced with a lot of problems like the complexity of the calculations doubts in the accuracy of the proposed water balance model non clarity of the temporal span and unclearness of its physical and statistical nature due to its need for a lot of information as pointed out by kao and govindaraju 2010 however colorado state university researchers offered a new probability index called as standardized precipitation index spi for better and accurate monitoring under the conditions of drought and wetness periods mckee et al 1993 1995 the standardized precipitation index spi is calculable for different time intervals and it has high importance for providing early warning and helping to assess the drought severity this index is also an appropriate tool in analyzing the precipitation data and has been considered by many researchers and it is widely used for monitoring and zoning regional and local droughts around the world such as iran karimpour et al 2009 raziei et al 2009 negaresh et al 2010 shahabfar and eitzinger 2013 safari shad et al 2013 akbari et al 2015 the mediterranean paulo and pereira 2007 lana et al 2001 turkey keskin 2009 touchan et al 2005 komuscu 1999 the united states guttman 1999 hayes et al 1999 keyantash et al 2002 and other parts of the world ntale and gan 2003 pandey et al 2008 patel et al 2007 roudier and mahe 2010 considering the advantages of this index which some of them were mentioned above this index has several unique limitations and disadvantages which they should be considered when using it one of these limitations is the sensitivity of this index to the probability distributions used in it since this index analyzes precipitation for monitoring droughts through gamma distribution and this distribution might not be appropriate for all regions or stations investigated blain 2011a a few studies have been carried out so far on the selection of the best probability distribution for this index blain 2011b in brazil angelidis et al 2012 in portugal ntale and gan 2003 in east africa another disadvantage of the standardized precipitation index spi is this index sensitivity to the lengths of the record used which very limited number studies are seen in this regard mirabbasi et al 2013 one of the most important studies conducted in this regard is the study of wu et al 2005 in this research they showed that the percentage related to non matches when the time scale of the data is longer the differences would be more significant for some stations another result of this research is the match of spi values for unique drought and flood years in short and long term scales besides spi values obtained from longer lengths of record are correlated with spi values obtained from shorter lengths of record for all time scales in the studied periods now it has been observed in a review of the subjective literature s resources of the present study that there are many strong and weak points of the various drought indices especially standardized precipitation index spi taken into account by many of the researches in such fields as hydrology geography meteorology climatology and agriculture but in between one of the weak points to which less attention has been paid is the sensitivity of the various drought indices to the length of the various temporal periods although wu et al 2005 have considered it for standard precipitation index spi there is a need for being that much sensitive to the other indices as well thus the present study sought to investigate the sensitivity of spi in addition to the sensitivities of other drought indices like zsi pn di mczi czi and edi to different lengths of record 2 study area and data given the specific geographical position and topography characteristics of each region of iran different climates govern it so that based on the classification performed by masoodian 2012 iran can be divided into eight climatic regions fig 1 in this research one station representing that climate region was selected fig 1 in this research monthly seasonal and annual precipitation data of the studied stations were used for a 55 year period 1960 2014 the names geographical coordinates mean annual temperatures total means of the annual precipitation establishment years and types of the used station have been presented in table 1 the lengths of record 55 50 45 40 35 and 30 years were extracted from the main period 1960 2014 for each of the monthly seasonal and annual time scales it should be stated that each of these lengths was the lengths ending in 2014 the reason that the minimum length of the studied lengths was selected to be 30 years was that it is the most appropriate length of the record to calculate the spi at best state of continuous lengths with minimum 30 years of data mckee et al 1993 3 methodology the model and method used in this research were derived from the research carried out by wu et al 2005 they examined the impact lengths of record of data on calculation of standardized precipitation index spi in this research drought indices were calculated for the mentioned time scales for all selected lengths of record dip software was used to calculate these indices this software was offered by morid et al in 2007 drought monitoring the indices used in the research are introduced in brief 3 1 standardized precipitation index spi this index was provided by mckee et al 1993 and widely used throughout the world this index is based only on the precipitation variable and it is an appropriate tool to realize the drought phenomena in different regions the first step in calculating the spi index is determining the probability distribution function based on the studies conducted by mckee et al 1995 guttman 1999 ntale and gan 2003 and wu et al 2007 the most appropriate probability distribution function for fit to precipitation data is gamma family functions which are defined as follows 1 g x 1 b a Œ≥ a x a 1 e x b in the equation above Œ± 0 is shape parameter Œ≤ 0 is scale parameter x is precipitation amount and Œ≥ Œ± is gamma function the parameters of gamma probability density function are estimated using the maximum likelihood method for each station and for each time scale so 2 Œ± 1 4 a 1 1 4 a 3 b x Œ± a ln x ln x n where n is the number of precipitation observations then calculated parameters are used to find the precipitation cumulative probability for the considered time scale for each of the stations assuming t x Œ≤ the cumulative probability is transformed into the incomplete gamma function 3 g x 0 x y x d x 1 b Œ± Œ≥ Œ± 0 x x Œ± 1 e x b d x when the gamma function is not defined for x 0 and precipitation distribution is zero the cumulative probability is calculated as follows 4 h x q 1 q g x in the equation above the precipitation probability is zero while m is the number of zeros in precipitation time series q is estimated in m n and h x is transformed into the normal variable z with the following approximation 5 z s p i t c 0 c 1 c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 h x 0 5 6 z s p i t c 0 c 1 c 2 t 2 1 d 1 t d 2 t 2 d 3 t 3 0 5 h x 1 0 where 7 t ln 1 h x 2 0 h x 0 5 8 t ln 1 1 0 h x 2 0 5 h x 1 0 and d 1 d 2 d 3 c 0 c 1 c 2 are constant coefficients as follows d 1 1 432788 c 0 2 515517 d 2 0 189269 c 1 0 802853 d 3 0 001308 c 2 0 010328 when the equation of probability of current precipitation data was obtained the spot probability of each of the observed precipitation data is calculated and used to calculate the standard normal probability density function which has the mean of zero and one unit standard deviation these values indicate the spi value for each precipitation data as spi values are fitted with same normal distribution it can be expected that approximately 68 of the times to be placed in values with one unit of standard deviation 95 of the times to be placed with two deviations and 99 of the times to be placed with three standard deviations of mean spi values are classified in table 2 3 2 percent of normal precipitation index pnpi percent of normal precipitation index pnpi is one of the simplest indices for detecting the droughts this index was first presented by wileke et al 1994 the basic concept of this index is the ratio of actual precipitation to its normal value in a specified time period expressed as a percentage and can be calculated for different time scales weekly monthly seasonal and annual the actual value of this index for the studied length of record and station is calculated using the following formula 9 p n p i p i p 100 where pnpi pi and p are the percent of normal precipitation index precipitation of the considered year and mean long term precipitation respectively the point which should not be forgotten in using this index is that this index can be used when the mean precipitation is matched with precipitation median or the precipitation distribution is normal if this condition does not govern precipitation time series its results might result in false interpretations however using this index is simple and has high flexibility for other calculations moreover the results of this index show the deviation from mean well and easily it is considered one advantage of pnpi index table 2 shows the drought classification based on this index 3 3 deciles index di this index was for the first time used in 1967 by gibbs and maher for the investigation of the historical droughts in australia in this index the long term monthly seasonal or annual precipitation values of the studied stations are arranged in ascending or descending order so that their cumulative frequency distribution to be formed then they are divided into groups of normal distribution each of these groups is called a decile the first decile is the amount of precipitation which is less than 10 of the precipitations the second decile shows the amount of precipitation which is less than 20 of the precipitation the fifth decile or median is the amount of precipitation which does not exceed 50 of the precipitations table 2 shows the classification of this index the point which should be remembered in using this index is that if the precipitation data do not follow the normal distribution the data should be normalized using one of the normalization methods one of the methods used in normalizing the data is box cox transformation in this research these transformations were used for stations where their distribution did not follow the normal distribution 3 4 z score index zsi index is calculated very simple it has been used in many drought studies such as tsakiris and vangelis 2004 patel et al 2007 morid et al 2006 the zsi index does not require transforming the fit data for distributions such as gamma or pearson type iii as used in spi and czi this index is obtained from the following equation 10 zsi x ij x œÉ i in the equation above x ij i s the precipitation of month j for length i and œÉi and x are the standard deviation of precipitation and mean in each time scale respectively table 2 shows the classification of this index 3 5 the china z index czi and the modified china z index mczi the czi index was widely used in 1995 by the national climate center of china the czi index is calculated based on the third wilson hilferty third root transformation wilson and hilferty 1931 assuming that the data follow the pearson type iii distribution the czi index is calculated as follows 11 œÉ 1 n i 1 n x i x 2 12 c s i 1 n x i x 3 n œÉ 3 13 czi 6 c s c s 2 z s c o r e 1 1 3 6 c s c s 6 in the equations above œÉ is the standard deviation n is the number of observations and cs is the coefficient of skewness xi and x are calculated exactly as xi and x are calculated in z score index the modified czi index mczi is calculated as czi is calculated while the median is used instead of the mean table 2 shows the severity of drought related to this index 3 6 effective drought index edi this index was developed by byun and wilhite in 1999 to detect and determine the start time and end time of droughts effective drought index edi in its original form is calculated based on daily data akhtari et al 2009 kalamaras et al 2010 kim and byun 2009 kim et al 2009 morid et al 2006 roudier and mahe 2010 unlike other drought indices however its principles can be generalized to monthly precipitation data as morid et al 2007 developed this index for monthly scale thus the monthly time scale developed by morid et al 2007 was used in the current research to calculate edi there are many steps which described later in brief the main concept in this index is effective precipitation ep effective precipitation is the sum of daily precipitation values with a time dependent reducing function which is calculated using the following equation 14 ep n 1 i m 1 n p m n in which i is the duration of summation and pm is precipitation up to m 1 days before in the next step of calculating this index the deviation of the ep of mep is calculated this deviation is calculated by calculating the dep which its equation is presented below in fact mep is the mean of ep for each calendar day which it is climatic characteristics in one place and time dep ep mep calculation of the precipitation needed for a return to normal daily conditions prn is another step of the calculation obtained using eq 12 16 prn dep n 1 j 1 n finally the edi which is the standardized form of prn is calculated according to the following equation 17 edi prn st prn in the equation above st prn represents the standard deviation of prn table 2 shows the classification of different degrees of drought in all the indices studied in this research after calculating the indices the pearson correlation coefficient and spearman rank correlation coefficient kendall and stuart 1977 measuring the power of the linear relationship between the pair of values of the indexes extracted from different lengths of record were calculated for all stations in time scales ranks of values of indices in a specified time period are an important index for the severity of drought and wetness events the rank of each single index value is specified based on its row in the list of ranks then pearson and spearman correlation coefficients are calculated between the pair of values of indices which ranks are used for it as the base for measuring the strength of the relationship between the two index values it should be noted that the numerical correlation coefficients are numbers between zero and one as the correlation value is close to number one the correlation between the two variables would be higher and as it is closer to zero the correlation would be lower the correlation equals to one means linear and 100 relationship correlation can be positive or negative in the second step match and non match between the occurrence severities obtained from the long and short lengths for each station are investigated in three 5time scales in the third step the values of indices obtained from different lengths of record in the unique years of the severe drought and flood in the recorded data were compared 4 results and discussion seven drought indices of di spi pnpi zsi mczi czi and edi were used in this research first the lengths of record of 55 50 45 40 35 and 30 years were extracted at monthly seasonal and annual time scales then the sensitivity of lengths of record was investigated in several steps the correlation coefficient of these indices and then the match and non match of the indices obtained from the longer lengths of record with values obtained from shorter lengths were determined and studied for each of three time scales finally unique drought and flood years of stations were compared for the mentioned time scales 4 1 comparing the correlation coefficients pearson correlation coefficient and spearman correlation coefficient rank were obtained for all studied stations for all lengths in monthly seasonal and annual time scales which 2 cases from each time scale were included in the paper as the results of the two correlation coefficients were very close and similar the results of the spearman correlation coefficient were included in the paper the results of the correlation coefficient obtained at monthly time scales suggested that edi index had the highest correlation coefficient among the indices as the length of record increases in this index the correlation coefficient between lengths of the record increases table 3 b in this scale the mczi index and then di index have the lowest correlation coefficient among the indices so that a weak correlation was found between them in some lengths of record table 3a in other indices the correlation coefficient between the lengths of record was obtained very strong and high for example the relationship between the length of records in the spi zsi and pnpi indices was above 0 90 it should be noted that the results obtained in the spi index are completely similar to the results of wu et al 2001 and confirm the results of their work in the seasonal time scale the edi index was removed since it can be calculated only on a daily and monthly scale the results of the correlation coefficient between the indices were similar to the monthly scale but the results of the correlation coefficient in the di index were reduced significantly so that weak relationship was observed between them in some of the lengths of record table 3c in this scale the highest correlation coefficient among the indices was related to the pnpi index which correlation coefficient between the lengths of the records was higher than 0 9 in all of the studied stations table 3d the correlation coefficient was obtained in annual scale at all stations the correlation coefficient was obtained very strong in all indices except for di index in this index the relationship between lengths of record was reduced and in some lengths the relationship was not found between the lengths of record table 3e in other indices such as zsi index the correlation coefficient between all lengths of record was obtained higher than 0 9 table 3f the mczi index was not calculated in this scale 4 2 comparison of match and non match in the studied indices investigating the match and non match of different classes of drought and wetness from the long term 1960 2014 and short term 1985 2014 was derived from the main length this match and non match are determined as follows if one class of classes of occurrence of droughts derived from long term lengths of record matches with short term lengths of record it is called match otherwise it is called non match hence percentage of non match is obtained by dividing the number of non matches into the sum of the number of matches and non matches moreover to show level of non match the number of frequencies in which difference of match was more than one class was also counted for example this case occurs when the value of the index obtained from the long term length of record is classified within the close to normal class and the value of corresponding index extracted from the short term length of record was classified into severe drought or very severe drought class in first the percentage of non match was generally obtained for all indices fig 2 findings revealed that the lowest non match in all stations except for abadan and babolsar stations was related to edi index so that this value in isfahan and abadan stations was 3 6 and 3 9 percent less than that in other indices additionally the highest non match in all stations except isfahan station was related to the mczi index in the range between 34 2 bandar abbas station and 47 2 abadan station following this index di index had the highest non match in the monthly time scale non match in the mczi and di indexes had difference more than one class the highest percentage of non match occurred in di index 21 9 at zahedan station and it occurred in the mczi index 40 at abadan station which this difference between the long term and the short term was one class table 4 the important point on the edi index is that the percentage of non match in this index in all stations except gorgan station was not more than one class the highest percentage of non match between short term and long term length in this index was 10 3 in the abadan station in the seasonal time scale as with the second stage edi index analysis section was removed in this scale the indices of zsi spi mczi and czi were calculated as moving mean the results obtained in this scale showed that the two indices of mczi and di had the highest non match between the two long and short term lengths so that the non match for the mczi index was more than 50 in sanandaj and abadan stations moreover this value has been repeated for two stations of zahedan and gorgan in the di index the lowest non match among the indices was in two indices of pnpi and spi at different stations at the stations of zahedan abadan and gorgan spi index had the lowest non match and at stations of babolsar isfahan khorramabad and sanandaj pnpi index had the lowest non match the important point observed in this scale was that in all indices the non match was more than 23 at the gorgan station in all indices fig 3 one of its reasons is the precipitation regime of this station which precipitation fluctuations of the station is not uniform the geographical position of this city is so that it is placed in the wet and dry region border in the seasonal time scale the difference of classes between the two mczi and di indices between long term and short term lengths was seen more than one class for example at abadan station non match in both indices of the three classes was different while this difference was up to two classes for other indices this difference of classes in spi index at all stations was one class except for sanandaj gorgan and zahedan stations as the distance of classes increases from one class to another class the distance between classes is reduced table 5 fig 4 shows total percentage of non match at the annual time scale at the studied stations in this scale the mczi index was removed from the sum of indices the highest percentage of non match among the indices belonged to di index at khoramabad station the percentage of non match in this index reached to more than 50 at stations of abadan bandar abbas and khoramabad the percentage of non match for the pnpi index was obtained zero at gorgan station as with other two scales the percentage of non match was increased for all studied indices which its value for all indices was more than 30 table 6 shows the difference of drought and wetness classes at the annual scale as seen the difference of classes in the pnpi index was not observed for many of stations such as abadan babolsar bandar abbas and khoramabad the highest difference of classes as with seasonal time scales is in the di index after the pnpi index the zsi index has the lowest difference in its classes no difference was seen in classes of this index even in abadan stations other indices like the spi index at all stations except for sanandaj station have one difference class the non match in the czi index is evident both in one and two difference classes in the studied stations 4 3 comparing values of different indices in unique years in order to examine the match and non match of the studied indices one very wet year and one very dry year were selected among the studied years in order to examine the length of record match and find the strength of the droughts and witnesses for this purpose the year 2005 was determined as the wet year and the year 2007 was selected as the drought year these years were recognized before by nooshirvani 2014 as shown in fig 5 the edi index has the best match among all lengths this index could easily identify the drought year of 2007 and the severe wet year of 2005 the indices of spi zsi and czi had relatively similar performance these indices as with edi index could not show drought and wetness of the considered years the performance mczi index is very different with that of other indices so that none of the lengths of record match with each other 5 conclusion nowadays preparing the long term data is one of the main concerns of researchers in many countries many studies have reported that at least 30 year data are required for a scientific research unfortunately it is impossible to provide 30 year data in many countries even developed countries even the recording the precipitation data in many of the regions varies from one station to another station there are also regions which cannot be ignored due to data less than 30 years this research tried to evaluate the sensitivity of precipitation lengths of record in different indices to introduce an index so that the lengths of record to have the lowest impact on its values and can cover this weakness of data shortage weakness it should be noted that this research has been conducted regardless of other shortcomings of the indices it means that only one aspect has been considered in the paper at a monthly scale the edi index showed better time stability compared to other indices in this index the values derived from the lengths of record did not differ significantly as the lengths of record increases the accuracy of index increases and the effect on the classes is reduced this index is very appropriate at these time scale for places and regions where they have no longer lengths of record the pnpi index at annual and seasonal scale at most of the stations had the lowest non match among the studied indices even at several stations no non match was seen among lengths of record in this index the zsi index is one of the indices which non match in this index is less compared to other indices this index has the lowest non match after the edi index at monthly time scale and after the pnpi index in the seasonal time scale this index at the annual scale both after the pnpi index and along with the czi index is among the indices showed the better match the czi index has shown better match compared to spi index the spi index showed appropriate performance but the results are not reliable non match at studied time scales was not equal for different stations at stations of gorgan khorramabad and sanandaj non match increases are from monthly time scale to seasonal time scale and from seasonal time scale to annual time scale however non match at stations such as zahedan babolsar isfahan reduces from monthly time scale to seasonal time scale and increases from seasonal time scale to annual time scale one of the most important non match at different stations is the probability distribution gamma used in spi index which is equal for all studied stations to solve this problem probability distribution should be obtained for each station and examine the length of record the highest non match among the studied indices was seen in two mczi and di indices very low time stability was seen in these indices at studied time scale these indices were severely sensitive to lengths of record and they should be used with caution in the studies declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 124181 these data include google maps of the most important areas described in this article appendix a supplementary data the following are the supplementary data to this article the following kml file contain the google maps of the most important areas described in this article map 
6069,community based monitoring of water and environmental resources is believed to have the potential to help produce more or better water and environmental data increase public participation in environmental monitoring respond to issues of common community concern and enhance informed democratic and transparent environmental decision making despite these perceived outcomes initial and long term engagement of different stakeholders with community based monitoring activities remains a challenge successful establishment of these initiatives has proven to be complex and there is little evidence that community based monitoring projects have an impact on environmental or water resources management processes or a legacy beyond their funding period whereas much attention is being paid to promoting community based monitoring as a tool for producing more or better water or environment related data there is little conceptual understanding of how to critically analyze and understand the features and functioning of these initiatives therefore we do not know whether or to what extent these initiatives deliver on their perceived potentials thus it is essential to learn from past experiences and critically document analyze and understand factors that might influence the establishment functioning and outcomes of community based monitoring initiatives based on the review of a large body of literature in the fields of community based monitoring citizen science and affiliated fields of research combined with the empirical evidence from a number of major eu funded community based monitoring projects this paper introduces a framework that can be utilized to analyze the dynamics underlying the establishment and functioning of community based monitoring initiatives the distinction between five different dimensions consisting of 22 internal and context related factors is a unique feature of this framework that broadens its applicability and makes it suitable for context analysis process evaluation and impact assessment of the initiatives the introduced framework is therefore called the cpi framework in short keywords citizen science community based monitoring context analysis process evaluation impact assessment 1 introduction population growth environmental degradation depletion of natural resources and climate change are among the most dominant challenges that increasingly affect our ecosystem placing fundamental threats on human well being and quality of life the most recent world economic forum s yearly reports on the global landscape of risks identifies environmental challenges such as extreme weather events natural disasters failure of climate change mitigation and adaptation and man made environmental disasters among the top ten risks in terms of likelihood of occurrence world economic forum 2019 world economic forum 2018 it is evident that addressing these global challenges and moving towards a sustainable future requires among other things improved policies and informed environmental decision making on the one hand one pre requisite for better informed environmental decision making is the availability of continuous and widespread observations of the environment for example of the water cycle and its components which can inform water and environment related policies this has been argued by the oecd s environmental outlook 2050 namely better information supports better policies so our knowledge base needs to be improved oecd 2012 on the other hand there is an ever increasing recognition that environmental science and policy should be more participatory transparent and democratic various international conventions and policy guidelines such as the aarhus convention hyogo framework for action and sustainable development goals sdgs have highlighted the importance of engaging citizen in environmental science and policy unece 1998 unisdr 2005 united nations 2015 this implies that environmental science should be opened up to the public and needs to incorporate locally relevant knowledge moreover water and environment related decisions should consider the voice of citizens whose well being and livelihood are being affected by those decisions citizen science is an emerging and fast growing field of participatory research that has a high perceived potential for enhancing informed democratic inclusive and transparent environment related decision making the fast growth and expansion of citizen science also due to the rapid diffusion of information communication technologies icts has made it possible for a large proportion of the general public to better understand and engage with water or environment related issues that affect their everyday lives an example of such engagement is the so called community based monitoring of water and environmental resources hereafter cbm cbm is a process where concerned citizens government agencies industry academia community groups and local institutions collaborate to monitor track and respond to issues of common community concern whitelaw et al 2003 410 as emphasized by conrad and hilchey 2011 cbm refers to both community based environmental monitoring and community based environmental management aspects of citizen science this definition is very close to what is also referred to as citizen observatories of the environment the concept of citizen observatory is mostly used in the european context and the european commission defines it as community based environmental monitoring and information systems using innovative and novel earth observation applications such as portable devices e g smart phones and collective intelligence to support both community and policy priorities european commission 2014 rubio iglesias 2015 lanfranchi et al 2014 cbm has been praised for its potential to contribute to better environmental decision making by empowering citizens and allowing them to take a more active role in environmental monitoring co operative planning and environmental stewardship european commission 2015 despite the huge potential portrayed for cbm initial and long term engagement of different stakeholders with cbm activities is still a challenge wehn and almomani 2019 in press successful establishment of these initiatives has proven to be complex and there is little evidence that they have had impact on water management or environmental management processes or in case of project based initiatives legacy beyond their funding period for example a recent eu wide inventory of citizen science initiatives shows that none of the citizen observatories for water and environmental management that were funded within the seventh framework programme of the european union i e citi sense citclops cobweb omniscientis wesenseit are currently active bio innovation service 2018 these projects started their activities in 2012 ran for two to four years received a combined funding of more than 26 million euro and established several cbm initiatives on both water related topics such as coast and ocean monitoring flood risk management or natural hazard management and more broad environmental monitoring and management topics such as biological monitoring environmental quality of life in urban areas and odour monitoring too much attention is paid to promoting cbm as a tool for producing more or better environmental data but the actual conceptual understanding required to critically analyze and understand the features and functioning of these initiatives is lagging behind therefore we do not know whether or to what extent they have delivered on their perceived potential this is partly due to the fact that the concept of community in a cbm initiative is highly context dependent dynamic and hence difficult to analyze in general terms a community is a social unit consisting of a group of individuals who have something in common in the context of a cbm this common denominator is usually interest in concerns about or stake in an environmental issue however the community in the context of cbm initiatives does not exist as a clearly defined and static entity rather it is shaped and reshaped over time by factors such as the initiation of the cbm the composition and the group of actors involved their goals and interests the power dynamics among the actors and enabling technologies it is therefore essential to learn from past experiences and critically document analyze and understand internal and context related factors that might influence the establishment functioning and outcomes of a cbm in order to do so there is a need for an analytical tool that allows unpacking the complexities of cbm initiatives and facilitates our understanding of the factors that can influence their establishment functioning and outcomes and how the epistemic community in a particular cbm initiative has evolved in practice such a framework provides an interpretation of the epistemic community for which it is used to evaluate and therefore helps construct or define the meaning of community in a cbm initiative adopting a mixed deductive and inductive research approach and building on a large body of theoretical and empirical literature in the fields of citizen science e participation science and technology studies sts and public participation in decision making processes this paper identifies five generic dimensions and several aspects that can influence the establishment and functioning of a cbm each dimension raises a core question about the cbm initiative and the context in which it is embedded and with which it interacts these dimensions and aspects are then synthesized into a conceptual framework which can serve to unpack the factors that influence the establishment and functioning of a cbm this paper is structured as follows the methodology that was followed for conducting the literature review and arriving at the proposed framework is detailed in section 2 section 3 introduces the identified dimensions aspects and core questions about the cbm initiative the synthesis of the conceptual framework is also presented in section 3 we conclude the paper in section 4 by elaborating on different applications of the proposed framework 2 methodology in order to identify the different dimensions and aspects that affect the establishment and functioning of cbms we critically reviewed a large body of literature that has previously elicited relevant factors this extensive literature review was carried out during a period of three years 2016 2018 and was conducted as an integrative review bandara et al 2015 which means it was informed by both theoretical and empirical evidence from the literature the literature included in this research was identified using three main methods i the authors expert knowledge about existing theoretical and empirical research in the field ii searching scientific databases e g web of science sciencedirect scopus and google scholar and iii backward and forward snowballing van wee and banister 2016 we started the literature review with a number of publications that were known to the authors and which identified or mentioned influential factors on establishment functioning or results of cbms next we searched the scientific databases for additional relevant literature in order to define the scope of our literature search we had to first identify different terminologies that are used to refer to cbm as stated by newman et al 2011 the terminologies that refer to various citizen based approaches in the field of citizen science still remains confusing and there are a number of overlapping terms which refer to the concept of cbm previous research including whitelaw et al 2003 newman et al 2011 conrad and hilchey 2011 including kullenberg and kasperowski 2016 has already identified and referred to these overlapping terminologies for example in a meta analysis of citizen science literature kullenberg and kasperowski 2016 identified overlapping concepts such as community based monitoring volunteer monitoring and participatory monitoring in another study newman et al 2011 found an overlap between the terms community based monitoring citizen based monitoring collaborative monitoring and volunteer monitoring in addition as discussed in the introduction there is a close link between cbm and the concept of citizen observatories this resulted in selecting the following set of terms for our literature search community based environmental monitoring participatory environmental monitoring collaborative environmental monitoring volunteer environmental monitoring citizen based environmental monitoring citizen observatory and citizen observatories the idea of conducting a systematic search was tested we searched the aforementioned databases for publications that referred to any of the identified terminologies in their title abstract or keywords the time span of the search was not limited and we included all documents that have ever been published on these repositories until 2018 this resulted in a very large number of publications e g more than 8000 records on google scholar reviewing this large number of documents was not manageable therefore we considered filtering the records by adding keywords that we were interested to find in these records e g aspect issue dimension factor output outcome impact etc this did not help reduce to the number of retrieved records to a great extent mainly due to the fact that these terms are usual suspects in a great majority of scientific publications therefore we decided to use backward and forward snowballing van wee and banister 2016 as the main method for expanding our search results i e where relevant we found citations in or to the reviewed literature in the case of backward snowballing the process of finding additional literature included reviewing the reference list of already identified literature and scanning the abstract and conclusion sections of potentially relevant literature based on this initial assessment newly identified literature was either excluded or marked for tentative inclusion in some cases we wanted to deepen our understanding about a specific concept that was identified in the reviewed references hence we used forward snowballing i e we searched scientific databases to find the literature which cited those references similarly we scanned the abstract and conclusions of the identified publications and if relevant marked those for potential inclusion the final decision for inclusion or exclusion of the references which were identified using backward and forward snowballing was made after the full review of the references besides their theoretical insights the identified publications in our literature search contained empirical insights from a wide range of past and ongoing citizen science and cbms in addition we wanted to further complement our literature review with empirical evidence from a number of cbms there are an overwhelming number of cbm projects that we could choose from for example a recent inventory of citizen science and cbm projects by the european commission includes 503 that have relevance for environmental policy bio innovation service 2018 this list consists of a diverse set of projects with different thematic foci including discontinued as well as ongoing and long established projects we decided to examine the five citizen observatories of water and environment that had been funded under the 7th framework programme for research and technological development in europe fp7 namely wesenseit citi sense citclops cobweb and omniscientis the main reason for this choice was the fact that these projects are considered pioneer or legacy cbm projects in europe easme 2016 this is due to the fact that these projects were the first attempt of the european commission to demonstrate the concept of citizen observatories of the environment in europe these projects therefore produced insights about the setting up of several cbms with diverse thematic foci in 16 countries in europe and beyond including the us and israel the experiences from these projects are now being applied in developing and scaling up several cbms under the horizon2020 funding program of the european commission 1 1 cbms that are being established or have been established include initiatives of projects such as ground truth 2 0 grow landsense scent d noses and monocle we also considered that these projects are relatively well documented and a lot of information about these projects can be retrieved via publically accessible project reports this yielded 67 project reports to the list of our reviewed literature a thorough processing of these documents revealed that a great majority of the reports only focus on scientific or technical aspects of the projects and only 14 reports had references to aspects that influence the establishment and functioning of cbms this added a shortlist of 14 reports to the literature included in our analysis our analytical method consisted of a mixed inductive and deductive approach starting inductively with no preconceived themes or categories we extracted different dimensions and aspects that had been identified in the reviewed literature and project reports as relevant factors for the establishment and functioning of citizen science or cbm initiatives during the review process we found a close link between the reviewed literature and major theories on public participation in decision making as well as literature from the field of science and technology studies sts therefore we deductively reviewed a number of relevant publications from those fields to further complement our understanding of the identified dimensions and aspects next we clustered and synthesized the results of the literature review the process of clustering and synthesizing the findings included three overlapping and iterative steps we started with coding the extracted aspects from the literature thematically the emerging and recurrent themes were then re categorized and merged as we progressed with the literature review this allowed us to identify the prominent themes these were then clustered and synthesized into the five dimensions that were generic across all cbms each dimension consists of several aspects and raises a core question about the intrinsic nature of an initiative as well as the technological institutional and political context in which it is embedded and with which it interacts table 1 summarizes the list of reviewed literature and indicates the relevance of the literature for the discussions in each dimension 3 synthesis of the literature and resulting dimensions of cbm initiatives the following sections present the five generic dimensions of cbms that were identified in this research namely goals and objectives technology participation power dynamics and results the discussion in each section includes referencing the reviewed literature and clarifies how each dimension was informed by the literature review based on the discussions of each dimension a core question is raised that aims to trigger critical thinking about that dimension subsequently the identified dimensions and aspects are synthesized into a conceptual framework which can be utilized to examine the contextual setting dynamic processes and outcomes of cbms 3 1 goals and objectives dimension of cbm initiatives a large part of the reviewed literature either referred to examples of goals and objectives of cbm initiatives or highlighted the importance of studying these goals and objectives e g ciravegna et al 2013 wehn et al 2015b roy et al 2012 world bank group 2016 gharesifard and wehn 2016a gharesifard and wehn 2016b kimura and kinchy 2016 tredick et al 2017 conrad and daoust 2008 kimura and kinchy 2016 argue that without attention to the objectives of a citizen science initiative it is not possible to study the quality and degree of participation in that initiative the world bank group 2016 goes one step further and emphasizes that without understanding the goals and objectives of digital citizen engagement stated or otherwise it is not possible to evaluate other dimensions of such initiatives cbm initiatives are typically formed around water or environment related issues and their overarching objectives are often set by the project initiators and or funders kimura and kinchy 2016 much less frequently objectives of cbm initiatives are co defined in consultation with all or a group of concerned stakeholders collecting environmental data raising environmental awareness increasing public participation in monitoring and management of water or environment related issues e g flood risk management water quality monitoring or environmental quality of public spaces creating new forms of communication between citizens scientists and decision makers and developing enabling technologies for the aforementioned purposes are examples of overarching objectives of the eu fp7 cbm projects that we reviewed in this study gilardoni et al 2013 cobweb consortium 2016 cobweb consortium 2015a arpaci et al 2016a omniscientis consortium 2014 no matter what the objectives of an initiative are or how they are defined it is highly important to realize the different stakeholders may have divergent interests or values silvertown 2009 wehn and almomani 2019 in press and the objectives of a cbm initiative may incline more towards preferences and wishes of some stakeholders than those of others moreover the overarching goals of a cbm initiative may not be bias free and might have been influenced by vested interests of funders researchers and technology providers this may result in some stakeholders benefiting more from the initiative than others an issue that is among the lessons learned from the citi sense projects arpaci et al 2016a previous research efforts have mainly focused on overarching objectives of the cbm initiatives and do not investigate how actor specific goals might differ from one actor group to another gharesifard and wehn 2016b there is also little attention to the synergies and contradictions between these goals and the overarching objectives of a cbm initiative a thorough study of the cbm objectives and goals of the actors involved may help answer a number of questions that are often mentioned with regards to paradoxes of participatory processes cleaver 1999 for example who gains most from the cbm activities and whose interest is least reflected the initial objectives of a cbm initiative may be modified or evolve over time cooper et al 2007 irwin 2015 this can happen because of different reasons for example financial or technological constraints power dynamics between involved stakeholders or adjustment of project ambitions the latter happened to both the citi sense and the cobweb projects which reportedly changed their objectives due to their realization of challenges with achieving their initial objectives arpaci et al 2016a cobweb consortium 2017 it is therefore also important to monitor any changes in the objectives and to understand why such changes have happened monitoring the objectives and the extent of their achievement is a benchmark for assessing intended outcomes and impacts of a cbm thus the first core question that we pose is what are the overarching objectives and actor specific goals of the cbm initiative and to what extent does the design of the initiative help achieve those goals objectives 3 2 technology dimension of cbm initiatives recent technological developments and advancements in icts have transformed and accelerated cbm initiatives to a great extent and have created new possibilities for stakeholder participation in science and policy it is therefore important to study how to engage different stakeholders in a cbm initiative macintosh 2004 wehn et al 2015b ciravegna et al 2013 world bank group 2016 gharesifard and wehn 2016b gharesifard and wehn 2016a the technological choices for a cbm initiative can be broadly divided into two main categories those technologies that existed and were being used before the establishment of the initiative and those that are newly developed or introduced to create the desired functionalities for a cbm initiative newman et al 2012 refer to these as make versus buy options each of these categories can be further broken down based on the functionality that is envisioned for them in a cbm initiative e g data collection visualization or communication adopting both existing and newly introduced technologies comes with a number of social political economic and even cultural changes that needs to be carefully considered before selecting different technological options this can be done by asking who is being included or excluded intentionally or unintentionally as result of specific technological choices the extent to which these choices create and or maintain specific social conditions that favor some and marginalize others and the degree to which they are more compatible with internal or external social and political structures and relationships than others therefore while establishing a cbm initiative there is a need for gaining an understanding of existing infrastructure and availability of different forms of access to a wide range of possible technologies by different stakeholder groups newman et al 2012 gouveia and fonseca 2008 this closely relates to discussions on the digital divide and forms of access to technology material motivational usage and skills e g van dijk 2006 and helps identify included excluded groups resulting from choices of technology moreover as many sts scholars have emphasized the perception that technology changes solely as a result of scientific advancements or on its own accord is a passive way of conceiving technology that focuses on how to adapt to technological changes rather than how they shape or are shaped by society the economy or politics mackenzie and wajcman 1999 winner 1986 mansell and wehn 1998 bijker et al 2012 for example a web platform of a cbm initiative that focuses on the issue of water or air quality is not only shaped by technological components that are a prerequisite for its creation and functioning but also for example by vested interests or economic constrains of its developers or the end users in the case of the five eu fp7 projects that were reviewed for this study most of the projects started their cbm activities with a technology driven model meaning they started developing tools and technologies that seemed suitable for achieving their objectives without gaining a thorough understanding of the social economic and political system that they were operating in for example cobweb mentions in its final report that they entered a process of rapid prototyping software development based on their identified requirements and only when they reached a certain level of technology readiness started to engage citizens cobweb consortium 2017 the interpretation of the results of this approach is different among different projects some call it a great success e g cobweb consortium 2017 omniscientis consortium 2014 and some identify it as a source of major difficulties in developing the cbm initiatives e g arpaci et al 2015 arpaci et al 2016b wesenseit consortium 2016 for example arpaci et al 2016b mentioned that technological developments became one of the key motives of the citi sense project and this caused major difficulties with engaging and empowering citizens because it shifted the project s attention and resources away from engagement and empowerment activities this dimension therefore considers how enabling technologies of a cbm initiative have been shaped and how these relate to existing infrastructure as well as social and technological capabilities by asking how effective and appropriate are the choices and delivery of the selected technologies 3 3 participation dimension of cbm initiatives enhancing public participation in environmental monitoring planning or management is a core concept of cbm initiatives and the first step to understanding the state of change in such participation processes is to deepen our understanding of the existing participation dynamics related to the water or environmental issue in focus since the level of engagement and commitment of participants differs across different cbm initiatives at different stages of its development and across different actors it is important to first clarify what participation in a cbm initiative implies participation in a cbm initiative is closely related to the higher purpose that the initiative serves and the type of activities that are being conducted as part of it there have been a number of attempts to classify citizen science initiatives and the extent of participation in these initiatives for example bonney et al 2009a classified citizen science projects based on the degree of participants involvement in scientific investigations steps into contributory collaborative and co created projects shirk et al 2012 expanded these categories to five models of public participation in scientific research that included contractual contributory collaborative co created and collegial haklay 2015 distinguished between six levels of participation based on the extent of engagement and commitment of participants namely passive sensing volunteer computing volunteer thinking environmental and ecological observations participatory sensing and civic community science another example is a meta analysis of citizen science literature in which kullenberg and kasperowski 2016 identified three types of initiatives according to their higher purpose namely citizen science as a method public engagement with science and policy or civic mobilization the purpose of highlighting these typologies is not to prescribe or recommend an existing typology rather it is to emphasis the importance of considering different typologies of participation during the evaluation of cbm initiatives and clarifying what participation in an initiative actually entails previous studies have identified geographic scope as an aspect that is often linked to the issue in focus of the cbm initiative and shows its breadth of focus haklay 2015 cooper et al 2007 macintosh 2004 roy et al 2012 wehn et al 2015b moreover the geographic scope of a cbm initiative determines the spectrum of currently involved and affected stakeholders and helps identify the potential pool of participants in the initiative moreover the geographic scope of a cbm may change over time for example as a result of its growth or its change of focus participant groups are the actors or stakeholders who are involved in a cbm initiative wehn et al 2015b ciravegna et al 2013 macintosh 2004 conrad and daoust 2008 depending on the type and objectives of an initiative these are normally individuals groups or organizations who had a role in the design and setting up of the initiative are actively involved in the initiative via data collection sharing analysis aggregation and visualization and or use its outputs for improving policy or decision making processes it is also equally important to understand which groups of stakeholders are not represented in a cbm initiative and to critically reflect on consequences of their absence although contributing to public policy and decision making processes is far from easy irwin 1995 and may not be among the objectives of a cbm initiative studying the stakeholders already involved in decision making processes offers the possibility to know who might be interested in the data and knowledge generated via cbm and also helps deepen our understanding of included and excluded groups wehn et al 2015b this is especially necessary for cbms that have the ambition to move beyond mere data collection and perceive a more active role for citizens in influencing decision making processes bonney et al 2015 dickinson et al 2012 kullenberg and kasperowski 2016 effort required to participate and support offered for participation are two other aspects of the participation dimension that have been identified by previous research conrad and daoust 2008 dickinson et al 2010 roy et al 2012 ciravegna et al 2013 liu et al 2014 pocock et al 2014 gharesifard and wehn 2016a gharesifard et al 2017 rutten et al 2017 effort required to participate refers to different types of requirements and investments that are needed from participants such as time or monetary investments or expertise citi sense cobweb and citclops identified examples of knowledge requirements such as participants understanding of complex environmental issues e g air pollution or flooding and their experience with data collection processes as factors that influenced their project engagement efforts bartonova et al 2016 cobweb consortium 2015b novoa and wernand 2013 support offered for participation considers the investments made by the initiators to communicate about the cbm initiative and to facilitate public participation via for example flexible participation methods easy to use web platforms and mobile applications incentives provided for participation and the availability of supporting materials guidelines and trainings communication in the context of a cbm initiative can go beyond just data push and in many cases cbms act as a medium for facilitating communication between different stakeholders liu et al 2014 wehn et al 2015b identifying the existing communication channels and current patterns of information flow between different stakeholders before the establishment of such an initiative is essential for understanding existing norms and mental frameworks for communication and helps explain how an initiative has affected these interaction patterns ciravegna et al 2013 and wehn et al 2015b distinguished between three different patterns of information flow namely unidirectional bi directional and interactive pattern of communication is considered to distinguish between cbms that only act as recipient of the data and those initiatives that either provide feedback through different communication channels or form an interactive exchange of information among the triangle of citizens data aggregators and policy makers wehn et al 2015a that may alter the existing pattern of information flow between these stakeholders finally it is important to understand how different stakeholders participate in a cbm initiative studies in the field of public participation in decision making provide insights about methods of participation in public settings for example fung 2006 identified six modes of communication i e listen as spectator express preferences and develop preferences and decision making i e aggregate and bargain deliberate and negotiate and technical expertise and defined it as the way by which participants interact within a venue of public discussion or decision fung 2006 68 wehn et al 2015b adjusted these modes for cbms by adding implicit and explicit data collection to this spectrum analyzing these methods of communication and participation in decision making before and after the initiation of a cbm helps to depict how participants used to interact in public discussions or decisions on the water or environment related issue in focus of the cbm initiative and how the initiative may have mediated or altered these interactions wehn et al 2015b studying the identified aspects in this dimensions helps to understand the participation dynamics in a cbm initiative and answering the key question who participates in the cbm initiative and how 3 4 power dynamics dimension of cbm initiatives environmental governance is inherently a political process that involves competing interests and conflicting norms and values for different actors cleaver 1999 since a cbm is established to help better understand or address a specific water or environment related issue existing power dynamics related to the governance of those issues are inevitably involved newman et al 2012 wehn et al 2015b furthermore the power im balance among different actors in a cbm creates internal power dynamics that shape the objectives functioning and outcomes of the initiatives this section summarizes the results of our review regarding internal and external power dynamics of a cbm initiative the importance of understanding the social institutional and political context which a cbm operates in has been highlighted in previous research e g irwin 2001 wehn et al 2017 emmett environmental law and policy clinic 2019 institutions here refer to the multi level social and legal arrangements that regulate actors behavior pahl wostl 2009 policies are understood as implicit and explicit procedures in managing natural resources and infrastructure kemerink et al 2013 understanding these contextual realities helps depict how the current system of decision making works by providing insights on the formal and informal rules and regulations related to the issue in focus of the cbm initiative the extent to which these rules and regulations are being implemented and enforced the roles and responsibilities of different actors and the role of public participation in these processes both the wesenseit and cobweb projects highlighted the importance of understanding the institutional and political context the water governance context of the case studies in wesenseit were systematically analyzed and reported in a number of project reports and publications e g wehn de montalvo et al 2013 wehn et al 2015b wehn et al 2016 in addition one of the lessons learned from cobweb is that without understanding the concepts and processes that underpin decision making processes it is not possible to understand the value added of the data produced by a cbm cobweb consortium 2015b authority and power or the actual level of impact of different stakeholders on decision making processes related to the environmental issue in focus of the cbm is the next aspect of power dynamics this aspect focuses on a dilemma that nelkin described as follows the complexity of public decisions seems to require highly specialized and esoteric knowledge and those who control this knowledge have considerable power yet democratic ideology suggests that people must be able to influence policy decisions that affect their lives nelkin 1975 37 cbm initiatives have the potential to close or at least narrow this knowledge gap and reduce a power imbalance in decision making processes but this is not definitive a lot of cbm projects claim that they have increased citizens influence on decision making processes but this claim is often hypothetical not evidence based or at least not well documented for example without providing details the omniscientis final report claims that local environmental governance was enhanced through citizen participation in project activities and monthly meetings omniscientis consortium 2014 in another example the final report of the cobweb identifies increased citizens influence on environmental governance as its chief expected impact but there is no reported evidence on how this impact actually happened cobweb consortium 2017 however a thorough study of the water governance aspects in the wesenseit project revealed that it is very difficult if not impossible to capture changes in citizens authority and power during the lifetime of a project wehn et al 2016 thus it is important to investigate the levels of authority and power of different stakeholders before and long after establishment of a cbm the five different levels of authority and power suggested by fung 2006 can serve to assess this aspect wehn et al 2015b these levels start from individual education and increase to communicative influence advise consult co govern and finally direct authority another aspect to be considered while examining power dynamics is access to and control over data irwin 2001 gouveia and fonseca 2008 roy et al 2012 world bank group 2016 wehn et al 2016 emmett environmental law and policy clinic 2019 ownership of the data and the ability to analyze the data are directly linked to its actual use who defines the level of access to water or environment related data for different participants who decides on the quality control procedure who has the required skills to analyze the data and who can veto the data collection and aggregation procedures and the publication of harmful data these are the type of questions that may be asked to determine the access to and control over data before and after the establishment of a cbm the stakeholders who establish a cbm usually have a strong say in defining its overarching objectives governance structure participation mechanisms and the chosen technologies the establishment mechanism is described as the way in which the cbm initiative is founded and has four distinct types top down bottom up commerce driven and co created the first two types were previously identified by ciravegna et al 2013 and using different titles i e consultative and transformative by conrad and hilchey 2011 for top down systems authorities and stakeholders at higher levels of policy or decision making initiate the cbm while for bottom up systems stakeholders such as citizens or volunteers are the initiators the commerce driven model is added to capture the establishment mechanism of those observatories that have been set up neither by official administrative bodies nor by lower levels of decision making hierarchy but are market based and for profit gharesifard et al 2017 finally the co created collaborative or co designed cbm is a novel approach that aims to provide to as many interested stakeholders as possible a chance to influence the design and functioning of cbms by involving them in different steps of its establishment process wehn et al 2015a conrad and hilchey 2011 revenue stream to sustain the initiative is the aspect that depicts how a cbm generates its revenue or receives its required funding this helps to explain critical issues such as financial motivations behind running the cbm its sustainability data ownership and the level of access to the generated information for the general public despite its importance this aspect has not received much attention in previous research for example the eu fp7 cbm projects that we reviewed in this study were pilot cbm projects and therefore did not consider revenue streams for sustaining the initiatives that they established macintosh 2004 touches upon funding issues when she discusses resources and promotion and briefly mentions that due to the novelty of e participation initiatives they are mostly funded by national governments through their r d budget wiggins and crowston 2011 mentioned that the largest citizen science projects of the us national science foundation nsf have received their funding in the form of sponsorships sales referrals or licensing perhaps the most comprehensive categorization of potential revenue streams of cbms is the seven categories identified by gharesifard et al 2017 this classification is adopted from osterwalder and pigneur 2010 and further adjusted to best capture the revenue streams for a cbm this classificationincludes government sponsorship data information usage fee subscription fee asset sale advertising licensing and donation a critical analysis of the aspects that were introduced in this dimension will increase our understanding of who controls and influences the cbm initiative and how this question helps depict both internal and external power dynamics of a cbm 3 5 results dimension of cbm initiatives during recent years the expertise to set up and run citizen science projects and cbm initiatives has grown at a very fast pace but as phillips et al 2014 stated there is still a critical gap between these competencies and those required to evaluate the value and impact of these initiatives a considerable part of the reviewed literature in this paper focuses on evaluating citizen science and cbm projects public participation in scientific research science learning in informal environments and e participation brossard et al 2005 friedman 2008 national research council 2009 bonney et al 2009a bonney et al 2009b phillips et al 2012 shirk et al 2012 jordan et al 2012 phillips et al 2014 bonney et al 2014 world bank group 2016 sch√§fer and kieslinger 2016 kieslinger et al 2017 wehn et al 2017 wiggins et al 2018 phillips et al 2018 kieslinger et al 2018 fernandez gimenez et al 2008 although providing detailed instructions on how to evaluate cbm projects is beyond the scope of this paper the review of this literature resulted in a number of critical points that need to be considered while evaluating cbm initiatives most of the reviewed literature including brossard et al 2005 national research council 2009 bonney et al 2009a bonney et al 2009b jordan et al 2012 bonney et al 2014 sch√§fer and kieslinger 2016 kieslinger et al 2017 wiggins et al 2018 and kieslinger et al 2018 does not distinguish between outputs i e direct products of an initiative and its outcomes and impacts i e the short term mid term and long term changes that can be attributed to the initiative friedman 2008 proposed the use of the logic model for evaluating informal science education programs and distinguishing between outputs e g the number of participants in these programs outcomes e g improved understanding about a certain topic among the participants and impacts e g lasting changes in the behavior of participants this idea was later adopted by a number of researchers for evaluating the results of citizen science projects e g shirk et al 2012 phillips et al 2012 phillips et al 2014 phillips et al 2018 wehn et al 2017 we argue that it is important to distinguish between the direct products of a cbm and the changes e g in the status quo of water resources that can be attributed to the existence and functioning of the initiative failing to recognize or acknowledge this difference or the fact that the results of cbms are likely to evolve and change over time may have practical implications for evaluation processes evaluating the direct products of an initiative may require fundamentally different methods than those required to assess the changes that result from that initiative for the purpose of this paper we define outputs as the direct products of a cbm initiative outcomes as incidental and short term changes that can be attributed to the existence of the cbm initiative and impacts as long term outcomes that are broad in scope and are associated with structural changes our review also revealed that most of the existing literature predominantly focuses on scientific outputs individual learning outcomes and to some extent on societal outcomes of an initiative e g friedman 2008 national research council 2009 bonney et al 2009a bonney et al 2009b phillips et al 2012 2014 2018 broader outcome categories such as environmental economic and governance related outcomes of the initiatives e g change in policies legislations or actors authority are often ignored assumed or speculated in a review of 10 years of relevant citizen science literature conrad and hilchey 2011 also concluded that the environment and governance related success stories of cbms are largely undocumented this is mainly because environmental economic and governance related changes are complex in nature interrelated difficult to study and unfold over a long period of time in addition at least for funded cbm projects evaluation often happens partially superficially towards the end of the project and primarily for reporting purposes as soon as the project funding ends hardly any effort is made to evaluate its mid term and long term impacts for example the final report of the citi sense project indicates that it was not possible to access the wider societal impacts of the project arpaci et al 2016b in another example the chief expected impact from cobweb was enabling greater citizen influence in environmental governance cobweb consortium 2017 4 however this hypothesized output is not supported by evidence studies such as fernandez gimenez et al 2008 shirk et al 2012 bonney et al 2014 world bank group 2016 kieslinger et al 2017 wehn et al 2017 and wiggins et al 2018 consider broader social environmental economic and governance related outputs and outcomes of cbms for the purpose of this paper we combined the typologies of outputs outcomes and outcomes from the reviewed literature and classified those into six meta categories table 2 provides an overview of these categories and sample outputs outcomes and impacts of a cbm we acknowledge the interdependencies and overlaps between these meta categories of results and believe that they cannot be studied independently from one another we have demonstrated this by providing examples of outputs and outcomes in table 2 that may belong to more than one category of results however recognizing these meta categories of results will help guide our conceptual thinking on the design and implementation of evaluation processes and it will help communicating the outputs outcomes and impacts with those who may be interested in a specific domain of results e g scientists or water managers we also believe that not all six meta categories of results may be relevant for each cbm since the results of an initiative among other things are related to its objectives the last question is thus what are the expected and realized outputs outcomes impacts of the cbm initiative it is important to note that outputs outcomes and impacts can be positive or negative furthermore comparing outputs outcomes and impacts with the objectives of a cbm will help identify intended and unintended results 3 6 synthesis of the conceptual framework the proposed conceptual framework for examining the contextual setting process evaluation and impact assessment of a cbm initiative in short the cpi framework is illustrated in fig 1 different aspects of each dimension are categorized and marked based on their relevance for the issue context in focus of a cbm initiative and whether they are internal to the initiative see the legend on the lower left of the framework the aspects discussed in the two dimensions goals objectives and results are directly related to the cbm while the technology participation and power dynamics dimensions cover a wide range of contextual factors related to the issue in focus of the initiative e g the institutional and political context its internal dynamics e g its establishment mechanism or both e g communication paradigm about the issue and within the cbm initiative the circular shape of the cpi framework is meant to acknowledge and emphasize the interdependencies between the five dimensions the distinction made between the context related and initiative related aspects broadens the applicability of the cpi framework for different purposes and makes it suitable for context analysis process evaluation and impact assessment of a cbm for the purpose of context analysis only the aspects that focus on the issue marked with a circle or circle square sign in the framework need to be examined for impact assessment the classifications provided for outputs outcomes and impacts can guide the evaluation of results generated by a cbm initiative for process evaluation purposes the core questions raised by the cpi framework e g who participates in the cbm initiative and how or who controls and influences the cbm initiative and how serve to analyze the processes that led to the outputs outcomes and impacts of the cbms and generate insights into why and how positive negative intended and unintended results are not being achieved in order to be able to capture changes in the contextual setting and to describe the establishment functioning and results of a cbm it is necessary to study these dimensions and aspects at different points in time at least once at the beginning of the establishment process of an initiative and once at the time of evaluating its outputs outcomes and impacts 4 conclusions cbms have a high perceived potential for enhancing informed inclusive democratic and transparent environmental decision making however the conceptual understanding required to evaluate and critically review the dynamics at play that might enable or hinder these initiatives from delivering on their potential is limited based on an extensive review of the literature and theories in the field of citizen science and other affiliated fields of research this paper proposed a conceptual framework consisting of five dimensions which based on the proposed guiding questions can help unpack what influences the establishment and functioning of a cbm while evaluating these influential factors the cpi framework provides an interpretation of the epistemic community and thus helps construct or define the meaning of community in a particular cbm a concept which is otherwise difficult to depict we envision three different applications for the cpi framework firstly it can be utilized as a framework for analyzing the baseline situation of contextual factors such as the social political institutional and technological setting that can influence the establishment and functioning of a cbm initiative if conducted before the establishment of a cbm such a baseline contextual analysis can provide highly valuable insights for the design of the initiative as well as for stakeholder engagement activities secondly this framework can be utilized for impact assessment purposes the classifications provided for outputs outcomes and impacts table 2 help evaluate the results generated by a cbm in a systematic and logical way the third application of the cpi framework is in process evaluation answers to the core questions raised by this framework e g who participates in the cbm initiative and how or who controls and influences the cbm initiative and how help enhance our understanding of the processes that led to the outputs outcomes and impacts of the cbm and provide valuable insights about why and how positive negative intended and unintended results were generated this multi purpose nature is a unique feature of the cpi framework that is not present in any other conceptualization of citizen science projects or cbms we hypothesize that the five dimensions of the proposed framework are common across all cbms and all dimensions and aspects need to be closely examined in order to gain a thorough understanding of an initiative at the same time we expect however that not all aspects may be equally important or relevant for each initiative we encourage researchers and practitioners to apply and test the proposed framework for analyzing the features and functioning of different cbm initiatives and to report on the implementation of the framework declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the research reported in this paper is part of the ground truth 2 0 project http gt20 eu which has received funding from the european union under grant agreement no 689744 the authors thank an anonymous reviewer whose comments helped clarifying the application of the proposed framework for constructing the meaning of community in a cbm 
6069,community based monitoring of water and environmental resources is believed to have the potential to help produce more or better water and environmental data increase public participation in environmental monitoring respond to issues of common community concern and enhance informed democratic and transparent environmental decision making despite these perceived outcomes initial and long term engagement of different stakeholders with community based monitoring activities remains a challenge successful establishment of these initiatives has proven to be complex and there is little evidence that community based monitoring projects have an impact on environmental or water resources management processes or a legacy beyond their funding period whereas much attention is being paid to promoting community based monitoring as a tool for producing more or better water or environment related data there is little conceptual understanding of how to critically analyze and understand the features and functioning of these initiatives therefore we do not know whether or to what extent these initiatives deliver on their perceived potentials thus it is essential to learn from past experiences and critically document analyze and understand factors that might influence the establishment functioning and outcomes of community based monitoring initiatives based on the review of a large body of literature in the fields of community based monitoring citizen science and affiliated fields of research combined with the empirical evidence from a number of major eu funded community based monitoring projects this paper introduces a framework that can be utilized to analyze the dynamics underlying the establishment and functioning of community based monitoring initiatives the distinction between five different dimensions consisting of 22 internal and context related factors is a unique feature of this framework that broadens its applicability and makes it suitable for context analysis process evaluation and impact assessment of the initiatives the introduced framework is therefore called the cpi framework in short keywords citizen science community based monitoring context analysis process evaluation impact assessment 1 introduction population growth environmental degradation depletion of natural resources and climate change are among the most dominant challenges that increasingly affect our ecosystem placing fundamental threats on human well being and quality of life the most recent world economic forum s yearly reports on the global landscape of risks identifies environmental challenges such as extreme weather events natural disasters failure of climate change mitigation and adaptation and man made environmental disasters among the top ten risks in terms of likelihood of occurrence world economic forum 2019 world economic forum 2018 it is evident that addressing these global challenges and moving towards a sustainable future requires among other things improved policies and informed environmental decision making on the one hand one pre requisite for better informed environmental decision making is the availability of continuous and widespread observations of the environment for example of the water cycle and its components which can inform water and environment related policies this has been argued by the oecd s environmental outlook 2050 namely better information supports better policies so our knowledge base needs to be improved oecd 2012 on the other hand there is an ever increasing recognition that environmental science and policy should be more participatory transparent and democratic various international conventions and policy guidelines such as the aarhus convention hyogo framework for action and sustainable development goals sdgs have highlighted the importance of engaging citizen in environmental science and policy unece 1998 unisdr 2005 united nations 2015 this implies that environmental science should be opened up to the public and needs to incorporate locally relevant knowledge moreover water and environment related decisions should consider the voice of citizens whose well being and livelihood are being affected by those decisions citizen science is an emerging and fast growing field of participatory research that has a high perceived potential for enhancing informed democratic inclusive and transparent environment related decision making the fast growth and expansion of citizen science also due to the rapid diffusion of information communication technologies icts has made it possible for a large proportion of the general public to better understand and engage with water or environment related issues that affect their everyday lives an example of such engagement is the so called community based monitoring of water and environmental resources hereafter cbm cbm is a process where concerned citizens government agencies industry academia community groups and local institutions collaborate to monitor track and respond to issues of common community concern whitelaw et al 2003 410 as emphasized by conrad and hilchey 2011 cbm refers to both community based environmental monitoring and community based environmental management aspects of citizen science this definition is very close to what is also referred to as citizen observatories of the environment the concept of citizen observatory is mostly used in the european context and the european commission defines it as community based environmental monitoring and information systems using innovative and novel earth observation applications such as portable devices e g smart phones and collective intelligence to support both community and policy priorities european commission 2014 rubio iglesias 2015 lanfranchi et al 2014 cbm has been praised for its potential to contribute to better environmental decision making by empowering citizens and allowing them to take a more active role in environmental monitoring co operative planning and environmental stewardship european commission 2015 despite the huge potential portrayed for cbm initial and long term engagement of different stakeholders with cbm activities is still a challenge wehn and almomani 2019 in press successful establishment of these initiatives has proven to be complex and there is little evidence that they have had impact on water management or environmental management processes or in case of project based initiatives legacy beyond their funding period for example a recent eu wide inventory of citizen science initiatives shows that none of the citizen observatories for water and environmental management that were funded within the seventh framework programme of the european union i e citi sense citclops cobweb omniscientis wesenseit are currently active bio innovation service 2018 these projects started their activities in 2012 ran for two to four years received a combined funding of more than 26 million euro and established several cbm initiatives on both water related topics such as coast and ocean monitoring flood risk management or natural hazard management and more broad environmental monitoring and management topics such as biological monitoring environmental quality of life in urban areas and odour monitoring too much attention is paid to promoting cbm as a tool for producing more or better environmental data but the actual conceptual understanding required to critically analyze and understand the features and functioning of these initiatives is lagging behind therefore we do not know whether or to what extent they have delivered on their perceived potential this is partly due to the fact that the concept of community in a cbm initiative is highly context dependent dynamic and hence difficult to analyze in general terms a community is a social unit consisting of a group of individuals who have something in common in the context of a cbm this common denominator is usually interest in concerns about or stake in an environmental issue however the community in the context of cbm initiatives does not exist as a clearly defined and static entity rather it is shaped and reshaped over time by factors such as the initiation of the cbm the composition and the group of actors involved their goals and interests the power dynamics among the actors and enabling technologies it is therefore essential to learn from past experiences and critically document analyze and understand internal and context related factors that might influence the establishment functioning and outcomes of a cbm in order to do so there is a need for an analytical tool that allows unpacking the complexities of cbm initiatives and facilitates our understanding of the factors that can influence their establishment functioning and outcomes and how the epistemic community in a particular cbm initiative has evolved in practice such a framework provides an interpretation of the epistemic community for which it is used to evaluate and therefore helps construct or define the meaning of community in a cbm initiative adopting a mixed deductive and inductive research approach and building on a large body of theoretical and empirical literature in the fields of citizen science e participation science and technology studies sts and public participation in decision making processes this paper identifies five generic dimensions and several aspects that can influence the establishment and functioning of a cbm each dimension raises a core question about the cbm initiative and the context in which it is embedded and with which it interacts these dimensions and aspects are then synthesized into a conceptual framework which can serve to unpack the factors that influence the establishment and functioning of a cbm this paper is structured as follows the methodology that was followed for conducting the literature review and arriving at the proposed framework is detailed in section 2 section 3 introduces the identified dimensions aspects and core questions about the cbm initiative the synthesis of the conceptual framework is also presented in section 3 we conclude the paper in section 4 by elaborating on different applications of the proposed framework 2 methodology in order to identify the different dimensions and aspects that affect the establishment and functioning of cbms we critically reviewed a large body of literature that has previously elicited relevant factors this extensive literature review was carried out during a period of three years 2016 2018 and was conducted as an integrative review bandara et al 2015 which means it was informed by both theoretical and empirical evidence from the literature the literature included in this research was identified using three main methods i the authors expert knowledge about existing theoretical and empirical research in the field ii searching scientific databases e g web of science sciencedirect scopus and google scholar and iii backward and forward snowballing van wee and banister 2016 we started the literature review with a number of publications that were known to the authors and which identified or mentioned influential factors on establishment functioning or results of cbms next we searched the scientific databases for additional relevant literature in order to define the scope of our literature search we had to first identify different terminologies that are used to refer to cbm as stated by newman et al 2011 the terminologies that refer to various citizen based approaches in the field of citizen science still remains confusing and there are a number of overlapping terms which refer to the concept of cbm previous research including whitelaw et al 2003 newman et al 2011 conrad and hilchey 2011 including kullenberg and kasperowski 2016 has already identified and referred to these overlapping terminologies for example in a meta analysis of citizen science literature kullenberg and kasperowski 2016 identified overlapping concepts such as community based monitoring volunteer monitoring and participatory monitoring in another study newman et al 2011 found an overlap between the terms community based monitoring citizen based monitoring collaborative monitoring and volunteer monitoring in addition as discussed in the introduction there is a close link between cbm and the concept of citizen observatories this resulted in selecting the following set of terms for our literature search community based environmental monitoring participatory environmental monitoring collaborative environmental monitoring volunteer environmental monitoring citizen based environmental monitoring citizen observatory and citizen observatories the idea of conducting a systematic search was tested we searched the aforementioned databases for publications that referred to any of the identified terminologies in their title abstract or keywords the time span of the search was not limited and we included all documents that have ever been published on these repositories until 2018 this resulted in a very large number of publications e g more than 8000 records on google scholar reviewing this large number of documents was not manageable therefore we considered filtering the records by adding keywords that we were interested to find in these records e g aspect issue dimension factor output outcome impact etc this did not help reduce to the number of retrieved records to a great extent mainly due to the fact that these terms are usual suspects in a great majority of scientific publications therefore we decided to use backward and forward snowballing van wee and banister 2016 as the main method for expanding our search results i e where relevant we found citations in or to the reviewed literature in the case of backward snowballing the process of finding additional literature included reviewing the reference list of already identified literature and scanning the abstract and conclusion sections of potentially relevant literature based on this initial assessment newly identified literature was either excluded or marked for tentative inclusion in some cases we wanted to deepen our understanding about a specific concept that was identified in the reviewed references hence we used forward snowballing i e we searched scientific databases to find the literature which cited those references similarly we scanned the abstract and conclusions of the identified publications and if relevant marked those for potential inclusion the final decision for inclusion or exclusion of the references which were identified using backward and forward snowballing was made after the full review of the references besides their theoretical insights the identified publications in our literature search contained empirical insights from a wide range of past and ongoing citizen science and cbms in addition we wanted to further complement our literature review with empirical evidence from a number of cbms there are an overwhelming number of cbm projects that we could choose from for example a recent inventory of citizen science and cbm projects by the european commission includes 503 that have relevance for environmental policy bio innovation service 2018 this list consists of a diverse set of projects with different thematic foci including discontinued as well as ongoing and long established projects we decided to examine the five citizen observatories of water and environment that had been funded under the 7th framework programme for research and technological development in europe fp7 namely wesenseit citi sense citclops cobweb and omniscientis the main reason for this choice was the fact that these projects are considered pioneer or legacy cbm projects in europe easme 2016 this is due to the fact that these projects were the first attempt of the european commission to demonstrate the concept of citizen observatories of the environment in europe these projects therefore produced insights about the setting up of several cbms with diverse thematic foci in 16 countries in europe and beyond including the us and israel the experiences from these projects are now being applied in developing and scaling up several cbms under the horizon2020 funding program of the european commission 1 1 cbms that are being established or have been established include initiatives of projects such as ground truth 2 0 grow landsense scent d noses and monocle we also considered that these projects are relatively well documented and a lot of information about these projects can be retrieved via publically accessible project reports this yielded 67 project reports to the list of our reviewed literature a thorough processing of these documents revealed that a great majority of the reports only focus on scientific or technical aspects of the projects and only 14 reports had references to aspects that influence the establishment and functioning of cbms this added a shortlist of 14 reports to the literature included in our analysis our analytical method consisted of a mixed inductive and deductive approach starting inductively with no preconceived themes or categories we extracted different dimensions and aspects that had been identified in the reviewed literature and project reports as relevant factors for the establishment and functioning of citizen science or cbm initiatives during the review process we found a close link between the reviewed literature and major theories on public participation in decision making as well as literature from the field of science and technology studies sts therefore we deductively reviewed a number of relevant publications from those fields to further complement our understanding of the identified dimensions and aspects next we clustered and synthesized the results of the literature review the process of clustering and synthesizing the findings included three overlapping and iterative steps we started with coding the extracted aspects from the literature thematically the emerging and recurrent themes were then re categorized and merged as we progressed with the literature review this allowed us to identify the prominent themes these were then clustered and synthesized into the five dimensions that were generic across all cbms each dimension consists of several aspects and raises a core question about the intrinsic nature of an initiative as well as the technological institutional and political context in which it is embedded and with which it interacts table 1 summarizes the list of reviewed literature and indicates the relevance of the literature for the discussions in each dimension 3 synthesis of the literature and resulting dimensions of cbm initiatives the following sections present the five generic dimensions of cbms that were identified in this research namely goals and objectives technology participation power dynamics and results the discussion in each section includes referencing the reviewed literature and clarifies how each dimension was informed by the literature review based on the discussions of each dimension a core question is raised that aims to trigger critical thinking about that dimension subsequently the identified dimensions and aspects are synthesized into a conceptual framework which can be utilized to examine the contextual setting dynamic processes and outcomes of cbms 3 1 goals and objectives dimension of cbm initiatives a large part of the reviewed literature either referred to examples of goals and objectives of cbm initiatives or highlighted the importance of studying these goals and objectives e g ciravegna et al 2013 wehn et al 2015b roy et al 2012 world bank group 2016 gharesifard and wehn 2016a gharesifard and wehn 2016b kimura and kinchy 2016 tredick et al 2017 conrad and daoust 2008 kimura and kinchy 2016 argue that without attention to the objectives of a citizen science initiative it is not possible to study the quality and degree of participation in that initiative the world bank group 2016 goes one step further and emphasizes that without understanding the goals and objectives of digital citizen engagement stated or otherwise it is not possible to evaluate other dimensions of such initiatives cbm initiatives are typically formed around water or environment related issues and their overarching objectives are often set by the project initiators and or funders kimura and kinchy 2016 much less frequently objectives of cbm initiatives are co defined in consultation with all or a group of concerned stakeholders collecting environmental data raising environmental awareness increasing public participation in monitoring and management of water or environment related issues e g flood risk management water quality monitoring or environmental quality of public spaces creating new forms of communication between citizens scientists and decision makers and developing enabling technologies for the aforementioned purposes are examples of overarching objectives of the eu fp7 cbm projects that we reviewed in this study gilardoni et al 2013 cobweb consortium 2016 cobweb consortium 2015a arpaci et al 2016a omniscientis consortium 2014 no matter what the objectives of an initiative are or how they are defined it is highly important to realize the different stakeholders may have divergent interests or values silvertown 2009 wehn and almomani 2019 in press and the objectives of a cbm initiative may incline more towards preferences and wishes of some stakeholders than those of others moreover the overarching goals of a cbm initiative may not be bias free and might have been influenced by vested interests of funders researchers and technology providers this may result in some stakeholders benefiting more from the initiative than others an issue that is among the lessons learned from the citi sense projects arpaci et al 2016a previous research efforts have mainly focused on overarching objectives of the cbm initiatives and do not investigate how actor specific goals might differ from one actor group to another gharesifard and wehn 2016b there is also little attention to the synergies and contradictions between these goals and the overarching objectives of a cbm initiative a thorough study of the cbm objectives and goals of the actors involved may help answer a number of questions that are often mentioned with regards to paradoxes of participatory processes cleaver 1999 for example who gains most from the cbm activities and whose interest is least reflected the initial objectives of a cbm initiative may be modified or evolve over time cooper et al 2007 irwin 2015 this can happen because of different reasons for example financial or technological constraints power dynamics between involved stakeholders or adjustment of project ambitions the latter happened to both the citi sense and the cobweb projects which reportedly changed their objectives due to their realization of challenges with achieving their initial objectives arpaci et al 2016a cobweb consortium 2017 it is therefore also important to monitor any changes in the objectives and to understand why such changes have happened monitoring the objectives and the extent of their achievement is a benchmark for assessing intended outcomes and impacts of a cbm thus the first core question that we pose is what are the overarching objectives and actor specific goals of the cbm initiative and to what extent does the design of the initiative help achieve those goals objectives 3 2 technology dimension of cbm initiatives recent technological developments and advancements in icts have transformed and accelerated cbm initiatives to a great extent and have created new possibilities for stakeholder participation in science and policy it is therefore important to study how to engage different stakeholders in a cbm initiative macintosh 2004 wehn et al 2015b ciravegna et al 2013 world bank group 2016 gharesifard and wehn 2016b gharesifard and wehn 2016a the technological choices for a cbm initiative can be broadly divided into two main categories those technologies that existed and were being used before the establishment of the initiative and those that are newly developed or introduced to create the desired functionalities for a cbm initiative newman et al 2012 refer to these as make versus buy options each of these categories can be further broken down based on the functionality that is envisioned for them in a cbm initiative e g data collection visualization or communication adopting both existing and newly introduced technologies comes with a number of social political economic and even cultural changes that needs to be carefully considered before selecting different technological options this can be done by asking who is being included or excluded intentionally or unintentionally as result of specific technological choices the extent to which these choices create and or maintain specific social conditions that favor some and marginalize others and the degree to which they are more compatible with internal or external social and political structures and relationships than others therefore while establishing a cbm initiative there is a need for gaining an understanding of existing infrastructure and availability of different forms of access to a wide range of possible technologies by different stakeholder groups newman et al 2012 gouveia and fonseca 2008 this closely relates to discussions on the digital divide and forms of access to technology material motivational usage and skills e g van dijk 2006 and helps identify included excluded groups resulting from choices of technology moreover as many sts scholars have emphasized the perception that technology changes solely as a result of scientific advancements or on its own accord is a passive way of conceiving technology that focuses on how to adapt to technological changes rather than how they shape or are shaped by society the economy or politics mackenzie and wajcman 1999 winner 1986 mansell and wehn 1998 bijker et al 2012 for example a web platform of a cbm initiative that focuses on the issue of water or air quality is not only shaped by technological components that are a prerequisite for its creation and functioning but also for example by vested interests or economic constrains of its developers or the end users in the case of the five eu fp7 projects that were reviewed for this study most of the projects started their cbm activities with a technology driven model meaning they started developing tools and technologies that seemed suitable for achieving their objectives without gaining a thorough understanding of the social economic and political system that they were operating in for example cobweb mentions in its final report that they entered a process of rapid prototyping software development based on their identified requirements and only when they reached a certain level of technology readiness started to engage citizens cobweb consortium 2017 the interpretation of the results of this approach is different among different projects some call it a great success e g cobweb consortium 2017 omniscientis consortium 2014 and some identify it as a source of major difficulties in developing the cbm initiatives e g arpaci et al 2015 arpaci et al 2016b wesenseit consortium 2016 for example arpaci et al 2016b mentioned that technological developments became one of the key motives of the citi sense project and this caused major difficulties with engaging and empowering citizens because it shifted the project s attention and resources away from engagement and empowerment activities this dimension therefore considers how enabling technologies of a cbm initiative have been shaped and how these relate to existing infrastructure as well as social and technological capabilities by asking how effective and appropriate are the choices and delivery of the selected technologies 3 3 participation dimension of cbm initiatives enhancing public participation in environmental monitoring planning or management is a core concept of cbm initiatives and the first step to understanding the state of change in such participation processes is to deepen our understanding of the existing participation dynamics related to the water or environmental issue in focus since the level of engagement and commitment of participants differs across different cbm initiatives at different stages of its development and across different actors it is important to first clarify what participation in a cbm initiative implies participation in a cbm initiative is closely related to the higher purpose that the initiative serves and the type of activities that are being conducted as part of it there have been a number of attempts to classify citizen science initiatives and the extent of participation in these initiatives for example bonney et al 2009a classified citizen science projects based on the degree of participants involvement in scientific investigations steps into contributory collaborative and co created projects shirk et al 2012 expanded these categories to five models of public participation in scientific research that included contractual contributory collaborative co created and collegial haklay 2015 distinguished between six levels of participation based on the extent of engagement and commitment of participants namely passive sensing volunteer computing volunteer thinking environmental and ecological observations participatory sensing and civic community science another example is a meta analysis of citizen science literature in which kullenberg and kasperowski 2016 identified three types of initiatives according to their higher purpose namely citizen science as a method public engagement with science and policy or civic mobilization the purpose of highlighting these typologies is not to prescribe or recommend an existing typology rather it is to emphasis the importance of considering different typologies of participation during the evaluation of cbm initiatives and clarifying what participation in an initiative actually entails previous studies have identified geographic scope as an aspect that is often linked to the issue in focus of the cbm initiative and shows its breadth of focus haklay 2015 cooper et al 2007 macintosh 2004 roy et al 2012 wehn et al 2015b moreover the geographic scope of a cbm initiative determines the spectrum of currently involved and affected stakeholders and helps identify the potential pool of participants in the initiative moreover the geographic scope of a cbm may change over time for example as a result of its growth or its change of focus participant groups are the actors or stakeholders who are involved in a cbm initiative wehn et al 2015b ciravegna et al 2013 macintosh 2004 conrad and daoust 2008 depending on the type and objectives of an initiative these are normally individuals groups or organizations who had a role in the design and setting up of the initiative are actively involved in the initiative via data collection sharing analysis aggregation and visualization and or use its outputs for improving policy or decision making processes it is also equally important to understand which groups of stakeholders are not represented in a cbm initiative and to critically reflect on consequences of their absence although contributing to public policy and decision making processes is far from easy irwin 1995 and may not be among the objectives of a cbm initiative studying the stakeholders already involved in decision making processes offers the possibility to know who might be interested in the data and knowledge generated via cbm and also helps deepen our understanding of included and excluded groups wehn et al 2015b this is especially necessary for cbms that have the ambition to move beyond mere data collection and perceive a more active role for citizens in influencing decision making processes bonney et al 2015 dickinson et al 2012 kullenberg and kasperowski 2016 effort required to participate and support offered for participation are two other aspects of the participation dimension that have been identified by previous research conrad and daoust 2008 dickinson et al 2010 roy et al 2012 ciravegna et al 2013 liu et al 2014 pocock et al 2014 gharesifard and wehn 2016a gharesifard et al 2017 rutten et al 2017 effort required to participate refers to different types of requirements and investments that are needed from participants such as time or monetary investments or expertise citi sense cobweb and citclops identified examples of knowledge requirements such as participants understanding of complex environmental issues e g air pollution or flooding and their experience with data collection processes as factors that influenced their project engagement efforts bartonova et al 2016 cobweb consortium 2015b novoa and wernand 2013 support offered for participation considers the investments made by the initiators to communicate about the cbm initiative and to facilitate public participation via for example flexible participation methods easy to use web platforms and mobile applications incentives provided for participation and the availability of supporting materials guidelines and trainings communication in the context of a cbm initiative can go beyond just data push and in many cases cbms act as a medium for facilitating communication between different stakeholders liu et al 2014 wehn et al 2015b identifying the existing communication channels and current patterns of information flow between different stakeholders before the establishment of such an initiative is essential for understanding existing norms and mental frameworks for communication and helps explain how an initiative has affected these interaction patterns ciravegna et al 2013 and wehn et al 2015b distinguished between three different patterns of information flow namely unidirectional bi directional and interactive pattern of communication is considered to distinguish between cbms that only act as recipient of the data and those initiatives that either provide feedback through different communication channels or form an interactive exchange of information among the triangle of citizens data aggregators and policy makers wehn et al 2015a that may alter the existing pattern of information flow between these stakeholders finally it is important to understand how different stakeholders participate in a cbm initiative studies in the field of public participation in decision making provide insights about methods of participation in public settings for example fung 2006 identified six modes of communication i e listen as spectator express preferences and develop preferences and decision making i e aggregate and bargain deliberate and negotiate and technical expertise and defined it as the way by which participants interact within a venue of public discussion or decision fung 2006 68 wehn et al 2015b adjusted these modes for cbms by adding implicit and explicit data collection to this spectrum analyzing these methods of communication and participation in decision making before and after the initiation of a cbm helps to depict how participants used to interact in public discussions or decisions on the water or environment related issue in focus of the cbm initiative and how the initiative may have mediated or altered these interactions wehn et al 2015b studying the identified aspects in this dimensions helps to understand the participation dynamics in a cbm initiative and answering the key question who participates in the cbm initiative and how 3 4 power dynamics dimension of cbm initiatives environmental governance is inherently a political process that involves competing interests and conflicting norms and values for different actors cleaver 1999 since a cbm is established to help better understand or address a specific water or environment related issue existing power dynamics related to the governance of those issues are inevitably involved newman et al 2012 wehn et al 2015b furthermore the power im balance among different actors in a cbm creates internal power dynamics that shape the objectives functioning and outcomes of the initiatives this section summarizes the results of our review regarding internal and external power dynamics of a cbm initiative the importance of understanding the social institutional and political context which a cbm operates in has been highlighted in previous research e g irwin 2001 wehn et al 2017 emmett environmental law and policy clinic 2019 institutions here refer to the multi level social and legal arrangements that regulate actors behavior pahl wostl 2009 policies are understood as implicit and explicit procedures in managing natural resources and infrastructure kemerink et al 2013 understanding these contextual realities helps depict how the current system of decision making works by providing insights on the formal and informal rules and regulations related to the issue in focus of the cbm initiative the extent to which these rules and regulations are being implemented and enforced the roles and responsibilities of different actors and the role of public participation in these processes both the wesenseit and cobweb projects highlighted the importance of understanding the institutional and political context the water governance context of the case studies in wesenseit were systematically analyzed and reported in a number of project reports and publications e g wehn de montalvo et al 2013 wehn et al 2015b wehn et al 2016 in addition one of the lessons learned from cobweb is that without understanding the concepts and processes that underpin decision making processes it is not possible to understand the value added of the data produced by a cbm cobweb consortium 2015b authority and power or the actual level of impact of different stakeholders on decision making processes related to the environmental issue in focus of the cbm is the next aspect of power dynamics this aspect focuses on a dilemma that nelkin described as follows the complexity of public decisions seems to require highly specialized and esoteric knowledge and those who control this knowledge have considerable power yet democratic ideology suggests that people must be able to influence policy decisions that affect their lives nelkin 1975 37 cbm initiatives have the potential to close or at least narrow this knowledge gap and reduce a power imbalance in decision making processes but this is not definitive a lot of cbm projects claim that they have increased citizens influence on decision making processes but this claim is often hypothetical not evidence based or at least not well documented for example without providing details the omniscientis final report claims that local environmental governance was enhanced through citizen participation in project activities and monthly meetings omniscientis consortium 2014 in another example the final report of the cobweb identifies increased citizens influence on environmental governance as its chief expected impact but there is no reported evidence on how this impact actually happened cobweb consortium 2017 however a thorough study of the water governance aspects in the wesenseit project revealed that it is very difficult if not impossible to capture changes in citizens authority and power during the lifetime of a project wehn et al 2016 thus it is important to investigate the levels of authority and power of different stakeholders before and long after establishment of a cbm the five different levels of authority and power suggested by fung 2006 can serve to assess this aspect wehn et al 2015b these levels start from individual education and increase to communicative influence advise consult co govern and finally direct authority another aspect to be considered while examining power dynamics is access to and control over data irwin 2001 gouveia and fonseca 2008 roy et al 2012 world bank group 2016 wehn et al 2016 emmett environmental law and policy clinic 2019 ownership of the data and the ability to analyze the data are directly linked to its actual use who defines the level of access to water or environment related data for different participants who decides on the quality control procedure who has the required skills to analyze the data and who can veto the data collection and aggregation procedures and the publication of harmful data these are the type of questions that may be asked to determine the access to and control over data before and after the establishment of a cbm the stakeholders who establish a cbm usually have a strong say in defining its overarching objectives governance structure participation mechanisms and the chosen technologies the establishment mechanism is described as the way in which the cbm initiative is founded and has four distinct types top down bottom up commerce driven and co created the first two types were previously identified by ciravegna et al 2013 and using different titles i e consultative and transformative by conrad and hilchey 2011 for top down systems authorities and stakeholders at higher levels of policy or decision making initiate the cbm while for bottom up systems stakeholders such as citizens or volunteers are the initiators the commerce driven model is added to capture the establishment mechanism of those observatories that have been set up neither by official administrative bodies nor by lower levels of decision making hierarchy but are market based and for profit gharesifard et al 2017 finally the co created collaborative or co designed cbm is a novel approach that aims to provide to as many interested stakeholders as possible a chance to influence the design and functioning of cbms by involving them in different steps of its establishment process wehn et al 2015a conrad and hilchey 2011 revenue stream to sustain the initiative is the aspect that depicts how a cbm generates its revenue or receives its required funding this helps to explain critical issues such as financial motivations behind running the cbm its sustainability data ownership and the level of access to the generated information for the general public despite its importance this aspect has not received much attention in previous research for example the eu fp7 cbm projects that we reviewed in this study were pilot cbm projects and therefore did not consider revenue streams for sustaining the initiatives that they established macintosh 2004 touches upon funding issues when she discusses resources and promotion and briefly mentions that due to the novelty of e participation initiatives they are mostly funded by national governments through their r d budget wiggins and crowston 2011 mentioned that the largest citizen science projects of the us national science foundation nsf have received their funding in the form of sponsorships sales referrals or licensing perhaps the most comprehensive categorization of potential revenue streams of cbms is the seven categories identified by gharesifard et al 2017 this classification is adopted from osterwalder and pigneur 2010 and further adjusted to best capture the revenue streams for a cbm this classificationincludes government sponsorship data information usage fee subscription fee asset sale advertising licensing and donation a critical analysis of the aspects that were introduced in this dimension will increase our understanding of who controls and influences the cbm initiative and how this question helps depict both internal and external power dynamics of a cbm 3 5 results dimension of cbm initiatives during recent years the expertise to set up and run citizen science projects and cbm initiatives has grown at a very fast pace but as phillips et al 2014 stated there is still a critical gap between these competencies and those required to evaluate the value and impact of these initiatives a considerable part of the reviewed literature in this paper focuses on evaluating citizen science and cbm projects public participation in scientific research science learning in informal environments and e participation brossard et al 2005 friedman 2008 national research council 2009 bonney et al 2009a bonney et al 2009b phillips et al 2012 shirk et al 2012 jordan et al 2012 phillips et al 2014 bonney et al 2014 world bank group 2016 sch√§fer and kieslinger 2016 kieslinger et al 2017 wehn et al 2017 wiggins et al 2018 phillips et al 2018 kieslinger et al 2018 fernandez gimenez et al 2008 although providing detailed instructions on how to evaluate cbm projects is beyond the scope of this paper the review of this literature resulted in a number of critical points that need to be considered while evaluating cbm initiatives most of the reviewed literature including brossard et al 2005 national research council 2009 bonney et al 2009a bonney et al 2009b jordan et al 2012 bonney et al 2014 sch√§fer and kieslinger 2016 kieslinger et al 2017 wiggins et al 2018 and kieslinger et al 2018 does not distinguish between outputs i e direct products of an initiative and its outcomes and impacts i e the short term mid term and long term changes that can be attributed to the initiative friedman 2008 proposed the use of the logic model for evaluating informal science education programs and distinguishing between outputs e g the number of participants in these programs outcomes e g improved understanding about a certain topic among the participants and impacts e g lasting changes in the behavior of participants this idea was later adopted by a number of researchers for evaluating the results of citizen science projects e g shirk et al 2012 phillips et al 2012 phillips et al 2014 phillips et al 2018 wehn et al 2017 we argue that it is important to distinguish between the direct products of a cbm and the changes e g in the status quo of water resources that can be attributed to the existence and functioning of the initiative failing to recognize or acknowledge this difference or the fact that the results of cbms are likely to evolve and change over time may have practical implications for evaluation processes evaluating the direct products of an initiative may require fundamentally different methods than those required to assess the changes that result from that initiative for the purpose of this paper we define outputs as the direct products of a cbm initiative outcomes as incidental and short term changes that can be attributed to the existence of the cbm initiative and impacts as long term outcomes that are broad in scope and are associated with structural changes our review also revealed that most of the existing literature predominantly focuses on scientific outputs individual learning outcomes and to some extent on societal outcomes of an initiative e g friedman 2008 national research council 2009 bonney et al 2009a bonney et al 2009b phillips et al 2012 2014 2018 broader outcome categories such as environmental economic and governance related outcomes of the initiatives e g change in policies legislations or actors authority are often ignored assumed or speculated in a review of 10 years of relevant citizen science literature conrad and hilchey 2011 also concluded that the environment and governance related success stories of cbms are largely undocumented this is mainly because environmental economic and governance related changes are complex in nature interrelated difficult to study and unfold over a long period of time in addition at least for funded cbm projects evaluation often happens partially superficially towards the end of the project and primarily for reporting purposes as soon as the project funding ends hardly any effort is made to evaluate its mid term and long term impacts for example the final report of the citi sense project indicates that it was not possible to access the wider societal impacts of the project arpaci et al 2016b in another example the chief expected impact from cobweb was enabling greater citizen influence in environmental governance cobweb consortium 2017 4 however this hypothesized output is not supported by evidence studies such as fernandez gimenez et al 2008 shirk et al 2012 bonney et al 2014 world bank group 2016 kieslinger et al 2017 wehn et al 2017 and wiggins et al 2018 consider broader social environmental economic and governance related outputs and outcomes of cbms for the purpose of this paper we combined the typologies of outputs outcomes and outcomes from the reviewed literature and classified those into six meta categories table 2 provides an overview of these categories and sample outputs outcomes and impacts of a cbm we acknowledge the interdependencies and overlaps between these meta categories of results and believe that they cannot be studied independently from one another we have demonstrated this by providing examples of outputs and outcomes in table 2 that may belong to more than one category of results however recognizing these meta categories of results will help guide our conceptual thinking on the design and implementation of evaluation processes and it will help communicating the outputs outcomes and impacts with those who may be interested in a specific domain of results e g scientists or water managers we also believe that not all six meta categories of results may be relevant for each cbm since the results of an initiative among other things are related to its objectives the last question is thus what are the expected and realized outputs outcomes impacts of the cbm initiative it is important to note that outputs outcomes and impacts can be positive or negative furthermore comparing outputs outcomes and impacts with the objectives of a cbm will help identify intended and unintended results 3 6 synthesis of the conceptual framework the proposed conceptual framework for examining the contextual setting process evaluation and impact assessment of a cbm initiative in short the cpi framework is illustrated in fig 1 different aspects of each dimension are categorized and marked based on their relevance for the issue context in focus of a cbm initiative and whether they are internal to the initiative see the legend on the lower left of the framework the aspects discussed in the two dimensions goals objectives and results are directly related to the cbm while the technology participation and power dynamics dimensions cover a wide range of contextual factors related to the issue in focus of the initiative e g the institutional and political context its internal dynamics e g its establishment mechanism or both e g communication paradigm about the issue and within the cbm initiative the circular shape of the cpi framework is meant to acknowledge and emphasize the interdependencies between the five dimensions the distinction made between the context related and initiative related aspects broadens the applicability of the cpi framework for different purposes and makes it suitable for context analysis process evaluation and impact assessment of a cbm for the purpose of context analysis only the aspects that focus on the issue marked with a circle or circle square sign in the framework need to be examined for impact assessment the classifications provided for outputs outcomes and impacts can guide the evaluation of results generated by a cbm initiative for process evaluation purposes the core questions raised by the cpi framework e g who participates in the cbm initiative and how or who controls and influences the cbm initiative and how serve to analyze the processes that led to the outputs outcomes and impacts of the cbms and generate insights into why and how positive negative intended and unintended results are not being achieved in order to be able to capture changes in the contextual setting and to describe the establishment functioning and results of a cbm it is necessary to study these dimensions and aspects at different points in time at least once at the beginning of the establishment process of an initiative and once at the time of evaluating its outputs outcomes and impacts 4 conclusions cbms have a high perceived potential for enhancing informed inclusive democratic and transparent environmental decision making however the conceptual understanding required to evaluate and critically review the dynamics at play that might enable or hinder these initiatives from delivering on their potential is limited based on an extensive review of the literature and theories in the field of citizen science and other affiliated fields of research this paper proposed a conceptual framework consisting of five dimensions which based on the proposed guiding questions can help unpack what influences the establishment and functioning of a cbm while evaluating these influential factors the cpi framework provides an interpretation of the epistemic community and thus helps construct or define the meaning of community in a particular cbm a concept which is otherwise difficult to depict we envision three different applications for the cpi framework firstly it can be utilized as a framework for analyzing the baseline situation of contextual factors such as the social political institutional and technological setting that can influence the establishment and functioning of a cbm initiative if conducted before the establishment of a cbm such a baseline contextual analysis can provide highly valuable insights for the design of the initiative as well as for stakeholder engagement activities secondly this framework can be utilized for impact assessment purposes the classifications provided for outputs outcomes and impacts table 2 help evaluate the results generated by a cbm in a systematic and logical way the third application of the cpi framework is in process evaluation answers to the core questions raised by this framework e g who participates in the cbm initiative and how or who controls and influences the cbm initiative and how help enhance our understanding of the processes that led to the outputs outcomes and impacts of the cbm and provide valuable insights about why and how positive negative intended and unintended results were generated this multi purpose nature is a unique feature of the cpi framework that is not present in any other conceptualization of citizen science projects or cbms we hypothesize that the five dimensions of the proposed framework are common across all cbms and all dimensions and aspects need to be closely examined in order to gain a thorough understanding of an initiative at the same time we expect however that not all aspects may be equally important or relevant for each initiative we encourage researchers and practitioners to apply and test the proposed framework for analyzing the features and functioning of different cbm initiatives and to report on the implementation of the framework declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the research reported in this paper is part of the ground truth 2 0 project http gt20 eu which has received funding from the european union under grant agreement no 689744 the authors thank an anonymous reviewer whose comments helped clarifying the application of the proposed framework for constructing the meaning of community in a cbm 
