index,text
25920,upscaling methodologies enforced on nested ocean modelling grids have become a subject of more intense research due to their benefits in modelling highly dynamic coastal areas in this paper an upscaling algorithm is developed for the 3d mohid water model enabling twoway implementations which considers the nudging of a child domain s velocities temperature and salinity fields by a parent domain the algorithm is validated for a schematic case and then applied to tagus region of freshwater influence tagusrofi portugal results for the schematic case show an improvement of the parent domain while generating minimal mass conservation loss tagusrofi model domains under twoway nesting improved the salinity transition between domain boundaries when reached by the estuarine plume this new 3d mohid water model feature improves the study of extreme scenarios where oneway downscaling produces discontinuities on the nested domain s open boundaries and enables the implementation of higher resolution domains with smaller size grids keywords upscaling 3d mohid model tagus twoway nesting estuarine plume 1 software the 3d mohid water model was first developed in 1985 and the current version is programmed in ansi fortran 95 using the object oriented philosophy the code size is 22 mb and is a free open access software developed and maintained in github https github com mohid water modelling system mohid more information on the software can be consulted in http mohid com 2 introduction increasing demand for high resolution model applications by government agencies aquaculture and energy companies is driving private and public entities to develop updated grid domains for coastal areas higher resolution nested grids lead to better numerical skills of the model and allow the use of more refined bathymetric and atmospheric data improving the overall hydrodynamic solution and reducing the errors of the downstream transport models this higher level of detail allows a direct comparison between very local field data e g currents and model results increasing the modelling system s confidence downscaling from a parent domain pd to a child domain cd is still the most common option to simulate the effect of large scale on local processes in the mohid water model campuzano et al 2015 2016 2016 fossati and piedra cueva 2013 franz et al 2014 2016 huhn et al 2012 janeiro et al 2017 and in many other structured grid models such as eco mars3d desmit et al 2018 mike3 gallego et al 2017 pom nagy et al 2017 nemo katavouta and thompson 2016 roms dabrowski et al 2014 and delft3d yin et al 2019 when using this methodology care must be taken to avoid drifting of the cd over time or instabilities will be produced at the border drifting can occur due to local features not reproduced by the parent domain noise created inside the child domain which is not kept under control and loss of mass conservation properties at the open boundary these issues are addressed in debreu and blayo 2008 flather 1976 and palma and matano 1998 where a number of solutions are provided to preserve mass conservation control noise at the open boundary and to smooth the transition between parent and child solutions the most common solutions for downscaling systems is the use of a flather 1976 boundary condition for the barotropic flow allied with a radiation scheme such as described in marchesiello et al 2001 and a flow relaxation scheme described by martinsen and engedahl 1987 another option commonly considered is the use of a biharmonic filter described by kantha and clayson 2000 that removes small wave length oscillations inside the child domain although it is more relevant in low dissipative environments to facilitate the performance of these techniques the boundary between nested domains should be far enough from local hydrodynamic features this way nested domains will produce comparable results in the interface allowing for easier radiation of outgoing waves and elimination of noise produced in the child domain oneway nested models assume that large scale processes affect local scale processes and enable the building of local solutions using global services e g copernicus or emodnet but not the other way around these web services provide solutions at ocean scale that are downscaled offline by regional and local models to provide services to coastal areas end users a way to fill this local information gap is to allow the cd which typically has local knowledge embedded to update the pd also known as the upscaling stage of a twoway nesting transferring results from smaller to larger scale reduces numerical diffusion in high gradient regions but also allows the modification of the large scale flow by local features as is the case of tidal jets at the mouth of large estuaries especially in tidal estuaries this provides stronger mixing of the water column changes the local coriolis effect on the pd improving its horizontal and vertical solution and changes the coastal transport different methodologies to implement twoway nesting have been proposed in the literature studies by urrego blanco et al 2016a 2014 used the semi prognostic method proposed by greatbatch et al 2004 which introduces a pressure correction term in the horizontal momentum equations marchesiello et al 2011 applied the roms agrif twoway capability debreu et al 2012 created for split explicit models which considers the feedback of surface elevation velocities and tracer properties and introduces a flux correction scheme berger and colella 1989 to enforce mass conservation at the interface between grid domains kelly et al 2016 studied tide dynamics using the fully implicit in time and space scheme developed by haley and lermusiaux 2010 in all of these methodologies the common approach is to relax although in the semi prognostic method it is not considered a typical relaxation the pd to its cd which has been considered to be the most successful option in transferring information from the local scale to the regional scale this option also has the advantage of using local measured data to improve the entire nesting system via feedback from the child domain in un structured grids a twoway system is easier to implement because the grids can be optimally nested as demonstrated by qi et al 2018 in their study the feedback was done only at the open boundary level which is possible due to the smooth transition between grid resolutions a review on the main methodologies for a twoway nesting system can be found in debreu et al 2008 conceptually transferring information from a cd to a pd in a multigrid system can be done in two ways 1 communication is done only at the interface between domains kurihara et al 1979 in which case there is no need to compute currents in the overlapped area and the feedback from the child domain is considered as an internal boundary condition 2 communication is done at the interface and the feedback is computed in the overlapped area however as the first technique forces the method to be coupled online and creates two boundary conditions leading to implementation complications the methodology selected for mohid model will follow the second technique fox and maskell 1995 oey and chen 1992 when a twoway nesting methodology is used another boundary issue arises caused by the parent domain update of physical variables from the child domain which are in turn dependent on the parent solution debreu and blayo 2008 in literature and due to this twoway communication the term interface has been divided in two terms regarding domain areas one for the traditional oneway information exchange dynamic interface and another for the update operation feedback interface in oneway nesting the dynamic interface typically occupies the first two numerical cells of the parent domain to allow 2nd order interpolations from the parent to the child domain on the other hand if noise is produced in the child domain it is expected to be heightened near the boundary with its parent domain this can lead to the propagation of a disturbance from the child domain into the parent domain in order to avoid such issues several authors barth et al 2005 debreu et al 2012 marchesiello et al 2011 sannino et al 2009 urrego blanco and sheng 2014 separated these two interfaces this interface separation although acting as a restraint on the feedback of noise into the parent domain may prevent a smooth transition between grids for that reason authors have suggested the use of sponge cells with artificially high viscosity on the child domain near the boundary in order to remove spurious flow oscillations barth et al 2007 debreu et al 2012 urrego blanco et al 2016b acosta et al 2015 did not separate these interfaces but used a flow relaxation scheme to account for the noise between domains also with good results the present study aims to develop an upscaling algorithm for the 3d mohid water model by nudging the cd into the pd across the overlapped area conceptually when the upscaling phase is integrated in an online modelling system a oneway coupling between grid domains becomes a twoway coupling this algorithm is first applied to a simple test case of a geostrophic equilibrium which has an analytical solution in order to assess not only the impact of the nested domain on its parent solution but also to quantify any mass conservation issues derived from transferring information from child to parent domain to this end a validation was made by comparison between surface elevation and surface velocity obtained by pd and cd under oneway and twoway formulations and the analytical solution also temperature and volume results obtained by the pc and the cd where compared to a reference solution for the second test case we selected a three month simulation period for the tagusrofi area portugal the modelling system includes a parent domain for the portuguese coast pcoms level2 and a nested child domain tagusrofi level3 this solution is then compared to the current oneway methodology for the same nesting system and validated against surface elevation and salinity data available for the period of january to april 2013 this twoway modelling methodology can be advantageous to any coastal area where strong gradients over extensive areas can occur these areas include estuaries rivers and their adjacent waters and cover not only salinity but also any water parameter with a strong gradient from fresh to salt water 3 materials and methods the mohid water model is a 3d finite volume model developed at maretec ist university of lisbon for arakawa c staggered grids which solves the 3d incompressible primitive equations leitão 2002 leitão et al 2005 martins et al 1998 2001 built and developed using an object oriented philosophy braunschweig et al 2004 hydrostatic equilibrium and boussinesq approximations are assumed temporal discretization is done using a semi implicit scheme alternating direction implicit adi with two time levels per iteration and the total varying diminishing tvd with a superbee limitation method is implemented for horizontal and vertical momentum of mass and heat the mass and momentum evolution equations defined in the mohid model are as follows 1 u i x i 0 2 u i t u i u j x j f u j 1 ρ p a t m x i g η x i g ρ z η ρ x i d z x j v u i x j 3 p z ρ g where f x and ν represent the coriolis parameter a parallel line to the surface elevation and the turbulent viscosity respectively tracer properties such as temperature and salinity are calculated with the computed flow using 4 p t p u i x i x i v p x i s p where s p stands for sink sources of the property p in question 3 1 upscaling algorithm the algorithm described here and implemented in mohid model system is based on the work of oey and chen 1992 and fox and maskell 1995 where feedback from cd occurs in the overlapped area the variables included in the feedback procedure are velocity temperature salinity and any biogeochemical property required by the user surface elevation will be left to evolve freely our proposed timescale for the interaction between the interpolation from the pd to the cd is described in fig 1 we consider as in oneway nesting that the cd time step is a multiple of its pd and as such an iteration starts with the integration of the pd for one time step after a full time step the pd provides open boundary conditions for the cd which runs the same integration period feedback takes place next with the cd updating the pd variables across an overlapped area the proposed upscaling algorithm considers a relaxation of the pd to a cd solution across an overlapped area which can be the entire cd area if there is no separation between dynamic and feedback interface or a smaller area if the separation of interfaces is desired this separation is done by defining a number of cd cells which will not be considered in the feedback operation two different upscaling options have been implemented into the mohid code 1 a volume weighted average operator which considers the volume based weight of a given cd cell inside a pd cell this option has the advantage of faster calculations and easier code implementation 2 inverse weighted distance method which will give more importance to the cd cells closest to the pd property cells centre this option goes in the direction of debreu et al 2012 who proposed the use of a full weighting operator which gives more importance to cd cells closest to its respective pd cells as their work suggests without this option a sponge layer near the boundary will be needed to properly damp sub grid scale features in a twoway methodology mohid equations 2 and 4 for the pd will now become 5 u i t u i u j x j f u j 1 ρ p a t m x i g η x i g ρ z η ρ x i d z x j v u i x j 6 u i u i u i c d u i t d δ t 7 p t p u i x i x i v p x i s p 8 p p p c d p t d δ t where u i c d and p c d stand for the volume weighted average of the i velocity component and tracer property of the cd cells td stands for the relaxation period in seconds a considerable difference between the approach followed in this work and many of those mentioned in this article is the td value which will be set to a time frame of hours instead of a close multiple of the pd time step this option will avoid the accumulation of mass conservation errors to dangerous levels and thus create erroneous circulation patterns or even produce numerical errors in any case a schematic example with a geostrophic equilibrium was tested to analyse the problem of mass conservation and circulation when using the upscaling methodology under a low td 4 schematic case geostrophic equilibrium when two water masses of different density come into contact at the same depth a density front is created this process creates a perpendicular to the density front transport that would only stop when the heaviest water mass lost its lateral contact with the lighter water mass when the coriolis force is present this process ends when the pressure gradient at the front and the coriolis force are in equilibrium this process has an analytical solution when the reduced gravity equations are used combined with a null density gradient along the density front infinite depth and a constant coriolis frequency over the study domain with these assumptions the primitive equations become 9 v t v v y f u g h y 10 u t v u y f v 0 11 h t y h v 0 where h stands for the layer thickness even though there is no solution for the transient regime there is for the final solution when an equilibrium is met between coriolis and pressure forces 12 f u g h y the final equations can be consulted in cushman roisin 1994 chapter 13 2 or in mellor 1996 chapter 7 4 and are as follows 13 h h 1 e x r i r i 14 u g h 1 e x r i r i 15 r i g h f where ri is the rossby deformation radius and corresponds to the distance along the front from which the coriolis force equals the pressure force physically this process creates a surface elevation gradient towards the front that is eliminated due to the density gradient surface elevation η0 associated with the first baroclinic mode can be deduced by the oscillation of the interface η1 16 η 0 δ ρ ρ 0 η 1 1 δ ρ ρ 0 1 from equations 13 and 14 one can determine the kinetic and potential energies variation which are given by 17 δ p e 1 4 g h 2 r 18 δ k e 1 12 g h 2 r these equations demonstrate that only a third of the potential energy is converted to kinetic energy the rest will be transported out perpendicularly to the front by internal waves along the interface 4 1 model setup the 3d mohid water model was used to model this process and to study the impact of upscaling a cd into a pd for this three domains were created with a constant depth of 1000 m the first two domains make a nested system with a parent domain 150 150 km and 3 km grid step and its nested domain at its centre 80 80 km and 1 km grid step a separate domain reference solution with 150 150 km and 1 km grid step overlaps the entire parent domain and was created to compare results obtained with oneway downscaling against the twoway methodology presented here details of these implementations are presented in table 1 for the analytical setup a 150 150 km domain with 1000 m depth and h equal to 100 m was considered on both modelling and analytical setups a density gradient was created with a constant salinity of 36 for the two masses but 18 c density 1026 070 kg m 3 for the lighter water mass and 15 c density 1026 725 kg m 3 for the heavier water mass assuming a latitude of 38 the coriolis frequency is 9 10 5 s 1 which leads to a rossby deformation radius ri of 9 km and using equations 13 15 the thickness of the lighter water mass and velocity above the interface can be computed in order to create the two different water masses the 3d temperature field was initialized with a box method this box covered the southern half of the domains and the first 4 vertical layers until 100 m and a temperature of 18 c was set inside it the remaining domain cells were initialized at 15 c since it is necessary to run the model 5 days until the baroclinic force is fully active the simulation period used for this test were 11 days 4 2 results schemactic case internal waves produced during the geostrophic equilibrium associated with cartesian vertical coordinates produce numerical vertical diffusion and therefore contribute to a reduction of the density gradient on the first 100 m depth drawing part of the available kinetic energy from the top 100 m layer in the end a smaller surface velocity is expected when compared to the analytical solution furthermore horizontal numerical diffusion will lead to mixing near the interface these factors are responsible for a velocity diffusion near the interface where a less steep curve on the perpendicular direction of the front is expected when compared to the theoretical velocity to reduce the problem of horizontal diffusion higher grid resolutions can be used and its effect on nested domains is demonstrated in this section after 11 days of simulation a clear front is visible in all grid domains fig 2 however with the reference grid resolution of 1 km fig 2a this front is narrower than with a 3 km grid resolution fig 2b as a result of both its grid step and numerical diffusion in order to get a better representation of the geostrophic equilibrium in the 3 km grid an online coupling with the 1 km nested grid domain fig 2c was made and the upscaling step was added following the implementation described in table 1 with a 1 km grid reference domain fig 3 a better representation of the surface elevation curve is obtained as less diffusion occurs through the interface between water masses this steeper surface elevation gradient produces an equally steep velocity gradient figs 2a and 3 velocities near the interface of the two water masses fig 3 right reach their maximum of 0 36 m s 1 generated by a surface elevation pressure gradient fig 3 left the x velocity component as the flow moves towards the front increases rapidly near the interface but instead of decreasing rapidly to zero as shown by the analytical solution it exhibits a concave curve adding the contribution from its nested 1 km domain brought its results closer to the ones obtained by the single 1 km reference grid solution in the overlapped area between the 3 km and its 1 km nested domains figs 2c and 3 results also show that this narrowing of the water level occurred only in the overlapped area and the solution adjusted well after crossing the interface between the domains both in water level and velocity fig 2c this effect can also be observed on a specific transect perpendicular to the front at the surface and in the middle of the domain since the reference and the 3 km grid solutions diverge over time due to their different resolutions the displacement observed in the x component of the velocity over this transect increases over time an equal displacement value 1 km obtained with and without feedback confirms this hypothesis in regards to mass conservation both volume and temperature were affected although to a small degree by the feedback operation results show an increase in divergence of surface elevation and velocity between the 3 km grid and the reference solution fig 3 as a result of different grid step and diffusion when velocities and temperature fields are updated using the cd solution a divergence is expected caused mainly by the inherent open boundary error from a low resolution domain to a higher resolution domain the question is whether this error is significant enough to produce a future instability on the pd which in this particular case rises over time at a rate of 2 5 10 5 in comparison with the reference solution fig 4 however the divergence between the 3 km grid domain without feedback and the reference solution tends to stabilize near the end as a result the divergence between the 3 km grid domain with feedback decreases its rate of increase near the end of the simulation although with a linear growth the solution s volume and temperature mass divergence fig 4 is small enough to be an acceptable cost to achieve a better overall solution note that the feedback time decay used was purposely set high to study a strong coupling in real application downscaling systems this nudging time decay from pd to cd is in the order of one day to a week de pablo et al 2019 franz et al 2016 mateus et al 2012 pham et al 2016 as such this divergence is expected to become smaller in real applications 5 twoway nesting in tagus rofi located in southwest of portugal crossing lisbon and with a surface area of 320 km2 of which 40 is intertidal fortunato et al 2017 the tagus estuary is one of the largest estuaries in europe tides with an average amplitude of 2 4 m in the river mouth with the tidal range varying from 0 9 m to around 4 1 m during neap tides and spring tides respectively gameiro et al 2007 set it as mesotidal estuary the tagus river which is its main source of fresh water has a mean flow of 258 m3 s 1 measured by a hydrometric station upstream http snirh apambiente pt from 2006 to 2018 representing about 2 of the tidal prism however in this study flow values reach almost 9000 m3 s 1 as a result of an extreme high flow event a good scenario to test the ability of the twoway methodology to transfer information between a regional and a local domain the adjacent coastal area is affected not only by the river discharge but also by upwelling under north winds and by a mountain range to the west the joint effect of these features is responsible for the extremely dynamical circulation in this adjacent coastal area wind is predominantly from the nw quadrant leading to common upwelling events in the summer months more studies on the hydrodynamic features of the estuary can be found in canas et al 2009 dias et al 2013 fortunato et al 1999 franz et al 2014 leitão 2002 vaz et al 2015 5 1 model setup in this study the 3d mohid water model was used in a nested grid configuration in both oneway and twoway formulations and a comparison between them was performed in order to validate the proposed upscaling methodology the nested system is comprised of three domains fig 5 1 2d barotropic regional domain with 5 7 km constant grid resolution for the portuguese coast level1 33 5 n 49 9 n 1 0 w 13 5 w running only with tidal forcing from fes 2004 lefèvre et al 2002 lyard et al 2006 2 3d full baroclinic regional domain for the portuguese coast level2 34 4 n 45 0 n and 12 6 w 5 5 w with a grid resolution of 5 7 km and 50 vertical layers 7 sigma at the surface and 43 cartesian below 3 3d full baroclinic domain for the tagusrofi level3 and adjacent coastal area with a variable grid from 2 km to 200 m 38 15 n 39 2 n 10 w 8 9 w and 50 vertical layers 7 sigma at the surface and 43 cartesian below a full description of the first two domains running operationally oneway in maretec is available in mateus et al 2012 and a description of the tagusrofi domain oneway is described in campuzano et al 2012 initial conditions were not necessary as the system started from results of the operational systems the period from january to april 2013 was simulated corresponding to a period of high precipitation in portugal which lead to an extreme event de pablo et al 2019 in flow rate of the tagus river the main difference in oneway and twoway nesting implemented in this study is the added feedback operation from level3 to level2 domain level1 will not receive updates from level2 as its purpose is solely to provide surface elevation and barotropic velocity values at the open boundary of level2 the entire system was run online so a comparison with a twoway methodology could be made integrating the currently in place downscaling and the newly developed upscaling algorithm time steps for the 3 levels were 60 s 60 s and 6 s respectively which represents a time refinement factor of 10 for the last level level2 domain receives its lateral open boundary conditions from the 2d barotropic domain and the mercator ocean psy2v4 to cope with the absence of barotropic velocities in the mercator solution the 2d solution level1 is linearly superimposed on the mercator solution as proposed in leitão et al 2005 to this integrated solution a flather 1976 radiation scheme was applied at the open boundary followed by a flow relaxation scheme proposed by martinsen and engedahl 1987 to the mercator solution as described in leitão et al 2005 the flow relaxation scheme in this setup considers an exponential decreasing relaxation coefficient for the first 10 numerical cells of level2 starting with a value 105s in the first boundary cell and ending at the 10th cell with 109 s the rest of the domain is relaxed to the mercator solution with a coefficient of 109 s additionally a biharmonic filter of 5 5 109 m4s 1 is applied to reduce high frequency noise inside level2 domain level3 domain is forced solely by level2 at the lateral open boundary using a flather radiation scheme and nudging the solution with a flow relaxation scheme using the same 10 cells and a nudging coefficient varying from 900 s in the first cell to 109 s in the 10th in this regard we follow the suggestions of debreu and blayo 2008 and consider that open boundary conditions already in place for a oneway nesting can and should still be used in twoway nesting at the atmospheric boundary level2 was forced by the combination of two mesoscale model mm5 grell et al 1994 domains running in maretec one with 12 km resolution covering the west iberia region and a nested one with 9 km resolution for the portuguese coast level3 was forced with a weather research and forecasting wrf domain with 3 km grid resolution trancoso 2012 regarding freshwater inputs three main freshwater sources contributions were added tagus sorraia and trancão rivers the minor rivers trancão and sorraia were imposed using climatological values with river flow ranging between 3 and 60 m3 s 1 for sorraia river and between 1 and 9 m3 s 1 for trancão river for the tagus river water level was retrieved from almourol hydrometrical station https snirh apambiente pt and then a flow curve was used to extract the flow rate the simulated period included an extreme precipitation event which resulted in a flow rate for the tagus river of over 7500 m3 s 1 for over 72 h compared to an average flow rate of 258 m3 s 1 feedback was implemented between level3 and level2 using the volume weighted average technique and with a 900 s nudging coefficient equivalent to fifteen pd time steps in order to avoid the feedback of noise created near the boundary a separation of the dynamic and feedback interfaces was considered with 6 cd cells an equivalent of at least one pd cell as the grid step is variable from the boundary being ignored in the volume weighted average calculations a description of the implementation is summarized in table 2 5 2 results tagus rofi 5 2 1 water level validation water level obtained by the four model implementations was validated against the cascais tide gauge during the period between 11th of january and 13th of march 2013 fig 6 results obtained by either type of implementation oneway and twoway for levels2 and 3 have correlations above 0 99 demonstrating the model capacity to represent water level variability mean bias values vary between 1 7 mm on level2 and 4 1 mm on level3 both with a twoway implementation median values are more representative when extreme values occur and in this particular case for level2 it is double the height of the mean bias value but one third for level3 indicating more extreme overestimation bias values in level2 and the contrary for level3 a greater decrease from mean to median is observed for level3 in twoway becoming smaller than that of a oneway implementation the contrary was verified on the bias of level2 where some extreme values were corrected at the cost of a slight rise in median bias it is important to note however that these values are extremely small as well as the differences between model implementations applied onto the same grid domain in regards to correlation between model data and tide gauge data all implementations provided results with a pearson value superior to 0 99 indicating a good agreement with the tide gauge rmse values showed a higher variability between oneway and twoway implementations for level2 indicating a slight improvement of the results these results are in agreement with those obtained by de pablo et al 2019 and demonstrate both the ability of the mohid model to reproduce water level in a highly dynamic region and the small effect produced by the upscaling procedure presented in model performance 5 2 2 salinity validation modelled surface salinity was validated against ctd data obtained between march and april 2013 fig 7 in a moored station located near the mouth of the estuary comparisons between data and both oneway and twoway implementations shows that the model was able to properly reproduce salinity variation during this period of extreme flow rate additionally the model has the ability of filling the missing data gap in the first days of april caused by a submergence of the buoy during the peak flow which in this case points to a very low salinity of 1 at the mouth of the estuary modelled mean and median bias for oneway 2 04 and 1 98 respectively and twoway 2 05 and 1 99 respectively table 3 implementations confirm an overestimation of the surface salinity throughout the simulated period in regards to correlation and model performance pearson 0 89 and the nash 0 68 values table 3 indicate a good agreement with field data without any visible effect of the twoway over the oneway implementation on all statistical indicators these results demonstrate the importance of extreme flow rates from the tagus river flow at the mouth of the estuary which could explain the similarity between oneway and twoway formulations for that reason inter model comparisons were made to assess the impact of these formulation over the entire domain and with more detail near the lateral open boundary of levels2 and 3 although metrics for a point time series show the same performance for both implementations it is at the open lateral boundary that a difference in the salinity results can be observed as fig 8 shows the estuary plume reached the north and its influence was registered over 25 km north of the boundary although in the figure only the first 15 km are shown with differences in salinity in the order of 2 5 in contrast under a oneway downscaling the estuary plume abruptly stops at the boundary with level2 seen at 2 am of april the 5th which led to a more rapid shift towards the southwest during the following hours as well as smaller salinity plume this impact not only changes the solution but actively removes salinity from the entire nesting system although compensated later on by the flow relaxation scheme applied to the boundary of level2 by the mercator daily solution this impact can be seen for over 4 days fig 9 after the minimum value is reached in both domains near their shared boundary as such during this shift lower surface salinity produced under a twoway nesting entered through the northern boundary improving the overall solution provided by the modelling system a comparison between time series produced by level2 and level3 at pp and cp respectively shows that the tagus plume s impact near the ocean model boundary was felt for over 7 days furthermore this transport of salinity from level3 to level2 by feedback considerably reduced the curve steepness from april 5th to april 10th on cp as its boundary condition for salinity given by level2 had been corrected although less visible one can also see the feedback impact on the evolution of the salinity peaks in cp which are smaller than those produced under the oneway methodology this is a result of salinity transport into level2 which is then transported back into level3 when the currents shifted at a lower corrected by feedback value therefore the area between the two curves can be seen as the amount of salinity lost due to the oneway approach during this extreme event these results show the advantage that this twoway nudging method can have in a nested modelling system subject to intense freshwater inputs without impacting the system s performance including the capability of properly simulating the surface buoyant plume commonly observed along the portuguese coast peliz et al 2005 teles machado et al 2016 from a global perspective the results demonstrate that for the time period selected for this study applying the feedback operation does not have a tangible impact on performance near the mouth of the estuary as it is mainly dependent on the high freshwater input from the tagus river this is the reason why all statistical parameters shown in this paper did not change with the twoway methodology however this paper only tackled the horizontal surface fields whereas the vertical salinity and temperature structures could also be impacted 6 conclusion as consequence of constant evolution in computation power there has been an increase in demand for higher resolution model implementations for coastal areas however for models using structured grids and implicit methods this task can easily become overwhelming to tackle this issue a typical approach is to use oneway downscaling from regional to local areas with high bathymetry variability and where the most socio economic and ecological interests are located downscaling comes with a price in computation as the size of the child domain must be sufficient to avoid instabilities in the open boundary with the parent domain an alternative approach is to use a twoway nesting methodology allowing the child domain to update the parent domain in order to provide 3d mohid water model with a twoway methodology an upscaling algorithm was developed and implemented in the model by nudging the child domain into the parent domain over the overlapped area to validate the upscaling methodology implemented two tests were performed a schematic and a real case the upscaling methodology proposed was first validated using a schematic case with an analytical solution this analysis suggested that the improvement of the parent domain came at the expense of mass conservation a fact pointed out by several authors debreu et al 2012 haley and lermusiaux 2010 however this loss in mass conservation was small 2 5e 5 and 3 3e 4 for volume and temperature over an 11 day period respectively compared with the overall improvement of the parent domain once the methodology was validated a real case application for the pcoms and tagusrofi nested domains was tested under an extreme freshwater flow its main goal was to evaluate the differences between the traditional oneway downscaling and the newly developed twoway approach in regards to the transition between model domains at the open boundary validation with in situ data located near the estuary s mouth proved that the methodology does not produce any observable performance change in the tagusrofi domain in that particular area however a comparison at the open boundaries proved a significant change in salinity fields as the plume crossed the boundary between domains and as such provided a more realistic open boundary condition for the tagusrofi domain in this work as opposed to the most common approach a multiple of the parent domain time step the decay time set in the upscaling stage was 1 h which is considered in the literature to reduce problems related to mass conservation and model instabilities debreu and blayo 2008 palma and matano 1998 yin et al 2019 these results demonstrate the use of a twoway methodology for extreme event studies with durations of at least 3 months due to the open boundary improvement for a nested domain it is a first validation of the newly added upscaling capability in mohid water and is expected as has over time to evolve as users become aware and apply this algorithm to different locations under different conditions the use of this twoway methodology extends to coastal areas where these events are more frequent and or more intense as a result of either flash floods or monsoons however as the tagusrofi model domain represents such a small part of the pcoms model domain a more extended validation should be performed in order for it to be used in operational modelling for this case study the computational cost of using the twoway online coupling over a oneway coupling was not visible this is likely caused by the long simulation times observed on both methodologies average of 6 h with an openmp technique with only 2 processors together with a low impact feedback routine as a development priority for the mohid modelling system the authors have begun to work on this broader validation another advantage mentioned in this article is the possibility to reduce the size of a grid domain while keeping a good overall solution performance as future work this would empower modellers to use higher resolution nested domains with smaller losses in computational time without performance losses funding the present work was performed within the framework of the research projects coordinated atlantic coastal operational oceanographic observatory mycoast funded by the eu interreg atlantic area transnational cooperation programme www atlanticarea eu this work was supported by fct mctes piddac through project larsys fct pluriannual funding 2020 2023 uidb 50009 2020 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge the portuguese hydrographic institute ih for kindly providing data on the water level in the study area special thanks to paulo chambel from hidromod for his valuable suggestions during the conceptualization of the upscaling methodology 
25920,upscaling methodologies enforced on nested ocean modelling grids have become a subject of more intense research due to their benefits in modelling highly dynamic coastal areas in this paper an upscaling algorithm is developed for the 3d mohid water model enabling twoway implementations which considers the nudging of a child domain s velocities temperature and salinity fields by a parent domain the algorithm is validated for a schematic case and then applied to tagus region of freshwater influence tagusrofi portugal results for the schematic case show an improvement of the parent domain while generating minimal mass conservation loss tagusrofi model domains under twoway nesting improved the salinity transition between domain boundaries when reached by the estuarine plume this new 3d mohid water model feature improves the study of extreme scenarios where oneway downscaling produces discontinuities on the nested domain s open boundaries and enables the implementation of higher resolution domains with smaller size grids keywords upscaling 3d mohid model tagus twoway nesting estuarine plume 1 software the 3d mohid water model was first developed in 1985 and the current version is programmed in ansi fortran 95 using the object oriented philosophy the code size is 22 mb and is a free open access software developed and maintained in github https github com mohid water modelling system mohid more information on the software can be consulted in http mohid com 2 introduction increasing demand for high resolution model applications by government agencies aquaculture and energy companies is driving private and public entities to develop updated grid domains for coastal areas higher resolution nested grids lead to better numerical skills of the model and allow the use of more refined bathymetric and atmospheric data improving the overall hydrodynamic solution and reducing the errors of the downstream transport models this higher level of detail allows a direct comparison between very local field data e g currents and model results increasing the modelling system s confidence downscaling from a parent domain pd to a child domain cd is still the most common option to simulate the effect of large scale on local processes in the mohid water model campuzano et al 2015 2016 2016 fossati and piedra cueva 2013 franz et al 2014 2016 huhn et al 2012 janeiro et al 2017 and in many other structured grid models such as eco mars3d desmit et al 2018 mike3 gallego et al 2017 pom nagy et al 2017 nemo katavouta and thompson 2016 roms dabrowski et al 2014 and delft3d yin et al 2019 when using this methodology care must be taken to avoid drifting of the cd over time or instabilities will be produced at the border drifting can occur due to local features not reproduced by the parent domain noise created inside the child domain which is not kept under control and loss of mass conservation properties at the open boundary these issues are addressed in debreu and blayo 2008 flather 1976 and palma and matano 1998 where a number of solutions are provided to preserve mass conservation control noise at the open boundary and to smooth the transition between parent and child solutions the most common solutions for downscaling systems is the use of a flather 1976 boundary condition for the barotropic flow allied with a radiation scheme such as described in marchesiello et al 2001 and a flow relaxation scheme described by martinsen and engedahl 1987 another option commonly considered is the use of a biharmonic filter described by kantha and clayson 2000 that removes small wave length oscillations inside the child domain although it is more relevant in low dissipative environments to facilitate the performance of these techniques the boundary between nested domains should be far enough from local hydrodynamic features this way nested domains will produce comparable results in the interface allowing for easier radiation of outgoing waves and elimination of noise produced in the child domain oneway nested models assume that large scale processes affect local scale processes and enable the building of local solutions using global services e g copernicus or emodnet but not the other way around these web services provide solutions at ocean scale that are downscaled offline by regional and local models to provide services to coastal areas end users a way to fill this local information gap is to allow the cd which typically has local knowledge embedded to update the pd also known as the upscaling stage of a twoway nesting transferring results from smaller to larger scale reduces numerical diffusion in high gradient regions but also allows the modification of the large scale flow by local features as is the case of tidal jets at the mouth of large estuaries especially in tidal estuaries this provides stronger mixing of the water column changes the local coriolis effect on the pd improving its horizontal and vertical solution and changes the coastal transport different methodologies to implement twoway nesting have been proposed in the literature studies by urrego blanco et al 2016a 2014 used the semi prognostic method proposed by greatbatch et al 2004 which introduces a pressure correction term in the horizontal momentum equations marchesiello et al 2011 applied the roms agrif twoway capability debreu et al 2012 created for split explicit models which considers the feedback of surface elevation velocities and tracer properties and introduces a flux correction scheme berger and colella 1989 to enforce mass conservation at the interface between grid domains kelly et al 2016 studied tide dynamics using the fully implicit in time and space scheme developed by haley and lermusiaux 2010 in all of these methodologies the common approach is to relax although in the semi prognostic method it is not considered a typical relaxation the pd to its cd which has been considered to be the most successful option in transferring information from the local scale to the regional scale this option also has the advantage of using local measured data to improve the entire nesting system via feedback from the child domain in un structured grids a twoway system is easier to implement because the grids can be optimally nested as demonstrated by qi et al 2018 in their study the feedback was done only at the open boundary level which is possible due to the smooth transition between grid resolutions a review on the main methodologies for a twoway nesting system can be found in debreu et al 2008 conceptually transferring information from a cd to a pd in a multigrid system can be done in two ways 1 communication is done only at the interface between domains kurihara et al 1979 in which case there is no need to compute currents in the overlapped area and the feedback from the child domain is considered as an internal boundary condition 2 communication is done at the interface and the feedback is computed in the overlapped area however as the first technique forces the method to be coupled online and creates two boundary conditions leading to implementation complications the methodology selected for mohid model will follow the second technique fox and maskell 1995 oey and chen 1992 when a twoway nesting methodology is used another boundary issue arises caused by the parent domain update of physical variables from the child domain which are in turn dependent on the parent solution debreu and blayo 2008 in literature and due to this twoway communication the term interface has been divided in two terms regarding domain areas one for the traditional oneway information exchange dynamic interface and another for the update operation feedback interface in oneway nesting the dynamic interface typically occupies the first two numerical cells of the parent domain to allow 2nd order interpolations from the parent to the child domain on the other hand if noise is produced in the child domain it is expected to be heightened near the boundary with its parent domain this can lead to the propagation of a disturbance from the child domain into the parent domain in order to avoid such issues several authors barth et al 2005 debreu et al 2012 marchesiello et al 2011 sannino et al 2009 urrego blanco and sheng 2014 separated these two interfaces this interface separation although acting as a restraint on the feedback of noise into the parent domain may prevent a smooth transition between grids for that reason authors have suggested the use of sponge cells with artificially high viscosity on the child domain near the boundary in order to remove spurious flow oscillations barth et al 2007 debreu et al 2012 urrego blanco et al 2016b acosta et al 2015 did not separate these interfaces but used a flow relaxation scheme to account for the noise between domains also with good results the present study aims to develop an upscaling algorithm for the 3d mohid water model by nudging the cd into the pd across the overlapped area conceptually when the upscaling phase is integrated in an online modelling system a oneway coupling between grid domains becomes a twoway coupling this algorithm is first applied to a simple test case of a geostrophic equilibrium which has an analytical solution in order to assess not only the impact of the nested domain on its parent solution but also to quantify any mass conservation issues derived from transferring information from child to parent domain to this end a validation was made by comparison between surface elevation and surface velocity obtained by pd and cd under oneway and twoway formulations and the analytical solution also temperature and volume results obtained by the pc and the cd where compared to a reference solution for the second test case we selected a three month simulation period for the tagusrofi area portugal the modelling system includes a parent domain for the portuguese coast pcoms level2 and a nested child domain tagusrofi level3 this solution is then compared to the current oneway methodology for the same nesting system and validated against surface elevation and salinity data available for the period of january to april 2013 this twoway modelling methodology can be advantageous to any coastal area where strong gradients over extensive areas can occur these areas include estuaries rivers and their adjacent waters and cover not only salinity but also any water parameter with a strong gradient from fresh to salt water 3 materials and methods the mohid water model is a 3d finite volume model developed at maretec ist university of lisbon for arakawa c staggered grids which solves the 3d incompressible primitive equations leitão 2002 leitão et al 2005 martins et al 1998 2001 built and developed using an object oriented philosophy braunschweig et al 2004 hydrostatic equilibrium and boussinesq approximations are assumed temporal discretization is done using a semi implicit scheme alternating direction implicit adi with two time levels per iteration and the total varying diminishing tvd with a superbee limitation method is implemented for horizontal and vertical momentum of mass and heat the mass and momentum evolution equations defined in the mohid model are as follows 1 u i x i 0 2 u i t u i u j x j f u j 1 ρ p a t m x i g η x i g ρ z η ρ x i d z x j v u i x j 3 p z ρ g where f x and ν represent the coriolis parameter a parallel line to the surface elevation and the turbulent viscosity respectively tracer properties such as temperature and salinity are calculated with the computed flow using 4 p t p u i x i x i v p x i s p where s p stands for sink sources of the property p in question 3 1 upscaling algorithm the algorithm described here and implemented in mohid model system is based on the work of oey and chen 1992 and fox and maskell 1995 where feedback from cd occurs in the overlapped area the variables included in the feedback procedure are velocity temperature salinity and any biogeochemical property required by the user surface elevation will be left to evolve freely our proposed timescale for the interaction between the interpolation from the pd to the cd is described in fig 1 we consider as in oneway nesting that the cd time step is a multiple of its pd and as such an iteration starts with the integration of the pd for one time step after a full time step the pd provides open boundary conditions for the cd which runs the same integration period feedback takes place next with the cd updating the pd variables across an overlapped area the proposed upscaling algorithm considers a relaxation of the pd to a cd solution across an overlapped area which can be the entire cd area if there is no separation between dynamic and feedback interface or a smaller area if the separation of interfaces is desired this separation is done by defining a number of cd cells which will not be considered in the feedback operation two different upscaling options have been implemented into the mohid code 1 a volume weighted average operator which considers the volume based weight of a given cd cell inside a pd cell this option has the advantage of faster calculations and easier code implementation 2 inverse weighted distance method which will give more importance to the cd cells closest to the pd property cells centre this option goes in the direction of debreu et al 2012 who proposed the use of a full weighting operator which gives more importance to cd cells closest to its respective pd cells as their work suggests without this option a sponge layer near the boundary will be needed to properly damp sub grid scale features in a twoway methodology mohid equations 2 and 4 for the pd will now become 5 u i t u i u j x j f u j 1 ρ p a t m x i g η x i g ρ z η ρ x i d z x j v u i x j 6 u i u i u i c d u i t d δ t 7 p t p u i x i x i v p x i s p 8 p p p c d p t d δ t where u i c d and p c d stand for the volume weighted average of the i velocity component and tracer property of the cd cells td stands for the relaxation period in seconds a considerable difference between the approach followed in this work and many of those mentioned in this article is the td value which will be set to a time frame of hours instead of a close multiple of the pd time step this option will avoid the accumulation of mass conservation errors to dangerous levels and thus create erroneous circulation patterns or even produce numerical errors in any case a schematic example with a geostrophic equilibrium was tested to analyse the problem of mass conservation and circulation when using the upscaling methodology under a low td 4 schematic case geostrophic equilibrium when two water masses of different density come into contact at the same depth a density front is created this process creates a perpendicular to the density front transport that would only stop when the heaviest water mass lost its lateral contact with the lighter water mass when the coriolis force is present this process ends when the pressure gradient at the front and the coriolis force are in equilibrium this process has an analytical solution when the reduced gravity equations are used combined with a null density gradient along the density front infinite depth and a constant coriolis frequency over the study domain with these assumptions the primitive equations become 9 v t v v y f u g h y 10 u t v u y f v 0 11 h t y h v 0 where h stands for the layer thickness even though there is no solution for the transient regime there is for the final solution when an equilibrium is met between coriolis and pressure forces 12 f u g h y the final equations can be consulted in cushman roisin 1994 chapter 13 2 or in mellor 1996 chapter 7 4 and are as follows 13 h h 1 e x r i r i 14 u g h 1 e x r i r i 15 r i g h f where ri is the rossby deformation radius and corresponds to the distance along the front from which the coriolis force equals the pressure force physically this process creates a surface elevation gradient towards the front that is eliminated due to the density gradient surface elevation η0 associated with the first baroclinic mode can be deduced by the oscillation of the interface η1 16 η 0 δ ρ ρ 0 η 1 1 δ ρ ρ 0 1 from equations 13 and 14 one can determine the kinetic and potential energies variation which are given by 17 δ p e 1 4 g h 2 r 18 δ k e 1 12 g h 2 r these equations demonstrate that only a third of the potential energy is converted to kinetic energy the rest will be transported out perpendicularly to the front by internal waves along the interface 4 1 model setup the 3d mohid water model was used to model this process and to study the impact of upscaling a cd into a pd for this three domains were created with a constant depth of 1000 m the first two domains make a nested system with a parent domain 150 150 km and 3 km grid step and its nested domain at its centre 80 80 km and 1 km grid step a separate domain reference solution with 150 150 km and 1 km grid step overlaps the entire parent domain and was created to compare results obtained with oneway downscaling against the twoway methodology presented here details of these implementations are presented in table 1 for the analytical setup a 150 150 km domain with 1000 m depth and h equal to 100 m was considered on both modelling and analytical setups a density gradient was created with a constant salinity of 36 for the two masses but 18 c density 1026 070 kg m 3 for the lighter water mass and 15 c density 1026 725 kg m 3 for the heavier water mass assuming a latitude of 38 the coriolis frequency is 9 10 5 s 1 which leads to a rossby deformation radius ri of 9 km and using equations 13 15 the thickness of the lighter water mass and velocity above the interface can be computed in order to create the two different water masses the 3d temperature field was initialized with a box method this box covered the southern half of the domains and the first 4 vertical layers until 100 m and a temperature of 18 c was set inside it the remaining domain cells were initialized at 15 c since it is necessary to run the model 5 days until the baroclinic force is fully active the simulation period used for this test were 11 days 4 2 results schemactic case internal waves produced during the geostrophic equilibrium associated with cartesian vertical coordinates produce numerical vertical diffusion and therefore contribute to a reduction of the density gradient on the first 100 m depth drawing part of the available kinetic energy from the top 100 m layer in the end a smaller surface velocity is expected when compared to the analytical solution furthermore horizontal numerical diffusion will lead to mixing near the interface these factors are responsible for a velocity diffusion near the interface where a less steep curve on the perpendicular direction of the front is expected when compared to the theoretical velocity to reduce the problem of horizontal diffusion higher grid resolutions can be used and its effect on nested domains is demonstrated in this section after 11 days of simulation a clear front is visible in all grid domains fig 2 however with the reference grid resolution of 1 km fig 2a this front is narrower than with a 3 km grid resolution fig 2b as a result of both its grid step and numerical diffusion in order to get a better representation of the geostrophic equilibrium in the 3 km grid an online coupling with the 1 km nested grid domain fig 2c was made and the upscaling step was added following the implementation described in table 1 with a 1 km grid reference domain fig 3 a better representation of the surface elevation curve is obtained as less diffusion occurs through the interface between water masses this steeper surface elevation gradient produces an equally steep velocity gradient figs 2a and 3 velocities near the interface of the two water masses fig 3 right reach their maximum of 0 36 m s 1 generated by a surface elevation pressure gradient fig 3 left the x velocity component as the flow moves towards the front increases rapidly near the interface but instead of decreasing rapidly to zero as shown by the analytical solution it exhibits a concave curve adding the contribution from its nested 1 km domain brought its results closer to the ones obtained by the single 1 km reference grid solution in the overlapped area between the 3 km and its 1 km nested domains figs 2c and 3 results also show that this narrowing of the water level occurred only in the overlapped area and the solution adjusted well after crossing the interface between the domains both in water level and velocity fig 2c this effect can also be observed on a specific transect perpendicular to the front at the surface and in the middle of the domain since the reference and the 3 km grid solutions diverge over time due to their different resolutions the displacement observed in the x component of the velocity over this transect increases over time an equal displacement value 1 km obtained with and without feedback confirms this hypothesis in regards to mass conservation both volume and temperature were affected although to a small degree by the feedback operation results show an increase in divergence of surface elevation and velocity between the 3 km grid and the reference solution fig 3 as a result of different grid step and diffusion when velocities and temperature fields are updated using the cd solution a divergence is expected caused mainly by the inherent open boundary error from a low resolution domain to a higher resolution domain the question is whether this error is significant enough to produce a future instability on the pd which in this particular case rises over time at a rate of 2 5 10 5 in comparison with the reference solution fig 4 however the divergence between the 3 km grid domain without feedback and the reference solution tends to stabilize near the end as a result the divergence between the 3 km grid domain with feedback decreases its rate of increase near the end of the simulation although with a linear growth the solution s volume and temperature mass divergence fig 4 is small enough to be an acceptable cost to achieve a better overall solution note that the feedback time decay used was purposely set high to study a strong coupling in real application downscaling systems this nudging time decay from pd to cd is in the order of one day to a week de pablo et al 2019 franz et al 2016 mateus et al 2012 pham et al 2016 as such this divergence is expected to become smaller in real applications 5 twoway nesting in tagus rofi located in southwest of portugal crossing lisbon and with a surface area of 320 km2 of which 40 is intertidal fortunato et al 2017 the tagus estuary is one of the largest estuaries in europe tides with an average amplitude of 2 4 m in the river mouth with the tidal range varying from 0 9 m to around 4 1 m during neap tides and spring tides respectively gameiro et al 2007 set it as mesotidal estuary the tagus river which is its main source of fresh water has a mean flow of 258 m3 s 1 measured by a hydrometric station upstream http snirh apambiente pt from 2006 to 2018 representing about 2 of the tidal prism however in this study flow values reach almost 9000 m3 s 1 as a result of an extreme high flow event a good scenario to test the ability of the twoway methodology to transfer information between a regional and a local domain the adjacent coastal area is affected not only by the river discharge but also by upwelling under north winds and by a mountain range to the west the joint effect of these features is responsible for the extremely dynamical circulation in this adjacent coastal area wind is predominantly from the nw quadrant leading to common upwelling events in the summer months more studies on the hydrodynamic features of the estuary can be found in canas et al 2009 dias et al 2013 fortunato et al 1999 franz et al 2014 leitão 2002 vaz et al 2015 5 1 model setup in this study the 3d mohid water model was used in a nested grid configuration in both oneway and twoway formulations and a comparison between them was performed in order to validate the proposed upscaling methodology the nested system is comprised of three domains fig 5 1 2d barotropic regional domain with 5 7 km constant grid resolution for the portuguese coast level1 33 5 n 49 9 n 1 0 w 13 5 w running only with tidal forcing from fes 2004 lefèvre et al 2002 lyard et al 2006 2 3d full baroclinic regional domain for the portuguese coast level2 34 4 n 45 0 n and 12 6 w 5 5 w with a grid resolution of 5 7 km and 50 vertical layers 7 sigma at the surface and 43 cartesian below 3 3d full baroclinic domain for the tagusrofi level3 and adjacent coastal area with a variable grid from 2 km to 200 m 38 15 n 39 2 n 10 w 8 9 w and 50 vertical layers 7 sigma at the surface and 43 cartesian below a full description of the first two domains running operationally oneway in maretec is available in mateus et al 2012 and a description of the tagusrofi domain oneway is described in campuzano et al 2012 initial conditions were not necessary as the system started from results of the operational systems the period from january to april 2013 was simulated corresponding to a period of high precipitation in portugal which lead to an extreme event de pablo et al 2019 in flow rate of the tagus river the main difference in oneway and twoway nesting implemented in this study is the added feedback operation from level3 to level2 domain level1 will not receive updates from level2 as its purpose is solely to provide surface elevation and barotropic velocity values at the open boundary of level2 the entire system was run online so a comparison with a twoway methodology could be made integrating the currently in place downscaling and the newly developed upscaling algorithm time steps for the 3 levels were 60 s 60 s and 6 s respectively which represents a time refinement factor of 10 for the last level level2 domain receives its lateral open boundary conditions from the 2d barotropic domain and the mercator ocean psy2v4 to cope with the absence of barotropic velocities in the mercator solution the 2d solution level1 is linearly superimposed on the mercator solution as proposed in leitão et al 2005 to this integrated solution a flather 1976 radiation scheme was applied at the open boundary followed by a flow relaxation scheme proposed by martinsen and engedahl 1987 to the mercator solution as described in leitão et al 2005 the flow relaxation scheme in this setup considers an exponential decreasing relaxation coefficient for the first 10 numerical cells of level2 starting with a value 105s in the first boundary cell and ending at the 10th cell with 109 s the rest of the domain is relaxed to the mercator solution with a coefficient of 109 s additionally a biharmonic filter of 5 5 109 m4s 1 is applied to reduce high frequency noise inside level2 domain level3 domain is forced solely by level2 at the lateral open boundary using a flather radiation scheme and nudging the solution with a flow relaxation scheme using the same 10 cells and a nudging coefficient varying from 900 s in the first cell to 109 s in the 10th in this regard we follow the suggestions of debreu and blayo 2008 and consider that open boundary conditions already in place for a oneway nesting can and should still be used in twoway nesting at the atmospheric boundary level2 was forced by the combination of two mesoscale model mm5 grell et al 1994 domains running in maretec one with 12 km resolution covering the west iberia region and a nested one with 9 km resolution for the portuguese coast level3 was forced with a weather research and forecasting wrf domain with 3 km grid resolution trancoso 2012 regarding freshwater inputs three main freshwater sources contributions were added tagus sorraia and trancão rivers the minor rivers trancão and sorraia were imposed using climatological values with river flow ranging between 3 and 60 m3 s 1 for sorraia river and between 1 and 9 m3 s 1 for trancão river for the tagus river water level was retrieved from almourol hydrometrical station https snirh apambiente pt and then a flow curve was used to extract the flow rate the simulated period included an extreme precipitation event which resulted in a flow rate for the tagus river of over 7500 m3 s 1 for over 72 h compared to an average flow rate of 258 m3 s 1 feedback was implemented between level3 and level2 using the volume weighted average technique and with a 900 s nudging coefficient equivalent to fifteen pd time steps in order to avoid the feedback of noise created near the boundary a separation of the dynamic and feedback interfaces was considered with 6 cd cells an equivalent of at least one pd cell as the grid step is variable from the boundary being ignored in the volume weighted average calculations a description of the implementation is summarized in table 2 5 2 results tagus rofi 5 2 1 water level validation water level obtained by the four model implementations was validated against the cascais tide gauge during the period between 11th of january and 13th of march 2013 fig 6 results obtained by either type of implementation oneway and twoway for levels2 and 3 have correlations above 0 99 demonstrating the model capacity to represent water level variability mean bias values vary between 1 7 mm on level2 and 4 1 mm on level3 both with a twoway implementation median values are more representative when extreme values occur and in this particular case for level2 it is double the height of the mean bias value but one third for level3 indicating more extreme overestimation bias values in level2 and the contrary for level3 a greater decrease from mean to median is observed for level3 in twoway becoming smaller than that of a oneway implementation the contrary was verified on the bias of level2 where some extreme values were corrected at the cost of a slight rise in median bias it is important to note however that these values are extremely small as well as the differences between model implementations applied onto the same grid domain in regards to correlation between model data and tide gauge data all implementations provided results with a pearson value superior to 0 99 indicating a good agreement with the tide gauge rmse values showed a higher variability between oneway and twoway implementations for level2 indicating a slight improvement of the results these results are in agreement with those obtained by de pablo et al 2019 and demonstrate both the ability of the mohid model to reproduce water level in a highly dynamic region and the small effect produced by the upscaling procedure presented in model performance 5 2 2 salinity validation modelled surface salinity was validated against ctd data obtained between march and april 2013 fig 7 in a moored station located near the mouth of the estuary comparisons between data and both oneway and twoway implementations shows that the model was able to properly reproduce salinity variation during this period of extreme flow rate additionally the model has the ability of filling the missing data gap in the first days of april caused by a submergence of the buoy during the peak flow which in this case points to a very low salinity of 1 at the mouth of the estuary modelled mean and median bias for oneway 2 04 and 1 98 respectively and twoway 2 05 and 1 99 respectively table 3 implementations confirm an overestimation of the surface salinity throughout the simulated period in regards to correlation and model performance pearson 0 89 and the nash 0 68 values table 3 indicate a good agreement with field data without any visible effect of the twoway over the oneway implementation on all statistical indicators these results demonstrate the importance of extreme flow rates from the tagus river flow at the mouth of the estuary which could explain the similarity between oneway and twoway formulations for that reason inter model comparisons were made to assess the impact of these formulation over the entire domain and with more detail near the lateral open boundary of levels2 and 3 although metrics for a point time series show the same performance for both implementations it is at the open lateral boundary that a difference in the salinity results can be observed as fig 8 shows the estuary plume reached the north and its influence was registered over 25 km north of the boundary although in the figure only the first 15 km are shown with differences in salinity in the order of 2 5 in contrast under a oneway downscaling the estuary plume abruptly stops at the boundary with level2 seen at 2 am of april the 5th which led to a more rapid shift towards the southwest during the following hours as well as smaller salinity plume this impact not only changes the solution but actively removes salinity from the entire nesting system although compensated later on by the flow relaxation scheme applied to the boundary of level2 by the mercator daily solution this impact can be seen for over 4 days fig 9 after the minimum value is reached in both domains near their shared boundary as such during this shift lower surface salinity produced under a twoway nesting entered through the northern boundary improving the overall solution provided by the modelling system a comparison between time series produced by level2 and level3 at pp and cp respectively shows that the tagus plume s impact near the ocean model boundary was felt for over 7 days furthermore this transport of salinity from level3 to level2 by feedback considerably reduced the curve steepness from april 5th to april 10th on cp as its boundary condition for salinity given by level2 had been corrected although less visible one can also see the feedback impact on the evolution of the salinity peaks in cp which are smaller than those produced under the oneway methodology this is a result of salinity transport into level2 which is then transported back into level3 when the currents shifted at a lower corrected by feedback value therefore the area between the two curves can be seen as the amount of salinity lost due to the oneway approach during this extreme event these results show the advantage that this twoway nudging method can have in a nested modelling system subject to intense freshwater inputs without impacting the system s performance including the capability of properly simulating the surface buoyant plume commonly observed along the portuguese coast peliz et al 2005 teles machado et al 2016 from a global perspective the results demonstrate that for the time period selected for this study applying the feedback operation does not have a tangible impact on performance near the mouth of the estuary as it is mainly dependent on the high freshwater input from the tagus river this is the reason why all statistical parameters shown in this paper did not change with the twoway methodology however this paper only tackled the horizontal surface fields whereas the vertical salinity and temperature structures could also be impacted 6 conclusion as consequence of constant evolution in computation power there has been an increase in demand for higher resolution model implementations for coastal areas however for models using structured grids and implicit methods this task can easily become overwhelming to tackle this issue a typical approach is to use oneway downscaling from regional to local areas with high bathymetry variability and where the most socio economic and ecological interests are located downscaling comes with a price in computation as the size of the child domain must be sufficient to avoid instabilities in the open boundary with the parent domain an alternative approach is to use a twoway nesting methodology allowing the child domain to update the parent domain in order to provide 3d mohid water model with a twoway methodology an upscaling algorithm was developed and implemented in the model by nudging the child domain into the parent domain over the overlapped area to validate the upscaling methodology implemented two tests were performed a schematic and a real case the upscaling methodology proposed was first validated using a schematic case with an analytical solution this analysis suggested that the improvement of the parent domain came at the expense of mass conservation a fact pointed out by several authors debreu et al 2012 haley and lermusiaux 2010 however this loss in mass conservation was small 2 5e 5 and 3 3e 4 for volume and temperature over an 11 day period respectively compared with the overall improvement of the parent domain once the methodology was validated a real case application for the pcoms and tagusrofi nested domains was tested under an extreme freshwater flow its main goal was to evaluate the differences between the traditional oneway downscaling and the newly developed twoway approach in regards to the transition between model domains at the open boundary validation with in situ data located near the estuary s mouth proved that the methodology does not produce any observable performance change in the tagusrofi domain in that particular area however a comparison at the open boundaries proved a significant change in salinity fields as the plume crossed the boundary between domains and as such provided a more realistic open boundary condition for the tagusrofi domain in this work as opposed to the most common approach a multiple of the parent domain time step the decay time set in the upscaling stage was 1 h which is considered in the literature to reduce problems related to mass conservation and model instabilities debreu and blayo 2008 palma and matano 1998 yin et al 2019 these results demonstrate the use of a twoway methodology for extreme event studies with durations of at least 3 months due to the open boundary improvement for a nested domain it is a first validation of the newly added upscaling capability in mohid water and is expected as has over time to evolve as users become aware and apply this algorithm to different locations under different conditions the use of this twoway methodology extends to coastal areas where these events are more frequent and or more intense as a result of either flash floods or monsoons however as the tagusrofi model domain represents such a small part of the pcoms model domain a more extended validation should be performed in order for it to be used in operational modelling for this case study the computational cost of using the twoway online coupling over a oneway coupling was not visible this is likely caused by the long simulation times observed on both methodologies average of 6 h with an openmp technique with only 2 processors together with a low impact feedback routine as a development priority for the mohid modelling system the authors have begun to work on this broader validation another advantage mentioned in this article is the possibility to reduce the size of a grid domain while keeping a good overall solution performance as future work this would empower modellers to use higher resolution nested domains with smaller losses in computational time without performance losses funding the present work was performed within the framework of the research projects coordinated atlantic coastal operational oceanographic observatory mycoast funded by the eu interreg atlantic area transnational cooperation programme www atlanticarea eu this work was supported by fct mctes piddac through project larsys fct pluriannual funding 2020 2023 uidb 50009 2020 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to acknowledge the portuguese hydrographic institute ih for kindly providing data on the water level in the study area special thanks to paulo chambel from hidromod for his valuable suggestions during the conceptualization of the upscaling methodology 
25921,the actual use of models and decision tools for real world reservoir operations is limited due to the gap between the models tools and the real world practices tedious amount of work in case by case model developments and computational difficulty of running complex numerical models this paper presents generic diagnostic reservoir operation tools drot the tools are developed based on generic properties derived from analytical optimization studies and data mining procedures instead of establishing a numerical model drot users can apply particular properties and or procedures to diagnose a specific reservoir operation problem by just providing required inputs drot is available online and also provides auxiliary tools such as a data retrieval tool and a data visualization tool drot provides an open software framework that can include additional generic tools of models algorithms and functions drot can be used by reservoir operators researchers and students to obtain diagnostic information for the operation of a reservoir keywords reservoir operation model decision support system generic diagnostic tool web based tool 1 introduction the need for streamflow regulation prompted extensive construction of dams globally during the 20th century as a result there are over 45 000 dams above 15 m high around the world with a total capacity of more than 6500 k m 3 and more than half of large river systems draining 54 of the world s lands are regulated nilsson et al 2005 streamflow is regulated to meet the needs of human society such as water supply flood control hydropower generation recreation and navigation thus it is important to provide reliable and timely support for reservoir operation in order to meet the operation objectives especially under changing water demand from the human society and changing water availability caused by global warming biemans et al 2011 this importance has stimulated long term extensive studies on reservoir operation in particular numerous numerical models and decision support systems dsss have been developed around the world yeh 1985 wurbs 1993 labadie 2004 lund et al 2017 however there are two outstanding issues along with those studies first the gap between the research developments and real world reservoir operation practices which ends with limited use of the aforementioned models dsss simonovic 1992 labadie 2004 hejazi and cai 2011 brown et al 2015 second the need of commonly accepted generic tools to mitigate tedious amount of work in case by case tool developments for specific reservoirs in this paper we address these issues by developing generic diagnostic reservoir operation tools drot taking advantage of relevant published studies that provide generic principles and or methods for various reservoir operation problems the gaps between reservoir operation research and applications are reflected in multiple aspects including limited applications of complex optimization models such as the optimization of a system of reservoirs over a long study period technical and institutional obstacles to the adoption of mid to long range inflow forecasts and insufficient use of widely observed operation records to better support real world reservoir operation practices while there is continuing progress on the development of advanced optimization models real world reservoir operation practices usually rely more on conventional operation rule curves simulation models or simple linear programming models koutsoyiannis et al 2002 labadie 2004 jahanpour et al 2014 researchers including karamouz et al 2005 and labadie 2004 attributed this situation to low confidence in optimization models developed based on simplified physical processes and systems high model complexity ending with difficulties in comprehending and using the models low flexibility that requires significant efforts for model development and customization for different reservoirs etc using inflow forecasts can improve the operation practices but the actual use of streamflow forecasts to support real world operation problems still faces a number of obstacles rayner et al 2005 whateley et al 2015 despite of research and institutional efforts such as the integrated forecast and reservoir management inform georgakakos et al 2007 and forecast informed reservoir operations firo jasperse et al 2017 and advances in forecasting skills whateley et al 2015 the obstacles include insufficient forecast skills complexities trialability observability of forecast adoption the efforts needed to modify existing models to adopt forecast information as well as institutional and political resistance rayner et al 2005 whateley et al 2015 beyond the extensive modeling work with widely observed historical records and ever growing data availability under the rapid growth of new techniques such as remote sensing based monitoring gao et al 2012 data of reservoir operations are now attracting more attention than before however these data can hardly be used to support real world operations without a ready to use platform a number of studies have used data mining techniques to either understand real world reservoir operations e g hejazi et al 2008 hejazi and cai 2009 and giuliani and herman 2018 or derive models for simulating real world operation decisions e g shrestha et al 1996 corani et al 2009 yang et al 2016 and coerver et al 2018 given near one century of reservoir operation practices abundant records including reservoir inflow storage and release for numerous reservoirs in the united states and other countries allow us to understand the actual operation rules and identify possible improvements of the real world practices in particular through better understanding real world reservoir operations the operations can be better supported through either developing more realistic optimization models hejazi and cai 2011 or building more realistic reservoir simulation components into hydrological simulation models wu et al 2020 long term historical data are especially important for decision analysis under changing climate and nonstationary hydrological conditions milly et al 2008 tetzlaff et al 2017 however accessing and integrating the historical reservoir operation data from multiple sources is challenging due to their inconsistent formats and different data query rules ames et al 2012 national academies of sciences engineering and medicine 2018 and a data retrieval tool as a component of a reservoir operation decision support system will help reduce users data collection work in summary the closure of these gaps between research and applications requires the development of accessible flexible and easy to use tools that help illustrating the advantages of new techniques reducing the complexity for using the techniques and making problem diagnosis accessible to real world reservoir operators which will subsequently prompt the adoption of the research developments a review of recent progress in reservoir operation cannot omit the applications of dsss developing dsss has been a considerable effort to use models and data to support real world reservoir operations since the 1980s a number of efforts have been made to develop dsss as generic tools for reservoir system operation decision support these tools allow users to customize reservoir system configurations such as system structures operational objectives and constraints for different reservoir systems and solve the customized problem using prescribed simulation or optimization models many of those tools are incorporated in the dsss primarily developed for basin wide water resources planning and management e g riverware eschenbach et al 2002 zagona et al 2001 modsim labadie 2006 calsim draper et al 2004 hec ressim us army corps of engineers hydrologic engineering center 2007 and raven craig et al 2020 these dsss simulate the operation of reservoirs based on user defined operation rules such as prioritized operation goals e g riverware zone based prioritized operation rules e g hec ressim combined use of prioritized demands and user defined operation rules e g modsim and calsim and time dependent reservoir operation rules e g raven among these ddss modsim calsim hec ressim and raven use simulation models which have limited capability of seeking optimal operation decisions or policies though calsim and modsim use optimization models to support the search of prioritized water supply to the various demands at each time step riverware uses preemptive linear goal programming method which is not flexible in analyzing tradeoffs among the multiple goals besides jahanpour et al 2014 and koutsoyiannis et al 2002 developed generic dsss based on simulation optimization models to optimize the parameters of parametric reservoir operation rules with respect to specific reservoir operation objective s via genetic algorithm ga jahanpour et al 2014 and nonlinear programming solvers koutsoyiannis 2002 most recently seifollahi aghmiuni and bozorg haddad 2019 developed a reservoir operation decision support tool that provides multiple functions including simulation based on various operation rules reservoir design optimization release decision optimization and parametric rule optimization the optimization problems are solved with the comprehensive evolutionary algorithm cea in summary these dsss can help users set up a ready to use simulation and or optimization model with necessary input data and provide a solver or algorithm to solve the model however these dsss are still subject to the fundamental challenges in applying numerical models especially optimization models to real world reservoir operations simple models are not sufficient to represent the complexity of the real world reservoir systems while complex models e g multiple reservoir systems with a long study horizon face the difficulty of computation labadie 2004 moreover due to the difficulty in generic model customization most of the dsss developed are case specific some of those adopted simulation models e g karbowski 1991 huang and yang 1999 stein et al 2001 cheng and chau 2004 ahmad and simonovic 2006 etc while others adopted optimization models e g huang 1996 shawwash et al 1999 karamouz et al 2000 karamouz et al 2005 alemu et al 2011 zeng et al 2012 and ahmad and hossain 2019 site specific ddss are usually sufficiently complex for a particular reservoir by including multiple components such as hydrological simulation and prediction data acquisition optional operation rule selection as well as customized graphical user interfaces gui despite the acceptable performance of a site specific dds for an individual reservoir system the high development cost imposed by sophisticated system structures and high customization requirements impede the extension of the dsss to other reservoir systems compared to existing generic tools as listed above for reservoir operation the diagnostic reservoir operation tools drot are unique in the following aspects first instead of relying on numerical simulation and or optimization models drot adopts recent analytical studies on reservoir operation optimization which by nature are generic for any reservoir with a specific function s such as water supply flooding control hydropower generation etc methods derived from analytical models can be applied to any reservoir without computational issues the results can be used to diagnose the existing operations in terms of possible improvements e g zhao et al 2020 show insights on tradeoffs between multiple operation objectives e g ding et al 2017 and provide guidelines to use forecasts more effectively e g zhao et al 2019 second drot provides ready to use data mining tools to extract reservoir operation rules and patterns from historical inflow storage and release records e g hejazi et al 2008 hejazi and cai 2009 the derived real world reservoir operation behaviors can be used to construct more realistic numerical models for reservoir operation simulation and or optimization hejazi and cai 2011 furthermore drot a web based online tool makes use of web techniques to improve its usability and accessibility ahmad and hossain 2019 and provides a gui and auxiliary functions which allow users to process access data via multiple ways users can either upload data from their own sources or retrieve data from online data sources via the data acquisition functions drot also provides data visualization functions to facilitate users to visualize both input and output data this paper aims at developing a platform to transform the general properties and models of reservoir operation optimization and procedures for analysis which exist in published papers into generic tools that are available online for users to obtain diagnostic information on the operation of a particular reservoir in a timely manner although an overview of the published studies of which the outputs are adopted in this paper are provided the details of the theories methods and procedures behind the tools of drot should be referred to those publications reviewed in the background section in the rest of this paper the background of the tools provided by a number of published studies will first be reviewed following that the software design will be described and the applications of drot will be demonstrated via some examples finally the future works of drot will be discussed readers are encouraged to navigate through the drot website www drotreservoir net where some in depth descriptions of each tool in drot and examples to test the tools are provided 2 background all tools currently included in drot are based on published studies as summarized in table 1 each of which is introduced briefly in this section this section does not intend to provide a comprehensive overview of reservoir operation models and tools that cover all types of reservoir operation problems but rather to provide the necessary background for the tools incorporated in drot and their demonstration examples thus the review focuses on a number of analytical studies and data mining studies on reservoir operation the reviewed studies cover several reservoir operation problems such as optimal operation of a single or a system of reservoirs for water supply multi objective operation problem that considers both water conservation and flood control objectives analysis of forecasts for real time operation and identification of reservoir operation decision factors using historical operation records 2 1 analytical studies on optimal operation decisions with single or multiple objectives among published studies on reservoir operations many present a generic optimization model for one or multiple functions e g water supply or both water supply and flooding control and derive closed form equations or computational procedures algorithms from the optimization conditions these studies then provide a method to develop generic tools for analyzing the optimal operation of certain types of reservoirs as reviewed in the following calculating reservoir release and carryover storage using closed form equations derived from hedging rules shiau 2011 formulated a two stage model to optimize hedging rules of reservoir operation which determines the release for the current stage and the carryover storage at the end of the current stage for future water use a weight is given to each of the two stages which reflects reservoir operators priority on the current water supply objective and water shortage risk reduction in the future a loss due to the deficit to the current or future demand is defined as an exponential function with one exponent parameter that describes the shape i e convexity of the loss function with a stage by stage rolling horizon approach optimal release for the entire study period over multiple stages e g week or month and carryover storage are calculated by the closed form equations derived from the optimization model the impact of hedging can be further explored with various weighting factors representing operators behavior and different loss functions representing the operation objectives and the performance of the optimal hedging rule can be assessed with respect to water shortage indices as demonstrated in the case study of shiau 2011 determining hedging rules for a single reservoir over multiple stages zhao et al 2019 formulated the optimal operation of a single reservoir over a number of stages as a multi stage nonlinear programming model that maximizes a concave water supply benefit function over the entire study period subject to mass balance constraints non negative storage constraints storage capacity constraints and non negative spill constraints the optimal release decisions of the reservoir at each stage are determined numerically following the derived the optimality conditions under a given deterministic inflow scenario both shiau 2011 and zhao et al 2019 solve optimal release decisions for the operation of a single water supply reservoir zhao et al 2019 obtains the global optimal solution over the entire study period i e with n stages while shiau 2011 approximates the n stage optimization problem into a series of two stage the current and the future problems and solves them using a moving window approach thus zhao et al 2019 can be used for a planning purpose and shiau 2011 for real time operation in addition both studies can be applied to historical reservoir inflow records to solve for the optimal solutions and the results can be compared with the actual operation and or the operation under the standard operation policy sop this comparison can shed light on the impact of hedging and provide guidelines to assist reservoir operators to improve the existing operations an algorithm based on derived operation rules to solve for optimal operations of a system of reservoirs in parallel zhao et al 2020 formulated the operation of a system of reservoirs in parallel with a single joint demand as a multi stage nonlinear programming model the model maximizes the total benefits over the entire study period subject to mass balance constraints non negative storage constraints storage capacity constraints and non negative spill constraints to derive the necessary and sufficient conditions for an optimal solution they assumed that the water supply benefit at each stage was a nonlinear concave function of the total release from all reservoirs the proposed algorithm solves the system level release at each stage and identifies stages with full empty ending storages and those with no release under the optimal solution a complete time series of releases for each of the reservoirs can be obtained with multiple options that satisfy the optimality conditions the proposed algorithm effectively reduces the computational complexity for solving the optimal operation decision for such reservoir systems as demonstrated through a case study in zhao et al 2020 the results of the algorithm identify the optimal conditions for the system level operation which can be used as a reference for real world operations or for examining historical operations multi objective hedging rules for tradeoff analysis between flood control and water conservation ding et al 2017 addressed the flood water conservation problem via a two stage optimization model i e water is conserved during the flood season at a possible cost of additional future flood risk which can be applied to real world operation using a rolling horizon approach the tradeoffs between water conservation and flood control are analyzed under the combined impacts of the decision preference represented by the relative weights specified for the flood control and water conservation objectives and the level of forecast uncertainty represented by the standard deviation of inflow forecast error for example when the forecast uncertainty is above a certain level the flood risk is high and the water conservation objective should not be considered the implemented results provide decision makers information such as whether or not tradeoff exists between the two objectives under given uncertainty and preference levels the minimum level of priority from the reservoir managers for water conservation to have some amount of water conservation or the maximum allowed uncertainty level of inflow forecast to make flood water conservation feasible the critical values are calculated following the optimality conditions derived from the optimization model also different combinations of the parameters can be tested to explore the impacts of water conservation priority and forecast uncertainty levels on the tradeoffs between the two objectives as a summary all the four studies reviewed above i e shiau 2011 zhao et al 2019 2020 and ding et al 2017 provided general properties or algorithms for generic reservoir optimization models for water supply specifically ding et al 2017 provided the procedures to determine the threshold inflow uncertainty and operation preferences i e the weighting factor required for floodwater conservation shiau 2011 derived closed form equations to calculate releases zhao et al 2019 2020 and ding et al 2017 provided algorithms computational procedures following the nonlinear programming nlp optimality conditions to solve the optimization models drot converts all these studies into tools that are based on the derived equations or algorithms to calculate reservoir releases and carryover storages drot users do not need to set up and run a primary optimization model but just specify the required inputs for the tools and run them with significantly reduced computational cost following the primary studies drot results provide meaningful insights on the optimization of reservoir operation problems e g marginal values of resources binding or nonbinding constraints trade offs between competing objectives impacts of forecast uncertainties on optimal operation decisions impacts of different hedging policies on optimal operation decisions etc 2 2 effective use of reservoir inflow forecasts adoption of inflow forecasts for various reservoir operation problems has been an important research issue given its limited use in reservoir operation practices hejazi et al 2009 whateley et al 2015 generic tools to analyze some well recognized problems with forecasts such as forecast uncertainty and forecast horizon will be useful for reservoir operation communities as shown by the studies reviewed below with an attempt to support better use of forecasts for real time operations determining effective inflow forecast horizon for reservoir operation to make forecasts more effectively used in real world reservoir operations one has to determine how far ahead forecasts should be used for decision making i e an appropriate forecast horizon for making optimal reservoir operation decisions the complexity to determine an effective forecast horizon efh lies with the observation that forecast uncertainty usually grows with the forecast horizon zhao et al 2011 to solve this problem zhao et al 2019 developed procedures to estimate efh and the longest forecast horizon lfh for the operation of a single water supply reservoir with a concave water use benefit function the lfh represents the forecast length that provides the maximum information for decision making i e only forecast information within the lfh is useful for decision making and information beyond the lfh does not influence current release decisions and the efh represents the forecast length at which the influence of forecast uncertainty is controlled under a prescribed acceptable level these forecast horizons inform reservoir operators in terms of an appropriate length of the forecast to use for optimal reservoir operation users can also test different efhs under different maximum acceptable uncertainty levels determining the threshold uncertainty level for a useful forecast specially for flooding water conservation a forecast of the next coming flood event is used in ding et al 2017 to assess flooding risk and the potential of flood water conservation given a prescribed acceptable flooding risk ding et al 2017 estimated the critical or threshold value of the forecast uncertainty level beyond which the flooding risk is higher than the acceptable level and the water conservation objective should not be considered in other word flood water conservation is possible only if the flooding forecast is accurate enough so that the uncertainty is below the determined threshold 2 3 data mining applications on reservoir operation more recent studies have been conducted to discover reservoir operation rules and decision factors e g yang et al 2016 coerver et al 2018 mason et al 2018 giuliani and herman 2018 which enables some generic tools that can be applied to analyzing reservoir operations using long term reservoir inflow storage and release data as an instance one of the early such studies hejazi et al 2009 is reviewed as follows input variable selection for water resources systems using a modified minimum redundancy maximum relevance mmrmr algorithm hejazi et al 2009 developed a data mining method for input variable selection i e mmrmr and applied the method to determine the most relevant input variables that influence the actual release decision for reservoir operation the proposed algorithm was tested using the historical reservoir operation records from 22 reservoirs in california to select input variables from 121 potential alternatives for making release decisions with the mmrmr algorithm the most relevant input variables are iteratively selected from a set of potential alternatives such as current inflow past inflow inflow forecast and storage the iterative selection process stops until any additional input variable cannot further explain the output variable i e the release the selected input variables including the relevant inputs and state variables can inform reservoir operators of the factors to be considered for the operation of a reservoir beyond the regular operation considerations such as inflow conditions moreover the results can be used to improve model accuracy for predicting reservoir operation decisions with a minimum increase of model complexity through adopting the selected variables into a dynamic programming model a more realistic reservoir operation decision scheme can be represented in reservoir optimization models which can provide more realistic optimal solutions for real world reservoir operations hejazi and cai 2011 3 drot software design drot is designed as a web based platform which provides a set of tools developed based on the studies listed in section 2 the principles for the drot development as stated in the introduction lie with realizing generic tools based on published studies which are supported by data access visualization and data mining functions the realized generic tools allow users to analyze and diagnose particular reservoir operation problems with provision of insights on an optimization problem and with tractable computation complexity without setting up and running a numerical algorithm to solve the optimization model this section describes the implementation of the platform including the software features the architecture and the workflow for using the tools 3 1 features of drot the current version of drot is composed of four sets of tools optimization tools based on analytical rules data mining data retrieval and data visualization tools fig 1 the major functions and tools of drot take advantage of the existing publications while shielding the complex modeling details but only requesting necessary model inputs and allowing users to obtain diagnostic information for actual operations as illustrated by the examples in section 4 the inputs and outputs of the tools provided by these tools are summarized in table 1 besides drot is designed in a way that can easily be extended to incorporate new tools when relevant advances in reservoir operation are available specifically the core functions of each of the tools are encapsulated in a callable module e g python module or an executable program and inserted into the control layer with a table containing required data fields created in the database and an interface built in the user interface layer to obtain user inputs further explanations are provided in drot architecture in the following the data retrieval tool can be used by users to automatically retrieve reservoir data from multiple public databases to alleviate users efforts in data collection for an illustration purpose the data sources in the current system include the publicly available databases in the california exchange data center the u s bureau of reclamation and the u s geological survey covering the records of streamflow storage and release of large reservoirs in california and the upper colorado region as demonstrated in fig 2 to retrieve data within drot users only need to select a reservoir from the given list and specify the data type e g inflow the time step e g daily monthly and the study period after receiving a data retrieval request drot searches its own database for relevant information and then retrieves data from one of the public databases retrieved data can be visualized by the data visualization tool and or saved as a downloadable csv file the data visualization tool can assist to visualize time series data and make the model results more understandable it either accepts time series data submitted by users through the user interface or interconnects with other tools to access the model outputs or retrieved data and display the data in an intuitive and interactive way fig 3 demonstrates the visualization tool where the time series data are made zoomable to different time ranges and smoothed to allow visual trend detection a heatmap is also created based on the time series to illuminate seasonality and inter annual variability more advanced functions of data retrieval and visualization can be added to drot in the future 3 2 architecture drot is built on the top of django 2019 a high level python web framework which follows the model template view mtv design pattern that splits the whole web application into three loosely coupled layers as shown in fig 4 in brief the model layer provides the relational database system e g sqlite where the data of drot are stored the relational database stores the user authentication information as well as data related to user created projects for each tool fig 4 the database of drot consists of user account information and datasets of finished and ongoing projects created by users users can retrieve a saved project based on the saved information the template layer provides user interfaces through which users specifications and customizations can be made this layer exchanges data dynamically with the view layer and generates webpages for the drot client side through which users are able to interact with drot functions e g providing required inputs to the system following step by step instructions and receiving results and explanations it generates web forms corresponding to the selected tool to collect the user inputs and transfers them to the view layer to process after the execution of a tool in the view layer the results are returned to the template layer which are then visualized and displayed to the users the view layer works as a controller of the entire web application including handling users requests and determining which direction the data should be delivered between the three layers for example if the user submits a web form to create a project a view function will be activated to convert the submitted data into a specified format for target uses deliver it to the model layer and save it in the database in another case that is to update an existing project a view function retrieves the project data from the model layer and sends it to the template layer for users interactions furthermore the operation tools realized by a set of python functions or classes are implemented in the view layer which provides functionalities to support computation taking the variable selection tool for instance it consists of data preprocessing e g data cleaning and normalization mmrmr algorithm realization and post processing e g organizing data format all of which are realized as python functions to accomplish the variable selection procedures and utilize the machine learning library scikit learn pedregosa et al 2011 to support the computation 3 3 workflow the workflow of drot as shown in fig 5 starts from the user authentication which requires an account to log in to the platform users can then access any of the existing tools for a particular problem diagnosis information can be obtained by creating a new project and then choosing the tools suitable for the problem analysis users can also retrieve an existing project saved from a previous run review the saved results modify the model inputs and rerun the project 4 examples demonstration examples of drot are provided following the background introduction for each of the tools implemented in the current version of drot the examples cover several reservoir operation problems to demonstrate the capability of drot including optimal operation of a single section 4 1 or a system of reservoirs section 4 3 for water supply multi objective operation problem that considers both water conservation and flood control objectives section 4 2 analysis of forecasts for real time operation section 4 2 and 4 4 and identification of reservoir operation decision factors using historical operation records section 4 5 more details about the case studies can be referred to the corresponding citations in the following examples readers can review and test the examples and create their own applications by logging into drot which can be accessed at www drotreservoir net 4 1 determining optimal releases under hedging for a single reservoir examples to determine optimal releases for a single reservoir with a concave water supply objective function were given in shiau 2011 and zhao et al 2019 these examples are demonstrated here using the tools in drot with the expected inflow and demand the initial storage the target carryover storage and reservoir capacity as inputs the optimal releases are calculated and shown in fig 6 releases under three methods are compared one sop rule that fulfills the current water demand and two hedging rules that consider the potential future water shortages shiau 2011 zhao et al 2019 the operation results in the largest water shortage under sop the lowest from the model of zhao et al 2019 and in between from the model of shiau 2011 this is because sop supplies current water demand as much as possible and does not consider future demands zhao et al 2019 considers hedging in the entire study period via a multistage model to maximize the overall water supply benefits over all stages shiau 2011 approximates the n stage optimization problem into a series of two stage models each of which optimizes the allocation of water between current and future these studies are subject to some assumptions zhao et al 2019 assumes perfect forecast over the entire study period which is not realistic for long term operation studies shiau 2011 relies on proper specifications of the target storages at the end of each time step due to inaccurate estimation of future water demand reservoir releases resulting from the model of shiau 2011 may not be optimal at some time periods for example unnecessary spill occurs at stage 16 due to the over estimate of future demands the reservoir evaporation loss can be added if the evaporation loss is not negligible 4 2 balancing requirements between water conservation and flood control a case study of the nierji reservoir from ding et al 2017 is used to demonstrate the tool to analyze flood season operation considering floodwater conservation the inflow forecast information critical storage levels of the reservoir and the downstream release requirement are taken as the inputs in addition the operator s preferences on objectives can also be specified the results for the demonstration case are shown in fig 7 where the maximum minimum and critical weighting factors for the water conservation objective are plotted against forecast uncertainty under a given forecast uncertainty level a weighting factor larger than the maximum weighting factor indicates that the water conservation objective dominates the operation a weighting factor smaller than the minimum weighting factor indicates that the flood control objective dominates the operation and weighting factors between the maximum and minimum provide the range where trade offs between water conservation and flood control exist it can be observed that as the uncertainty increases the feasible range between the minimum weighting factor and the maximum one shrinks this is because with higher forecast uncertainty the flood risk increases and thus the trade off between flood control and water conservation exists only within a smaller range different regions in fig 7 correspond to different types of hedging rules depending on which objective plays a dominant role in the operation as discussed by ding et al 2017 4 3 determining optimal release for multi reservoirs in parallel with a joint demand the tool for the optimal operation of a multi reservoir system is applied to a real world case from zhao et al 2020 where a system of three reservoirs in parallel located in liaoning province in china is considered the input data required for this tool include reservoir properties e g reservoir capacities initial and ending storages inflow conditions and joint water demand monthly releases during the historical period of 1956 2006 are calculated by the algorithm developed by zhao et al 2020 implemented in drot fig 8 displays the optimal operation requirements for both the reservoir system and individual reservoirs which follows the derived analytical solution in the original paper zhao et al 2020 for the two plots at the bottom of fig 8 the 0 symbol in the left plot means there should be no release from the indicated reservoir in the indicated time periods positive storages in the right plot means that the storage of the indicated reservoir should take a prescribed value in the indicated time periods as shown in zhao et al 2020 there exists one unique system level solution that maximizes the total water supply benefit while multiple individual reservoir release schedules may exist underlying the system optimal solution the plots in fig 8 provide conditions for an optimal release schedule for individual reservoirs in the system following which users can disaggregate the system level release into individual reservoir releases according to their own preferences the system level releases as well as some requirements for individual reservoirs such as no release or full or empty storage at particular time periods shown in fig 8 can be compared to the actual release schedules for possible improvements of the actual operation 4 4 determining inflow forecast horizons for reservoir operation the tool of forecast horizon determination is applied to a hypothetical example with time series of inflow under the most optimistic and pessimistic scenarios storage bounds at all stages water demand and the maximum allowable error bound eb as inputs to determine the longest forecast horizon lfh and the effective forecast horizon efh as defined in zhao et al 2019 since the eb determines the efh 4 levels of eb are tested and the results are shown in table 2 and fig 9 fig 9 plots the error bounds under different forecast horizons as well as the lfh and the efh determined with different ebs the error bound is calculated as the largest possible difference between the optimal releases resulting from any two inflow scenarios under a given uncertain forecast thus the value of the error bound evaluates the reliability of the release decision under the given uncertain forecast with a certain forecast horizon a larger error bound indicates higher uncertainty and lower reliability of a release decision as shown in fig 9 with a longer forecast horizon the error bound fluctuates at the beginning and then becomes stable after the lfh this is because it is not reasonable to use the reservoir to regulate streamflow to meet the purposes beyond the lfh due to the limited storage capacity and the inflow and water demands after the lfh do not affect the current release decision thus any forecast longer than the lfh is not needed efh considers the tolerance of a decision maker on forecast uncertainty and efh is determined as the longest one among all forecast horizons that satisfy eb since a larger eb indicates higher acceptability on forecast uncertainty the larger the eb the longer the efh while the lfh does not change with the eb besides if the acceptable eb is set too small efh may not exist which intuitively implies that the desired decision reliability i e with acceptable eb is so high that any acceptable eb cannot be determined 4 5 input variable selection for water resources systems the application of the data mining tool is demonstrated using the historical records of the blue mesa reservoir located in colorado the purpose is to find a set of input variables e g inflow one day ago current storage releases one week ago etc that are most relevant to the daily release decisions from large dataset which is similar to the case studies in hejazi et al 2009 the basic input data include the historical records of potential variables related to daily releases hejazi et al 2009 fig 10 displays the results generated by drot where the selected variables as well as the information regarding how much they contribute to the release decision are provided as can be seen the release one day ago the current inflow and the release two days ago are selected the relevance evaluated by the mutual information between variables among the selected inputs and the target output are shown in the heat map fig 10 as can be seen the mutual information is the highest between the current release and the release one day ago and the release one day ago is selected as the most important variable that contributes to the release decision at the current day although the mutual information between the current release and the release two days ago is higher than that between the current release and the current inflow the current inflow is selected as the second important input variable for release decisions that is because with the release one day ago already being selected the current inflow will be more informative for predicting the current release since the mutual information is also high between the release one day ago and the release two days ago furthermore the scatter plot in fig 10 provides some basic statistical tests with respect to the relevance of the selected variables to the release decisions and shows that the selected variables are suitable to model the release decisions given the low bias and variance levels 5 conclusion and future work this paper presents generic diagnostic reservoir operation tools drot which are publicly available via the internet the tools are developed based on generic properties for optimal operations or procedures e g data mining algorithms to identify key variables for real world reservoir operations the properties and procedures are derived from published analytical optimization studies rather than solving optimization models numerically without using any information related to a specific reservoir and they are applicable to any reservoir with a particular operation purpose e g water supply flooding control etc users of drot do not need to establish any numerical model for a particular reservoir operation problem but simply specify model parameters e g storage capacity inflow water requirement etc which skips the computational burden for solving optimization models numerically especially algorithms with generic applications are provided to determine the effective forecast horizon support input variable selection for building a reservoir operation optimization model and search for optimal operations of a system of reservoirs in parallel with a reduced computational requirement drot is an attempt to make more effective use of reservoir operation models and decision tools for supporting real world operation practices by reducing the tedious modeling work in case by case developments and mitigating computational difficulty of running complex numerical models as demonstrated by the examples drot can be used to obtain diagnostic information for the operation of any reservoir with a number of particular questions to address including how different a historical operation is from an optimal one what is the appropriate inflow forecast heading time with a given inflow forecast uncertainty level what inputs an optimization model should include to make the results more realistic should floodwater be conserved and how much for water supply given forecast uncertainty and operation preferences on flooding risk control and water conservation etc the online accessibility easy to use gui and the generality of the tools enable the accessibility user friendliness and usability of drot making it a triable and promising tool for various users including reservoir operators researchers and students drot provides some unique functions that are complementary to those provided by existing reservoir operation models and decision support tools based on numerical solvers on the one hand despite of the advantages of drot demonstrated in this study the results provided by drot are subject to the assumptions and simplifications adopted from the primary studies for example the assumptions of forecast error bounds in zhao et al 2019 unbiased gaussian distributed forecast errors in ding et al 2017 and deterministic inflow in zhao et al 2020 besides the current version of drot is not a comprehensive tool that can be applicable to any types of reservoir operation given that the purpose to present drot is to convert the generic properties derived from analytical optimization studies and some data mining procedures into diagnosis tools for certain types of reservoir operation mostly on water supply tools for other types of reservoir operation problems e g hydropower operation can be added to drot as soon as the generic properties and or general data analysis procedures suitable for those problems are available on the other hand numerical models designed for specific reservoirs can capture more realities in reservoir operations with the price of heavy computation requirement and high development cost drot does not mean to replace existing tools developed for specific reservoirs instead drot provides quick and diagnostic information to examine whether actual operations or the results from any numerical models satisfy some generic principles of optimization in addition drot also provides procedures to identify useful information e g appropriate lead time for inflow forecast and critical inputs for model formulation to support reservoir operation modeling analysis and operation practices the current version of drot includes only several cases with analytically derived optimization properties and one data mining tool mainly for demonstrating that generic properties and or general data analysis procedures can be converted into tools that can be commonly used to diagnose certain types of reservoir operation problems however since drot is designed to have an open structure to incorporate any existing or new tools based on generic properties and or procedures it can be continuously updated as more relevant studies being published in the future to cover a wider range of reservoir operation problems in addition although we do not attempt to develop drot using an open source approach we will share the most updated code of drot with readers upon a request we welcome new development with python from operation researchers to add their own tools to drot on the general software development side possible future extensions of drot include providing programming macros for application customization linking the drot database to more data sources available online and extending drot to benefit wider fields related to environmental modeling in addition further development of the auxiliary tools and the gui design is another direction to improve the usability of drot such as expanding the data retrieval tool to include more reservoirs including a data consistency checking tool adding tools for handling missing data providing more options on data visualizations that can better aid users to visually explore different types of data and adding example scripts for users to add their tools to drot the methodology of drot can be applied to other environmental fields to promote the use of environmental data and models following the two principles behind the development of drot first we promote the use of generic tools for a category of environmental system operations which are based on general properties and models of system optimization and procedures for analysis second we show the complementary benefits of drot to commonly used case by case optimization models that are usually computationally heavy by providing quick diagnostic information to examine whether actual operations or the results from any numerical models satisfy some generic principles of optimization these two principles behind the methodology of drot can be applied to other environmental fields to promote the use of environmental data and models for example many analytical groundwater models are available in the literature and those models can be transformed into generic tools for users in the field of groundwater as demonstrated by glass et al 2018 data availability all data models or code that support the findings of this study are available from the corresponding author upon reasonable request declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25921,the actual use of models and decision tools for real world reservoir operations is limited due to the gap between the models tools and the real world practices tedious amount of work in case by case model developments and computational difficulty of running complex numerical models this paper presents generic diagnostic reservoir operation tools drot the tools are developed based on generic properties derived from analytical optimization studies and data mining procedures instead of establishing a numerical model drot users can apply particular properties and or procedures to diagnose a specific reservoir operation problem by just providing required inputs drot is available online and also provides auxiliary tools such as a data retrieval tool and a data visualization tool drot provides an open software framework that can include additional generic tools of models algorithms and functions drot can be used by reservoir operators researchers and students to obtain diagnostic information for the operation of a reservoir keywords reservoir operation model decision support system generic diagnostic tool web based tool 1 introduction the need for streamflow regulation prompted extensive construction of dams globally during the 20th century as a result there are over 45 000 dams above 15 m high around the world with a total capacity of more than 6500 k m 3 and more than half of large river systems draining 54 of the world s lands are regulated nilsson et al 2005 streamflow is regulated to meet the needs of human society such as water supply flood control hydropower generation recreation and navigation thus it is important to provide reliable and timely support for reservoir operation in order to meet the operation objectives especially under changing water demand from the human society and changing water availability caused by global warming biemans et al 2011 this importance has stimulated long term extensive studies on reservoir operation in particular numerous numerical models and decision support systems dsss have been developed around the world yeh 1985 wurbs 1993 labadie 2004 lund et al 2017 however there are two outstanding issues along with those studies first the gap between the research developments and real world reservoir operation practices which ends with limited use of the aforementioned models dsss simonovic 1992 labadie 2004 hejazi and cai 2011 brown et al 2015 second the need of commonly accepted generic tools to mitigate tedious amount of work in case by case tool developments for specific reservoirs in this paper we address these issues by developing generic diagnostic reservoir operation tools drot taking advantage of relevant published studies that provide generic principles and or methods for various reservoir operation problems the gaps between reservoir operation research and applications are reflected in multiple aspects including limited applications of complex optimization models such as the optimization of a system of reservoirs over a long study period technical and institutional obstacles to the adoption of mid to long range inflow forecasts and insufficient use of widely observed operation records to better support real world reservoir operation practices while there is continuing progress on the development of advanced optimization models real world reservoir operation practices usually rely more on conventional operation rule curves simulation models or simple linear programming models koutsoyiannis et al 2002 labadie 2004 jahanpour et al 2014 researchers including karamouz et al 2005 and labadie 2004 attributed this situation to low confidence in optimization models developed based on simplified physical processes and systems high model complexity ending with difficulties in comprehending and using the models low flexibility that requires significant efforts for model development and customization for different reservoirs etc using inflow forecasts can improve the operation practices but the actual use of streamflow forecasts to support real world operation problems still faces a number of obstacles rayner et al 2005 whateley et al 2015 despite of research and institutional efforts such as the integrated forecast and reservoir management inform georgakakos et al 2007 and forecast informed reservoir operations firo jasperse et al 2017 and advances in forecasting skills whateley et al 2015 the obstacles include insufficient forecast skills complexities trialability observability of forecast adoption the efforts needed to modify existing models to adopt forecast information as well as institutional and political resistance rayner et al 2005 whateley et al 2015 beyond the extensive modeling work with widely observed historical records and ever growing data availability under the rapid growth of new techniques such as remote sensing based monitoring gao et al 2012 data of reservoir operations are now attracting more attention than before however these data can hardly be used to support real world operations without a ready to use platform a number of studies have used data mining techniques to either understand real world reservoir operations e g hejazi et al 2008 hejazi and cai 2009 and giuliani and herman 2018 or derive models for simulating real world operation decisions e g shrestha et al 1996 corani et al 2009 yang et al 2016 and coerver et al 2018 given near one century of reservoir operation practices abundant records including reservoir inflow storage and release for numerous reservoirs in the united states and other countries allow us to understand the actual operation rules and identify possible improvements of the real world practices in particular through better understanding real world reservoir operations the operations can be better supported through either developing more realistic optimization models hejazi and cai 2011 or building more realistic reservoir simulation components into hydrological simulation models wu et al 2020 long term historical data are especially important for decision analysis under changing climate and nonstationary hydrological conditions milly et al 2008 tetzlaff et al 2017 however accessing and integrating the historical reservoir operation data from multiple sources is challenging due to their inconsistent formats and different data query rules ames et al 2012 national academies of sciences engineering and medicine 2018 and a data retrieval tool as a component of a reservoir operation decision support system will help reduce users data collection work in summary the closure of these gaps between research and applications requires the development of accessible flexible and easy to use tools that help illustrating the advantages of new techniques reducing the complexity for using the techniques and making problem diagnosis accessible to real world reservoir operators which will subsequently prompt the adoption of the research developments a review of recent progress in reservoir operation cannot omit the applications of dsss developing dsss has been a considerable effort to use models and data to support real world reservoir operations since the 1980s a number of efforts have been made to develop dsss as generic tools for reservoir system operation decision support these tools allow users to customize reservoir system configurations such as system structures operational objectives and constraints for different reservoir systems and solve the customized problem using prescribed simulation or optimization models many of those tools are incorporated in the dsss primarily developed for basin wide water resources planning and management e g riverware eschenbach et al 2002 zagona et al 2001 modsim labadie 2006 calsim draper et al 2004 hec ressim us army corps of engineers hydrologic engineering center 2007 and raven craig et al 2020 these dsss simulate the operation of reservoirs based on user defined operation rules such as prioritized operation goals e g riverware zone based prioritized operation rules e g hec ressim combined use of prioritized demands and user defined operation rules e g modsim and calsim and time dependent reservoir operation rules e g raven among these ddss modsim calsim hec ressim and raven use simulation models which have limited capability of seeking optimal operation decisions or policies though calsim and modsim use optimization models to support the search of prioritized water supply to the various demands at each time step riverware uses preemptive linear goal programming method which is not flexible in analyzing tradeoffs among the multiple goals besides jahanpour et al 2014 and koutsoyiannis et al 2002 developed generic dsss based on simulation optimization models to optimize the parameters of parametric reservoir operation rules with respect to specific reservoir operation objective s via genetic algorithm ga jahanpour et al 2014 and nonlinear programming solvers koutsoyiannis 2002 most recently seifollahi aghmiuni and bozorg haddad 2019 developed a reservoir operation decision support tool that provides multiple functions including simulation based on various operation rules reservoir design optimization release decision optimization and parametric rule optimization the optimization problems are solved with the comprehensive evolutionary algorithm cea in summary these dsss can help users set up a ready to use simulation and or optimization model with necessary input data and provide a solver or algorithm to solve the model however these dsss are still subject to the fundamental challenges in applying numerical models especially optimization models to real world reservoir operations simple models are not sufficient to represent the complexity of the real world reservoir systems while complex models e g multiple reservoir systems with a long study horizon face the difficulty of computation labadie 2004 moreover due to the difficulty in generic model customization most of the dsss developed are case specific some of those adopted simulation models e g karbowski 1991 huang and yang 1999 stein et al 2001 cheng and chau 2004 ahmad and simonovic 2006 etc while others adopted optimization models e g huang 1996 shawwash et al 1999 karamouz et al 2000 karamouz et al 2005 alemu et al 2011 zeng et al 2012 and ahmad and hossain 2019 site specific ddss are usually sufficiently complex for a particular reservoir by including multiple components such as hydrological simulation and prediction data acquisition optional operation rule selection as well as customized graphical user interfaces gui despite the acceptable performance of a site specific dds for an individual reservoir system the high development cost imposed by sophisticated system structures and high customization requirements impede the extension of the dsss to other reservoir systems compared to existing generic tools as listed above for reservoir operation the diagnostic reservoir operation tools drot are unique in the following aspects first instead of relying on numerical simulation and or optimization models drot adopts recent analytical studies on reservoir operation optimization which by nature are generic for any reservoir with a specific function s such as water supply flooding control hydropower generation etc methods derived from analytical models can be applied to any reservoir without computational issues the results can be used to diagnose the existing operations in terms of possible improvements e g zhao et al 2020 show insights on tradeoffs between multiple operation objectives e g ding et al 2017 and provide guidelines to use forecasts more effectively e g zhao et al 2019 second drot provides ready to use data mining tools to extract reservoir operation rules and patterns from historical inflow storage and release records e g hejazi et al 2008 hejazi and cai 2009 the derived real world reservoir operation behaviors can be used to construct more realistic numerical models for reservoir operation simulation and or optimization hejazi and cai 2011 furthermore drot a web based online tool makes use of web techniques to improve its usability and accessibility ahmad and hossain 2019 and provides a gui and auxiliary functions which allow users to process access data via multiple ways users can either upload data from their own sources or retrieve data from online data sources via the data acquisition functions drot also provides data visualization functions to facilitate users to visualize both input and output data this paper aims at developing a platform to transform the general properties and models of reservoir operation optimization and procedures for analysis which exist in published papers into generic tools that are available online for users to obtain diagnostic information on the operation of a particular reservoir in a timely manner although an overview of the published studies of which the outputs are adopted in this paper are provided the details of the theories methods and procedures behind the tools of drot should be referred to those publications reviewed in the background section in the rest of this paper the background of the tools provided by a number of published studies will first be reviewed following that the software design will be described and the applications of drot will be demonstrated via some examples finally the future works of drot will be discussed readers are encouraged to navigate through the drot website www drotreservoir net where some in depth descriptions of each tool in drot and examples to test the tools are provided 2 background all tools currently included in drot are based on published studies as summarized in table 1 each of which is introduced briefly in this section this section does not intend to provide a comprehensive overview of reservoir operation models and tools that cover all types of reservoir operation problems but rather to provide the necessary background for the tools incorporated in drot and their demonstration examples thus the review focuses on a number of analytical studies and data mining studies on reservoir operation the reviewed studies cover several reservoir operation problems such as optimal operation of a single or a system of reservoirs for water supply multi objective operation problem that considers both water conservation and flood control objectives analysis of forecasts for real time operation and identification of reservoir operation decision factors using historical operation records 2 1 analytical studies on optimal operation decisions with single or multiple objectives among published studies on reservoir operations many present a generic optimization model for one or multiple functions e g water supply or both water supply and flooding control and derive closed form equations or computational procedures algorithms from the optimization conditions these studies then provide a method to develop generic tools for analyzing the optimal operation of certain types of reservoirs as reviewed in the following calculating reservoir release and carryover storage using closed form equations derived from hedging rules shiau 2011 formulated a two stage model to optimize hedging rules of reservoir operation which determines the release for the current stage and the carryover storage at the end of the current stage for future water use a weight is given to each of the two stages which reflects reservoir operators priority on the current water supply objective and water shortage risk reduction in the future a loss due to the deficit to the current or future demand is defined as an exponential function with one exponent parameter that describes the shape i e convexity of the loss function with a stage by stage rolling horizon approach optimal release for the entire study period over multiple stages e g week or month and carryover storage are calculated by the closed form equations derived from the optimization model the impact of hedging can be further explored with various weighting factors representing operators behavior and different loss functions representing the operation objectives and the performance of the optimal hedging rule can be assessed with respect to water shortage indices as demonstrated in the case study of shiau 2011 determining hedging rules for a single reservoir over multiple stages zhao et al 2019 formulated the optimal operation of a single reservoir over a number of stages as a multi stage nonlinear programming model that maximizes a concave water supply benefit function over the entire study period subject to mass balance constraints non negative storage constraints storage capacity constraints and non negative spill constraints the optimal release decisions of the reservoir at each stage are determined numerically following the derived the optimality conditions under a given deterministic inflow scenario both shiau 2011 and zhao et al 2019 solve optimal release decisions for the operation of a single water supply reservoir zhao et al 2019 obtains the global optimal solution over the entire study period i e with n stages while shiau 2011 approximates the n stage optimization problem into a series of two stage the current and the future problems and solves them using a moving window approach thus zhao et al 2019 can be used for a planning purpose and shiau 2011 for real time operation in addition both studies can be applied to historical reservoir inflow records to solve for the optimal solutions and the results can be compared with the actual operation and or the operation under the standard operation policy sop this comparison can shed light on the impact of hedging and provide guidelines to assist reservoir operators to improve the existing operations an algorithm based on derived operation rules to solve for optimal operations of a system of reservoirs in parallel zhao et al 2020 formulated the operation of a system of reservoirs in parallel with a single joint demand as a multi stage nonlinear programming model the model maximizes the total benefits over the entire study period subject to mass balance constraints non negative storage constraints storage capacity constraints and non negative spill constraints to derive the necessary and sufficient conditions for an optimal solution they assumed that the water supply benefit at each stage was a nonlinear concave function of the total release from all reservoirs the proposed algorithm solves the system level release at each stage and identifies stages with full empty ending storages and those with no release under the optimal solution a complete time series of releases for each of the reservoirs can be obtained with multiple options that satisfy the optimality conditions the proposed algorithm effectively reduces the computational complexity for solving the optimal operation decision for such reservoir systems as demonstrated through a case study in zhao et al 2020 the results of the algorithm identify the optimal conditions for the system level operation which can be used as a reference for real world operations or for examining historical operations multi objective hedging rules for tradeoff analysis between flood control and water conservation ding et al 2017 addressed the flood water conservation problem via a two stage optimization model i e water is conserved during the flood season at a possible cost of additional future flood risk which can be applied to real world operation using a rolling horizon approach the tradeoffs between water conservation and flood control are analyzed under the combined impacts of the decision preference represented by the relative weights specified for the flood control and water conservation objectives and the level of forecast uncertainty represented by the standard deviation of inflow forecast error for example when the forecast uncertainty is above a certain level the flood risk is high and the water conservation objective should not be considered the implemented results provide decision makers information such as whether or not tradeoff exists between the two objectives under given uncertainty and preference levels the minimum level of priority from the reservoir managers for water conservation to have some amount of water conservation or the maximum allowed uncertainty level of inflow forecast to make flood water conservation feasible the critical values are calculated following the optimality conditions derived from the optimization model also different combinations of the parameters can be tested to explore the impacts of water conservation priority and forecast uncertainty levels on the tradeoffs between the two objectives as a summary all the four studies reviewed above i e shiau 2011 zhao et al 2019 2020 and ding et al 2017 provided general properties or algorithms for generic reservoir optimization models for water supply specifically ding et al 2017 provided the procedures to determine the threshold inflow uncertainty and operation preferences i e the weighting factor required for floodwater conservation shiau 2011 derived closed form equations to calculate releases zhao et al 2019 2020 and ding et al 2017 provided algorithms computational procedures following the nonlinear programming nlp optimality conditions to solve the optimization models drot converts all these studies into tools that are based on the derived equations or algorithms to calculate reservoir releases and carryover storages drot users do not need to set up and run a primary optimization model but just specify the required inputs for the tools and run them with significantly reduced computational cost following the primary studies drot results provide meaningful insights on the optimization of reservoir operation problems e g marginal values of resources binding or nonbinding constraints trade offs between competing objectives impacts of forecast uncertainties on optimal operation decisions impacts of different hedging policies on optimal operation decisions etc 2 2 effective use of reservoir inflow forecasts adoption of inflow forecasts for various reservoir operation problems has been an important research issue given its limited use in reservoir operation practices hejazi et al 2009 whateley et al 2015 generic tools to analyze some well recognized problems with forecasts such as forecast uncertainty and forecast horizon will be useful for reservoir operation communities as shown by the studies reviewed below with an attempt to support better use of forecasts for real time operations determining effective inflow forecast horizon for reservoir operation to make forecasts more effectively used in real world reservoir operations one has to determine how far ahead forecasts should be used for decision making i e an appropriate forecast horizon for making optimal reservoir operation decisions the complexity to determine an effective forecast horizon efh lies with the observation that forecast uncertainty usually grows with the forecast horizon zhao et al 2011 to solve this problem zhao et al 2019 developed procedures to estimate efh and the longest forecast horizon lfh for the operation of a single water supply reservoir with a concave water use benefit function the lfh represents the forecast length that provides the maximum information for decision making i e only forecast information within the lfh is useful for decision making and information beyond the lfh does not influence current release decisions and the efh represents the forecast length at which the influence of forecast uncertainty is controlled under a prescribed acceptable level these forecast horizons inform reservoir operators in terms of an appropriate length of the forecast to use for optimal reservoir operation users can also test different efhs under different maximum acceptable uncertainty levels determining the threshold uncertainty level for a useful forecast specially for flooding water conservation a forecast of the next coming flood event is used in ding et al 2017 to assess flooding risk and the potential of flood water conservation given a prescribed acceptable flooding risk ding et al 2017 estimated the critical or threshold value of the forecast uncertainty level beyond which the flooding risk is higher than the acceptable level and the water conservation objective should not be considered in other word flood water conservation is possible only if the flooding forecast is accurate enough so that the uncertainty is below the determined threshold 2 3 data mining applications on reservoir operation more recent studies have been conducted to discover reservoir operation rules and decision factors e g yang et al 2016 coerver et al 2018 mason et al 2018 giuliani and herman 2018 which enables some generic tools that can be applied to analyzing reservoir operations using long term reservoir inflow storage and release data as an instance one of the early such studies hejazi et al 2009 is reviewed as follows input variable selection for water resources systems using a modified minimum redundancy maximum relevance mmrmr algorithm hejazi et al 2009 developed a data mining method for input variable selection i e mmrmr and applied the method to determine the most relevant input variables that influence the actual release decision for reservoir operation the proposed algorithm was tested using the historical reservoir operation records from 22 reservoirs in california to select input variables from 121 potential alternatives for making release decisions with the mmrmr algorithm the most relevant input variables are iteratively selected from a set of potential alternatives such as current inflow past inflow inflow forecast and storage the iterative selection process stops until any additional input variable cannot further explain the output variable i e the release the selected input variables including the relevant inputs and state variables can inform reservoir operators of the factors to be considered for the operation of a reservoir beyond the regular operation considerations such as inflow conditions moreover the results can be used to improve model accuracy for predicting reservoir operation decisions with a minimum increase of model complexity through adopting the selected variables into a dynamic programming model a more realistic reservoir operation decision scheme can be represented in reservoir optimization models which can provide more realistic optimal solutions for real world reservoir operations hejazi and cai 2011 3 drot software design drot is designed as a web based platform which provides a set of tools developed based on the studies listed in section 2 the principles for the drot development as stated in the introduction lie with realizing generic tools based on published studies which are supported by data access visualization and data mining functions the realized generic tools allow users to analyze and diagnose particular reservoir operation problems with provision of insights on an optimization problem and with tractable computation complexity without setting up and running a numerical algorithm to solve the optimization model this section describes the implementation of the platform including the software features the architecture and the workflow for using the tools 3 1 features of drot the current version of drot is composed of four sets of tools optimization tools based on analytical rules data mining data retrieval and data visualization tools fig 1 the major functions and tools of drot take advantage of the existing publications while shielding the complex modeling details but only requesting necessary model inputs and allowing users to obtain diagnostic information for actual operations as illustrated by the examples in section 4 the inputs and outputs of the tools provided by these tools are summarized in table 1 besides drot is designed in a way that can easily be extended to incorporate new tools when relevant advances in reservoir operation are available specifically the core functions of each of the tools are encapsulated in a callable module e g python module or an executable program and inserted into the control layer with a table containing required data fields created in the database and an interface built in the user interface layer to obtain user inputs further explanations are provided in drot architecture in the following the data retrieval tool can be used by users to automatically retrieve reservoir data from multiple public databases to alleviate users efforts in data collection for an illustration purpose the data sources in the current system include the publicly available databases in the california exchange data center the u s bureau of reclamation and the u s geological survey covering the records of streamflow storage and release of large reservoirs in california and the upper colorado region as demonstrated in fig 2 to retrieve data within drot users only need to select a reservoir from the given list and specify the data type e g inflow the time step e g daily monthly and the study period after receiving a data retrieval request drot searches its own database for relevant information and then retrieves data from one of the public databases retrieved data can be visualized by the data visualization tool and or saved as a downloadable csv file the data visualization tool can assist to visualize time series data and make the model results more understandable it either accepts time series data submitted by users through the user interface or interconnects with other tools to access the model outputs or retrieved data and display the data in an intuitive and interactive way fig 3 demonstrates the visualization tool where the time series data are made zoomable to different time ranges and smoothed to allow visual trend detection a heatmap is also created based on the time series to illuminate seasonality and inter annual variability more advanced functions of data retrieval and visualization can be added to drot in the future 3 2 architecture drot is built on the top of django 2019 a high level python web framework which follows the model template view mtv design pattern that splits the whole web application into three loosely coupled layers as shown in fig 4 in brief the model layer provides the relational database system e g sqlite where the data of drot are stored the relational database stores the user authentication information as well as data related to user created projects for each tool fig 4 the database of drot consists of user account information and datasets of finished and ongoing projects created by users users can retrieve a saved project based on the saved information the template layer provides user interfaces through which users specifications and customizations can be made this layer exchanges data dynamically with the view layer and generates webpages for the drot client side through which users are able to interact with drot functions e g providing required inputs to the system following step by step instructions and receiving results and explanations it generates web forms corresponding to the selected tool to collect the user inputs and transfers them to the view layer to process after the execution of a tool in the view layer the results are returned to the template layer which are then visualized and displayed to the users the view layer works as a controller of the entire web application including handling users requests and determining which direction the data should be delivered between the three layers for example if the user submits a web form to create a project a view function will be activated to convert the submitted data into a specified format for target uses deliver it to the model layer and save it in the database in another case that is to update an existing project a view function retrieves the project data from the model layer and sends it to the template layer for users interactions furthermore the operation tools realized by a set of python functions or classes are implemented in the view layer which provides functionalities to support computation taking the variable selection tool for instance it consists of data preprocessing e g data cleaning and normalization mmrmr algorithm realization and post processing e g organizing data format all of which are realized as python functions to accomplish the variable selection procedures and utilize the machine learning library scikit learn pedregosa et al 2011 to support the computation 3 3 workflow the workflow of drot as shown in fig 5 starts from the user authentication which requires an account to log in to the platform users can then access any of the existing tools for a particular problem diagnosis information can be obtained by creating a new project and then choosing the tools suitable for the problem analysis users can also retrieve an existing project saved from a previous run review the saved results modify the model inputs and rerun the project 4 examples demonstration examples of drot are provided following the background introduction for each of the tools implemented in the current version of drot the examples cover several reservoir operation problems to demonstrate the capability of drot including optimal operation of a single section 4 1 or a system of reservoirs section 4 3 for water supply multi objective operation problem that considers both water conservation and flood control objectives section 4 2 analysis of forecasts for real time operation section 4 2 and 4 4 and identification of reservoir operation decision factors using historical operation records section 4 5 more details about the case studies can be referred to the corresponding citations in the following examples readers can review and test the examples and create their own applications by logging into drot which can be accessed at www drotreservoir net 4 1 determining optimal releases under hedging for a single reservoir examples to determine optimal releases for a single reservoir with a concave water supply objective function were given in shiau 2011 and zhao et al 2019 these examples are demonstrated here using the tools in drot with the expected inflow and demand the initial storage the target carryover storage and reservoir capacity as inputs the optimal releases are calculated and shown in fig 6 releases under three methods are compared one sop rule that fulfills the current water demand and two hedging rules that consider the potential future water shortages shiau 2011 zhao et al 2019 the operation results in the largest water shortage under sop the lowest from the model of zhao et al 2019 and in between from the model of shiau 2011 this is because sop supplies current water demand as much as possible and does not consider future demands zhao et al 2019 considers hedging in the entire study period via a multistage model to maximize the overall water supply benefits over all stages shiau 2011 approximates the n stage optimization problem into a series of two stage models each of which optimizes the allocation of water between current and future these studies are subject to some assumptions zhao et al 2019 assumes perfect forecast over the entire study period which is not realistic for long term operation studies shiau 2011 relies on proper specifications of the target storages at the end of each time step due to inaccurate estimation of future water demand reservoir releases resulting from the model of shiau 2011 may not be optimal at some time periods for example unnecessary spill occurs at stage 16 due to the over estimate of future demands the reservoir evaporation loss can be added if the evaporation loss is not negligible 4 2 balancing requirements between water conservation and flood control a case study of the nierji reservoir from ding et al 2017 is used to demonstrate the tool to analyze flood season operation considering floodwater conservation the inflow forecast information critical storage levels of the reservoir and the downstream release requirement are taken as the inputs in addition the operator s preferences on objectives can also be specified the results for the demonstration case are shown in fig 7 where the maximum minimum and critical weighting factors for the water conservation objective are plotted against forecast uncertainty under a given forecast uncertainty level a weighting factor larger than the maximum weighting factor indicates that the water conservation objective dominates the operation a weighting factor smaller than the minimum weighting factor indicates that the flood control objective dominates the operation and weighting factors between the maximum and minimum provide the range where trade offs between water conservation and flood control exist it can be observed that as the uncertainty increases the feasible range between the minimum weighting factor and the maximum one shrinks this is because with higher forecast uncertainty the flood risk increases and thus the trade off between flood control and water conservation exists only within a smaller range different regions in fig 7 correspond to different types of hedging rules depending on which objective plays a dominant role in the operation as discussed by ding et al 2017 4 3 determining optimal release for multi reservoirs in parallel with a joint demand the tool for the optimal operation of a multi reservoir system is applied to a real world case from zhao et al 2020 where a system of three reservoirs in parallel located in liaoning province in china is considered the input data required for this tool include reservoir properties e g reservoir capacities initial and ending storages inflow conditions and joint water demand monthly releases during the historical period of 1956 2006 are calculated by the algorithm developed by zhao et al 2020 implemented in drot fig 8 displays the optimal operation requirements for both the reservoir system and individual reservoirs which follows the derived analytical solution in the original paper zhao et al 2020 for the two plots at the bottom of fig 8 the 0 symbol in the left plot means there should be no release from the indicated reservoir in the indicated time periods positive storages in the right plot means that the storage of the indicated reservoir should take a prescribed value in the indicated time periods as shown in zhao et al 2020 there exists one unique system level solution that maximizes the total water supply benefit while multiple individual reservoir release schedules may exist underlying the system optimal solution the plots in fig 8 provide conditions for an optimal release schedule for individual reservoirs in the system following which users can disaggregate the system level release into individual reservoir releases according to their own preferences the system level releases as well as some requirements for individual reservoirs such as no release or full or empty storage at particular time periods shown in fig 8 can be compared to the actual release schedules for possible improvements of the actual operation 4 4 determining inflow forecast horizons for reservoir operation the tool of forecast horizon determination is applied to a hypothetical example with time series of inflow under the most optimistic and pessimistic scenarios storage bounds at all stages water demand and the maximum allowable error bound eb as inputs to determine the longest forecast horizon lfh and the effective forecast horizon efh as defined in zhao et al 2019 since the eb determines the efh 4 levels of eb are tested and the results are shown in table 2 and fig 9 fig 9 plots the error bounds under different forecast horizons as well as the lfh and the efh determined with different ebs the error bound is calculated as the largest possible difference between the optimal releases resulting from any two inflow scenarios under a given uncertain forecast thus the value of the error bound evaluates the reliability of the release decision under the given uncertain forecast with a certain forecast horizon a larger error bound indicates higher uncertainty and lower reliability of a release decision as shown in fig 9 with a longer forecast horizon the error bound fluctuates at the beginning and then becomes stable after the lfh this is because it is not reasonable to use the reservoir to regulate streamflow to meet the purposes beyond the lfh due to the limited storage capacity and the inflow and water demands after the lfh do not affect the current release decision thus any forecast longer than the lfh is not needed efh considers the tolerance of a decision maker on forecast uncertainty and efh is determined as the longest one among all forecast horizons that satisfy eb since a larger eb indicates higher acceptability on forecast uncertainty the larger the eb the longer the efh while the lfh does not change with the eb besides if the acceptable eb is set too small efh may not exist which intuitively implies that the desired decision reliability i e with acceptable eb is so high that any acceptable eb cannot be determined 4 5 input variable selection for water resources systems the application of the data mining tool is demonstrated using the historical records of the blue mesa reservoir located in colorado the purpose is to find a set of input variables e g inflow one day ago current storage releases one week ago etc that are most relevant to the daily release decisions from large dataset which is similar to the case studies in hejazi et al 2009 the basic input data include the historical records of potential variables related to daily releases hejazi et al 2009 fig 10 displays the results generated by drot where the selected variables as well as the information regarding how much they contribute to the release decision are provided as can be seen the release one day ago the current inflow and the release two days ago are selected the relevance evaluated by the mutual information between variables among the selected inputs and the target output are shown in the heat map fig 10 as can be seen the mutual information is the highest between the current release and the release one day ago and the release one day ago is selected as the most important variable that contributes to the release decision at the current day although the mutual information between the current release and the release two days ago is higher than that between the current release and the current inflow the current inflow is selected as the second important input variable for release decisions that is because with the release one day ago already being selected the current inflow will be more informative for predicting the current release since the mutual information is also high between the release one day ago and the release two days ago furthermore the scatter plot in fig 10 provides some basic statistical tests with respect to the relevance of the selected variables to the release decisions and shows that the selected variables are suitable to model the release decisions given the low bias and variance levels 5 conclusion and future work this paper presents generic diagnostic reservoir operation tools drot which are publicly available via the internet the tools are developed based on generic properties for optimal operations or procedures e g data mining algorithms to identify key variables for real world reservoir operations the properties and procedures are derived from published analytical optimization studies rather than solving optimization models numerically without using any information related to a specific reservoir and they are applicable to any reservoir with a particular operation purpose e g water supply flooding control etc users of drot do not need to establish any numerical model for a particular reservoir operation problem but simply specify model parameters e g storage capacity inflow water requirement etc which skips the computational burden for solving optimization models numerically especially algorithms with generic applications are provided to determine the effective forecast horizon support input variable selection for building a reservoir operation optimization model and search for optimal operations of a system of reservoirs in parallel with a reduced computational requirement drot is an attempt to make more effective use of reservoir operation models and decision tools for supporting real world operation practices by reducing the tedious modeling work in case by case developments and mitigating computational difficulty of running complex numerical models as demonstrated by the examples drot can be used to obtain diagnostic information for the operation of any reservoir with a number of particular questions to address including how different a historical operation is from an optimal one what is the appropriate inflow forecast heading time with a given inflow forecast uncertainty level what inputs an optimization model should include to make the results more realistic should floodwater be conserved and how much for water supply given forecast uncertainty and operation preferences on flooding risk control and water conservation etc the online accessibility easy to use gui and the generality of the tools enable the accessibility user friendliness and usability of drot making it a triable and promising tool for various users including reservoir operators researchers and students drot provides some unique functions that are complementary to those provided by existing reservoir operation models and decision support tools based on numerical solvers on the one hand despite of the advantages of drot demonstrated in this study the results provided by drot are subject to the assumptions and simplifications adopted from the primary studies for example the assumptions of forecast error bounds in zhao et al 2019 unbiased gaussian distributed forecast errors in ding et al 2017 and deterministic inflow in zhao et al 2020 besides the current version of drot is not a comprehensive tool that can be applicable to any types of reservoir operation given that the purpose to present drot is to convert the generic properties derived from analytical optimization studies and some data mining procedures into diagnosis tools for certain types of reservoir operation mostly on water supply tools for other types of reservoir operation problems e g hydropower operation can be added to drot as soon as the generic properties and or general data analysis procedures suitable for those problems are available on the other hand numerical models designed for specific reservoirs can capture more realities in reservoir operations with the price of heavy computation requirement and high development cost drot does not mean to replace existing tools developed for specific reservoirs instead drot provides quick and diagnostic information to examine whether actual operations or the results from any numerical models satisfy some generic principles of optimization in addition drot also provides procedures to identify useful information e g appropriate lead time for inflow forecast and critical inputs for model formulation to support reservoir operation modeling analysis and operation practices the current version of drot includes only several cases with analytically derived optimization properties and one data mining tool mainly for demonstrating that generic properties and or general data analysis procedures can be converted into tools that can be commonly used to diagnose certain types of reservoir operation problems however since drot is designed to have an open structure to incorporate any existing or new tools based on generic properties and or procedures it can be continuously updated as more relevant studies being published in the future to cover a wider range of reservoir operation problems in addition although we do not attempt to develop drot using an open source approach we will share the most updated code of drot with readers upon a request we welcome new development with python from operation researchers to add their own tools to drot on the general software development side possible future extensions of drot include providing programming macros for application customization linking the drot database to more data sources available online and extending drot to benefit wider fields related to environmental modeling in addition further development of the auxiliary tools and the gui design is another direction to improve the usability of drot such as expanding the data retrieval tool to include more reservoirs including a data consistency checking tool adding tools for handling missing data providing more options on data visualizations that can better aid users to visually explore different types of data and adding example scripts for users to add their tools to drot the methodology of drot can be applied to other environmental fields to promote the use of environmental data and models following the two principles behind the development of drot first we promote the use of generic tools for a category of environmental system operations which are based on general properties and models of system optimization and procedures for analysis second we show the complementary benefits of drot to commonly used case by case optimization models that are usually computationally heavy by providing quick diagnostic information to examine whether actual operations or the results from any numerical models satisfy some generic principles of optimization these two principles behind the methodology of drot can be applied to other environmental fields to promote the use of environmental data and models for example many analytical groundwater models are available in the literature and those models can be transformed into generic tools for users in the field of groundwater as demonstrated by glass et al 2018 data availability all data models or code that support the findings of this study are available from the corresponding author upon reasonable request declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25922,the mainstems data model implements the catchment and flowpath concepts from waterml2 part 3 surface hydrology features hy features for persistent cross scale identification of hydrologic features the data model itself provides a focused and lightweight method to describe hydrologic networks with minimum but sufficient information the design is intended to provide a model for data integration that can be used for network navigation and persistent hydrologic indexing hydrographic addressing functionality mainstems is designed to provide long term stability with minimal maintenance requirements the data model is not meant to advance hydrologic process representation or uniquely represent geomorphic characteristics the principle assumption in mainstems is that all drainage basins have one and only one headwater source area and a single mainstem that flows to a single outlet using these base feature types headwater outlet mainstem and drainage basin a nested set of drainage basins and the associated dendritic network of mainstems can be identified graphical abstract uml class diagram showing classes and associations from hy features and those introduced as subclasses drainage basin and mainstem inherit the associations of catchment and flowpath more specific associations contributingdrainagebasin and primaryflowpath are introduced image 1 keywords hydrography mainstem drainage basin logical data model hydrologic location abbreviations common hydrology features chyf geospatial fabric gf hydrologic unit hu national hydrography dataset nhd national hydrography dataset plus version 1 nhdplusv1 national hydrography dataset plus version 2 nhdplusv2 national hydro network nhn network linked data index nldi nhdplusv2 catchment id comid points of interest pois river reach file 1 rf1 waterml2 part 3 surface hydrology features hy features watershed boundary dataset wbd 1 introduction petts 1996 describes drainage basin as a basic hydrologic unit of the landscape that encompasses a cascading system of connected hillslope and channel subsystems as early as the 1500s it was recognized that rain accumulates in catchment areas to form rivers and springs biswas 1970 in the 1600s edme marriotte mapped the seine river upstream of paris including its drainage basin boundary flowpath network and source dooge 1959 marriotte s work included calculations of catchment area mean annual rainfall and total annual rainfall volume since these early notions of quantitative hydrology a fundamental relationship between a drainage basin area and a predominant mainstem that transports water from a source headwater to an outlet has been recognized nearly 400 years later the familiar and intuitive properties of these landscape mechanics have resulted in a general vagueness about how hydrologic features are described referenced and understood in the computer age where knowledge must be expressed explicitly for machine interpretation and learning this vagueness limits the integration and long term compilation of knowledge i e progress in hydrographic hydrologic hydrodynamic or hydrometric sciences collectively hydroscience such a challenge is not newly recognized abbot 1993 pointed to the need to encapsulate knowledge i e adding nuance and context to data to further hydroscience integration archfield et al 2015 called for a machine independent information sharing infrastructure to enable communication and integration across hydroscience domains and in jiang et al 2019 described the potential value in using a knowledge based approach to catalog and re use specific application context for integrated hydroscience modeling these examples illustrate the need for and continuing lack of focus in hydroscience knowledge representation to start addressing the problem of vagueness in surface hydrology the first international standard for surface water features waterml2 part 3 surface hydrology features hy features was published by the open geospatial consortium in 2018 see box 1 this standard describes building blocks for formalizing imprecise terminology in support of data integration and scientific reproducibility in the hydrosciences atkinson 2012 blodgett and dornblut 2018 while hy features defines concepts for a common abstraction it does not specify implementation logic in practice integration and reproducibility is achieved only through use of a common delineation methodology a specific dataset or a particular modeling software this current state of the hydroscience field is so diverse that reproducibility and interoperability built on these foundations can be impossible without expert interpretation hutton 2016 as a purely conceptual model hy features was intended to be adopted in use specific logical and or physical data models as described by brodaric et al 2018 box 2 the challenge with modern hydrologic applications is that many physical data models were developed before the existence of a common conceptual model with the introduction of hy features there is an opportunity to create explicit logical models to use as a tool for unifying existing physical data models toward this end this research presents the mainstems logical data model shortened to mainstems which is built on the hy features concepts the goal of mainstems is to specify a minimum set of location linear and areal feature types needed to define and integrate disparate datasets using features that can be uniquely and easily identified mainstems is especially useful for integrating spatially precise but inexact feature geometries meant to represent networks of rivers catchments and locations related to observation and prediction of hydrologic phenomena more broadly mainstems is intended to be implemented in multiple physical data models in support of hydroscience data integration 1 1 detailed problem statement and research question all hydroscience physical applied data models describe hydrology through a set of concepts logic and constraints that are useful to specific applications and scales users wanting to apply the data outside of those contexts must modify or integrate their data in a way that respects both the geographic and hydrologic representation of the original data in this research data integration refers to the alignment of spatial features and the conflation of properties to establish matching features by hydrologic function these coupled needs prompt a number of questions with respect to what type of data should and should not be integrated and the nuances that need to be considered prior to doing so 1 is hydrology represented in the same way in each dataset 2 are geometries in different datasets meant to represent the same feature 3 is the scale of feature types compatible 4 does the original intent of a dataset align with the needs of the new application without common concepts the only way to integrate datasets is through spatial proximity or alignment spatial proximity is a challenging integrator when using datasets that map coordinates with varying levels of accuracy or coarseness of scale but with high levels of precision coordinates are exact points on the earth alternatively the use of well defined concepts and logic could allow data to be aligned by the features purpose intention or identity that is that features in the various data sources would be aligned based on the real world features they represent and not just their nearness in an arbitrary scale a secondary and perhaps more relatable challenge that limits data integration is that the spatial coverage and attribute richness of most authoritative datasets come at the cost of complexity and data volume for instance the national hydrography dataset plus version 2 nhdplusv2 mckay 2015 is a multiple gigabyte database with hundreds of inter related attributes across millions of features while necessary for some applications data complexity and volume can pose a major barrier to use therefore to provide a functional integrative data model built on consistent concepts the mainstems model must be able to satisfy both the lack of a shared conceptual model and the complexity and volume of existing datasets the aim of this research is to establish whether a relatively lightweight logical data model i e mainstems grounded in a conceptual standard i e hy features can meet these goals if feasible concept based hydrologic feature integration will allow relative hydrologic location to be an empowering technique for structuring shared knowledge within the hydrosciences in this vein testing of the mainstems model focuses on three key benchmarks to measure success concepts can the hy features conceptual model be used with varied historical datasets functionality can a general lightweight logical data model mainstems provide the required functionality for indexing and network operations over large complex data integration can hydrologic feature integration be used to better solve traditional geographic issues of scale and granularity than spatial integration alone to communicate the details of mainstems rigorous and precise terminology is required appendix a contains terms and definitions specific to hy features catchment flowpath nexus hydrologic location and the mainstems data model headwater outlet mainstem drainage basin these terms are italicized throughout this paper 1 2 data modeling and scope the intended scope of the hy features and the mainstems logical data model is broad to enable data integration they can be applied to any hydroscience data model or workflow but do not introduce new techniques or methods specific physical data models such as nhdplusv2 or hydrology aspects of model interface specifications such as the community surface dynamics modeling system csdms basic model interface and standard names peckham 2013 2014 should be viewed as implementations that mainstems is compatible with mainstems is not intended to be a new or different hydrologic network coding system such as gravelius order gravelius 1914 or to introduce unique fluvial geomorphic characteristics or representations instead it is intended to allow integration and representation of datasets that encode such systems 1 3 case studies case studies used in the development and evaluation of mainstems are presented here to illustrate the utility and functionality supported by the model the following is a brief summary of the case studies and how they specifically evaluate mainstems 1 the first case study concerns an integrated hydrologic network indexing system based on the nhdplus data model called the network linked data index it shows how mainstems can be used to provide continental scale data indexing and network navigation functionality 2 the second case study integrates linear and areal continental scale datasets the nhdplus and watershed boundary dataset wbd using a mainstems based hydrologic network to match watershed outlet locations this case study shows how mainstems can be used as a tool in matching network locations by their place in an overall hydrologic network 3 the third case study integrates a linear representation of a hydrologic network flowpaths with an aerial representation of hydrologic units catchment boundaries this example shows how mainstems can be used to unify networks of polygonal units with networks of linear features across scale 4 the fourth case study integrates a coarse network the u s river reach file known as rf1 with a more resolved network of flowpaths and catchments the nhdplus version 2 1 this case study explores the functional limitations of mainstems based integration in headwater areas 5 the final case study describes integration of a new graph theoretic data model the common hydrology features known as chyf for representation of catchments and flowpaths with unique identifiers for mainstems and drainage basins this case study shows how mainstems based identifiers can be embedded in a modern highly resolved network graph of hydrologic features these case studies are described in detail in section 3 of this paper data models of the datasets used for case studies are described in appendix b 2 mainstems logical data model 2 1 overview in geography location describes a relation and not a property kuhn 2012 all descriptions of location express a spatial relation between features to be located and chosen reference system a region a street network coordinate axes absolute location uses precise if approximate coordinates e g latitude 37 5467 longitude 119 5678 to describe the finite location of a feature on a reference coordinate system goodchild 1992 herring 2010 typical spatial integration looks for features that share the same absolute location with some level of error while absolute location can establish spatial proximity there is an equal need for a relative referencing system that is meaningful to people and software that use hydroscience data e g a specific gage is upstream of a specific dam the typical way this is achieved in hydrographic data is with linear referencing such as that in nhdplusv2 while this approach achieves a degree of relative referencing it is limited to the scope of a single data model and or a specific geometry as a result the utility of linear referencing for broad cross dataset integration is limited an alternative representation of location describes one feature in relation to another e g the school is right behind the post office referencing by relative location requires contextual knowledge of at least one of the places e g the location of the post office context can also be driven by concepts such as homes are buildings in residential zonings and stores are buildings in commercial zonings this idea of concept driven relative referencing is how mainstems seek to match features by the hydrologic processes they serve mainstems aspires to provide a nested multi resolution system to provide persistent features for relative referencing of hydroscience data to any hydroscience dataset an application that illustrates mainstems intended use is integration of observed and simulated information for example consider a set of monitoring stations and a hydrologic model that predicts streamflow at unmonitored locations within a drainage basin if we know the absolute location of the monitoring and prediction locations and what mainstem they are on relative location we know their hydrologic location and can draw meaningful comparisons between the two sources while existing coordinate reference systems and linear referencing systems can be used to define absolute location a multi scale relative reference system for hydrologic networks does not exist to handle cross scale issues within the concept of catchment mainstems emphasizes incremental catchments incremental catchment datasets exist both globally lehner 2013 yamazaki 2019 and for specific countries mckay 2015 sondheim 2019 bureau of meteorology 2012 these datasets discretize the landscape into one incremental catchment area per confluence to confluence flowpath using well established elevation derived hydrography processing methods dixon and uddameri 2015 a coverage of incremental catchments can be delineated from elevation and existing incremental flowpaths an important feature of mainstems is that incremental catchments can be seen as a flattened combination of nested drainage basin boundaries a mainstem flowpath network and associated total drainage basins are embedded in an incremental catchment network by defining mainstem flowpaths and identifying them across datasets the sophistication of incremental catchment data models can be handled simultaneously with a persistent and minimal network of mainstem flowpaths connecting headwater and outlet locations fig 1 illustrates the mainstem flowpath drainage basin headwater and relationship with incremental catchments 2 2 headwaters flowpath and hydrologic location a headwater is the region where flow coalesces and starts to form a flowing body of water montgomery and dietrich 1988 1992 wohl 2018 regardless of physical reality or geomorphic theory in a given hydroscience dataset the headwater is the area upstream of an observed or predicted flowing river as the nesting level of incremental drainage basins increases and their sizes decrease the spatial characteristics of a headwater location must be known with increasing precision the mainstems data model builds on the understanding that the spatial representation of a headwater can vary across datasets the characteristics of headwater areas upstream of observable flowpaths or shorelines are not explored in this research but are required for a complete hydrographic data model and provide avenues for future work headwater areas often contain isolated drainage basins that do not connect into nearby dendritic systems through surface channels in these instances it is practical to include them as parts of larger downgradient drainage basins by focusing on sufficiently coarse spatial resolution drainage basins large enough to have an established flowpath at their outlet what schumm 1977 termed the transfer and storage zones mainstems avoids the complexities of local hydrology yet maintains wide applicability and stability mainstems assumes dendritic connections in the downstream direction meaning divergences are treated as new headwater locations if divergences are identified as hydrologic locations capable applications of mainstems could route flow through divergent parts of the network the dendritic assumption helps reduce complexity promotes stability and improves reliability of references and integrations that use the logical data model 2 3 flowpath catchment and hydro nexus the downstream end of a mainstem flowpath is a hydrologic location of type outlet outlets can be referenced to the next downstream flowpath each outlet location has one and only one associated headwater location if a given dataset includes incremental catchments an outlet location could be a realization of a hydrologic nexus hy hydronexus connecting contributing and receiving catchments hy features describes a hy hydronexus as the interface between two catchments if implemented in a hydrologic model a nexus occurs when an upstream model domain is coupled to a downstream domain in a hydrographic dataset a nexus feature is implemented with attributes describing what catchments are upstream and or downstream of a given feature hy features allows nexus locations to be realized as different kinds of hydrologic features and or more complex classes such as modeling software interfaces while other nexus realizations can be specified only hydrologic locations with explicit point geometries are specified by hy features mainstems does not require that nexuses between catchments be included but it is compatible with systems that require nexus interfaces between catchments and their flowpaths such as the nhdplusv2 or hydrologic models that explicitly represent processes at confluences see fig 2 for a formal unified markup language uml representation of the mainstems extension of hy features classes and relations 3 case studies the following case studies focus on the relationship between mainstem flowpaths and hydrologic locations while testing the complete mainstems data model dataset specific feature types and attributes are denoted with bold text and defined in detail in appendix b 3 1 network linked data index the network linked data index nldi https waterdata usgs gov blog nldi intro fig 3 provides navigation functions over the flowline network and returns indexed hydrologic locations found along the navigation the nldi system works with the complex continental scale nhdplusv2 dataset and any number of datasets indexed to the nhdplusv2 the nldi system is a test and demonstration of mainstems ability to provide intuitive functions for network navigation and hydrologic data discovery nldi indexing and data retrieval resolve hydrologic locations to predefined spatially indexed nhdplusv2 catchment ids comid all navigation requests start at a known comid and each comid is associated with a unique level path id mainstem id and hydro sequence upstream downstream sort order that can be used for flowline navigation the upstream mainstem is defined by all features associated with the same level path mainstem id with a hydro sequence greater than the starting location downstream mainstem and upstream with tributaries use similar logic but recursively follow relationships between mainstems their tributaries and the larger mainstems to which they contribute the nldi also supports the retrieval of drainage basin boundaries for any nhdplusv2 catchment outlet given this functionality the nldi system can resolve the mainstem hydrographic network drainage basin and linked hydrologic locations for any nhdplusv2 comid or any hydrologic location that has been indexed to the nhdplusv2 network this case study illustrates the utility of mainstems for indexing and discovering hydrologic locations when a location is indexed the association is recorded as a relationship with a comid since the comid has a unique mainstem level path id it defines the mainstem that the hydrologic location is on if the identifiers for flowpaths and catchments of other relevant hydrographic datasets are added to the nldi as linked hydrologic locations this approach opens the possibility to interface hydrography and hydrologic location data from any integrated dataset the challenge is how to identify the mainstem in nhdplusv2 therefore nldi with mainstem features from other hydrologic representations 3 2 associating the national hydrologic model geospatial fabric to twelve digit hydrologic units this case study tests mainstems ability to integrate network locations outlet points referenced to different large scale and complex hydrographic networks the case study focuses on integrating the national hydrologic model geospatial fabric gf viger 2014 and outlets of the watershed boundary dataset twelve digit hydrologic units hu12s u s geological survey 2019 price 2018 the association between these outlets was needed for a daily water balance modeling study the gf includes approximately 100 000 catchments called hydrologic response units hrus the hydrologic nexuses of gf hrus referred to as points of interest pois were defined based on the hydrologic location of stream gages water quality sample sites and modeling criteria like maximum flow distance hu12 outlets were established after publication of the gf so they were not included as gf pois a complication that makes this an especially useful test case for mainstems is that the gf is based on nhdplusv1 while the hu12 outlets are based on nhdplusv2 meaning the underlying networks are not identical to reconcile this both hydrologic and spatial associations were established where substantial upstream drainage area and flow exist both the hu12 and gf datasets had representations of equivalent mainstems fortunately a near complete mapping from nhdplusv1 to nhdplusv2 is available so creating one here was not required with a known mapping hu12 outlets and gf pois could be placed relative to each other along mainstems and linear distance and drainage area differences could be established with this information network matches hydrologic associations were established and drainage area ratios were created to adjust total flow from the gf poi on the same mainstem and with the nearest drainage area to each hu12 outlet in headwater areas with insufficient flow or drainage area to use this approach spatial intersection relations were used instead the need for spatial intersection for some hu12 outlets illustrates an important limitation of mainstems in headwater areas there may be areas that have ambiguous or poorly established flowpaths this is not a limiting factor of the logical model and rather a practical limit of the data as a mainstem flowpath is defined as a feature where flow can be observed and or predictions of flow can be made a mainstem flowpath should not be expected to extend further upstream than flowing water is regularly observed 3 3 nhdplusv2 mapping to twelve digit hydrologic units this case study integrates two hydrographic datasets that use different incremental catchments these include the nhdplusv2 which contains linear flowpaths and polygon catchment boundaries and the wbd hu12s which contains only polygon catchment boundaries integrating these datasets requires determining the most representative nhdplusv2 flowpath for each wbd hu12 catchment this task is a good test of mainstems because it deals with mainstem collections of polygonal hu12s that correspond to mainstem collections of linear nhdplusv2 flowlines this ability to identify collections of linear or polygonal features that make up the same mainstem as shown in fig 4 is a core function provided by mainstems the boundaries of wbd hu12s were hand drawn using a variety of base maps resulting in potential disagreement with different scale versions of the digitally derived nhd to associate nhdplusv2 flowlines and hu12 units two sources of evidence were used 1 the collection of hu12s found via spatial intersection with a mainstem of nhdplusv2 flowlines and 2 the headwater to outlet connectivity of hu12s the processing required a dendritic tree of hu12s and removal of non dendritic and coastal nhd flowlines three phases of matching and two cleanup steps were performed 1 first nhdplusv2 flowlines were intersected with the hu12 units and the most downstream largest intersecting mainstem for each hu12 was found 2 mainstem collections of hu12s were identified by tracing the hydrologic connectivity attributes from headwater to outlet hu12s 3 results of part one and two were compared noting where the spatial and hydrologic matches are different 4 hu12s present in set 1 but not set 2 were assigned to the next smallest mainstem contained in set 1 5 hu12s that were in set 2 but not set 1 were flagged as potential errors and assigned the largest non intersecting mainstem in set 2 this case study illustrates how mainstems can help identify hydrologically similar collections of flowpaths and catchment boundaries from disparate datasets this process is particularly useful near confluences in datasets that do not have perfectly aligned geometries fig 5 in these cases it was helpful to identify a single set of hu12s for each mainstem through a process of elimination starting with the most dominant longest mainstem in the network this ensures that large mainstems have a complete set of hu12s smaller mainstems do not get matched to river bottom hu12s they cross and that every hu12 that intersects multiple flowlines gets attributed to the largest river it intersects a challenge when matching mainstems across datasets is the identification of headwater locations in the case of hu12s and nhdplusv2 flowlines the top of a flowline sometimes crosses over a drainage basin boundary such that if the upper extent of the flowline were used for matching the wrong headwater hu12 would be identified in areas of low relief especially where ditches have been created it is not always clear where the true boundary begins to manage these situations the outlet of a first order nhdplusv2 catchment typically much smaller than a hu12 was used for headwater matching this issue is included here to further illustrate that headwater areas must be treated with care when implementing the mainstems model 3 4 nhdplusv2 mapping to river reach file 1 to further exercise the mainstems data model our fourth case study integrates an early digital hydrographic data model the river reach file 1 rf1 nolan 2003 brakebill 2011 with the more modern nhdplusv2 in contrast to the nhdplusv2 with over 2 7 million catchments for the conterminous united states rf1 has less than 70 000 the problem addressed here is to identify the collection of rf1 segments the rf1 name for flowpaths that correspond to the mainstems of the nhdplusv2 this is a good test to explore limitations of mainstems where datasets have different headwater flowpath density and geometry precision the process of integrating rf1 segments and nhdplusv2 flowlines started by matching the mid point along a headwater rf1 segment to a nhdplusv2 catchment given that the nhdplusv2 network contains much smaller headwater catchments than the headwater rf1 segments the top of rf1 segments can fall in a headwater catchment that are not the headwater catchment of the nhdplusv2 indicated mainstem to work around this an algorithm using a largest river first process of elimination similar to that implemented in previous case studies was used to find the representative mainstem for each nhdplusv2 catchment matched to a headwater rf1 segment once the representative nhdplusv2 mainstem was established for each rf1 headwater segment the same largest river first process of elimination was used to match collections of rf1 segments to nhdplusv2 mainstems this process worked largely as expected fig 4 an expected issue regarding the upstream limit of mainstems is shown in fig 6 for a dataset such as rf1 that resolves headwater catchments at coarser resolutions than the dataset being integrated headwater flowpaths may diverge from the finer scale mainstems this should be viewed as a limitation of the resolution of hydrographic datasets used 3 5 defining mainstems and drainage basins with chyf this case study questions whether mainstems and associated drainage basins can be determined programmatically using a test area in the richelieu river valley in southern quebec canada the challenge here is that the chyf data model and service implementation uses computation rather than pre calculated attributes as much as possible while maintaining hydrologically consistent and correct relationships between flowpaths and catchments this case study tested whether mainstems is compatible with basic network operations using a graph theoretical technical baseline that is if the geometries associated with existing and calculated attributes can be used to determine mainstems and associated drainage basins input data consisted of elementary incremental flowpaths and catchments as well as the boundary for the area of interest the flowpaths have various attributes including a primary name and rank designating whether the flowpath represents a primary or secondary flow when data are first read into a chyf repository a graph is created and attributes including length strahler order stream order horton order and hack gravelius order gravelious 1914 hack 1957 stream level are populated in chyf a collection of flowpaths designated as a mainstem has several key characteristics all elementary flowpaths represent primary flows have the same name and are assigned the same gravelius order value additionally the mainstem of a drainage basin can be specified as meeting a minimum length or drainage area criterion both of which can readily be determined length is calculated by summing the elementary flowpath lengths along the mainstem and area drained by summing of the areas of the upstream elementary catchments as assessed by graph navigation a geometric union of these elementary catchments gives a polygon representing the associated drainage basin in the same way as the nldi the process described above works but it has two caveats that illustrate nuances related to mainstems first it depends on gravelius order which has been calculated using a longest path with geographic name approach to reach the headwater this assumes that gravelius order as defined corresponds to the mainstem second the results are not necessarily as expected due to divergent flows chyf allows for secondary diverted flows with the result that one large drainage can leak into another if one or more secondary flows connect them to circumvent this as is implied by mainstems the navigation algorithms could be adjusted to ignore secondary flows or to treat them as primary flows as described below for canada with no equivalent of the level of detail provided by hu12 in the united states the automated technique described above is worth investigating further provided the input data are of sufficient quality it may be practical for major mainstems and drainage basins to be determined relatively quickly across much of the country 3 6 case study summary the collection of case studies presented show the utility of mainstems to integrate point representations of hydrologic locations linear representations of flowpaths and polygon representations of catchment boundaries the first uses mainstems as the primary index in a network navigation and linked data discovery utility the second demonstrates how mainstems can be used to associate catchment outlets using mainstem matching the third shows how mainstems can integrate mainstem collections of linear flowpaths and polygon catchment boundaries the fourth provides an important test and demonstration of how the mainstems data model behaves in headwater areas the final case study illustrates how the mainstems model can extend to datasets from other countries and those that are implemented using graph concepts while generally positive the results if these case studies illustrate some important limitations of mainstems the first is that headwater is a scale dependent location and each hydrographic dataset considered has one upstream most catchment along a given path the entire upstream most feature could be considered a representation of the headwater of the mainstem in question as a result anything upstream of the outlet of a headwater catchment area itself a small drainage basin should not be expected to match from one dataset to another this is illustrated in fig 6 where the red line is one rf1 segment and the blue line is the nhdplusv2 level path with the same outlet the rf1 segment is a headwater path that diverges from the nhdplusv2 the data model has value in that it provides a stable reference for a mainstem but for the upper extents of a mainstem the precision is limited by the resolution of the datasets in question practically this means the mainstems data model should be used with caution in headwaters divergences present some interesting issues for mainstems practically there were three types of divergences encountered in the case studies 1 anthropogenic divergences 2 hydrologic divergences and 3 complex flowpaths anthropogenic divergences are not directly considered by mainstems other than treating them as hydrologic locations hydrologic divergences form new headwaters and a specific data model for locating headwaters of divergences along their source flowpath could be the subject of future work complex flowpaths such as a river encircling an island may be represented by a single line in one dataset and several segments in another in this case all flowpaths could be considered part of the mainstem as there is no independent drainage basin resolved in mainstems the distinction between hydrologic divergences and complex flowpaths is dependent on the resolution of the smallest drainage basins in a given implementation of mainstems as a result we suggest the mainstems model be used on basins of sufficient size to have an established flowpath in general the case studies demonstrate that using a single mainstem that flows from a headwater source area to the outlet of a drainage basin has great utility for persistent identification of rivers in hydrographic addressing mainstems can provide a minimum yet sufficient set of easily identified linear paths through a hydrologic network for integration of hydrologic locations and linear and aerial representations of catchment networks mainstems provides a data model and set of assumptions that aid processing 4 considerations and future work the australian hydrologic geospatial fabric commonwealth of australia bureau of meteorology 2012 introduces the concept of contracted nodes as permanent hydrologic locations that are intended to persist through space and time mainstems does not include this concept explicitly however the nexuses of persistent mainstem flowpaths confluences are implicit contracted nodes a given implementation of mainstems could create identifiers for these mainstem confluence locations and other important hydrologic locations in the spirit of contracted nodes as an implementation issue chyf allows for these major nexuses to be identified as contracted nodes mainstems assumes that all drainage basins have one headwater and one outlet this assumption is only valid for drainage basins that have a mainstem that terminates at its outlet areas with no flowpaths either upstream of a first order flowpath or along the shore of a waterbody so called zero order catchments dietrich 1987 are not accounted for in mainstems such areas must be encompassed in a drainage basin that includes an identifiable mainstem in order to be included in the hydrologic landscape this is not an issue for flowpath oriented hydrologic integration and addressing but will need to be accounted for in future work aimed at integration of surface water groundwater and especially waterbodies the upstream most location of a mainstem is not a single point in reality there is some drainage basin without flowpaths upstream of the top of the initiation of flowing water these locations might be a wetland a spring a glacier or a field in each case there are unique nuances of hydrogeomorphology that dictate how and when a mainstem can be said to exist exploration of data models to support these kinds of headwater areas to more concretely establish the characteristics and geometry of headwaters is left for future work if implemented for all rivers from large to small the mainstem drainage basin paradigm implies a collection of incremental catchments that cover the landscape it does not address the specific logical data model for implementing them when disaggregating the landscape into a collection of incremental catchments these catchments correspond to a directed acyclic graph with each catchment draining into another the associated flowpaths form a separate directed acyclic graph that can be combined with the first such that catchments and flowpaths are represented in the same graph each drainage basin and mainstem can be defined as the union of elements represented in the graph a wide array of hydrologic locations such as tributary confluences too small to be part of the mainstems network stream gages dams and outlets of major waterbodies can all be related to locations on the graph thus a specific data model for incremental catchments and associated flowpaths can be built on graph theoretical constructs chyf does exactly this by providing a logical data model defined as a profile of hy features in the context of graph theory this approach has two strong benefits provided that the data are topologically clean with correct flowpath catchment relationships at nexuses the first benefit is that assigning identifiers to graph elements and building the directed acyclic graph using them is a fast process this limits the importance of maintaining identifiers especially for smaller streams and catchments since point and linear referencing along the flowpath network can be based on xy coordinates the second benefit pertains to the fast navigation through the graph that can be implemented which can be combined with a new coverage union operation davis 2019 to quickly create drainage basins or other large catchments from incremental catchments chyf recognizes the importance of mainstems and drainage basins supports them in its data model and will be adding services to support their use 4 1 conclusion this research documents the design and testing of the mainstems data model the case studies presented in this paper demonstrate that hy features concepts which are the basis for mainstems are compatible with varied historical datasets that the mainstems data model supports both hydrologic indexing hydrographic addressing and network navigation functions and that mainstems based logic supports integration of hydrographic data in ways that spatial integration alone cannot the case studies illustrate important limitations of mainstems in headwater regions and how the dendritic assumption of the model can accommodate divergences as hydrologic locations our research has shown that mainstems provides a useful approach to support persistent identification through a minimum yet sufficient set of networked hydrologic features declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests acknowledgements all u s geological survey work documented in this paper was funded by the u s geological survey water mission area water availability and use science program the ongoing development of the common hydrology features model is being funded by the centre for mapping and earth observation ccmeo natural resources canada and supported by both that agency and the national hydrological services environment and climate change canada usgs personnel have also provided substantial support and encouragement to chyf developments through ongoing interaction with ccmeo appendix a terminology and concepts note the source of the term is denoted as hy features or mainstems 7 1 1 areal features catchment hy features hy features defines the catchment concept as a holistic geomorphic feature type that represents all the aspects of hydrology draining to an identified outlet catchments are typically organized in a hydrologic cascade that fully partitions the landscape only breaking at major waterbodies a catchment receives flow from zero or one inflows and contributes flow to zero or one outlets drainage basin mainstems like the catchment feature type a drainage basin is also a holistic feature it is defined as the total upstream area draining to an outlet it is comparable to a catchment with no inflows and a single outlet drainage basins can be thought of as a total accumulated or total upstream catchment while having no formal description in hy features drainage basin is a commonly used term petts 1996 schumm 1977 a drainage basin can be described with a pair of locations 1 the headwtater area with no discernible flowpaths where flow initiates and 2 the outlet where flow enters a larger river or waterbody a single mainstem flowpath connects a drainage basin s headwater to its outlet 7 1 2 location features hydrologic nexus hy features a hydrologic nexus shortened to nexus represents the interface along a flowpath between two or more catchments one or more catchments contribute flow to a nexus which contributes flow to one or more other catchments conceptually a nexus can be defined anywhere on the landscape but datasets typically establish them at confluences along a flowpath or other important network locations such as stream gaging stations hydrologic location hy features any location that can be thought to be on a hydrologic network a hydrologic location may or may not be coincident with a hydrologic nexus any geospatial representation of a hydrologic nexus is inherently a hydrologic location hydrologic locations are commonly associated with multiple hydrographic datasets and or hydrologic models providing points of integration outlet hy features an outlet defines the most downstream location in a catchment where water exits into the ocean or the next downstream waterbody or catchment hy features formalizes the type of hydrologic location as a catchmentoutlet which is functionally where flow exits a catchment and a nexus is where multiple catchments flow mix and or split to contribute to one or more downstream catchments practically every catchment drains to a single outlet hydrologic nexus which could be represented by a catchmentoutlet hydrologic location headwater mainstems a headwater is scale dependent and represents the most upstream location where water can theoretically exist in a drainage basin typically on a drainage basin boundary given that the definition of a flowpath does not necessitate the existence of water headwater can be imagined as a point where an extended flowpath touches a drainage basin boundary much in the same way location theory explains how the location of economic activities can be determined on a broad level such as a region or metropolitan area or on a narrow one such as a zone neighborhood city block or an individual site the idea of headwaters can be defined by a drainage basin boundary hillslope or a specific point in space 7 1 3 linear features flowpath hy features a flowpath represents a one dimensional idealized path that water follows through a catchment in the case of a catchment with no inlet a flowpath might extend along a main path to the catchment boundary mainstem mainstems the mainstem concept extends and constraints the concept of a flowpath by designating a single path from a headwater source to an outlet as the primary water feature used to traverse the network through a drainage basin in other words a mainstem is a linear realization or backbone of a drainage basin appendix b hydrographic data sources 9 1 1 river reach file 1 the rf1 was first introduced by the u s environmental protection agency in 1985 horn 1994 it is a linear network of major rivers in the continental united states dewald 2015 the version of the rf1 used here is the most recent version which has been quality controlled for network connectivity and value added attributes such as drainage area and time of travel nolan 2003 the rf1 network includes only linear representations of rivers which are referred to as segments some non dendritic connections are present but all connections have an identified primary path in the network 9 1 2 watershed boundary dataset the wbd u s geological survey 2013 u s geological survey 2019 is a collection of nested basin boundaries based on a hierarchical drainage system of hydrologic units for the united states major river basins are given two digit codes and progressively smaller hydrologic units are identified by 4 6 8 10 and 12 digit hydrologic unit codes shortened to hu2 through hu12 the wbd has developed over time with improvements in elevation data used for delineation and knowledge of hydrologic characteristics two versions of the wbd are used a static snapshot of the hu12s that was used in the production of the nhdplusv2 moore and dewald 2016 and the current release which includes the best available geometry and attributes at the time of access usgs 2018 an attribute tohu provides routing capabilities and dendritic hydrologic unit connectivity it is used extensively to identify the network of wbd hu12s in this paper 9 1 3 national hydrography dataset plus the nhdplus has two static versions v1 and v2 that share the same data model moore and dewald 2016 mckay 2015 bondelid 2010 nhdplusv2 is used almost exclusively here the nhdplusv2 provides an integration of linear river geometry polygonal catchment boundary geometry gridded elevation data and value added attributes such as landscape characteristics and flow estimates nhdplusv2 is created with a catchment delineation algorithm where pre existing river flowlines and hydrologic units are used to modify elevation data in preparation for flow direction accumulation processing nhdplusv2 catchment boundary geometries are created for each incremental typically confluence to confluence nhdplusv2 flowline segment numerous value added attributes have been created for each set of catchments the value added attributes associated with network connectivity and navigation are of particular importance here 9 1 4 national hydro network the nhn model was first published as a canadian standard in 2004 nhn pertains specifically to features associated with the hydrographic network and does not include descriptions of catchments or their boundaries although linear referencing is described in the model it has not been implemented as well hierarchical and containment relationships are not an explicit part of the model one of the main drivers behind the nhn has been to produce a national coverage suitable for network analysis the nhn data are grouped into 1382 large drainage areas that cover canada these correspond to the water survey of canada sub sub drainage areas the nhn has been created from existing topographic data ranging in scale from 1 50 000 to 1 20 000 the data are categorized into four completeness levels cl1 through cl4 these levels pertain respectively to network topology waterbody differentiation data continuity and toponymy belzile 2008 united states canada cross border hydro harmonization efforts under the international joint commission have been based on the nhdplus and the nhn 9 1 5 common hydrology features chyf is a recent data model developed by natural resources canada that implements catchment boundaries for incremental linear river geometries chyf incorporates the concepts and capabilities of graph theory applied to hydrologic elements in an analogous fashion to routing and navigation through a road network and uses the concepts of hy features catchments and flowpaths can be defined at different levels of granularity chyf supports the functional scope of the nhdplusv2 while allowing for regular updates to underlying data and maintaining stability for integrated applications chyf specifies a hy features profile and includes some extensions required to implement graph theoretic functionality the latter involves the definition of what is called a hygraph a graph structure made up by features referred to as elementary catchments elementary flowpaths and hydronodes version 0 9 of chyf is being finalized at the time of this writing and supports the mainstem and drainage basin concepts described here sondheim and hodgson 2019 
25922,the mainstems data model implements the catchment and flowpath concepts from waterml2 part 3 surface hydrology features hy features for persistent cross scale identification of hydrologic features the data model itself provides a focused and lightweight method to describe hydrologic networks with minimum but sufficient information the design is intended to provide a model for data integration that can be used for network navigation and persistent hydrologic indexing hydrographic addressing functionality mainstems is designed to provide long term stability with minimal maintenance requirements the data model is not meant to advance hydrologic process representation or uniquely represent geomorphic characteristics the principle assumption in mainstems is that all drainage basins have one and only one headwater source area and a single mainstem that flows to a single outlet using these base feature types headwater outlet mainstem and drainage basin a nested set of drainage basins and the associated dendritic network of mainstems can be identified graphical abstract uml class diagram showing classes and associations from hy features and those introduced as subclasses drainage basin and mainstem inherit the associations of catchment and flowpath more specific associations contributingdrainagebasin and primaryflowpath are introduced image 1 keywords hydrography mainstem drainage basin logical data model hydrologic location abbreviations common hydrology features chyf geospatial fabric gf hydrologic unit hu national hydrography dataset nhd national hydrography dataset plus version 1 nhdplusv1 national hydrography dataset plus version 2 nhdplusv2 national hydro network nhn network linked data index nldi nhdplusv2 catchment id comid points of interest pois river reach file 1 rf1 waterml2 part 3 surface hydrology features hy features watershed boundary dataset wbd 1 introduction petts 1996 describes drainage basin as a basic hydrologic unit of the landscape that encompasses a cascading system of connected hillslope and channel subsystems as early as the 1500s it was recognized that rain accumulates in catchment areas to form rivers and springs biswas 1970 in the 1600s edme marriotte mapped the seine river upstream of paris including its drainage basin boundary flowpath network and source dooge 1959 marriotte s work included calculations of catchment area mean annual rainfall and total annual rainfall volume since these early notions of quantitative hydrology a fundamental relationship between a drainage basin area and a predominant mainstem that transports water from a source headwater to an outlet has been recognized nearly 400 years later the familiar and intuitive properties of these landscape mechanics have resulted in a general vagueness about how hydrologic features are described referenced and understood in the computer age where knowledge must be expressed explicitly for machine interpretation and learning this vagueness limits the integration and long term compilation of knowledge i e progress in hydrographic hydrologic hydrodynamic or hydrometric sciences collectively hydroscience such a challenge is not newly recognized abbot 1993 pointed to the need to encapsulate knowledge i e adding nuance and context to data to further hydroscience integration archfield et al 2015 called for a machine independent information sharing infrastructure to enable communication and integration across hydroscience domains and in jiang et al 2019 described the potential value in using a knowledge based approach to catalog and re use specific application context for integrated hydroscience modeling these examples illustrate the need for and continuing lack of focus in hydroscience knowledge representation to start addressing the problem of vagueness in surface hydrology the first international standard for surface water features waterml2 part 3 surface hydrology features hy features was published by the open geospatial consortium in 2018 see box 1 this standard describes building blocks for formalizing imprecise terminology in support of data integration and scientific reproducibility in the hydrosciences atkinson 2012 blodgett and dornblut 2018 while hy features defines concepts for a common abstraction it does not specify implementation logic in practice integration and reproducibility is achieved only through use of a common delineation methodology a specific dataset or a particular modeling software this current state of the hydroscience field is so diverse that reproducibility and interoperability built on these foundations can be impossible without expert interpretation hutton 2016 as a purely conceptual model hy features was intended to be adopted in use specific logical and or physical data models as described by brodaric et al 2018 box 2 the challenge with modern hydrologic applications is that many physical data models were developed before the existence of a common conceptual model with the introduction of hy features there is an opportunity to create explicit logical models to use as a tool for unifying existing physical data models toward this end this research presents the mainstems logical data model shortened to mainstems which is built on the hy features concepts the goal of mainstems is to specify a minimum set of location linear and areal feature types needed to define and integrate disparate datasets using features that can be uniquely and easily identified mainstems is especially useful for integrating spatially precise but inexact feature geometries meant to represent networks of rivers catchments and locations related to observation and prediction of hydrologic phenomena more broadly mainstems is intended to be implemented in multiple physical data models in support of hydroscience data integration 1 1 detailed problem statement and research question all hydroscience physical applied data models describe hydrology through a set of concepts logic and constraints that are useful to specific applications and scales users wanting to apply the data outside of those contexts must modify or integrate their data in a way that respects both the geographic and hydrologic representation of the original data in this research data integration refers to the alignment of spatial features and the conflation of properties to establish matching features by hydrologic function these coupled needs prompt a number of questions with respect to what type of data should and should not be integrated and the nuances that need to be considered prior to doing so 1 is hydrology represented in the same way in each dataset 2 are geometries in different datasets meant to represent the same feature 3 is the scale of feature types compatible 4 does the original intent of a dataset align with the needs of the new application without common concepts the only way to integrate datasets is through spatial proximity or alignment spatial proximity is a challenging integrator when using datasets that map coordinates with varying levels of accuracy or coarseness of scale but with high levels of precision coordinates are exact points on the earth alternatively the use of well defined concepts and logic could allow data to be aligned by the features purpose intention or identity that is that features in the various data sources would be aligned based on the real world features they represent and not just their nearness in an arbitrary scale a secondary and perhaps more relatable challenge that limits data integration is that the spatial coverage and attribute richness of most authoritative datasets come at the cost of complexity and data volume for instance the national hydrography dataset plus version 2 nhdplusv2 mckay 2015 is a multiple gigabyte database with hundreds of inter related attributes across millions of features while necessary for some applications data complexity and volume can pose a major barrier to use therefore to provide a functional integrative data model built on consistent concepts the mainstems model must be able to satisfy both the lack of a shared conceptual model and the complexity and volume of existing datasets the aim of this research is to establish whether a relatively lightweight logical data model i e mainstems grounded in a conceptual standard i e hy features can meet these goals if feasible concept based hydrologic feature integration will allow relative hydrologic location to be an empowering technique for structuring shared knowledge within the hydrosciences in this vein testing of the mainstems model focuses on three key benchmarks to measure success concepts can the hy features conceptual model be used with varied historical datasets functionality can a general lightweight logical data model mainstems provide the required functionality for indexing and network operations over large complex data integration can hydrologic feature integration be used to better solve traditional geographic issues of scale and granularity than spatial integration alone to communicate the details of mainstems rigorous and precise terminology is required appendix a contains terms and definitions specific to hy features catchment flowpath nexus hydrologic location and the mainstems data model headwater outlet mainstem drainage basin these terms are italicized throughout this paper 1 2 data modeling and scope the intended scope of the hy features and the mainstems logical data model is broad to enable data integration they can be applied to any hydroscience data model or workflow but do not introduce new techniques or methods specific physical data models such as nhdplusv2 or hydrology aspects of model interface specifications such as the community surface dynamics modeling system csdms basic model interface and standard names peckham 2013 2014 should be viewed as implementations that mainstems is compatible with mainstems is not intended to be a new or different hydrologic network coding system such as gravelius order gravelius 1914 or to introduce unique fluvial geomorphic characteristics or representations instead it is intended to allow integration and representation of datasets that encode such systems 1 3 case studies case studies used in the development and evaluation of mainstems are presented here to illustrate the utility and functionality supported by the model the following is a brief summary of the case studies and how they specifically evaluate mainstems 1 the first case study concerns an integrated hydrologic network indexing system based on the nhdplus data model called the network linked data index it shows how mainstems can be used to provide continental scale data indexing and network navigation functionality 2 the second case study integrates linear and areal continental scale datasets the nhdplus and watershed boundary dataset wbd using a mainstems based hydrologic network to match watershed outlet locations this case study shows how mainstems can be used as a tool in matching network locations by their place in an overall hydrologic network 3 the third case study integrates a linear representation of a hydrologic network flowpaths with an aerial representation of hydrologic units catchment boundaries this example shows how mainstems can be used to unify networks of polygonal units with networks of linear features across scale 4 the fourth case study integrates a coarse network the u s river reach file known as rf1 with a more resolved network of flowpaths and catchments the nhdplus version 2 1 this case study explores the functional limitations of mainstems based integration in headwater areas 5 the final case study describes integration of a new graph theoretic data model the common hydrology features known as chyf for representation of catchments and flowpaths with unique identifiers for mainstems and drainage basins this case study shows how mainstems based identifiers can be embedded in a modern highly resolved network graph of hydrologic features these case studies are described in detail in section 3 of this paper data models of the datasets used for case studies are described in appendix b 2 mainstems logical data model 2 1 overview in geography location describes a relation and not a property kuhn 2012 all descriptions of location express a spatial relation between features to be located and chosen reference system a region a street network coordinate axes absolute location uses precise if approximate coordinates e g latitude 37 5467 longitude 119 5678 to describe the finite location of a feature on a reference coordinate system goodchild 1992 herring 2010 typical spatial integration looks for features that share the same absolute location with some level of error while absolute location can establish spatial proximity there is an equal need for a relative referencing system that is meaningful to people and software that use hydroscience data e g a specific gage is upstream of a specific dam the typical way this is achieved in hydrographic data is with linear referencing such as that in nhdplusv2 while this approach achieves a degree of relative referencing it is limited to the scope of a single data model and or a specific geometry as a result the utility of linear referencing for broad cross dataset integration is limited an alternative representation of location describes one feature in relation to another e g the school is right behind the post office referencing by relative location requires contextual knowledge of at least one of the places e g the location of the post office context can also be driven by concepts such as homes are buildings in residential zonings and stores are buildings in commercial zonings this idea of concept driven relative referencing is how mainstems seek to match features by the hydrologic processes they serve mainstems aspires to provide a nested multi resolution system to provide persistent features for relative referencing of hydroscience data to any hydroscience dataset an application that illustrates mainstems intended use is integration of observed and simulated information for example consider a set of monitoring stations and a hydrologic model that predicts streamflow at unmonitored locations within a drainage basin if we know the absolute location of the monitoring and prediction locations and what mainstem they are on relative location we know their hydrologic location and can draw meaningful comparisons between the two sources while existing coordinate reference systems and linear referencing systems can be used to define absolute location a multi scale relative reference system for hydrologic networks does not exist to handle cross scale issues within the concept of catchment mainstems emphasizes incremental catchments incremental catchment datasets exist both globally lehner 2013 yamazaki 2019 and for specific countries mckay 2015 sondheim 2019 bureau of meteorology 2012 these datasets discretize the landscape into one incremental catchment area per confluence to confluence flowpath using well established elevation derived hydrography processing methods dixon and uddameri 2015 a coverage of incremental catchments can be delineated from elevation and existing incremental flowpaths an important feature of mainstems is that incremental catchments can be seen as a flattened combination of nested drainage basin boundaries a mainstem flowpath network and associated total drainage basins are embedded in an incremental catchment network by defining mainstem flowpaths and identifying them across datasets the sophistication of incremental catchment data models can be handled simultaneously with a persistent and minimal network of mainstem flowpaths connecting headwater and outlet locations fig 1 illustrates the mainstem flowpath drainage basin headwater and relationship with incremental catchments 2 2 headwaters flowpath and hydrologic location a headwater is the region where flow coalesces and starts to form a flowing body of water montgomery and dietrich 1988 1992 wohl 2018 regardless of physical reality or geomorphic theory in a given hydroscience dataset the headwater is the area upstream of an observed or predicted flowing river as the nesting level of incremental drainage basins increases and their sizes decrease the spatial characteristics of a headwater location must be known with increasing precision the mainstems data model builds on the understanding that the spatial representation of a headwater can vary across datasets the characteristics of headwater areas upstream of observable flowpaths or shorelines are not explored in this research but are required for a complete hydrographic data model and provide avenues for future work headwater areas often contain isolated drainage basins that do not connect into nearby dendritic systems through surface channels in these instances it is practical to include them as parts of larger downgradient drainage basins by focusing on sufficiently coarse spatial resolution drainage basins large enough to have an established flowpath at their outlet what schumm 1977 termed the transfer and storage zones mainstems avoids the complexities of local hydrology yet maintains wide applicability and stability mainstems assumes dendritic connections in the downstream direction meaning divergences are treated as new headwater locations if divergences are identified as hydrologic locations capable applications of mainstems could route flow through divergent parts of the network the dendritic assumption helps reduce complexity promotes stability and improves reliability of references and integrations that use the logical data model 2 3 flowpath catchment and hydro nexus the downstream end of a mainstem flowpath is a hydrologic location of type outlet outlets can be referenced to the next downstream flowpath each outlet location has one and only one associated headwater location if a given dataset includes incremental catchments an outlet location could be a realization of a hydrologic nexus hy hydronexus connecting contributing and receiving catchments hy features describes a hy hydronexus as the interface between two catchments if implemented in a hydrologic model a nexus occurs when an upstream model domain is coupled to a downstream domain in a hydrographic dataset a nexus feature is implemented with attributes describing what catchments are upstream and or downstream of a given feature hy features allows nexus locations to be realized as different kinds of hydrologic features and or more complex classes such as modeling software interfaces while other nexus realizations can be specified only hydrologic locations with explicit point geometries are specified by hy features mainstems does not require that nexuses between catchments be included but it is compatible with systems that require nexus interfaces between catchments and their flowpaths such as the nhdplusv2 or hydrologic models that explicitly represent processes at confluences see fig 2 for a formal unified markup language uml representation of the mainstems extension of hy features classes and relations 3 case studies the following case studies focus on the relationship between mainstem flowpaths and hydrologic locations while testing the complete mainstems data model dataset specific feature types and attributes are denoted with bold text and defined in detail in appendix b 3 1 network linked data index the network linked data index nldi https waterdata usgs gov blog nldi intro fig 3 provides navigation functions over the flowline network and returns indexed hydrologic locations found along the navigation the nldi system works with the complex continental scale nhdplusv2 dataset and any number of datasets indexed to the nhdplusv2 the nldi system is a test and demonstration of mainstems ability to provide intuitive functions for network navigation and hydrologic data discovery nldi indexing and data retrieval resolve hydrologic locations to predefined spatially indexed nhdplusv2 catchment ids comid all navigation requests start at a known comid and each comid is associated with a unique level path id mainstem id and hydro sequence upstream downstream sort order that can be used for flowline navigation the upstream mainstem is defined by all features associated with the same level path mainstem id with a hydro sequence greater than the starting location downstream mainstem and upstream with tributaries use similar logic but recursively follow relationships between mainstems their tributaries and the larger mainstems to which they contribute the nldi also supports the retrieval of drainage basin boundaries for any nhdplusv2 catchment outlet given this functionality the nldi system can resolve the mainstem hydrographic network drainage basin and linked hydrologic locations for any nhdplusv2 comid or any hydrologic location that has been indexed to the nhdplusv2 network this case study illustrates the utility of mainstems for indexing and discovering hydrologic locations when a location is indexed the association is recorded as a relationship with a comid since the comid has a unique mainstem level path id it defines the mainstem that the hydrologic location is on if the identifiers for flowpaths and catchments of other relevant hydrographic datasets are added to the nldi as linked hydrologic locations this approach opens the possibility to interface hydrography and hydrologic location data from any integrated dataset the challenge is how to identify the mainstem in nhdplusv2 therefore nldi with mainstem features from other hydrologic representations 3 2 associating the national hydrologic model geospatial fabric to twelve digit hydrologic units this case study tests mainstems ability to integrate network locations outlet points referenced to different large scale and complex hydrographic networks the case study focuses on integrating the national hydrologic model geospatial fabric gf viger 2014 and outlets of the watershed boundary dataset twelve digit hydrologic units hu12s u s geological survey 2019 price 2018 the association between these outlets was needed for a daily water balance modeling study the gf includes approximately 100 000 catchments called hydrologic response units hrus the hydrologic nexuses of gf hrus referred to as points of interest pois were defined based on the hydrologic location of stream gages water quality sample sites and modeling criteria like maximum flow distance hu12 outlets were established after publication of the gf so they were not included as gf pois a complication that makes this an especially useful test case for mainstems is that the gf is based on nhdplusv1 while the hu12 outlets are based on nhdplusv2 meaning the underlying networks are not identical to reconcile this both hydrologic and spatial associations were established where substantial upstream drainage area and flow exist both the hu12 and gf datasets had representations of equivalent mainstems fortunately a near complete mapping from nhdplusv1 to nhdplusv2 is available so creating one here was not required with a known mapping hu12 outlets and gf pois could be placed relative to each other along mainstems and linear distance and drainage area differences could be established with this information network matches hydrologic associations were established and drainage area ratios were created to adjust total flow from the gf poi on the same mainstem and with the nearest drainage area to each hu12 outlet in headwater areas with insufficient flow or drainage area to use this approach spatial intersection relations were used instead the need for spatial intersection for some hu12 outlets illustrates an important limitation of mainstems in headwater areas there may be areas that have ambiguous or poorly established flowpaths this is not a limiting factor of the logical model and rather a practical limit of the data as a mainstem flowpath is defined as a feature where flow can be observed and or predictions of flow can be made a mainstem flowpath should not be expected to extend further upstream than flowing water is regularly observed 3 3 nhdplusv2 mapping to twelve digit hydrologic units this case study integrates two hydrographic datasets that use different incremental catchments these include the nhdplusv2 which contains linear flowpaths and polygon catchment boundaries and the wbd hu12s which contains only polygon catchment boundaries integrating these datasets requires determining the most representative nhdplusv2 flowpath for each wbd hu12 catchment this task is a good test of mainstems because it deals with mainstem collections of polygonal hu12s that correspond to mainstem collections of linear nhdplusv2 flowlines this ability to identify collections of linear or polygonal features that make up the same mainstem as shown in fig 4 is a core function provided by mainstems the boundaries of wbd hu12s were hand drawn using a variety of base maps resulting in potential disagreement with different scale versions of the digitally derived nhd to associate nhdplusv2 flowlines and hu12 units two sources of evidence were used 1 the collection of hu12s found via spatial intersection with a mainstem of nhdplusv2 flowlines and 2 the headwater to outlet connectivity of hu12s the processing required a dendritic tree of hu12s and removal of non dendritic and coastal nhd flowlines three phases of matching and two cleanup steps were performed 1 first nhdplusv2 flowlines were intersected with the hu12 units and the most downstream largest intersecting mainstem for each hu12 was found 2 mainstem collections of hu12s were identified by tracing the hydrologic connectivity attributes from headwater to outlet hu12s 3 results of part one and two were compared noting where the spatial and hydrologic matches are different 4 hu12s present in set 1 but not set 2 were assigned to the next smallest mainstem contained in set 1 5 hu12s that were in set 2 but not set 1 were flagged as potential errors and assigned the largest non intersecting mainstem in set 2 this case study illustrates how mainstems can help identify hydrologically similar collections of flowpaths and catchment boundaries from disparate datasets this process is particularly useful near confluences in datasets that do not have perfectly aligned geometries fig 5 in these cases it was helpful to identify a single set of hu12s for each mainstem through a process of elimination starting with the most dominant longest mainstem in the network this ensures that large mainstems have a complete set of hu12s smaller mainstems do not get matched to river bottom hu12s they cross and that every hu12 that intersects multiple flowlines gets attributed to the largest river it intersects a challenge when matching mainstems across datasets is the identification of headwater locations in the case of hu12s and nhdplusv2 flowlines the top of a flowline sometimes crosses over a drainage basin boundary such that if the upper extent of the flowline were used for matching the wrong headwater hu12 would be identified in areas of low relief especially where ditches have been created it is not always clear where the true boundary begins to manage these situations the outlet of a first order nhdplusv2 catchment typically much smaller than a hu12 was used for headwater matching this issue is included here to further illustrate that headwater areas must be treated with care when implementing the mainstems model 3 4 nhdplusv2 mapping to river reach file 1 to further exercise the mainstems data model our fourth case study integrates an early digital hydrographic data model the river reach file 1 rf1 nolan 2003 brakebill 2011 with the more modern nhdplusv2 in contrast to the nhdplusv2 with over 2 7 million catchments for the conterminous united states rf1 has less than 70 000 the problem addressed here is to identify the collection of rf1 segments the rf1 name for flowpaths that correspond to the mainstems of the nhdplusv2 this is a good test to explore limitations of mainstems where datasets have different headwater flowpath density and geometry precision the process of integrating rf1 segments and nhdplusv2 flowlines started by matching the mid point along a headwater rf1 segment to a nhdplusv2 catchment given that the nhdplusv2 network contains much smaller headwater catchments than the headwater rf1 segments the top of rf1 segments can fall in a headwater catchment that are not the headwater catchment of the nhdplusv2 indicated mainstem to work around this an algorithm using a largest river first process of elimination similar to that implemented in previous case studies was used to find the representative mainstem for each nhdplusv2 catchment matched to a headwater rf1 segment once the representative nhdplusv2 mainstem was established for each rf1 headwater segment the same largest river first process of elimination was used to match collections of rf1 segments to nhdplusv2 mainstems this process worked largely as expected fig 4 an expected issue regarding the upstream limit of mainstems is shown in fig 6 for a dataset such as rf1 that resolves headwater catchments at coarser resolutions than the dataset being integrated headwater flowpaths may diverge from the finer scale mainstems this should be viewed as a limitation of the resolution of hydrographic datasets used 3 5 defining mainstems and drainage basins with chyf this case study questions whether mainstems and associated drainage basins can be determined programmatically using a test area in the richelieu river valley in southern quebec canada the challenge here is that the chyf data model and service implementation uses computation rather than pre calculated attributes as much as possible while maintaining hydrologically consistent and correct relationships between flowpaths and catchments this case study tested whether mainstems is compatible with basic network operations using a graph theoretical technical baseline that is if the geometries associated with existing and calculated attributes can be used to determine mainstems and associated drainage basins input data consisted of elementary incremental flowpaths and catchments as well as the boundary for the area of interest the flowpaths have various attributes including a primary name and rank designating whether the flowpath represents a primary or secondary flow when data are first read into a chyf repository a graph is created and attributes including length strahler order stream order horton order and hack gravelius order gravelious 1914 hack 1957 stream level are populated in chyf a collection of flowpaths designated as a mainstem has several key characteristics all elementary flowpaths represent primary flows have the same name and are assigned the same gravelius order value additionally the mainstem of a drainage basin can be specified as meeting a minimum length or drainage area criterion both of which can readily be determined length is calculated by summing the elementary flowpath lengths along the mainstem and area drained by summing of the areas of the upstream elementary catchments as assessed by graph navigation a geometric union of these elementary catchments gives a polygon representing the associated drainage basin in the same way as the nldi the process described above works but it has two caveats that illustrate nuances related to mainstems first it depends on gravelius order which has been calculated using a longest path with geographic name approach to reach the headwater this assumes that gravelius order as defined corresponds to the mainstem second the results are not necessarily as expected due to divergent flows chyf allows for secondary diverted flows with the result that one large drainage can leak into another if one or more secondary flows connect them to circumvent this as is implied by mainstems the navigation algorithms could be adjusted to ignore secondary flows or to treat them as primary flows as described below for canada with no equivalent of the level of detail provided by hu12 in the united states the automated technique described above is worth investigating further provided the input data are of sufficient quality it may be practical for major mainstems and drainage basins to be determined relatively quickly across much of the country 3 6 case study summary the collection of case studies presented show the utility of mainstems to integrate point representations of hydrologic locations linear representations of flowpaths and polygon representations of catchment boundaries the first uses mainstems as the primary index in a network navigation and linked data discovery utility the second demonstrates how mainstems can be used to associate catchment outlets using mainstem matching the third shows how mainstems can integrate mainstem collections of linear flowpaths and polygon catchment boundaries the fourth provides an important test and demonstration of how the mainstems data model behaves in headwater areas the final case study illustrates how the mainstems model can extend to datasets from other countries and those that are implemented using graph concepts while generally positive the results if these case studies illustrate some important limitations of mainstems the first is that headwater is a scale dependent location and each hydrographic dataset considered has one upstream most catchment along a given path the entire upstream most feature could be considered a representation of the headwater of the mainstem in question as a result anything upstream of the outlet of a headwater catchment area itself a small drainage basin should not be expected to match from one dataset to another this is illustrated in fig 6 where the red line is one rf1 segment and the blue line is the nhdplusv2 level path with the same outlet the rf1 segment is a headwater path that diverges from the nhdplusv2 the data model has value in that it provides a stable reference for a mainstem but for the upper extents of a mainstem the precision is limited by the resolution of the datasets in question practically this means the mainstems data model should be used with caution in headwaters divergences present some interesting issues for mainstems practically there were three types of divergences encountered in the case studies 1 anthropogenic divergences 2 hydrologic divergences and 3 complex flowpaths anthropogenic divergences are not directly considered by mainstems other than treating them as hydrologic locations hydrologic divergences form new headwaters and a specific data model for locating headwaters of divergences along their source flowpath could be the subject of future work complex flowpaths such as a river encircling an island may be represented by a single line in one dataset and several segments in another in this case all flowpaths could be considered part of the mainstem as there is no independent drainage basin resolved in mainstems the distinction between hydrologic divergences and complex flowpaths is dependent on the resolution of the smallest drainage basins in a given implementation of mainstems as a result we suggest the mainstems model be used on basins of sufficient size to have an established flowpath in general the case studies demonstrate that using a single mainstem that flows from a headwater source area to the outlet of a drainage basin has great utility for persistent identification of rivers in hydrographic addressing mainstems can provide a minimum yet sufficient set of easily identified linear paths through a hydrologic network for integration of hydrologic locations and linear and aerial representations of catchment networks mainstems provides a data model and set of assumptions that aid processing 4 considerations and future work the australian hydrologic geospatial fabric commonwealth of australia bureau of meteorology 2012 introduces the concept of contracted nodes as permanent hydrologic locations that are intended to persist through space and time mainstems does not include this concept explicitly however the nexuses of persistent mainstem flowpaths confluences are implicit contracted nodes a given implementation of mainstems could create identifiers for these mainstem confluence locations and other important hydrologic locations in the spirit of contracted nodes as an implementation issue chyf allows for these major nexuses to be identified as contracted nodes mainstems assumes that all drainage basins have one headwater and one outlet this assumption is only valid for drainage basins that have a mainstem that terminates at its outlet areas with no flowpaths either upstream of a first order flowpath or along the shore of a waterbody so called zero order catchments dietrich 1987 are not accounted for in mainstems such areas must be encompassed in a drainage basin that includes an identifiable mainstem in order to be included in the hydrologic landscape this is not an issue for flowpath oriented hydrologic integration and addressing but will need to be accounted for in future work aimed at integration of surface water groundwater and especially waterbodies the upstream most location of a mainstem is not a single point in reality there is some drainage basin without flowpaths upstream of the top of the initiation of flowing water these locations might be a wetland a spring a glacier or a field in each case there are unique nuances of hydrogeomorphology that dictate how and when a mainstem can be said to exist exploration of data models to support these kinds of headwater areas to more concretely establish the characteristics and geometry of headwaters is left for future work if implemented for all rivers from large to small the mainstem drainage basin paradigm implies a collection of incremental catchments that cover the landscape it does not address the specific logical data model for implementing them when disaggregating the landscape into a collection of incremental catchments these catchments correspond to a directed acyclic graph with each catchment draining into another the associated flowpaths form a separate directed acyclic graph that can be combined with the first such that catchments and flowpaths are represented in the same graph each drainage basin and mainstem can be defined as the union of elements represented in the graph a wide array of hydrologic locations such as tributary confluences too small to be part of the mainstems network stream gages dams and outlets of major waterbodies can all be related to locations on the graph thus a specific data model for incremental catchments and associated flowpaths can be built on graph theoretical constructs chyf does exactly this by providing a logical data model defined as a profile of hy features in the context of graph theory this approach has two strong benefits provided that the data are topologically clean with correct flowpath catchment relationships at nexuses the first benefit is that assigning identifiers to graph elements and building the directed acyclic graph using them is a fast process this limits the importance of maintaining identifiers especially for smaller streams and catchments since point and linear referencing along the flowpath network can be based on xy coordinates the second benefit pertains to the fast navigation through the graph that can be implemented which can be combined with a new coverage union operation davis 2019 to quickly create drainage basins or other large catchments from incremental catchments chyf recognizes the importance of mainstems and drainage basins supports them in its data model and will be adding services to support their use 4 1 conclusion this research documents the design and testing of the mainstems data model the case studies presented in this paper demonstrate that hy features concepts which are the basis for mainstems are compatible with varied historical datasets that the mainstems data model supports both hydrologic indexing hydrographic addressing and network navigation functions and that mainstems based logic supports integration of hydrographic data in ways that spatial integration alone cannot the case studies illustrate important limitations of mainstems in headwater regions and how the dendritic assumption of the model can accommodate divergences as hydrologic locations our research has shown that mainstems provides a useful approach to support persistent identification through a minimum yet sufficient set of networked hydrologic features declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests acknowledgements all u s geological survey work documented in this paper was funded by the u s geological survey water mission area water availability and use science program the ongoing development of the common hydrology features model is being funded by the centre for mapping and earth observation ccmeo natural resources canada and supported by both that agency and the national hydrological services environment and climate change canada usgs personnel have also provided substantial support and encouragement to chyf developments through ongoing interaction with ccmeo appendix a terminology and concepts note the source of the term is denoted as hy features or mainstems 7 1 1 areal features catchment hy features hy features defines the catchment concept as a holistic geomorphic feature type that represents all the aspects of hydrology draining to an identified outlet catchments are typically organized in a hydrologic cascade that fully partitions the landscape only breaking at major waterbodies a catchment receives flow from zero or one inflows and contributes flow to zero or one outlets drainage basin mainstems like the catchment feature type a drainage basin is also a holistic feature it is defined as the total upstream area draining to an outlet it is comparable to a catchment with no inflows and a single outlet drainage basins can be thought of as a total accumulated or total upstream catchment while having no formal description in hy features drainage basin is a commonly used term petts 1996 schumm 1977 a drainage basin can be described with a pair of locations 1 the headwtater area with no discernible flowpaths where flow initiates and 2 the outlet where flow enters a larger river or waterbody a single mainstem flowpath connects a drainage basin s headwater to its outlet 7 1 2 location features hydrologic nexus hy features a hydrologic nexus shortened to nexus represents the interface along a flowpath between two or more catchments one or more catchments contribute flow to a nexus which contributes flow to one or more other catchments conceptually a nexus can be defined anywhere on the landscape but datasets typically establish them at confluences along a flowpath or other important network locations such as stream gaging stations hydrologic location hy features any location that can be thought to be on a hydrologic network a hydrologic location may or may not be coincident with a hydrologic nexus any geospatial representation of a hydrologic nexus is inherently a hydrologic location hydrologic locations are commonly associated with multiple hydrographic datasets and or hydrologic models providing points of integration outlet hy features an outlet defines the most downstream location in a catchment where water exits into the ocean or the next downstream waterbody or catchment hy features formalizes the type of hydrologic location as a catchmentoutlet which is functionally where flow exits a catchment and a nexus is where multiple catchments flow mix and or split to contribute to one or more downstream catchments practically every catchment drains to a single outlet hydrologic nexus which could be represented by a catchmentoutlet hydrologic location headwater mainstems a headwater is scale dependent and represents the most upstream location where water can theoretically exist in a drainage basin typically on a drainage basin boundary given that the definition of a flowpath does not necessitate the existence of water headwater can be imagined as a point where an extended flowpath touches a drainage basin boundary much in the same way location theory explains how the location of economic activities can be determined on a broad level such as a region or metropolitan area or on a narrow one such as a zone neighborhood city block or an individual site the idea of headwaters can be defined by a drainage basin boundary hillslope or a specific point in space 7 1 3 linear features flowpath hy features a flowpath represents a one dimensional idealized path that water follows through a catchment in the case of a catchment with no inlet a flowpath might extend along a main path to the catchment boundary mainstem mainstems the mainstem concept extends and constraints the concept of a flowpath by designating a single path from a headwater source to an outlet as the primary water feature used to traverse the network through a drainage basin in other words a mainstem is a linear realization or backbone of a drainage basin appendix b hydrographic data sources 9 1 1 river reach file 1 the rf1 was first introduced by the u s environmental protection agency in 1985 horn 1994 it is a linear network of major rivers in the continental united states dewald 2015 the version of the rf1 used here is the most recent version which has been quality controlled for network connectivity and value added attributes such as drainage area and time of travel nolan 2003 the rf1 network includes only linear representations of rivers which are referred to as segments some non dendritic connections are present but all connections have an identified primary path in the network 9 1 2 watershed boundary dataset the wbd u s geological survey 2013 u s geological survey 2019 is a collection of nested basin boundaries based on a hierarchical drainage system of hydrologic units for the united states major river basins are given two digit codes and progressively smaller hydrologic units are identified by 4 6 8 10 and 12 digit hydrologic unit codes shortened to hu2 through hu12 the wbd has developed over time with improvements in elevation data used for delineation and knowledge of hydrologic characteristics two versions of the wbd are used a static snapshot of the hu12s that was used in the production of the nhdplusv2 moore and dewald 2016 and the current release which includes the best available geometry and attributes at the time of access usgs 2018 an attribute tohu provides routing capabilities and dendritic hydrologic unit connectivity it is used extensively to identify the network of wbd hu12s in this paper 9 1 3 national hydrography dataset plus the nhdplus has two static versions v1 and v2 that share the same data model moore and dewald 2016 mckay 2015 bondelid 2010 nhdplusv2 is used almost exclusively here the nhdplusv2 provides an integration of linear river geometry polygonal catchment boundary geometry gridded elevation data and value added attributes such as landscape characteristics and flow estimates nhdplusv2 is created with a catchment delineation algorithm where pre existing river flowlines and hydrologic units are used to modify elevation data in preparation for flow direction accumulation processing nhdplusv2 catchment boundary geometries are created for each incremental typically confluence to confluence nhdplusv2 flowline segment numerous value added attributes have been created for each set of catchments the value added attributes associated with network connectivity and navigation are of particular importance here 9 1 4 national hydro network the nhn model was first published as a canadian standard in 2004 nhn pertains specifically to features associated with the hydrographic network and does not include descriptions of catchments or their boundaries although linear referencing is described in the model it has not been implemented as well hierarchical and containment relationships are not an explicit part of the model one of the main drivers behind the nhn has been to produce a national coverage suitable for network analysis the nhn data are grouped into 1382 large drainage areas that cover canada these correspond to the water survey of canada sub sub drainage areas the nhn has been created from existing topographic data ranging in scale from 1 50 000 to 1 20 000 the data are categorized into four completeness levels cl1 through cl4 these levels pertain respectively to network topology waterbody differentiation data continuity and toponymy belzile 2008 united states canada cross border hydro harmonization efforts under the international joint commission have been based on the nhdplus and the nhn 9 1 5 common hydrology features chyf is a recent data model developed by natural resources canada that implements catchment boundaries for incremental linear river geometries chyf incorporates the concepts and capabilities of graph theory applied to hydrologic elements in an analogous fashion to routing and navigation through a road network and uses the concepts of hy features catchments and flowpaths can be defined at different levels of granularity chyf supports the functional scope of the nhdplusv2 while allowing for regular updates to underlying data and maintaining stability for integrated applications chyf specifies a hy features profile and includes some extensions required to implement graph theoretic functionality the latter involves the definition of what is called a hygraph a graph structure made up by features referred to as elementary catchments elementary flowpaths and hydronodes version 0 9 of chyf is being finalized at the time of this writing and supports the mainstem and drainage basin concepts described here sondheim and hodgson 2019 
25923,computer programs have taken an important role in the prediction of future ecological trajectories this study reviewed the existing computer programs that aim to predict future trajectories of ecosystems biological populations or ecological systems overall 106 programs were examined a rich set of programs exist and most of them are free a substantial proportion 43 are distributed open source a majority 57 of these programs took some form of uncertainty into account although not always in a rigorous way programs considering uncertainty were preferentially implemented in a standard compiled language c fortran or a statistical language r the vast majority of the programs were delivered with recent sometimes extensive documentation none of the reviewed programs used an open source collaborative framework two points require future attention from developers of software for ecological prediction greater care in the implementation of uncertainty particularly with appropriate statistical methods and adoption of an open source collaborative framework keywords biodiversity ecosystem forecasting modelling software prediction is very difficult especially about the future https quoteinvestigator com 2013 10 20 no predict 1 introduction computer programs and software systems have taken an increasingly important role in predicting the future trajectories of ecosystems and natural populations the increasing impact of human activities on ecosystems has increased the need for predicting their consequences positive or negative in 2016 the intergovernmental science policy platform on biodiversity and ecosystem services ipbes published a report on modelling and scenarios of biodiversity and ecoystem services stating among other things that scenarios and models can contribute significantly to policy support even though several barriers have impeded their widespread use to date ipbes 2016 p xii however a number of weaknesses in the use of models were pointed out in this report for example currently available scenarios do not fully address the needs of platform assessments due to incomplete consideration of relevant drivers policy goals and intervention options another important point in this ipbes report relates to uncertainty of preditions uncertainty associated with models is often poorly evaluated and reported in published studies which may lead to serious misconceptions p xxvi computer simulations are a central part of assessing future responses of ecosystems or natural populations that face environmental changes botkin et al 2007 dawson et al 2011 bonnot et al 2017 dijak et al 2017 some specific applications of simulations include predicting future biodiversity responses to climate changes trisurat et al 2010 2014 staudinger et al 2013 mantyka pringle et al 2014 baltensperger and huettmann 2015 mapping ecosystem services kong et al 2018 life cycle assessment chaplin kramer et al 2017 food security mason d croz et al 2016 or future land use lehsten et al 2015 requena mullor et al 2017 some attention has been paid on the development and validation of conceptual frameworks used to predict future trajectories of ecosystems drielsma et al 2014 oliver and roy 2015 zasada et al 2017b however it is not clear how best practices in the development and implementation of these computer programs can be enhanced to improve predictions as well as policy recommendations newman et al 2017 zasada et al 2017a for instance ipbes 2016 p 61 emphasized the lack of repeatability of approaches such as strategic environmental assessments clearly computer programs have an important role to play here since uncertainty assessment is typically based on computer intensive methods the rise of open source software and worldwide networks such as the internet has been a formidable stimulus for the development and spread of computer resources for instance scientific fields such as bioinformatics have now adopted a free and open source software foss model for the publication of computer programs furthermore the availability of freely distributed computer programs is a requirement for publication in journals such as bioinformatics bmc bioinformatics or methods in ecology and evolution foss is not only about the price of the computer programs but also about portability repeatability and open knowledge wheeler 2015 the following definitions are used in this paper an ecological system is a set of interacting living entities that also interact with their environment which can itself be composed of living and or non living entities an ecosystem is an ecological system that is restriced to a geographically defined area e g a lake a forest a biological population is an ecological system whose entities are individuals belonging to the same species so their interactions are directed by some specific activities e g mating feeding an ecological system is characterized by a number of variables e g nutrients species richness number of individuals age structure prediction aims at finding the predicted values of these variables in the future in this paper i report the results of an investigation of the availability of computer programs aimed at predicting the future trajectories of ecosystems ecological systems or biological populations the main objectives were firstly to provide a global picture of the software ecosystem manikas 2016 available for ecological prediction and secondly to identify the issues that require attention to improve this ecosystem following the statements from ipbes some suggestions on future directions are given at the end of this paper 2 methods computer programs aimed at prediction of ecosystems ecological systems or biological populations were searched using internet search engines and the literature the programs selected for further analysis were those available for download or purchase the programs available for purchase were considered to answer some of the questions below but were not purchased all the investigated programs were downloaded and checked for some features programs were selected on the basis that they provide tools models or approaches that can be directly related to prediction of ecosystems populations or other ecological systems programs dedicated to human health or epidemiology were excluded specifically the following questions were addressed for each program 1 what is are the computer language s used to implement the program 2 is the program freely distributed 3 is the source code of the program available 4 what operating systems oss are supported 5 what is the main output file format 6 is it a specialist or a generalist program 7 does the program consider uncertainty 8 is a manual available if yes how many pages 9 is there a support for users 10 is there a mailing discussion list these questions were defined before investigating the programs however the way they were addressed was adjusted during the study considering the large number of programs found that meet the above criteria it was not practically possible to run and test all of them the answers to questions 1 and 3 7 were searched by reading the documentation or the general presentation of the program e g section about of a web page questions 2 and 8 10 were answered by looking at the web pages of the program further information to answer questions 1 3 and 8 were found by inspecting the downloaded programs questions 2 and 3 are not independent and are related to the distribution licence of the programs however the licence under which a computer program is distributed is a complex issue as illustrated by the many existing free licences e g https en wikipedia org wiki free and open source software furthermore a program can be published under several licences or its licencing status can change through time e g https www r project org licenses although this is clearly an important isssue it was out of the scope of the present study which considered only the availability of source code questions 3 and 4 were connected since some programs are distributed simply as source code and not as compiled executables for one or several specific oss so source code was a separate category when answering question 4 in order to be more specific if any form of source or computer code was available then the program was considered as open source question 3 whereas if a program was packaged only with its source code then it was considered as source code question 4 thus a program could be open source while not being distributed as source code whereas a program classified as source code is necessarily open source the distinction between these two categories stems from the fact source code programs are often independent of the os in order to answer question 6 the programs that model a specific system e g diffusion of pollutants or consider a specific geographical area were classified as specialist programs that consider or model a system which can be considered generic e g a biological population a watershed were classified as generalist question 6 stems from the importance of being able to use the outputs of a program for further downstream analyses with other program s for instance for uncertainty assessment or graphical display question 7 was answered yes if the documentation mentioned uncertainty explicitly or the approach described in the documentation was probabilistic all data analyses and graphics presented below were done with r version 3 6 0 r core team 2019 the r code is available in the supplementary information 3 results a large number of web pages and resources were found a substantial number of programs were described in development or coming soon other programs were listed on some web pages but could not be located or downloaded these orphaned or lost programs were not counted precisely in the end of the search 106 computer programs were found and examined table s1 the majority of the programs selected for this study 59 or 56 were distributed by a us federal agency main domain of the web site url ending with gov mil or us these included 24 programs by the environmental protection agency epa 15 by the us forest service usfs 11 by the us army corps of engineers usace three by the us department of agriculture usda and three by the us geological service usgs almost all programs were distributed on dedicated web pages only two were distributed on github and two others on r forge one hundred and two programs 96 were available free some of them after registration three were available as commercial products and one was available as a free demo version for 34 programs 32 it was not possible to find the computer programming language or platform used for implementation for 24 programs 23 a standard compiled language c or fortran or one of their variants or dialects f77 f90 c or c was used fig 1 eleven programs were implemented in excel six in r six in python six as argis modules four in java one in julia and one in delphi six programs were modules of commercial programs e g sas matlab finally seven programs were available as web forms through internet and not available for download forty six programs 43 were available as open source 33 31 were distributed only as compiled applications and their sources were not available one was available as open source subject to collaboration and four were commercially distributed the open source status of the remaining 22 programs 21 could not be determined fig 2 for the analysis of oss the programs coded in excel or in java were considered as source code because a wide range of office applications can run excel spreadsheets on most oss and there are many java environments on most oss as well the vast majority of programs were available as applications running under windows 73 or 69 or even only for this os 55 or 52 fig 3 twenty nine 27 programs were distributed as source code and exclusively in this form for 22 of them mainly as excel code and secondarily as r programs which are os independent only one program was available only for linux and none of them were distributed as macos application additionally one program run under 16 bit ms dos and the running os of two programs was not found a majority of programs 47 or 44 output their results as text files either only 37 or 35 or in association with other formats gis or hdf5 fig 4 six programs output their results in various file formats labelled as many on fig 4 seventeen programs 16 did not output files 13 output excel files and two output results in files that cannot be interfaced with other software pdf reports or private format finally the output format could not be determined for 13 programs 12 the vast majority of the programs 71 or 67 were specialist there seemed to be an association between this variable and the programming language used programs coded in excel or as web forms were all specialist whereas the generalist ones were more represented among the programs implemented in c fortran r or under a commercial platform fig 5 no association with other variables were apparent uncertainty was a feature in 60 57 programs while this could not be found in six of the 106 6 there was a very significant association between this variable and whether a program is specialist or generalist among the 35 generalist programs 30 took uncertainty into account whereas 30 specialist programs did out of 71 fisher s exact test p 0 0001 this test excluded the six programs where handling of uncertainty was unknown there was also an association with the programing language programs taking uncertainty into account were implemented in c fortran r all four of them or with commercial programs also all four of them fig 6 on the other hand programs in python excel or available as web forms did not mostly consider uncertainty a manual in pdf format was available for 71 programs 67 in html for 18 17 as an on line wiki for three and no manual or documentation was found for 12 of them 11 fig 7 the mean number of pages of the manuals in pdf format was 234 sd 346 median 104 min 6 max 2262 most of the available documentation was recent 55 52 were dated after january 1 2016 and six were produced in 2020 fig 8 the oldest manual was dated september 1994 and six manuals were dated before 2001 support to users was offered on the web pages for 76 72 of the programs non free support was proposed for one program and no apparent support was observed for the remaining 29 programs a mailing list was found for 20 programs 19 there was no apparent association between these two variables and the previously analysed ones 4 discussion the present study leads to draw an overall positive picture of software for ecosystem prediction a remarkable diversity of free programs are available their associated documentations are generally of good quality sometimes very extensive and a good percentage 43 are also distributed open source another significantly positive feature is that a majority of programs output their results in file formats which are easily read by other software considering that excel files can be open by many other programs see for instance the r package readxl wickham and bryan 2019 remarkably us federal agencies took a major part of the programs considered here this highlights several points first this emphasises the importance of public agencies in making available to the public the research work on ecosystems and biodiversity second a substantial number of these programs were published before 2000 so that they constitute an important archive for researchers and students even if the distributed programs are only available as executables running on vintage os the associated documentation often containing the model description details on the algorithms and references to the literature is a very useful source of information third most of these programs are distributed as windows executables which explain at least partly the predominance of this os uncertainty was considered in a majority of programs 57 unfortunately it was not possible to assess for the present study whether uncertainty is correctly implemented in these programs for instance some manuals state that uncertainty can be taken into account by changing the input parameters of the program this is a crude approach which could be useful in some situations e g if the predictions are not changed substantially by the different input parameter values but that could lead to difficulties in interpreting the results if the predictions differ with respect to the input parameter values a more rigorous approach would be to weigh the outputs by the likelihood of the input values there is a vast literature on this topic especially oriented towards the use of bayesian methods hoeting et al 1999 clyde and george 2004 uncertainty is a difficult topic that often requires computationally intensive methods and or sophisticated statistical techniques draper 1995 evans and swartz 1995 efron and hastie 2016 even if some of these methods are complicated to implement weighting outputs by the likelihood of the input values seems as a bare minimum to take uncertainty into account from a practical point of view it is important for programs to include the possibility to save their outputs in a format which can be read and write by the vast majority of software typically text parallel computing will also certainly attract more attention in the future in order to implement such intensive computing tasks interestingly parallel programming is available in the major languages observed in this study c c fortran r python it is interesting to note that the programs considering uncertainty were preferentially implemented in compiled languages c fortran or in a statistical language r this highlights the need to use a performing computer language to implement uncertainty moreover these languages are widely used free and efficient implementations e g the gcc compilers are available to all users it appears therefore that considering uncertainty in a program devoted to ecosystem prediction has several benefitial effects it not only increases its usefulness and relevance for prediction but it also increases its likelihood to use an efficient open source implementation open source is not yet a prominent feature of software for ecosystem prediction however the above observations are encouraging the programs that take uncertainty into account are more likely to be implemented in a language commonly associated with open source interestingly a number of programs 7 distributed for windows are also available as source code this emphasises that open source is independent of the os on the other hand the software for ecosystem prediction clearly lag behind other scientific fields in terms of code sharing only two programs are currently distributed on github a platform for code sharing used by dozens of thousands of developers and currently hosting more than 100 million repositories quite illustrative of this sympton none of the r packages reviewed here are distributed on the comprehensive r archive network cran which is the standard internet repository of r packages the more than 15 000 packages currently on cran are checked daily to ensure that they can be installed and run correctly on most common operating systems currently linux windows macos x and solaris it is regrettable that the computer programs for ecosystem prediction do not currently benefit of this free service open source is not only about the price of the software it also makes possible to develop code in a more transparent and efficient manner with two major side effects scalability and integration the latter feature is of particular importance for ecosystem prediction indeed predicting future ecosystem trajectories or some of its characteristics such as ecosystem services often requires the integration of different components titeux et al 2016 di minin et al 2017 open software makes integration of different components much easier than closed systems wheeler 2015 in this perspective the integration of spatial data for instance land use and land cover data is a predominant feature of many studies attempting to predict changes in ecosystems or biodiversity titeux et al 2016 bonnot et al 2017 chaplin kramer et al 2017 newman et al 2017 reviewed 101 papers on decision support systems and found that most effort has been placed on assessing areas of risk and economic consequences of direct losses whereas less effort has been placed on assessing risk reduction options these authors listed a series of recommendations for future research although they did not mention explicitly the development of better software this is clearly an area that deserves to be considered as carefully as others as rightly stated by these authors impacts of natural hazards are likely to increase significantly in the future so that more rigorous predictions of environmental changes are becoming more and more crucial zasada et al 2017b performed a review of 60 european projects aiming at developing decision support systems and found that 88 of them were available after two years and only 61 after eight years furthermore only 50 of these tools are being updated after the end of the project interestingly only a small portion of these tools 3 4 were available as downloadable programs and a minority 31 were integrated with other tools no mention of either source code or open source is made in this study 5 conclusion and recommendations the present study agrees with some statements from ipbes notably there are large gaps in the availability of data for constructing and testing scenarios and models and significant barriers to data sharing remain ipbes 2016 p xxvii such statements clearly call for significant improvements of the software ecosystem for ecosystem prediction in addition to the recommendations from ipbes i wish to formulate a few recommendations 1 open source this feature is coming into wider acceptance in many scientific fields including ecosystem prediction however open source should be considered in the wider context of portability so that software can be installed and run on as many computing platforms as possible in this perspective the computer languages r c and fortran and the dialects of these last two appear as best choices to implement software for ecosystem and biodiversity prediction there are free implementations for all common oss of these languages furthermore they make possible high performance computing and there already exist a wide range of tools in these languages to handle the data commonly encountered in ecosystem modelling see for instance the package rgdal for reading gis data in a wide range of formats bivand et al 2018 2 uncertainty there is need to have more rigorous implementation of uncertainty in ecosystem predictive modelling the statement that different input parameter values can be tested is not generally a valid approach and should be avoided statistical techniques such as weighted integration should be considered more widely 3 output file formats greater care should be taken on output formats even if using the standard text output files a number of difficulties may be encountered typically related to encoding text layout or file sizes for gis data an open binary format e g geotiff or netcdf for more complex data structures should be preferred to simple text files the main criterion for guiding decisions in an open source software development project should always be quality over quantity releasing a lot of computer code that it is not operational that has not been tested or documentated is very likely to be a waste of resources declaration of competing interest the author declares that he has no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements i am thankful to four anonymous reviewers for their very constructive comments this is publication isem 2020 233 this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104872 
25923,computer programs have taken an important role in the prediction of future ecological trajectories this study reviewed the existing computer programs that aim to predict future trajectories of ecosystems biological populations or ecological systems overall 106 programs were examined a rich set of programs exist and most of them are free a substantial proportion 43 are distributed open source a majority 57 of these programs took some form of uncertainty into account although not always in a rigorous way programs considering uncertainty were preferentially implemented in a standard compiled language c fortran or a statistical language r the vast majority of the programs were delivered with recent sometimes extensive documentation none of the reviewed programs used an open source collaborative framework two points require future attention from developers of software for ecological prediction greater care in the implementation of uncertainty particularly with appropriate statistical methods and adoption of an open source collaborative framework keywords biodiversity ecosystem forecasting modelling software prediction is very difficult especially about the future https quoteinvestigator com 2013 10 20 no predict 1 introduction computer programs and software systems have taken an increasingly important role in predicting the future trajectories of ecosystems and natural populations the increasing impact of human activities on ecosystems has increased the need for predicting their consequences positive or negative in 2016 the intergovernmental science policy platform on biodiversity and ecosystem services ipbes published a report on modelling and scenarios of biodiversity and ecoystem services stating among other things that scenarios and models can contribute significantly to policy support even though several barriers have impeded their widespread use to date ipbes 2016 p xii however a number of weaknesses in the use of models were pointed out in this report for example currently available scenarios do not fully address the needs of platform assessments due to incomplete consideration of relevant drivers policy goals and intervention options another important point in this ipbes report relates to uncertainty of preditions uncertainty associated with models is often poorly evaluated and reported in published studies which may lead to serious misconceptions p xxvi computer simulations are a central part of assessing future responses of ecosystems or natural populations that face environmental changes botkin et al 2007 dawson et al 2011 bonnot et al 2017 dijak et al 2017 some specific applications of simulations include predicting future biodiversity responses to climate changes trisurat et al 2010 2014 staudinger et al 2013 mantyka pringle et al 2014 baltensperger and huettmann 2015 mapping ecosystem services kong et al 2018 life cycle assessment chaplin kramer et al 2017 food security mason d croz et al 2016 or future land use lehsten et al 2015 requena mullor et al 2017 some attention has been paid on the development and validation of conceptual frameworks used to predict future trajectories of ecosystems drielsma et al 2014 oliver and roy 2015 zasada et al 2017b however it is not clear how best practices in the development and implementation of these computer programs can be enhanced to improve predictions as well as policy recommendations newman et al 2017 zasada et al 2017a for instance ipbes 2016 p 61 emphasized the lack of repeatability of approaches such as strategic environmental assessments clearly computer programs have an important role to play here since uncertainty assessment is typically based on computer intensive methods the rise of open source software and worldwide networks such as the internet has been a formidable stimulus for the development and spread of computer resources for instance scientific fields such as bioinformatics have now adopted a free and open source software foss model for the publication of computer programs furthermore the availability of freely distributed computer programs is a requirement for publication in journals such as bioinformatics bmc bioinformatics or methods in ecology and evolution foss is not only about the price of the computer programs but also about portability repeatability and open knowledge wheeler 2015 the following definitions are used in this paper an ecological system is a set of interacting living entities that also interact with their environment which can itself be composed of living and or non living entities an ecosystem is an ecological system that is restriced to a geographically defined area e g a lake a forest a biological population is an ecological system whose entities are individuals belonging to the same species so their interactions are directed by some specific activities e g mating feeding an ecological system is characterized by a number of variables e g nutrients species richness number of individuals age structure prediction aims at finding the predicted values of these variables in the future in this paper i report the results of an investigation of the availability of computer programs aimed at predicting the future trajectories of ecosystems ecological systems or biological populations the main objectives were firstly to provide a global picture of the software ecosystem manikas 2016 available for ecological prediction and secondly to identify the issues that require attention to improve this ecosystem following the statements from ipbes some suggestions on future directions are given at the end of this paper 2 methods computer programs aimed at prediction of ecosystems ecological systems or biological populations were searched using internet search engines and the literature the programs selected for further analysis were those available for download or purchase the programs available for purchase were considered to answer some of the questions below but were not purchased all the investigated programs were downloaded and checked for some features programs were selected on the basis that they provide tools models or approaches that can be directly related to prediction of ecosystems populations or other ecological systems programs dedicated to human health or epidemiology were excluded specifically the following questions were addressed for each program 1 what is are the computer language s used to implement the program 2 is the program freely distributed 3 is the source code of the program available 4 what operating systems oss are supported 5 what is the main output file format 6 is it a specialist or a generalist program 7 does the program consider uncertainty 8 is a manual available if yes how many pages 9 is there a support for users 10 is there a mailing discussion list these questions were defined before investigating the programs however the way they were addressed was adjusted during the study considering the large number of programs found that meet the above criteria it was not practically possible to run and test all of them the answers to questions 1 and 3 7 were searched by reading the documentation or the general presentation of the program e g section about of a web page questions 2 and 8 10 were answered by looking at the web pages of the program further information to answer questions 1 3 and 8 were found by inspecting the downloaded programs questions 2 and 3 are not independent and are related to the distribution licence of the programs however the licence under which a computer program is distributed is a complex issue as illustrated by the many existing free licences e g https en wikipedia org wiki free and open source software furthermore a program can be published under several licences or its licencing status can change through time e g https www r project org licenses although this is clearly an important isssue it was out of the scope of the present study which considered only the availability of source code questions 3 and 4 were connected since some programs are distributed simply as source code and not as compiled executables for one or several specific oss so source code was a separate category when answering question 4 in order to be more specific if any form of source or computer code was available then the program was considered as open source question 3 whereas if a program was packaged only with its source code then it was considered as source code question 4 thus a program could be open source while not being distributed as source code whereas a program classified as source code is necessarily open source the distinction between these two categories stems from the fact source code programs are often independent of the os in order to answer question 6 the programs that model a specific system e g diffusion of pollutants or consider a specific geographical area were classified as specialist programs that consider or model a system which can be considered generic e g a biological population a watershed were classified as generalist question 6 stems from the importance of being able to use the outputs of a program for further downstream analyses with other program s for instance for uncertainty assessment or graphical display question 7 was answered yes if the documentation mentioned uncertainty explicitly or the approach described in the documentation was probabilistic all data analyses and graphics presented below were done with r version 3 6 0 r core team 2019 the r code is available in the supplementary information 3 results a large number of web pages and resources were found a substantial number of programs were described in development or coming soon other programs were listed on some web pages but could not be located or downloaded these orphaned or lost programs were not counted precisely in the end of the search 106 computer programs were found and examined table s1 the majority of the programs selected for this study 59 or 56 were distributed by a us federal agency main domain of the web site url ending with gov mil or us these included 24 programs by the environmental protection agency epa 15 by the us forest service usfs 11 by the us army corps of engineers usace three by the us department of agriculture usda and three by the us geological service usgs almost all programs were distributed on dedicated web pages only two were distributed on github and two others on r forge one hundred and two programs 96 were available free some of them after registration three were available as commercial products and one was available as a free demo version for 34 programs 32 it was not possible to find the computer programming language or platform used for implementation for 24 programs 23 a standard compiled language c or fortran or one of their variants or dialects f77 f90 c or c was used fig 1 eleven programs were implemented in excel six in r six in python six as argis modules four in java one in julia and one in delphi six programs were modules of commercial programs e g sas matlab finally seven programs were available as web forms through internet and not available for download forty six programs 43 were available as open source 33 31 were distributed only as compiled applications and their sources were not available one was available as open source subject to collaboration and four were commercially distributed the open source status of the remaining 22 programs 21 could not be determined fig 2 for the analysis of oss the programs coded in excel or in java were considered as source code because a wide range of office applications can run excel spreadsheets on most oss and there are many java environments on most oss as well the vast majority of programs were available as applications running under windows 73 or 69 or even only for this os 55 or 52 fig 3 twenty nine 27 programs were distributed as source code and exclusively in this form for 22 of them mainly as excel code and secondarily as r programs which are os independent only one program was available only for linux and none of them were distributed as macos application additionally one program run under 16 bit ms dos and the running os of two programs was not found a majority of programs 47 or 44 output their results as text files either only 37 or 35 or in association with other formats gis or hdf5 fig 4 six programs output their results in various file formats labelled as many on fig 4 seventeen programs 16 did not output files 13 output excel files and two output results in files that cannot be interfaced with other software pdf reports or private format finally the output format could not be determined for 13 programs 12 the vast majority of the programs 71 or 67 were specialist there seemed to be an association between this variable and the programming language used programs coded in excel or as web forms were all specialist whereas the generalist ones were more represented among the programs implemented in c fortran r or under a commercial platform fig 5 no association with other variables were apparent uncertainty was a feature in 60 57 programs while this could not be found in six of the 106 6 there was a very significant association between this variable and whether a program is specialist or generalist among the 35 generalist programs 30 took uncertainty into account whereas 30 specialist programs did out of 71 fisher s exact test p 0 0001 this test excluded the six programs where handling of uncertainty was unknown there was also an association with the programing language programs taking uncertainty into account were implemented in c fortran r all four of them or with commercial programs also all four of them fig 6 on the other hand programs in python excel or available as web forms did not mostly consider uncertainty a manual in pdf format was available for 71 programs 67 in html for 18 17 as an on line wiki for three and no manual or documentation was found for 12 of them 11 fig 7 the mean number of pages of the manuals in pdf format was 234 sd 346 median 104 min 6 max 2262 most of the available documentation was recent 55 52 were dated after january 1 2016 and six were produced in 2020 fig 8 the oldest manual was dated september 1994 and six manuals were dated before 2001 support to users was offered on the web pages for 76 72 of the programs non free support was proposed for one program and no apparent support was observed for the remaining 29 programs a mailing list was found for 20 programs 19 there was no apparent association between these two variables and the previously analysed ones 4 discussion the present study leads to draw an overall positive picture of software for ecosystem prediction a remarkable diversity of free programs are available their associated documentations are generally of good quality sometimes very extensive and a good percentage 43 are also distributed open source another significantly positive feature is that a majority of programs output their results in file formats which are easily read by other software considering that excel files can be open by many other programs see for instance the r package readxl wickham and bryan 2019 remarkably us federal agencies took a major part of the programs considered here this highlights several points first this emphasises the importance of public agencies in making available to the public the research work on ecosystems and biodiversity second a substantial number of these programs were published before 2000 so that they constitute an important archive for researchers and students even if the distributed programs are only available as executables running on vintage os the associated documentation often containing the model description details on the algorithms and references to the literature is a very useful source of information third most of these programs are distributed as windows executables which explain at least partly the predominance of this os uncertainty was considered in a majority of programs 57 unfortunately it was not possible to assess for the present study whether uncertainty is correctly implemented in these programs for instance some manuals state that uncertainty can be taken into account by changing the input parameters of the program this is a crude approach which could be useful in some situations e g if the predictions are not changed substantially by the different input parameter values but that could lead to difficulties in interpreting the results if the predictions differ with respect to the input parameter values a more rigorous approach would be to weigh the outputs by the likelihood of the input values there is a vast literature on this topic especially oriented towards the use of bayesian methods hoeting et al 1999 clyde and george 2004 uncertainty is a difficult topic that often requires computationally intensive methods and or sophisticated statistical techniques draper 1995 evans and swartz 1995 efron and hastie 2016 even if some of these methods are complicated to implement weighting outputs by the likelihood of the input values seems as a bare minimum to take uncertainty into account from a practical point of view it is important for programs to include the possibility to save their outputs in a format which can be read and write by the vast majority of software typically text parallel computing will also certainly attract more attention in the future in order to implement such intensive computing tasks interestingly parallel programming is available in the major languages observed in this study c c fortran r python it is interesting to note that the programs considering uncertainty were preferentially implemented in compiled languages c fortran or in a statistical language r this highlights the need to use a performing computer language to implement uncertainty moreover these languages are widely used free and efficient implementations e g the gcc compilers are available to all users it appears therefore that considering uncertainty in a program devoted to ecosystem prediction has several benefitial effects it not only increases its usefulness and relevance for prediction but it also increases its likelihood to use an efficient open source implementation open source is not yet a prominent feature of software for ecosystem prediction however the above observations are encouraging the programs that take uncertainty into account are more likely to be implemented in a language commonly associated with open source interestingly a number of programs 7 distributed for windows are also available as source code this emphasises that open source is independent of the os on the other hand the software for ecosystem prediction clearly lag behind other scientific fields in terms of code sharing only two programs are currently distributed on github a platform for code sharing used by dozens of thousands of developers and currently hosting more than 100 million repositories quite illustrative of this sympton none of the r packages reviewed here are distributed on the comprehensive r archive network cran which is the standard internet repository of r packages the more than 15 000 packages currently on cran are checked daily to ensure that they can be installed and run correctly on most common operating systems currently linux windows macos x and solaris it is regrettable that the computer programs for ecosystem prediction do not currently benefit of this free service open source is not only about the price of the software it also makes possible to develop code in a more transparent and efficient manner with two major side effects scalability and integration the latter feature is of particular importance for ecosystem prediction indeed predicting future ecosystem trajectories or some of its characteristics such as ecosystem services often requires the integration of different components titeux et al 2016 di minin et al 2017 open software makes integration of different components much easier than closed systems wheeler 2015 in this perspective the integration of spatial data for instance land use and land cover data is a predominant feature of many studies attempting to predict changes in ecosystems or biodiversity titeux et al 2016 bonnot et al 2017 chaplin kramer et al 2017 newman et al 2017 reviewed 101 papers on decision support systems and found that most effort has been placed on assessing areas of risk and economic consequences of direct losses whereas less effort has been placed on assessing risk reduction options these authors listed a series of recommendations for future research although they did not mention explicitly the development of better software this is clearly an area that deserves to be considered as carefully as others as rightly stated by these authors impacts of natural hazards are likely to increase significantly in the future so that more rigorous predictions of environmental changes are becoming more and more crucial zasada et al 2017b performed a review of 60 european projects aiming at developing decision support systems and found that 88 of them were available after two years and only 61 after eight years furthermore only 50 of these tools are being updated after the end of the project interestingly only a small portion of these tools 3 4 were available as downloadable programs and a minority 31 were integrated with other tools no mention of either source code or open source is made in this study 5 conclusion and recommendations the present study agrees with some statements from ipbes notably there are large gaps in the availability of data for constructing and testing scenarios and models and significant barriers to data sharing remain ipbes 2016 p xxvii such statements clearly call for significant improvements of the software ecosystem for ecosystem prediction in addition to the recommendations from ipbes i wish to formulate a few recommendations 1 open source this feature is coming into wider acceptance in many scientific fields including ecosystem prediction however open source should be considered in the wider context of portability so that software can be installed and run on as many computing platforms as possible in this perspective the computer languages r c and fortran and the dialects of these last two appear as best choices to implement software for ecosystem and biodiversity prediction there are free implementations for all common oss of these languages furthermore they make possible high performance computing and there already exist a wide range of tools in these languages to handle the data commonly encountered in ecosystem modelling see for instance the package rgdal for reading gis data in a wide range of formats bivand et al 2018 2 uncertainty there is need to have more rigorous implementation of uncertainty in ecosystem predictive modelling the statement that different input parameter values can be tested is not generally a valid approach and should be avoided statistical techniques such as weighted integration should be considered more widely 3 output file formats greater care should be taken on output formats even if using the standard text output files a number of difficulties may be encountered typically related to encoding text layout or file sizes for gis data an open binary format e g geotiff or netcdf for more complex data structures should be preferred to simple text files the main criterion for guiding decisions in an open source software development project should always be quality over quantity releasing a lot of computer code that it is not operational that has not been tested or documentated is very likely to be a waste of resources declaration of competing interest the author declares that he has no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements i am thankful to four anonymous reviewers for their very constructive comments this is publication isem 2020 233 this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104872 
25924,models are important tools to integrate ecological and socio economic knowledge to better understand and manage social ecological systems challenges include among others the adequate representation of feedback loops between the socio economic and the ecological subsystems uncertainties and human behaviour to analyse how well models are able to address these challenges in the fields of biodiversity conservation and ecosystem services management the present paper systematically reviews recent mechanistic models of the field and analyses them with respect to a number of binary criteria the reviewed models generally contain quite a few of the above mentioned system features but still fall short when it comes to the adequate representation of the socio economic dimension sorting the models by the labels given to them by their authors such as ecological economic or system dynamic allows assessing model variation within and among labels and indicates that there is a fruitful level of diversity in the models keywords agent based models bio economic models ecological economic models social ecological models system dynamic models 1 introduction despite various political and scientific initiatives ma 2005 cbd 2007 ipbes díaz et al 2018 teeb 2010 the loss of biodiversity and the degradation of ecosystem services is still ongoing worldwide eea 2019 next to climate change one of the main drivers of these losses is human land use ma 2005 which in turn is driven by the socio economic conditions such as agricultural policy e g lakner et al 2019 under which the land users operate to understand the human induced decline of biodiversity and ecosystem services both the ecological and the socio economic dimensions have to be considered in an integrated manner shogren et al 1999 teeb 2010 wätzold et al 2006 a challenge here is that the coupled ecological and socio economic processes are usually dynamic partly involving feedbacks so that e g the ecological subsystem affects the socio economic subsystem and vice versa polasky and segerson 2009 spatially structured so that e g the distance between habitats affects the dispersal and the survival of a species hanski 1999 or the deforestation in the tropics leads to the fragmentation of rainforests taubert et al 2018 subject to risk and uncertainty since for instance the dynamics of species populations are often influenced by random factors beissinger et al 2002 or systems may tip from one state to another where the location of the tipping point is fully or partly unknown bauch et al 2016 and influenced by non trivial behaviour of humans where humans partly try to maximise their economic profits but in their decisions are also influenced by other motives e g bartkowski and bartke 2018 mathematical models have become important tools for the improvement and support of the understanding prediction and management of complex systems such as the world s climate system e g neelin 2010 or the dynamics of animal diseases e g vicente et al 2019 which also holds for those cases in which several scientific disciplines in particular natural sciences and social sciences need to be considered in an integrated manner voinov 2008 clark 2010 flichman et al 2011 schlüter et al 2012 drechsler 2020 purposes of models are manifold baumgärtner et al 2008 probably the most important being a better understanding of systems and observed phenomena e g getzin et al 2016 taubert et al 2018 prediction of system dynamics e g bauch et al 2016 and decision support e g efsa et al 2017 to increase their relevance for decision support models should ideally consider that human land use is often influenced by agricultural environmental and other policies de vries and hanley 2016 pe er et al 2017 a major obstacle to the development of policies is asymmetric information laffont and mortimort 2002 following the environmental economics literature e g hanley et al 2007 a case of asymmetric information is present when one actor has more information about some relevant facts than another e g when landowners know their costs of carrying out a conservation measure but a conservation agency that wishes to introduce a conservation policy does not the question arises q1 to what extent current models used for the integration of ecology and socio economics in the fields of biodiversity conservation and the management of ecosystem services capture the above mentioned issues of spatial temporal and behavioural complexity and address the needs of deciders and policy makers to address this question a quantitative analysis of research papers from the field is carried out based on a systematic search from the past five years and focusing on mechanistic models the papers are analysed with respect to a number of characteristics including the purpose for which the models have been developed and analysed structural features such as spatial structure or dynamics issues of system complexity such as emergence models of human behaviour issues relevant in policy making and the method by which the model is implemented and analysed with regard to agent based models a similar analysis has been carried out by groeneveld et al 2017 who focus on behaviour of land users and egli et al 2019 who explore the consideration of resilience in agent based models however while these two reviews address model features similar to those listed above they consider different fields of model applications and most importantly consider only agent based models agent based models however form only a limited subset of models integrating ecology and socio economics in the fields of biodiversity conservation and the management of ecosystem services instead next to agent based models in the field are known under very different labels such as bio economic or system dynamic including these other labels on the one hand broadens the scope of the analysis and on the other hand raises additional research questions q2 do different labels reflect different model structures possibly implying different abilities of the models to capture the features and fulfil the purposes described above further how strongly are models of different labels related to each other and do the different labels indicate the presence of separate modelling communities with only limited communication among each other to address these questions the reviewed models are sorted by the labels given to them and the models found under each label are analysed separately and the results compared among the different labels the way models are built and labeled may change over time and thus research question q3 reads what are the magnitudes and statistical significance of these changes to address the three research questions q1 q3 relevant papers from the years 2015 2019 are identified and analysed as outlined above and described in detail below in the methods the results section presents the outcomes of the analyses and in the discussion conclusions are drawn from these outcomes to formulate answers to the three research questions 2 methods 2 1 data collection the research context of the present analysis is mechanistic or process based models that explicitly consider both the ecological and the socio economic dimension of problems in the field of biodiversity resource and ecosystem services management the basis of the quantitative literature review is thus a search with scopus performed in february 2020 for title abs key model w 10 social or socio or economic and model w 10 ecological and biodiversity or resource or ecosystem w 5 service and exclude subjarea medi or exclude subjarea bioc or exclude subjarea arts or exclude subjarea psyc or exclude subjarea nurs or exclude subjarea ceng or exclude subjarea neur or exclude subjarea immu or exclude subjarea mate or exclude subjarea phys or exclude subjarea chem or exclude subjarea heal or exclude subjarea phar or exclude subjarea vete this search string was chosen to detect modelling papers considering i a social economic or socio economic dimension ii an ecological dimension and iii addressing issues of biodiversity resources or ecosystem services note that in scopus the command w n requires that the two connected keywords must not more than n words apart from each other and to avoid an explosion of work load thematic fields most likely to be irrelevant in the context of biodiversity were excluded in total 1082 papers were identified from which 73 66 85 86 and 101 papers fell into the years 2015 2016 2017 2018 and 2019 which form the basis of the present analysis next all the 411 papers were subjected to a rigorous manual screening process to avoid mis classification of papers due to malfunctioning search filters cf zare et al 2017 and ensure that the remaining papers fall into the above defined context about twenty papers dropped out because they were not accessible e g because they appeared in a journal of minor range or not written in english language and or where the model description was too superficial because e g the paper is an extended abstract for a conference to allow for the below described detailed characterisation of the model then a considerable proportion of papers dropped out whose models are of a qualitative conceptual or statistical nature statistical models were excluded because these models are by their nature largely independent of the research context a linear regression analysis e g simply correlates data and looks the same regardless whether the data are from biological social or astronomic observations cf drechsler et al 2007 quite a few papers also dropped out because other than suggested by their title keywords or abstract which were the targets of the scopus search they included only one of the two dimensions of ecology and socio economics or even none of them lastly models containing a mere aggregation of numbers into an index such as ecological footprint analysis or simple multi criteria analysis that did not include any further ecological and socio economic modelling were discarded 2 2 selection of model characteristics and labels as a result 122 papers cf appendix a in the supplementary material are retained which or precisely of course the models in which are characterised by the purpose for which the model was built the structure of the model particular issues addressed and the formal implementation and analysis of the model the selection of the criteria was influenced by drechsler et al 2007 baumgärtner et al 2008 schlüter et al 2012 egli et al 2019 and drechsler 2020 and the criteria are chosen to explicitly address the issues raised in the introduction is the model 1 general 2 specific 3 built for positive analysis 4 built for normative analysis 5 used to improve the understanding of the modeled system or develop theory 6 used to make predictions of the system dynamics 7 used to include stakeholders and or support management decisions does the model explicitly consider 8 system dynamics 9 spatial structure 10 randomness stochasticity 11 feedback loops 12 individual agents 13 networks regarding human actions does the model address issues of 14 asymmetric information 15 prediction and learning of actors and is based on a 16 utilitarian framework in particular the human model of homo oeconomicus 17 or employing alternative non classical models of human behaviour does the model analysis address issues of 18 non linearity such as resilience or discontinuous transitions tipping points 19 emergence in particular spatial pattern formation 20 policy interventions on the system is the model formulated through 21 differential or difference equations 22 algorithms and rules and is it solved or analysed 23 analytically or 24 numerically via computer simulation and how was the model labeled by its authors similar to drechsler 2020 a general model is understood as a model that is not applied to a specific geographically localised case but formulated in a general manner by quantities like economic cost population growth rate etc if a model is analysed numerically it is counted as general if a systematic sensitivity analysis is carried out to explore the general behaviour of the model a specific model in contrast is applied and parametrised to a specific case without any sensitivity analysis positive analysis is understood cf drechsler 2020 as exploring how the system looks like or will develop while normative analysis is understood as addressing how a system should be managed to maximise certain objectives like cost effectiveness or social welfare characteristic 7 is meant to capture participatory modelling approaches e g voinov et al 2018 which includes research were stakeholders are not only sources of information like in a survey but actively and significantly involved in the research characteristic 12 contains multi agent systems gilbert 2007 but also game theoretical approaches tadelis 2013 often with only two agents while networks characteristic 13 can e g be ecological pascual and dunne 2005 or social networks bruggeman 2008 asymmetric information characteristic 14 was explained in the introduction characteristic 16 measures whether decisions are based on the maximisation of some utility function as does e g a welfare maximising policy maker or the rational utility maximising homo oeconomicus while non classical models characteristic 17 may include altruism or inequity aversion in agents e g fehr and schmidt 1999 satisficing behaviour simon 1979 or social interaction such as copying opinions or decisions of other agents weisbuch 2006 or the decisions may be modeled by statistical models with the rest of the model being mechanistic as explained above fitted to observed decisions lewis and plantinga 2007 so that a utility function is or cannot be derived explicitly most models in the sample include some non linear elements however such non linearity in the model structure e g logistic growth of an animal population does not necessarily lead to non trivial model dynamics that can address issues of resilience or tipping points similarly resource management models may contain a feedback loop in their formulation but may be analysed only to identify a monotonic optimal harvesting trajectory non linearity in the context of the present paper characteristic 18 does not refer to such non linearities in the model formulation but only to the question of whether issues of non linearity like resilience are addressed explicitly in the model analysis characteristic 20 addresses e g agricultural policies or the establishment of nature reserves some models contain policies as an exogenous driver but do not explicitly analyse the effects of these policies these models are not classified as considering policy intervention the last question above addresses the observation that models used in the present context have quite different labels such as bio economic or system dynamic 2 3 determination of the frequency distributions of the model characteristics research question q1 having analysed all 122 papers with regard to the 24 characteristics the relative frequencies of the models falling into each of these 24 categories are counted regarding the authors label many models have been given only an unspecific label like simulation model or coupled model and are classified as not specified although the label network model is specific it is not particularly relevant to the issue of ecological and socio economic integration and so network models are also classified as not specified for the five labels with the highest numbers of models the frequencies of the 24 characteristics are counted in the same way as for the set of all 122 models 2 4 determination of relationships between model labels question q2 the counts of the model characteristics in the different model labels are used to identify characteristics typical for each model label to obtain a first understanding of the differences and similarities between the model labels this is followed by a quantitative assessment of the relationships between the five model labels for this the frequency distributions are considered as vectors and pearson correlation coefficients between these vectors are calculated as an indicator of overlap and communication between different modelling communities for each model label the journals are identified in which models of that label are published and the journals are identified that contain a particular number of model labels 2 5 determination of trends in the consideration of model characteristics and model labels question q3 although five years of data is a rather short time frame to detect significant trends two trend analyses are carried out using linear regression with time as the explaining variable in the first analysis the explained variables are the frequencies of the model characteristics within the sample of all 122 models while the second analysis considers the frequencies of the five model labels as explained variables 3 results 3 1 distribution of the model characteristics research question q1 the general distribution of the characteristics based on all 122 models is shown in fig 1 about one third of the models is general while two thirds are specific note that the sum of general and specific models is slightly above 100 since a few papers contain both a general and a specific analysis almost 80 of the models were used for a positive analysis while about 30 are normative note that some papers contain both a positive and a normative analysis about half of the models were analysed for system understanding and theory development about two third were used for prediction while only about five percent were developed and applied in a participatory approach half of the models consider spatial structure stochasticity and feedback loops 80 are dynamic but less than one third consider agents and less than ten percent consider networks asymmetric information is considered only in less than five percent of all models and the consideration of prediction and learning is only slightly more abundant about half of all models include some sort of utilitarian approach of decision making less than 20 assume non classical human behaviour while in the rest of the models modes of decision making or human behaviour are irrelevant or not addressed about one third of the models address issues of non linearity while only ten percent consider emergence effects of policy intervention were analysed in about 30 of the models lastly about one third of the models is equation based while two thirds are algorithmic and almost all models were analysed numerically or by computer simulation 3 2 distribution of the model characteristics for the dominant model labels research question q2 as described in the methods an issue of interest is the label attached to the model by its author s in the sample of 122 papers 24 models were labeled socio ecological or social ecological sem 23 are ecological economic eem 14 bio economic bem 13 agent based or multi agent abm and eight are system dynamic model sdm five models have two labels like agent based social ecological model or ecological socio economic model and were sorted in both respective classes in addition the labels land use model and multi objective model are observed three times each and two game models are in the sample the labels business model carbon cycle model disease economic model growth model and socio hydrological occur once each and all other models are not specified as defined in the methods for the five most frequent labels fig 2 shows the characteristics distributions analogous to fig 1 frequencies between 0 25 and 0 75 this choice is if course somewhat arbitrary in a characteristic indicate that both presences and absences are quite abundant so that this characteristic is neither very typical nor very untypical for the considered model label larger frequencies 0 75 in contrast indicate that the characteristic is typical for the model label while smaller frequencies 0 25 indicate that the characteristic is untypical table 1 summaries for each label the typical and the untypical characteristics by these definitions of typical and untypical participatory approaches or decision support are untypical purposes for all model labels except for the eem all model labels are typically dynamic typically there is no consideration of networks asymmetric information or learning with the exceptions of abms consideration of emergence is untypical and models of all labels are typically analysed numerically beyond this abms recall according to the authors own labelling are typically used for positive and not for normative analysis contain many of the features like stochasticity and feedbacks etc and consider non classical human behaviour policy analysis is untypical as well as an equation based formulation instead the models are typically formulated and solved algorithmically bems are typically deterministic employ a utilitarian framework like the human model of homo oeconomicus and are equation based they typically disregard non linearities and are equation based agent based approaches including the consideration of non classical behaviour are untypical in eems sems are very similar to the abms but in contrast and like the eems typically disregard non classical behaviour and emergence sdms are typically specific and not general are used for positive rather than normative analysis and for prediction they are typically non spatial and deterministic but consider feedbacks they do not consider agents and since they are typically not used for normative analysis like cost effectiveness analysis they also do not use a utilitarian framework like the bems they are typically equation based if a model characteristic is found typical or untypical in only one model label then that model label may be regarded as distinctive in the considered characteristic by this definition abms are distinctive by their consideration of spatial structure and stochasticity and naturally by their use of an agent based approach this allows them to distinctively consider non classical behaviour and implies that they are formulated algorithmically rather than through mathematical equations bems in contrast are distinctive by their use of a utilitarian framework and their formulation through equations eems and sems are by the present definition not distinctive in any characteristic however one should note that these outcomes of course depend on the choice of the thresholds 0 75 and 0 25 by which a characteristic is denoted as typical or untypical respectively the fact that sems e g are not distinctive for feedback loops is because on the one hand the proportion of models with feedback loops in that label 0 72 is below the threshold of 0 75 and on the other hand by the chosen definition a model label is distinctive in a characteristic only if it is the only label in which that characteristic is typical and because feedback loops are typical also for abms if the threshold was lowered for instance to 0 7 feedback loops would be typical for both abms and sems and none of both labels would be judged distinctive with respect to feedback loops therefore if a label is not denoted as distinctive by a particular characteristic this does not imply that this characteristic is rare in that label but it means that the label does not stand out in this characteristic relative to the other labels 3 3 relations between the models question q2 continued in the previous section the main similarities and differences between abms bems eems sems and sdms have been highlighted according to table 1 quite a lot of the 24 characteristics are either typical or untypical or neither of both in most or even all model labels only 12 instances were found where a model label is distinctive by a certain characteristic grey shaded cells in table 1 the degree of overlap between the five model labels can be measured quantitatively by regarding the frequency distributions in fig 2 as vectors and calculating the pearson s correlation coefficients between these vectors table 2 the average correlation between a model label with the four respective others labels ranges from 1 8 4 0 45 abm to 0 71 eem and 0 74 sem the highest pairwise correlation is between bem and eem 0 90 sem and sdm 0 81 and sem and eem 0 80 these results identify quite a substantial overlap between the model labels in particular between bio economic ecological economic and social ecological models one may wonder whether this overlap also reflects in the journals in which the models were published comparing the diagonal cells of table 3 with the off diagonal cells reveals that for each model label the umber of unique journals in which no other model label was observed given in the diagonal cells of the table is about equal to the number of journals in which also other model labels were found given in the off diagonal cells although the smallness of the sample size demands some caution this indicates that the authors of different model labels partly prefer different journals to publish their papers but that there is also a substantial overlap through shared journals the broadest journals in that sense that contain more than two model labels are ecological economics containing bem eem sem and sdm ecological modelling containing abm bem eem and sem journal of environmental management containing abm bem eem sem proceedings of the national academy of sciences of the usa pnas containing abm bem sem and sdm and land use policy containing bem eem and sem 3 4 trends question q3 the first part of the trend analysis is to relate the number of papers represented by each model label to the publication year for the numerical values see appendix c in the supplementary material table 4 shows the average annual changes and their statistical significance obtained by linear regression while bems eems and sdms exhibit slight but highly insignificant declines there is a weakly significant increase of about one abm paper per year and a strongly significant increase of about two sem papers per year for comparison for the years 2015 2019 the sum of the numbers of abms bems eems sems and sdms equals 27 20 24 20 31 reflecting in a highly insignificant average annual change of 0 8 table 4 thus sems increase significantly faster than the average of all five model labels while abms seem to exhibit an average growth analogously table 5 shows the trends in selected model characteristics for the numerical values see appendix c in the supplementary material most characteristics exhibit insignificant trends with p values above 0 2 while significant trends with p values equal to or below 0 07 are observed only for the characteristics general stochastic and non linearity 4 discussion and conclusions 4 1 summary of the main results 122 papers dealing with the model based integration of ecology and socio economics in the fields of biodiversity conservation ecosystem services and natural resource management from the years 2015 2019 were analysed with regard to 24 characteristics the characteristics measure the purpose of the model study structural features of the model consideration of information human behaviour system complexity environmental policy as well as the formal implementation and analysis of the model in most model characteristics there is high variation among the models so that between 25 and 75 percent of the models have that characteristic and the complementary percentage does not cf fig 1 rather frequently observed characteristics 75 are positive analysis dynamic and numerical analysis while networks asymmetric information learning in agents non classical agent behaviour and emergence are considered only relatively rarely 25 and only very few studies are participatory these observations do not seem to change over time as a trend analysis shows cf table 5 significant increases are found only in the characteristics general stochastic and non linearity which are quite abundant anyway in the sample some of the large variation in the first mentioned characteristics with occurrences between 25 and 75 percent is captured by the labels assigned to the models by the authors the five most frequent labels found in the sample are agent based models abm 13 bio economic models bem 14 ecological economic models eem 23 social ecological models sem 25 and system dynamic models sdm 8 in comparison to the other models the abms have a high number of structural features and next to the classical assumption of utility maximising agents also consider alternative models of human behaviour although most of the abms do assume utility maximising agents confirming groeneveld et al 2017 cf table 1 similar to observations made by egli et al 2019 emergence is also considered only in a minority of all abms in the sample on the opposite end are the bems which contain only relatively few structural features and make use of a utilitarian framework such as the human model of homo oeconomicus in between one can find the eems the sems and the sdms which however also differ between each other such that e g the sdms rarely consider spatial structure usually contain feedback loops and are often equation based however although there are differences between the models with different labels there are still many similarities which can be seen in fig 2 and table 1 and is numerically confirmed by high pairwise correlation coefficients taking the frequency distributions in fig 2 as vectors cf table 2 while abms somewhat differ the other four model labels are correlated quite strongly especially bem with eem sem with sdm and sem with eem with correlation coefficients 0 8 that the abms are closely related to each other and somewhat different from the other model labels is also indicated by the results of a cluster analysis of the model characteristics in appendix d of the supplementary material pairwise correlations between the model characteristics are calculated each characteristic is represented by a 122 element vector whose k th element is one zero if the k th model in the sample of all models has does not have the characteristic a high correlation between two characteristics i and j indicates that if characteristic i is present absent in a model then characteristic j is likely to be present absent in that model as well the two overlapping clusters d and e in fig d2 contain the characteristics spatial stochastic algorithmic agents and non classical behaviour which are five of the typical characteristics of abms and exactly those five which render abms distinctive table 1 the other clusters in fig d2 cannot be mapped one to one to model labels the partial overlaps between the model labels indicated by table 2 are also reflected in the journals in which the reviewed model papers have been published table 3 although some journals were found to contain only one model label a number of journals have published models of several labels in particular ecological economics ecological modelling journal of environmental management and pnas which include four model labels each while there is a substantial overlap between the structure of the models within the different model labels some differences exist with regard to temporal developments while the number of published sems in the sample increased by about two per year the numbers in the other model labels seem to remain rather constant table 4 4 2 evaluation of the main results addressing research question q1 there appears to be quite a good balance between general and specific models between positive and normative analyses and between the model purposes of system understanding and prediction also features like dynamics spatial structure stochasticity agents and feedback loops are quite often considered on the downside issues that are likely to be relevant and complicate policy making in the real such as asymmetric information non rational behaviour of agents and social networks are rarely addressed and despite calls for more participation of stakeholders in research models are still very rarely used in participatory research as the trend analysis in table 5 indicates this does not seem to change over time addressing research question q3 addressing question q2 the labels attached to the models by their author s partly indicate a typical structure of the model so that agent based models abms tend to differ from the models with other labels in particular the sdm and bio economic models bems explaining these differences between the models with different labels is clearly beyond the scope of the present paper one explanation could be the disciplinary background even though the 122 models were selected for interdisciplinarity of the model authors although with different characteristics drechsler et al 2007 and drechsler 2020 compared in a similar way ecological economic and ecological economic models from the field of biodiversity conservation and found that the ecological models tended to contain more structural features and were more complex than the economic models on the other hand despite these differences there is quite some overlap between the model labels indicated by the correlation coefficients in table 2 which reflect that e g the models have similar purposes share some structural features like dynamics and share deficiencies like the wide absence of participatory applications the overlap between the models also reflects in the observation that various journals include models of several labels these observation can altogether be regarded as a positive signal such that there seems to be enough diversity in the modelling cultures to avoid inbreeding but enough similarities to allow for communication and cross fertilisation among different modelling communities a problematic observation though is that the number of papers with the present type of mechanistic models designed to integrate ecology and socio economics for the management of biodiversity and ecosystem services grows only slowly addressing research question q3 cf table 4 qualitatively this is confirmed by another scopus search not shown carried out in june 2020 with the same search string as in section 2 1 and adding in turn the terms agent based bio economic ecological economic socio ecological or social ecological and system dynamic although the tedious manual screening described in section 2 was excluded for simplicity so the two searches can be compared only loosely the qualitative result is the same such that except for sem the number of papers seems to remain constant over the past decade while the number of sem papers has increased from about 10 in 2010 to about 50 in 2019 4 3 limitations of the analysis and future research the present study involves a number of limitations the literature search via scopus section 2 1 will certainly not have found all the papers of the considered field this is indicated e g by the fact that the same search a few months later led to slightly different results further the manual screening of the obtained papers may have not been free of any errors in addition the choice of the search terms is subjective and may have led to the omission of relevant articles for instances it did not yield any papers with integrated models that also contain applications in the field of environmental management related to this is the fact that the selection of the model characteristics section 2 2 is subjective too smaller errors may have also occurred in the evaluation of the models with regard to the model characteristics section 2 3 although it is used only as a supplement to the correlation analyses described in section 2 4 the manual cluster analysis in appendix d of the supplementary material involves subjective elements lastly for time constraints only five years of data were considered which limits the significance of the results of the trend analysis section 2 5 while the errors in sections 2 2 2 4 are probably minor the errors in the generation of the data base in section 2 1 and the trend analysis in section 2 5 call for further research the use of alternative possibly broader search terms and a longer time frame could lead to interesting insights beyond those of the present study 4 4 conclusion to conclude mechanistic models integrating ecology and socio economics for the management of biodiversity and ecosystem services by now consider quite a lot of system features such as spatial structure agents and feedback loops but are still largely to varying degrees depending on the model label disregarding quite a number of issues such as the distribution and acquisition of information among and by the human actors as well as the way in which the human actors translate available information into decisions the human factor is also under represented in the sense that only very few models are used within participatory studies nevertheless there seems to be a fruitful level of diversity in modelling cultures but also sufficient overlap for cross fertilisation which may help further improving the models in the field declaration of competing interest there are no conflicts of interests with this manuscript acknowledgments i am very grateful for constructive comments of three anonymous reviewers and the journal editor sondoss elsawah that were of substantial help in the revision of this manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104892 
25924,models are important tools to integrate ecological and socio economic knowledge to better understand and manage social ecological systems challenges include among others the adequate representation of feedback loops between the socio economic and the ecological subsystems uncertainties and human behaviour to analyse how well models are able to address these challenges in the fields of biodiversity conservation and ecosystem services management the present paper systematically reviews recent mechanistic models of the field and analyses them with respect to a number of binary criteria the reviewed models generally contain quite a few of the above mentioned system features but still fall short when it comes to the adequate representation of the socio economic dimension sorting the models by the labels given to them by their authors such as ecological economic or system dynamic allows assessing model variation within and among labels and indicates that there is a fruitful level of diversity in the models keywords agent based models bio economic models ecological economic models social ecological models system dynamic models 1 introduction despite various political and scientific initiatives ma 2005 cbd 2007 ipbes díaz et al 2018 teeb 2010 the loss of biodiversity and the degradation of ecosystem services is still ongoing worldwide eea 2019 next to climate change one of the main drivers of these losses is human land use ma 2005 which in turn is driven by the socio economic conditions such as agricultural policy e g lakner et al 2019 under which the land users operate to understand the human induced decline of biodiversity and ecosystem services both the ecological and the socio economic dimensions have to be considered in an integrated manner shogren et al 1999 teeb 2010 wätzold et al 2006 a challenge here is that the coupled ecological and socio economic processes are usually dynamic partly involving feedbacks so that e g the ecological subsystem affects the socio economic subsystem and vice versa polasky and segerson 2009 spatially structured so that e g the distance between habitats affects the dispersal and the survival of a species hanski 1999 or the deforestation in the tropics leads to the fragmentation of rainforests taubert et al 2018 subject to risk and uncertainty since for instance the dynamics of species populations are often influenced by random factors beissinger et al 2002 or systems may tip from one state to another where the location of the tipping point is fully or partly unknown bauch et al 2016 and influenced by non trivial behaviour of humans where humans partly try to maximise their economic profits but in their decisions are also influenced by other motives e g bartkowski and bartke 2018 mathematical models have become important tools for the improvement and support of the understanding prediction and management of complex systems such as the world s climate system e g neelin 2010 or the dynamics of animal diseases e g vicente et al 2019 which also holds for those cases in which several scientific disciplines in particular natural sciences and social sciences need to be considered in an integrated manner voinov 2008 clark 2010 flichman et al 2011 schlüter et al 2012 drechsler 2020 purposes of models are manifold baumgärtner et al 2008 probably the most important being a better understanding of systems and observed phenomena e g getzin et al 2016 taubert et al 2018 prediction of system dynamics e g bauch et al 2016 and decision support e g efsa et al 2017 to increase their relevance for decision support models should ideally consider that human land use is often influenced by agricultural environmental and other policies de vries and hanley 2016 pe er et al 2017 a major obstacle to the development of policies is asymmetric information laffont and mortimort 2002 following the environmental economics literature e g hanley et al 2007 a case of asymmetric information is present when one actor has more information about some relevant facts than another e g when landowners know their costs of carrying out a conservation measure but a conservation agency that wishes to introduce a conservation policy does not the question arises q1 to what extent current models used for the integration of ecology and socio economics in the fields of biodiversity conservation and the management of ecosystem services capture the above mentioned issues of spatial temporal and behavioural complexity and address the needs of deciders and policy makers to address this question a quantitative analysis of research papers from the field is carried out based on a systematic search from the past five years and focusing on mechanistic models the papers are analysed with respect to a number of characteristics including the purpose for which the models have been developed and analysed structural features such as spatial structure or dynamics issues of system complexity such as emergence models of human behaviour issues relevant in policy making and the method by which the model is implemented and analysed with regard to agent based models a similar analysis has been carried out by groeneveld et al 2017 who focus on behaviour of land users and egli et al 2019 who explore the consideration of resilience in agent based models however while these two reviews address model features similar to those listed above they consider different fields of model applications and most importantly consider only agent based models agent based models however form only a limited subset of models integrating ecology and socio economics in the fields of biodiversity conservation and the management of ecosystem services instead next to agent based models in the field are known under very different labels such as bio economic or system dynamic including these other labels on the one hand broadens the scope of the analysis and on the other hand raises additional research questions q2 do different labels reflect different model structures possibly implying different abilities of the models to capture the features and fulfil the purposes described above further how strongly are models of different labels related to each other and do the different labels indicate the presence of separate modelling communities with only limited communication among each other to address these questions the reviewed models are sorted by the labels given to them and the models found under each label are analysed separately and the results compared among the different labels the way models are built and labeled may change over time and thus research question q3 reads what are the magnitudes and statistical significance of these changes to address the three research questions q1 q3 relevant papers from the years 2015 2019 are identified and analysed as outlined above and described in detail below in the methods the results section presents the outcomes of the analyses and in the discussion conclusions are drawn from these outcomes to formulate answers to the three research questions 2 methods 2 1 data collection the research context of the present analysis is mechanistic or process based models that explicitly consider both the ecological and the socio economic dimension of problems in the field of biodiversity resource and ecosystem services management the basis of the quantitative literature review is thus a search with scopus performed in february 2020 for title abs key model w 10 social or socio or economic and model w 10 ecological and biodiversity or resource or ecosystem w 5 service and exclude subjarea medi or exclude subjarea bioc or exclude subjarea arts or exclude subjarea psyc or exclude subjarea nurs or exclude subjarea ceng or exclude subjarea neur or exclude subjarea immu or exclude subjarea mate or exclude subjarea phys or exclude subjarea chem or exclude subjarea heal or exclude subjarea phar or exclude subjarea vete this search string was chosen to detect modelling papers considering i a social economic or socio economic dimension ii an ecological dimension and iii addressing issues of biodiversity resources or ecosystem services note that in scopus the command w n requires that the two connected keywords must not more than n words apart from each other and to avoid an explosion of work load thematic fields most likely to be irrelevant in the context of biodiversity were excluded in total 1082 papers were identified from which 73 66 85 86 and 101 papers fell into the years 2015 2016 2017 2018 and 2019 which form the basis of the present analysis next all the 411 papers were subjected to a rigorous manual screening process to avoid mis classification of papers due to malfunctioning search filters cf zare et al 2017 and ensure that the remaining papers fall into the above defined context about twenty papers dropped out because they were not accessible e g because they appeared in a journal of minor range or not written in english language and or where the model description was too superficial because e g the paper is an extended abstract for a conference to allow for the below described detailed characterisation of the model then a considerable proportion of papers dropped out whose models are of a qualitative conceptual or statistical nature statistical models were excluded because these models are by their nature largely independent of the research context a linear regression analysis e g simply correlates data and looks the same regardless whether the data are from biological social or astronomic observations cf drechsler et al 2007 quite a few papers also dropped out because other than suggested by their title keywords or abstract which were the targets of the scopus search they included only one of the two dimensions of ecology and socio economics or even none of them lastly models containing a mere aggregation of numbers into an index such as ecological footprint analysis or simple multi criteria analysis that did not include any further ecological and socio economic modelling were discarded 2 2 selection of model characteristics and labels as a result 122 papers cf appendix a in the supplementary material are retained which or precisely of course the models in which are characterised by the purpose for which the model was built the structure of the model particular issues addressed and the formal implementation and analysis of the model the selection of the criteria was influenced by drechsler et al 2007 baumgärtner et al 2008 schlüter et al 2012 egli et al 2019 and drechsler 2020 and the criteria are chosen to explicitly address the issues raised in the introduction is the model 1 general 2 specific 3 built for positive analysis 4 built for normative analysis 5 used to improve the understanding of the modeled system or develop theory 6 used to make predictions of the system dynamics 7 used to include stakeholders and or support management decisions does the model explicitly consider 8 system dynamics 9 spatial structure 10 randomness stochasticity 11 feedback loops 12 individual agents 13 networks regarding human actions does the model address issues of 14 asymmetric information 15 prediction and learning of actors and is based on a 16 utilitarian framework in particular the human model of homo oeconomicus 17 or employing alternative non classical models of human behaviour does the model analysis address issues of 18 non linearity such as resilience or discontinuous transitions tipping points 19 emergence in particular spatial pattern formation 20 policy interventions on the system is the model formulated through 21 differential or difference equations 22 algorithms and rules and is it solved or analysed 23 analytically or 24 numerically via computer simulation and how was the model labeled by its authors similar to drechsler 2020 a general model is understood as a model that is not applied to a specific geographically localised case but formulated in a general manner by quantities like economic cost population growth rate etc if a model is analysed numerically it is counted as general if a systematic sensitivity analysis is carried out to explore the general behaviour of the model a specific model in contrast is applied and parametrised to a specific case without any sensitivity analysis positive analysis is understood cf drechsler 2020 as exploring how the system looks like or will develop while normative analysis is understood as addressing how a system should be managed to maximise certain objectives like cost effectiveness or social welfare characteristic 7 is meant to capture participatory modelling approaches e g voinov et al 2018 which includes research were stakeholders are not only sources of information like in a survey but actively and significantly involved in the research characteristic 12 contains multi agent systems gilbert 2007 but also game theoretical approaches tadelis 2013 often with only two agents while networks characteristic 13 can e g be ecological pascual and dunne 2005 or social networks bruggeman 2008 asymmetric information characteristic 14 was explained in the introduction characteristic 16 measures whether decisions are based on the maximisation of some utility function as does e g a welfare maximising policy maker or the rational utility maximising homo oeconomicus while non classical models characteristic 17 may include altruism or inequity aversion in agents e g fehr and schmidt 1999 satisficing behaviour simon 1979 or social interaction such as copying opinions or decisions of other agents weisbuch 2006 or the decisions may be modeled by statistical models with the rest of the model being mechanistic as explained above fitted to observed decisions lewis and plantinga 2007 so that a utility function is or cannot be derived explicitly most models in the sample include some non linear elements however such non linearity in the model structure e g logistic growth of an animal population does not necessarily lead to non trivial model dynamics that can address issues of resilience or tipping points similarly resource management models may contain a feedback loop in their formulation but may be analysed only to identify a monotonic optimal harvesting trajectory non linearity in the context of the present paper characteristic 18 does not refer to such non linearities in the model formulation but only to the question of whether issues of non linearity like resilience are addressed explicitly in the model analysis characteristic 20 addresses e g agricultural policies or the establishment of nature reserves some models contain policies as an exogenous driver but do not explicitly analyse the effects of these policies these models are not classified as considering policy intervention the last question above addresses the observation that models used in the present context have quite different labels such as bio economic or system dynamic 2 3 determination of the frequency distributions of the model characteristics research question q1 having analysed all 122 papers with regard to the 24 characteristics the relative frequencies of the models falling into each of these 24 categories are counted regarding the authors label many models have been given only an unspecific label like simulation model or coupled model and are classified as not specified although the label network model is specific it is not particularly relevant to the issue of ecological and socio economic integration and so network models are also classified as not specified for the five labels with the highest numbers of models the frequencies of the 24 characteristics are counted in the same way as for the set of all 122 models 2 4 determination of relationships between model labels question q2 the counts of the model characteristics in the different model labels are used to identify characteristics typical for each model label to obtain a first understanding of the differences and similarities between the model labels this is followed by a quantitative assessment of the relationships between the five model labels for this the frequency distributions are considered as vectors and pearson correlation coefficients between these vectors are calculated as an indicator of overlap and communication between different modelling communities for each model label the journals are identified in which models of that label are published and the journals are identified that contain a particular number of model labels 2 5 determination of trends in the consideration of model characteristics and model labels question q3 although five years of data is a rather short time frame to detect significant trends two trend analyses are carried out using linear regression with time as the explaining variable in the first analysis the explained variables are the frequencies of the model characteristics within the sample of all 122 models while the second analysis considers the frequencies of the five model labels as explained variables 3 results 3 1 distribution of the model characteristics research question q1 the general distribution of the characteristics based on all 122 models is shown in fig 1 about one third of the models is general while two thirds are specific note that the sum of general and specific models is slightly above 100 since a few papers contain both a general and a specific analysis almost 80 of the models were used for a positive analysis while about 30 are normative note that some papers contain both a positive and a normative analysis about half of the models were analysed for system understanding and theory development about two third were used for prediction while only about five percent were developed and applied in a participatory approach half of the models consider spatial structure stochasticity and feedback loops 80 are dynamic but less than one third consider agents and less than ten percent consider networks asymmetric information is considered only in less than five percent of all models and the consideration of prediction and learning is only slightly more abundant about half of all models include some sort of utilitarian approach of decision making less than 20 assume non classical human behaviour while in the rest of the models modes of decision making or human behaviour are irrelevant or not addressed about one third of the models address issues of non linearity while only ten percent consider emergence effects of policy intervention were analysed in about 30 of the models lastly about one third of the models is equation based while two thirds are algorithmic and almost all models were analysed numerically or by computer simulation 3 2 distribution of the model characteristics for the dominant model labels research question q2 as described in the methods an issue of interest is the label attached to the model by its author s in the sample of 122 papers 24 models were labeled socio ecological or social ecological sem 23 are ecological economic eem 14 bio economic bem 13 agent based or multi agent abm and eight are system dynamic model sdm five models have two labels like agent based social ecological model or ecological socio economic model and were sorted in both respective classes in addition the labels land use model and multi objective model are observed three times each and two game models are in the sample the labels business model carbon cycle model disease economic model growth model and socio hydrological occur once each and all other models are not specified as defined in the methods for the five most frequent labels fig 2 shows the characteristics distributions analogous to fig 1 frequencies between 0 25 and 0 75 this choice is if course somewhat arbitrary in a characteristic indicate that both presences and absences are quite abundant so that this characteristic is neither very typical nor very untypical for the considered model label larger frequencies 0 75 in contrast indicate that the characteristic is typical for the model label while smaller frequencies 0 25 indicate that the characteristic is untypical table 1 summaries for each label the typical and the untypical characteristics by these definitions of typical and untypical participatory approaches or decision support are untypical purposes for all model labels except for the eem all model labels are typically dynamic typically there is no consideration of networks asymmetric information or learning with the exceptions of abms consideration of emergence is untypical and models of all labels are typically analysed numerically beyond this abms recall according to the authors own labelling are typically used for positive and not for normative analysis contain many of the features like stochasticity and feedbacks etc and consider non classical human behaviour policy analysis is untypical as well as an equation based formulation instead the models are typically formulated and solved algorithmically bems are typically deterministic employ a utilitarian framework like the human model of homo oeconomicus and are equation based they typically disregard non linearities and are equation based agent based approaches including the consideration of non classical behaviour are untypical in eems sems are very similar to the abms but in contrast and like the eems typically disregard non classical behaviour and emergence sdms are typically specific and not general are used for positive rather than normative analysis and for prediction they are typically non spatial and deterministic but consider feedbacks they do not consider agents and since they are typically not used for normative analysis like cost effectiveness analysis they also do not use a utilitarian framework like the bems they are typically equation based if a model characteristic is found typical or untypical in only one model label then that model label may be regarded as distinctive in the considered characteristic by this definition abms are distinctive by their consideration of spatial structure and stochasticity and naturally by their use of an agent based approach this allows them to distinctively consider non classical behaviour and implies that they are formulated algorithmically rather than through mathematical equations bems in contrast are distinctive by their use of a utilitarian framework and their formulation through equations eems and sems are by the present definition not distinctive in any characteristic however one should note that these outcomes of course depend on the choice of the thresholds 0 75 and 0 25 by which a characteristic is denoted as typical or untypical respectively the fact that sems e g are not distinctive for feedback loops is because on the one hand the proportion of models with feedback loops in that label 0 72 is below the threshold of 0 75 and on the other hand by the chosen definition a model label is distinctive in a characteristic only if it is the only label in which that characteristic is typical and because feedback loops are typical also for abms if the threshold was lowered for instance to 0 7 feedback loops would be typical for both abms and sems and none of both labels would be judged distinctive with respect to feedback loops therefore if a label is not denoted as distinctive by a particular characteristic this does not imply that this characteristic is rare in that label but it means that the label does not stand out in this characteristic relative to the other labels 3 3 relations between the models question q2 continued in the previous section the main similarities and differences between abms bems eems sems and sdms have been highlighted according to table 1 quite a lot of the 24 characteristics are either typical or untypical or neither of both in most or even all model labels only 12 instances were found where a model label is distinctive by a certain characteristic grey shaded cells in table 1 the degree of overlap between the five model labels can be measured quantitatively by regarding the frequency distributions in fig 2 as vectors and calculating the pearson s correlation coefficients between these vectors table 2 the average correlation between a model label with the four respective others labels ranges from 1 8 4 0 45 abm to 0 71 eem and 0 74 sem the highest pairwise correlation is between bem and eem 0 90 sem and sdm 0 81 and sem and eem 0 80 these results identify quite a substantial overlap between the model labels in particular between bio economic ecological economic and social ecological models one may wonder whether this overlap also reflects in the journals in which the models were published comparing the diagonal cells of table 3 with the off diagonal cells reveals that for each model label the umber of unique journals in which no other model label was observed given in the diagonal cells of the table is about equal to the number of journals in which also other model labels were found given in the off diagonal cells although the smallness of the sample size demands some caution this indicates that the authors of different model labels partly prefer different journals to publish their papers but that there is also a substantial overlap through shared journals the broadest journals in that sense that contain more than two model labels are ecological economics containing bem eem sem and sdm ecological modelling containing abm bem eem and sem journal of environmental management containing abm bem eem sem proceedings of the national academy of sciences of the usa pnas containing abm bem sem and sdm and land use policy containing bem eem and sem 3 4 trends question q3 the first part of the trend analysis is to relate the number of papers represented by each model label to the publication year for the numerical values see appendix c in the supplementary material table 4 shows the average annual changes and their statistical significance obtained by linear regression while bems eems and sdms exhibit slight but highly insignificant declines there is a weakly significant increase of about one abm paper per year and a strongly significant increase of about two sem papers per year for comparison for the years 2015 2019 the sum of the numbers of abms bems eems sems and sdms equals 27 20 24 20 31 reflecting in a highly insignificant average annual change of 0 8 table 4 thus sems increase significantly faster than the average of all five model labels while abms seem to exhibit an average growth analogously table 5 shows the trends in selected model characteristics for the numerical values see appendix c in the supplementary material most characteristics exhibit insignificant trends with p values above 0 2 while significant trends with p values equal to or below 0 07 are observed only for the characteristics general stochastic and non linearity 4 discussion and conclusions 4 1 summary of the main results 122 papers dealing with the model based integration of ecology and socio economics in the fields of biodiversity conservation ecosystem services and natural resource management from the years 2015 2019 were analysed with regard to 24 characteristics the characteristics measure the purpose of the model study structural features of the model consideration of information human behaviour system complexity environmental policy as well as the formal implementation and analysis of the model in most model characteristics there is high variation among the models so that between 25 and 75 percent of the models have that characteristic and the complementary percentage does not cf fig 1 rather frequently observed characteristics 75 are positive analysis dynamic and numerical analysis while networks asymmetric information learning in agents non classical agent behaviour and emergence are considered only relatively rarely 25 and only very few studies are participatory these observations do not seem to change over time as a trend analysis shows cf table 5 significant increases are found only in the characteristics general stochastic and non linearity which are quite abundant anyway in the sample some of the large variation in the first mentioned characteristics with occurrences between 25 and 75 percent is captured by the labels assigned to the models by the authors the five most frequent labels found in the sample are agent based models abm 13 bio economic models bem 14 ecological economic models eem 23 social ecological models sem 25 and system dynamic models sdm 8 in comparison to the other models the abms have a high number of structural features and next to the classical assumption of utility maximising agents also consider alternative models of human behaviour although most of the abms do assume utility maximising agents confirming groeneveld et al 2017 cf table 1 similar to observations made by egli et al 2019 emergence is also considered only in a minority of all abms in the sample on the opposite end are the bems which contain only relatively few structural features and make use of a utilitarian framework such as the human model of homo oeconomicus in between one can find the eems the sems and the sdms which however also differ between each other such that e g the sdms rarely consider spatial structure usually contain feedback loops and are often equation based however although there are differences between the models with different labels there are still many similarities which can be seen in fig 2 and table 1 and is numerically confirmed by high pairwise correlation coefficients taking the frequency distributions in fig 2 as vectors cf table 2 while abms somewhat differ the other four model labels are correlated quite strongly especially bem with eem sem with sdm and sem with eem with correlation coefficients 0 8 that the abms are closely related to each other and somewhat different from the other model labels is also indicated by the results of a cluster analysis of the model characteristics in appendix d of the supplementary material pairwise correlations between the model characteristics are calculated each characteristic is represented by a 122 element vector whose k th element is one zero if the k th model in the sample of all models has does not have the characteristic a high correlation between two characteristics i and j indicates that if characteristic i is present absent in a model then characteristic j is likely to be present absent in that model as well the two overlapping clusters d and e in fig d2 contain the characteristics spatial stochastic algorithmic agents and non classical behaviour which are five of the typical characteristics of abms and exactly those five which render abms distinctive table 1 the other clusters in fig d2 cannot be mapped one to one to model labels the partial overlaps between the model labels indicated by table 2 are also reflected in the journals in which the reviewed model papers have been published table 3 although some journals were found to contain only one model label a number of journals have published models of several labels in particular ecological economics ecological modelling journal of environmental management and pnas which include four model labels each while there is a substantial overlap between the structure of the models within the different model labels some differences exist with regard to temporal developments while the number of published sems in the sample increased by about two per year the numbers in the other model labels seem to remain rather constant table 4 4 2 evaluation of the main results addressing research question q1 there appears to be quite a good balance between general and specific models between positive and normative analyses and between the model purposes of system understanding and prediction also features like dynamics spatial structure stochasticity agents and feedback loops are quite often considered on the downside issues that are likely to be relevant and complicate policy making in the real such as asymmetric information non rational behaviour of agents and social networks are rarely addressed and despite calls for more participation of stakeholders in research models are still very rarely used in participatory research as the trend analysis in table 5 indicates this does not seem to change over time addressing research question q3 addressing question q2 the labels attached to the models by their author s partly indicate a typical structure of the model so that agent based models abms tend to differ from the models with other labels in particular the sdm and bio economic models bems explaining these differences between the models with different labels is clearly beyond the scope of the present paper one explanation could be the disciplinary background even though the 122 models were selected for interdisciplinarity of the model authors although with different characteristics drechsler et al 2007 and drechsler 2020 compared in a similar way ecological economic and ecological economic models from the field of biodiversity conservation and found that the ecological models tended to contain more structural features and were more complex than the economic models on the other hand despite these differences there is quite some overlap between the model labels indicated by the correlation coefficients in table 2 which reflect that e g the models have similar purposes share some structural features like dynamics and share deficiencies like the wide absence of participatory applications the overlap between the models also reflects in the observation that various journals include models of several labels these observation can altogether be regarded as a positive signal such that there seems to be enough diversity in the modelling cultures to avoid inbreeding but enough similarities to allow for communication and cross fertilisation among different modelling communities a problematic observation though is that the number of papers with the present type of mechanistic models designed to integrate ecology and socio economics for the management of biodiversity and ecosystem services grows only slowly addressing research question q3 cf table 4 qualitatively this is confirmed by another scopus search not shown carried out in june 2020 with the same search string as in section 2 1 and adding in turn the terms agent based bio economic ecological economic socio ecological or social ecological and system dynamic although the tedious manual screening described in section 2 was excluded for simplicity so the two searches can be compared only loosely the qualitative result is the same such that except for sem the number of papers seems to remain constant over the past decade while the number of sem papers has increased from about 10 in 2010 to about 50 in 2019 4 3 limitations of the analysis and future research the present study involves a number of limitations the literature search via scopus section 2 1 will certainly not have found all the papers of the considered field this is indicated e g by the fact that the same search a few months later led to slightly different results further the manual screening of the obtained papers may have not been free of any errors in addition the choice of the search terms is subjective and may have led to the omission of relevant articles for instances it did not yield any papers with integrated models that also contain applications in the field of environmental management related to this is the fact that the selection of the model characteristics section 2 2 is subjective too smaller errors may have also occurred in the evaluation of the models with regard to the model characteristics section 2 3 although it is used only as a supplement to the correlation analyses described in section 2 4 the manual cluster analysis in appendix d of the supplementary material involves subjective elements lastly for time constraints only five years of data were considered which limits the significance of the results of the trend analysis section 2 5 while the errors in sections 2 2 2 4 are probably minor the errors in the generation of the data base in section 2 1 and the trend analysis in section 2 5 call for further research the use of alternative possibly broader search terms and a longer time frame could lead to interesting insights beyond those of the present study 4 4 conclusion to conclude mechanistic models integrating ecology and socio economics for the management of biodiversity and ecosystem services by now consider quite a lot of system features such as spatial structure agents and feedback loops but are still largely to varying degrees depending on the model label disregarding quite a number of issues such as the distribution and acquisition of information among and by the human actors as well as the way in which the human actors translate available information into decisions the human factor is also under represented in the sense that only very few models are used within participatory studies nevertheless there seems to be a fruitful level of diversity in modelling cultures but also sufficient overlap for cross fertilisation which may help further improving the models in the field declaration of competing interest there are no conflicts of interests with this manuscript acknowledgments i am very grateful for constructive comments of three anonymous reviewers and the journal editor sondoss elsawah that were of substantial help in the revision of this manuscript appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2020 104892 
