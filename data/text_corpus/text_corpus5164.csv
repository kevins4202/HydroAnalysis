index,text
25820,water resources are under growing pressure globally sustainable water management requires an understanding of how much water is available where it is stored and used and how future developments may impact availability understanding this requires investment in data models and experts these investments are labour intensive with considerable effort spent in three main areas collecting and transforming data building calibrating running and maintaining models and developing required reports and visualisations we present basin futures a cloud based product developed to lower this initial effort by providing pre integrated data a template model structure that makes some simplifying assumptions for speed easy setup of new scenarios a scalable data processing and simulation architecture and delivery through a web browser the case studies and results presented show the product is quick to learn fast in execution and provides an easy way to explore water resource development scenarios for river basin management and planning keywords basin planning watershed planning iwrm user centred design cloud computing hydroinformatics cyberinfrastructure environmental modelling global data scenario exploration tool 1 introduction understanding the state of water systems and connectivity with its many uses is crucial to planning and improving management practices however the complexity and uncertainty associated with water systems make decisions regarding their development and management challenging particularly when considering the dynamics of socio ecological systems typically models are used to support understanding current and future water availability döll et al 2003 sordo ward et al 2019 and consequences associated with alternative investments or policies schmolke et al 2010 xu and tung 2008 to inform planning on water resource decisions for example when considering an investment in water infrastructure for irrigation schemes or hydropower water models must consider related systems such as water storages domestic demands agriculture among others this modelling is complex time consuming and expensive the trade off in accuracy cost and consequences associated with modelling for decision making is well established acreman 2005 our experience concurs with that of kirby et al 2013 that there is value in tools that provide a broad initial picture of a basin s water resource base at a lower cost while also providing a connection to the water related economic social and environmental aspects of a river basin various challenges are faced by developers and users of these models a large amount of time and effort is required in collecting and transforming data building calibrating and maintaining models and developing required reports and visualisations while there are many tools to assist with each of these activities assembling the separate parts into a useable solution requires significant expertise often at great expense consequently many countries particularly developing countries rely on external expertise to perform this work scott stevens 2019 this can lead to poor uptake of the solutions as the organisation may not trust or have the expertise to absorb the technology or the infrastructure to support the external solution nelson et al 2019 the quality and availability of global and regional climate data is ever improving through investments in earth observations new sensors and data management practices chen and han 2016 vitolo et al 2015 however the diversity and size of these data present many challenges for users chen and zhang 2014 finding integrating and testing necessary data requires large investments to bring insights to decision makers nativi et al 2015 additionally studies suggest that the percentage of available climate data that is actually used in aiding decision making is low dahlhaus et al 2015 lehmann et al 2014 advances in the application of information and communication technologies ict or cyberinfrastructure essawy et al 2018 sun et al 2020 wan et al 2014 are helping to address these challenges specific developments in these areas include the provision of software as a service and its many flavours including modelling as a service nelson et al 2019 cloud computing and modernisation of data analysis platforms these new ways to develop and deploy software assist in overcoming many issues with traditional desktop style software including increased scalability easier handling of large data sets decreased implementation and maintenance costs and simplified model setup and configuration among others delipetrev et al 2012 glenis et al 2013 spichkova et al 2016 these approaches form the technical basis on which we developed an integrated product basin futures with the aim of conducting rapid basin scale water assessments with a low technical footprint for users the development of basin futures focussed on three high level requirements 1 global application it must be able to run for any basin in the world 2 ease of implementation and use we wanted users to be able to run models in the browser quickly to allow a faster comparison and exploration of scenarios we want users to focus on exploring options and trade offs 3 reduced learning curve the tool must be easy to learn to reduce the time spent on tasks not associated with building understanding of the river basin being explored the tool was developed to provide a first pass tool to explore three key questions much water is available where is it stored and used and how future developments may impact its availability first pass here refers to generating a preliminary picture of a basin s water resources in a short period of time it also implies a higher level of uncertainty given the rapid nature of the assessment in this paper we detail the design and testing of basin futures we begin with a brief coverage of relevant prior work the basin modelling requirements and context are then covered followed by details of the models used we then describe the user workflow and design of the cloud based system the global and regional data used and then describe the application through a case study and testing of the product to date and finish with discussion and conclusions covering the key points arising from this work 2 related work the approach taken in developing basin futures is at the intersection between integrated basin scale management and cloud enabled modelling systems here we briefly cover some of the key concepts and related work at this intersection hydrological models and more specifically in the context of this paper models used for basin planning are commonly established and employed to assist decision making challenges in their use are still present ensuring appropriate scale blöschl and sivapalan 1995 the effort required to setup calibrate and deploy them and understanding their inherent uncertainties when informing the decision making process among others it is also recognised that models need to be supported by high quality data and monitoring processes silberstein 2006 models that integrate systems that interact with water on a broader level such as coupling concepts of land management agriculture climate society and economics are more nascent harou et al 2009 lerner et al 2011 wang et al 2019 li et al 2018 provide a framework for considering the challenges for the next generation of integrated basin models these models must link natural and social sciences be based on sound scientific principles carefully consider uncertainty and take advantage of new technologies and research the suggested framework highlights the importance of the intersection of the watershed system model and the watershed cyberinfrastructure the latter being the enabling technology platform on which next generation systems may be built there are many initiatives using advances in data availability and ict to address environmental modelling and assessment challenges a recent position paper from chen et al 2020 provides review of integrated modelling and simulation systems and their overlap with service oriented architectures with a forward looking focus on open web distributed integrated modelling among the conclusions of this work the authors recommend systems that focus on user experience to enable adoption and participation the use of standards is highlighted as a key enabling technology something that has been a focus of our work here section 5 2 the importance of computational patterns for model execution are also highlighted with reproducibility a key concern we discuss in section 8 as well as issues relating to system environments dependencies and tracking changes in resources our work demonstrates how containerisation technologies can assist addressing some of these challenges though many remain versioning of models data and other resources over the web is still large challenge hutton et al 2016 stagge et al 2019 there are initiatives investigating approaches to these challenges essawy et al 2018 recent work on modernisation of geographical information systems gis suggest systems need to be easy to use and easy to compute zhu et al 2020 our approach is well aligned with these recommendations the easy to use quality refers to three aspects of being intuitive assisted and cyber enabled easy to compute refers to the use of high performance computing and facilitating complex computing for example the ability to handle computation of many complex interrelated processes these concepts are in accordance with the three high level requirements for the development of basin futures section 1 the number of systems that integrate models into cloud and web based systems are growing the soil and water assessment tool swat model jayakrishnan et al 2005 has been applied in web environments for specific purposes such as watershed management zhang et al 2015 sharing of model outputs and education giuliani et al 2013 rajib et al 2016 modularisation and visualisation mcdonald et al 2019 and calibration and uncertainty analysis zhang et al 2016 these systems make use of the accessibility of having models and their results online offer benefits of reproducibility and the flexibility of cloud based processing there are also frameworks arising that focus on generalised environments to manage data integration and model execution coombe et al 2017 liu et al 2012 sensitivity analysis for hazard modelling kc et al 2020 and execution of scientific workflows oliveira et al 2012 that can support models or simulation there are important lessons from these pieces of work that are relevant to our work including considerations for scheduling execution and contention of resources within public clouds liu et al 2012 within water management there are ongoing efforts towards improving reproducibility and online sharing of models and resources the hydroshare and geotrust projects have demonstrated this in application of the modlow model within the united states essawy et al 2018 through connection to the amazon web services aws cloud environment there is potential to use sharing platforms like these as a mechanism to publish basin futures model results we have summarised some of the key features of related cloud based modelling systems in table 1 this provides some context for how these systems relate to the key features columns within basin futures 3 basin modelling basin modelling is commonly applied to assist decision makers in planning and managing water resources and related natural and manmade systems alluvium et al 2020 these include rivers water storages reservoirs lakes dams groundwater wetlands as well as systems that consume or demand water resources for example agriculture domestic use industry or demands from outside the basin via water transfers these systems are dynamic complex and interdependent additionally the number and diversity of stakeholders and their needs adds to the complexity of effective planning consequently decision making relating to equitable sharing of water is highly problematic grafton 2017 basin data and models are used in three main areas to inform understanding of the state of a basin historical and current inform future planning decisions within the basin using simulation of changes or future conditions or for operational decisions such as operating dams irrigation system access control etc zhang et al 2016 the use of basin futures can assist in the first two of these roles though we also see it having application in education and training for water resource management and hydrology this section outlines the models that provide the core simulations within the basin futures system the focus of this paper is the system as a whole particularly the software architecture data infrastructure and services however we provide details of the models to ensure transparency 3 1 basin futures model structure basin futures currently has two main modelling components rainfall runoff via gr4j perrin et al 2003 to generate sub catchment runoff and a reach model engine for undertaking water management and transfer activities such as water storage hydropower generation routing of flows through the basin unaccounted losses and gains and rural urban industrial irrigation and environmental demands an overview of the reach model engine components is shown in fig 1 the models run on a daily timestep but given their conceptual lumping the results are reported on a monthly timestep the following sections describe the model components with details provided in the supporting material when selecting the models for the basin futures system a number of key requirements were identified simplicity for end users minimal parameters and ease of deriving parameters data requirements that could be met by published global datasets but augmented with local data as available defensible results and fast runtime speed low memory use the models described here implement well published and widely used model components that satisfy these requirements other models could be used in their place providing they match in the level of granularity and parameterisation 3 2 rainfall runoff model the rainfall runoff gr4j model operates at the sub basin scale and takes the daily rainfall and pet data generated at the sub basin scale to estimate daily runoff time series as with other components in basin futures the configuration and calibration of the runoff component are influenced by the availability of relevant global data sets users have the option of directly setting parameters for the model or calibration using two options run a calibration to target a mean annual runoff value or 12 mean monthly runoff values these values are derived from a global runoff grid provided by fekete et al 2002 the mean annual and monthly runoff targets were implemented first as they do not require local streamflow observations to be available and are thus globally applicable the system is able to calibrate the rainfall runoff model to observed streamflow from the available station databases see section 6 2 however this is not yet available through the user interface once the climate data has been processed a calibration wizard guides users through a process of estimating the rainfall runoff parameters based on the selected target calibrations are run using the python optimisation package spotpy houska et al 2015 multiple optimisers are available our current implementation uses the shuffle complex evolution vrugt et al 2003 algorithm to maximise the nash sutcliffe efficiency nse coefficient for mean monthly runoff or minimise the root mean squared error rmse for mean annual runoff once target runoff values have been selected worker processes are initiated that run in parallel using the worker sub system the results of calibration are stored for the user to access once complete as well as providing a historical record of calibration runs calibration results may be reloaded into the model allowing different calibrations to be easily compared or reproduced at later stages 3 3 reach model engine the modelling component that captures the river system processes is the reach model engine fig 1 this model component is implemented in fortran for execution speed and wrapped in python a reach is defined as a segment of river that transfers water from upstream sub basins to downstream sub basins contained within the reach are some of the key water management processes such as water storage hydropower generation and water extraction for pattern demands and crop irrigation the reach model engine forms a common template for all reaches with these various model components being present in each reach in the same order regardless of whether a particular component such as hydropower is in use within a reach the reach template approach is more similar to that used in australian water resource assessment river system model dutta et al 2017 than a node link network approach welsh et al 2013 3 3 1 storages the general model structure places the storage if present in a reach at the top of the reach from which water demands are supplied to downstream users within the reach inflows to the storage come from the outflows of upstream reaches and from a portion of the runoff generated within the local catchment area of the reach outflows from a storage are governed by level volume area relationships controlled release mechanisms such as valves and multiple outlet paths and types including uncontrolled release pathways spillways hydropower production is a function of discharge head and specified turbine efficiency full details of the storage model are provided in the supplementary material storages for each reach are identified and parameters suggested to the user via a global storage definition database see section 4 1 4 these details include the storage volume and surface area which can then be adjusted by the user the system calculates rough level volume area and release curve relationships from the volume and area parameters based on a simple wedge geometry user supplied level volume area tables will be supported in future versions the simplification of the storage geometry introduces uncertainty to the storage dynamics which is outline in section 8 5 both irrigated and dryland farms may optionally include on farm storages the farm may have multiple storages that are described by level volume area relationships inactive storage volume and seepage as a function of storage level in addition to the on farm storage there is also a storage that represents overbank flow floodplain storage fig 2 3 3 2 routing and demands in addition to storage mass balance modelling the reach model engine routes flows within a reach using storage koussis 2009 or piecewise linear routing and incorporates local catchment inflow unaccounted reach losses or gains water demands from irrigated crops water balance for multiple crop types simultaneously and other demands hydropower urban industrial environmental water demands are passed up a reach to the reach storage where water is released subject to outlet constraints incorporating the travel time and losses to attempt to fulfil the downstream demand the model architecture prohibits the propagation of water orders beyond the reach to upstream reaches diminishing the need for iterative solvers to calculate the water demand cascade between all reaches this model structure decision allows linear computation sequence and thereby much faster computation times the model level implications for this are discussed in the discussion section 3 3 3 crop model the crop model implemented by basin futures is similar to the aquacrop model raes et al 2009 developed by the fao food and agricultural organisation the crop model simulates the yield response of herbaceous crops to water stress and is particularly suited for simulating irrigation scenarios and associated impacts on yield andarzian et al 2011 the model also captures fallow land and associated runoff the model is simple it only uses a relatively small number of explicit parameters and mostly intuitive input variables requiring simple methods for their determination with global datasets available to parameterise the model where local data is unavailable economic and nutritional estimates are post processed 3 3 4 environmental flow metrics we use well established algorithms for calculating key flow metrics sengupta et al 2018 implemented in r and wrapped using the rpy2 package rpy2 r in python 2019 2 to provide calculations of key flow metrics the metrics used are supplied in the supplementary material table 1 these metrics are calculated as part of the reporting of the hydrological index of alteration this allows users to compare the changes in basin flows between multiple scenarios at a reach and basin scale given the computation expense these metrics are performed by the worker subsystem 3 4 current limitations of the model there are two key concepts that are not currently modelled by the river system model groundwater and snow glacier runoff there are aspects of groundwater interaction that are supported by the model such as groundwater extraction via pumps for irrigation and deep drainage from irrigation however the state of the groundwater system i e aquifer levels are not modelled this is largely due to the limited available data for aquifers although we have conducted initial research into potential approaches for snow glacier runoff contributions we have implemented an extension to the gr4j model gr4j sg similar to the approach described by nepal et al 2017 the data requirements for the sg component are more intensive and are still under development for a future release the model also does not allow a reach to order water from reaches upstream of the storage thus simplifying computation and allowing quicker run times the reach model engine is able to order water from storages within a reach but not pass these water orders backward through upper reaches this results in the model not being suitable for use in more regulated water systems where it is common for orders to be propagated through a river network to implement complex water management rules welsh et al 2013 the uncertainties of the system as a whole are described in more detail in section 8 5 4 user workflow the user workflow of basin futures follows four broad stages basin exploration model and scenario setup scenario exploration and exploring impacts fig 3 basin exploration step 1 is done within basinpedia and is described in section 2 2 1 model and scenario setup step 2 are described in the following section with steps 3 4 and 5 covered in section 5 1 2 4 1 model and scenario setup using a basin selected from basinpedia a user can progress into the model implementation phase a basin model is created through the following steps fig 4 4 configuring spatial resolution and sub catchment structure 5 selection of desired climate data 6 calibration of rainfall runoff model 7 parameterisation of reaches including storages crops soils irrigation demands and environmental flows 4 1 1 configuring spatial resolution and sub catchment structure the first step in creating a model is to divide the basin into river reaches that represent the conceptual catchment units this can be done in three ways 1 the first is to use predefined hydrosheds basins lehner and grill 2013 2 manually create reaches using the reach creation tool this allows users to select points on the river network as defined in the hydrosheds data set through the interface users can click on the map component and points are snapped to the river network by the server and reflected in the ui the upstream catchment area of the snapped points is then calculated using flow direction grids through the taudem tool tarboton 2005 that runs on the server the reach structure is shown to users to allow refinement of the basin substructure 3 create reaches based on gauging station locations the gauging station approach defines points on the river network that correspond with flow measurements available from the global streamflow index metadata gsim database section 6 2 these locations are then used for flow accumulation in the same way as the manual reach creation this approach allows direct correspondence with observation locations to assess performance of the model s river flow simulations 4 1 2 selecting climate data climate data selection requires a choice of precipitation and potential evapotranspiration from the available climate datasets see 6 1 the choice of precipitation is aided by a rainfall comparison tool see 5 7 1 once climate choices have been made data processing jobs are submitted to the back end system for calculation of sub basin scale data 4 1 3 rainfall runoff calibration calibration is currently only performed on the gr4j rainfall runoff model the user can choose to do this reach by reach or using a wizard this process is detailed in section 3 2 both climate data processing and calibration are longer running processes and thus cannot be completed in time to feedback directly to the user our approach is to have jobs submitted to the back end system and allow the user to continue working while these tasks run however this requires managing data dependencies running rainfall runoff calibrations or scenarios cannot occur until all climate data has been processed for each reach this adds requirements to the interface to keep the user up to date with these back end analysis tasks and block particular tasks until earlier tasks are completed 4 1 4 reach parameterisation parameterisation of individual reaches step 4 in section 4 1 is performed in the basin futures model editor this is used for initial model implementation and the subsequent exploration of model scenarios each reach contains parameters that describe five components rainfall runoff calibration settings storages crops irrigation demands water transfers and environmental flows where available the setting of these parameters is aided by the use of global data as shown in fig 4 4 2 rapid scenario development for exploring future pathways the ability to rapidly create and configure scenarios provides a flexible way to explore impacts arising from developments within a river basin steps 2 3 4 and 5 in fig 3 form an explorative approach to basin analysis that when coupled with the speed and accessibility of the system allow exploration of many scenarios examples of the scenarios that can be explored and the system functions to support these are shown in table 2 these scenarios have all been used within the system to date including in training contexts as described in section 7 2 these scenarios can be setup and configured through the web based scenario editor section 5 1 2 and configured for varying combinations e g crop and irrigation scenarios under climate change 5 cloud based system for data processing and model simulation basin futures consists of a web application supporting middleware and a cloud deployment architecture the following three sections cover these in turn the overall design of the system has been guided by three technical principles use service based components via suitable web based application programming interfaces apis maximise component and library reuse by building on open and existing source code containerise all services using docker to isolate dependencies and simplify deployment 5 1 web application the web application has been developed using the angular google 2017 user interface framework and the typescript programming language angular is well suited to building dynamic web applications that interface to web apis and services the user interface provides spatial context to users through relevant maps and spatial data 5 1 1 basinpedia users begin with a basin exploration phase in a part of the application called basinpedia users are presented with a global map of river basins at various levels of resolutions as provided by hydrosheds lehner and grill 2013 the user can click on any of these basins and is provided with a set of key water related summaries including land cover water stress indicators population catchment area endangered species groundwater features country boundaries and protected areas fig 5 these summaries are all calculated at runtime when a user selects a basin based on the selected geometry of the basin we use multiple global datasets to generate basinpedia summaries table 2 supplementary material these datasets are produced by experts and we do not alter them outside of calculating spatial summaries at different resolutions this approach is similar to that taken in development to hydroatlas linke et al 2019 whereby various datasets are attributed to basins to ease accessibility when a user selects a basin in the interface requests are issued to a server that calculates basin scale values which are then rendered in the map visualisation fig 5 5 1 2 model and scenario editor models and their related scenarios are created through the web application users follow the workflow that is described in section 4 the main component of this workflow is the editing of scenarios a labelled example is shown in fig 6 5 1 3 running models and viewing results model scenarios can be run in parallel through the user interface results are viewable either in a single scenario view or can be compared in a scenario comparison view and cover the following areas whole basin water balance reach hydrology indicators agriculture hydro power flow metrics and streamflow comparisons fig 7 shows an example of a single scenario river basin result page 5 1 4 user tools for data verification given the range of data available to users of basin futures the application provides features to assist users in choosing data and assessing a model s streamflow outputs these are described in the following two sections 5 1 4 1 rainfall analysis tool for any given basin there will be several global scale datasets available and possibly one or more regional datasets each will produce different results and they will have strengths and weaknesses for particular applications to give users an indication of the performance of rainfall data in the selected basin basin futures includes a rainfall analysis tool this tool integrates data from the global historical climatology network ghcn menne et al 2012 which consists of 206 857 timeseries of daily rainfall observations the server component maintains a database of all the rainfall analyses run on the system this allows results to be cached but also provides an ever growing database of the performance of various global and regional gridded data against the ghcn data this may be used in the future to provide more generalised guidance on the performance of particular data in different climatic regions 5 1 4 2 river streamflow comparisons we have included a streamflow comparison component that allows users to compare modelled results against observations of river streamflow there are two global datasets that are available for comparison the global runoff discharge centre grdc data the global runoff data centre 2017 that collates streamflow observation data from water authorities around the world and the global streamflow index metadata gsim data do et al 2018 gudmundsson et al 2018 the gsim data includes the grdc data but broadens its base to include more recent data particularly in areas such as south america and asia in addition to the global databases two country level connections have been implemented the australia water resource information system awris and the usgs water data services see section 5 2 1 2 these provide dynamic access to the entire countries gauging station data 5 2 design of the cloud based middleware the core of the system is a suite of middleware service components databases and integrated third party apis fig 8 the components used in the implementation of the platform are consistent with the ecosystem of tools described by palomino et al 2017 specifically we use open source geospatial environmental and data processing tools and standards that have been widely adopted in research communities swain et al 2015 the application server is responsible for the interaction between the web application and back end services it exposes an api for querying and accessing data spatial definition processes model definition and operation user accounts and worker based processing e g climate data processing and calibration it is implemented in python using python flask ronacher 2017 and python eve iarocci 2017 for mapping of domain model objects to api endpoints authentication and authorisation have been customised on top of the python eve implementation each of the application apis handles the interactions with specific internal and third party libraries and data for example the model api handles the interaction with the python fortran model wrapper the hydrosheds api interacts with the hydrosheds data which is stored and spatially indexed in postgis the reach model engine is implemented in fortran with a python wrapper that marshals function calls using ctypes heller 2020 it also ensures parameter validity in terms of structure e g array sizing to minimise model parameter interfacing errors the server is responsible for handling requests for data summaries such as those generated from rasters including land cover population density crop areas and global runoff geoserver deoliveira 2008 is used to serve open geospatial consortium ogc web mapping service wms web feature service wfs and web processing service wps interfaces to the client application it is linked to the postgis database the web application makes use of the wfs and wps services to query and extract relevant features from hydrosheds the climate data sets are stored in netcdf and processed using a python library rahman 2017 which makes use of the rasterstats perry 2019 library basin futures stores all timeseries data including reach scale aggregated climate data in a timeseries storage and processing platform called senaps coombe et al 2017 senaps is a scalable sensor data and metadata system that provides application programming interfaces apis for timeseries ingestion aggregation querying and extraction a senaps python client was used to import these data csiro 2020 the python api is used directly to extract query and aggregate data as needed for analysis and visualisation a redis key value store is used for queuing within the worker subsystem described below storing calibration results as a time series cache for senaps data and as a timeseries storage for model results the storage of timeseries in the cache is done using a sorted set with time based indexing implemented using a compound key of unix timestamps and individual values a mongodb instance is used to store application data such as model and scenario definitions user information model and calibration results and metadata elements 5 2 1 integration with third party apis third party apis have been integrated to allow dynamic querying of data proxied through the basin futures web application this allows the use of data curated by respective experts and allow them to be managed outside of the system 5 2 1 1 iucn red list the iucn red list is a global database of endangered species rodrigues et al 2006 we have implemented a dual approach to integrating these data we maintain a local spatially indexed version to allow flexibility in filtering and spatial querying e g within basin polygons and dynamic on demand access via the iucn api calls to the api resolve common names and broker access to details of individual species in the future we may move to a direct api approach to avoid replication and synchronisation required for maintaining a local version this will require more advanced filtering to be added to the iucn api the spatial querying and dynamic api access are all handled by the basin futures application server 5 2 1 2 national streamflow data services two national streamflow data apis have been integrated the australian water resources information system awris apis bom 2020 and the usgs water data service apis usgs 2020 these services both use waterml2 0 taylor 2012 data standards to publish national monitoring data this facilitates easier integration into services and web applications allowing basin futures to spatially and temporally subset requests on demand the application server proxies requests to the senaps api using the senaps python client library this adds post processing functions to the basin futures api calls such as server based resampling e g temporal aggregation and statistics while also adding required senaps authorisation 5 2 2 basin search basinpedia provides a river basin search function allowing users to textually search for any river system this was initially implemented using any name associated with the hydrobasins catchments however the naming of these is patchy and is generally only attributed for larger scale rivers we have since implemented search using the geonames api wick 2020 the api provides a spatially enabled feature type search which allows proximity searches of rivers and lake names we call this api on demand from the web application and cross reference the results with hydrobasins catchment areas 5 2 3 hydrobasins and hydrolakes the hydrobasins lehner and grill 2013 and hydrolakes messager et al 2016 data is stored using postgresql with postgis extensions for spatial indexing and querying we have implemented rest apis for accessing these data that provide a range of functions spatial querying topological navigation using the pfafstetter coding system verdin and verdin 1999 encoding in json bray 2014 relating relevant features river networks water storages and manual reach creation these functions support the reach creation process described in section 4 1 1 5 2 4 timeseries processing the timeseries api calls support typical timeseries processing operations such as calculating statistics and temporal aggregation these are implemented using the python pandas package mckinney 2011 also as a wrapper over the senaps api this component also calculates basin indices such as agricultural productivity water scarcity and storage reliability some more complex data processing tasks are also provided by the server such as those required for specific visualisations for example sankey water balance diagrams schmidt 2008 and flow duration curves these provide processed and restructured data that are then rendered client side this reduces load on the browser and makes use of server scalability 5 2 5 worker subsystem the worker sub system uses the celery framework celery 2019 for job submission queuing and worker nodes the basin futures api provides endpoints for asynchronous tasks to be submitted namely aggregating reach climate data climate change scenario scaling calibration of rainfall runoff models and other more intensive calculation processes tasks are split into task typed queues that allow flexibility to assign and scale to specific job types this ensures that when a large number of calibration tasks are submitted other processing tasks are not held up for example the running of scenarios docker containers are defined for worker nodes allowing flexible scaling up of both the number of system processes and compute instances future work may link scaling to demand to allow a truly elastic computing setup where computation resources are dynamic based on user load the current setup allows separation of task types ensuring that many calibrations can run in parallel while still allowing model runs and other higher priority processing tasks to occur 5 3 cloud deployment docker compose docker inc 2020 is used to setup the multi container environments for deployment this provides environment flexibility where development staging and production environments can be deployed rapidly either locally or to new cloud providers with consistent setup achieved through automation there are two primary deployments for hosting basinfutures com and staging basinfutures com these are hosted on the nectar research cloud an amazon web services aws hosted instance was deployed specifically for training in india to reduce latency for users and provide an example of a regional based deployment with the environment available now in aws it is possible to deploy in any of the aws availability zones the production deployment typically scales the number of workers to match available cpu cores 10 currently this would allow 10 scenarios or calibrations to be run in parallel we have preconfigured snapshot images for all workers allowing new instances to be added to the compute pool with no configuration we also have configurations where worker nodes are deployed onto dedicated instances allowing auto scaling via tools like kubernetes burns et al 2016 6 global and regional data and services 6 1 climate data the two required climate data inputs for the rainfall runoff and river system model are rainfall and potential evapotranspiration global scale climate datasets are increasingly being developed due to the improvements of earth observations data van dijk and renzullo 2011 the current global climate data sets made available in basin futures are shown in supplementary material table 3 climate scenario data has been integrated from the inter sectoral impact model inter comparison project isimip rosenzweig et al 2017 this project provides a range of harmonised climate change scenario datasets that are derived from the cmip5 models taylor et al 2012 p 5 we use both the historical and projected climate scenario data to allow setup and running of basin models under historical and future climate scenarios 6 2 station data in the context of this paper we refer to station data as actual observations or data summarising observations from monitoring stations e g monthly mean discharge measured at a location there are a number of efforts that collate global or regional databases do et al 2018 fekete et al 2002 gudmundsson et al 2018 menne et al 2012 the global runoff data centre 2020 of station data of particular types e g hydrological climatological additionally there are an increasing number of national systems that report station data at a national level dixon et al 2013 the station data available in basin futures is detailed in the supplementary material table 4 these data are primarily used to support model validation 6 3 agriculture data global agriculture data see supplementary material table 5 for details are used to provide estimates of crop areas to users when parameterising crop areas and for estimations of land suitability to assist in developing scenarios for future agricultural development 7 case studies and test results 7 1 brahmani river basin case study we have compared basin futures to other water modelling tools to compare data inputs model outputs and time and resource efforts to generate a water balance model we present a sample case study here for the brahmani river basin in india this case study compared the outputs generated from basin futures to a published water resource assessment on the basin icid 2005 the two assessments cover the same overall area albeit with different structure of sub basins reaches fig 9 while these different structures make it difficult to compare fine granularity results it is adequate for comparing basin level outputs a baseline model was constructed in basin futures with the default parameters and precipitation a baseline model was constructed in basin futures with the default parameters and precipitation data using the indian meteorological department imd and princeton potential evapotranspiration key basin results are compared in table 3 the mean annual outflow shows two set of results that reflect the icid reporting one set show observed mean annual discharge for three years 1998 1999 and 2000 while the other shows mean annual outflow for the icid model running in past mode which is pre 2000 to test the performance of different rainfall runoff calibration targets we created a brahmani basin model with a reach structure that matched the locations of the gsim gauging stations this used the gauge reach creation method described in section 4 1 1 we then ran 3 scenarios using default gr4j parameters calibrated to mean annual runoff and calibrated to mean monthly runoff this provides testing of the calibration approaches available within the user interface and differs from the testing provided in section 7 3 which uses a timeseries target from the gsim database for evaluation of the model performance we use the r2 nse and percent bias as recommended by moriasi et al 2015 as well as the ratio of the root mean squared error rsr for a unitless error metric moriasi et al 2007 the results are shown in table 4 these results indicate that for this case study the calibration to the global mean monthly runoff is providing a better nse and error deviation for monthly flows when comparing to the gsim observed monthly river flows bias is similar for the two calibration targets the annual target runoff calibration does not appear to improve on the default parameterisation we also executed the model simulation for three different climate datasets the indian meteorological department imd rainfall mswep and aphrodite see section 6 1 for descriptions these were selected as they provide examples of different scale data sets imd covers india aphrodite covers monsoon asia and mswep is global basin futures generates comparison statistics for each reach when compared to the gsim monthly river data the full results for each reach are shown in table 6 in the supplementary material a summary of the results is provided in table 5 the summary table shows counts of rating categories for each metric r2 nse bias and rsr according to moriasi et al 2007 2015 for monthly mean monthly and annual values results show the model is correlating with the monthly and mean monthly flow patterns reasonably well with the main issue being bias in some of the reach climate combinations this could be due to a number of factors including influences of groundwater and other consumptive such as crop and domestic use additionally the calibration is targeting mean monthly discharge with a nse target another option we plan to investigate is setting a bias objective function as well as more granular target runoff series the results show the annual flows are not matching well this is likely due to the calibration targeting mean monthly flows a closer analysis of the calibration approaches is required this should cover varying hydroclimate regimes areas with varying data availability which effects the global runoff grid targets and improving consistency in temporal separation of calibration and validation periods as well as alignment with the time period of the global gridded data future work will also include streamflow timeseries targets for calibration discussed in section 8 4 this simple case study shows basin futures is able to capture some of the key basin attributes and components of the water balance more detailed case studies are planned that will provide further results on the system s performance 7 2 application within a training setting one of the aims of basin futures is to lower the amount of effort required to start a basin water assessment and conduct subsequent scenario analysis this effort involves data preparation software installation and configuration computing setup and maintenance and actual software operation to understand the user experience and ability of the system to achieve these goals we conducted training using basin futures with eight water professionals from six different organisations in the south asia region each of the participants was guided through theory coupled with practical exercises using the system to study a basin as part of this training we conducted a user survey to assess the ease of use and usefulness of the software while the group was small the results indicated that the tool was easy to learn and had potential to be used as part of basin planning and management discussions users provided the following observations they commented on the high speed of the system and how it could be used to quickly assess different scenarios they were able to develop basin case studies over a matter of days with no prior knowledge of the tool they commented that the tool provided a complementary practical view of the theoretical concepts covered in the training users commented that the rainfall selection tool section 5 7 1 was valuable in guiding users in their choice of climate data and added transparency on how well the input climate was performing in the region we also noted that users were able to quickly collate statistics on the performance of models using different climate inputs and then related this to performance of the model against gauging station data 7 3 bulk testing rainfall runoff data model and calibration we conducted an automated approach to bulk test components of the system workflow selecting basins creating manual reaches generating climate data calibration of rainfall runoff to target values timeseries and generation of performance statistics this workflow uses the basin futures apis via a python jupyter notebook this provides a scalable computational environment whereby requests can be directed to different servers where required while result analysis is contained customisable and reproducible using this workflow we tested combinations of climate data sets and rainfall runoff model parameters and calibration targets in different regions it is possible to run this workflow for every gsim gauging station in the database 30 000 sites though for this analysis we have focussed on testing a specific region only future work would include running for all gauging stations which would allow summarised results to assist in guiding user decisions and warning in areas of low performance fig 10 show results in india using three climate precipitation data sets these results demonstrate the system is able to calculate upstream catchment areas from gsim locations red dots generate climate data for each sub area and run calibrations against a range of target values timeseries the nse results fig 10 are for calibration of climate data to the gsim observed monthly streamflow data the nse is for the model s representation of mean monthly flows targeting of calibration to the gsim data is not available from the user interface as the implementation requires consideration for the user selected reach structure flow target outlets and the location of the streamflow gauge this is discussed further in section 8 in addition to testing system operation these results provide a flexible way to test different climate data sets and identify any patterns of performance in regions this paper does not explore any possible conclusions arising from these results e g the spatial pattern of nses displayed in the test catchments below these analyses will be conducted in future work the focus here is demonstration that the system components are functioning and the use of data and models of data are sound results from india show performance of the available climate and rainfall runoff model are reasonable for northern basins with lower performance in the south the southern basins generally show a model overestimation of flows which in part could be due to these tests only modelling runoff without the routing storage and demand components of the model future work will include these aspects of the model by linking the whole reach model engine with the default parameterisation setups as described in section 5 7 4 performance results one of the key requirements for basin futures was to allow users to run scenarios in a web browser section 1 consequently scenarios must be able to run and return results within a timeframe that provides a reasonable user experience typically measured in seconds for the longer running tasks namely generating climate data at basin scale and calibration we initiate these processes while allowing users to continue to edit models in order to provide a continuous workflow that does not block users we have collected performance metrics from the execution subsystem see section 5 5 through development and testing phases of the system these results are shown in table 6 our aim was to collect results from actual use of the system as a whole rather than running models externally from the system under artificial conditions subsequently these numbers provide a reasonable indication of the performance of the system the data were collected over a period of 12 months of running the main testing server note that this also includes some changes in software versions to provide further insights into performance of the model run time and results save times we also tested across two environments by executing bulk scenarios we ran five different models with varied combinations of reach structures 3 9 reaches climate storage and crop configurations scenarios were run 50 times for each environment for a total 250 runs per environment results are shown in table 7 these execution times include retrieving climate data running the rainfall runoff models and running the reach model engine environment 1 16 cores 2 6 ghz 31 gb memory virtualised infrastructure open stack environment 2 8 cores 2 3 ghz i9 64 gb memory model run times are similar across the two environments and thus provide a reasonable indication of the expected performance of model execution the db save time is more consistent in environment 2 likely due to its higher write speed drive these tests are running docker containers on the single machine instances however we have implemented horizontal scaling for task workers allowing new instances to be added to run models calibrate and generate climate a scaled environment should thus offer run times consistent with these numbers we have used this setup in workshops with multiple users and the results show reliable run times 8 discussion 8 1 novelty of the basin futures system basin future combines a number of approaches to data model and cloud integration to deliver a novel approach to web based water assessments this appears to be the first integrated globally applicable web based tool for building hydrological models and rapidly developing scenarios there are tools that have some similar features but none of these provide the complete workflow from basin exploration model creation parameterisation scenario definition and results analysis this workflow supports users to explore many basin development scenario options section 4 2 that represent significant and contemporary water challenges our approach is similar to a recent web implementation of the soil and water assessment tool swat online mcdonald et al 2019 however we key differentiators include scenario development result assessment integrated third party apis and a user focused web application to guide the user through model setup and execution our approach also presents similarities to swatshare rajib et al 2016 specifically because of the focus on the creation of reproducible online and sharable models however basin futures differs in that it provides the model and scenario development workflow within the tool and has pre integrated global data and connection to regional web services to allow parameter estimation and model comparison this forms the basis of reducing effort for users in model setup and configuration there are also other similar systems that focus in other specific water management areas examples include florean provides a web based platform for flood forecasting svatoň et al 2017 castrogiovanni et al 2005 describe a web gis system for flood design and risk analysis recently a web based application for investigating groundwater sustainability evans et al 2020 or the climb geoportal blaschek et al 2015 as a generalised approach for sharing hydrological modelling data via open web services among others increasingly cloud based systems are also used as a way of scaling calibration and or sensitivity analysis kc et al 2020 our worker subsystem uses the same concepts typically deployed in these environments through the integration and use of global and country level web services we have demonstrated the value of data holders providing apis web services for the publication of data these services allow tools such as basin futures to dynamically query and retrieve data from a well maintained point of truth this avoids the traditional approach of data integration via downloading one off files translating and integrating the benefits of using a service approach include data is curated and maintained by those who know the data best updates to data are reflected in the downstream tools automatically communities can benefit from shared implementations of retrieval and analysis code we are not aware of any globally applicable web based hydrological models that integrate across this range of data services the implementation of the web based model editor that provides recommended parameterisation of model components from data and services differs from these existing systems this is a concept that is applicable to a range of service based systems and gives a mechanism for data providers to integrated directly with modelling and analysis workflows an advantage of basin futures is its low barrier to entry and accessible interface through a web browser this helps to address the accessibility challenges of modelling systems identified by al sabhan al sdlubhan mulligan and blackburn 2003 interfacing is difficult knowledge of gis is required platform dependency customisation of models is difficult and limited accessibility of data our approach aligns with recommendations identified for data science of the natural environment specifically to offer levels of abstraction and associated services that are much better suited to the domain of science including high level support for running complex integrated modelling in the cloud blair et al 2019 by removing the requirement for users to work through software installation data gathering and transformation and model setup we are able to get users focussed on developing a preliminary understanding of water resources availability in a basin subsequently they are able to rapidly explore the impacts of different development scenarios and explore related consequences 8 2 considerations for integrated cloud based model data environments there are benefits and trade offs to having a fully integrated model data environment these include 8 users lose the flexibility of modular modelling environments where different models may be swapped in and out however these modular environments are often difficult to develop the use of service or api wrapped models is an increasingly used approach to handle these challenges gao et al 2019 gichamo et al 2020 granell et al 2010 mcdonald et al 2019 nelson et al 2019 roman et al 2009 9 there is more reliance on the availability of the models and data that have already been integrated into the platform however users are not required to invest time into any data integration tasks 10 transparency of the underlying data and models may be reduced if there is not adequate documentation references etc we attempt to alleviate this by providing contextual help that describes and references the relevant algorithms data and literature 8 2 1 data updates and access consideration needs to be given to handling data updates and integration of new data update processes can be automated for example when new versions of climate data are published if there is support at the point of data publishing however many traditional data publishing mechanisms involve publishing data on websites or on ftp servers in compressed archives with only text file descriptions of formats and access protocols this situation is improving with many data publishers moving to support web services and apis for data discovery description and access beran and piasecki 2009 taylor 2016 vitolo et al 2015 our work here shows examples of a spectrum of these approaches integration of one off published data from research through to integration with nationally harmonised and updated data sets through apis such as those from the usgs and the australian bureau of meteorology services as national and global systems mature it will allow a more decoupled composition of systems and services that can be updated at the point of truth and easily integrated to other applications and services changes to underlying data raises the issue of how to handle these changes in the models that use them when an update occurs to a data set there needs to be consideration for how this effects existing models the model needs to reference a stable data version to ensure that previous model runs can be reproduced with the same results for example there may be mechanisms put in place that would advise users when there are new versions of data available for existing models a benefit of the encapsulated model data environment is that data generated by the system can be re used and or contribute to new combined data sets for example the rainfall comparison tool will over time build up a dataset of statistics of performance of particular climate data in different regions this data could then be used in recommenders and or published as a new data set in its own right for example via a system such as suggested by essawy et al 2018 often intermediate datasets of comparison activities are lost an integrated platform allows the collection of this data over time 8 2 2 benefits of cloud based models cloud based modelling services offer users a range of benefits including integration of all the component parts hiding complexity services that may be integrated in to their own software workflows and product that has broad reach globally pushing down the requirements of a user to a web browser and an internet connection in effect it outsources the major challenges that a modeller may have including compute storage management of complex workflows and an improved user experience these benefits have been reflected in the feedback received from users section 7 2 users can focus on the process of constructing a model choosing model data scenarios combinations and analysing the results rather than complexity of building models from scratch the cloud based architecture described provides a flexible computational environment that can be scaled according to the number of users this removes the need for users to deploy infrastructure and handle resources directly the ongoing cost of operating a cloud hosted system needs to be considered and planned for most software as a service provides recover costs via a commercial model the water modelling community predominately uses desktop based software either from commercial providers or through open source software basin futures has a different delivery mechanism and is a vertically integrated package we are planning the most appropriate approach for ongoing hosting the system stores all model results and provides download options through the interface or apis to allow analysis or integration with other software in development of the system this was done within a python jupyter notebook environment models can be shared between users and are also versioned a new version is added for every change that is saved to the server this puts in place the functions required to revert to specific versions and reference specific versions of a model instance these features are important considerations within the broader reproducible science discussion gichamo et al 2020 munafò et al 2017 8 3 system performance the performance results in section 7 4 demonstrate the system is able to generate climate run scenarios and calibrate rainfall runoff in times that are acceptable for use in a web application of this nature closer inspection of the scenario run time shows the majority of time is spent post processing and writing results to the timeseries database a model of 9 reaches run over 40 years the average model run length will produce in the range of 2 3 million timeseries values at daily resolution most of these timeseries are summarised to monthly statistics for database storage reach level daily flows are used for comparison of environmental flow metrics resulting in more than 200 000 timeseries values including the required daily series generated per model run the majority of computation time for the output writing is in the temporal aggregation and conversions we expect to optimise this in a future release 8 4 model scope calibration and performance the basin future representation of the water balance and its inherent uncertainties requires further testing the model lumps and simplifies physical processes and thus contains many uncertainties the range of testing and results described demonstrates the system is able to capture some of the main hydrological relationships catchment structures climate data rainfall runoff relationships there are still aspects that require further testing comparisons of different aspects of the river system model including storage behaviour agriculture demands and indicators the testing to date indicates the system is able to adequately represent basin catchment areas and structure monthly flows identify storages and represent demands the rainfall runoff results demonstrate the system is able to calibrate to different targets and is showing some acceptable performance in comparison to gsim monthly observed streamflow however the bulk rainfall runoff results do not show performance of the different calibration targets or the areas that the data and models are not performing adequately the brahmani basin case study shows results using the different calibration targets and indicate the calibration to mean monthly values does improve the representation of monthly flows when compared to gsim the approach to rainfall runoff calibration was implemented to allow global application it is however a non standard approach to calibration most rainfall runoff models are calibrated to streamflow timeseries where gauging data is not available or is not within a reasonable proximity of a calibration point other approaches must be taken such as regionalisation techniques wagener et al 2004 the approach we have taken is to start with a coarse target that can be used anywhere then build in more sophisticated approaches such as calibrating to streamflow timeseries this is perhaps the most familiar approach for many modellers but has not been implemented in basin futures to date due to the need to conflate the gauging station location with the model structure recognising that the locations of streamflow measurement stations may not provide an appropriate scenario centric delineation of model reaches the option to define reaches by gauging station location section 4 1 1 provides a first step to alleviating this problem the mean runoff targets are a coarse calibration approach that were chosen as a starting point for global application but will suffer from high parameter uncertainty and the equifinality issue beven 2006 calibration is currently only performed on the rainfall runoff component of the model this leaves the crop model storage and demand components uncalibrated we do provide some assistance in the parameterisation of these components section 4 1 4 however it is up to the user to assess the model results for these components this has been done to date through comparison with numbers in the literature the basin future simplifications influence which basins it is capable of modelling see section 3 4 in order to assist users in assessing a models uncertainty we plan to provide warnings when either there is a high level of groundwater influence or a strong snow glacier runoff influence determining how this would be achieved is to be resolved 8 5 uncertainty in basin future model data and methods there is a high level of uncertainty inherent in the combination of global data and lumped models an overview of our preliminary assessment of sources of uncertainty are show in table 8 the potential level of uncertainty in results from basin futures is high as is the case with most models poor input and or parameterisation will result in poor outputs given this tool aims to be easy to use we aim to provide sufficient warnings to users so they are aware of the uncertainty when interpreting results designing these warnings is something we are working through we have initial heuristics that could be used to warn users that in specific areas the data and or representation of the system is not adequate these would consider different factors such as insufficient calibration data historical performance of chosen climate data in a region correlation with nearby streamflow observation stations or known gaps in the global data that has been used within the model in future work we would look to incorporate these into the user facing parts of the system 9 conclusions this paper presents a new product basin futures for entry level basin modelling initial assessments for water development projects and education the product aims to simplify the modelling and scenario process by standardising the user workflow pre integrating models and data providing on demand computer resources and delivering the capability through an easy to use web application experience with users indicates they are able to develop initial case studies after one to two days using the software user testing has shown it is easy to use and provides valuable information for basin scale water assessment and scenario investigation the integrated approach to basin scenario definition provides a rapid way for users to begin assessing changes arising from developments in agriculture water storages population growth and climate change all of which are significant challenges for water planners and educators declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the development of basin futures was funded through a strategic alliance between csiro and the international centre of excellence in water resources management ice warm the authors wish to acknowledge the early support of the international commission of irrigation and drainage icid especially harish varma and avinash b pande also to darryl day peter wallbrink joel stewart tony weber and neil byron for their constructive input through the development process we would like to thank the australian national university s water futures institute team for their ongoing support and feedback we would also like to thank the australian national eresearch collaboration tools and resources nectar project for their ongoing provision of cloud computing resources to support this work thanks to hongxing zheng and susan cuddy csiro for their constructive feedback on the paper many thanks to the four anonymous reviewers for their constructive feedback on the manuscript we also wish to acknowledge the many data producers and custodians who have made available the range of data used in this system appendix a supplementary data the following is the supplementary data related to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2021 105049 software and or data availability the initial version of basin futures is available at https basinpedia basinfutures com which contains basinpedia the full version will be released once testing has been completed 
25820,water resources are under growing pressure globally sustainable water management requires an understanding of how much water is available where it is stored and used and how future developments may impact availability understanding this requires investment in data models and experts these investments are labour intensive with considerable effort spent in three main areas collecting and transforming data building calibrating running and maintaining models and developing required reports and visualisations we present basin futures a cloud based product developed to lower this initial effort by providing pre integrated data a template model structure that makes some simplifying assumptions for speed easy setup of new scenarios a scalable data processing and simulation architecture and delivery through a web browser the case studies and results presented show the product is quick to learn fast in execution and provides an easy way to explore water resource development scenarios for river basin management and planning keywords basin planning watershed planning iwrm user centred design cloud computing hydroinformatics cyberinfrastructure environmental modelling global data scenario exploration tool 1 introduction understanding the state of water systems and connectivity with its many uses is crucial to planning and improving management practices however the complexity and uncertainty associated with water systems make decisions regarding their development and management challenging particularly when considering the dynamics of socio ecological systems typically models are used to support understanding current and future water availability döll et al 2003 sordo ward et al 2019 and consequences associated with alternative investments or policies schmolke et al 2010 xu and tung 2008 to inform planning on water resource decisions for example when considering an investment in water infrastructure for irrigation schemes or hydropower water models must consider related systems such as water storages domestic demands agriculture among others this modelling is complex time consuming and expensive the trade off in accuracy cost and consequences associated with modelling for decision making is well established acreman 2005 our experience concurs with that of kirby et al 2013 that there is value in tools that provide a broad initial picture of a basin s water resource base at a lower cost while also providing a connection to the water related economic social and environmental aspects of a river basin various challenges are faced by developers and users of these models a large amount of time and effort is required in collecting and transforming data building calibrating and maintaining models and developing required reports and visualisations while there are many tools to assist with each of these activities assembling the separate parts into a useable solution requires significant expertise often at great expense consequently many countries particularly developing countries rely on external expertise to perform this work scott stevens 2019 this can lead to poor uptake of the solutions as the organisation may not trust or have the expertise to absorb the technology or the infrastructure to support the external solution nelson et al 2019 the quality and availability of global and regional climate data is ever improving through investments in earth observations new sensors and data management practices chen and han 2016 vitolo et al 2015 however the diversity and size of these data present many challenges for users chen and zhang 2014 finding integrating and testing necessary data requires large investments to bring insights to decision makers nativi et al 2015 additionally studies suggest that the percentage of available climate data that is actually used in aiding decision making is low dahlhaus et al 2015 lehmann et al 2014 advances in the application of information and communication technologies ict or cyberinfrastructure essawy et al 2018 sun et al 2020 wan et al 2014 are helping to address these challenges specific developments in these areas include the provision of software as a service and its many flavours including modelling as a service nelson et al 2019 cloud computing and modernisation of data analysis platforms these new ways to develop and deploy software assist in overcoming many issues with traditional desktop style software including increased scalability easier handling of large data sets decreased implementation and maintenance costs and simplified model setup and configuration among others delipetrev et al 2012 glenis et al 2013 spichkova et al 2016 these approaches form the technical basis on which we developed an integrated product basin futures with the aim of conducting rapid basin scale water assessments with a low technical footprint for users the development of basin futures focussed on three high level requirements 1 global application it must be able to run for any basin in the world 2 ease of implementation and use we wanted users to be able to run models in the browser quickly to allow a faster comparison and exploration of scenarios we want users to focus on exploring options and trade offs 3 reduced learning curve the tool must be easy to learn to reduce the time spent on tasks not associated with building understanding of the river basin being explored the tool was developed to provide a first pass tool to explore three key questions much water is available where is it stored and used and how future developments may impact its availability first pass here refers to generating a preliminary picture of a basin s water resources in a short period of time it also implies a higher level of uncertainty given the rapid nature of the assessment in this paper we detail the design and testing of basin futures we begin with a brief coverage of relevant prior work the basin modelling requirements and context are then covered followed by details of the models used we then describe the user workflow and design of the cloud based system the global and regional data used and then describe the application through a case study and testing of the product to date and finish with discussion and conclusions covering the key points arising from this work 2 related work the approach taken in developing basin futures is at the intersection between integrated basin scale management and cloud enabled modelling systems here we briefly cover some of the key concepts and related work at this intersection hydrological models and more specifically in the context of this paper models used for basin planning are commonly established and employed to assist decision making challenges in their use are still present ensuring appropriate scale blöschl and sivapalan 1995 the effort required to setup calibrate and deploy them and understanding their inherent uncertainties when informing the decision making process among others it is also recognised that models need to be supported by high quality data and monitoring processes silberstein 2006 models that integrate systems that interact with water on a broader level such as coupling concepts of land management agriculture climate society and economics are more nascent harou et al 2009 lerner et al 2011 wang et al 2019 li et al 2018 provide a framework for considering the challenges for the next generation of integrated basin models these models must link natural and social sciences be based on sound scientific principles carefully consider uncertainty and take advantage of new technologies and research the suggested framework highlights the importance of the intersection of the watershed system model and the watershed cyberinfrastructure the latter being the enabling technology platform on which next generation systems may be built there are many initiatives using advances in data availability and ict to address environmental modelling and assessment challenges a recent position paper from chen et al 2020 provides review of integrated modelling and simulation systems and their overlap with service oriented architectures with a forward looking focus on open web distributed integrated modelling among the conclusions of this work the authors recommend systems that focus on user experience to enable adoption and participation the use of standards is highlighted as a key enabling technology something that has been a focus of our work here section 5 2 the importance of computational patterns for model execution are also highlighted with reproducibility a key concern we discuss in section 8 as well as issues relating to system environments dependencies and tracking changes in resources our work demonstrates how containerisation technologies can assist addressing some of these challenges though many remain versioning of models data and other resources over the web is still large challenge hutton et al 2016 stagge et al 2019 there are initiatives investigating approaches to these challenges essawy et al 2018 recent work on modernisation of geographical information systems gis suggest systems need to be easy to use and easy to compute zhu et al 2020 our approach is well aligned with these recommendations the easy to use quality refers to three aspects of being intuitive assisted and cyber enabled easy to compute refers to the use of high performance computing and facilitating complex computing for example the ability to handle computation of many complex interrelated processes these concepts are in accordance with the three high level requirements for the development of basin futures section 1 the number of systems that integrate models into cloud and web based systems are growing the soil and water assessment tool swat model jayakrishnan et al 2005 has been applied in web environments for specific purposes such as watershed management zhang et al 2015 sharing of model outputs and education giuliani et al 2013 rajib et al 2016 modularisation and visualisation mcdonald et al 2019 and calibration and uncertainty analysis zhang et al 2016 these systems make use of the accessibility of having models and their results online offer benefits of reproducibility and the flexibility of cloud based processing there are also frameworks arising that focus on generalised environments to manage data integration and model execution coombe et al 2017 liu et al 2012 sensitivity analysis for hazard modelling kc et al 2020 and execution of scientific workflows oliveira et al 2012 that can support models or simulation there are important lessons from these pieces of work that are relevant to our work including considerations for scheduling execution and contention of resources within public clouds liu et al 2012 within water management there are ongoing efforts towards improving reproducibility and online sharing of models and resources the hydroshare and geotrust projects have demonstrated this in application of the modlow model within the united states essawy et al 2018 through connection to the amazon web services aws cloud environment there is potential to use sharing platforms like these as a mechanism to publish basin futures model results we have summarised some of the key features of related cloud based modelling systems in table 1 this provides some context for how these systems relate to the key features columns within basin futures 3 basin modelling basin modelling is commonly applied to assist decision makers in planning and managing water resources and related natural and manmade systems alluvium et al 2020 these include rivers water storages reservoirs lakes dams groundwater wetlands as well as systems that consume or demand water resources for example agriculture domestic use industry or demands from outside the basin via water transfers these systems are dynamic complex and interdependent additionally the number and diversity of stakeholders and their needs adds to the complexity of effective planning consequently decision making relating to equitable sharing of water is highly problematic grafton 2017 basin data and models are used in three main areas to inform understanding of the state of a basin historical and current inform future planning decisions within the basin using simulation of changes or future conditions or for operational decisions such as operating dams irrigation system access control etc zhang et al 2016 the use of basin futures can assist in the first two of these roles though we also see it having application in education and training for water resource management and hydrology this section outlines the models that provide the core simulations within the basin futures system the focus of this paper is the system as a whole particularly the software architecture data infrastructure and services however we provide details of the models to ensure transparency 3 1 basin futures model structure basin futures currently has two main modelling components rainfall runoff via gr4j perrin et al 2003 to generate sub catchment runoff and a reach model engine for undertaking water management and transfer activities such as water storage hydropower generation routing of flows through the basin unaccounted losses and gains and rural urban industrial irrigation and environmental demands an overview of the reach model engine components is shown in fig 1 the models run on a daily timestep but given their conceptual lumping the results are reported on a monthly timestep the following sections describe the model components with details provided in the supporting material when selecting the models for the basin futures system a number of key requirements were identified simplicity for end users minimal parameters and ease of deriving parameters data requirements that could be met by published global datasets but augmented with local data as available defensible results and fast runtime speed low memory use the models described here implement well published and widely used model components that satisfy these requirements other models could be used in their place providing they match in the level of granularity and parameterisation 3 2 rainfall runoff model the rainfall runoff gr4j model operates at the sub basin scale and takes the daily rainfall and pet data generated at the sub basin scale to estimate daily runoff time series as with other components in basin futures the configuration and calibration of the runoff component are influenced by the availability of relevant global data sets users have the option of directly setting parameters for the model or calibration using two options run a calibration to target a mean annual runoff value or 12 mean monthly runoff values these values are derived from a global runoff grid provided by fekete et al 2002 the mean annual and monthly runoff targets were implemented first as they do not require local streamflow observations to be available and are thus globally applicable the system is able to calibrate the rainfall runoff model to observed streamflow from the available station databases see section 6 2 however this is not yet available through the user interface once the climate data has been processed a calibration wizard guides users through a process of estimating the rainfall runoff parameters based on the selected target calibrations are run using the python optimisation package spotpy houska et al 2015 multiple optimisers are available our current implementation uses the shuffle complex evolution vrugt et al 2003 algorithm to maximise the nash sutcliffe efficiency nse coefficient for mean monthly runoff or minimise the root mean squared error rmse for mean annual runoff once target runoff values have been selected worker processes are initiated that run in parallel using the worker sub system the results of calibration are stored for the user to access once complete as well as providing a historical record of calibration runs calibration results may be reloaded into the model allowing different calibrations to be easily compared or reproduced at later stages 3 3 reach model engine the modelling component that captures the river system processes is the reach model engine fig 1 this model component is implemented in fortran for execution speed and wrapped in python a reach is defined as a segment of river that transfers water from upstream sub basins to downstream sub basins contained within the reach are some of the key water management processes such as water storage hydropower generation and water extraction for pattern demands and crop irrigation the reach model engine forms a common template for all reaches with these various model components being present in each reach in the same order regardless of whether a particular component such as hydropower is in use within a reach the reach template approach is more similar to that used in australian water resource assessment river system model dutta et al 2017 than a node link network approach welsh et al 2013 3 3 1 storages the general model structure places the storage if present in a reach at the top of the reach from which water demands are supplied to downstream users within the reach inflows to the storage come from the outflows of upstream reaches and from a portion of the runoff generated within the local catchment area of the reach outflows from a storage are governed by level volume area relationships controlled release mechanisms such as valves and multiple outlet paths and types including uncontrolled release pathways spillways hydropower production is a function of discharge head and specified turbine efficiency full details of the storage model are provided in the supplementary material storages for each reach are identified and parameters suggested to the user via a global storage definition database see section 4 1 4 these details include the storage volume and surface area which can then be adjusted by the user the system calculates rough level volume area and release curve relationships from the volume and area parameters based on a simple wedge geometry user supplied level volume area tables will be supported in future versions the simplification of the storage geometry introduces uncertainty to the storage dynamics which is outline in section 8 5 both irrigated and dryland farms may optionally include on farm storages the farm may have multiple storages that are described by level volume area relationships inactive storage volume and seepage as a function of storage level in addition to the on farm storage there is also a storage that represents overbank flow floodplain storage fig 2 3 3 2 routing and demands in addition to storage mass balance modelling the reach model engine routes flows within a reach using storage koussis 2009 or piecewise linear routing and incorporates local catchment inflow unaccounted reach losses or gains water demands from irrigated crops water balance for multiple crop types simultaneously and other demands hydropower urban industrial environmental water demands are passed up a reach to the reach storage where water is released subject to outlet constraints incorporating the travel time and losses to attempt to fulfil the downstream demand the model architecture prohibits the propagation of water orders beyond the reach to upstream reaches diminishing the need for iterative solvers to calculate the water demand cascade between all reaches this model structure decision allows linear computation sequence and thereby much faster computation times the model level implications for this are discussed in the discussion section 3 3 3 crop model the crop model implemented by basin futures is similar to the aquacrop model raes et al 2009 developed by the fao food and agricultural organisation the crop model simulates the yield response of herbaceous crops to water stress and is particularly suited for simulating irrigation scenarios and associated impacts on yield andarzian et al 2011 the model also captures fallow land and associated runoff the model is simple it only uses a relatively small number of explicit parameters and mostly intuitive input variables requiring simple methods for their determination with global datasets available to parameterise the model where local data is unavailable economic and nutritional estimates are post processed 3 3 4 environmental flow metrics we use well established algorithms for calculating key flow metrics sengupta et al 2018 implemented in r and wrapped using the rpy2 package rpy2 r in python 2019 2 to provide calculations of key flow metrics the metrics used are supplied in the supplementary material table 1 these metrics are calculated as part of the reporting of the hydrological index of alteration this allows users to compare the changes in basin flows between multiple scenarios at a reach and basin scale given the computation expense these metrics are performed by the worker subsystem 3 4 current limitations of the model there are two key concepts that are not currently modelled by the river system model groundwater and snow glacier runoff there are aspects of groundwater interaction that are supported by the model such as groundwater extraction via pumps for irrigation and deep drainage from irrigation however the state of the groundwater system i e aquifer levels are not modelled this is largely due to the limited available data for aquifers although we have conducted initial research into potential approaches for snow glacier runoff contributions we have implemented an extension to the gr4j model gr4j sg similar to the approach described by nepal et al 2017 the data requirements for the sg component are more intensive and are still under development for a future release the model also does not allow a reach to order water from reaches upstream of the storage thus simplifying computation and allowing quicker run times the reach model engine is able to order water from storages within a reach but not pass these water orders backward through upper reaches this results in the model not being suitable for use in more regulated water systems where it is common for orders to be propagated through a river network to implement complex water management rules welsh et al 2013 the uncertainties of the system as a whole are described in more detail in section 8 5 4 user workflow the user workflow of basin futures follows four broad stages basin exploration model and scenario setup scenario exploration and exploring impacts fig 3 basin exploration step 1 is done within basinpedia and is described in section 2 2 1 model and scenario setup step 2 are described in the following section with steps 3 4 and 5 covered in section 5 1 2 4 1 model and scenario setup using a basin selected from basinpedia a user can progress into the model implementation phase a basin model is created through the following steps fig 4 4 configuring spatial resolution and sub catchment structure 5 selection of desired climate data 6 calibration of rainfall runoff model 7 parameterisation of reaches including storages crops soils irrigation demands and environmental flows 4 1 1 configuring spatial resolution and sub catchment structure the first step in creating a model is to divide the basin into river reaches that represent the conceptual catchment units this can be done in three ways 1 the first is to use predefined hydrosheds basins lehner and grill 2013 2 manually create reaches using the reach creation tool this allows users to select points on the river network as defined in the hydrosheds data set through the interface users can click on the map component and points are snapped to the river network by the server and reflected in the ui the upstream catchment area of the snapped points is then calculated using flow direction grids through the taudem tool tarboton 2005 that runs on the server the reach structure is shown to users to allow refinement of the basin substructure 3 create reaches based on gauging station locations the gauging station approach defines points on the river network that correspond with flow measurements available from the global streamflow index metadata gsim database section 6 2 these locations are then used for flow accumulation in the same way as the manual reach creation this approach allows direct correspondence with observation locations to assess performance of the model s river flow simulations 4 1 2 selecting climate data climate data selection requires a choice of precipitation and potential evapotranspiration from the available climate datasets see 6 1 the choice of precipitation is aided by a rainfall comparison tool see 5 7 1 once climate choices have been made data processing jobs are submitted to the back end system for calculation of sub basin scale data 4 1 3 rainfall runoff calibration calibration is currently only performed on the gr4j rainfall runoff model the user can choose to do this reach by reach or using a wizard this process is detailed in section 3 2 both climate data processing and calibration are longer running processes and thus cannot be completed in time to feedback directly to the user our approach is to have jobs submitted to the back end system and allow the user to continue working while these tasks run however this requires managing data dependencies running rainfall runoff calibrations or scenarios cannot occur until all climate data has been processed for each reach this adds requirements to the interface to keep the user up to date with these back end analysis tasks and block particular tasks until earlier tasks are completed 4 1 4 reach parameterisation parameterisation of individual reaches step 4 in section 4 1 is performed in the basin futures model editor this is used for initial model implementation and the subsequent exploration of model scenarios each reach contains parameters that describe five components rainfall runoff calibration settings storages crops irrigation demands water transfers and environmental flows where available the setting of these parameters is aided by the use of global data as shown in fig 4 4 2 rapid scenario development for exploring future pathways the ability to rapidly create and configure scenarios provides a flexible way to explore impacts arising from developments within a river basin steps 2 3 4 and 5 in fig 3 form an explorative approach to basin analysis that when coupled with the speed and accessibility of the system allow exploration of many scenarios examples of the scenarios that can be explored and the system functions to support these are shown in table 2 these scenarios have all been used within the system to date including in training contexts as described in section 7 2 these scenarios can be setup and configured through the web based scenario editor section 5 1 2 and configured for varying combinations e g crop and irrigation scenarios under climate change 5 cloud based system for data processing and model simulation basin futures consists of a web application supporting middleware and a cloud deployment architecture the following three sections cover these in turn the overall design of the system has been guided by three technical principles use service based components via suitable web based application programming interfaces apis maximise component and library reuse by building on open and existing source code containerise all services using docker to isolate dependencies and simplify deployment 5 1 web application the web application has been developed using the angular google 2017 user interface framework and the typescript programming language angular is well suited to building dynamic web applications that interface to web apis and services the user interface provides spatial context to users through relevant maps and spatial data 5 1 1 basinpedia users begin with a basin exploration phase in a part of the application called basinpedia users are presented with a global map of river basins at various levels of resolutions as provided by hydrosheds lehner and grill 2013 the user can click on any of these basins and is provided with a set of key water related summaries including land cover water stress indicators population catchment area endangered species groundwater features country boundaries and protected areas fig 5 these summaries are all calculated at runtime when a user selects a basin based on the selected geometry of the basin we use multiple global datasets to generate basinpedia summaries table 2 supplementary material these datasets are produced by experts and we do not alter them outside of calculating spatial summaries at different resolutions this approach is similar to that taken in development to hydroatlas linke et al 2019 whereby various datasets are attributed to basins to ease accessibility when a user selects a basin in the interface requests are issued to a server that calculates basin scale values which are then rendered in the map visualisation fig 5 5 1 2 model and scenario editor models and their related scenarios are created through the web application users follow the workflow that is described in section 4 the main component of this workflow is the editing of scenarios a labelled example is shown in fig 6 5 1 3 running models and viewing results model scenarios can be run in parallel through the user interface results are viewable either in a single scenario view or can be compared in a scenario comparison view and cover the following areas whole basin water balance reach hydrology indicators agriculture hydro power flow metrics and streamflow comparisons fig 7 shows an example of a single scenario river basin result page 5 1 4 user tools for data verification given the range of data available to users of basin futures the application provides features to assist users in choosing data and assessing a model s streamflow outputs these are described in the following two sections 5 1 4 1 rainfall analysis tool for any given basin there will be several global scale datasets available and possibly one or more regional datasets each will produce different results and they will have strengths and weaknesses for particular applications to give users an indication of the performance of rainfall data in the selected basin basin futures includes a rainfall analysis tool this tool integrates data from the global historical climatology network ghcn menne et al 2012 which consists of 206 857 timeseries of daily rainfall observations the server component maintains a database of all the rainfall analyses run on the system this allows results to be cached but also provides an ever growing database of the performance of various global and regional gridded data against the ghcn data this may be used in the future to provide more generalised guidance on the performance of particular data in different climatic regions 5 1 4 2 river streamflow comparisons we have included a streamflow comparison component that allows users to compare modelled results against observations of river streamflow there are two global datasets that are available for comparison the global runoff discharge centre grdc data the global runoff data centre 2017 that collates streamflow observation data from water authorities around the world and the global streamflow index metadata gsim data do et al 2018 gudmundsson et al 2018 the gsim data includes the grdc data but broadens its base to include more recent data particularly in areas such as south america and asia in addition to the global databases two country level connections have been implemented the australia water resource information system awris and the usgs water data services see section 5 2 1 2 these provide dynamic access to the entire countries gauging station data 5 2 design of the cloud based middleware the core of the system is a suite of middleware service components databases and integrated third party apis fig 8 the components used in the implementation of the platform are consistent with the ecosystem of tools described by palomino et al 2017 specifically we use open source geospatial environmental and data processing tools and standards that have been widely adopted in research communities swain et al 2015 the application server is responsible for the interaction between the web application and back end services it exposes an api for querying and accessing data spatial definition processes model definition and operation user accounts and worker based processing e g climate data processing and calibration it is implemented in python using python flask ronacher 2017 and python eve iarocci 2017 for mapping of domain model objects to api endpoints authentication and authorisation have been customised on top of the python eve implementation each of the application apis handles the interactions with specific internal and third party libraries and data for example the model api handles the interaction with the python fortran model wrapper the hydrosheds api interacts with the hydrosheds data which is stored and spatially indexed in postgis the reach model engine is implemented in fortran with a python wrapper that marshals function calls using ctypes heller 2020 it also ensures parameter validity in terms of structure e g array sizing to minimise model parameter interfacing errors the server is responsible for handling requests for data summaries such as those generated from rasters including land cover population density crop areas and global runoff geoserver deoliveira 2008 is used to serve open geospatial consortium ogc web mapping service wms web feature service wfs and web processing service wps interfaces to the client application it is linked to the postgis database the web application makes use of the wfs and wps services to query and extract relevant features from hydrosheds the climate data sets are stored in netcdf and processed using a python library rahman 2017 which makes use of the rasterstats perry 2019 library basin futures stores all timeseries data including reach scale aggregated climate data in a timeseries storage and processing platform called senaps coombe et al 2017 senaps is a scalable sensor data and metadata system that provides application programming interfaces apis for timeseries ingestion aggregation querying and extraction a senaps python client was used to import these data csiro 2020 the python api is used directly to extract query and aggregate data as needed for analysis and visualisation a redis key value store is used for queuing within the worker subsystem described below storing calibration results as a time series cache for senaps data and as a timeseries storage for model results the storage of timeseries in the cache is done using a sorted set with time based indexing implemented using a compound key of unix timestamps and individual values a mongodb instance is used to store application data such as model and scenario definitions user information model and calibration results and metadata elements 5 2 1 integration with third party apis third party apis have been integrated to allow dynamic querying of data proxied through the basin futures web application this allows the use of data curated by respective experts and allow them to be managed outside of the system 5 2 1 1 iucn red list the iucn red list is a global database of endangered species rodrigues et al 2006 we have implemented a dual approach to integrating these data we maintain a local spatially indexed version to allow flexibility in filtering and spatial querying e g within basin polygons and dynamic on demand access via the iucn api calls to the api resolve common names and broker access to details of individual species in the future we may move to a direct api approach to avoid replication and synchronisation required for maintaining a local version this will require more advanced filtering to be added to the iucn api the spatial querying and dynamic api access are all handled by the basin futures application server 5 2 1 2 national streamflow data services two national streamflow data apis have been integrated the australian water resources information system awris apis bom 2020 and the usgs water data service apis usgs 2020 these services both use waterml2 0 taylor 2012 data standards to publish national monitoring data this facilitates easier integration into services and web applications allowing basin futures to spatially and temporally subset requests on demand the application server proxies requests to the senaps api using the senaps python client library this adds post processing functions to the basin futures api calls such as server based resampling e g temporal aggregation and statistics while also adding required senaps authorisation 5 2 2 basin search basinpedia provides a river basin search function allowing users to textually search for any river system this was initially implemented using any name associated with the hydrobasins catchments however the naming of these is patchy and is generally only attributed for larger scale rivers we have since implemented search using the geonames api wick 2020 the api provides a spatially enabled feature type search which allows proximity searches of rivers and lake names we call this api on demand from the web application and cross reference the results with hydrobasins catchment areas 5 2 3 hydrobasins and hydrolakes the hydrobasins lehner and grill 2013 and hydrolakes messager et al 2016 data is stored using postgresql with postgis extensions for spatial indexing and querying we have implemented rest apis for accessing these data that provide a range of functions spatial querying topological navigation using the pfafstetter coding system verdin and verdin 1999 encoding in json bray 2014 relating relevant features river networks water storages and manual reach creation these functions support the reach creation process described in section 4 1 1 5 2 4 timeseries processing the timeseries api calls support typical timeseries processing operations such as calculating statistics and temporal aggregation these are implemented using the python pandas package mckinney 2011 also as a wrapper over the senaps api this component also calculates basin indices such as agricultural productivity water scarcity and storage reliability some more complex data processing tasks are also provided by the server such as those required for specific visualisations for example sankey water balance diagrams schmidt 2008 and flow duration curves these provide processed and restructured data that are then rendered client side this reduces load on the browser and makes use of server scalability 5 2 5 worker subsystem the worker sub system uses the celery framework celery 2019 for job submission queuing and worker nodes the basin futures api provides endpoints for asynchronous tasks to be submitted namely aggregating reach climate data climate change scenario scaling calibration of rainfall runoff models and other more intensive calculation processes tasks are split into task typed queues that allow flexibility to assign and scale to specific job types this ensures that when a large number of calibration tasks are submitted other processing tasks are not held up for example the running of scenarios docker containers are defined for worker nodes allowing flexible scaling up of both the number of system processes and compute instances future work may link scaling to demand to allow a truly elastic computing setup where computation resources are dynamic based on user load the current setup allows separation of task types ensuring that many calibrations can run in parallel while still allowing model runs and other higher priority processing tasks to occur 5 3 cloud deployment docker compose docker inc 2020 is used to setup the multi container environments for deployment this provides environment flexibility where development staging and production environments can be deployed rapidly either locally or to new cloud providers with consistent setup achieved through automation there are two primary deployments for hosting basinfutures com and staging basinfutures com these are hosted on the nectar research cloud an amazon web services aws hosted instance was deployed specifically for training in india to reduce latency for users and provide an example of a regional based deployment with the environment available now in aws it is possible to deploy in any of the aws availability zones the production deployment typically scales the number of workers to match available cpu cores 10 currently this would allow 10 scenarios or calibrations to be run in parallel we have preconfigured snapshot images for all workers allowing new instances to be added to the compute pool with no configuration we also have configurations where worker nodes are deployed onto dedicated instances allowing auto scaling via tools like kubernetes burns et al 2016 6 global and regional data and services 6 1 climate data the two required climate data inputs for the rainfall runoff and river system model are rainfall and potential evapotranspiration global scale climate datasets are increasingly being developed due to the improvements of earth observations data van dijk and renzullo 2011 the current global climate data sets made available in basin futures are shown in supplementary material table 3 climate scenario data has been integrated from the inter sectoral impact model inter comparison project isimip rosenzweig et al 2017 this project provides a range of harmonised climate change scenario datasets that are derived from the cmip5 models taylor et al 2012 p 5 we use both the historical and projected climate scenario data to allow setup and running of basin models under historical and future climate scenarios 6 2 station data in the context of this paper we refer to station data as actual observations or data summarising observations from monitoring stations e g monthly mean discharge measured at a location there are a number of efforts that collate global or regional databases do et al 2018 fekete et al 2002 gudmundsson et al 2018 menne et al 2012 the global runoff data centre 2020 of station data of particular types e g hydrological climatological additionally there are an increasing number of national systems that report station data at a national level dixon et al 2013 the station data available in basin futures is detailed in the supplementary material table 4 these data are primarily used to support model validation 6 3 agriculture data global agriculture data see supplementary material table 5 for details are used to provide estimates of crop areas to users when parameterising crop areas and for estimations of land suitability to assist in developing scenarios for future agricultural development 7 case studies and test results 7 1 brahmani river basin case study we have compared basin futures to other water modelling tools to compare data inputs model outputs and time and resource efforts to generate a water balance model we present a sample case study here for the brahmani river basin in india this case study compared the outputs generated from basin futures to a published water resource assessment on the basin icid 2005 the two assessments cover the same overall area albeit with different structure of sub basins reaches fig 9 while these different structures make it difficult to compare fine granularity results it is adequate for comparing basin level outputs a baseline model was constructed in basin futures with the default parameters and precipitation a baseline model was constructed in basin futures with the default parameters and precipitation data using the indian meteorological department imd and princeton potential evapotranspiration key basin results are compared in table 3 the mean annual outflow shows two set of results that reflect the icid reporting one set show observed mean annual discharge for three years 1998 1999 and 2000 while the other shows mean annual outflow for the icid model running in past mode which is pre 2000 to test the performance of different rainfall runoff calibration targets we created a brahmani basin model with a reach structure that matched the locations of the gsim gauging stations this used the gauge reach creation method described in section 4 1 1 we then ran 3 scenarios using default gr4j parameters calibrated to mean annual runoff and calibrated to mean monthly runoff this provides testing of the calibration approaches available within the user interface and differs from the testing provided in section 7 3 which uses a timeseries target from the gsim database for evaluation of the model performance we use the r2 nse and percent bias as recommended by moriasi et al 2015 as well as the ratio of the root mean squared error rsr for a unitless error metric moriasi et al 2007 the results are shown in table 4 these results indicate that for this case study the calibration to the global mean monthly runoff is providing a better nse and error deviation for monthly flows when comparing to the gsim observed monthly river flows bias is similar for the two calibration targets the annual target runoff calibration does not appear to improve on the default parameterisation we also executed the model simulation for three different climate datasets the indian meteorological department imd rainfall mswep and aphrodite see section 6 1 for descriptions these were selected as they provide examples of different scale data sets imd covers india aphrodite covers monsoon asia and mswep is global basin futures generates comparison statistics for each reach when compared to the gsim monthly river data the full results for each reach are shown in table 6 in the supplementary material a summary of the results is provided in table 5 the summary table shows counts of rating categories for each metric r2 nse bias and rsr according to moriasi et al 2007 2015 for monthly mean monthly and annual values results show the model is correlating with the monthly and mean monthly flow patterns reasonably well with the main issue being bias in some of the reach climate combinations this could be due to a number of factors including influences of groundwater and other consumptive such as crop and domestic use additionally the calibration is targeting mean monthly discharge with a nse target another option we plan to investigate is setting a bias objective function as well as more granular target runoff series the results show the annual flows are not matching well this is likely due to the calibration targeting mean monthly flows a closer analysis of the calibration approaches is required this should cover varying hydroclimate regimes areas with varying data availability which effects the global runoff grid targets and improving consistency in temporal separation of calibration and validation periods as well as alignment with the time period of the global gridded data future work will also include streamflow timeseries targets for calibration discussed in section 8 4 this simple case study shows basin futures is able to capture some of the key basin attributes and components of the water balance more detailed case studies are planned that will provide further results on the system s performance 7 2 application within a training setting one of the aims of basin futures is to lower the amount of effort required to start a basin water assessment and conduct subsequent scenario analysis this effort involves data preparation software installation and configuration computing setup and maintenance and actual software operation to understand the user experience and ability of the system to achieve these goals we conducted training using basin futures with eight water professionals from six different organisations in the south asia region each of the participants was guided through theory coupled with practical exercises using the system to study a basin as part of this training we conducted a user survey to assess the ease of use and usefulness of the software while the group was small the results indicated that the tool was easy to learn and had potential to be used as part of basin planning and management discussions users provided the following observations they commented on the high speed of the system and how it could be used to quickly assess different scenarios they were able to develop basin case studies over a matter of days with no prior knowledge of the tool they commented that the tool provided a complementary practical view of the theoretical concepts covered in the training users commented that the rainfall selection tool section 5 7 1 was valuable in guiding users in their choice of climate data and added transparency on how well the input climate was performing in the region we also noted that users were able to quickly collate statistics on the performance of models using different climate inputs and then related this to performance of the model against gauging station data 7 3 bulk testing rainfall runoff data model and calibration we conducted an automated approach to bulk test components of the system workflow selecting basins creating manual reaches generating climate data calibration of rainfall runoff to target values timeseries and generation of performance statistics this workflow uses the basin futures apis via a python jupyter notebook this provides a scalable computational environment whereby requests can be directed to different servers where required while result analysis is contained customisable and reproducible using this workflow we tested combinations of climate data sets and rainfall runoff model parameters and calibration targets in different regions it is possible to run this workflow for every gsim gauging station in the database 30 000 sites though for this analysis we have focussed on testing a specific region only future work would include running for all gauging stations which would allow summarised results to assist in guiding user decisions and warning in areas of low performance fig 10 show results in india using three climate precipitation data sets these results demonstrate the system is able to calculate upstream catchment areas from gsim locations red dots generate climate data for each sub area and run calibrations against a range of target values timeseries the nse results fig 10 are for calibration of climate data to the gsim observed monthly streamflow data the nse is for the model s representation of mean monthly flows targeting of calibration to the gsim data is not available from the user interface as the implementation requires consideration for the user selected reach structure flow target outlets and the location of the streamflow gauge this is discussed further in section 8 in addition to testing system operation these results provide a flexible way to test different climate data sets and identify any patterns of performance in regions this paper does not explore any possible conclusions arising from these results e g the spatial pattern of nses displayed in the test catchments below these analyses will be conducted in future work the focus here is demonstration that the system components are functioning and the use of data and models of data are sound results from india show performance of the available climate and rainfall runoff model are reasonable for northern basins with lower performance in the south the southern basins generally show a model overestimation of flows which in part could be due to these tests only modelling runoff without the routing storage and demand components of the model future work will include these aspects of the model by linking the whole reach model engine with the default parameterisation setups as described in section 5 7 4 performance results one of the key requirements for basin futures was to allow users to run scenarios in a web browser section 1 consequently scenarios must be able to run and return results within a timeframe that provides a reasonable user experience typically measured in seconds for the longer running tasks namely generating climate data at basin scale and calibration we initiate these processes while allowing users to continue to edit models in order to provide a continuous workflow that does not block users we have collected performance metrics from the execution subsystem see section 5 5 through development and testing phases of the system these results are shown in table 6 our aim was to collect results from actual use of the system as a whole rather than running models externally from the system under artificial conditions subsequently these numbers provide a reasonable indication of the performance of the system the data were collected over a period of 12 months of running the main testing server note that this also includes some changes in software versions to provide further insights into performance of the model run time and results save times we also tested across two environments by executing bulk scenarios we ran five different models with varied combinations of reach structures 3 9 reaches climate storage and crop configurations scenarios were run 50 times for each environment for a total 250 runs per environment results are shown in table 7 these execution times include retrieving climate data running the rainfall runoff models and running the reach model engine environment 1 16 cores 2 6 ghz 31 gb memory virtualised infrastructure open stack environment 2 8 cores 2 3 ghz i9 64 gb memory model run times are similar across the two environments and thus provide a reasonable indication of the expected performance of model execution the db save time is more consistent in environment 2 likely due to its higher write speed drive these tests are running docker containers on the single machine instances however we have implemented horizontal scaling for task workers allowing new instances to be added to run models calibrate and generate climate a scaled environment should thus offer run times consistent with these numbers we have used this setup in workshops with multiple users and the results show reliable run times 8 discussion 8 1 novelty of the basin futures system basin future combines a number of approaches to data model and cloud integration to deliver a novel approach to web based water assessments this appears to be the first integrated globally applicable web based tool for building hydrological models and rapidly developing scenarios there are tools that have some similar features but none of these provide the complete workflow from basin exploration model creation parameterisation scenario definition and results analysis this workflow supports users to explore many basin development scenario options section 4 2 that represent significant and contemporary water challenges our approach is similar to a recent web implementation of the soil and water assessment tool swat online mcdonald et al 2019 however we key differentiators include scenario development result assessment integrated third party apis and a user focused web application to guide the user through model setup and execution our approach also presents similarities to swatshare rajib et al 2016 specifically because of the focus on the creation of reproducible online and sharable models however basin futures differs in that it provides the model and scenario development workflow within the tool and has pre integrated global data and connection to regional web services to allow parameter estimation and model comparison this forms the basis of reducing effort for users in model setup and configuration there are also other similar systems that focus in other specific water management areas examples include florean provides a web based platform for flood forecasting svatoň et al 2017 castrogiovanni et al 2005 describe a web gis system for flood design and risk analysis recently a web based application for investigating groundwater sustainability evans et al 2020 or the climb geoportal blaschek et al 2015 as a generalised approach for sharing hydrological modelling data via open web services among others increasingly cloud based systems are also used as a way of scaling calibration and or sensitivity analysis kc et al 2020 our worker subsystem uses the same concepts typically deployed in these environments through the integration and use of global and country level web services we have demonstrated the value of data holders providing apis web services for the publication of data these services allow tools such as basin futures to dynamically query and retrieve data from a well maintained point of truth this avoids the traditional approach of data integration via downloading one off files translating and integrating the benefits of using a service approach include data is curated and maintained by those who know the data best updates to data are reflected in the downstream tools automatically communities can benefit from shared implementations of retrieval and analysis code we are not aware of any globally applicable web based hydrological models that integrate across this range of data services the implementation of the web based model editor that provides recommended parameterisation of model components from data and services differs from these existing systems this is a concept that is applicable to a range of service based systems and gives a mechanism for data providers to integrated directly with modelling and analysis workflows an advantage of basin futures is its low barrier to entry and accessible interface through a web browser this helps to address the accessibility challenges of modelling systems identified by al sabhan al sdlubhan mulligan and blackburn 2003 interfacing is difficult knowledge of gis is required platform dependency customisation of models is difficult and limited accessibility of data our approach aligns with recommendations identified for data science of the natural environment specifically to offer levels of abstraction and associated services that are much better suited to the domain of science including high level support for running complex integrated modelling in the cloud blair et al 2019 by removing the requirement for users to work through software installation data gathering and transformation and model setup we are able to get users focussed on developing a preliminary understanding of water resources availability in a basin subsequently they are able to rapidly explore the impacts of different development scenarios and explore related consequences 8 2 considerations for integrated cloud based model data environments there are benefits and trade offs to having a fully integrated model data environment these include 8 users lose the flexibility of modular modelling environments where different models may be swapped in and out however these modular environments are often difficult to develop the use of service or api wrapped models is an increasingly used approach to handle these challenges gao et al 2019 gichamo et al 2020 granell et al 2010 mcdonald et al 2019 nelson et al 2019 roman et al 2009 9 there is more reliance on the availability of the models and data that have already been integrated into the platform however users are not required to invest time into any data integration tasks 10 transparency of the underlying data and models may be reduced if there is not adequate documentation references etc we attempt to alleviate this by providing contextual help that describes and references the relevant algorithms data and literature 8 2 1 data updates and access consideration needs to be given to handling data updates and integration of new data update processes can be automated for example when new versions of climate data are published if there is support at the point of data publishing however many traditional data publishing mechanisms involve publishing data on websites or on ftp servers in compressed archives with only text file descriptions of formats and access protocols this situation is improving with many data publishers moving to support web services and apis for data discovery description and access beran and piasecki 2009 taylor 2016 vitolo et al 2015 our work here shows examples of a spectrum of these approaches integration of one off published data from research through to integration with nationally harmonised and updated data sets through apis such as those from the usgs and the australian bureau of meteorology services as national and global systems mature it will allow a more decoupled composition of systems and services that can be updated at the point of truth and easily integrated to other applications and services changes to underlying data raises the issue of how to handle these changes in the models that use them when an update occurs to a data set there needs to be consideration for how this effects existing models the model needs to reference a stable data version to ensure that previous model runs can be reproduced with the same results for example there may be mechanisms put in place that would advise users when there are new versions of data available for existing models a benefit of the encapsulated model data environment is that data generated by the system can be re used and or contribute to new combined data sets for example the rainfall comparison tool will over time build up a dataset of statistics of performance of particular climate data in different regions this data could then be used in recommenders and or published as a new data set in its own right for example via a system such as suggested by essawy et al 2018 often intermediate datasets of comparison activities are lost an integrated platform allows the collection of this data over time 8 2 2 benefits of cloud based models cloud based modelling services offer users a range of benefits including integration of all the component parts hiding complexity services that may be integrated in to their own software workflows and product that has broad reach globally pushing down the requirements of a user to a web browser and an internet connection in effect it outsources the major challenges that a modeller may have including compute storage management of complex workflows and an improved user experience these benefits have been reflected in the feedback received from users section 7 2 users can focus on the process of constructing a model choosing model data scenarios combinations and analysing the results rather than complexity of building models from scratch the cloud based architecture described provides a flexible computational environment that can be scaled according to the number of users this removes the need for users to deploy infrastructure and handle resources directly the ongoing cost of operating a cloud hosted system needs to be considered and planned for most software as a service provides recover costs via a commercial model the water modelling community predominately uses desktop based software either from commercial providers or through open source software basin futures has a different delivery mechanism and is a vertically integrated package we are planning the most appropriate approach for ongoing hosting the system stores all model results and provides download options through the interface or apis to allow analysis or integration with other software in development of the system this was done within a python jupyter notebook environment models can be shared between users and are also versioned a new version is added for every change that is saved to the server this puts in place the functions required to revert to specific versions and reference specific versions of a model instance these features are important considerations within the broader reproducible science discussion gichamo et al 2020 munafò et al 2017 8 3 system performance the performance results in section 7 4 demonstrate the system is able to generate climate run scenarios and calibrate rainfall runoff in times that are acceptable for use in a web application of this nature closer inspection of the scenario run time shows the majority of time is spent post processing and writing results to the timeseries database a model of 9 reaches run over 40 years the average model run length will produce in the range of 2 3 million timeseries values at daily resolution most of these timeseries are summarised to monthly statistics for database storage reach level daily flows are used for comparison of environmental flow metrics resulting in more than 200 000 timeseries values including the required daily series generated per model run the majority of computation time for the output writing is in the temporal aggregation and conversions we expect to optimise this in a future release 8 4 model scope calibration and performance the basin future representation of the water balance and its inherent uncertainties requires further testing the model lumps and simplifies physical processes and thus contains many uncertainties the range of testing and results described demonstrates the system is able to capture some of the main hydrological relationships catchment structures climate data rainfall runoff relationships there are still aspects that require further testing comparisons of different aspects of the river system model including storage behaviour agriculture demands and indicators the testing to date indicates the system is able to adequately represent basin catchment areas and structure monthly flows identify storages and represent demands the rainfall runoff results demonstrate the system is able to calibrate to different targets and is showing some acceptable performance in comparison to gsim monthly observed streamflow however the bulk rainfall runoff results do not show performance of the different calibration targets or the areas that the data and models are not performing adequately the brahmani basin case study shows results using the different calibration targets and indicate the calibration to mean monthly values does improve the representation of monthly flows when compared to gsim the approach to rainfall runoff calibration was implemented to allow global application it is however a non standard approach to calibration most rainfall runoff models are calibrated to streamflow timeseries where gauging data is not available or is not within a reasonable proximity of a calibration point other approaches must be taken such as regionalisation techniques wagener et al 2004 the approach we have taken is to start with a coarse target that can be used anywhere then build in more sophisticated approaches such as calibrating to streamflow timeseries this is perhaps the most familiar approach for many modellers but has not been implemented in basin futures to date due to the need to conflate the gauging station location with the model structure recognising that the locations of streamflow measurement stations may not provide an appropriate scenario centric delineation of model reaches the option to define reaches by gauging station location section 4 1 1 provides a first step to alleviating this problem the mean runoff targets are a coarse calibration approach that were chosen as a starting point for global application but will suffer from high parameter uncertainty and the equifinality issue beven 2006 calibration is currently only performed on the rainfall runoff component of the model this leaves the crop model storage and demand components uncalibrated we do provide some assistance in the parameterisation of these components section 4 1 4 however it is up to the user to assess the model results for these components this has been done to date through comparison with numbers in the literature the basin future simplifications influence which basins it is capable of modelling see section 3 4 in order to assist users in assessing a models uncertainty we plan to provide warnings when either there is a high level of groundwater influence or a strong snow glacier runoff influence determining how this would be achieved is to be resolved 8 5 uncertainty in basin future model data and methods there is a high level of uncertainty inherent in the combination of global data and lumped models an overview of our preliminary assessment of sources of uncertainty are show in table 8 the potential level of uncertainty in results from basin futures is high as is the case with most models poor input and or parameterisation will result in poor outputs given this tool aims to be easy to use we aim to provide sufficient warnings to users so they are aware of the uncertainty when interpreting results designing these warnings is something we are working through we have initial heuristics that could be used to warn users that in specific areas the data and or representation of the system is not adequate these would consider different factors such as insufficient calibration data historical performance of chosen climate data in a region correlation with nearby streamflow observation stations or known gaps in the global data that has been used within the model in future work we would look to incorporate these into the user facing parts of the system 9 conclusions this paper presents a new product basin futures for entry level basin modelling initial assessments for water development projects and education the product aims to simplify the modelling and scenario process by standardising the user workflow pre integrating models and data providing on demand computer resources and delivering the capability through an easy to use web application experience with users indicates they are able to develop initial case studies after one to two days using the software user testing has shown it is easy to use and provides valuable information for basin scale water assessment and scenario investigation the integrated approach to basin scenario definition provides a rapid way for users to begin assessing changes arising from developments in agriculture water storages population growth and climate change all of which are significant challenges for water planners and educators declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the development of basin futures was funded through a strategic alliance between csiro and the international centre of excellence in water resources management ice warm the authors wish to acknowledge the early support of the international commission of irrigation and drainage icid especially harish varma and avinash b pande also to darryl day peter wallbrink joel stewart tony weber and neil byron for their constructive input through the development process we would like to thank the australian national university s water futures institute team for their ongoing support and feedback we would also like to thank the australian national eresearch collaboration tools and resources nectar project for their ongoing provision of cloud computing resources to support this work thanks to hongxing zheng and susan cuddy csiro for their constructive feedback on the paper many thanks to the four anonymous reviewers for their constructive feedback on the manuscript we also wish to acknowledge the many data producers and custodians who have made available the range of data used in this system appendix a supplementary data the following is the supplementary data related to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2021 105049 software and or data availability the initial version of basin futures is available at https basinpedia basinfutures com which contains basinpedia the full version will be released once testing has been completed 
25821,under the impacts of hydrologic extremes there is a growing need for integrated frameworks for flood inundation mapping in this study we introduce a framework the coupled routing and excess storage for inundation mapping and prediction crest imap it utilizes a highly parallelized and fully integrated hydrologic hydraulic model and aims to improve flood prediction to highlight the advantages a synthetic rainfall event and the 500 year hurricane harvey event were investigated using the crest imap compared with a hydrologic model a hydraulic model and a simplified hydrologic hydraulic model the results indicate the crest imap achieves good performances in both hydrologic simulation and floodplain inundation mapping moreover the antecedent soil moisture is the most sensitive parameter to model accuracy followed by the land surface characteristics the infiltration process to a flood forecasting model is significant overall the crest imap delivers accurate and timely flood information making it one of the latest developments of an integrated hydrologic hydraulic expert system keywords flood inundation mapping hydrologic hydraulic modeling framework hurricane harvey infiltration process 1 introduction flooding is one of the most devastating and deadliest natural hazards in the united states for instance there is a median value of 81 flood fatalities per year from 1959 to 2005 ashley and ashley 2008 and almost ten percent of the flash floods have resulted in agricultural and economic losses beyond 100 000 u s dollars per event gourley et al 2017 mitigating such damages in a proper manner mainly necessitates the use of hydrologic models to date numerous hydrologic models have been developed across multiple scales and different degrees of physical representations beven and kirkby 1979 savenije 2010 wang et al 2011 wu et al 2014 zhao 1995 more information about the modeling efforts are elaborated in singh 1995 and sood and smakhtin 2015 in a nutshell hydrologic models can be categorized across a spectrum from process based or fully physical models to conceptual or empirical models the process based model solves the mathematical governing equations in the hydrologic processes such as evaporation infiltration with continuous soil moisture accounting and river routing abbott et al 1986 arnold et al 1998 while the conceptual model does not but in lieu of parsimonious expressions or simplified degrees of representations nash and sutcliffe 1970 wang et al 2011 singh 1995 for instance a conceptual model like hymod approximates the evaporation rate by applying an efficiency factor to the potential evapotranspiration pet instead of solving the penman monteith equation from an energy conservation perspective a hydrologic model normally comprises a water balance module and a river routing module the water balance module transforms rainfall into surface runoff via the hydrologic processes in the vertical direction laterally these runoffs are routed to an outlet point by the routing module however the routing scheme e g unit hydrograph methods linear reservoir and 1d kinematic wave model is often oversimplified for most hydrologic models which is perceived as a weakness for flood forecasts felder et al 2017 kim et al 2012 nguyen et al 2016 pontes et al 2017 wood et al 2011 regarding the pure hydraulic model the ignored or crudely represented infiltration process likely leads to overestimations in flood simulation ni et al 2020 therefore several studies have hitherto attempted to couple a hydrologic model with a hydraulic hydrodynamic model herein denoted as the h h model felder et al 2017 montanari et al 2009 zhu et al 2016 pontes et al 2017 sampson et al 2015 wu et al 2014 zischg et al 2018 the coupled models enable streamflow generation flood extent delineation and peak flood depth estimation all at once and have been applied at local regional continental and global scales the real time global flood monitoring system gfms jointly developed by the national aeronautics and space administration nasa and the university of maryland sets an example that couples the variable infiltration capacity vic model and dominant river tracing based runoff routing drtr model at 12 km spatial resolution wu et al 2014 nguyen et al 2016 coupled the hydrology laboratory research distributed hydrologic model hl rdhm with the brezo model and showcased results in the baron fork oklahoma felder et al 2017 integrated a semi distributed hydrologic model prevah and a hydraulic model basement to examine the joint advantages in peak flow simulation specifically despite a compelling need for developing h h models a few challenges still remain for a coupled system first different means of integrating the two models are critical for operational flood monitoring a majority of the previous studies loosely couple the two i e offline couple in which hydrologic simulation in the upstream basin is a prerequisite to provide boundary conditions before the hydraulic model runs montanari et al 2009 nguyen et al 2016 felder et al 2017 in this regard the offline coupling compromises its timely data delivery for emergency responders additionally the offline coupling entails calibrating two models separately making it time consuming although the hydraulic model typically has fewer parameters to tune second the design of computational meshes that are scalable and suitable for all applications is challenging structural meshes quadrilateral cells at fixed resolution are so far a common approach in hydraulic models e g tuflow classic 2d flowroute i divast sobek suite cama flood and lisflood fp because they resemble the grids as the topographic data and thus exhibit less structural errors kim et al 2014 the structured mesh however could lead to numerous computational elements limiting the utility of the coupled modelling system for large scale implementation saksena et al 2020 teng et al 2017 the recent development of unstructured meshes triangular meshes or blended triangular and quadrilateral meshes such as anuga delft 3d and mike fm enhances the flexibility of the model to have fine resolution in complex watersheds to reflect subtle changes in topography or coarse resolution in areas of less interest or less heterogeneity to save computational time ivanov et al 2004 saksena et al 2020 the flexibility in this regard helps to make the model scalable and efficient while not sacrificing too much accuracy third there is a necessity for a fully integrated system that not only couples the h h model but also includes extended features such as uncertainty quantification mesh generation sensitivity analysis and calibration in the presence of these challenges and limitations we developed a new end to end h h modeling framework the coupled routing and excess storage inundation mapping and prediction crest imap such a framework contains a flexible mesh generator that efficiently reduces structural errors a h h model that stems from the widely used the crest model crest wang et al 2011 for the water balance part and the anuga hydro for the hydraulic part nielsen et al 2005 a suite of sensitivity and uncertainty analysis tools and global calibration schemes the physical representation of hydrologic processes and routing in conjunction with flexible and efficient mesh grids makes this framework one of the latest developments of an h h expert system in this paper the main purpose is to release and introduce the first version of crest imap that is suited for operational flood forecasts for the analysis we examine the similarity and difference of crest imap with a pure hydraulic model a hydrologic model and a hydraulic model combined with a simple infiltration scheme this article is structured as follows the second section details each component within this framework along with a methodology describing the designed experiment the third section presents the results from the synthetic experiment and showcases a real flood simulation against observations from in situ instruments and remote sensing products for the 500 year hurricane harvey event 2 methods 2 1 crest imap framework fig 1 shows an overview of the designed crest imap framework the model engine consists of two components the crest hydrologic model that vertically transforms rainfall into surface runoff and a 2d hydraulic model that routes surface runoff spatially driven by topographic inputs for the model setup it is required to first design the mesh and prepare a priori distributed parameters detailed information regarding mesh and parameter generation are provided in section 2 3 and 2 4 respectively for model calibrations we provided two approaches one conventional optimization approach that minimizes the desired objective function through a set of advanced algorithms and the other one termed surrogate modeling to mitigate extensive or infeasible calibration efforts by learning the response surface furthermore we also include a sensitivity analysis that can investigate how the parameters interact and influence the results 2 2 hydrologic processes the natural hydrologic process is depicted in fig 2 a in which both natural landscapes and urban areas are taken into account for flood monitoring it is often recognized that a hydrologic model has the advantage of mimicking natural hydrologic processes while being limited in representing water routing in urban regions due to complicated hydraulic structures and controls on the contrary a hydraulic model could be applied for urban flood simulation while ignoring the hydrologic processes of infiltration canopy interception etc by coupling these two models as in crest imap we preserve the advantage of modeling hydrologic process and extends its capacity for flood prediction and inundation in urban areas it is noteworthy that traditional hydrologic models often omit local ponds and only simulate the streamflow in the natural waterway in this coupled system it is possible to also account for ponding that could impact the timing and magnitude of localized flooding the detailed hydrologic processes represented in crest imap is shown in fig 2b which originates from crest v2 1 flamig et al 2020 xue et al 2013 the crest model is a distributed hydrologic model that is jointly developed by the university of oklahoma https hydro ou edu and the nasa servir project team wang et al 2011 it has been implemented as a flood detection toolkit across the globe wu et al 2012 and for operational flash flood forecasting in the united states and territories gourley et al 2017 in near real time the atmospheric forcing data acquired from the gridded products are firstly partitioned to surface runoff and subsurface flow according to the surface characteristics and prior model states the subsurface flow is further separated via a variable infiltration curve zhao 1995 thereafter multiple linear reservoirs are used to represent sub grid routing for overland flow and interflow the detailed relationships and expressions of theses interactions can are discussed in xue et al 2013 in flash flood forecasting model efficiency can be maintained by routing surface flow through a hydraulic model while ignoring the less impactful fluxes such as the interflow term as an intermediate product users can export the fluxes such as surface flow and subsurface flow and the soil moisture state as shown in fig 2c the proposed crest imap framework has seven distributed or lumped parameters as described in table 1 amongst them the saturated hydraulic conductivity ksat mean soil water capacity wm exponent of the variable infiltration curve b impervious area ratio im and the ratio of the pet to actual evapotranspiration ke can be estimated as a priori parameter set using the land cover types and soil texture data based on a look up table chow et al 1988 the initial soil moisture sm0 is an antecedent model state which can be approximated from an external data source such as soil moisture active passive smap or interpolated soil moisture values from ground observations or via a long warm up period it is the only lumped parameter that scales the wm from 0 to 1 2 3 hydraulic components the hydraulic model is derived from anuga hydro v2 1 nielsen et al 2005 which is an open source software that is suitable for predicting the consequences of hydrological disasters such as riverine flooding storm surges and tsunamis this model has been applied to a wide range of 2d flood simulations griffin et al 2015 guerra et al 2014 issermann and chang 2020 it solves the 2d shallow water equation depth averaged navier stokes equation that is derived from mass balance and momentum balance equations by ignoring the vertical acceleration term the 2d finite volume method fvm is used as the solver to the mathematical representations in the crest imap framework the surface runoff output from the hydrologic model is set as the input for this hydraulic model for the end results users can choose to export the flood extent gridded flood depth flow velocity and volumetric flow rate notably the gridded volumetric flow rate output requires a set of cross sections as input that can be derived from the system for automated geoscientific analyses saga package cross profiles conrad et al 2015 2 4 flexible mesh generator there is a tradeoff of structuring the mesh that could minimize the structural error from topographic inputs and also retaining the computational efficiency traditionally the unstructured meshes are designed according to the user defined maximum and minimum areas minimum angle of the triangular area as illustrated in fig 3 a some advanced generators can refine the areas of interest in the study domain with nested cells such as the one shown in fig 3b however the landscape heterogeneity is mostly ignored but could substantially increase the computational burden if the mesh is not optimized in conjunction with the mesh quality marsh et al 2018 experiments have demonstrated that the computational effort is significantly reduced by 90 by simulating complex watersheds using an adaptive mesh to represent terrain marsh et al 2018 ivanov et al 2004 therefore a quality guaranteed and flexible mesh design is essential to meet these challenges here we identify the flexible mesh by being able to satisfy specific user demands which can accomplish a dense meshes in the regions that have large heterogeneity of input features e g elevation soil property and flow accumulation b coarse meshes in the regions that are of less interest or homogeneous and c dividing the meshes based on user specified constraints e g river networks in this framework we adopted the novel mesh generator scheme proposed by marsh et al 2018 and integrated it into our modeling framework fig 3 displays the a traditional uniformly spaced meshes b refined meshes for the inner river network and c flexible meshes that are based on the variation of topographic inputs intuitively the traditional way cannot reveal the local abrupt changes of terrain e g concave and convex while the flexible design enables more meshes to reflect local variations and less so in homogeneous surfaces the root mean square error rmse quantitatively demonstrates that the flexible mesh could best reconstruct the structural input dem among the three with the lowest rmse 0 61 m the refined river network improves slightly compared to the uniform mesh in response to flow simulations it is widely reported in the literature that the adaptive meshes could significantly reduce the computational demand and preserve the localized flow characteristics ivanov et al 2004 marsh et al 2018 saksena et al 2020 teng et al 2017 2 5 sensitivity analysis and calibration parameters are inherent and uncertain in most environmental models beven and binley 1992 beven and freer 2001 duan et al 2006 gupta et al 1998 teng et al 2017 parameter sensitivity and uncertainty have profound implications for hydrologic models sensitivity analysis is advantageous in environmental models including uncertainty assessment model calibration and evaluation an exhaustive review on the sensitivity analysis that is specific to environmental modeling can be found in pianosi et al 2016 the intentions here of incorporating sensitivity analysis in our framework are two fold first the sensitivity result is a pre examination against our prior hypotheses of the basin characteristics for instance soil property related parameters are theoretically less sensitive than friction terms in a highly urbanized area second only the sensitive parameters will be calibrated in the automatic calibration scheme for the sake of efficiency gan et al 2018 we herein include two of the most widely applied algorithms one at a time oat and all at a time aat the oat simply measures the partial derivative of a parameter at the nominal value and it is referred to as the local sensitivity method while the aat measures global sensitivity by aggregating individual sensitivities the specific aat method used in this framework is the well established morris method morris 1991 to quantify the model parameters efficiently necessitates a global search calibration algorithm the well known shuffle complex evolution sce ua by duan et al 1992 is implemented in this framework additionally a set of evolutionary algorithms such as the genetic algorithm ga markov chain monte carlo mcmc and particle swarm are also included for different user demands the calibration is conducted by comparing simulated river stage and discharge with stream gauges but in the future we believe the calibration can be extended with promising remotely sensed data such as flood extent stage derived from synthetic aperture radar sar montanari et al 2009 and crowdsourcing data chen et al 2016 2 6 study region and data acquisition in the following experiment we apply our modeling framework to the greens bayou watershed in the houston metropolitan area illustrated in fig 4 this area endures frequent tropical cyclone and hurricane activity which was most evident with hurricane harvey in 2017 where 955 mm of rainfall impacted the region over five days heavy rainfall from tropical systems combined with expansive urban development results in numerous fatalities and vast economic losses the sub basin in fig 4c is upstream of buffalo bayou in houston the total drainage area is 457 9 km2 and the average elevation slope is 23 65 m 1 46 due to the flat slope the simplified 1d routing scheme i e kinematic wave in the hydrologic model is problematic which complicates streamflow generation getirana and paiva 2013 vergara et al 2016 fig 4d depicts the 15 different land surface types from the national land cover database of which the majority 89 7 is developed land especially in the southwest this areal impervious ratio is 33 8 on average forests are situated on the eastern part of this region creating a natural buffer to storm rainfall there are five united states geological survey usgs stream gauges located at three main tributaries garners bayou greens bayou and halls bayou from north to south because the upstream basin of the gauge 08075900 is a highly developed urban area the flow simulation is complicated by urban controls and stores on the hydraulic simulation therefore in the following flow analysis this gauge is excluded the digital elevation model dem was obtained from the usgs elevation products 3dep in the usgs at 1 3 arc second roughly 10 m resolution the original dem underwent a series of pre processing steps including noise removal with the speckle filter depression fill and burn in of river channels for the atmospheric forcing the multi radar multi sensor mrms data at 2 min and 1 km resolution are used for rainfall inputs zhang et al 2016 and the potential evapotranspiration rate is obtained from usgs fews data port https earlywarning usgs gov fews at daily and 1 spatial resolution allen et al 1998 these forcing data are specific for the hurricane harvey case study from 2017 08 25 to 2017 08 31 in addition the distributed model parameters are acquired from the crest model configured as part of the flooded locations and simulated hydrographs flash project where the existing parameters are provided and calibrated for delivering operational us wide discharge gourley et al 2017 fig 5 the surveyed soil type compositions are downloaded from united states department of agriculture ssurgo dataset at https websoilsurvey nrcs usda gov in order to validate the model simulated flood extent with observations two remote sensing products are correspondingly retrieved as follows the radar produced inundation diary rapid incorporates the sentinel 1 sar data to produce high resolution 10 m flood extent shen et al 2019 the dartmouth flood observatory flood extent herein denoted as dfo was produced by merging multiple data sources including the sentinel 1 moderate resolution imaging spectroradiometer modis radarsat 2 and the constellation of small satellites for mediterranean basin observation cosmo skymed these images are resampled to the same resolution as our simulation results in addition to inundated areas the usgs high water marks hwms collected during a post event ground survey of water marks are utilized in this study to comprehensively compare to the simulated peak flood depths it is noteworthy that these observations though used as reference are not error free 2 7 experiments and computational metrics to assess the uncertainty of the model engines i e crest imap non coupled hydraulic and non coupled hydrologic models and model parameters we implement a synthetic rainfall study as well as a real case study additionally in order to reflect the advances in infiltration process simulated by the hydrologic model the hydraulic component plus a simple infiltration model added to it are compared to one another the infiltration model for this study is adopted from an empirical method described by huggins and monke 1968 in eq 1 therefore for the model comparison crest imap pure hydraulic component herein referred to as hydraulic hydrologic component herein referred to as crest and a hydraulic plus simple infiltration denoted as hydraulic infiltration are taken into consideration 1 f k s a t 5 k s a t θ s a t θ i l f l θ s a t 0 65 where f represents the infiltration rate mm h 1 and f is the accumulated infiltration k s a t is the saturated hydraulic conductivity mm h 1 approximated from the look up table θ i θ s a t are the initial and saturated moisture content the parameter sensitivity is assessed using the morris method morris 1991 which evaluates the global sensitivity aat the corresponding computational metrics are summarized in table 2 the nash sutcliff efficiency nse is a standardized indicator to evaluate the correspondence and magnitude of the simulated and observed streamflow relative bias rb indicates the difference of the flow volume in a systematic manner time to peak error in hours h and peak flow error in cubic meter per second cms indicate the timing and magnitude difference of the peak flow when comparing flood extent in a binary form a contingency table is constructed to compute the percentage of true positives tp false negatives fn false positives fp and true negatives tn in terms of the real case we simulated the hurricane harvey event from 2017 08 25 to 2017 09 01 since model parameters have been well calibrated previously we simply split this simulation period to a fine tuning period 2017 08 25 to 2017 08 26 and a verification period 2017 08 27 to 2017 09 01 the purpose of model fine tuning is to refine the soil moisture states and water levels in the streams some sensitive parameters discovered in the sensitivity analysis are tuned to better represent the basin attributes we applied a scaling factor in the calibration stage to perturb the distributed parameters similar to the approach used in the crest model flamig et al 2020 xue et al 2013 the objective function for the fine tuning period is based on the nse 3 results 3 1 synthetic experiment in this section we examine the performance of the four model engines for a synthetic rainfall event according to the following three aspects first the sensitivity of the model parameters of crest imap is investigated which is primarily linked to basin characteristics second the hydrologic comparison provides insights on the difference of the hydrologic infiltration process and soil moisture dynamics lastly the flood simulation cross compares the flood extent and flood depth generated by different model engines in this experiment the synthetic rainfall is uniformly distributed in this study area at a rate of 100 mm h 1 for a 2 h duration twenty four hour simulations from the four model configurations are thereafter generated the sensitivity is conducted via the morris method and statistical metrics are computed at the basin outlet by perturbing seven model parameters for crest imap the standard deviation and means of the gradient are calculated to reflect the change of parameter value per perturbation the simulation time of each model engine is as follows crest imap costs 1 42 h in total using 36 cpu cores implemented on intel xeon 3 00 ghz similarly hydraulic and hydraulic infiltration require 1 58 h and 1 42 h respectively notably this total simulation time is an accumulation of time run per step which is explicitly derived to satisfy the known courant fredrichs levy cfl condition in eq 2 2 δ t u c δ x where u is the magnitude of flow velocity m s 1 and δ x is the radius of the inscribed circle of a cell m c is the courant number that is typically fixed to 1 therefore the time per step is determined by the flow velocity and the shape of the unstructured grid the pure hydraulic model which solely transforms all rainfall to overland flow is anticipated to have a higher flow rate and thus more time spent per step compared to crest imap and the scenario of hydraulic infiltration configuration in contrast the crest costs 1 72 h on a single cpu core since the routing scheme is not fully parallelized 3 1 1 model parameter sensitivity the sensitivity of model parameters in this study is investigated to not only examine the basin characteristics but to identify a set of parameters to calibrate the model fig 6 depicts the global sensitivity of each parameter from the means and standard deviations of the gradient benchmarked using the a priori parameter set by default the initial soil moisture sm 0 is set to 0 across all the metrics sm 0 stands out to be the foremost sensitive parameter to the model results it is anticipated that antecedent soil moisture is a determining factor to flooding and previous studies also exemplified this point using a range of urbanized basins smith et al 2002 yang et al 2011 in addition the manning s coefficient n is the second most sensitive parameter that governs overland flow for the hydraulic model it is the only parameter to tune the parameter im as the third most sensitive parameter has important implications for timing of the peak flows broadly speaking a higher fraction of impervious ratio urbanization leads to flashier hydrographs other parameters related to soil properties and evaporation are less significant in this study as the majority of the land cover is well developed therefore out of the seven parameters in crest imap only the most sensitive ones i e sm 0 im n are selected to fine tune the model for the real case using the sce ua algorithm meantime all model configurations are optimized with the same technique in the fine tuning period 3 1 2 infiltration and soil moisture the distributed intermediate variables have expanded the data sources for model evaluation especially when considering the availability of remotely sensed data in addition to more conventional use of basin integrated streamflow furthermore these intermediate variables can be used in the process of data assimilation to improve the model prediction skill in this section the intermediate soil moisture infiltration rate and overland flow rate at a specific timeframe are compared to one another the overland flow rate and soil moisture at 1 h after the synthetic rainfall has been introduced are shown in fig 7 it is visually obvious that crest imap shares a spatial similarity with crest in contrast to the other two configurations in terms of the overland flow rate and the soil moisture content moreover the basin averaged time series of infiltration rate of the two configurations exponentially decay with time the soil moisture change in time is also comparable peaking at the same time 2 h however the difference of percent of saturated soil cells with time is discernible in fig 7h the crest model contains a higher fraction of saturated grid cells than crest imap after 12 h this difference can be attributed to the structural difference caused by different representation of mesh grids as crest imap uses the triangular meshes that is at a pseudo 10 m resolution while crest uses regular 10 m grid cells in addition due to different settings of interflow the soil water depletion could essentially differ under the scenario of hydraulic only fig 7a the model treats every drop of rainfall as overland flow to route but omits the soil infiltration capacity and therefore the overflow rate saturates at 100 mm h 1 homogeneously across the region under the scenario of hydraulic with simple infiltration fig 7b the soil saturates across the majority of the land surface because water soil interaction is not properly represented due to the simplification i e infiltration rate is not a function of soil moisture state but at least this simple infiltration captures saturation in the developed land surfaces leaving the areas with high soil water capacity as unsaturated from the basin average infiltration rate shown in fig 7g the simple infiltration performs similarly with crest imap and crest except for a higher infiltration rate at the beginning and earlier saturation in summary both crest imap and crest exhibit more hydrologically reasonable spatial variation of the soil moisture and infiltration process as opposed to the simulation results under the hydraulic only and hydraulic with infiltration scenarios 3 1 3 flood simulation the end products including river stage discharge flood extent and flood depth are inter compared crest uses a 1d channel routing scheme and does not produce flood inundation maps so it is excluded in this analysis fig 8 a and b depict the basin integrated river stage and discharge at the outlet point respectively crest imap with advanced infiltration process shares similar performance with the hydraulic infiltration however the hydraulic infiltration configuration generates slightly greater flow volume in the rising limb and earlier peak time because its soil state reaches saturation earlier than crest imap the hydraulic simulation due to zero infiltration generates a higher river stage and volumetric flow rate compared to the other two regarding the flood extent comparisons crest imap is considered the benchmark or observation despite the hydraulic only model capturing higher percent of tp 21 7 than the hydraulic infiltration 19 9 it raises markedly more fp 13 4 versus 1 0 because of the systematically higher overland flow the same reason leads to the regionally positive difference of the maximum water depth between the hydraulic and crest imap in fig 8e however most of the grid cells in fig 8f show negative differences between the hydraulic infiltration and crest imap 3 2 case study hurricane harvey the above study based on a synthetic rainfall event revealed the inter comparison of different model engines and the sign of the results were expected there is a need to verify the models with respect to observations in a real world case study to this end we simulate an extreme event the 500 year hurricane harvey that has been a well studied event for a modeling purposes chen et al 2020 noh et al 2019 saksena et al 2019 wing et al 2019 hurricane harvey starting as a tropical storm became a category four hurricane while making landfall in texas causing devastating urban flooding in august 2017 the regional accumulative rainfall set a record 1625 mm since the 1880s for its seven day lifespan li et al 2020 the torrential rainfall has resulted in unprecedented pluvial and fluvial combined flooding thereby leading to at least 70 fatalities and economic damages beyond 125 billion us dollars the basin average rainfall rate time series is illustrated in fig 9 with markedly intense rates beyond 60 mm h 1 occurring during 08 27 2017 to 08 28 2017 four individual model engines at their optimal performance fine tuned are intercompared and also verified against the observations for this event 3 2 1 integrated streamflow the streamflow at collocated usgs sites are retrieved for four model engines the crest imap crest hydraulic and hydraulic infiltration as shown in fig 9 table 3 correspondingly summarizes the validation metrics described in table 2 notably the outlet gauge usgs 08076700 only records reliable streamflow data until 08 28 2017 probably due to damage of the in situ instrument compared to the hydrologic models i e crest the coupled hydraulic models i e crest imap hydraulic and hydraulic infiltration overall better capture the streamflow as indicated visually and with higher nse values this observation relates to two limitations of the crest model first the routing scheme i e kinematic wave encounters issues in flat terrain as previous studies stated getirana and paiva 2013 vergara et al 2016 second the hydrologic model mandates sufficient calibration data to match the observation while the tuning period is not adequate conversely it points to the main advantage of this coupled model which requires less calibration efforts to produce reasonable results amongst all hydraulic involved models crest imap outperforms the other two for all the gauge stations with the highest nse values the lowest rmse and peak flow errors on the other hand the hydraulic and hydraulic infiltration reach comparable results the hydraulic only configuration unsurprisingly overpredicts the streamflow as indicated by the rb due to ignored infiltration process at five gauges however the hydraulic infiltration due to crudely represented infiltration process exhibits less flow volume than crest imap in summary the infiltration process is essential and sensitive for the generation of basin integrated streamflow and the hydrologically sound infiltration process improves the streamflow prediction significantly 3 2 2 flood extent the flood extent from two remotely sensed products i e rapid and dfo and simulated by crest imap are overlaid at the same time as shown in fig 10 a and b the percentages of binary counts with respect to tp fp fn and tn are shown in fig 10c and d referenced by the rapid and dfo flood extent products first there is certainly a visual agreement between the remote sensing product and crest imap simulated results especially near the confluence of the greens bayou and garners bayou in contrast the dfo and model results are overlaid with higher percentages of tp 4 60 on average as opposed to rapid 2 00 in this case the merged product dfo may better measure the inundation area rather than the single sourced product rapid however the higher fraction of fn 2 07 vs 0 83 in dfo might be subject to the non distinguishable backscattering signals from water surfaces and urban structures instead rapid undergoes rigorous preprocessing steps such as morphologic removal water classification and machine learning corrections to eliminate noise second our simulations tend to predict more inundated areas than the remote sensing observations in the floodplain especially downstream such as the deep forested area near the basin outlet the remote sensing products did not capture the flooded areas this could be explained by the inherent issues for the remote sensing measurements i e sar and passive microwave as the vegetated areas and submerged wetlands enhance the dihedral scattering martinis and rieke 2015 in that regard it is likely that they miss flood events in the deep forested area some related studies such as saksena et al 2020 also generate similar flood extent as crest imap ensuring the rationality of the result for the model engines crest imap achieves a comparable percentage of tp with the hydraulic referenced by rapid and dfo however the fp are adequately reduced 19 6 and 24 2 for the hydraulic vs 17 9 and 22 5 for crest imap compared to hydraulic infiltration crest imap shows more than 0 1 higher percentage of tp and similar fp because the hydraulic only configuration obviously generates more inundated grid cells than models including infiltration processes it is challenging to justify the performance solely based on tp meanwhile remote sensing products suffer inherent errors which may bias our judgement therefore it is only reliable to conclude the flood extent by crest imap is comparable with the hydraulic model which proves its applicability in flood prediction 3 2 3 flood depth the simulated peak flood depth is compared with hwms collected from 23 sites shown in fig 11 a first all the hwms are located within the simulated flood extent second for the greens bayou the crest imap exhibits higher depths than the hwms while lower depths for the halls bayou in the south nevertheless according to the harris county local flood report https www hcfcd org portals 62 harvey immediate flood report final hurricane harvey 2017 pdf during hurricane harvey the greens bayou gauge broke the flood record 500 year return but the halls bayou only experienced a 10 50 year return flood our simulations align well with this frequency analysis it is worth mentioning the uncertainties when comparing hwms to model simulations first there is a large deviation between surveyed elevation and dem used for modeling generally ranging from 1 to 2 m depending on the location second the qualities of hmws vary resulting in differences of 0 5 m third uncertainties between point values i e hwms and area values i e simulations are apparent the locations of hwms could be off tens of meters because of truncation errors despite of this fact the maximum difference of 2 6 m is reasonable and acceptable with respect to the model engines fig 11b reveals the peak depth difference of all 23 hwms 9 8 sites show that the crest imap hydraulic outperforms with the lowest absolute difference the remaining 6 sites have better relative simulations from the hydraulic infiltration model also the distributions of peak flow differences in fig 11c indicate the performance in a broad view for crest imap the errors between estimates and observations vary from 2 4 to 2 1 m with 74 of them situated within 1 5 1 5 meters which is comparable with the results of 79 from saksena et al 2020 however their results experience overestimations of 3 m for the hydraulic the errors vary from 2 3 to 2 8 m with 69 of them situated within 1 5 1 5 meters lastly for the hydraulic infiltration the errors vary from 2 9 to 2 3 m with 57 of them located within 1 5 1 5 meters it is obvious that crest imap has the narrowest range of the differences between simulations and observations and the highest percentage of differences within an acceptable error range among all model configurations the crest imap exhibits the best performance due to the joint advantages of hydrologic and hydraulic simulations 4 conclusions and future work this study introduces a new flood forecasting framework which is comprised of a mesh generator an h h model and a set of uncertainty sensitivity analysis tools and calibration schemes to explore the advances and sensitivities a synthetic rainfall study and the 500 year hurricane harvey event are simulated to systematically evaluate the different model configurations crest hydraulic only hydraulic infiltration and crest imap here are the main findings for crest imap 1 for the model efficiency it is highly parallelized and fully integrated promoting its applicability for operational flood prediction and inundation mapping 2 the flexible mesh generator minimizes structural errors compared to traditional mesh designs 3 for the parameter sensitivity antecedent soil moisture is the foremost sensitive parameter for these case studies followed by land surface characteristics manning s n and impervious area ratio the other parameters related to soil moisture are less sensitive which is attributed to the characteristics of study basin 89 7 developed land 4 for the hydrologic physical process representation the crest imap and crest reasonably capture the spatial and temporal dynamics of the soil moisture and infiltration rates while the hydraulic and hydraulic infiltration misrepresent them which leads to the different performance in the end products 5 the infiltration process is central to a flood mapping model as it greatly influences the basin integrated discharge flood extent and peak flood depth a real case study of hurricane harvey also indicates that crest imap systematically outperforms the hydraulic simulation without infiltration and the hydraulic infiltration with crudely represented infiltration process further assessment of crest imap is necessary to improve this framework first current work does not include surveyed channel geometries which is acceptable with respect to model performance in hydraulic simulations we expect to see the added values by incorporating refined channel cross sections and terrains second the mesh generator needs to be systematically evaluated with respect to different basin attributes and the strategies of designing an optimized mesh should be explored lastly an impact based forecasting module could complete this modeling chain to specifically focus on the potential damages for public awareness instead of the natural hazard characteristics alone e g intensity extent discharge and frequency software availability the main package is developed using the python language version 2 7 some bottlenecks that are computationally expensive e g hydrologic component and mesh generator are written and compiled in c language for efficiency some revisions for the hydraulic model anuga are based upon version 2 1 it has been tested on linux operating systems this framework is openly available at https www hydroshare org resource 50ce0d7d80b642898f74d8bf56798565 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the first author is partially sponsored by the university of oklahoma hydrology and water security program national science foundation pire project and graduate college hoving fellowship the authors would like to thank the efforts by the national oceanic and atmospheric administration national severe storms laboratory team for making the mrms data accessible the flood extent simulated by rapid system is obtained at https xinyi shen uconn edu inundation maps of recent flood events from rapid sentinel 1 and the dartmouth flood observatory simulated flood extent during hurricane harvey is obtained at https floodobservatory colorado edu events 2017usa4510 2017usa4510 html the material is based upon work supported by the national science foundation under grant no oia 1946093 and its subaward no epscor 2020 3 
25821,under the impacts of hydrologic extremes there is a growing need for integrated frameworks for flood inundation mapping in this study we introduce a framework the coupled routing and excess storage for inundation mapping and prediction crest imap it utilizes a highly parallelized and fully integrated hydrologic hydraulic model and aims to improve flood prediction to highlight the advantages a synthetic rainfall event and the 500 year hurricane harvey event were investigated using the crest imap compared with a hydrologic model a hydraulic model and a simplified hydrologic hydraulic model the results indicate the crest imap achieves good performances in both hydrologic simulation and floodplain inundation mapping moreover the antecedent soil moisture is the most sensitive parameter to model accuracy followed by the land surface characteristics the infiltration process to a flood forecasting model is significant overall the crest imap delivers accurate and timely flood information making it one of the latest developments of an integrated hydrologic hydraulic expert system keywords flood inundation mapping hydrologic hydraulic modeling framework hurricane harvey infiltration process 1 introduction flooding is one of the most devastating and deadliest natural hazards in the united states for instance there is a median value of 81 flood fatalities per year from 1959 to 2005 ashley and ashley 2008 and almost ten percent of the flash floods have resulted in agricultural and economic losses beyond 100 000 u s dollars per event gourley et al 2017 mitigating such damages in a proper manner mainly necessitates the use of hydrologic models to date numerous hydrologic models have been developed across multiple scales and different degrees of physical representations beven and kirkby 1979 savenije 2010 wang et al 2011 wu et al 2014 zhao 1995 more information about the modeling efforts are elaborated in singh 1995 and sood and smakhtin 2015 in a nutshell hydrologic models can be categorized across a spectrum from process based or fully physical models to conceptual or empirical models the process based model solves the mathematical governing equations in the hydrologic processes such as evaporation infiltration with continuous soil moisture accounting and river routing abbott et al 1986 arnold et al 1998 while the conceptual model does not but in lieu of parsimonious expressions or simplified degrees of representations nash and sutcliffe 1970 wang et al 2011 singh 1995 for instance a conceptual model like hymod approximates the evaporation rate by applying an efficiency factor to the potential evapotranspiration pet instead of solving the penman monteith equation from an energy conservation perspective a hydrologic model normally comprises a water balance module and a river routing module the water balance module transforms rainfall into surface runoff via the hydrologic processes in the vertical direction laterally these runoffs are routed to an outlet point by the routing module however the routing scheme e g unit hydrograph methods linear reservoir and 1d kinematic wave model is often oversimplified for most hydrologic models which is perceived as a weakness for flood forecasts felder et al 2017 kim et al 2012 nguyen et al 2016 pontes et al 2017 wood et al 2011 regarding the pure hydraulic model the ignored or crudely represented infiltration process likely leads to overestimations in flood simulation ni et al 2020 therefore several studies have hitherto attempted to couple a hydrologic model with a hydraulic hydrodynamic model herein denoted as the h h model felder et al 2017 montanari et al 2009 zhu et al 2016 pontes et al 2017 sampson et al 2015 wu et al 2014 zischg et al 2018 the coupled models enable streamflow generation flood extent delineation and peak flood depth estimation all at once and have been applied at local regional continental and global scales the real time global flood monitoring system gfms jointly developed by the national aeronautics and space administration nasa and the university of maryland sets an example that couples the variable infiltration capacity vic model and dominant river tracing based runoff routing drtr model at 12 km spatial resolution wu et al 2014 nguyen et al 2016 coupled the hydrology laboratory research distributed hydrologic model hl rdhm with the brezo model and showcased results in the baron fork oklahoma felder et al 2017 integrated a semi distributed hydrologic model prevah and a hydraulic model basement to examine the joint advantages in peak flow simulation specifically despite a compelling need for developing h h models a few challenges still remain for a coupled system first different means of integrating the two models are critical for operational flood monitoring a majority of the previous studies loosely couple the two i e offline couple in which hydrologic simulation in the upstream basin is a prerequisite to provide boundary conditions before the hydraulic model runs montanari et al 2009 nguyen et al 2016 felder et al 2017 in this regard the offline coupling compromises its timely data delivery for emergency responders additionally the offline coupling entails calibrating two models separately making it time consuming although the hydraulic model typically has fewer parameters to tune second the design of computational meshes that are scalable and suitable for all applications is challenging structural meshes quadrilateral cells at fixed resolution are so far a common approach in hydraulic models e g tuflow classic 2d flowroute i divast sobek suite cama flood and lisflood fp because they resemble the grids as the topographic data and thus exhibit less structural errors kim et al 2014 the structured mesh however could lead to numerous computational elements limiting the utility of the coupled modelling system for large scale implementation saksena et al 2020 teng et al 2017 the recent development of unstructured meshes triangular meshes or blended triangular and quadrilateral meshes such as anuga delft 3d and mike fm enhances the flexibility of the model to have fine resolution in complex watersheds to reflect subtle changes in topography or coarse resolution in areas of less interest or less heterogeneity to save computational time ivanov et al 2004 saksena et al 2020 the flexibility in this regard helps to make the model scalable and efficient while not sacrificing too much accuracy third there is a necessity for a fully integrated system that not only couples the h h model but also includes extended features such as uncertainty quantification mesh generation sensitivity analysis and calibration in the presence of these challenges and limitations we developed a new end to end h h modeling framework the coupled routing and excess storage inundation mapping and prediction crest imap such a framework contains a flexible mesh generator that efficiently reduces structural errors a h h model that stems from the widely used the crest model crest wang et al 2011 for the water balance part and the anuga hydro for the hydraulic part nielsen et al 2005 a suite of sensitivity and uncertainty analysis tools and global calibration schemes the physical representation of hydrologic processes and routing in conjunction with flexible and efficient mesh grids makes this framework one of the latest developments of an h h expert system in this paper the main purpose is to release and introduce the first version of crest imap that is suited for operational flood forecasts for the analysis we examine the similarity and difference of crest imap with a pure hydraulic model a hydrologic model and a hydraulic model combined with a simple infiltration scheme this article is structured as follows the second section details each component within this framework along with a methodology describing the designed experiment the third section presents the results from the synthetic experiment and showcases a real flood simulation against observations from in situ instruments and remote sensing products for the 500 year hurricane harvey event 2 methods 2 1 crest imap framework fig 1 shows an overview of the designed crest imap framework the model engine consists of two components the crest hydrologic model that vertically transforms rainfall into surface runoff and a 2d hydraulic model that routes surface runoff spatially driven by topographic inputs for the model setup it is required to first design the mesh and prepare a priori distributed parameters detailed information regarding mesh and parameter generation are provided in section 2 3 and 2 4 respectively for model calibrations we provided two approaches one conventional optimization approach that minimizes the desired objective function through a set of advanced algorithms and the other one termed surrogate modeling to mitigate extensive or infeasible calibration efforts by learning the response surface furthermore we also include a sensitivity analysis that can investigate how the parameters interact and influence the results 2 2 hydrologic processes the natural hydrologic process is depicted in fig 2 a in which both natural landscapes and urban areas are taken into account for flood monitoring it is often recognized that a hydrologic model has the advantage of mimicking natural hydrologic processes while being limited in representing water routing in urban regions due to complicated hydraulic structures and controls on the contrary a hydraulic model could be applied for urban flood simulation while ignoring the hydrologic processes of infiltration canopy interception etc by coupling these two models as in crest imap we preserve the advantage of modeling hydrologic process and extends its capacity for flood prediction and inundation in urban areas it is noteworthy that traditional hydrologic models often omit local ponds and only simulate the streamflow in the natural waterway in this coupled system it is possible to also account for ponding that could impact the timing and magnitude of localized flooding the detailed hydrologic processes represented in crest imap is shown in fig 2b which originates from crest v2 1 flamig et al 2020 xue et al 2013 the crest model is a distributed hydrologic model that is jointly developed by the university of oklahoma https hydro ou edu and the nasa servir project team wang et al 2011 it has been implemented as a flood detection toolkit across the globe wu et al 2012 and for operational flash flood forecasting in the united states and territories gourley et al 2017 in near real time the atmospheric forcing data acquired from the gridded products are firstly partitioned to surface runoff and subsurface flow according to the surface characteristics and prior model states the subsurface flow is further separated via a variable infiltration curve zhao 1995 thereafter multiple linear reservoirs are used to represent sub grid routing for overland flow and interflow the detailed relationships and expressions of theses interactions can are discussed in xue et al 2013 in flash flood forecasting model efficiency can be maintained by routing surface flow through a hydraulic model while ignoring the less impactful fluxes such as the interflow term as an intermediate product users can export the fluxes such as surface flow and subsurface flow and the soil moisture state as shown in fig 2c the proposed crest imap framework has seven distributed or lumped parameters as described in table 1 amongst them the saturated hydraulic conductivity ksat mean soil water capacity wm exponent of the variable infiltration curve b impervious area ratio im and the ratio of the pet to actual evapotranspiration ke can be estimated as a priori parameter set using the land cover types and soil texture data based on a look up table chow et al 1988 the initial soil moisture sm0 is an antecedent model state which can be approximated from an external data source such as soil moisture active passive smap or interpolated soil moisture values from ground observations or via a long warm up period it is the only lumped parameter that scales the wm from 0 to 1 2 3 hydraulic components the hydraulic model is derived from anuga hydro v2 1 nielsen et al 2005 which is an open source software that is suitable for predicting the consequences of hydrological disasters such as riverine flooding storm surges and tsunamis this model has been applied to a wide range of 2d flood simulations griffin et al 2015 guerra et al 2014 issermann and chang 2020 it solves the 2d shallow water equation depth averaged navier stokes equation that is derived from mass balance and momentum balance equations by ignoring the vertical acceleration term the 2d finite volume method fvm is used as the solver to the mathematical representations in the crest imap framework the surface runoff output from the hydrologic model is set as the input for this hydraulic model for the end results users can choose to export the flood extent gridded flood depth flow velocity and volumetric flow rate notably the gridded volumetric flow rate output requires a set of cross sections as input that can be derived from the system for automated geoscientific analyses saga package cross profiles conrad et al 2015 2 4 flexible mesh generator there is a tradeoff of structuring the mesh that could minimize the structural error from topographic inputs and also retaining the computational efficiency traditionally the unstructured meshes are designed according to the user defined maximum and minimum areas minimum angle of the triangular area as illustrated in fig 3 a some advanced generators can refine the areas of interest in the study domain with nested cells such as the one shown in fig 3b however the landscape heterogeneity is mostly ignored but could substantially increase the computational burden if the mesh is not optimized in conjunction with the mesh quality marsh et al 2018 experiments have demonstrated that the computational effort is significantly reduced by 90 by simulating complex watersheds using an adaptive mesh to represent terrain marsh et al 2018 ivanov et al 2004 therefore a quality guaranteed and flexible mesh design is essential to meet these challenges here we identify the flexible mesh by being able to satisfy specific user demands which can accomplish a dense meshes in the regions that have large heterogeneity of input features e g elevation soil property and flow accumulation b coarse meshes in the regions that are of less interest or homogeneous and c dividing the meshes based on user specified constraints e g river networks in this framework we adopted the novel mesh generator scheme proposed by marsh et al 2018 and integrated it into our modeling framework fig 3 displays the a traditional uniformly spaced meshes b refined meshes for the inner river network and c flexible meshes that are based on the variation of topographic inputs intuitively the traditional way cannot reveal the local abrupt changes of terrain e g concave and convex while the flexible design enables more meshes to reflect local variations and less so in homogeneous surfaces the root mean square error rmse quantitatively demonstrates that the flexible mesh could best reconstruct the structural input dem among the three with the lowest rmse 0 61 m the refined river network improves slightly compared to the uniform mesh in response to flow simulations it is widely reported in the literature that the adaptive meshes could significantly reduce the computational demand and preserve the localized flow characteristics ivanov et al 2004 marsh et al 2018 saksena et al 2020 teng et al 2017 2 5 sensitivity analysis and calibration parameters are inherent and uncertain in most environmental models beven and binley 1992 beven and freer 2001 duan et al 2006 gupta et al 1998 teng et al 2017 parameter sensitivity and uncertainty have profound implications for hydrologic models sensitivity analysis is advantageous in environmental models including uncertainty assessment model calibration and evaluation an exhaustive review on the sensitivity analysis that is specific to environmental modeling can be found in pianosi et al 2016 the intentions here of incorporating sensitivity analysis in our framework are two fold first the sensitivity result is a pre examination against our prior hypotheses of the basin characteristics for instance soil property related parameters are theoretically less sensitive than friction terms in a highly urbanized area second only the sensitive parameters will be calibrated in the automatic calibration scheme for the sake of efficiency gan et al 2018 we herein include two of the most widely applied algorithms one at a time oat and all at a time aat the oat simply measures the partial derivative of a parameter at the nominal value and it is referred to as the local sensitivity method while the aat measures global sensitivity by aggregating individual sensitivities the specific aat method used in this framework is the well established morris method morris 1991 to quantify the model parameters efficiently necessitates a global search calibration algorithm the well known shuffle complex evolution sce ua by duan et al 1992 is implemented in this framework additionally a set of evolutionary algorithms such as the genetic algorithm ga markov chain monte carlo mcmc and particle swarm are also included for different user demands the calibration is conducted by comparing simulated river stage and discharge with stream gauges but in the future we believe the calibration can be extended with promising remotely sensed data such as flood extent stage derived from synthetic aperture radar sar montanari et al 2009 and crowdsourcing data chen et al 2016 2 6 study region and data acquisition in the following experiment we apply our modeling framework to the greens bayou watershed in the houston metropolitan area illustrated in fig 4 this area endures frequent tropical cyclone and hurricane activity which was most evident with hurricane harvey in 2017 where 955 mm of rainfall impacted the region over five days heavy rainfall from tropical systems combined with expansive urban development results in numerous fatalities and vast economic losses the sub basin in fig 4c is upstream of buffalo bayou in houston the total drainage area is 457 9 km2 and the average elevation slope is 23 65 m 1 46 due to the flat slope the simplified 1d routing scheme i e kinematic wave in the hydrologic model is problematic which complicates streamflow generation getirana and paiva 2013 vergara et al 2016 fig 4d depicts the 15 different land surface types from the national land cover database of which the majority 89 7 is developed land especially in the southwest this areal impervious ratio is 33 8 on average forests are situated on the eastern part of this region creating a natural buffer to storm rainfall there are five united states geological survey usgs stream gauges located at three main tributaries garners bayou greens bayou and halls bayou from north to south because the upstream basin of the gauge 08075900 is a highly developed urban area the flow simulation is complicated by urban controls and stores on the hydraulic simulation therefore in the following flow analysis this gauge is excluded the digital elevation model dem was obtained from the usgs elevation products 3dep in the usgs at 1 3 arc second roughly 10 m resolution the original dem underwent a series of pre processing steps including noise removal with the speckle filter depression fill and burn in of river channels for the atmospheric forcing the multi radar multi sensor mrms data at 2 min and 1 km resolution are used for rainfall inputs zhang et al 2016 and the potential evapotranspiration rate is obtained from usgs fews data port https earlywarning usgs gov fews at daily and 1 spatial resolution allen et al 1998 these forcing data are specific for the hurricane harvey case study from 2017 08 25 to 2017 08 31 in addition the distributed model parameters are acquired from the crest model configured as part of the flooded locations and simulated hydrographs flash project where the existing parameters are provided and calibrated for delivering operational us wide discharge gourley et al 2017 fig 5 the surveyed soil type compositions are downloaded from united states department of agriculture ssurgo dataset at https websoilsurvey nrcs usda gov in order to validate the model simulated flood extent with observations two remote sensing products are correspondingly retrieved as follows the radar produced inundation diary rapid incorporates the sentinel 1 sar data to produce high resolution 10 m flood extent shen et al 2019 the dartmouth flood observatory flood extent herein denoted as dfo was produced by merging multiple data sources including the sentinel 1 moderate resolution imaging spectroradiometer modis radarsat 2 and the constellation of small satellites for mediterranean basin observation cosmo skymed these images are resampled to the same resolution as our simulation results in addition to inundated areas the usgs high water marks hwms collected during a post event ground survey of water marks are utilized in this study to comprehensively compare to the simulated peak flood depths it is noteworthy that these observations though used as reference are not error free 2 7 experiments and computational metrics to assess the uncertainty of the model engines i e crest imap non coupled hydraulic and non coupled hydrologic models and model parameters we implement a synthetic rainfall study as well as a real case study additionally in order to reflect the advances in infiltration process simulated by the hydrologic model the hydraulic component plus a simple infiltration model added to it are compared to one another the infiltration model for this study is adopted from an empirical method described by huggins and monke 1968 in eq 1 therefore for the model comparison crest imap pure hydraulic component herein referred to as hydraulic hydrologic component herein referred to as crest and a hydraulic plus simple infiltration denoted as hydraulic infiltration are taken into consideration 1 f k s a t 5 k s a t θ s a t θ i l f l θ s a t 0 65 where f represents the infiltration rate mm h 1 and f is the accumulated infiltration k s a t is the saturated hydraulic conductivity mm h 1 approximated from the look up table θ i θ s a t are the initial and saturated moisture content the parameter sensitivity is assessed using the morris method morris 1991 which evaluates the global sensitivity aat the corresponding computational metrics are summarized in table 2 the nash sutcliff efficiency nse is a standardized indicator to evaluate the correspondence and magnitude of the simulated and observed streamflow relative bias rb indicates the difference of the flow volume in a systematic manner time to peak error in hours h and peak flow error in cubic meter per second cms indicate the timing and magnitude difference of the peak flow when comparing flood extent in a binary form a contingency table is constructed to compute the percentage of true positives tp false negatives fn false positives fp and true negatives tn in terms of the real case we simulated the hurricane harvey event from 2017 08 25 to 2017 09 01 since model parameters have been well calibrated previously we simply split this simulation period to a fine tuning period 2017 08 25 to 2017 08 26 and a verification period 2017 08 27 to 2017 09 01 the purpose of model fine tuning is to refine the soil moisture states and water levels in the streams some sensitive parameters discovered in the sensitivity analysis are tuned to better represent the basin attributes we applied a scaling factor in the calibration stage to perturb the distributed parameters similar to the approach used in the crest model flamig et al 2020 xue et al 2013 the objective function for the fine tuning period is based on the nse 3 results 3 1 synthetic experiment in this section we examine the performance of the four model engines for a synthetic rainfall event according to the following three aspects first the sensitivity of the model parameters of crest imap is investigated which is primarily linked to basin characteristics second the hydrologic comparison provides insights on the difference of the hydrologic infiltration process and soil moisture dynamics lastly the flood simulation cross compares the flood extent and flood depth generated by different model engines in this experiment the synthetic rainfall is uniformly distributed in this study area at a rate of 100 mm h 1 for a 2 h duration twenty four hour simulations from the four model configurations are thereafter generated the sensitivity is conducted via the morris method and statistical metrics are computed at the basin outlet by perturbing seven model parameters for crest imap the standard deviation and means of the gradient are calculated to reflect the change of parameter value per perturbation the simulation time of each model engine is as follows crest imap costs 1 42 h in total using 36 cpu cores implemented on intel xeon 3 00 ghz similarly hydraulic and hydraulic infiltration require 1 58 h and 1 42 h respectively notably this total simulation time is an accumulation of time run per step which is explicitly derived to satisfy the known courant fredrichs levy cfl condition in eq 2 2 δ t u c δ x where u is the magnitude of flow velocity m s 1 and δ x is the radius of the inscribed circle of a cell m c is the courant number that is typically fixed to 1 therefore the time per step is determined by the flow velocity and the shape of the unstructured grid the pure hydraulic model which solely transforms all rainfall to overland flow is anticipated to have a higher flow rate and thus more time spent per step compared to crest imap and the scenario of hydraulic infiltration configuration in contrast the crest costs 1 72 h on a single cpu core since the routing scheme is not fully parallelized 3 1 1 model parameter sensitivity the sensitivity of model parameters in this study is investigated to not only examine the basin characteristics but to identify a set of parameters to calibrate the model fig 6 depicts the global sensitivity of each parameter from the means and standard deviations of the gradient benchmarked using the a priori parameter set by default the initial soil moisture sm 0 is set to 0 across all the metrics sm 0 stands out to be the foremost sensitive parameter to the model results it is anticipated that antecedent soil moisture is a determining factor to flooding and previous studies also exemplified this point using a range of urbanized basins smith et al 2002 yang et al 2011 in addition the manning s coefficient n is the second most sensitive parameter that governs overland flow for the hydraulic model it is the only parameter to tune the parameter im as the third most sensitive parameter has important implications for timing of the peak flows broadly speaking a higher fraction of impervious ratio urbanization leads to flashier hydrographs other parameters related to soil properties and evaporation are less significant in this study as the majority of the land cover is well developed therefore out of the seven parameters in crest imap only the most sensitive ones i e sm 0 im n are selected to fine tune the model for the real case using the sce ua algorithm meantime all model configurations are optimized with the same technique in the fine tuning period 3 1 2 infiltration and soil moisture the distributed intermediate variables have expanded the data sources for model evaluation especially when considering the availability of remotely sensed data in addition to more conventional use of basin integrated streamflow furthermore these intermediate variables can be used in the process of data assimilation to improve the model prediction skill in this section the intermediate soil moisture infiltration rate and overland flow rate at a specific timeframe are compared to one another the overland flow rate and soil moisture at 1 h after the synthetic rainfall has been introduced are shown in fig 7 it is visually obvious that crest imap shares a spatial similarity with crest in contrast to the other two configurations in terms of the overland flow rate and the soil moisture content moreover the basin averaged time series of infiltration rate of the two configurations exponentially decay with time the soil moisture change in time is also comparable peaking at the same time 2 h however the difference of percent of saturated soil cells with time is discernible in fig 7h the crest model contains a higher fraction of saturated grid cells than crest imap after 12 h this difference can be attributed to the structural difference caused by different representation of mesh grids as crest imap uses the triangular meshes that is at a pseudo 10 m resolution while crest uses regular 10 m grid cells in addition due to different settings of interflow the soil water depletion could essentially differ under the scenario of hydraulic only fig 7a the model treats every drop of rainfall as overland flow to route but omits the soil infiltration capacity and therefore the overflow rate saturates at 100 mm h 1 homogeneously across the region under the scenario of hydraulic with simple infiltration fig 7b the soil saturates across the majority of the land surface because water soil interaction is not properly represented due to the simplification i e infiltration rate is not a function of soil moisture state but at least this simple infiltration captures saturation in the developed land surfaces leaving the areas with high soil water capacity as unsaturated from the basin average infiltration rate shown in fig 7g the simple infiltration performs similarly with crest imap and crest except for a higher infiltration rate at the beginning and earlier saturation in summary both crest imap and crest exhibit more hydrologically reasonable spatial variation of the soil moisture and infiltration process as opposed to the simulation results under the hydraulic only and hydraulic with infiltration scenarios 3 1 3 flood simulation the end products including river stage discharge flood extent and flood depth are inter compared crest uses a 1d channel routing scheme and does not produce flood inundation maps so it is excluded in this analysis fig 8 a and b depict the basin integrated river stage and discharge at the outlet point respectively crest imap with advanced infiltration process shares similar performance with the hydraulic infiltration however the hydraulic infiltration configuration generates slightly greater flow volume in the rising limb and earlier peak time because its soil state reaches saturation earlier than crest imap the hydraulic simulation due to zero infiltration generates a higher river stage and volumetric flow rate compared to the other two regarding the flood extent comparisons crest imap is considered the benchmark or observation despite the hydraulic only model capturing higher percent of tp 21 7 than the hydraulic infiltration 19 9 it raises markedly more fp 13 4 versus 1 0 because of the systematically higher overland flow the same reason leads to the regionally positive difference of the maximum water depth between the hydraulic and crest imap in fig 8e however most of the grid cells in fig 8f show negative differences between the hydraulic infiltration and crest imap 3 2 case study hurricane harvey the above study based on a synthetic rainfall event revealed the inter comparison of different model engines and the sign of the results were expected there is a need to verify the models with respect to observations in a real world case study to this end we simulate an extreme event the 500 year hurricane harvey that has been a well studied event for a modeling purposes chen et al 2020 noh et al 2019 saksena et al 2019 wing et al 2019 hurricane harvey starting as a tropical storm became a category four hurricane while making landfall in texas causing devastating urban flooding in august 2017 the regional accumulative rainfall set a record 1625 mm since the 1880s for its seven day lifespan li et al 2020 the torrential rainfall has resulted in unprecedented pluvial and fluvial combined flooding thereby leading to at least 70 fatalities and economic damages beyond 125 billion us dollars the basin average rainfall rate time series is illustrated in fig 9 with markedly intense rates beyond 60 mm h 1 occurring during 08 27 2017 to 08 28 2017 four individual model engines at their optimal performance fine tuned are intercompared and also verified against the observations for this event 3 2 1 integrated streamflow the streamflow at collocated usgs sites are retrieved for four model engines the crest imap crest hydraulic and hydraulic infiltration as shown in fig 9 table 3 correspondingly summarizes the validation metrics described in table 2 notably the outlet gauge usgs 08076700 only records reliable streamflow data until 08 28 2017 probably due to damage of the in situ instrument compared to the hydrologic models i e crest the coupled hydraulic models i e crest imap hydraulic and hydraulic infiltration overall better capture the streamflow as indicated visually and with higher nse values this observation relates to two limitations of the crest model first the routing scheme i e kinematic wave encounters issues in flat terrain as previous studies stated getirana and paiva 2013 vergara et al 2016 second the hydrologic model mandates sufficient calibration data to match the observation while the tuning period is not adequate conversely it points to the main advantage of this coupled model which requires less calibration efforts to produce reasonable results amongst all hydraulic involved models crest imap outperforms the other two for all the gauge stations with the highest nse values the lowest rmse and peak flow errors on the other hand the hydraulic and hydraulic infiltration reach comparable results the hydraulic only configuration unsurprisingly overpredicts the streamflow as indicated by the rb due to ignored infiltration process at five gauges however the hydraulic infiltration due to crudely represented infiltration process exhibits less flow volume than crest imap in summary the infiltration process is essential and sensitive for the generation of basin integrated streamflow and the hydrologically sound infiltration process improves the streamflow prediction significantly 3 2 2 flood extent the flood extent from two remotely sensed products i e rapid and dfo and simulated by crest imap are overlaid at the same time as shown in fig 10 a and b the percentages of binary counts with respect to tp fp fn and tn are shown in fig 10c and d referenced by the rapid and dfo flood extent products first there is certainly a visual agreement between the remote sensing product and crest imap simulated results especially near the confluence of the greens bayou and garners bayou in contrast the dfo and model results are overlaid with higher percentages of tp 4 60 on average as opposed to rapid 2 00 in this case the merged product dfo may better measure the inundation area rather than the single sourced product rapid however the higher fraction of fn 2 07 vs 0 83 in dfo might be subject to the non distinguishable backscattering signals from water surfaces and urban structures instead rapid undergoes rigorous preprocessing steps such as morphologic removal water classification and machine learning corrections to eliminate noise second our simulations tend to predict more inundated areas than the remote sensing observations in the floodplain especially downstream such as the deep forested area near the basin outlet the remote sensing products did not capture the flooded areas this could be explained by the inherent issues for the remote sensing measurements i e sar and passive microwave as the vegetated areas and submerged wetlands enhance the dihedral scattering martinis and rieke 2015 in that regard it is likely that they miss flood events in the deep forested area some related studies such as saksena et al 2020 also generate similar flood extent as crest imap ensuring the rationality of the result for the model engines crest imap achieves a comparable percentage of tp with the hydraulic referenced by rapid and dfo however the fp are adequately reduced 19 6 and 24 2 for the hydraulic vs 17 9 and 22 5 for crest imap compared to hydraulic infiltration crest imap shows more than 0 1 higher percentage of tp and similar fp because the hydraulic only configuration obviously generates more inundated grid cells than models including infiltration processes it is challenging to justify the performance solely based on tp meanwhile remote sensing products suffer inherent errors which may bias our judgement therefore it is only reliable to conclude the flood extent by crest imap is comparable with the hydraulic model which proves its applicability in flood prediction 3 2 3 flood depth the simulated peak flood depth is compared with hwms collected from 23 sites shown in fig 11 a first all the hwms are located within the simulated flood extent second for the greens bayou the crest imap exhibits higher depths than the hwms while lower depths for the halls bayou in the south nevertheless according to the harris county local flood report https www hcfcd org portals 62 harvey immediate flood report final hurricane harvey 2017 pdf during hurricane harvey the greens bayou gauge broke the flood record 500 year return but the halls bayou only experienced a 10 50 year return flood our simulations align well with this frequency analysis it is worth mentioning the uncertainties when comparing hwms to model simulations first there is a large deviation between surveyed elevation and dem used for modeling generally ranging from 1 to 2 m depending on the location second the qualities of hmws vary resulting in differences of 0 5 m third uncertainties between point values i e hwms and area values i e simulations are apparent the locations of hwms could be off tens of meters because of truncation errors despite of this fact the maximum difference of 2 6 m is reasonable and acceptable with respect to the model engines fig 11b reveals the peak depth difference of all 23 hwms 9 8 sites show that the crest imap hydraulic outperforms with the lowest absolute difference the remaining 6 sites have better relative simulations from the hydraulic infiltration model also the distributions of peak flow differences in fig 11c indicate the performance in a broad view for crest imap the errors between estimates and observations vary from 2 4 to 2 1 m with 74 of them situated within 1 5 1 5 meters which is comparable with the results of 79 from saksena et al 2020 however their results experience overestimations of 3 m for the hydraulic the errors vary from 2 3 to 2 8 m with 69 of them situated within 1 5 1 5 meters lastly for the hydraulic infiltration the errors vary from 2 9 to 2 3 m with 57 of them located within 1 5 1 5 meters it is obvious that crest imap has the narrowest range of the differences between simulations and observations and the highest percentage of differences within an acceptable error range among all model configurations the crest imap exhibits the best performance due to the joint advantages of hydrologic and hydraulic simulations 4 conclusions and future work this study introduces a new flood forecasting framework which is comprised of a mesh generator an h h model and a set of uncertainty sensitivity analysis tools and calibration schemes to explore the advances and sensitivities a synthetic rainfall study and the 500 year hurricane harvey event are simulated to systematically evaluate the different model configurations crest hydraulic only hydraulic infiltration and crest imap here are the main findings for crest imap 1 for the model efficiency it is highly parallelized and fully integrated promoting its applicability for operational flood prediction and inundation mapping 2 the flexible mesh generator minimizes structural errors compared to traditional mesh designs 3 for the parameter sensitivity antecedent soil moisture is the foremost sensitive parameter for these case studies followed by land surface characteristics manning s n and impervious area ratio the other parameters related to soil moisture are less sensitive which is attributed to the characteristics of study basin 89 7 developed land 4 for the hydrologic physical process representation the crest imap and crest reasonably capture the spatial and temporal dynamics of the soil moisture and infiltration rates while the hydraulic and hydraulic infiltration misrepresent them which leads to the different performance in the end products 5 the infiltration process is central to a flood mapping model as it greatly influences the basin integrated discharge flood extent and peak flood depth a real case study of hurricane harvey also indicates that crest imap systematically outperforms the hydraulic simulation without infiltration and the hydraulic infiltration with crudely represented infiltration process further assessment of crest imap is necessary to improve this framework first current work does not include surveyed channel geometries which is acceptable with respect to model performance in hydraulic simulations we expect to see the added values by incorporating refined channel cross sections and terrains second the mesh generator needs to be systematically evaluated with respect to different basin attributes and the strategies of designing an optimized mesh should be explored lastly an impact based forecasting module could complete this modeling chain to specifically focus on the potential damages for public awareness instead of the natural hazard characteristics alone e g intensity extent discharge and frequency software availability the main package is developed using the python language version 2 7 some bottlenecks that are computationally expensive e g hydrologic component and mesh generator are written and compiled in c language for efficiency some revisions for the hydraulic model anuga are based upon version 2 1 it has been tested on linux operating systems this framework is openly available at https www hydroshare org resource 50ce0d7d80b642898f74d8bf56798565 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the first author is partially sponsored by the university of oklahoma hydrology and water security program national science foundation pire project and graduate college hoving fellowship the authors would like to thank the efforts by the national oceanic and atmospheric administration national severe storms laboratory team for making the mrms data accessible the flood extent simulated by rapid system is obtained at https xinyi shen uconn edu inundation maps of recent flood events from rapid sentinel 1 and the dartmouth flood observatory simulated flood extent during hurricane harvey is obtained at https floodobservatory colorado edu events 2017usa4510 2017usa4510 html the material is based upon work supported by the national science foundation under grant no oia 1946093 and its subaward no epscor 2020 3 
25822,this study develops a novel reservoir regulation routine incorporated into a continental scale hydrologic model in the nelson churchill yenisey ob and lena basins this regulation routine is integrated into the hydrological predictions for the environment hype hydrologic model used for continental scale applications applying this daily timestep regulation routine at 19 reservoirs in the arctic ocean watershed performance is shown to improve upon the reservoir regulation currently available in the hype model when testing outflow and storage nash sutcliffe efficiencies nses improvements stem from intra annually variable storage rule curves and a variety of stage dependent outflow functions improving simulation skill median nse increases of 0 18 over 21 reservoir outflow records and 0 49 over 19 reservoir storage records this new reservoir regulation routine is suitable for continental scale modelling by deriving varying rather than fixed threshold water surface levels and associated outflow rules in a programmatic way for multiple reservoirs keywords hydrologic modelling hydroelectric regulation hudson bay software and data availability hype access to the hydrologic predictions for the environment hype and hydrologic simulation system hyss model codes was granted by the swedish meteorological and hydrologic institute smhi details can be found at https sourceforge net projects hype microsoft excel a commercially available spreadsheet interface tool available with the microsoft office suite of products r rstudio has been used to develop code for estimating reservoir parameters simulating reservoir outflow and storage analyzing simulated data and plotting results data input data used in modelling for reference calibration validation are freely available these are obtained from the water survey of canada wsc https wateroffice ec gc ca the global runoff data centre grdc https portal grdc bafg de and the global reservoir and lake monitoring program g realm https ipad fas usda gov cropexplorer global reservoir 1 introduction in a world increasingly affected by anthropogenic effects it is natural that interest in modelling of damming and reservoir regulation on streamflow would grow alongside increased resolution and scale in hydrologic modelling reservoir regulation exists as an optional extension to some degree of sophistication in most hydrologic models nazemi wheater 2015a 2015b modelling of reservoir regulation is most straightforwardly seen in basin scale studies such as those where regulation has been shown to improve operational modelling piman et al 2016 ahn et al 2014 a practical combination of hydrologic and reservoir modelling is seen in a canada wide study of climate change s effect on hydroelectric production looking to develop empirical relationships between historical climatology and hydroelectric production then projecting these results to a possible future climate amir jabbari and nazemi 2019 this study cites manitoba and saskatchewan studied extensively here as difficult to predict areas due to their streamflow largely originating far upstream of regulation points and having high interannual variability a reasonable solution to this problem is the full integration of hydrologic and reservoir regulation modelling at the watershed or continental scale covering numerous reservoirs simultaneously as computational hydrology has grown to include continental scale studies so too has interest in regulation s effects on continental or global hydrology qin et al 2019 and modelling to simulate anthropogenic impacts and climate change with varying degrees of success yassin et al 2019 coerver et al 2018 arheimer et al 2017 zajac et al 2017 bellin et al 2016 zhao et al 2016 pechlivanidis and arheimer 2015 zhou and guo 2013 pokhrel et al 2012 the hydrological predictions for the environment hype lindström et al 2010 model is proven to be useful for simulating hydrology at the continental scale pechlivanidis and arheimer 2015 but the regulation algorithm can be problematic at that scale due to the need to calibrate reservoir parameters separately from autocalibration this routine has been indirectly evaluated and found to be poorly represented at larger scales and or in data sparse regions arheimer et al 2020 donnelly et al 2014 2016 andersson et al 2015 bergstrand et al 2013 human water interactions reservoir management irrigation etc are also noted as a problem area in other continental scale hydrologic models and global land surface models zaherpour et al 2018 wada et al 2017 wanders and wada 2015 zhou and guo 2013 pokhrel et al 2012 hanasaki et al 2006 a useful survey of the representation of human water interactions in macroscale hydrologic models can be found nazemi and wheater 2015a with regulation of reservoirs implemented into large scale hydrologic modelling studies of sensitivity uncertainty or the effects of climate change at the continental scale become possible studies have created reservoir regulation site specific models developed to be integrated directly into larger hydrological models alvarez et al 2014 welsh et al 2013 li et al 2010a minville et al 2010 minville et al 2009a many studies are developed using historical data and applied to overtly non stationary future climates using dynamically or stochastically optimized methods denaro et al 2017 haguma et al 2014a b haguma et al 2014a b malekmohammadi et al 2009 other canada based studies have used future climatic ensembles and current reservoir operations rules as the work presented in this paper will but instead to analyse reservoir reliability sensitivity or uncertainty hassanzadeh et al 2014 li et al 2010 minville et al 2009b as this work will not an important development in the rarefication of regulation modelling is accounting for intra annual changes to operations due to ice cover inflow regime or hydroelectric demand operational rule curves or optimal release curves based on storage with hedging or with curves optimized dynamically have been validated on historical periods and proposed for operational use prasanchum and kangrang 2018 zhang et al 2017 nunes et al 2016 adeloye et al 2015 taghian et al 2013 liu et al 2011 matrosov et al 2011 an example of the utility of intra annually variable target storage curves is presented in this work in the context of basins with variable interannual climatic variability and intra annual nival regime inflow the effects of future climate change and changing inflow regimes are sure to pass on to reservoir operations the cumulative future effects of regulation and climate change are of growing concern the climate is changing rapidly in northern canada déry et al 2009 2011 leading to changes in the duration and depth of snowpacks kang et al 2014 and ultimately resulting in alteration of both the timing and volume of freshwater export to the arctic ocean at the same time regulation control over freshwater exports for example to the hudson bay complex from the nelson churchill river basin ncrb and la grande rivière complex lgrc have been increasing through time influencing the timing and volume of freshwater exports déry et al 2016 2018 the confluence of the effects of regulation and climate change on hudson bay triggered the onset of the baysys group of projects barber 2014 designed to examine the full extent of these impacts on the marine system of hudson bay of interest is the question is climate change or hydroelectric regulation the primary driver of changes in hudson bay to determine the answer the effects of both drivers must be quantifiably simulated separated and analysed models used to project future terrestrial freshwater exports must be robust in changing climates reliable for long term projections in cold regions and responsive to changing or variable inflow conditions to regulated reservoirs which is often not the case in currently existing hydrological models the hudson bay drainage basin hbdb and those rivers draining to the arctic ocean as a whole contain multiple regulation points reservoirs control structures generating stations diversions etc with close to half of the freshwater of the hbdb by volume impacted by regulation déry et al 2018 and the impact of regulation on environmental factors of note in the yakutia region of russia tyaptirgyanov and tyaptirgyanova 2016 crate 2002 the freshwater systems group team 2 of baysys barber 2014 is tasked with generating two hydrologic models to simulate an ensemble of climate scenarios 1 a regulated system model and 2 a re naturalized model to do so an improved reservoir routine embedded in hype is necessary it must effectively simulate reservoir outflows under natural climatic variability year to year and long term climatic change 30 year periods or longer this will be used to assess anthropogenic influence of hydroelectric regulation on freshwater exports we develop a more robust regulation routine for the hudson bay hype h hype model to simulate regulation of 15 ncrb reservoirs and to test the method on four reservoirs draining to the arctic ocean from russia ob yenisey and lena rivers regulation rules are based on near current operational storage outflow relationships 2001 2010 for the ncrb 1991 to 2000 for the russian reservoirs and do not account for new hydropower developments altered power sales markets or system integration this excludes dynamic or cascading reservoir optimization as has been demonstrated in other studies asadzadeh et al 2014 malekmohammadi et al 2009 cheng and chau 2004 we focus on rivers feeding the nelson and churchill rivers the two largest contributors of freshwater outflows to southwestern hudson bay déry et al 2011 both with increasing anthropogenic influence on their freshwater regimes since the 1970s déry et al 2018 and four reservoirs throughout the russian arctic drainage basin the methods presented aim to include monthly storage targets as seen in yassin et al 2019 while also providing the option for more detailed and dynamic relationships between reservoir level and outflow 1 1 objective the gap this work addresses is that of a reservoir regulation routine suitable for sub basin discretized continental scale modelling that also considers daily target water surface levels to bridge this gap the objective of this work is to develop a reservoir regulation routine which can be applied to multiple reservoirs of significance in our study region simulated using the hype model by analyzing observations in a programmatic fashion it must improve the modelling performance short term and reliability long term of simulated historical outflow in the most influential regulated reservoirs in the ncrb this work also aims to reduce modelling reliance on prescribed outflow as prescribed daily or monthly outflow schedules assume consistent interannual volume and timing of inflow and climatic stationarity by extension to achieve this objective this work is broken into three main steps 1 to develop a broadly applicable regulation routine synthesizing multiple types of processes used in industrial hydroelectric regulation models 2 to develop an offline analysis tool to calibrate reservoir parameters before their inclusion in a continental scale hydrologic model and 3 to test multiple reservoir processes using historic storage outflow relationships and select parameter sets which favour seasonal outflow and storage performance 2 study domains this study focusses on simulating the regulation of 19 reservoirs from five river basins draining to the arctic ocean many of these reservoirs have a theoretical storage time of less than a year no interannual storage fig 1 table 1 according to the modification of the natural river regime these basins are subject to severe nelson and yenisey heavy churchill and ob and moderate lena regulation by the river regulation index presented in grill et al 2015 in the ncrb this regulated storage capacity is heavily leveraged to re apportion the mixed to nival river regime stadnyk et al 2019 to produce a hydrograph more consistent with hydroelectric production needs i e inflows withheld in spring and summer then released consistently throughout the winter déry et al 2018 reservoir physical characteristics and their basin climatic characteristics are presented in tables 1 and 2 locations detailed in fig 1 reservoirs were selected where at least 15 months of overlapping reported water surface level wsl and outflow data were available these 15 months represent a relatively sparse eighth of the 10 year reference period used and sixteenth of the 20 year validation period daily discharge records inflow and outflow are obtained from the water survey of canada wsc 2020 and the global runoff data centre grdc 2020 daily wsl records are obtained from the wsc wsc 2020 and reservoir levels at a 10 day repeat are obtained from the united states department of agriculture s foreign agricultural service global reservoirs and lakes monitor database g realm usda fas 2020 reservoir surface areas and depths are obtained from the global lake and wetland database glwd lehner and döll 2004 the global lake database v2 kourzeneva 2010 and the global reservoir and dam database v1 1 grand lehner et al 2016 reservoir upstream area is reported from the arctic hype a hype andersson et al 2015 hydrologic model live depth is the computed depth between the historic minimum and maximum wsls since the onset of reservoir operations post filling live storage is computed as the live depth multiplied by the reservoir surface area hype reservoirs are modelled as rectangular prisms accounting for no dynamic surface area detention time is the ratio of live storage to average inflow over the period 1971 to 2015 fig 1 table 2 reservoirs simulated in this study have theoretical detention times between 0 2 and 24 months examining the skill in simulation of run of the river reservoirs little to no detention time and large multi year reservoirs can theoretically store more than 12 months of inflow mean annual upstream climatic conditions total precipitation snowfall rainfall temperature potential evapotranspiration and runoff are computed from a hype using the hydrological global forcing dataset for daily precipitation daily max temperature daily min temperature hydrogfd berg et al 2018 abraham lake in the canadian rocky mountains and the rafferty reservoir in the canadian prairies represent the extremes in runoff ratio equivalent runoff depth relative to total precipitation depth 0 79 and 0 08 respectively table 2 aridity index total precipitation relative to potential evapotranspiration 2 38 and 0 52 respectively table 2 and snowfall ratio snowfall relative to total precipitation 0 57 and 0 19 respectively table 2 remaining reservoirs span the gamut between these extremes representing various combinations of dryness snowfall and runoff efficiency this gives a broad base of reservoir types excluding rainforest or tropical conditions on which to test a new reservoir regulation routine 3 methods and models the skill of the hype model in simulating reservoir regulation has been tested for 19 reservoirs using two algorithms the first is that belonging to hype in its current release the second is that developed herein the existing regulation algorithm in arctic hype version 3 a hype hereafter andersson et al 2015 is described as well as the development of the regulation used in hudson bay hype h hype hereafter stadnyk et al 2020 3 1 a hype dam routine the hype hydrological model lindström et al 2010 developed by the swedish meteorological and hydrological institute smhi discretizes watersheds to sub basins any of which can be in part or in full a lake or reservoir computation of the reservoir level and outflow is governed by a routine that simulates reservoir regulation this hype dam routine includes sub routines for four dam purposes 1 flood control 2 water supply 3 irrigation and 4 hydroelectric reservoirs can use one or two outlets to simulate diversions the existing hype routine for regulated dams focusses on physically based variables to produce a target daily outflow complete details regarding the routines governing dam outflow operations in hype can be found on smhi s hype wiki under the rivers and lakes section river and lakes 2020 reservoirs in hype are modelled as rectangular storage units with uniform surface area and variable level computation of outflow by time step will access different elements of piecewise functions using the wsl computed for the previous time step and two threshold parameters called minimum stage and reference stages in fig 2 these stages divide the reservoir into three zones low flow zone below minimum stage spillway flow zone above reference stage and production flow zone between minimum and reference stages how much or little water is discharged daily from the reservoir in the production flow zone will depend on the dam s purpose specified by the user all reservoirs compared in this work were calibrated using the existing hype regulation routine stadnyk et al 2019 2020 as hydroelectric dams with a sine curve outflow when in the production zone fig 2 equation a 51 table a2 appendix a a weir type equation in the spillway zone fig 2 equation a 53 table a2 appendix a these relationships result in seven parameters for single outlet reservoirs two wsl thresholds three sine function parameters amplitude phase mean and two parameters for the spillway coefficient and exponent of a power curve four additional parameters are added for bifurcated branched reservoirs minimum and maximum main outlet flow maximum branch flow and the desired fraction of total flow to the branched outlet rivers and lakes 2020 methods exist in a hype to specify two means of the sine function split by two datums expressed in days these methods are not employed here as the means to split historical records intra annually by varying dates are not considered 3 2 h hype dam routine development a new reservoir regulation routine is presented for the hype model tested in r to be written into hype in fortran access to the hype code was provided by smhi for the purposes of this project this new routine ties together operations and modelled state variables maintaining applicability to reservoirs of many types of operation and many sizes this applicability allows the routine to be applied to any reservoir which modellers wish to represent with a minimum of operational knowledge necessary prior to running the model the new routine formulation is the synthesis of the processes of nine reservoir regulation models developed by manitoba hydro each governing a single reservoir as in a hype each of these models uses a fixed set of stage wise processes i e monthly storage outflow curves minimum ecological outflow target outflow by day of year etc for a varying number of reservoir thresholds fixed stages or stage curves a model is developed with multiple possible formulations fig 3 of the piecewise function governing outflow with parameters derived from historical stage outflow relationships the reservoir is divided into five zones based on two fixed stages and two stage curves the zone and level of the reservoir for each simulated time step will dictate outflow equation used and overall volume of outflow for timestep i month j general versions of the formulation are presented stages zones and options for each zone are summarized in fig 3 fixed value equations a 18 and a 19 table a1 appendix a indicates that when the simulated wsl is in that zone the outflow is a fixed value allowable maximum or minimum monthly equation 1 below equations a 11 to a 17 table a1 appendix a indicates a monthly linear storage outflow relationship for wsls within that zone for that month above wsl β j which varies monthly fixed curve equation 2 below equations a 8 to a 10 table a1 appendix a indicates an exponential storage outflow relationship within that zone above wsl δ ideal storage equation 3 below equations a 21 to a 29 table a1 appendix a methods use the distance between the current day s wsl and the target storage curve θ not a parameter as well the previous two weeks inflow and previous two weeks gradient of the target storage curve to dictate outflow condition equation 4 below equations a 30 and a 31 table a1 appendix a indicates a relationship between the outflow of the reservoir and an external timeseries outflow of another sub basin fifteen parameters govern the threshold stages of wsl 12 parameters for target storage on the first day of each month the depth of the operations zone the flood stage and the drought stage fixed values introduce two parameters flood maximum and drought minimum outflow per outlet monthly relationships 24 one coefficient α j per month two zones per outlet fixed curves six one coefficient γ and power ε three zones per outlet with an additional parameter for maximum daily change of outflow conditional flow introduces four parameters μ ρ τ and ω 1 q i α j w s l i w s l β j 2 q i γ w s l i w s l δ ε 3 q i θ 1 i 13 i q i n i 14 i 13 i s i s i 1 14 4 q i μ q e x t e r n a l ρ τ ω the applicability of this routine is tested by deriving parameters stage outflow relationships derived based on paired observed data from a reference period not calibrated and simulating outflow and storage over 30 years the use of this new regulation routine is meant as a proof of concept to demonstrate that a diverse set of reservoirs can be simulated using paired observed data without prior knowledge of reservoir operations the routine presented does not pre suppose a prior understanding of what processes govern outflow computation within different zones of the reservoir excluding drought zone for any given reservoir and uses an offline tool r function external to the hype model to test combinations of processes and select the optimal set of processes by testing multiple combinations of piecewise flow processes referred to as zone options figs 3 and 4 table 3 we avoid applying empirical regulation codes based on real world operations specific to individual reservoirs this aims to avoid the black box effect kirchner 2006 if coded directly into a hydrologic model this routine aims to reduce parametric uncertainty an issue highlighted by beven 2012 juston et al 2013 by making use of physically based processes rather unlike operation schemes using neural networks or hidden logic which have also been applied successfully in macro scale modelling schemes coerver et al 2018 ehsani et al 2016 an important element of this routine is the interannually variable storage rule curves which govern the low operations and high zone in h hype fig 3 rather than fixed thresholds for piecewise operations throughout the year three zones in a hype fig 2 use of variable target storage values throughout the year are shown to improve reservoir model performance yassin et al 2019 wu and chen 2012 by imposing seasonally or monthly variant thresholds to reservoir outflow behaviour for each reservoir a statistically optimal set of options process dictating outflow for each zone is generated by the reservoir analysis tool rat section 3 3 reported in table 3 a description of the function of the regulation routine within each timestep is shown in fig 4 it further helps describe the use of the daily outflow to calculate storage calculated from the wsl for the next timestep section 3 4 describes the process used to systematically mix the integer parameters and wsl limits for both models section 4 describes the results of these multiple simulations optimal storage outflow relationships whether linear monthly or fixed curve are derived using the rat and near current wsl and outflow records 2001 2010 for canadian reservoirs 1991 to 2000 for russian reservoirs referred to as the reference period this reference period is selected to provide the most up to date possible regulation rules for the studied historical period though these equations introduce parameters to the formulation the parameters are designed to be kept fixed relative to a set of governing stages in this way because the parameters are related to historical physical observations they are similar to other fixed variables such as reservoir surface area in that they are untouched by optimization using fixed parameters based on historical storage outflow relationships is proven to provide adequate though not optimal modelling of reservoirs performance compared to simpler methods referred to as a generalized parameter set by yassin et al 2019 while offering the option to improve performance with a full optimization with 610 sets of wsls tested here to vary the stage discharge relationships the a hype parameters defining the minimum stage and spillway stage are defined as the minimum and maximum limits of the derived h hype operations stage curves wslop and wslop respectively fig 3 parameters defining the storage outflow relationship of the spillway curve equation a 28 table a1 appendix a are derived using lsr on all paired data above the spillway stage wslreference fig 2 log transformed to linearize the data parameters defining the sine curve are computed using observed outflow where wsl falls in the defined operations zone fig 2 errors are minimized between a synthetic sine curve using amplitude mean and phase and that defined by the reference period production zone average annual daily equation a 27 table a appendix a 3 3 reservoir analysis tool rat before introducing new reservoirs to h hype reservoir process selection narrowing the zone options of fig 3 to a single set as shown in fig 4 details in table 3 is automated using the rat this tool replicates the routine added to h hype without the need to run an entire hype simulation to directly compare the skill of the reservoir regulation rather than the full hydrologic model reservoirs were compared by supplying each reservoir with its observed daily inflow timeseries precipitation onto reservoirs is taken from the hydrogfd dataset and reservoir evaporation losses are calculated in a hype using the priestley taylor method where the difference between maximum and minimum daily air temperature approximates radiative forcing processes above ground 2020 and assuming that lakes act as free evaporation surfaces each reservoir is simulated as a sub basin in a hype and h hype eliminating the need for a volume and or momentum based methods to pass water within a reservoir between grid cells or sub basins as seen in shin et al 2019 functioning of the rat offline from hype relies on complete inflow records these are developed for each reservoir using public records from the wsc grdc or using synthetic methods shorter gaps in observed inflow records 2 days were filled using linear interpolation where significant gaps exist in inflow records 2 days gap filling was performed using the next upstream gauge available from the wsc 2020 or grdc 2020 and proportional drainage area scaling déry et al 2005 2011 hernández henríquez et al 2010 outflow and wsl are not gap filled since these data are used exclusively to evaluate performance and develop storage outflow relationships these records can be found in table a3 appendix a where no inflow data are available synthetic time series of inflow are generated these are created using the relationship between throughflow and storage equations 5 and 6 where sa reservoir surface area m2 q in daily inflow m3 day 1 q out daily outflow m3 day 1 wsl daily water surface level m δs is daily storage change m3 p daily precipitation mm et daily total evapotranspiration mm between days i and i 1 or δt timestep day records were further synthetically extended by using the average annual daily value of existing data these existing gaps are ignored during statistical calculations so as not to introduce added uncertainty into parameter estimation uses of full records and synthetic inflow series are summarized in table a3 appendix a table a1 appendix a presents the input records used for parameter derivation outflow and wsl and simulation inflow precipitation and evaporation 5 s a w s l i w s l i 1 δ s δ t q i n i q o u t i 1 s a p e t 10 3 6 q i n i s a w s l i w s l i 1 δ t e t p 10 3 q o u t i 1 the scope of the baysys group of projects excludes optimization of cascading reservoirs reservoirs are calibrated individually on their individual skill scores not on an aggregated basin wide score regulation rules are also designed to be static these rules do not change or adapt to future climatological conditions to achieve reliable results with these static rules the reservoir operation routines must strive to maintain desirable reservoir levels rather than dictating optimal outflow values as inflow volume and timing are likely to change in the future dynamic optimization of reservoirs for power production or financial gain is ignored with the maintenance of reservoir levels consistent with historic operations prioritized instead 3 4 optimal selection the rat simulates 610 sets of stage limits by modifying operations depth operations shift and extreme stage depth in h hype described in section 3 2 ranges presented in fig 5 which relate to wslminimum and wslreference a hype evaluating all h hype zone option combinations 16 for a single outlet or 256 for a double outlet reservoir and the associated a hype options 1 for a single outlet or 2 for a double outlet reservoir for each set of stage limits outflow and storage performance of 610 16 9760 or 610 256 156160 timeseries for h hype 610 or 1220 timeseries for a hype is used to select an optimal parameterization for each model this selection is based on the performance of daily timeseries in the reference period 1 january 2001 to 31 december 2010 for canadian and 1 january 1991 to 31 december 2000 for russian reservoirs these periods are split into seasonal timeseries using standard hydrological seasons winter djf spring mam summer jja autumn son this performance is then validated for an earlier period 1 january 1981 to 31 december 2000 for canadian and 1 january 1971 to 31 december 1990 for russian reservoirs reference periods are selected to maximize overlapping wsl and outflow records with validation periods taken as the preceding twenty years the combined outflow and storage performance is computed to select the optimal stage limits and zone options this is taken as the sum of seasonal outflow and storage nash sutcliffe efficiencies nse nash and sutcliffe 1970 of daily timeseries 4 seasons 2 variables 8 where there were two outlets the sum of nses for all seasons for storage and outlets is optimized 4 seasons 3 variables 12 seasonal nse is used rather than the seasonal kling gupta efficiencies kge gupta et al 2009 due to the nse being shown to be more sensitive in calibration of reservoir regulation in h hype stadnyk et al 2020 the ideal combination of zone options and stages table 3 is selected as the greatest sum of nses the number of equifinal solutions are listed in table 3 as a fraction of the total number of combinations assessed equifinality is seen in a hype in both reservoirs with two outlets lake st joseph and southern indian lake h and o in figs 6 to 12 and two others abraham and rafferty reservoirs and two reservoirs in h hype two matching optima in each case in both models these values represent a negligible fraction of the total range of wsls a hype and h hype or integer options h hype tested 4 results and discussion fig 6 presents the a hype and h hype values of nse for continuous daily timeseries n 3652 for reference and n 7304 for validation periods the sums of seasonal statistics maximum sum of nses are used to inform the selection of processes in the rat the selected best performing rat parameter set is shown for each outlet as well as its a hype counterpart with the optimal performance for two performance metrics nse and percent error of standard deviation presented for both models reference and validation periods outflow and storage in tables 4 and 5 and mapped spatially in figs 8 and 9 testing 610 sets of base wsl characteristics fig 5 and evaluating all possible simulations with related parameters gives a range of results for both models examining boxplot performance the bottoms of the interquartile ranges fig 6 of the full timeseries h hype are in some cases higher than the top of a hype for the same this is the case for the full timeseries annual storage in 10 reference and 7 validation of 19 reservoirs and outflow in 13 reference and 8 validation of 21 outlets fig 6 this demonstrates that not only is the optimal solution improved figs 7 9 tables 4 5 there is increased probability of stronger performance even if the selection of an optimum may contain uncertainty such as that due to the choice of selection metric seasonal improvements can be seen in the daily optimal simulation figs 12 and 13 as well as in the mean regime average annual daily figs 10 and 11 over the 30 years of the reference and validation combined periods fig 7 presents the optimal results selected for each reservoir also seen in fig 6 in nine and eight of 21 outlets for validation and reference respectively fig 7 the nse of outflow simulated in h hype is greater than 0 5 considered the threshold for satisfactory performance for watershed scale hydrological simulation by moriasi et al 2015 compared to three and five for the same in a hype while these results are initially underwhelming we must remember that these simulations are governed by historical relationships i e storage outflow relationships compared against measured data which are governed by human judgement highly interconnected operational systems and individual dam operators this does not excuse poor nse performance but should be considered when contextualizing the difficulty in simulating short scale human operations rather than the predictable physically based processes of the environment assessing the optimal nse performance of reservoir outflow and storage table 4 figs 7 9 we see an improvement using the h hype regulation in the reference period median nse improves by 0 18 and 0 49 for outflow and storage where a hype results less than 3 5 are excluded figs 7 9 this reference period 2001 2010 for canadian and 1991 to 2000 for russian reservoirs is where the paired wsl and outflow data are used to develop the parameters and due to the added parameterization of the new routine improved performance here is expected as seen in the lighter shaded region in figs 12 and 13 in the validation period median nse improvement is by 0 10 and 0 20 for outflow and storage again where a hype results less than 3 5 are excluded figs 7 9 outflow results improve by more than 0 1 in 14 and change by a nominal amount 0 1 in four of 21 outlets in the reference period fig 8a and b and improve in nine and change by a nominal amount in five of 21 outlets in the validation period fig 8c and d storage results improve in 14 and change by a nominal amount in four of 19 reservoirs in the reference period fig 9a and b and improve in 10 and change by a nominal amount in two of 15 reservoirs for the validation period no validation data available for storage in russian reservoirs fig 9c and d because reservoirs are modelled with observed inflow there is no spatial pattern to improvements in nse fig 7 and 8 due to cascading results despite a lack of spatial pattern these show improvement over a hype with few exceptions these results suggest that in the majority of instances the model is better able to react to interannual climatic and intra annual i e shorter duration floods variability and correctly apportion water exiting the reservoir seasonally for both the reference and validation historic periods 1981 2010 for canadian 1971 to 2000 for russian reservoirs it further proves that the storage is better maintained at the seasonal resolution for that same period improvements of seasonal storage performance are important to long term reliability of results and shown to improve in the majority of presented reservoirs data availability in this period 1981 to 2000 for canadian and 1971 to 1990 for russian reservoirs is more variable with no wsl data available for the russian reservoirs in this period despite the relative sparsity of observation data and the fact that the regulation rules are derived in the future of these observations have not yet known performance is still shown to improve using h hype over a hype and in fact shows a greater median improvement than the reference period we further assess changes to the relative error of the standard deviation res table 5 a component of the kling gupta efficiency and a practical measure of the simulation skill at replicating sub weekly reservoir operations or longer scale climatic variability the effects of weekly operations can be seen particularly in hydroelectric reservoirs déry et al 2018 the absolute value of res by using h hype improves by a median of 8 9 and 6 4 percent for outflow and storage respectively excluding a hype errors exceeding 100 these present a reduction of error and therefore a closer approximation of the measured variability in the validation period the median change to res is 7 6 and 15 percent for outflow and storage respectively again excluding a hype errors exceeding 100 in this sense the variability of the outflow and storage are improved over ahype for both reference and validation periods average annual hydrographs are presented to qualitatively compare a hype and h hype skill at predicting yearly flow regime relative to observations each day represents the 30 year average outflow by day of year reference and validation together day of the week is not considered as seen in déry et al 2018 and as such hydro peaking and statutory holiday effects are generally not visible these offer an assessment of the skill of the seasonality and sub seasonal model responses fig 10 shows an improved seasonality across the majority of reservoirs for outflow regardless of the shape of observed outflow seasonality h hype shows qualitative improvements in dynamic systems with high interannual variability except in the case of cedar lake fig 10e lake manitoba fig 10l sayano shushenskoye fig 10q and krasnoyarskoye fig 10r this is seen in the case of lake manitoba fig 11l for wsl as well sayano shushenskoye and vilyuyskoye have very limited records of overlapping wsl outflow data fig 1 this limits the ability to parameterize the model based on historic observations notable improvements are shown in pointe du bois reservoir figs 10j and 11j rafferty reservoir figs 10k and 11k southern indian lake fig 10o1 10o2 11o1 and novosibiriskoye figs 10p and 11p for both outflow and wsl in the case of southern indian lake a reservoir with two outlets improvements are shown in each outlet leading to improved seasonality in both and as a result storage skill at simulating mean regime over climatic scale periods 30 years is important for long term simulation but over and above improvements to 30 year mean seasonality skill in daily outflow and wsl is important to examine instances of the most robust hydrograph improvements arise in reservoirs with the greatest interannual variability of water supply whether by variable inflow or by p pet ratio table 2 such as lake diefenbaker figs 10c and 12c and oldman reservoir figs 10b and 11b this is also seen in reservoirs with less predictable behaviour such as the hydrograph drawdown operations seen in lake winnipeg august to october fig 10m or tobin lake may to june fig 10d reservoirs with interannual variability in water surface level also show improvement such as namakan rainy lake figs 11f and 13f and lake of the woods figs 11g and 13g in both cases these reservoirs fail to be as well represented by the a hype prescribed sine curve target outflow but are more accurately captured by h hype where outflow is more sensitive to daily storage and daily storage is sensitive to an intra annually variable curve target storage improvements to performance and the h hype performance itself are more variable in the russian reservoirs than their canadian counterparts simulation of average storage and storage intra annual variability are improved by h hype in all russian reservoirs fig 13p 13q 13r 13s outflow performance in russian reservoirs is improved and greater than 0 5 for novosibiriskoye fig 10p and improved though unsatisfactory for vilyuyskoye fig 10s performance of the yenisey river reservoirs outflow fig 10q 10r improve in the reference period though they are unsatisfactory and degrade in the validation period any improvements to skill are related to the length of synchronous wsl and outflow records fig 1 distribution of records throughout the year will provide improved parameter estimation over seasonal gauge records simulating multiple sets of governing wsls which dictate the parameter estimation a suite of h hype parameter sets is assessed to determine the optimal formulation for each reservoir in the case of the russian reservoirs the period of overlap is much shorter greater than 1 full year but generally less than 4 where the canadian records are closer to the full 10 year reference period the wsl records of russian reservoirs are derived from a 10 day satellite pass which will also account for consistent gaps in the records the poor performance in the validation period of the russian discharge stations is also due to three of the four stations being commissioned sayano shushenskoye 1985 krasnoyarskoye 1972 and vilyuyskoye 1973 table 1 in the validation period i e the outflow was natural until then fig 12q 12r 12s this is particularly of note in krasnoyarskoye figs 10r 11r and 12r and 13r where the regulated outflow is capped at its fixed maximum while the outflow reaches naturalistic peaks 5 study limitations 5 1 basin similarities and reservoir discontinuity the rat and the regulation routine in h hype should continue to be tested in basins of different climatic conditions and basins with different inter reservoir connectivity i e series of cascading reservoirs parallel reservoirs to assess its applicability in modelling at different time and spatial scales these reservoirs are tested in isolation using observed inflow records to nudge the hydrologic model in largely nival basins a study of basin wide sensitivity to the propagation of improved or degraded simulation performance would be useful in determining the degree of upstream effect of each reservoir studies using remote sensing to determine wsls show increasing promise for integrated operational modelling mehran et al 2017 revilla romero et al 2016 as well as more detailed depth surface area modelling rather than as a rectangular prism more accurate than keeping surface area fixed shin et al 2019 while less impressive than the gauged counterparts reservoirs with satellite wsl records russian reservoirs courtesy of g realm are shown to function in h hype treating these results as improving on those available through current a hype the rat should be coupled with remote sensing to further test applicability in even more remote areas such as throughout the arctic in a hype 5 2 regulation stationarity this work holds regulation rules and infrastructure presence constant constant infrastructure assumes that no new control structures will be brought online through 2070 which is already questionable given the construction of the keeyask generating station in the ncrb with a commissioning date in late 2020 this study omits existing regulation points in the basins examined due to record availability such as three reservoirs or generating station forebays on the lower nelson river generation complex in the ncrb and four reservoirs on the angara river downstream of lake baikal the regulated system model assumes an energy future consistent with today s power demand and energy production no alteration to operations this further assumes the daily target wsls selected from the reference period will not change flood and drought stages of reservoirs rarely change as they would require costly infrastructure redesign the extent of the operations stages within the safe limits flood to drought are tied to the seasonality of power demand but by no means stationary although the seasonality of the operations zone is unlikely to change the depth of the zone and its location relative to flood and drought stages easily could as noted by nazemi and wheater 2015b future studies should examine a a systematic scheme for dealing with non stationary parametric estimation or a method examining changing flow regimes such as inflow or temperature as in solander et al 2016 to change the rules used to govern regulation this could be achieved by using the rat to develop different regulation rules from different reference periods updated periodically in multi decade simulations 5 3 fixed parameter sets and full optimization though this method offers more flexibility in the type of outflow used by zone monthly storage outflow storage based etc it carries the associated burden of much higher dimensionality if the historic least squares relationships are to be improved upon by means of a true optimization this progression beyond a generalized parameter set has been shown by yassin et al 2019 to offer largest improvements in those reservoirs with the lowest base performance this optimization could improve those reservoirs currently underperforming e g reindeer lake relative to a hype a full examination of a calibrated parameterization rather than deriving a generalized set based on historic data would further illuminate parametric uncertainty in the model and could be useful in examining the identifiability of both free storage outflow coefficients and exponents and integer zone option flag parameters 6 conclusions the new regulation routine presented herein is applicable to many types of reservoirs or operational schemes and presents more robust results relative to the default regulation routines available in hype i e a hype this synthesis of numerous processes modelled in other macroscale regulation routines as well as the offline analysis system fulfill objectives of 1 and 2 outlined in the introduction section 1 1 by presenting a methodology for automated determination of regulated reservoir stage and outflow relationships used in hype though applicable to any hydrologic model this work presents a possible solution to an ongoing question in continental and global scale hydrologic modelling a general problem with modelling river regulation is that reservoirs can have multiple purposes and must be examined individually arheimer et al 2020 at a global scale the recent worldwide hype model employs 2500 regulated reservoirs arheimer et al 2020 by presenting a viable workflow to parameterize reservoirs using openly available observed records this work hopes to address a need for a method to systematically assess point scale reservoir operations which cumulatively affect the continental to global scale hydrologic cycle in semi distributed hydrologic models the value of this model is proven by examining the results from 15 reservoirs within western canada and four spread across russian rivers these span snow fed hydroelectric plants in the rocky mountains to semi arid canadian prairie water supply reservoirs running the gamut of average daily throughflow from 2 5 m3s 1 in the canadian prairies to 2500 m3s 1 in the largest rivers of siberia an advantage of the h hype regulation routine is that it can be structured as simple as necessary or as complex as data availability allows physical parameters are derived based on historic observations as in yassin et al 2019 and tested for hundreds of combinations of the wsls governing the zones and parameter derivation using the reservoir analysis tool before inclusion in the larger hydrological model and shown to avoid equifinality with few exceptions simulated outflows from the new h hype dam routine generally improve upon those simulated by the existing a hype dam routine this is reflected in the statistical improvement of the long term seasonal regulated outflows and when comparing individual seasons where the h hype routine better adjusts to intra annual storm flood events and interannual prolonged floods and droughts hydro climatic periods in a manner more consistent with the observed record for historic 20 year periods using rules derived from more recent 10 year periods the improvement of h hype over a hype is proven in eight locations in the canadian prairies cited as problem area in previous studies of regulation modelling amir jabbari and nazemi 2019 the majority of results also show improvement in storage proving the routine s ability to simultaneously simulate inter connected elements of reservoir regulation addressing objective 3 of in the introduction further investigation of multiple parameter sets would be of interest in quantifying uncertainty but in estimating parameter sets we prove the utility of this routine and the reservoir analysis tool in simulating reservoir outflow and storage for 19 reservoirs in canada and russia over 30 year periods this employs a methodology which systematically tests multiple combinations of the formulation of a piecewise equation and multiple thresholds of that piecewise equation to replicate simple run of the river hydroelectric plants complex interannually variant or seasonally ice covered and multi use multiple operations goals dependant on seasonal or annual wetness reservoir operations in doing so improvements are made in the simulation of processes which while regulated are often chaotic or tied to human judgement declaration of interest this work was undertaken as part of a series of projects baysys barber 2014 including collaboration with manitoba hydro university of manitoba and supported in part by the natural sciences and engineering research council of canada nserc nserc funding was provided as part of the funding to baysys under crd number 477028 14 manitoba hydro interest in development of study scope and focus was limited to provision of internal reports summarizing reservoir regulation access to extended streamflow and water surface level records and access to in house reservoir regulation model code used in developing governing algorithms no limitations on research scope or focus were imposed and contributions are limited to those noted in text contributions of co authors dr macdonald was instrumental in the prior development of the hudson bay hype h hype model the hydrological predictions for the environment hype sub model developed specifically for this project through his work with the swedish meteorological and hydrological institute smhi dr stadnyk provided guidance on project scope and the editing of the manuscript kristina koenig and phil slota provided industrial knowledge related to the nelson churchill river basin and the manitoba hydro regulated system as well as high level guidance on reservoirs selected for regulation in hydrologic modelling john crawford developed the original cedar lake lake winnipeg sil lake of the woods namakan lake rainy lake and lake st joseph lac seul spreadsheet models phil slota developed the original reindeer lake spreadsheet model john crawford was the primary developer of the ideal storage method used in the h hype regulation routine and designed the reservoir specific sub functions of the spreadsheet models some of these sub functions in the spreadsheet models would later be modified adapted and aggregated to form the basis of the reservoir analysis tool rat and the h hype regulation routine matthew hamilton aided in the coding of the hype regulation routine used in this work all authors contributed to the editing of the manuscript text declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements thanks to university of manitoba manitoba hydro and partners funding through the natural sciences and engineering research council of canada through funding of the baysys project many thanks to manitoba hydro for technical and logistical support of regulation system modelling many thanks to the water survey of canada wsc global runoff data centre grdc and the global reservoirs and lakes monitor g realm for the gathering and dissemination of discharge and wsl data appendix a h hype and a hype governing equations table a1 h hype governing equations equation numbers correspond to figs 3 and 4 symbol θ indicates a parameter derived using the reservoir analysis tool rat from historic records summarized in table a3 table a1 where equation a 1 no conditions w s l o p i d o y i f d o y j θ w s l a v g j 1 θ w s l a v g j f d o y j 1 f d o y j θ w s l a v g j θ o p d e p t h 2 a 2 no conditions w s l o p i d o y i f d o y j θ w s l a v g j 1 θ w s l a v g j f d o y j 1 f d o y j θ w s l a v g j θ o p d e p t h 2 a 3 no conditions w s l t r i w s l o p i θ t r a n s d e p t h a 4 no conditions w s l t r i w s l o p i θ t r a n s d e p t h a 5 no conditions w s l d r θ w s l d r a 6 no conditions w s l f l θ w s l f l a 7 no conditions w s l i 1 w s l i 86400 q i n i q o u t i s a 10 6 p i e t i 10 3 equations a 1 through a 6 compute daily threshold stages for day i describing the seven zones used to determine reservoir outflow drought and flood stages wsl fl wsl dr m are fixed values θ wsl dr θ wsl fl m daily upper and lower bounds of the operations zone wsl op i wsl op i m are computed daily using the target stage θ wsl avg j m for the first day fdoy day of month j the current day of year doy i and the depth of the operations zone θ opdepth m the upper and lower extents of the transition zones wsl tr wsl tr m are specified by the day s operations depths and the depth of the transition zones θ transdepth m the current timestep s total inflow q in i 1 m 3 s 1 computed total outflow q out i1 m 3 s 1 wsl wsl i m precipitation and evaporation off of the lake surface p i et i mm and the reservoir surface area sa km 2 are used to determine the next timestep s wsl as described by equation a 7 these equations are executed for timestep where equation a 8 w s l d r w s l i w s l t r i q l o w i θ f i x e d a l o w s l i w s l d r θ f i x e d b l o a 9 w s l o p i w s l i w s l o p i q o p i θ f i x e d a o p w s l i m i n w s l o p θ f i x e d b o p a 10 w s l t r i w s l i w s l f l q h i i θ f i x e d a h i w s l i m i n w s l o p θ f i x e d b h i equations a 8 a 9 and a 10 compute daily outflow based on a single year round storage outflow curve fixed curve in fig 3 table 3 this curve relates the daily wsl wsl i m to the outflow using two parameters θ fixeda stage θ fixedb stage for each of the low operations and high zones and the depth above the bottom of the current zone wsl dr min wsl op or min wsl op where the bottom of a zone varies throughout the year the stage depth is computed relative to the minimum min wsl stage it is effectively used to mimic a known relationship i e turbine efficiency vs reservoir level spillway geometry weir equations etc these computations are executed at each timestep but only when the stage options φ lo φ op or φ hi for the relevant stages are set to the fixed curve flag value for the primary or secondary outlet this is the case for all high stages for primary outlets where equation a 11 w s l d r w s l i w s l t r i q l o j θ m o n t h l y l o j w s l i w s l d r a 12 w s l d r w s l i w s l t r i q l o i q l o j ω i j q l o j 1 1 ω i j a 13 w s l o p i w s l i w s l o p i q l o b a s e j θ m o n t h l y l o j m i n w s l o p j w s l d r a 14 w s l o p i w s l i w s l o p i q o p j θ m o n t h l y o p j w s l i m i n w s l o p j q l o b a s e i a 15 w s l o p i w s l i w s l o p i q o p i q o p j ω i j q o p j 1 1 ω i j a 16 d o m i 15 ω i j 0 5 d o m i 30 5 a 17 d o m i 15 ω i j 1 5 d o m i 30 5 equations a 11 through a 15 compute daily outflow based on linear monthly storage outflow relationships monthly in fig 3 table 3 equations a 16 and a 17 determines the current day of month s dom i weight between the midpoints of the current month and the next month ω i j this curve relates the daily wsl wsl i m to the outflow using monthly parameters θ monthly stage j for each of the low and operations zones the depth above the bottom of the current zone for the current month wsl dr or min wsl op j the operations zone outflow includes the maximum low zone outflow q lo base j as if they form a compound pair of linear relationships this is used to replicate seasonally variant operations i e increased or decreased hydroelectric demand modified hydraulics based on ice cover etc while bypassing manual calibration these computations are executed at each timestep but only when the stage options φ lo or φ op for the relevant stages are set to the monthly flag value for the primary or secondary outlet where equation a 18 w s l i w s l d r i q d r i θ q d r a 19 w s l i w s l f l i q f l i θ q f l equations a 18 and a 19 compute fixed daily outflow fixed in fig 3 table 3 for drought and flood respectively values are computed based on extrema within historical records θ dr θ fl these values reproduce operations for specified ecological minima or the allowable downstream maxima these computations are executed at each timestep but only when the stage options φ dr or φ fl for the relevant stages are set to the fixed value flag value for the primary or secondary outlet this is the case for all drought stages where equation a 20 no conditions q f l i q h i i equation 20 computes flood zone outflow where high zone operations are extended extend high in fig 3 table 3 since high zone outflow is sensitive to daily level wsl i extending the high zone to flood zone equations results in flood zone outflows intensifying to relieve over burdened reservoirs which is consistent with real world operations these computations are executed at each timestep but only when the flood option φ fl is set to the extend high flag value for the primary or secondary outlet where equation a 21 no conditions q o p i 1 θ i i 13 i q i n i 14 s a 10 6 86400 i 13 i δ s a v g i 14 a 22 no conditions δ s a v g i w s l o p i w s l o p i 1 a 23 w s l i w s l t r i θ i 0 25 a 24 w s l t r i w s l i w s l a v g i θ i 0 25 w s l i w s l o p i θ o p d e p t h w s l t r i w s l o p i θ o p d e p t h a 25 w s l a v g i w s l i w s l t r i θ i 0 25 w s l i w s l o p i θ o p d e p t h w s l t r i w s l o p i θ o p d e p t h a 26 w s l t r i w s l i θ i 0 25 equations a 21 through a 26 are used to determine the daily outflow based on the ideal daily storage operations zone for primary outlets only ideal storage in fig 3 table 3 this method calculates the outflow necessary to reach daily target storage wsl avg i based on the previous two weeks average inflow and the gradient of the target wsl curve this option is employed in reservoirs with limited overlapping outflow and wsl records which prevents development of monthly or year round relationships this method was proposed by john crawford for manitoba hydro for historic and projected simulation of operations this method maintains operations zone wsls very efficiently these computations are executed at each timestep but only when the operations option φ op is set to the ideal storage flag value for the primary outlet where equation a 27 no conditions q i n a v g i i 1 i 7 q i n 7 a 28 no conditions q o u t p r i m a r y a v g i i 1 i 7 q o u t p r i m a r y 7 a 29 no conditions q h i i q i n a v g i q o u t p r i m a r y a v g i equations a 27 a 28 and a 29 compute daily outflow to prevent flooding in a two outlet reservoir high zone for secondary outlets only also called ideal storage in fig 3 table 3 this method uses a seven day inflow gradient to respond to shorter more intense high inflow events this option is used to simulate secondary outlets where the secondary outlet flow is not heavily governed but used to protect reservoir storage or safe levels the two ideal storage options can only be applied to separate zones and separate outlets because in development they made the model unstable if jointly applied these computations are executed at each timestep but only when the high option φ hi is set to the ideal storage flag value for the secondary outlet where equation a 30 no conditions q c o n d a v g i i 14 i 1 q c o n d 14 a 31 w s l d r w s l i w s l f l q o p i θ a c o n d q c o n d a v g i θ b c o n d θ c c o n d θ d c o n d equations a 30 and a 31 compute daily outflow based on the discharge at another sub basin within the model operations zone for main outlet only condition in fig 3 table 3 this option is used where the outflow of a reservoir needs to be limited or increased based on conditions at another gauge station this method uses a four parameter curve θ a cond θ b cond θ c cond and θ d cond to relate the calculated outflow for a reservoir to another sub basin s previous two weeks outflow the application of a conditioned outflow can be automatically selected by the rat but will only create feasible values if a corresponding record or simulated point in h hype is present which pre supposes a degree of understanding of the regulated system these computations are executed at each timestep but only when the high option φ op is set to the condition flag value for the primary outlet where equation a 32 q l o i q d r i q l o i q d r i a 33 q l o i q f l i q l o i q f l i a 34 q h i i q f l i q h i i q f l i a 35 q h i i q d r i q h i i q d r i a 36 q o p i q l o i q o p i q l o i a 37 q o p i q h i i q o p i q h i i a 38 no conditions q t r i q l o i q o p i q l o i w s l i w s l t r i w s l o p i w s l t r i a 39 no conditions q t r i q o p i q h i i q o p i w s l i w s l o p i w s l t r i w s l o p i a 40 w s l i w s l d r i q d e c i q d r i a 41 w s l d r i w s l i w s l t r i q d e c i q l o w i a 42 w s l t r i w s l i w s l o p i q d e c i q t r i a 43 w s l o p i w s l i w s l o p i q d e c i q o p i a 44 w s l o p i w s l i w s l t r i q d e c i q t r i a 45 w s l t r i w s l i w s l f l i q d e c i q h i i a 46 w s l f l i w s l i q d e c i q f l i a 47 q d e c i q o u t i 1 θ δ q q o u t i q o u t i 1 θ δ q a 48 q d e c i q o u t i 1 θ δ q q o u t i q o u t i 1 θ δ q equations a 32 through a 37 run logical corrections equations a 38 and a 39 compute transition flow between low and operations zones q tr i and operations and high zones q tr i based linear interpolation between corrected zonal flows q lo i q op i and q hi i zone stages wsl tr i wsl tr i wsl op i and wsl op i and daily computed wsl wsl i to smooth transitions between operational types equations a40 through a 46 determine the selected outflow for the given outlet primary or secondary q dec i based on the current timestep s wsl wsl i and the stages separating zones wsl dr wsl tr i wsl tr i wsl op i wsl op i wsl fl equations a 47 and a 48 restrict daily changes to outflow based on the historical maximum daily change θ δq these operational restrictions limit maximum change of outflow between two timesteps and are used to simulate operations which might limit potential damage to reservoir infrastructure or downstream municipalities from dramatic changes i e riverbed scour flash flooding wildlife isolation and are computed from historic records 2001 to 2010 table a2 a hype governing equations equation numbers correspond to fig 2 symbol φ indicates a parameter derived using the reservoir analysis tool rat with derivation from historic records summarized in table a3 table a2 where equation a 49 no conditions w s l i 1 w s l i 86400 q i n i q o u t i s a 10 6 p i e t i 10 3 a 50 no conditions q d e f a u l t w s l r e f w s l m i n s a 10 6 86400 a 51 no conditions q p r o d i p r o d 1 a m p sin 2 π d o y i p h a s e 365 a 52 no conditions q e c o n i q p r o d i w s l i w s l l i m w s l l i m w s l m i n a 53 no conditions q s p i l l i r a t e w s l i w s l r e f e x p a 54 w s l i w s l m i n q p r o d i q e c o n i q o u t i q p r o d i a 55 w s l i w s l m i n q p r o d i q e c o n i q o u t i q e c o n i a 56 w s l m i n w s l i w s l r e f q p r o d i q d e f a u l t i q o u t i q d e f a u l t i a 57 w s l m i n w s l i w s l r e f q p r o d i q d e f a u l t i q o u t i q p r o d i a 58 w s l i w s l r e f q p r o d i q s p i l l i q o u t i q p r o d i a 59 w s l i w s l r e f q p r o d i q s p i l l i q o u t i q s p i l l i these equations summarize the outflow and wsl computations used for hydroelectric reservoirs in hype rivers and lakes 2020 equation a 49 computes the daily level as in a 7 equation 50 computes the default outflow for a regulated reservoir q default is the equivalent volume between the minimum and spillway depths φ wsl min and φ wsl ref for a single timestep equation 51 computes the daily production zone target outflow q prod i based on the current day of year doy i and three parameters defining a sine curve φ prod φ amp and φ phase equation 52 computes the daily storage economizing outflow q econ i by linear interpolation below a threshold φ wsl lim equation 53 computes daily outflow representative of a spillway q spill i based on daily wsl wsl i the depth above the dam top φ wsl ref and two parameters computed by log10 least squares regression φ rate and φ exp equations a 54 through a 59 determine the current timestep s outflow based on the current lake depth and relative values of outflow q econ i q default i q prod i and q spill i where equation a 60 no conditions q t h r e s h o l d 1 q m a i n m a x q m a i n m i n f r a c t i o n q m a i n m i n a 61 no conditions q t h r e s h o l d 2 q b r m a x 1 f r a c t i o n q m a i n m i n a 62 no conditions q t h r e s h o l d m a x q t h r e s h o l d 1 q t h r e s h o l d 2 0 a 63 no conditions q t o t a l i q o u t i a 64 q t o t a l i q m a i n m i n q o u t i q t o t a l i a 65 q m a i n m i n q t o t a l i q t h r e s h o l d q o u t i q t o t a l i q m a i n m i n f r a c t i o n q m a i n m i n a 66 q t h r e s h o l d q t o t a l i q t h r e s h o l d q t h r e s h o l d 1 q o u t i q m a i n m a x a 67 q t h r e s h o l d q t o t a l i q t h r e s h o l d q t h r e s h o l d 2 q o u t i q t o t a l i q b r m a x a 68 no conditions q b r i q t o t a l i q o u t i equations a 60 through a 68 are only computed where a second outlet exists equations a 60 a 61 and a 62 compute the threshold main outlet outflow q threshold based on the available parameters equation a 64 computes the daily main outlet outflow when the total available outflow is less than the threshold equation a 65 computes main outlet outflow based on two parameters the minimum main outlet outflow φ qmain min and the fraction of outflow devoted to main outlet φ fraction equation a 66 computes main outlet outflow where a maximum main outlet outflow parameter has been defined φ qmain max equation a 67 computes main outlet outflow where a maximum secondary outlet outflow parameter has been defined φ qbr max equation a 68 computes secondary outlet outflow q br i based on the new main outlet outflow q out i and total available daily outflow q total i main and secondary outlet outflow are used to compute the next timestep s wsl equation a 49 table a3 source of inflow outflow and water surface level datasets by reservoir database data listed as synthetic are computed as summarized in section 3 3 period indicates gauged years used in this work alterations to gauged data unaltered gauges exist at the inlet outlet of a reservoir or gauged drainage area is within 1 of reservoir drainage area scaled up scaled down gauged data are scaled directly by the ratio of gauged and reservoir drainage areas table a3 label reservoir river data id database period alteration reference a abraham reservoir n a wsl 05dc009 wsc 1972 2012 unaltered n saskatchewan river qout 05dc007 wsc 1953 1968 unaltered n saskatchewan river qin 05dc010 wsc 1972 2015 scaled up b oldman reservoir n a wsl 05aa032 wsc 1992 2015 unaltered oldman river qout 05aa023 wsc 1949 2008 scaled down oldman river qin 05aa035 wsc 2009 2015 scaled up oldman river qin synthetic 1981 2008 n a c lake diefenbaker n a wsl 05hf003 wsc 1964 2015 unaltered shook and pomeroy 2016 s saskatchewan river qout 05hg001 wsc 1911 2015 scaled down total inflow qin synthetic 1981 2015 n a d tobin lake n a wsl 05kd004 wsc 1962 2015 unaltered saskatchewan river qout 05kd003 wsc 1962 2015 scaled down total inflow qin synthetic 1981 2015 n a e cedar lake n a wsl 05kl005 wsc 1940 2014 unaltered saskatchewan river qout 05kl001 wsc 1909 2014 unaltered saskatchewan river qin 05kj001 wsc 1913 2016 scaled up f namakan rainy lake n a wsl 05pb007 wsc 1911 2015 unaltered lake of the woods 2006 lwcb n a wsl 05pa003 wsc 1912 2007 unaltered rainy river qout 05pc019 wsc 1905 2015 unaltered seine river qin 05pb009 wsc 1963 2015 scaled up turtle river qin 05pb014 wsc 1914 2015 scaled up namakan river qin 05pa006 wsc 1921 2015 scaled up g lake of the woods n a wsl 05pe012 wsc 1913 2015 unaltered lake of the woods 2006 lwcb winnipeg river e outlet qout 05pe006 wsc 1907 2015 unaltered winnipeg river w outlet qout 05pe011 wsc 1913 2015 unaltered rainy river qin 05pc018 wsc 1928 2015 scaled up h lake st joseph n a wsl 05ga004 wsc 1934 1994 unaltered lake of the woods 2006 lwcb albany river qout 04ga001 wsc 1968 1994 unaltered albany river qout 04gc002 wsc 1970 2015 scaled down albany river qout synthetic 1994 2006 n a root river qout 05qb006 wsc 1957 1994 unaltered root river qout synthetic 1994 2010 n a cat river qin 04ga002 wsc 1970 2015 unaltered i lac seul n a wsl 05qb003 wsc 1917 2015 unaltered lake of the woods 2006 lwcb english river qout 05qe006 wsc 1907 1994 unaltered root river qin 05qb006 wsc 1957 1994 unaltered total inflow qin synthetic 1981 2010 n a j pointe du bois reservoir n a wsl 05pf051 wsc 1928 2015 n a winnipeg river qout 05pf063 wsc 1907 2015 scaled down english river qin 05qe005 wsc 1927 1994 unaltered winnipeg river qin 05pe020 wsc 1892 2010 unaltered winnipeg and english rivers qin synthetic 1994 2015 n a k rafferty reservoir n a wsl 05nb032 wsc 1991 2015 unaltered souris river qout 05nb036 wsc 1992 2015 unaltered souris river qin 05nb017 wsc 1959 2011 scaled up l lake manitoba n a wsl 05lk002 wsc 1923 2015 unaltered fairford river qout 05lm001 wsc 1912 2015 unaltered waterhen river qin 05lh005 wsc 1950 2015 unaltered whitemud river qin 05ll002 wsc 1971 2015 scaled up portage diversion qin 05ll019 wsc 1970 2015 unaltered m lake winnipeg n a wsl 05re003 wsc 1983 2015 unaltered water power licences 2010 manitoba hydro lake winnipeg regulation 2014 a g manitoba hydro nelson river e channel qout 05ub008 wsc 1967 2014 scaled down nelson river jenpeg qout 05ub009 wsc 1975 2014 scaled down dauphin river qin 05lm006 wsc 1077 2015 unaltered saskatchewan river qin 05kl001 wsc 1909 2014 unaltered winnipeg river qin 05pf063 wsc 1907 2014 scaled up red river qin 05oj010 wsc 1962 2008 scaled up pigeon river qin 05rd008 wsc 1957 1996 scaled up beren s river qin 05rd007 wsc 1957 1992 scaled up poplar river qin 05re001 wsc 1967 1996 scaled up total inflow qin synthetic 1981 2014 n a n reindeer lake n a wsl 06db001 wsc 1930 2015 unaltered reindeer river qout 06dd002 wsc 1985 2015 unaltered reindeer river qout 06db002 wsc 1929 1987 unaltered cochrane river qin 06da002 wsc 1968 2015 scaled up wathaman river qin 06dc001 wsc 1071 2015 scaled up o southern indian lake n a wsl 06ec001 wsc 1956 2015 unaltered regional 2015 manitoba hydro water power 1973 province of manitoba final licence 1975 province of manitoba water power 2018 province of manitoba churchill river qin 06eb004 wsc 1973 2015 scaled up churchill river qout 06fb001 wsc 1960 2015 scaled down gauer river qout 06fa001 wsc 1979 2015 scaled down s channel diversion qout 06ec002 wsc 1993 2010 unaltered s channel diversion qout synthetic 1981 1992 n a p novosibiriskoye n a wsl 1378 g realm 1992 2003 unaltered n a wsl 1378 g realm 2008 2019 unaltered ob river qout 2910605 grdc 1958 2000 scaled down karakan river qin 2910635 grdc 1956 1998 scaled up berd river qin 2910650 grdc 1956 2000 scaled up ob river qin 2910606 grdc 1936 2000 scaled up total inflow qin synthetic 1998 2010 n a q sayano shushenskoye n a wsl 0459 g realm 2008 2019 unaltered yenisey qout 2909158 grdc 1911 1999 scaled down us qin 2909250 grdc 1951 1999 scaled up yenisey qin 2909160 grdc 1926 2015 scaled up khemchik qin 2909240 grdc 1975 1993 scaled up kantegir qin 2909313 grdc 1979 1993 scaled up total inflow qin synthetic 1993 2010 n a r krasnoyaraskoye n a wsl 0425 g realm 1992 2019 unaltered yenisey qout 2909156 grdc 1955 1999 scaled down abakan qin 2909260 grdc 1953 2015 scaled up yenisey qin 2909158 grdc 1911 1999 scaled up tuba qin 2909314 grdc 1941 1989 scaled up total inflow qin synthetic 1989 2010 n a s vilyuyskoye n a wsl 0434 g realm 1992 2019 unaltered vilyuy qout 2903703 grdc 1959 1994 scaled down batyr qin 2903750 grdc 1970 1994 scaled up churkuo qin 2903745 grdc 1971 1992 scaled up vilyuy qin 2903704 grdc 1965 2015 scaled up total inflow qin synthetic 1994 2010 n a 
25822,this study develops a novel reservoir regulation routine incorporated into a continental scale hydrologic model in the nelson churchill yenisey ob and lena basins this regulation routine is integrated into the hydrological predictions for the environment hype hydrologic model used for continental scale applications applying this daily timestep regulation routine at 19 reservoirs in the arctic ocean watershed performance is shown to improve upon the reservoir regulation currently available in the hype model when testing outflow and storage nash sutcliffe efficiencies nses improvements stem from intra annually variable storage rule curves and a variety of stage dependent outflow functions improving simulation skill median nse increases of 0 18 over 21 reservoir outflow records and 0 49 over 19 reservoir storage records this new reservoir regulation routine is suitable for continental scale modelling by deriving varying rather than fixed threshold water surface levels and associated outflow rules in a programmatic way for multiple reservoirs keywords hydrologic modelling hydroelectric regulation hudson bay software and data availability hype access to the hydrologic predictions for the environment hype and hydrologic simulation system hyss model codes was granted by the swedish meteorological and hydrologic institute smhi details can be found at https sourceforge net projects hype microsoft excel a commercially available spreadsheet interface tool available with the microsoft office suite of products r rstudio has been used to develop code for estimating reservoir parameters simulating reservoir outflow and storage analyzing simulated data and plotting results data input data used in modelling for reference calibration validation are freely available these are obtained from the water survey of canada wsc https wateroffice ec gc ca the global runoff data centre grdc https portal grdc bafg de and the global reservoir and lake monitoring program g realm https ipad fas usda gov cropexplorer global reservoir 1 introduction in a world increasingly affected by anthropogenic effects it is natural that interest in modelling of damming and reservoir regulation on streamflow would grow alongside increased resolution and scale in hydrologic modelling reservoir regulation exists as an optional extension to some degree of sophistication in most hydrologic models nazemi wheater 2015a 2015b modelling of reservoir regulation is most straightforwardly seen in basin scale studies such as those where regulation has been shown to improve operational modelling piman et al 2016 ahn et al 2014 a practical combination of hydrologic and reservoir modelling is seen in a canada wide study of climate change s effect on hydroelectric production looking to develop empirical relationships between historical climatology and hydroelectric production then projecting these results to a possible future climate amir jabbari and nazemi 2019 this study cites manitoba and saskatchewan studied extensively here as difficult to predict areas due to their streamflow largely originating far upstream of regulation points and having high interannual variability a reasonable solution to this problem is the full integration of hydrologic and reservoir regulation modelling at the watershed or continental scale covering numerous reservoirs simultaneously as computational hydrology has grown to include continental scale studies so too has interest in regulation s effects on continental or global hydrology qin et al 2019 and modelling to simulate anthropogenic impacts and climate change with varying degrees of success yassin et al 2019 coerver et al 2018 arheimer et al 2017 zajac et al 2017 bellin et al 2016 zhao et al 2016 pechlivanidis and arheimer 2015 zhou and guo 2013 pokhrel et al 2012 the hydrological predictions for the environment hype lindström et al 2010 model is proven to be useful for simulating hydrology at the continental scale pechlivanidis and arheimer 2015 but the regulation algorithm can be problematic at that scale due to the need to calibrate reservoir parameters separately from autocalibration this routine has been indirectly evaluated and found to be poorly represented at larger scales and or in data sparse regions arheimer et al 2020 donnelly et al 2014 2016 andersson et al 2015 bergstrand et al 2013 human water interactions reservoir management irrigation etc are also noted as a problem area in other continental scale hydrologic models and global land surface models zaherpour et al 2018 wada et al 2017 wanders and wada 2015 zhou and guo 2013 pokhrel et al 2012 hanasaki et al 2006 a useful survey of the representation of human water interactions in macroscale hydrologic models can be found nazemi and wheater 2015a with regulation of reservoirs implemented into large scale hydrologic modelling studies of sensitivity uncertainty or the effects of climate change at the continental scale become possible studies have created reservoir regulation site specific models developed to be integrated directly into larger hydrological models alvarez et al 2014 welsh et al 2013 li et al 2010a minville et al 2010 minville et al 2009a many studies are developed using historical data and applied to overtly non stationary future climates using dynamically or stochastically optimized methods denaro et al 2017 haguma et al 2014a b haguma et al 2014a b malekmohammadi et al 2009 other canada based studies have used future climatic ensembles and current reservoir operations rules as the work presented in this paper will but instead to analyse reservoir reliability sensitivity or uncertainty hassanzadeh et al 2014 li et al 2010 minville et al 2009b as this work will not an important development in the rarefication of regulation modelling is accounting for intra annual changes to operations due to ice cover inflow regime or hydroelectric demand operational rule curves or optimal release curves based on storage with hedging or with curves optimized dynamically have been validated on historical periods and proposed for operational use prasanchum and kangrang 2018 zhang et al 2017 nunes et al 2016 adeloye et al 2015 taghian et al 2013 liu et al 2011 matrosov et al 2011 an example of the utility of intra annually variable target storage curves is presented in this work in the context of basins with variable interannual climatic variability and intra annual nival regime inflow the effects of future climate change and changing inflow regimes are sure to pass on to reservoir operations the cumulative future effects of regulation and climate change are of growing concern the climate is changing rapidly in northern canada déry et al 2009 2011 leading to changes in the duration and depth of snowpacks kang et al 2014 and ultimately resulting in alteration of both the timing and volume of freshwater export to the arctic ocean at the same time regulation control over freshwater exports for example to the hudson bay complex from the nelson churchill river basin ncrb and la grande rivière complex lgrc have been increasing through time influencing the timing and volume of freshwater exports déry et al 2016 2018 the confluence of the effects of regulation and climate change on hudson bay triggered the onset of the baysys group of projects barber 2014 designed to examine the full extent of these impacts on the marine system of hudson bay of interest is the question is climate change or hydroelectric regulation the primary driver of changes in hudson bay to determine the answer the effects of both drivers must be quantifiably simulated separated and analysed models used to project future terrestrial freshwater exports must be robust in changing climates reliable for long term projections in cold regions and responsive to changing or variable inflow conditions to regulated reservoirs which is often not the case in currently existing hydrological models the hudson bay drainage basin hbdb and those rivers draining to the arctic ocean as a whole contain multiple regulation points reservoirs control structures generating stations diversions etc with close to half of the freshwater of the hbdb by volume impacted by regulation déry et al 2018 and the impact of regulation on environmental factors of note in the yakutia region of russia tyaptirgyanov and tyaptirgyanova 2016 crate 2002 the freshwater systems group team 2 of baysys barber 2014 is tasked with generating two hydrologic models to simulate an ensemble of climate scenarios 1 a regulated system model and 2 a re naturalized model to do so an improved reservoir routine embedded in hype is necessary it must effectively simulate reservoir outflows under natural climatic variability year to year and long term climatic change 30 year periods or longer this will be used to assess anthropogenic influence of hydroelectric regulation on freshwater exports we develop a more robust regulation routine for the hudson bay hype h hype model to simulate regulation of 15 ncrb reservoirs and to test the method on four reservoirs draining to the arctic ocean from russia ob yenisey and lena rivers regulation rules are based on near current operational storage outflow relationships 2001 2010 for the ncrb 1991 to 2000 for the russian reservoirs and do not account for new hydropower developments altered power sales markets or system integration this excludes dynamic or cascading reservoir optimization as has been demonstrated in other studies asadzadeh et al 2014 malekmohammadi et al 2009 cheng and chau 2004 we focus on rivers feeding the nelson and churchill rivers the two largest contributors of freshwater outflows to southwestern hudson bay déry et al 2011 both with increasing anthropogenic influence on their freshwater regimes since the 1970s déry et al 2018 and four reservoirs throughout the russian arctic drainage basin the methods presented aim to include monthly storage targets as seen in yassin et al 2019 while also providing the option for more detailed and dynamic relationships between reservoir level and outflow 1 1 objective the gap this work addresses is that of a reservoir regulation routine suitable for sub basin discretized continental scale modelling that also considers daily target water surface levels to bridge this gap the objective of this work is to develop a reservoir regulation routine which can be applied to multiple reservoirs of significance in our study region simulated using the hype model by analyzing observations in a programmatic fashion it must improve the modelling performance short term and reliability long term of simulated historical outflow in the most influential regulated reservoirs in the ncrb this work also aims to reduce modelling reliance on prescribed outflow as prescribed daily or monthly outflow schedules assume consistent interannual volume and timing of inflow and climatic stationarity by extension to achieve this objective this work is broken into three main steps 1 to develop a broadly applicable regulation routine synthesizing multiple types of processes used in industrial hydroelectric regulation models 2 to develop an offline analysis tool to calibrate reservoir parameters before their inclusion in a continental scale hydrologic model and 3 to test multiple reservoir processes using historic storage outflow relationships and select parameter sets which favour seasonal outflow and storage performance 2 study domains this study focusses on simulating the regulation of 19 reservoirs from five river basins draining to the arctic ocean many of these reservoirs have a theoretical storage time of less than a year no interannual storage fig 1 table 1 according to the modification of the natural river regime these basins are subject to severe nelson and yenisey heavy churchill and ob and moderate lena regulation by the river regulation index presented in grill et al 2015 in the ncrb this regulated storage capacity is heavily leveraged to re apportion the mixed to nival river regime stadnyk et al 2019 to produce a hydrograph more consistent with hydroelectric production needs i e inflows withheld in spring and summer then released consistently throughout the winter déry et al 2018 reservoir physical characteristics and their basin climatic characteristics are presented in tables 1 and 2 locations detailed in fig 1 reservoirs were selected where at least 15 months of overlapping reported water surface level wsl and outflow data were available these 15 months represent a relatively sparse eighth of the 10 year reference period used and sixteenth of the 20 year validation period daily discharge records inflow and outflow are obtained from the water survey of canada wsc 2020 and the global runoff data centre grdc 2020 daily wsl records are obtained from the wsc wsc 2020 and reservoir levels at a 10 day repeat are obtained from the united states department of agriculture s foreign agricultural service global reservoirs and lakes monitor database g realm usda fas 2020 reservoir surface areas and depths are obtained from the global lake and wetland database glwd lehner and döll 2004 the global lake database v2 kourzeneva 2010 and the global reservoir and dam database v1 1 grand lehner et al 2016 reservoir upstream area is reported from the arctic hype a hype andersson et al 2015 hydrologic model live depth is the computed depth between the historic minimum and maximum wsls since the onset of reservoir operations post filling live storage is computed as the live depth multiplied by the reservoir surface area hype reservoirs are modelled as rectangular prisms accounting for no dynamic surface area detention time is the ratio of live storage to average inflow over the period 1971 to 2015 fig 1 table 2 reservoirs simulated in this study have theoretical detention times between 0 2 and 24 months examining the skill in simulation of run of the river reservoirs little to no detention time and large multi year reservoirs can theoretically store more than 12 months of inflow mean annual upstream climatic conditions total precipitation snowfall rainfall temperature potential evapotranspiration and runoff are computed from a hype using the hydrological global forcing dataset for daily precipitation daily max temperature daily min temperature hydrogfd berg et al 2018 abraham lake in the canadian rocky mountains and the rafferty reservoir in the canadian prairies represent the extremes in runoff ratio equivalent runoff depth relative to total precipitation depth 0 79 and 0 08 respectively table 2 aridity index total precipitation relative to potential evapotranspiration 2 38 and 0 52 respectively table 2 and snowfall ratio snowfall relative to total precipitation 0 57 and 0 19 respectively table 2 remaining reservoirs span the gamut between these extremes representing various combinations of dryness snowfall and runoff efficiency this gives a broad base of reservoir types excluding rainforest or tropical conditions on which to test a new reservoir regulation routine 3 methods and models the skill of the hype model in simulating reservoir regulation has been tested for 19 reservoirs using two algorithms the first is that belonging to hype in its current release the second is that developed herein the existing regulation algorithm in arctic hype version 3 a hype hereafter andersson et al 2015 is described as well as the development of the regulation used in hudson bay hype h hype hereafter stadnyk et al 2020 3 1 a hype dam routine the hype hydrological model lindström et al 2010 developed by the swedish meteorological and hydrological institute smhi discretizes watersheds to sub basins any of which can be in part or in full a lake or reservoir computation of the reservoir level and outflow is governed by a routine that simulates reservoir regulation this hype dam routine includes sub routines for four dam purposes 1 flood control 2 water supply 3 irrigation and 4 hydroelectric reservoirs can use one or two outlets to simulate diversions the existing hype routine for regulated dams focusses on physically based variables to produce a target daily outflow complete details regarding the routines governing dam outflow operations in hype can be found on smhi s hype wiki under the rivers and lakes section river and lakes 2020 reservoirs in hype are modelled as rectangular storage units with uniform surface area and variable level computation of outflow by time step will access different elements of piecewise functions using the wsl computed for the previous time step and two threshold parameters called minimum stage and reference stages in fig 2 these stages divide the reservoir into three zones low flow zone below minimum stage spillway flow zone above reference stage and production flow zone between minimum and reference stages how much or little water is discharged daily from the reservoir in the production flow zone will depend on the dam s purpose specified by the user all reservoirs compared in this work were calibrated using the existing hype regulation routine stadnyk et al 2019 2020 as hydroelectric dams with a sine curve outflow when in the production zone fig 2 equation a 51 table a2 appendix a a weir type equation in the spillway zone fig 2 equation a 53 table a2 appendix a these relationships result in seven parameters for single outlet reservoirs two wsl thresholds three sine function parameters amplitude phase mean and two parameters for the spillway coefficient and exponent of a power curve four additional parameters are added for bifurcated branched reservoirs minimum and maximum main outlet flow maximum branch flow and the desired fraction of total flow to the branched outlet rivers and lakes 2020 methods exist in a hype to specify two means of the sine function split by two datums expressed in days these methods are not employed here as the means to split historical records intra annually by varying dates are not considered 3 2 h hype dam routine development a new reservoir regulation routine is presented for the hype model tested in r to be written into hype in fortran access to the hype code was provided by smhi for the purposes of this project this new routine ties together operations and modelled state variables maintaining applicability to reservoirs of many types of operation and many sizes this applicability allows the routine to be applied to any reservoir which modellers wish to represent with a minimum of operational knowledge necessary prior to running the model the new routine formulation is the synthesis of the processes of nine reservoir regulation models developed by manitoba hydro each governing a single reservoir as in a hype each of these models uses a fixed set of stage wise processes i e monthly storage outflow curves minimum ecological outflow target outflow by day of year etc for a varying number of reservoir thresholds fixed stages or stage curves a model is developed with multiple possible formulations fig 3 of the piecewise function governing outflow with parameters derived from historical stage outflow relationships the reservoir is divided into five zones based on two fixed stages and two stage curves the zone and level of the reservoir for each simulated time step will dictate outflow equation used and overall volume of outflow for timestep i month j general versions of the formulation are presented stages zones and options for each zone are summarized in fig 3 fixed value equations a 18 and a 19 table a1 appendix a indicates that when the simulated wsl is in that zone the outflow is a fixed value allowable maximum or minimum monthly equation 1 below equations a 11 to a 17 table a1 appendix a indicates a monthly linear storage outflow relationship for wsls within that zone for that month above wsl β j which varies monthly fixed curve equation 2 below equations a 8 to a 10 table a1 appendix a indicates an exponential storage outflow relationship within that zone above wsl δ ideal storage equation 3 below equations a 21 to a 29 table a1 appendix a methods use the distance between the current day s wsl and the target storage curve θ not a parameter as well the previous two weeks inflow and previous two weeks gradient of the target storage curve to dictate outflow condition equation 4 below equations a 30 and a 31 table a1 appendix a indicates a relationship between the outflow of the reservoir and an external timeseries outflow of another sub basin fifteen parameters govern the threshold stages of wsl 12 parameters for target storage on the first day of each month the depth of the operations zone the flood stage and the drought stage fixed values introduce two parameters flood maximum and drought minimum outflow per outlet monthly relationships 24 one coefficient α j per month two zones per outlet fixed curves six one coefficient γ and power ε three zones per outlet with an additional parameter for maximum daily change of outflow conditional flow introduces four parameters μ ρ τ and ω 1 q i α j w s l i w s l β j 2 q i γ w s l i w s l δ ε 3 q i θ 1 i 13 i q i n i 14 i 13 i s i s i 1 14 4 q i μ q e x t e r n a l ρ τ ω the applicability of this routine is tested by deriving parameters stage outflow relationships derived based on paired observed data from a reference period not calibrated and simulating outflow and storage over 30 years the use of this new regulation routine is meant as a proof of concept to demonstrate that a diverse set of reservoirs can be simulated using paired observed data without prior knowledge of reservoir operations the routine presented does not pre suppose a prior understanding of what processes govern outflow computation within different zones of the reservoir excluding drought zone for any given reservoir and uses an offline tool r function external to the hype model to test combinations of processes and select the optimal set of processes by testing multiple combinations of piecewise flow processes referred to as zone options figs 3 and 4 table 3 we avoid applying empirical regulation codes based on real world operations specific to individual reservoirs this aims to avoid the black box effect kirchner 2006 if coded directly into a hydrologic model this routine aims to reduce parametric uncertainty an issue highlighted by beven 2012 juston et al 2013 by making use of physically based processes rather unlike operation schemes using neural networks or hidden logic which have also been applied successfully in macro scale modelling schemes coerver et al 2018 ehsani et al 2016 an important element of this routine is the interannually variable storage rule curves which govern the low operations and high zone in h hype fig 3 rather than fixed thresholds for piecewise operations throughout the year three zones in a hype fig 2 use of variable target storage values throughout the year are shown to improve reservoir model performance yassin et al 2019 wu and chen 2012 by imposing seasonally or monthly variant thresholds to reservoir outflow behaviour for each reservoir a statistically optimal set of options process dictating outflow for each zone is generated by the reservoir analysis tool rat section 3 3 reported in table 3 a description of the function of the regulation routine within each timestep is shown in fig 4 it further helps describe the use of the daily outflow to calculate storage calculated from the wsl for the next timestep section 3 4 describes the process used to systematically mix the integer parameters and wsl limits for both models section 4 describes the results of these multiple simulations optimal storage outflow relationships whether linear monthly or fixed curve are derived using the rat and near current wsl and outflow records 2001 2010 for canadian reservoirs 1991 to 2000 for russian reservoirs referred to as the reference period this reference period is selected to provide the most up to date possible regulation rules for the studied historical period though these equations introduce parameters to the formulation the parameters are designed to be kept fixed relative to a set of governing stages in this way because the parameters are related to historical physical observations they are similar to other fixed variables such as reservoir surface area in that they are untouched by optimization using fixed parameters based on historical storage outflow relationships is proven to provide adequate though not optimal modelling of reservoirs performance compared to simpler methods referred to as a generalized parameter set by yassin et al 2019 while offering the option to improve performance with a full optimization with 610 sets of wsls tested here to vary the stage discharge relationships the a hype parameters defining the minimum stage and spillway stage are defined as the minimum and maximum limits of the derived h hype operations stage curves wslop and wslop respectively fig 3 parameters defining the storage outflow relationship of the spillway curve equation a 28 table a1 appendix a are derived using lsr on all paired data above the spillway stage wslreference fig 2 log transformed to linearize the data parameters defining the sine curve are computed using observed outflow where wsl falls in the defined operations zone fig 2 errors are minimized between a synthetic sine curve using amplitude mean and phase and that defined by the reference period production zone average annual daily equation a 27 table a appendix a 3 3 reservoir analysis tool rat before introducing new reservoirs to h hype reservoir process selection narrowing the zone options of fig 3 to a single set as shown in fig 4 details in table 3 is automated using the rat this tool replicates the routine added to h hype without the need to run an entire hype simulation to directly compare the skill of the reservoir regulation rather than the full hydrologic model reservoirs were compared by supplying each reservoir with its observed daily inflow timeseries precipitation onto reservoirs is taken from the hydrogfd dataset and reservoir evaporation losses are calculated in a hype using the priestley taylor method where the difference between maximum and minimum daily air temperature approximates radiative forcing processes above ground 2020 and assuming that lakes act as free evaporation surfaces each reservoir is simulated as a sub basin in a hype and h hype eliminating the need for a volume and or momentum based methods to pass water within a reservoir between grid cells or sub basins as seen in shin et al 2019 functioning of the rat offline from hype relies on complete inflow records these are developed for each reservoir using public records from the wsc grdc or using synthetic methods shorter gaps in observed inflow records 2 days were filled using linear interpolation where significant gaps exist in inflow records 2 days gap filling was performed using the next upstream gauge available from the wsc 2020 or grdc 2020 and proportional drainage area scaling déry et al 2005 2011 hernández henríquez et al 2010 outflow and wsl are not gap filled since these data are used exclusively to evaluate performance and develop storage outflow relationships these records can be found in table a3 appendix a where no inflow data are available synthetic time series of inflow are generated these are created using the relationship between throughflow and storage equations 5 and 6 where sa reservoir surface area m2 q in daily inflow m3 day 1 q out daily outflow m3 day 1 wsl daily water surface level m δs is daily storage change m3 p daily precipitation mm et daily total evapotranspiration mm between days i and i 1 or δt timestep day records were further synthetically extended by using the average annual daily value of existing data these existing gaps are ignored during statistical calculations so as not to introduce added uncertainty into parameter estimation uses of full records and synthetic inflow series are summarized in table a3 appendix a table a1 appendix a presents the input records used for parameter derivation outflow and wsl and simulation inflow precipitation and evaporation 5 s a w s l i w s l i 1 δ s δ t q i n i q o u t i 1 s a p e t 10 3 6 q i n i s a w s l i w s l i 1 δ t e t p 10 3 q o u t i 1 the scope of the baysys group of projects excludes optimization of cascading reservoirs reservoirs are calibrated individually on their individual skill scores not on an aggregated basin wide score regulation rules are also designed to be static these rules do not change or adapt to future climatological conditions to achieve reliable results with these static rules the reservoir operation routines must strive to maintain desirable reservoir levels rather than dictating optimal outflow values as inflow volume and timing are likely to change in the future dynamic optimization of reservoirs for power production or financial gain is ignored with the maintenance of reservoir levels consistent with historic operations prioritized instead 3 4 optimal selection the rat simulates 610 sets of stage limits by modifying operations depth operations shift and extreme stage depth in h hype described in section 3 2 ranges presented in fig 5 which relate to wslminimum and wslreference a hype evaluating all h hype zone option combinations 16 for a single outlet or 256 for a double outlet reservoir and the associated a hype options 1 for a single outlet or 2 for a double outlet reservoir for each set of stage limits outflow and storage performance of 610 16 9760 or 610 256 156160 timeseries for h hype 610 or 1220 timeseries for a hype is used to select an optimal parameterization for each model this selection is based on the performance of daily timeseries in the reference period 1 january 2001 to 31 december 2010 for canadian and 1 january 1991 to 31 december 2000 for russian reservoirs these periods are split into seasonal timeseries using standard hydrological seasons winter djf spring mam summer jja autumn son this performance is then validated for an earlier period 1 january 1981 to 31 december 2000 for canadian and 1 january 1971 to 31 december 1990 for russian reservoirs reference periods are selected to maximize overlapping wsl and outflow records with validation periods taken as the preceding twenty years the combined outflow and storage performance is computed to select the optimal stage limits and zone options this is taken as the sum of seasonal outflow and storage nash sutcliffe efficiencies nse nash and sutcliffe 1970 of daily timeseries 4 seasons 2 variables 8 where there were two outlets the sum of nses for all seasons for storage and outlets is optimized 4 seasons 3 variables 12 seasonal nse is used rather than the seasonal kling gupta efficiencies kge gupta et al 2009 due to the nse being shown to be more sensitive in calibration of reservoir regulation in h hype stadnyk et al 2020 the ideal combination of zone options and stages table 3 is selected as the greatest sum of nses the number of equifinal solutions are listed in table 3 as a fraction of the total number of combinations assessed equifinality is seen in a hype in both reservoirs with two outlets lake st joseph and southern indian lake h and o in figs 6 to 12 and two others abraham and rafferty reservoirs and two reservoirs in h hype two matching optima in each case in both models these values represent a negligible fraction of the total range of wsls a hype and h hype or integer options h hype tested 4 results and discussion fig 6 presents the a hype and h hype values of nse for continuous daily timeseries n 3652 for reference and n 7304 for validation periods the sums of seasonal statistics maximum sum of nses are used to inform the selection of processes in the rat the selected best performing rat parameter set is shown for each outlet as well as its a hype counterpart with the optimal performance for two performance metrics nse and percent error of standard deviation presented for both models reference and validation periods outflow and storage in tables 4 and 5 and mapped spatially in figs 8 and 9 testing 610 sets of base wsl characteristics fig 5 and evaluating all possible simulations with related parameters gives a range of results for both models examining boxplot performance the bottoms of the interquartile ranges fig 6 of the full timeseries h hype are in some cases higher than the top of a hype for the same this is the case for the full timeseries annual storage in 10 reference and 7 validation of 19 reservoirs and outflow in 13 reference and 8 validation of 21 outlets fig 6 this demonstrates that not only is the optimal solution improved figs 7 9 tables 4 5 there is increased probability of stronger performance even if the selection of an optimum may contain uncertainty such as that due to the choice of selection metric seasonal improvements can be seen in the daily optimal simulation figs 12 and 13 as well as in the mean regime average annual daily figs 10 and 11 over the 30 years of the reference and validation combined periods fig 7 presents the optimal results selected for each reservoir also seen in fig 6 in nine and eight of 21 outlets for validation and reference respectively fig 7 the nse of outflow simulated in h hype is greater than 0 5 considered the threshold for satisfactory performance for watershed scale hydrological simulation by moriasi et al 2015 compared to three and five for the same in a hype while these results are initially underwhelming we must remember that these simulations are governed by historical relationships i e storage outflow relationships compared against measured data which are governed by human judgement highly interconnected operational systems and individual dam operators this does not excuse poor nse performance but should be considered when contextualizing the difficulty in simulating short scale human operations rather than the predictable physically based processes of the environment assessing the optimal nse performance of reservoir outflow and storage table 4 figs 7 9 we see an improvement using the h hype regulation in the reference period median nse improves by 0 18 and 0 49 for outflow and storage where a hype results less than 3 5 are excluded figs 7 9 this reference period 2001 2010 for canadian and 1991 to 2000 for russian reservoirs is where the paired wsl and outflow data are used to develop the parameters and due to the added parameterization of the new routine improved performance here is expected as seen in the lighter shaded region in figs 12 and 13 in the validation period median nse improvement is by 0 10 and 0 20 for outflow and storage again where a hype results less than 3 5 are excluded figs 7 9 outflow results improve by more than 0 1 in 14 and change by a nominal amount 0 1 in four of 21 outlets in the reference period fig 8a and b and improve in nine and change by a nominal amount in five of 21 outlets in the validation period fig 8c and d storage results improve in 14 and change by a nominal amount in four of 19 reservoirs in the reference period fig 9a and b and improve in 10 and change by a nominal amount in two of 15 reservoirs for the validation period no validation data available for storage in russian reservoirs fig 9c and d because reservoirs are modelled with observed inflow there is no spatial pattern to improvements in nse fig 7 and 8 due to cascading results despite a lack of spatial pattern these show improvement over a hype with few exceptions these results suggest that in the majority of instances the model is better able to react to interannual climatic and intra annual i e shorter duration floods variability and correctly apportion water exiting the reservoir seasonally for both the reference and validation historic periods 1981 2010 for canadian 1971 to 2000 for russian reservoirs it further proves that the storage is better maintained at the seasonal resolution for that same period improvements of seasonal storage performance are important to long term reliability of results and shown to improve in the majority of presented reservoirs data availability in this period 1981 to 2000 for canadian and 1971 to 1990 for russian reservoirs is more variable with no wsl data available for the russian reservoirs in this period despite the relative sparsity of observation data and the fact that the regulation rules are derived in the future of these observations have not yet known performance is still shown to improve using h hype over a hype and in fact shows a greater median improvement than the reference period we further assess changes to the relative error of the standard deviation res table 5 a component of the kling gupta efficiency and a practical measure of the simulation skill at replicating sub weekly reservoir operations or longer scale climatic variability the effects of weekly operations can be seen particularly in hydroelectric reservoirs déry et al 2018 the absolute value of res by using h hype improves by a median of 8 9 and 6 4 percent for outflow and storage respectively excluding a hype errors exceeding 100 these present a reduction of error and therefore a closer approximation of the measured variability in the validation period the median change to res is 7 6 and 15 percent for outflow and storage respectively again excluding a hype errors exceeding 100 in this sense the variability of the outflow and storage are improved over ahype for both reference and validation periods average annual hydrographs are presented to qualitatively compare a hype and h hype skill at predicting yearly flow regime relative to observations each day represents the 30 year average outflow by day of year reference and validation together day of the week is not considered as seen in déry et al 2018 and as such hydro peaking and statutory holiday effects are generally not visible these offer an assessment of the skill of the seasonality and sub seasonal model responses fig 10 shows an improved seasonality across the majority of reservoirs for outflow regardless of the shape of observed outflow seasonality h hype shows qualitative improvements in dynamic systems with high interannual variability except in the case of cedar lake fig 10e lake manitoba fig 10l sayano shushenskoye fig 10q and krasnoyarskoye fig 10r this is seen in the case of lake manitoba fig 11l for wsl as well sayano shushenskoye and vilyuyskoye have very limited records of overlapping wsl outflow data fig 1 this limits the ability to parameterize the model based on historic observations notable improvements are shown in pointe du bois reservoir figs 10j and 11j rafferty reservoir figs 10k and 11k southern indian lake fig 10o1 10o2 11o1 and novosibiriskoye figs 10p and 11p for both outflow and wsl in the case of southern indian lake a reservoir with two outlets improvements are shown in each outlet leading to improved seasonality in both and as a result storage skill at simulating mean regime over climatic scale periods 30 years is important for long term simulation but over and above improvements to 30 year mean seasonality skill in daily outflow and wsl is important to examine instances of the most robust hydrograph improvements arise in reservoirs with the greatest interannual variability of water supply whether by variable inflow or by p pet ratio table 2 such as lake diefenbaker figs 10c and 12c and oldman reservoir figs 10b and 11b this is also seen in reservoirs with less predictable behaviour such as the hydrograph drawdown operations seen in lake winnipeg august to october fig 10m or tobin lake may to june fig 10d reservoirs with interannual variability in water surface level also show improvement such as namakan rainy lake figs 11f and 13f and lake of the woods figs 11g and 13g in both cases these reservoirs fail to be as well represented by the a hype prescribed sine curve target outflow but are more accurately captured by h hype where outflow is more sensitive to daily storage and daily storage is sensitive to an intra annually variable curve target storage improvements to performance and the h hype performance itself are more variable in the russian reservoirs than their canadian counterparts simulation of average storage and storage intra annual variability are improved by h hype in all russian reservoirs fig 13p 13q 13r 13s outflow performance in russian reservoirs is improved and greater than 0 5 for novosibiriskoye fig 10p and improved though unsatisfactory for vilyuyskoye fig 10s performance of the yenisey river reservoirs outflow fig 10q 10r improve in the reference period though they are unsatisfactory and degrade in the validation period any improvements to skill are related to the length of synchronous wsl and outflow records fig 1 distribution of records throughout the year will provide improved parameter estimation over seasonal gauge records simulating multiple sets of governing wsls which dictate the parameter estimation a suite of h hype parameter sets is assessed to determine the optimal formulation for each reservoir in the case of the russian reservoirs the period of overlap is much shorter greater than 1 full year but generally less than 4 where the canadian records are closer to the full 10 year reference period the wsl records of russian reservoirs are derived from a 10 day satellite pass which will also account for consistent gaps in the records the poor performance in the validation period of the russian discharge stations is also due to three of the four stations being commissioned sayano shushenskoye 1985 krasnoyarskoye 1972 and vilyuyskoye 1973 table 1 in the validation period i e the outflow was natural until then fig 12q 12r 12s this is particularly of note in krasnoyarskoye figs 10r 11r and 12r and 13r where the regulated outflow is capped at its fixed maximum while the outflow reaches naturalistic peaks 5 study limitations 5 1 basin similarities and reservoir discontinuity the rat and the regulation routine in h hype should continue to be tested in basins of different climatic conditions and basins with different inter reservoir connectivity i e series of cascading reservoirs parallel reservoirs to assess its applicability in modelling at different time and spatial scales these reservoirs are tested in isolation using observed inflow records to nudge the hydrologic model in largely nival basins a study of basin wide sensitivity to the propagation of improved or degraded simulation performance would be useful in determining the degree of upstream effect of each reservoir studies using remote sensing to determine wsls show increasing promise for integrated operational modelling mehran et al 2017 revilla romero et al 2016 as well as more detailed depth surface area modelling rather than as a rectangular prism more accurate than keeping surface area fixed shin et al 2019 while less impressive than the gauged counterparts reservoirs with satellite wsl records russian reservoirs courtesy of g realm are shown to function in h hype treating these results as improving on those available through current a hype the rat should be coupled with remote sensing to further test applicability in even more remote areas such as throughout the arctic in a hype 5 2 regulation stationarity this work holds regulation rules and infrastructure presence constant constant infrastructure assumes that no new control structures will be brought online through 2070 which is already questionable given the construction of the keeyask generating station in the ncrb with a commissioning date in late 2020 this study omits existing regulation points in the basins examined due to record availability such as three reservoirs or generating station forebays on the lower nelson river generation complex in the ncrb and four reservoirs on the angara river downstream of lake baikal the regulated system model assumes an energy future consistent with today s power demand and energy production no alteration to operations this further assumes the daily target wsls selected from the reference period will not change flood and drought stages of reservoirs rarely change as they would require costly infrastructure redesign the extent of the operations stages within the safe limits flood to drought are tied to the seasonality of power demand but by no means stationary although the seasonality of the operations zone is unlikely to change the depth of the zone and its location relative to flood and drought stages easily could as noted by nazemi and wheater 2015b future studies should examine a a systematic scheme for dealing with non stationary parametric estimation or a method examining changing flow regimes such as inflow or temperature as in solander et al 2016 to change the rules used to govern regulation this could be achieved by using the rat to develop different regulation rules from different reference periods updated periodically in multi decade simulations 5 3 fixed parameter sets and full optimization though this method offers more flexibility in the type of outflow used by zone monthly storage outflow storage based etc it carries the associated burden of much higher dimensionality if the historic least squares relationships are to be improved upon by means of a true optimization this progression beyond a generalized parameter set has been shown by yassin et al 2019 to offer largest improvements in those reservoirs with the lowest base performance this optimization could improve those reservoirs currently underperforming e g reindeer lake relative to a hype a full examination of a calibrated parameterization rather than deriving a generalized set based on historic data would further illuminate parametric uncertainty in the model and could be useful in examining the identifiability of both free storage outflow coefficients and exponents and integer zone option flag parameters 6 conclusions the new regulation routine presented herein is applicable to many types of reservoirs or operational schemes and presents more robust results relative to the default regulation routines available in hype i e a hype this synthesis of numerous processes modelled in other macroscale regulation routines as well as the offline analysis system fulfill objectives of 1 and 2 outlined in the introduction section 1 1 by presenting a methodology for automated determination of regulated reservoir stage and outflow relationships used in hype though applicable to any hydrologic model this work presents a possible solution to an ongoing question in continental and global scale hydrologic modelling a general problem with modelling river regulation is that reservoirs can have multiple purposes and must be examined individually arheimer et al 2020 at a global scale the recent worldwide hype model employs 2500 regulated reservoirs arheimer et al 2020 by presenting a viable workflow to parameterize reservoirs using openly available observed records this work hopes to address a need for a method to systematically assess point scale reservoir operations which cumulatively affect the continental to global scale hydrologic cycle in semi distributed hydrologic models the value of this model is proven by examining the results from 15 reservoirs within western canada and four spread across russian rivers these span snow fed hydroelectric plants in the rocky mountains to semi arid canadian prairie water supply reservoirs running the gamut of average daily throughflow from 2 5 m3s 1 in the canadian prairies to 2500 m3s 1 in the largest rivers of siberia an advantage of the h hype regulation routine is that it can be structured as simple as necessary or as complex as data availability allows physical parameters are derived based on historic observations as in yassin et al 2019 and tested for hundreds of combinations of the wsls governing the zones and parameter derivation using the reservoir analysis tool before inclusion in the larger hydrological model and shown to avoid equifinality with few exceptions simulated outflows from the new h hype dam routine generally improve upon those simulated by the existing a hype dam routine this is reflected in the statistical improvement of the long term seasonal regulated outflows and when comparing individual seasons where the h hype routine better adjusts to intra annual storm flood events and interannual prolonged floods and droughts hydro climatic periods in a manner more consistent with the observed record for historic 20 year periods using rules derived from more recent 10 year periods the improvement of h hype over a hype is proven in eight locations in the canadian prairies cited as problem area in previous studies of regulation modelling amir jabbari and nazemi 2019 the majority of results also show improvement in storage proving the routine s ability to simultaneously simulate inter connected elements of reservoir regulation addressing objective 3 of in the introduction further investigation of multiple parameter sets would be of interest in quantifying uncertainty but in estimating parameter sets we prove the utility of this routine and the reservoir analysis tool in simulating reservoir outflow and storage for 19 reservoirs in canada and russia over 30 year periods this employs a methodology which systematically tests multiple combinations of the formulation of a piecewise equation and multiple thresholds of that piecewise equation to replicate simple run of the river hydroelectric plants complex interannually variant or seasonally ice covered and multi use multiple operations goals dependant on seasonal or annual wetness reservoir operations in doing so improvements are made in the simulation of processes which while regulated are often chaotic or tied to human judgement declaration of interest this work was undertaken as part of a series of projects baysys barber 2014 including collaboration with manitoba hydro university of manitoba and supported in part by the natural sciences and engineering research council of canada nserc nserc funding was provided as part of the funding to baysys under crd number 477028 14 manitoba hydro interest in development of study scope and focus was limited to provision of internal reports summarizing reservoir regulation access to extended streamflow and water surface level records and access to in house reservoir regulation model code used in developing governing algorithms no limitations on research scope or focus were imposed and contributions are limited to those noted in text contributions of co authors dr macdonald was instrumental in the prior development of the hudson bay hype h hype model the hydrological predictions for the environment hype sub model developed specifically for this project through his work with the swedish meteorological and hydrological institute smhi dr stadnyk provided guidance on project scope and the editing of the manuscript kristina koenig and phil slota provided industrial knowledge related to the nelson churchill river basin and the manitoba hydro regulated system as well as high level guidance on reservoirs selected for regulation in hydrologic modelling john crawford developed the original cedar lake lake winnipeg sil lake of the woods namakan lake rainy lake and lake st joseph lac seul spreadsheet models phil slota developed the original reindeer lake spreadsheet model john crawford was the primary developer of the ideal storage method used in the h hype regulation routine and designed the reservoir specific sub functions of the spreadsheet models some of these sub functions in the spreadsheet models would later be modified adapted and aggregated to form the basis of the reservoir analysis tool rat and the h hype regulation routine matthew hamilton aided in the coding of the hype regulation routine used in this work all authors contributed to the editing of the manuscript text declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements thanks to university of manitoba manitoba hydro and partners funding through the natural sciences and engineering research council of canada through funding of the baysys project many thanks to manitoba hydro for technical and logistical support of regulation system modelling many thanks to the water survey of canada wsc global runoff data centre grdc and the global reservoirs and lakes monitor g realm for the gathering and dissemination of discharge and wsl data appendix a h hype and a hype governing equations table a1 h hype governing equations equation numbers correspond to figs 3 and 4 symbol θ indicates a parameter derived using the reservoir analysis tool rat from historic records summarized in table a3 table a1 where equation a 1 no conditions w s l o p i d o y i f d o y j θ w s l a v g j 1 θ w s l a v g j f d o y j 1 f d o y j θ w s l a v g j θ o p d e p t h 2 a 2 no conditions w s l o p i d o y i f d o y j θ w s l a v g j 1 θ w s l a v g j f d o y j 1 f d o y j θ w s l a v g j θ o p d e p t h 2 a 3 no conditions w s l t r i w s l o p i θ t r a n s d e p t h a 4 no conditions w s l t r i w s l o p i θ t r a n s d e p t h a 5 no conditions w s l d r θ w s l d r a 6 no conditions w s l f l θ w s l f l a 7 no conditions w s l i 1 w s l i 86400 q i n i q o u t i s a 10 6 p i e t i 10 3 equations a 1 through a 6 compute daily threshold stages for day i describing the seven zones used to determine reservoir outflow drought and flood stages wsl fl wsl dr m are fixed values θ wsl dr θ wsl fl m daily upper and lower bounds of the operations zone wsl op i wsl op i m are computed daily using the target stage θ wsl avg j m for the first day fdoy day of month j the current day of year doy i and the depth of the operations zone θ opdepth m the upper and lower extents of the transition zones wsl tr wsl tr m are specified by the day s operations depths and the depth of the transition zones θ transdepth m the current timestep s total inflow q in i 1 m 3 s 1 computed total outflow q out i1 m 3 s 1 wsl wsl i m precipitation and evaporation off of the lake surface p i et i mm and the reservoir surface area sa km 2 are used to determine the next timestep s wsl as described by equation a 7 these equations are executed for timestep where equation a 8 w s l d r w s l i w s l t r i q l o w i θ f i x e d a l o w s l i w s l d r θ f i x e d b l o a 9 w s l o p i w s l i w s l o p i q o p i θ f i x e d a o p w s l i m i n w s l o p θ f i x e d b o p a 10 w s l t r i w s l i w s l f l q h i i θ f i x e d a h i w s l i m i n w s l o p θ f i x e d b h i equations a 8 a 9 and a 10 compute daily outflow based on a single year round storage outflow curve fixed curve in fig 3 table 3 this curve relates the daily wsl wsl i m to the outflow using two parameters θ fixeda stage θ fixedb stage for each of the low operations and high zones and the depth above the bottom of the current zone wsl dr min wsl op or min wsl op where the bottom of a zone varies throughout the year the stage depth is computed relative to the minimum min wsl stage it is effectively used to mimic a known relationship i e turbine efficiency vs reservoir level spillway geometry weir equations etc these computations are executed at each timestep but only when the stage options φ lo φ op or φ hi for the relevant stages are set to the fixed curve flag value for the primary or secondary outlet this is the case for all high stages for primary outlets where equation a 11 w s l d r w s l i w s l t r i q l o j θ m o n t h l y l o j w s l i w s l d r a 12 w s l d r w s l i w s l t r i q l o i q l o j ω i j q l o j 1 1 ω i j a 13 w s l o p i w s l i w s l o p i q l o b a s e j θ m o n t h l y l o j m i n w s l o p j w s l d r a 14 w s l o p i w s l i w s l o p i q o p j θ m o n t h l y o p j w s l i m i n w s l o p j q l o b a s e i a 15 w s l o p i w s l i w s l o p i q o p i q o p j ω i j q o p j 1 1 ω i j a 16 d o m i 15 ω i j 0 5 d o m i 30 5 a 17 d o m i 15 ω i j 1 5 d o m i 30 5 equations a 11 through a 15 compute daily outflow based on linear monthly storage outflow relationships monthly in fig 3 table 3 equations a 16 and a 17 determines the current day of month s dom i weight between the midpoints of the current month and the next month ω i j this curve relates the daily wsl wsl i m to the outflow using monthly parameters θ monthly stage j for each of the low and operations zones the depth above the bottom of the current zone for the current month wsl dr or min wsl op j the operations zone outflow includes the maximum low zone outflow q lo base j as if they form a compound pair of linear relationships this is used to replicate seasonally variant operations i e increased or decreased hydroelectric demand modified hydraulics based on ice cover etc while bypassing manual calibration these computations are executed at each timestep but only when the stage options φ lo or φ op for the relevant stages are set to the monthly flag value for the primary or secondary outlet where equation a 18 w s l i w s l d r i q d r i θ q d r a 19 w s l i w s l f l i q f l i θ q f l equations a 18 and a 19 compute fixed daily outflow fixed in fig 3 table 3 for drought and flood respectively values are computed based on extrema within historical records θ dr θ fl these values reproduce operations for specified ecological minima or the allowable downstream maxima these computations are executed at each timestep but only when the stage options φ dr or φ fl for the relevant stages are set to the fixed value flag value for the primary or secondary outlet this is the case for all drought stages where equation a 20 no conditions q f l i q h i i equation 20 computes flood zone outflow where high zone operations are extended extend high in fig 3 table 3 since high zone outflow is sensitive to daily level wsl i extending the high zone to flood zone equations results in flood zone outflows intensifying to relieve over burdened reservoirs which is consistent with real world operations these computations are executed at each timestep but only when the flood option φ fl is set to the extend high flag value for the primary or secondary outlet where equation a 21 no conditions q o p i 1 θ i i 13 i q i n i 14 s a 10 6 86400 i 13 i δ s a v g i 14 a 22 no conditions δ s a v g i w s l o p i w s l o p i 1 a 23 w s l i w s l t r i θ i 0 25 a 24 w s l t r i w s l i w s l a v g i θ i 0 25 w s l i w s l o p i θ o p d e p t h w s l t r i w s l o p i θ o p d e p t h a 25 w s l a v g i w s l i w s l t r i θ i 0 25 w s l i w s l o p i θ o p d e p t h w s l t r i w s l o p i θ o p d e p t h a 26 w s l t r i w s l i θ i 0 25 equations a 21 through a 26 are used to determine the daily outflow based on the ideal daily storage operations zone for primary outlets only ideal storage in fig 3 table 3 this method calculates the outflow necessary to reach daily target storage wsl avg i based on the previous two weeks average inflow and the gradient of the target wsl curve this option is employed in reservoirs with limited overlapping outflow and wsl records which prevents development of monthly or year round relationships this method was proposed by john crawford for manitoba hydro for historic and projected simulation of operations this method maintains operations zone wsls very efficiently these computations are executed at each timestep but only when the operations option φ op is set to the ideal storage flag value for the primary outlet where equation a 27 no conditions q i n a v g i i 1 i 7 q i n 7 a 28 no conditions q o u t p r i m a r y a v g i i 1 i 7 q o u t p r i m a r y 7 a 29 no conditions q h i i q i n a v g i q o u t p r i m a r y a v g i equations a 27 a 28 and a 29 compute daily outflow to prevent flooding in a two outlet reservoir high zone for secondary outlets only also called ideal storage in fig 3 table 3 this method uses a seven day inflow gradient to respond to shorter more intense high inflow events this option is used to simulate secondary outlets where the secondary outlet flow is not heavily governed but used to protect reservoir storage or safe levels the two ideal storage options can only be applied to separate zones and separate outlets because in development they made the model unstable if jointly applied these computations are executed at each timestep but only when the high option φ hi is set to the ideal storage flag value for the secondary outlet where equation a 30 no conditions q c o n d a v g i i 14 i 1 q c o n d 14 a 31 w s l d r w s l i w s l f l q o p i θ a c o n d q c o n d a v g i θ b c o n d θ c c o n d θ d c o n d equations a 30 and a 31 compute daily outflow based on the discharge at another sub basin within the model operations zone for main outlet only condition in fig 3 table 3 this option is used where the outflow of a reservoir needs to be limited or increased based on conditions at another gauge station this method uses a four parameter curve θ a cond θ b cond θ c cond and θ d cond to relate the calculated outflow for a reservoir to another sub basin s previous two weeks outflow the application of a conditioned outflow can be automatically selected by the rat but will only create feasible values if a corresponding record or simulated point in h hype is present which pre supposes a degree of understanding of the regulated system these computations are executed at each timestep but only when the high option φ op is set to the condition flag value for the primary outlet where equation a 32 q l o i q d r i q l o i q d r i a 33 q l o i q f l i q l o i q f l i a 34 q h i i q f l i q h i i q f l i a 35 q h i i q d r i q h i i q d r i a 36 q o p i q l o i q o p i q l o i a 37 q o p i q h i i q o p i q h i i a 38 no conditions q t r i q l o i q o p i q l o i w s l i w s l t r i w s l o p i w s l t r i a 39 no conditions q t r i q o p i q h i i q o p i w s l i w s l o p i w s l t r i w s l o p i a 40 w s l i w s l d r i q d e c i q d r i a 41 w s l d r i w s l i w s l t r i q d e c i q l o w i a 42 w s l t r i w s l i w s l o p i q d e c i q t r i a 43 w s l o p i w s l i w s l o p i q d e c i q o p i a 44 w s l o p i w s l i w s l t r i q d e c i q t r i a 45 w s l t r i w s l i w s l f l i q d e c i q h i i a 46 w s l f l i w s l i q d e c i q f l i a 47 q d e c i q o u t i 1 θ δ q q o u t i q o u t i 1 θ δ q a 48 q d e c i q o u t i 1 θ δ q q o u t i q o u t i 1 θ δ q equations a 32 through a 37 run logical corrections equations a 38 and a 39 compute transition flow between low and operations zones q tr i and operations and high zones q tr i based linear interpolation between corrected zonal flows q lo i q op i and q hi i zone stages wsl tr i wsl tr i wsl op i and wsl op i and daily computed wsl wsl i to smooth transitions between operational types equations a40 through a 46 determine the selected outflow for the given outlet primary or secondary q dec i based on the current timestep s wsl wsl i and the stages separating zones wsl dr wsl tr i wsl tr i wsl op i wsl op i wsl fl equations a 47 and a 48 restrict daily changes to outflow based on the historical maximum daily change θ δq these operational restrictions limit maximum change of outflow between two timesteps and are used to simulate operations which might limit potential damage to reservoir infrastructure or downstream municipalities from dramatic changes i e riverbed scour flash flooding wildlife isolation and are computed from historic records 2001 to 2010 table a2 a hype governing equations equation numbers correspond to fig 2 symbol φ indicates a parameter derived using the reservoir analysis tool rat with derivation from historic records summarized in table a3 table a2 where equation a 49 no conditions w s l i 1 w s l i 86400 q i n i q o u t i s a 10 6 p i e t i 10 3 a 50 no conditions q d e f a u l t w s l r e f w s l m i n s a 10 6 86400 a 51 no conditions q p r o d i p r o d 1 a m p sin 2 π d o y i p h a s e 365 a 52 no conditions q e c o n i q p r o d i w s l i w s l l i m w s l l i m w s l m i n a 53 no conditions q s p i l l i r a t e w s l i w s l r e f e x p a 54 w s l i w s l m i n q p r o d i q e c o n i q o u t i q p r o d i a 55 w s l i w s l m i n q p r o d i q e c o n i q o u t i q e c o n i a 56 w s l m i n w s l i w s l r e f q p r o d i q d e f a u l t i q o u t i q d e f a u l t i a 57 w s l m i n w s l i w s l r e f q p r o d i q d e f a u l t i q o u t i q p r o d i a 58 w s l i w s l r e f q p r o d i q s p i l l i q o u t i q p r o d i a 59 w s l i w s l r e f q p r o d i q s p i l l i q o u t i q s p i l l i these equations summarize the outflow and wsl computations used for hydroelectric reservoirs in hype rivers and lakes 2020 equation a 49 computes the daily level as in a 7 equation 50 computes the default outflow for a regulated reservoir q default is the equivalent volume between the minimum and spillway depths φ wsl min and φ wsl ref for a single timestep equation 51 computes the daily production zone target outflow q prod i based on the current day of year doy i and three parameters defining a sine curve φ prod φ amp and φ phase equation 52 computes the daily storage economizing outflow q econ i by linear interpolation below a threshold φ wsl lim equation 53 computes daily outflow representative of a spillway q spill i based on daily wsl wsl i the depth above the dam top φ wsl ref and two parameters computed by log10 least squares regression φ rate and φ exp equations a 54 through a 59 determine the current timestep s outflow based on the current lake depth and relative values of outflow q econ i q default i q prod i and q spill i where equation a 60 no conditions q t h r e s h o l d 1 q m a i n m a x q m a i n m i n f r a c t i o n q m a i n m i n a 61 no conditions q t h r e s h o l d 2 q b r m a x 1 f r a c t i o n q m a i n m i n a 62 no conditions q t h r e s h o l d m a x q t h r e s h o l d 1 q t h r e s h o l d 2 0 a 63 no conditions q t o t a l i q o u t i a 64 q t o t a l i q m a i n m i n q o u t i q t o t a l i a 65 q m a i n m i n q t o t a l i q t h r e s h o l d q o u t i q t o t a l i q m a i n m i n f r a c t i o n q m a i n m i n a 66 q t h r e s h o l d q t o t a l i q t h r e s h o l d q t h r e s h o l d 1 q o u t i q m a i n m a x a 67 q t h r e s h o l d q t o t a l i q t h r e s h o l d q t h r e s h o l d 2 q o u t i q t o t a l i q b r m a x a 68 no conditions q b r i q t o t a l i q o u t i equations a 60 through a 68 are only computed where a second outlet exists equations a 60 a 61 and a 62 compute the threshold main outlet outflow q threshold based on the available parameters equation a 64 computes the daily main outlet outflow when the total available outflow is less than the threshold equation a 65 computes main outlet outflow based on two parameters the minimum main outlet outflow φ qmain min and the fraction of outflow devoted to main outlet φ fraction equation a 66 computes main outlet outflow where a maximum main outlet outflow parameter has been defined φ qmain max equation a 67 computes main outlet outflow where a maximum secondary outlet outflow parameter has been defined φ qbr max equation a 68 computes secondary outlet outflow q br i based on the new main outlet outflow q out i and total available daily outflow q total i main and secondary outlet outflow are used to compute the next timestep s wsl equation a 49 table a3 source of inflow outflow and water surface level datasets by reservoir database data listed as synthetic are computed as summarized in section 3 3 period indicates gauged years used in this work alterations to gauged data unaltered gauges exist at the inlet outlet of a reservoir or gauged drainage area is within 1 of reservoir drainage area scaled up scaled down gauged data are scaled directly by the ratio of gauged and reservoir drainage areas table a3 label reservoir river data id database period alteration reference a abraham reservoir n a wsl 05dc009 wsc 1972 2012 unaltered n saskatchewan river qout 05dc007 wsc 1953 1968 unaltered n saskatchewan river qin 05dc010 wsc 1972 2015 scaled up b oldman reservoir n a wsl 05aa032 wsc 1992 2015 unaltered oldman river qout 05aa023 wsc 1949 2008 scaled down oldman river qin 05aa035 wsc 2009 2015 scaled up oldman river qin synthetic 1981 2008 n a c lake diefenbaker n a wsl 05hf003 wsc 1964 2015 unaltered shook and pomeroy 2016 s saskatchewan river qout 05hg001 wsc 1911 2015 scaled down total inflow qin synthetic 1981 2015 n a d tobin lake n a wsl 05kd004 wsc 1962 2015 unaltered saskatchewan river qout 05kd003 wsc 1962 2015 scaled down total inflow qin synthetic 1981 2015 n a e cedar lake n a wsl 05kl005 wsc 1940 2014 unaltered saskatchewan river qout 05kl001 wsc 1909 2014 unaltered saskatchewan river qin 05kj001 wsc 1913 2016 scaled up f namakan rainy lake n a wsl 05pb007 wsc 1911 2015 unaltered lake of the woods 2006 lwcb n a wsl 05pa003 wsc 1912 2007 unaltered rainy river qout 05pc019 wsc 1905 2015 unaltered seine river qin 05pb009 wsc 1963 2015 scaled up turtle river qin 05pb014 wsc 1914 2015 scaled up namakan river qin 05pa006 wsc 1921 2015 scaled up g lake of the woods n a wsl 05pe012 wsc 1913 2015 unaltered lake of the woods 2006 lwcb winnipeg river e outlet qout 05pe006 wsc 1907 2015 unaltered winnipeg river w outlet qout 05pe011 wsc 1913 2015 unaltered rainy river qin 05pc018 wsc 1928 2015 scaled up h lake st joseph n a wsl 05ga004 wsc 1934 1994 unaltered lake of the woods 2006 lwcb albany river qout 04ga001 wsc 1968 1994 unaltered albany river qout 04gc002 wsc 1970 2015 scaled down albany river qout synthetic 1994 2006 n a root river qout 05qb006 wsc 1957 1994 unaltered root river qout synthetic 1994 2010 n a cat river qin 04ga002 wsc 1970 2015 unaltered i lac seul n a wsl 05qb003 wsc 1917 2015 unaltered lake of the woods 2006 lwcb english river qout 05qe006 wsc 1907 1994 unaltered root river qin 05qb006 wsc 1957 1994 unaltered total inflow qin synthetic 1981 2010 n a j pointe du bois reservoir n a wsl 05pf051 wsc 1928 2015 n a winnipeg river qout 05pf063 wsc 1907 2015 scaled down english river qin 05qe005 wsc 1927 1994 unaltered winnipeg river qin 05pe020 wsc 1892 2010 unaltered winnipeg and english rivers qin synthetic 1994 2015 n a k rafferty reservoir n a wsl 05nb032 wsc 1991 2015 unaltered souris river qout 05nb036 wsc 1992 2015 unaltered souris river qin 05nb017 wsc 1959 2011 scaled up l lake manitoba n a wsl 05lk002 wsc 1923 2015 unaltered fairford river qout 05lm001 wsc 1912 2015 unaltered waterhen river qin 05lh005 wsc 1950 2015 unaltered whitemud river qin 05ll002 wsc 1971 2015 scaled up portage diversion qin 05ll019 wsc 1970 2015 unaltered m lake winnipeg n a wsl 05re003 wsc 1983 2015 unaltered water power licences 2010 manitoba hydro lake winnipeg regulation 2014 a g manitoba hydro nelson river e channel qout 05ub008 wsc 1967 2014 scaled down nelson river jenpeg qout 05ub009 wsc 1975 2014 scaled down dauphin river qin 05lm006 wsc 1077 2015 unaltered saskatchewan river qin 05kl001 wsc 1909 2014 unaltered winnipeg river qin 05pf063 wsc 1907 2014 scaled up red river qin 05oj010 wsc 1962 2008 scaled up pigeon river qin 05rd008 wsc 1957 1996 scaled up beren s river qin 05rd007 wsc 1957 1992 scaled up poplar river qin 05re001 wsc 1967 1996 scaled up total inflow qin synthetic 1981 2014 n a n reindeer lake n a wsl 06db001 wsc 1930 2015 unaltered reindeer river qout 06dd002 wsc 1985 2015 unaltered reindeer river qout 06db002 wsc 1929 1987 unaltered cochrane river qin 06da002 wsc 1968 2015 scaled up wathaman river qin 06dc001 wsc 1071 2015 scaled up o southern indian lake n a wsl 06ec001 wsc 1956 2015 unaltered regional 2015 manitoba hydro water power 1973 province of manitoba final licence 1975 province of manitoba water power 2018 province of manitoba churchill river qin 06eb004 wsc 1973 2015 scaled up churchill river qout 06fb001 wsc 1960 2015 scaled down gauer river qout 06fa001 wsc 1979 2015 scaled down s channel diversion qout 06ec002 wsc 1993 2010 unaltered s channel diversion qout synthetic 1981 1992 n a p novosibiriskoye n a wsl 1378 g realm 1992 2003 unaltered n a wsl 1378 g realm 2008 2019 unaltered ob river qout 2910605 grdc 1958 2000 scaled down karakan river qin 2910635 grdc 1956 1998 scaled up berd river qin 2910650 grdc 1956 2000 scaled up ob river qin 2910606 grdc 1936 2000 scaled up total inflow qin synthetic 1998 2010 n a q sayano shushenskoye n a wsl 0459 g realm 2008 2019 unaltered yenisey qout 2909158 grdc 1911 1999 scaled down us qin 2909250 grdc 1951 1999 scaled up yenisey qin 2909160 grdc 1926 2015 scaled up khemchik qin 2909240 grdc 1975 1993 scaled up kantegir qin 2909313 grdc 1979 1993 scaled up total inflow qin synthetic 1993 2010 n a r krasnoyaraskoye n a wsl 0425 g realm 1992 2019 unaltered yenisey qout 2909156 grdc 1955 1999 scaled down abakan qin 2909260 grdc 1953 2015 scaled up yenisey qin 2909158 grdc 1911 1999 scaled up tuba qin 2909314 grdc 1941 1989 scaled up total inflow qin synthetic 1989 2010 n a s vilyuyskoye n a wsl 0434 g realm 1992 2019 unaltered vilyuy qout 2903703 grdc 1959 1994 scaled down batyr qin 2903750 grdc 1970 1994 scaled up churkuo qin 2903745 grdc 1971 1992 scaled up vilyuy qin 2903704 grdc 1965 2015 scaled up total inflow qin synthetic 1994 2010 n a 
25823,wildfire behavior predictions typically suffer from significant uncertainty however wildfire modeling uncertainties remain largely unquantified in the literature mainly due to computing constraints new multifidelity techniques provide a promising opportunity to overcome these limitations therefore this paper explores the applicability of multifidelity approaches to wildland fire spread prediction problems using a canonical simulation scenario we assessed the performance of control variates monte carlo mc and multilevel mc strategies achieving speedups of up to 100x in comparison to a standard mc method this improvement was leveraged to quantify aleatoric uncertainties and analyze the sensitivity of the fire rate of spread ros to weather and fuel parameters using a full physics fire model namely the wildland urban interface fire dynamics simulator wfds at an affordable computation cost the proposed methodology may also be used to analyze uncertainty in other relevant fire behavior metrics such as heat transfer fuel consumption and smoke production indicators keywords forest fire multifidelity monte carlo predictive science engineering sensitivity analysis uncertainty quantification fds glossary of acronyms cfd computational fluid dynamics cov coefficient of variation cv control variates csiro commonwealth scientific and industrial research organisation fds fire dynamics simulator gsa global sensitivity analysis hf high fidelity lf low fidelity mc monte carlo mf multifidelity ml multilevel mse mean squared error pce polynomial chaos expansion pde partial differential equation qoi quantity of interest ros rate of spread sa sensitivity analysis sav surface area to volume ratio uq uncertainty quantification v v verification and validation wfds wildland urban interface fire dynamics simulator 1 introduction the number of uncertainties involved in the study of wildfire spread is typically large due to i the modeling assumptions required to mathematically describe the different physics and their couplings i e epistemic uncertainty and ii the aleatoric incertitude resulting for instance from the lack of detailed evidence regarding initial and boundary conditions therefore numerical analyses based on a single deterministic realization for a particular set of input parameters are typically not conclusive and neither truly predictive arca et al 2007 alexander and cruz 2013 cruz and alexander 2013 filippi et al 2014 sá et al 2017 cruz et al 2018 a solution to this problem is to consider the system under study stochastic and analyze the relationship between input and output probability distributions by means of efficient statistical methods in this regard the fields of uncertainty quantification uq and sensitivity analysis sa have remarkably grown over the last decades within the computational fluid dynamics cfd community najm 2009 masquelet et al 2017 jofre et al 2018 2019 and it is now extensively accepted that the potential of estimating and minimizing uncertainties in combination with numerical verification and physics validation v v is crucial for augmenting the confidence in the numerical predictions in the specific case of wildfire spread modeling and prediction uncertainty quantification is essential to prioritize the needs in data collection inform decisions about future research investments and improve communication between modelers and managers leading to more informed fire management decisions riley and thompson 2016 the benefits of quantifying uncertainty in wildfire spread studies have already been demonstrated see for instance cruz 2010 and multiple authors have emphasized the need to improve the statistical characterization of fire model outputs benali et al 2016 pinto et al 2016 ramirez et al 2019 however previous attempts to quantify uncertainty in forest fire modeling suffer from significant limitations primarily caused by unattainable computing requirements full physics models which carefully resolve and or model the physical and chemical phenomena involved in fire spread are too computationally expensive to be used within monte carlo mc analyses consequently most of the previous studies on fire spread uncertainty have been restricted to rothermel s semi empirical model rothermel 1972 and a few other completely empirical formulations e g cheney and gould 1997 cruz et al 2008 liu et al 2014 one of the first attempts to apply global sensitivity analysis gsa techniques to rothermel s model was carried out by salvador et al 2001 since then several authors have extended their work anderson et al 2007 quantified aleatoric uncertainties by applying random perturbations to weather variables namely temperature relative humidity wind speed and wind direction in a monte carlo fashion a similar approach was followed by finney et al 2011 who proposed a probabilistic framework to account for uncertainties in weather variables based on ensemble simulations of the fire spread model described by finney 2002 cruz 2010 studied the response of another fully empirical model to 10 m open wind speed and dead fuel moisture content later cruz and alexander 2017 extended the work of cruz 2010 to account for crown fire ignition and spread they continued to use fuel moisture content and wind speed as uncertain inputs and they added uncertainty ranges to fuel structure parameters such as fuel load surface fuel depth canopy base height stand height and canopy bulk density alternatively to the mc approach which may become computationally prohibitive for large sample sizes bachmann and allöwer 2002 assessed uncertainty propagation in rothermel s model using a first order approximation based on a taylor series expansion in a similar attempt to reduce the computational cost of the original mc method jimenez et al 2008 proposed a sampling algorithm to accelerate convergence using sensitivity derivative information such algorithms prioritize the input variables that have a larger impact on the model outputs to reduce the dimensionality of the problem however that approach can only be applied to differentiable formulations that meet certain smoothness conditions liu et al 2015 extended the work of jimenez et al 2008 by using gsa techniques to simplify the fuel representation required in rothermel s fire spread model afterwards they combined a sensitivity derivative enhanced sampling sdes algorithm with a control variates scheme to accelerate the convergence of a randomized quasi mc method to quantify aleatoric uncertainties recently yuan et al 2020 presented a first attempt to characterize epistemic uncertainty in a semi physical fire spread model developed by liu et al 2014 specifically they studied the effect on fire rate of spread of model parameters that describe energy transfer including flame temperature and emissivity flame length and tilt angle fuel temperature of ignition fuel consumption efficiency and the heat convection coefficient despite the recent improvements in uncertainty quantification studies focused on wildfire spread no study so far has included full physics models in the analysis while empirical and semi empirical fire spread models are of most value for rapid operational purposes they do not resolve physical and chemical phenomena essential to accurately describe fire behavior this fact has two important implications first not resolving fundamental physics mechanisms prevents the study of epistemic uncertainties related to such phenomena second because empirical models are built upon statistical relationships between macroscopic variables rather than physical principles their application cannot be easily extrapolated beyond the conditions used to develop the models acquiring experimental data in a range of conditions wide enough to generalize empirical models is practically unfeasible which also limits the study of aleatoric uncertainties conversely physics based cfd simulators which are intended to resolve and or model all relevant physical and chemical mechanisms that characterize wildfire spread are exceedingly expensive to be used within uncertainty quantification studies based on standard mc methodologies the resulting high dimensional parameter space in conjunction with the large computational demands of the simulation runs required necessitates cost efficient non intrusive i e sampling based uq methods that accurately estimate the statistics of the quantities of interest qoi many widely used non intrusive methods such as stochastic collocation mathelin and hussaini 2003 xiu and hesthaven 2005 and polynomial chaos expansions pce ghanem and spanos 2003 xiu and karniadakis 2002 doostan and owhadi 2011 suffer from a rapid up to exponential growth of computational cost as a function of the number of input variables characterizing the uncertainty on the other hand mc methods are popular and powerful approaches for the estimation of statistical parameters due to their robust convergence behavior independent of the number of uncertainties however it is well known that the mean square error mse of the mc estimator converges slowly as a function of the sample size n this slow convergence may thus become a critical issue or even prohibitive especially if sampling involves computationally expensive operations such as solving a discretized partial differential equation pde recent research has targeted the development of cost reduction techniques to improve mc sampling methods which are usually based on multifidelity mf methodologies in mf frameworks high fidelity hf models are exploited to provide the required level of accuracy and insight into detailed physical phenomena whereas low fidelity lf simulations are leveraged to economically improve the statistical characterization of modeled qois at present the performance of these strategies has been mainly assessed on canonical pdes and rather simplified flow problems however to the best of the authors knowledge very few uq studies of complex large scale high dimensional systems have been conducted and published in the literature selected recent examples include shock turbulent boundary layer interaction in scramjet engines bermejo moreno et al 2012 analysis and optimization of high performance aircraft nozzles alonso et al 2017 multiphase flow simulations of cloud cavitation collapse sukys et al 2017 and the study of radiative heat transfer in particle laden turbulence jofre et al 2020 therefore the objective of this work is to demonstrate the potential of mf techniques to reduce the computing requirements of performing uncertainty quantification and sensitivity analysis in physics based wildfire spread computational predictions allowing in this manner a more complete characterization of aleatoric and epistemic uncertainties the paper is organized as follows first a description of the considered mf strategies is provided in section 2 next section 3 introduces the wildfire models utilized section 4 presents the canonical simulation problem analyzed in this paper and section 5 describes and discusses the results obtained finally section 6 summarizes the work provides conclusions and proposes future research 2 multifidelity sampling strategies in computational science and engineering multiple physical mathematical numerical models with different features can be constructed to characterize a system of interest typically computationally expensive hf models are designed to describe the system with the degree of accuracy required by the problem under study while lf models are formulated as cheaper representations usually at the expense of lower accuracy robustness or generality outer loop problems such as inference uq and optimization require large numbers of model evaluations for different input values resulting in unaffordable computational requirements in the case of large scale multiphysics calculations the objective of mf methods therefore is to reduce the cost of the outer loop problem by combining the accuracy of the hf models with the speedup achieved by the lf representations different mf uq strategies exist in the literature see for example the reviews by peherstorfer et al 2018 and fernandez godino et al 2016 2019 however due to the high dimensional input space and the complexity of the conservation equations involved this study is restricted to a reduced subset of acceleration strategies appertaining to surrogate based mc type sampling approaches as its name indicates mc type approaches are derived from the original monte carlo method in which the expectation of the qoi as a function of the stochastic inputs ξ q q ξ is estimated via a sample average let e q and v q denote the mean and variance of q given n independent realizations of the stochastic input denoted ξ i the mc estimator of e q is defined as q ˆ n mc n 1 i 1 n q i where q i q ξ i although unbiased the precision of q ˆ n mc measured by its standard deviation v q n decays slowly as a function of n therefore for a fixed computational budget n a viable alternative to increase the mc precision is to possibly replace q with other quantities with smaller variances 2 1 multilevel monte carlo one of the most popular acceleration strategies is the multilevel ml method giles 2008 adcock et al 2020 this technique inspired by the multigrid solver idea in linear algebra is based on evaluating realizations of q from a hierarchy of models with different levels ℓ ℓ 0 l with l the most accurate model in which q is replaced by the sum of differences y ℓ q ℓ q ℓ 1 to simplify the notation for level 0 the expression is redefined to y 0 q 0 as a result the qois of the original and new ml problems have the same mean e q an example of a level is the grid resolution considered for solving the system of equations so that a lf or hf model can be established by simulating q on a coarse or fine grid then e q can be computed using the ml qoi and an independent mc estimator on each level ℓ as 1 q ˆ ml ℓ 0 l y ˆ ℓ mc ℓ 0 l 1 n ℓ i 1 n ℓ y ℓ i this approach is referred to as multilevel monte carlo mlmc or simply ml and the resulting estimator has a variance equal to 2 v q ˆ ml ℓ 0 l v y ℓ n ℓ consequently if the level definition is such that q ℓ q in mean square sense then v y ℓ 0 as ℓ and therefore fewer samples are required on the finer level l in particular it is possible to show that the optimal sample allocation across levels n ℓ is obtained in closed form given a target variance of the ml estimator equal to ε 2 2 and resulting in giles 2008 3 n ℓ k 0 l c k v y k ε 2 2 v y ℓ c ℓ where the computational cost of the individual y ℓ evaluations is denoted by c ℓ and ε 2 represents the mse of the estimator it is important to note that the variance decay can be proven to be satisfied only for levels based on a numerical discretization spatial temporal meshes and not for general hierarchies of models such as 2 d versus 1 d large eddy simulation les versus reynolds averaged navier stokes rans etc 2 2 control variates monte carlo to accommodate lf representations that are not obtained directly from coarsening the hf models a common approach is to utilize lf realizations as a control variate peherstorfer et al 2018 pasupathy et al 2014 geraci et al 2017 in statistics the control variates approach replaces a generic quantity q by q α e g g where g is a function chosen for its high correlation with q and for which the value of e g is readily available however in the problem of interest here the lf correlations and expected values are not available a priori and consequently need to be established during the computations along with the hf calculations as a consequence the expected values of the lf models are generally approximated by means of mc estimators requiring a set of additional independent lf computations the control variates cv mc estimator is defined as 4 q ˆ cv q ˆ hf mc α e q lf q ˆ lf mc where q ˆ hf mc n hf 1 i 1 n hf q hf i e q lf n lf n hf 1 1 i n hf 1 n lf q lf i q ˆ lf mc n hf 1 i 1 n hf q lf i n hf and n lf are the number of hf and lf samples respectively and α c q hf q lf v q lf is the control variates coefficient chosen to minimize the variance of q ˆ cv c q hf q lf denotes the covariance between q hf and q lf the optimal α selection leads to 5 v q ˆ cv v q hf 1 ρ 2 r r 1 with 1 ρ c q hf q lf v q hf v q lf 1 the pearson correlation coefficient between the hf and lf models and r is used to parameterize the additional r n hf lf realizations with respect to hf as described by geraci et al 2017 the optimal control variates is obtained for 6 r c hf c lf ρ 2 1 ρ 2 1 where c hf and c lf are the costs of a hf and lf sample respectively a comprehensive description of the control variates mc estimator like for example the derivation of optimal coefficients and number of samples per fidelity is detailed in peherstorfer et al 2018 3 wildfire spread models over the past decades numerous approaches have been proposed to model and predict wildfire behavior these strategies range from completely empirical correlations to detailed physics based simulation frameworks see for instance sullivan 2009a 2009b 2009c for a comprehensive review tools designed to be used operationally for decision support need to be computationally fast and provide easy to interpret information regarding macroscopic variables such as rate of spread flame height and fire line intensity therefore operational simulators are frequently built upon empirical or semi empirical models conversely the detailed study of fire dynamics requires additional insight into the physical and chemical phenomena involved in fire spread including among others pyrolysis combustion heat transfer and turbulence such level of detail can only be achieved by means of cfd approaches which typically require intense computing resources that are several orders of magnitude larger than what operational simulators demand one of the most popular solutions among operational wildfire simulators is the rothermel model rothermel 1972 based on semi empirical relationships between the parameters that determine the heat emitted by the fire and the energy needed by the unburned fuel to ignite the rothermel model provides a well balanced combination of physical insight and operational capabilities while its application requires empirical adjustment of fuel and wind parameters the fact that such parameters are defined following physical principles facilitates extrapolating the use of the model to new vegetation types and diverse weather conditions nonetheless the rothermel model has important limitations and consequently it is usually coupled with additional models that account for phenomena not considered initially such as crown ignition and spotting from a full physics modeling perspective several cfd simulation frameworks have been designed specifically for wildfire applications some of the most popular solutions include the wildland urban interface fire dynamics simulator wfds mell et al 2007 firetec linn et al 2002 and firestar morvan et al 2006 2018 wfds was selected in this study due to its widespread adoption by the scientific community wfds is currently part of the broader fire dynamics simulator fds forney et al 2003 floyd and mcgrattan 2008 a cfd fire and smoke simulation tool widely used for fire safety applications fds is an open source solver 1 1 https github com firemodels fds maintained by the us national institute of standards and technology nist and jointly developed by several academic institutions in multiple countries finally there exist a variety of fully empirical fire models that have demonstrated high accuracy and applicability when used within specific parameter ranges these models were not included in the present analysis due to the wide range of alternatives available but they constitute an important pool of lf candidates to be considered in the mf strategies introduced in section 2 the subsections below provide further details on the wildfire models used in this study 3 1 the rothermel model rothermel s original formulation initially published in 1972 rothermel 1972 is based on an energy balance between the heat emitted by a flaming fire front and the energy required to ignite the fuel ahead of it the model is given by andrews 2018 7 r i r ξ 1 φ w φ s ρ b ε q i g where r is the fire rate of spread i r is the reaction intensity ρ b is the fuel bulk density and q i g is the heat required to ignite the fuel the remaining variables are empirical parameters that allow matching observed fire behavior to this simple formulation ξ is the propagating flux ratio and represents the portion of reaction intensity that propagates toward the unburned fuel φ w and φ s are named wind and slope factors respectively and account for the increase in heat transfer that occurs when the fire spreads in the direction of the wind and or upslope finally ε is an efficiency parameter dependent on the fuel particle size and shape rothermel developed empirical functions so that the value of these variables could be derived directly from fuel and environmental parameters providing in this manner physical intuition to their calibration through such empirical relationships the fire rate of spread can ultimately be expressed as a function of fuel heat content h fuel total mineral content s t fuel effective mineral content s e oven dry fuel particle density ρ p fuel particle surface area to volume sav ratio σ oven dry fuel load w 0 fuel bed depth δ dead fuel moisture of extinction m x fuel moisture content m f wind velocity at midflame height u and terrain slope φ in the form 8 r f h s t s e ρ p σ w 0 δ m x m f u φ following the formulation outlined in eq 8 the fuel related parameters are usually grouped into standard categories that broadly represent the most common vegetation distributions such categories are known as fuel models and have experienced substantial development since the first version proposed by rothermel multiple authors have highlighted the importance of the fuel input parameters on the predictive capability of fire spread achieved by the rothermel model e g arca et al 2007 for this reason ad hoc fuel models are usually developed prior to applying the rothermel model to a new geographical area and or vegetation type the original rothermel model is one dimensional 1d and consequently its practical application requires coupling it with a two dimensional 2d propagation scheme several propagation methodologies have been proposed following eulerian and lagrangian approaches bova et al 2016 furthermore the rothermel model has been incorporated into a significant number of 1d and 2d simulators such as behaveplus heinsch and andrews 2010 farsite finney 1998 and wrf sfire mandel et al 2011 which are at present extensively used internationally by fire managers and researchers 3 2 wildland urban interface fire dynamics simulator wfds was designed as an extension of fds to include fire spread in vegetative fuels mell et al 2007 fds is a cfd model of fire driven fluid flow which numerically solves a form of the navier stokes equations appropriate for low speed mach numbers below m a 0 3 thermally driven flow with an emphasis on smoke and heat transport from fires it is widely used in fire protection engineering problems and its applicability to study fundamental fire dynamics and combustion phenomena is gaining increasing attention the core hydrodynamic formulation is solved by an explicit predictor corrector scheme which is second order accurate in space and time and spatially discretized on a rectilinear mesh by default the small scale turbulent fluctuations are modeled by means of les strategies although it is possible to perform direct numerical simulations dns if the underlying numerical mesh is fine enough for most applications combustion is modeled through a single step mixing controlled chemical reaction radiative heat transfer is included in the model and solved via a discrete ordinates method dom with a default number of 100 discretization angles the radiation transport equation is solved for a grey gas and in some limited cases using a wide band model in addition fds includes langrangian particle tracking capabilities to represent elements that are not captured by the eulerian grid mcgrattan et al 2019a like for example fuel and soot particles the wfds extension now merged into fds added the functionalities needed to i describe vegetative fuels ii resolve convective and radiative heat transfer within those fuels and iii calculate their thermal degradation pyrolysis and combustion 4 description of the wildfire spread scenario the mf techniques presented in section 2 were applied to the canonical wildfire spread simulation problem described below the analyzed scenario belongs to a set of medium scale field fire experiments conducted by the commonwealth scientific and industrial research organisation csiro in the northern territory of australia in 1986 cheney et al 1993 these tests were monitored to measure the fire rate of spread and evaluate its correlation with fuel and weather variables such as fuel height fuel moisture content fuel load fuel bulk density and wind speed two of the experiments had been simulated using wfds mell et al 2007 and incorporated into the fds test suite as validation examples mcgrattan et al 2019b furthermore the fact that the experiments were conducted on horizontal grassland fields facilitates the application of rothermel s model for surface fire spread particularly this study considers the csiro grassland f19 experiment which burned a square field of 200 m 200 m using a 175 m long ignition line this type of experiment design is very frequent in wildfire behavior studies 4 1 problem setup the setup of the problem is depicted in fig 1 this configuration was generated with wfds by reproducing the validation study performed by mell et al 2007 for the hf samples the computational domain of size 240 m 240 m 20 m was discretized using a uniform cartesian grid with δ 0 5 m resolution turbulence was solved by means of a les strategy based on deardorff s turbulent viscosity model time integration was performed by limiting the courant friedrichs lewy cfl value to cfl 1 and radiation transport was calculated utilizing a dom method with 100 discrete angles mcgrattan et al 2019a vegetation grass was represented as a homogeneous bed of lagrangian combustible particles whose main physical and chemical properties are summarized in table 1 grass particles were arranged in a rectangular prismatic space with a predefined bulk density and fuel bed depth these two parameters were included into the list of uncertainties analyzed together with the fuel moisture fraction and the particle sav ratio see section 4 2 for a detailed discussion of their values 4 2 uncertainties and quantities of interest wildfire spread modeling requires the selection of a large number of parameters however most of the aleatoric uncertainty is usually concentrated in a limited subset of the input variables previous works identified the following variables as significant sources of aleatoric uncertainty in wildfire spread 1 h fuel moisture content salvador et al 2001 clark et al 2008 finney et al 2011 ervilha et al 2017 1 h fuel load liu et al 2015 cai et al 2019 fuel bed depth salvador et al 2001 jimenez et al 2008 liu et al 2015 ervilha et al 2017 cai et al 2019 fuel particle sav ratio jimenez et al 2008 liu et al 2015 ervilha et al 2017 cai et al 2019 and wind speed salvador et al 2001 anderson et al 2007 jimenez et al 2008 clark et al 2008 finney et al 2011 liu et al 2015 benali et al 2016 ervilha et al 2017 consequently this list of variables were considered as uncertain inputs ξ i in this work with their stochastic ranges characterized from studies and experiments available in the scientific literature scott and burgan 2005 summarized a series of standardized fuel models which are extensively used at present to model fire behavior their list of models contains 9 grass type options each of them with a characteristic value of fine fuel load sav ratio and packing ratio additionally they suggested a range of dead fuel moisture and wind conditions to evaluate these fuel models the data variability considered by scott and burgan 2005 was used in the present study to limit the sampling space as detailed in table 2 in the case of wind speed mid flame estimations were converted to values at a 20 feet height using a conversion factor of 0 4 as recommended by the us national wildfire coordinating group estimating winds for fire behavior 2019 amidst the large number of output statistics that can be obtained from a wildfire spread calculation the fire rate of spread ros is one of the most critical quantities to understand fire behavior and its effects on the environment o brien et al 2016 among other applications ros provides a quantitative representation of fire evolution and it can be used to analyze the effect of varying weather conditions or possible fuel treatments in a specific area consequently this study uses the rate of spread averaged in the simulation domain as qoi simulated ros was measured by recording the longitudinal coordinate of the point with maximum gas temperature at every time step the search for maximum temperatures was restricted to a narrow longitudinal band placed along the domain symmetry plane and close to the ground the resulting time distance distribution was fitted to a linear function in order to estimate the average ros 4 3 multifidelity modeling strategy the mf strategies described in section 2 rely on the construction of levels with different ratios of fidelity and computational cost to accelerate the process of reducing the variance of the estimators diverse approaches can be pursued to develop such cheaper models with the only requirement that these lower fidelity representations need to be orders of magnitude faster to compute while maintaining some degree of interdependence the higher the better with the qoi calculated at the different levels in this work two different methods to build coarser representations of the hf simulation were tested the first strategy is based on the ml method in which the hf cfd scenario is resolved using decreasing levels of resolution in i flow cell size ii integration time step δ t and iii number of discrete angles utilized to resolve the radiative heat transport based on preliminary tests we designed three different levels named lf 2x lf 5x and lf 10x which are 25 250 and 2500 cheaper to compute than the hf level respectively the different resolution levels for i and iii are specified in table 3 the integration time step was automatically adjusted at every iteration based on the cfl constraint approximately a cell size increase of 2 corresponds to a two fold increase of δ t the second approach explores the benefits of introducing the output of the rothermel fire spread model as a control variate this was accomplished through the execution of farsite simulations for a similar scenario and with the same input parameters this fidelity is referred to as lf cv and is 2500 faster to compute than the hf level a visualization of a sample output obtained from farsite is depicted in fig 2 the map of fire time of arrival was used to compute an average value for the ros 5 results and discussion this section presents and analyzes the data and results for the problem described in section 4 which were obtained by running hf and lf simulations based on the modeling approaches described in section 3 and provides a discussion of the statistics calculated by utilizing the methodologies introduced in section 2 first section 5 1 presents a concise statistical characterization of the ros the qoi considered in this work for the different fidelities next in section 5 2 the performance of various mf estimators is studied to select the optimal strategies in terms of balancing variance reduction correlation and computational costs the list of mf designs considered is visually summarized in table 4 in section 5 3 the uncertainty of the problem is propagated through the model and quantified by making use of the acceleration techniques chosen in the previous subsection finally section 5 4 discusses a variance based sensitivity analysis performed to rank the effect of the uncertainties on qoi variability 5 1 pilot sampling of the quantity of interest as a first step to construct efficient mf estimators exploratory data was collected by running the same 32 pilot samples for the 5 fidelities designed this set of samples were generated following a design of experiment doe based on the kdoe approach roy et al 2020 kdoe is an iterative method that introduces stochasticity in the sampling process by means of a variable kernel density estimation to optimize the uniformity of the doe this approach provides a more homogeneous exploration of the input parameter space especially when the number of samples is relatively small for example instantaneous snapshots of the vertical velocity field for the first sample generated by the hf lf 2x lf 5x and lf 10x fidelities are depicted in fig 3 it can be inferred from these snapshots that i the lowest resolution fidelities e g lf 10x tend to underresolve eddies located at the fire front which could affect the rate of convective heat transfer and consequently the predicted fire rate of spread ii nonetheless larger scale turbulent motions are sufficiently resolved with buoyancy pulses present in all fidelity levels iii velocity values maintain similar absolute ranges across all fidelity levels although iv the velocity field becomes increasingly diffused in space as spatial resolution decreases conclusive arguments however cannot be obtained by solely analyzing fig 3 as i the qoi targeted in this work is the average ros and ii the performance of the mf estimators is not directly related to a first order approximation to the accuracy of the lf results with respect to the hf data the data generated from the pilot samples for the different fidelities were collected and visually summarized in fig 4 by means of boxplots the fidelities are sorted left to right in decreasing computational cost starting from hf ending with lf 10x and spanning a total of 4 orders of magnitude as stated in the paragraph above the accuracy of the lf data with respect to the hf results is not the principal component for the performance of the ml and cv estimators as they are respectively formulated in terms of variance reduction and correlation nevertheless it is instructive to analyze the relations between the hf and lf data from a statistical perspective to gain insight and facilitate the effective construction of the mf estimators the distributions in fig 4 show that the data are organized in 2 main blocks across fidelities i hf lf 2x lf 5x and lf 10x generate data distributed around q 2 5 and displaying coefficients of variation with values cov v q e q 0 4 whereas ii lf cv tends to underestimate q by approximately 1 6 and presents a significantly larger cov 0 7 5 2 performance of the multifidelity estimators the performance of various candidate mf estimators constructed by means of cv and ml strategies was analyzed by utilizing the pilot data described in the previous subsection as discussed in section 2 the speedup obtained by the ml and cv approaches is function respectively of the variance of y ℓ v y ℓ in eq 2 and the pearson correlation coefficient ρ between fidelities in eq 5 consequently v y ℓ and ρ for all potential combinations are listed in table 5 in the case of cv based mf estimators which are constructed utilizing hf information and lf samples as a control variate the best lf candidates are lf 2x and lf 5x as they present correlations of ρ 0 995 and ρ 0 990 with speedups of approximately 25 and 250 respectively instead lf cv and lf 10x are slightly less correlated with hf as their values are ρ 0 884 and ρ 0 869 if considering ml strategies in which hf and different lf are combined forming a telescopic sum a good hierarchical structure is composed by the lower fidelities lf 2x lf 5x and lf 10x as their v y ℓ values decay orders of magnitude 0 002 0 017 and 0 224 specifically while becoming 25 250 and 2500 faster to compute than hf the extrapolated performances of a straightforward mc approach and the cv and ml estimators proposed above are reported in fig 5 the horizontal logarithmic scale axis corresponds to the total cost of each estimator normalized by the cost of a hf sample the total costs are evaluated as c mc n hf c hf c cv n hf c hf r c lf and c ml ℓ 0 l n ℓ c ℓ for the mc cv and ml respectively on the vertical logarithmic scale axis target estimators mse ε 2 v q ˆ normalized by a reference mc value ε 0 mc 2 obtained from the 32 pilot samples are shown for mc and ml estimators through evaluating eq 3 and for the cv estimators utilizing the expression peherstorfer et al 2018 9 ε 2 ε 0 mc 2 1 ρ 2 c lf c hf ρ 2 2 the results depicted in fig 5 show that the speedups of the mf estimators with respect to mc are in the order of 100 to 1000 for the best performant cv constructed with hf and lf 5x and ml generated by levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x strategies respectively for example to reduce ε 2 by an order of magnitude with respect to ε 0 mc 2 the mc approach requires computing 320 hf runs while the cv composed by 1 hf and 493 lf 5x samples and ml composed by 1 hf 19 lf 2x 222 lf 5x and 1556 lf 10x samples demand only 3 0 and 2 8 equivalent hf runs studying in detail the differences in performance between the candidate cv estimators considered at the beginning of this subsection it is clear from fig 5 that ρ is a very important parameter for maximizing the speedup in particular the lower fidelities lf cv and lf 10x which present correlation coefficients slightly smaller than lf 2x and lf 5x performed only 10 faster than mc instead of 100 even in the case of using lf 10x that is 10 and 100 faster than lf 2x and lf 5x respectively this observation is corroborated by the mathematical expression of the cv estimator s variance given in eq 5 in which the impact of ρ on the reduction of v q ˆ cv is quadratic while sublinearly proportional to the ratio c hf c lf through the parameter r however if two or more fidelities have similar correlation with hf the computational cost becomes the dominant parameter and the cheapest lf generates the most efficient cv estimator as in the case of lf 2x and lf 5x in which the latter is the best performant option carefully analyzing the speedups of the ml estimators considered in fig 5 two observations can be made the first observation is that ml strategies based on utilizing lf cv realizations which are not generated from coarsening the hf model notably underperformed with respect to standard ml estimators created by coarsening the hf resolution as in the case of lf 2x lf 5x and lf 10x for instance the 2 level ml estimator generated by hf and lf 2x outperformed by 10 the same cost ml estimator constructed with hf and lf cv this observation agrees with the statement made at the end of section 2 1 that the variance decay can be proven to be satisfied only for levels based on numerical discretizations spatial temporal meshes and not for general hierarchies of models the second observation is that the combination of variance decay and cheaper calculations across levels provides the optimal recipe for constructing efficient ml estimators as the 4 level one generated in this work with fidelities hf lf 2x lf 5x and lf 10x levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x the mathematical explanation of this behavior can be inferred from the ml estimator s variance provided in eq 2 as it is composed by a sum of v y ℓ n ℓ and therefore reducing each of the addends results in an decrease of the total sum the results shown in fig 5 highlight the better performance of the ml with respect to the cv estimators in the case of lf models levels that present small bias and moderate cov as revealed in fig 4 however in a more general problem involving very complex non linear fire spreads in which such good lf models are more challenging to design and or discover the cv approach may be a more robust option thus hybridization strategies like for example the bi fidelity bf approximation fairbanks et al 2017 2020 jofre et al 2017 and the multilevel multifidelity mlmf approach geraci et al 2017 gorodetsky et al 2019 are promising extensions of the standard ml and cv methods for accelerating the convergence rate of statistical estimators in challenging wildfire spread scenarios 5 3 uncertainty propagation and quantification as discussed in the previous subsection the best performant mf estimators correspond to the cv constructed with hf and lf 5x and the ml generated by levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x the next step therefore is to utilize these mf estimators to propagate the uncertainty and quantify its impact on the qoi for the problem described in section 4 the precision in the prediction of the qoi by means of the mf estimators is given in terms of a coefficient of variation defined as cov mf v q ˆ mf q ˆ mf in the case of targeting cov mf 2 the best performant cv estimator requires approximately 4 hf and 1540 lf 5x realizations with an equivalent cost of 10 hf runs and the optimal ml estimator demands approximately 4 hf 61 lf 2x 695 lf 5x and 4862 lf 10x samples with an equivalent cost of 9 hf runs in contrast the same cov for a mc strategy based on hf i e cov mc 2 would require 1000 hf runs which is approximately 100 more expensive than using the mf estimators selected the estimation of ros under uncertainty using the mf and mc estimators for different hf equivalent costs is shown in fig 6 for all three estimators the predictions were not accurate when utilizing 2 hf equivalent runs however starting from 4 hf equivalent runs the cv and ml predictions rapidly improved by approaching the expected estimation approximated from 128 hf samples and reducing their variance whereas the mc estimator converged very slowly as revealed by the wide boxplots in fact even when utilizing the total 128 hf samples available the coefficient of variation of the mc prediction was cov mc 9 while it was cov mf 2 approximately 5 smaller for the mf strategies with less than 10 hf equivalent runs finally as indicated by the mc and mf approaches the prediction of ros tends to q 3 1 m s when increasing the precision of the three estimators this estimation of ros convergence can be understood as a conservative approximation due to the wide uncertainty ranges defined for the input parameters table 2 such a broad sampling space was used in this study to demonstrate the potential of mf approaches even when knowledge about critical fuel and weather variables is extremely scarce however at least a rough characterization of the wind field and easy to measure fuel properties such as fuel load and fuel bed depth will frequently be available in field experiments this knowledge allows narrowing the uncertainty input distribution thus reducing spread in the simulated qois and accelerating convergence in these cases the convergence trends shown in fig 6 are expected to improve for all mf estimators the relative efficiency of mf estimators however is not likely to change 5 4 variance based sensitivity analysis the final step is to characterize how the variability of the qoi is divided and allocated to the different sources of uncertainty present in the inputs of the problem by means of sa the classification of uncertainties is of main importance as it clearly indicates the modeler where to concentrate resources to decrease the input incertitude by means of for example improved physics modeling or by acquiring additional experimental data with the objective to maximize the reduction of output s variability there are many methods to perform sa ghanem et al 2017 for example regression analysis derivative based local methods screening variogram analysis of response surfaces variance based methods and scatter plots in this work the variance based approach based on sobol indices sobol 1993 was selected as it allows full exploration of the stochastic input space accounting for interactions and nonlinear responses the underlying principle of the methodology is to quantify the input and output uncertainties as probability distributions and decompose the output variance into parts attributable to input variables and their combinations the sensitivity of the output to an input variable is therefore measured by the amount of variance in the output caused by that input for the sa discussion focus was placed on the ml estimator as it performed moderately better than the mf cv strategy see sections 5 2 and 5 3 for details originally designed for the estimation of expectations as presented in section 2 1 ml has been recently extended to the estimation of higher order statistical moments such as variances bierig and chernov 2015 and covariances mycek and de lozzo 2020 the combination of these extensions allows to formulate sobol indices within a ml framework following the work by mycek de lozzo 2020 the first order sobol index s i associated to the i th random input ξ i and corresponding to the share of output variance attributable to ξ i individually can be written in pick and freeze formulation janon et al 2014 as 10 s i v ξ i e ξ i q ξ i v q v q ˆ ξ i ml v q ˆ ml where subindex ξ i indicates the stochastic input variable picked and held frozen based on the best performant ml estimator levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x characterized in sections 5 2 and 5 3 for a cov mf 2 a sa study for q ros is depicted in fig 7 utilizing sobol indices accelerated by means of the mf strategy described in the paragraph above computationally the savings with respect to a straightforward mc based sa are proportional to the speedup achieved by the mf estimator and it scales linearly with the number of stochastic input parameters in terms of impact on the qoi the sa results indicate that the fuel moisture fraction ξ 1 the fine fuel load ξ 3 and the speed of wind ξ 5 are the uncertainties responsible for most of the variation approximately 20 30 each followed in decreasing s i ml value by the depth of the fuel bed ξ 2 and the fuel particle sav ratio ξ 4 each of which account for a slightly smaller share of the total variance approximately 10 15 these results are in line with previous findings obtained utilizing empirical and semi empirical fire spread models for example salvador et al 2001 identified fuel depth and dead fuel moisture as the most influential parameters on fire rate of spread under moderate winds with the importance of wind speed increasing in high wind scenarios similarly anderson et al 2007 found that variations in wind speed and ambient humidity have the largest impact on the variability of the extensions burned moreover clark et al 2008 reported that wind speed and dead fuel moisture accounted for the majority of the variation on the rate of spread followed by fuel model parameters more recently the analysis performed by ervilha et al 2017 using pce identified the dead fuel moisture content as the most influencing parameter in the variability of rothermel s rate of spread followed in decreasing order by wind speed fuel bed depth and fuel particle sav ratio finally liu et al 2015 reported a slightly different order in parameter importance presenting highest sobol indices for wind speed followed by fuel bed depth and fuel particle sav ratio and lower contributions to ros variance by fuel load and fuel moisture 6 summary conclusions and future work performing uncertainty quantification in wildfire modeling studies is usually challenging due to the expensive high fidelity calculations required and the large number of uncertainties typically encountered consequently this work explored the applicability of state of the art multifidelity techniques to quantify uncertainty and conduct sensitivity analyses in wildland fire simulations by constructing and using multifidelity estimators this study was able to notably accelerate the propagation of aleatoric uncertainty through a cfd framework and quantify the sensitivity of the fire rate of spread to different weather and fuel variables on the basis of the problem of interest and methods considered the multifidelity estimators achieved speedups larger than 100 with respect to straightforward monte carlo methods particularly the multilevel method performed slightly better than the control variates due to the small bias and moderate variability of the low fidelity data generated however in a more general problem involving very complex fire behavior in which good low fidelity models are challenging to design and or discover the control variates approach may be a more robust option the acceleration of propagating uncertainty through the problem was leveraged to perform a sensitivity analysis the results indicate that the fuel moisture fraction the fine fuel load and the wind speed are the uncertainties responsible for most of the variation in fire rate of spread followed in decreasing order by the depth of the fuel bed and the fuel particle sav ratio to the best of the authors knowledge this work is the first study in which wildfire spread uncertainty is propagated and quantified using full physics cfd models the notable reduction in computing requirements achieved opens an avenue of further research in addition to the analysis of other qois this study may be extended to quantify aleatoric uncertainty emanating from additional weather fuel and terrain dependent variables that are not resolved in empirical and semi empirical models furthermore multifidelity strategies may facilitate for the first time a detailed analysis of parametric uncertainties related to specific physical and chemical phenomena such as pyrolysis and combustion reactions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was financially supported by the beatriz galindo program distinguished researcher bgp18 00026 of the ministerio de ciencia innovación y universidades spain the authors thank the anonymous reviewers for their valuable comments and suggestions that helped improve the quality of the paper the work presented in this paper used the extreme science and engineering discovery environment xsede which is supported by the national science foundation nsf grant no aci 1548562 in particular the authors acknowledge the texas advanced computing center tacc at the university of texas at austin through allocation tg cts190073 for providing high performance computing resources that have contributed to the results presented in this paper 
25823,wildfire behavior predictions typically suffer from significant uncertainty however wildfire modeling uncertainties remain largely unquantified in the literature mainly due to computing constraints new multifidelity techniques provide a promising opportunity to overcome these limitations therefore this paper explores the applicability of multifidelity approaches to wildland fire spread prediction problems using a canonical simulation scenario we assessed the performance of control variates monte carlo mc and multilevel mc strategies achieving speedups of up to 100x in comparison to a standard mc method this improvement was leveraged to quantify aleatoric uncertainties and analyze the sensitivity of the fire rate of spread ros to weather and fuel parameters using a full physics fire model namely the wildland urban interface fire dynamics simulator wfds at an affordable computation cost the proposed methodology may also be used to analyze uncertainty in other relevant fire behavior metrics such as heat transfer fuel consumption and smoke production indicators keywords forest fire multifidelity monte carlo predictive science engineering sensitivity analysis uncertainty quantification fds glossary of acronyms cfd computational fluid dynamics cov coefficient of variation cv control variates csiro commonwealth scientific and industrial research organisation fds fire dynamics simulator gsa global sensitivity analysis hf high fidelity lf low fidelity mc monte carlo mf multifidelity ml multilevel mse mean squared error pce polynomial chaos expansion pde partial differential equation qoi quantity of interest ros rate of spread sa sensitivity analysis sav surface area to volume ratio uq uncertainty quantification v v verification and validation wfds wildland urban interface fire dynamics simulator 1 introduction the number of uncertainties involved in the study of wildfire spread is typically large due to i the modeling assumptions required to mathematically describe the different physics and their couplings i e epistemic uncertainty and ii the aleatoric incertitude resulting for instance from the lack of detailed evidence regarding initial and boundary conditions therefore numerical analyses based on a single deterministic realization for a particular set of input parameters are typically not conclusive and neither truly predictive arca et al 2007 alexander and cruz 2013 cruz and alexander 2013 filippi et al 2014 sá et al 2017 cruz et al 2018 a solution to this problem is to consider the system under study stochastic and analyze the relationship between input and output probability distributions by means of efficient statistical methods in this regard the fields of uncertainty quantification uq and sensitivity analysis sa have remarkably grown over the last decades within the computational fluid dynamics cfd community najm 2009 masquelet et al 2017 jofre et al 2018 2019 and it is now extensively accepted that the potential of estimating and minimizing uncertainties in combination with numerical verification and physics validation v v is crucial for augmenting the confidence in the numerical predictions in the specific case of wildfire spread modeling and prediction uncertainty quantification is essential to prioritize the needs in data collection inform decisions about future research investments and improve communication between modelers and managers leading to more informed fire management decisions riley and thompson 2016 the benefits of quantifying uncertainty in wildfire spread studies have already been demonstrated see for instance cruz 2010 and multiple authors have emphasized the need to improve the statistical characterization of fire model outputs benali et al 2016 pinto et al 2016 ramirez et al 2019 however previous attempts to quantify uncertainty in forest fire modeling suffer from significant limitations primarily caused by unattainable computing requirements full physics models which carefully resolve and or model the physical and chemical phenomena involved in fire spread are too computationally expensive to be used within monte carlo mc analyses consequently most of the previous studies on fire spread uncertainty have been restricted to rothermel s semi empirical model rothermel 1972 and a few other completely empirical formulations e g cheney and gould 1997 cruz et al 2008 liu et al 2014 one of the first attempts to apply global sensitivity analysis gsa techniques to rothermel s model was carried out by salvador et al 2001 since then several authors have extended their work anderson et al 2007 quantified aleatoric uncertainties by applying random perturbations to weather variables namely temperature relative humidity wind speed and wind direction in a monte carlo fashion a similar approach was followed by finney et al 2011 who proposed a probabilistic framework to account for uncertainties in weather variables based on ensemble simulations of the fire spread model described by finney 2002 cruz 2010 studied the response of another fully empirical model to 10 m open wind speed and dead fuel moisture content later cruz and alexander 2017 extended the work of cruz 2010 to account for crown fire ignition and spread they continued to use fuel moisture content and wind speed as uncertain inputs and they added uncertainty ranges to fuel structure parameters such as fuel load surface fuel depth canopy base height stand height and canopy bulk density alternatively to the mc approach which may become computationally prohibitive for large sample sizes bachmann and allöwer 2002 assessed uncertainty propagation in rothermel s model using a first order approximation based on a taylor series expansion in a similar attempt to reduce the computational cost of the original mc method jimenez et al 2008 proposed a sampling algorithm to accelerate convergence using sensitivity derivative information such algorithms prioritize the input variables that have a larger impact on the model outputs to reduce the dimensionality of the problem however that approach can only be applied to differentiable formulations that meet certain smoothness conditions liu et al 2015 extended the work of jimenez et al 2008 by using gsa techniques to simplify the fuel representation required in rothermel s fire spread model afterwards they combined a sensitivity derivative enhanced sampling sdes algorithm with a control variates scheme to accelerate the convergence of a randomized quasi mc method to quantify aleatoric uncertainties recently yuan et al 2020 presented a first attempt to characterize epistemic uncertainty in a semi physical fire spread model developed by liu et al 2014 specifically they studied the effect on fire rate of spread of model parameters that describe energy transfer including flame temperature and emissivity flame length and tilt angle fuel temperature of ignition fuel consumption efficiency and the heat convection coefficient despite the recent improvements in uncertainty quantification studies focused on wildfire spread no study so far has included full physics models in the analysis while empirical and semi empirical fire spread models are of most value for rapid operational purposes they do not resolve physical and chemical phenomena essential to accurately describe fire behavior this fact has two important implications first not resolving fundamental physics mechanisms prevents the study of epistemic uncertainties related to such phenomena second because empirical models are built upon statistical relationships between macroscopic variables rather than physical principles their application cannot be easily extrapolated beyond the conditions used to develop the models acquiring experimental data in a range of conditions wide enough to generalize empirical models is practically unfeasible which also limits the study of aleatoric uncertainties conversely physics based cfd simulators which are intended to resolve and or model all relevant physical and chemical mechanisms that characterize wildfire spread are exceedingly expensive to be used within uncertainty quantification studies based on standard mc methodologies the resulting high dimensional parameter space in conjunction with the large computational demands of the simulation runs required necessitates cost efficient non intrusive i e sampling based uq methods that accurately estimate the statistics of the quantities of interest qoi many widely used non intrusive methods such as stochastic collocation mathelin and hussaini 2003 xiu and hesthaven 2005 and polynomial chaos expansions pce ghanem and spanos 2003 xiu and karniadakis 2002 doostan and owhadi 2011 suffer from a rapid up to exponential growth of computational cost as a function of the number of input variables characterizing the uncertainty on the other hand mc methods are popular and powerful approaches for the estimation of statistical parameters due to their robust convergence behavior independent of the number of uncertainties however it is well known that the mean square error mse of the mc estimator converges slowly as a function of the sample size n this slow convergence may thus become a critical issue or even prohibitive especially if sampling involves computationally expensive operations such as solving a discretized partial differential equation pde recent research has targeted the development of cost reduction techniques to improve mc sampling methods which are usually based on multifidelity mf methodologies in mf frameworks high fidelity hf models are exploited to provide the required level of accuracy and insight into detailed physical phenomena whereas low fidelity lf simulations are leveraged to economically improve the statistical characterization of modeled qois at present the performance of these strategies has been mainly assessed on canonical pdes and rather simplified flow problems however to the best of the authors knowledge very few uq studies of complex large scale high dimensional systems have been conducted and published in the literature selected recent examples include shock turbulent boundary layer interaction in scramjet engines bermejo moreno et al 2012 analysis and optimization of high performance aircraft nozzles alonso et al 2017 multiphase flow simulations of cloud cavitation collapse sukys et al 2017 and the study of radiative heat transfer in particle laden turbulence jofre et al 2020 therefore the objective of this work is to demonstrate the potential of mf techniques to reduce the computing requirements of performing uncertainty quantification and sensitivity analysis in physics based wildfire spread computational predictions allowing in this manner a more complete characterization of aleatoric and epistemic uncertainties the paper is organized as follows first a description of the considered mf strategies is provided in section 2 next section 3 introduces the wildfire models utilized section 4 presents the canonical simulation problem analyzed in this paper and section 5 describes and discusses the results obtained finally section 6 summarizes the work provides conclusions and proposes future research 2 multifidelity sampling strategies in computational science and engineering multiple physical mathematical numerical models with different features can be constructed to characterize a system of interest typically computationally expensive hf models are designed to describe the system with the degree of accuracy required by the problem under study while lf models are formulated as cheaper representations usually at the expense of lower accuracy robustness or generality outer loop problems such as inference uq and optimization require large numbers of model evaluations for different input values resulting in unaffordable computational requirements in the case of large scale multiphysics calculations the objective of mf methods therefore is to reduce the cost of the outer loop problem by combining the accuracy of the hf models with the speedup achieved by the lf representations different mf uq strategies exist in the literature see for example the reviews by peherstorfer et al 2018 and fernandez godino et al 2016 2019 however due to the high dimensional input space and the complexity of the conservation equations involved this study is restricted to a reduced subset of acceleration strategies appertaining to surrogate based mc type sampling approaches as its name indicates mc type approaches are derived from the original monte carlo method in which the expectation of the qoi as a function of the stochastic inputs ξ q q ξ is estimated via a sample average let e q and v q denote the mean and variance of q given n independent realizations of the stochastic input denoted ξ i the mc estimator of e q is defined as q ˆ n mc n 1 i 1 n q i where q i q ξ i although unbiased the precision of q ˆ n mc measured by its standard deviation v q n decays slowly as a function of n therefore for a fixed computational budget n a viable alternative to increase the mc precision is to possibly replace q with other quantities with smaller variances 2 1 multilevel monte carlo one of the most popular acceleration strategies is the multilevel ml method giles 2008 adcock et al 2020 this technique inspired by the multigrid solver idea in linear algebra is based on evaluating realizations of q from a hierarchy of models with different levels ℓ ℓ 0 l with l the most accurate model in which q is replaced by the sum of differences y ℓ q ℓ q ℓ 1 to simplify the notation for level 0 the expression is redefined to y 0 q 0 as a result the qois of the original and new ml problems have the same mean e q an example of a level is the grid resolution considered for solving the system of equations so that a lf or hf model can be established by simulating q on a coarse or fine grid then e q can be computed using the ml qoi and an independent mc estimator on each level ℓ as 1 q ˆ ml ℓ 0 l y ˆ ℓ mc ℓ 0 l 1 n ℓ i 1 n ℓ y ℓ i this approach is referred to as multilevel monte carlo mlmc or simply ml and the resulting estimator has a variance equal to 2 v q ˆ ml ℓ 0 l v y ℓ n ℓ consequently if the level definition is such that q ℓ q in mean square sense then v y ℓ 0 as ℓ and therefore fewer samples are required on the finer level l in particular it is possible to show that the optimal sample allocation across levels n ℓ is obtained in closed form given a target variance of the ml estimator equal to ε 2 2 and resulting in giles 2008 3 n ℓ k 0 l c k v y k ε 2 2 v y ℓ c ℓ where the computational cost of the individual y ℓ evaluations is denoted by c ℓ and ε 2 represents the mse of the estimator it is important to note that the variance decay can be proven to be satisfied only for levels based on a numerical discretization spatial temporal meshes and not for general hierarchies of models such as 2 d versus 1 d large eddy simulation les versus reynolds averaged navier stokes rans etc 2 2 control variates monte carlo to accommodate lf representations that are not obtained directly from coarsening the hf models a common approach is to utilize lf realizations as a control variate peherstorfer et al 2018 pasupathy et al 2014 geraci et al 2017 in statistics the control variates approach replaces a generic quantity q by q α e g g where g is a function chosen for its high correlation with q and for which the value of e g is readily available however in the problem of interest here the lf correlations and expected values are not available a priori and consequently need to be established during the computations along with the hf calculations as a consequence the expected values of the lf models are generally approximated by means of mc estimators requiring a set of additional independent lf computations the control variates cv mc estimator is defined as 4 q ˆ cv q ˆ hf mc α e q lf q ˆ lf mc where q ˆ hf mc n hf 1 i 1 n hf q hf i e q lf n lf n hf 1 1 i n hf 1 n lf q lf i q ˆ lf mc n hf 1 i 1 n hf q lf i n hf and n lf are the number of hf and lf samples respectively and α c q hf q lf v q lf is the control variates coefficient chosen to minimize the variance of q ˆ cv c q hf q lf denotes the covariance between q hf and q lf the optimal α selection leads to 5 v q ˆ cv v q hf 1 ρ 2 r r 1 with 1 ρ c q hf q lf v q hf v q lf 1 the pearson correlation coefficient between the hf and lf models and r is used to parameterize the additional r n hf lf realizations with respect to hf as described by geraci et al 2017 the optimal control variates is obtained for 6 r c hf c lf ρ 2 1 ρ 2 1 where c hf and c lf are the costs of a hf and lf sample respectively a comprehensive description of the control variates mc estimator like for example the derivation of optimal coefficients and number of samples per fidelity is detailed in peherstorfer et al 2018 3 wildfire spread models over the past decades numerous approaches have been proposed to model and predict wildfire behavior these strategies range from completely empirical correlations to detailed physics based simulation frameworks see for instance sullivan 2009a 2009b 2009c for a comprehensive review tools designed to be used operationally for decision support need to be computationally fast and provide easy to interpret information regarding macroscopic variables such as rate of spread flame height and fire line intensity therefore operational simulators are frequently built upon empirical or semi empirical models conversely the detailed study of fire dynamics requires additional insight into the physical and chemical phenomena involved in fire spread including among others pyrolysis combustion heat transfer and turbulence such level of detail can only be achieved by means of cfd approaches which typically require intense computing resources that are several orders of magnitude larger than what operational simulators demand one of the most popular solutions among operational wildfire simulators is the rothermel model rothermel 1972 based on semi empirical relationships between the parameters that determine the heat emitted by the fire and the energy needed by the unburned fuel to ignite the rothermel model provides a well balanced combination of physical insight and operational capabilities while its application requires empirical adjustment of fuel and wind parameters the fact that such parameters are defined following physical principles facilitates extrapolating the use of the model to new vegetation types and diverse weather conditions nonetheless the rothermel model has important limitations and consequently it is usually coupled with additional models that account for phenomena not considered initially such as crown ignition and spotting from a full physics modeling perspective several cfd simulation frameworks have been designed specifically for wildfire applications some of the most popular solutions include the wildland urban interface fire dynamics simulator wfds mell et al 2007 firetec linn et al 2002 and firestar morvan et al 2006 2018 wfds was selected in this study due to its widespread adoption by the scientific community wfds is currently part of the broader fire dynamics simulator fds forney et al 2003 floyd and mcgrattan 2008 a cfd fire and smoke simulation tool widely used for fire safety applications fds is an open source solver 1 1 https github com firemodels fds maintained by the us national institute of standards and technology nist and jointly developed by several academic institutions in multiple countries finally there exist a variety of fully empirical fire models that have demonstrated high accuracy and applicability when used within specific parameter ranges these models were not included in the present analysis due to the wide range of alternatives available but they constitute an important pool of lf candidates to be considered in the mf strategies introduced in section 2 the subsections below provide further details on the wildfire models used in this study 3 1 the rothermel model rothermel s original formulation initially published in 1972 rothermel 1972 is based on an energy balance between the heat emitted by a flaming fire front and the energy required to ignite the fuel ahead of it the model is given by andrews 2018 7 r i r ξ 1 φ w φ s ρ b ε q i g where r is the fire rate of spread i r is the reaction intensity ρ b is the fuel bulk density and q i g is the heat required to ignite the fuel the remaining variables are empirical parameters that allow matching observed fire behavior to this simple formulation ξ is the propagating flux ratio and represents the portion of reaction intensity that propagates toward the unburned fuel φ w and φ s are named wind and slope factors respectively and account for the increase in heat transfer that occurs when the fire spreads in the direction of the wind and or upslope finally ε is an efficiency parameter dependent on the fuel particle size and shape rothermel developed empirical functions so that the value of these variables could be derived directly from fuel and environmental parameters providing in this manner physical intuition to their calibration through such empirical relationships the fire rate of spread can ultimately be expressed as a function of fuel heat content h fuel total mineral content s t fuel effective mineral content s e oven dry fuel particle density ρ p fuel particle surface area to volume sav ratio σ oven dry fuel load w 0 fuel bed depth δ dead fuel moisture of extinction m x fuel moisture content m f wind velocity at midflame height u and terrain slope φ in the form 8 r f h s t s e ρ p σ w 0 δ m x m f u φ following the formulation outlined in eq 8 the fuel related parameters are usually grouped into standard categories that broadly represent the most common vegetation distributions such categories are known as fuel models and have experienced substantial development since the first version proposed by rothermel multiple authors have highlighted the importance of the fuel input parameters on the predictive capability of fire spread achieved by the rothermel model e g arca et al 2007 for this reason ad hoc fuel models are usually developed prior to applying the rothermel model to a new geographical area and or vegetation type the original rothermel model is one dimensional 1d and consequently its practical application requires coupling it with a two dimensional 2d propagation scheme several propagation methodologies have been proposed following eulerian and lagrangian approaches bova et al 2016 furthermore the rothermel model has been incorporated into a significant number of 1d and 2d simulators such as behaveplus heinsch and andrews 2010 farsite finney 1998 and wrf sfire mandel et al 2011 which are at present extensively used internationally by fire managers and researchers 3 2 wildland urban interface fire dynamics simulator wfds was designed as an extension of fds to include fire spread in vegetative fuels mell et al 2007 fds is a cfd model of fire driven fluid flow which numerically solves a form of the navier stokes equations appropriate for low speed mach numbers below m a 0 3 thermally driven flow with an emphasis on smoke and heat transport from fires it is widely used in fire protection engineering problems and its applicability to study fundamental fire dynamics and combustion phenomena is gaining increasing attention the core hydrodynamic formulation is solved by an explicit predictor corrector scheme which is second order accurate in space and time and spatially discretized on a rectilinear mesh by default the small scale turbulent fluctuations are modeled by means of les strategies although it is possible to perform direct numerical simulations dns if the underlying numerical mesh is fine enough for most applications combustion is modeled through a single step mixing controlled chemical reaction radiative heat transfer is included in the model and solved via a discrete ordinates method dom with a default number of 100 discretization angles the radiation transport equation is solved for a grey gas and in some limited cases using a wide band model in addition fds includes langrangian particle tracking capabilities to represent elements that are not captured by the eulerian grid mcgrattan et al 2019a like for example fuel and soot particles the wfds extension now merged into fds added the functionalities needed to i describe vegetative fuels ii resolve convective and radiative heat transfer within those fuels and iii calculate their thermal degradation pyrolysis and combustion 4 description of the wildfire spread scenario the mf techniques presented in section 2 were applied to the canonical wildfire spread simulation problem described below the analyzed scenario belongs to a set of medium scale field fire experiments conducted by the commonwealth scientific and industrial research organisation csiro in the northern territory of australia in 1986 cheney et al 1993 these tests were monitored to measure the fire rate of spread and evaluate its correlation with fuel and weather variables such as fuel height fuel moisture content fuel load fuel bulk density and wind speed two of the experiments had been simulated using wfds mell et al 2007 and incorporated into the fds test suite as validation examples mcgrattan et al 2019b furthermore the fact that the experiments were conducted on horizontal grassland fields facilitates the application of rothermel s model for surface fire spread particularly this study considers the csiro grassland f19 experiment which burned a square field of 200 m 200 m using a 175 m long ignition line this type of experiment design is very frequent in wildfire behavior studies 4 1 problem setup the setup of the problem is depicted in fig 1 this configuration was generated with wfds by reproducing the validation study performed by mell et al 2007 for the hf samples the computational domain of size 240 m 240 m 20 m was discretized using a uniform cartesian grid with δ 0 5 m resolution turbulence was solved by means of a les strategy based on deardorff s turbulent viscosity model time integration was performed by limiting the courant friedrichs lewy cfl value to cfl 1 and radiation transport was calculated utilizing a dom method with 100 discrete angles mcgrattan et al 2019a vegetation grass was represented as a homogeneous bed of lagrangian combustible particles whose main physical and chemical properties are summarized in table 1 grass particles were arranged in a rectangular prismatic space with a predefined bulk density and fuel bed depth these two parameters were included into the list of uncertainties analyzed together with the fuel moisture fraction and the particle sav ratio see section 4 2 for a detailed discussion of their values 4 2 uncertainties and quantities of interest wildfire spread modeling requires the selection of a large number of parameters however most of the aleatoric uncertainty is usually concentrated in a limited subset of the input variables previous works identified the following variables as significant sources of aleatoric uncertainty in wildfire spread 1 h fuel moisture content salvador et al 2001 clark et al 2008 finney et al 2011 ervilha et al 2017 1 h fuel load liu et al 2015 cai et al 2019 fuel bed depth salvador et al 2001 jimenez et al 2008 liu et al 2015 ervilha et al 2017 cai et al 2019 fuel particle sav ratio jimenez et al 2008 liu et al 2015 ervilha et al 2017 cai et al 2019 and wind speed salvador et al 2001 anderson et al 2007 jimenez et al 2008 clark et al 2008 finney et al 2011 liu et al 2015 benali et al 2016 ervilha et al 2017 consequently this list of variables were considered as uncertain inputs ξ i in this work with their stochastic ranges characterized from studies and experiments available in the scientific literature scott and burgan 2005 summarized a series of standardized fuel models which are extensively used at present to model fire behavior their list of models contains 9 grass type options each of them with a characteristic value of fine fuel load sav ratio and packing ratio additionally they suggested a range of dead fuel moisture and wind conditions to evaluate these fuel models the data variability considered by scott and burgan 2005 was used in the present study to limit the sampling space as detailed in table 2 in the case of wind speed mid flame estimations were converted to values at a 20 feet height using a conversion factor of 0 4 as recommended by the us national wildfire coordinating group estimating winds for fire behavior 2019 amidst the large number of output statistics that can be obtained from a wildfire spread calculation the fire rate of spread ros is one of the most critical quantities to understand fire behavior and its effects on the environment o brien et al 2016 among other applications ros provides a quantitative representation of fire evolution and it can be used to analyze the effect of varying weather conditions or possible fuel treatments in a specific area consequently this study uses the rate of spread averaged in the simulation domain as qoi simulated ros was measured by recording the longitudinal coordinate of the point with maximum gas temperature at every time step the search for maximum temperatures was restricted to a narrow longitudinal band placed along the domain symmetry plane and close to the ground the resulting time distance distribution was fitted to a linear function in order to estimate the average ros 4 3 multifidelity modeling strategy the mf strategies described in section 2 rely on the construction of levels with different ratios of fidelity and computational cost to accelerate the process of reducing the variance of the estimators diverse approaches can be pursued to develop such cheaper models with the only requirement that these lower fidelity representations need to be orders of magnitude faster to compute while maintaining some degree of interdependence the higher the better with the qoi calculated at the different levels in this work two different methods to build coarser representations of the hf simulation were tested the first strategy is based on the ml method in which the hf cfd scenario is resolved using decreasing levels of resolution in i flow cell size ii integration time step δ t and iii number of discrete angles utilized to resolve the radiative heat transport based on preliminary tests we designed three different levels named lf 2x lf 5x and lf 10x which are 25 250 and 2500 cheaper to compute than the hf level respectively the different resolution levels for i and iii are specified in table 3 the integration time step was automatically adjusted at every iteration based on the cfl constraint approximately a cell size increase of 2 corresponds to a two fold increase of δ t the second approach explores the benefits of introducing the output of the rothermel fire spread model as a control variate this was accomplished through the execution of farsite simulations for a similar scenario and with the same input parameters this fidelity is referred to as lf cv and is 2500 faster to compute than the hf level a visualization of a sample output obtained from farsite is depicted in fig 2 the map of fire time of arrival was used to compute an average value for the ros 5 results and discussion this section presents and analyzes the data and results for the problem described in section 4 which were obtained by running hf and lf simulations based on the modeling approaches described in section 3 and provides a discussion of the statistics calculated by utilizing the methodologies introduced in section 2 first section 5 1 presents a concise statistical characterization of the ros the qoi considered in this work for the different fidelities next in section 5 2 the performance of various mf estimators is studied to select the optimal strategies in terms of balancing variance reduction correlation and computational costs the list of mf designs considered is visually summarized in table 4 in section 5 3 the uncertainty of the problem is propagated through the model and quantified by making use of the acceleration techniques chosen in the previous subsection finally section 5 4 discusses a variance based sensitivity analysis performed to rank the effect of the uncertainties on qoi variability 5 1 pilot sampling of the quantity of interest as a first step to construct efficient mf estimators exploratory data was collected by running the same 32 pilot samples for the 5 fidelities designed this set of samples were generated following a design of experiment doe based on the kdoe approach roy et al 2020 kdoe is an iterative method that introduces stochasticity in the sampling process by means of a variable kernel density estimation to optimize the uniformity of the doe this approach provides a more homogeneous exploration of the input parameter space especially when the number of samples is relatively small for example instantaneous snapshots of the vertical velocity field for the first sample generated by the hf lf 2x lf 5x and lf 10x fidelities are depicted in fig 3 it can be inferred from these snapshots that i the lowest resolution fidelities e g lf 10x tend to underresolve eddies located at the fire front which could affect the rate of convective heat transfer and consequently the predicted fire rate of spread ii nonetheless larger scale turbulent motions are sufficiently resolved with buoyancy pulses present in all fidelity levels iii velocity values maintain similar absolute ranges across all fidelity levels although iv the velocity field becomes increasingly diffused in space as spatial resolution decreases conclusive arguments however cannot be obtained by solely analyzing fig 3 as i the qoi targeted in this work is the average ros and ii the performance of the mf estimators is not directly related to a first order approximation to the accuracy of the lf results with respect to the hf data the data generated from the pilot samples for the different fidelities were collected and visually summarized in fig 4 by means of boxplots the fidelities are sorted left to right in decreasing computational cost starting from hf ending with lf 10x and spanning a total of 4 orders of magnitude as stated in the paragraph above the accuracy of the lf data with respect to the hf results is not the principal component for the performance of the ml and cv estimators as they are respectively formulated in terms of variance reduction and correlation nevertheless it is instructive to analyze the relations between the hf and lf data from a statistical perspective to gain insight and facilitate the effective construction of the mf estimators the distributions in fig 4 show that the data are organized in 2 main blocks across fidelities i hf lf 2x lf 5x and lf 10x generate data distributed around q 2 5 and displaying coefficients of variation with values cov v q e q 0 4 whereas ii lf cv tends to underestimate q by approximately 1 6 and presents a significantly larger cov 0 7 5 2 performance of the multifidelity estimators the performance of various candidate mf estimators constructed by means of cv and ml strategies was analyzed by utilizing the pilot data described in the previous subsection as discussed in section 2 the speedup obtained by the ml and cv approaches is function respectively of the variance of y ℓ v y ℓ in eq 2 and the pearson correlation coefficient ρ between fidelities in eq 5 consequently v y ℓ and ρ for all potential combinations are listed in table 5 in the case of cv based mf estimators which are constructed utilizing hf information and lf samples as a control variate the best lf candidates are lf 2x and lf 5x as they present correlations of ρ 0 995 and ρ 0 990 with speedups of approximately 25 and 250 respectively instead lf cv and lf 10x are slightly less correlated with hf as their values are ρ 0 884 and ρ 0 869 if considering ml strategies in which hf and different lf are combined forming a telescopic sum a good hierarchical structure is composed by the lower fidelities lf 2x lf 5x and lf 10x as their v y ℓ values decay orders of magnitude 0 002 0 017 and 0 224 specifically while becoming 25 250 and 2500 faster to compute than hf the extrapolated performances of a straightforward mc approach and the cv and ml estimators proposed above are reported in fig 5 the horizontal logarithmic scale axis corresponds to the total cost of each estimator normalized by the cost of a hf sample the total costs are evaluated as c mc n hf c hf c cv n hf c hf r c lf and c ml ℓ 0 l n ℓ c ℓ for the mc cv and ml respectively on the vertical logarithmic scale axis target estimators mse ε 2 v q ˆ normalized by a reference mc value ε 0 mc 2 obtained from the 32 pilot samples are shown for mc and ml estimators through evaluating eq 3 and for the cv estimators utilizing the expression peherstorfer et al 2018 9 ε 2 ε 0 mc 2 1 ρ 2 c lf c hf ρ 2 2 the results depicted in fig 5 show that the speedups of the mf estimators with respect to mc are in the order of 100 to 1000 for the best performant cv constructed with hf and lf 5x and ml generated by levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x strategies respectively for example to reduce ε 2 by an order of magnitude with respect to ε 0 mc 2 the mc approach requires computing 320 hf runs while the cv composed by 1 hf and 493 lf 5x samples and ml composed by 1 hf 19 lf 2x 222 lf 5x and 1556 lf 10x samples demand only 3 0 and 2 8 equivalent hf runs studying in detail the differences in performance between the candidate cv estimators considered at the beginning of this subsection it is clear from fig 5 that ρ is a very important parameter for maximizing the speedup in particular the lower fidelities lf cv and lf 10x which present correlation coefficients slightly smaller than lf 2x and lf 5x performed only 10 faster than mc instead of 100 even in the case of using lf 10x that is 10 and 100 faster than lf 2x and lf 5x respectively this observation is corroborated by the mathematical expression of the cv estimator s variance given in eq 5 in which the impact of ρ on the reduction of v q ˆ cv is quadratic while sublinearly proportional to the ratio c hf c lf through the parameter r however if two or more fidelities have similar correlation with hf the computational cost becomes the dominant parameter and the cheapest lf generates the most efficient cv estimator as in the case of lf 2x and lf 5x in which the latter is the best performant option carefully analyzing the speedups of the ml estimators considered in fig 5 two observations can be made the first observation is that ml strategies based on utilizing lf cv realizations which are not generated from coarsening the hf model notably underperformed with respect to standard ml estimators created by coarsening the hf resolution as in the case of lf 2x lf 5x and lf 10x for instance the 2 level ml estimator generated by hf and lf 2x outperformed by 10 the same cost ml estimator constructed with hf and lf cv this observation agrees with the statement made at the end of section 2 1 that the variance decay can be proven to be satisfied only for levels based on numerical discretizations spatial temporal meshes and not for general hierarchies of models the second observation is that the combination of variance decay and cheaper calculations across levels provides the optimal recipe for constructing efficient ml estimators as the 4 level one generated in this work with fidelities hf lf 2x lf 5x and lf 10x levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x the mathematical explanation of this behavior can be inferred from the ml estimator s variance provided in eq 2 as it is composed by a sum of v y ℓ n ℓ and therefore reducing each of the addends results in an decrease of the total sum the results shown in fig 5 highlight the better performance of the ml with respect to the cv estimators in the case of lf models levels that present small bias and moderate cov as revealed in fig 4 however in a more general problem involving very complex non linear fire spreads in which such good lf models are more challenging to design and or discover the cv approach may be a more robust option thus hybridization strategies like for example the bi fidelity bf approximation fairbanks et al 2017 2020 jofre et al 2017 and the multilevel multifidelity mlmf approach geraci et al 2017 gorodetsky et al 2019 are promising extensions of the standard ml and cv methods for accelerating the convergence rate of statistical estimators in challenging wildfire spread scenarios 5 3 uncertainty propagation and quantification as discussed in the previous subsection the best performant mf estimators correspond to the cv constructed with hf and lf 5x and the ml generated by levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x the next step therefore is to utilize these mf estimators to propagate the uncertainty and quantify its impact on the qoi for the problem described in section 4 the precision in the prediction of the qoi by means of the mf estimators is given in terms of a coefficient of variation defined as cov mf v q ˆ mf q ˆ mf in the case of targeting cov mf 2 the best performant cv estimator requires approximately 4 hf and 1540 lf 5x realizations with an equivalent cost of 10 hf runs and the optimal ml estimator demands approximately 4 hf 61 lf 2x 695 lf 5x and 4862 lf 10x samples with an equivalent cost of 9 hf runs in contrast the same cov for a mc strategy based on hf i e cov mc 2 would require 1000 hf runs which is approximately 100 more expensive than using the mf estimators selected the estimation of ros under uncertainty using the mf and mc estimators for different hf equivalent costs is shown in fig 6 for all three estimators the predictions were not accurate when utilizing 2 hf equivalent runs however starting from 4 hf equivalent runs the cv and ml predictions rapidly improved by approaching the expected estimation approximated from 128 hf samples and reducing their variance whereas the mc estimator converged very slowly as revealed by the wide boxplots in fact even when utilizing the total 128 hf samples available the coefficient of variation of the mc prediction was cov mc 9 while it was cov mf 2 approximately 5 smaller for the mf strategies with less than 10 hf equivalent runs finally as indicated by the mc and mf approaches the prediction of ros tends to q 3 1 m s when increasing the precision of the three estimators this estimation of ros convergence can be understood as a conservative approximation due to the wide uncertainty ranges defined for the input parameters table 2 such a broad sampling space was used in this study to demonstrate the potential of mf approaches even when knowledge about critical fuel and weather variables is extremely scarce however at least a rough characterization of the wind field and easy to measure fuel properties such as fuel load and fuel bed depth will frequently be available in field experiments this knowledge allows narrowing the uncertainty input distribution thus reducing spread in the simulated qois and accelerating convergence in these cases the convergence trends shown in fig 6 are expected to improve for all mf estimators the relative efficiency of mf estimators however is not likely to change 5 4 variance based sensitivity analysis the final step is to characterize how the variability of the qoi is divided and allocated to the different sources of uncertainty present in the inputs of the problem by means of sa the classification of uncertainties is of main importance as it clearly indicates the modeler where to concentrate resources to decrease the input incertitude by means of for example improved physics modeling or by acquiring additional experimental data with the objective to maximize the reduction of output s variability there are many methods to perform sa ghanem et al 2017 for example regression analysis derivative based local methods screening variogram analysis of response surfaces variance based methods and scatter plots in this work the variance based approach based on sobol indices sobol 1993 was selected as it allows full exploration of the stochastic input space accounting for interactions and nonlinear responses the underlying principle of the methodology is to quantify the input and output uncertainties as probability distributions and decompose the output variance into parts attributable to input variables and their combinations the sensitivity of the output to an input variable is therefore measured by the amount of variance in the output caused by that input for the sa discussion focus was placed on the ml estimator as it performed moderately better than the mf cv strategy see sections 5 2 and 5 3 for details originally designed for the estimation of expectations as presented in section 2 1 ml has been recently extended to the estimation of higher order statistical moments such as variances bierig and chernov 2015 and covariances mycek and de lozzo 2020 the combination of these extensions allows to formulate sobol indices within a ml framework following the work by mycek de lozzo 2020 the first order sobol index s i associated to the i th random input ξ i and corresponding to the share of output variance attributable to ξ i individually can be written in pick and freeze formulation janon et al 2014 as 10 s i v ξ i e ξ i q ξ i v q v q ˆ ξ i ml v q ˆ ml where subindex ξ i indicates the stochastic input variable picked and held frozen based on the best performant ml estimator levels y 0 lf 10x y 1 lf 5x lf 10x y 2 lf 2x lf 5x and y 3 hf lf 2x characterized in sections 5 2 and 5 3 for a cov mf 2 a sa study for q ros is depicted in fig 7 utilizing sobol indices accelerated by means of the mf strategy described in the paragraph above computationally the savings with respect to a straightforward mc based sa are proportional to the speedup achieved by the mf estimator and it scales linearly with the number of stochastic input parameters in terms of impact on the qoi the sa results indicate that the fuel moisture fraction ξ 1 the fine fuel load ξ 3 and the speed of wind ξ 5 are the uncertainties responsible for most of the variation approximately 20 30 each followed in decreasing s i ml value by the depth of the fuel bed ξ 2 and the fuel particle sav ratio ξ 4 each of which account for a slightly smaller share of the total variance approximately 10 15 these results are in line with previous findings obtained utilizing empirical and semi empirical fire spread models for example salvador et al 2001 identified fuel depth and dead fuel moisture as the most influential parameters on fire rate of spread under moderate winds with the importance of wind speed increasing in high wind scenarios similarly anderson et al 2007 found that variations in wind speed and ambient humidity have the largest impact on the variability of the extensions burned moreover clark et al 2008 reported that wind speed and dead fuel moisture accounted for the majority of the variation on the rate of spread followed by fuel model parameters more recently the analysis performed by ervilha et al 2017 using pce identified the dead fuel moisture content as the most influencing parameter in the variability of rothermel s rate of spread followed in decreasing order by wind speed fuel bed depth and fuel particle sav ratio finally liu et al 2015 reported a slightly different order in parameter importance presenting highest sobol indices for wind speed followed by fuel bed depth and fuel particle sav ratio and lower contributions to ros variance by fuel load and fuel moisture 6 summary conclusions and future work performing uncertainty quantification in wildfire modeling studies is usually challenging due to the expensive high fidelity calculations required and the large number of uncertainties typically encountered consequently this work explored the applicability of state of the art multifidelity techniques to quantify uncertainty and conduct sensitivity analyses in wildland fire simulations by constructing and using multifidelity estimators this study was able to notably accelerate the propagation of aleatoric uncertainty through a cfd framework and quantify the sensitivity of the fire rate of spread to different weather and fuel variables on the basis of the problem of interest and methods considered the multifidelity estimators achieved speedups larger than 100 with respect to straightforward monte carlo methods particularly the multilevel method performed slightly better than the control variates due to the small bias and moderate variability of the low fidelity data generated however in a more general problem involving very complex fire behavior in which good low fidelity models are challenging to design and or discover the control variates approach may be a more robust option the acceleration of propagating uncertainty through the problem was leveraged to perform a sensitivity analysis the results indicate that the fuel moisture fraction the fine fuel load and the wind speed are the uncertainties responsible for most of the variation in fire rate of spread followed in decreasing order by the depth of the fuel bed and the fuel particle sav ratio to the best of the authors knowledge this work is the first study in which wildfire spread uncertainty is propagated and quantified using full physics cfd models the notable reduction in computing requirements achieved opens an avenue of further research in addition to the analysis of other qois this study may be extended to quantify aleatoric uncertainty emanating from additional weather fuel and terrain dependent variables that are not resolved in empirical and semi empirical models furthermore multifidelity strategies may facilitate for the first time a detailed analysis of parametric uncertainties related to specific physical and chemical phenomena such as pyrolysis and combustion reactions declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was financially supported by the beatriz galindo program distinguished researcher bgp18 00026 of the ministerio de ciencia innovación y universidades spain the authors thank the anonymous reviewers for their valuable comments and suggestions that helped improve the quality of the paper the work presented in this paper used the extreme science and engineering discovery environment xsede which is supported by the national science foundation nsf grant no aci 1548562 in particular the authors acknowledge the texas advanced computing center tacc at the university of texas at austin through allocation tg cts190073 for providing high performance computing resources that have contributed to the results presented in this paper 
25824,this study introduces the california food energy water system calfews simulation model to describe the integrated multi sector dynamics that emerge from the coordinated management of surface and groundwater supplies throughout california s central valley the calfews simulation framework links the operation of state wide interbasin transfer projects i e state water project central valley project with coordinated water management strategies abstracted to the scale of irrigation water districts this study contributes a historic baseline october 1996 september 2016 evaluation of the model s performance against observations including reservoir storage inter basin transfers environmental endpoints and groundwater banking accounts state aware rules based representations of critical component systems enable calfews to simulate adaptive management responses to alternative climate infrastructure and regulatory scenarios moreover calfews has been designed to maintain interoperability with electric power dispatch and agricultural production models as such calfews provides a platform to evaluate internally consistent scenarios for the integrated management of water supply energy generation and food production keywords adaptive management water resources groundwater recharge interbasin transfers dynamic simulation 1 introduction throughout the 20th century large scale water storage and conveyance projects were developed to support urban growth and agricultural production in california these projects have generated significant economic benefits for the state particularly within the central valley where water storage and conveyance infrastructure support irrigation in four of the five most productive agricultural counties in the united states usda 2012 however surface water deliveries from these projects are highly uncertain due to complex interactions between hydrologic variability environmental regulations and infrastructure capacity constraints cadwr 2018 water users are often able to partially mitigate surface water shortfalls by pumping groundwater but doing this repeatedly has resulted in substantial drawdowns of central valley aquifers particularly during recent droughts in 2007 2009 and 2012 2016 xiao et al 2017 in the tulare basin aquifers are managed through a network of groundwater recharge basins recovery wells and surface conveyance much of the capacity in this system has been developed through groundwater banking institutions in which excess surface water is recharged banked via spreading basins so that it can be subsequently recovered withdrawn during wetter periods christian smith 2013 recharge and recovery capacity have been developed jointly by local irrigators and municipal urban users from around the state wells fargo 2017 usbr 2013 operated through cooperative agreements and exchanges between municipal and agricultural sectors the importance of the groundwater banking system to both agricultural and municipal contractors underscores the need for simulation models that can capture multi scale institutional responses to floods and droughts ranging from state and federal management of reservoirs and inter basin transfer projects to local irrigation and groundwater banking decisions within the field of water resources systems analysis there is a growing recognition of the need for tools that enable the prediction of system dynamics and outcomes that provide the basis for evaluating the effects of exogenous changes and policy choices brown et al 2015 such tools are especially important in institutionally complex regions like california where infrastructure planning and the management of surface and groundwater supplies are subject to distributed decisions of many interacting agents with differing goals and unique contexts existing surface water models for california like calsim draper et al 2004 callite islam et al 2011 and calvin draper et al 2003 are deterministic mathematical programming mp models that represent reservoir systems using prescriptive optimization models to determine optimal water allocations at the statewide scale individual water suppliers like metropolitan water district groves et al 2015 and the inland empire utilities agency lempert and groves 2010 perform vulnerability assessments with customized regional weap models yates et al 2009 that use linear programming to solve constrained water allocation problems other mp models are widely used for drought planning labadie and larson 2007 zagona et al 2001 and recent work has shown how they can be coupled with non linear groundwater models to better reconcile the impact of surface groundwater substitution on stream aquifer interactions dogrul et al 2016 broadly this class of mp models are designed to determine optimal allocations of water given a set of welfare or benefit functions distributed through time they do not typically capture institutional interactions that govern surface water rights groundwater management and regulatory constraints on conveyance an accurate representation of operating agreements between institutions is critical for representing the water balance dynamics that arise from the interdependent management of extreme flood and drought events in california this manuscript presents a simulation based representation of california s coordinated water resources operations calfews by simulating water management decisions as a set of interacting responses to changing environmental conditions the calfews model provides a more detailed understanding of how water rights and regulatory institutions introduce heterogeneity in water resources systems the novel framework developed here is designed to address research questions related to the impacts of changes to operating policies infrastructure and or hydrologic conditions on institutional relationships across scales and sectors at a daily time step infrastructure and regulatory constraints impact the coordinated operations between statewide water import projects and their local contractors irrigation and water storage districts that are missed when aggregating operations to a monthly scale particularly with respect to periods of high flow during which water is most readily available for groundwater recharge groundwater banking institutions and other conjunctive use operations increase the importance of multi year path dependencies between these relatively short high flow periods and extended periods of drought the location magnitude and timing of groundwater recharge determine how much groundwater can be sustainably recovered in the future creating incentives for multi sector partnerships e g urban agricultural to more efficiently manage periods of high flows in an effort to increase resilience to multi year droughts cadwr 2020 calfews provides a framework to evaluate how institutional responses to continually changing conditions drive water distribution throughout california s central valley the calfews simulation based approach is capable of representing california s coordinated water resources operations across institutionally complex systems by conditioning actions on shared state variables that represent hydrologic and regulatory conditions as recommended by haimes 2018 within calfews a set of common dynamic state variables related to snowpack and streamflow are used to toggle between operating rules when they have been explicitly defined by the relevant stakeholders e g swrcb 1990 usace 1970 and to evaluate adaptive decision rules when operations are empirically derived from historical relationships as a daily simulation model state variables and operations can be evaluated relative to historical observations cdec 2020a at a number of critical locations throughout the central valley system including storage at 12 major surface water reservoirs pumping rates through swp and cvp facilities in the sacramento san joaquin delta delta that bring water into central and southern california estimates of delta salinity which can limit pumping and storage accounts in major groundwater banks see fig 1 simulation results can be directly compared to these observations as a means of quantifying how well decision rules simulate observed responses to the broad range of changing hydrologic cdec 2020b regulatory nmfs 2009 meade 2013 and infrastructure aecom 2016 usace 2017 conditions that have shaped system dynamics surrounding california s north south interbasin water transfers from the delta to contractors throughout central and southern california this simulation framework specifically supports monte carlo exploratory modelling results particularly with respect to irrigation deliveries and pumping requirements that can be linked to state of the art agricultural production howitt et al 2012 and electric power dispatch kern et al 2020 models decision rules are spatially resolved at the scale of individual irrigation and water districts which have historically been the primary unit of organization for consolidating water rights and financing water infrastructure in california particularly in the southern san joaquin and tulare basins hanak et al 2011 by allocating water through individual district turnouts on canals and natural channels the decisions are able to better reflect the relationship between water rights institutions and the ownership and operation of storage and conveyance infrastructure which is not possible using models that rely on broader regional aggregation of water supplies and demands calfews therefore operates at the spatial and temporal resolution required to link food energy and water systems through consistent hydrologic scenarios enabling it to serve as a useful platform for evaluating complex risks that can be transmitted between these systems bazilian et al 2011 liu 2016 cai et al 2018 haimes 2018 2 methods the calfews model simulates coupled water storage and conveyance networks in california s central valley fig 1 two large water transfer projects link the sacramento san joaquin and tulare basins first via swp and cvp delta pumping facilities that convey water to san luis reservoir and second through the friant kern canal complex environmental regulations constrain pumping based on hydrologic conditions in the delta state swp and federal cvp agencies manage delta hydrologic conditions and export pumping through coordinated releases from seven reservoirs in the sacramento and san joaquin headwaters individual irrigation and water districts control imports from san luis and millerton reservoirs through a shared network of canals connecting districts to the california aqueduct friant kern canal groundwater banks and local reservoir storage in wet years districts recharge aquifers with excess surface water when surface storage capacity becomes insufficient state and federal actions to manage flow storage and water exports interact with local decisions made by institutional users including irrigation and water storage districts calfews simulates this dynamic by linking infrastructure operations to institutional decisions tied to hydrologic and other water management states such as snowpack observations and reservoir storage the total number of each model node structure types by region is shown in table 1 the flow of information between observed states e g snowpack full natural flow distributed decision making e g reservoir releases groundwater recharge diversions and modelled state responses e g reservoir storage groundwater bank accounts during a single calfews simulation step are illustrated in fig 2 at the beginning of each time step new hydrologic input data are used to update observed states at storage regulatory and demand nodes throughout the sacramento san joaquin and tulare basins new observations along with seasonal trends extracted from a historical record are used to inform a battery of distributed heterogeneous decisions made by urban and agricultural water users reservoir operators and local imported water project managers modelled state variables including reservoir storage and groundwater account balances are updated by aggregating the distributed decisions through priority based operational rules that determine infrastructure capacity utilization fig 1 priority based rules refer to the relative priority between water contracts delivery types and ownership of joint assets like groundwater recharge capacity when sharing capacity within a canal contracts with a higher priority are delivered first e g friant class 2 contracts can only be delivered via canal capacity that remains after all friant class 1 contracts are delivered likewise some delivery types are also prioritized over others e g flood release deliveries can only be delivered using canal capacity that remains after normal contract deliveries are filled if capacity must be shared among delivery contracts and or types with equal priority the capacity is shared proportionally based on demands at each node as described in equations 34 and 35 hydrologic preprocessing and reservoir decisions extend an initial study in the sacramento valley by cohen et al 2020 the methods section is organized into four parts describing i how observed state variables are defined based on hydrologic data ii how metrics used to drive management decisions are calculated from observed and modelled state variables iii how management decisions are triggered through applying seasonal adaptive thresholds to the calculated metrics and iv how distributed management decisions are aggregated to update modelled state variables 2 1 hydrologic data and observed state variables daily hydrologic time series data obtained through the california data exchange center cdec are used to update hydrologic states at storage nodes reservoirs regulatory nodes flow gauge and demand nodes irrigation water districts groundwater banks and urban withdrawal points at a daily time step storage nodes are associated with cdec full natural flow reservoir inflow and snowpack stations as listed in table 2 full natural flow and snowpack observations are state variables used for distributed decisions and do not directly interact with calfews infrastructure flow observations from reservoir inflow nodes are used to make daily storage updates regulatory nodes use downstream flow observations to generate incremental flows within a given reach based on the difference between cdec flow gauge data and upstream releases such that 1 i n c r t d o w n r t w u r w u t r u i n c r u t where inc incremental flows m3 s down flow at downstream gauge location m3 s r upstream release m3 s r regulatory node w u reservoirs upstream of regulatory node r r u regulatory nodes upstream of regulatory node r t time step index incremental flows aggregate the unobserved contribution of uncontrolled tributaries stream aquifer interactions consumptive uses and return flows that take place within reaches defined by the location of reservoir outlets and control gauges as shown in fig 1 table 2 also lists the cdec flow stations and upstream reference gauges used to develop incremental flows at each downstream location data for within delta consumptive uses and the contribution of the eastside streams are taken from the california dwr s dayflow data set cdec 2020c negative incremental flow values signify a losing reach within the sacramento san joaquin flow network delta inflows are equal to the sum of incremental flows at all regulatory nodes and releases at all reservoir nodes delta outflows are subject to a water balance within the delta to account for consumptive and exported losses such that 2 d o u t t d i n t e t d e p l e t i o n s t where e delta exports transfers to san luis reservoir m3 s dout total delta outflow m3 s din total delta inflow m3 s depletions consumptive use between delta inflow and delta outflow gages m3 s and w d reservoirs that drain to the delta pumping in the delta is highly regulated and recent changes aimed at improving ecological functions have reduced swp and cvp project yields presenting challenges to large water providers who are reliant on imports mwd 2016 regulatory constraints reflect rules outlined in state water control board decision 1641 swrcb 1990 and national marine and fisheries services biological opinions nmfs 2009 governing minimum outflow requirements inflow export ratios seasonal limits on pumping rates and salinity targets calfews uses the relationship between delta outflows and the x2 salinity line jassby et al 1995 to apply salinity constraints to model operations delta outflows impact the salinity within the transitional area between the sacramento san joaquin delta and the san francisco bay the delta x2 line measures the point relative to the golden gate bridge where salinity 1 m from the bottom of the delta bed is equal to 2 parts per thousand the x2 relationship is calculated according to mueller solger 2012 updating the value of x2 in each time step based on the previous time step delta outflow such that 3 x 2 t 10 16 0 945 x 2 t 1 1 487 log 10 d o u t t 1 where x2 delta x2 salinity line km the tulare basin portion of the model does not contain downstream regulatory nodes instead reservoirs are connected to demand nodes by canals or river channels reservoir operations are determined based on state aware decisions that simulate requests for water use at individual demand nodes irrigation and water districts use management metrics derived from hydrologic states to transition between non linear rules used to request deliveries under normal flood and drought conditions deliveries are requested as a function of water demand at each node explicitly simulated based on land cover and historic withdrawals at municipal diversion points cadwr 2018 id4 2018 land cover data is determined based on crop types described in historic pesticide permitting data mall and herman 2019 or listed in agricultural water management plans aggregated by irrigation district daily consumptive demands are calculated by applying expected seasonal et requirements itrc 2003 to the total crop acreage by district such that 4 d e m a n d d t m d d d t c r o p k l o s s e t c r o p d o w y e a d c r o p y where demand maximum node demand m3 s mdd daily municipal demand m3 s et daily crop evapotranspiration m a acres of crop cover within irrigation district service area m2 dowy day of the water year 1 2 3 365 y year d irrigation district crop crop type e environmental index based hydrologic conditions and k loss loss factor for seepage and evaporation during conveyance 2 2 relating observed states to management relevant metrics daily hydrologic state variables provide calfews with a snapshot of flow snowpack and water demand conditions at nodes throughout the central valley fig 1 however management decisions that incorporate estimates of future hydrologic conditions can make more efficient use of limited infrastructure capacity including reservoir storage delta pumps spreading basins extraction wells and canal conveyance to this end calfews uses a training data series to relate snowpack and full natural flow to seasonal hydrologic conditions including estimates of total snowmelt season april july flows and future flows at one month intervals the historical training series covers the period october 1996 september 2016 for which cdec contains daily data for all model hydrologic states a series of daily linear regressions developed from the training series are used to relate the hydrologic state on a given day of the water year to future water availability aggregated over management relevant periods first estimates from snowpack stations in each watershed are related to reservoir inflow stations as listed in table 2 the total inflow to each reservoir during the snowmelt season april 1 july 31 can be expressed as a function of the total snowpack accumulation at the associated sites through a given day of the water year new snowpack observations can be used to produce an estimate of the subsequent snowmelt season inflows to a reservoir using unique linear coefficients for each day as in cohen et al 2020 such that 5 s m i w t m s n o w w d o w y s p w t b s n o w w d o w y where smi estimated reservoir inflow during the snowmelt season april july m3 dowy day of the water year sp aggregated index of snow water equivalent swe depth m msnow linear regression coefficient m2 bsnow linear regression constant m3 w watershed using the 20 year historical training period regression coefficients can be estimated for each day of the water year such that the sum of squared errors between the estimates produced in equation 5 and the eventual snowmelt season inflow observations are minimized such that 6 m s n o w w d o w y ˆ b s n o w w d o w y ˆ argmin y 1997 2016 s m i w d o w y y d a 181 304 q w d a y 2 where q reservoir inflow m3 s the 20 year historical training period provides 20 unique snowpack accumulation observations to inform each daily regression the daily linear relationships between snowpack observations and the subsequent total snowmelt season inflow at selected reservoirs are shown in fig 3 column 1 with colored lines corresponding to the line of best fit for snowpack observations occurring every day from oct 1st april 1st individual observations from every year of the historical record are shown for three specific days october 1st blue points january 1st green points and april 1st beige points to illustrate seasonal changes in the fit of this data to this linear relationship although the relationship is noisy the linear fit for all reservoirs watersheds improves over the course of the water year as more information about the total snowpack accumulation becomes available a statistical summary of goodness of fit metrics can be found in supplement a snowpack observations send strong signals about water availability during the snowmelt season when most irrigation demand takes place however shorter term monthly estimates of future water availability can also inform infrastructure operations with respect to managing reservoir flood control pools or maintaining adequate supplies for seasonal environmental releases at each time step in the training period the previous 30 days of full natural flow observations can be linearly related to future reservoir inflow observations aggregated into 12 unique consecutive periods of 30 days using 12 sets of linear coefficients for each day of the water year the next 360 days of flow in 30 day increments can be estimated at each timestep based on the trailing 30 day moving average full natural flow such that 7 q w i n t t b f l o w w d o w y i n t m f l o w w d o w y i n t d a t 30 t f n f d a w 30 where q estimated reservoir inflow in time interval int m3 int future flow interval 0 1 2 11 bflow linear regression constant m3 mflow linear regression coefficient fnf full natural flow m3 s as in equation 6 the 20 year historical training period is used to estimate regression coefficients for each day of the water year such that the sum of squared errors between the estimates produced in equation 7 and the observed reservoir inflow observations are minimized for every future interval such that 8 m f l o w w d o w y i n t ˆ b f l o w w d o w y i n t ˆ argmin y 1997 2016 q w i n t d o w y y d a d o w y d o w y 30 i n t q w d a y 2 where q total reservoir inflow m3 s bflow linear regression coefficient mflow linear regression constant fnf full natural flow m3 s int interval index 0 1 2 11 the last two columns of fig 3 show daily linear relationships between the trailing 30 day moving average full natural flow and the expected reservoir inflow aggregated over future periods of 30 and 120 days as in the snowpack accumulation column observations from every october 1st january 1st and april 1st in the historical training period are shown to illustrate data fit to the daily linear relationships the relationships are unique to each watershed and change over the course of the water year to reflect seasonal flow patterns as the aggregation period gets longer and includes observations further into the future the linear relationship becomes noisier as shown in the difference between the 30 and 120 day aggregation periods in addition to estimating flow into reservoirs management related metrics also take advantage of estimates of future incremental flows inc at each gauge location r substituting incremental flows as calculated in equation 1 for reservoir inflow q in equation 8 linear coefficients can be generated to estimate inc using the trailing 30 day moving average full natural flow in equation 7 full natural flow estimators can be aggregated to reflect the drainage area of each incremental flow station as in table 2 in addition to the hydrologic indicators outlined in equations 5 8 tulare basin management metrics also incorporate estimates of the future demand at each demand node through the end of a given water year future demands are estimated as a combination of municipal and irrigation demands as in equation 4 irrigation demands are calculated based on land cover and municipal demands are calculated using observations from historical records municipal demands are estimated through the end of a given water year based on the current allocation of municipal supplies such that 9 m d d d t b u r b d d o w y m u r b d d o w y c o n t r a c t a l l o c d c o n t r a c t y where mdd expected municipal demand m3 s burb linear regression constant for municipal demand murb linear regression coefficient for municipal demand alloc total water contract allocation m3 contract contract type y year d water district irrigation demands are estimated through the end of a given water year based on crop acreages within the service area of an irrigation district and expected crop evapotranspiration itrc 2003 such that 10 i r d d t d a d o w y 365 c r o p k l o s s e t c r o p d a e a d c r o p y where ird irrigation demand m3 s et daily crop evapotranspiration m a acres of crop cover within irrigation district service area m2 y year d irrigation district crop crop type and k loss loss factor for seepage and evaporation during conveyance the management relevant metrics calculated in equations 5 10 are updated at each node illustrated in fig 1 with daily hydrologic observations together these metrics serve as the building blocks for adaptive rules used to inform institutional decisions and operate shared infrastructure 2 3 multi scale adaptive decision making rules calfews abstracts various decision making institutions as sets of decision rules that can be triggered using the management relevant metrics calculated in equations 5 10 in this section we explain the rules that describe the actions of reservoir operators water contract managers and irrigation water districts the three institutional groups that jointly determine calfews infrastructure operations transitions between rule formulations driven by changes to metrics updated with new hydrologic observations enable the adaptive operation of infrastructure illustrated in fig 1 2 3 1 reservoir operators reservoir operations are implemented using independent rules governing minimum environmental releases and flood control pools at each reservoir rules change seasonally as a function of environmental indices that are calculated from hydrologic observations and management metrics from equations 5 10 environmental release rules at each reservoir constrain releases to meet seasonal minimum flows at three locations immediately below the dam outlet at the reservoir specific downstream gages described in equation 1 and at the delta inflow gauges described in equation 2 such that 11 m i n s t r w t max e r l w m e e d n w m e i n c r w t k d i w e i n b m e r b i n c r b t where minstr minimum release at reservoir to meet instream flow requirement m3 s e rl environmental minimum flow at dam outlet m3 s e dn environmental minimum flow at downstream gauge m3 s e in environmental minimum flow at delta inflow gauge m month e environmental index kdi delta inflow requirement sharing coefficient b delta inflow drainage basin r w incremental reach downstream of reservoir w r b incremental reaches associated with delta inflow gage b rio vista vernalis in addition to instream flow requirements managers in sacramento river basin reservoirs maintain responsibility for meeting inflow and outflow regulations in the sacramento san joaquin delta including the location of the x2 line used to measure salinity described in equation 3 as with instream flow requirements the delta rules change seasonally as a function of environmental indices calculated from equations 5 8 if downstream incremental flows are insufficient to maintain minimum delta outflows after meeting consumptive uses within the delta additional delta outflow releases must be made from the sacramento river basin reservoirs such that 12 m i n o u t w t c r l w m a x d m i n m e d x 2 t d e p l e t i o n s t r i n c r t 0 where minout minimum release for delta outflow m3 s crl article 6 swp cvp sharing fraction for in basin releases dmin minimum delta outflow m3 s dx2 minimum outflow to meet x2 salinity requirements m3 s depletions within delta consumptive use m3 s inc incremental flows m3 s minstream minimum release for instream flow requirements m3 s minflood minimum release for flood control m3 s r incremental flow nodes and w d reservoirs nodes that drain to the delta the minimum delta outflow that is required to meet x2 location requirements is calculated each day by rearranging equation 3 used to calculate the x2 location mueller solger 2012 such that 13 d x 2 t 10 10 16 0 945 x 2 t 1 x 2 m a x d o w y e 1 487 where dx2 minimum delta outflow required to maintain x2 location salinity requirements m3 s x2 max x2 regulatory line km x2 simulated x2 value km when minout is positive calfews distributes responsibility for making releases to individual reservoirs based on the swp cvp coordinated operations agreement usbr 2018 that states when water must be withdrawn from reservoir storage to meet in basin uses 75 of the responsibility is borne by the cvp and 25 is borne by the swp in calfews the swp portion of this responsibility is applied to calculations of available water stored at oroville reservoir and the cvp portion of this responsibility is released from shasta reservoir such that crl in equation 11 is equal to 0 75 at shasta 0 25 at oroville and 0 0 everywhere else a complete schedule of instream flow requirements delta outflow requirements and index thresholds reflecting state water resources control board decisions national marine and fisheries services biological opinions and other streamflow agreements cadwr 1967 ferc 2015 ferc 2016 ferc 2019 nmfs 2009 sacramento water forum 2015 swrcb 1990 swrcb 2000 ycwa 2007 can be found supplemental section a calfews also simulates the flood control decisions made by reservoir operators flood control rules are formulated as seasonal flood pool requirements used by the army corps of engineers to provide a cushion of unused storage for flood control effective capacity in each reservoir is determined using indices from the reservoir specific army corps flood control manuals usace 1970 usace 1977 usace 1980 usace 1981 usace 1987 usace 2004 mid and tid 2011 the flood control pool is designed to prevent storage from reaching the maximum design capacity beyond which uncontrolled flows spill from the reservoir risking downstream flooding and potentially threatening the integrity of the dam itself if storage encroaches into the flood control pool reservoir operators must release water to clear this space as a modelling convention 20 of the total volume of flood pool encroachment is released every day until storage has either been cleared from the pool or reaches the maximum design capacity such that 14 m i n f l o o d w t m a x 0 2 s w t t o c w f c i t s w t s m a x w 0 where minflood minimum release for flood control m3 s toc top of conservation pool smax maximum storage capacity fci flood control index value a complete schedule of flood pool volumes and flood control index thresholds for all reservoirs can be found in supplemental section a 2 3 2 water contract managers water contracts entitle owners to some amount of surface water either as flow in a river or a portion of the yield in an imported water project e g swp cvp water deliveries from these contracts are simulated in calfews through requests for reservoir releases and subsequent withdrawals from rivers and canals each contract is associated with one or more reservoirs table 3 where contractors can store their water some reservoirs store multiple contracts under a priority based system to allocate supplies between the contracts before deliveries can be made water contract managers must use hydrologic variables to estimate the total contract allocation in a given year and or when to make additional flood flows available to contractors decisions about contract allocations and flood flow availability help contractors make their own coordinated surface and groundwater use decisions based on individual supplies and demands calfews includes ten unique water contracts including water rights along the kings river kaweah river tule river and kern river delta imports delivered through the state water project central valley project san luis division central valley project exchange division and central valley project cross valley division as well as two classes of central valley project water delivered through the friant kern canal friant class 1 and friant class 2 contract allocations rely upon estimates of total flow through the end of a given water year sept 30th calculated by updating equations 5 8 with new snowpack and full natural flow observations in each time step the expected available water at each reservoir is estimated to be the existing storage plus the total expected inflows less the total volume needed to meet instream flow requirements and maintain end of water year sept 30th storage targets such that 15 a w w t s w t e o s w m t m s e p t r i w m d a t t 365 d o w y max m i n s t r w d a m i n o u t w d a where aw available water m3 s current storage m3 eos end of september storage target m3 e environmental index ri remaining inflow m3 as calculated from equations 5 and 7 and tm month of current time step water that is available through swp and cvp contracts is stored in reservoirs north of the delta as described in table 3 and must be pumped through the delta and into san luis reservoir before it can be delivered to contractors water allocations sourced north of the delta are subject to variability caused by a the need to release stored water to meet delta outflow requirements b the ability to export unstored incremental flows that are available in excess of delta regulations and c conveyance limitations within the delta caused by infrastructure capacity and regulatory constraints equation 15 reflects the additional responsibility of reservoir operators to make releases to support delta outflows minout reducing the amount of water stored in these reservoirs that can be assumed available for delivery to contractors however if incremental flows are high enough throughout the sacramento san joaquin watershed unstored flows that reach the delta in excess of the required outflows can be exported through swp cvp pumps as with their shared responsibility to meet delta outflow requirements unstored exports are divided between the projects based on the swp cvp coordinated operations agreement which states that unstored water available for export is allocated 55 45 to the cvp and swp respectively usbr 2018 such that 16 u w c t c e x c d a t d o w y 365 m a x r i n c r t d m i n m e d e p l e t i o n s t 0 where uw unstored water available m3 cex article 6 swp cvp sharing fraction for excess unstored flows inc estimated incremental flows from training period m3 s and depletions estimated in delta consumptive use from training period m3 s individual contracts allocate estimated available and unstored water as a percentage of a full annual delivery in reservoirs that hold more than one type of water contract allocations are determined based on seniority such that 17 a l l o c c t max u w c t w c a w w c t j n c d e l j n c s n c d e l s n c s n c d e l m a x s n c j n c d e l m a x j n c 0 where alloc contract allocations del year to date contract deliveries m3 delmax maximum annual contract delivery m3 w c reservoirs used to store contract c snc all contracts at reservoir w that have a higher seniority than contract c jnc all contracts at reservoir w with the same seniority as contract c senior water contracts that share storage with more junior contracts i e cvp exchange and friant class 1 have defined maximum annual deliveries as listed in table 3 and contract allocations in equation 17 are capped at 1 0 the junior contracts at each storage reservoir receive an allocation only after full allocations are granted to their more senior counterparts the maximum annual contract delivery values for junior contracts are limited by pumping and conveyance constraints enumerated in supplement a local water rights on the kern tule kaweah and kings river are the senior rights stored in their respective reservoirs but those reservoirs contain no junior water rights the maximum annual contract delivery for these contracts is unlimited and allocations as formulated in equation 17 are calculated using the average annual flow of each river as the value for delmax with allocations allowed to be 1 0 annual contract allocation decisions allow irrigation water districts to schedule contract deliveries based on their individual allocations and estimated demands over the course of a water year water contract managers can also make unscheduled deliveries available to irrigation water districts during brief intermittent periods when reservoir storage is expected to encroach on the flood pool these deliveries are made in addition to scheduled deliveries and can be used to meet consumptive demands or for targeted aquifer recharge when water is being cleared from the flood control pool release rates as calculated in equation 14 often exceed the capacity to recharge aquifers and or the immediate demands for any other productive uses of the water to allow irrigation water districts to use as much of this unscheduled water as possible water contract managers make unscheduled water deliveries available before storage levels reach the flood control pool the unscheduled water available in each time step is equal to the minimum rate that storage would need to be released to avoid flood pool encroachment over any look ahead period n such that 18 u n s c h w t max n 0 365 s w t d a t t n q w m n t n u m d a y s m d w d e m a n d d w n t o c w e n n where unsch maximum flow rate for unscheduled deliveries m3 s n lookahead period d q estimated reservoir inflow in time interval m m3 s numdays number of days in time interval m demand maximum node demand m3 s d w irrigation districts that store water in reservoir w toc top of conservation pool m3 s reservoir storage m3 if the unscheduled delivery rate rises above a given threshold defined here equal to the total recharge capacity of contractor districts unscheduled deliveries become available to any district that makes a request contract manager decisions about the size of an annual allocation and the rate and timing of unscheduled flows as calculated in equations 17 18 form the basis for thresholds used by districts to make adaptive state based decisions 2 3 3 districts imported water contracts and local water rights in the tulare basin are delivered to individual contractors from one of six surface water reservoirs conveyed through a system of natural channels and canals fig 1 contractors are typically organized into districts that provide water within a service area that contains individual consumptive demands and or capacity for aquifer recharge here we refer to an irrigation district id as a contractor that delivers water to irrigators but does not engage in groundwater recharge within the boundaries of their service area a water district wd refers to a contractor that makes deliveries primarily to municipal users or suppliers water storage districts wsd refer to contractors that have both irrigation demands and groundwater recharge facilities within their service areas finally a groundwater bank gwb is a standalone entity with no irrigation demands that includes groundwater recharge and recovery capacity that are owned and operated by one or more id wd or wsds a list of canals and the orientation of their nodes can be found in tables 4 and 5 consumptive demands are described in equation 4 and represent either irrigation demand diversion to a municipal water treatment plant or pumping into a canal branch that leaves the tulare basin shown in fig 1 as the pacheco tunnel las perillas and edmonston pumping plants aquifer recharge capacity in a wsd or gwb represents the rate at which water can be diverted into dedicated spreading basins and percolate into the groundwater aquifer spreading basins within a wsd service area are operated with the intention of increasing groundwater levels which has the effect of reducing pumping costs for district landowners when wsd surface water supplies are insufficient to meet irrigation demands deliveries to districts for irrigation and recharge are dependent on shared infrastructure including surface water storage canal conveyance and groundwater recharge and recovery capacity district decisions represent requests on this shared infrastructure subject to priority based capacity sharing rules when contract managers decide to make unscheduled water available to districts the unscheduled request at each canal node is equal to the maximum amount of water that can be diverted at each node the sum of consumptive demand and recharge capacity such that 19 r e q u n c n i d t d e m a n d d c n i t k o c n i d t b c a p c n i where requn unscheduled water request m3 s cni canal node index demand consumptive demand m3 s d cni irrigation water district at canal node cni ko district ownership share of groundwater recharge capacity at canal node cni bcap initial aquifer recharge capacity m3 s districts also receive scheduled deliveries from their individual water contract accounts scheduled deliveries are equal to some fraction of the maximum unscheduled request based on the estimated district supplies district supplies from local water rights and or imported swp and cvp contracts are calculated as a fixed percentage of the total contract allocation calculate in equation 17 such that 20 s u p p l y d c t k a l l o c d c a l l o c c t c a r r y d c y where supply annual estimated district water supplies m3 d district c contract alloc contract allocation m3 carry previous year s unused contract allocation credited towards this year s supplies m3 y year under normal conditions districts are able to carry over their water accounts from one water year to the next using excess reservoir storage capacity at the beginning of each new water year october 1st contract allocations are reset and districts are granted a carry over credit for any of the previous year s allocation that was not delivered to the district via scheduled delivery such that 21 c a r r y d c y s u p p l y d c t 1 d a t 365 t 1 d e l d c d a where del scheduled contract deliveries m3 s when reservoirs fill this unused storage capacity with new inflow districts forfeit any carry over water that is stored in the reservoir their individual carry over water is redistributed as part of the current year s contract allocation to replace any unscheduled deliveries or flood spills caused by storing the previous year s water to avoid losing their carry over supplies in this fashion districts request increased deliveries for recharge before the reservoir fills at each time step the time to fill can be calculated such that 22 n f i l l w d o w y ˆ argmin t o c w e n f i l l s w t d a t t n f i l l q w m d a t n u m d a y s m d w d e m a n d d w d a 2 where nfill time until the reservoir reaches capacity days q estimated reservoir inflow in time interval m m3 s numdays number of days in time interval m demand maximum node demand m3 s d w irrigation districts that store water in reservoir w toc top of conservation pool m3 and s reservoir storage m3 equation 22 is calculated through simulation in each time step if s starts out greater than toc the reservoir is already full and nfill is equal to zero if the value of nfill results in storage less than the top of the conservation pool such that 23 t o c w e n f i l l s w t d a t t n f i l l w d o w y ˆ q w m d a t n u m d a y s m d w d e m a n d d w d a the reservoir is not expected to fill and nfill is set to a maximum value of 365 given a reservoir fill time of nfill districts can calculate a dynamic recharge capacity based on the rate at which surface water can be recharged into the aquifer such that 24 d r c h g d w t c n i k b g w b d t b c g w b n f i l l w d o w y where drchg dynamic recharge capacity during reservoir fill period m3 kb district ownership share of spreading basin capacity bc groundwater recharge capacity m3 s gwb groundwater bank index d district index when a district has carry over water stored in a reservoir the carry over supplies are at risk of being lost if the district does not take delivery of the water before that reservoir fills if the total carry over water that has not yet been delivered to the district is greater than the district s dynamic recharge capacity calculated in equation 24 the district requests an expedited scheduled delivery such that 25 r e q s c h d c t min c a r r y d c y d r c h g d w c t d a w y s t d e l d c d a c n i r e q u n c n i d t where reqsch scheduled contract delivery request m3 s carry previous year s unused contract allocation m3 del scheduled contract deliveries m3 drchg dynamic recharge capacity m3 requn maximum unscheduled water request m3 s wys first day of the water year october 1 if a district has adequate dynamic recharge capacity for their carry over supplies they will request a normal scheduled delivery as a function of their remaining supplies that have not been delivered during the current water year such that 26 r e q s c h d c t min s u p p l y d c t d a t d o w y t d e l d c d a m d d d t i r d d t 1 0 d e m a n d d t where mdd expected municipal demands through the end of the year m3 ird expected irrigation demands through the end of the year m3 supply annual estimated contract supplies m3 del scheduled contract deliveries m3 s equation 26 represents the request that a district would make to a surface water reservoir storing the district s water contract likewise a district can also make a request to a groundwater bank for recovery of that district s banked groundwater nodes that represent out of district groundwater banks also have the capacity to recover groundwater making it available either as a direct delivery via canal or as an exchange for the stored surface water of another district districts with positive banking accounts can request recovery of those accounts when their surface water supplies are low groundwater recovery is limited by the pumping capacity at the bank so districts initiate groundwater recovery before they have completely exhausted their surface supplies similar to deliveries made for groundwater recharge groundwater recovery is a state aware decision made by individual districts comparing their total recovery capacity to the expected surface water shortfall recovery capacity is evaluated through the end of the water year such that 27 d r c v y d t 365 d o w y t g w b k w g w b d t w c g w b where drcvy remaining recovery capacity m3 dowy day of water year index beginning october 1 1 365 kw district ownership share of recovery well capacity and wc total recovery well capacity m3 s when this threshold is greater than the difference between a district s consumptive demand and its surface water supplies through the end of the water year recovery well requests are triggered such that 28 r w b g w b d t m d d d t i r d d t c s u p p l y d c t d a w y s t d e l d c d a d r c v y d t where rwb groundwater bank recovery well request m3 s mdd expected municipal demands through the end of the year m3 ird expected irrigation demands through the end of the year m3 supply annual estimated contract supplies m3 del scheduled contract deliveries m3 s wys first day of the water year equations 19 28 represent the thresholds and decision rules used to estimate the requests made by individual districts these requests are then subject to priority based infrastructure capacity sharing rules that translate individual requests into water deliveries and other changes in model state variables priority over groundwater banking infrastructure represents ownership shares that give a district the first right to use a certain portion of the capacity any capacity not used by the owner district s is made available to all member districts in equal proportions 2 4 operational rules for shared infrastructure water distribution in each time step and the resulting changes to model state variables surface and groundwater accounts delta x2 reservoir storage are governed by infrastructure operations including shared capacity in surface reservoirs pumping plants canal conveyance spreading basins and recovery wells decisions made by reservoir operators contract managers and irrigation water districts described in equations 11 28 are aggregated to joint infrastructure operations via priority based sharing rules to resolve swp and cvp operations in the delta reservoir operations integrate the reservoir operator decisions described in equations 11 14 with releases based on cvp and swp contract manager allocation decisions described in equations 15 18 swp and cvp contract managers face the additional decision of scheduling releases from north of the delta storage to support pumping while meeting regulatory constraints several seasonal and contextual limits are placed on maximum pumping levels at swp and cvp facilities swrcb 2000 nmfs 2009 including a rule specifying the minimum allowed ratio between delta exports through swp and cvp pumps and delta inflows when this rule called the e i ratio is binding any increase in the combined pumping rate in the delta must also be met with a larger increase in total delta inflow some of which escapes the delta as outflow swrcb 2000 rearranging equation 2 and using a general delta inflow term to replace the summations of reservoir releases and incremental flows the maximum export rate can be expressed as a function of e i ratio delta outflow and delta depletions consumptive uses within the delta such that 29 e t e i r m d o u t t d e p l e t i o n s t 1 e i r m where e delta exports m3 s dout delta outflow m3 s depletions delta consumptive use m3 s and eirm e i ratio in month m i e 0 35 or 0 65 substituting minimum delta outflow regulations for dout in equation 17 results in the maximum allowable export rate when delta outflow is at the minimum target levels even though the permitted capacity at any given moment may be higher than this rate pumping above this level will result in additional required delta outflows reducing the yield of the swp and cvp delta export projects calfews decision rules use this rate as a maximum target to schedule reservoir releases for export such that 30 e c t w c a w w c t m a x d a t 365 d o w y t e t w s w p a w w c t w c v p a w w c t min e t p m a x m e where e target export rate for individual contract swp cvp m3 s e maximum total export at minimum delta outflow m3 s aw available water at each reservoir m3 pmax maximum combined pumping capacity at swp and cvp delta pumps m3 s swp and cvp contract managers augment downstream incremental flows and regulatory releases described in equations 11 14 with additional releases meant to support exports at the level calculated in equation 30 such that 31 r e x p c t e c t c e x c r i n c r t w c e n v r e l w t d m i n m e d e p l e t i o n s t where rexp total contract releases for delta export m3 s cex swp cvp sharing agreement for excess unstored flows inc incremental flows m3 s envrel minimum reservoir release to meet in stream requirements delta outflow requirements and flood control releases m3 s releases for each contract swp and cvp are distributed between the north of delta reservoirs based on the fraction of the total expected available water aw stored in each reservoir the export rate e is a target used to manage reservoir releases but delta pumps can also capture downstream incremental flows that are larger than the required delta outflow and depletions subject to the swp cvp sharing agreement in swrcb 2000 such that 32 e c t m a x e c t min c e x c r i n c r t w c e n v r e l w t d m i n m e d e p l e t i o n s t p m a x c m e where totexp total delta exports m3 s e environmental index and tm month of current time step e target export rate for individual contract m3 s operations in the tulare basin integrate the reservoir operator decisions described in equations 11 14 with the decisions to request deliveries made by irrigation water districts in equations 19 28 deliveries for irrigation and groundwater recharge travel through a shared network of canals and natural channels before they can fulfill district requests each canal reach has a conveyance capacity which is shared between nodes using a priority based system such that 33 d e l c n i c t k c c n i w p d c n i r e q p c n i d c n i c t k c c n i n p d c n i r e q n p c n i d c n i c t where delivery cni c total deliveries to a canal node cni from surface water contract c m3 s cni canal node index k p canal sharing coefficient for priority requests kc np canal sharing coefficient for non priority requests reqp priority district requests scheduled or unscheduled m3 s reqnp non priority district requests scheduled or unscheduled m3 s d cni districts with ownership rights at the canal node the canal sharing coefficient kc cni p is calculated to share the conveyance of any given reach equally with all requests made down canal of that reach giving priority to priority requests such that 34 k c c n i p min c c a p c n i n d c n i c n i e n d d n d r e q n d d n d p t 1 0 and 35 k c c n i n p m i n m a x c c a p c n i n d c n i c n i e n d d n d r e q n d d n d p t 0 0 n d c n i c n i e n d d n d r e q n d d n d n p t 1 0 where req district request scheduled or unscheduled m3 s ccap canal conveyance capacity in reach cni m3 s releases for canal deliveries are made from each reservoir in addition to the regulatory releases described in equations 11 14 such that 36 r d e l c t n d c n i s t a r t c n i e n d d e l n d c t groundwater recovery requests originate from within the canal network rather than at the head of the canal network when requests are made for surface water delivery it is not always possible to deliver this recovered groundwater directly to the district that is making pumped withdrawals from their groundwater banking account instead recovered groundwater can be delivered to any other district for exchange provided that the district has surface water stored in an accessible reservoir in calfews recovery exchange is simulated by delivering recovered water to districts with turnouts along the downstream canal nodes such that 37 d e l c n i g w b t max min d c n i r e q s c h d c n i c t r e q r v y c n i d t n d c n i g w b c n i d e l n d g w b t 0 0 where delivery cni gwb delivery of recovered groundwater from groundwater bank gwb to canal node cni m3 s reqsch scheduled request at delivery node m3 s reqrvy banked recovery request at bank node m3 s deliveries to each node within the canal network as detailed in tables 4 and 5 are calculated through iteration fig 4 illustrates the flow of water through different system states over the course of a single water year the flow begins in northern california where water is either routed to the delta outflow sink along the top of the chart pumped through the delta to san luis reservoir or carried over into the next year as surface water storage the flow can come from one of four reservoirs used as north of the delta storage by the swp and cvp or from uncontrolled sources closer to the delta from san luis reservoir water is delivered to users in the tulare basin along with water stored in the other surface water reservoirs in the basin including millerton reservoir via the friant kern canal annual flows to those reservoirs are divided into various surface water contracts table 3 where along with the previous year s contract carry over water it forms this year s contract allocation some of the surface water is delivered as unscheduled flood deliveries contract allocations and unscheduled deliveries are divided among individual contractors grouped here by general geographic characteristics for visual simplicity the complete list of contractors and groundwater banks included in calfews is shown in tables 4 and 5 based on contractor requests contract allocations and unscheduled deliveries are sent for irrigation municipal use and direct or in lieu groundwater recharge contractors can also save undelivered carry over water for the next water year whatever contractor demands cannot be met via individual surface water supplies are met through groundwater pumping either via banked recovery or private in district wells all groundwater pumping from districts or groundwater banks in the tulare basin assume a bucket model of the underlying aquifer depth to groundwater in the region is assumed to be sufficiently far below the surface that surface water groundwater interactions from changes in pumping rate can be ignored brush et al 2013 groundwater seepage from surface water conveyance in natural channels and unlined canals are accounted for with the term k loss in equation 10 all water diverted for recharge is assumed to achieve deep percolation with no return surface water flows after delta exports and district deliveries are resolved calfews updates state variables based on infrastructure operations reservoir releases calculated in equations 11 14 and 36 are used to update storage at each simulated surface water reservoir and the total delta outflow which is used to update the x2 salinity line as in equations 3 4 recharge and recovery operations at groundwater banks are used to update individual district banking accounts changes in groundwater banking storage accounts also assume a bucket model within each groundwater bank with no surface water groundwater interactions or lateral flow of groundwater between banks or district service areas groundwater storage accounts are simulated to determine the volume of water that is allowed to be withdrawn from a given water bank and not as an explicit model of aquifer storage or groundwater level groundwater banking storage accounts do not have a set capacity within calfews as extensive groundwater depletion throughout the tulare basin region has created unused groundwater storage capacity that is assumed to be significantly greater than any storage volumes simulated within the model o geen et al 2015 scheduled contract deliveries are used to update allocations and individual district accounts to surface water contracts updated state variable values are carried through to the next time step where they form the basis for the next iteration of adaptive decisions 3 results 3 1 model evaluation and capabilities the adaptive operating rules employed in calfews enable simulations based on any daily input time series of flow and snowpack data at the storage and regulatory nodes shown in fig 1 simulation results based on historical input data can be compared to observations at a number of critical locations throughout the central valley system as a means of quantifying how well decision rules capture historical system operations in addition to encompassing a range of hydrologic conditions the 20 year historical period of comparison october 1996 september 2016 includes substantial changes to statewide regulatory regimes that have impacted the operation of the swp and cvp as well as significant infrastructure expansion within kern county groundwater banks during simulations of this historical evaluation period calfews representations of these changes including environmental flow requirements pumping limits and infrastructure capacities are integrated to reflect the timing of their implementation choosing an evaluation period that experienced these types of structural changes in addition to a wide range of hydrologic conditions increases confidence that the system of adaptive rules embedded within calfews can provide insight into future uncertainties related to hydrologic change infrastructure development and environmental policies fig 5 shows the performance between observed storage and simulated results during the 20 year historical period at all twelve surface reservoirs in the sacramento basin all four simulated reservoirs shasta oroville folsom and new bullards bar dam fig 5a d display r2 values ranging between 0 86 and 0 94 these large reservoirs form the bulk of the releases to regulate delta outflows and support north south exports san joaquin reservoirs fig 5e g including new melones don pedro and exchequer have slightly higher levels of performance with r2 values ranging from 0 93 to 0 97 many of the releases for these reservoirs are made to deliver water to downstream agricultural users agricultural demands supplied by these three reservoirs are not modelled based on implied et demands from land cover as calfews does for tulare basin irrigators instead historical withdrawals for irrigation are calculated as negative incremental flows in the reaches between these reservoirs and their downstream regulatory node as in equation 1 negative incremental flows force the reservoirs to release water to meet downstream flow requirements meeting the demands without the type of explicit agricultural modelling that occurs in the tulare basin region of calfews as described by equation 10 although new melones don pedro and exchequer are not explicitly operated to support swp and cvp delta export programs the three reservoirs here perform important flood control and minimum flow regulation for delta inflows through the vernalis gauge that can impact pumping rates releases from millerton reservoir are not included when regulating flows at vernalis even though the dam controls the headwaters of the san joaquin river we assume here that most excess releases are consumed at the mendota pool before interacting with any gages in the delta system and any releases that do contribute to delta inflows are included in the observed uncontrolled flows on the san joaquin river the reservoirs shown in fig 5h l millerton pine flat kaweah success and isabella deliver water directly to the tulare basin irrigation water districts the simulation results for millerton reservoir fig 5h are the poorest of the calfews represented reservoirs but still generate an r2 value of 0 57 millerton is a smaller reservoir subject to flashy flows especially during the winter wet periods flood control releases can be large and potentially occur well in advance of the reservoir reaching full capacity as operators attempt to deliver as much flood water as possible to contractors along the conveyance constrained friant kern canal the flow estimates used in equation 18 to schedule flood control decisions in calfews do not capture all of the information used by millerton reservoir operators and friant contract managers when they make their flood control decisions leading to errors in storage when the timing of flood releases are mismatched model operations would likely be improved by more resolved estimation of wet period flow in the san joaquin headwaters it should be noted however that operational rules used in calfews do broadly capture major storage dynamics in millerton and perform quite well in simulating the recent 2012 2016 drought suggesting that they can adequately represent the influence of the san joaquin river restoration project which began in 2009 on dry year storage levels in millerton reservoir flow that makes it to the delta is either exported through swp fig 6 a and cvp fig 6b pumping works or allowed to flow out to the san francisco bay where the impact on the x2 salinity line fig 6c can be measured the delta x2 salinity line measures the point where salinity in the delta is equal to 2 parts per thousand 1 m from the bottom of the bay floor relative to the golden gate bridge x2 values peak in the late summer early fall after low summer flows have allowed delta salinity to move eastward inland farther from the golden gate bridge and reach their low point in the spring after high winter flows push the salinity back towards the sea simulated x2 corresponds well with historical values as calculated in the california dwr s dayflow time series displaying an r2 of 0 95 for weekly average values and 0 96 for monthly averages simulations of exports at the swp and cvp delta pumps also correspond well with historical observations at the annual scale r2 of 0 89 and 0 91 for the swp and cvp respectively with the relationship holding up well even when compared on a weekly time step r2 of 0 64 and 0 59 respectively the sub annual results are particularly important because the pumping time series serve as inflows into san luis reservoir and the timing of inflows impacts the size and type of deliveries that can be made to tulare basin contractors the model s ability to capture the storage dynamics in san luis reservoir both the state and federal portions are shown in fig 7 despite being subject to some degree of modelling error in inflow delta pumping estimations and reservoir releases district demand estimations they broadly capture the monthly observed storage monthly is the only time step at which individual swp and cvp storage accounts are recorded in san luis reservoir simulated storage in san luis reservoir has an r2 value of 0 73 in the swp portion and 0 66 in the cvp portion given the sheer complexity of the san luis reservoir s operations the calfews simulation manages to capture the general timing variability and bounds of the system s storage water delivered for groundwater recharge is delivered either within the service area of an wsd or to a gwb outside of the district service area water recharged in gwbs can be recovered and delivered to an id wd wsd but only if the district has a positive balance in the bank fig 8 illustrates the correspondence between simulated and observed cdec 2018 hanak et al 2012 groundwater storage accounts in the kern gwb kwb and semitropic wsd swsd where most of the banking users are swp contractors the kwb is primarily operated for agricultural users while banking members in the swsd are mostly municipal water districts calfews is able to capture the historical groundwater banking dynamics with relatively high r2 of 0 70 and 0 67 for the annual change in storage accounts at kwb and swsd respectively high levels of r2 at kwb 0 77 and swsd 0 64 are also attained for the total cumulative balance in each bank at both banks errors are largest in very wet years in which simulated results do not recharge as much water as is reflected in observed accounts simulation results have better correspondence with observations during dry years as the most downstream part of the calfews model groundwater banking results are subject to modelling errors in reservoir releases delta pumping and contractor water demands however the errors observed in banking accounts in both the kwb and swsd are not systematically biased in any direction and storage accounts in both banks are very close to the observed accounts at the end of the 20 year simulation to the authors knowledge no simulation system outside of calfews has ever been able to capture the complexity of human systems operations and water balance dynamics with the level of fidelity shown here errors between simulated groundwater banking storage accounts and observed storage accounts overall appear not to be amplified across years that is our simulation results do not show sustained inter annual over or under prediction 3 2 state aware decisions the general agreement between observed and simulated results at key central valley locations set the stage for a deeper look into the dynamic and adaptive ways calfews simulations represent stakeholder decisions simulated infrastructure operations are the product of individual heterogeneous agents making decisions in response to changing hydrologic and management states these states are based on the translation of environmental variables into simulated management relevant states like those relating to state water project allocations shown in fig 9 simulated allocations are updated in every timestep based on the component parts of the swp contract allocation described in equations 15 17 during the calfews simulation of the historical evaluation period oct 1996 sept 2016 the expected swp allocation white line responds to changes in the expected available water at oroville and new bullards the swp portion of any expected unstored flows and the year to date exports that have already been delivered to san luis reservoir in addition annual simulated allocations are also constrained by the expected pumping capacity through the end of the water year during the historical evaluation pumping constraints cause the expected swp allocation to occasionally fall below the sum of its component parts particularly during wet periods when this occurs swp contract managers carry over this excess water in oroville and or new bullards resulting in end of year storage above target levels in the following years this extra carry over storage is included in the calculations of expected available storage in the respective reservoirs increasing initial estimates of that year s swp allocation calculations of swp allocations fig 9 are translated into individual contractor allocations that can be used to make district level water supply decisions as demonstrated for a specific irrigation district wheeler ridge maricopa fig 10 the historical evaluation period includes a significant recent drought from 2013 to 2016 during which calfews simulated the district s groundwater recovery operations in 2013 the first year of the drought the district s portion of the swp allocation was equal to approximately half of its expected irrigation demand the district made requests for surface water deliveries based on this allocation according to equation 27 with the balance of the irrigation demand met through recovery of the district s banked groundwater originating in groundwater banks outside the district s service area and private groundwater pumping by the district s irrigators although the district had sufficient supplies in their groundwater banking account in 2013 the district s recovery pumping capacity at the bank limited the rate at which the banked water could be delivered to the district requiring some amount of in district private groundwater pumping the following winter low snowpack levels caused expected swp allocations to drop further fig 9 which in turn reduced wheeler ridge maricopa s expected surface water supply fig 10 the district relied heavily on banked groundwater recovery in water year 2014 to make up for reduced surface water deliveries and by the end of the irrigation season the district completely depleted their banked groundwater storage calfews simulation rules do not permit groundwater recovery when banked storage accounts are empty so when the simulated historical drought continued in 2015 the district s irrigation was almost entirely supplied by private groundwater pumping at wells within the district s service area the final year of the drought 2016 started out dry but increased precipitation led to larger expected contract allocations increasing district surface water supplies irrigators within the district began the year pumping private groundwater expecting that the rest of the year would be dry as well but were able to cease pumping by july when it was clear the remaining demands could be met through surface water deliveries from the swp due to increases to the swp allocation late in the year the district was able to end the year with additional supplies and thus carry over swp supplies into the next year during wet periods calfews also simulates unscheduled flood deliveries to contractors decisions about the timing and magnitude of these releases are made by surface water contract managers when reservoirs are close to filling as reservoir storage increases reservoir fill time falls in accordance with seasonal trends e g the same storage volume will correspond to a shorter fill time if it is observed in december and a longer fill time if it is observed in june after a significant portion of snowmelt has already occurred and as storage approaches capacity fill time goes to zero fig 11 at san luis reservoir natural inflow is negligible and the reservoir is almost entirely fed by swp cvp pumps at the delta pumping capacity limits the rate of inflow into san luis reservoir during high flow periods reducing the need for pre emptive flood releases driven by expected future inflows as in equation 19 in calfews swp flood releases are not made from san luis reservoir until storage approaches capacity in the state owned portion of san luis reservoir however reservoir fill time in san luis is an important metric for individual districts attempting to manage their carry over water if a swp contractor does not deliver their entire swp contract they are able to carry it over in san luis reservoir any carry over water remaining in san luis when it reaches capacity is forfeited by the district carrying it over and instead delivered to any contractor with the capacity to take it districts therefore will attempt to use any carry over water if they observe the reservoir filling up this decision is triggered when a district s cumulative recharge capacity during the expected reservoir fill time calculated in equation 24 is less than a district s current and or expected cumulative carryover individual district carry over operations as shown in fig 12 are designed to store excess surface water allocations carry over water from one year for use in the next either for groundwater recharge or when possible to meet irrigation or municipal demands in the historical simulation wheeler ridge maricopa begins water year 2005 october 2004 with about 25 taf 31 106 m3 of unused carry over water in san luis reservoir as shown by the white line however san luis reservoir also had a significant volume of unused storage capacity at this time and the district s metric to measure their dynamic recharge capacity the total volume of water that could be diverted into district groundwater recharge facilities before san luis reached its storage capacity remained larger than the volume of carry over water they stored in san luis as the winter progressed the simulation delivered the district s carry over water to meet winter irrigation demands the district was able to use all of their carry over water for irrigation before san luis reservoir filled in february of 2005 fig 12 expectations for that year s swp contract allocation continued to increase throughout 2005 as previously shown in fig 9 eventually causing wheeler ridge maricopa s individual swp supplies to exceed their remaining irrigation demand the district carried over a similar volume in water year 2006 but san luis reservoir was much closer to capacity because other contractors were also storing carry over water reservoir fill time fell much more quickly at the beginning of water year 2006 reflected in the district s falling dynamic recharge capacity dark blue area of fig 12 at the point during water year 2006 when this dynamic recharge capacity fell below the districts remaining carry over storage calfews triggered the district s decision to begin delivering their carry over water to groundwater recharge facilities the use of groundwater recharge capacity allowed wheeler ridge maricopa to deliver all their carry over water earlier than in 2005 avoiding the need to forfeit unused supplies water year 2006 also saw very high expected swp contract allocations and by mid summer of 2006 the district was expected to bring a very large volume 60 106 m3 of carry over water into the next year high simulated storage levels at san luis reservoir again resulted in low dynamic recharge capacity for the district and the combination of high expected carry over storage and low dynamic recharge capacity caused the district to begin delivering their potential carry over water to groundwater banking facilities before the end of water year 2006 the district was able to recharge this water more quickly than expected because few other districts were recharging surface water at this time and wheeler ridge maricopa was able to take advantage of unused capacity at their groundwater banking facilities at the start of water year 2007 the district delivered their remaining carry over water for irrigation and groundwater recharge before san luis reservoir could re fill in early 2007 carry over storage operations in calfews enable individual districts to make coordinated surface and groundwater use decisions saving their surface water for irrigation or municipal demands when possible while still avoiding losing their supplies through selective use of groundwater recharge capacity 3 3 extended historical re evaluation the rules based adaptations that drive simulations allow calfews to evaluate reservoir releases delta operations irrigation deliveries and groundwater recharge recovery under a wide range of input conditions infrastructure configurations and regulatory regimes over the course of the 20 year historical evaluation period october 1996 september 2016 decisions rules adapt to increasing capacity in tulare basin groundwater banks aecom 2016 the imposition of the national fisheries and wildlife services old middle river rule nmfs 2009 limiting the capacity of delta pumps between january and june and the san joaquin river restoration project meade 2013 which increases the required environmental releases from millerton reservoir these changes are implemented into model simulations as they occur in real time construction of the kern water bank 2001 2003 old middle river delta rule 2008 san joaquin river restoration 2009 over the historical evaluation period but we can also conduct an extended historical re evaluation applying regulatory changes to the entirety of an extended full natural flow record available through the california data exchange center cdec full natural flow records in the sacramento san joaquin and tulare basins reach back as far as 1905 enabling a 111 year extended historical re evaluation under scenarios reflective of current infrastructure and regulatory conditions in watersheds where flow and snowpack data were not available over the entire period they are synthetically extended using historical relationships with existing data in addition incremental flow and reservoir inflow datasets are not available for the same historical duration so inputs are synthetically generated based on more recent 10 1996 09 2016 observed relationships with the full natural flow data as described in supplemental section b simulation results illustrate the water availability that would have been observed in the system under historical hydrologic variability and a static set of institutional conditions including current land use population infrastructure and regulatory regimes fig 13 compares the distribution of swp and cvp delta pumping and delta outflows under the extended historical re evaluation scenario 111 years water years 1906 2016 the historical evaluation scenario 20 years water years 1997 2016 and historical observations 20 years water years 1997 2016 although the extended historical period 1905 2016 contains a slightly higher portion of wet and above normal water years than the historical evaluation period 1996 2016 it produces a much lower frequency of years with very high annual exports through both the swp pumps 4300 x 106 m3 year and cvp pumps 3400 x 106 m3 year this illustrates the impact of applying the recent regulatory changes across the entire extended historical period rather than only during the 2008 16 period under which they are applied in the historical evaluation scenario new regulations applied to the delta primarily limit pumping rates from january to june preventing the pumps from running at capacity for a substantial portion of the year and limiting the water that can be exported during the typical high flow season the regulatory impact can also be observed in very dry years which form a second smaller peak in the bi modal pumping distribution that is most pronounced in the extended historical scenario during these years there is often very little snowpack above swp and cvp storage reservoirs and most of the water that could be exported is available as uncontrolled inflows to the delta during brief periods in the wetter winter months however regulations become more restrictive to wintertime pumping operations when conditions are the driest in addition to having fewer supplies to export swp and cvp managers are also effectively operating with reduced infrastructure capacity during dry years leading to the bimodal distribution shown in fig 13 4 discussion this study presents results from a 20 year historical simulation and a 111 year synthetically extended historical re evaluation in both scenarios infrastructure and land cover are set deterministically the former tracking the observed changes over the 20 year period october 1996 september 2016 and the latter applying current conditions to the entire hydrologic record that occurred from october 1905 september 2016 the historical simulation provides a benchmark for quantifying how well the decision rules described in calfews capture stakeholder adaptations to continually changing surface and groundwater conditions throughout the state of california in contrast with statewide mp based models such as calvin draper et al 2003 calsim draper et al 2004 or callite islam et al 2011 that seek to identify optimal allocations of surface water under a specific set of hydrologic and demand conditions the state aware decision rules framework adopted here seeks to describe the system as it currently exists perhaps more importantly the framework describes how decisions within the current system is driven by different environmental indicators e g snowpack flow land cover the ability to quantify and evaluate how individual water users respond to changing conditions is particularly helpful in identifying how they are impacted by marginal changes from current operations like those that could arise from the state s flood mar research and data development plan cadwr 2020 by linking decision rules to a heterogeneous set of users and stakeholders like irrigation districts or reservoir operators the analysis can also capture the distributional effects of changes to operating policies and or infrastructure these distributional effects are particularly important with respect to the continuing development of groundwater recharge and recovery efforts in the state the location magnitude and timing of groundwater recharge determines how much groundwater can be recovered in the future and by whom the groundwater banking rules used in calfews limiting groundwater recovery to only water that has been previously recharged at the site aids in understanding these multi year regulatory links between flood and drought periods the spatial and temporal scale used within the calfews simulation framework also allow it to be interoperable with land use and power dispatch models land cover selection used to estimate irrigation demand in this study is deterministic ignoring the relationship between surface water variability and irrigated acreage irrigation demands that are not met by surface water or banked recovery deliveries are assumed to be met through private groundwater pumping however literature suggests that the relationship between surface water availability groundwater pumping and irrigated acreage is a more complex economic decision for irrigators medellin azuara et al 2015 in future work irrigation deliveries generated by calfews can be linked with economic models of agricultural production such as california s swap howitt et al 2012 to represent adaptive land use decisions in order to get an accurate picture of the pumping costs faced by irrigators future versions of calfews can also include an explicit representation of the changes to groundwater levels that result from direct aquifer recharge and groundwater pumping in a given spatial area an important factor in meeting sustainability targets described in the sustainable groundwater management act extending the state aware decision framework to groundwater levels as an environmental indicator and district level land cover using a decision rule could enable the exploration of more complex groundwater management strategies likewise state of the art power dispatch modelling has demonstrated the connection between drought and wholesale energy prices in california kern et al 2020 with a particular attention to changes in hydropower generation and temperature based variability in energy use for the cooling of buildings however these models can also consider changes to other energy consumption related to surface water drought in california such as changes to the volume of groundwater pumping or conveyance of the state water project the single largest energy user in the state coordinated modelling of surface and groundwater use paired with estimates of wholesale and retail electric power prices can provide insight into the financial risks faced by irrigation districts groundwater banks and individual irrigators these risks impact the ability of institutions to repay loans and meet other fixed cost obligations playing a role in determining investment decisions future versions of calfews can incorporate feedbacks between environmentally driven changes in energy consumption energy prices and financial risk to irrigators and groundwater bankers as water supplies become more diversified as outlined in the state of california s resilient water portfolio initiative canra 2020 institutions that are capable of managing the year to year financial variability will be capable of greater adaptation in response to hydrologic and regulatory uncertainty 5 conclusions this study introduces the california food energy water system calfews simulation model to illustrate the integrated multi sector dynamics that emerge from the coordinated management of surface and groundwater in the state of california the calfews simulation framework captures the relationships between actors at multiple scales linking the operation of inter basin transfer projects in california s central valley with coordinated water management strategies abstracted to the more highly resolved scale of irrigation and water storage districts a set of interdependent rules conditioned on dynamic environmental variables enable the model to abstract the coordinated management of surface and groundwater resources in the central valley these abstractions are evaluated against observations from a recent 20 year period oct 1996 sept 2016 and are shown to accurately represent swp cvp deliveries surface water storage and groundwater banking operations in california s tulare basin distributed state aware decisions provide insight into how a range of institutions adapt to changing hydrologic and regulatory conditions in a way that is consistent with recent historical observations of surface water storage delta exports and water quality metrics and groundwater banking accounts in the tulare basin flexible decision rules enable calfews to evaluate alternative streamflow scenarios under particular infrastructure and regulatory assumptions the simulation framework can specifically support monte carlo exploratory modelling results particularly with respect to irrigation deliveries and pumping requirements simulations can be linked with agricultural production and electric power dispatch models to create hydrologically consistent scenarios upon which to evaluate risks to food and power systems economic models of agricultural production like the statewide agricultural production swap model used in california howitt et al 2012 use surface water deliveries and groundwater access to estimate crop choice decisions groundwater pumping and annual agricultural yields abstractions of groundwater banking operations made within calfews can better resolve water deliveries to individual districts allowing for more detailed projections of land use and groundwater pumping medellin azuara et al 2015 hydropower is responsible for between 7 and 21 of california s total energy generation useia 2020 but energy used for conveyance and distribution can offset a significant portion of this production during the period 1998 2004 the energy used to convey state water project supplies alone ranged between 8 wet year and 24 dry year of the total annual hydropower production cec 2010 nyberg 2020 state of the art electric power dispatch modelling has demonstrated the connection between drought and wholesale energy prices in california kern et al 2020 based on changes to hydropower generation and energy use for cooling structures however the literature has not considered any potential drought induced covariation between hydropower production and the energy demands for surface water conveyance and groundwater pumping instead of a prescribed sequence of optimal water deliveries assigned to specific time periods calfews formulates daily data input series into a number of state variables that are used to coordinate infrastructure operations model rules adapt to dynamic regulatory constraints on infrastructure enabling monte carlo simulations that combine different hydrologic regulatory and infrastructure scenarios institutional abstraction at multiple scales e g inter basin transfer projects irrigation districts joint groundwater banks enables rule based coordination between regional and statewide actors linked through conditions throughout the state regulations and hydrologic conditions that affect exports through swp and cvp delta pumps for example also affect imported water contract allocations and floodwater availability which in turn influences how individual districts operate their groundwater recharge and recovery infrastructure groundwater banking and other coordinated use operations create a relationship between flood and drought periods limiting recovery operations as a function of previous recharge this relationship may become more important to irrigators and municipal users as the issue of groundwater sustainability increases in salience due to the recently enacted sustainable groundwater management act cadwr 2020 calfews provides a foundational framework that can support future monte carlo exploratory modeling efforts to understand the path dependent impacts of hydrologic and regulatory uncertainty on coordinated surface and groundwater management revealing potential risks and opportunities as they play a larger role in statewide resilient water portfolios canra et al 2020 calfews is able to resolve these actions at the level of individual irrigation and urban water districts providing insight into financial risks and water use at a management relevant scale tools that allow institutions to evaluate and manage co evolving physical and financial risks are crucial to the process of developing sustainable and resilient water solutions for institutionally complex contexts like the american west name of software calfews developers h b zeff zeff live unc edu a l hamilton k malek j d herman j s cohen with contributions from g w characklis p m reed and j medellin azuara software date availability all code and data for this project including figure generation are available in a live repository http github com hbz5000 calfews and a permanent archive https doi org 10 5281 zenodo 4091708 source language python cython license mit declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national science foundation through the innovations at the nexus of food energy and water systems infews program cns 1639268 appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105052 
25824,this study introduces the california food energy water system calfews simulation model to describe the integrated multi sector dynamics that emerge from the coordinated management of surface and groundwater supplies throughout california s central valley the calfews simulation framework links the operation of state wide interbasin transfer projects i e state water project central valley project with coordinated water management strategies abstracted to the scale of irrigation water districts this study contributes a historic baseline october 1996 september 2016 evaluation of the model s performance against observations including reservoir storage inter basin transfers environmental endpoints and groundwater banking accounts state aware rules based representations of critical component systems enable calfews to simulate adaptive management responses to alternative climate infrastructure and regulatory scenarios moreover calfews has been designed to maintain interoperability with electric power dispatch and agricultural production models as such calfews provides a platform to evaluate internally consistent scenarios for the integrated management of water supply energy generation and food production keywords adaptive management water resources groundwater recharge interbasin transfers dynamic simulation 1 introduction throughout the 20th century large scale water storage and conveyance projects were developed to support urban growth and agricultural production in california these projects have generated significant economic benefits for the state particularly within the central valley where water storage and conveyance infrastructure support irrigation in four of the five most productive agricultural counties in the united states usda 2012 however surface water deliveries from these projects are highly uncertain due to complex interactions between hydrologic variability environmental regulations and infrastructure capacity constraints cadwr 2018 water users are often able to partially mitigate surface water shortfalls by pumping groundwater but doing this repeatedly has resulted in substantial drawdowns of central valley aquifers particularly during recent droughts in 2007 2009 and 2012 2016 xiao et al 2017 in the tulare basin aquifers are managed through a network of groundwater recharge basins recovery wells and surface conveyance much of the capacity in this system has been developed through groundwater banking institutions in which excess surface water is recharged banked via spreading basins so that it can be subsequently recovered withdrawn during wetter periods christian smith 2013 recharge and recovery capacity have been developed jointly by local irrigators and municipal urban users from around the state wells fargo 2017 usbr 2013 operated through cooperative agreements and exchanges between municipal and agricultural sectors the importance of the groundwater banking system to both agricultural and municipal contractors underscores the need for simulation models that can capture multi scale institutional responses to floods and droughts ranging from state and federal management of reservoirs and inter basin transfer projects to local irrigation and groundwater banking decisions within the field of water resources systems analysis there is a growing recognition of the need for tools that enable the prediction of system dynamics and outcomes that provide the basis for evaluating the effects of exogenous changes and policy choices brown et al 2015 such tools are especially important in institutionally complex regions like california where infrastructure planning and the management of surface and groundwater supplies are subject to distributed decisions of many interacting agents with differing goals and unique contexts existing surface water models for california like calsim draper et al 2004 callite islam et al 2011 and calvin draper et al 2003 are deterministic mathematical programming mp models that represent reservoir systems using prescriptive optimization models to determine optimal water allocations at the statewide scale individual water suppliers like metropolitan water district groves et al 2015 and the inland empire utilities agency lempert and groves 2010 perform vulnerability assessments with customized regional weap models yates et al 2009 that use linear programming to solve constrained water allocation problems other mp models are widely used for drought planning labadie and larson 2007 zagona et al 2001 and recent work has shown how they can be coupled with non linear groundwater models to better reconcile the impact of surface groundwater substitution on stream aquifer interactions dogrul et al 2016 broadly this class of mp models are designed to determine optimal allocations of water given a set of welfare or benefit functions distributed through time they do not typically capture institutional interactions that govern surface water rights groundwater management and regulatory constraints on conveyance an accurate representation of operating agreements between institutions is critical for representing the water balance dynamics that arise from the interdependent management of extreme flood and drought events in california this manuscript presents a simulation based representation of california s coordinated water resources operations calfews by simulating water management decisions as a set of interacting responses to changing environmental conditions the calfews model provides a more detailed understanding of how water rights and regulatory institutions introduce heterogeneity in water resources systems the novel framework developed here is designed to address research questions related to the impacts of changes to operating policies infrastructure and or hydrologic conditions on institutional relationships across scales and sectors at a daily time step infrastructure and regulatory constraints impact the coordinated operations between statewide water import projects and their local contractors irrigation and water storage districts that are missed when aggregating operations to a monthly scale particularly with respect to periods of high flow during which water is most readily available for groundwater recharge groundwater banking institutions and other conjunctive use operations increase the importance of multi year path dependencies between these relatively short high flow periods and extended periods of drought the location magnitude and timing of groundwater recharge determine how much groundwater can be sustainably recovered in the future creating incentives for multi sector partnerships e g urban agricultural to more efficiently manage periods of high flows in an effort to increase resilience to multi year droughts cadwr 2020 calfews provides a framework to evaluate how institutional responses to continually changing conditions drive water distribution throughout california s central valley the calfews simulation based approach is capable of representing california s coordinated water resources operations across institutionally complex systems by conditioning actions on shared state variables that represent hydrologic and regulatory conditions as recommended by haimes 2018 within calfews a set of common dynamic state variables related to snowpack and streamflow are used to toggle between operating rules when they have been explicitly defined by the relevant stakeholders e g swrcb 1990 usace 1970 and to evaluate adaptive decision rules when operations are empirically derived from historical relationships as a daily simulation model state variables and operations can be evaluated relative to historical observations cdec 2020a at a number of critical locations throughout the central valley system including storage at 12 major surface water reservoirs pumping rates through swp and cvp facilities in the sacramento san joaquin delta delta that bring water into central and southern california estimates of delta salinity which can limit pumping and storage accounts in major groundwater banks see fig 1 simulation results can be directly compared to these observations as a means of quantifying how well decision rules simulate observed responses to the broad range of changing hydrologic cdec 2020b regulatory nmfs 2009 meade 2013 and infrastructure aecom 2016 usace 2017 conditions that have shaped system dynamics surrounding california s north south interbasin water transfers from the delta to contractors throughout central and southern california this simulation framework specifically supports monte carlo exploratory modelling results particularly with respect to irrigation deliveries and pumping requirements that can be linked to state of the art agricultural production howitt et al 2012 and electric power dispatch kern et al 2020 models decision rules are spatially resolved at the scale of individual irrigation and water districts which have historically been the primary unit of organization for consolidating water rights and financing water infrastructure in california particularly in the southern san joaquin and tulare basins hanak et al 2011 by allocating water through individual district turnouts on canals and natural channels the decisions are able to better reflect the relationship between water rights institutions and the ownership and operation of storage and conveyance infrastructure which is not possible using models that rely on broader regional aggregation of water supplies and demands calfews therefore operates at the spatial and temporal resolution required to link food energy and water systems through consistent hydrologic scenarios enabling it to serve as a useful platform for evaluating complex risks that can be transmitted between these systems bazilian et al 2011 liu 2016 cai et al 2018 haimes 2018 2 methods the calfews model simulates coupled water storage and conveyance networks in california s central valley fig 1 two large water transfer projects link the sacramento san joaquin and tulare basins first via swp and cvp delta pumping facilities that convey water to san luis reservoir and second through the friant kern canal complex environmental regulations constrain pumping based on hydrologic conditions in the delta state swp and federal cvp agencies manage delta hydrologic conditions and export pumping through coordinated releases from seven reservoirs in the sacramento and san joaquin headwaters individual irrigation and water districts control imports from san luis and millerton reservoirs through a shared network of canals connecting districts to the california aqueduct friant kern canal groundwater banks and local reservoir storage in wet years districts recharge aquifers with excess surface water when surface storage capacity becomes insufficient state and federal actions to manage flow storage and water exports interact with local decisions made by institutional users including irrigation and water storage districts calfews simulates this dynamic by linking infrastructure operations to institutional decisions tied to hydrologic and other water management states such as snowpack observations and reservoir storage the total number of each model node structure types by region is shown in table 1 the flow of information between observed states e g snowpack full natural flow distributed decision making e g reservoir releases groundwater recharge diversions and modelled state responses e g reservoir storage groundwater bank accounts during a single calfews simulation step are illustrated in fig 2 at the beginning of each time step new hydrologic input data are used to update observed states at storage regulatory and demand nodes throughout the sacramento san joaquin and tulare basins new observations along with seasonal trends extracted from a historical record are used to inform a battery of distributed heterogeneous decisions made by urban and agricultural water users reservoir operators and local imported water project managers modelled state variables including reservoir storage and groundwater account balances are updated by aggregating the distributed decisions through priority based operational rules that determine infrastructure capacity utilization fig 1 priority based rules refer to the relative priority between water contracts delivery types and ownership of joint assets like groundwater recharge capacity when sharing capacity within a canal contracts with a higher priority are delivered first e g friant class 2 contracts can only be delivered via canal capacity that remains after all friant class 1 contracts are delivered likewise some delivery types are also prioritized over others e g flood release deliveries can only be delivered using canal capacity that remains after normal contract deliveries are filled if capacity must be shared among delivery contracts and or types with equal priority the capacity is shared proportionally based on demands at each node as described in equations 34 and 35 hydrologic preprocessing and reservoir decisions extend an initial study in the sacramento valley by cohen et al 2020 the methods section is organized into four parts describing i how observed state variables are defined based on hydrologic data ii how metrics used to drive management decisions are calculated from observed and modelled state variables iii how management decisions are triggered through applying seasonal adaptive thresholds to the calculated metrics and iv how distributed management decisions are aggregated to update modelled state variables 2 1 hydrologic data and observed state variables daily hydrologic time series data obtained through the california data exchange center cdec are used to update hydrologic states at storage nodes reservoirs regulatory nodes flow gauge and demand nodes irrigation water districts groundwater banks and urban withdrawal points at a daily time step storage nodes are associated with cdec full natural flow reservoir inflow and snowpack stations as listed in table 2 full natural flow and snowpack observations are state variables used for distributed decisions and do not directly interact with calfews infrastructure flow observations from reservoir inflow nodes are used to make daily storage updates regulatory nodes use downstream flow observations to generate incremental flows within a given reach based on the difference between cdec flow gauge data and upstream releases such that 1 i n c r t d o w n r t w u r w u t r u i n c r u t where inc incremental flows m3 s down flow at downstream gauge location m3 s r upstream release m3 s r regulatory node w u reservoirs upstream of regulatory node r r u regulatory nodes upstream of regulatory node r t time step index incremental flows aggregate the unobserved contribution of uncontrolled tributaries stream aquifer interactions consumptive uses and return flows that take place within reaches defined by the location of reservoir outlets and control gauges as shown in fig 1 table 2 also lists the cdec flow stations and upstream reference gauges used to develop incremental flows at each downstream location data for within delta consumptive uses and the contribution of the eastside streams are taken from the california dwr s dayflow data set cdec 2020c negative incremental flow values signify a losing reach within the sacramento san joaquin flow network delta inflows are equal to the sum of incremental flows at all regulatory nodes and releases at all reservoir nodes delta outflows are subject to a water balance within the delta to account for consumptive and exported losses such that 2 d o u t t d i n t e t d e p l e t i o n s t where e delta exports transfers to san luis reservoir m3 s dout total delta outflow m3 s din total delta inflow m3 s depletions consumptive use between delta inflow and delta outflow gages m3 s and w d reservoirs that drain to the delta pumping in the delta is highly regulated and recent changes aimed at improving ecological functions have reduced swp and cvp project yields presenting challenges to large water providers who are reliant on imports mwd 2016 regulatory constraints reflect rules outlined in state water control board decision 1641 swrcb 1990 and national marine and fisheries services biological opinions nmfs 2009 governing minimum outflow requirements inflow export ratios seasonal limits on pumping rates and salinity targets calfews uses the relationship between delta outflows and the x2 salinity line jassby et al 1995 to apply salinity constraints to model operations delta outflows impact the salinity within the transitional area between the sacramento san joaquin delta and the san francisco bay the delta x2 line measures the point relative to the golden gate bridge where salinity 1 m from the bottom of the delta bed is equal to 2 parts per thousand the x2 relationship is calculated according to mueller solger 2012 updating the value of x2 in each time step based on the previous time step delta outflow such that 3 x 2 t 10 16 0 945 x 2 t 1 1 487 log 10 d o u t t 1 where x2 delta x2 salinity line km the tulare basin portion of the model does not contain downstream regulatory nodes instead reservoirs are connected to demand nodes by canals or river channels reservoir operations are determined based on state aware decisions that simulate requests for water use at individual demand nodes irrigation and water districts use management metrics derived from hydrologic states to transition between non linear rules used to request deliveries under normal flood and drought conditions deliveries are requested as a function of water demand at each node explicitly simulated based on land cover and historic withdrawals at municipal diversion points cadwr 2018 id4 2018 land cover data is determined based on crop types described in historic pesticide permitting data mall and herman 2019 or listed in agricultural water management plans aggregated by irrigation district daily consumptive demands are calculated by applying expected seasonal et requirements itrc 2003 to the total crop acreage by district such that 4 d e m a n d d t m d d d t c r o p k l o s s e t c r o p d o w y e a d c r o p y where demand maximum node demand m3 s mdd daily municipal demand m3 s et daily crop evapotranspiration m a acres of crop cover within irrigation district service area m2 dowy day of the water year 1 2 3 365 y year d irrigation district crop crop type e environmental index based hydrologic conditions and k loss loss factor for seepage and evaporation during conveyance 2 2 relating observed states to management relevant metrics daily hydrologic state variables provide calfews with a snapshot of flow snowpack and water demand conditions at nodes throughout the central valley fig 1 however management decisions that incorporate estimates of future hydrologic conditions can make more efficient use of limited infrastructure capacity including reservoir storage delta pumps spreading basins extraction wells and canal conveyance to this end calfews uses a training data series to relate snowpack and full natural flow to seasonal hydrologic conditions including estimates of total snowmelt season april july flows and future flows at one month intervals the historical training series covers the period october 1996 september 2016 for which cdec contains daily data for all model hydrologic states a series of daily linear regressions developed from the training series are used to relate the hydrologic state on a given day of the water year to future water availability aggregated over management relevant periods first estimates from snowpack stations in each watershed are related to reservoir inflow stations as listed in table 2 the total inflow to each reservoir during the snowmelt season april 1 july 31 can be expressed as a function of the total snowpack accumulation at the associated sites through a given day of the water year new snowpack observations can be used to produce an estimate of the subsequent snowmelt season inflows to a reservoir using unique linear coefficients for each day as in cohen et al 2020 such that 5 s m i w t m s n o w w d o w y s p w t b s n o w w d o w y where smi estimated reservoir inflow during the snowmelt season april july m3 dowy day of the water year sp aggregated index of snow water equivalent swe depth m msnow linear regression coefficient m2 bsnow linear regression constant m3 w watershed using the 20 year historical training period regression coefficients can be estimated for each day of the water year such that the sum of squared errors between the estimates produced in equation 5 and the eventual snowmelt season inflow observations are minimized such that 6 m s n o w w d o w y ˆ b s n o w w d o w y ˆ argmin y 1997 2016 s m i w d o w y y d a 181 304 q w d a y 2 where q reservoir inflow m3 s the 20 year historical training period provides 20 unique snowpack accumulation observations to inform each daily regression the daily linear relationships between snowpack observations and the subsequent total snowmelt season inflow at selected reservoirs are shown in fig 3 column 1 with colored lines corresponding to the line of best fit for snowpack observations occurring every day from oct 1st april 1st individual observations from every year of the historical record are shown for three specific days october 1st blue points january 1st green points and april 1st beige points to illustrate seasonal changes in the fit of this data to this linear relationship although the relationship is noisy the linear fit for all reservoirs watersheds improves over the course of the water year as more information about the total snowpack accumulation becomes available a statistical summary of goodness of fit metrics can be found in supplement a snowpack observations send strong signals about water availability during the snowmelt season when most irrigation demand takes place however shorter term monthly estimates of future water availability can also inform infrastructure operations with respect to managing reservoir flood control pools or maintaining adequate supplies for seasonal environmental releases at each time step in the training period the previous 30 days of full natural flow observations can be linearly related to future reservoir inflow observations aggregated into 12 unique consecutive periods of 30 days using 12 sets of linear coefficients for each day of the water year the next 360 days of flow in 30 day increments can be estimated at each timestep based on the trailing 30 day moving average full natural flow such that 7 q w i n t t b f l o w w d o w y i n t m f l o w w d o w y i n t d a t 30 t f n f d a w 30 where q estimated reservoir inflow in time interval int m3 int future flow interval 0 1 2 11 bflow linear regression constant m3 mflow linear regression coefficient fnf full natural flow m3 s as in equation 6 the 20 year historical training period is used to estimate regression coefficients for each day of the water year such that the sum of squared errors between the estimates produced in equation 7 and the observed reservoir inflow observations are minimized for every future interval such that 8 m f l o w w d o w y i n t ˆ b f l o w w d o w y i n t ˆ argmin y 1997 2016 q w i n t d o w y y d a d o w y d o w y 30 i n t q w d a y 2 where q total reservoir inflow m3 s bflow linear regression coefficient mflow linear regression constant fnf full natural flow m3 s int interval index 0 1 2 11 the last two columns of fig 3 show daily linear relationships between the trailing 30 day moving average full natural flow and the expected reservoir inflow aggregated over future periods of 30 and 120 days as in the snowpack accumulation column observations from every october 1st january 1st and april 1st in the historical training period are shown to illustrate data fit to the daily linear relationships the relationships are unique to each watershed and change over the course of the water year to reflect seasonal flow patterns as the aggregation period gets longer and includes observations further into the future the linear relationship becomes noisier as shown in the difference between the 30 and 120 day aggregation periods in addition to estimating flow into reservoirs management related metrics also take advantage of estimates of future incremental flows inc at each gauge location r substituting incremental flows as calculated in equation 1 for reservoir inflow q in equation 8 linear coefficients can be generated to estimate inc using the trailing 30 day moving average full natural flow in equation 7 full natural flow estimators can be aggregated to reflect the drainage area of each incremental flow station as in table 2 in addition to the hydrologic indicators outlined in equations 5 8 tulare basin management metrics also incorporate estimates of the future demand at each demand node through the end of a given water year future demands are estimated as a combination of municipal and irrigation demands as in equation 4 irrigation demands are calculated based on land cover and municipal demands are calculated using observations from historical records municipal demands are estimated through the end of a given water year based on the current allocation of municipal supplies such that 9 m d d d t b u r b d d o w y m u r b d d o w y c o n t r a c t a l l o c d c o n t r a c t y where mdd expected municipal demand m3 s burb linear regression constant for municipal demand murb linear regression coefficient for municipal demand alloc total water contract allocation m3 contract contract type y year d water district irrigation demands are estimated through the end of a given water year based on crop acreages within the service area of an irrigation district and expected crop evapotranspiration itrc 2003 such that 10 i r d d t d a d o w y 365 c r o p k l o s s e t c r o p d a e a d c r o p y where ird irrigation demand m3 s et daily crop evapotranspiration m a acres of crop cover within irrigation district service area m2 y year d irrigation district crop crop type and k loss loss factor for seepage and evaporation during conveyance the management relevant metrics calculated in equations 5 10 are updated at each node illustrated in fig 1 with daily hydrologic observations together these metrics serve as the building blocks for adaptive rules used to inform institutional decisions and operate shared infrastructure 2 3 multi scale adaptive decision making rules calfews abstracts various decision making institutions as sets of decision rules that can be triggered using the management relevant metrics calculated in equations 5 10 in this section we explain the rules that describe the actions of reservoir operators water contract managers and irrigation water districts the three institutional groups that jointly determine calfews infrastructure operations transitions between rule formulations driven by changes to metrics updated with new hydrologic observations enable the adaptive operation of infrastructure illustrated in fig 1 2 3 1 reservoir operators reservoir operations are implemented using independent rules governing minimum environmental releases and flood control pools at each reservoir rules change seasonally as a function of environmental indices that are calculated from hydrologic observations and management metrics from equations 5 10 environmental release rules at each reservoir constrain releases to meet seasonal minimum flows at three locations immediately below the dam outlet at the reservoir specific downstream gages described in equation 1 and at the delta inflow gauges described in equation 2 such that 11 m i n s t r w t max e r l w m e e d n w m e i n c r w t k d i w e i n b m e r b i n c r b t where minstr minimum release at reservoir to meet instream flow requirement m3 s e rl environmental minimum flow at dam outlet m3 s e dn environmental minimum flow at downstream gauge m3 s e in environmental minimum flow at delta inflow gauge m month e environmental index kdi delta inflow requirement sharing coefficient b delta inflow drainage basin r w incremental reach downstream of reservoir w r b incremental reaches associated with delta inflow gage b rio vista vernalis in addition to instream flow requirements managers in sacramento river basin reservoirs maintain responsibility for meeting inflow and outflow regulations in the sacramento san joaquin delta including the location of the x2 line used to measure salinity described in equation 3 as with instream flow requirements the delta rules change seasonally as a function of environmental indices calculated from equations 5 8 if downstream incremental flows are insufficient to maintain minimum delta outflows after meeting consumptive uses within the delta additional delta outflow releases must be made from the sacramento river basin reservoirs such that 12 m i n o u t w t c r l w m a x d m i n m e d x 2 t d e p l e t i o n s t r i n c r t 0 where minout minimum release for delta outflow m3 s crl article 6 swp cvp sharing fraction for in basin releases dmin minimum delta outflow m3 s dx2 minimum outflow to meet x2 salinity requirements m3 s depletions within delta consumptive use m3 s inc incremental flows m3 s minstream minimum release for instream flow requirements m3 s minflood minimum release for flood control m3 s r incremental flow nodes and w d reservoirs nodes that drain to the delta the minimum delta outflow that is required to meet x2 location requirements is calculated each day by rearranging equation 3 used to calculate the x2 location mueller solger 2012 such that 13 d x 2 t 10 10 16 0 945 x 2 t 1 x 2 m a x d o w y e 1 487 where dx2 minimum delta outflow required to maintain x2 location salinity requirements m3 s x2 max x2 regulatory line km x2 simulated x2 value km when minout is positive calfews distributes responsibility for making releases to individual reservoirs based on the swp cvp coordinated operations agreement usbr 2018 that states when water must be withdrawn from reservoir storage to meet in basin uses 75 of the responsibility is borne by the cvp and 25 is borne by the swp in calfews the swp portion of this responsibility is applied to calculations of available water stored at oroville reservoir and the cvp portion of this responsibility is released from shasta reservoir such that crl in equation 11 is equal to 0 75 at shasta 0 25 at oroville and 0 0 everywhere else a complete schedule of instream flow requirements delta outflow requirements and index thresholds reflecting state water resources control board decisions national marine and fisheries services biological opinions and other streamflow agreements cadwr 1967 ferc 2015 ferc 2016 ferc 2019 nmfs 2009 sacramento water forum 2015 swrcb 1990 swrcb 2000 ycwa 2007 can be found supplemental section a calfews also simulates the flood control decisions made by reservoir operators flood control rules are formulated as seasonal flood pool requirements used by the army corps of engineers to provide a cushion of unused storage for flood control effective capacity in each reservoir is determined using indices from the reservoir specific army corps flood control manuals usace 1970 usace 1977 usace 1980 usace 1981 usace 1987 usace 2004 mid and tid 2011 the flood control pool is designed to prevent storage from reaching the maximum design capacity beyond which uncontrolled flows spill from the reservoir risking downstream flooding and potentially threatening the integrity of the dam itself if storage encroaches into the flood control pool reservoir operators must release water to clear this space as a modelling convention 20 of the total volume of flood pool encroachment is released every day until storage has either been cleared from the pool or reaches the maximum design capacity such that 14 m i n f l o o d w t m a x 0 2 s w t t o c w f c i t s w t s m a x w 0 where minflood minimum release for flood control m3 s toc top of conservation pool smax maximum storage capacity fci flood control index value a complete schedule of flood pool volumes and flood control index thresholds for all reservoirs can be found in supplemental section a 2 3 2 water contract managers water contracts entitle owners to some amount of surface water either as flow in a river or a portion of the yield in an imported water project e g swp cvp water deliveries from these contracts are simulated in calfews through requests for reservoir releases and subsequent withdrawals from rivers and canals each contract is associated with one or more reservoirs table 3 where contractors can store their water some reservoirs store multiple contracts under a priority based system to allocate supplies between the contracts before deliveries can be made water contract managers must use hydrologic variables to estimate the total contract allocation in a given year and or when to make additional flood flows available to contractors decisions about contract allocations and flood flow availability help contractors make their own coordinated surface and groundwater use decisions based on individual supplies and demands calfews includes ten unique water contracts including water rights along the kings river kaweah river tule river and kern river delta imports delivered through the state water project central valley project san luis division central valley project exchange division and central valley project cross valley division as well as two classes of central valley project water delivered through the friant kern canal friant class 1 and friant class 2 contract allocations rely upon estimates of total flow through the end of a given water year sept 30th calculated by updating equations 5 8 with new snowpack and full natural flow observations in each time step the expected available water at each reservoir is estimated to be the existing storage plus the total expected inflows less the total volume needed to meet instream flow requirements and maintain end of water year sept 30th storage targets such that 15 a w w t s w t e o s w m t m s e p t r i w m d a t t 365 d o w y max m i n s t r w d a m i n o u t w d a where aw available water m3 s current storage m3 eos end of september storage target m3 e environmental index ri remaining inflow m3 as calculated from equations 5 and 7 and tm month of current time step water that is available through swp and cvp contracts is stored in reservoirs north of the delta as described in table 3 and must be pumped through the delta and into san luis reservoir before it can be delivered to contractors water allocations sourced north of the delta are subject to variability caused by a the need to release stored water to meet delta outflow requirements b the ability to export unstored incremental flows that are available in excess of delta regulations and c conveyance limitations within the delta caused by infrastructure capacity and regulatory constraints equation 15 reflects the additional responsibility of reservoir operators to make releases to support delta outflows minout reducing the amount of water stored in these reservoirs that can be assumed available for delivery to contractors however if incremental flows are high enough throughout the sacramento san joaquin watershed unstored flows that reach the delta in excess of the required outflows can be exported through swp cvp pumps as with their shared responsibility to meet delta outflow requirements unstored exports are divided between the projects based on the swp cvp coordinated operations agreement which states that unstored water available for export is allocated 55 45 to the cvp and swp respectively usbr 2018 such that 16 u w c t c e x c d a t d o w y 365 m a x r i n c r t d m i n m e d e p l e t i o n s t 0 where uw unstored water available m3 cex article 6 swp cvp sharing fraction for excess unstored flows inc estimated incremental flows from training period m3 s and depletions estimated in delta consumptive use from training period m3 s individual contracts allocate estimated available and unstored water as a percentage of a full annual delivery in reservoirs that hold more than one type of water contract allocations are determined based on seniority such that 17 a l l o c c t max u w c t w c a w w c t j n c d e l j n c s n c d e l s n c s n c d e l m a x s n c j n c d e l m a x j n c 0 where alloc contract allocations del year to date contract deliveries m3 delmax maximum annual contract delivery m3 w c reservoirs used to store contract c snc all contracts at reservoir w that have a higher seniority than contract c jnc all contracts at reservoir w with the same seniority as contract c senior water contracts that share storage with more junior contracts i e cvp exchange and friant class 1 have defined maximum annual deliveries as listed in table 3 and contract allocations in equation 17 are capped at 1 0 the junior contracts at each storage reservoir receive an allocation only after full allocations are granted to their more senior counterparts the maximum annual contract delivery values for junior contracts are limited by pumping and conveyance constraints enumerated in supplement a local water rights on the kern tule kaweah and kings river are the senior rights stored in their respective reservoirs but those reservoirs contain no junior water rights the maximum annual contract delivery for these contracts is unlimited and allocations as formulated in equation 17 are calculated using the average annual flow of each river as the value for delmax with allocations allowed to be 1 0 annual contract allocation decisions allow irrigation water districts to schedule contract deliveries based on their individual allocations and estimated demands over the course of a water year water contract managers can also make unscheduled deliveries available to irrigation water districts during brief intermittent periods when reservoir storage is expected to encroach on the flood pool these deliveries are made in addition to scheduled deliveries and can be used to meet consumptive demands or for targeted aquifer recharge when water is being cleared from the flood control pool release rates as calculated in equation 14 often exceed the capacity to recharge aquifers and or the immediate demands for any other productive uses of the water to allow irrigation water districts to use as much of this unscheduled water as possible water contract managers make unscheduled water deliveries available before storage levels reach the flood control pool the unscheduled water available in each time step is equal to the minimum rate that storage would need to be released to avoid flood pool encroachment over any look ahead period n such that 18 u n s c h w t max n 0 365 s w t d a t t n q w m n t n u m d a y s m d w d e m a n d d w n t o c w e n n where unsch maximum flow rate for unscheduled deliveries m3 s n lookahead period d q estimated reservoir inflow in time interval m m3 s numdays number of days in time interval m demand maximum node demand m3 s d w irrigation districts that store water in reservoir w toc top of conservation pool m3 s reservoir storage m3 if the unscheduled delivery rate rises above a given threshold defined here equal to the total recharge capacity of contractor districts unscheduled deliveries become available to any district that makes a request contract manager decisions about the size of an annual allocation and the rate and timing of unscheduled flows as calculated in equations 17 18 form the basis for thresholds used by districts to make adaptive state based decisions 2 3 3 districts imported water contracts and local water rights in the tulare basin are delivered to individual contractors from one of six surface water reservoirs conveyed through a system of natural channels and canals fig 1 contractors are typically organized into districts that provide water within a service area that contains individual consumptive demands and or capacity for aquifer recharge here we refer to an irrigation district id as a contractor that delivers water to irrigators but does not engage in groundwater recharge within the boundaries of their service area a water district wd refers to a contractor that makes deliveries primarily to municipal users or suppliers water storage districts wsd refer to contractors that have both irrigation demands and groundwater recharge facilities within their service areas finally a groundwater bank gwb is a standalone entity with no irrigation demands that includes groundwater recharge and recovery capacity that are owned and operated by one or more id wd or wsds a list of canals and the orientation of their nodes can be found in tables 4 and 5 consumptive demands are described in equation 4 and represent either irrigation demand diversion to a municipal water treatment plant or pumping into a canal branch that leaves the tulare basin shown in fig 1 as the pacheco tunnel las perillas and edmonston pumping plants aquifer recharge capacity in a wsd or gwb represents the rate at which water can be diverted into dedicated spreading basins and percolate into the groundwater aquifer spreading basins within a wsd service area are operated with the intention of increasing groundwater levels which has the effect of reducing pumping costs for district landowners when wsd surface water supplies are insufficient to meet irrigation demands deliveries to districts for irrigation and recharge are dependent on shared infrastructure including surface water storage canal conveyance and groundwater recharge and recovery capacity district decisions represent requests on this shared infrastructure subject to priority based capacity sharing rules when contract managers decide to make unscheduled water available to districts the unscheduled request at each canal node is equal to the maximum amount of water that can be diverted at each node the sum of consumptive demand and recharge capacity such that 19 r e q u n c n i d t d e m a n d d c n i t k o c n i d t b c a p c n i where requn unscheduled water request m3 s cni canal node index demand consumptive demand m3 s d cni irrigation water district at canal node cni ko district ownership share of groundwater recharge capacity at canal node cni bcap initial aquifer recharge capacity m3 s districts also receive scheduled deliveries from their individual water contract accounts scheduled deliveries are equal to some fraction of the maximum unscheduled request based on the estimated district supplies district supplies from local water rights and or imported swp and cvp contracts are calculated as a fixed percentage of the total contract allocation calculate in equation 17 such that 20 s u p p l y d c t k a l l o c d c a l l o c c t c a r r y d c y where supply annual estimated district water supplies m3 d district c contract alloc contract allocation m3 carry previous year s unused contract allocation credited towards this year s supplies m3 y year under normal conditions districts are able to carry over their water accounts from one water year to the next using excess reservoir storage capacity at the beginning of each new water year october 1st contract allocations are reset and districts are granted a carry over credit for any of the previous year s allocation that was not delivered to the district via scheduled delivery such that 21 c a r r y d c y s u p p l y d c t 1 d a t 365 t 1 d e l d c d a where del scheduled contract deliveries m3 s when reservoirs fill this unused storage capacity with new inflow districts forfeit any carry over water that is stored in the reservoir their individual carry over water is redistributed as part of the current year s contract allocation to replace any unscheduled deliveries or flood spills caused by storing the previous year s water to avoid losing their carry over supplies in this fashion districts request increased deliveries for recharge before the reservoir fills at each time step the time to fill can be calculated such that 22 n f i l l w d o w y ˆ argmin t o c w e n f i l l s w t d a t t n f i l l q w m d a t n u m d a y s m d w d e m a n d d w d a 2 where nfill time until the reservoir reaches capacity days q estimated reservoir inflow in time interval m m3 s numdays number of days in time interval m demand maximum node demand m3 s d w irrigation districts that store water in reservoir w toc top of conservation pool m3 and s reservoir storage m3 equation 22 is calculated through simulation in each time step if s starts out greater than toc the reservoir is already full and nfill is equal to zero if the value of nfill results in storage less than the top of the conservation pool such that 23 t o c w e n f i l l s w t d a t t n f i l l w d o w y ˆ q w m d a t n u m d a y s m d w d e m a n d d w d a the reservoir is not expected to fill and nfill is set to a maximum value of 365 given a reservoir fill time of nfill districts can calculate a dynamic recharge capacity based on the rate at which surface water can be recharged into the aquifer such that 24 d r c h g d w t c n i k b g w b d t b c g w b n f i l l w d o w y where drchg dynamic recharge capacity during reservoir fill period m3 kb district ownership share of spreading basin capacity bc groundwater recharge capacity m3 s gwb groundwater bank index d district index when a district has carry over water stored in a reservoir the carry over supplies are at risk of being lost if the district does not take delivery of the water before that reservoir fills if the total carry over water that has not yet been delivered to the district is greater than the district s dynamic recharge capacity calculated in equation 24 the district requests an expedited scheduled delivery such that 25 r e q s c h d c t min c a r r y d c y d r c h g d w c t d a w y s t d e l d c d a c n i r e q u n c n i d t where reqsch scheduled contract delivery request m3 s carry previous year s unused contract allocation m3 del scheduled contract deliveries m3 drchg dynamic recharge capacity m3 requn maximum unscheduled water request m3 s wys first day of the water year october 1 if a district has adequate dynamic recharge capacity for their carry over supplies they will request a normal scheduled delivery as a function of their remaining supplies that have not been delivered during the current water year such that 26 r e q s c h d c t min s u p p l y d c t d a t d o w y t d e l d c d a m d d d t i r d d t 1 0 d e m a n d d t where mdd expected municipal demands through the end of the year m3 ird expected irrigation demands through the end of the year m3 supply annual estimated contract supplies m3 del scheduled contract deliveries m3 s equation 26 represents the request that a district would make to a surface water reservoir storing the district s water contract likewise a district can also make a request to a groundwater bank for recovery of that district s banked groundwater nodes that represent out of district groundwater banks also have the capacity to recover groundwater making it available either as a direct delivery via canal or as an exchange for the stored surface water of another district districts with positive banking accounts can request recovery of those accounts when their surface water supplies are low groundwater recovery is limited by the pumping capacity at the bank so districts initiate groundwater recovery before they have completely exhausted their surface supplies similar to deliveries made for groundwater recharge groundwater recovery is a state aware decision made by individual districts comparing their total recovery capacity to the expected surface water shortfall recovery capacity is evaluated through the end of the water year such that 27 d r c v y d t 365 d o w y t g w b k w g w b d t w c g w b where drcvy remaining recovery capacity m3 dowy day of water year index beginning october 1 1 365 kw district ownership share of recovery well capacity and wc total recovery well capacity m3 s when this threshold is greater than the difference between a district s consumptive demand and its surface water supplies through the end of the water year recovery well requests are triggered such that 28 r w b g w b d t m d d d t i r d d t c s u p p l y d c t d a w y s t d e l d c d a d r c v y d t where rwb groundwater bank recovery well request m3 s mdd expected municipal demands through the end of the year m3 ird expected irrigation demands through the end of the year m3 supply annual estimated contract supplies m3 del scheduled contract deliveries m3 s wys first day of the water year equations 19 28 represent the thresholds and decision rules used to estimate the requests made by individual districts these requests are then subject to priority based infrastructure capacity sharing rules that translate individual requests into water deliveries and other changes in model state variables priority over groundwater banking infrastructure represents ownership shares that give a district the first right to use a certain portion of the capacity any capacity not used by the owner district s is made available to all member districts in equal proportions 2 4 operational rules for shared infrastructure water distribution in each time step and the resulting changes to model state variables surface and groundwater accounts delta x2 reservoir storage are governed by infrastructure operations including shared capacity in surface reservoirs pumping plants canal conveyance spreading basins and recovery wells decisions made by reservoir operators contract managers and irrigation water districts described in equations 11 28 are aggregated to joint infrastructure operations via priority based sharing rules to resolve swp and cvp operations in the delta reservoir operations integrate the reservoir operator decisions described in equations 11 14 with releases based on cvp and swp contract manager allocation decisions described in equations 15 18 swp and cvp contract managers face the additional decision of scheduling releases from north of the delta storage to support pumping while meeting regulatory constraints several seasonal and contextual limits are placed on maximum pumping levels at swp and cvp facilities swrcb 2000 nmfs 2009 including a rule specifying the minimum allowed ratio between delta exports through swp and cvp pumps and delta inflows when this rule called the e i ratio is binding any increase in the combined pumping rate in the delta must also be met with a larger increase in total delta inflow some of which escapes the delta as outflow swrcb 2000 rearranging equation 2 and using a general delta inflow term to replace the summations of reservoir releases and incremental flows the maximum export rate can be expressed as a function of e i ratio delta outflow and delta depletions consumptive uses within the delta such that 29 e t e i r m d o u t t d e p l e t i o n s t 1 e i r m where e delta exports m3 s dout delta outflow m3 s depletions delta consumptive use m3 s and eirm e i ratio in month m i e 0 35 or 0 65 substituting minimum delta outflow regulations for dout in equation 17 results in the maximum allowable export rate when delta outflow is at the minimum target levels even though the permitted capacity at any given moment may be higher than this rate pumping above this level will result in additional required delta outflows reducing the yield of the swp and cvp delta export projects calfews decision rules use this rate as a maximum target to schedule reservoir releases for export such that 30 e c t w c a w w c t m a x d a t 365 d o w y t e t w s w p a w w c t w c v p a w w c t min e t p m a x m e where e target export rate for individual contract swp cvp m3 s e maximum total export at minimum delta outflow m3 s aw available water at each reservoir m3 pmax maximum combined pumping capacity at swp and cvp delta pumps m3 s swp and cvp contract managers augment downstream incremental flows and regulatory releases described in equations 11 14 with additional releases meant to support exports at the level calculated in equation 30 such that 31 r e x p c t e c t c e x c r i n c r t w c e n v r e l w t d m i n m e d e p l e t i o n s t where rexp total contract releases for delta export m3 s cex swp cvp sharing agreement for excess unstored flows inc incremental flows m3 s envrel minimum reservoir release to meet in stream requirements delta outflow requirements and flood control releases m3 s releases for each contract swp and cvp are distributed between the north of delta reservoirs based on the fraction of the total expected available water aw stored in each reservoir the export rate e is a target used to manage reservoir releases but delta pumps can also capture downstream incremental flows that are larger than the required delta outflow and depletions subject to the swp cvp sharing agreement in swrcb 2000 such that 32 e c t m a x e c t min c e x c r i n c r t w c e n v r e l w t d m i n m e d e p l e t i o n s t p m a x c m e where totexp total delta exports m3 s e environmental index and tm month of current time step e target export rate for individual contract m3 s operations in the tulare basin integrate the reservoir operator decisions described in equations 11 14 with the decisions to request deliveries made by irrigation water districts in equations 19 28 deliveries for irrigation and groundwater recharge travel through a shared network of canals and natural channels before they can fulfill district requests each canal reach has a conveyance capacity which is shared between nodes using a priority based system such that 33 d e l c n i c t k c c n i w p d c n i r e q p c n i d c n i c t k c c n i n p d c n i r e q n p c n i d c n i c t where delivery cni c total deliveries to a canal node cni from surface water contract c m3 s cni canal node index k p canal sharing coefficient for priority requests kc np canal sharing coefficient for non priority requests reqp priority district requests scheduled or unscheduled m3 s reqnp non priority district requests scheduled or unscheduled m3 s d cni districts with ownership rights at the canal node the canal sharing coefficient kc cni p is calculated to share the conveyance of any given reach equally with all requests made down canal of that reach giving priority to priority requests such that 34 k c c n i p min c c a p c n i n d c n i c n i e n d d n d r e q n d d n d p t 1 0 and 35 k c c n i n p m i n m a x c c a p c n i n d c n i c n i e n d d n d r e q n d d n d p t 0 0 n d c n i c n i e n d d n d r e q n d d n d n p t 1 0 where req district request scheduled or unscheduled m3 s ccap canal conveyance capacity in reach cni m3 s releases for canal deliveries are made from each reservoir in addition to the regulatory releases described in equations 11 14 such that 36 r d e l c t n d c n i s t a r t c n i e n d d e l n d c t groundwater recovery requests originate from within the canal network rather than at the head of the canal network when requests are made for surface water delivery it is not always possible to deliver this recovered groundwater directly to the district that is making pumped withdrawals from their groundwater banking account instead recovered groundwater can be delivered to any other district for exchange provided that the district has surface water stored in an accessible reservoir in calfews recovery exchange is simulated by delivering recovered water to districts with turnouts along the downstream canal nodes such that 37 d e l c n i g w b t max min d c n i r e q s c h d c n i c t r e q r v y c n i d t n d c n i g w b c n i d e l n d g w b t 0 0 where delivery cni gwb delivery of recovered groundwater from groundwater bank gwb to canal node cni m3 s reqsch scheduled request at delivery node m3 s reqrvy banked recovery request at bank node m3 s deliveries to each node within the canal network as detailed in tables 4 and 5 are calculated through iteration fig 4 illustrates the flow of water through different system states over the course of a single water year the flow begins in northern california where water is either routed to the delta outflow sink along the top of the chart pumped through the delta to san luis reservoir or carried over into the next year as surface water storage the flow can come from one of four reservoirs used as north of the delta storage by the swp and cvp or from uncontrolled sources closer to the delta from san luis reservoir water is delivered to users in the tulare basin along with water stored in the other surface water reservoirs in the basin including millerton reservoir via the friant kern canal annual flows to those reservoirs are divided into various surface water contracts table 3 where along with the previous year s contract carry over water it forms this year s contract allocation some of the surface water is delivered as unscheduled flood deliveries contract allocations and unscheduled deliveries are divided among individual contractors grouped here by general geographic characteristics for visual simplicity the complete list of contractors and groundwater banks included in calfews is shown in tables 4 and 5 based on contractor requests contract allocations and unscheduled deliveries are sent for irrigation municipal use and direct or in lieu groundwater recharge contractors can also save undelivered carry over water for the next water year whatever contractor demands cannot be met via individual surface water supplies are met through groundwater pumping either via banked recovery or private in district wells all groundwater pumping from districts or groundwater banks in the tulare basin assume a bucket model of the underlying aquifer depth to groundwater in the region is assumed to be sufficiently far below the surface that surface water groundwater interactions from changes in pumping rate can be ignored brush et al 2013 groundwater seepage from surface water conveyance in natural channels and unlined canals are accounted for with the term k loss in equation 10 all water diverted for recharge is assumed to achieve deep percolation with no return surface water flows after delta exports and district deliveries are resolved calfews updates state variables based on infrastructure operations reservoir releases calculated in equations 11 14 and 36 are used to update storage at each simulated surface water reservoir and the total delta outflow which is used to update the x2 salinity line as in equations 3 4 recharge and recovery operations at groundwater banks are used to update individual district banking accounts changes in groundwater banking storage accounts also assume a bucket model within each groundwater bank with no surface water groundwater interactions or lateral flow of groundwater between banks or district service areas groundwater storage accounts are simulated to determine the volume of water that is allowed to be withdrawn from a given water bank and not as an explicit model of aquifer storage or groundwater level groundwater banking storage accounts do not have a set capacity within calfews as extensive groundwater depletion throughout the tulare basin region has created unused groundwater storage capacity that is assumed to be significantly greater than any storage volumes simulated within the model o geen et al 2015 scheduled contract deliveries are used to update allocations and individual district accounts to surface water contracts updated state variable values are carried through to the next time step where they form the basis for the next iteration of adaptive decisions 3 results 3 1 model evaluation and capabilities the adaptive operating rules employed in calfews enable simulations based on any daily input time series of flow and snowpack data at the storage and regulatory nodes shown in fig 1 simulation results based on historical input data can be compared to observations at a number of critical locations throughout the central valley system as a means of quantifying how well decision rules capture historical system operations in addition to encompassing a range of hydrologic conditions the 20 year historical period of comparison october 1996 september 2016 includes substantial changes to statewide regulatory regimes that have impacted the operation of the swp and cvp as well as significant infrastructure expansion within kern county groundwater banks during simulations of this historical evaluation period calfews representations of these changes including environmental flow requirements pumping limits and infrastructure capacities are integrated to reflect the timing of their implementation choosing an evaluation period that experienced these types of structural changes in addition to a wide range of hydrologic conditions increases confidence that the system of adaptive rules embedded within calfews can provide insight into future uncertainties related to hydrologic change infrastructure development and environmental policies fig 5 shows the performance between observed storage and simulated results during the 20 year historical period at all twelve surface reservoirs in the sacramento basin all four simulated reservoirs shasta oroville folsom and new bullards bar dam fig 5a d display r2 values ranging between 0 86 and 0 94 these large reservoirs form the bulk of the releases to regulate delta outflows and support north south exports san joaquin reservoirs fig 5e g including new melones don pedro and exchequer have slightly higher levels of performance with r2 values ranging from 0 93 to 0 97 many of the releases for these reservoirs are made to deliver water to downstream agricultural users agricultural demands supplied by these three reservoirs are not modelled based on implied et demands from land cover as calfews does for tulare basin irrigators instead historical withdrawals for irrigation are calculated as negative incremental flows in the reaches between these reservoirs and their downstream regulatory node as in equation 1 negative incremental flows force the reservoirs to release water to meet downstream flow requirements meeting the demands without the type of explicit agricultural modelling that occurs in the tulare basin region of calfews as described by equation 10 although new melones don pedro and exchequer are not explicitly operated to support swp and cvp delta export programs the three reservoirs here perform important flood control and minimum flow regulation for delta inflows through the vernalis gauge that can impact pumping rates releases from millerton reservoir are not included when regulating flows at vernalis even though the dam controls the headwaters of the san joaquin river we assume here that most excess releases are consumed at the mendota pool before interacting with any gages in the delta system and any releases that do contribute to delta inflows are included in the observed uncontrolled flows on the san joaquin river the reservoirs shown in fig 5h l millerton pine flat kaweah success and isabella deliver water directly to the tulare basin irrigation water districts the simulation results for millerton reservoir fig 5h are the poorest of the calfews represented reservoirs but still generate an r2 value of 0 57 millerton is a smaller reservoir subject to flashy flows especially during the winter wet periods flood control releases can be large and potentially occur well in advance of the reservoir reaching full capacity as operators attempt to deliver as much flood water as possible to contractors along the conveyance constrained friant kern canal the flow estimates used in equation 18 to schedule flood control decisions in calfews do not capture all of the information used by millerton reservoir operators and friant contract managers when they make their flood control decisions leading to errors in storage when the timing of flood releases are mismatched model operations would likely be improved by more resolved estimation of wet period flow in the san joaquin headwaters it should be noted however that operational rules used in calfews do broadly capture major storage dynamics in millerton and perform quite well in simulating the recent 2012 2016 drought suggesting that they can adequately represent the influence of the san joaquin river restoration project which began in 2009 on dry year storage levels in millerton reservoir flow that makes it to the delta is either exported through swp fig 6 a and cvp fig 6b pumping works or allowed to flow out to the san francisco bay where the impact on the x2 salinity line fig 6c can be measured the delta x2 salinity line measures the point where salinity in the delta is equal to 2 parts per thousand 1 m from the bottom of the bay floor relative to the golden gate bridge x2 values peak in the late summer early fall after low summer flows have allowed delta salinity to move eastward inland farther from the golden gate bridge and reach their low point in the spring after high winter flows push the salinity back towards the sea simulated x2 corresponds well with historical values as calculated in the california dwr s dayflow time series displaying an r2 of 0 95 for weekly average values and 0 96 for monthly averages simulations of exports at the swp and cvp delta pumps also correspond well with historical observations at the annual scale r2 of 0 89 and 0 91 for the swp and cvp respectively with the relationship holding up well even when compared on a weekly time step r2 of 0 64 and 0 59 respectively the sub annual results are particularly important because the pumping time series serve as inflows into san luis reservoir and the timing of inflows impacts the size and type of deliveries that can be made to tulare basin contractors the model s ability to capture the storage dynamics in san luis reservoir both the state and federal portions are shown in fig 7 despite being subject to some degree of modelling error in inflow delta pumping estimations and reservoir releases district demand estimations they broadly capture the monthly observed storage monthly is the only time step at which individual swp and cvp storage accounts are recorded in san luis reservoir simulated storage in san luis reservoir has an r2 value of 0 73 in the swp portion and 0 66 in the cvp portion given the sheer complexity of the san luis reservoir s operations the calfews simulation manages to capture the general timing variability and bounds of the system s storage water delivered for groundwater recharge is delivered either within the service area of an wsd or to a gwb outside of the district service area water recharged in gwbs can be recovered and delivered to an id wd wsd but only if the district has a positive balance in the bank fig 8 illustrates the correspondence between simulated and observed cdec 2018 hanak et al 2012 groundwater storage accounts in the kern gwb kwb and semitropic wsd swsd where most of the banking users are swp contractors the kwb is primarily operated for agricultural users while banking members in the swsd are mostly municipal water districts calfews is able to capture the historical groundwater banking dynamics with relatively high r2 of 0 70 and 0 67 for the annual change in storage accounts at kwb and swsd respectively high levels of r2 at kwb 0 77 and swsd 0 64 are also attained for the total cumulative balance in each bank at both banks errors are largest in very wet years in which simulated results do not recharge as much water as is reflected in observed accounts simulation results have better correspondence with observations during dry years as the most downstream part of the calfews model groundwater banking results are subject to modelling errors in reservoir releases delta pumping and contractor water demands however the errors observed in banking accounts in both the kwb and swsd are not systematically biased in any direction and storage accounts in both banks are very close to the observed accounts at the end of the 20 year simulation to the authors knowledge no simulation system outside of calfews has ever been able to capture the complexity of human systems operations and water balance dynamics with the level of fidelity shown here errors between simulated groundwater banking storage accounts and observed storage accounts overall appear not to be amplified across years that is our simulation results do not show sustained inter annual over or under prediction 3 2 state aware decisions the general agreement between observed and simulated results at key central valley locations set the stage for a deeper look into the dynamic and adaptive ways calfews simulations represent stakeholder decisions simulated infrastructure operations are the product of individual heterogeneous agents making decisions in response to changing hydrologic and management states these states are based on the translation of environmental variables into simulated management relevant states like those relating to state water project allocations shown in fig 9 simulated allocations are updated in every timestep based on the component parts of the swp contract allocation described in equations 15 17 during the calfews simulation of the historical evaluation period oct 1996 sept 2016 the expected swp allocation white line responds to changes in the expected available water at oroville and new bullards the swp portion of any expected unstored flows and the year to date exports that have already been delivered to san luis reservoir in addition annual simulated allocations are also constrained by the expected pumping capacity through the end of the water year during the historical evaluation pumping constraints cause the expected swp allocation to occasionally fall below the sum of its component parts particularly during wet periods when this occurs swp contract managers carry over this excess water in oroville and or new bullards resulting in end of year storage above target levels in the following years this extra carry over storage is included in the calculations of expected available storage in the respective reservoirs increasing initial estimates of that year s swp allocation calculations of swp allocations fig 9 are translated into individual contractor allocations that can be used to make district level water supply decisions as demonstrated for a specific irrigation district wheeler ridge maricopa fig 10 the historical evaluation period includes a significant recent drought from 2013 to 2016 during which calfews simulated the district s groundwater recovery operations in 2013 the first year of the drought the district s portion of the swp allocation was equal to approximately half of its expected irrigation demand the district made requests for surface water deliveries based on this allocation according to equation 27 with the balance of the irrigation demand met through recovery of the district s banked groundwater originating in groundwater banks outside the district s service area and private groundwater pumping by the district s irrigators although the district had sufficient supplies in their groundwater banking account in 2013 the district s recovery pumping capacity at the bank limited the rate at which the banked water could be delivered to the district requiring some amount of in district private groundwater pumping the following winter low snowpack levels caused expected swp allocations to drop further fig 9 which in turn reduced wheeler ridge maricopa s expected surface water supply fig 10 the district relied heavily on banked groundwater recovery in water year 2014 to make up for reduced surface water deliveries and by the end of the irrigation season the district completely depleted their banked groundwater storage calfews simulation rules do not permit groundwater recovery when banked storage accounts are empty so when the simulated historical drought continued in 2015 the district s irrigation was almost entirely supplied by private groundwater pumping at wells within the district s service area the final year of the drought 2016 started out dry but increased precipitation led to larger expected contract allocations increasing district surface water supplies irrigators within the district began the year pumping private groundwater expecting that the rest of the year would be dry as well but were able to cease pumping by july when it was clear the remaining demands could be met through surface water deliveries from the swp due to increases to the swp allocation late in the year the district was able to end the year with additional supplies and thus carry over swp supplies into the next year during wet periods calfews also simulates unscheduled flood deliveries to contractors decisions about the timing and magnitude of these releases are made by surface water contract managers when reservoirs are close to filling as reservoir storage increases reservoir fill time falls in accordance with seasonal trends e g the same storage volume will correspond to a shorter fill time if it is observed in december and a longer fill time if it is observed in june after a significant portion of snowmelt has already occurred and as storage approaches capacity fill time goes to zero fig 11 at san luis reservoir natural inflow is negligible and the reservoir is almost entirely fed by swp cvp pumps at the delta pumping capacity limits the rate of inflow into san luis reservoir during high flow periods reducing the need for pre emptive flood releases driven by expected future inflows as in equation 19 in calfews swp flood releases are not made from san luis reservoir until storage approaches capacity in the state owned portion of san luis reservoir however reservoir fill time in san luis is an important metric for individual districts attempting to manage their carry over water if a swp contractor does not deliver their entire swp contract they are able to carry it over in san luis reservoir any carry over water remaining in san luis when it reaches capacity is forfeited by the district carrying it over and instead delivered to any contractor with the capacity to take it districts therefore will attempt to use any carry over water if they observe the reservoir filling up this decision is triggered when a district s cumulative recharge capacity during the expected reservoir fill time calculated in equation 24 is less than a district s current and or expected cumulative carryover individual district carry over operations as shown in fig 12 are designed to store excess surface water allocations carry over water from one year for use in the next either for groundwater recharge or when possible to meet irrigation or municipal demands in the historical simulation wheeler ridge maricopa begins water year 2005 october 2004 with about 25 taf 31 106 m3 of unused carry over water in san luis reservoir as shown by the white line however san luis reservoir also had a significant volume of unused storage capacity at this time and the district s metric to measure their dynamic recharge capacity the total volume of water that could be diverted into district groundwater recharge facilities before san luis reached its storage capacity remained larger than the volume of carry over water they stored in san luis as the winter progressed the simulation delivered the district s carry over water to meet winter irrigation demands the district was able to use all of their carry over water for irrigation before san luis reservoir filled in february of 2005 fig 12 expectations for that year s swp contract allocation continued to increase throughout 2005 as previously shown in fig 9 eventually causing wheeler ridge maricopa s individual swp supplies to exceed their remaining irrigation demand the district carried over a similar volume in water year 2006 but san luis reservoir was much closer to capacity because other contractors were also storing carry over water reservoir fill time fell much more quickly at the beginning of water year 2006 reflected in the district s falling dynamic recharge capacity dark blue area of fig 12 at the point during water year 2006 when this dynamic recharge capacity fell below the districts remaining carry over storage calfews triggered the district s decision to begin delivering their carry over water to groundwater recharge facilities the use of groundwater recharge capacity allowed wheeler ridge maricopa to deliver all their carry over water earlier than in 2005 avoiding the need to forfeit unused supplies water year 2006 also saw very high expected swp contract allocations and by mid summer of 2006 the district was expected to bring a very large volume 60 106 m3 of carry over water into the next year high simulated storage levels at san luis reservoir again resulted in low dynamic recharge capacity for the district and the combination of high expected carry over storage and low dynamic recharge capacity caused the district to begin delivering their potential carry over water to groundwater banking facilities before the end of water year 2006 the district was able to recharge this water more quickly than expected because few other districts were recharging surface water at this time and wheeler ridge maricopa was able to take advantage of unused capacity at their groundwater banking facilities at the start of water year 2007 the district delivered their remaining carry over water for irrigation and groundwater recharge before san luis reservoir could re fill in early 2007 carry over storage operations in calfews enable individual districts to make coordinated surface and groundwater use decisions saving their surface water for irrigation or municipal demands when possible while still avoiding losing their supplies through selective use of groundwater recharge capacity 3 3 extended historical re evaluation the rules based adaptations that drive simulations allow calfews to evaluate reservoir releases delta operations irrigation deliveries and groundwater recharge recovery under a wide range of input conditions infrastructure configurations and regulatory regimes over the course of the 20 year historical evaluation period october 1996 september 2016 decisions rules adapt to increasing capacity in tulare basin groundwater banks aecom 2016 the imposition of the national fisheries and wildlife services old middle river rule nmfs 2009 limiting the capacity of delta pumps between january and june and the san joaquin river restoration project meade 2013 which increases the required environmental releases from millerton reservoir these changes are implemented into model simulations as they occur in real time construction of the kern water bank 2001 2003 old middle river delta rule 2008 san joaquin river restoration 2009 over the historical evaluation period but we can also conduct an extended historical re evaluation applying regulatory changes to the entirety of an extended full natural flow record available through the california data exchange center cdec full natural flow records in the sacramento san joaquin and tulare basins reach back as far as 1905 enabling a 111 year extended historical re evaluation under scenarios reflective of current infrastructure and regulatory conditions in watersheds where flow and snowpack data were not available over the entire period they are synthetically extended using historical relationships with existing data in addition incremental flow and reservoir inflow datasets are not available for the same historical duration so inputs are synthetically generated based on more recent 10 1996 09 2016 observed relationships with the full natural flow data as described in supplemental section b simulation results illustrate the water availability that would have been observed in the system under historical hydrologic variability and a static set of institutional conditions including current land use population infrastructure and regulatory regimes fig 13 compares the distribution of swp and cvp delta pumping and delta outflows under the extended historical re evaluation scenario 111 years water years 1906 2016 the historical evaluation scenario 20 years water years 1997 2016 and historical observations 20 years water years 1997 2016 although the extended historical period 1905 2016 contains a slightly higher portion of wet and above normal water years than the historical evaluation period 1996 2016 it produces a much lower frequency of years with very high annual exports through both the swp pumps 4300 x 106 m3 year and cvp pumps 3400 x 106 m3 year this illustrates the impact of applying the recent regulatory changes across the entire extended historical period rather than only during the 2008 16 period under which they are applied in the historical evaluation scenario new regulations applied to the delta primarily limit pumping rates from january to june preventing the pumps from running at capacity for a substantial portion of the year and limiting the water that can be exported during the typical high flow season the regulatory impact can also be observed in very dry years which form a second smaller peak in the bi modal pumping distribution that is most pronounced in the extended historical scenario during these years there is often very little snowpack above swp and cvp storage reservoirs and most of the water that could be exported is available as uncontrolled inflows to the delta during brief periods in the wetter winter months however regulations become more restrictive to wintertime pumping operations when conditions are the driest in addition to having fewer supplies to export swp and cvp managers are also effectively operating with reduced infrastructure capacity during dry years leading to the bimodal distribution shown in fig 13 4 discussion this study presents results from a 20 year historical simulation and a 111 year synthetically extended historical re evaluation in both scenarios infrastructure and land cover are set deterministically the former tracking the observed changes over the 20 year period october 1996 september 2016 and the latter applying current conditions to the entire hydrologic record that occurred from october 1905 september 2016 the historical simulation provides a benchmark for quantifying how well the decision rules described in calfews capture stakeholder adaptations to continually changing surface and groundwater conditions throughout the state of california in contrast with statewide mp based models such as calvin draper et al 2003 calsim draper et al 2004 or callite islam et al 2011 that seek to identify optimal allocations of surface water under a specific set of hydrologic and demand conditions the state aware decision rules framework adopted here seeks to describe the system as it currently exists perhaps more importantly the framework describes how decisions within the current system is driven by different environmental indicators e g snowpack flow land cover the ability to quantify and evaluate how individual water users respond to changing conditions is particularly helpful in identifying how they are impacted by marginal changes from current operations like those that could arise from the state s flood mar research and data development plan cadwr 2020 by linking decision rules to a heterogeneous set of users and stakeholders like irrigation districts or reservoir operators the analysis can also capture the distributional effects of changes to operating policies and or infrastructure these distributional effects are particularly important with respect to the continuing development of groundwater recharge and recovery efforts in the state the location magnitude and timing of groundwater recharge determines how much groundwater can be recovered in the future and by whom the groundwater banking rules used in calfews limiting groundwater recovery to only water that has been previously recharged at the site aids in understanding these multi year regulatory links between flood and drought periods the spatial and temporal scale used within the calfews simulation framework also allow it to be interoperable with land use and power dispatch models land cover selection used to estimate irrigation demand in this study is deterministic ignoring the relationship between surface water variability and irrigated acreage irrigation demands that are not met by surface water or banked recovery deliveries are assumed to be met through private groundwater pumping however literature suggests that the relationship between surface water availability groundwater pumping and irrigated acreage is a more complex economic decision for irrigators medellin azuara et al 2015 in future work irrigation deliveries generated by calfews can be linked with economic models of agricultural production such as california s swap howitt et al 2012 to represent adaptive land use decisions in order to get an accurate picture of the pumping costs faced by irrigators future versions of calfews can also include an explicit representation of the changes to groundwater levels that result from direct aquifer recharge and groundwater pumping in a given spatial area an important factor in meeting sustainability targets described in the sustainable groundwater management act extending the state aware decision framework to groundwater levels as an environmental indicator and district level land cover using a decision rule could enable the exploration of more complex groundwater management strategies likewise state of the art power dispatch modelling has demonstrated the connection between drought and wholesale energy prices in california kern et al 2020 with a particular attention to changes in hydropower generation and temperature based variability in energy use for the cooling of buildings however these models can also consider changes to other energy consumption related to surface water drought in california such as changes to the volume of groundwater pumping or conveyance of the state water project the single largest energy user in the state coordinated modelling of surface and groundwater use paired with estimates of wholesale and retail electric power prices can provide insight into the financial risks faced by irrigation districts groundwater banks and individual irrigators these risks impact the ability of institutions to repay loans and meet other fixed cost obligations playing a role in determining investment decisions future versions of calfews can incorporate feedbacks between environmentally driven changes in energy consumption energy prices and financial risk to irrigators and groundwater bankers as water supplies become more diversified as outlined in the state of california s resilient water portfolio initiative canra 2020 institutions that are capable of managing the year to year financial variability will be capable of greater adaptation in response to hydrologic and regulatory uncertainty 5 conclusions this study introduces the california food energy water system calfews simulation model to illustrate the integrated multi sector dynamics that emerge from the coordinated management of surface and groundwater in the state of california the calfews simulation framework captures the relationships between actors at multiple scales linking the operation of inter basin transfer projects in california s central valley with coordinated water management strategies abstracted to the more highly resolved scale of irrigation and water storage districts a set of interdependent rules conditioned on dynamic environmental variables enable the model to abstract the coordinated management of surface and groundwater resources in the central valley these abstractions are evaluated against observations from a recent 20 year period oct 1996 sept 2016 and are shown to accurately represent swp cvp deliveries surface water storage and groundwater banking operations in california s tulare basin distributed state aware decisions provide insight into how a range of institutions adapt to changing hydrologic and regulatory conditions in a way that is consistent with recent historical observations of surface water storage delta exports and water quality metrics and groundwater banking accounts in the tulare basin flexible decision rules enable calfews to evaluate alternative streamflow scenarios under particular infrastructure and regulatory assumptions the simulation framework can specifically support monte carlo exploratory modelling results particularly with respect to irrigation deliveries and pumping requirements simulations can be linked with agricultural production and electric power dispatch models to create hydrologically consistent scenarios upon which to evaluate risks to food and power systems economic models of agricultural production like the statewide agricultural production swap model used in california howitt et al 2012 use surface water deliveries and groundwater access to estimate crop choice decisions groundwater pumping and annual agricultural yields abstractions of groundwater banking operations made within calfews can better resolve water deliveries to individual districts allowing for more detailed projections of land use and groundwater pumping medellin azuara et al 2015 hydropower is responsible for between 7 and 21 of california s total energy generation useia 2020 but energy used for conveyance and distribution can offset a significant portion of this production during the period 1998 2004 the energy used to convey state water project supplies alone ranged between 8 wet year and 24 dry year of the total annual hydropower production cec 2010 nyberg 2020 state of the art electric power dispatch modelling has demonstrated the connection between drought and wholesale energy prices in california kern et al 2020 based on changes to hydropower generation and energy use for cooling structures however the literature has not considered any potential drought induced covariation between hydropower production and the energy demands for surface water conveyance and groundwater pumping instead of a prescribed sequence of optimal water deliveries assigned to specific time periods calfews formulates daily data input series into a number of state variables that are used to coordinate infrastructure operations model rules adapt to dynamic regulatory constraints on infrastructure enabling monte carlo simulations that combine different hydrologic regulatory and infrastructure scenarios institutional abstraction at multiple scales e g inter basin transfer projects irrigation districts joint groundwater banks enables rule based coordination between regional and statewide actors linked through conditions throughout the state regulations and hydrologic conditions that affect exports through swp and cvp delta pumps for example also affect imported water contract allocations and floodwater availability which in turn influences how individual districts operate their groundwater recharge and recovery infrastructure groundwater banking and other coordinated use operations create a relationship between flood and drought periods limiting recovery operations as a function of previous recharge this relationship may become more important to irrigators and municipal users as the issue of groundwater sustainability increases in salience due to the recently enacted sustainable groundwater management act cadwr 2020 calfews provides a foundational framework that can support future monte carlo exploratory modeling efforts to understand the path dependent impacts of hydrologic and regulatory uncertainty on coordinated surface and groundwater management revealing potential risks and opportunities as they play a larger role in statewide resilient water portfolios canra et al 2020 calfews is able to resolve these actions at the level of individual irrigation and urban water districts providing insight into financial risks and water use at a management relevant scale tools that allow institutions to evaluate and manage co evolving physical and financial risks are crucial to the process of developing sustainable and resilient water solutions for institutionally complex contexts like the american west name of software calfews developers h b zeff zeff live unc edu a l hamilton k malek j d herman j s cohen with contributions from g w characklis p m reed and j medellin azuara software date availability all code and data for this project including figure generation are available in a live repository http github com hbz5000 calfews and a permanent archive https doi org 10 5281 zenodo 4091708 source language python cython license mit declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national science foundation through the innovations at the nexus of food energy and water systems infews program cns 1639268 appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2021 105052 
