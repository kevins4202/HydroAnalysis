index,text
1740,confluences play a key node role in the river network because they affect flow sediment transport water quality and ecological patterns hydrodynamic features of the confluence hydrodynamic zone are complicated due to their three dimensional 3d flow structure the present research goal is to investigate the effects of discharge ratio and momentum ratio on depths and free surface profiles at a 45 confluence laboratory experiments and numerical simulations were carried out to investigate the water surface characteristics at confluences under different discharge and momentum ratios the spatial variation backwater degree umbilication degree and horizontal and longitudinal free surface slope ratio of the water depth at the confluence were examined in detail the relationship between the water surface characteristics and the normalized momentum ratios m are constructed via regression analysis we conclude that i the water surface characteristics at the confluence can be grouped into the backwater zone separation zone contractile zone and recovery zone ii the momentum ratio has a more appropriate correlation with the area ratio the area of low water depth in the separation zone to the area of downstream channel al than the discharge ratio iii the backwater may be closely related to the amount of incoming flow rate iv the logarithmic regression model between m and area ratio al was established and it is found that al increases as m increases this study provides a broader understanding of controls on spatial gradients of the water depth and provides guidance for the study of mass transport of pollutants at the confluence keywords confluence water surface characteristics water depth turbulent model water surface simulation data availability data will be made available on request 1 introduction the complex fluid hydrodynamics at confluences constantinescu et al 2011 2014 bradbrook et al 2000 2001 affect the local mixing and distribution of water temperature constantinescu et al 2016 sediments biron and lane 2008 szupiany et al 2012 wang et al 2019 ribeiro et al 2012 and pollutants xiao et al 2019 tang et al 2017 that form the background of local water environment yoshimura et al 2015 chen et al 2017 cheng and constantinescu 2018 bahmanpouri et al 2021 indeed the unique characteristics and nutrient distributions of water mixing from two different sources can result in important local fish habitat that is not replicable in either upstream reach or the downstream main river stream ginney 2001 rice et al 2001 czeglédi et al 2016 furthermore confluence physics alter what might be called the hydromechanical habitat as illustrated in fig 1 the depth temperature distributions velocities and total dissolved gas supersaturation tdgs that also affect habitat suitability therefore dam operational management targeting confluence behavior and in stream engineering practices could be used as part of holistic management techniques to maintain and improve confluence hydromechanical habitat but such efforts are stymied by our lack of understanding of the controls on various aspects of the confluence behaviors physical models have been extensively used to understand the flow patterns mosley 1976 cortés et al 2014 shayan et al 2015 kazemi et al 2016 shen et al 2016 2019 patterns of suspended sediment transport huai et al 2019 2020 yang et al 2021 in open channel indeed the roles of the major control factors on the confluence zones have been investigated over three decades using physical confluence models in the laboratory hager 1987 1989 ramamurthy et al 1988 weerakoon et al 2010 best and roy 1991 biron et al 1996 gurram et al 1997 shen et al 2022 numerical models have also been widely used to quantify confluence hydrodynamics bradbrook et al 2000 huang et al 2002 biron et al 2004 sinha et al 2012 lyubimova et al 2014 duguay et al 2022 here we distinguish between attempts to represent confluence effects on two dimensional 2d depth averaged models from the three dimensional 3d models that provide insight into the confluence hydrodynamics the main difficulties in 3d simulation of confluence flow are rapid change water surface and choice of turbulence models yang et al 2021 a variety of methods have been developed to predict changes in water depth from upstream to downstream along a main channel at confluence taylor 1944 ramamurthy et al 1988 shabayek et al 2002 creëlle et al 2017 however almost all of these methods adopt one dimensional 1d hydraulic analysis without regard to the highly turbulent and the 3d distribution of water depth rhoads 2020 the 1d approximations do not fully capture the 3d complexity of confluence hydraulics luo et al 2018 therefore it is necessary to carry out 3d studies to obtain fine depth structure at confluences in addition many scholars have also conducted numerical studies on the water surface of open channel bends there were also some numerical research about water surface in open channel bends seyedashraf and akhtari 2017 studied the free surface flow in a steeply curved open channel with a 30 bend gholami et al 2014 conducted experiment and numerical study on the water surface in a highly bent 90 open channel curve using the volume of fluid vof method depth is recognized as playing a critical role in habitat through fish preferences e g carps and flat finned loaches prefer depths less than 0 4 m wang and yan 2008 and also by the compounding effects of depth on tdgs dissipation qu et al 2011 the depths across a confluence play an important role in both the reoxygenation of dissolved oxygen do in the water and tdgs dissipation li et al 2013 for every 1 m increase in water depth tdgs decreases by 9 6 in relation to the solubility of the gas in the water colt 1984 furthermore it is known that a confluence separation zone has shallower depths than flow constriction zones best 1985 biron et al 1996 weber et al 2001 schindfessel et al 2017 which may combine with turbulent mixing effects on tdgs to provide fish refuge during otherwise unsuitable habitat conditions our overall understanding of confluence hydrodynamics is built on the work of best 1987 who identified six zones including flow deflection flow separation flow stagnation maximum velocity flow recovery and distinct shear layers these categories have been widely adopted to place specific study results into a broader context hager 1989 ramamurthy et al 1994 blanckaert 2009 leite ribeiro et al 2012 zhang et al 2015 yuan et al 2019 lewis et al 2020 prior studies of river confluences generally focus on the analysis of flow structure separation zone and secondary flow with relatively little discussion of depth effects hsu et al 1998a 1998b shumate 1998 sukhodolov and rhoads 2001 weber et al 2001 rice et al 2006 rhoads et al 2009 leite ribeiro et al 2012 ramón et al 2013 2016 trevethan et al 2015 guillén ludeña et al 2016 herrero et al 2018 the confluence hydrodynamics are considered 3d i e they are poorly described by depth averaged or depth integrated equations as illustrated by the experiments of wang et al 2006 for open channel confluences for the separation zone of particular interest is how the separation zone shifts in response to changes in the discharge ratio which is the ratio of tributary discharge to the discharge in the main stem boyer et al 2006 parsons et al 2007 ramón et al 2013 wang et al 2019 liu et al 2023 best and reid 1984 concluded that as the discharge ratio increased the length and width of the separation zone increased while its shape index remained almost constant zhang et al 2013 studied the effects of the discharge ratio on river confluences based on the momentum principle yuan et al 2017 observed a region with low velocity between the shear layer and the region of maximum velocity when the discharge ratio is small but it disappears when the discharge ratio increases the causes of this phenomenon and the rules that it follows require further inquiry the discharge ratio and momentum flux ratio have been identified as key parameters which influences the processes at confluence ramamurthy et al 1988 hager 1989 best 1985 hsu et al 1998a 1998b mignot et al 2013 and provides the principle framework for quantifying confluence effects as used herein above most of the models are informed by detailed campaigns of velocity measurements and observations of flow structure and of morphological change evidence on how the flow structures affect the water surface however is relatively sparse biron et al 2004 the present work remedies this gap with a quantitative focus on spatial distribution of water depths at confluences which provides a companion to prior studies on spatial distribution of tdgs dissipation shen et al 2016 2019 2021 the purpose of this study is to investigate the effects of discharge ratio momentum ratio and the normalized momentum ratio m on depths and free surface profiles at confluences an experimental of open channel flume with a 45 junction angle was conducted along with validated numerical experiments to develop regression models that explain depth behavior at the confluence based on controlling parameters this study contributes to finding a broader understanding of controls on spatial gradients of the water depth with respect to momentum ratio as well as to understanding the flow and pollutants processes that are present in confluences the flume experiment numerical simulations and regression modeling in this paper are organized as follows section 2 provides experimental apparatus and measurement method which in presented in more detail in shen et al 2019 provides a synopsis of the 3d numerical simulation with volume of fluid vof model and provides overview of the regression model section 3 provides an integrated presentation of results and discussion of the experiment numerical simulations and the regression analysis a summary of the findings is presented in section 4 2 materials and methods 2 1 experimental approach 2 1 1 experimental setup channel and instrumentation laboratory experiments were conducted in an open channel flume that consists of two 0 5 m width channels meeting at a 45 angle as illustrated in fig 2 b which was used in experiments of shen et al 2019 the flume is constructed of organic acrylic glass fig 2 a with a bottom slope of 0 1 a 1 mm difference over 10 m the water supply system uses independent supply tanks for the tributary channel and main channel the flow is a single pass through i e without recirculation weirs are used at the upstream entrance to each flume for flow measurement with a triangular weir in the main channel fig 2d e and a rectangular weir on the tributary a barrier downstream which is located at the end of the main channel governs the flow in the main channel all the weirs and barriers are free submerged the initial water level can be controlled by adjusting the height of the barrier the constant head tank maintains a constant flow rates throughout an experiment water depths are measured with the water level measuring needle slz60 fig 2f the measuring ruler is 30 cm the tip diameter is 0 15 mm the total length of the vernier scale is 9 mm and the accuracy is 0 1 mm the data were collected for 45 s and the result showed in this study is time averaged value 2 1 2 experimental cases four experiments were carried out table 1 we always control the inlet flow rate of the main stream or tributary to change the discharge ratio and momentum ratio the discharge and depth shown here were measured by measuring instrument while the velocity was calculated as discharge area data collected in the experiment are measured water depth at 126 locations distributed over the length and width of the main stream flume as shown in fig 2 c the water level point was measured by needle water level gauge the accuracy of the needle water level gauge is 0 1 mm these were measured with a point gage mounted on a movable carriages each measurement point was measured five times and was averaged to gauge the repeatability and experimental uncertainty the reported value is an average of multiple readings throughout the duration of the experiment the point velocity in the x y and z three directions was measured by acoustic doppler velocimeter adv the measurement points for velocities are also shown in fig 2 c the accuracy of velocity is 0 01 and the sampling rate is 200 hz these data are integrated to create longitudinal profiles at selected transverse locations and as transverse profiles at selected longitudinal locations data locations are reported based on an x y coordinate system where x is increasing along the flow direction of the main stream and y is increasing across the flume the 0 0 origin of coordinate system is the downstream conjunction of the tributary and the main stream flume as illustrated in fig 2 c the primary measurement focus is the 3d separation and mixing region just downstream from the confluence 2 2 numerical modeling 2 2 1 governing equations the reynolds averaged navier stokes equations rans are solved with the openfoam software shen et al 2019 osama and huckaby 2009 the governing equations are 1 u i x i 0 2 u i t u j u i x j p x i x j ν ν t u i x j g where t s is time u i m s is the vector flow velocity of the node of computational grid p pa is pressure g m s2 is gravitational acceleration ν m2 s is the molecular viscosity coefficient and ν t m2 s indicates the eddy viscosity coefficient modeled as 3 ν t c μ k 2 ε where c μ is an empirical parameter the turbulent kinetic energy is k m2 s2 and ε is turbulent dissipation rate 2 2 2 turbulence closure equations the rng k ε model renormalization group k ε turbulence model of yakhot and orszag 1986 was used for the turbulence closure the transport equations for kinetic energy and the dissipation rate are 4 k t u j k x j u i u j u i x j x j k m k σ k x j ε 5 ε t u j ε x j c ε 1 ε k u i u j u i x j x j k m ε σ ε x j c ε 2 ε 2 k r where local definitions are 6 k m ν 1 ν t ν 1 2 2 7 r c μ η 3 1 η η 0 ε 2 1 β η 3 k 8 η k ε u i x j u j x i u i x j 1 2 k m is the time average strain rate r is the non equilibrium strain rate term η is the dimensionless shear rate coefficients c ε 1 and c ε 2 are empirical constants taken as 1 42 and 1 68 shen et al 2019 2021 σ k and σ ε are the turbulent prandtl numbers of k and ε respectively both are taken as 0 7179 and β is an empirical constant taken as 0 012 2 2 3 volume of fluid vof equation vof model was used to capture the free liquid surface this method defines the functions fw x y z t and fa x y z t respectively to represent the volume fraction of water and air in the numerical domain the value and gradient of f can be used to determine the position and normal direction of the air water interface respectively the governing equation of f is 9 f t f u i 0 where t s is time u m s is the average velocity of the compute node 2 2 4 discretization and solving method the governing equations are discretized with a finite volume method in space with a difference scheme for time the convection terms were discretized in the non conservation form combining the discretization method of the central differencing scheme and the upwind scheme the pimple method was used to solve the equations osama and huckaby 2009 which merged the simple and piso in the pimplefoam solver an advantage of this technique is that it is computationally efficient for transient incompressible flow with large time steps shen et al 2021 the smoothsolver algorithm form openfoam is used to solve implicit matrices for velocity k ε and other variables the volume of fluid vof method was utilized to track the free surface park and park 2021 shen et al 2022 2 2 5 boundary conditions and meshes the computational domain conforms with the flume experiment i e the model grid walls and bottom are coincident with the walls and bottom of the flume the inlet boundary conditions of the main stream and tributary are velocity conditions with a neumann zero gradient surface elevation and the outlet boundary condition of the main stream is set as a neumann zero gradient conditions two initial calculations were made to determine the flow at each tributary was fully developed prior to reaching the confluence the surface of the flume is set as atmospheric pressure the initial velocity of tributary and main stream inlet velocities flow rates and areas are shown in to table 1 the initial value of k and ε for the turbulence model as descripted by shen et al 2019 are 10 k in 0 00375 v in 2 11 ε in k in 0 4 h in where v in m s is inlet flow velocity h in m is initial water depth as shown in table 1 the computational mesh for three different tributary widths are shown in fig 3 the model uses 1 793 586 tributary width 0 5 m 1 659 266 tributary width 0 3 m and 1 524 946 tributary width 0 1 m unstructured quadrilateral grid cells generating the meshes for mesh sensitivity analysis was easily performed by the initial implementation of parametric resolution parameters in the mesh which could be changed to generate a finer and a coarser mesh blocken and gualtieri 2012 finer cells were imposed where significant gradients are expected i e on the regions close to the junction and the walls the size of a single cell next to the channel boundary is 20 0 mm 5 0 mm 10 0 mm the size of a single cell in the free stream region is 20 0 mm 20 0 mm 3 0 mm the calculation results of grid convergence index gci are displayed in supplementary materials when the minimum mesh unit size is 0 03 m the gci value is already less than 3 which meet the requirement of calculation accuracy the approach to simulate flows near the solid boundaries is wall function method the standard wall function is as follows 12 u y y 11 63 1 κ ln e y y 11 63 13 u u c μ 1 4 k 1 2 τ w ρ 14 y ρ c μ 1 4 k 1 2 y μ u and y are dimensionless parameters and represent velocity and distance κ is karman constant taken as 0 41 e is the experimental constant taken as 9 81 τ w is wall shear stress k is the turbulent kinetic energy at the computational node μ is the dynamic viscosity of the fluid 2 3 analysis of free surface slope for general flumes the longitudinal free surface slope lfs chanson 2004 refers to the reduction of water surface elevation per unit flow length along the flow direction and the transversal free surface slope tfs is the surface slope perpendicular to the direction of the main stream the tfs is mainly the elevation difference of the same cross section caused by centrifugal inertial force due to the separation zone xu et al 2009 carried out the curve water flow model test and obtained the distribution characteristics of the tfs along the curve water surface the lfs and the tfs are calculated as 15 lfs dz dl 16 tfs dz dw where dz m is the elevation difference of unit width dl m is the unit length and dw m is the unit width a positive lfs or tfs indicate an increasing free surface elevation and a negative lfs or tfs corresponds to a decreasing free surface elevation 2 4 regression model to quantify the impact of discharge ratios and momentum ratios on the water surface characteristics we introduced the parameters db the backwater degree computed as the maximum depth at the confluence zone hmax minus average depth haver divided by average depth the equation is 17 d b h max h aver h aver du the umbilication degree computed as average depth haver minus minimum depth around the confluence hmin divided by average depth the equation is 18 d u h aver h min h aver al the area ratio computed as the ratio the area of the separation zone as to the area of downstream channel ad the as is defined as the area surrounded by the counter line of the mean water level of the cross section at the lowest point of the separation zone the al equation is 19 a l a s a d the above parameters were used to build statistical regression models that predict the db du and al with different discharge ratios λ momentum ratios η and normalized momentum ratios m for the 45 confluence the momentum ratio η and normalized momentum ratio m are introduced in this study to consider the influence of the velocity magnitude of inlet flow on the flow structure and top support characteristics of confluence area they are defined as 20 η ρ q t u t ρ q m u m 21 m ρ q t u t ρ q m u m q t q m q m where ρ kg m3 is the fluid density qt m3 s and qm m3 s are the inlet flow rate of the tributary and main stream ut m s and um m s are the inlet velocity of the tributary and main stream both the water surface characteristics and the size of the flow separation zone for an asymmetrical confluence with a main channel of fixed size joined by a lateral tributary as modeled here should be influenced independently by two factors 1 the total discharge of the incoming flows and 2 the relative momentum fluxes of the incoming flows in most previous literature the ratio of the tributary flow to the mainstream flow or the total flow rate is studied and analyzed but the influence of the magnitude of velocity of inlet flow is not fully considered 3 results and discussion 3 1 validation of the numerical simulations the numerical simulations validate reasonably well against the experimental data for water surface elevation wsd with maximum errors less than 9 of full depth and good agreement of the longitudinal free surface slope fig 4 table 2 the error values between the experiment and simulation varied from 8 9 to 5 3 in addition fig 6 show the wse and free surface slope in the longitudinal direction and transversal direction between the experiments and the simulations to be more precise the quantitative assessment of the validation for the four cases are carried out the key residual criteria of bias mean square error mse root mean square error rmse mean absolute error mae absolute maximum error ame methods introduced by neil et al 2013 and the mean relative error mre are used to validate the velocity in all measurement points which are shown in table 3 the smaller the value absolute value for bias is the closer to the experiment the model is it can be seen that the simulated and experimental values are in good agreement for example the values of the error metrics of mse are 0 00008 0 00002 0 00006 and 0 00066 for case 1a case 2a case 3a and case 5a respectively while the values of mre are 0 027 0 015 0 025 and 0 111 respectively in addition a quantile quantile plot qq plot with confidence intervals is used to check the applicability of the four cases as shown in fig 5 a d the comparison of measured and simulated values of velocity are shown in fig 5e f the qq plot mainly shows the distribution of the data against the expected normal distribution if the data is normally distributed the points fall on the 45 reference line if the data are non normal the points deviate noticeably from the reference line it is used to compare two samples simulation and experiment if the scatter plot is distributed around the line y x then the two samples are similarly distributed it can be seen that it fits best in case 3a the data in case 5a are shown as right skewed data and the data in case 1a and case 2a are shown as left skewed data 3 2 the typical spatial configuration of water surface at the confluence the convergence of the main stream and tributary leads to sudden change of the pressure field at the confluence which results in uneven water surface characteristics at the confluence in this section we generalized the typical spatial configuration of water surface the universal laws at confluence by analyzing experimental data and simulation results 3 2 1 statistical analysis of the experimental data to enhance the universality of the study results we conducted dimensionless y direction analysis b y b where y is the distance across the main stream channel and b is the main stream breadth as shown in fig 6 the water surface along the main stream changes suddenly at the junction indicating that the tributary flow has a extrusion stress effect on the flow of the main channel and an obstruction in the upstream of the main channel the smaller the b the closer the tributary the more complex the water changes fig 7 displays the summary boxplots of measured results obtained from experimental cases through the comparison of cases 1a 2a and 5a it can be observed that with the discharge ratio increases due to the decrease in main stream flow rate resulting in a significant reduction in longitudinal water depth at confluence and a more concentrated longitudinal distribution this reduction in water depth is caused by a decrease in the total flow of the main and tributary this concentrated longitudinal water level distribution indicates that the longitudinal water surface at the confluence becomes smoother as the main stream flow decreases by comparing case 2a and 3a it can be found that an increase of the discharge ratio due to the increase in tributary flow rate leads to a significant expansion of the longitudinal water depth distribution range at the confluence it indicates that an increase of tributary flow while the main stream remains unchanged will result in a more pronounced heterogeneity of the water surface at the confluence from the height of the box we know that for each case the longitudinal axes with the most concentrated distribution are b 0 4 case 1a from 0 290 m to 0 310 m b 0 4 case 2a from 0 235 m to 0 245 m b 0 8 case 3a from 0 245 m to 0 257 m and b 1 0 case 5a from 0 191 m to 0 194 m respectively and the longitudinal axes with the most dispersed distribution are b 0 6 case 1a from 0 287 m to 0 308 m b 0 6 case 2a from 0 232 m to 0 246 m b 0 6 case 3a from 0 241 m to 0 273 m and b 0 8 case 5a from 0 19 m to 0 20 m the results show that the range of elevations along the longitudinal profile is larger when b 0 6 or b 0 8 in all cases comparing the distance between the upper and lower quartiles to the median it can be observed that case5a exhibits the most pronounced unevenness in distribution comparing the position of the median value we find the mean elevation of the four cases present as case 1a case 3a case 2a case 5a 3 2 2 generalized characteristics of water surface at the confluence in fig 8 a g show the simulated water surface under different discharge ratio cases and fig 9 a c show the simulated water surface under different momentum ratio cases the water surface geometry at confluence is characterized by a highly complex 3d flow structure with enhanced flow strength we find two distinct phenomena one is the upstream backwater and the other is the low water depth in the downstream separation zone the low depth phenomena is similar to those observed at the mozigou zumuzu river confluence by shen et al 2016 we named these two regions as backwater zone and umbilication zone focus on the range of water surface elevation displayed by the color labels of contours in different cases by comparing case1a 2a 4a 5a 6a and 7a it is evident that as the discharge ratio increases with constant tributary flow but decreasing main stream flow both upper and lower limits of water surface elevation decrease the cause of this phenomenon is the reduction in flow rate of the main stream resulting in a deceleration of backwater and an increased impact from the tributary on the main stream this leads to a narrower confluence with an enlarged separation zone and depressed water surface by comparing case2aand 3a we found that when the main stream flow rate is the same the case with larger tributary flow has greater upper limit of water surface elevation which indicates that the increase of tributary flow will significantly aggravate the backwater in the upstream of the confluence case3 and case4 have similar flow ratio and momentum ratio but the flow of the main stream and the tributary of case4 is much smaller than that of case3 by comparing fig 8 c and d it can be observed that the water surface elevation distribution of cas3 and cas4 exhibits overall similarity albeit with a consistently lower value for cas4 however when the discharge ratio is 1 the greater the momentum ratio the larger the al fig 9a c here we increase the momentum by reducing the tributary s width this may indicate that the discharge ratio is not the key influencing factor in some cases to compare the influence degree of the different parameters and quantify this effect we further established the regression model in section 3 5 above all the division and definition of the spatial configuration of water surface profile at 45 junction can be proposed and illustrated in fig 10 flow depth within the junction is dominated by five distinct elements i a zone of backwater area near the upstream junction in the main stream bz 1 backwater zone 1 ii a zone of backwater flow area near the upstream junction in the tributary bz 2 backwater zone 2 iii a zone of separated flow below the downstream junction corner sz separation zone iv a zone of extrusion contraction adjacent to sz cz contractile zone v a zone of gradual flow depth recovery downstream from the flow separation zone rz recovery zone among them item 3 and item 5 are almost the same as best 1987 3 3 quantitative analysis of free surface at confluence 3 3 1 longitudinal variation of free surface in different cases in general the change of water depth at the confluence is relatively complex as proposed by gurram et al 1997 the role of discharge ratio bed discordance or concordance density differences and bathymetric in controlling river mixing at confluences were well established see for example boyer et al 2006 mignot etal 2013 ramón et al 2013 here we will further analyze the longitudinal variation of free surface slope as mentioned above water surface characteristics such as backwater extrusion contraction and separation umbilication exist at the confluence which will lead to the instability of longitudinal water surface distribution at the confluence fig 11 shows the wse m and lfs of the longitudinal profiles for case 1a to case 7a starting from the upper reaches of the main stream the longitudinal water surface lines decreases slowly first decreases sharply near the outlet of the tributary and then slowly recovers to a steady state with fluctuations throughout the whole process however in cases of severe backwater case1a case2a and case3a the longitudinal surface line upstream of the tributary outlet will gradually rise to a peak before sharply decreasing at the outlet of the tributary the changes of the lfs between x 0 8 m and x 0 8 m in different cases were highlighted fig 11 due to the separation zone the greatest drop lowest lfs and lift greatest lfs occurred in close proximity to the tributary side the maximum value of lfs 31 occurs at 0 0 for case 3a this point is defined as stagnation point by best 1987 larger discharge ratio and momentum ratio leads to larger free surface slope which is also associated with more severe oscillation of depth and more intricate fluctuation pattern of the free surface in fig 8d i show the distribution of wse and wse m and lfs of the longitudinal profiles for case 6a case 6b and case 6c the effect of momentum ratio from 1 0 to 1 667 to 5 0 at a discharge ratio of 1 0 is illustrated in fig 7a c it can be seen that when the discharge ratio is 1 the greater the momentum ratio the greater the local lfs of the confluence 3 3 2 transversal free surface characteristics in different cases in fig 12 shows the variation of wse and transverse free surface slope tfs on the typical cross sections x 2 2 m x 0 m x 1 0 m x 1 8 m x 2 8 m and x 6 2 m of the nine cases as noted by chanson 2004 the uniform equilibrium open channel flows are commonly called uniform flows and the depth corresponding to uniform flow in a particular channel is called the uniform flow depth by observing the cross section of x 6 2 m it can be noted that the wse are almost equal and tfs changes within a very small range from 1 to 1 5 which indicates that the water depths are uniform flow depths and the flows are uniform flows the lowest mean depth in the cross sections are obtained at x 2 2 m case 7a x 0 m case 7a x 1 0 m case 6c x 1 8 m case 6c x 2 8 m case 6c and x 6 2 m case 6c respectively the biggest difference of transverse slope in the cross sections are obtained at x 2 2 m case 1a x 0 m case 1a x 1 0 m case 6c x 1 8 m case 6c x 2 8 m case 6c and x 6 2 m case 6c respectively the average water depth of each cross section gradually declines with increasing distance from the confluence as shown in fig 12b c due to the lateral extrusion effect of the tributary the water depth is lower on the right the tributary side and higher on the left the opposite side of the tributary at junction area x 0 m and x 1 0 m as the momentum ratio increases the location with the smallest mean depth shifts towards downstream indicating greater extrusion effect of the tributary flow on the main stream the smallest depth is found downstream of the confluence near the tributary side x 0 m y 0 15 m where the separation zone is gradually formed which is consistent with the conclusion that the water depth in the separation zone is smaller than other zones behrangi et al 2005 mohammadiun et al 2015 schindfessel et al 2015 yoshimura et al 2015 creëlle et al 2017 the value of tfs is capable of depicting the lateral fluctuations of water surface we conclude that the positions of the maximum and minimum values of tfs in each case and lateral sections are different fig 12 as shown in fig 12a and c the most drastic change occurred in the section x 2 2 m and x 1 0 m the former maybe caused by the shear stress increases with the velocity so the largest is case 1a with 1 786 m s produced by the side wall of the flume main stream while the latter is caused by the extrusion effect of the tributary the largest momentum ratio is case 6c and its tfs changes the most note that the wse of case 6c appeared lower right and higher left phenomenon at x 1 8 m and x 2 8 m this could be indicated that when the momentum ratio is large enough the situation of higher wse on the tributary side and lower wse on the opposite bank may occur it can also be found in fig 8c there is a small backwater area downstream of the separation zone it may be that when the flow velocity of the tributary is large enough the transverse velocity has a secondary extrusion effect on the main stream due to the rebound of the opposite bank 3 4 development of statistic regression model 3 4 1 regression model for backwater degree and umbilication degree in previous studies the ratio of tributary flow to main stream flow or total flow was used as the discharge ratio to analyze the confluence flow and the influence of inlet velocity on the confluence flow was not fully considered ramamurthy et al 1988 hager 1989 hsu et al 1998a mignot et al 2013 the flow structure at a confluence is driven by the inflow characteristics of the main stream and tributary in concert with the geometry of their connection in the present study we not only explored 45 confluence with different flow ratios cases 1a through 6a but also explored confluence cases with different momentum ratios by changing the width of the tributary cases 6a 6b 6c in this section we aimed at the water surface at the confluence of each case and selected six longitudinal water surface lines to calculate their db and du we then calculated the mean value of each case to represent the overall water surface characteristics the mathematical relationships between water surface indexes db and du and confluence parameters discharge ratio and momentum ratio are discussed in groups the process of regression involves creating a scatter plot of related variables x y analyzing their relationship trend selecting the most appropriate relationship equation determining the equation s coefficient and constant through least squares regression fitting and calculating r2 to assess its accuracy the r2 is calculated as 22 r 2 1 y i y 2 y i y 2 where i represents different dependent variables yi is the value of the dependent variable y is the regression predicted value of the dependent variable and y is the mean value of the dependent variable in fig 13 shows the characteristic values of longitudinal change of water depth with the data provide in table 4 fig 13a and b show the db and du with m when λ 1 we conclude that with increasing m db and du increasing logarithmically and the correlations are greater than 0 9 the resulting regression equations are 23 d b 5 0 869 l n m 9 55 0 7 λ 1 24 d u 6 3855 l n m 0 3648 λ 1 in fig 13c e show the db with λ η and m when λ 1 we conclude that with increasing λ η m db and du decreasing exponentially and the correlations are greater than 0 9 the resulting regression equations are 25 d b 28 173e 0 8 0 6 λ λ 1 26 d b 23 868 e 0 667 η η 1 λ 1 27 d b 25 2 0 7e 0 717m m λ 1 in fig 13f h show the du with λ η and m when λ 1 we conclude that with increasing λ η m db and du increasing polynomial but the correlations are lower than 0 8 from the above analysis it can be found that the change trends of db and du are different in different regions we further performed regression analysis on the data and finally form the regression model presented in fig 14 which shows the db and du with consistent λ η m respectively as shown in fig 14 among the three the highest correlation with db and du is m as follows 28 d b 2 019 m 2 11 082 m 22 926 0 m 5 29 d u 0 5789 m 2 0 9655 m 1 2 0 m 5 3 4 2 regression model for area ratio of low water depth as described in section 3 5 al increase with λ and η fig 7 al only increase with η fig 8 we built a regression model for this as shown in fig 15 it can be seen that among the three parameters λ η and m the highest correlation with al is m as follows 30 a l 0 673 ln m 1 8293 the above regression models for d b du and al can be used to predict the area of low water depth the backwater and umbilication degree near a 45 junction for straight channels but it may be a reasonable approximation for any channel in which the radius of curvature is much larger than the channel width i e where the curvature effects can be expected to be a secondary perturbation of the flow shen et al 2021 4 conclusions the water surface characteristics water depth at a river confluence with 45 junction angle under different discharge ratios and momentum ratios are investigated through laboratory experiments and numerical simulations the relationship between the water surface characteristics and the normalized momentum ratios are constructed via regression analysis based on the characteristics of the depth profile we conclude that the water surface at the confluence presents significant 3d features the main findings of this study are as follows the distribution of water surface elevation wse at confluences is complex and presents 3d features with large free surface slope in transversal and longitudinal directions with experiment and simulation observations the convergence of the tributary water increases the upstream wse and reduces the wse near the downstream separation zone which influence shelter area for fish survival and reproduction the 3d wse model at confluences is developed and verified by flume experiment data of which maximum relative error presents as 8 9 combining the study simulation cases the wse distribution in the channel is affected by i discharge ratio of the tributary to the main stream ii the total inflows amount of the tributary and the main stream iii the amount of incoming flow rate and iv momentum ratio of the tributary to the main stream the impact of discharge ratio on the water surface at the confluence is mainly manifested in the backwater area while the effect of total flow ratio is mainly reflected in the overall water level within confluence inlet flow velocity and momentum ratio significantly influence both separation and contractile areas water levels a regression model figs 13 and 14 for backwater degree d b and umbilication degree d u with discharge ratio λ momentum ratio η and normalized momentum ratio m are established and compared m can be seen as the parameter with greatest correlation the regression models are d b 2 019 m 2 11 082 m 22 926 0 m 5 d u 0 5789 m 2 0 9655 m 1 2 0 m 5 a regression model fig 15 for area ratio of low water depth in the separation zone al with discharge ratio λ momentum ratio η and normalized momentum ratio m are established and compared m also be seen as the parameter with greatest correlation the regression model is a l 0 673 l n m 1 8293 0 m 5 the understanding of water surface characteristics at confluences is relevant not only for hydro morphodynamics but also for the water environment and ecology it provides a scientific basis for potential hydraulic modifications at confluences to enlarge refuge space of low tdg and suitable hydromechanical habitat zone for fish survival and also for utilizing the flow structure at confluences to improve the river ecosystem as well as for accurately predicting the dissolved oxygen and other water quality indicators at confluences in the future credit authorship contribution statement xia shen conceptualization methodology formal analysis data curation resources writing original draft writing review editing supervision investigation funding acquisition weizheng gao writing review editing liwei cao writing review editing sheng li writing review editing huanjie cai funding acquisition supervision ran li methodology project administration funding acquisition ben r hodges writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china grant no 52109101 the key research and development projects of shaanxi province grant no 2022sf 443 the open fund of the state key laboratory of hydraulics and mountain river engineering sichuan university grant no skhl2212 and the china postdoctoral science foundation grant no 2019m653762 we would like to thank the editor associate editor and all anonymous reviewers for their constructive and insightful comments appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129787 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1740,confluences play a key node role in the river network because they affect flow sediment transport water quality and ecological patterns hydrodynamic features of the confluence hydrodynamic zone are complicated due to their three dimensional 3d flow structure the present research goal is to investigate the effects of discharge ratio and momentum ratio on depths and free surface profiles at a 45 confluence laboratory experiments and numerical simulations were carried out to investigate the water surface characteristics at confluences under different discharge and momentum ratios the spatial variation backwater degree umbilication degree and horizontal and longitudinal free surface slope ratio of the water depth at the confluence were examined in detail the relationship between the water surface characteristics and the normalized momentum ratios m are constructed via regression analysis we conclude that i the water surface characteristics at the confluence can be grouped into the backwater zone separation zone contractile zone and recovery zone ii the momentum ratio has a more appropriate correlation with the area ratio the area of low water depth in the separation zone to the area of downstream channel al than the discharge ratio iii the backwater may be closely related to the amount of incoming flow rate iv the logarithmic regression model between m and area ratio al was established and it is found that al increases as m increases this study provides a broader understanding of controls on spatial gradients of the water depth and provides guidance for the study of mass transport of pollutants at the confluence keywords confluence water surface characteristics water depth turbulent model water surface simulation data availability data will be made available on request 1 introduction the complex fluid hydrodynamics at confluences constantinescu et al 2011 2014 bradbrook et al 2000 2001 affect the local mixing and distribution of water temperature constantinescu et al 2016 sediments biron and lane 2008 szupiany et al 2012 wang et al 2019 ribeiro et al 2012 and pollutants xiao et al 2019 tang et al 2017 that form the background of local water environment yoshimura et al 2015 chen et al 2017 cheng and constantinescu 2018 bahmanpouri et al 2021 indeed the unique characteristics and nutrient distributions of water mixing from two different sources can result in important local fish habitat that is not replicable in either upstream reach or the downstream main river stream ginney 2001 rice et al 2001 czeglédi et al 2016 furthermore confluence physics alter what might be called the hydromechanical habitat as illustrated in fig 1 the depth temperature distributions velocities and total dissolved gas supersaturation tdgs that also affect habitat suitability therefore dam operational management targeting confluence behavior and in stream engineering practices could be used as part of holistic management techniques to maintain and improve confluence hydromechanical habitat but such efforts are stymied by our lack of understanding of the controls on various aspects of the confluence behaviors physical models have been extensively used to understand the flow patterns mosley 1976 cortés et al 2014 shayan et al 2015 kazemi et al 2016 shen et al 2016 2019 patterns of suspended sediment transport huai et al 2019 2020 yang et al 2021 in open channel indeed the roles of the major control factors on the confluence zones have been investigated over three decades using physical confluence models in the laboratory hager 1987 1989 ramamurthy et al 1988 weerakoon et al 2010 best and roy 1991 biron et al 1996 gurram et al 1997 shen et al 2022 numerical models have also been widely used to quantify confluence hydrodynamics bradbrook et al 2000 huang et al 2002 biron et al 2004 sinha et al 2012 lyubimova et al 2014 duguay et al 2022 here we distinguish between attempts to represent confluence effects on two dimensional 2d depth averaged models from the three dimensional 3d models that provide insight into the confluence hydrodynamics the main difficulties in 3d simulation of confluence flow are rapid change water surface and choice of turbulence models yang et al 2021 a variety of methods have been developed to predict changes in water depth from upstream to downstream along a main channel at confluence taylor 1944 ramamurthy et al 1988 shabayek et al 2002 creëlle et al 2017 however almost all of these methods adopt one dimensional 1d hydraulic analysis without regard to the highly turbulent and the 3d distribution of water depth rhoads 2020 the 1d approximations do not fully capture the 3d complexity of confluence hydraulics luo et al 2018 therefore it is necessary to carry out 3d studies to obtain fine depth structure at confluences in addition many scholars have also conducted numerical studies on the water surface of open channel bends there were also some numerical research about water surface in open channel bends seyedashraf and akhtari 2017 studied the free surface flow in a steeply curved open channel with a 30 bend gholami et al 2014 conducted experiment and numerical study on the water surface in a highly bent 90 open channel curve using the volume of fluid vof method depth is recognized as playing a critical role in habitat through fish preferences e g carps and flat finned loaches prefer depths less than 0 4 m wang and yan 2008 and also by the compounding effects of depth on tdgs dissipation qu et al 2011 the depths across a confluence play an important role in both the reoxygenation of dissolved oxygen do in the water and tdgs dissipation li et al 2013 for every 1 m increase in water depth tdgs decreases by 9 6 in relation to the solubility of the gas in the water colt 1984 furthermore it is known that a confluence separation zone has shallower depths than flow constriction zones best 1985 biron et al 1996 weber et al 2001 schindfessel et al 2017 which may combine with turbulent mixing effects on tdgs to provide fish refuge during otherwise unsuitable habitat conditions our overall understanding of confluence hydrodynamics is built on the work of best 1987 who identified six zones including flow deflection flow separation flow stagnation maximum velocity flow recovery and distinct shear layers these categories have been widely adopted to place specific study results into a broader context hager 1989 ramamurthy et al 1994 blanckaert 2009 leite ribeiro et al 2012 zhang et al 2015 yuan et al 2019 lewis et al 2020 prior studies of river confluences generally focus on the analysis of flow structure separation zone and secondary flow with relatively little discussion of depth effects hsu et al 1998a 1998b shumate 1998 sukhodolov and rhoads 2001 weber et al 2001 rice et al 2006 rhoads et al 2009 leite ribeiro et al 2012 ramón et al 2013 2016 trevethan et al 2015 guillén ludeña et al 2016 herrero et al 2018 the confluence hydrodynamics are considered 3d i e they are poorly described by depth averaged or depth integrated equations as illustrated by the experiments of wang et al 2006 for open channel confluences for the separation zone of particular interest is how the separation zone shifts in response to changes in the discharge ratio which is the ratio of tributary discharge to the discharge in the main stem boyer et al 2006 parsons et al 2007 ramón et al 2013 wang et al 2019 liu et al 2023 best and reid 1984 concluded that as the discharge ratio increased the length and width of the separation zone increased while its shape index remained almost constant zhang et al 2013 studied the effects of the discharge ratio on river confluences based on the momentum principle yuan et al 2017 observed a region with low velocity between the shear layer and the region of maximum velocity when the discharge ratio is small but it disappears when the discharge ratio increases the causes of this phenomenon and the rules that it follows require further inquiry the discharge ratio and momentum flux ratio have been identified as key parameters which influences the processes at confluence ramamurthy et al 1988 hager 1989 best 1985 hsu et al 1998a 1998b mignot et al 2013 and provides the principle framework for quantifying confluence effects as used herein above most of the models are informed by detailed campaigns of velocity measurements and observations of flow structure and of morphological change evidence on how the flow structures affect the water surface however is relatively sparse biron et al 2004 the present work remedies this gap with a quantitative focus on spatial distribution of water depths at confluences which provides a companion to prior studies on spatial distribution of tdgs dissipation shen et al 2016 2019 2021 the purpose of this study is to investigate the effects of discharge ratio momentum ratio and the normalized momentum ratio m on depths and free surface profiles at confluences an experimental of open channel flume with a 45 junction angle was conducted along with validated numerical experiments to develop regression models that explain depth behavior at the confluence based on controlling parameters this study contributes to finding a broader understanding of controls on spatial gradients of the water depth with respect to momentum ratio as well as to understanding the flow and pollutants processes that are present in confluences the flume experiment numerical simulations and regression modeling in this paper are organized as follows section 2 provides experimental apparatus and measurement method which in presented in more detail in shen et al 2019 provides a synopsis of the 3d numerical simulation with volume of fluid vof model and provides overview of the regression model section 3 provides an integrated presentation of results and discussion of the experiment numerical simulations and the regression analysis a summary of the findings is presented in section 4 2 materials and methods 2 1 experimental approach 2 1 1 experimental setup channel and instrumentation laboratory experiments were conducted in an open channel flume that consists of two 0 5 m width channels meeting at a 45 angle as illustrated in fig 2 b which was used in experiments of shen et al 2019 the flume is constructed of organic acrylic glass fig 2 a with a bottom slope of 0 1 a 1 mm difference over 10 m the water supply system uses independent supply tanks for the tributary channel and main channel the flow is a single pass through i e without recirculation weirs are used at the upstream entrance to each flume for flow measurement with a triangular weir in the main channel fig 2d e and a rectangular weir on the tributary a barrier downstream which is located at the end of the main channel governs the flow in the main channel all the weirs and barriers are free submerged the initial water level can be controlled by adjusting the height of the barrier the constant head tank maintains a constant flow rates throughout an experiment water depths are measured with the water level measuring needle slz60 fig 2f the measuring ruler is 30 cm the tip diameter is 0 15 mm the total length of the vernier scale is 9 mm and the accuracy is 0 1 mm the data were collected for 45 s and the result showed in this study is time averaged value 2 1 2 experimental cases four experiments were carried out table 1 we always control the inlet flow rate of the main stream or tributary to change the discharge ratio and momentum ratio the discharge and depth shown here were measured by measuring instrument while the velocity was calculated as discharge area data collected in the experiment are measured water depth at 126 locations distributed over the length and width of the main stream flume as shown in fig 2 c the water level point was measured by needle water level gauge the accuracy of the needle water level gauge is 0 1 mm these were measured with a point gage mounted on a movable carriages each measurement point was measured five times and was averaged to gauge the repeatability and experimental uncertainty the reported value is an average of multiple readings throughout the duration of the experiment the point velocity in the x y and z three directions was measured by acoustic doppler velocimeter adv the measurement points for velocities are also shown in fig 2 c the accuracy of velocity is 0 01 and the sampling rate is 200 hz these data are integrated to create longitudinal profiles at selected transverse locations and as transverse profiles at selected longitudinal locations data locations are reported based on an x y coordinate system where x is increasing along the flow direction of the main stream and y is increasing across the flume the 0 0 origin of coordinate system is the downstream conjunction of the tributary and the main stream flume as illustrated in fig 2 c the primary measurement focus is the 3d separation and mixing region just downstream from the confluence 2 2 numerical modeling 2 2 1 governing equations the reynolds averaged navier stokes equations rans are solved with the openfoam software shen et al 2019 osama and huckaby 2009 the governing equations are 1 u i x i 0 2 u i t u j u i x j p x i x j ν ν t u i x j g where t s is time u i m s is the vector flow velocity of the node of computational grid p pa is pressure g m s2 is gravitational acceleration ν m2 s is the molecular viscosity coefficient and ν t m2 s indicates the eddy viscosity coefficient modeled as 3 ν t c μ k 2 ε where c μ is an empirical parameter the turbulent kinetic energy is k m2 s2 and ε is turbulent dissipation rate 2 2 2 turbulence closure equations the rng k ε model renormalization group k ε turbulence model of yakhot and orszag 1986 was used for the turbulence closure the transport equations for kinetic energy and the dissipation rate are 4 k t u j k x j u i u j u i x j x j k m k σ k x j ε 5 ε t u j ε x j c ε 1 ε k u i u j u i x j x j k m ε σ ε x j c ε 2 ε 2 k r where local definitions are 6 k m ν 1 ν t ν 1 2 2 7 r c μ η 3 1 η η 0 ε 2 1 β η 3 k 8 η k ε u i x j u j x i u i x j 1 2 k m is the time average strain rate r is the non equilibrium strain rate term η is the dimensionless shear rate coefficients c ε 1 and c ε 2 are empirical constants taken as 1 42 and 1 68 shen et al 2019 2021 σ k and σ ε are the turbulent prandtl numbers of k and ε respectively both are taken as 0 7179 and β is an empirical constant taken as 0 012 2 2 3 volume of fluid vof equation vof model was used to capture the free liquid surface this method defines the functions fw x y z t and fa x y z t respectively to represent the volume fraction of water and air in the numerical domain the value and gradient of f can be used to determine the position and normal direction of the air water interface respectively the governing equation of f is 9 f t f u i 0 where t s is time u m s is the average velocity of the compute node 2 2 4 discretization and solving method the governing equations are discretized with a finite volume method in space with a difference scheme for time the convection terms were discretized in the non conservation form combining the discretization method of the central differencing scheme and the upwind scheme the pimple method was used to solve the equations osama and huckaby 2009 which merged the simple and piso in the pimplefoam solver an advantage of this technique is that it is computationally efficient for transient incompressible flow with large time steps shen et al 2021 the smoothsolver algorithm form openfoam is used to solve implicit matrices for velocity k ε and other variables the volume of fluid vof method was utilized to track the free surface park and park 2021 shen et al 2022 2 2 5 boundary conditions and meshes the computational domain conforms with the flume experiment i e the model grid walls and bottom are coincident with the walls and bottom of the flume the inlet boundary conditions of the main stream and tributary are velocity conditions with a neumann zero gradient surface elevation and the outlet boundary condition of the main stream is set as a neumann zero gradient conditions two initial calculations were made to determine the flow at each tributary was fully developed prior to reaching the confluence the surface of the flume is set as atmospheric pressure the initial velocity of tributary and main stream inlet velocities flow rates and areas are shown in to table 1 the initial value of k and ε for the turbulence model as descripted by shen et al 2019 are 10 k in 0 00375 v in 2 11 ε in k in 0 4 h in where v in m s is inlet flow velocity h in m is initial water depth as shown in table 1 the computational mesh for three different tributary widths are shown in fig 3 the model uses 1 793 586 tributary width 0 5 m 1 659 266 tributary width 0 3 m and 1 524 946 tributary width 0 1 m unstructured quadrilateral grid cells generating the meshes for mesh sensitivity analysis was easily performed by the initial implementation of parametric resolution parameters in the mesh which could be changed to generate a finer and a coarser mesh blocken and gualtieri 2012 finer cells were imposed where significant gradients are expected i e on the regions close to the junction and the walls the size of a single cell next to the channel boundary is 20 0 mm 5 0 mm 10 0 mm the size of a single cell in the free stream region is 20 0 mm 20 0 mm 3 0 mm the calculation results of grid convergence index gci are displayed in supplementary materials when the minimum mesh unit size is 0 03 m the gci value is already less than 3 which meet the requirement of calculation accuracy the approach to simulate flows near the solid boundaries is wall function method the standard wall function is as follows 12 u y y 11 63 1 κ ln e y y 11 63 13 u u c μ 1 4 k 1 2 τ w ρ 14 y ρ c μ 1 4 k 1 2 y μ u and y are dimensionless parameters and represent velocity and distance κ is karman constant taken as 0 41 e is the experimental constant taken as 9 81 τ w is wall shear stress k is the turbulent kinetic energy at the computational node μ is the dynamic viscosity of the fluid 2 3 analysis of free surface slope for general flumes the longitudinal free surface slope lfs chanson 2004 refers to the reduction of water surface elevation per unit flow length along the flow direction and the transversal free surface slope tfs is the surface slope perpendicular to the direction of the main stream the tfs is mainly the elevation difference of the same cross section caused by centrifugal inertial force due to the separation zone xu et al 2009 carried out the curve water flow model test and obtained the distribution characteristics of the tfs along the curve water surface the lfs and the tfs are calculated as 15 lfs dz dl 16 tfs dz dw where dz m is the elevation difference of unit width dl m is the unit length and dw m is the unit width a positive lfs or tfs indicate an increasing free surface elevation and a negative lfs or tfs corresponds to a decreasing free surface elevation 2 4 regression model to quantify the impact of discharge ratios and momentum ratios on the water surface characteristics we introduced the parameters db the backwater degree computed as the maximum depth at the confluence zone hmax minus average depth haver divided by average depth the equation is 17 d b h max h aver h aver du the umbilication degree computed as average depth haver minus minimum depth around the confluence hmin divided by average depth the equation is 18 d u h aver h min h aver al the area ratio computed as the ratio the area of the separation zone as to the area of downstream channel ad the as is defined as the area surrounded by the counter line of the mean water level of the cross section at the lowest point of the separation zone the al equation is 19 a l a s a d the above parameters were used to build statistical regression models that predict the db du and al with different discharge ratios λ momentum ratios η and normalized momentum ratios m for the 45 confluence the momentum ratio η and normalized momentum ratio m are introduced in this study to consider the influence of the velocity magnitude of inlet flow on the flow structure and top support characteristics of confluence area they are defined as 20 η ρ q t u t ρ q m u m 21 m ρ q t u t ρ q m u m q t q m q m where ρ kg m3 is the fluid density qt m3 s and qm m3 s are the inlet flow rate of the tributary and main stream ut m s and um m s are the inlet velocity of the tributary and main stream both the water surface characteristics and the size of the flow separation zone for an asymmetrical confluence with a main channel of fixed size joined by a lateral tributary as modeled here should be influenced independently by two factors 1 the total discharge of the incoming flows and 2 the relative momentum fluxes of the incoming flows in most previous literature the ratio of the tributary flow to the mainstream flow or the total flow rate is studied and analyzed but the influence of the magnitude of velocity of inlet flow is not fully considered 3 results and discussion 3 1 validation of the numerical simulations the numerical simulations validate reasonably well against the experimental data for water surface elevation wsd with maximum errors less than 9 of full depth and good agreement of the longitudinal free surface slope fig 4 table 2 the error values between the experiment and simulation varied from 8 9 to 5 3 in addition fig 6 show the wse and free surface slope in the longitudinal direction and transversal direction between the experiments and the simulations to be more precise the quantitative assessment of the validation for the four cases are carried out the key residual criteria of bias mean square error mse root mean square error rmse mean absolute error mae absolute maximum error ame methods introduced by neil et al 2013 and the mean relative error mre are used to validate the velocity in all measurement points which are shown in table 3 the smaller the value absolute value for bias is the closer to the experiment the model is it can be seen that the simulated and experimental values are in good agreement for example the values of the error metrics of mse are 0 00008 0 00002 0 00006 and 0 00066 for case 1a case 2a case 3a and case 5a respectively while the values of mre are 0 027 0 015 0 025 and 0 111 respectively in addition a quantile quantile plot qq plot with confidence intervals is used to check the applicability of the four cases as shown in fig 5 a d the comparison of measured and simulated values of velocity are shown in fig 5e f the qq plot mainly shows the distribution of the data against the expected normal distribution if the data is normally distributed the points fall on the 45 reference line if the data are non normal the points deviate noticeably from the reference line it is used to compare two samples simulation and experiment if the scatter plot is distributed around the line y x then the two samples are similarly distributed it can be seen that it fits best in case 3a the data in case 5a are shown as right skewed data and the data in case 1a and case 2a are shown as left skewed data 3 2 the typical spatial configuration of water surface at the confluence the convergence of the main stream and tributary leads to sudden change of the pressure field at the confluence which results in uneven water surface characteristics at the confluence in this section we generalized the typical spatial configuration of water surface the universal laws at confluence by analyzing experimental data and simulation results 3 2 1 statistical analysis of the experimental data to enhance the universality of the study results we conducted dimensionless y direction analysis b y b where y is the distance across the main stream channel and b is the main stream breadth as shown in fig 6 the water surface along the main stream changes suddenly at the junction indicating that the tributary flow has a extrusion stress effect on the flow of the main channel and an obstruction in the upstream of the main channel the smaller the b the closer the tributary the more complex the water changes fig 7 displays the summary boxplots of measured results obtained from experimental cases through the comparison of cases 1a 2a and 5a it can be observed that with the discharge ratio increases due to the decrease in main stream flow rate resulting in a significant reduction in longitudinal water depth at confluence and a more concentrated longitudinal distribution this reduction in water depth is caused by a decrease in the total flow of the main and tributary this concentrated longitudinal water level distribution indicates that the longitudinal water surface at the confluence becomes smoother as the main stream flow decreases by comparing case 2a and 3a it can be found that an increase of the discharge ratio due to the increase in tributary flow rate leads to a significant expansion of the longitudinal water depth distribution range at the confluence it indicates that an increase of tributary flow while the main stream remains unchanged will result in a more pronounced heterogeneity of the water surface at the confluence from the height of the box we know that for each case the longitudinal axes with the most concentrated distribution are b 0 4 case 1a from 0 290 m to 0 310 m b 0 4 case 2a from 0 235 m to 0 245 m b 0 8 case 3a from 0 245 m to 0 257 m and b 1 0 case 5a from 0 191 m to 0 194 m respectively and the longitudinal axes with the most dispersed distribution are b 0 6 case 1a from 0 287 m to 0 308 m b 0 6 case 2a from 0 232 m to 0 246 m b 0 6 case 3a from 0 241 m to 0 273 m and b 0 8 case 5a from 0 19 m to 0 20 m the results show that the range of elevations along the longitudinal profile is larger when b 0 6 or b 0 8 in all cases comparing the distance between the upper and lower quartiles to the median it can be observed that case5a exhibits the most pronounced unevenness in distribution comparing the position of the median value we find the mean elevation of the four cases present as case 1a case 3a case 2a case 5a 3 2 2 generalized characteristics of water surface at the confluence in fig 8 a g show the simulated water surface under different discharge ratio cases and fig 9 a c show the simulated water surface under different momentum ratio cases the water surface geometry at confluence is characterized by a highly complex 3d flow structure with enhanced flow strength we find two distinct phenomena one is the upstream backwater and the other is the low water depth in the downstream separation zone the low depth phenomena is similar to those observed at the mozigou zumuzu river confluence by shen et al 2016 we named these two regions as backwater zone and umbilication zone focus on the range of water surface elevation displayed by the color labels of contours in different cases by comparing case1a 2a 4a 5a 6a and 7a it is evident that as the discharge ratio increases with constant tributary flow but decreasing main stream flow both upper and lower limits of water surface elevation decrease the cause of this phenomenon is the reduction in flow rate of the main stream resulting in a deceleration of backwater and an increased impact from the tributary on the main stream this leads to a narrower confluence with an enlarged separation zone and depressed water surface by comparing case2aand 3a we found that when the main stream flow rate is the same the case with larger tributary flow has greater upper limit of water surface elevation which indicates that the increase of tributary flow will significantly aggravate the backwater in the upstream of the confluence case3 and case4 have similar flow ratio and momentum ratio but the flow of the main stream and the tributary of case4 is much smaller than that of case3 by comparing fig 8 c and d it can be observed that the water surface elevation distribution of cas3 and cas4 exhibits overall similarity albeit with a consistently lower value for cas4 however when the discharge ratio is 1 the greater the momentum ratio the larger the al fig 9a c here we increase the momentum by reducing the tributary s width this may indicate that the discharge ratio is not the key influencing factor in some cases to compare the influence degree of the different parameters and quantify this effect we further established the regression model in section 3 5 above all the division and definition of the spatial configuration of water surface profile at 45 junction can be proposed and illustrated in fig 10 flow depth within the junction is dominated by five distinct elements i a zone of backwater area near the upstream junction in the main stream bz 1 backwater zone 1 ii a zone of backwater flow area near the upstream junction in the tributary bz 2 backwater zone 2 iii a zone of separated flow below the downstream junction corner sz separation zone iv a zone of extrusion contraction adjacent to sz cz contractile zone v a zone of gradual flow depth recovery downstream from the flow separation zone rz recovery zone among them item 3 and item 5 are almost the same as best 1987 3 3 quantitative analysis of free surface at confluence 3 3 1 longitudinal variation of free surface in different cases in general the change of water depth at the confluence is relatively complex as proposed by gurram et al 1997 the role of discharge ratio bed discordance or concordance density differences and bathymetric in controlling river mixing at confluences were well established see for example boyer et al 2006 mignot etal 2013 ramón et al 2013 here we will further analyze the longitudinal variation of free surface slope as mentioned above water surface characteristics such as backwater extrusion contraction and separation umbilication exist at the confluence which will lead to the instability of longitudinal water surface distribution at the confluence fig 11 shows the wse m and lfs of the longitudinal profiles for case 1a to case 7a starting from the upper reaches of the main stream the longitudinal water surface lines decreases slowly first decreases sharply near the outlet of the tributary and then slowly recovers to a steady state with fluctuations throughout the whole process however in cases of severe backwater case1a case2a and case3a the longitudinal surface line upstream of the tributary outlet will gradually rise to a peak before sharply decreasing at the outlet of the tributary the changes of the lfs between x 0 8 m and x 0 8 m in different cases were highlighted fig 11 due to the separation zone the greatest drop lowest lfs and lift greatest lfs occurred in close proximity to the tributary side the maximum value of lfs 31 occurs at 0 0 for case 3a this point is defined as stagnation point by best 1987 larger discharge ratio and momentum ratio leads to larger free surface slope which is also associated with more severe oscillation of depth and more intricate fluctuation pattern of the free surface in fig 8d i show the distribution of wse and wse m and lfs of the longitudinal profiles for case 6a case 6b and case 6c the effect of momentum ratio from 1 0 to 1 667 to 5 0 at a discharge ratio of 1 0 is illustrated in fig 7a c it can be seen that when the discharge ratio is 1 the greater the momentum ratio the greater the local lfs of the confluence 3 3 2 transversal free surface characteristics in different cases in fig 12 shows the variation of wse and transverse free surface slope tfs on the typical cross sections x 2 2 m x 0 m x 1 0 m x 1 8 m x 2 8 m and x 6 2 m of the nine cases as noted by chanson 2004 the uniform equilibrium open channel flows are commonly called uniform flows and the depth corresponding to uniform flow in a particular channel is called the uniform flow depth by observing the cross section of x 6 2 m it can be noted that the wse are almost equal and tfs changes within a very small range from 1 to 1 5 which indicates that the water depths are uniform flow depths and the flows are uniform flows the lowest mean depth in the cross sections are obtained at x 2 2 m case 7a x 0 m case 7a x 1 0 m case 6c x 1 8 m case 6c x 2 8 m case 6c and x 6 2 m case 6c respectively the biggest difference of transverse slope in the cross sections are obtained at x 2 2 m case 1a x 0 m case 1a x 1 0 m case 6c x 1 8 m case 6c x 2 8 m case 6c and x 6 2 m case 6c respectively the average water depth of each cross section gradually declines with increasing distance from the confluence as shown in fig 12b c due to the lateral extrusion effect of the tributary the water depth is lower on the right the tributary side and higher on the left the opposite side of the tributary at junction area x 0 m and x 1 0 m as the momentum ratio increases the location with the smallest mean depth shifts towards downstream indicating greater extrusion effect of the tributary flow on the main stream the smallest depth is found downstream of the confluence near the tributary side x 0 m y 0 15 m where the separation zone is gradually formed which is consistent with the conclusion that the water depth in the separation zone is smaller than other zones behrangi et al 2005 mohammadiun et al 2015 schindfessel et al 2015 yoshimura et al 2015 creëlle et al 2017 the value of tfs is capable of depicting the lateral fluctuations of water surface we conclude that the positions of the maximum and minimum values of tfs in each case and lateral sections are different fig 12 as shown in fig 12a and c the most drastic change occurred in the section x 2 2 m and x 1 0 m the former maybe caused by the shear stress increases with the velocity so the largest is case 1a with 1 786 m s produced by the side wall of the flume main stream while the latter is caused by the extrusion effect of the tributary the largest momentum ratio is case 6c and its tfs changes the most note that the wse of case 6c appeared lower right and higher left phenomenon at x 1 8 m and x 2 8 m this could be indicated that when the momentum ratio is large enough the situation of higher wse on the tributary side and lower wse on the opposite bank may occur it can also be found in fig 8c there is a small backwater area downstream of the separation zone it may be that when the flow velocity of the tributary is large enough the transverse velocity has a secondary extrusion effect on the main stream due to the rebound of the opposite bank 3 4 development of statistic regression model 3 4 1 regression model for backwater degree and umbilication degree in previous studies the ratio of tributary flow to main stream flow or total flow was used as the discharge ratio to analyze the confluence flow and the influence of inlet velocity on the confluence flow was not fully considered ramamurthy et al 1988 hager 1989 hsu et al 1998a mignot et al 2013 the flow structure at a confluence is driven by the inflow characteristics of the main stream and tributary in concert with the geometry of their connection in the present study we not only explored 45 confluence with different flow ratios cases 1a through 6a but also explored confluence cases with different momentum ratios by changing the width of the tributary cases 6a 6b 6c in this section we aimed at the water surface at the confluence of each case and selected six longitudinal water surface lines to calculate their db and du we then calculated the mean value of each case to represent the overall water surface characteristics the mathematical relationships between water surface indexes db and du and confluence parameters discharge ratio and momentum ratio are discussed in groups the process of regression involves creating a scatter plot of related variables x y analyzing their relationship trend selecting the most appropriate relationship equation determining the equation s coefficient and constant through least squares regression fitting and calculating r2 to assess its accuracy the r2 is calculated as 22 r 2 1 y i y 2 y i y 2 where i represents different dependent variables yi is the value of the dependent variable y is the regression predicted value of the dependent variable and y is the mean value of the dependent variable in fig 13 shows the characteristic values of longitudinal change of water depth with the data provide in table 4 fig 13a and b show the db and du with m when λ 1 we conclude that with increasing m db and du increasing logarithmically and the correlations are greater than 0 9 the resulting regression equations are 23 d b 5 0 869 l n m 9 55 0 7 λ 1 24 d u 6 3855 l n m 0 3648 λ 1 in fig 13c e show the db with λ η and m when λ 1 we conclude that with increasing λ η m db and du decreasing exponentially and the correlations are greater than 0 9 the resulting regression equations are 25 d b 28 173e 0 8 0 6 λ λ 1 26 d b 23 868 e 0 667 η η 1 λ 1 27 d b 25 2 0 7e 0 717m m λ 1 in fig 13f h show the du with λ η and m when λ 1 we conclude that with increasing λ η m db and du increasing polynomial but the correlations are lower than 0 8 from the above analysis it can be found that the change trends of db and du are different in different regions we further performed regression analysis on the data and finally form the regression model presented in fig 14 which shows the db and du with consistent λ η m respectively as shown in fig 14 among the three the highest correlation with db and du is m as follows 28 d b 2 019 m 2 11 082 m 22 926 0 m 5 29 d u 0 5789 m 2 0 9655 m 1 2 0 m 5 3 4 2 regression model for area ratio of low water depth as described in section 3 5 al increase with λ and η fig 7 al only increase with η fig 8 we built a regression model for this as shown in fig 15 it can be seen that among the three parameters λ η and m the highest correlation with al is m as follows 30 a l 0 673 ln m 1 8293 the above regression models for d b du and al can be used to predict the area of low water depth the backwater and umbilication degree near a 45 junction for straight channels but it may be a reasonable approximation for any channel in which the radius of curvature is much larger than the channel width i e where the curvature effects can be expected to be a secondary perturbation of the flow shen et al 2021 4 conclusions the water surface characteristics water depth at a river confluence with 45 junction angle under different discharge ratios and momentum ratios are investigated through laboratory experiments and numerical simulations the relationship between the water surface characteristics and the normalized momentum ratios are constructed via regression analysis based on the characteristics of the depth profile we conclude that the water surface at the confluence presents significant 3d features the main findings of this study are as follows the distribution of water surface elevation wse at confluences is complex and presents 3d features with large free surface slope in transversal and longitudinal directions with experiment and simulation observations the convergence of the tributary water increases the upstream wse and reduces the wse near the downstream separation zone which influence shelter area for fish survival and reproduction the 3d wse model at confluences is developed and verified by flume experiment data of which maximum relative error presents as 8 9 combining the study simulation cases the wse distribution in the channel is affected by i discharge ratio of the tributary to the main stream ii the total inflows amount of the tributary and the main stream iii the amount of incoming flow rate and iv momentum ratio of the tributary to the main stream the impact of discharge ratio on the water surface at the confluence is mainly manifested in the backwater area while the effect of total flow ratio is mainly reflected in the overall water level within confluence inlet flow velocity and momentum ratio significantly influence both separation and contractile areas water levels a regression model figs 13 and 14 for backwater degree d b and umbilication degree d u with discharge ratio λ momentum ratio η and normalized momentum ratio m are established and compared m can be seen as the parameter with greatest correlation the regression models are d b 2 019 m 2 11 082 m 22 926 0 m 5 d u 0 5789 m 2 0 9655 m 1 2 0 m 5 a regression model fig 15 for area ratio of low water depth in the separation zone al with discharge ratio λ momentum ratio η and normalized momentum ratio m are established and compared m also be seen as the parameter with greatest correlation the regression model is a l 0 673 l n m 1 8293 0 m 5 the understanding of water surface characteristics at confluences is relevant not only for hydro morphodynamics but also for the water environment and ecology it provides a scientific basis for potential hydraulic modifications at confluences to enlarge refuge space of low tdg and suitable hydromechanical habitat zone for fish survival and also for utilizing the flow structure at confluences to improve the river ecosystem as well as for accurately predicting the dissolved oxygen and other water quality indicators at confluences in the future credit authorship contribution statement xia shen conceptualization methodology formal analysis data curation resources writing original draft writing review editing supervision investigation funding acquisition weizheng gao writing review editing liwei cao writing review editing sheng li writing review editing huanjie cai funding acquisition supervision ran li methodology project administration funding acquisition ben r hodges writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china grant no 52109101 the key research and development projects of shaanxi province grant no 2022sf 443 the open fund of the state key laboratory of hydraulics and mountain river engineering sichuan university grant no skhl2212 and the china postdoctoral science foundation grant no 2019m653762 we would like to thank the editor associate editor and all anonymous reviewers for their constructive and insightful comments appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129787 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1741,the techniques and modeling methods of low impact development lid a more decentralized approach that uses or mimics natural processes to mange stormwater has been extensively studied due to their positive impacts on urban flooding and water environment traditional lid modeling has been typically allocated on a plane layout based on rough land use classification and hydrological characterization as the lids cannot be combined in the same space due to modeling restrictions the lid effects on runoff control are often underestimated this paper proposed a vertical lid model construction method based on a refined land use classification and improved hydrological characterization by establishing a flow connection flux in the lid controller calculations the overflows of different lids can be interconnected and transferred for further infiltration storage and conveyance results showed that the refined approach provided more accurate spatial allocation guidance for lids and the obtained catchment outflow was reduced by 25 34 in comparison to conventional land use classification in a case study in northern china the vertical construction method allowed a multi dimensional lid allocation in space and function and achieved a higher control effect on total outflow volume and peak value the combined lids could cope with the rainfall i e no outflow from the lid plots within the 50 year event and the total outflow volume was 13 26 lower than the one from the plane layout method keywords refined hydrological characterization flow connection paths lid modeling water balance vertical spatial planning data availability data will be made available on request 1 introduction influenced by the process of urbanization the paved areas of cities usually increase substantially and the related hydrological conditions change leading to decreased time of concentration and increased peak and volume of surface runoff arnone et al 2018 mahmoud and gan 2018 zang et al 2019 at the same time the associated heat island effect changes the temperature and circulation in cities making extreme weather events more frequent and intense deng et al 2013 huong and pathirana 2013 jung et al 2015 rosenberger et al 2021 in the face of increasing drainage pressure it is challenging to discharge all excess runoff in time by relying solely on the drainage system moreover the drainage has been criticized for being inflexible and environmentally unfriendly given its long service life chocat et al 2007 zhou et al 2019 the cost of drainage renovation and adaptation is also enormous and therefore other types of measures are necessary to complement and assist the existing drainage system fletcher et al 2015 hua et al 2020 zhang et al 2017 low impact development lid measures inspired by the city s original development mode adopt a more sustainable and ecological treatment manner of urban runoff fletcher et al 2015 stahre 2006 lids refer to a number of technologies and practices that can actively promote the retention infiltration and attenuation of urban runoff both at the source and path ji and bai 2021 wang 2013 zhou 2014 internationally there are a number of measures with the similar concepts such as the sustainable urban drainage system suds ferrans et al 2022 zhou 2014 water sensitive urban design wsud ahammed 2017 fletcher et al 2015 and sponge city chan et al 2018 jiang et al 2018 a large number of studies have shown that lids combined with existing drainage can reduce the peak and volume of catchment outflow thus effectively reducing the risk of urban flooding ferrans et al 2022 fu et al 2019 jayasooriya and ng 2014 liu et al 2013 palla and gnecco 2019 cipolla et al 2016 conducted long term hydrological monitoring and modeling of green roofs which was found to have beneficial effects on annual runoff mitigation li et al 2015 simulated and compared the effects of rain gardens with different sizes on runoff and the results showed that the larger the proportion of rain gardens allocated the better the runoff control effects zhou et al 2019 explored the individual role and combination strategies of drainage and lids by considering the trade off between hydrological and economic feasibility the complementary effects between drainage and lids were clearly reported especially when the conditions of drainage renovation were restricted despite the large number of lid studies in literature most of which mainly adopted simulation models and or modeling algorithms for direct case applications ahiablame and shakya 2016 cipolla et al 2016 palla and gnecco 2015 xie et al 2017 few studies have explored the calculation methods and modeling settings of lids to ensure the accuracy and validity of the simulation and evaluation for lid modeling the first thing to be assessed is how to guide and allocate lid layouts based on descriptions of land use conventional urban land use classification was rather rough which usually ignored the difference between similar land use types and their regulating effects on runoff ahiablame et al 2012 zare et al 2012 zhou et al 2022 for example xu et al 2019 studied the runoff characteristics of lawns and shrubs under various types of rainfall and addressed the difference in the resulting runoff coefficients however these two types of land use have been commonly categorized into the same type in the conventional approach which can lead to inaccurate assessment of surface runoff and affect subsequent lid planning in terms of hydrological characterization total impervious area tia is conventionally used to describe the runoff yield of subcatchments but this type of indicator can not accurately reflect the connection path and pattern of impervious area kong et al 2017b roy and shuster 2009 sohn et al 2020 several studies have further suggested distinguishing the land use types and hydrological characteristics in the conventional approach by subdividing the tia into direct impervious areas dcia and other impervious areas the pervious areas pa adjacent to indirect impervious areas icia were set to a buffer zone kong et al 2017a lee et al 2018a lee et al 2012 yao et al 2016 despite the improved classification method of landuse in previous studies the refined hydrological characterization with linkage to lid allocation and the related runoff simulation within the lids have not been explored the simulation of lids at the early stage was very simple by means of directly changing the imperviousness of the subcatchment where the lid was allocated yao et al 2016 zhou et al 2012 this type of method treated the lid as a part of the catchment area and the regulation effect was roughly reflected by reducing the runoff coefficient the problem was that the calculation process ignored the differences in the interception infiltration and regulation functions of different lids soon after mainstream modeling tools simulation software gradually proposed a variety of independent lid modules hu et al 2015 jia et al 2012 kong et al 2017a xie et al 2017 such as rain garden green roof and vegetation swale with these more sophisticated simulation tools lids can be better modeled in terms of type location and extent generally there are two commonly used methods rossman and huber 2016 one is to add one or more lids in a subcatchment by replacing the same amount of catchment area the lid is set as a proportion of the catchment area but its exact layout position and shape cannot be defined the other method is to segment a separate plot for each type of lid i e the lid takes up 100 of the plot so that the layout and position of the lid can be clearly displayed and modeled however no matter which method is used current lid simulation is mainly set in the plane layout without considering the possibility of overlapping areas of different lids at the spatial level the runoff interactions between lids cannot be simulated which affects the accuracy of simulated measures in the actual allocation process a variety of lids are complementary in function and location the multi dimensional spatial layout in many cases needs to be carried out in the same plot and the runoffs between different lids are also interconnected lid outflow at a higher site can be first conveyed to lids at the lower level for infiltration storage and transfer the excess runoff can then be transported to the drainage system liu et al 2015 reported that the simulation of lids only on independent individuals could not accurately reflect the actual layout the lids needed to be simulated in the series mode so that the modeling results were more consistent with the observations similarly by analyzing the effects of single biological retention ponds and their series on runoff regulation gao et al 2019 reported a higher runoff control efficiency of the lid series than the single measure zhang et al 2021 explored the influence of different connection modes of lids on runoff control and found that cascading lid chains multi stage series could reduce runoff more effectively than connecting lids in parallel although previous studies have provided valuable insights there has been a lack of in depth exploration on how to model the detailed connection modes between lids and simulate the complex runoff conveyance and transfer paths sustain has launched an integrated lid simulation tool which can simulate the effect of the multi level combination of lids however the tool can not reflect the detailed spatial layout and runoff path within the lids ferrans et al 2022 lee et al 2012 therefore an accurate and detailed lid model is of great importance to simulate the combined effect of lids in the multi dimensional space this paper carried out refined land use classification and hydrological characterization to provide more accurate guidance for lid allocation at the urban scale on this basis a vertical lid construction method was proposed in order to model the multi dimensional layout of lids at the spatial level an outdoor lid experiment was conducted to examine the reliability of the methodology it is shown that the method enables an overlap of a variety of lids in the same plot and calculates the flow interactions among the measures as well as the changes in runoff and water depths within each lid the method not only took into account the detailed land use type but also provided the tools on how to combine different lid measures in space and function making the modeling of lids e g type proportion location and flow direction more realistic by increasing the simulation paths of lid outflow infiltration and storage the method provides higher accuracy and flexibility for lid allocation and its combination layout optimization 2 methodology 2 1 refined land use classification and hydrologic characterization the simulation accuracy of lid model can be greatly influenced by the degree of subdivision of spatial elements i e land use classification in the subcatchments elliott and trowsdale 2007 lee et al 2018a the conventional classification approach simplifies urban land use into several common types fig 1 a including roofs roads pavements greenbelts and water bodies the associated hydrological characterization is also rough and the options available for runoff routing paths are limited kong et al 2017a lee et al 2018a rossman and huber 2016 the land use is only classified as impervious area ia and pervious area pa rossman 2016 the subarea routing method often adopts the outlet mode that is in each subcatchment the surface runoff in the ia is directly discharged into the drainage network fig 1b as for pa with part of the flow undergoing the infiltration process the remaining is discharged into the pipe directly however there is no runoff interaction transfer between the ia and pa regions the refined approach further subdivides the land use types mentioned above lee et al 2018b for example roofs are subdivided into main buildings and miscellaneous buildings and roads are categorized into driveways sidewalks plazas and parking lots correspondingly the hydrological characterization of the subdivided land use has been refined and includes the directly connected impervious area dcia indirectly connected impervious area icia buffering pervious area bpa and standalone pervious area spa kong et al 2017a lee et al 2018a rossman and huber 2016 fig 2 shows an example on how the classification of land use can directly affect the hydrological characterization conventionally the runoff directions of the two types of roofs are not distinguished and thus both buildings are defined as ias on the other hand the refined approach takes into account the actual flow path and drainage condition the roof in fig 2a cannot collect rainfall and therefore the rain water is firstly discharged to the surrounding green spaces and then the pipe network in this case the roof is categorized into miscellaneous buildings and defined as icia in contrast the roof in fig 2b has an independent rainwater collection system and its runoff directly flows to the pipe network therefore the building is categorized into the main building and defined as dcia more categorizations of the land use can be found in table 1 as for the subarea routing methods i e choice of internal routing between pervious and impervious subareas the refined approach adopts the pervious mode as illustrated in fig 1b runoff in icia is affected by terrain slope and flows preferentially to bpa until bpa is penetrated and saturated the surface runoff is discharged into the adjacent drainage and conveyed away in this way the refined model enables the simulation of runoff transfer and infiltration in some impervious areas fig 3 shows an example on how local hydrological characterizations further affect the selection of subarea routing methods and the percent of runoff routed between the subareas in conventional classification fig 3b the parking area and the driveways are both defined as ias and the outlet mode is selected that is no runoff exchange occurs between ias and pas when the refined classification is adopted fig 3c runoff from parking areas would first flow to adjacent lawns and thus the parking area is defined as icia and the area of driveways is dcia in this case the pervious mode is used and the routed percentage is the ratio of icia area the division and spatial extent of subcatchments are predefined based on e g local topography road network key city infrastructures and lid planning for each subcatchment the reclassified land use is aggregated to estimate the impervious ratio i e imperv calculated as the impervious area to the total area the manning s n for the impervious area n imperv and pervious area n perv is preliminarily set referring to the regional geological condition geographic information and precipitation data and further aggregated by means of the weighted average method at the subcatchment level 2 2 lid controls model the storm water management model swmm developed by u s environmental protection agency provides a lid controls module rossman and huber 2016 to simulate several commonly adopted low impact development practices such as bioretention cells bc green roofs gr permeable pavements pp and rain barrels rb investigated in this study see fig 4 a d swmm simulates these lids through a generalized conceptual model consisting of a series of vertical layers whose properties are defined on a per unit area basis according to the physical characteristic the theoretical model mainly contains five structural layers and one outlet component fig 4e including the surface layer covering vegetation the pavement layer allowing rapid water infiltration the soil layer serving as the growing medium the storage layer storing the infiltrated water from the soil layer the drainage mat layer that used for water discharge and the underdrain outlet used to convey out the water that cannot be contained by the lid device in addition to the underdrain outlet each of the above layers has its independent water balance calculation formula and can be combined for real time simulation the underdrain cannot perform an independent water balance but can choose whether there is a drain or not specifically the bioretention cell has beneficial impacts on water evaporation retention infiltration and purification its structural layers contain surface soil storage layers and an underdrain fig 4a green roof can effectively increase the urban green space by implementing the devices on various types of building roofs its model consists of surface soil and drainage mat layers fig 4b permeable pavement has the function of water infiltration and collection and is composed of surface pavement and storage layers with an underdrain fig 4c the model structure of the rain barrel is relatively simple and is only generalized as a storage layer with an underdrain to convey water out fig 4d during a lid simulation a water balance calculation is conducted to track the water flow between and within each layer thus reflecting the overall input runoff infiltration evaporation and output of the lid device the simulation variables and modeling procedures are illustrated in fig 4e generally the total inflow of the lid model includes the regional rainfall i and external inflow q 0 except for the surface layer the inflow of the other structural layers is the infiltration rate f derived from its upper layer the outflow consists of several parts including the evaporation rate e of each layer the overflow q 1 of the surface layer the overflow q 41 of the storage layer of the rain barrel and the underdrain flow q 4 and q 5 of the storage and drainage mat layers respectively the specific simulation process is as follows first of all the total inflow directly acts on the surface layer and the depression storage begins to form when the infiltration rate of the surface layer decreases the overflow rate q 1 starts to generate when the depth of the depression exceeds the height of the berm the infiltrated water from the surface layer quickly enters through the pavement layer and reaches the soil layer this layer can contain a certain amount of water until it is saturated there are two ways out 1 the flow will continue to infiltrate into the storage layer and eventually reaches the natural soil if the storage layer is not waterproof or be discharged to the drainage network through an underdrain outlet 2 the water is directly conveyed out through the drainage mat layer note that this layer is only equipped for green roof so the flow cannot seep down through the drainage mat layer in addition also note that when modeling the rain barrel the inflow rate is set as the external captured inflow q x as there is no surface layer eqs 1 5 describe the general water balance formulas for each structural layer and table 2 explains the associated variables used in the equations more detailed information such as the specific calculation equations of other related variables such as the evaporation rate e and infiltration rate f can be found in the swmm user manual rossman and huber 2016 in general these water balance formulas describe the changes in water depths over time as a function of the differences between the inflow and the outflow rates 1 s u r f a c e l a y e r ζ 1 h 1 t i q 0 e 1 f 1 q 1 2 p a v e m e n t l a y e r h 2 1 f 2 θ 2 t f 1 e 2 f 2 3 s o i l l a y e r h 3 θ 3 t f 2 e 3 f 3 4 s t o r a g e l a y e r ζ 4 h 4 t f 3 q x e 4 f 4 q 4 q 41 5 d r a i n a g e m a t l a y e r ζ 5 h 5 t f 4 e 5 q 5 to verify the consistency between the theoretical calculations and model simulation this study established a simple swmm model with one catchment where the four types of lid controllers were separately added for parametric modeling and testing the changes in the inflow rate outflow rate and depth in each structural layer as a function of rainfall time series were calculated with the theoretical equations fig 5 shows a comparative estimation of the theoretical calculation results and the swmm outputs using the goodness of fit index r the closer the value is to 1 the higher the degree of consistency all the obtained r values were between 0 91 and 1 0 verifying the reliability of the theoretical calculation note that if the modeled lid does not have a specific type of structural layer it is necessary to skip the corresponding theoretical calculation for the specific layer take bc as an example eqs 2 and 5 are skipped as it does not have the pavement and drainage met layers 2 3 establishing vertical flow connection paths for lid combinations as shown in fig 6 a the existing simulation tools e g swmm adopt the plane mode for lid allocation the total allocated area of lids cannot account for more than 100 of the subcatchment area that is overlapping of lids is not allowed in the same plot and the runoff of different measures cannot be conveyed to each other but directly to the drainage system to solve the restriction the vertical layout method proposed in this paper fig 6b establishes the connecting linkages between different lids based on the theoretical calculation model in this way multiple types of lids can be constructed in a top down and three dimensional manner and the lid inflow and outflow can be transferred in the same plot for the plane layout the detailed flow directions are illustrated in fig 6c the outflows from the four types of measures are directly discharged into the drainage network independently in the vertical layout the direction of lid outflow is firstly influenced by the terrain slope and regional connection path by establishing the connection flux q lid runoff from the upper level of lid can be transferred to lower levels thus providing additional infiltration and retention paths extending flow concentration time and eventually reducing the total outflow of lids take the example in fig 6d rain falling on the green roof is firstly collected by the outlet pipe to the rain barrel for storage when there is insufficient storage space overflow can occur at the top of the barrel or be drained through the barrel outlet according to the flow direction analysis the overflow can be collected through drainage or enter pp at the lower level both pp and bc can receive outflow from nearby lids finally the extra outflow is sent to the drainage network on the basis of the water balance calculation the connection flux q lid namely the total inflow rate from the upper lids is integrated into the total inflow in the surface layer the overflow or outflow from the upper lids transmits to the surface layer of the lower levels meanwhile the external inflow is also taken into account the aggregated inflow then goes through the infiltration storage and drainage calculation processes the water volume and depth changes in and out of different lids can be accurately calculated the specific calculations of q lid and total inflow are shown in eqs 6 8 6 s u r f a c e l a y e r w i t h f l o w p a t h l i n k a g e ζ 1 h 1 t i q 0 q lid e 1 f 1 q 1 7 q lid q i a i a lid 8 q i q 1 q 4 q 5 where the subscript i reflects the type of lids bc gr pp and rb at the upper level q i represents the upper lid outflow a i is the outflow area of the upper lids and a lid is the receiving area of the lower lids q 1 q 4 and q 5 is the overflow of the surface storage and drainage mat layers respectively 3 outdoor lid experiments for method validation an independent experiment on a large outdoor lid experimental device was carried out to examine the reliability of the proposed method a comparison of flow control effects by the individual lids and their combination was performed as shown in fig 7 a the lid experimental device included an artificial rainfall system and a large lid simulation bed to measure the volume of runoff and seepage from various types of lids under different precipitations the rainfall system contained three groups of rainfall nozzles with sizes of small medium and large placed in the upper center of the device with a height of 8 m see fig 7b the simulation system fig 7c included c1 a central controller c2 a solenoid valve c3 pipeline systems and c4 a water tank the central controller was used for setting up the rainfall intensity and duration water supply pressure and controlling the sprinkler nozzles the pipe material was polypropylene with a diameter of dn50 the water tank has a maximum capacity of 6 tons of water and is made of stainless steel the lid simulation bed was composed of 15 individual compartments each with a size of 1 m 1 m a concrete foundation and an i steel truss fig 7d each compartment had two independent outfalls to measure the volume of runoff o1 and volume of seepage o2 during rainfall events plastic tubes were used to convey the outflows to the collection containers see more details in supplementary material sfigure 1 with rainfall inputs different types of lids and their configuration settings can be tested and compared simultaneously all the experiments were taken under sunny weather with low no wind two types of lids namely green roof gr and rain garden rg were investigated their schematic diagrams experiment images and lid controller models are shown in fig 8 specifically the berm height surface slope and soil thickness of green roof were 90 mm 0 2 and 90 mm respectively for rain garden the three parameters were 90 mm 35 and 450 mm an illustration example of the vertical combination of gr and rg and the conceptual model are shown in fig 9 in many cases lids will overlap in the vertical direction due to architectural structures and spatial planning fig 10 shows a comparison of the laboratory measurements swmm modeling results and theoretical calculation proposed in our approach for the two lids and their combination it is shown that the swmm model and theoretical calculation could both simulate the runoff control effects of lids reasonably well more importantly the benefits of the combined lids were clearly shown with largely improved control impacts on the outflow volume and flow generation time taking the measured data for example table 3 the time of flow generation achieved by gr rg was delayed 30 min and the peak outflow was reduced by about 42 in comparison to the individual lids the total volume of outflow was decreased by 55 by considering the mean effects of both lids 4 application results and discussion the case study is located in a city in northern china supplementary material sfigure 2 and within a temperate continental climate zone the annual rainfall is unevenly distributed with an average depth of 398 mm most rainfall concentrates in summer and autumn which account for approximately 80 of the annual volume the topography of the area is high in the northeast and low in the southwest with a total catchment area of approximately 37 ha the primary land use contains residential buildings several large science and technology museums green areas and farmlands two scenarios were tested in the case 1 a comparison of conventional and refined land use classification 2 a comparison of the plane and vertical construction methods based on the refined land use model furthermore six rainfall events i e 3 5 10 20 50 and 100 year events with a duration of 120 min were adopted for the scenario analyses fig 11 shows the detailed classifications of land use and subsequent hydrological characterization using the conventional and refined approaches in the case of conventional classification there were 28 4 greenbelts 22 4 roofs and 49 2 of roads i e 28 4 pa and 71 6 ia whereas for the refined approach each of the main land use types was further divided and there were 19 7 8 7 49 5 and 22 1 of spa bpa dcia and icia respectively in terms of runoff routing the conventional approach assumed that 100 of the surface flow in the area was discharged into the drainage system in contrast in the refined layout it was estimated that 30 9 i e the ratio of icia to ia of the flow in the ia area was first conveyed to and infiltrated by bpa and then discharged into the drainage when the infiltration capacity was exceeded on basis of that the area was divided into a series of subcatchments by taking into account the local topography streets critical infrastructure and pipeline distributions for both approaches the values of the attenuation constant manning coefficient and pipeline loss coefficient were the same the parameters associated with pervious and impervious zone were calculated individually by combining the contributions of all associated land use via the weighted mean method table 4 describes the detailed parameters setting for the two types of approaches in hydrologic characterization fig 12 shows the difference in the catchment outflow of the conventional and refined approaches with the same return period the total overflow volume duration curve i e instantaneous overflow as a function of time and peak value of the refined model were smaller than those of the conventional model this is because that in the refined model the impervious area was divided into dcia and icia in which part of the water belonging to icia infiltrated through the nearby permeable area the refined model thus increased the flow pathways and reduced the total discharge from the catchment however note that as a function of the increasing return period the percentage of decrease of total outflow and peak value decreased from 34 1 to 25 1 and from 37 2 to 34 8 respectively this indicates that the difference in land use and hydrological characterization had a declining effect on runoff response with increasing rainfall the main reason is that under extreme precipitations the infiltration capacity of subcatchments was very limited and there was an increasing amount of rainfall directly transferred to surface runoff therefore the difference caused by the two types of approaches was reduced fig 13 compares the allocations of lids in the plane and vertical layouts specifically the lids accounted for 27 1 of the total area in the plane mode fig 8a among that green roof 9 8 was mainly implemented in the sky gardens on top of the science and technology museums rain barrel was equipped next to the residential buildings and took up little space 0 1 bioretention cell 1 3 was mostly located in the large lawn area permeable pavement accounted for a larger proportion 16 1 of the area as there were many pavements can be implemented in the parking lots sidewalks and squares nevertheless none of the lids can be set overlapping in the model and there was no runoff interaction between the lids the vertical method achieved a multi dimension arrangement of these lids in space several buildings surrounded by lids were arranged with rooftop downspout disconnection treatment a lot of space under green roof was allocated as permeable pavement fig 13b with the spatial rearrangement in the vertical layout the percent routed of the catchment was decreased from 37 4 to 15 2 i e with the plane mode fig 14 shows three examples of vertical allocation for the first case in the plane layout gr rb and pp were allocated in different places and their flows directly went to the network the vertical mode provided the pathways highlighted by red arrows for gr outflow to be transferred to rb and pp in the second case the structures above and below were elevated buildings and squares respectively and surrounded by a large lawn area at the gr location the pp could not be allocated again due to the restrictions in the plane layout in contrast in the vertical layout the gr flow could be conveyed to pp and bc in different flow states there was also a diversion design on the terrain so that the overflow from pp could be transported to bc the third example illustrated a similar case in summary thanks to the vertical construction method the percentage of lid allocation was increased from 27 to 36 among which pp contributed the most the difference between the influence of plane and vertical layouts on catchment runoff is summarized in fig 15 with the same rainfall input the overflow duration curve and its peak value of the vertical layout were both smaller than the ones of the plane layout with a reduction percentage of 12 8 26 3 dito and 17 1 21 6 dip for total overflow volume and peak value respectively note that the dito values increased as a function of increasing rainfall this indicates that the vertical layout could effectively utilize the multiple types of lids to control the surface runoff in smaller rainfall events the combined lids can even achieve zero discharge the main reason was that the vertical layout in this study greatly increased the pp allocation and reduced the generated flow from the impervious areas also the added runoff interactions between the lids increased the flow routing paths and prolonged the runoff concentration time 5 conclusions conventional lid modeling has been associated with problems of inaccurate land use classification and rough hydrologic characterization more importantly there is a lack of modeling method for simulating vertical layout lid measures and their combined impacts on runoff control this paper addressed this gap by proposing a refined vertical lid model construction method which explored the detailed connection modes between lids and established their flow connection paths in the vertical layout thus achieving a multi dimensional lid allocation modeling and assessment the results showed that the refined approach could distinguish the spatial location area and proportion of dcia and icia so as to more accurately reflect the subarea divisions and flow directions and better guide the lid allocation what is more the vertical method increased the flow linkages between lids thus realizing the feasibility of simulating multi dimensional lids in the same plot this is essential especially in existing urban areas as there is very limited space to be utilized for lids and it is necessary to make full use of space so that the runoff can be infiltrated stored and conveyed multiple times to realize an ideal control results showed that the outflow volume and peak value of the vertical method were lower than the plane layout even with high return periods the surface flow could still be well controlled by the multi dimensional lids and a low level of discharge was achieved there were some limitations in this study firstly this study employed independent experiments to validate the proposed approach further work is planned in the case study to conduct a systemic field measurement to better examine the effects of the refined method secondly this paper arranged the lids based on expert opinions and experience optimization algorithms are considered to achieve a more intelligent and robust allocation of lids despite the limitations the method proposed solved the problems of the conventional lid modeling approaches and provided a scientific tool for the modeling of multi dimensional lids in space and function the method can more accurately evaluate the lids ability in runoff control and better guide the allocation simulation and implementation of lids in practical projects credit authorship contribution statement qianqian zhou conceptualization funding acquisition project administration supervision writing review editing junman feng data curation methodology formal analysis validation visualization writing original draft wan en feng investigation writing original draft validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was funded by the youth promotion program of the natural science foundation of guangdong province china grant no 2023a1515030126 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129809 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1741,the techniques and modeling methods of low impact development lid a more decentralized approach that uses or mimics natural processes to mange stormwater has been extensively studied due to their positive impacts on urban flooding and water environment traditional lid modeling has been typically allocated on a plane layout based on rough land use classification and hydrological characterization as the lids cannot be combined in the same space due to modeling restrictions the lid effects on runoff control are often underestimated this paper proposed a vertical lid model construction method based on a refined land use classification and improved hydrological characterization by establishing a flow connection flux in the lid controller calculations the overflows of different lids can be interconnected and transferred for further infiltration storage and conveyance results showed that the refined approach provided more accurate spatial allocation guidance for lids and the obtained catchment outflow was reduced by 25 34 in comparison to conventional land use classification in a case study in northern china the vertical construction method allowed a multi dimensional lid allocation in space and function and achieved a higher control effect on total outflow volume and peak value the combined lids could cope with the rainfall i e no outflow from the lid plots within the 50 year event and the total outflow volume was 13 26 lower than the one from the plane layout method keywords refined hydrological characterization flow connection paths lid modeling water balance vertical spatial planning data availability data will be made available on request 1 introduction influenced by the process of urbanization the paved areas of cities usually increase substantially and the related hydrological conditions change leading to decreased time of concentration and increased peak and volume of surface runoff arnone et al 2018 mahmoud and gan 2018 zang et al 2019 at the same time the associated heat island effect changes the temperature and circulation in cities making extreme weather events more frequent and intense deng et al 2013 huong and pathirana 2013 jung et al 2015 rosenberger et al 2021 in the face of increasing drainage pressure it is challenging to discharge all excess runoff in time by relying solely on the drainage system moreover the drainage has been criticized for being inflexible and environmentally unfriendly given its long service life chocat et al 2007 zhou et al 2019 the cost of drainage renovation and adaptation is also enormous and therefore other types of measures are necessary to complement and assist the existing drainage system fletcher et al 2015 hua et al 2020 zhang et al 2017 low impact development lid measures inspired by the city s original development mode adopt a more sustainable and ecological treatment manner of urban runoff fletcher et al 2015 stahre 2006 lids refer to a number of technologies and practices that can actively promote the retention infiltration and attenuation of urban runoff both at the source and path ji and bai 2021 wang 2013 zhou 2014 internationally there are a number of measures with the similar concepts such as the sustainable urban drainage system suds ferrans et al 2022 zhou 2014 water sensitive urban design wsud ahammed 2017 fletcher et al 2015 and sponge city chan et al 2018 jiang et al 2018 a large number of studies have shown that lids combined with existing drainage can reduce the peak and volume of catchment outflow thus effectively reducing the risk of urban flooding ferrans et al 2022 fu et al 2019 jayasooriya and ng 2014 liu et al 2013 palla and gnecco 2019 cipolla et al 2016 conducted long term hydrological monitoring and modeling of green roofs which was found to have beneficial effects on annual runoff mitigation li et al 2015 simulated and compared the effects of rain gardens with different sizes on runoff and the results showed that the larger the proportion of rain gardens allocated the better the runoff control effects zhou et al 2019 explored the individual role and combination strategies of drainage and lids by considering the trade off between hydrological and economic feasibility the complementary effects between drainage and lids were clearly reported especially when the conditions of drainage renovation were restricted despite the large number of lid studies in literature most of which mainly adopted simulation models and or modeling algorithms for direct case applications ahiablame and shakya 2016 cipolla et al 2016 palla and gnecco 2015 xie et al 2017 few studies have explored the calculation methods and modeling settings of lids to ensure the accuracy and validity of the simulation and evaluation for lid modeling the first thing to be assessed is how to guide and allocate lid layouts based on descriptions of land use conventional urban land use classification was rather rough which usually ignored the difference between similar land use types and their regulating effects on runoff ahiablame et al 2012 zare et al 2012 zhou et al 2022 for example xu et al 2019 studied the runoff characteristics of lawns and shrubs under various types of rainfall and addressed the difference in the resulting runoff coefficients however these two types of land use have been commonly categorized into the same type in the conventional approach which can lead to inaccurate assessment of surface runoff and affect subsequent lid planning in terms of hydrological characterization total impervious area tia is conventionally used to describe the runoff yield of subcatchments but this type of indicator can not accurately reflect the connection path and pattern of impervious area kong et al 2017b roy and shuster 2009 sohn et al 2020 several studies have further suggested distinguishing the land use types and hydrological characteristics in the conventional approach by subdividing the tia into direct impervious areas dcia and other impervious areas the pervious areas pa adjacent to indirect impervious areas icia were set to a buffer zone kong et al 2017a lee et al 2018a lee et al 2012 yao et al 2016 despite the improved classification method of landuse in previous studies the refined hydrological characterization with linkage to lid allocation and the related runoff simulation within the lids have not been explored the simulation of lids at the early stage was very simple by means of directly changing the imperviousness of the subcatchment where the lid was allocated yao et al 2016 zhou et al 2012 this type of method treated the lid as a part of the catchment area and the regulation effect was roughly reflected by reducing the runoff coefficient the problem was that the calculation process ignored the differences in the interception infiltration and regulation functions of different lids soon after mainstream modeling tools simulation software gradually proposed a variety of independent lid modules hu et al 2015 jia et al 2012 kong et al 2017a xie et al 2017 such as rain garden green roof and vegetation swale with these more sophisticated simulation tools lids can be better modeled in terms of type location and extent generally there are two commonly used methods rossman and huber 2016 one is to add one or more lids in a subcatchment by replacing the same amount of catchment area the lid is set as a proportion of the catchment area but its exact layout position and shape cannot be defined the other method is to segment a separate plot for each type of lid i e the lid takes up 100 of the plot so that the layout and position of the lid can be clearly displayed and modeled however no matter which method is used current lid simulation is mainly set in the plane layout without considering the possibility of overlapping areas of different lids at the spatial level the runoff interactions between lids cannot be simulated which affects the accuracy of simulated measures in the actual allocation process a variety of lids are complementary in function and location the multi dimensional spatial layout in many cases needs to be carried out in the same plot and the runoffs between different lids are also interconnected lid outflow at a higher site can be first conveyed to lids at the lower level for infiltration storage and transfer the excess runoff can then be transported to the drainage system liu et al 2015 reported that the simulation of lids only on independent individuals could not accurately reflect the actual layout the lids needed to be simulated in the series mode so that the modeling results were more consistent with the observations similarly by analyzing the effects of single biological retention ponds and their series on runoff regulation gao et al 2019 reported a higher runoff control efficiency of the lid series than the single measure zhang et al 2021 explored the influence of different connection modes of lids on runoff control and found that cascading lid chains multi stage series could reduce runoff more effectively than connecting lids in parallel although previous studies have provided valuable insights there has been a lack of in depth exploration on how to model the detailed connection modes between lids and simulate the complex runoff conveyance and transfer paths sustain has launched an integrated lid simulation tool which can simulate the effect of the multi level combination of lids however the tool can not reflect the detailed spatial layout and runoff path within the lids ferrans et al 2022 lee et al 2012 therefore an accurate and detailed lid model is of great importance to simulate the combined effect of lids in the multi dimensional space this paper carried out refined land use classification and hydrological characterization to provide more accurate guidance for lid allocation at the urban scale on this basis a vertical lid construction method was proposed in order to model the multi dimensional layout of lids at the spatial level an outdoor lid experiment was conducted to examine the reliability of the methodology it is shown that the method enables an overlap of a variety of lids in the same plot and calculates the flow interactions among the measures as well as the changes in runoff and water depths within each lid the method not only took into account the detailed land use type but also provided the tools on how to combine different lid measures in space and function making the modeling of lids e g type proportion location and flow direction more realistic by increasing the simulation paths of lid outflow infiltration and storage the method provides higher accuracy and flexibility for lid allocation and its combination layout optimization 2 methodology 2 1 refined land use classification and hydrologic characterization the simulation accuracy of lid model can be greatly influenced by the degree of subdivision of spatial elements i e land use classification in the subcatchments elliott and trowsdale 2007 lee et al 2018a the conventional classification approach simplifies urban land use into several common types fig 1 a including roofs roads pavements greenbelts and water bodies the associated hydrological characterization is also rough and the options available for runoff routing paths are limited kong et al 2017a lee et al 2018a rossman and huber 2016 the land use is only classified as impervious area ia and pervious area pa rossman 2016 the subarea routing method often adopts the outlet mode that is in each subcatchment the surface runoff in the ia is directly discharged into the drainage network fig 1b as for pa with part of the flow undergoing the infiltration process the remaining is discharged into the pipe directly however there is no runoff interaction transfer between the ia and pa regions the refined approach further subdivides the land use types mentioned above lee et al 2018b for example roofs are subdivided into main buildings and miscellaneous buildings and roads are categorized into driveways sidewalks plazas and parking lots correspondingly the hydrological characterization of the subdivided land use has been refined and includes the directly connected impervious area dcia indirectly connected impervious area icia buffering pervious area bpa and standalone pervious area spa kong et al 2017a lee et al 2018a rossman and huber 2016 fig 2 shows an example on how the classification of land use can directly affect the hydrological characterization conventionally the runoff directions of the two types of roofs are not distinguished and thus both buildings are defined as ias on the other hand the refined approach takes into account the actual flow path and drainage condition the roof in fig 2a cannot collect rainfall and therefore the rain water is firstly discharged to the surrounding green spaces and then the pipe network in this case the roof is categorized into miscellaneous buildings and defined as icia in contrast the roof in fig 2b has an independent rainwater collection system and its runoff directly flows to the pipe network therefore the building is categorized into the main building and defined as dcia more categorizations of the land use can be found in table 1 as for the subarea routing methods i e choice of internal routing between pervious and impervious subareas the refined approach adopts the pervious mode as illustrated in fig 1b runoff in icia is affected by terrain slope and flows preferentially to bpa until bpa is penetrated and saturated the surface runoff is discharged into the adjacent drainage and conveyed away in this way the refined model enables the simulation of runoff transfer and infiltration in some impervious areas fig 3 shows an example on how local hydrological characterizations further affect the selection of subarea routing methods and the percent of runoff routed between the subareas in conventional classification fig 3b the parking area and the driveways are both defined as ias and the outlet mode is selected that is no runoff exchange occurs between ias and pas when the refined classification is adopted fig 3c runoff from parking areas would first flow to adjacent lawns and thus the parking area is defined as icia and the area of driveways is dcia in this case the pervious mode is used and the routed percentage is the ratio of icia area the division and spatial extent of subcatchments are predefined based on e g local topography road network key city infrastructures and lid planning for each subcatchment the reclassified land use is aggregated to estimate the impervious ratio i e imperv calculated as the impervious area to the total area the manning s n for the impervious area n imperv and pervious area n perv is preliminarily set referring to the regional geological condition geographic information and precipitation data and further aggregated by means of the weighted average method at the subcatchment level 2 2 lid controls model the storm water management model swmm developed by u s environmental protection agency provides a lid controls module rossman and huber 2016 to simulate several commonly adopted low impact development practices such as bioretention cells bc green roofs gr permeable pavements pp and rain barrels rb investigated in this study see fig 4 a d swmm simulates these lids through a generalized conceptual model consisting of a series of vertical layers whose properties are defined on a per unit area basis according to the physical characteristic the theoretical model mainly contains five structural layers and one outlet component fig 4e including the surface layer covering vegetation the pavement layer allowing rapid water infiltration the soil layer serving as the growing medium the storage layer storing the infiltrated water from the soil layer the drainage mat layer that used for water discharge and the underdrain outlet used to convey out the water that cannot be contained by the lid device in addition to the underdrain outlet each of the above layers has its independent water balance calculation formula and can be combined for real time simulation the underdrain cannot perform an independent water balance but can choose whether there is a drain or not specifically the bioretention cell has beneficial impacts on water evaporation retention infiltration and purification its structural layers contain surface soil storage layers and an underdrain fig 4a green roof can effectively increase the urban green space by implementing the devices on various types of building roofs its model consists of surface soil and drainage mat layers fig 4b permeable pavement has the function of water infiltration and collection and is composed of surface pavement and storage layers with an underdrain fig 4c the model structure of the rain barrel is relatively simple and is only generalized as a storage layer with an underdrain to convey water out fig 4d during a lid simulation a water balance calculation is conducted to track the water flow between and within each layer thus reflecting the overall input runoff infiltration evaporation and output of the lid device the simulation variables and modeling procedures are illustrated in fig 4e generally the total inflow of the lid model includes the regional rainfall i and external inflow q 0 except for the surface layer the inflow of the other structural layers is the infiltration rate f derived from its upper layer the outflow consists of several parts including the evaporation rate e of each layer the overflow q 1 of the surface layer the overflow q 41 of the storage layer of the rain barrel and the underdrain flow q 4 and q 5 of the storage and drainage mat layers respectively the specific simulation process is as follows first of all the total inflow directly acts on the surface layer and the depression storage begins to form when the infiltration rate of the surface layer decreases the overflow rate q 1 starts to generate when the depth of the depression exceeds the height of the berm the infiltrated water from the surface layer quickly enters through the pavement layer and reaches the soil layer this layer can contain a certain amount of water until it is saturated there are two ways out 1 the flow will continue to infiltrate into the storage layer and eventually reaches the natural soil if the storage layer is not waterproof or be discharged to the drainage network through an underdrain outlet 2 the water is directly conveyed out through the drainage mat layer note that this layer is only equipped for green roof so the flow cannot seep down through the drainage mat layer in addition also note that when modeling the rain barrel the inflow rate is set as the external captured inflow q x as there is no surface layer eqs 1 5 describe the general water balance formulas for each structural layer and table 2 explains the associated variables used in the equations more detailed information such as the specific calculation equations of other related variables such as the evaporation rate e and infiltration rate f can be found in the swmm user manual rossman and huber 2016 in general these water balance formulas describe the changes in water depths over time as a function of the differences between the inflow and the outflow rates 1 s u r f a c e l a y e r ζ 1 h 1 t i q 0 e 1 f 1 q 1 2 p a v e m e n t l a y e r h 2 1 f 2 θ 2 t f 1 e 2 f 2 3 s o i l l a y e r h 3 θ 3 t f 2 e 3 f 3 4 s t o r a g e l a y e r ζ 4 h 4 t f 3 q x e 4 f 4 q 4 q 41 5 d r a i n a g e m a t l a y e r ζ 5 h 5 t f 4 e 5 q 5 to verify the consistency between the theoretical calculations and model simulation this study established a simple swmm model with one catchment where the four types of lid controllers were separately added for parametric modeling and testing the changes in the inflow rate outflow rate and depth in each structural layer as a function of rainfall time series were calculated with the theoretical equations fig 5 shows a comparative estimation of the theoretical calculation results and the swmm outputs using the goodness of fit index r the closer the value is to 1 the higher the degree of consistency all the obtained r values were between 0 91 and 1 0 verifying the reliability of the theoretical calculation note that if the modeled lid does not have a specific type of structural layer it is necessary to skip the corresponding theoretical calculation for the specific layer take bc as an example eqs 2 and 5 are skipped as it does not have the pavement and drainage met layers 2 3 establishing vertical flow connection paths for lid combinations as shown in fig 6 a the existing simulation tools e g swmm adopt the plane mode for lid allocation the total allocated area of lids cannot account for more than 100 of the subcatchment area that is overlapping of lids is not allowed in the same plot and the runoff of different measures cannot be conveyed to each other but directly to the drainage system to solve the restriction the vertical layout method proposed in this paper fig 6b establishes the connecting linkages between different lids based on the theoretical calculation model in this way multiple types of lids can be constructed in a top down and three dimensional manner and the lid inflow and outflow can be transferred in the same plot for the plane layout the detailed flow directions are illustrated in fig 6c the outflows from the four types of measures are directly discharged into the drainage network independently in the vertical layout the direction of lid outflow is firstly influenced by the terrain slope and regional connection path by establishing the connection flux q lid runoff from the upper level of lid can be transferred to lower levels thus providing additional infiltration and retention paths extending flow concentration time and eventually reducing the total outflow of lids take the example in fig 6d rain falling on the green roof is firstly collected by the outlet pipe to the rain barrel for storage when there is insufficient storage space overflow can occur at the top of the barrel or be drained through the barrel outlet according to the flow direction analysis the overflow can be collected through drainage or enter pp at the lower level both pp and bc can receive outflow from nearby lids finally the extra outflow is sent to the drainage network on the basis of the water balance calculation the connection flux q lid namely the total inflow rate from the upper lids is integrated into the total inflow in the surface layer the overflow or outflow from the upper lids transmits to the surface layer of the lower levels meanwhile the external inflow is also taken into account the aggregated inflow then goes through the infiltration storage and drainage calculation processes the water volume and depth changes in and out of different lids can be accurately calculated the specific calculations of q lid and total inflow are shown in eqs 6 8 6 s u r f a c e l a y e r w i t h f l o w p a t h l i n k a g e ζ 1 h 1 t i q 0 q lid e 1 f 1 q 1 7 q lid q i a i a lid 8 q i q 1 q 4 q 5 where the subscript i reflects the type of lids bc gr pp and rb at the upper level q i represents the upper lid outflow a i is the outflow area of the upper lids and a lid is the receiving area of the lower lids q 1 q 4 and q 5 is the overflow of the surface storage and drainage mat layers respectively 3 outdoor lid experiments for method validation an independent experiment on a large outdoor lid experimental device was carried out to examine the reliability of the proposed method a comparison of flow control effects by the individual lids and their combination was performed as shown in fig 7 a the lid experimental device included an artificial rainfall system and a large lid simulation bed to measure the volume of runoff and seepage from various types of lids under different precipitations the rainfall system contained three groups of rainfall nozzles with sizes of small medium and large placed in the upper center of the device with a height of 8 m see fig 7b the simulation system fig 7c included c1 a central controller c2 a solenoid valve c3 pipeline systems and c4 a water tank the central controller was used for setting up the rainfall intensity and duration water supply pressure and controlling the sprinkler nozzles the pipe material was polypropylene with a diameter of dn50 the water tank has a maximum capacity of 6 tons of water and is made of stainless steel the lid simulation bed was composed of 15 individual compartments each with a size of 1 m 1 m a concrete foundation and an i steel truss fig 7d each compartment had two independent outfalls to measure the volume of runoff o1 and volume of seepage o2 during rainfall events plastic tubes were used to convey the outflows to the collection containers see more details in supplementary material sfigure 1 with rainfall inputs different types of lids and their configuration settings can be tested and compared simultaneously all the experiments were taken under sunny weather with low no wind two types of lids namely green roof gr and rain garden rg were investigated their schematic diagrams experiment images and lid controller models are shown in fig 8 specifically the berm height surface slope and soil thickness of green roof were 90 mm 0 2 and 90 mm respectively for rain garden the three parameters were 90 mm 35 and 450 mm an illustration example of the vertical combination of gr and rg and the conceptual model are shown in fig 9 in many cases lids will overlap in the vertical direction due to architectural structures and spatial planning fig 10 shows a comparison of the laboratory measurements swmm modeling results and theoretical calculation proposed in our approach for the two lids and their combination it is shown that the swmm model and theoretical calculation could both simulate the runoff control effects of lids reasonably well more importantly the benefits of the combined lids were clearly shown with largely improved control impacts on the outflow volume and flow generation time taking the measured data for example table 3 the time of flow generation achieved by gr rg was delayed 30 min and the peak outflow was reduced by about 42 in comparison to the individual lids the total volume of outflow was decreased by 55 by considering the mean effects of both lids 4 application results and discussion the case study is located in a city in northern china supplementary material sfigure 2 and within a temperate continental climate zone the annual rainfall is unevenly distributed with an average depth of 398 mm most rainfall concentrates in summer and autumn which account for approximately 80 of the annual volume the topography of the area is high in the northeast and low in the southwest with a total catchment area of approximately 37 ha the primary land use contains residential buildings several large science and technology museums green areas and farmlands two scenarios were tested in the case 1 a comparison of conventional and refined land use classification 2 a comparison of the plane and vertical construction methods based on the refined land use model furthermore six rainfall events i e 3 5 10 20 50 and 100 year events with a duration of 120 min were adopted for the scenario analyses fig 11 shows the detailed classifications of land use and subsequent hydrological characterization using the conventional and refined approaches in the case of conventional classification there were 28 4 greenbelts 22 4 roofs and 49 2 of roads i e 28 4 pa and 71 6 ia whereas for the refined approach each of the main land use types was further divided and there were 19 7 8 7 49 5 and 22 1 of spa bpa dcia and icia respectively in terms of runoff routing the conventional approach assumed that 100 of the surface flow in the area was discharged into the drainage system in contrast in the refined layout it was estimated that 30 9 i e the ratio of icia to ia of the flow in the ia area was first conveyed to and infiltrated by bpa and then discharged into the drainage when the infiltration capacity was exceeded on basis of that the area was divided into a series of subcatchments by taking into account the local topography streets critical infrastructure and pipeline distributions for both approaches the values of the attenuation constant manning coefficient and pipeline loss coefficient were the same the parameters associated with pervious and impervious zone were calculated individually by combining the contributions of all associated land use via the weighted mean method table 4 describes the detailed parameters setting for the two types of approaches in hydrologic characterization fig 12 shows the difference in the catchment outflow of the conventional and refined approaches with the same return period the total overflow volume duration curve i e instantaneous overflow as a function of time and peak value of the refined model were smaller than those of the conventional model this is because that in the refined model the impervious area was divided into dcia and icia in which part of the water belonging to icia infiltrated through the nearby permeable area the refined model thus increased the flow pathways and reduced the total discharge from the catchment however note that as a function of the increasing return period the percentage of decrease of total outflow and peak value decreased from 34 1 to 25 1 and from 37 2 to 34 8 respectively this indicates that the difference in land use and hydrological characterization had a declining effect on runoff response with increasing rainfall the main reason is that under extreme precipitations the infiltration capacity of subcatchments was very limited and there was an increasing amount of rainfall directly transferred to surface runoff therefore the difference caused by the two types of approaches was reduced fig 13 compares the allocations of lids in the plane and vertical layouts specifically the lids accounted for 27 1 of the total area in the plane mode fig 8a among that green roof 9 8 was mainly implemented in the sky gardens on top of the science and technology museums rain barrel was equipped next to the residential buildings and took up little space 0 1 bioretention cell 1 3 was mostly located in the large lawn area permeable pavement accounted for a larger proportion 16 1 of the area as there were many pavements can be implemented in the parking lots sidewalks and squares nevertheless none of the lids can be set overlapping in the model and there was no runoff interaction between the lids the vertical method achieved a multi dimension arrangement of these lids in space several buildings surrounded by lids were arranged with rooftop downspout disconnection treatment a lot of space under green roof was allocated as permeable pavement fig 13b with the spatial rearrangement in the vertical layout the percent routed of the catchment was decreased from 37 4 to 15 2 i e with the plane mode fig 14 shows three examples of vertical allocation for the first case in the plane layout gr rb and pp were allocated in different places and their flows directly went to the network the vertical mode provided the pathways highlighted by red arrows for gr outflow to be transferred to rb and pp in the second case the structures above and below were elevated buildings and squares respectively and surrounded by a large lawn area at the gr location the pp could not be allocated again due to the restrictions in the plane layout in contrast in the vertical layout the gr flow could be conveyed to pp and bc in different flow states there was also a diversion design on the terrain so that the overflow from pp could be transported to bc the third example illustrated a similar case in summary thanks to the vertical construction method the percentage of lid allocation was increased from 27 to 36 among which pp contributed the most the difference between the influence of plane and vertical layouts on catchment runoff is summarized in fig 15 with the same rainfall input the overflow duration curve and its peak value of the vertical layout were both smaller than the ones of the plane layout with a reduction percentage of 12 8 26 3 dito and 17 1 21 6 dip for total overflow volume and peak value respectively note that the dito values increased as a function of increasing rainfall this indicates that the vertical layout could effectively utilize the multiple types of lids to control the surface runoff in smaller rainfall events the combined lids can even achieve zero discharge the main reason was that the vertical layout in this study greatly increased the pp allocation and reduced the generated flow from the impervious areas also the added runoff interactions between the lids increased the flow routing paths and prolonged the runoff concentration time 5 conclusions conventional lid modeling has been associated with problems of inaccurate land use classification and rough hydrologic characterization more importantly there is a lack of modeling method for simulating vertical layout lid measures and their combined impacts on runoff control this paper addressed this gap by proposing a refined vertical lid model construction method which explored the detailed connection modes between lids and established their flow connection paths in the vertical layout thus achieving a multi dimensional lid allocation modeling and assessment the results showed that the refined approach could distinguish the spatial location area and proportion of dcia and icia so as to more accurately reflect the subarea divisions and flow directions and better guide the lid allocation what is more the vertical method increased the flow linkages between lids thus realizing the feasibility of simulating multi dimensional lids in the same plot this is essential especially in existing urban areas as there is very limited space to be utilized for lids and it is necessary to make full use of space so that the runoff can be infiltrated stored and conveyed multiple times to realize an ideal control results showed that the outflow volume and peak value of the vertical method were lower than the plane layout even with high return periods the surface flow could still be well controlled by the multi dimensional lids and a low level of discharge was achieved there were some limitations in this study firstly this study employed independent experiments to validate the proposed approach further work is planned in the case study to conduct a systemic field measurement to better examine the effects of the refined method secondly this paper arranged the lids based on expert opinions and experience optimization algorithms are considered to achieve a more intelligent and robust allocation of lids despite the limitations the method proposed solved the problems of the conventional lid modeling approaches and provided a scientific tool for the modeling of multi dimensional lids in space and function the method can more accurately evaluate the lids ability in runoff control and better guide the allocation simulation and implementation of lids in practical projects credit authorship contribution statement qianqian zhou conceptualization funding acquisition project administration supervision writing review editing junman feng data curation methodology formal analysis validation visualization writing original draft wan en feng investigation writing original draft validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was funded by the youth promotion program of the natural science foundation of guangdong province china grant no 2023a1515030126 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129809 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1742,current approaches for calculating propagation time and rate from meteorological to hydrological drought mainly focus on the time series of spi and sri and most of these methods are conducted in time domain e g correlation analysis and frequency domain e g wavelet analysis which are regarded as linear statistic methods inaccuracy could emerge when the complexity and nonlinearity of drought propagation is addressed by such linear methods in light of this problem this research adopts nonlinear dynamic system nds conducted in phase domain which provides a nonlinear and systematic perspective on drought propagation nds may conditionally generate chaos commonly known as butterfly phenomenon which was not covered by previous studies on drought propagation assuming an underlying nds for drought events we demonstrate the nds of drought propagation could generate chaos and the nonlinear information about the propagation from meteorological to hydrological droughts can be detected within such chaotic nds the propagation time of 1 5 months and the propagation rate of 0 686 were found in the pearl river basin in addition the propagation time of 3 7 and 11 months was also found in the wei river basin to prove the broad applicability of our method the results for these two basins are verified by previous studies keywords drought propagation nonlinear dynamic system nds chaos theory phase domain data availability data will be made available on request 1 introduction drought is a major natural disaster that can seriously threaten water security agricultural production and ecological health leading to various socioeconomic impacts huang et al 2017 zhou et al 2020 droughts are commonly divided into four types meteorological hydrological agricultural and socioeconomic drought ding et al 2021 where meteorological drought i e long term precipitation deficit is usually regarded as the fuse of others and notably the relationship between meteorological and hydrological drought i e decrease of river flow and groundwater level arouses the most extensive research interest since hydrological drought is considered as the first receptor of meteorological drought haslinger et al 2014 zhou et al 2021a zhou et al 2021b the propagation time and rate from meteorological to hydrological drought are of major concern as it relates to drought prediction and early warning wang et al 2011 ma et al 2015 for the calculation of propagation time and rate two indices describing meteorological and hydrological drought i e standardized precipitation index spi and standardized runoff index sri are mostly applied spi sri are usually presented in the form of time series and they describe the characteristics of drought at different time scales from 1 month to 24 month barker et al 2016 shukla and wood 2008 based on the time series of spi sri most current analyses of propagation time and rate rely on two methods correlation analysis and wavelet analysis which are conducted in the time domain and the frequency domain respectively sirisha 2017 bittner et al 2021 however both methods are categorized as linear statistical approaches sugihara et al 2012 ye et al 2015b they detect the drought propagation time and rate by comparing the similarity and discrepancy in the time series of spi sri e g peaks valleys and duration such approaches could be effective if the drought propagation is linear to a great extent however zhou et al 2021a found that nonlinear dependence is of great significance in propagation characteristics the nonlinearity in drought propagation implies that the magnitude of a hydrological drought might be nonlinearly amplified or shrunk after being transferred from a meteorological one and the time delay between two types of drought might not be always deterministic therefore linear views would be inadequate to fully address the complexity of drought propagation chang et al 2017 the nonlinearity in drought propagation is derived from fact that drought events usually receive multiple complicated impacts from other hydrological factors and processes with different extents such as antecedent soil moisture snow ice melting operation of reservoirs and even some large scale atmospheric circulations huang et al 2015 ding et al 2021 wu et al 2018 therefore in order to sufficiently consider the nonlinearity in drought propagation it is irrational to exclusively focus on precipitation and runoff processes i e the time series of spi sri instead the analysis of drought propagation should be conducted from a both nonlinear and systematical perspective to this end this research introduces the concept of nonlinear dynamic system nds into drought propagation the concept of nds is explained in phase domain and it assumes that there is a much more integrated and complex system to which drought events belong lombardo et al 2010 where different hydroclimatic activities including meteorological and hydrological droughts are interacting with each other in highly nonlinear manners framed in an nds the propagation time and rate between meteorological and hydrological drought could be analyzed with the consideration of nonlinearity ombadi et al 2021 the assumption of nds in this research signifies several assuming characteristics regarding drought events a framed in an nds the propagation from meteorological to hydrological drought is nonlinearly impacted by other hydroclimatic processes and the temporal behaviors of spi sri could somehow reflect such impacts otherwise the magnitude and duration of hydrological drought would be in proportion to the meteorological one i e the time series of spi and sri are alike b even though exist the potential nonlinear impacts from other hydroclimatic processes are untraceable we have no idea how many of such impacts are within this nds and what are they in other word the underlying nds is unable to be thoroughly depicted and the series of spi sri representing drought events which we only care about are the only thing that can be detected and recorded however the trace of nonlinear information from nds could be reflected in the time series of spi sri c the time series of spi sri can be regarded as two one dimensional projections from the nds in the time domain nowack et al 2020 deyle et al 2011 and the underlying nds controls the temporal behaviors of spi sri as well as the nonlinear propagation between them by injecting nonlinear information into the time series of spi sri like an iceberg the time series of spi sri are the only thing above the surface and a complex nds beneath the surface conceals abundant nonlinear information about drought propagation therefore the core of this research is to restore the nonlinear information about drought propagation concealed in the underlying nds of meteorological and hydrological droughts where the propagation time and rate between them could be detected only with the time series of spi sri nds can be described by deterministic differential equations demonstrating complex interactions among internal variables e g lorenz model in the following section fig 1 deterministic though the nonlinearity in the nds could conditionally generate some seeming disorder behaviors i e chaos the famous butterfly effect kędra 2014 di et al 2019 nds indicates that chaos is essentially an extreme nonlinearity and when the underlying nds is chaotic its internal variables would have seeming random in time series however common nonlinear analysis approaches like mutual information fang et al 2018 2020 quilty et al 2016 fail to describe the chaos and even worse they would misinterpret chaos as stochastic i e the time series of internal variables are overwhelmed by random noise whereas the chaos actually generates from a deterministic nds and is fundamentally different from stochastic text s1 within an nds we can clearly see how chaos generates from extreme nonlinearity and such exclusive interpretation about chaos is an advantage of nds compared with other nonlinear approaches for drought propagation the existence of chaos has been proven in precipitation and runoff labat et al 2016 sivakumar 2000 which would also play an important role in drought propagation yet failed to be considered in previous researches therefore we found it necessary to provide the analysis perspective from nds for the issue of drought propagation in general this research assumes that there is an underlying nds that controls the nonlinearity in the propagation from meteorological to hydrological drought and conceals the nonlinear information about their propagation time and rate which is reflected in the time series of spi sri based on this assumption the drought propagation from meteorological to hydrological drought in pearl river basin prb will be investigated in this research in the following sections we will restore the underlying nds from the time series of spi sri assess the nonlinear chaos characteristics of this nds and extract the nonlinear information about drought propagation time and rate from such a chaotic nds as a supplementary perspective for the linear approaches which inadequately address the complexity of drought propagation this research embraces a both nonlinear and systematical perspective on drought propagation with nds in phase domain besides although chaos is recognized in precipitation and runoff processes it has been rarely considered in drought propagation therefore nds could also provide a new perspective for common nonlinear views in drought propagation 2 materials and methods in this section the underlying nds of the time series of spi sri is restored and illustrated in phase domain by phase space reconstruction psr and then two methods correlation dimensions cd and largest lyapunov exponent lle are applied to describe the underlying nds and assess its chaotic behaviors based on which convergent cross mapping ccm is applied to detect the nonlinear information about the propagation time and rate between two droughts 2 1 drought indices compared with the original time series of precipitation and runoff spi and sri are commonly applied in drought propagation research given their good performances in characterizing meteorological and hydrological droughts they can numerically quantify drought severity at different time scales the calculations of spi and sri are the same which include three steps zhou et al 2021b 1 the cumulative precipitation runoff series of a specific time scale from one month to twelve months 2 these long term records are fitted into a probability distribution which is used to estimate the cumulative probability of time series values 3 the spi sri value is calculated by converting the cumulative probability to a standard normal distribution see text s3 for details zhou et al 2021b conducted systematic analysis with solid results for drought propagation time and rate in pearl river basin prb in china 21 31 26 49 n 102 14 115 53 e therefore this study also takes the prb as the study area with the purpose of comparison with previous findings to verify our findings using the monthly precipitation and runoff data with the spatial resolution of 0 1 during 1981 2020 which are from the era5 land global reanalysis dataset spi and sri in the prb are calculated at different time scales from 1 month to 12 month 2 2 nonlinear dynamic system nds this research resorts to lorenz model 1963 fig 1 to illustrate nds chaos and phase domain in this three dimensional model x y and z could represent any real world hydrometeorological variables including but not limited to precipitation runoff and evaporation within this model the change of one variable with time is contributed by other variables in a nonlinear manner denoted by ordinary differential equations as shown in fig 1 the value of each point in this model which is commonly referred to as a phase is jointly contributed by the three coordinates within this phase domain with time marching a point which is arbitrarily given an initial phase mt1 f xt1 yt1 zt1 will be moving according to the equations given long enough time the trajectory of this point will form a non integer dimensional butterfly shape manifold this butterfly is referred as an attractor for any given initial condition constrained in this system the position of the point i e phase will be eventually and determinately attracted to this butterfly given long enough period it is worth noting that 1 attractor is the final form of nds and they are equivalent to some extent so hereafter we only focus on the characteristics of attractor 2 the magnitude of chaos is determined by the dimension of attractor of nds i e how weird an attractor is and analysis methods of chaos theory could be adopted to calculate that dimension and 3 in reality however it is unable to observe any butterflies of nds but only those one dimensional time series like spi sri based on the concept of nds we could also assume an nds with time series of spi sri being its internal variables e g x spi y sri the nonlinear information about the propagation from meteorological to hydrological drought i e spi sri is derived from such nds therefore a method which could restore the underlying nds and its internal nonlinear information merely from time series of spi sri is the first step see text s2 for more detailed explanations about time series of spi sri drought events and their relationships with nds 2 2 1 phase space reconstruction psr as mentioned above phase space reconstruction psr is the method for restoring the underlying nds merely from time series kadir et al 2020 adenan et al 2017 shu et al 2021 fig 2 takens 2006 proposed a theorem proving that a topologically equivalent and one one mapping approximation of the phase space of the original nds and related attractor could be reconstructed from a one dimensional time series referred as shadow attractor such shadow attractor inherits abundant nonlinear information from the original one again take the butterfly in lorenz model 1963 to illustrate for each point m t from the original attractor m three time series each contributes a value from its own dimension m t φ x t y t z t focusing on one single dimension e g x t a shadow attractor mx can be reconstructed simply by creating three copies of x t each of which has a time lag by τ compared to the former one mx t φ x t x t τ x t 2τ fig 3 shadow attractors my and mz could be reconstructed in the same way the form of reconstructed attractor is generically a diffeomorphism and preserves essential mathematical properties including nonlinear information of the original system local neighborhoods and their trajectories in mx or my and mz map to that of the original system besides this one one mapping characteristic is not limited between m and mx but also among all shadow attractors fig 4 the performance of psr is decided by the two parameters time delay τ and embedding dimension e according to takens theorem 2006 in order to effectively restore the original system the optimal embedding dimension e should be e 2d 1 where d is the dimension of original system however theoretically embedding dimension smaller than the optimal one could also create some low dimensional approximation of original attractor 2 2 2 correlation dimension cd now that the shadow attractor of underlying nds which preserves important nonlinear information is reconstructed by psr from individual time series some descriptions for such shadow attractor is required to help us better understanding the behavior of underlying nds given that the shadow attractor could be multi dimensional which is difficult to de directly illustrated a quantitative description correlation dimension cd is most commonly used di et al 2019 a cd of a time series indicates the number of dominant variables that control the temporal evolution of the underlying nds in general ndss with infinite cd values are considered to be stochastic note that pure stochasticity is different from chaos see text s3 whereas the ones with finite non integer cd values are considered to be chaotic furthermore the value of cd is directly proportional to the level of complexity in the system that is the systems with high cds are more complex while those with low cds are simpler and exhibit low dimensional deterministic behaviors di et al 2019 the algorithm of grassberger and procaccia g p algorithm 1983 was mostly used text s4 2 2 3 largest lyapunov exponent lle the lyapunov exponent le is widely applied for estimating chaos of nds given the sensitivity to initial condition in chaos le quantifies the rate of separation between two infinitesimally close trajectories in the phase space di et al 2019 generally the existence of a positive le indicates the presence of chaos in a system whereas a negative one indicates that the system is stable or exhibits periodic behaviors rodriguez iturbe et al 1989 when le is 0 it suggests that the underlying nds is in a quasi stable state in applications the largest lyapunov exponent lle is usually used to identify whether a system exhibits chaotic behaviors wolf et al 1985 rosenstein et al 1993 similar to the computation of cds where the psr is the first step the method proposed by wolf et al 1985 was employed to compute lle text s5 2 2 4 convergent cross mapping ccm cd and lle describe the shadow attractor of individual time series and assess their chaotic characteristics whereas ccm compares two shadow attractors to find nonlinear information about drought propagation time and rate ccm was firstly proposed to detect the causality between two time series variables sugihara et al 2012 runge et al 2019 ombadi et al 2020 imagine two time series and their reconstructed attractors mx and my fig 5 for any given point y t0 in my a time corresponding point x t0 will be found in mx three nearest neighbors of y t0 could be found on my y ty1 y ty2 and y ty3 and their time corresponding points in mx will also be found x ty1 x ty2 and x ty3 this process is called cross mapping when x unidirectionally causes y my must contain some causal information from mx but not vice versa from the perspective of manifold the nearest neighbors in my remain the nearest in mx since x causes y and the nearest neighbors in my were causes by the nearest neighbors in mx whereas the nearest neighbors in mx might not remain as the nearest since this nearest behaviors in mx is not affected by the behaviors of my and the cross mapping does not guarantee the nearest fig 5 b another situation is that x and y are reciprocal causes and effects and cross mapping will guarantee the nearest reciprocally fig 5 c it is worth noting that the direction of cross mapping and that of causal information flow are inverse that is the cross mapping from y to x indicates the causal information flow from x to y figure s1 to avoid confusion the directions e g spi sri hereafter indicate the directions of causal information flow the cross mapping skill ρ is used to evaluate how nearest remains after the cross mapping from one manifold to other and the calculation of ρ is the same as the calculation of pearson correlation coefficient the cross mapping will traverse all time points from two manifolds the longer the time series is i e the larger n is the denser the manifold would be and more accurate the cross mapping would be ρ would be convergent to a certain level with time growing figure s2 between two information flow the higher convergence value indicates a stronger causality and the lower convergence value indicates a weaker figure s3 or none figure s4 causality 3 results and discussion 3 1 psr of spi sri this section demonstrates the behaviors of spi sri in phase space i e the shadow attractors of spi sri as mentioned before a perfect phase space reconstruction requires the optimal selection of embedding dimension e and time delay τ so that the nonlinear information about propagation time and rate could be effectively obtained in our previous study detecting the causality between meteorological and hydrological droughts in the same area shi et al 2022 these two parameters were selected according to a common experience i e e 2 and τ 1 which are commonly applied in many other researches regarding psr in this research we improved the calculation by applying the cao method chen et al 2014 di et al 2019 as an improvement of false nearest point method text s6 and autocorrelation coefficient method text s7 to quantify e and τ respectively for both spi and sri the results of cao method indicate that the optimal embedding dimension e is 5 for most spi and sri time scales except that several spi of short time intervals have the optimal embedding dimension of 6 fig 6 left as for the optimal time delay τ varies from 3 months to 7 months for spi and from 4 months to 7 months for sri both increasing with time scale fig 6 right the effectiveness of a shadow attractor retrieving nonlinear information from its original attractor largely depends on the value of parameter τ a narrow time delay τ would cause information overlap and redundancy in shadow attractor whereas a spread time delay would cause information loss yasmin and sivakumar 2018 we find that the time delay of spi sri12 7 months is larger than that of spi sri1 3 4 months which means that the information contained in spi sri12 are overlapped to some extent compared with that in spi sri 1 and a larger time delay 7 months would make sure the overlap be stretched such results imply that in phase space one unit of spi sri 12 contains much more abundant information than that of spi sri 1 also a low dimensional reconstruction could also provide some information here we present some two dimensional reconstructions of some representative spi and sri 1 month 3 month 6 month and 12 month just to give a general impression of shadow attractors high dimensional manifolds are impossible to illustrate as shown in fig 7 visually the trajectories were attracted to a well structured narrow region i e attractor which rotates around the line x t 1 x t indicating the shadow attractor of spi sri was chaotic the left bottom area of the attractor indicates a relatively arid situation whereas the right upper area indicates a relatively moist situation and both situations are stable since x shows no significant disparity in time i e x t 1 x t when x t 1 x t it suggests positive net water input into the underlying nds of spi sri and the x t 1 x t area indicates the underlying nds of spi sri is losing water both situations indicate the attractor is moving 3 2 cd and lle for the shadow attractors of spi sri now that the shadow attractors of spi sri are obtained we use cd and lle to assess their nonlinearity and chaos fig 8 illustrates the results of cd and lle for spi and sri with time scale from 1 month to 12 month cd of spi sri fig 8 left shows that the complexity of the underlying nds to which spi sri are subject to are non integer varying between 1 5 2 5 a system with a 1 5 2 5 complexity implies that the underlying nds of drought events is chaotic moreover it indicates that this underlying nds is 2 or 3 dimensional given different spi sri time scales which means that there could be other variable affecting spi sri other than precipitation and runoff within this nds to our knowledge evaporation could be the third part which plays an important role even though this variable is not directly related to the calculation of spi or sri as for lle fig 8 right spi and sri has similar pattern of lle larger than 0 and varying between 2 5 3 5 which also proves the existence of chaotic behaviors in spi and sri both methods generally depict the chaotic behaviors of drought events providing the precondition of the application of ccm 3 3 convergent cross mapping based on previous discussion about the effect of time delay and the time scale of spi sri on information overlap this research chose to focus on the shadow attractors of spi sri 1 month with the optimal embedding dimension of 5 and time delay of 3 months to make sure that the nonlinear information about propagation time and rate can be extracted efficiently 3 3 1 causal relationship between meteorological and hydrological drought as explained in section 2 2 4 the propagation time and rate can be detected only after the causality between spi and sri is proven figure s6 shows the result of ccm between spi 1 and sri 1 unlike the example situations figure s3 and s4 the cross mapping skill ρ values of both directions i e spi sri and sri spi are both convergent to a high value above 0 90 and the convergence value of sri spi even exceeds that of the other direction which means that the ccm believes that the cause effect relationship between spi and sri is reciprocal the behavior of spi leads to the change of sri and vice versa and the impact from sri on spi is even more obvious than that from the other direction such result is physically impossible since the behavior of precipitation is always the unidirectional cause of runoff and spi sri is expected to converge to a relatively higher value than sri spi sugihara et al 2012 explained that ccm is weak at distinguishing causality of unidirectional but strong coupled relationship i e synchrony wang et al 2019 and could confuse it with true bidirectional causality moreover figure s6 actually shows an instantaneous causality cross mapping is conducted between two time corresponding points between spi and sri fig 9 whereas in reality a driving variable usually acts with some time delay on a response variable e g peak of precipitation peak of flood that is instantaneous ccm also fails to unveil the drought propagation time in this case ye et al 2015a suggested a ccm with time lags fig 10 and this improved ccm on drought propagation could detect the real time lags between driving variables and receptor i e using past a to cross mapping future b and vice versa zhang and wang 2021 and distinguish the real causal direction between spi and sri we conduct ccm with different time lag including positive and inverse time lag and collect the final convergence values for each time lag among which the time lag with largest convergence value indicates the potential time interval for the receptor to response the driving variable figure s7 text s8 simply speaking we can detect the real propagation time from spi to sri by identifying the position of maximum value of cross mapping fig 11 shows the results of ccm with time lag blue line indicates the final convergent cross mapping skill in each time lag of spi sri while red line indicates the other way around according to fig 10 two lines are divided into four zones from i to iv the maximum value of red line sri spi is found in inverse time lag zone iii whereas blue line peaks in positive time lag zone ii zone ii indicates information flow from past to future whereas zone iii indicates the other way around and since the real information can only flow from past to future we believe that the maximum of red line is actually a pseudo one and the maximum of blue line is real this proves that the unidirectional causality from spi to sri i e sri cannot have any causal impacts on spi and the similarity between spi sri and sri spi is merely a synchrony instead of causality ma et al 2017 ma et al 2018 3 3 2 propagation time from meteorological to hydrological drought now focusing on zone ii in fig 11 separated out and shown in fig 12 we know that the maximum value in this zone indicates propagation time instead of peaking at a certain point blue line in zone ii remains highest around 0 96 in the form of a plateau from 1 to 5 months of time lag it is worth noting that this research uses e 5 as the optimal embedding dimension as opposed to our previous work e 2 and we found a defect that the highest values of final convergent cross mapping skill is different from our previous findings shi et al 2022 ma et al 2017 pointed that this is due to the imperfection in the calculation of convergent cross mapping skill in ye et al 2015a b which is effective in low dimensional situation like e 2 but invalid in high dimensional psr like e 5 therefore ma et al 2017 proposed a new cross mapping evaluation score by which we found the correct time lag such result 1 5 months of propagation time corresponds to the previous result of 2 5 months in different seasons zhou et al 2021a zhou et al 2021b we believe that such consecutive time lag is caused by seasonality in drought events the attractor actually contains all possible phases of seasons all year round and different parts of phases could represent different seasons figure s10 the plateau of 1 5 months is a collective behavior of the butterfly which buries the seasonality and given its integrality it is difficult to take this butterfly apart yet it is rational to assume that the propagation time in wet spring summer seasons is short 1 2 months and that in dry seasons autumn winter is long 5 months and such an assumption is supported by xu et al 2019 this is presumably because that the runoff generation time is short and hence the flow travel time is shorter with higher flow rate in wet season than dry season pomeroy et al 2016 in addition we applied the same method to the wei river basin wrb a semi arid and semi humid region in china 103 5 e 110 5 e and 33 5 n 37 5 n to validate our results and assumption as shown in fig 13 we found the actual propagation time of 3 7 and 11 months respectively this result basically corresponds to the conclusions of ma et al 2021 that the propagation time in the wrb were 2 3 8 and 13 months in summer autumn spring and winter respectively 3 3 3 propagation rate from meteorological to hydrological drought propagation rate reflects changes in the frequency duration severity and intensity between meteorological and hydrological droughts zhang et al 2022 we believe that the nonlinear information regarding propagation rate between two droughts could be found in shadow attractors and this research proposed the new thought to find such rate by comparing the similarity between two butterflies zhou et al 2021a compared the magnitudes severity of meteorological and hydrological drought events 2 5 months later to determine the drought propagation rate with the same time lag 2 5 months we analyze the similarity between shadow attractors of those two drought events to reveal the drought propagation rate according to sugihara et al 2012 when the causality between two variables is unidirectional the instantaneous ccm skill of information flow from receptor to driving factor should be fluctuating around zero red line in figure s4 indicating no information flows from receptor to driving factor and the ccm skill of information flow from driving factor to receptor could quantify causal impact however in our case the causality between spi and sri was proven to be a strong coupled synchrony by improved ccm with time lag rather than a true bidirectional causal relationship in the positive time lag zone in fig 11 both blue and red points indicate information flow from a past attractor to a future one 2 5 months later and that guarantees two shadow attractors are linked in a correct temporal logic blue points in zone ii indicate information flow from current spi to sri that in 2 5 months later and are all convergent to above 0 95 whereas the red points in zone iv indicate the causal information flow from the other direction sri spi with the same time lag however red points fluctuate around 0 70 instead of zero due to the existence of synchrony between spi and sri red points i e information flow from sri to spi will remain around a certain value above zero until time lag is large enough and the convergence completely vanishes figure s9 therefore ccm skills sri spi i e information flow from the receptor to the driving factor actually imply the magnitude of synchrony which reflects the sensitivity of hydrological to meteorological drought i e propagation rate whereas ccm skill of spi sri could be pushed into a false high value by synchrony and is not reliable zhou et al 2021b found that under the 2 5 months propagation time the average propagation rate from meteorological to hydrological droughts is 0 686 0 69 0 66 0 77 0 70 and 0 61 in 5 subregions in prb respectively accordingly we extract the final ccm skills of sri spi 2 5 months in zone iv as shown in fig 12 right and find that the average of ccm skills sri spi is 0 6856 consistent with previous result to a great extent 4 conclusions the significance of nonlinearity in most hydrometeorological events including drought propagation are commonly acknowledged and common applied linear approaches cannot fully address the complexity of drought propagation this study innovatively introduced the concept of nds into drought propagation research which provides a both nonlinear and systematical perspective in addition nds could also explain the concept of chaos which is commonly misinterpreted with nds in the phase domain we managed to find and depict the underlying chaotic butterflies of drought events by cd and lle then we adopted ccm to compare the reconstructed shadow attractors and its nonlinear information to unveil the propagation time and rate major findings are summarized as follows 1 despite not exactly shaped as butterfly the shadow attractor does exist in spi sri representing the real attractor of underlying nds to which drought events are subject furthermore the existence of chaotic behaviors of spi sri and the chaos in nds were investigated and proved by cd and lle indicating that chaos is of great significance in drought propagation 2 in prb the propagation time of 1 5 months from meteorological to hydrological drought was detected by ccm which is supported by previous findings for supplementary we adopted the same analysis in wrb and detected the propagation time of 3 7 and 11 months in different seasons respectively such findings also correspond to previous findings 3 the similarity between two shadow attractors of spi and sri manifesting propagation rate of 0 686 from meteorological to hydrological drought was also detected by ccm which is supported by previous finding and proved that ccm is effective in detecting propagation rate in our previous work regarding drought propagation time ccm was also applied to the same study areas i e the prb and wrb basins see shi zhao et al 2022 but the assumption in that study was that the propagation between meteorological and hydrological droughts conforms with a causal relationship and the method ccm was based on the concept of causality detection besides some important parameters was selected simply based on experience instead of precise calculation by contrast in this research the nonlinearity and complexity of drought propagation are analyzed systematically transferring a causality based assumption to an nds based theoretical construct since causality represents only partial nonlinear information concealed in an nds in addition we also tuned important parameters for psr i e τ and e and conducted cd and lle analyses for providing a solid rationale for the application of ccm to detect drought propagation time and rate overall this study introduced a new nonlinear perspective in drought propagation analysis and demonstrated its high potential for a broad range of hydrometeorological research credit authorship contribution statement yiyang zhao conceptualization methodology formal analysis validation writing original draft tingju zhu methodology supervision writing original draft writing review editing funding acquisition zhaoqiang zhou validation hejiang cai validation zhaodan cao validation declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests tingju zhu reports financial support was provided by national natural science foundation of china tingju zhu reports financial support was provided by national key research and development program of china acknowledgments this study was supported by the national key research and development program of china 2020yfa0608603 the national natural science foundation of china 51961125204 and the national key research and development program of china study on simultaneous wet or dry years in the yangtze river and the yellow river under changing environment and water allocation in extreme dry years 2022yfc3202300 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129810 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1742,current approaches for calculating propagation time and rate from meteorological to hydrological drought mainly focus on the time series of spi and sri and most of these methods are conducted in time domain e g correlation analysis and frequency domain e g wavelet analysis which are regarded as linear statistic methods inaccuracy could emerge when the complexity and nonlinearity of drought propagation is addressed by such linear methods in light of this problem this research adopts nonlinear dynamic system nds conducted in phase domain which provides a nonlinear and systematic perspective on drought propagation nds may conditionally generate chaos commonly known as butterfly phenomenon which was not covered by previous studies on drought propagation assuming an underlying nds for drought events we demonstrate the nds of drought propagation could generate chaos and the nonlinear information about the propagation from meteorological to hydrological droughts can be detected within such chaotic nds the propagation time of 1 5 months and the propagation rate of 0 686 were found in the pearl river basin in addition the propagation time of 3 7 and 11 months was also found in the wei river basin to prove the broad applicability of our method the results for these two basins are verified by previous studies keywords drought propagation nonlinear dynamic system nds chaos theory phase domain data availability data will be made available on request 1 introduction drought is a major natural disaster that can seriously threaten water security agricultural production and ecological health leading to various socioeconomic impacts huang et al 2017 zhou et al 2020 droughts are commonly divided into four types meteorological hydrological agricultural and socioeconomic drought ding et al 2021 where meteorological drought i e long term precipitation deficit is usually regarded as the fuse of others and notably the relationship between meteorological and hydrological drought i e decrease of river flow and groundwater level arouses the most extensive research interest since hydrological drought is considered as the first receptor of meteorological drought haslinger et al 2014 zhou et al 2021a zhou et al 2021b the propagation time and rate from meteorological to hydrological drought are of major concern as it relates to drought prediction and early warning wang et al 2011 ma et al 2015 for the calculation of propagation time and rate two indices describing meteorological and hydrological drought i e standardized precipitation index spi and standardized runoff index sri are mostly applied spi sri are usually presented in the form of time series and they describe the characteristics of drought at different time scales from 1 month to 24 month barker et al 2016 shukla and wood 2008 based on the time series of spi sri most current analyses of propagation time and rate rely on two methods correlation analysis and wavelet analysis which are conducted in the time domain and the frequency domain respectively sirisha 2017 bittner et al 2021 however both methods are categorized as linear statistical approaches sugihara et al 2012 ye et al 2015b they detect the drought propagation time and rate by comparing the similarity and discrepancy in the time series of spi sri e g peaks valleys and duration such approaches could be effective if the drought propagation is linear to a great extent however zhou et al 2021a found that nonlinear dependence is of great significance in propagation characteristics the nonlinearity in drought propagation implies that the magnitude of a hydrological drought might be nonlinearly amplified or shrunk after being transferred from a meteorological one and the time delay between two types of drought might not be always deterministic therefore linear views would be inadequate to fully address the complexity of drought propagation chang et al 2017 the nonlinearity in drought propagation is derived from fact that drought events usually receive multiple complicated impacts from other hydrological factors and processes with different extents such as antecedent soil moisture snow ice melting operation of reservoirs and even some large scale atmospheric circulations huang et al 2015 ding et al 2021 wu et al 2018 therefore in order to sufficiently consider the nonlinearity in drought propagation it is irrational to exclusively focus on precipitation and runoff processes i e the time series of spi sri instead the analysis of drought propagation should be conducted from a both nonlinear and systematical perspective to this end this research introduces the concept of nonlinear dynamic system nds into drought propagation the concept of nds is explained in phase domain and it assumes that there is a much more integrated and complex system to which drought events belong lombardo et al 2010 where different hydroclimatic activities including meteorological and hydrological droughts are interacting with each other in highly nonlinear manners framed in an nds the propagation time and rate between meteorological and hydrological drought could be analyzed with the consideration of nonlinearity ombadi et al 2021 the assumption of nds in this research signifies several assuming characteristics regarding drought events a framed in an nds the propagation from meteorological to hydrological drought is nonlinearly impacted by other hydroclimatic processes and the temporal behaviors of spi sri could somehow reflect such impacts otherwise the magnitude and duration of hydrological drought would be in proportion to the meteorological one i e the time series of spi and sri are alike b even though exist the potential nonlinear impacts from other hydroclimatic processes are untraceable we have no idea how many of such impacts are within this nds and what are they in other word the underlying nds is unable to be thoroughly depicted and the series of spi sri representing drought events which we only care about are the only thing that can be detected and recorded however the trace of nonlinear information from nds could be reflected in the time series of spi sri c the time series of spi sri can be regarded as two one dimensional projections from the nds in the time domain nowack et al 2020 deyle et al 2011 and the underlying nds controls the temporal behaviors of spi sri as well as the nonlinear propagation between them by injecting nonlinear information into the time series of spi sri like an iceberg the time series of spi sri are the only thing above the surface and a complex nds beneath the surface conceals abundant nonlinear information about drought propagation therefore the core of this research is to restore the nonlinear information about drought propagation concealed in the underlying nds of meteorological and hydrological droughts where the propagation time and rate between them could be detected only with the time series of spi sri nds can be described by deterministic differential equations demonstrating complex interactions among internal variables e g lorenz model in the following section fig 1 deterministic though the nonlinearity in the nds could conditionally generate some seeming disorder behaviors i e chaos the famous butterfly effect kędra 2014 di et al 2019 nds indicates that chaos is essentially an extreme nonlinearity and when the underlying nds is chaotic its internal variables would have seeming random in time series however common nonlinear analysis approaches like mutual information fang et al 2018 2020 quilty et al 2016 fail to describe the chaos and even worse they would misinterpret chaos as stochastic i e the time series of internal variables are overwhelmed by random noise whereas the chaos actually generates from a deterministic nds and is fundamentally different from stochastic text s1 within an nds we can clearly see how chaos generates from extreme nonlinearity and such exclusive interpretation about chaos is an advantage of nds compared with other nonlinear approaches for drought propagation the existence of chaos has been proven in precipitation and runoff labat et al 2016 sivakumar 2000 which would also play an important role in drought propagation yet failed to be considered in previous researches therefore we found it necessary to provide the analysis perspective from nds for the issue of drought propagation in general this research assumes that there is an underlying nds that controls the nonlinearity in the propagation from meteorological to hydrological drought and conceals the nonlinear information about their propagation time and rate which is reflected in the time series of spi sri based on this assumption the drought propagation from meteorological to hydrological drought in pearl river basin prb will be investigated in this research in the following sections we will restore the underlying nds from the time series of spi sri assess the nonlinear chaos characteristics of this nds and extract the nonlinear information about drought propagation time and rate from such a chaotic nds as a supplementary perspective for the linear approaches which inadequately address the complexity of drought propagation this research embraces a both nonlinear and systematical perspective on drought propagation with nds in phase domain besides although chaos is recognized in precipitation and runoff processes it has been rarely considered in drought propagation therefore nds could also provide a new perspective for common nonlinear views in drought propagation 2 materials and methods in this section the underlying nds of the time series of spi sri is restored and illustrated in phase domain by phase space reconstruction psr and then two methods correlation dimensions cd and largest lyapunov exponent lle are applied to describe the underlying nds and assess its chaotic behaviors based on which convergent cross mapping ccm is applied to detect the nonlinear information about the propagation time and rate between two droughts 2 1 drought indices compared with the original time series of precipitation and runoff spi and sri are commonly applied in drought propagation research given their good performances in characterizing meteorological and hydrological droughts they can numerically quantify drought severity at different time scales the calculations of spi and sri are the same which include three steps zhou et al 2021b 1 the cumulative precipitation runoff series of a specific time scale from one month to twelve months 2 these long term records are fitted into a probability distribution which is used to estimate the cumulative probability of time series values 3 the spi sri value is calculated by converting the cumulative probability to a standard normal distribution see text s3 for details zhou et al 2021b conducted systematic analysis with solid results for drought propagation time and rate in pearl river basin prb in china 21 31 26 49 n 102 14 115 53 e therefore this study also takes the prb as the study area with the purpose of comparison with previous findings to verify our findings using the monthly precipitation and runoff data with the spatial resolution of 0 1 during 1981 2020 which are from the era5 land global reanalysis dataset spi and sri in the prb are calculated at different time scales from 1 month to 12 month 2 2 nonlinear dynamic system nds this research resorts to lorenz model 1963 fig 1 to illustrate nds chaos and phase domain in this three dimensional model x y and z could represent any real world hydrometeorological variables including but not limited to precipitation runoff and evaporation within this model the change of one variable with time is contributed by other variables in a nonlinear manner denoted by ordinary differential equations as shown in fig 1 the value of each point in this model which is commonly referred to as a phase is jointly contributed by the three coordinates within this phase domain with time marching a point which is arbitrarily given an initial phase mt1 f xt1 yt1 zt1 will be moving according to the equations given long enough time the trajectory of this point will form a non integer dimensional butterfly shape manifold this butterfly is referred as an attractor for any given initial condition constrained in this system the position of the point i e phase will be eventually and determinately attracted to this butterfly given long enough period it is worth noting that 1 attractor is the final form of nds and they are equivalent to some extent so hereafter we only focus on the characteristics of attractor 2 the magnitude of chaos is determined by the dimension of attractor of nds i e how weird an attractor is and analysis methods of chaos theory could be adopted to calculate that dimension and 3 in reality however it is unable to observe any butterflies of nds but only those one dimensional time series like spi sri based on the concept of nds we could also assume an nds with time series of spi sri being its internal variables e g x spi y sri the nonlinear information about the propagation from meteorological to hydrological drought i e spi sri is derived from such nds therefore a method which could restore the underlying nds and its internal nonlinear information merely from time series of spi sri is the first step see text s2 for more detailed explanations about time series of spi sri drought events and their relationships with nds 2 2 1 phase space reconstruction psr as mentioned above phase space reconstruction psr is the method for restoring the underlying nds merely from time series kadir et al 2020 adenan et al 2017 shu et al 2021 fig 2 takens 2006 proposed a theorem proving that a topologically equivalent and one one mapping approximation of the phase space of the original nds and related attractor could be reconstructed from a one dimensional time series referred as shadow attractor such shadow attractor inherits abundant nonlinear information from the original one again take the butterfly in lorenz model 1963 to illustrate for each point m t from the original attractor m three time series each contributes a value from its own dimension m t φ x t y t z t focusing on one single dimension e g x t a shadow attractor mx can be reconstructed simply by creating three copies of x t each of which has a time lag by τ compared to the former one mx t φ x t x t τ x t 2τ fig 3 shadow attractors my and mz could be reconstructed in the same way the form of reconstructed attractor is generically a diffeomorphism and preserves essential mathematical properties including nonlinear information of the original system local neighborhoods and their trajectories in mx or my and mz map to that of the original system besides this one one mapping characteristic is not limited between m and mx but also among all shadow attractors fig 4 the performance of psr is decided by the two parameters time delay τ and embedding dimension e according to takens theorem 2006 in order to effectively restore the original system the optimal embedding dimension e should be e 2d 1 where d is the dimension of original system however theoretically embedding dimension smaller than the optimal one could also create some low dimensional approximation of original attractor 2 2 2 correlation dimension cd now that the shadow attractor of underlying nds which preserves important nonlinear information is reconstructed by psr from individual time series some descriptions for such shadow attractor is required to help us better understanding the behavior of underlying nds given that the shadow attractor could be multi dimensional which is difficult to de directly illustrated a quantitative description correlation dimension cd is most commonly used di et al 2019 a cd of a time series indicates the number of dominant variables that control the temporal evolution of the underlying nds in general ndss with infinite cd values are considered to be stochastic note that pure stochasticity is different from chaos see text s3 whereas the ones with finite non integer cd values are considered to be chaotic furthermore the value of cd is directly proportional to the level of complexity in the system that is the systems with high cds are more complex while those with low cds are simpler and exhibit low dimensional deterministic behaviors di et al 2019 the algorithm of grassberger and procaccia g p algorithm 1983 was mostly used text s4 2 2 3 largest lyapunov exponent lle the lyapunov exponent le is widely applied for estimating chaos of nds given the sensitivity to initial condition in chaos le quantifies the rate of separation between two infinitesimally close trajectories in the phase space di et al 2019 generally the existence of a positive le indicates the presence of chaos in a system whereas a negative one indicates that the system is stable or exhibits periodic behaviors rodriguez iturbe et al 1989 when le is 0 it suggests that the underlying nds is in a quasi stable state in applications the largest lyapunov exponent lle is usually used to identify whether a system exhibits chaotic behaviors wolf et al 1985 rosenstein et al 1993 similar to the computation of cds where the psr is the first step the method proposed by wolf et al 1985 was employed to compute lle text s5 2 2 4 convergent cross mapping ccm cd and lle describe the shadow attractor of individual time series and assess their chaotic characteristics whereas ccm compares two shadow attractors to find nonlinear information about drought propagation time and rate ccm was firstly proposed to detect the causality between two time series variables sugihara et al 2012 runge et al 2019 ombadi et al 2020 imagine two time series and their reconstructed attractors mx and my fig 5 for any given point y t0 in my a time corresponding point x t0 will be found in mx three nearest neighbors of y t0 could be found on my y ty1 y ty2 and y ty3 and their time corresponding points in mx will also be found x ty1 x ty2 and x ty3 this process is called cross mapping when x unidirectionally causes y my must contain some causal information from mx but not vice versa from the perspective of manifold the nearest neighbors in my remain the nearest in mx since x causes y and the nearest neighbors in my were causes by the nearest neighbors in mx whereas the nearest neighbors in mx might not remain as the nearest since this nearest behaviors in mx is not affected by the behaviors of my and the cross mapping does not guarantee the nearest fig 5 b another situation is that x and y are reciprocal causes and effects and cross mapping will guarantee the nearest reciprocally fig 5 c it is worth noting that the direction of cross mapping and that of causal information flow are inverse that is the cross mapping from y to x indicates the causal information flow from x to y figure s1 to avoid confusion the directions e g spi sri hereafter indicate the directions of causal information flow the cross mapping skill ρ is used to evaluate how nearest remains after the cross mapping from one manifold to other and the calculation of ρ is the same as the calculation of pearson correlation coefficient the cross mapping will traverse all time points from two manifolds the longer the time series is i e the larger n is the denser the manifold would be and more accurate the cross mapping would be ρ would be convergent to a certain level with time growing figure s2 between two information flow the higher convergence value indicates a stronger causality and the lower convergence value indicates a weaker figure s3 or none figure s4 causality 3 results and discussion 3 1 psr of spi sri this section demonstrates the behaviors of spi sri in phase space i e the shadow attractors of spi sri as mentioned before a perfect phase space reconstruction requires the optimal selection of embedding dimension e and time delay τ so that the nonlinear information about propagation time and rate could be effectively obtained in our previous study detecting the causality between meteorological and hydrological droughts in the same area shi et al 2022 these two parameters were selected according to a common experience i e e 2 and τ 1 which are commonly applied in many other researches regarding psr in this research we improved the calculation by applying the cao method chen et al 2014 di et al 2019 as an improvement of false nearest point method text s6 and autocorrelation coefficient method text s7 to quantify e and τ respectively for both spi and sri the results of cao method indicate that the optimal embedding dimension e is 5 for most spi and sri time scales except that several spi of short time intervals have the optimal embedding dimension of 6 fig 6 left as for the optimal time delay τ varies from 3 months to 7 months for spi and from 4 months to 7 months for sri both increasing with time scale fig 6 right the effectiveness of a shadow attractor retrieving nonlinear information from its original attractor largely depends on the value of parameter τ a narrow time delay τ would cause information overlap and redundancy in shadow attractor whereas a spread time delay would cause information loss yasmin and sivakumar 2018 we find that the time delay of spi sri12 7 months is larger than that of spi sri1 3 4 months which means that the information contained in spi sri12 are overlapped to some extent compared with that in spi sri 1 and a larger time delay 7 months would make sure the overlap be stretched such results imply that in phase space one unit of spi sri 12 contains much more abundant information than that of spi sri 1 also a low dimensional reconstruction could also provide some information here we present some two dimensional reconstructions of some representative spi and sri 1 month 3 month 6 month and 12 month just to give a general impression of shadow attractors high dimensional manifolds are impossible to illustrate as shown in fig 7 visually the trajectories were attracted to a well structured narrow region i e attractor which rotates around the line x t 1 x t indicating the shadow attractor of spi sri was chaotic the left bottom area of the attractor indicates a relatively arid situation whereas the right upper area indicates a relatively moist situation and both situations are stable since x shows no significant disparity in time i e x t 1 x t when x t 1 x t it suggests positive net water input into the underlying nds of spi sri and the x t 1 x t area indicates the underlying nds of spi sri is losing water both situations indicate the attractor is moving 3 2 cd and lle for the shadow attractors of spi sri now that the shadow attractors of spi sri are obtained we use cd and lle to assess their nonlinearity and chaos fig 8 illustrates the results of cd and lle for spi and sri with time scale from 1 month to 12 month cd of spi sri fig 8 left shows that the complexity of the underlying nds to which spi sri are subject to are non integer varying between 1 5 2 5 a system with a 1 5 2 5 complexity implies that the underlying nds of drought events is chaotic moreover it indicates that this underlying nds is 2 or 3 dimensional given different spi sri time scales which means that there could be other variable affecting spi sri other than precipitation and runoff within this nds to our knowledge evaporation could be the third part which plays an important role even though this variable is not directly related to the calculation of spi or sri as for lle fig 8 right spi and sri has similar pattern of lle larger than 0 and varying between 2 5 3 5 which also proves the existence of chaotic behaviors in spi and sri both methods generally depict the chaotic behaviors of drought events providing the precondition of the application of ccm 3 3 convergent cross mapping based on previous discussion about the effect of time delay and the time scale of spi sri on information overlap this research chose to focus on the shadow attractors of spi sri 1 month with the optimal embedding dimension of 5 and time delay of 3 months to make sure that the nonlinear information about propagation time and rate can be extracted efficiently 3 3 1 causal relationship between meteorological and hydrological drought as explained in section 2 2 4 the propagation time and rate can be detected only after the causality between spi and sri is proven figure s6 shows the result of ccm between spi 1 and sri 1 unlike the example situations figure s3 and s4 the cross mapping skill ρ values of both directions i e spi sri and sri spi are both convergent to a high value above 0 90 and the convergence value of sri spi even exceeds that of the other direction which means that the ccm believes that the cause effect relationship between spi and sri is reciprocal the behavior of spi leads to the change of sri and vice versa and the impact from sri on spi is even more obvious than that from the other direction such result is physically impossible since the behavior of precipitation is always the unidirectional cause of runoff and spi sri is expected to converge to a relatively higher value than sri spi sugihara et al 2012 explained that ccm is weak at distinguishing causality of unidirectional but strong coupled relationship i e synchrony wang et al 2019 and could confuse it with true bidirectional causality moreover figure s6 actually shows an instantaneous causality cross mapping is conducted between two time corresponding points between spi and sri fig 9 whereas in reality a driving variable usually acts with some time delay on a response variable e g peak of precipitation peak of flood that is instantaneous ccm also fails to unveil the drought propagation time in this case ye et al 2015a suggested a ccm with time lags fig 10 and this improved ccm on drought propagation could detect the real time lags between driving variables and receptor i e using past a to cross mapping future b and vice versa zhang and wang 2021 and distinguish the real causal direction between spi and sri we conduct ccm with different time lag including positive and inverse time lag and collect the final convergence values for each time lag among which the time lag with largest convergence value indicates the potential time interval for the receptor to response the driving variable figure s7 text s8 simply speaking we can detect the real propagation time from spi to sri by identifying the position of maximum value of cross mapping fig 11 shows the results of ccm with time lag blue line indicates the final convergent cross mapping skill in each time lag of spi sri while red line indicates the other way around according to fig 10 two lines are divided into four zones from i to iv the maximum value of red line sri spi is found in inverse time lag zone iii whereas blue line peaks in positive time lag zone ii zone ii indicates information flow from past to future whereas zone iii indicates the other way around and since the real information can only flow from past to future we believe that the maximum of red line is actually a pseudo one and the maximum of blue line is real this proves that the unidirectional causality from spi to sri i e sri cannot have any causal impacts on spi and the similarity between spi sri and sri spi is merely a synchrony instead of causality ma et al 2017 ma et al 2018 3 3 2 propagation time from meteorological to hydrological drought now focusing on zone ii in fig 11 separated out and shown in fig 12 we know that the maximum value in this zone indicates propagation time instead of peaking at a certain point blue line in zone ii remains highest around 0 96 in the form of a plateau from 1 to 5 months of time lag it is worth noting that this research uses e 5 as the optimal embedding dimension as opposed to our previous work e 2 and we found a defect that the highest values of final convergent cross mapping skill is different from our previous findings shi et al 2022 ma et al 2017 pointed that this is due to the imperfection in the calculation of convergent cross mapping skill in ye et al 2015a b which is effective in low dimensional situation like e 2 but invalid in high dimensional psr like e 5 therefore ma et al 2017 proposed a new cross mapping evaluation score by which we found the correct time lag such result 1 5 months of propagation time corresponds to the previous result of 2 5 months in different seasons zhou et al 2021a zhou et al 2021b we believe that such consecutive time lag is caused by seasonality in drought events the attractor actually contains all possible phases of seasons all year round and different parts of phases could represent different seasons figure s10 the plateau of 1 5 months is a collective behavior of the butterfly which buries the seasonality and given its integrality it is difficult to take this butterfly apart yet it is rational to assume that the propagation time in wet spring summer seasons is short 1 2 months and that in dry seasons autumn winter is long 5 months and such an assumption is supported by xu et al 2019 this is presumably because that the runoff generation time is short and hence the flow travel time is shorter with higher flow rate in wet season than dry season pomeroy et al 2016 in addition we applied the same method to the wei river basin wrb a semi arid and semi humid region in china 103 5 e 110 5 e and 33 5 n 37 5 n to validate our results and assumption as shown in fig 13 we found the actual propagation time of 3 7 and 11 months respectively this result basically corresponds to the conclusions of ma et al 2021 that the propagation time in the wrb were 2 3 8 and 13 months in summer autumn spring and winter respectively 3 3 3 propagation rate from meteorological to hydrological drought propagation rate reflects changes in the frequency duration severity and intensity between meteorological and hydrological droughts zhang et al 2022 we believe that the nonlinear information regarding propagation rate between two droughts could be found in shadow attractors and this research proposed the new thought to find such rate by comparing the similarity between two butterflies zhou et al 2021a compared the magnitudes severity of meteorological and hydrological drought events 2 5 months later to determine the drought propagation rate with the same time lag 2 5 months we analyze the similarity between shadow attractors of those two drought events to reveal the drought propagation rate according to sugihara et al 2012 when the causality between two variables is unidirectional the instantaneous ccm skill of information flow from receptor to driving factor should be fluctuating around zero red line in figure s4 indicating no information flows from receptor to driving factor and the ccm skill of information flow from driving factor to receptor could quantify causal impact however in our case the causality between spi and sri was proven to be a strong coupled synchrony by improved ccm with time lag rather than a true bidirectional causal relationship in the positive time lag zone in fig 11 both blue and red points indicate information flow from a past attractor to a future one 2 5 months later and that guarantees two shadow attractors are linked in a correct temporal logic blue points in zone ii indicate information flow from current spi to sri that in 2 5 months later and are all convergent to above 0 95 whereas the red points in zone iv indicate the causal information flow from the other direction sri spi with the same time lag however red points fluctuate around 0 70 instead of zero due to the existence of synchrony between spi and sri red points i e information flow from sri to spi will remain around a certain value above zero until time lag is large enough and the convergence completely vanishes figure s9 therefore ccm skills sri spi i e information flow from the receptor to the driving factor actually imply the magnitude of synchrony which reflects the sensitivity of hydrological to meteorological drought i e propagation rate whereas ccm skill of spi sri could be pushed into a false high value by synchrony and is not reliable zhou et al 2021b found that under the 2 5 months propagation time the average propagation rate from meteorological to hydrological droughts is 0 686 0 69 0 66 0 77 0 70 and 0 61 in 5 subregions in prb respectively accordingly we extract the final ccm skills of sri spi 2 5 months in zone iv as shown in fig 12 right and find that the average of ccm skills sri spi is 0 6856 consistent with previous result to a great extent 4 conclusions the significance of nonlinearity in most hydrometeorological events including drought propagation are commonly acknowledged and common applied linear approaches cannot fully address the complexity of drought propagation this study innovatively introduced the concept of nds into drought propagation research which provides a both nonlinear and systematical perspective in addition nds could also explain the concept of chaos which is commonly misinterpreted with nds in the phase domain we managed to find and depict the underlying chaotic butterflies of drought events by cd and lle then we adopted ccm to compare the reconstructed shadow attractors and its nonlinear information to unveil the propagation time and rate major findings are summarized as follows 1 despite not exactly shaped as butterfly the shadow attractor does exist in spi sri representing the real attractor of underlying nds to which drought events are subject furthermore the existence of chaotic behaviors of spi sri and the chaos in nds were investigated and proved by cd and lle indicating that chaos is of great significance in drought propagation 2 in prb the propagation time of 1 5 months from meteorological to hydrological drought was detected by ccm which is supported by previous findings for supplementary we adopted the same analysis in wrb and detected the propagation time of 3 7 and 11 months in different seasons respectively such findings also correspond to previous findings 3 the similarity between two shadow attractors of spi and sri manifesting propagation rate of 0 686 from meteorological to hydrological drought was also detected by ccm which is supported by previous finding and proved that ccm is effective in detecting propagation rate in our previous work regarding drought propagation time ccm was also applied to the same study areas i e the prb and wrb basins see shi zhao et al 2022 but the assumption in that study was that the propagation between meteorological and hydrological droughts conforms with a causal relationship and the method ccm was based on the concept of causality detection besides some important parameters was selected simply based on experience instead of precise calculation by contrast in this research the nonlinearity and complexity of drought propagation are analyzed systematically transferring a causality based assumption to an nds based theoretical construct since causality represents only partial nonlinear information concealed in an nds in addition we also tuned important parameters for psr i e τ and e and conducted cd and lle analyses for providing a solid rationale for the application of ccm to detect drought propagation time and rate overall this study introduced a new nonlinear perspective in drought propagation analysis and demonstrated its high potential for a broad range of hydrometeorological research credit authorship contribution statement yiyang zhao conceptualization methodology formal analysis validation writing original draft tingju zhu methodology supervision writing original draft writing review editing funding acquisition zhaoqiang zhou validation hejiang cai validation zhaodan cao validation declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests tingju zhu reports financial support was provided by national natural science foundation of china tingju zhu reports financial support was provided by national key research and development program of china acknowledgments this study was supported by the national key research and development program of china 2020yfa0608603 the national natural science foundation of china 51961125204 and the national key research and development program of china study on simultaneous wet or dry years in the yangtze river and the yellow river under changing environment and water allocation in extreme dry years 2022yfc3202300 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129810 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
1743,depleted oil gas reservoirs can be used for co2 sequestration and utilization co2 plume geothermal cpg production from a co2 geological storage reservoir has emerged as a viable approach owing to its favorable thermodynamic properties however most oil gas reservoirs are separated by faults into geological blocks and the impact of these fault boundaries on cpg performance remains unclear this study evaluated and compared the technical performances of a horizontal well triplet placement and cpg operation in a thin geothermal reservoir between open and close boundaries a meta model simulation optimization framework was also applied for the economic assessment of both systems for each boundary system 200 samples of the horizontal well triplet design including injection well overpressure horizontal perforation length of injection and production wells and distance between injection and production well were derived from a 4d parameter space constrained by particular ranges these 200 samples of input parameters yielded 200 numerical models for the simulation of cpg operations a suite of technical metrics including lifespan injected produced and stored co2 recovered heat energy and produced heat flux were computed from the model simulations for technical performance evaluations meta models for economic objectives were developed based on the 200 input output datasets and used in optimization a multi objective particle swarm optimization mopso approach was utilized to obtain the appropriate optimal designs of the well triplet for the two boundary systems the results indicated that performance of both systems was controlled by the well space which was positively correlated to co2 storage and total heat recovery but negatively to power plant capacity high horizontal well lengths and overpressure facilitated co2 storage heat recovery and plant capacity the open system could generate much more overall profit than the close system owing to co2 storage income keywords horizontal well triplet co2 plume geothermal meta model multi objective optimization open boundary close boundary data availability data will be made available on request 1 introduction geothermal energy can contribute to renewable energy growth in the middle east and globally rajabi et al 2021 chen et al 2022a ezekiel et al 2022a 2022b xu et al 2022 co2 plume geothermal production cpg as an emerging technique has been demonstrated as a promising co2 usage method coupled with co2 geological storage in the past decades sun et al 2018 dai et al 2020 chatelin and harada 2021 fleming et al 2020 rajabi et al 2022 particularly the co2 circulated system was more efficient than the water based system due to the substantial thermosiphon effects fouillac et al 2004 atrens et al 2009 adams et al 2014 adams et al 2015 babaei and nick 2019 studied different numerical models to evaluate the effects of heterogeneity on lifespan concerning well configurations rasheed et al 2020 assessed the heterogeneity impacts on co2 storage babaei et al 2022 attempted to maximize the geothermal performance for the spatially correlated heterogeneous channels and norouzi et al 2022 studied the heterogeneous cpg systems to define the optimum well spaces however managing co2 in geothermal reservoir systems considering various profit making objectives is still complicated and challenging depending on the optimal design and configuration of the cpg system sun et al 2018 adams et al 2021 eldardiry and hossain 2021 hence intelligent optimization models should be coupled with numerical models to evaluate the optimum development of geothermal reservoirs norouzi et al 2021 norouzi et al 2022 recently commercial software such as comsol qu et al 2017 and schlumberger eclipse e300 babaei 2019 and academia codes such as tough transport of unsaturated groundwater and heat hu et al 2020 and nuft non isothermal unsaturated saturated flow and transport chen et al 2021 have been utilized to evaluate the co2 geothermal reservoirs some studies coupled the tough model for the co2 geothermal reservoirs with a genetic algorithm ga biagi et al 2015 and multi physics object oriented simulation environment moose ravilov 2019 to obtain optimum geothermal reservoirs configurations and designs however it has been found that most of the physics based model runs incurred in optimization are very computationally demanding rajabi et al 2021 van brummen et al 2022 to address this issue meta models have been implemented to surrogate the physics models for fast estimations or predictions in the different numerical simulation optimization frameworks rajabi and chen 2022 ezekiel et al 2022a 2022b the multivariate adaptive regression splines method mars has been demonstrated as a special and efficient meta modeling algorithm chen et al 2021 2022b choosing the superior optimal solution from the results of optimization models is a multi criteria decision making mcdm problem yu et al 2004 zhu et al 2016 several mcdm models have been adopted in the literature for defining the superior optimal design of water and environmental problems such as the technique for order preference by similarity to ideal solution topsis fu 2008 goal programming mamun et al 2015 and complex proportional assessment copras method roozbahani et al 2021 however as our knowledge allows there is no study in the literature applying copras to rank several alternatives resulting from applying multi objective optimization models to cpg related problems in this study we attempted to integrate the multi objective particle swarm optimization mopso wang et al 2012 with meta model mars and reservoir model nuft for a co2 geothermal reservoir evaluation to obtain the copras based rank optimal results boundary conditions have been widely known to influence fluid flow and associated heat transfer in subsurface formations holloway and burnard 2009 babaei and nick 2019 proposed a comparative evaluation of cpg performance in sedimentary aquifers between the open and close boundary conditions in which various standard vertical well placements were investigated and evaluated for both systems in this study we targeted high porous low permeable and thin reservoir blocks which widely exist in the potential geothermal region of north oman only horizontal wells were feasible for cpg operation in this thin formation with low permeability faults sealed the blocks and the boundaries could have different permeability to our knowledge horizontal well placement with various perforation lengths and distances had never been investigated for a cpg system three tiers of comparative analysis were performed to comprehensively investigate the impact of open and close boundaries on the performance of the horizontal well triplet placement for co2 storage and geothermal harvest operation first spatiotemporal behaviors of open and close geothermal reservoirs were analyzed for the base case with a fixed well triplet placement and injection overpressure second 200 combinations of well placement well perforation lengths and well space and overpressure were configured and simulated for both systems and a suite of technical performance indicators were computed from each of the 200 model simulations and comparatively analyzed third economic models were developed and used as the objective functions of well triplet optimization using the proposed methods finally economic objectives optimal well configurations and operations were compared between the two reservoir systems for the convenience of description we will refer open boundary and close boundary reservoir systems as ob and cb from here on 2 methodology 2 1 co2 circulated geothermal simulations 2 1 1 study field and hydrogeothermal properties the target geothermal reservoir was based on the shu aiba limestone formation in a fault block in the daleel oil field oman morettini et al 2005 where high underground temperatures were found al lamki and terken 1996 as shown in fig 1 the simplified model domain was 3 km 2 km and 20 m in x y and z directions at a depth of 1500 m the pressure and temperature of the reservoir were 17 mpa and 100 c respectively the rock properties were almost homogeneous with low permeability 10 14 m2 and high porosity 0 28 initially the pore space was saturated with 30 irreducible brine and 70 co2 in volume after co2 sequestration or improved oil recovery the caprock and bedrock are assumed impermeable while lateral boundaries could be permeable ob or impermeable cb depending on fault seals table 1 showed the other key rock and hydrothermal properties rajabi et al 2021 2 1 2 horizontal well triplet considering the low permeable and thin reservoir block where horizontal water flooding had been conducted in the oil recovery history morettini et al 2005 a horizontal well triplet was deployed to harvest heat energy by circulating co2 a horizontal injection well iw was located in the central x in parallel to the y axis and two parallel production wells pw were symmetrically positioned on each side of the iw fig 1 compared to a doublet a triplet can double the heat sweeping area and associated heat extraction limited by the size of the reservoir block only one triplet set can be accommodated the injection well is placed at the bottom while the two production wells are placed at the top to take advantage of co2 buoyancy in the heavier brine and full range of vertical sweeping area cold co2 30 c was injected under constant overpressure the additional pressure imposed upon initial pressure and the pressures of two pws were specified constant on their initial values during operations the injection overpressure in increased from zero to the specified value in the 1st year and remains at that value thereafter under this pressure gradient between iw pw hot co2 was extracted to the surface power plant went through a co2 turbine to generate electricity and cooled co2 was re injected to the reservoir the horizontal perforation lengths and well space injection overpressure were our targets to be optimized for both open and close reservoirs the open boundary of the model domain was realized by multiplying the volumes of the boundary grid cells by 106 to mimic the far field accommodating fluid outflow 2 1 3 nuft code the models simulating non isothermal two phase liquid gas and three components water salt co2 flow and transport in the porous formation were developed using nuft code a robust hydrogeological simulator developed by lawrence livermore national laboratory usa nitao 1998 nuft is equipped with a reliable equation of state for co2 thermodynamics and has been used in several co2 related reservoir modeling applications chen et al 2020 chen et al 2022a water thermodynamics is estimated by american society of mechanical engineers 2006 steam tables co2 thermodynamic properties density enthalpy viscosity are described by the correlations of span and wagner 1996 garcia 2001 and fenghour et al 1998 respectively miscibility is considered that is co2 concentration in the liquid phase and water concentration in the gas phase are simulated however salt nacl is only allowed to be dissolved in the liquid phase geochemical reactions between rock water co2 are not considered in our simulations as it is only considerable in long term hundreds of years molecular diffusion of each component in liquid and gas phases are specified by the method of reid et al 1987 capillary pressure and relative permeability of co2 and water are governed by the classic van genuchten correlations 2 2 model simulation experiment to explain the temporal and spatial behaviors of the geothermal reservoir under the horizontal well triplet operation we run a baseline case for both ob and cb respectively as shown in table 2 the iw and pw perforation was 800 and 1000 m respectively the iw pw distance was 1000 m and the injection overpressure was 12 mpa co2 circulations under this well placement and overpressure for both boundary conditions were simulated for 30 years the time series of key performance indicators including temperature decline and associated lifespan co2 mass injected produced stored and recovered heat energy were compared between ob and cb moreover the spatial distribution of pressure and temperature by the end of the operation was also comparatively analyzed in addition to the baseline case study 200 combinations of the four uncertain input parameters i e well space disl iw and pw perforation lengths iwl pwl and injection overpressure iwop were sampled using latin hypercube approach mckay et al 1979 from the 4 d input parameter space accompanied by their ranges table 2 six technical performance indicators including lifespan co2 mass injected injco2 produced prodco2 and stored netco2 total heat energy recovered totheat and average produced thermal flux flxheat in lifespan were calculated from each of the 200 reservoir models for both ob and cb table 3 based on the 200 sets of input output simulation data sensitivity and 2d contour map of each technical indicator to the input parameters were calculated and comparatively analyzed between ob and cb 2 3 global sensitivity analysis the global sensitivity of a dependent variable y to an independent variable x can be measured by sobol total order index sti the sensitivity indices are expressed as sobol 2001 1 s i i v a r e y x i var y 2 s i ij v a r e y x i x j v a r e y x i v a r e y x j v a r y 3 st i i s i i j i s i ij j i k j s i ijk where var represents variance s i i is x i sensitivity in the first order s i ij is the second order indices of x i and x j calculating their interactions contribution sti represents the total variance contribution of the input to the output variables including interactions between input variables the ranges of sti indices are 0 to 1 and when the sti 0 05 it was assumed as sensitive 2 4 meta modeling approach applying a fast meta model plays a prominent role in developing a time effective simulation optimization approach the multivariate adaptive regression splines mars model is a robust meta modeling approach that prepares a continuous prediction for each targeted function based on an arbitrary order of derivatives in addition this technique has the advantage of including different interaction levels at each step by maintaining the parent basis function within the analysis so that it can generate purely additive models to the complex models with an easy and fast procedure to apply this model a model consisting of the weighted sum of multivariate spline basis functions was fitted due to eq 4 in this formulation each spline was a basis function multiplied by its coefficient each basis function was in one of the following forms 1 a constant value 2 a hinge function the mars model chose the variables based on the knots of hinge functions 3 a product of different hinge functions these basis functions could model the interaction between various variables knafl and ding 2016 4 e y i i 0 n a i b i x i where a i is the coefficient predicted by the generalized cross validation fitting technique and the multivariate spline is the product of the univariate spline basis function defined by eq 5 5 b i x 1 x n s 1 r k b x i s k t s k 1 k r where i s k is a specific explanatory variable and the basis spline for that parameter puts a knot at t s k the predictive quality of the mars model is verified by cross validation of the fitted models before being used in the simulation optimization the coefficient of determination r2 was used to measure the match between the data driven mars model and the physics based nuft model 6 r 2 1 i 1 n x i y i 2 i 1 n x i x i 2 where x i and y i are the result for the sample i from physics and meta models respectively x i is the average value 2 5 the multi objective optimization framework 2 5 1 multi objective particle swarm optimization mopso model the particle swarm optimization pso model is a robust optimization approach introduced by kennedy and eberhart 1995 the pso model can be applied successfully for complex optimization models due to its advantages compared to other evolutionary algorithms 1 it has an accurate and fast convergence considering the fitness based on the probability evolution 2 the localized optimization is lowly probable due to the method s random search space wang et al 2012 the mopso model is a multi objective extension of the pso approach effectively used for complicated multi objective optimization models to implement the mopso model the following steps should be performed 1 generating the particle swarm s internal and external set 2 choosing the non dominated solutions from the internal particle swarm to input in the external set 3 calculating the variation of the internal particle and the mutation rate 4 defining the iteration times considering updated external archives set the mospo optimization model investigated optimal well placement and overpressure for ob and cb 2 5 2 objective functions formulating a suitable objective function is essential in optimization models yazdandoost et al 2021 nematollahi et al 2022a nematollahi et al 2022b the objectives of the mopso optimization model could be formulated as minimizing the yearly cost maximizing the yearly benefit and maximizing the net present value as shown by eqs 7 8 and 13 minimize 7 z 1 i 1 ls c t maximize 8 z 2 i 1 ls pr t where pr t is average yearly profit c t is the average yearly cost i is the year number and ls is the lifespan in each scenario pr t and c t can be formulated as eqs 9 and 10 based on the definition of the average yearly electricity generation w t mwh by eq 11 randolph and saar 2011 9 pr t w t e s r c o 2 t i c o 2 10 c t i j c o 2 t c o ij w t c o pt 11 w t 1 t avs t res pr o t e f where e is the electricity s price mwh s r c o 2 t is the average yearly co2 mass tons and i c o 2 is the income per ton co2 equal to 14 in the proposed model furthermore i j c o 2 t is the net injection of the co2 c o ij is the cost for the co2 injection tonco2 and c o pt is the cost of the power plant mwh in addition t avs is the average yearly surface temperature k as 301 15 k t res is the reservoir temperature k pr o t is the thermal energy production mwh ef is the efficiency of the mechanical system equal to 0 5 the relationship between produced heat at well bottom and surface power generation is simplified by the above equations as the focus of this study is on the impacts of the reservoir boundaries which are simulated in the geothermal reservoir models simulation of a complete cycle of a cpg system can be found in the study by levy et al 2018 then for estimating the cost of co2 injection eq 12 was used 12 c o ij b 1 r a ij b 2 b 3 where r a ij is the average rate of yearly injection tons b 1 b 2 and b 3 are 24 856 0 433 and 0 5 respectively calculated by carneiro et al 2015 in addition the net present value for different scenarios was calculated as follows maximize 13 n v t t 1 ls pr t c t 1 i t c con p t c var where n v t is the total net present value representing the cumulative benefits of electricity generation and co2 sequestration minus the total costs rajabi et al 2021 moreover c con is the fixed initial cost pt is the cost of power plant energy generation mw and c var is the variable initial cost 2 6 complex proportional assessment copras decision making technique complex proportional assessment copras method is a decisive multi criterion decision making mcdm model to rank the alternatives associated with the results of the multi objective optimization models this approach s superior optimal solution corresponds to the alternative with the highest utility pitchipoo et al 2014 zhu et al 2018 3 results and discussion 3 1 spatiotemporal behavior of a cpg fig 2 compared baseline case simulations between ob and cb regarding co2 injection production rates net injected rate and cumulative mass temperature and produced thermal flux and cumulative heat recovery in 30 years of operation the flow rates were almost stabilized after the initial three years in response to the linear increase of injection pressure from zero to 12 mpa in the 1st year and remaining constant after that although the co2 injection rate in ob was higher than that in cb by about 25 the production rate in ob was only about half of cb fig 2a consequently both net injection rate storage rate and associated cumulative co2 mass storage in ob were significantly more than those in cb fig 2b these results make sense since driven by the 12 mpa of overpressure injected co2 could migrate to the far field in addition to well extraction in ob while it could only be extracted by production wells in cb it was also found that the average storage rate in ob was around 50 kg s much higher than 30 kg s of the average production rate in contrast the co2 storage rate was less than 10 of the production rate in cb after 30 years of operation only 37 of the injected co2 was circulated for geothermal harvest in ob while it was 90 in cb table 4 as shown in fig 2c the reservoir heat depleted faster in cb than that in ob due to the higher circulation rate by the 30th year produced temperature dropped to 71 94 and 67 24 c and total recovered heat reached 11 54 and 22 24 1015 joules in ob and cb respectively as 80 c of cutoff temperature was applied to defining the geothermal lifespan which was 26 5 years in ob and 24 3 years in cb the heat recovered in their respective lifespan was 10 37 and 18 51 1015 joules table 4 and fig 2d these results suggested that even with a shorter lifespan the cb could recover much more heat energy than ob under the proposed well placement and operation scheme cb can yield more produced co2 mass 43 23 vs 23 95 mt and associated heat energy than ob within its lifespan table 4 figs 3 and 4 presented snapshots of spatial distributions of pressure and temperature on the top horizontal plane at 30 years for both ob and cb the pressure of iw and pw were specified at constant 29 initial 17 mpa plus 12 mpa overpressure and 17 mpa respectively as depicted in fig 3 the pressure distribution between iw and pw was similar between ob and cb owing to the same iw pw pressure gradient however it was quite different beyond the inter well region due to the different boundary conditions the pressure was relieved towards open boundaries but built up near the close boundaries correspondingly the cold co2 front extended substantially towards the back and front boundaries in ob but was well constrained in cb fig 4 3 2 technical performances of the open and close reservoirs the six technical performance indicators derived from the 200 nuft models were statistically analyzed for ob and cb the descriptions of the six variables were given in table 3 in the following sub sections stis of the six output indicators to the four inputs were utilized to rank the sensitivity of outputs to inputs fig 5 contour maps of each output variable with respect to the sensitive parameters sti 0 05 or the top two sensitive ones were plotted pairwise for 2d sensitivity analysis in fig 6 the relationships between the six indicators were also analyzed using the joint probability fig 7 3 2 1 sensitivity screening fig 5 showed the sti of the six output variables to the four input parameters for both ob and cb among the four input parameters well space disl was the dominant one affecting all six outputs of both ob and cb iw perforation length iwl had a more substantial influence on produced thermal flux flxheat in cb than that in ob sti 0 21 vs 0 11 however the other three outputs were nearly insensitive to iwl in both systems pw perforation length pwl showed moderate impacts on both produced co2 mass prodco2 and total recovered heat totheat only in ob sti 0 21 and slight impacts sti 0 07 0 08 on flxheat in both systems injection overpressure iwop moderately affected lifespan and flxheat in both systems sti 0 2 0 39 in the following subsections 2d contour maps of each of the six output variables in response to its pairwise sensitive parameters were presented for sensitivity analysis fig 6 sti values were labeled for associated input parameters to facilitate the comparative analysis between ob and cb 3 2 2 sensitivity analysis for lifespan fig 6 showed the impact of disl and iwop on geothermal lifespan for ob 1a and cb 1b ob s lifespan was longer than cb s because extracted co2 and associated heat flux were more minor from the reservoir with an ob than cb fig 8 apparently a larger disl led to a longer lifespan to achieve an optimal lifespan between 20 and 50 years disl should be between 600 and 900 m and be larger than 950 m for 5 and 15 mpa of iwop respectively the results indicated that a large disl should be paired with a high iwop to yield an appropriate lifespan in general iwop slightly moderately affected lifespan and its impact was obviously stronger at the bottom right area of the contour map large disl low iwop as iwop was usually restricted by geomechanical conditions of the reservoir well space should be carefully determined to obtain an optimal lifespan 3 2 3 sensitivity analysis for co2 mass figs 6 and 7 gave cumulative injected produced and stored co2 mass responding to the sensitive pairwise parameters in the respective lifespan of ob and cb as shown in fig 6 large disl would induce more injco2 and the increasing rate for ob was double of cb s this result suggested that more injected co2 migrated to the far field instead of the pws in ob as disl is longer less fluid was attracted to the pws and more co2 was driven across the boundaries considered as storage as the distance extended in contrast most of injected co2 was produced by pws in cb as there was no other way to escape a minor amount could be stored in the reservoir rock s pore space due to fluid and rock compressibility note that the reservoir pores were initially assumed to be filled with 70 co2 in volume and 30 of irreducible brine although iwl was ranked as the 2nd sensitive parameter its impact on injco2 was slight larger iwl could be led to more injco2 as shown in fig 6 prodco2 for ob was less than that for cb despite much more injco2 for ob as the same as injco2 disl was the dominant parameter for prodco2 however pwl instead of iwl was ranked as the 2nd sensitive parameter in addition pwl sensitivity became stronger for the ob reservoir especially in large disl areas given the large iw pw distance in an open reservoir system this result indicated that lengthening the pws could considerably promote co2 and associated heat production as most injected co2 was extracted from the reservoir with a cb its maximal netco2 was less than 8 mt given the largest iwl and disl fig 7 on the contrary the maximum of ob s netco2 reached over 90 mt even much more than its prodco2 3 2 4 sensitivity analysis for heat recovery as shown in fig 7 totheat shared a similar 2d sensitivity map with prodco2 as the total recovered heat was derived from the produced hot co2 mass again similar to prodco2 totheat from ob was substantially less than from cb flxheat however was affected by all four input parameters hence three 2d maps with respect to parameter sets between the most sensitive disl and each of the other three were presented in fig 8 flxheat was the averaged heat flux in lifespan calculated as totheat lifespan the 2d maps for ob shared similar patterns as for cb though ob s values were smaller owing to ob s lower totheat and longer lifespan contrary to output 1 5 flxheat was negatively correlated to disl as disl represented the sweeping area of the geothermal reservoir higher disl would yield a larger amount of injected produced stored co2 mass recovered heat as well as lifespan although both totheat and lifespan were positively correlated to disl the gradient of lifespan apparently overpassed totheat leading to a negative correlation between flxheat and disl it should be noted that shorter disl could yield higher flxheat but it also led to a shorter lifespan which was not economically feasible for a geothermal power plant if 20 years of lifespan were considered the minimal value the maximal flxheat would be about 15 mw and 25 mw for cb and ob respectively figs 6 and 8 these results suggested that a reservoir with ob could contribute more to co2 storage while cb could generate more geothermal electricity the other three parameters iwl pwl and iwop were all positively correlated to flxheat especially iwl and iwop showed considerable impacts on flxheat as either iwl or pwl had negligible impact on lifespan they should be designed as long as possible to maximize co2 storage and heat recovery iwop however should be determined according to geomechanical assessment and the feasible lifespan of the geothermal reservoir compared to ob iwl and iwop showed more significant impacts on flxheat for cb while disl s impact was reduced sti 0 461 vs 0 763 these results indicated that well space dominated the geothermal power plant capacity in an open system while the impact of iw overpressure was equivalent to well space in a close system 3 2 5 relations between the performance indicators the relationships between the six output indicators could be roughly derived from their respective correlations to the key input parameters as discussed in the aforementioned 2d sensitivity maps fig 9 gave a more direct and precise demonstration of their relationships using joint probability jp based on the 200 simulations to facilitate description each jp in fig 9 was denoted as jpxy hereunder where y and x represented the output number in the y and x direction of the figure overall jps of ob and cb showed similar trends for example outputs 1 5 were positively correlated to each other but negatively correlated to flxheat totheat was linearly correlated to prodco2 jp53 however there were prominent distinctions for some jps between ob and cb owing to their different co2 mass flows for example as injected and produced co2 flow rates for cb were nearly equivalent prodco2 showed a linear correlation to injco2 jp32 in fig 9b leading to a stronger linearity between output 2 5 than for ob fig 9a 3 3 meta model based optimization the mars meta modeling approach was utilized to fast predict the three economic objectives in the optimization process the 200 nuft model simulations dataset was used to train and cross validate the mars models fig 10 showed that the fitted mars models could predict these objectives accurately according to the high r2 values between mars and nuft model data pareto optimal solutions were derived by the coupled mars and mopso models the best superior optimal solution was selected using the copras model fig 11 presented the pareto optimal solutions of the three objectives for ob and cb the first four optimal solutions ranked by the copras model for ob and cb were listed in table 5 for the first rank the ranges of optimal benefit for cb and ob were 34 77 to 208 48 and 106 22 to 1332 79 million dollars respectively on the other hand the ranges for the optimal cost for cb and ob were 1 23 to 56 and 1 19 to 62 7 million dollars respectively according to the optimized objective functions the cb was subjected to substantially less benefit than the ob but relatively equivalent cost hence the ob was more cost efficient than the cb it was because much more co2 could be stored in ob while more co2 was circulated for electricity generation in cb given the current co2 storage credit and electricity price the difference in co2 storage income surpassed that of the geothermal electricity revenue between ob and cb the optimal values of disl iwl and iwop were close to their up limits for both ob and cb the optimal pwl for ob however approximated its low limit 400 m while it was around 1000 m for cb ob s revenue was significantly higher than cb s because co2 storage income was much more than electricity income to maximize the profit in ob the optimizing process would try to reduce produced co2 to increase stored co2 by minimizing the pw length 4 summary and conclusions co2 circulated geothermal harvest and co2 geological storage were numerically analyzed for a high porous low permeable thin fault block with an open and close boundary respectively key factors affecting the open and close systems were identified and their impacts were quantitatively assessed in addition technical and optimal economic performances of the horizontal well triplet placement and operation in the open and close reservoir systems were comparatively analyzed a summary of gained insights was given below well space was the dominant factor that controls the six technical performance indicators for both open and close reservoir systems a larger well space could increase lifespan injected produced and stored co2 mass and cumulative heat recovery leading to a smaller power plant capacity produced heat flux the large horizontal length of injection and production wells would facilitate co2 circulation and storage as well as associated heat flux and total heat energy production for both systems however the impacts were mostly minor only the impact of injection well length on heat flux for the close system and production well length on produced co2 mass and heat for the open system were found at a moderate level a high overpressure could shorten the lifespan moderately for both systems however it also moderately elevated the geothermal power capacity for open and close systems between the two systems the open reservoir required more co2 injection and accommodated much more co2 storage while the close reservoir could recover more heat energy but store few co2 the recovered heat is correlated to the produced co2 mass positively and linearly for both systems the positive linear correlations between the injected produced stored co2 mass and total heat recovery mass was much stronger for the close system than for the open system although more electricity revenue could be generated from the close system the open reservoir s overall profit was significantly higher owing to the co2 storage income future work may extend the comparative analysis to a heterogeneous formation for example the impact of economic parameters such as electricity price and co2 storage credit on optimal economic objectives for both systems should be further studied in addition the system with intermediately permeable boundaries between entirely open and close conditions may also deserve a comprehensive investigation credit authorship contribution statement banafsheh nematollahi conceptualization methodology software investigation resources data curation visualization writing original draft mingjie chen supervision conceptualization methodology software investigation data curation validation funding acquisition project administration resources visualization writing review editing mohammad reza nikoo methodology validation conceptualization writing review editing ali al maktoumi conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the study is funded by grants cl squ iggcas wrc 23 01 rc rg dvc wrc 21 02 and ig dvc wrc 22 02 the squ research group dr rg 17 is greatly appreciated for its technical support 
1743,depleted oil gas reservoirs can be used for co2 sequestration and utilization co2 plume geothermal cpg production from a co2 geological storage reservoir has emerged as a viable approach owing to its favorable thermodynamic properties however most oil gas reservoirs are separated by faults into geological blocks and the impact of these fault boundaries on cpg performance remains unclear this study evaluated and compared the technical performances of a horizontal well triplet placement and cpg operation in a thin geothermal reservoir between open and close boundaries a meta model simulation optimization framework was also applied for the economic assessment of both systems for each boundary system 200 samples of the horizontal well triplet design including injection well overpressure horizontal perforation length of injection and production wells and distance between injection and production well were derived from a 4d parameter space constrained by particular ranges these 200 samples of input parameters yielded 200 numerical models for the simulation of cpg operations a suite of technical metrics including lifespan injected produced and stored co2 recovered heat energy and produced heat flux were computed from the model simulations for technical performance evaluations meta models for economic objectives were developed based on the 200 input output datasets and used in optimization a multi objective particle swarm optimization mopso approach was utilized to obtain the appropriate optimal designs of the well triplet for the two boundary systems the results indicated that performance of both systems was controlled by the well space which was positively correlated to co2 storage and total heat recovery but negatively to power plant capacity high horizontal well lengths and overpressure facilitated co2 storage heat recovery and plant capacity the open system could generate much more overall profit than the close system owing to co2 storage income keywords horizontal well triplet co2 plume geothermal meta model multi objective optimization open boundary close boundary data availability data will be made available on request 1 introduction geothermal energy can contribute to renewable energy growth in the middle east and globally rajabi et al 2021 chen et al 2022a ezekiel et al 2022a 2022b xu et al 2022 co2 plume geothermal production cpg as an emerging technique has been demonstrated as a promising co2 usage method coupled with co2 geological storage in the past decades sun et al 2018 dai et al 2020 chatelin and harada 2021 fleming et al 2020 rajabi et al 2022 particularly the co2 circulated system was more efficient than the water based system due to the substantial thermosiphon effects fouillac et al 2004 atrens et al 2009 adams et al 2014 adams et al 2015 babaei and nick 2019 studied different numerical models to evaluate the effects of heterogeneity on lifespan concerning well configurations rasheed et al 2020 assessed the heterogeneity impacts on co2 storage babaei et al 2022 attempted to maximize the geothermal performance for the spatially correlated heterogeneous channels and norouzi et al 2022 studied the heterogeneous cpg systems to define the optimum well spaces however managing co2 in geothermal reservoir systems considering various profit making objectives is still complicated and challenging depending on the optimal design and configuration of the cpg system sun et al 2018 adams et al 2021 eldardiry and hossain 2021 hence intelligent optimization models should be coupled with numerical models to evaluate the optimum development of geothermal reservoirs norouzi et al 2021 norouzi et al 2022 recently commercial software such as comsol qu et al 2017 and schlumberger eclipse e300 babaei 2019 and academia codes such as tough transport of unsaturated groundwater and heat hu et al 2020 and nuft non isothermal unsaturated saturated flow and transport chen et al 2021 have been utilized to evaluate the co2 geothermal reservoirs some studies coupled the tough model for the co2 geothermal reservoirs with a genetic algorithm ga biagi et al 2015 and multi physics object oriented simulation environment moose ravilov 2019 to obtain optimum geothermal reservoirs configurations and designs however it has been found that most of the physics based model runs incurred in optimization are very computationally demanding rajabi et al 2021 van brummen et al 2022 to address this issue meta models have been implemented to surrogate the physics models for fast estimations or predictions in the different numerical simulation optimization frameworks rajabi and chen 2022 ezekiel et al 2022a 2022b the multivariate adaptive regression splines method mars has been demonstrated as a special and efficient meta modeling algorithm chen et al 2021 2022b choosing the superior optimal solution from the results of optimization models is a multi criteria decision making mcdm problem yu et al 2004 zhu et al 2016 several mcdm models have been adopted in the literature for defining the superior optimal design of water and environmental problems such as the technique for order preference by similarity to ideal solution topsis fu 2008 goal programming mamun et al 2015 and complex proportional assessment copras method roozbahani et al 2021 however as our knowledge allows there is no study in the literature applying copras to rank several alternatives resulting from applying multi objective optimization models to cpg related problems in this study we attempted to integrate the multi objective particle swarm optimization mopso wang et al 2012 with meta model mars and reservoir model nuft for a co2 geothermal reservoir evaluation to obtain the copras based rank optimal results boundary conditions have been widely known to influence fluid flow and associated heat transfer in subsurface formations holloway and burnard 2009 babaei and nick 2019 proposed a comparative evaluation of cpg performance in sedimentary aquifers between the open and close boundary conditions in which various standard vertical well placements were investigated and evaluated for both systems in this study we targeted high porous low permeable and thin reservoir blocks which widely exist in the potential geothermal region of north oman only horizontal wells were feasible for cpg operation in this thin formation with low permeability faults sealed the blocks and the boundaries could have different permeability to our knowledge horizontal well placement with various perforation lengths and distances had never been investigated for a cpg system three tiers of comparative analysis were performed to comprehensively investigate the impact of open and close boundaries on the performance of the horizontal well triplet placement for co2 storage and geothermal harvest operation first spatiotemporal behaviors of open and close geothermal reservoirs were analyzed for the base case with a fixed well triplet placement and injection overpressure second 200 combinations of well placement well perforation lengths and well space and overpressure were configured and simulated for both systems and a suite of technical performance indicators were computed from each of the 200 model simulations and comparatively analyzed third economic models were developed and used as the objective functions of well triplet optimization using the proposed methods finally economic objectives optimal well configurations and operations were compared between the two reservoir systems for the convenience of description we will refer open boundary and close boundary reservoir systems as ob and cb from here on 2 methodology 2 1 co2 circulated geothermal simulations 2 1 1 study field and hydrogeothermal properties the target geothermal reservoir was based on the shu aiba limestone formation in a fault block in the daleel oil field oman morettini et al 2005 where high underground temperatures were found al lamki and terken 1996 as shown in fig 1 the simplified model domain was 3 km 2 km and 20 m in x y and z directions at a depth of 1500 m the pressure and temperature of the reservoir were 17 mpa and 100 c respectively the rock properties were almost homogeneous with low permeability 10 14 m2 and high porosity 0 28 initially the pore space was saturated with 30 irreducible brine and 70 co2 in volume after co2 sequestration or improved oil recovery the caprock and bedrock are assumed impermeable while lateral boundaries could be permeable ob or impermeable cb depending on fault seals table 1 showed the other key rock and hydrothermal properties rajabi et al 2021 2 1 2 horizontal well triplet considering the low permeable and thin reservoir block where horizontal water flooding had been conducted in the oil recovery history morettini et al 2005 a horizontal well triplet was deployed to harvest heat energy by circulating co2 a horizontal injection well iw was located in the central x in parallel to the y axis and two parallel production wells pw were symmetrically positioned on each side of the iw fig 1 compared to a doublet a triplet can double the heat sweeping area and associated heat extraction limited by the size of the reservoir block only one triplet set can be accommodated the injection well is placed at the bottom while the two production wells are placed at the top to take advantage of co2 buoyancy in the heavier brine and full range of vertical sweeping area cold co2 30 c was injected under constant overpressure the additional pressure imposed upon initial pressure and the pressures of two pws were specified constant on their initial values during operations the injection overpressure in increased from zero to the specified value in the 1st year and remains at that value thereafter under this pressure gradient between iw pw hot co2 was extracted to the surface power plant went through a co2 turbine to generate electricity and cooled co2 was re injected to the reservoir the horizontal perforation lengths and well space injection overpressure were our targets to be optimized for both open and close reservoirs the open boundary of the model domain was realized by multiplying the volumes of the boundary grid cells by 106 to mimic the far field accommodating fluid outflow 2 1 3 nuft code the models simulating non isothermal two phase liquid gas and three components water salt co2 flow and transport in the porous formation were developed using nuft code a robust hydrogeological simulator developed by lawrence livermore national laboratory usa nitao 1998 nuft is equipped with a reliable equation of state for co2 thermodynamics and has been used in several co2 related reservoir modeling applications chen et al 2020 chen et al 2022a water thermodynamics is estimated by american society of mechanical engineers 2006 steam tables co2 thermodynamic properties density enthalpy viscosity are described by the correlations of span and wagner 1996 garcia 2001 and fenghour et al 1998 respectively miscibility is considered that is co2 concentration in the liquid phase and water concentration in the gas phase are simulated however salt nacl is only allowed to be dissolved in the liquid phase geochemical reactions between rock water co2 are not considered in our simulations as it is only considerable in long term hundreds of years molecular diffusion of each component in liquid and gas phases are specified by the method of reid et al 1987 capillary pressure and relative permeability of co2 and water are governed by the classic van genuchten correlations 2 2 model simulation experiment to explain the temporal and spatial behaviors of the geothermal reservoir under the horizontal well triplet operation we run a baseline case for both ob and cb respectively as shown in table 2 the iw and pw perforation was 800 and 1000 m respectively the iw pw distance was 1000 m and the injection overpressure was 12 mpa co2 circulations under this well placement and overpressure for both boundary conditions were simulated for 30 years the time series of key performance indicators including temperature decline and associated lifespan co2 mass injected produced stored and recovered heat energy were compared between ob and cb moreover the spatial distribution of pressure and temperature by the end of the operation was also comparatively analyzed in addition to the baseline case study 200 combinations of the four uncertain input parameters i e well space disl iw and pw perforation lengths iwl pwl and injection overpressure iwop were sampled using latin hypercube approach mckay et al 1979 from the 4 d input parameter space accompanied by their ranges table 2 six technical performance indicators including lifespan co2 mass injected injco2 produced prodco2 and stored netco2 total heat energy recovered totheat and average produced thermal flux flxheat in lifespan were calculated from each of the 200 reservoir models for both ob and cb table 3 based on the 200 sets of input output simulation data sensitivity and 2d contour map of each technical indicator to the input parameters were calculated and comparatively analyzed between ob and cb 2 3 global sensitivity analysis the global sensitivity of a dependent variable y to an independent variable x can be measured by sobol total order index sti the sensitivity indices are expressed as sobol 2001 1 s i i v a r e y x i var y 2 s i ij v a r e y x i x j v a r e y x i v a r e y x j v a r y 3 st i i s i i j i s i ij j i k j s i ijk where var represents variance s i i is x i sensitivity in the first order s i ij is the second order indices of x i and x j calculating their interactions contribution sti represents the total variance contribution of the input to the output variables including interactions between input variables the ranges of sti indices are 0 to 1 and when the sti 0 05 it was assumed as sensitive 2 4 meta modeling approach applying a fast meta model plays a prominent role in developing a time effective simulation optimization approach the multivariate adaptive regression splines mars model is a robust meta modeling approach that prepares a continuous prediction for each targeted function based on an arbitrary order of derivatives in addition this technique has the advantage of including different interaction levels at each step by maintaining the parent basis function within the analysis so that it can generate purely additive models to the complex models with an easy and fast procedure to apply this model a model consisting of the weighted sum of multivariate spline basis functions was fitted due to eq 4 in this formulation each spline was a basis function multiplied by its coefficient each basis function was in one of the following forms 1 a constant value 2 a hinge function the mars model chose the variables based on the knots of hinge functions 3 a product of different hinge functions these basis functions could model the interaction between various variables knafl and ding 2016 4 e y i i 0 n a i b i x i where a i is the coefficient predicted by the generalized cross validation fitting technique and the multivariate spline is the product of the univariate spline basis function defined by eq 5 5 b i x 1 x n s 1 r k b x i s k t s k 1 k r where i s k is a specific explanatory variable and the basis spline for that parameter puts a knot at t s k the predictive quality of the mars model is verified by cross validation of the fitted models before being used in the simulation optimization the coefficient of determination r2 was used to measure the match between the data driven mars model and the physics based nuft model 6 r 2 1 i 1 n x i y i 2 i 1 n x i x i 2 where x i and y i are the result for the sample i from physics and meta models respectively x i is the average value 2 5 the multi objective optimization framework 2 5 1 multi objective particle swarm optimization mopso model the particle swarm optimization pso model is a robust optimization approach introduced by kennedy and eberhart 1995 the pso model can be applied successfully for complex optimization models due to its advantages compared to other evolutionary algorithms 1 it has an accurate and fast convergence considering the fitness based on the probability evolution 2 the localized optimization is lowly probable due to the method s random search space wang et al 2012 the mopso model is a multi objective extension of the pso approach effectively used for complicated multi objective optimization models to implement the mopso model the following steps should be performed 1 generating the particle swarm s internal and external set 2 choosing the non dominated solutions from the internal particle swarm to input in the external set 3 calculating the variation of the internal particle and the mutation rate 4 defining the iteration times considering updated external archives set the mospo optimization model investigated optimal well placement and overpressure for ob and cb 2 5 2 objective functions formulating a suitable objective function is essential in optimization models yazdandoost et al 2021 nematollahi et al 2022a nematollahi et al 2022b the objectives of the mopso optimization model could be formulated as minimizing the yearly cost maximizing the yearly benefit and maximizing the net present value as shown by eqs 7 8 and 13 minimize 7 z 1 i 1 ls c t maximize 8 z 2 i 1 ls pr t where pr t is average yearly profit c t is the average yearly cost i is the year number and ls is the lifespan in each scenario pr t and c t can be formulated as eqs 9 and 10 based on the definition of the average yearly electricity generation w t mwh by eq 11 randolph and saar 2011 9 pr t w t e s r c o 2 t i c o 2 10 c t i j c o 2 t c o ij w t c o pt 11 w t 1 t avs t res pr o t e f where e is the electricity s price mwh s r c o 2 t is the average yearly co2 mass tons and i c o 2 is the income per ton co2 equal to 14 in the proposed model furthermore i j c o 2 t is the net injection of the co2 c o ij is the cost for the co2 injection tonco2 and c o pt is the cost of the power plant mwh in addition t avs is the average yearly surface temperature k as 301 15 k t res is the reservoir temperature k pr o t is the thermal energy production mwh ef is the efficiency of the mechanical system equal to 0 5 the relationship between produced heat at well bottom and surface power generation is simplified by the above equations as the focus of this study is on the impacts of the reservoir boundaries which are simulated in the geothermal reservoir models simulation of a complete cycle of a cpg system can be found in the study by levy et al 2018 then for estimating the cost of co2 injection eq 12 was used 12 c o ij b 1 r a ij b 2 b 3 where r a ij is the average rate of yearly injection tons b 1 b 2 and b 3 are 24 856 0 433 and 0 5 respectively calculated by carneiro et al 2015 in addition the net present value for different scenarios was calculated as follows maximize 13 n v t t 1 ls pr t c t 1 i t c con p t c var where n v t is the total net present value representing the cumulative benefits of electricity generation and co2 sequestration minus the total costs rajabi et al 2021 moreover c con is the fixed initial cost pt is the cost of power plant energy generation mw and c var is the variable initial cost 2 6 complex proportional assessment copras decision making technique complex proportional assessment copras method is a decisive multi criterion decision making mcdm model to rank the alternatives associated with the results of the multi objective optimization models this approach s superior optimal solution corresponds to the alternative with the highest utility pitchipoo et al 2014 zhu et al 2018 3 results and discussion 3 1 spatiotemporal behavior of a cpg fig 2 compared baseline case simulations between ob and cb regarding co2 injection production rates net injected rate and cumulative mass temperature and produced thermal flux and cumulative heat recovery in 30 years of operation the flow rates were almost stabilized after the initial three years in response to the linear increase of injection pressure from zero to 12 mpa in the 1st year and remaining constant after that although the co2 injection rate in ob was higher than that in cb by about 25 the production rate in ob was only about half of cb fig 2a consequently both net injection rate storage rate and associated cumulative co2 mass storage in ob were significantly more than those in cb fig 2b these results make sense since driven by the 12 mpa of overpressure injected co2 could migrate to the far field in addition to well extraction in ob while it could only be extracted by production wells in cb it was also found that the average storage rate in ob was around 50 kg s much higher than 30 kg s of the average production rate in contrast the co2 storage rate was less than 10 of the production rate in cb after 30 years of operation only 37 of the injected co2 was circulated for geothermal harvest in ob while it was 90 in cb table 4 as shown in fig 2c the reservoir heat depleted faster in cb than that in ob due to the higher circulation rate by the 30th year produced temperature dropped to 71 94 and 67 24 c and total recovered heat reached 11 54 and 22 24 1015 joules in ob and cb respectively as 80 c of cutoff temperature was applied to defining the geothermal lifespan which was 26 5 years in ob and 24 3 years in cb the heat recovered in their respective lifespan was 10 37 and 18 51 1015 joules table 4 and fig 2d these results suggested that even with a shorter lifespan the cb could recover much more heat energy than ob under the proposed well placement and operation scheme cb can yield more produced co2 mass 43 23 vs 23 95 mt and associated heat energy than ob within its lifespan table 4 figs 3 and 4 presented snapshots of spatial distributions of pressure and temperature on the top horizontal plane at 30 years for both ob and cb the pressure of iw and pw were specified at constant 29 initial 17 mpa plus 12 mpa overpressure and 17 mpa respectively as depicted in fig 3 the pressure distribution between iw and pw was similar between ob and cb owing to the same iw pw pressure gradient however it was quite different beyond the inter well region due to the different boundary conditions the pressure was relieved towards open boundaries but built up near the close boundaries correspondingly the cold co2 front extended substantially towards the back and front boundaries in ob but was well constrained in cb fig 4 3 2 technical performances of the open and close reservoirs the six technical performance indicators derived from the 200 nuft models were statistically analyzed for ob and cb the descriptions of the six variables were given in table 3 in the following sub sections stis of the six output indicators to the four inputs were utilized to rank the sensitivity of outputs to inputs fig 5 contour maps of each output variable with respect to the sensitive parameters sti 0 05 or the top two sensitive ones were plotted pairwise for 2d sensitivity analysis in fig 6 the relationships between the six indicators were also analyzed using the joint probability fig 7 3 2 1 sensitivity screening fig 5 showed the sti of the six output variables to the four input parameters for both ob and cb among the four input parameters well space disl was the dominant one affecting all six outputs of both ob and cb iw perforation length iwl had a more substantial influence on produced thermal flux flxheat in cb than that in ob sti 0 21 vs 0 11 however the other three outputs were nearly insensitive to iwl in both systems pw perforation length pwl showed moderate impacts on both produced co2 mass prodco2 and total recovered heat totheat only in ob sti 0 21 and slight impacts sti 0 07 0 08 on flxheat in both systems injection overpressure iwop moderately affected lifespan and flxheat in both systems sti 0 2 0 39 in the following subsections 2d contour maps of each of the six output variables in response to its pairwise sensitive parameters were presented for sensitivity analysis fig 6 sti values were labeled for associated input parameters to facilitate the comparative analysis between ob and cb 3 2 2 sensitivity analysis for lifespan fig 6 showed the impact of disl and iwop on geothermal lifespan for ob 1a and cb 1b ob s lifespan was longer than cb s because extracted co2 and associated heat flux were more minor from the reservoir with an ob than cb fig 8 apparently a larger disl led to a longer lifespan to achieve an optimal lifespan between 20 and 50 years disl should be between 600 and 900 m and be larger than 950 m for 5 and 15 mpa of iwop respectively the results indicated that a large disl should be paired with a high iwop to yield an appropriate lifespan in general iwop slightly moderately affected lifespan and its impact was obviously stronger at the bottom right area of the contour map large disl low iwop as iwop was usually restricted by geomechanical conditions of the reservoir well space should be carefully determined to obtain an optimal lifespan 3 2 3 sensitivity analysis for co2 mass figs 6 and 7 gave cumulative injected produced and stored co2 mass responding to the sensitive pairwise parameters in the respective lifespan of ob and cb as shown in fig 6 large disl would induce more injco2 and the increasing rate for ob was double of cb s this result suggested that more injected co2 migrated to the far field instead of the pws in ob as disl is longer less fluid was attracted to the pws and more co2 was driven across the boundaries considered as storage as the distance extended in contrast most of injected co2 was produced by pws in cb as there was no other way to escape a minor amount could be stored in the reservoir rock s pore space due to fluid and rock compressibility note that the reservoir pores were initially assumed to be filled with 70 co2 in volume and 30 of irreducible brine although iwl was ranked as the 2nd sensitive parameter its impact on injco2 was slight larger iwl could be led to more injco2 as shown in fig 6 prodco2 for ob was less than that for cb despite much more injco2 for ob as the same as injco2 disl was the dominant parameter for prodco2 however pwl instead of iwl was ranked as the 2nd sensitive parameter in addition pwl sensitivity became stronger for the ob reservoir especially in large disl areas given the large iw pw distance in an open reservoir system this result indicated that lengthening the pws could considerably promote co2 and associated heat production as most injected co2 was extracted from the reservoir with a cb its maximal netco2 was less than 8 mt given the largest iwl and disl fig 7 on the contrary the maximum of ob s netco2 reached over 90 mt even much more than its prodco2 3 2 4 sensitivity analysis for heat recovery as shown in fig 7 totheat shared a similar 2d sensitivity map with prodco2 as the total recovered heat was derived from the produced hot co2 mass again similar to prodco2 totheat from ob was substantially less than from cb flxheat however was affected by all four input parameters hence three 2d maps with respect to parameter sets between the most sensitive disl and each of the other three were presented in fig 8 flxheat was the averaged heat flux in lifespan calculated as totheat lifespan the 2d maps for ob shared similar patterns as for cb though ob s values were smaller owing to ob s lower totheat and longer lifespan contrary to output 1 5 flxheat was negatively correlated to disl as disl represented the sweeping area of the geothermal reservoir higher disl would yield a larger amount of injected produced stored co2 mass recovered heat as well as lifespan although both totheat and lifespan were positively correlated to disl the gradient of lifespan apparently overpassed totheat leading to a negative correlation between flxheat and disl it should be noted that shorter disl could yield higher flxheat but it also led to a shorter lifespan which was not economically feasible for a geothermal power plant if 20 years of lifespan were considered the minimal value the maximal flxheat would be about 15 mw and 25 mw for cb and ob respectively figs 6 and 8 these results suggested that a reservoir with ob could contribute more to co2 storage while cb could generate more geothermal electricity the other three parameters iwl pwl and iwop were all positively correlated to flxheat especially iwl and iwop showed considerable impacts on flxheat as either iwl or pwl had negligible impact on lifespan they should be designed as long as possible to maximize co2 storage and heat recovery iwop however should be determined according to geomechanical assessment and the feasible lifespan of the geothermal reservoir compared to ob iwl and iwop showed more significant impacts on flxheat for cb while disl s impact was reduced sti 0 461 vs 0 763 these results indicated that well space dominated the geothermal power plant capacity in an open system while the impact of iw overpressure was equivalent to well space in a close system 3 2 5 relations between the performance indicators the relationships between the six output indicators could be roughly derived from their respective correlations to the key input parameters as discussed in the aforementioned 2d sensitivity maps fig 9 gave a more direct and precise demonstration of their relationships using joint probability jp based on the 200 simulations to facilitate description each jp in fig 9 was denoted as jpxy hereunder where y and x represented the output number in the y and x direction of the figure overall jps of ob and cb showed similar trends for example outputs 1 5 were positively correlated to each other but negatively correlated to flxheat totheat was linearly correlated to prodco2 jp53 however there were prominent distinctions for some jps between ob and cb owing to their different co2 mass flows for example as injected and produced co2 flow rates for cb were nearly equivalent prodco2 showed a linear correlation to injco2 jp32 in fig 9b leading to a stronger linearity between output 2 5 than for ob fig 9a 3 3 meta model based optimization the mars meta modeling approach was utilized to fast predict the three economic objectives in the optimization process the 200 nuft model simulations dataset was used to train and cross validate the mars models fig 10 showed that the fitted mars models could predict these objectives accurately according to the high r2 values between mars and nuft model data pareto optimal solutions were derived by the coupled mars and mopso models the best superior optimal solution was selected using the copras model fig 11 presented the pareto optimal solutions of the three objectives for ob and cb the first four optimal solutions ranked by the copras model for ob and cb were listed in table 5 for the first rank the ranges of optimal benefit for cb and ob were 34 77 to 208 48 and 106 22 to 1332 79 million dollars respectively on the other hand the ranges for the optimal cost for cb and ob were 1 23 to 56 and 1 19 to 62 7 million dollars respectively according to the optimized objective functions the cb was subjected to substantially less benefit than the ob but relatively equivalent cost hence the ob was more cost efficient than the cb it was because much more co2 could be stored in ob while more co2 was circulated for electricity generation in cb given the current co2 storage credit and electricity price the difference in co2 storage income surpassed that of the geothermal electricity revenue between ob and cb the optimal values of disl iwl and iwop were close to their up limits for both ob and cb the optimal pwl for ob however approximated its low limit 400 m while it was around 1000 m for cb ob s revenue was significantly higher than cb s because co2 storage income was much more than electricity income to maximize the profit in ob the optimizing process would try to reduce produced co2 to increase stored co2 by minimizing the pw length 4 summary and conclusions co2 circulated geothermal harvest and co2 geological storage were numerically analyzed for a high porous low permeable thin fault block with an open and close boundary respectively key factors affecting the open and close systems were identified and their impacts were quantitatively assessed in addition technical and optimal economic performances of the horizontal well triplet placement and operation in the open and close reservoir systems were comparatively analyzed a summary of gained insights was given below well space was the dominant factor that controls the six technical performance indicators for both open and close reservoir systems a larger well space could increase lifespan injected produced and stored co2 mass and cumulative heat recovery leading to a smaller power plant capacity produced heat flux the large horizontal length of injection and production wells would facilitate co2 circulation and storage as well as associated heat flux and total heat energy production for both systems however the impacts were mostly minor only the impact of injection well length on heat flux for the close system and production well length on produced co2 mass and heat for the open system were found at a moderate level a high overpressure could shorten the lifespan moderately for both systems however it also moderately elevated the geothermal power capacity for open and close systems between the two systems the open reservoir required more co2 injection and accommodated much more co2 storage while the close reservoir could recover more heat energy but store few co2 the recovered heat is correlated to the produced co2 mass positively and linearly for both systems the positive linear correlations between the injected produced stored co2 mass and total heat recovery mass was much stronger for the close system than for the open system although more electricity revenue could be generated from the close system the open reservoir s overall profit was significantly higher owing to the co2 storage income future work may extend the comparative analysis to a heterogeneous formation for example the impact of economic parameters such as electricity price and co2 storage credit on optimal economic objectives for both systems should be further studied in addition the system with intermediately permeable boundaries between entirely open and close conditions may also deserve a comprehensive investigation credit authorship contribution statement banafsheh nematollahi conceptualization methodology software investigation resources data curation visualization writing original draft mingjie chen supervision conceptualization methodology software investigation data curation validation funding acquisition project administration resources visualization writing review editing mohammad reza nikoo methodology validation conceptualization writing review editing ali al maktoumi conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the study is funded by grants cl squ iggcas wrc 23 01 rc rg dvc wrc 21 02 and ig dvc wrc 22 02 the squ research group dr rg 17 is greatly appreciated for its technical support 
1744,this study presents a method to improve the reconstruction of historical flows on gauged and ungauged basins to do so a multi model weighted averaging of hydrological model simulations for a large spatial domain in the province of quebec canada is used the distributed hydrological model hydrotel was implemented over the region and covered 95 gauged basins an optimal interpolation oi assimilation method was first implemented as a baseline to improve the hydrotel flow simulations over the 95 basins then a series of multi model averaging techniques were applied to an ensemble of 144 hydrotel simulations that were generated by modifying parameter sets driving weather datasets and evapotranspiration modules the averaging methods were applied in a leave one out cross validation scheme where all 94 gauged basins were pooled together to compute the weights and those weights were applied to the 95th basin all basins were evaluated in such a manner and compared to the oi method implementing a year by year or shorter period weighting scheme instead of computing weights over all available data significantly improved the results this allowed the weights to better reflect each year s hydrological characteristics rather than compromising to improve the overall average the kling gupta efficiency kge and peak flow metrics showed that the granger ramanathan variant a gra was similar in performance to the oi method but did not have the drawbacks that oi can typically introduce the multi model application can also be further improved by adding more simulations from other hydrological models whereas the oi method cannot make use of such additional information thus hitting a performance plateau this study shows that it is possible to improve regional hydrological model simulations both for overall flows and peak flows and on the historical period for both gauged and ungauged basins this can then be used to better estimate risk in flood frequency analysis and other statistical analyses keywords multi model averaging technique optimal interpolation distributed hydrological model hydrotel prediction in ungauged basins data availability data will be made available on request 1 introduction using flood frequency analyses for the extrapolation of rare flood events e g 100 year floods is important when dealing with floodplain mapping and the design of hydraulic structures such as bridges and culverts extrapolating to such recurrences entails significant levels of epistemic uncertainty especially when dealing with relatively small time series considering that there is also an interest in conducting such analyses in areas where streamflow observations are not available at all there is a need for prediction in ungauged basins pub to rebuild historical streamflow pseudo observations hrachowitz et al 2013 however pub also leads to its share of challenges and uncertainties blöschl et al 2013 sivapalan et al 2003 while a regional flood frequency analysis could theoretically be used instead several shortcomings such as short time series and basins heterogeneity in terms physical properties climatology and hydrological processes can render this option sub optimal and even undesirable ouarda et al 2008 shu and ouarda 2007 for peak flows particularly other methods can be used such as in kim and shin 2018 where peak flow is estimated using the relationship between the ungauged basin s runoff coefficient and curve number which are estimated from donor basins these methods rely on regionalization of parameters to the ungauged sites and can be considered model independent these methods also only generate statistical descriptors of the flow regime flow indicators and do not allow generating complete time series hydrological modelling is an important tool to perform pub allowing to simulate streamflow time series that could ultimately serve as the basis for flood frequency analyses razavi and coulibaly 2013 lumped hydrological models can be applied on ungauged basins by using different types of regionalization methods such as spatial proximity or physical similarity arsenault and brissette 2014 on the other hand distributed hydrological models have inherent characteristics allowing them to simulate streamflow across entire regions under study including as many ungauged sub basins as needed while in theory this makes distributed models the ideal option when dealing with pub other difficulties such as the larger amount of physical and climatological data required the time needed for model setup and model calibration martel et al 2020 should not be overlooked even though lumped or distributed models can provide streamflow pub multiple sources of uncertainty remain such as the hydrological model s structure arsenault and brissette 2016 the climatological and physiographic data used papacharalampous and tyralis 2022 the calibration parameters and their equifinality arsenault and brissette 2014 and errors in hydrometric and meteorological observations used to calibrate the models troin et al 2022 thus in order to obtain the most accurate historical streamflow pseudo observations possible there is an advantage to post process the hydrological model outputs before conducting a flood frequency analysis lachance cloutier et al 2017 this type of post processing can be achieved with different methods the optimal interpolation oi lachance cloutier et al 2017 having shown to be a strong contender in essence oi is a statistically optimal method based on known theory which evaluates the spatial structure of errors in the distributed model response compared to the available observations and interpolates this error in such a way that the ungauged sites can be corrected this type of data assimilation technique has recently been shown to provide an immediate and significant gain in performance compared to the raw simulation from a hydrological model lachance cloutier et al 2017 ly et al 2013 but has traditionally been used in the field of meteorology heo et al 2018 oke et al 2010 phillips 1982 another way of dealing with these different sources of uncertainty is to address them through an ensemble of different hydrological simulations arsenault et al 2015 from both lumped and distributed models then different multi model averaging methods aim at obtaining an optimal weighting of each individual simulation that makes it possible to combine the strengths from several raw simulations to make gains in robustness and performance diks and vrugt 2010 arsenault et al 2015 showed that multi model averaging techniques generally provided better streamflow simulations than those of any individual model that is part of the ensemble on 76 of a set of 429 basins in the united states furthermore results showed that multi model averaging has the advantage of providing excellent performance without needing to identify a priori which hydrological model would be the best for the given basin finally the authors identify the granger ramanathan type c grc granger and ramanathan 1994 as the best solution for site specific flow estimation from the nine tested methods the same methods were also tested on 383 basins in china with the results again pointing to grc as being the best multi model averaging method in streamflow estimation at gauged locations wan et al 2021 arsenault and brissette 2016 applied multi model averaging concepts to ungauged basins but noted that the grc method which includes a bias correction term could lead to problems under regionalization due to the bias term scaling and thus implemented the granger ramanathan type a gra granger and ramanathan 1984 algorithm which does not require the bias term they found that regionalization of lumped hydrological models to ungauged sites generated streamflow that did not preserve statistics that could be corrected with multi model averaging and thus found that multi model regionalization of lumped models was not recommended however exbrayat et al 2011 and razavi and coulibaly 2016 showed that multi model averaging could perform well in regionalization depending on the region of interest as well as the number and type of contributing hydrological model when dealing with pub the combination of simulations from a distributed model can be more interesting since it will avoid the additional uncertainty from regionalization methods needed to transpose lumped models on ungauged sites however while combining a small number of raw simulations will provide improvements it may not be enough to surpass a method such as the oi in terms of performance to generate the most accurate historical streamflow pseudo observations to conduct a flood frequency analysis in ungauged basins the question remains what is the most optimal method to use our hypothesis is that using a sufficiently large sample of raw hydrological simulations will provide access to more flexibility and degrees of freedom that can lead to further performance gains with some diminishing returns in the right context this has the potential to outperform a method like oi which is limited to a one time but significant gain in performance furthermore using raw simulations from a distributed hydrological model would not be subject to the data assimilation techniques shortcomings previously raised the aim of this paper is to develop a methodology allowing to combine multiple raw simulations from a distributed hydrological model that outperforms the baseline data assimilation technique for the historical reconstruction of daily streamflow pseudo observations and annual maxima time series in ungauged basins section 2 of the paper presents the study site test bench and proposed methodology to reach the study s objectives results are then presented in section 3 and discussed in section 4 followed by a conclusion and future work in section 5 2 methodology 2 1 study site this study focuses on the meridional part of the province of quebec covering an area of approximately 726 000 square kilometers a selection of 95 basins shown in fig 1 from the 259 gauged basins operated by the direction de l expertise hydrique deh of the ministry of the environment and fight against climate change melcc was made this selection was designed to provide coverage of both south 32 basins and north 63 basins shores of the st lawrence river covering about 31 of the study area while keeping the hydrometric stations with longer observational records of good quality the average physical characteristics annual climatology and distribution of land use is provided in table 1 each of the basins will be used in a leave one out cross validation loocv to evaluate the proposed methodology in the context of ungauged basins 2 2 hydrological modeling hydrotel is a semi distributed hydrological model developed by fortin et al 2001a and fortin et al 2001b the deh exploits this model for its daily hydrological forecasts over 259 gauged and 28 035 ungauged basins and river reaches across the region of interest a strong motivation behind the use of the hydrotel semi distributed model is that the deh has shared the complete calibrated platform used operationally for the region of interest see fig 1 this allowed the development of a test bench based on multiple calibration strategies involving different parameters input meteorological datasets and potential evapotranspiration formulas that also enable to emulate the operational limits fortin et al 2001a provides a complete description of hydrotel s required inputs and simulation of hydrological processes which are summarized hereafter in terms of input variables hydrotel requires drainage structure land use soil type from high resolution remotely sensed data as well as distributed meteorological inputs i e total daily precipitation in water equivalent daily minimum and maximum temperature each basin gauged or ungauged is split into multiple homogenous sub basins for which all hydrological processes e g snowmelt and evapotranspiration are computed independently gridded meteorological datasets are used as inputs and corrections are also made based on each sub basin s average elevation precipitation is also separated into rain and snow components on each sub basin with a linear interpolation using both minimum and maximum daily temperature as well as a threshold temperature for the separation between rain and snow which is calibrated the evolution of the snow cover s characteristics is done with a mixed degree day and energy balance method however the net absorbed solar radiation is simply estimated from a degree day methodology three land use classes are considered for the snowpack simulation with distinct melting factors for coniferous forests deciduous forests and open areas the 95 selected basin s land use types described in table 1 are split into these three categories accordingly the hydrotel model has the option to switch between six potential evapotranspiration pet formulas but only three were selected in this study hydro québec linacre and mcguinness the selection of these three pet formulas was made with the goal to provide a wide range of the inter model variability needed for this study while limiting the number of calibrations to be performed the first is an empirical equation developed over local basins by hydro quebec fortin 2000 and only requires minimum and maximum air temperature as inputs the linacre 1977 formula is derived from penman and keen 1948 and requires dew point and air temperatures as well as both elevation and latitude of the station as inputs mcguinness mcguinness and bordne 1972 is a radiation based formula that only requires mean air temperature as well as extra terrestrial radiation which can be estimated using the basin average latitude and the julian day it can be noted that oudin et al 2005 compared 27 evapotranspiration formulas including linacre and mcguiness and showed that mcguinness provided the best results for hydrological modeling over 308 basins located in france australia and the united states the vertical water balance is conducted using a three layers soil model allowing to approximate the physical macro processes involved during the infiltration and vertical redistribution of water over a soil column the first and relatively thin layer 10 to 20 cm is affected by the soil evaporation and controls the surface runoff the second layer is a transition zone between the first and third layer and produces delayed flows the third layer is typically saturated and provides the base flow all three layers can be affected by transpiration depending on land properties the combined flow from the vertical water balance is then routed using a reference geomorphological hydrograph specific to each sub basin this geomorphological hydrograph is derived using the kinematic wave approximation with a reference flow depth and is obtained using two different land uses forested and open areas for which different manning s roughness coefficients are used flow through the hydrographic network is also computed using the kinematic wave estimation these computations are performed for each river reach based on their respective characteristics namely the length width slope and manning s roughness coefficient however when the reach is a lake or a reservoir the classical continuity equation is used instead and the flow is estimated using a flow depth relationship depending on the width of the lake outlet 2 3 meteorological datasets a selection of meteorological datasets was made with two goals in mind 1 a reasonably long temporal coverage to conduct a flood frequency analysis and 2 diversity among the types of datasets a total of three different meteorological datasets were thus selected to provide precipitation and temperature inputs to the hydrotel model the melcc gridded observed dataset the era5 reanalysis and the scdna weather station product the common period for these three datasets was from 1979 to 2018 and was kept for this study daily precipitation minimum and maximum temperature were extracted for all three datasets and used as inputs for the various calibrations of the hydrotel model the daily observation gridded dataset developed by the melcc dcaq bergeron 2016 was selected as it is currently used as inputs in the hydrotel model for the deh daily forecasting quality controlled weather stations from both melcc and environment and climate change canada eccc networks were used for the interpolation providing coverage for the period between 1961 and 2021 ordinary kriging interpolation is used to obtain the best non biased estimations without requiring the mean over the entire domain nor assuming its stationarity wackernagel 2003 this method enables the consideration of a local average through the use of a restricted interpolation neighborhood bergeron et al 2016 li and heap 2014 the era5 c3s 2019 hersbach et al 2020 reanalysis dataset is also used as inputs to hydrotel era5 is the fifth generation of the european centre for medium range weather forecasts ecmwf which provides global hydrometeorological and atmospheric variables from 1950 to present this reanalysis provides hourly outputs at a horizontal resolution of 0 25 0 25 tarek et al 2020 demonstrated that hydrological modeling using era5 as inputs to hydrological modeling provides equivalent performance to observations over most of north america including the region of interest the weather station product used is the station based serially complete dataset for north america scdna tang et al 2020 covering the 1979 2018 period this dataset includes 27 276 stations for which a strict quality control is performed and the missing data is reconstructed using different strategies such as machine learning quantile mapping and spatial interpolation while the observed weather network used to generate the melcc gridded dataset could also have been used it was decided that it would only bring marginal additional information compared to its interpolated version limiting the targeted degrees of freedom 2 4 development of the test bench a test bench was developed using the platform provided by the deh to test the work hypothesis the hydrotel parameters objective function and optimization algorithm for the calibration of the different hydrotel models will be covered in this section followed by the calibration strategy to generate a total of 144 different calibrations over each of the two regions of interest i e north and south domains 2 4 1 hydrotel parameters hydrotel has a total of 27 internal parameters that can be adjusted based on previous work done by turcotte et al 2007 16 of these parameters can be fixed considering their low impact on the calibration objective function or due to their additive or multiplicative corrective nature applied to input data the remaining eleven parameters to be calibrated are described in table 2 along the eleven free parameters described in table 2 two additional fixed parameters were modified to provide the desired flexibility within the hydrotel calibrations the reference flow depth for the geomorphological hydrograph and a multiplicative constant for the lake outlet s width for the flow over the terrestrial part of the basin two different reference flow depths were used to consider the relationship between flow depth and the strahler stream order previous testing allowed selecting optimal flow depth values for the study site 0 006 and 0 010 m and showed that a higher strahler number performed better with smaller flow depth and vice versa for the flow through the hydrographic network the large number of lakes especially on the north shore of the st lawrence river has shown to have a significant impact on the resulting hydrographs previous testing by the deh showed that using larger width for the lake outlet allowed it to provide a more realistic hydrograph in this context to account for this a multiplicative constant of 1 82 applied to the lake outlet s width was found to provide the best results in this study both values of 1 00 and 1 82 were considered 2 4 2 objective function and optimization algorithm to evaluate the performance of the hydrotel model during its calibration and validation processes the modified kling gupta efficiency kge gupta et al 2009 kling et al 2012 objective function was used and is defined as follows 1 1 k g e r 1 2 α 1 2 β 1 2 where r is the linear correlation coefficient α is the ratio of the coefficients of variation and β is the bias ratio all these values are dimensionless and are computed between observed and simulated streamflow the kge ranges from a value of to 1 where 1 represents a perfect fit between observed and simulated streamflow as suggested by huot 2014 the best suited optimization method for the hydrotel model is the dynamically dimensioned search dds algorithm tolson and shoemaker 2007 a total of 500 model iterations was chosen as a compromise between good enough calibration quality and time to complete the most combinations possible the goal here is not to obtain the best possible local optima but rather to generate good enough calibration that will provide additional flexibility and degrees of freedom when combining all available simulations using a multi model averaging method 2 4 3 calibration strategy to obtain the desired level of flexibility from the hydrotel simulations multiple calibrations of hydrotel parameters were conducted using different meteorological datasets each of the hydrotel calibrations follow the procedure detailed in fig 2 all combinations of meteorological datasets dcaq era5 scdna flow depth 0 006 and 0 010 m lake s outlet width multiplicative constant 1 00 and 1 82 pet formulas linacre hydro québec and mcguinness calibration period 1979 1987 1988 1997 1998 2007 and 2008 2017 and split between the north and south shores were calibrated following the procedure described in the previous two sections resulting in a total of 288 different hydrotel calibrations with 144 calibrations for each of the north and south shores while the north and south shores were calibrated independently they were ultimately combined resulting in 144 possible simulations to be averaged to ensure a good representation of both north and south shores of the st lawrence river two thirds of the available stations in both areas were randomly selected for the calibration and the remaining third for the validation this random selection ensured that only hydrometric stations with at least 5 years of records over the current calibration period e g 2008 2017 and was kept for all combinations of hydrotel models using the same period 2 5 proposed methodology the proposed methodology is presented in the flow chart in fig 3 and described in the following subsections 2 5 1 baseline the optimal interpolation optimal interpolation oi is a proven data assimilation technique with similarities to kriging tabios and salas 1985 used in the fields of meteorology fortin et al 2015 and hydrology lachance cloutier et al 2017 when dealing with streamflow the oi aims at combining available local observations with simulations from a distributed hydrological model referred to as the background field at each hydrometric station the difference between the observations and the simulations is first evaluated a log transformation is typically applied to avoid obtaining negative streamflow the oi technique consists in exploiting the spatial correlation of the error to interpolate its value on all sites of interest i e ungauged basins for each site corrected values are obtained by 2 z e m e i 1 n w i z i m i where z e and me are respectively the corrected and the background field values at an estimation site e and zi mi is the difference between the observation and the background field at a given hydrometric station i the weights wj are obtained by finding the solution to the system of linear equations 3 b i σ o 2 σ b 2 w b where b represents the correlation matrix of the error of the background field between the reference sites i and j i is a diagonal unit matrix σ o 2 and σ b 2 are the variance of the observation and background field error respectively w is the vector of the weights for each reference sites and b is a vector of the correlation between the reference sites and the estimation sites e the ratio σ o 2 σ b 2 was fixed to 0 15 following trial and error calibration for the daily time series of streamflow the oi analysis is independently conducted at each time step the initial calibration of the distributed hydrological model provided by the deh was post processed using this methodology and will serve as the benchmark to evaluate the proposed methodology 2 5 2 multi model averaging methods a total of five multi model average methods were tested in this study and are summarized in table 3 these different methods allow estimating the optimal set of weights except for the simple arithmetic average avg method which simply provides equal weights to all simulations for all 95 individual hydrotel simulations to combine them together this multi model averaging approach aims at combining the different simulations strengths to outperform each individual simulation arsenault et al 2015 and wan et al 2021 showed that weighting methods generally perform better than the individual hydrological model simulations the simple arithmetic average avg simply consists in assigning equal weights to each simulation the bates and granger averaging bga bates and granger 1969 method relies on the assumption that the simulations are unbiased and that their errors are uncorrelated the bga method computes weights wbga as follows w bga 1 σ i 2 i 1 n 1 σ i 2 where σi refers to the variance of the simulated streamflow from simulation i finally the granger ramanathan methods a b and c granger and ramanathan 1984 methods were employed in this study method a gra is based on the ordinary least squares ols algorithm and computes its weights wgra as follows w gra q s i m t qsim t 1 qsim t q o b s where qobs and qsim are the observed vector and simulated matrix of streamflow respectively variant b grb is similar to the gra but the ols algorithm is constrained to ensure that the sums of the weights are equal to unity variant c grc is unconstrained but it incorporates a bias correction of the average streamflow using a constant term initially the bayesian model averaging bma neuman 2003 was considered in this study however it was found that it was unable to converge to an acceptable set of weights when using all 144 hydrotel simulations additionally due to its iterative nature the bma s long computing time made it impractical to use throughout the analyses two different metrics were used to evaluate the performance of the various multi model averaging methods the kge see equation 1 and the normalized root mean squared error nrmse of the daily annual maxima streamflow qx1day while the kge provides a measure of performance across the whole hydrograph the nrmse qx1day metric aims at larger values which are more closely related to the values typically used in a flood frequency analysis however the nrmse qx1day does not take the timing of the events into consideration 3 results 3 1 calibration results the first step was to generate an ensemble of hydrotel simulations with as much variability as possible to maximize the flexibility of the multi model averaging approaches in total 144 simulations were generated by combining various meteorological data sources and model physiographic parameters as illustrated in fig 2 the calibration results for each basin y axis and each model setup x axis are presented in fig 4 most cases generate acceptable and generally good quality kge scores meaning that the calibrations performed well on those cases calibration kge scores are acceptable for most basins considering the regional calibration method employed which sacrifices basin specific skill for overall robustness over the entire domain a clear pattern is also seen wherein every 16 simulations a significant change in performance is observed this structure reflects changes in the input meteorological data where the dcaq era5 and scdna data appear in succession the selection of a meteorological dataset for calibration is the element that produced the most variability within the results as can be seen by this repeating cycle of 16 simulations the parameters related to the hydrotel physiographic setup were less impactful and only generated small differences within the simulated hydrographs 3 2 multi model averaging using all basins once the 144 calibrations were produced the simulated hydrographs were generated and combined using a variety of multi model averaging algorithms using a leave one out cross validation loocv each of the 95 basins was considered pseudo ungauged and the simulated flows were combined for the pseudo ungauged basin the kge and nrmse qx1day were computed and reported in fig 5 first the optimal interpolation oi allows a significant gain in performance compared to the raw hydrotel simulations hyd both in terms of higher kge scores and lower nrmse values for qx1day furthermore the multi model combinations were not able to improve upon the raw simulations as significantly as the oi but some small improvements could be noted over the raw simulations for all but the grc method however either no gains or only marginal gains were obtained no matter what multi model averaging method was used results are also presented spatially for the oi simple average avg and the gra weighting method which was considered the best multi model averaging method here in fig 6 however no striking pattern emerges from these results all multi model averaging methods seem to perform similarly over the study domain 3 3 multi model averaging using a year by year approach the next step was to attempt to extract more information from the data by performing multi model weightings for each year instead of on the entire period of the available datasets results are shown in fig 7 and spatially distributed results for methods oi avg and gra again are shown in fig 8 it is clear from fig 7 that there is a significant additional gain in performance when computing weights year by year giving more flexibility to the multi model averaging algorithms to fit the optimal weights for the given year and not forcing it to compromise to be adequate for all years in the year by year approach some multi model averaging methods clearly respond better than when all data was pooled together notably the gra and grb methods gra was slightly better in this respect and was used for the rest of the study it can be seen in fig 8 that gra performed better than the raw simulations for 67 and 63 out of 95 basins for the kge and nrmse qx1day respectively while the oi performed better than the raw simulations for 70 and 66 basins out of 95 for the kge and nrmse qx1day respectively therefore the gra seems to perform at least as well as the oi for this study area and hydrological model simulations both in terms of overall flow simulation kge and peak flows nrmse qx1day 4 discussion 4 1 improvement using the optimal interpolation optimal interpolation oi aims to improve the simulation results overall without regard to discontinuities in the generated hydrographs since the domain is composed of basins of all sizes peak flows occur at different dates even when driven by the same meteorological conditions due to flow routing in larger basins oi aims to apply spatial corrections at each time step disregarding the state of specific hydrographs this means that a compromise must be made during the interpolation whereby some peak flows are artificially reduced and others are increased simply due to the timing of nearby basins that are utilized in the optimal interpolation nonetheless the method provides good results on average which is not surprising given that for this purpose oi is a statistically optimal method the oi simulations were consistently better than the raw simulations for a majority of basins 70 to 75 of basins both in terms of kge and nrmse qx1day as seen in the top of the boxplots of figs 5 and 7 this method is therefore recommended as a good approach for processing distributed model flows as there is a significant gain in overall and peak flow estimations during this study an attempt was made to combine several simulations post processed by the oi not shown with the multi model averaging methods proposed these tests showed that there was a gain in robustness which was on average better than the individual simulations with oi the robustness comes from the fact that it is not possible to select the right simulation from the start when dealing with ungauged basins the gains were only marginal however regardless of the weighting method used with similar results obtained with the avg method one disadvantage of processing oi simulations in a multi model framework is that multi model weighting schemes maximize performance by using each simulation s strengths to reduce the overall error this requires some flexibility and variety in the ensemble of members that are used during the weighting however oi applies corrections in such a way that the resulting hydrographs are much more similar leaving fewer degrees of freedom to the multi model averaging methods to perform efficiently therefore adding more oi simulations to the multi model averaging process only produces asymptotic performance gains in an operational setting if multiple oi simulations are available it is recommended to use a simple average of all these simulations to make gains in robustness but the gains in performance are expected to be marginal therefore the multi model approach can provide better results than oi due to the fact that more information is available in the entire process for multi model methods than what oi can use 4 2 comparing the different multi model averaging methods when using the multi model averaging methods on the 144 simulations it was found that significant improvements in simulation accuracy could be observed even with the simplest averaging methods this is in line with similar studies using lumped hydrological models arsenault et al 2015 one exception is grc which contains a bias element that is not specific to each site this constant bias ends up introducing errors to all basins except for the basins whose flows are near the ensemble average with the exception of grc the other results are in line with what was found previously in the literature where the avg and bga methods perform generally worse lower nash sutcliffe values larger biases than with the gra and grb methods wan et al 2021 furthermore methods such as gra and grb performed better than the others especially so when the weights were computed on a yearly basis this approach of computing one set of weights per simulation year and shorter periods as described in the following section allowed the weighting algorithms to adapt to specific hydrometeorological conditions over the domain and thus allow for more accurate weighted simulations this methodology could be criticized for certain contexts as it goes against the prevailing notion that models should be as good as possible in all conditions and the current methodology implements a form of overfitting that would not be applicable for simulation of longer time series however when considering the goal of performing a flood frequency analysis especially over ungauged basins overfitting is not necessarily an issue we argue that it is an advantage the goal is to have the most optimal streamflow simulation with as little uncertainty as possible and by simulating these hydrographs on a year by year basis with the most precise information as possible for each year the resulting hydrograph is of higher quality than if the weighting was performed with a single set of weights for the whole period representing the long term compromise this method is thus applicable in this study since the models and methods are not used for forecasting but for historical simulations therefore overfitting is not an issue in this study 4 3 improvement by computing weights over shorter periods as demonstrated with the comparison of boxplots from figs 5 and 7 and maps from figs 6 and 8 there is a clear gain in performance by averaging weights over a shorter period with significant gains obtained by going from the weights for the whole periods to a year by year basis it was of interest to evaluate the limit of using an even shorter period and to determine at which point overfitting would start occurring using the gra method which provided the best results in this study six different periods were tested for the computation of the weights year by year season by season i e every three months starting with january february and march month by month 2 weeks by 2 weeks week by week and day by day results shown in fig 9 indicate that by decreasing the period up to the month by month period there is an increase in performance for both tested metrics by going beyond the year by year period the multi model averaging method also starts to perform similarly to the oi method however when going beyond the month by month period weights are starting to be overfitted resulting in poorer performance when conducted in a cross validation context like the one in this study for instance the day by day period not shown in fig 9 since all the values were below the 0 5 kge value is strongly impacted by overfitting since there 144 weights to fit 95 values only to determine if a pattern exists in the improvement observed in fig 9 we compared these results with basin descriptors presented in table 1 however we found no correlation between any of the basin descriptors and the kge or nrmse qx1day results obtained in this study for all periods used to compute the weighting i e year by year up to week by week notably arsenault et al 2015 and wan et al 2021 conducted geographic analyses and identified low performance basins located in arid regions with total annual precipitation below 500 600 mm year this could be attributed to the hydrological model being more suitable for humid climates and areas with strong snow accumulation in our study the driest basins had an average annual precipitation of around 800 mm year which is significantly above the threshold suggested by arsenault et al 2015 and wan et al 2021 this finding may explain why almost all basins exhibit improved results from the computation of weights over shorter periods 4 4 using more diverse hydrological models when it comes to adding more flexibility to the sample of simulations different formulations and models for the different hydrological processes can also be used unfortunately the flexibility offered by the distributed model used in this study was limited to different potential evapotranspiration formulas in this regard the focus has been put on different types of calibration and datasets to obtain the desired flexibility in our sample it is expected that different formulations and models for the hydrological processes or even different hydrological models altogether could achieve the desired results as well to test this hypothesis additional tests were conducted by calibrating three lumped hydrological models only using the melcc dataset and the oudin pet formula oudin et al 2005 gr4j with the cemaneige snow module perrin et al 2003 valéry 2010 hmets martel et al 2017 mohyse fortin and turcotte 2007 even though the use of lumped models has its own shortcomings when it comes to dealing with prediction in ungauged basins pub such as the need to regionalize parameters they still allow us to glean some insights on the benefit of adding completely different hydrological model structures the multi model average methods were applied on all three lumped hydrological models as well as the raw hydrotel simulation four simulations in total it can be seen in fig 10 that greater improvements were obtained in comparison with the different simulations from hydrotel exceeding the oi in terms of performance this suggests that hydrotel did not provide sufficient flexibility in its structure limiting the hydrograph variability to that of the various datasets and calibration schemes thus combining different hydrological models both lumped and distributed or using a model with more flexibility in its structure could allow it to reach the desired gains in performance hydrological models have varying strengths and weaknesses and no single model outperforms others in all basins in this study three lumped hydrological models were tested and gr4j hmets and mohyse achieved the best kge values respectively on 82 11 16 84 and 1 05 of the basins as suggested by wan et al 2021 combining multiple hydrological models calibrated with different objective functions can lead to more efficient and robust results as observed in this study with significant improvement obtained using multiple hydrotel calibrations figs 5 to 9 and different hydrological models fig 10 arsenault et al 2015 also demonstrated that even models that yield poorer results across all basins should still be included as they can contribute to the multi model averaging performance they showed this using a multi objective optimization approach aimed at maximizing the objective function and minimizing the number of simulations in the multi model averaging with even the worst performing model also mohyse making regular contributions it should be noted that the oi used as a baseline in this study is conducted using a regional calibration from hydrotel that is not specifically calibrated at each local site on the other hand the lumped hydrological models used in this additional analysis are calibrated locally at each site while the results showed improved performance by using these lumped hydrological models over the oi it can be expected that the simulation at ungauged sites from a regional model like hydrotel are likely to be more robust than those from lumped models that would require to be regionalized as demonstrated in the previous section additional gains in performance can be obtained by computing weights over a shorter period e g year by year season by season or month by month it can be noted that improvement is obtained even up to the day by day period this is likely due to the fact that there are only 4 hydrological models being combined resulting in 4 weights for a minimum of 95 values at the day by day period avoiding overfitting however the gain in performance when combining the four hydrological models fig 10 compared to the combination of all 144 hydrotel simulations fig 9 is much smaller this is likely because the four hydrological models are already providing most of the flexibility needed reducing the potential gain in performance to be made by computing weights over shorter periods this finding suggests that the flexibility needed to increase the multi model averaging performance can be obtained in different manners namely 1 increasing the number of calibrations from a given hydrological models by using alternative parameters meteorological datasets or model structure 2 increasing the number and variety of hydrological models both lumped and distributed 3 reducing the period at which to compute the weights of the multi model averaging 4 5 flood frequency analyses comparison considering that the main objective of this study was to generate the most accurate historical streamflow pseudo observations for conducting a flood frequency analysis in ungauged basins additional analyses were conducted to evaluate the proposed methodology to carry out these analyses four different basins were selected including one large and one small basin located on the north shore as well as one large and one small basin on the south shore all four selected basins had complete time records between 1979 and 2017 the best overall multi model method gra which uses a year by year period gra y for computing the weights was compared with oi and observations table 4 shows the results of kge and nrmse qx1day values for the four chosen basins these four basins exhibit a similar pattern to the boxplots illustrated in fig 9 improvements in performance can be observed up to the season by season or month by month period followed by a decline although this trend is apparent in the kge results some differences are noticeable for the nrmse qx1day particularly in the basin 061022 the simulations of the annual maxima series qx1day were first compared as these are directly used by the flood frequency analysis the results are shown in fig 11 however it is important to note that not all basins provided satisfactory results for either the gra s the oi or both overall it was observed that both methods provide good estimations of observed streamflow in a loocv context gra y does not typically lead to overestimations of qx1day while oi tends to slightly overestimate the results for the larger basins fig 11 a and b however gra y underestimates the results for basin 030 282 fig 11 d using the qx1day time series presented in fig 11 flood frequency analyses were conducted and the results are presented in fig 12 the gumbel distribution was used and its parameters were adjusted using the maximum likelihood approach in all cases both methods are able to provide good results mostly within the 95 confidence intervals of the observations except for the lower return periods in basin 061 022 fig 12 b with respect to the selected basins the gra y method tends to provide results closer to observations while oi tends to slightly overestimate the values while remaining within the confidence interval boundaries in line with results obtained in fig 11 however this is not necessarily the case for all basins where different behaviors are observed the aim of this analysis was simply to validate if the estimations provided by both methods led to satisfactory results for a flood frequency analysis as a reminder the results obtained for the multi model approach could be significantly improved if more structural variability was possible for hydrotel as demonstrated with results and discussion in section 4 4 and fig 10 thus while already providing satisfactory results this method can still be improved beyond what is obtained in this paper 4 6 what is the best method to use in this study raw simulations were improved through two approaches the optimal interpolation oi as implemented by lachance cloutier et al 2017 was used as the reference case and the multi model averaging method both methods have advantages and shortcomings that need to be mentioned first it is important to note that this study implements a two step approach to estimating flows at ungauged basins on a regional scale typically regionalization methods perform either 1 model parameter regionalization at ungauged sites 2 distributed model regional simulations or 3 for hydrological indicators statistical methods such as regression and kriging have also been proposed model parameter regionalization requires modelling each basin individually and simulating them with a hydrological model which is parameterized using donor basin parameters this method introduces high levels of uncertainty and introduces major spatial discontinuities between neighboring basins depending on their physical characteristics arsenault and brissette 2014 razavi and coulibaly 2013 the distributed hydrological model method performs reasonably well in this study raw hydrotel simulation but it is also a compromise solution where the model is made to simulate flows adequately on all sites by allowing loss of skill on some of the basins kumar and samaniego 2013 finally statistical methods to regionalize peak flows have been proposed but suffer from the same limitations as model parameter regionalization in terms of uncertainty perez et al 2019 recently deep learning approaches have started being used to estimate streamflow at ungauged sites but these have been applied in large scale applications of multiple basins and not on a regional domain with a wide array of basin scales arsenault et al 2023 kratzert et al 2019 a combined approach was implemented by wang et al 2023 where a distributed model had its parameters regionalized using random forest methods in china with success therefore the two methods presented in this study are post processing steps that take the result from a distributed regional model and improve them by reducing the effects of the compromise of regional calibration the oi is a simple data assimilation technique that has multiple advantages it is a statistically optimal method based on known theory provides smooth spatial corrections by taking all spatial components into consideration can be conducted on each day independently and requires low computational power however this method also has various shortcomings that should not be overlooked breaking down the spatial structure of data discontinuities in the data smoothing of maximum events does not provide correction for sites where the closest observation is too far and generation of inconsistent reaction times since the method does not guarantee mass balance preservation essentially oi can lead to discontinuity in the hydrograph because the error field is interpolated each day based on the differences between the observations and the model simulations at the gauged sites the error field is then spatially applied to all simulated discharges in the modelled region however this can cause problems when the hydrological model output is dependent on exogeneous variables such as basin size indeed a large basin could have a delayed response multiple days to a precipitation event whereas a small neighboring or nested basin would react on the same day therefore the error field would correct the large peak flood at a later date which could then impose a large yet unnecessary correction on the smaller basin also significant discontinuities can be introduced since the closest observed hydrometric stations can vary over time when some enter service and others are shut down while a technique like oi provides significant gains in terms of performance over the raw simulation from a hydrological model its various shortcomings are undesirable when conducting a flood frequency analysis especially on ungauged basins the multi model averaging method has the advantage of not having the shortcomings from a typical data assimilation method such as oi since the time series are continuous except during transitions when weights change and depend on blending model outputs which does not produce temporal inconsistencies contrary to the oi sites far away from observations will also be corrected since the same weights will be applied to all simulations regardless of their location also the multi model method does not perform any smoothing of time series since the same weights are applied each day which means the timing of hydrographs peaks is preserved furthermore additional degrees of freedom can be relatively easily added to improve its performance by adding more simulations and or by computing the weights over a shorter period however temporal breaks can end up introduced when using weighting based on shorter periods e g year by year or month by month in an operational context the challenge lies in the ability to generate a limited number of simulations that are sufficiently different from one another to combine their strengths while typically using the same hydrological model used by the agency or organization to limit overhead related to maintenance and training on multiple models there are other shortcomings what should not be overlooked as well this method does not adjust to the information available at measurement sites it has no guarantee of mass balance preservation it can propose negative weights or weights not adding up to 1 which can have a dubious physical meaning and it scores highly on average values kge but can be less efficient on peak values it was hypothesized that accessing a wider variety of simulations would give more flexibility to the multi model averaging scheme which would then allow for more accurate simulations by design this method would not create discontinuities except at the beginning of each period due to the weights being recomputed if a shorter period than the full period is used currently the multi model approaches using the 144 hydrotel simulations achieve similar performance levels as oi and better results when the period is reduced while a relatively large number of simulations were used they were mostly based on various climatological datasets and different calibrations ideally changes in model structure e g snowmelt routing and infiltration modules could have provided more variety and potentially helped improve the results even further as suggested by the results of the previous section however hydrotel s internal mechanics could not be modified in this study a potential advantage of the multi model average method over the oi that was not investigated in this study would be the capacity to apply the weighting in a context where observations would not be available for instance in a climate change impact study using future simulations pre computed weights for the multi model averaging could still be used 4 7 limitations this study was performed on a regional distributed model and the results were evaluated on pseudo ungauged sites however the gauged basins are typically relatively large the smallest was 44 km2 and the median was almost 1000 km2 it is therefore possible that the results do not scale well with much smaller size basins since this has not been tested however this is also true for the oi method application therefore no strong conclusion on the generalizability of either method can be made the results seem to point to the methods being applicable without any correlation to basin size but this cannot be proven at this time this should be tested in future studies where very small gauged basins would also be included another limitation is that of observed flow uncertainty observed flow measurements are known to be highly uncertain and noisy which can lead to errors that propagate throughout the process for example the multi model weights are computed by minimizing differences between the weighted streamflow and the observed flows any errors or biases in the observed flows would then propagate into the multi model weights and would affect the quality of the simulation on the gauged and ungauged basins however by taking weights over longer periods the epistemic uncertainties should be abated somewhat leading to a more robust signal on the other hand oi generates error fields that are computed each day so it could be prone to more uncertainty emanating from the observed flow random errors therefore obtaining a good estimate of observed flow uncertainty would help finding more robust methods that could take this uncertainty into consideration during the calculation of weights finally this study investigates the performance of the simulation methods using two metrics kge and nrmse qx1day it is important to note that the hydrological model was always calibrated using kge and therefore is expected to reproduce overall hydrographs well with a smaller emphasis on the peak flows it could have been possible to calibrate on an objective function that weights the peak flows more heavily in order to maximize performance of the qx1day metrics but this would have been at the expense of the other flow regimes therefore the calibration on kge is a compromise solution that can still provide estimates of qx1day with a good level of confidence 5 conclusion estimating streamflow and peak flows at ungauged sites is still a challenge today due to the various sources of uncertainty and highly spatially heterogeneous nature of hydrological processes in this study we attempted to provide the most precise hydrographs possible on a historical period and using a distributed hydrological model in such a way that it would be possible to process the hydrological model simulations to obtain accurate hydrographs on the entire region using a leave one out cross validation methodology applied to 95 basins we were able to show that the hydrotel model simulations could be substantially improved using optimal interpolation oi however some drawbacks associated with this method led us to attempt a second method the alternative method was the application of multi model averaging techniques to a large variety of hydrological model simulations some multi model methods performed better than others but the gra method showed similar performance to that of oi without any of the drawbacks this means that the historical period hydrographs could be generated with more confidence which can then lead to better estimates of peak flows this is an important step towards modeling peak flows for flood frequency analysis given the fact that these results were all obtained considering the basins as ungauged there is a high confidence that the method can be applied over the entire domain covered by the hydrotel model this also means that estimating flood risk at these ungauged basins can be made with higher confidence interestingly the multi model averaging approach does not suffer from the scale issues faced by the oi method indeed oi generates correction factors for each time step independently from one another meaning that errors computed from small gauges with reactive basins will propagate to larger basins with slower reaction time therefore impacting the peak flow timing and amplitude the multi model averaging method does not have this inconsistency as all weights are computed over longer time horizons and over many basins but then applied on the simulated flow for the specific basins therefore peak flow amplitude and timing are preserved this study also highlighted the fact that multi model averaging methods require a certain level of variability within the simulations pool to maximize their effectiveness the hydrotel model although driven with multiple weather forcings parameters and time horizons was not able to provide as much structural variability as required and as demonstrated by using the lumped hydrological models future research should make use of additional distributed hydrological models to implement regional multi model simulations with a higher degree of simulation variability credit authorship contribution statement jean luc martel conceptualization methodology software validation formal analysis investigation data curation writing original draft visualization richard arsenault conceptualization methodology writing review editing supervision project administration funding acquisition simon lachance cloutier resources supervision writing review editing mariana castaneda gonzalez resources data curation writing review editing richard turcotte supervision writing review editing annie poulin methodology supervision writing review editing declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests richard arsenault reports financial support was provided by ouranos acknowledgements the authors would like to thank the teams at the direction de l expertise hydrique du québec deh and ouranos that made this project possible in the context of the info crue research program this project was funded by the info crue program project 702300 the authors would also like to thank the ecmwf for providing the era5 reanalysis data through the copernicus data store at https climate copernicus eu climate reanalysis they would also like to acknowledge the contribution of dr tang and co authors for making the scdna database available at https zenodo org record 3735534 
1744,this study presents a method to improve the reconstruction of historical flows on gauged and ungauged basins to do so a multi model weighted averaging of hydrological model simulations for a large spatial domain in the province of quebec canada is used the distributed hydrological model hydrotel was implemented over the region and covered 95 gauged basins an optimal interpolation oi assimilation method was first implemented as a baseline to improve the hydrotel flow simulations over the 95 basins then a series of multi model averaging techniques were applied to an ensemble of 144 hydrotel simulations that were generated by modifying parameter sets driving weather datasets and evapotranspiration modules the averaging methods were applied in a leave one out cross validation scheme where all 94 gauged basins were pooled together to compute the weights and those weights were applied to the 95th basin all basins were evaluated in such a manner and compared to the oi method implementing a year by year or shorter period weighting scheme instead of computing weights over all available data significantly improved the results this allowed the weights to better reflect each year s hydrological characteristics rather than compromising to improve the overall average the kling gupta efficiency kge and peak flow metrics showed that the granger ramanathan variant a gra was similar in performance to the oi method but did not have the drawbacks that oi can typically introduce the multi model application can also be further improved by adding more simulations from other hydrological models whereas the oi method cannot make use of such additional information thus hitting a performance plateau this study shows that it is possible to improve regional hydrological model simulations both for overall flows and peak flows and on the historical period for both gauged and ungauged basins this can then be used to better estimate risk in flood frequency analysis and other statistical analyses keywords multi model averaging technique optimal interpolation distributed hydrological model hydrotel prediction in ungauged basins data availability data will be made available on request 1 introduction using flood frequency analyses for the extrapolation of rare flood events e g 100 year floods is important when dealing with floodplain mapping and the design of hydraulic structures such as bridges and culverts extrapolating to such recurrences entails significant levels of epistemic uncertainty especially when dealing with relatively small time series considering that there is also an interest in conducting such analyses in areas where streamflow observations are not available at all there is a need for prediction in ungauged basins pub to rebuild historical streamflow pseudo observations hrachowitz et al 2013 however pub also leads to its share of challenges and uncertainties blöschl et al 2013 sivapalan et al 2003 while a regional flood frequency analysis could theoretically be used instead several shortcomings such as short time series and basins heterogeneity in terms physical properties climatology and hydrological processes can render this option sub optimal and even undesirable ouarda et al 2008 shu and ouarda 2007 for peak flows particularly other methods can be used such as in kim and shin 2018 where peak flow is estimated using the relationship between the ungauged basin s runoff coefficient and curve number which are estimated from donor basins these methods rely on regionalization of parameters to the ungauged sites and can be considered model independent these methods also only generate statistical descriptors of the flow regime flow indicators and do not allow generating complete time series hydrological modelling is an important tool to perform pub allowing to simulate streamflow time series that could ultimately serve as the basis for flood frequency analyses razavi and coulibaly 2013 lumped hydrological models can be applied on ungauged basins by using different types of regionalization methods such as spatial proximity or physical similarity arsenault and brissette 2014 on the other hand distributed hydrological models have inherent characteristics allowing them to simulate streamflow across entire regions under study including as many ungauged sub basins as needed while in theory this makes distributed models the ideal option when dealing with pub other difficulties such as the larger amount of physical and climatological data required the time needed for model setup and model calibration martel et al 2020 should not be overlooked even though lumped or distributed models can provide streamflow pub multiple sources of uncertainty remain such as the hydrological model s structure arsenault and brissette 2016 the climatological and physiographic data used papacharalampous and tyralis 2022 the calibration parameters and their equifinality arsenault and brissette 2014 and errors in hydrometric and meteorological observations used to calibrate the models troin et al 2022 thus in order to obtain the most accurate historical streamflow pseudo observations possible there is an advantage to post process the hydrological model outputs before conducting a flood frequency analysis lachance cloutier et al 2017 this type of post processing can be achieved with different methods the optimal interpolation oi lachance cloutier et al 2017 having shown to be a strong contender in essence oi is a statistically optimal method based on known theory which evaluates the spatial structure of errors in the distributed model response compared to the available observations and interpolates this error in such a way that the ungauged sites can be corrected this type of data assimilation technique has recently been shown to provide an immediate and significant gain in performance compared to the raw simulation from a hydrological model lachance cloutier et al 2017 ly et al 2013 but has traditionally been used in the field of meteorology heo et al 2018 oke et al 2010 phillips 1982 another way of dealing with these different sources of uncertainty is to address them through an ensemble of different hydrological simulations arsenault et al 2015 from both lumped and distributed models then different multi model averaging methods aim at obtaining an optimal weighting of each individual simulation that makes it possible to combine the strengths from several raw simulations to make gains in robustness and performance diks and vrugt 2010 arsenault et al 2015 showed that multi model averaging techniques generally provided better streamflow simulations than those of any individual model that is part of the ensemble on 76 of a set of 429 basins in the united states furthermore results showed that multi model averaging has the advantage of providing excellent performance without needing to identify a priori which hydrological model would be the best for the given basin finally the authors identify the granger ramanathan type c grc granger and ramanathan 1994 as the best solution for site specific flow estimation from the nine tested methods the same methods were also tested on 383 basins in china with the results again pointing to grc as being the best multi model averaging method in streamflow estimation at gauged locations wan et al 2021 arsenault and brissette 2016 applied multi model averaging concepts to ungauged basins but noted that the grc method which includes a bias correction term could lead to problems under regionalization due to the bias term scaling and thus implemented the granger ramanathan type a gra granger and ramanathan 1984 algorithm which does not require the bias term they found that regionalization of lumped hydrological models to ungauged sites generated streamflow that did not preserve statistics that could be corrected with multi model averaging and thus found that multi model regionalization of lumped models was not recommended however exbrayat et al 2011 and razavi and coulibaly 2016 showed that multi model averaging could perform well in regionalization depending on the region of interest as well as the number and type of contributing hydrological model when dealing with pub the combination of simulations from a distributed model can be more interesting since it will avoid the additional uncertainty from regionalization methods needed to transpose lumped models on ungauged sites however while combining a small number of raw simulations will provide improvements it may not be enough to surpass a method such as the oi in terms of performance to generate the most accurate historical streamflow pseudo observations to conduct a flood frequency analysis in ungauged basins the question remains what is the most optimal method to use our hypothesis is that using a sufficiently large sample of raw hydrological simulations will provide access to more flexibility and degrees of freedom that can lead to further performance gains with some diminishing returns in the right context this has the potential to outperform a method like oi which is limited to a one time but significant gain in performance furthermore using raw simulations from a distributed hydrological model would not be subject to the data assimilation techniques shortcomings previously raised the aim of this paper is to develop a methodology allowing to combine multiple raw simulations from a distributed hydrological model that outperforms the baseline data assimilation technique for the historical reconstruction of daily streamflow pseudo observations and annual maxima time series in ungauged basins section 2 of the paper presents the study site test bench and proposed methodology to reach the study s objectives results are then presented in section 3 and discussed in section 4 followed by a conclusion and future work in section 5 2 methodology 2 1 study site this study focuses on the meridional part of the province of quebec covering an area of approximately 726 000 square kilometers a selection of 95 basins shown in fig 1 from the 259 gauged basins operated by the direction de l expertise hydrique deh of the ministry of the environment and fight against climate change melcc was made this selection was designed to provide coverage of both south 32 basins and north 63 basins shores of the st lawrence river covering about 31 of the study area while keeping the hydrometric stations with longer observational records of good quality the average physical characteristics annual climatology and distribution of land use is provided in table 1 each of the basins will be used in a leave one out cross validation loocv to evaluate the proposed methodology in the context of ungauged basins 2 2 hydrological modeling hydrotel is a semi distributed hydrological model developed by fortin et al 2001a and fortin et al 2001b the deh exploits this model for its daily hydrological forecasts over 259 gauged and 28 035 ungauged basins and river reaches across the region of interest a strong motivation behind the use of the hydrotel semi distributed model is that the deh has shared the complete calibrated platform used operationally for the region of interest see fig 1 this allowed the development of a test bench based on multiple calibration strategies involving different parameters input meteorological datasets and potential evapotranspiration formulas that also enable to emulate the operational limits fortin et al 2001a provides a complete description of hydrotel s required inputs and simulation of hydrological processes which are summarized hereafter in terms of input variables hydrotel requires drainage structure land use soil type from high resolution remotely sensed data as well as distributed meteorological inputs i e total daily precipitation in water equivalent daily minimum and maximum temperature each basin gauged or ungauged is split into multiple homogenous sub basins for which all hydrological processes e g snowmelt and evapotranspiration are computed independently gridded meteorological datasets are used as inputs and corrections are also made based on each sub basin s average elevation precipitation is also separated into rain and snow components on each sub basin with a linear interpolation using both minimum and maximum daily temperature as well as a threshold temperature for the separation between rain and snow which is calibrated the evolution of the snow cover s characteristics is done with a mixed degree day and energy balance method however the net absorbed solar radiation is simply estimated from a degree day methodology three land use classes are considered for the snowpack simulation with distinct melting factors for coniferous forests deciduous forests and open areas the 95 selected basin s land use types described in table 1 are split into these three categories accordingly the hydrotel model has the option to switch between six potential evapotranspiration pet formulas but only three were selected in this study hydro québec linacre and mcguinness the selection of these three pet formulas was made with the goal to provide a wide range of the inter model variability needed for this study while limiting the number of calibrations to be performed the first is an empirical equation developed over local basins by hydro quebec fortin 2000 and only requires minimum and maximum air temperature as inputs the linacre 1977 formula is derived from penman and keen 1948 and requires dew point and air temperatures as well as both elevation and latitude of the station as inputs mcguinness mcguinness and bordne 1972 is a radiation based formula that only requires mean air temperature as well as extra terrestrial radiation which can be estimated using the basin average latitude and the julian day it can be noted that oudin et al 2005 compared 27 evapotranspiration formulas including linacre and mcguiness and showed that mcguinness provided the best results for hydrological modeling over 308 basins located in france australia and the united states the vertical water balance is conducted using a three layers soil model allowing to approximate the physical macro processes involved during the infiltration and vertical redistribution of water over a soil column the first and relatively thin layer 10 to 20 cm is affected by the soil evaporation and controls the surface runoff the second layer is a transition zone between the first and third layer and produces delayed flows the third layer is typically saturated and provides the base flow all three layers can be affected by transpiration depending on land properties the combined flow from the vertical water balance is then routed using a reference geomorphological hydrograph specific to each sub basin this geomorphological hydrograph is derived using the kinematic wave approximation with a reference flow depth and is obtained using two different land uses forested and open areas for which different manning s roughness coefficients are used flow through the hydrographic network is also computed using the kinematic wave estimation these computations are performed for each river reach based on their respective characteristics namely the length width slope and manning s roughness coefficient however when the reach is a lake or a reservoir the classical continuity equation is used instead and the flow is estimated using a flow depth relationship depending on the width of the lake outlet 2 3 meteorological datasets a selection of meteorological datasets was made with two goals in mind 1 a reasonably long temporal coverage to conduct a flood frequency analysis and 2 diversity among the types of datasets a total of three different meteorological datasets were thus selected to provide precipitation and temperature inputs to the hydrotel model the melcc gridded observed dataset the era5 reanalysis and the scdna weather station product the common period for these three datasets was from 1979 to 2018 and was kept for this study daily precipitation minimum and maximum temperature were extracted for all three datasets and used as inputs for the various calibrations of the hydrotel model the daily observation gridded dataset developed by the melcc dcaq bergeron 2016 was selected as it is currently used as inputs in the hydrotel model for the deh daily forecasting quality controlled weather stations from both melcc and environment and climate change canada eccc networks were used for the interpolation providing coverage for the period between 1961 and 2021 ordinary kriging interpolation is used to obtain the best non biased estimations without requiring the mean over the entire domain nor assuming its stationarity wackernagel 2003 this method enables the consideration of a local average through the use of a restricted interpolation neighborhood bergeron et al 2016 li and heap 2014 the era5 c3s 2019 hersbach et al 2020 reanalysis dataset is also used as inputs to hydrotel era5 is the fifth generation of the european centre for medium range weather forecasts ecmwf which provides global hydrometeorological and atmospheric variables from 1950 to present this reanalysis provides hourly outputs at a horizontal resolution of 0 25 0 25 tarek et al 2020 demonstrated that hydrological modeling using era5 as inputs to hydrological modeling provides equivalent performance to observations over most of north america including the region of interest the weather station product used is the station based serially complete dataset for north america scdna tang et al 2020 covering the 1979 2018 period this dataset includes 27 276 stations for which a strict quality control is performed and the missing data is reconstructed using different strategies such as machine learning quantile mapping and spatial interpolation while the observed weather network used to generate the melcc gridded dataset could also have been used it was decided that it would only bring marginal additional information compared to its interpolated version limiting the targeted degrees of freedom 2 4 development of the test bench a test bench was developed using the platform provided by the deh to test the work hypothesis the hydrotel parameters objective function and optimization algorithm for the calibration of the different hydrotel models will be covered in this section followed by the calibration strategy to generate a total of 144 different calibrations over each of the two regions of interest i e north and south domains 2 4 1 hydrotel parameters hydrotel has a total of 27 internal parameters that can be adjusted based on previous work done by turcotte et al 2007 16 of these parameters can be fixed considering their low impact on the calibration objective function or due to their additive or multiplicative corrective nature applied to input data the remaining eleven parameters to be calibrated are described in table 2 along the eleven free parameters described in table 2 two additional fixed parameters were modified to provide the desired flexibility within the hydrotel calibrations the reference flow depth for the geomorphological hydrograph and a multiplicative constant for the lake outlet s width for the flow over the terrestrial part of the basin two different reference flow depths were used to consider the relationship between flow depth and the strahler stream order previous testing allowed selecting optimal flow depth values for the study site 0 006 and 0 010 m and showed that a higher strahler number performed better with smaller flow depth and vice versa for the flow through the hydrographic network the large number of lakes especially on the north shore of the st lawrence river has shown to have a significant impact on the resulting hydrographs previous testing by the deh showed that using larger width for the lake outlet allowed it to provide a more realistic hydrograph in this context to account for this a multiplicative constant of 1 82 applied to the lake outlet s width was found to provide the best results in this study both values of 1 00 and 1 82 were considered 2 4 2 objective function and optimization algorithm to evaluate the performance of the hydrotel model during its calibration and validation processes the modified kling gupta efficiency kge gupta et al 2009 kling et al 2012 objective function was used and is defined as follows 1 1 k g e r 1 2 α 1 2 β 1 2 where r is the linear correlation coefficient α is the ratio of the coefficients of variation and β is the bias ratio all these values are dimensionless and are computed between observed and simulated streamflow the kge ranges from a value of to 1 where 1 represents a perfect fit between observed and simulated streamflow as suggested by huot 2014 the best suited optimization method for the hydrotel model is the dynamically dimensioned search dds algorithm tolson and shoemaker 2007 a total of 500 model iterations was chosen as a compromise between good enough calibration quality and time to complete the most combinations possible the goal here is not to obtain the best possible local optima but rather to generate good enough calibration that will provide additional flexibility and degrees of freedom when combining all available simulations using a multi model averaging method 2 4 3 calibration strategy to obtain the desired level of flexibility from the hydrotel simulations multiple calibrations of hydrotel parameters were conducted using different meteorological datasets each of the hydrotel calibrations follow the procedure detailed in fig 2 all combinations of meteorological datasets dcaq era5 scdna flow depth 0 006 and 0 010 m lake s outlet width multiplicative constant 1 00 and 1 82 pet formulas linacre hydro québec and mcguinness calibration period 1979 1987 1988 1997 1998 2007 and 2008 2017 and split between the north and south shores were calibrated following the procedure described in the previous two sections resulting in a total of 288 different hydrotel calibrations with 144 calibrations for each of the north and south shores while the north and south shores were calibrated independently they were ultimately combined resulting in 144 possible simulations to be averaged to ensure a good representation of both north and south shores of the st lawrence river two thirds of the available stations in both areas were randomly selected for the calibration and the remaining third for the validation this random selection ensured that only hydrometric stations with at least 5 years of records over the current calibration period e g 2008 2017 and was kept for all combinations of hydrotel models using the same period 2 5 proposed methodology the proposed methodology is presented in the flow chart in fig 3 and described in the following subsections 2 5 1 baseline the optimal interpolation optimal interpolation oi is a proven data assimilation technique with similarities to kriging tabios and salas 1985 used in the fields of meteorology fortin et al 2015 and hydrology lachance cloutier et al 2017 when dealing with streamflow the oi aims at combining available local observations with simulations from a distributed hydrological model referred to as the background field at each hydrometric station the difference between the observations and the simulations is first evaluated a log transformation is typically applied to avoid obtaining negative streamflow the oi technique consists in exploiting the spatial correlation of the error to interpolate its value on all sites of interest i e ungauged basins for each site corrected values are obtained by 2 z e m e i 1 n w i z i m i where z e and me are respectively the corrected and the background field values at an estimation site e and zi mi is the difference between the observation and the background field at a given hydrometric station i the weights wj are obtained by finding the solution to the system of linear equations 3 b i σ o 2 σ b 2 w b where b represents the correlation matrix of the error of the background field between the reference sites i and j i is a diagonal unit matrix σ o 2 and σ b 2 are the variance of the observation and background field error respectively w is the vector of the weights for each reference sites and b is a vector of the correlation between the reference sites and the estimation sites e the ratio σ o 2 σ b 2 was fixed to 0 15 following trial and error calibration for the daily time series of streamflow the oi analysis is independently conducted at each time step the initial calibration of the distributed hydrological model provided by the deh was post processed using this methodology and will serve as the benchmark to evaluate the proposed methodology 2 5 2 multi model averaging methods a total of five multi model average methods were tested in this study and are summarized in table 3 these different methods allow estimating the optimal set of weights except for the simple arithmetic average avg method which simply provides equal weights to all simulations for all 95 individual hydrotel simulations to combine them together this multi model averaging approach aims at combining the different simulations strengths to outperform each individual simulation arsenault et al 2015 and wan et al 2021 showed that weighting methods generally perform better than the individual hydrological model simulations the simple arithmetic average avg simply consists in assigning equal weights to each simulation the bates and granger averaging bga bates and granger 1969 method relies on the assumption that the simulations are unbiased and that their errors are uncorrelated the bga method computes weights wbga as follows w bga 1 σ i 2 i 1 n 1 σ i 2 where σi refers to the variance of the simulated streamflow from simulation i finally the granger ramanathan methods a b and c granger and ramanathan 1984 methods were employed in this study method a gra is based on the ordinary least squares ols algorithm and computes its weights wgra as follows w gra q s i m t qsim t 1 qsim t q o b s where qobs and qsim are the observed vector and simulated matrix of streamflow respectively variant b grb is similar to the gra but the ols algorithm is constrained to ensure that the sums of the weights are equal to unity variant c grc is unconstrained but it incorporates a bias correction of the average streamflow using a constant term initially the bayesian model averaging bma neuman 2003 was considered in this study however it was found that it was unable to converge to an acceptable set of weights when using all 144 hydrotel simulations additionally due to its iterative nature the bma s long computing time made it impractical to use throughout the analyses two different metrics were used to evaluate the performance of the various multi model averaging methods the kge see equation 1 and the normalized root mean squared error nrmse of the daily annual maxima streamflow qx1day while the kge provides a measure of performance across the whole hydrograph the nrmse qx1day metric aims at larger values which are more closely related to the values typically used in a flood frequency analysis however the nrmse qx1day does not take the timing of the events into consideration 3 results 3 1 calibration results the first step was to generate an ensemble of hydrotel simulations with as much variability as possible to maximize the flexibility of the multi model averaging approaches in total 144 simulations were generated by combining various meteorological data sources and model physiographic parameters as illustrated in fig 2 the calibration results for each basin y axis and each model setup x axis are presented in fig 4 most cases generate acceptable and generally good quality kge scores meaning that the calibrations performed well on those cases calibration kge scores are acceptable for most basins considering the regional calibration method employed which sacrifices basin specific skill for overall robustness over the entire domain a clear pattern is also seen wherein every 16 simulations a significant change in performance is observed this structure reflects changes in the input meteorological data where the dcaq era5 and scdna data appear in succession the selection of a meteorological dataset for calibration is the element that produced the most variability within the results as can be seen by this repeating cycle of 16 simulations the parameters related to the hydrotel physiographic setup were less impactful and only generated small differences within the simulated hydrographs 3 2 multi model averaging using all basins once the 144 calibrations were produced the simulated hydrographs were generated and combined using a variety of multi model averaging algorithms using a leave one out cross validation loocv each of the 95 basins was considered pseudo ungauged and the simulated flows were combined for the pseudo ungauged basin the kge and nrmse qx1day were computed and reported in fig 5 first the optimal interpolation oi allows a significant gain in performance compared to the raw hydrotel simulations hyd both in terms of higher kge scores and lower nrmse values for qx1day furthermore the multi model combinations were not able to improve upon the raw simulations as significantly as the oi but some small improvements could be noted over the raw simulations for all but the grc method however either no gains or only marginal gains were obtained no matter what multi model averaging method was used results are also presented spatially for the oi simple average avg and the gra weighting method which was considered the best multi model averaging method here in fig 6 however no striking pattern emerges from these results all multi model averaging methods seem to perform similarly over the study domain 3 3 multi model averaging using a year by year approach the next step was to attempt to extract more information from the data by performing multi model weightings for each year instead of on the entire period of the available datasets results are shown in fig 7 and spatially distributed results for methods oi avg and gra again are shown in fig 8 it is clear from fig 7 that there is a significant additional gain in performance when computing weights year by year giving more flexibility to the multi model averaging algorithms to fit the optimal weights for the given year and not forcing it to compromise to be adequate for all years in the year by year approach some multi model averaging methods clearly respond better than when all data was pooled together notably the gra and grb methods gra was slightly better in this respect and was used for the rest of the study it can be seen in fig 8 that gra performed better than the raw simulations for 67 and 63 out of 95 basins for the kge and nrmse qx1day respectively while the oi performed better than the raw simulations for 70 and 66 basins out of 95 for the kge and nrmse qx1day respectively therefore the gra seems to perform at least as well as the oi for this study area and hydrological model simulations both in terms of overall flow simulation kge and peak flows nrmse qx1day 4 discussion 4 1 improvement using the optimal interpolation optimal interpolation oi aims to improve the simulation results overall without regard to discontinuities in the generated hydrographs since the domain is composed of basins of all sizes peak flows occur at different dates even when driven by the same meteorological conditions due to flow routing in larger basins oi aims to apply spatial corrections at each time step disregarding the state of specific hydrographs this means that a compromise must be made during the interpolation whereby some peak flows are artificially reduced and others are increased simply due to the timing of nearby basins that are utilized in the optimal interpolation nonetheless the method provides good results on average which is not surprising given that for this purpose oi is a statistically optimal method the oi simulations were consistently better than the raw simulations for a majority of basins 70 to 75 of basins both in terms of kge and nrmse qx1day as seen in the top of the boxplots of figs 5 and 7 this method is therefore recommended as a good approach for processing distributed model flows as there is a significant gain in overall and peak flow estimations during this study an attempt was made to combine several simulations post processed by the oi not shown with the multi model averaging methods proposed these tests showed that there was a gain in robustness which was on average better than the individual simulations with oi the robustness comes from the fact that it is not possible to select the right simulation from the start when dealing with ungauged basins the gains were only marginal however regardless of the weighting method used with similar results obtained with the avg method one disadvantage of processing oi simulations in a multi model framework is that multi model weighting schemes maximize performance by using each simulation s strengths to reduce the overall error this requires some flexibility and variety in the ensemble of members that are used during the weighting however oi applies corrections in such a way that the resulting hydrographs are much more similar leaving fewer degrees of freedom to the multi model averaging methods to perform efficiently therefore adding more oi simulations to the multi model averaging process only produces asymptotic performance gains in an operational setting if multiple oi simulations are available it is recommended to use a simple average of all these simulations to make gains in robustness but the gains in performance are expected to be marginal therefore the multi model approach can provide better results than oi due to the fact that more information is available in the entire process for multi model methods than what oi can use 4 2 comparing the different multi model averaging methods when using the multi model averaging methods on the 144 simulations it was found that significant improvements in simulation accuracy could be observed even with the simplest averaging methods this is in line with similar studies using lumped hydrological models arsenault et al 2015 one exception is grc which contains a bias element that is not specific to each site this constant bias ends up introducing errors to all basins except for the basins whose flows are near the ensemble average with the exception of grc the other results are in line with what was found previously in the literature where the avg and bga methods perform generally worse lower nash sutcliffe values larger biases than with the gra and grb methods wan et al 2021 furthermore methods such as gra and grb performed better than the others especially so when the weights were computed on a yearly basis this approach of computing one set of weights per simulation year and shorter periods as described in the following section allowed the weighting algorithms to adapt to specific hydrometeorological conditions over the domain and thus allow for more accurate weighted simulations this methodology could be criticized for certain contexts as it goes against the prevailing notion that models should be as good as possible in all conditions and the current methodology implements a form of overfitting that would not be applicable for simulation of longer time series however when considering the goal of performing a flood frequency analysis especially over ungauged basins overfitting is not necessarily an issue we argue that it is an advantage the goal is to have the most optimal streamflow simulation with as little uncertainty as possible and by simulating these hydrographs on a year by year basis with the most precise information as possible for each year the resulting hydrograph is of higher quality than if the weighting was performed with a single set of weights for the whole period representing the long term compromise this method is thus applicable in this study since the models and methods are not used for forecasting but for historical simulations therefore overfitting is not an issue in this study 4 3 improvement by computing weights over shorter periods as demonstrated with the comparison of boxplots from figs 5 and 7 and maps from figs 6 and 8 there is a clear gain in performance by averaging weights over a shorter period with significant gains obtained by going from the weights for the whole periods to a year by year basis it was of interest to evaluate the limit of using an even shorter period and to determine at which point overfitting would start occurring using the gra method which provided the best results in this study six different periods were tested for the computation of the weights year by year season by season i e every three months starting with january february and march month by month 2 weeks by 2 weeks week by week and day by day results shown in fig 9 indicate that by decreasing the period up to the month by month period there is an increase in performance for both tested metrics by going beyond the year by year period the multi model averaging method also starts to perform similarly to the oi method however when going beyond the month by month period weights are starting to be overfitted resulting in poorer performance when conducted in a cross validation context like the one in this study for instance the day by day period not shown in fig 9 since all the values were below the 0 5 kge value is strongly impacted by overfitting since there 144 weights to fit 95 values only to determine if a pattern exists in the improvement observed in fig 9 we compared these results with basin descriptors presented in table 1 however we found no correlation between any of the basin descriptors and the kge or nrmse qx1day results obtained in this study for all periods used to compute the weighting i e year by year up to week by week notably arsenault et al 2015 and wan et al 2021 conducted geographic analyses and identified low performance basins located in arid regions with total annual precipitation below 500 600 mm year this could be attributed to the hydrological model being more suitable for humid climates and areas with strong snow accumulation in our study the driest basins had an average annual precipitation of around 800 mm year which is significantly above the threshold suggested by arsenault et al 2015 and wan et al 2021 this finding may explain why almost all basins exhibit improved results from the computation of weights over shorter periods 4 4 using more diverse hydrological models when it comes to adding more flexibility to the sample of simulations different formulations and models for the different hydrological processes can also be used unfortunately the flexibility offered by the distributed model used in this study was limited to different potential evapotranspiration formulas in this regard the focus has been put on different types of calibration and datasets to obtain the desired flexibility in our sample it is expected that different formulations and models for the hydrological processes or even different hydrological models altogether could achieve the desired results as well to test this hypothesis additional tests were conducted by calibrating three lumped hydrological models only using the melcc dataset and the oudin pet formula oudin et al 2005 gr4j with the cemaneige snow module perrin et al 2003 valéry 2010 hmets martel et al 2017 mohyse fortin and turcotte 2007 even though the use of lumped models has its own shortcomings when it comes to dealing with prediction in ungauged basins pub such as the need to regionalize parameters they still allow us to glean some insights on the benefit of adding completely different hydrological model structures the multi model average methods were applied on all three lumped hydrological models as well as the raw hydrotel simulation four simulations in total it can be seen in fig 10 that greater improvements were obtained in comparison with the different simulations from hydrotel exceeding the oi in terms of performance this suggests that hydrotel did not provide sufficient flexibility in its structure limiting the hydrograph variability to that of the various datasets and calibration schemes thus combining different hydrological models both lumped and distributed or using a model with more flexibility in its structure could allow it to reach the desired gains in performance hydrological models have varying strengths and weaknesses and no single model outperforms others in all basins in this study three lumped hydrological models were tested and gr4j hmets and mohyse achieved the best kge values respectively on 82 11 16 84 and 1 05 of the basins as suggested by wan et al 2021 combining multiple hydrological models calibrated with different objective functions can lead to more efficient and robust results as observed in this study with significant improvement obtained using multiple hydrotel calibrations figs 5 to 9 and different hydrological models fig 10 arsenault et al 2015 also demonstrated that even models that yield poorer results across all basins should still be included as they can contribute to the multi model averaging performance they showed this using a multi objective optimization approach aimed at maximizing the objective function and minimizing the number of simulations in the multi model averaging with even the worst performing model also mohyse making regular contributions it should be noted that the oi used as a baseline in this study is conducted using a regional calibration from hydrotel that is not specifically calibrated at each local site on the other hand the lumped hydrological models used in this additional analysis are calibrated locally at each site while the results showed improved performance by using these lumped hydrological models over the oi it can be expected that the simulation at ungauged sites from a regional model like hydrotel are likely to be more robust than those from lumped models that would require to be regionalized as demonstrated in the previous section additional gains in performance can be obtained by computing weights over a shorter period e g year by year season by season or month by month it can be noted that improvement is obtained even up to the day by day period this is likely due to the fact that there are only 4 hydrological models being combined resulting in 4 weights for a minimum of 95 values at the day by day period avoiding overfitting however the gain in performance when combining the four hydrological models fig 10 compared to the combination of all 144 hydrotel simulations fig 9 is much smaller this is likely because the four hydrological models are already providing most of the flexibility needed reducing the potential gain in performance to be made by computing weights over shorter periods this finding suggests that the flexibility needed to increase the multi model averaging performance can be obtained in different manners namely 1 increasing the number of calibrations from a given hydrological models by using alternative parameters meteorological datasets or model structure 2 increasing the number and variety of hydrological models both lumped and distributed 3 reducing the period at which to compute the weights of the multi model averaging 4 5 flood frequency analyses comparison considering that the main objective of this study was to generate the most accurate historical streamflow pseudo observations for conducting a flood frequency analysis in ungauged basins additional analyses were conducted to evaluate the proposed methodology to carry out these analyses four different basins were selected including one large and one small basin located on the north shore as well as one large and one small basin on the south shore all four selected basins had complete time records between 1979 and 2017 the best overall multi model method gra which uses a year by year period gra y for computing the weights was compared with oi and observations table 4 shows the results of kge and nrmse qx1day values for the four chosen basins these four basins exhibit a similar pattern to the boxplots illustrated in fig 9 improvements in performance can be observed up to the season by season or month by month period followed by a decline although this trend is apparent in the kge results some differences are noticeable for the nrmse qx1day particularly in the basin 061022 the simulations of the annual maxima series qx1day were first compared as these are directly used by the flood frequency analysis the results are shown in fig 11 however it is important to note that not all basins provided satisfactory results for either the gra s the oi or both overall it was observed that both methods provide good estimations of observed streamflow in a loocv context gra y does not typically lead to overestimations of qx1day while oi tends to slightly overestimate the results for the larger basins fig 11 a and b however gra y underestimates the results for basin 030 282 fig 11 d using the qx1day time series presented in fig 11 flood frequency analyses were conducted and the results are presented in fig 12 the gumbel distribution was used and its parameters were adjusted using the maximum likelihood approach in all cases both methods are able to provide good results mostly within the 95 confidence intervals of the observations except for the lower return periods in basin 061 022 fig 12 b with respect to the selected basins the gra y method tends to provide results closer to observations while oi tends to slightly overestimate the values while remaining within the confidence interval boundaries in line with results obtained in fig 11 however this is not necessarily the case for all basins where different behaviors are observed the aim of this analysis was simply to validate if the estimations provided by both methods led to satisfactory results for a flood frequency analysis as a reminder the results obtained for the multi model approach could be significantly improved if more structural variability was possible for hydrotel as demonstrated with results and discussion in section 4 4 and fig 10 thus while already providing satisfactory results this method can still be improved beyond what is obtained in this paper 4 6 what is the best method to use in this study raw simulations were improved through two approaches the optimal interpolation oi as implemented by lachance cloutier et al 2017 was used as the reference case and the multi model averaging method both methods have advantages and shortcomings that need to be mentioned first it is important to note that this study implements a two step approach to estimating flows at ungauged basins on a regional scale typically regionalization methods perform either 1 model parameter regionalization at ungauged sites 2 distributed model regional simulations or 3 for hydrological indicators statistical methods such as regression and kriging have also been proposed model parameter regionalization requires modelling each basin individually and simulating them with a hydrological model which is parameterized using donor basin parameters this method introduces high levels of uncertainty and introduces major spatial discontinuities between neighboring basins depending on their physical characteristics arsenault and brissette 2014 razavi and coulibaly 2013 the distributed hydrological model method performs reasonably well in this study raw hydrotel simulation but it is also a compromise solution where the model is made to simulate flows adequately on all sites by allowing loss of skill on some of the basins kumar and samaniego 2013 finally statistical methods to regionalize peak flows have been proposed but suffer from the same limitations as model parameter regionalization in terms of uncertainty perez et al 2019 recently deep learning approaches have started being used to estimate streamflow at ungauged sites but these have been applied in large scale applications of multiple basins and not on a regional domain with a wide array of basin scales arsenault et al 2023 kratzert et al 2019 a combined approach was implemented by wang et al 2023 where a distributed model had its parameters regionalized using random forest methods in china with success therefore the two methods presented in this study are post processing steps that take the result from a distributed regional model and improve them by reducing the effects of the compromise of regional calibration the oi is a simple data assimilation technique that has multiple advantages it is a statistically optimal method based on known theory provides smooth spatial corrections by taking all spatial components into consideration can be conducted on each day independently and requires low computational power however this method also has various shortcomings that should not be overlooked breaking down the spatial structure of data discontinuities in the data smoothing of maximum events does not provide correction for sites where the closest observation is too far and generation of inconsistent reaction times since the method does not guarantee mass balance preservation essentially oi can lead to discontinuity in the hydrograph because the error field is interpolated each day based on the differences between the observations and the model simulations at the gauged sites the error field is then spatially applied to all simulated discharges in the modelled region however this can cause problems when the hydrological model output is dependent on exogeneous variables such as basin size indeed a large basin could have a delayed response multiple days to a precipitation event whereas a small neighboring or nested basin would react on the same day therefore the error field would correct the large peak flood at a later date which could then impose a large yet unnecessary correction on the smaller basin also significant discontinuities can be introduced since the closest observed hydrometric stations can vary over time when some enter service and others are shut down while a technique like oi provides significant gains in terms of performance over the raw simulation from a hydrological model its various shortcomings are undesirable when conducting a flood frequency analysis especially on ungauged basins the multi model averaging method has the advantage of not having the shortcomings from a typical data assimilation method such as oi since the time series are continuous except during transitions when weights change and depend on blending model outputs which does not produce temporal inconsistencies contrary to the oi sites far away from observations will also be corrected since the same weights will be applied to all simulations regardless of their location also the multi model method does not perform any smoothing of time series since the same weights are applied each day which means the timing of hydrographs peaks is preserved furthermore additional degrees of freedom can be relatively easily added to improve its performance by adding more simulations and or by computing the weights over a shorter period however temporal breaks can end up introduced when using weighting based on shorter periods e g year by year or month by month in an operational context the challenge lies in the ability to generate a limited number of simulations that are sufficiently different from one another to combine their strengths while typically using the same hydrological model used by the agency or organization to limit overhead related to maintenance and training on multiple models there are other shortcomings what should not be overlooked as well this method does not adjust to the information available at measurement sites it has no guarantee of mass balance preservation it can propose negative weights or weights not adding up to 1 which can have a dubious physical meaning and it scores highly on average values kge but can be less efficient on peak values it was hypothesized that accessing a wider variety of simulations would give more flexibility to the multi model averaging scheme which would then allow for more accurate simulations by design this method would not create discontinuities except at the beginning of each period due to the weights being recomputed if a shorter period than the full period is used currently the multi model approaches using the 144 hydrotel simulations achieve similar performance levels as oi and better results when the period is reduced while a relatively large number of simulations were used they were mostly based on various climatological datasets and different calibrations ideally changes in model structure e g snowmelt routing and infiltration modules could have provided more variety and potentially helped improve the results even further as suggested by the results of the previous section however hydrotel s internal mechanics could not be modified in this study a potential advantage of the multi model average method over the oi that was not investigated in this study would be the capacity to apply the weighting in a context where observations would not be available for instance in a climate change impact study using future simulations pre computed weights for the multi model averaging could still be used 4 7 limitations this study was performed on a regional distributed model and the results were evaluated on pseudo ungauged sites however the gauged basins are typically relatively large the smallest was 44 km2 and the median was almost 1000 km2 it is therefore possible that the results do not scale well with much smaller size basins since this has not been tested however this is also true for the oi method application therefore no strong conclusion on the generalizability of either method can be made the results seem to point to the methods being applicable without any correlation to basin size but this cannot be proven at this time this should be tested in future studies where very small gauged basins would also be included another limitation is that of observed flow uncertainty observed flow measurements are known to be highly uncertain and noisy which can lead to errors that propagate throughout the process for example the multi model weights are computed by minimizing differences between the weighted streamflow and the observed flows any errors or biases in the observed flows would then propagate into the multi model weights and would affect the quality of the simulation on the gauged and ungauged basins however by taking weights over longer periods the epistemic uncertainties should be abated somewhat leading to a more robust signal on the other hand oi generates error fields that are computed each day so it could be prone to more uncertainty emanating from the observed flow random errors therefore obtaining a good estimate of observed flow uncertainty would help finding more robust methods that could take this uncertainty into consideration during the calculation of weights finally this study investigates the performance of the simulation methods using two metrics kge and nrmse qx1day it is important to note that the hydrological model was always calibrated using kge and therefore is expected to reproduce overall hydrographs well with a smaller emphasis on the peak flows it could have been possible to calibrate on an objective function that weights the peak flows more heavily in order to maximize performance of the qx1day metrics but this would have been at the expense of the other flow regimes therefore the calibration on kge is a compromise solution that can still provide estimates of qx1day with a good level of confidence 5 conclusion estimating streamflow and peak flows at ungauged sites is still a challenge today due to the various sources of uncertainty and highly spatially heterogeneous nature of hydrological processes in this study we attempted to provide the most precise hydrographs possible on a historical period and using a distributed hydrological model in such a way that it would be possible to process the hydrological model simulations to obtain accurate hydrographs on the entire region using a leave one out cross validation methodology applied to 95 basins we were able to show that the hydrotel model simulations could be substantially improved using optimal interpolation oi however some drawbacks associated with this method led us to attempt a second method the alternative method was the application of multi model averaging techniques to a large variety of hydrological model simulations some multi model methods performed better than others but the gra method showed similar performance to that of oi without any of the drawbacks this means that the historical period hydrographs could be generated with more confidence which can then lead to better estimates of peak flows this is an important step towards modeling peak flows for flood frequency analysis given the fact that these results were all obtained considering the basins as ungauged there is a high confidence that the method can be applied over the entire domain covered by the hydrotel model this also means that estimating flood risk at these ungauged basins can be made with higher confidence interestingly the multi model averaging approach does not suffer from the scale issues faced by the oi method indeed oi generates correction factors for each time step independently from one another meaning that errors computed from small gauges with reactive basins will propagate to larger basins with slower reaction time therefore impacting the peak flow timing and amplitude the multi model averaging method does not have this inconsistency as all weights are computed over longer time horizons and over many basins but then applied on the simulated flow for the specific basins therefore peak flow amplitude and timing are preserved this study also highlighted the fact that multi model averaging methods require a certain level of variability within the simulations pool to maximize their effectiveness the hydrotel model although driven with multiple weather forcings parameters and time horizons was not able to provide as much structural variability as required and as demonstrated by using the lumped hydrological models future research should make use of additional distributed hydrological models to implement regional multi model simulations with a higher degree of simulation variability credit authorship contribution statement jean luc martel conceptualization methodology software validation formal analysis investigation data curation writing original draft visualization richard arsenault conceptualization methodology writing review editing supervision project administration funding acquisition simon lachance cloutier resources supervision writing review editing mariana castaneda gonzalez resources data curation writing review editing richard turcotte supervision writing review editing annie poulin methodology supervision writing review editing declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests richard arsenault reports financial support was provided by ouranos acknowledgements the authors would like to thank the teams at the direction de l expertise hydrique du québec deh and ouranos that made this project possible in the context of the info crue research program this project was funded by the info crue program project 702300 the authors would also like to thank the ecmwf for providing the era5 reanalysis data through the copernicus data store at https climate copernicus eu climate reanalysis they would also like to acknowledge the contribution of dr tang and co authors for making the scdna database available at https zenodo org record 3735534 
