index,text
835,hydroclimatic processes come in all shapes and sizes they are characterized by different spatiotemporal correlation structures and probability distributions that can be continuous mixed type discrete or even binary simulating such processes by reproducing precisely their marginal distribution and linear correlation structure including features like intermittency can greatly improve hydrological analysis and design traditionally modelling schemes are case specific and typically attempt to preserve few statistical moments providing inadequate and potentially risky distribution approximations here a single framework is proposed that unifies extends and improves a general purpose modelling strategy based on the assumption that any process can emerge by transforming a specific parent gaussian process a novel mathematical representation of this scheme introducing parametric correlation transformation functions enables straightforward estimation of the parent gaussian process yielding the target process after the marginal back transformation while it provides a general description that supersedes previous specific parameterizations offering a simple fast and efficient simulation procedure for every stationary process at any spatiotemporal scale this framework also applicable for cyclostationary and multivariate modelling is augmented with flexible parametric correlation structures that parsimoniously describe observed correlations real world simulations of various hydroclimatic processes with different correlation structures and marginals such as precipitation river discharge wind speed humidity extreme events per year etc as well as a multivariate example highlight the flexibility advantages and complete generality of the method keywords stochastic modelling weather generator parent gaussian framework transformations hydroclimatic processes precipitation river discharge temperature wind speed humidity 1 introduction make things as simple as possible but not simpler albert einstein the stochastic structure and the marginal probability laws of hydroclimatic processes like precipitation river discharge temperature wind or relevant processes with discrete or binary marginal distributions like the number of extremes per year wet dry sequences etc show complexities that current methodologies are unable to unify in a single modelling framework these processes differ in their spatiotemporal correlation structures cs with stronger structures being observed for example in temperature than in precipitation e g wilks and wilby 1999 moreover they have different marginal distributions e g temperature is normally distributed breinl et al 2015 kilsby et al 2007 while the intermittent and highly skewed character of precipitation at fine spatiotemporal scales demands the use of mixed type distributions herr and krzysztofowicz 2005 papalexiou and koutsoyiannis 2016 stern and coe 1984 wilks 1998 complexities of these processes are further enhanced by seasonality and diurnal variation as well as a tendency to normality as we shift from fine to coarser scales due to the central limit theorem these reasons led to a very large number of stochastic modelling schemes see e g aghakouchak et al 2010 bárdossy and pegram 2009 bardossy and plate 1992 buishand 1978 cowpertwait et al 2007 foufoula georgiou and krajewski 1995 foufoula georgiou and lettenmaier 1987 grimaldi and serinaldi 2006 hering et al 2015 kleiber et al 2012 lee and salas 2011 lombardo et al 2014 mehrotra and sharma 2009 onof et al 2000 onof and wheater 1993 over and gupta 1996 papalexiou et al 2011 paschalis et al 2014 rodriguez iturbe et al 1987 salas et al 2006 serinaldi 2009 serinaldi and kilsby 2014a 2016 sirangelo et al 2007 villarini et al 2014 waymire and gupta 1981 wheater et al 2005 wilks 1999 youngman and stephenson 2016 to name just a few we posit that a general unified approach is however possible by assuming that an arbitrary target process x t with prescribed marginal distribution fx x and autocorrelation structure acs ρ x τ has a parent or else an equivalent gaussian process pgp z t with standard gaussian marginal φ z z and a specific linear acs ρ z τ therefore modelling and simulating x t only requires the definition of two functions g and t such that x t g z t and ρ z τ t ρ x τ while g is easily identified as g z f x 1 φ z z this transformation of the marginal distribution does not preserve the linear acs expressed by the pearson correlation coefficient but only rank correlations as g is nonlinear and the acs depends on the marginal distribution fx x embrechts et al 2002 in particular for bivariate normally distributed vectors zi zj and an arbitrary transformation g r r one can show that ρ x cor g zi g zj cor zi zj ρ z kendall and stuart 1979 p 600 this means that we need inflated ρ z values to obtain the target ρ x therefore the modelling problem reduces to the definition of a correlation transformation function ctf t to estimate the parent gaussian autocorrelation pgacs ρ z τ from a given ρ x τ this modelling framework was previously considered in several fields to solve specific problems thus resulting in a sparse literature dealing with simulation of cross correlated but serially independent realizations from multivariate distributions with specified binary discrete and or continuous marginal distributions demirtas 2014 2017 emrich and piedmonte 1991 macke et al 2009 or independent time series with specified serial correlation and binary discrete and or continuous marginal distributions cario and nelson 1997 1998 kugiumtzis 2002 macke et al 2009 serinaldi and lombardo 2017 or focusing on periodic processes tsoukalas et al 2018 moreover most of these studies focused on specific classes of marginal distributions and cs s along with ad hoc solutions for the definition of the ctf t in this study we present a unified and fully general mathematical representation of the parent gaussian modelling framework going beyond specific cases we highlight its generality and its ability to model and simulate processes with both cross and autocorrelations such as spatio temporal hydrological processes we introduce a general and efficient procedure to define the function t based on a simple and flexible parametric function as well as a general purpose technique to simulate the pgp with suitably inflated prescribed cs finally we illustrate the performance of the generalized parent gaussian framework by using a variety of cs s and marginal distributions of discrete continuous and mixed type that provide a suitable representation for most of hydroclimatic processes these diverse examples emphasize how the generalized parent gaussian theory can overcome all ad hoc solutions previously proposed in the literature thus offering a powerful but simple tool that improves the analysis of hydroclimatic variables the paper is organized as follows section 2 provides the theoretical background introducing a unified mathematical representation of the parent gaussian framework starting from the univariate case i e serially autocorrelated processes and then discussing the multivariate extension section 3 starts with a review of marginal distributions and proposes a general framework on how to define and use parametric auto or cross correlation structures suitable to describe a large variety of hydroclimatic processes covering most of the cases of practical interest in hydrological studies then we present a novel general purpose ctf along with a general technique to simulate the parent gaussian process concluding with a step by step synopsis of the simulation algorithm section 4 reports several case studies involving hydroclimatic processes with heterogeneous marginal distributions discrete continuous and mixed type and different cs s e g precipitation river discharge wind speed relative humidity number of extreme events per year etc as well as a multivariate case of rainfall wind and relative humidity finally conclusions are summarized in section 5 2 theoretical framework 2 1 univariate case let x t t t be a stationary stochastic process over an indexed set t having an arbitrary autocorrelation structure acs ρ x t τ for lag τ and with the random variable r v x t following an arbitrary marginal distribution function f x t x stationarity entails no change in the joint probability distribution of any order and for any shift in time and thus x t for brevity t t is omitted hereafter is defined by a single acs ρ x τ and a single marginal distribution fx x as ρ x t τ ρ x τ and f x t x fx x for any t t let z t t t be a standard gaussian process gp with cs ρ z τ implying that any linear combination of z t 1 z tk has a joint standard normal distribution see e g feller 1971 p 87 and any z t follows the standard normal distribution n 0 1 gaussian processes have well defined properties and their simulation is easy therefore the key concept is to identify a parent gp that can be transformed into the process x t therefore to simulate reproduce a stochastic process x t with a given linear acs ρ x τ and a given marginal fx x we need to assess and transform the pgp as the marginal of the gp is known this transformation only requires to assess the acs of the parent gaussian process pgacs ρ z τ yielding the desired target acs let g be a real one to one function with x t g z t transforming z t into x t and z t g 1 x t transforming x t into z t it follows that g z t maps gaussian r v s z t n 0 1 to r v s x t fx x and the pgacs ρ z τ to the target acs ρ x τ and vice versa if g 1 x t is applied to x t this creates a unique mapping between the two processes i e 1 z t z t n 0 1 ρ z τ x t g z t z t g 1 x t x t x t f x x ρ x τ now let us define the transformations 2 x g z q x φ z z 3 z g 1 x q z f x x where φ z z 1 2 erfc z 2 and q z u 2 erf c 1 2 u with 0 u 1 are respectively the distribution and quantile functions of the standard gaussian variate z and qx u the quantile function of x it is well known that qx φ z z maps z to x with qz fx x being its inverse transformation mapping x to z thus for the r v s z t n 0 1 and x t fx x where fx x is any well defined distribution function a pair of transformation exists transforming one into the other and vice versa let x t and x τ x t τ this definition is used for notational simplicity be a pair of x t r v s at an arbitrary time point t lagged by τ and having a correlation coefficient ρ x τ given by 4 ρ x τ e x t μ x t x τ μ x τ σ x t σ x τ e x t x τ μ x 2 σ x 2 where μ x and σ x 2 are the mean and the variance of the r v x given that they are finite as there are r v s with infinite mean and variance in which case the correlation cannot be defined and 5 e x t x τ x t x τ f x t x τ x t x τ d x t d x τ where f x t x τ x t x τ is the joint probability density function pdf of x t and x τ which in general does not have a simple parametric form yet since z t and z τ are jointly normally distributed with correlation ρ z τ and with bivariate pdf 6 φ z t z τ z t z τ 1 2 π 1 ρ z τ 2 exp z t 2 2 ρ z τ z t z τ z τ 2 2 1 ρ z τ 2 we can use the theory of r v s transformations see e g feller 1971 and eq 3 to estimate directly the joint pdf of x t and x τ i e 7 f x t x τ x t x τ φ z t z τ g 1 x t g 1 x τ ρ z τ j x t x τ where j x t x τ g 1 x t x t 0 0 g 1 x τ x τ is the jacobian of the transformation see e g papoulis and pillai 2002 p 244 inspection of 7 reveals that f x t x τ x t x τ is a function of the fx x parameters and of ρ z τ if we insert eq 7 into eq 5 with known ρ z τ and fx x parameters we can calculate numerically the integral and thus the corresponding ρ x τ from eq 4 this creates a one to one link between ρ z τ and ρ x τ the above approach has not been previously proposed in the literature and although it results in complex f x t x τ x t x τ expressions that may affect the numerical integration speed in some cases encountered in numerical experiments e g when gamma type marginals are involved it was faster than the more standard approach described next note that the computation of the jacobian demands the existence of partial derivatives and thus for discrete marginal cases this approach may not be applicable another approach to estimate the ρ x τ is by applying the fundamental probability theorem feller 1971 p 5 stating that given an r v y with known pdf fy y and an r v x h y where h is a real function the expectation of x can be expressed in terms of fy y i e e x e h y h y f y y d y avoiding the calculation of e x x f x x d x which requires knowledge of fx x this theorem applies in higher dimensions and can be used to evaluate e x t x τ in terms of the bivariate standard gaussian pdf eq 6 in combination with the eq 3 transformation the autocovariance transformation integral c θ x ρ z τ is given then by 8 c θ x ρ z τ e x t x τ e q x φ z z t q x φ z z τ q x φ z z t q x φ z z τ φ z t z τ z t z τ ρ z τ d z t d z τ where θ x θ 1 θ n is the parameter vector of the distribution fx x in the copula literature eq 9 is known as the nataf transformation nataf 1962 liu and der kiureghian 1986 li et al 2008 lebrun and dutfoy 2009 xiao 2014 in general the double integral c θ x ρ z τ does not have an analytical solution yet its numerical estimation is trivial introducing c θ x ρ z τ into eq 4 we get the autocorrelation transformation integral acti r θ x ρ z τ i e 9 ρ x τ r θ x ρ z τ c θ x ρ z τ μ x 2 σ x 2 clearly r θ x ρ z τ is a function of θ x and of ρ z τ as μ x and σ x 2 are functions of θ x as well likewise combining f x t x τ x t x τ with eq 4 to calculate ρ x τ the acti creates a link between the ρ x τ and ρ z τ and thus can be applied for any pair of z t z τ or else for all lag values τ 1 τ max transforming essentially the gaussian acs ρ z τ into the acs ρ x τ note this relationship transforms a known ρ z τ value into a ρ x τ value while our goal is to transform an observed or a given ρ x τ value into the corresponding ρ z τ value this is described in detail in section 3 3 2 2 multivariate and cyclostationary case equations previously shown refer to a single stationary stochastic process yet eq 9 can be applied more generally as natural processes vary in space and time we need multivariate and cyclostationary models bartolini et al 1988 salas 1980 salas et al 1982 shao and lund 2004 let us assume n processes e g a single process observed in n different locations n different processes in the same location etc and m seasons e g 12 months 365 days etc i e a total of n m processes and with x i j t denoting the i th process at j th season where i 1 n and j 1 m accordingly for each process we assume a marginal distribution f x i j x an acs ρ x i j τ and for every pair of processes with i j a cross correlation structure ccs ρ x i j x k l τ where k 1 n and l 1 m in this case eq 8 becomes 10 c x i j x k l θ x i j θ x k l ρ z i j z k l τ q x i j φ z i j z t q x k l φ z k l z τ φ z i j t z k l τ z t z τ ρ z i j z k l τ d z t d z τ and thus the cross correlation transformation integral ccti becomes 11 ρ x i j x k l τ r θ x i j θ x k l ρ z i j z k l τ c x i j x k l θ x i j θ x k l ρ z i j z k l τ μ x i j μ x k l σ x i j σ x k l where θ x i j and θ x k l are parameter vectors of fxi j x and fxk l x distributions respectively thus r θ x i j θ x k l ρ z i j z k l τ can be seen as a function transforming a given lag τ correlation ρ z i j z k l τ in a pair of standard gp s into the lag τ correlation ρ x i j x k l τ between x i j t and x k l τ processes thus the difference compared with the univariate stationary case is that here we have a set of n m processes x i j t and we want to assess a set of parent gp s z i j t or else their pgccs s ρ z i j z k l τ given this a multivariate and cyclostationary gp can be transformed into the set of x i j t processes using the corresponding transformations x i j t q x i j φ z i j z t as a result the problem of generating time series from a multivariate cyclostationary model comprising processes with different characteristics simplifies in generating time series from a multivariate cyclostationary standard gp 3 from theory to practice 3 1 marginal distributions of hydroclimatic processes 3 1 1 continuous common hydroclimatic processes like temperature wind precipitation river discharge relative humidity etc have continuous or mixed type partly continuous and partly discrete marginal probability distributions the number of parametric distributions found in the literature to describe hydroclimatic r v s is very large air temperatures is commonly described by the gaussian distribution e g klein tank and können 2003 the two parameter weibull has been the prevailing model for wind speeds e g justus et al 1978 seguro and lambert 2000 yet gamma lognormal and pearson type i distributions have also been used for wind for a review see carta et al 2009 nonzero daily precipitation has been modelled by gamma e g buishand 1978 bruhn et al 1979 geng et al 1986 weibull e g swift and schreuder 1981 wilson and toumi 2005 exponential and mixed exponentials distributions e g smith and schreiber 1974 todorovic and woolhiser 1975 wilks 1999 or by heavier tailed distributions like the lognormal e g swift and schreuder 1981 kappa mielke 1973 mielke and johnson 1973 hosking 1994 park et al 2009 and the generalized beta distribution mielke and johnson 1974 for a detailed global investigation on the distribution of seasonal daily precipitation see papalexiou and koutsoyiannis 2016 where the generalized gamma and the burr type xii have been used for global analyses on precipitation extremes see papalexiou et al 2013 papalexiou and koutsoyiannis 2013 serinaldi and kilsby 2014b river flows have been described by the lognormal and pareto distributions e g bowers et al 2012 the pearson type iii and the 3 parameter lognormal distributions were suggested for low stream flows kroll and vogel 2002 the beta distribution has been found to describe very well relative humidity values e g yao 1974 and also is a candidate model for percentage r v s like probability dry percentage of area affected by extreme temperature or precipitation etc a complete review on the probability models applied in geophysical and hydroclimatic processes would be a difficult task by itself and out of the scope this study a common practice is to fit many distributions and select the best fitted yet this approach is susceptible to sample variations in an attempt to simplify this procedure and based on entropy information measures a general theoretical framework was proposed papalexiou and koutsoyiannis 2012 that led to consistent distributions for positive geophysical and hydroclimatic r v s particularly the generalized gamma g g stacy 1962 stacy and mihram 1965 and the burr type xii distributions b r xii burr 1942 tadikamalla 1980 were derived yet the burr type iii b r iii is also proposed here as a general and flexible power type model the probability density function of g g distribution and the distribution functions of the b r xii and b r iii are given respectively by 12 f g g x β γ 1 γ 2 γ 2 β γ γ 1 γ 2 x β γ 1 1 exp x β γ 2 13 f b r xii x β γ 1 γ 2 1 1 γ 2 x β γ 1 1 γ 1 γ 2 14 f b r iii x β γ 1 γ 2 1 1 γ 1 x β 1 γ 2 γ 1 γ 2 these distributions defined for x 0 have the scale parameter β 0 and the shape parameters γ 1 0 and γ 2 0 controlling the left and right tails respectively their pdf s are j shaped for γ 1 1 and bell shaped for γ 1 1 while the parameter γ 2 controls mainly the heaviness of the right tail and thus the behaviour of extreme events note that g g is of exponential form with finite moments while b r xii and b r iii are power type distributions that can have very heavy tails and infinite moments the g g can be considered as a generalization of the two parameter gamma and weibull distributions while the b r xii includes as special cases the pareto type ii for γ 1 1 or the weibull distribution as limiting case for γ 2 clearly the principle of parsimony which requires to always seek for the simplest model i e to use the smallest number of parameters possible see e g box et al 2008 p 16 should always be applied for example if a weibull distribution performs satisfactorily under desired criteria then it should be preferred over the three parameter g g the same holds for the power type distributions b r xii and b r iii where the simpler pareto type ii should be the first choice under adequate performance 3 1 2 mixed type discrete and binary several natural processes like precipitation at fine temporal scales e g at daily or subdaily scales discharge of small streams or even wind are intermittent processes thus their marginal distribution comprises a probability mass concentrated at zero e g probability dry in precipitation and a continuous part for the positive values expressed by a parametric distribution function the framework to simulate intermittent processes is the same see section 2 the difference lies in the expressions of the distribution function fx x and the quantile function qx u that are now related to the conditional expressions for x x 0 particularly if p x 0 p 0 is probability zero then the cdf pdf and quantile function of x are given respectively by 15 f x x 1 p 0 f x x 0 x p 0 x 0 16 f x x p 0 x 0 1 p 0 f x x 0 x x 0 17 x u q x u 0 0 u p 0 q x x 0 u p 0 1 p 0 p 0 u 1 the dirac delta notation can also be used to define the pdf additionally the expressions of the mean and variance of x used to estimate the ctf s in eq 9 or eq 11 become 18 μ x 1 p 0 μ x x 0 19 σ x 2 1 p 0 σ x x 0 2 p 0 1 p 0 μ x x 0 2 the probability zero can be easily assessed from the empirical data as p 0 n 0 n with n 0 and n denoting respectively number of dry and total days while for positive values any suitable parametric continuous distribution f x x 0 x could be used this framework can be extended to include cases where values above a threshold are considered i e the discrete part can express the pr x xp for an arbitrary value xp and the continuous part values for x x xp finally more general mixed type marginal distributions can be considered e g the water storage in a reservoir varies theoretically from zero to a maximum level when capacity is reached thus as a variable it may have two discrete states i e probability zero and probability for maximum capacity all in between values can be described by a continuous bounded distribution important aspects of various geophysical processes can be considered to have a discrete or a binary marginal distribution see e g chung and salas 2000 molotch et al 2005 serinaldi and lombardo 2017 for example the number of consecutive wet and dry spells in days hours etc the number of days per year having a specific property e g temperature precipitation or wind speed above a threshold extremes the number of wet days per year binary sequences to describe wet and dry days and many more as in the mixed type case the methodology remains the same modified only by using expressions for the quantile mean and variance that correspond to the discrete or the binary probability mass function chosen 3 2 autocorrelation acs and cross correlation structures ccs empirical autocorrelation or cross correlation ρ τ especially for small samples and for large lags τ is sensitive to sample variations and calculated up to a maximum lag 1 3 of the sample size is usually suggested a better approach may be to fit a parametric acs to ρ τ expressed by a simple function ρ τ θ where θ θ 1 θ k is the parameter space of the acs essentially interpolating the values of ρ τ and providing a smoother result also it could be desirable to assign a prescribed acs or ccs e g in sensitivity analysis scenarios or if regional information is transferred to a location of interest as in waldo tobler s first law of geography stating that near things are more related than distant things it is well known things closer in time are more related than distant things thus we can assume that a monotonically decreasing function of lag τ or distance having ρ 0 θ 1 and lim τ ρ τ θ 0 can serve as an acs a general class of functions proposed here with these properties are the complementary cumulative distribution functions ccdf but now treated as functions and not as probability laws note that valid acs s and ccs s have to be positive definite to guarantee that the parent gaussian processes are stationary see e g yaglom 2012 p 57 we deem that by definition a ccdf function fulfils this conditions for a treatise on strictly positive definite functions see chang 1996 however pathological cases may be possible to be formed for example a function that equals to 1 up to a given lag and then gets 0 cannot be a proper correlation function for more examples see e g dolloff et al 2006 yet in real world cases this specific issue cannot be observed as correlation equal to 1 in a dataset indicates an exact linear deterministic relationship and thus the correlations for any lag would also equal to 1 excluding the possibility for any other value in any case positive definiteness of a function should be considered when we construct theoretical acf s and ccf s based on the previously described rational the weibull acs is then given by 20 ρ w τ b c exp τ b c with b 0 and c 0 and forms a generalization of the celebrated markovian acs as it is identical for c 1 yet decays slower for c 1 and faster for c 1 note that ρ w τ can be expressed also in terms of the lag 1 correlation ρ 1 i e ρ w τ ρ 1 τ c a similar stretched exponential form was used for space correlation of rainfall ciach and krajewski 2006 likewise a power type acs is formed by the pareto ii ccdf i e 21 ρ pii τ b c 1 c τ b 1 c with b 0 and c 0 the pii acs decays always slower than the markovian yet it becomes identical as c 0 a similar two parameter power type acs named cauchy class was also proposed by gneiting and schlather 2004 as generalization of the fractional gaussian noise fgn acs the weibull and pii acs s can be merged into a three parameter expression which coincides with the burr type xii ccdf i e 22 ρ brxii τ b c 1 c 2 1 c 2 τ b c 1 1 c 1 c 2 with b 0 c 1 0 and c 2 0 for c 2 0 ρ brxii τ b c 1 c 2 ρ w τ b c 1 1 c 1 c 1 and for c 1 1 it equals the pii acs this general expression with a different parametrization was also used in papalexiou et al 2011 yet it was not suggested within the general framework proposed here and was not identified as the burr type xii ccdf note that we can form acs s decaying even slower than power type acs s e g a general logarithmic expression gl proposed here generalizing also the markovian acs is 23 ρ gl τ b c 1 ln 1 c x b 1 c with b 0 and c 0 for c 0 coincides with the markovian acs i e lim c ρ gl τ b c exp x b this acs for large values of c can have extremely slow decay rates and may be useful for processes at the second or millisecond time scales another noteworthy acs is the celebrated fgn or hurst acs e g beran 1994 p 52 linked to long term persistence ltp and fgn processes hurst 1951 mandelbrot and wallis 1968 1969 given by 24 ρ fgn τ h 1 2 τ 1 2 h 2 τ 2 h τ 1 2 h τ 2 1 h where 0 h 1 is the hurst coefficient also farima models granger and joyeux 1980 hosking 1981 have a similar acs asymptotically equivalent to the ρ fgn τ yet their acs is more flexible as it allows to control short term correlations see e g hosking 1984 montanari et al 1997 for applications in hydrology noteworthy recent global studies on annual precipitation iliopoulou et al 2016 and river discharge markonis et al 2018 challenge the ltp hypothesis as the findings suggest very low values of the h coefficient that could also emerge from markovian processes here we propose a convenient generalization of the fgn acs i e the generalized fgn gfgn given by 25 ρ gfgn τ ρ 1 h h 2 h 1 τ 1 ρ 1 h 2 h 1 1 2 1 h 2 1 h τ 2 1 h this acs well defined for τ 1 converges very fast to the classical fgn acs yet for lag τ 1 we have ρ gfgn 1 ρ 1 h ρ 1 and thus it allows full control of the short term properties of the acs also various other correlation functions have been proposed e g for wind and atmospheric data buell 1972 gneiting 1999 in the cross correlation case between two process e g of xi t and xj t since ρ x i x j τ ρ x i x j τ for τ 0 and ρ x i x j 0 1 we can still use parametric ccs s similar to the acs s framework if this is desired by modifying them as 26 ρ x i x j τ ρ cs τ 1 θ τ 0 ρ cs 1 τ θ τ 0 where ρ cs τ can be any parametric cs like the weibull pii etc with different parameter values for τ 0 and τ 0 to fulfil the condition of ρ x i x j τ ρ x i x j τ of course an infinite number of acs or ccs s can be formed with many more parameters yet according to the parsimony principle we should choose the one with the less possible parameters box et al 2008 p 16 although bias issues in estimating empirical correlations are beyond the scope of this study yet it is crucial to mention that the empirical acs of a process having a very intense underlying acs e g an fgn with high values of h will be observed most probably weaker especially for small samples and will also affect the sample standard deviation in general a straightforward and easy method to estimate any linear acs without bias does not exist formulas exist only for special cases like the fgn acs see e g beran 1994 and should be applied if there is evidence for ltp before estimating the pgacs for most hydroclimatic processes however and when dealing with time scales larger than the daily or even hourly for precipitation the empirical acs s are not intense and thus the bias is not expected to be significant also as afore mentioned the existence of ltp in processes like river discharge is challenged see e g markonis et al 2018 nevertheless for processes at fine temporal scales we may observe very strong acs s see the example in section 4 1 that can lead to significant biases in the estimation of the underlying acs and of the standard deviation see e g papalexiou et al 2011 and references therein finally it should be clear that the parent gaussian framework reproduces linear correlation structures as expressed by the pearson correlation coefficient and does not consider other types of correlations e g rank correlations kendal s tau spearman s rho etc or more general correlation topologies that can emerge by other models for example there is an increasing interest over the last decade on the spatial dependence structure of extreme events using max stable processes see e g davison et al 2012 huser et al 2016 huser and genton 2016 ribatet 2013 stephenson et al 2016 an approach that may lead to structures which the framework presented here may not be able to reproduce yet it is still a matter of debate if modelling extremes directly is a better approach compared to modelling the process itself e g in the presence of ltp it was shown that the latter approach should be preferred serinaldi et al 2018 also note that the behaviour of spatial extremes is essentially governed by the tail of a multivariate distribution or by the random field properties and thus it is rational to assume that if the multivariate process or the field itself is simulated accurately then the structure of extremes will be also consistently reproduced certainly both approaches have advantages and disadvantages that depend on many factors for example analysis of above a threshold extremes provides a more accurate estimation of the distribution tail see e g papalexiou et al 2013 than using the whole set of observations in contrast using annual maxima may lead to increased uncertainty in the estimation of the heaviness of the tail especially when fixed block maxima are used papalexiou et al 2016 van montfort 1990 3 3 auto and cross correlation transformation function 3 3 1 autocorrelation transformation function actf the acti in eq 9 transforms a specific autocorrelation value ρ z between a pair of z t and z τ r v s of the gp lagged by τ into the autocorrelation ρ x between the x t and x τ r v s of the target process yet the inverse relationship is desired for all practical purposes that is an actf t ρ x where we introduce any value of ρ x or any acs ρ x τ and get respectively the pgp ρ z value or the pgacs ρ z τ we assume here positive correlations ranging in 0 1 yet the framework can be expanded easily for negative correlations too essentially we evaluate the acti in a small set of ρ z values to create ρ x ρ z points and interpolate them by fitting a simple parametric function since ρ z τ ρ x τ kendall and stuart 1979 p 600 the actf t should have the potential to be concave and also pass from the 0 0 and 1 1 points as for ρ z equal to 0 and 1 ρ x is also 0 and 1 a simple two parameter function with these properties that is proposed here is heuristically evaluated and found to perform perfectly in all cases of continuous and mixed type marginals studied is 27 ρ z t ρ x b c 1 b ρ x 1 c 1 1 b 1 c 1 which is concave for b 0 and c 0 while for b 0 and c 1 we have ρ z ρ x unless stated this will be the basic actf used in the examples of this study the previous function performs also well for the discrete and binary case yet the alternative 28 ρ z t ρ x b c 1 1 ρ x b c seems to perform better for discrete cases and especially for the binary case this function is concave for 0 b 1 and c 1 for b 1 and c 1 we have ρ z ρ x note that eq 28 coincides with the kumaraswamy cdf kumaraswamy 1980 yet here is used as parametric function and not as probability law thus we can now form a one to one relationship that enables the calculation of the pgp ρ z either as a single value or as a parametric pgacs if a parametric acs ρ x τ is plugged into eq 27 or eq 28 any of the actf s t ρ x b c functions can be easily fitted if we evaluate the acti eq 9 for ρ z 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 95 and use the corresponding set of ρ x ρ z points we stress that this approach is simpler and by far more efficient than iterative methods and polynomial approximations previously proposed see e g demirtas 2014 ferrari and barbiero 2012 kugiumtzis 2002 let us assume that we target a process x t having a weibull w β γ marginal distribution f x x f w x 1 exp x β γ and a markovian acs ρ x τ ρ m τ ρ 1 ρ 1 τ with ρ 1 0 8 for illustration and comparison purposes we assume three different w distributions fig 1 a with scale parameter β 1 and shape parameters γ 2 0 5 0 25 respectively the estimated ρ x ρ z points gray dots in fig 1b and the fitted t ρ x b c functions fig 1b show very different transformation profiles i e for the bell shaped w 1 2 which resembles the gaussian distribution essentially ρ z ρ x and the pgacs coincides with ρ x τ fig 1c as we deviate from normality e g the w 1 0 25 has a heavy tail and very high skewness the actf becomes more concave resulting in very different pgacs s fig 1c note that a markovian acs ρ x τ is not reproduced by a markovian pgacs e g for the w 1 0 25 case the ρ x 1 0 80 corresponds to ρ z 1 0 93 which does not imply that the markovian acs ρ z τ 0 93 τ will reproduce the ρ x τ 0 80 τ it will only preserve the ρ x 1 another example showing how the concavity of the actf changes regards mixed type marginal distributions suitable to model intermittent processes like precipitation or wind and discharge in some cases let us target for an intermittent process x t having probability zero p 0 a pareto ii p ii β γ marginal distribution f x x f p ii x 1 1 γ x β 1 γ for nonzero values with β 1 and γ 0 3 and an fgn acs eq 24 ρ x τ ρ fgn τ h with h 0 75 for comparison we use p 0 0 0 9 0 99 with the unconditional p ii pdf s shown in fig 1d note that it is common to observe p 0 equal to high values such as 0 90 and 0 99 for daily and hourly rainfall records respectively the ρ x ρ z points and the fitted t ρ x b c functions fig 1e show how concavity increases as p 0 increases resulting in very different pgacs fig 1c and thus for large values of p 0 a much stronger ρ z τ is necessary to preserve the ρ x τ as in the previous example the pgacs of the fgn acs is not an fgn acs with just a different h value in summary we note that the concavity of the actf or else the difference between the target acs and the pgacs depends on how much the target marginal deviates from normality cleary a unique method to quantify this deviation does not exist as deviations may regard the general shape e g skewed vs symmetric densities the heaviness of the tail e g exponential vs power type tails or the type of the density i e mixed type vs continuous type consequently we could speculate that when the target marginal is of continuous type has a moderately skewed and bell shaped pdf e g as in the bell shaped weibull pdf example fig 1a then the linear correlation has a small bias in other words ρ z τ could be approximated by the actual ρ x τ and thus we can directly transform the gaussian time series avoiding calculating the integrals and fitting the actf 3 3 2 cross correlation transformation function cctf in the previous case the actf was constrained to pass from the 1 1 point yet for cross correlation this is not mandatory the cross correlation ρ x i x j between two stationary processes xi t and xj t has boundaries depending on the marginal distributions f x i x and f x j x thus there is a range of admissible ρ x i x j values according to the frechet hoeffding theoretical limits i e 1 min ρ x i x j ρ x i x j max ρ x i x j 1 embrechts et al 2002 fréchet 1957 hoeffding 1994 these boundary values can be checked for each specific application by using for example the procedure suggested by demirtas and hedeker 2011 however this check is not required in our approach as the interpolation procedure automatically determines the feasible range of ρ x i x j and thus the ρ max max ρ x i x j here we propose as cctf a simple two parameter function that performed extremely well in all cases studied i e 29 ρ z i z j t ρ x i x j b c 1 b ρ x i x j c 1 note that if more flexibility is needed the three parameter ρ z i z j 1 b ρ x i x j c 1 c 2 1 can be used this function eq 29 is essentially the same as the actf in eq 27 but without the denominator part which forced the function to pass from 1 1 it is valid for b 0 concave for c 1 linear for c 1 and convex for c 1 as in the actf case we can easily fit the cctf by evaluating the ccti in eq 11 for ρ z i z j 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 95 0 99 and creating the corresponding ρ x i x j ρ z i z j points once the cctf parameters are estimated we can determine easily the ρ max by setting ρ z i z j 1 in eq 29 and solve for ρ x i x j i e 30 ρ max 2 1 c 1 b let us assume a process x 1 t with a weibull marginal w 1 0 5 and a process x 2 t with a beta marginal b γ 1 γ 2 for comparison purposes we use three different beta pdf s having negative zero and positive skewness fig 2 a we use the ccti of eq 11 to estimate the ρ x i x j ρ z i z j points grey dots in fig 2b and we fit the cctf in eq 29 noteworthy for the negatively skewed beta the cctf is convex almost a straight line for the symmetric and concave for the positively skewed while the corresponding ρ x i x j limits estimated from eq 30 are 0 53 0 64 and 0 75 respectively this indicates that the more the two marginals differ the more their maximum cross correlation value ρ x i x j will be decreased we also show the pgccs of a markovian ccs fig 2c clearly not all ccs are feasible due to the maximum limit another interesting example is to assume cross correlated processes with mixed type marginals that differ in probability zero we assume a heavy tailed continuous marginal p ii 1 0 3 for the first process x 1 t while for x 2 t we use three different mixed type p ii 1 0 3 marginals with p 0 0 5 0 9 0 99 fig 2d using the ccti of eq 11 we calculate the ρ x i x j ρ z i z j points grey dots in fig 2e and we fit the cctf of eq 29 all cctf s are concave while the corresponding ρ x i x j limits estimated from eq 30 are 0 98 0 89 and 0 66 respectively indicating a decrease in the maximum cross correlation as p 0 increases or else as the two marginals differ more in fig 2f we show the pgccs of the markovian ccs used in the previous example clearly as p 0 increases much stronger pgccs are needed to reproduce the target ccs 3 4 gaussian univariate and multivariate processes with arbitrary cs we can easily simulate a standard gp i e with μ 0 and σ 1 having an arbitrary parametric acs ρ z τ by using an autoregressive process of order p ar p defined by 31 z t i 1 p a i z t i ɛ t where ɛ t n 0 σ ɛ 2 is gaussian random noise with σ ɛ 2 1 i 1 p a i ρ z τ and ai are the model parameters for a given parametric acs ρ z τ the a 1 ap can be easily and analytically computed using the yule walker equations e g box et al 2008 p 67 i e a p 1 ρ where a t a 1 ap is the parameter vector ρ t ρ z 1 ρ z p is the correlation vector up to lag p and p ρ z i j is the p p correlation matrix with i and j denoting respectively the i th row and j th column e g the p 2 3 element is simply the value of ρ z 1 for more on ar models see box et al 2008 thus an ar p model preserves exactly a given acs ρ z τ up to lag p and then for τ p 1 decays according to ρ ar p τ i 1 p a i ρ z τ i a relation that can be easily applied recursively for example fig 3 shows the approximation of two parametric acs up to various lags i e of a weibull with b 10 and c 0 5 decaying thus slower than the markovian acs and a very strong pareto ii acs with b 5 and c 4 clearly the closer the acs is to the markovian the better will be approximated by the ρ ar p τ for τ p 1 in any case a parametric acs can be approximated up to any desired lag e g even an ar 5000 can be easily fitted to avoid any confusion we emphasize that here we fit the theoretical acf of an ar p model to a target parametric acs this method only requires estimation of a couple of parameters i e those of the fitted parametric acs to the data while the p parameters of the fitted ar p model are simply coefficients constants estimated analytically and without uncertainty corresponding to the target parametric acf thus this approach is parsimonious and efficient e g an ar 5000 fitted to a two parameter acs is essentially a two parameter model another approach to generate time series from a standard gp having an arbitrary acs ρ z τ is based on approximating ρ z τ by a sum of independent ar 1 processes an idea originally proposed and used by mandelbrot 1971 to approximate the fgn acs particularly if we define 32 z t i 1 n y i t with yi t ρ i 1 yi t 1 ε i t being the i th ar 1 process in the sum having mean μ y i 0 standard deviation σ y i lag 1 correlation ρ i 1 and ɛ i t n 0 1 ρ i 1 2 σ y i 2 then since the ar 1 processes are independent the variance and the cs of the sum process are σ z 2 i 1 n σ y i 2 and ρ σ τ 1 σ z 2 i 1 n ρ i 1 τ σ y i 2 respectively of course if we demand z t to have σ z 2 1 then i 1 n σ y i 2 is also constrained to equal 1 the ar 1 parameters can be estimated by numerically minimizing an error norm between ρ σ τ and ρ z τ up to a desired lag τ for an application using five independent ar 1 approximating the acs given eq 22 see papalexiou et al 2011 the corresponding multivariate autoregressive model mar p of n processes is defined by 33 z t i 1 p a i z t i b ɛ t where z t z 1 t zn t t a i and b are n n parameter matrices and ε t ε1 t ε n t t is an n vector of independent standard gaussian variables for a general algorithm to fit mar p models of large order see neumaier and schneider 2001 schneider and neumaier 2001 and schlögl 2006 clearly large order mar models are complicated and often unnecessary e g when markovian acs and ccs are observed a mar 1 is sufficient the parameters of the mar 1 model z t az t 1 bε t can be estimated by using the relations a k z 0 k z 1 1 and b b t k z 0 ak z t 1 thus b can be found using e g choleski decomposition where k z 0 and k z 1 are the correlation matrices of the n gaussian processes see also section 4 5 for an application clearly analytical or exact estimation of b demands the matrix bb t to be positive definite a condition that is not always fulfilled in this case the matrix b can be approximated using near matrix methods see e g higham 1988 2002 finally note that cyclostationarity can be introduced by using different mar processes for each season 3 5 a stochastic modelling recipe step by step the proposed stochastic modelling framework is summarized in the following steps 1 assess suitable marginal distributions and correlation structures auto and cross correlations for the multivariate case from the empirical time series 2 estimate the ρ x ρ z points for the proposed ρ z values see section 3 3 1 using the acti in eq 9 and fit the parametric actf of eq 27 or eq 28 for binary marginals to the points for the multivariate case estimate ρ z i z j ρ x i x j points using the ccti in eq 11 and fit the cctf in eq 29 3 insert the target acs ρ x τ into the fitted actf t ρ x τ b c to estimate the pgacs ρ z τ for the multivariate case use the fitted cctf t ρ x i x j τ b c to find the pgccs ρ z i z j τ 4 use the estimated pgacs and the pgccs to fit an ar p or mar p model and generate gaussian univariate or multivariate time series 5 transform the gaussian time series using the corresponding transformation x i t q x i φ z i z t based on the fitted distributions from step 1 4 real world examples 4 1 storm events of fine temporal resolution the method is applied to simulate rainfall events at fine temporal scale 10 seconds resolution a process displaying strong acs highly skewed and heavy tailed continuous marginal distribution the original data are seven storm events recorded at the hydrometeorology laboratory at the iowa university georgakakos et al 1994 note this dataset has been used also in other studies see e g papalexiou et al 2011 for a statistical and stochastic analysis cârsteanu and foufoula georgiou 1996 for a multifractal analysis and kumar and foufoula georgiou 1997 for a wavelet analysis we assume that these events are the outcome of a single process papalexiou et al 2011 and thus the characteristics of the process are better determined if all events are merged into one set despite their large statistical differences see fig 4 a nonetheless the aim here is not a detailed analysis of the data but rather to illustrate the applicability of the method in a highly non gaussian process with strong acs in addition other issues like the bias in the estimation of the acs are not considered for these details see papalexiou et al 2011 the method is graphically demonstrated in fig 4 first a parametric distribution is fitted to the empirical distribution fig 4b here the b r x ii is used the estimated parameters using the method of l moments hosking 1990 are β 2 13 γ 1 0 74 and γ 2 0 22 see papalexiou and koutsoyiannis 2016 for details about fitting the b r xii using l moments second the observed acs ρ x τ is approximated by numerically fitting the parametric weibull acs ρ w τ given in eq 20 with estimated parameters β 80 6 and γ 0 73 fig 4c i e it is assumed that ρ x τ ρ w τ β γ third the αcti r θ x ρ z in eq 9 is applied using the fitted b r xii distribution to estimate a few ρ x ρ z points grey dots in fig 4d which are interpolated by the actf in eq 27 with parameters c 1 2 96 and c 2 0 93 fourth the fitted actf is applied to the estimated ρ w τ β γ to obtain the pgacs ρ z τ fig 4e fifth a large order ar model is used i e ar 1000 to reproduce the fitted pgacs ρ z τ and generate gaussian time series fig 4f sixth synthetic time series emerge by simply transforming the gaussian time series using eq 2 and the fitted b r xii fig 4e for verification the empirical distribution of the synthetic time series is compared with the target b r xii that was fitted to the original data fig 4h while the empirical acs of the gaussian and synthetic time series are compared with the target ρ z τ and ρ x τ fig 4i 4 2 hourly precipitation stochastic modelling of hourly precipitation has been the subject of active research for more than three decades having important applications e g in rainfall run off modelling previous methods have mainly focus on point process models like the barlett lewis and the neyman scott see e g istok and boersma 1989 onof et al 2000 onof and wheater 1993 rodriguez iturbe et al 1987 verhoest et al 1997 wheater et al 2005 these models do not reproduce the actual marginal distribution but rather attempt to approximate it by preserving a number of statistical moments usually up to the third aiming to reproduce skewness at their core exponential and gamma distributions are used that may underestimate return levels which is a well known weakness that has motivated alternative approaches see e g onof et al 2005 the framework presented here is scale free as it can be applied at any time scale including hourly we demonstrate the performance of the method by using an hourly precipitation record from the unites states randomly selected from the ncdc database hammer and steurer 1997 station code 063456 covering the period from 01 08 1954 to 30 11 2011 fig 5 a assuming hourly precipitation as a cyclostationary process i e stationary at each month we apply the steps described in section 3 5 twelve times in brief high probability dry values are observed within the twelve months ranging from 0 90 to 0 95 figs 5c d and a 1 while the nonzero hourly rainfall is adequately described by fitted g g distributions eq 12 the estimated parameters for all months are given in fig a 1 the pareto ii acs eq 21 interpolates accurately the linear empirical acs see correlograms and estimated parameters in figs 5e f and a 2 and the pgacs for each month is estimated using the expressions for the mixed type case eqs 17 19 high probability dry values and high skewness of the target marginals inflate significantly the pgacs which approximates 0 in all months for τ 3 24 thus an ar 72 was used to generate the gaussian time series the synthetic rainfall was generated for the same period as the observed one fig 5b and emerged by transforming the gaussian time series using the corresponding marginal back transformations of each month the empirical probability distributions figs 5c d and a 1 as well as the empirical acs s figs 5e f and a 2 of the synthetic time series show the precise reproduction of their target counterparts of course any minor deviations shown are due to random sample variations and not due to any systematic bias of the method we also highlight the one state framework of this method as common precipitation generators e g point process models use two states one to simulate the wet dry days sequence and a second one to calculate the intensity of wet days see also wilks 1998 here the intermittency is introduced naturally by applying the mixed type marginal back transformation note that this framework compared to the afore mentioned popular models has the advantage of reproducing the actual marginal and acs while it can be equally or even more parsimonious depending of course on the selected marginal distribution and parametric acs for example the total number of parameters we estimate to model hourly precipitation for each month is just five i e three for the marginal and two for the acs all the rest are deterministically estimated and thus are not essentially parameters 4 3 daily precipitation river discharge and wind daily precipitation is another important case of an intermittent process that plays a crucial role in hydrology here we use october s daily rainfall recorded at the national observatory of athens in greece from 24 04 1927 to 20 02 1990 fig 6 a assuming stationarity within the month the probability dry was found p 0 0 78 the nonzero rainfall was described by an f g g x 16 5 0 39 0 97 distribution eq 12 papalexiou and koutsoyiannis 2016 and a weibull acs eq 20 was fitted to the empirical acs i e ρ x τ ρ w τ 0 43 0 48 fig 6e the acti in eq 9 was used to estimate ρ x ρ z points fig 6b using the corresponding expressions for the mixed type case i e the quantile function mean and variance are given now by eqs 17 19 respectively the correlation transformation function t ρ x 13 88 0 75 fitted perfectly to the ρ x ρ z points fig 6b and was used to estimate the pgacs i e ρ z τ t ρ w τ 0 43 0 48 13 88 0 75 fig 6e the ρ z τ 0 for τ 20 thus an ar 20 was fitted to ρ z τ for τ 1 20 and used to generate a gaussian time series of 1000 months 31 1000 values the gaussian time series was transformed to synthetic rainfall fig 6c shows sample size equal with the original time series by applying the transformation in eq 2 with qx being the mixed type quantile in eq 17 with the estimated p 0 and the fitted g g quantile for verification the empirical distribution and the empirical acs of the synthetic sample is compared with the target f g g x 16 5 0 39 0 97 distribution fig 6d and the target acs ρ x τ ρ w τ 0 43 0 48 fig 6e another important variable is daily river discharge here we use daily values of april observed in the middle fork snoqualmie river at the usa from 01 02 1961 to 06 11 2016 fig 6f assuming again a stationary process for same month days daily discharge was found to be well described by the heavy tailed f b r iii x 40 5 12 6 0 37 distribution eq 14 while the empirical acs fitted well to a relatively slowly decaying weibull acs eq 20 i e ρ x τ ρ w τ 3 5 0 79 fig 6j the estimated correlation transformation function t ρ x 0 74 2 77 fig 6g was applied to evaluate the pgacs ρ z τ fig 6j which gets ρ z τ 0 for τ 25 thus a gaussian time series of 1000 months 31 1000 values was generated from a fitted ar 25 and was transformed to synthetic daily discharge fig 6h by applying the transformation in eq 2 with qx being the quantile of the fitted b r iii the synthetic time series have the expected f b r iii x 40 5 12 6 0 37 marginal fig 6i and the expected acs ρ w τ 3 5 0 79 fig 6j as a final example the method is applied to daily wind speed of january recorded at maastricht in the netherlands from 01 01 1957 to 31 12 2016 fig 6k daily wind speed is described here by the f g g x 4 4 2 66 1 76 distribution eq 12 as commonly used models like the two parameter weibull distribution or the two parameter gamma distribution did not perform well also zero values were not recorded and thus the marginal is assumed continuous the pii acs in eq 21 was fitted to the empirical acs i e ρ x τ ρ pii τ 1 7 0 68 the estimated correlation transformation function t ρ x 0 31 0 18 fig 6l shows no concavity and thus the pgacs ρ z τ coincides with ρ x τ lines overlap in fig 6o the ρ z τ ρ x τ 0 for τ 25 and thus an ar 25 was used to generate a gaussian time series 31 1000 values which was then converted to synthetic daily wind speed fig 6m by applying the transformation in eq 2 with qx being the quantile of the fitted g g the synthetic time series have the expected marginal fig 6n and the expected acs fig 6o 4 4 relative humidity discrete and binary cases many variables in nature can be expressed in the 0 1 range e g relative humidity probability dry percentage variables etc here the method is applied on november daily values of relative humidity recorded at maastricht in the netherlands from 01 01 1957 to 31 12 2016 fig 7 a a two parameter beta b distribution was used i e f b x 16 1 2 3 and a pii acs eq 21 was fitted to the empirical acs i e ρ x τ ρ pii τ 0 80 1 16 the estimated actf t ρ x 3 24 0 07 fig 7b is a straight line and the pgacs ρ z τ coincides with ρ x τ lines overlap in fig 7e the ρ z τ ρ x τ 0 for τ 30 and thus an ar 30 was used to generate a gaussian time series 31 1000 values which was transformed to synthetic daily relative humidity fig 7c by applying the transformation in eq 2 with qx being the quantile of the fitted beta the synthetic time series have the expected marginal fig 7d and the expected acs fig 7e as an example of a process with discrete marginal distribution we use the number of extreme daily precipitation events per year i e in an n year record we identify the n largest values and their dates and count the number in each year here we used a long daily rainfall record randomly selected from the ghcn daily database id asn00008067 to form the number of extremes per year time series fig 7f a two parameter discrete distribution was used i e the polya aeppli p a distribution f p a x 0 85 0 15 to describe the probability to observe a given number of extremes in any year the empirical autocorrelation is essentially 0 and thus for demonstration purposes a pii acs eq 21 was prescribed i e ρ x τ ρ pii τ 1 1 we fit the kumaraswamy actf in eq 28 i e t ρ x 1 0 1 22 fig 7g while the pgacs ρ z τ 0 for τ 30 fig 7j and thus an ar 30 was used to generate a gaussian time series 3000 years which was transformed to synthetic number of extremes per year fig 7h by applying the transformation in eq 2 with qx being the quantile of the fitted polya aeppli distribution the synthetic time series have the expected marginal fig 7i and the expected acs fig 7j in many cases we may desire to express a variable in two states e g rain and no rain we use the same daily rainfall record asn00008067 aggregated to the annual timescale to form a binary time series by assigning 0 to annual precipitation values that belong to the first quartile low values indicating drought years and 1 to the rest fig 7k the bernoulli b e distribution was used with pr x 0 0 25 to describe the probability to observe a drought year and a weibull acs was prescribed i e ρ x τ ρ w τ 2 0 5 to demonstrate the method as the empirical correlation is almost zero the estimated kumaraswamy actf t ρ x 1 03 1 97 fig 7l shows moderate to strong concavity with a perfect fit to the points while the pgacs ρ z τ 0 for τ 30 fig 7o gaussian time series 3000 years were generated from an ar 30 and transformed to binary time series accordingly fig 7m the synthetic binary time series have the expected marginal fig 7n and the expected acs fig 7o 4 5 a multivariate simulation of precipitation wind and relative humidity as a final example we demonstrate the method in a multivariate simulation of three different processes at daily scale i e of precipitation x 1 t wind speed x 2 t and relative humidity x 3 t for precipitation we assume probability dry p 0 0 7 and for positive values a power type b r xii 2 0 9 0 2 distribution for wind probability of zero speed p 0 0 1 and for positive values the two parameter weibull w 5 1 2 distribution and for relative humidity a kumaraswamy k u 11 5 marginal distribution fig 8 a c thus we have two mixed type marginals with different p 0 and different continuous part and a continuous marginal bounded in 0 1 also we assume lag 0 and lag 1 correlation matrices 34 k x 0 1 0 50 0 35 0 50 1 0 60 0 35 0 60 1 k x 1 0 30 0 25 0 15 0 10 0 40 0 35 0 12 0 30 0 50 with the i j element expressing the cross correlation coefficients ρ x i x j τ for lags 0 or 1 between the i th and j th process of course the diagonal in k x 1 refers to the lag 1 autocorrelation note that k x 0 is always symmetric while k x 1 is not the actf s fig 8d f show moderate concavity for the precipitation marginal slight for wind and essentially zero for relative humidity the cctf is concave for rainfall wind fig 8g with estimated upper limit 0 80 while it is clearly convex for rainfall humidity with limit 0 42 fig 8h and slightly convex for the wind humidity case with limit 0 76 fig 8i these functions were used to estimate the pgp correlation matrices i e 35 k z 0 1 0 69 071 0 69 1 0 70 0 71 0 70 1 k z 1 0 49 0 38 0 27 0 17 0 44 0 40 0 21 0 34 0 51 which were used to fit a multivariate ar 1 and generate a multivariate time series of 10 000 values accordingly as in the previous cases each gaussian time series was transformed into its target process time series using the corresponding transformations x i t q x i φ z i z t the synthetic time series fig 8j l preserve all desired properties i e p 0 marginal distributions and the lag 0 and lag 1 correlation matrices while the actual topology of the correlation structure can be seen in the scatter plots of fig a 3 of course it is straightforward to apply this framework for the multivariate cyclostationary case and use higher order mar models if desired 5 summary and conclusions natural processes have a dynamic randomness unveiled by structural dependencies in time and or space and by probability laws governing the frequency of their values there is no unique correlation structure or probability law to describe the pluralism and the polyphony observed in natural processes therefore and in order to avoid ad hoc solutions we need a general stochastic framework capable of reproducing this dynamic randomness irrespective of the correlation structure or the marginal probability law the framework presented here unifies introduces new elements extends and simplifies previous attempts proposing a single approach for stochastic modelling of any hydroclimatic process and beyond the basic assumption is that a stationary or cyclostationary process x t with any prescribed marginal distribution fx x and any linear correlation structure ρ x τ has a parent gaussian process that can be easily assessed for the multivariate case this implies that a set of processes have a corresponding set of parent gaussian processes in this direction a unified framework is introduced based on simple analytical auto and cross correlation transformation functions that enable fast and easy estimation of the parent gaussian processes avoiding iterative and case specific methods proposed in the past the method is applied in a large variety of hydroclimatic processes ranging from intermittent variables like precipitation and wind speed to processes with heavy tail marginals like river discharge and to processes with bounded marginals like relative humidity or even to discrete and binary cases the versatility of the method is also demonstrated in a multivariate case where processes with very different marginals and linear correlation structures are reproduced exactly as a final remark the framework proposed enables an easy estimation of the limit or the maximum feasible cross correlation between two processes and reveals that when their marginals differ significantly in shape then their linear cross correlation cannot be intense the same remark holds also for single processes and although there is no limit and the autocorrelation can reach up to 1 processes with very different marginals from the gaussian e g highly skewed and heavy tailed will be observed with weak linear autocorrelation structures indicating maybe that nature likes to hide its internal structure acknowledgements i honestly thank y markonis for providing the river discharge wind and humidity data as well as for his general support k m andreadis for spotting many typos and the reviewers for meticulously reading the manuscript and providing constructive remarks which led in a significantly improved version appendix a aghakouchak et al 2010 a aghakouchak e habib a bárdossy a comparison of three remotely sensed rainfall ensemble generators atmos res 98 2010 387 399 bárdossy and pegram 2009 a bárdossy g g s pegram copula based multisite model for daily precipitation simulation hydrol earth syst sci 13 2009 2299 bardossy and plate 1992 a bardossy e j plate space time model for daily rainfall using atmospheric circulation patterns water resour res 28 1992 1247 1259 https doi org 10 1029 91wr02589 bartolini et al 1988 p bartolini j d salas j t b obeysekera multivariate periodic arma 1 1 processes water resour res 24 1988 1237 1246 beran 1994 j beran statistics for long memory processes 1994 crc press bowers et al 2012 m c bowers w w tung j b gao on the distributions of seasonal river flows lognormal or power law water resour res 48 2012 w05536 https doi org 10 1029 2011wr011308 box et al 2008 g e p box g m jenkins g c reinsel time series analysis forecasting and control fourth ed 2008 wiley hoboken n j breinl et al 2015 k breinl t turkington m stowasser simulating daily precipitation and temperature a weather generation framework for assessing hydrometeorological hazards meteorol appl 22 2015 334 347 bruhn et al 1979 j a bruhn w e fry g w fick simulation of daily weather data using theoretical probability distributions j appl meteor 19 1979 1029 1036 https doi org 10 1175 1520 0450 1980 019 1029 sodwdu 2 0 co 2 buell 1972 c e buell correlation functions for wind and geopotential on isobaric surfaces j appl meteor 11 1972 51 59 https doi org 10 1175 1520 0450 1972 011 0051 cffwag 2 0 co 2 buishand 1978 t a buishand some remarks on the use of daily rainfall models j hydrol 36 1978 295 308 https doi org 10 1016 0022 1694 78 90150 6 burr 1942 i w burr cumulative frequency functions ann math stat 13 1942 215 232 cario and nelson 1998 m c cario b l nelson numerical methods for fitting and simulating autoregressive to anything processes informs j comput 10 1998 72 81 cario and nelson 1997 m c cario b l nelson modeling and generating random vectors with arbitrary marginal distributions and correlation matrix 1997 department of industrial engineering and management sciences northwestern university evanston illinois technical report cârsteanu and foufoula georgiou 1996 a cârsteanu e foufoula georgiou assessing dependence among weights in a multiplicative cascade model of temporal rainfall j geophys res 101 1996 26363 26370 https doi org 10 1029 96jd01657 carta et al 2009 j a carta p ramírez s velázquez a review of wind speed probability distributions used in wind energy analysis renewable sustainable energy rev 13 2009 933 955 https doi org 10 1016 j rser 2008 05 005 chang 1996 k f chang strictly positive definite functions j approx theory 87 1996 148 158 https doi org 10 1006 jath 1996 0097 chung and salas 2000 c chung j d salas drought occurrence probabilities and risks of dependent hydrologic processes j hydrol eng 5 2000 259 268 ciach and krajewski 2006 g j ciach w f krajewski analysis and modeling of spatial correlation structure in small scale rainfall in central oklahoma adv water res 29 2006 1450 1463 https doi org 10 1016 j advwatres 2005 11 003 cowpertwait et al 2007 p cowpertwait v isham c onof point process models of rainfall developments for fine scale structure proc r soc lond a 463 2007 2569 2587 https doi org 10 1098 rspa 2007 1889 davison et al 2012 a c davison s a padoan m ribatet statistical modeling of spatial extremes stat sci 27 2012 161 186 demirtas 2017 h demirtas concurrent generation of binary and nonnormal continuous data through fifth order power polynomials commun stat simul comput 46 2017 344 357 demirtas 2014 h demirtas joint generation of binary and nonnormal continuous data j biometr biostat 2014 1 demirtas and hedeker 2011 h demirtas d hedeker a practical way for computing approximate lower and upper correlation bounds am statistician 65 2011 104 109 dolloff et al 2006 j dolloff b lofy a sussman c taylor strictly positive definite correlation functions signal processing sensor fusion and target recognition xv 2006 international society for optics and photonics 62351 a https doi org 10 1117 12 663967 embrechts et al 2002 p embrechts a mcneil d straumann correlation and dependence in risk management properties and pitfalls risk management value at risk and beyond 2002 176223 emrich and piedmonte 1991 l j emrich m r piedmonte a method for generating high dimensional multivariate binary variates am stat 45 1991 302 304 feller 1971 w feller 2 ed introduction to the theory of probability and its applications 2 1971 wiley new york ferrari and barbiero 2012 p a ferrari a barbiero simulating ordinal data multivariate behav res 47 2012 566 589 https doi org 10 1080 00273171 2012 692630 foufoula georgiou and krajewski 1995 e foufoula georgiou w krajewski recent advances in rainfall modeling estimation and forecasting rev geophys 33 1995 1125 1137 https doi org 10 1029 95rg00338 foufoula georgiou and lettenmaier 1987 e foufoula georgiou d p lettenmaier a markov renewal model for rainfall occurrences water resour res 23 1987 875 884 https doi org 10 1029 wr023i005p00875 fréchet 1957 m fréchet les tableaux de corrélation et les programmes linéaires revue de l institut international de statistique 1957 23 40 geng et al 1986 s geng f w t penning de vries i supit a simple method for generating daily rainfall data agric forest meteorol 36 1986 363 376 https doi org 10 1016 0168 1923 86 90014 6 georgakakos et al 1994 k p georgakakos a a carsteanu p l sturdevant j a cramer observation and analysis of midwestern rain rates j appl meteorol 33 1994 1433 1444 gneiting 1999 t gneiting correlation functions for atmospheric data analysis q j r meteorol soc 125 1999 2449 2464 https doi org 10 1002 qj 49712555906 gneiting and schlather 2004 t gneiting m schlather stochastic models that separate fractal dimension and the hurst effect siam rev 46 2004 269 282 https doi org 10 1137 s0036144501394387 granger and joyeux 1980 c w granger r joyeux an introduction to long memory time series models and fractional differencing j time ser anal 1 1980 15 29 grimaldi and serinaldi 2006 s grimaldi f serinaldi asymmetric copula in multivariate flood frequency analysis adv water res 29 2006 1155 1167 hammer and steurer 1997 g r hammer p m steurer data set documentation for hourly precipitation data noaa ncdc td3240 documentation series asheville nc 1997 18 hering et al 2015 a s hering k kazor w kleiber a markov switching vector autoregressive stochastic wind generator for multiple spatial and temporal scales resources 4 2015 70 92 herr and krzysztofowicz 2005 h d herr r krzysztofowicz generic probability distribution of rainfall in space the bivariate model j hydrol 306 2005 234 263 higham 2002 n j higham computing the nearest correlation matrix a problem from finance ima j numer anal 22 2002 329 343 https doi org 10 1093 imanum 22 3 329 higham 1988 n j higham computing a nearest symmetric positive semidefinite matrix linear algebra appl 103 1988 103 118 https doi org 10 1016 0024 3795 88 90223 6 hoeffding 1994 w hoeffding scale invariant correlation theory the collected works of wassily hoeffding 1994 springer 57 107 hosking 1984 j r hosking modeling persistence in hydrological time series using fractional differencing water resour res 20 1984 1898 1908 hosking 1981 j r hosking fractional differencing biometrika 68 1981 165 176 hosking 1994 j r m hosking the four parameter kappa distribution ibm j res dev 38 1994 251 258 hosking 1990 j r m hosking l moments analysis and estimation of distributions using linear combinations of order statistics j r stat soc ser b methodological 52 1990 105 124 hurst 1951 h e hurst long term storage capacity of reservoirs trans am soc civil eng 116 1951 770 808 huser et al 2016 r huser a c davison m g genton likelihood estimators for multivariate extremes extremes 19 2016 79 103 https doi org 10 1007 s10687 015 0230 4 huser and genton 2016 r huser m g genton non stationary dependence structures for spatial extremes jabes 21 2016 470 491 https doi org 10 1007 s13253 016 0247 4 iliopoulou et al 2016 t iliopoulou s m papalexiou y markonis d koutsoyiannis revisiting long range dependence in annual precipitation j hydrol 2016 https doi org 10 1016 j jhydrol 2016 04 015 istok and boersma 1989 j d istok l boersma a stochastic cluster model for hourly precipitation data j hydrol 106 1989 257 285 https doi org 10 1016 0022 1694 89 90076 0 justus et al 1978 c g justus w r hargraves a mikhail d graber methods for estimating wind speed frequency distributions j appl meteor 17 1978 350 353 https doi org 10 1175 1520 0450 1978 017 0350 mfewsf 2 0 co 2 kendall and stuart 1979 m kendall a stuart handbook of statistics 1979 griffin company london kilsby et al 2007 c g kilsby p d jones a burton a c ford h j fowler c harpham p james a smith r l wilby a daily weather generator for use in climate change studies environ modell softw 22 2007 1705 1719 kleiber et al 2012 w kleiber r w katz b rajagopalan daily spatiotemporal precipitation simulation using latent and transformed gaussian processes water resour res 48 2012 w01523 https doi org 10 1029 2011wr011105 klein tank and können 2003 a m g klein tank g p können trends in indices of daily temperature and precipitation extremes in europe 1946 99 j climate 16 2003 3665 3680 https doi org 10 1175 1520 0442 2003 016 3665 tiiodt 2 0 co 2 kroll and vogel 2002 c n kroll r m vogel probability distribution of low streamflow series in the united states j hydrol eng 7 2002 137 146 kugiumtzis 2002 d kugiumtzis statically transformed autoregressive process and surrogate data test for nonlinearity phys rev e 66 2002 025201 kumar and foufoula georgiou 1997 p kumar e foufoula georgiou wavelet analysis for geophysical applications rev geophys 35 1997 385 412 https doi org 10 1029 97rg00427 kumaraswamy 1980 p kumaraswamy a generalized probability density function for double bounded random processes j hydrol 46 1980 79 88 https doi org 10 1016 0022 1694 80 90036 0 lebrun and dutfoy 2009 r lebrun a dutfoy an innovating analysis of the nataf transformation from the copula viewpoint probab eng mech 24 2009 312 320 https doi org 10 1016 j probengmech 2008 08 001 lee and salas 2011 t lee j d salas copula based stochastic simulation of hydrological data applied to nile river flows hydrol res 42 2011 318 330 li et al 2008 h li z lü x yuan nataf transformation based point estimate method chin sci bull 53 2008 2586 https doi org 10 1007 s11434 008 0351 0 liu and der kiureghian 1986 p l liu a der kiureghian multivariate distribution models with prescribed marginals and covariances probab eng mech 1 1986 105 112 https doi org 10 1016 0266 8920 86 90033 0 lombardo et al 2014 f lombardo e volpi d koutsoyiannis s m papalexiou just two moments a cautionary note against use of high order moments in multifractal models in hydrology hydrol earth syst sci 18 1 2014 243 255 https doi org 10 5194 hess 18 243 2014 macke et al 2009 j h macke p berens a s ecker a s tolias m bethge generating spike trains with specified correlation coefficients neural comput 21 2009 397 423 mandelbrot 1971 b b mandelbrot a fast fractional gaussian noise generator water resour res 7 1971 543 553 mandelbrot and wallis 1969 b b mandelbrot j r wallis some long run properties of geophysical records water resour res 5 1969 321 340 https doi org 10 1029 wr005i002p00321 mandelbrot and wallis 1968 b b mandelbrot j r wallis noah joseph and operational hydrology water resour res 4 1968 909 918 https doi org 10 1029 wr004i005p00909 markonis et al 2018 y markonis y moustakis c nasika p sychova p dimitriadis m hanel p máca s m papalexiou global estimation of long term persistence in annual river runoff adv water res 113 2018 1 12 https doi org 10 1016 j advwatres 2018 01 003 mehrotra and sharma 2009 r mehrotra a sharma evaluating spatio temporal representations in daily rainfall sequences from three stochastic multi site weather generation approaches adv water res 32 2009 948 962 mielke 1973 p w mielke jr another family of distributions for describing and analyzing precipitation data j appl meteorol 12 1973 275 280 mielke and johnson 1974 p w mielke jr e s johnson some generalized beta distributions of the second kind having desirable application features in hydrology and meteorology water resour res 10 1974 223 226 mielke and johnson 1973 p w mielke jr e s johnson three parameter kappa distribution maximum likelihood estimates and likelihood ratio tests mon weather rev 101 1973 701 707 molotch et al 2005 n p molotch m t colee r c bales j dozier estimating the spatial distribution of snow water equivalent in an alpine basin using binary regression tree models the impact of digital elevation data and independent variable selection hydrol processes 19 2005 1459 1479 montanari et al 1997 a montanari r rosso m s taqqu fractionally differenced arima models applied to hydrologic time series identification estimation and simulation water resour res 33 1997 1035 1044 nataf 1962 a nataf statistique mathematique determination des distributions de probabilites dont les marges sont donnees comptes rendus hebdomadaires des seances de l academie des sciences 255 1962 42 neumaier and schneider 2001 a neumaier t schneider estimation of parameters and eigenmodes of multivariate autoregressive models acm trans math softw toms 27 2001 27 57 onof et al 2000 c onof r e chandler a kakou p northrop h s wheater v isham rainfall modelling using poisson cluster processes a review of developments stochastic environ res risk assess 14 2000 384 411 https doi org 10 1007 s004770000043 onof et al 2005 c onof j townend r kee comparison of two hourly to 5 min rainfall disaggregators atmospheric research precipitation in urban areas6th international workshop on precipitation in urban areas 77 2005 176 187 https doi org 10 1016 j atmosres 2004 10 022 onof and wheater 1993 c onof h s wheater modelling of british rainfall using a random parameter bartlett lewis rectangular pulse model j hydrol conventry groundwater invest 149 1993 67 95 https doi org 10 1016 0022 1694 93 90100 n over and gupta 1996 t m over v k gupta a space time theory of mesoscale rainfall using random cascades j geophys res 101 1996 26319 26331 https doi org 10 1029 96jd02033 papalexiou et al 2016 s m papalexiou y g dialynas s grimaldi hershfield factor revisited correcting annual maximum precipitation j hydrol 542 2016 884 895 https doi org 10 1016 j jhydrol 2016 09 058 papalexiou and koutsoyiannis 2016 s m papalexiou d koutsoyiannis a global survey on the seasonal variation of the marginal distribution of daily precipitation adv water res 94 2016 131 145 https doi org 10 1016 j advwatres 2016 05 005 papalexiou and koutsoyiannis 2013 s m papalexiou d koutsoyiannis battle of extreme value distributions a global survey on extreme daily rainfall water resour res 49 2013 187 201 https doi org 10 1029 2012wr012557 papalexiou and koutsoyiannis 2012 s m papalexiou d koutsoyiannis entropy based derivation of probability distributions a case study to daily rainfall adv water resour 45 2012 51 57 space time precipitation from urban scale to global change https doi org 10 1016 j advwatres 2011 11 007 papalexiou et al 2013 s m papalexiou d koutsoyiannis c makropoulos how extreme is extreme an assessment of daily rainfall distribution tails hydrol earth syst sci 17 2013 851 862 https doi org 10 5194 hess 17 851 2013 papalexiou et al 2011 s m papalexiou d koutsoyiannis a montanari can a simple stochastic model generate rich patterns of rainfall events j hydrol 411 2011 279 289 https doi org 10 1016 j jhydrol 2011 10 008 papoulis and pillai 2002 a papoulis s u pillai probability random variables and stochastic processes 2002 tata mcgraw hill education park et al 2009 j s park s c seo t y kim a kappa distribution with a hydrological application stochastic environ res risk assess 23 2009 579 586 https doi org 10 1007 s00477 008 0243 5 paschalis et al 2014 a paschalis p molnar s fatichi p burlando on temporal stochastic modeling of precipitation nesting models across scales adv water res 63 2014 152 166 https doi org 10 1016 j advwatres 2013 11 006 ribatet 2013 m ribatet spatial extremes max stable processes at work j de la société française de statistique 154 2013 156 177 rodriguez iturbe et al 1987 i rodriguez iturbe d r cox v isham some models for rainfall based on stochastic point processes proc r soc lond a 410 1987 269 288 https doi org 10 1098 rspa 1987 0039 salas 1980 j d salas applied modeling of hydrologic time series 1980 water resources publication salas et al 1982 j d salas d c boes r a smith estimation of arma models with seasonal parameters water resour res 18 1982 1006 1010 https doi org 10 1029 wr018i004p01006 salas et al 2006 j d salas o g sveinsson w l lane d k frevert stochastic streamflow simulation using sams 2003 j irrig drain eng 132 2006 112 122 schlögl 2006 a schlögl a comparison of multivariate autoregressive estimators signal process 86 2006 2426 2429 schneider and neumaier 2001 t schneider a neumaier algorithm 808 arfit a matlab package for the estimation of parameters and eigenmodes of multivariate autoregressive models acm trans math softw toms 27 2001 58 65 seguro and lambert 2000 j v seguro t w lambert modern estimation of the parameters of the weibull wind speed distribution for wind energy analysis j wind eng ind aerodyn 85 2000 75 84 https doi org 10 1016 s0167 6105 99 00122 1 serinaldi 2009 f serinaldi a multisite daily rainfall generator driven by bivariate copula based mixed distributions j geophys res 114 2009 serinaldi and kilsby 2016 f serinaldi c g kilsby a blueprint for full collective flood risk estimation demonstration for european river flooding risk anal 2016 serinaldi and kilsby 2014a f serinaldi c g kilsby simulating daily rainfall fields over large areas for collective risk estimation j hydrol 512 2014 285 302 serinaldi and kilsby 2014b f serinaldi c g kilsby rainfall extremes toward reconciliation after the battle of distributions water resour res 50 2014 336 352 https doi org 10 1002 2013wr014211 serinaldi et al 2018 f serinaldi c g kilsby f lombardo untenable nonstationarity an assessment of the fitness for purpose of trend tests in hydrology adv water res 111 2018 132 155 https doi org 10 1016 j advwatres 2017 10 015 serinaldi and lombardo 2017 f serinaldi f lombardo general simulation algorithm for autocorrelated binary processes phys rev e 95 2017 023312 shao and lund 2004 q shao r lund computation and characterization of autocorrelations and partial autocorrelations in periodic arma models j time ser anal 25 2004 359 372 sirangelo et al 2007 b sirangelo p versace d l de luca rainfall nowcasting by at site stochastic model praise hydrol earth syst sci discuss 4 2007 151 177 smith and schreiber 1974 r l smith h a schreiber point processes of seasonal thunderstorm rainfal 2 rainfall depth probabilities water resour res 1974 stacy 1962 e w stacy a generalization of the gamma distribution ann math stat 33 1962 1187 1192 stacy and mihram 1965 e w stacy g a mihram parameter estimation for a generalized gamma distribution technometrics 7 1965 349 358 stephenson et al 2016 a g stephenson e a lehmann a phatak a max stable process model for rainfall extremes at different accumulation durations weather climate extremes 13 2016 44 53 https doi org 10 1016 j wace 2016 07 002 stern and coe 1984 r d stern r coe a model fitting analysis of daily rainfall data j r stat soc ser a general 147 1984 1 https doi org 10 2307 2981736 swift and schreuder 1981 l w swift h t schreuder fitting daily precipitation amounts using the sb distribution mon weather rev 109 1981 2535 2540 https doi org 10 1175 1520 0493 1981 109 2535 fdpaut 2 0 co 2 tadikamalla 1980 p r tadikamalla a look at the burr and related distributions int stat rev 48 1980 337 344 revue internationale de statistique todorovic and woolhiser 1975 p todorovic d a woolhiser a stochastic model of n day precipitation j appl meteorol 14 1975 17 24 tsoukalas et al 2018 i tsoukalas a efstratiadis c makropoulos stochastic periodic autoregressive to anything sparta modeling and simulation of cyclostationary processes with arbitrary marginal distributions water resour res 2018 n a n a https doi org 10 1002 2017wr021394 van montfort 1990 m a j van montfort sliding maxima j hydrol 118 1990 77 85 https doi org 10 1016 0022 1694 90 90251 r verhoest et al 1997 n verhoest p a troch f p de troch on the applicability of bartlett lewis rectangular pulses models in the modeling of design storms at a point j hydrol 202 1997 108 120 https doi org 10 1016 s0022 1694 97 00060 7 villarini et al 2014 g villarini b c seo f serinaldi w f krajewski spatial and temporal modeling of radar rainfall uncertainties atmos res 135 2014 91 101 waymire and gupta 1981 e waymire v k gupta the mathematical structure of rainfall representations 1 a review of the stochastic rainfall models water resour res 17 1981 1261 1272 https doi org 10 1029 wr017i005p01261 wheater et al 2005 h s wheater r e chandler c j onof v s isham e bellone c yang d lekkas g lourmas m l segond spatial temporal rainfall modelling for flood risk estimation stochastic environ res risk assess 19 2005 403 416 https doi org 10 1007 s00477 005 0011 8 wilks 1999 d s wilks simultaneous stochastic simulation of daily precipitation temperature and solar radiation at multiple sites in complex terrain agric forest meteorol 96 1999 85 101 wilks 1998 d s wilks multisite generalization of a daily stochastic precipitation generation model j hydrol 210 1998 178 191 https doi org 10 1016 s0022 1694 98 00186 3 wilks and wilby 1999 d s wilks r l wilby the weather generation game a review of stochastic weather models prog phys geogr 23 1999 329 357 wilson and toumi 2005 p s wilson r toumi a fundamental probability distribution for heavy rainfall geophys res lett 32 2005 l14812 https doi org 10 1029 2005gl022465 xiao 2014 q xiao evaluating correlation coefficient for nataf transformation probab eng mech 37 2014 1 6 https doi org 10 1016 j probengmech 2014 03 010 yaglom 2012 a m yaglom correlation theory of stationary and related random functions 2012 springer science business media supplementary notes and 
835,hydroclimatic processes come in all shapes and sizes they are characterized by different spatiotemporal correlation structures and probability distributions that can be continuous mixed type discrete or even binary simulating such processes by reproducing precisely their marginal distribution and linear correlation structure including features like intermittency can greatly improve hydrological analysis and design traditionally modelling schemes are case specific and typically attempt to preserve few statistical moments providing inadequate and potentially risky distribution approximations here a single framework is proposed that unifies extends and improves a general purpose modelling strategy based on the assumption that any process can emerge by transforming a specific parent gaussian process a novel mathematical representation of this scheme introducing parametric correlation transformation functions enables straightforward estimation of the parent gaussian process yielding the target process after the marginal back transformation while it provides a general description that supersedes previous specific parameterizations offering a simple fast and efficient simulation procedure for every stationary process at any spatiotemporal scale this framework also applicable for cyclostationary and multivariate modelling is augmented with flexible parametric correlation structures that parsimoniously describe observed correlations real world simulations of various hydroclimatic processes with different correlation structures and marginals such as precipitation river discharge wind speed humidity extreme events per year etc as well as a multivariate example highlight the flexibility advantages and complete generality of the method keywords stochastic modelling weather generator parent gaussian framework transformations hydroclimatic processes precipitation river discharge temperature wind speed humidity 1 introduction make things as simple as possible but not simpler albert einstein the stochastic structure and the marginal probability laws of hydroclimatic processes like precipitation river discharge temperature wind or relevant processes with discrete or binary marginal distributions like the number of extremes per year wet dry sequences etc show complexities that current methodologies are unable to unify in a single modelling framework these processes differ in their spatiotemporal correlation structures cs with stronger structures being observed for example in temperature than in precipitation e g wilks and wilby 1999 moreover they have different marginal distributions e g temperature is normally distributed breinl et al 2015 kilsby et al 2007 while the intermittent and highly skewed character of precipitation at fine spatiotemporal scales demands the use of mixed type distributions herr and krzysztofowicz 2005 papalexiou and koutsoyiannis 2016 stern and coe 1984 wilks 1998 complexities of these processes are further enhanced by seasonality and diurnal variation as well as a tendency to normality as we shift from fine to coarser scales due to the central limit theorem these reasons led to a very large number of stochastic modelling schemes see e g aghakouchak et al 2010 bárdossy and pegram 2009 bardossy and plate 1992 buishand 1978 cowpertwait et al 2007 foufoula georgiou and krajewski 1995 foufoula georgiou and lettenmaier 1987 grimaldi and serinaldi 2006 hering et al 2015 kleiber et al 2012 lee and salas 2011 lombardo et al 2014 mehrotra and sharma 2009 onof et al 2000 onof and wheater 1993 over and gupta 1996 papalexiou et al 2011 paschalis et al 2014 rodriguez iturbe et al 1987 salas et al 2006 serinaldi 2009 serinaldi and kilsby 2014a 2016 sirangelo et al 2007 villarini et al 2014 waymire and gupta 1981 wheater et al 2005 wilks 1999 youngman and stephenson 2016 to name just a few we posit that a general unified approach is however possible by assuming that an arbitrary target process x t with prescribed marginal distribution fx x and autocorrelation structure acs ρ x τ has a parent or else an equivalent gaussian process pgp z t with standard gaussian marginal φ z z and a specific linear acs ρ z τ therefore modelling and simulating x t only requires the definition of two functions g and t such that x t g z t and ρ z τ t ρ x τ while g is easily identified as g z f x 1 φ z z this transformation of the marginal distribution does not preserve the linear acs expressed by the pearson correlation coefficient but only rank correlations as g is nonlinear and the acs depends on the marginal distribution fx x embrechts et al 2002 in particular for bivariate normally distributed vectors zi zj and an arbitrary transformation g r r one can show that ρ x cor g zi g zj cor zi zj ρ z kendall and stuart 1979 p 600 this means that we need inflated ρ z values to obtain the target ρ x therefore the modelling problem reduces to the definition of a correlation transformation function ctf t to estimate the parent gaussian autocorrelation pgacs ρ z τ from a given ρ x τ this modelling framework was previously considered in several fields to solve specific problems thus resulting in a sparse literature dealing with simulation of cross correlated but serially independent realizations from multivariate distributions with specified binary discrete and or continuous marginal distributions demirtas 2014 2017 emrich and piedmonte 1991 macke et al 2009 or independent time series with specified serial correlation and binary discrete and or continuous marginal distributions cario and nelson 1997 1998 kugiumtzis 2002 macke et al 2009 serinaldi and lombardo 2017 or focusing on periodic processes tsoukalas et al 2018 moreover most of these studies focused on specific classes of marginal distributions and cs s along with ad hoc solutions for the definition of the ctf t in this study we present a unified and fully general mathematical representation of the parent gaussian modelling framework going beyond specific cases we highlight its generality and its ability to model and simulate processes with both cross and autocorrelations such as spatio temporal hydrological processes we introduce a general and efficient procedure to define the function t based on a simple and flexible parametric function as well as a general purpose technique to simulate the pgp with suitably inflated prescribed cs finally we illustrate the performance of the generalized parent gaussian framework by using a variety of cs s and marginal distributions of discrete continuous and mixed type that provide a suitable representation for most of hydroclimatic processes these diverse examples emphasize how the generalized parent gaussian theory can overcome all ad hoc solutions previously proposed in the literature thus offering a powerful but simple tool that improves the analysis of hydroclimatic variables the paper is organized as follows section 2 provides the theoretical background introducing a unified mathematical representation of the parent gaussian framework starting from the univariate case i e serially autocorrelated processes and then discussing the multivariate extension section 3 starts with a review of marginal distributions and proposes a general framework on how to define and use parametric auto or cross correlation structures suitable to describe a large variety of hydroclimatic processes covering most of the cases of practical interest in hydrological studies then we present a novel general purpose ctf along with a general technique to simulate the parent gaussian process concluding with a step by step synopsis of the simulation algorithm section 4 reports several case studies involving hydroclimatic processes with heterogeneous marginal distributions discrete continuous and mixed type and different cs s e g precipitation river discharge wind speed relative humidity number of extreme events per year etc as well as a multivariate case of rainfall wind and relative humidity finally conclusions are summarized in section 5 2 theoretical framework 2 1 univariate case let x t t t be a stationary stochastic process over an indexed set t having an arbitrary autocorrelation structure acs ρ x t τ for lag τ and with the random variable r v x t following an arbitrary marginal distribution function f x t x stationarity entails no change in the joint probability distribution of any order and for any shift in time and thus x t for brevity t t is omitted hereafter is defined by a single acs ρ x τ and a single marginal distribution fx x as ρ x t τ ρ x τ and f x t x fx x for any t t let z t t t be a standard gaussian process gp with cs ρ z τ implying that any linear combination of z t 1 z tk has a joint standard normal distribution see e g feller 1971 p 87 and any z t follows the standard normal distribution n 0 1 gaussian processes have well defined properties and their simulation is easy therefore the key concept is to identify a parent gp that can be transformed into the process x t therefore to simulate reproduce a stochastic process x t with a given linear acs ρ x τ and a given marginal fx x we need to assess and transform the pgp as the marginal of the gp is known this transformation only requires to assess the acs of the parent gaussian process pgacs ρ z τ yielding the desired target acs let g be a real one to one function with x t g z t transforming z t into x t and z t g 1 x t transforming x t into z t it follows that g z t maps gaussian r v s z t n 0 1 to r v s x t fx x and the pgacs ρ z τ to the target acs ρ x τ and vice versa if g 1 x t is applied to x t this creates a unique mapping between the two processes i e 1 z t z t n 0 1 ρ z τ x t g z t z t g 1 x t x t x t f x x ρ x τ now let us define the transformations 2 x g z q x φ z z 3 z g 1 x q z f x x where φ z z 1 2 erfc z 2 and q z u 2 erf c 1 2 u with 0 u 1 are respectively the distribution and quantile functions of the standard gaussian variate z and qx u the quantile function of x it is well known that qx φ z z maps z to x with qz fx x being its inverse transformation mapping x to z thus for the r v s z t n 0 1 and x t fx x where fx x is any well defined distribution function a pair of transformation exists transforming one into the other and vice versa let x t and x τ x t τ this definition is used for notational simplicity be a pair of x t r v s at an arbitrary time point t lagged by τ and having a correlation coefficient ρ x τ given by 4 ρ x τ e x t μ x t x τ μ x τ σ x t σ x τ e x t x τ μ x 2 σ x 2 where μ x and σ x 2 are the mean and the variance of the r v x given that they are finite as there are r v s with infinite mean and variance in which case the correlation cannot be defined and 5 e x t x τ x t x τ f x t x τ x t x τ d x t d x τ where f x t x τ x t x τ is the joint probability density function pdf of x t and x τ which in general does not have a simple parametric form yet since z t and z τ are jointly normally distributed with correlation ρ z τ and with bivariate pdf 6 φ z t z τ z t z τ 1 2 π 1 ρ z τ 2 exp z t 2 2 ρ z τ z t z τ z τ 2 2 1 ρ z τ 2 we can use the theory of r v s transformations see e g feller 1971 and eq 3 to estimate directly the joint pdf of x t and x τ i e 7 f x t x τ x t x τ φ z t z τ g 1 x t g 1 x τ ρ z τ j x t x τ where j x t x τ g 1 x t x t 0 0 g 1 x τ x τ is the jacobian of the transformation see e g papoulis and pillai 2002 p 244 inspection of 7 reveals that f x t x τ x t x τ is a function of the fx x parameters and of ρ z τ if we insert eq 7 into eq 5 with known ρ z τ and fx x parameters we can calculate numerically the integral and thus the corresponding ρ x τ from eq 4 this creates a one to one link between ρ z τ and ρ x τ the above approach has not been previously proposed in the literature and although it results in complex f x t x τ x t x τ expressions that may affect the numerical integration speed in some cases encountered in numerical experiments e g when gamma type marginals are involved it was faster than the more standard approach described next note that the computation of the jacobian demands the existence of partial derivatives and thus for discrete marginal cases this approach may not be applicable another approach to estimate the ρ x τ is by applying the fundamental probability theorem feller 1971 p 5 stating that given an r v y with known pdf fy y and an r v x h y where h is a real function the expectation of x can be expressed in terms of fy y i e e x e h y h y f y y d y avoiding the calculation of e x x f x x d x which requires knowledge of fx x this theorem applies in higher dimensions and can be used to evaluate e x t x τ in terms of the bivariate standard gaussian pdf eq 6 in combination with the eq 3 transformation the autocovariance transformation integral c θ x ρ z τ is given then by 8 c θ x ρ z τ e x t x τ e q x φ z z t q x φ z z τ q x φ z z t q x φ z z τ φ z t z τ z t z τ ρ z τ d z t d z τ where θ x θ 1 θ n is the parameter vector of the distribution fx x in the copula literature eq 9 is known as the nataf transformation nataf 1962 liu and der kiureghian 1986 li et al 2008 lebrun and dutfoy 2009 xiao 2014 in general the double integral c θ x ρ z τ does not have an analytical solution yet its numerical estimation is trivial introducing c θ x ρ z τ into eq 4 we get the autocorrelation transformation integral acti r θ x ρ z τ i e 9 ρ x τ r θ x ρ z τ c θ x ρ z τ μ x 2 σ x 2 clearly r θ x ρ z τ is a function of θ x and of ρ z τ as μ x and σ x 2 are functions of θ x as well likewise combining f x t x τ x t x τ with eq 4 to calculate ρ x τ the acti creates a link between the ρ x τ and ρ z τ and thus can be applied for any pair of z t z τ or else for all lag values τ 1 τ max transforming essentially the gaussian acs ρ z τ into the acs ρ x τ note this relationship transforms a known ρ z τ value into a ρ x τ value while our goal is to transform an observed or a given ρ x τ value into the corresponding ρ z τ value this is described in detail in section 3 3 2 2 multivariate and cyclostationary case equations previously shown refer to a single stationary stochastic process yet eq 9 can be applied more generally as natural processes vary in space and time we need multivariate and cyclostationary models bartolini et al 1988 salas 1980 salas et al 1982 shao and lund 2004 let us assume n processes e g a single process observed in n different locations n different processes in the same location etc and m seasons e g 12 months 365 days etc i e a total of n m processes and with x i j t denoting the i th process at j th season where i 1 n and j 1 m accordingly for each process we assume a marginal distribution f x i j x an acs ρ x i j τ and for every pair of processes with i j a cross correlation structure ccs ρ x i j x k l τ where k 1 n and l 1 m in this case eq 8 becomes 10 c x i j x k l θ x i j θ x k l ρ z i j z k l τ q x i j φ z i j z t q x k l φ z k l z τ φ z i j t z k l τ z t z τ ρ z i j z k l τ d z t d z τ and thus the cross correlation transformation integral ccti becomes 11 ρ x i j x k l τ r θ x i j θ x k l ρ z i j z k l τ c x i j x k l θ x i j θ x k l ρ z i j z k l τ μ x i j μ x k l σ x i j σ x k l where θ x i j and θ x k l are parameter vectors of fxi j x and fxk l x distributions respectively thus r θ x i j θ x k l ρ z i j z k l τ can be seen as a function transforming a given lag τ correlation ρ z i j z k l τ in a pair of standard gp s into the lag τ correlation ρ x i j x k l τ between x i j t and x k l τ processes thus the difference compared with the univariate stationary case is that here we have a set of n m processes x i j t and we want to assess a set of parent gp s z i j t or else their pgccs s ρ z i j z k l τ given this a multivariate and cyclostationary gp can be transformed into the set of x i j t processes using the corresponding transformations x i j t q x i j φ z i j z t as a result the problem of generating time series from a multivariate cyclostationary model comprising processes with different characteristics simplifies in generating time series from a multivariate cyclostationary standard gp 3 from theory to practice 3 1 marginal distributions of hydroclimatic processes 3 1 1 continuous common hydroclimatic processes like temperature wind precipitation river discharge relative humidity etc have continuous or mixed type partly continuous and partly discrete marginal probability distributions the number of parametric distributions found in the literature to describe hydroclimatic r v s is very large air temperatures is commonly described by the gaussian distribution e g klein tank and können 2003 the two parameter weibull has been the prevailing model for wind speeds e g justus et al 1978 seguro and lambert 2000 yet gamma lognormal and pearson type i distributions have also been used for wind for a review see carta et al 2009 nonzero daily precipitation has been modelled by gamma e g buishand 1978 bruhn et al 1979 geng et al 1986 weibull e g swift and schreuder 1981 wilson and toumi 2005 exponential and mixed exponentials distributions e g smith and schreiber 1974 todorovic and woolhiser 1975 wilks 1999 or by heavier tailed distributions like the lognormal e g swift and schreuder 1981 kappa mielke 1973 mielke and johnson 1973 hosking 1994 park et al 2009 and the generalized beta distribution mielke and johnson 1974 for a detailed global investigation on the distribution of seasonal daily precipitation see papalexiou and koutsoyiannis 2016 where the generalized gamma and the burr type xii have been used for global analyses on precipitation extremes see papalexiou et al 2013 papalexiou and koutsoyiannis 2013 serinaldi and kilsby 2014b river flows have been described by the lognormal and pareto distributions e g bowers et al 2012 the pearson type iii and the 3 parameter lognormal distributions were suggested for low stream flows kroll and vogel 2002 the beta distribution has been found to describe very well relative humidity values e g yao 1974 and also is a candidate model for percentage r v s like probability dry percentage of area affected by extreme temperature or precipitation etc a complete review on the probability models applied in geophysical and hydroclimatic processes would be a difficult task by itself and out of the scope this study a common practice is to fit many distributions and select the best fitted yet this approach is susceptible to sample variations in an attempt to simplify this procedure and based on entropy information measures a general theoretical framework was proposed papalexiou and koutsoyiannis 2012 that led to consistent distributions for positive geophysical and hydroclimatic r v s particularly the generalized gamma g g stacy 1962 stacy and mihram 1965 and the burr type xii distributions b r xii burr 1942 tadikamalla 1980 were derived yet the burr type iii b r iii is also proposed here as a general and flexible power type model the probability density function of g g distribution and the distribution functions of the b r xii and b r iii are given respectively by 12 f g g x β γ 1 γ 2 γ 2 β γ γ 1 γ 2 x β γ 1 1 exp x β γ 2 13 f b r xii x β γ 1 γ 2 1 1 γ 2 x β γ 1 1 γ 1 γ 2 14 f b r iii x β γ 1 γ 2 1 1 γ 1 x β 1 γ 2 γ 1 γ 2 these distributions defined for x 0 have the scale parameter β 0 and the shape parameters γ 1 0 and γ 2 0 controlling the left and right tails respectively their pdf s are j shaped for γ 1 1 and bell shaped for γ 1 1 while the parameter γ 2 controls mainly the heaviness of the right tail and thus the behaviour of extreme events note that g g is of exponential form with finite moments while b r xii and b r iii are power type distributions that can have very heavy tails and infinite moments the g g can be considered as a generalization of the two parameter gamma and weibull distributions while the b r xii includes as special cases the pareto type ii for γ 1 1 or the weibull distribution as limiting case for γ 2 clearly the principle of parsimony which requires to always seek for the simplest model i e to use the smallest number of parameters possible see e g box et al 2008 p 16 should always be applied for example if a weibull distribution performs satisfactorily under desired criteria then it should be preferred over the three parameter g g the same holds for the power type distributions b r xii and b r iii where the simpler pareto type ii should be the first choice under adequate performance 3 1 2 mixed type discrete and binary several natural processes like precipitation at fine temporal scales e g at daily or subdaily scales discharge of small streams or even wind are intermittent processes thus their marginal distribution comprises a probability mass concentrated at zero e g probability dry in precipitation and a continuous part for the positive values expressed by a parametric distribution function the framework to simulate intermittent processes is the same see section 2 the difference lies in the expressions of the distribution function fx x and the quantile function qx u that are now related to the conditional expressions for x x 0 particularly if p x 0 p 0 is probability zero then the cdf pdf and quantile function of x are given respectively by 15 f x x 1 p 0 f x x 0 x p 0 x 0 16 f x x p 0 x 0 1 p 0 f x x 0 x x 0 17 x u q x u 0 0 u p 0 q x x 0 u p 0 1 p 0 p 0 u 1 the dirac delta notation can also be used to define the pdf additionally the expressions of the mean and variance of x used to estimate the ctf s in eq 9 or eq 11 become 18 μ x 1 p 0 μ x x 0 19 σ x 2 1 p 0 σ x x 0 2 p 0 1 p 0 μ x x 0 2 the probability zero can be easily assessed from the empirical data as p 0 n 0 n with n 0 and n denoting respectively number of dry and total days while for positive values any suitable parametric continuous distribution f x x 0 x could be used this framework can be extended to include cases where values above a threshold are considered i e the discrete part can express the pr x xp for an arbitrary value xp and the continuous part values for x x xp finally more general mixed type marginal distributions can be considered e g the water storage in a reservoir varies theoretically from zero to a maximum level when capacity is reached thus as a variable it may have two discrete states i e probability zero and probability for maximum capacity all in between values can be described by a continuous bounded distribution important aspects of various geophysical processes can be considered to have a discrete or a binary marginal distribution see e g chung and salas 2000 molotch et al 2005 serinaldi and lombardo 2017 for example the number of consecutive wet and dry spells in days hours etc the number of days per year having a specific property e g temperature precipitation or wind speed above a threshold extremes the number of wet days per year binary sequences to describe wet and dry days and many more as in the mixed type case the methodology remains the same modified only by using expressions for the quantile mean and variance that correspond to the discrete or the binary probability mass function chosen 3 2 autocorrelation acs and cross correlation structures ccs empirical autocorrelation or cross correlation ρ τ especially for small samples and for large lags τ is sensitive to sample variations and calculated up to a maximum lag 1 3 of the sample size is usually suggested a better approach may be to fit a parametric acs to ρ τ expressed by a simple function ρ τ θ where θ θ 1 θ k is the parameter space of the acs essentially interpolating the values of ρ τ and providing a smoother result also it could be desirable to assign a prescribed acs or ccs e g in sensitivity analysis scenarios or if regional information is transferred to a location of interest as in waldo tobler s first law of geography stating that near things are more related than distant things it is well known things closer in time are more related than distant things thus we can assume that a monotonically decreasing function of lag τ or distance having ρ 0 θ 1 and lim τ ρ τ θ 0 can serve as an acs a general class of functions proposed here with these properties are the complementary cumulative distribution functions ccdf but now treated as functions and not as probability laws note that valid acs s and ccs s have to be positive definite to guarantee that the parent gaussian processes are stationary see e g yaglom 2012 p 57 we deem that by definition a ccdf function fulfils this conditions for a treatise on strictly positive definite functions see chang 1996 however pathological cases may be possible to be formed for example a function that equals to 1 up to a given lag and then gets 0 cannot be a proper correlation function for more examples see e g dolloff et al 2006 yet in real world cases this specific issue cannot be observed as correlation equal to 1 in a dataset indicates an exact linear deterministic relationship and thus the correlations for any lag would also equal to 1 excluding the possibility for any other value in any case positive definiteness of a function should be considered when we construct theoretical acf s and ccf s based on the previously described rational the weibull acs is then given by 20 ρ w τ b c exp τ b c with b 0 and c 0 and forms a generalization of the celebrated markovian acs as it is identical for c 1 yet decays slower for c 1 and faster for c 1 note that ρ w τ can be expressed also in terms of the lag 1 correlation ρ 1 i e ρ w τ ρ 1 τ c a similar stretched exponential form was used for space correlation of rainfall ciach and krajewski 2006 likewise a power type acs is formed by the pareto ii ccdf i e 21 ρ pii τ b c 1 c τ b 1 c with b 0 and c 0 the pii acs decays always slower than the markovian yet it becomes identical as c 0 a similar two parameter power type acs named cauchy class was also proposed by gneiting and schlather 2004 as generalization of the fractional gaussian noise fgn acs the weibull and pii acs s can be merged into a three parameter expression which coincides with the burr type xii ccdf i e 22 ρ brxii τ b c 1 c 2 1 c 2 τ b c 1 1 c 1 c 2 with b 0 c 1 0 and c 2 0 for c 2 0 ρ brxii τ b c 1 c 2 ρ w τ b c 1 1 c 1 c 1 and for c 1 1 it equals the pii acs this general expression with a different parametrization was also used in papalexiou et al 2011 yet it was not suggested within the general framework proposed here and was not identified as the burr type xii ccdf note that we can form acs s decaying even slower than power type acs s e g a general logarithmic expression gl proposed here generalizing also the markovian acs is 23 ρ gl τ b c 1 ln 1 c x b 1 c with b 0 and c 0 for c 0 coincides with the markovian acs i e lim c ρ gl τ b c exp x b this acs for large values of c can have extremely slow decay rates and may be useful for processes at the second or millisecond time scales another noteworthy acs is the celebrated fgn or hurst acs e g beran 1994 p 52 linked to long term persistence ltp and fgn processes hurst 1951 mandelbrot and wallis 1968 1969 given by 24 ρ fgn τ h 1 2 τ 1 2 h 2 τ 2 h τ 1 2 h τ 2 1 h where 0 h 1 is the hurst coefficient also farima models granger and joyeux 1980 hosking 1981 have a similar acs asymptotically equivalent to the ρ fgn τ yet their acs is more flexible as it allows to control short term correlations see e g hosking 1984 montanari et al 1997 for applications in hydrology noteworthy recent global studies on annual precipitation iliopoulou et al 2016 and river discharge markonis et al 2018 challenge the ltp hypothesis as the findings suggest very low values of the h coefficient that could also emerge from markovian processes here we propose a convenient generalization of the fgn acs i e the generalized fgn gfgn given by 25 ρ gfgn τ ρ 1 h h 2 h 1 τ 1 ρ 1 h 2 h 1 1 2 1 h 2 1 h τ 2 1 h this acs well defined for τ 1 converges very fast to the classical fgn acs yet for lag τ 1 we have ρ gfgn 1 ρ 1 h ρ 1 and thus it allows full control of the short term properties of the acs also various other correlation functions have been proposed e g for wind and atmospheric data buell 1972 gneiting 1999 in the cross correlation case between two process e g of xi t and xj t since ρ x i x j τ ρ x i x j τ for τ 0 and ρ x i x j 0 1 we can still use parametric ccs s similar to the acs s framework if this is desired by modifying them as 26 ρ x i x j τ ρ cs τ 1 θ τ 0 ρ cs 1 τ θ τ 0 where ρ cs τ can be any parametric cs like the weibull pii etc with different parameter values for τ 0 and τ 0 to fulfil the condition of ρ x i x j τ ρ x i x j τ of course an infinite number of acs or ccs s can be formed with many more parameters yet according to the parsimony principle we should choose the one with the less possible parameters box et al 2008 p 16 although bias issues in estimating empirical correlations are beyond the scope of this study yet it is crucial to mention that the empirical acs of a process having a very intense underlying acs e g an fgn with high values of h will be observed most probably weaker especially for small samples and will also affect the sample standard deviation in general a straightforward and easy method to estimate any linear acs without bias does not exist formulas exist only for special cases like the fgn acs see e g beran 1994 and should be applied if there is evidence for ltp before estimating the pgacs for most hydroclimatic processes however and when dealing with time scales larger than the daily or even hourly for precipitation the empirical acs s are not intense and thus the bias is not expected to be significant also as afore mentioned the existence of ltp in processes like river discharge is challenged see e g markonis et al 2018 nevertheless for processes at fine temporal scales we may observe very strong acs s see the example in section 4 1 that can lead to significant biases in the estimation of the underlying acs and of the standard deviation see e g papalexiou et al 2011 and references therein finally it should be clear that the parent gaussian framework reproduces linear correlation structures as expressed by the pearson correlation coefficient and does not consider other types of correlations e g rank correlations kendal s tau spearman s rho etc or more general correlation topologies that can emerge by other models for example there is an increasing interest over the last decade on the spatial dependence structure of extreme events using max stable processes see e g davison et al 2012 huser et al 2016 huser and genton 2016 ribatet 2013 stephenson et al 2016 an approach that may lead to structures which the framework presented here may not be able to reproduce yet it is still a matter of debate if modelling extremes directly is a better approach compared to modelling the process itself e g in the presence of ltp it was shown that the latter approach should be preferred serinaldi et al 2018 also note that the behaviour of spatial extremes is essentially governed by the tail of a multivariate distribution or by the random field properties and thus it is rational to assume that if the multivariate process or the field itself is simulated accurately then the structure of extremes will be also consistently reproduced certainly both approaches have advantages and disadvantages that depend on many factors for example analysis of above a threshold extremes provides a more accurate estimation of the distribution tail see e g papalexiou et al 2013 than using the whole set of observations in contrast using annual maxima may lead to increased uncertainty in the estimation of the heaviness of the tail especially when fixed block maxima are used papalexiou et al 2016 van montfort 1990 3 3 auto and cross correlation transformation function 3 3 1 autocorrelation transformation function actf the acti in eq 9 transforms a specific autocorrelation value ρ z between a pair of z t and z τ r v s of the gp lagged by τ into the autocorrelation ρ x between the x t and x τ r v s of the target process yet the inverse relationship is desired for all practical purposes that is an actf t ρ x where we introduce any value of ρ x or any acs ρ x τ and get respectively the pgp ρ z value or the pgacs ρ z τ we assume here positive correlations ranging in 0 1 yet the framework can be expanded easily for negative correlations too essentially we evaluate the acti in a small set of ρ z values to create ρ x ρ z points and interpolate them by fitting a simple parametric function since ρ z τ ρ x τ kendall and stuart 1979 p 600 the actf t should have the potential to be concave and also pass from the 0 0 and 1 1 points as for ρ z equal to 0 and 1 ρ x is also 0 and 1 a simple two parameter function with these properties that is proposed here is heuristically evaluated and found to perform perfectly in all cases of continuous and mixed type marginals studied is 27 ρ z t ρ x b c 1 b ρ x 1 c 1 1 b 1 c 1 which is concave for b 0 and c 0 while for b 0 and c 1 we have ρ z ρ x unless stated this will be the basic actf used in the examples of this study the previous function performs also well for the discrete and binary case yet the alternative 28 ρ z t ρ x b c 1 1 ρ x b c seems to perform better for discrete cases and especially for the binary case this function is concave for 0 b 1 and c 1 for b 1 and c 1 we have ρ z ρ x note that eq 28 coincides with the kumaraswamy cdf kumaraswamy 1980 yet here is used as parametric function and not as probability law thus we can now form a one to one relationship that enables the calculation of the pgp ρ z either as a single value or as a parametric pgacs if a parametric acs ρ x τ is plugged into eq 27 or eq 28 any of the actf s t ρ x b c functions can be easily fitted if we evaluate the acti eq 9 for ρ z 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 95 and use the corresponding set of ρ x ρ z points we stress that this approach is simpler and by far more efficient than iterative methods and polynomial approximations previously proposed see e g demirtas 2014 ferrari and barbiero 2012 kugiumtzis 2002 let us assume that we target a process x t having a weibull w β γ marginal distribution f x x f w x 1 exp x β γ and a markovian acs ρ x τ ρ m τ ρ 1 ρ 1 τ with ρ 1 0 8 for illustration and comparison purposes we assume three different w distributions fig 1 a with scale parameter β 1 and shape parameters γ 2 0 5 0 25 respectively the estimated ρ x ρ z points gray dots in fig 1b and the fitted t ρ x b c functions fig 1b show very different transformation profiles i e for the bell shaped w 1 2 which resembles the gaussian distribution essentially ρ z ρ x and the pgacs coincides with ρ x τ fig 1c as we deviate from normality e g the w 1 0 25 has a heavy tail and very high skewness the actf becomes more concave resulting in very different pgacs s fig 1c note that a markovian acs ρ x τ is not reproduced by a markovian pgacs e g for the w 1 0 25 case the ρ x 1 0 80 corresponds to ρ z 1 0 93 which does not imply that the markovian acs ρ z τ 0 93 τ will reproduce the ρ x τ 0 80 τ it will only preserve the ρ x 1 another example showing how the concavity of the actf changes regards mixed type marginal distributions suitable to model intermittent processes like precipitation or wind and discharge in some cases let us target for an intermittent process x t having probability zero p 0 a pareto ii p ii β γ marginal distribution f x x f p ii x 1 1 γ x β 1 γ for nonzero values with β 1 and γ 0 3 and an fgn acs eq 24 ρ x τ ρ fgn τ h with h 0 75 for comparison we use p 0 0 0 9 0 99 with the unconditional p ii pdf s shown in fig 1d note that it is common to observe p 0 equal to high values such as 0 90 and 0 99 for daily and hourly rainfall records respectively the ρ x ρ z points and the fitted t ρ x b c functions fig 1e show how concavity increases as p 0 increases resulting in very different pgacs fig 1c and thus for large values of p 0 a much stronger ρ z τ is necessary to preserve the ρ x τ as in the previous example the pgacs of the fgn acs is not an fgn acs with just a different h value in summary we note that the concavity of the actf or else the difference between the target acs and the pgacs depends on how much the target marginal deviates from normality cleary a unique method to quantify this deviation does not exist as deviations may regard the general shape e g skewed vs symmetric densities the heaviness of the tail e g exponential vs power type tails or the type of the density i e mixed type vs continuous type consequently we could speculate that when the target marginal is of continuous type has a moderately skewed and bell shaped pdf e g as in the bell shaped weibull pdf example fig 1a then the linear correlation has a small bias in other words ρ z τ could be approximated by the actual ρ x τ and thus we can directly transform the gaussian time series avoiding calculating the integrals and fitting the actf 3 3 2 cross correlation transformation function cctf in the previous case the actf was constrained to pass from the 1 1 point yet for cross correlation this is not mandatory the cross correlation ρ x i x j between two stationary processes xi t and xj t has boundaries depending on the marginal distributions f x i x and f x j x thus there is a range of admissible ρ x i x j values according to the frechet hoeffding theoretical limits i e 1 min ρ x i x j ρ x i x j max ρ x i x j 1 embrechts et al 2002 fréchet 1957 hoeffding 1994 these boundary values can be checked for each specific application by using for example the procedure suggested by demirtas and hedeker 2011 however this check is not required in our approach as the interpolation procedure automatically determines the feasible range of ρ x i x j and thus the ρ max max ρ x i x j here we propose as cctf a simple two parameter function that performed extremely well in all cases studied i e 29 ρ z i z j t ρ x i x j b c 1 b ρ x i x j c 1 note that if more flexibility is needed the three parameter ρ z i z j 1 b ρ x i x j c 1 c 2 1 can be used this function eq 29 is essentially the same as the actf in eq 27 but without the denominator part which forced the function to pass from 1 1 it is valid for b 0 concave for c 1 linear for c 1 and convex for c 1 as in the actf case we can easily fit the cctf by evaluating the ccti in eq 11 for ρ z i z j 0 1 0 2 0 3 0 4 0 5 0 6 0 7 0 8 0 9 0 95 0 99 and creating the corresponding ρ x i x j ρ z i z j points once the cctf parameters are estimated we can determine easily the ρ max by setting ρ z i z j 1 in eq 29 and solve for ρ x i x j i e 30 ρ max 2 1 c 1 b let us assume a process x 1 t with a weibull marginal w 1 0 5 and a process x 2 t with a beta marginal b γ 1 γ 2 for comparison purposes we use three different beta pdf s having negative zero and positive skewness fig 2 a we use the ccti of eq 11 to estimate the ρ x i x j ρ z i z j points grey dots in fig 2b and we fit the cctf in eq 29 noteworthy for the negatively skewed beta the cctf is convex almost a straight line for the symmetric and concave for the positively skewed while the corresponding ρ x i x j limits estimated from eq 30 are 0 53 0 64 and 0 75 respectively this indicates that the more the two marginals differ the more their maximum cross correlation value ρ x i x j will be decreased we also show the pgccs of a markovian ccs fig 2c clearly not all ccs are feasible due to the maximum limit another interesting example is to assume cross correlated processes with mixed type marginals that differ in probability zero we assume a heavy tailed continuous marginal p ii 1 0 3 for the first process x 1 t while for x 2 t we use three different mixed type p ii 1 0 3 marginals with p 0 0 5 0 9 0 99 fig 2d using the ccti of eq 11 we calculate the ρ x i x j ρ z i z j points grey dots in fig 2e and we fit the cctf of eq 29 all cctf s are concave while the corresponding ρ x i x j limits estimated from eq 30 are 0 98 0 89 and 0 66 respectively indicating a decrease in the maximum cross correlation as p 0 increases or else as the two marginals differ more in fig 2f we show the pgccs of the markovian ccs used in the previous example clearly as p 0 increases much stronger pgccs are needed to reproduce the target ccs 3 4 gaussian univariate and multivariate processes with arbitrary cs we can easily simulate a standard gp i e with μ 0 and σ 1 having an arbitrary parametric acs ρ z τ by using an autoregressive process of order p ar p defined by 31 z t i 1 p a i z t i ɛ t where ɛ t n 0 σ ɛ 2 is gaussian random noise with σ ɛ 2 1 i 1 p a i ρ z τ and ai are the model parameters for a given parametric acs ρ z τ the a 1 ap can be easily and analytically computed using the yule walker equations e g box et al 2008 p 67 i e a p 1 ρ where a t a 1 ap is the parameter vector ρ t ρ z 1 ρ z p is the correlation vector up to lag p and p ρ z i j is the p p correlation matrix with i and j denoting respectively the i th row and j th column e g the p 2 3 element is simply the value of ρ z 1 for more on ar models see box et al 2008 thus an ar p model preserves exactly a given acs ρ z τ up to lag p and then for τ p 1 decays according to ρ ar p τ i 1 p a i ρ z τ i a relation that can be easily applied recursively for example fig 3 shows the approximation of two parametric acs up to various lags i e of a weibull with b 10 and c 0 5 decaying thus slower than the markovian acs and a very strong pareto ii acs with b 5 and c 4 clearly the closer the acs is to the markovian the better will be approximated by the ρ ar p τ for τ p 1 in any case a parametric acs can be approximated up to any desired lag e g even an ar 5000 can be easily fitted to avoid any confusion we emphasize that here we fit the theoretical acf of an ar p model to a target parametric acs this method only requires estimation of a couple of parameters i e those of the fitted parametric acs to the data while the p parameters of the fitted ar p model are simply coefficients constants estimated analytically and without uncertainty corresponding to the target parametric acf thus this approach is parsimonious and efficient e g an ar 5000 fitted to a two parameter acs is essentially a two parameter model another approach to generate time series from a standard gp having an arbitrary acs ρ z τ is based on approximating ρ z τ by a sum of independent ar 1 processes an idea originally proposed and used by mandelbrot 1971 to approximate the fgn acs particularly if we define 32 z t i 1 n y i t with yi t ρ i 1 yi t 1 ε i t being the i th ar 1 process in the sum having mean μ y i 0 standard deviation σ y i lag 1 correlation ρ i 1 and ɛ i t n 0 1 ρ i 1 2 σ y i 2 then since the ar 1 processes are independent the variance and the cs of the sum process are σ z 2 i 1 n σ y i 2 and ρ σ τ 1 σ z 2 i 1 n ρ i 1 τ σ y i 2 respectively of course if we demand z t to have σ z 2 1 then i 1 n σ y i 2 is also constrained to equal 1 the ar 1 parameters can be estimated by numerically minimizing an error norm between ρ σ τ and ρ z τ up to a desired lag τ for an application using five independent ar 1 approximating the acs given eq 22 see papalexiou et al 2011 the corresponding multivariate autoregressive model mar p of n processes is defined by 33 z t i 1 p a i z t i b ɛ t where z t z 1 t zn t t a i and b are n n parameter matrices and ε t ε1 t ε n t t is an n vector of independent standard gaussian variables for a general algorithm to fit mar p models of large order see neumaier and schneider 2001 schneider and neumaier 2001 and schlögl 2006 clearly large order mar models are complicated and often unnecessary e g when markovian acs and ccs are observed a mar 1 is sufficient the parameters of the mar 1 model z t az t 1 bε t can be estimated by using the relations a k z 0 k z 1 1 and b b t k z 0 ak z t 1 thus b can be found using e g choleski decomposition where k z 0 and k z 1 are the correlation matrices of the n gaussian processes see also section 4 5 for an application clearly analytical or exact estimation of b demands the matrix bb t to be positive definite a condition that is not always fulfilled in this case the matrix b can be approximated using near matrix methods see e g higham 1988 2002 finally note that cyclostationarity can be introduced by using different mar processes for each season 3 5 a stochastic modelling recipe step by step the proposed stochastic modelling framework is summarized in the following steps 1 assess suitable marginal distributions and correlation structures auto and cross correlations for the multivariate case from the empirical time series 2 estimate the ρ x ρ z points for the proposed ρ z values see section 3 3 1 using the acti in eq 9 and fit the parametric actf of eq 27 or eq 28 for binary marginals to the points for the multivariate case estimate ρ z i z j ρ x i x j points using the ccti in eq 11 and fit the cctf in eq 29 3 insert the target acs ρ x τ into the fitted actf t ρ x τ b c to estimate the pgacs ρ z τ for the multivariate case use the fitted cctf t ρ x i x j τ b c to find the pgccs ρ z i z j τ 4 use the estimated pgacs and the pgccs to fit an ar p or mar p model and generate gaussian univariate or multivariate time series 5 transform the gaussian time series using the corresponding transformation x i t q x i φ z i z t based on the fitted distributions from step 1 4 real world examples 4 1 storm events of fine temporal resolution the method is applied to simulate rainfall events at fine temporal scale 10 seconds resolution a process displaying strong acs highly skewed and heavy tailed continuous marginal distribution the original data are seven storm events recorded at the hydrometeorology laboratory at the iowa university georgakakos et al 1994 note this dataset has been used also in other studies see e g papalexiou et al 2011 for a statistical and stochastic analysis cârsteanu and foufoula georgiou 1996 for a multifractal analysis and kumar and foufoula georgiou 1997 for a wavelet analysis we assume that these events are the outcome of a single process papalexiou et al 2011 and thus the characteristics of the process are better determined if all events are merged into one set despite their large statistical differences see fig 4 a nonetheless the aim here is not a detailed analysis of the data but rather to illustrate the applicability of the method in a highly non gaussian process with strong acs in addition other issues like the bias in the estimation of the acs are not considered for these details see papalexiou et al 2011 the method is graphically demonstrated in fig 4 first a parametric distribution is fitted to the empirical distribution fig 4b here the b r x ii is used the estimated parameters using the method of l moments hosking 1990 are β 2 13 γ 1 0 74 and γ 2 0 22 see papalexiou and koutsoyiannis 2016 for details about fitting the b r xii using l moments second the observed acs ρ x τ is approximated by numerically fitting the parametric weibull acs ρ w τ given in eq 20 with estimated parameters β 80 6 and γ 0 73 fig 4c i e it is assumed that ρ x τ ρ w τ β γ third the αcti r θ x ρ z in eq 9 is applied using the fitted b r xii distribution to estimate a few ρ x ρ z points grey dots in fig 4d which are interpolated by the actf in eq 27 with parameters c 1 2 96 and c 2 0 93 fourth the fitted actf is applied to the estimated ρ w τ β γ to obtain the pgacs ρ z τ fig 4e fifth a large order ar model is used i e ar 1000 to reproduce the fitted pgacs ρ z τ and generate gaussian time series fig 4f sixth synthetic time series emerge by simply transforming the gaussian time series using eq 2 and the fitted b r xii fig 4e for verification the empirical distribution of the synthetic time series is compared with the target b r xii that was fitted to the original data fig 4h while the empirical acs of the gaussian and synthetic time series are compared with the target ρ z τ and ρ x τ fig 4i 4 2 hourly precipitation stochastic modelling of hourly precipitation has been the subject of active research for more than three decades having important applications e g in rainfall run off modelling previous methods have mainly focus on point process models like the barlett lewis and the neyman scott see e g istok and boersma 1989 onof et al 2000 onof and wheater 1993 rodriguez iturbe et al 1987 verhoest et al 1997 wheater et al 2005 these models do not reproduce the actual marginal distribution but rather attempt to approximate it by preserving a number of statistical moments usually up to the third aiming to reproduce skewness at their core exponential and gamma distributions are used that may underestimate return levels which is a well known weakness that has motivated alternative approaches see e g onof et al 2005 the framework presented here is scale free as it can be applied at any time scale including hourly we demonstrate the performance of the method by using an hourly precipitation record from the unites states randomly selected from the ncdc database hammer and steurer 1997 station code 063456 covering the period from 01 08 1954 to 30 11 2011 fig 5 a assuming hourly precipitation as a cyclostationary process i e stationary at each month we apply the steps described in section 3 5 twelve times in brief high probability dry values are observed within the twelve months ranging from 0 90 to 0 95 figs 5c d and a 1 while the nonzero hourly rainfall is adequately described by fitted g g distributions eq 12 the estimated parameters for all months are given in fig a 1 the pareto ii acs eq 21 interpolates accurately the linear empirical acs see correlograms and estimated parameters in figs 5e f and a 2 and the pgacs for each month is estimated using the expressions for the mixed type case eqs 17 19 high probability dry values and high skewness of the target marginals inflate significantly the pgacs which approximates 0 in all months for τ 3 24 thus an ar 72 was used to generate the gaussian time series the synthetic rainfall was generated for the same period as the observed one fig 5b and emerged by transforming the gaussian time series using the corresponding marginal back transformations of each month the empirical probability distributions figs 5c d and a 1 as well as the empirical acs s figs 5e f and a 2 of the synthetic time series show the precise reproduction of their target counterparts of course any minor deviations shown are due to random sample variations and not due to any systematic bias of the method we also highlight the one state framework of this method as common precipitation generators e g point process models use two states one to simulate the wet dry days sequence and a second one to calculate the intensity of wet days see also wilks 1998 here the intermittency is introduced naturally by applying the mixed type marginal back transformation note that this framework compared to the afore mentioned popular models has the advantage of reproducing the actual marginal and acs while it can be equally or even more parsimonious depending of course on the selected marginal distribution and parametric acs for example the total number of parameters we estimate to model hourly precipitation for each month is just five i e three for the marginal and two for the acs all the rest are deterministically estimated and thus are not essentially parameters 4 3 daily precipitation river discharge and wind daily precipitation is another important case of an intermittent process that plays a crucial role in hydrology here we use october s daily rainfall recorded at the national observatory of athens in greece from 24 04 1927 to 20 02 1990 fig 6 a assuming stationarity within the month the probability dry was found p 0 0 78 the nonzero rainfall was described by an f g g x 16 5 0 39 0 97 distribution eq 12 papalexiou and koutsoyiannis 2016 and a weibull acs eq 20 was fitted to the empirical acs i e ρ x τ ρ w τ 0 43 0 48 fig 6e the acti in eq 9 was used to estimate ρ x ρ z points fig 6b using the corresponding expressions for the mixed type case i e the quantile function mean and variance are given now by eqs 17 19 respectively the correlation transformation function t ρ x 13 88 0 75 fitted perfectly to the ρ x ρ z points fig 6b and was used to estimate the pgacs i e ρ z τ t ρ w τ 0 43 0 48 13 88 0 75 fig 6e the ρ z τ 0 for τ 20 thus an ar 20 was fitted to ρ z τ for τ 1 20 and used to generate a gaussian time series of 1000 months 31 1000 values the gaussian time series was transformed to synthetic rainfall fig 6c shows sample size equal with the original time series by applying the transformation in eq 2 with qx being the mixed type quantile in eq 17 with the estimated p 0 and the fitted g g quantile for verification the empirical distribution and the empirical acs of the synthetic sample is compared with the target f g g x 16 5 0 39 0 97 distribution fig 6d and the target acs ρ x τ ρ w τ 0 43 0 48 fig 6e another important variable is daily river discharge here we use daily values of april observed in the middle fork snoqualmie river at the usa from 01 02 1961 to 06 11 2016 fig 6f assuming again a stationary process for same month days daily discharge was found to be well described by the heavy tailed f b r iii x 40 5 12 6 0 37 distribution eq 14 while the empirical acs fitted well to a relatively slowly decaying weibull acs eq 20 i e ρ x τ ρ w τ 3 5 0 79 fig 6j the estimated correlation transformation function t ρ x 0 74 2 77 fig 6g was applied to evaluate the pgacs ρ z τ fig 6j which gets ρ z τ 0 for τ 25 thus a gaussian time series of 1000 months 31 1000 values was generated from a fitted ar 25 and was transformed to synthetic daily discharge fig 6h by applying the transformation in eq 2 with qx being the quantile of the fitted b r iii the synthetic time series have the expected f b r iii x 40 5 12 6 0 37 marginal fig 6i and the expected acs ρ w τ 3 5 0 79 fig 6j as a final example the method is applied to daily wind speed of january recorded at maastricht in the netherlands from 01 01 1957 to 31 12 2016 fig 6k daily wind speed is described here by the f g g x 4 4 2 66 1 76 distribution eq 12 as commonly used models like the two parameter weibull distribution or the two parameter gamma distribution did not perform well also zero values were not recorded and thus the marginal is assumed continuous the pii acs in eq 21 was fitted to the empirical acs i e ρ x τ ρ pii τ 1 7 0 68 the estimated correlation transformation function t ρ x 0 31 0 18 fig 6l shows no concavity and thus the pgacs ρ z τ coincides with ρ x τ lines overlap in fig 6o the ρ z τ ρ x τ 0 for τ 25 and thus an ar 25 was used to generate a gaussian time series 31 1000 values which was then converted to synthetic daily wind speed fig 6m by applying the transformation in eq 2 with qx being the quantile of the fitted g g the synthetic time series have the expected marginal fig 6n and the expected acs fig 6o 4 4 relative humidity discrete and binary cases many variables in nature can be expressed in the 0 1 range e g relative humidity probability dry percentage variables etc here the method is applied on november daily values of relative humidity recorded at maastricht in the netherlands from 01 01 1957 to 31 12 2016 fig 7 a a two parameter beta b distribution was used i e f b x 16 1 2 3 and a pii acs eq 21 was fitted to the empirical acs i e ρ x τ ρ pii τ 0 80 1 16 the estimated actf t ρ x 3 24 0 07 fig 7b is a straight line and the pgacs ρ z τ coincides with ρ x τ lines overlap in fig 7e the ρ z τ ρ x τ 0 for τ 30 and thus an ar 30 was used to generate a gaussian time series 31 1000 values which was transformed to synthetic daily relative humidity fig 7c by applying the transformation in eq 2 with qx being the quantile of the fitted beta the synthetic time series have the expected marginal fig 7d and the expected acs fig 7e as an example of a process with discrete marginal distribution we use the number of extreme daily precipitation events per year i e in an n year record we identify the n largest values and their dates and count the number in each year here we used a long daily rainfall record randomly selected from the ghcn daily database id asn00008067 to form the number of extremes per year time series fig 7f a two parameter discrete distribution was used i e the polya aeppli p a distribution f p a x 0 85 0 15 to describe the probability to observe a given number of extremes in any year the empirical autocorrelation is essentially 0 and thus for demonstration purposes a pii acs eq 21 was prescribed i e ρ x τ ρ pii τ 1 1 we fit the kumaraswamy actf in eq 28 i e t ρ x 1 0 1 22 fig 7g while the pgacs ρ z τ 0 for τ 30 fig 7j and thus an ar 30 was used to generate a gaussian time series 3000 years which was transformed to synthetic number of extremes per year fig 7h by applying the transformation in eq 2 with qx being the quantile of the fitted polya aeppli distribution the synthetic time series have the expected marginal fig 7i and the expected acs fig 7j in many cases we may desire to express a variable in two states e g rain and no rain we use the same daily rainfall record asn00008067 aggregated to the annual timescale to form a binary time series by assigning 0 to annual precipitation values that belong to the first quartile low values indicating drought years and 1 to the rest fig 7k the bernoulli b e distribution was used with pr x 0 0 25 to describe the probability to observe a drought year and a weibull acs was prescribed i e ρ x τ ρ w τ 2 0 5 to demonstrate the method as the empirical correlation is almost zero the estimated kumaraswamy actf t ρ x 1 03 1 97 fig 7l shows moderate to strong concavity with a perfect fit to the points while the pgacs ρ z τ 0 for τ 30 fig 7o gaussian time series 3000 years were generated from an ar 30 and transformed to binary time series accordingly fig 7m the synthetic binary time series have the expected marginal fig 7n and the expected acs fig 7o 4 5 a multivariate simulation of precipitation wind and relative humidity as a final example we demonstrate the method in a multivariate simulation of three different processes at daily scale i e of precipitation x 1 t wind speed x 2 t and relative humidity x 3 t for precipitation we assume probability dry p 0 0 7 and for positive values a power type b r xii 2 0 9 0 2 distribution for wind probability of zero speed p 0 0 1 and for positive values the two parameter weibull w 5 1 2 distribution and for relative humidity a kumaraswamy k u 11 5 marginal distribution fig 8 a c thus we have two mixed type marginals with different p 0 and different continuous part and a continuous marginal bounded in 0 1 also we assume lag 0 and lag 1 correlation matrices 34 k x 0 1 0 50 0 35 0 50 1 0 60 0 35 0 60 1 k x 1 0 30 0 25 0 15 0 10 0 40 0 35 0 12 0 30 0 50 with the i j element expressing the cross correlation coefficients ρ x i x j τ for lags 0 or 1 between the i th and j th process of course the diagonal in k x 1 refers to the lag 1 autocorrelation note that k x 0 is always symmetric while k x 1 is not the actf s fig 8d f show moderate concavity for the precipitation marginal slight for wind and essentially zero for relative humidity the cctf is concave for rainfall wind fig 8g with estimated upper limit 0 80 while it is clearly convex for rainfall humidity with limit 0 42 fig 8h and slightly convex for the wind humidity case with limit 0 76 fig 8i these functions were used to estimate the pgp correlation matrices i e 35 k z 0 1 0 69 071 0 69 1 0 70 0 71 0 70 1 k z 1 0 49 0 38 0 27 0 17 0 44 0 40 0 21 0 34 0 51 which were used to fit a multivariate ar 1 and generate a multivariate time series of 10 000 values accordingly as in the previous cases each gaussian time series was transformed into its target process time series using the corresponding transformations x i t q x i φ z i z t the synthetic time series fig 8j l preserve all desired properties i e p 0 marginal distributions and the lag 0 and lag 1 correlation matrices while the actual topology of the correlation structure can be seen in the scatter plots of fig a 3 of course it is straightforward to apply this framework for the multivariate cyclostationary case and use higher order mar models if desired 5 summary and conclusions natural processes have a dynamic randomness unveiled by structural dependencies in time and or space and by probability laws governing the frequency of their values there is no unique correlation structure or probability law to describe the pluralism and the polyphony observed in natural processes therefore and in order to avoid ad hoc solutions we need a general stochastic framework capable of reproducing this dynamic randomness irrespective of the correlation structure or the marginal probability law the framework presented here unifies introduces new elements extends and simplifies previous attempts proposing a single approach for stochastic modelling of any hydroclimatic process and beyond the basic assumption is that a stationary or cyclostationary process x t with any prescribed marginal distribution fx x and any linear correlation structure ρ x τ has a parent gaussian process that can be easily assessed for the multivariate case this implies that a set of processes have a corresponding set of parent gaussian processes in this direction a unified framework is introduced based on simple analytical auto and cross correlation transformation functions that enable fast and easy estimation of the parent gaussian processes avoiding iterative and case specific methods proposed in the past the method is applied in a large variety of hydroclimatic processes ranging from intermittent variables like precipitation and wind speed to processes with heavy tail marginals like river discharge and to processes with bounded marginals like relative humidity or even to discrete and binary cases the versatility of the method is also demonstrated in a multivariate case where processes with very different marginals and linear correlation structures are reproduced exactly as a final remark the framework proposed enables an easy estimation of the limit or the maximum feasible cross correlation between two processes and reveals that when their marginals differ significantly in shape then their linear cross correlation cannot be intense the same remark holds also for single processes and although there is no limit and the autocorrelation can reach up to 1 processes with very different marginals from the gaussian e g highly skewed and heavy tailed will be observed with weak linear autocorrelation structures indicating maybe that nature likes to hide its internal structure acknowledgements i honestly thank y markonis for providing the river discharge wind and humidity data as well as for his general support k m andreadis for spotting many typos and the reviewers for meticulously reading the manuscript and providing constructive remarks which led in a significantly improved version appendix a aghakouchak et al 2010 a aghakouchak e habib a bárdossy a comparison of three remotely sensed rainfall ensemble generators atmos res 98 2010 387 399 bárdossy and pegram 2009 a bárdossy g g s pegram copula based multisite model for daily precipitation simulation hydrol earth syst sci 13 2009 2299 bardossy and plate 1992 a bardossy e j plate space time model for daily rainfall using atmospheric circulation patterns water resour res 28 1992 1247 1259 https doi org 10 1029 91wr02589 bartolini et al 1988 p bartolini j d salas j t b obeysekera multivariate periodic arma 1 1 processes water resour res 24 1988 1237 1246 beran 1994 j beran statistics for long memory processes 1994 crc press bowers et al 2012 m c bowers w w tung j b gao on the distributions of seasonal river flows lognormal or power law water resour res 48 2012 w05536 https doi org 10 1029 2011wr011308 box et al 2008 g e p box g m jenkins g c reinsel time series analysis forecasting and control fourth ed 2008 wiley hoboken n j breinl et al 2015 k breinl t turkington m stowasser simulating daily precipitation and temperature a weather generation framework for assessing hydrometeorological hazards meteorol appl 22 2015 334 347 bruhn et al 1979 j a bruhn w e fry g w fick simulation of daily weather data using theoretical probability distributions j appl meteor 19 1979 1029 1036 https doi org 10 1175 1520 0450 1980 019 1029 sodwdu 2 0 co 2 buell 1972 c e buell correlation functions for wind and geopotential on isobaric surfaces j appl meteor 11 1972 51 59 https doi org 10 1175 1520 0450 1972 011 0051 cffwag 2 0 co 2 buishand 1978 t a buishand some remarks on the use of daily rainfall models j hydrol 36 1978 295 308 https doi org 10 1016 0022 1694 78 90150 6 burr 1942 i w burr cumulative frequency functions ann math stat 13 1942 215 232 cario and nelson 1998 m c cario b l nelson numerical methods for fitting and simulating autoregressive to anything processes informs j comput 10 1998 72 81 cario and nelson 1997 m c cario b l nelson modeling and generating random vectors with arbitrary marginal distributions and correlation matrix 1997 department of industrial engineering and management sciences northwestern university evanston illinois technical report cârsteanu and foufoula georgiou 1996 a cârsteanu e foufoula georgiou assessing dependence among weights in a multiplicative cascade model of temporal rainfall j geophys res 101 1996 26363 26370 https doi org 10 1029 96jd01657 carta et al 2009 j a carta p ramírez s velázquez a review of wind speed probability distributions used in wind energy analysis renewable sustainable energy rev 13 2009 933 955 https doi org 10 1016 j rser 2008 05 005 chang 1996 k f chang strictly positive definite functions j approx theory 87 1996 148 158 https doi org 10 1006 jath 1996 0097 chung and salas 2000 c chung j d salas drought occurrence probabilities and risks of dependent hydrologic processes j hydrol eng 5 2000 259 268 ciach and krajewski 2006 g j ciach w f krajewski analysis and modeling of spatial correlation structure in small scale rainfall in central oklahoma adv water res 29 2006 1450 1463 https doi org 10 1016 j advwatres 2005 11 003 cowpertwait et al 2007 p cowpertwait v isham c onof point process models of rainfall developments for fine scale structure proc r soc lond a 463 2007 2569 2587 https doi org 10 1098 rspa 2007 1889 davison et al 2012 a c davison s a padoan m ribatet statistical modeling of spatial extremes stat sci 27 2012 161 186 demirtas 2017 h demirtas concurrent generation of binary and nonnormal continuous data through fifth order power polynomials commun stat simul comput 46 2017 344 357 demirtas 2014 h demirtas joint generation of binary and nonnormal continuous data j biometr biostat 2014 1 demirtas and hedeker 2011 h demirtas d hedeker a practical way for computing approximate lower and upper correlation bounds am statistician 65 2011 104 109 dolloff et al 2006 j dolloff b lofy a sussman c taylor strictly positive definite correlation functions signal processing sensor fusion and target recognition xv 2006 international society for optics and photonics 62351 a https doi org 10 1117 12 663967 embrechts et al 2002 p embrechts a mcneil d straumann correlation and dependence in risk management properties and pitfalls risk management value at risk and beyond 2002 176223 emrich and piedmonte 1991 l j emrich m r piedmonte a method for generating high dimensional multivariate binary variates am stat 45 1991 302 304 feller 1971 w feller 2 ed introduction to the theory of probability and its applications 2 1971 wiley new york ferrari and barbiero 2012 p a ferrari a barbiero simulating ordinal data multivariate behav res 47 2012 566 589 https doi org 10 1080 00273171 2012 692630 foufoula georgiou and krajewski 1995 e foufoula georgiou w krajewski recent advances in rainfall modeling estimation and forecasting rev geophys 33 1995 1125 1137 https doi org 10 1029 95rg00338 foufoula georgiou and lettenmaier 1987 e foufoula georgiou d p lettenmaier a markov renewal model for rainfall occurrences water resour res 23 1987 875 884 https doi org 10 1029 wr023i005p00875 fréchet 1957 m fréchet les tableaux de corrélation et les programmes linéaires revue de l institut international de statistique 1957 23 40 geng et al 1986 s geng f w t penning de vries i supit a simple method for generating daily rainfall data agric forest meteorol 36 1986 363 376 https doi org 10 1016 0168 1923 86 90014 6 georgakakos et al 1994 k p georgakakos a a carsteanu p l sturdevant j a cramer observation and analysis of midwestern rain rates j appl meteorol 33 1994 1433 1444 gneiting 1999 t gneiting correlation functions for atmospheric data analysis q j r meteorol soc 125 1999 2449 2464 https doi org 10 1002 qj 49712555906 gneiting and schlather 2004 t gneiting m schlather stochastic models that separate fractal dimension and the hurst effect siam rev 46 2004 269 282 https doi org 10 1137 s0036144501394387 granger and joyeux 1980 c w granger r joyeux an introduction to long memory time series models and fractional differencing j time ser anal 1 1980 15 29 grimaldi and serinaldi 2006 s grimaldi f serinaldi asymmetric copula in multivariate flood frequency analysis adv water res 29 2006 1155 1167 hammer and steurer 1997 g r hammer p m steurer data set documentation for hourly precipitation data noaa ncdc td3240 documentation series asheville nc 1997 18 hering et al 2015 a s hering k kazor w kleiber a markov switching vector autoregressive stochastic wind generator for multiple spatial and temporal scales resources 4 2015 70 92 herr and krzysztofowicz 2005 h d herr r krzysztofowicz generic probability distribution of rainfall in space the bivariate model j hydrol 306 2005 234 263 higham 2002 n j higham computing the nearest correlation matrix a problem from finance ima j numer anal 22 2002 329 343 https doi org 10 1093 imanum 22 3 329 higham 1988 n j higham computing a nearest symmetric positive semidefinite matrix linear algebra appl 103 1988 103 118 https doi org 10 1016 0024 3795 88 90223 6 hoeffding 1994 w hoeffding scale invariant correlation theory the collected works of wassily hoeffding 1994 springer 57 107 hosking 1984 j r hosking modeling persistence in hydrological time series using fractional differencing water resour res 20 1984 1898 1908 hosking 1981 j r hosking fractional differencing biometrika 68 1981 165 176 hosking 1994 j r m hosking the four parameter kappa distribution ibm j res dev 38 1994 251 258 hosking 1990 j r m hosking l moments analysis and estimation of distributions using linear combinations of order statistics j r stat soc ser b methodological 52 1990 105 124 hurst 1951 h e hurst long term storage capacity of reservoirs trans am soc civil eng 116 1951 770 808 huser et al 2016 r huser a c davison m g genton likelihood estimators for multivariate extremes extremes 19 2016 79 103 https doi org 10 1007 s10687 015 0230 4 huser and genton 2016 r huser m g genton non stationary dependence structures for spatial extremes jabes 21 2016 470 491 https doi org 10 1007 s13253 016 0247 4 iliopoulou et al 2016 t iliopoulou s m papalexiou y markonis d koutsoyiannis revisiting long range dependence in annual precipitation j hydrol 2016 https doi org 10 1016 j jhydrol 2016 04 015 istok and boersma 1989 j d istok l boersma a stochastic cluster model for hourly precipitation data j hydrol 106 1989 257 285 https doi org 10 1016 0022 1694 89 90076 0 justus et al 1978 c g justus w r hargraves a mikhail d graber methods for estimating wind speed frequency distributions j appl meteor 17 1978 350 353 https doi org 10 1175 1520 0450 1978 017 0350 mfewsf 2 0 co 2 kendall and stuart 1979 m kendall a stuart handbook of statistics 1979 griffin company london kilsby et al 2007 c g kilsby p d jones a burton a c ford h j fowler c harpham p james a smith r l wilby a daily weather generator for use in climate change studies environ modell softw 22 2007 1705 1719 kleiber et al 2012 w kleiber r w katz b rajagopalan daily spatiotemporal precipitation simulation using latent and transformed gaussian processes water resour res 48 2012 w01523 https doi org 10 1029 2011wr011105 klein tank and können 2003 a m g klein tank g p können trends in indices of daily temperature and precipitation extremes in europe 1946 99 j climate 16 2003 3665 3680 https doi org 10 1175 1520 0442 2003 016 3665 tiiodt 2 0 co 2 kroll and vogel 2002 c n kroll r m vogel probability distribution of low streamflow series in the united states j hydrol eng 7 2002 137 146 kugiumtzis 2002 d kugiumtzis statically transformed autoregressive process and surrogate data test for nonlinearity phys rev e 66 2002 025201 kumar and foufoula georgiou 1997 p kumar e foufoula georgiou wavelet analysis for geophysical applications rev geophys 35 1997 385 412 https doi org 10 1029 97rg00427 kumaraswamy 1980 p kumaraswamy a generalized probability density function for double bounded random processes j hydrol 46 1980 79 88 https doi org 10 1016 0022 1694 80 90036 0 lebrun and dutfoy 2009 r lebrun a dutfoy an innovating analysis of the nataf transformation from the copula viewpoint probab eng mech 24 2009 312 320 https doi org 10 1016 j probengmech 2008 08 001 lee and salas 2011 t lee j d salas copula based stochastic simulation of hydrological data applied to nile river flows hydrol res 42 2011 318 330 li et al 2008 h li z lü x yuan nataf transformation based point estimate method chin sci bull 53 2008 2586 https doi org 10 1007 s11434 008 0351 0 liu and der kiureghian 1986 p l liu a der kiureghian multivariate distribution models with prescribed marginals and covariances probab eng mech 1 1986 105 112 https doi org 10 1016 0266 8920 86 90033 0 lombardo et al 2014 f lombardo e volpi d koutsoyiannis s m papalexiou just two moments a cautionary note against use of high order moments in multifractal models in hydrology hydrol earth syst sci 18 1 2014 243 255 https doi org 10 5194 hess 18 243 2014 macke et al 2009 j h macke p berens a s ecker a s tolias m bethge generating spike trains with specified correlation coefficients neural comput 21 2009 397 423 mandelbrot 1971 b b mandelbrot a fast fractional gaussian noise generator water resour res 7 1971 543 553 mandelbrot and wallis 1969 b b mandelbrot j r wallis some long run properties of geophysical records water resour res 5 1969 321 340 https doi org 10 1029 wr005i002p00321 mandelbrot and wallis 1968 b b mandelbrot j r wallis noah joseph and operational hydrology water resour res 4 1968 909 918 https doi org 10 1029 wr004i005p00909 markonis et al 2018 y markonis y moustakis c nasika p sychova p dimitriadis m hanel p máca s m papalexiou global estimation of long term persistence in annual river runoff adv water res 113 2018 1 12 https doi org 10 1016 j advwatres 2018 01 003 mehrotra and sharma 2009 r mehrotra a sharma evaluating spatio temporal representations in daily rainfall sequences from three stochastic multi site weather generation approaches adv water res 32 2009 948 962 mielke 1973 p w mielke jr another family of distributions for describing and analyzing precipitation data j appl meteorol 12 1973 275 280 mielke and johnson 1974 p w mielke jr e s johnson some generalized beta distributions of the second kind having desirable application features in hydrology and meteorology water resour res 10 1974 223 226 mielke and johnson 1973 p w mielke jr e s johnson three parameter kappa distribution maximum likelihood estimates and likelihood ratio tests mon weather rev 101 1973 701 707 molotch et al 2005 n p molotch m t colee r c bales j dozier estimating the spatial distribution of snow water equivalent in an alpine basin using binary regression tree models the impact of digital elevation data and independent variable selection hydrol processes 19 2005 1459 1479 montanari et al 1997 a montanari r rosso m s taqqu fractionally differenced arima models applied to hydrologic time series identification estimation and simulation water resour res 33 1997 1035 1044 nataf 1962 a nataf statistique mathematique determination des distributions de probabilites dont les marges sont donnees comptes rendus hebdomadaires des seances de l academie des sciences 255 1962 42 neumaier and schneider 2001 a neumaier t schneider estimation of parameters and eigenmodes of multivariate autoregressive models acm trans math softw toms 27 2001 27 57 onof et al 2000 c onof r e chandler a kakou p northrop h s wheater v isham rainfall modelling using poisson cluster processes a review of developments stochastic environ res risk assess 14 2000 384 411 https doi org 10 1007 s004770000043 onof et al 2005 c onof j townend r kee comparison of two hourly to 5 min rainfall disaggregators atmospheric research precipitation in urban areas6th international workshop on precipitation in urban areas 77 2005 176 187 https doi org 10 1016 j atmosres 2004 10 022 onof and wheater 1993 c onof h s wheater modelling of british rainfall using a random parameter bartlett lewis rectangular pulse model j hydrol conventry groundwater invest 149 1993 67 95 https doi org 10 1016 0022 1694 93 90100 n over and gupta 1996 t m over v k gupta a space time theory of mesoscale rainfall using random cascades j geophys res 101 1996 26319 26331 https doi org 10 1029 96jd02033 papalexiou et al 2016 s m papalexiou y g dialynas s grimaldi hershfield factor revisited correcting annual maximum precipitation j hydrol 542 2016 884 895 https doi org 10 1016 j jhydrol 2016 09 058 papalexiou and koutsoyiannis 2016 s m papalexiou d koutsoyiannis a global survey on the seasonal variation of the marginal distribution of daily precipitation adv water res 94 2016 131 145 https doi org 10 1016 j advwatres 2016 05 005 papalexiou and koutsoyiannis 2013 s m papalexiou d koutsoyiannis battle of extreme value distributions a global survey on extreme daily rainfall water resour res 49 2013 187 201 https doi org 10 1029 2012wr012557 papalexiou and koutsoyiannis 2012 s m papalexiou d koutsoyiannis entropy based derivation of probability distributions a case study to daily rainfall adv water resour 45 2012 51 57 space time precipitation from urban scale to global change https doi org 10 1016 j advwatres 2011 11 007 papalexiou et al 2013 s m papalexiou d koutsoyiannis c makropoulos how extreme is extreme an assessment of daily rainfall distribution tails hydrol earth syst sci 17 2013 851 862 https doi org 10 5194 hess 17 851 2013 papalexiou et al 2011 s m papalexiou d koutsoyiannis a montanari can a simple stochastic model generate rich patterns of rainfall events j hydrol 411 2011 279 289 https doi org 10 1016 j jhydrol 2011 10 008 papoulis and pillai 2002 a papoulis s u pillai probability random variables and stochastic processes 2002 tata mcgraw hill education park et al 2009 j s park s c seo t y kim a kappa distribution with a hydrological application stochastic environ res risk assess 23 2009 579 586 https doi org 10 1007 s00477 008 0243 5 paschalis et al 2014 a paschalis p molnar s fatichi p burlando on temporal stochastic modeling of precipitation nesting models across scales adv water res 63 2014 152 166 https doi org 10 1016 j advwatres 2013 11 006 ribatet 2013 m ribatet spatial extremes max stable processes at work j de la société française de statistique 154 2013 156 177 rodriguez iturbe et al 1987 i rodriguez iturbe d r cox v isham some models for rainfall based on stochastic point processes proc r soc lond a 410 1987 269 288 https doi org 10 1098 rspa 1987 0039 salas 1980 j d salas applied modeling of hydrologic time series 1980 water resources publication salas et al 1982 j d salas d c boes r a smith estimation of arma models with seasonal parameters water resour res 18 1982 1006 1010 https doi org 10 1029 wr018i004p01006 salas et al 2006 j d salas o g sveinsson w l lane d k frevert stochastic streamflow simulation using sams 2003 j irrig drain eng 132 2006 112 122 schlögl 2006 a schlögl a comparison of multivariate autoregressive estimators signal process 86 2006 2426 2429 schneider and neumaier 2001 t schneider a neumaier algorithm 808 arfit a matlab package for the estimation of parameters and eigenmodes of multivariate autoregressive models acm trans math softw toms 27 2001 58 65 seguro and lambert 2000 j v seguro t w lambert modern estimation of the parameters of the weibull wind speed distribution for wind energy analysis j wind eng ind aerodyn 85 2000 75 84 https doi org 10 1016 s0167 6105 99 00122 1 serinaldi 2009 f serinaldi a multisite daily rainfall generator driven by bivariate copula based mixed distributions j geophys res 114 2009 serinaldi and kilsby 2016 f serinaldi c g kilsby a blueprint for full collective flood risk estimation demonstration for european river flooding risk anal 2016 serinaldi and kilsby 2014a f serinaldi c g kilsby simulating daily rainfall fields over large areas for collective risk estimation j hydrol 512 2014 285 302 serinaldi and kilsby 2014b f serinaldi c g kilsby rainfall extremes toward reconciliation after the battle of distributions water resour res 50 2014 336 352 https doi org 10 1002 2013wr014211 serinaldi et al 2018 f serinaldi c g kilsby f lombardo untenable nonstationarity an assessment of the fitness for purpose of trend tests in hydrology adv water res 111 2018 132 155 https doi org 10 1016 j advwatres 2017 10 015 serinaldi and lombardo 2017 f serinaldi f lombardo general simulation algorithm for autocorrelated binary processes phys rev e 95 2017 023312 shao and lund 2004 q shao r lund computation and characterization of autocorrelations and partial autocorrelations in periodic arma models j time ser anal 25 2004 359 372 sirangelo et al 2007 b sirangelo p versace d l de luca rainfall nowcasting by at site stochastic model praise hydrol earth syst sci discuss 4 2007 151 177 smith and schreiber 1974 r l smith h a schreiber point processes of seasonal thunderstorm rainfal 2 rainfall depth probabilities water resour res 1974 stacy 1962 e w stacy a generalization of the gamma distribution ann math stat 33 1962 1187 1192 stacy and mihram 1965 e w stacy g a mihram parameter estimation for a generalized gamma distribution technometrics 7 1965 349 358 stephenson et al 2016 a g stephenson e a lehmann a phatak a max stable process model for rainfall extremes at different accumulation durations weather climate extremes 13 2016 44 53 https doi org 10 1016 j wace 2016 07 002 stern and coe 1984 r d stern r coe a model fitting analysis of daily rainfall data j r stat soc ser a general 147 1984 1 https doi org 10 2307 2981736 swift and schreuder 1981 l w swift h t schreuder fitting daily precipitation amounts using the sb distribution mon weather rev 109 1981 2535 2540 https doi org 10 1175 1520 0493 1981 109 2535 fdpaut 2 0 co 2 tadikamalla 1980 p r tadikamalla a look at the burr and related distributions int stat rev 48 1980 337 344 revue internationale de statistique todorovic and woolhiser 1975 p todorovic d a woolhiser a stochastic model of n day precipitation j appl meteorol 14 1975 17 24 tsoukalas et al 2018 i tsoukalas a efstratiadis c makropoulos stochastic periodic autoregressive to anything sparta modeling and simulation of cyclostationary processes with arbitrary marginal distributions water resour res 2018 n a n a https doi org 10 1002 2017wr021394 van montfort 1990 m a j van montfort sliding maxima j hydrol 118 1990 77 85 https doi org 10 1016 0022 1694 90 90251 r verhoest et al 1997 n verhoest p a troch f p de troch on the applicability of bartlett lewis rectangular pulses models in the modeling of design storms at a point j hydrol 202 1997 108 120 https doi org 10 1016 s0022 1694 97 00060 7 villarini et al 2014 g villarini b c seo f serinaldi w f krajewski spatial and temporal modeling of radar rainfall uncertainties atmos res 135 2014 91 101 waymire and gupta 1981 e waymire v k gupta the mathematical structure of rainfall representations 1 a review of the stochastic rainfall models water resour res 17 1981 1261 1272 https doi org 10 1029 wr017i005p01261 wheater et al 2005 h s wheater r e chandler c j onof v s isham e bellone c yang d lekkas g lourmas m l segond spatial temporal rainfall modelling for flood risk estimation stochastic environ res risk assess 19 2005 403 416 https doi org 10 1007 s00477 005 0011 8 wilks 1999 d s wilks simultaneous stochastic simulation of daily precipitation temperature and solar radiation at multiple sites in complex terrain agric forest meteorol 96 1999 85 101 wilks 1998 d s wilks multisite generalization of a daily stochastic precipitation generation model j hydrol 210 1998 178 191 https doi org 10 1016 s0022 1694 98 00186 3 wilks and wilby 1999 d s wilks r l wilby the weather generation game a review of stochastic weather models prog phys geogr 23 1999 329 357 wilson and toumi 2005 p s wilson r toumi a fundamental probability distribution for heavy rainfall geophys res lett 32 2005 l14812 https doi org 10 1029 2005gl022465 xiao 2014 q xiao evaluating correlation coefficient for nataf transformation probab eng mech 37 2014 1 6 https doi org 10 1016 j probengmech 2014 03 010 yaglom 2012 a m yaglom correlation theory of stationary and related random functions 2012 springer science business media supplementary notes and 
836,this study theoretically analyzes the concept of apparent saturation hysteresis combined with the scott et al 1983 scaling approach as suggested by parker and lenhard 1987 to account for the effect of air entrapment and release on the soil water hysteresis we found that the theory of parker and lenhard 1987 is comprised of some mutually canceling mathematical operations and when cleared of the superfluous intermediate calculations their model reduces to the original scott et al s 1983 scaling method supplemented with the requirement of closure of scanning loops our analysis reveals that actually there is no effect of their technique of accounting for the entrapped air on the final prediction of the effective saturation or water content scanning curves our consideration indicates that the use of the land 1968 formula for assessing the amount of entrapped air is in disaccord with the apparent saturation concept as introduced by parker and lenhard 1987 in this paper a proper routine is suggested for predicting hysteretic scanning curves of any order given the two measured main curves in the complete hysteretic domain and some verification tests are carried out versus measured results accordingly explicit closed form formulae for direct prediction with no need of intermediate calculation of scanning curves up to the third order are derived to sustain our analysis keywords soil water hysteresis air entrapment hysteretic scanning curves scaling domain theory abbreviations fdc mdc and mwc first drying curve main drying curve and main wetting curve respectively 1 introduction a general overview of the different theories and models of soil water hysteresis is given in our previous studies mualem and beriozkin 2008 2009 these latter reviews are relevant to the present study as well so as to avoid repetition the adduced review refers only to studies related to the present subject matter dealing with the apparent saturation model based on the scott et al 1983 empirical scaling technique using a simplified two parametric form of the van genuchten 1980 formula scott et al 1983 suggested that two shape parameters of any primary drying curve be the same as those pertaining to the mdc similarly two shape parameters of any primary wetting curve are the same as those pertaining to the mwc kool and parker 1987 applied the scott et al 1983 model when using the three parameter form of the van genuchten 1980 formula and assuming the exponent of the capillary head ψ to be the same for wetting and drying curves however their model suffered from an artifact of a pumping effect producing unclosed scanning loops parker and lenhard 1987 followed by a series of publications lenhard 1992 lenhard and parker 1987 lenhard et al 1988 kaluarachchi and parker 1992 lenhard et al 1989 lenhard et al 1991 lenhard and parker 1992 dane and lenhard 2004 etc introduced the concept of apparent saturation defined as a sum of effective saturations of water and trapped air applying the scott et al 1983 scaling principle they proposed a hysteresis model based on the apparent saturation concept in this model the scaling technique was applied to the apparent saturation capillary head curves and air entrapment and release were described by a linear law as suggested in the mualem 1974 model this linear law is approximative with respect to the measured data of a number of soils and it is intended to give a reasonable description until developing a comprehensive conceptual model based on the water retention curve with possible accounting for the rate of process for estimation of the entrapped air content at completion points i e at ψ 0 of the primary wetting curves departing from the fdc parker and lenhard 1987 used the empirical formula of land 1968 they also enforced closure of scanning loops to eliminate the pumping effect of kool and parker 1987 dane and lenhard 2004 highly estimated the model of parker and lenhard 1987 and its air water version by lenhard et al 1991 noting the best available hysteresis model for air water relations is probably lenhard s however this conclusion is neither founded on sound theoretical analysis nor on any verification tests versus other models and experimental results our preliminary tests revealed that parker and lenhard s 1987 presumptions are not substantiated and according to their own apparent saturation model there should be no effect at all of the entrapped air on the final prediction of the effective saturation or water content within the main hysteretic loop these results cast doubts regarding their analysis and conclusions taking into account the multiple use of the apparent saturation concept in numerous publications including those concerned with relative permeability saturation relations e g lenhard and parker 1987 lenhard and parker 1992 dane and lenhard 2004 it is of theoretical and practical interest to thoroughly investigate this concept and derive physically and mathematically sound conclusions regarding its applicability while the linear law of air entrapment was used in several models e g mualem 1974 lenhard and parker 1987 lenhard et al 1989 observations were made regarding its common reliability particularly stonestrom and rubin 1989 obtained non linear water content dependence of the entrapped air content using an air pycnometer device they obtained reproducible hysteretic relationships between the water and entrapped air contents during the main wetting and drying processes however as we show hereafter fig 4 e a significant discrepancy is found between the measured fdc i e departing from the fully saturated state and that calculated using the air entrapment data obtained with the air pycnometer method this fact implies a necessity of physically based converting of the air pycnometer data the amount of entrapped air in wetting and drying processes has been linearly approximated in more recent studies e g finsterle et al 1998 dane and lenhard 2004 rudiyanto et al 2015 particularly the model of finsterle et al 1998 with built in air entrapment linear law was implemented in the inverse modeling module itough2 incorporated within the tough2 software package designed for simulating multiphase flow in fractured porous media in the past we have shown mualem and beriozkin 2009 that the similarity hypothesis of mualem 1974 implies shape similarity of all wetting curves regardless of their orders according to this similarity hypothesis the bivariate domain density distribution function f ψw ψd where ψw and ψd being the capillary head values of filling and emptying a domain respectively is represented as a product of two univariate functions l ψw and h ψd the feature of shape similarity of the wetting theoretical scans is valid not only when the independent domain model of mualem 1974 is applied but also holds valid when using the dependent domain models of mualem and dagan 1975 and mualem 1984 both of which account for the air entry blockage consequently all the wetting theoretical scans are described by the same unified normalized scaling equation however regarding the prediction of the drying scans from the given mdc mualem and beriozkin 2009 have shown that the use of scaling is not in accord with the domain theory and may yield large prediction errors for soils that exhibit significant blockage against air entry in the main drainage rudiyanto et al 2013 studied the hysteresis modeling with regard to the dual porosity soils and applied the kool and parker 1987 scaling model based on the van genuchten 1980 retention function to prediction of the wetting and drying scans rudiyanto et al 2013 suggested considering hysteresis only within the range of the macropore inter aggregate sub region whereas in the micropore intra aggregate sub region a non hysteretic retention relationship was assumed however if the measured hysteresis loop extends beyond the macropore sub region then ignoring the fact that in this case the most negative capillary head of this loop i e of the lower point of the loop closure is more negative than that of the inflection point between the two above sub regions will inevitably lead to errors in prediction by scaling method already in the stage of obtaining a primary drying curve in this case a predicted primary drying curve will intersect the mdc generally the lower point of the loop closure remains fixed under rescaling the mdc to primary drying curves thereby the adequate determination of the water content at this point is important since the study of topp et al 1967 it has been commonly acknowledged that the θ ψ relationships are determined not only by the wetting drying prehistory of the current state but also by the rate of change of the system capillary head in the modeling of transient dynamic flow events the use of water retention curves measured in the steady state conditions as well as of hysteresis models calibrated by these curves requires accounting for the rate of water saturation changes in time the necessary theoretical framework including non equilibrium hysteresis has been developed by hassanizadeh and grey 1993 beliaev and hassanizadeh 2001 and hassanizadeh et al 2002 who derived a rate dependent water saturation capillary head equation including a dynamic term with relaxation parameter τ these studies were followed by a series of contributions e g egorov et al 2003 nieber et al 2005 manthey 2006 sander et al 2008 milišić 2017 considering non equilibrium unsaturated flows a comprehensive data set of long term monitoring of hysteretic water content capillary head relationships measured under mainly transient non equilibrium conditions have been obtained in the study of hannes et al 2016 that has been carried out in the framework of the german soilcan lysimeter network tereno three hysteresis models parker and lenhard 1987 mualem 1984 and poulovassilis and kargas 2000 were examined on the subject of their ability to describe the observed behavior of different families of non equilibrium hysteresis curves the general regularity observed is that the faster the changes in ψ the more significant the difference between the measured transient θ ψ trajectories and the corresponding equilibrium ones and the faster the changes in ψ the more significant the difference between the measured transient θ ψ trajectories and the based on them model predicted hysteresis curves an additional finding of hannes et al 2016 is that different rates of wetting lead to different final amounts of entrapped air a forward looking approach to hysteresis modeling has been undertaken by lamorski et al 2017 who applied a machine learning based predictive approach for a representative amount of measured data they obtained the authors used the support vector machines algorithm for prediction of the mwc from the only measured mdc and obtained the better agreement between measured and estimated mwc than in the cases of using the one branch model of mualem 1977 and the one branch version of the kool and parker 1987 model the objectives of the present study are 1 to consider the role of the apparent saturation concept with regard to prediction of the soil water hysteresis and also address in this framework the consequences of applying the land 1968 formula of air entrapment 2 to check the mathematical and physical consistency of the predictive procedure as suggested by parker and lenhard 1987 and identify the relations of their model to the similarity approach of mualem 1974 and 3 to suggest a mathematically sound and experimentally verified predictive routine based on the domain theory with concise closed form formulae of the scanning curves in the complete hysteresis domain which also properly accounts for the air entrapment and release 2 theory the concept of apparent saturation defined as a sum of effective saturations of water and of trapped air was introduced by parker and lenhard 1987 in order to describe the hysteretic relationships by following the evolution of the wetting fluid continuous air interface their model incorporates a linear law of air entrapment in wetting processes and release of the entrapped air in drying processes except for the first drainage along with a scaling technique the predictive procedure suggested by parker and lenhard 1987 leads to prediction of a desired water content capillary head scan via a transitional prediction of its associated apparent saturation scan the section hereinafter systematically analyzes the nature of the operations constituting this predictive procedure as well as how the predicted scans are related to the corresponding scans derived by the mualem 1974 hysteresis model 2 1 definition and properties of scaling transformation generally one may consider the above operations to be mathematically equivalent to sequential scaling transformations to substantiate this statement let us relate to the basic definition of a scaling transformation let a xa ya and b xb yb be two points on the x y plane this pair of points uniquely define a scaling transformation q a b by which to any function f x with f xb f xa corresponds its image function q a b f that passes through points a and b and its derivative differs from df dx by a constant coefficient by this definition the scaling is a non linear transformation which has the form 1 a q a b f y b y b y a f x b f x a f x f x b or equivalently 1 b q a b f y a y b y a f x b f x a f x f x a thus if two functions f x and h x satisfy the relationship 2 h x λ f x over some interval x 1 x 2 with λ being some constant then transformation q a b where a x 1 h x 1 and b x 2 h x 2 implies h x q a b f now let q b c and q p r be two maps where xb xp xr xc then for any monotonous f x there exist images φ q b c f and g q p r φ according to 1 φ x and g x can be represented by φ x γ νf x and g x η λφ x where γ ν η and λ are certain constants which may be determined by 1 a or 1 b hence we have g x η λ γ ν f x η λ γ λ ν f x consequently g x λ ν f x therefore relation 2 is fulfilled for g x and f x and thus there exists a one step scaling transformation producing g x directly from f x and moreover it must be just q p r because g x passes through the points p and r namely 3 q p r q b c f q p r f accordingly relationship 3 can be further extended as follows let q a q q b c and q p r be maps where xa xb xp xr xc xq then their product is equivalent to the last one so that for any monotonous f x we have 3 a q p r q b c q a q f q p r f hereby an important property of scaling transformations is stated as follows the result of any series of sequential scaling transformations applied to a monotonous function f is equal to the last direct scaling transformation of the original function f 2 2 application of scaling transformation for describing air entrapment as defined by parker and lenhard 1987 the apparent saturation is a sum 5 s s s a t where 6 s θ θ r θ s θ r is the effective saturation of water and 7 s a t θ a t θ s θ r is the effective saturation of trapped air θ vw vt is the actual volumetric water content vt being a total volume θ a t v a t v t denotes the entrapped part of volumetric air content θ r and θ s are the residual and saturated water contents respectively fig 1 and vw and v a t are the volumes of water and entrapped air within the soil sample denote θ u to be the actual volumetric water content at the completion of the wetting process of an initially dry soil fig 1 when θ θ u and therefore s s u θ u θ r θ s θ r then quantity s a t takes on its maximum possible value θ s θ u θ s θ r in accord with these designations we denote s md ψ and s fd ψ to be the effective water saturation mdc and fdc respectively the difference s fd ψ s md ψ is the effective saturation of trapped air s a t during the main drainage i e 8 s md ψ s fd ψ obviously along the first drainage where s a t 0 there is no difference between the apparent and effective water saturations i e s fd ψ s fd ψ according to mualem s 1974 linear law of air entrapment mualem 1974 eqs 22 24 29 and 30 the amount of trapped air s a t in any process except the first drainage is described as 9 s a t 1 s pw f i n s pw f i n s fd ψ 1 δ s where s pw f i n denotes the effective saturation at the endpoint of the most recent primary wetting process departing from the first drainage at capillary head ψ1 δ s is the difference between the effective water saturation at a current state of the soil water air system s and that at the reversal from the first drainage to the most recent primary wetting process i e s fd ψ 1 in the limit case where the main wetting process plays a role of the most recent primary wetting process that branches from the first drainage i e s pw f i n s u s fd ψ 1 0 and δ s s eq 9 reduces as follows 9 a s a t 1 s u s u s this case relates to the mwc and mdc themselves as well as to any sequence of scans branching from the main boundary loop made up of the mwc and mdc denote δ s to be the difference between the apparent water saturation s at a current state of the soil water air system and that at the reversal from the first drainage to the most recent primary wetting process i e s fd ψ 1 ψ1 being the capillary head at the reversal substituting eq 5 into eq 9 leads to the following relation between s a t and δ s 10 s a t 1 s pw f i n 1 s fd ψ 1 δ s valid for any process except for the first drainage the obtained eq 10 like the above eq 9 reflects mualem s 1974 linear law of air entrapment conformably to a primary wetting process branching at ψ1 from the first drainage eq 10 reduces to eq 16 of parker and lenhard 1987 using eqs 9 and 10 the relation between δ s and δ s along any process except the first drainage takes the form 11 δ s ψ 1 s fd ψ 1 s pw f i n s fd ψ 1 δ s ψ when applied to the limit case in which the most recent primary wetting is the main wetting process i e s pw f i n s u s fd ψ 1 0 δ s s and δ s s the above eq 11 becomes as follows 11 a s s s u what means that functions s ψ and s ψ obey eq 2 consequently conversion of effective water saturation curve into the corresponding apparent water saturation curve and vice versa is equivalent to scaling transformation suppose we need to predict a water content primary wetting curve r 1 r 0 fig 1 b based on the input data of measured θ ψ points of the mdc mwc including θ u and θ r and the value of θs in this case the most recent primary wetting process departing from the first drainage is the main wetting process itself being the limit case according to the apparent saturation model of parker and lenhard 1987 the predictive procedure includes i conversion of the water content mwc and mdc i e θmw ψ and θmd ψ to the apparent saturation mwc and mdc i e s mw ψ and s md ψ respectively fig 2 this transition is realized by eqs 6 and 11 a ii obtainment of the apparent saturation primary wetting curve s pw ψ by rescaling the apparent saturation mwc s mw ψ to interpolate between two reversal points located on curve s md ψ at ψ ψ1 and ψ ψmax fig 2 this transition is realized by eq 1 a rewritten in the form 1 a s pw ψ 1 1 s md ψ 1 1 s mw ψ 1 1 s mw ψ iii conversion of the obtained apparent saturation primary wetting curve s pw ψ to the corresponding effective saturation primary wetting curve s pw ψ fig 2 followed by conversion of the latter to the desired water content primary wetting curve θpw ψ this transition is realized by eqs 5 10 and 6 where eq 10 reduces to s a t 1 s u s pw according to eqs 1 a b and 11 a the operations i and iii are tantamount to certain scaling transformations whereas the operation ii is by definition a scaling transformation then taking into account that intermediate transitions from θ to s and backwards are also equivalent to certain scaling transformations we eventually obtain a sequence of scaling transformations which in view of eq 3 a can be replaced by a single equivalent direct transformation of rescaling curve θmw ψ to interpolate between points r 1 and r 0 fig 1 b suppose now we need to predict a water content primary wetting curve q 1 q 0 fig 1 b based on the input data of measured water content fdc and mwc according to the parker and lenhard 1987 model the predictive procedure in this case includes i conversion of the measured water content mwc θmw ψ to the apparent saturation mwc s mw ψ fig 3 this transition is realized by eqs 6 and 11 a ii obtaining the apparent saturation primary wetting curve s pw ψ branching at ψ ψ1 from the effective saturation fdc s fd ψ fig 3 by rescaling the apparent saturation mwc s mw ψ to interpolate between the two reversal points located on curve s fd ψ at ψ ψ1 and ψ ψmax this transition is realized by eq 1 a iii conversion of the obtained apparent saturation primary wetting curve s pw ψ to the corresponding effective saturation primary wetting curve s pw ψ fig 3 followed by conversion of this s pw ψ to the desired water content primary wetting curve θpw ψ this transition is realized by eqs 5 10 and 6 while in eq 10 the difference s pw ψ s fd ψ 1 stands for δ s and s pw f i n is calculated by the land 1968 formula eq 12 hereinafter again all the above transitions are altogether tantamount to a single direct transformation of rescaling the measured water content mwc θmw ψ into the desired water content primary wetting curve θpw ψ that starts from point q 1 and ends at point q 0 fig 1 b in the model of parker and lenhard 1987 point q 0 is calculated by the land 1968 formula the problem of consistency of using land s formula jointly with applying the apparent saturation concept is considered in the following subsection from the viewpoint of the domain theory of mualem 1974 the two primary wetting processes r 1 r 0 and q 1 q 0 fig 1 b are parallel mualem 1974 eq 29 and therefore the water content at q 0 is θ u θfd ψ1 θmd ψ1 where according to 6 8 and 11 a 12 θ md ψ 1 θ r θ fd ψ 1 θ r θ u θ r θ s θ r the consideration similar to those conducted above with respect to the primary wetting processes r 1 r 0 and q 1 q 0 fig 1 b can be carried out analogously regarding the prediction of any sequential drying and wetting scanning curves it will lead to the same conclusion all scanning curves can be directly predicted from the measured θ ψ hysteresis boundary curves without the application of the apparent saturation concept since it leads to surplus operations that mutually cancel themselves and only create an erroneous impression of exploiting a real physical relationship 2 3 comparison of air entrapment relationships in the models of parker and lenhard 1987 and mualem 1974 to substantiate application of the apparent saturation approach lenhard et al 1991 reasoned to account for nonwetting fluid entrapment in s p relations we employ the concept of an apparent saturation to track movements of interfaces that separate wetting fluid from a continuous nonwetting phase the rationale behind the use of the apparent saturation approach is further explained in the paper of lenhard and parker 1992 as follows the use of apparent saturation has physical merit in that it indexes locations of interfaces which separate the wetting phase from the continuous nonwetting phase employing apparent saturations to model hysteretic permeability saturation capillary head relations that include effects of nonwetting fluid entrapment is thus physically more reasonable than employing effective or actual saturations in order to consider the consistency of this reasoning in the framework of the apparent saturation model of parker and lenhard 1987 we can track two primary wetting processes r 1 r 0 and q 1 q 0 fig 1 b point r 1 with water content θmd ψ1 uniquely corresponds to a certain particular configuration of the water continuous air interface which encompasses water phase together with entrapped bubbles of air imagine we replace air in those bubbles with water such replacement should not cause any change in the spatial configuration of water continuous air interface and therefore the capillary head would not be changed remaining as ψ1 the obtained soil water state is described by point q 1 on the first drainage fig 1 b with water content being θfd ψ1 suppose we increase the capillary head from ψ1 to some value ψ ψ ψ1 starting simultaneously from both points r 1 and q 1 reasoning from a deterministic viewpoint with regard to the water retention phenomenon one should state that in both primary wetting processes identical spatial configurations of water continuous air interface configurations should be attained at each ψ consequently transition from ψ1 to ψ along these two processes should be accompanied by the same increase in effective saturation or water content as well as by the same increase of amount of the entrapped air this implies that the above two primary wetting processes should be described by parallel effective saturation or water content capillary head curves s ψ or θ ψ this property of parallelism between such corresponding primary wetting curves as well as between the subsequent drying curves departing from points r 0 and q 0 shown in fig 1 b is substantiated in mualem s 1974 study see eqs 29 and 30 there furthermore based on mualem s 1974 model this conclusion can readily be extended to all pairs of corresponding to each other higher order scanning curves i e two secondary drying curves starting from points r 2 and q 2 two tertiary wetting curves starting from points r 3 and q 3 etc fig 1 b although the described property of parallelism equally follows from both the domain theory of hysteresis of mualem 1974 and the above cited physical rationale underlying the usage of the apparent saturation concept as explicated by lenhard et al 1991 and lenhard and parker 1992 the actual fact is that between two primary wetting curves r 1 r 0 and q 1 q 0 fig 1 b predicted by the parker and lenhard 1987 model no parallelism can be manifested due to employing the land 1968 air entrapment formula to show this consider again two primary wetting processes departing at capillary head ψ1 from points r 1 and q 1 fig 1 b the differences between final and initial effective water saturations for each of these two processes are s u s md ψ 1 for r 1 r 0 and s l s fd ψ 1 for q 1 q 0 s l being the final effective water saturation in this process defined by land s formula land 1968 eq 2 13 1 1 s l 1 1 s fd ψ 1 s u 1 s u on the other hand using eqs 8 and 11 a we obtain another version of eq 12 12 a s md ψ 1 s u s fd ψ 1 then combining eqs 13 and 12 a we have 14 s l s fd ψ 1 s u s md ψ 1 1 s fd ψ 1 1 s u s fd ψ 1 1 this means that the two considered primary wetting processes predicted by the parker and lenhard 1987 model both featured by the same evolution of the water continuous air interface configuration and hence by the common apparent saturation curve are described by non parallel effective saturation curves displaying different increments of water content during the same changes of capillary head thus beyond the practical aspect of using an available computational tool i e land s 1968 formula 13 parker and lenhard 1987 introduced inconsistency into the apparent saturation model 2 4 formulation of closed form scaling equations for scanning curves consider the prediction of scanning curves based on the measured mdc or fdc and mwc for soil with small difference between air entry value and ψmax fig 1 in this case rescaling of the mdc or fdc for predicting the drying scans should not lead to significant predictive errors mualem and beriozkin 2009 denote the effective water content by θ θ θ r and let ri ψ i θi be a reversal point from the i 1 th to the ith order scanning curve in a sequence of wetting and drying scanning processes let ψ md θ be the inverse function for θ md ψ if r 1 is on the mdc fig 1 b then we define r 0 to be a starting point of the mdc i e r 0 ψmax θu analogously if r 1 is on the mwc fig 1 a then we define r 0 to be a starting point of the mwc i e r 0 ψmin 0 now according to eq 1 a an ith wetting scan θ w ψ i ψ is written as 15 θ w ψ i ψ θ i 1 θ i 1 θ i θ mw ψ i 1 θ mw ψ i θ mw ψ θ mw ψ i 1 eq 6 mualem and beriozkin 2009 where on the left hand side enderby s 1955 notation is used analogously according to eq 1 b a jth drying scan θ w ψ j ψ is written as 16 θ d ψ j ψ θ j 1 θ j θ j 1 θ md ψ j θ md ψ j 1 θ md ψ θ md ψ j 1 the scaling relationships of the apparent saturation model parker and lenhard 1987 eqs 12 13 lenhard and parker 1992 eqs 8 9 dane and lenhard 2004 eqs 22 23 are mathematically analogous to the above eqs 15 and 16 however instead of direct use of water contents θ or effective saturations s they are written in terms of apparent saturations s expressed through the van genuchten 1980 equation now we can write the closed form equations for wetting and drying scans denote for short θ mw ψ1 θ mw1 θ md ψ1 θ md1 θ fd ψ1 θ fd1 etc for a sequence of scanning curves departing from the mdc the primary wetting curve is 17 θ w ψ md θ u ψ ψ 1 θ u θ u θ md 1 θ u θ mw 1 θ u θ mw ψ the secondary drying curve is 18 θ d ψ md θ u ψ 2 ψ 1 ψ θ md 1 θ u θ md 1 θ md 2 θ md 1 θ mw 2 θ mw 1 θ u θ mw 1 θ md ψ θ md 1 and the tertiary wetting curve is 19 θ w ψ md θ u ψ 2 ψ ψ 1 ψ 3 θ u θ u θ md 1 θ u θ mw 1 θ u θ mw 2 θ md 2 θ md 3 θ mw 2 θ mw 3 θ mw 2 θ mw 1 θ md 2 θ md 1 θ mw 2 θ mw ψ with these closed form direct formulas there is no need to calculate all the foregoing scanning curves a sequence of scans departing from the fdc can readily be obtained from the above eqs 17 18 and 19 by parallel shift e g by adding to each of them constant number θ fd1 θ md1 for a sequence of scanning curves departing from the mwc the primary drying curve is 20 θ d ψ 1 ψ m i n ψ θ 1 θ md 1 θ md ψ the secondary wetting curve is 21 θ w ψ 1 ψ ψ m i n ψ 2 θ 1 θ 1 θ md 1 θ md 2 θ 1 θ mw 2 θ 1 θ mw ψ θ md 1 and the tertiary drying curve is 22 θ d ψ 1 ψ 3 ψ m i n ψ 2 ψ θ 1 θ md 1 θ md 2 θ md 1 θ md 2 θ mw 3 θ mw 2 θ 1 θ mw 2 θ md 3 θ md 2 θ md ψ θ md 2 the wetting scans of the fourth order are readily obtained by rescaling the mwc to interpolate between two reversal points with prescribed capillary heads ψ4 and ψ3 both of these points lie on the foregoing tertiary drying scan given by eq 22 analogously the drying scans of the fourth order are readily obtained by rescaling the mdc or fdc to interpolate between two reversal points with prescribed capillary heads ψ4 and ψ3 both of these points lie on the foregoing tertiary wetting scan given by eq 19 the scans of any higher order than the fourth would be described by rather cumbrous direct formulas and so should be calculated in a few stages 3 results and discussion in the following the linear law of the air entrapment in wetting processes and of the release of trapped air in drying processes as introduced and substantiated in the mualem 1974 model along with the scaling principle that follows inherently from the idem model are tested against experimental data shown in fig 4 fig 4 a b c and d shows that the fdc predicted from the measured mdc and vice versa by using eq 12 a match quite well the corresponding experimental curves for four porous media measured by poulovassilis 1970a and 1970b and wanna etiem 1982 the prediction of the fdc for oakley sand fig 4 e is obtained by rescaling the mdc within interval 27 11 96 84 of capillary heads cm h2o where the point with ψ 27 11 cm h2o on the mdc is identified as the air entry value there are significant deviations of the fdc predicted by rescaling the measured mdc from the measured fdc and of the mdc predicted by rescaling the measured fdc from the measured mdc it indicates that the linear law of air entrapment is approximative and it does not work well in this case alongside with that a more significant discrepancy is observed between the measured fdc fig 4 e solid line and the fdc calculated using the air entrapment data measured by stonestrom and rubin 1989 with the air pycnometer method along the mdc fig 4 e solid squares the linear law of air entrapment is further implemented with respect to the prediction of scanning curves inside of the main hysteresis loop as well as outside of it namely in the whole domain between the mwc and fdc according to the above consideration subsection 2 3 any two primary wetting curves one of which departs from the mdc at some capillary head and another from the fdc at the same capillary head must be parallel to each other as substantiated in the mualem 1974 model see eqs 29 and 30 there fig 5 shows three primary wetting curves starting from the mdc which are predicted by a parallel shift of the corresponding measured primary wetting curves starting from the fdc the predicted curves all pass through the measured points indicating excellent accuracy mualem and beriozkin 2009 have shown that the prediction of a wetting curve of any order according to the domain theory mualem 1974 1977 and 1984 mualem and dagan 1975 mualem and miller 1979 is equivalent to rescaling the mwc fig 6 shows three primary wetting curves departing from the mdc predicted by the scaling technique for the porous medium measured by poulovassilis 1970b while in the case shown in fig 6 there is some systematic overestimation of the water content by the predicted primary wetting curves a more acceptable prediction of the primary wetting curve is obtained for the mie andisol rudiyanto et al 2013 as presented in fig 8 b application of the scaling technique for predicting the drying scans has become repeatedly used empirical method scott et al 1983 lenhard and parker 1987 huang et al 2005 and others in this case unlike the case of predicting the wetting scans application of the scaling technique for predicting the drying scans does not follow rigorously from the domain theory nevertheless the drying scans predicted by the scaling technique and those predicted by the independent domain version of the domain theory e g by the model of mualem 1974 do not differ significantly from each other fig 7 a b and fig 8 b therefore in the case of soils for which the independent domain concept is suitable with relatively low absolute value of air entry the use of the scaling approach for predicting the drying scans can hold acceptably as shown in fig 7 b caribou silt loam by topp 1971 and fig 8 b mie andisol by rudiyanto et al 2013 at the same time for the soils with a high degree of water blockage against air entry i e with relatively high absolute air entry value the use of the scaling would lead to very unsatisfactory results as shown in fig 7 a rubicon sandy loam by topp 1969 particularly with regard to the prediction of the primary scanning curves by scaling technique the knowledge of the water contents at both points of closure of the main loop is necessary because the point of closure with lower water content i e with more negative capillary head remains fixed under rescaling the mdc and the point of closure with higher water content remains fixed under rescaling the mwc this becomes important in cases when the water content at closure of the main hysteresis loop with more negative capillary head is higher than the residual water content a soil with dual porosity i e having bimodal pore size distribution can be one of such cases the prediction of the primary drying curve for the bimodal mie andisol fig 8 b is based on the lower closure point θ 0 329 cm3 cm3 ψ 19 0 cm h2o as a fixed point of scaling in the case of the mie andisol of rudiyanto et al 2013 the scaling technique was applied directly to the data points of the main processes to describe the primary wetting and drying processes after which the obtained points were fitted by an approximating polynomial of the sixth degree dotted line for the primary wetting and dashed line for the primary drying fig 8 b the data points of the main processes were fitted by an approximating polynomial of the sixth degree as well solid lines fig 8 b 4 summary and conclusions a thorough theoretical analysis of the apparent saturation model suggested by parker and lenhard 1987 followed by lenhard et al 1991 lenhard and parker 1992 and dane and lenhard 2004 with respect to prediction of hysteresis in the two phase air water system reveals that it is based on invalid presumptions the operations of converting the measured water content mwc and mdc into the corresponding apparent saturation mwc and mdc rescaling the apparent saturation mwc or mdc to describe the appropriate apparent saturation scan subject to be rescaled back to predict the desired effective saturation or water content scan are superfluous these operations together including also intermediate transition from the water content mwc and mdc to the effective saturation mwc and mdc are all just the same as direct scaling of a desired wetting scanning curve from the measured mwc or direct scaling of a desired drying scanning curve from the mdc or fdc thus the intermediate operations associated with implementation of the apparent saturation concept are mutually cancelled and therefore of no theoretical merit instead the use of one of the six direct scaling relationships eqs 17 22 provides the prediction of a desired scan up to the third order the scans of the fourth order can readily be scaled from the corresponding main curve to interpolate between two reversal points with prescribed capillary heads ψ4 and ψ3 both of these points lie on the preceding tertiary scan described by either eq 22 for predicting drying scan or by eq 19 for predicting wetting scan the scans of the fifth and higher orders can be calculated in a few stages with additional use of eqs 15 and 16 another consequence of this study is that the air entrapment does not affect the predicting procedure of the hysteretic scans within the main hysteretic loop our analysis shows see eq 14 that the use of the entrapped air formula of land 1968 implies non parallelism of any two primary wetting curves one of which departs from the mdc at some capillary head ψ1 and another from the fdc at the same ψ1 this introduces inconsistency into the apparent saturation model itself because according to the primal physical rationale underlying the usage of the apparent saturation concept as argued in subsection 2 3 lenhard et al 1991 lenhard and parker 1992 such two primary wetting curves have to be parallel this drawback is avoided when the domain theory of hysteresis of mualem 1974 is applied as stated above application of scott et al s 1983 scaling model for predicting the drying scans may result in significant errors for soils with a high degree of blockage against air entry e g fig 6 rubicon sandy loam on the other hand the method of predicting the wetting scans based on rescaling the mwc to pass through appropriate reversal points is not just an empirical one but has a sound physical basis that is the domain theory of hysteresis mualem and beriozkin 2009 have shown that the method of rescaling the mwc is inherent to the similarity model of mualem 1974 in which all wetting curves are pairwise shape similar over a common domain of definition of each pair independently of their orders as shown herein subsection 2 4 it has the significant advantage of allowing an explicit formulation for the primary secondary and tertiary wetting scans directly from the given mwc finally the scaling transformation is independent of the kind of functional relationships used to describe the soil water retention curves thereby the scaling transformation is applicable not only for the van genuchten 1980 formula and can be performed pointwise for measured data as well 
836,this study theoretically analyzes the concept of apparent saturation hysteresis combined with the scott et al 1983 scaling approach as suggested by parker and lenhard 1987 to account for the effect of air entrapment and release on the soil water hysteresis we found that the theory of parker and lenhard 1987 is comprised of some mutually canceling mathematical operations and when cleared of the superfluous intermediate calculations their model reduces to the original scott et al s 1983 scaling method supplemented with the requirement of closure of scanning loops our analysis reveals that actually there is no effect of their technique of accounting for the entrapped air on the final prediction of the effective saturation or water content scanning curves our consideration indicates that the use of the land 1968 formula for assessing the amount of entrapped air is in disaccord with the apparent saturation concept as introduced by parker and lenhard 1987 in this paper a proper routine is suggested for predicting hysteretic scanning curves of any order given the two measured main curves in the complete hysteretic domain and some verification tests are carried out versus measured results accordingly explicit closed form formulae for direct prediction with no need of intermediate calculation of scanning curves up to the third order are derived to sustain our analysis keywords soil water hysteresis air entrapment hysteretic scanning curves scaling domain theory abbreviations fdc mdc and mwc first drying curve main drying curve and main wetting curve respectively 1 introduction a general overview of the different theories and models of soil water hysteresis is given in our previous studies mualem and beriozkin 2008 2009 these latter reviews are relevant to the present study as well so as to avoid repetition the adduced review refers only to studies related to the present subject matter dealing with the apparent saturation model based on the scott et al 1983 empirical scaling technique using a simplified two parametric form of the van genuchten 1980 formula scott et al 1983 suggested that two shape parameters of any primary drying curve be the same as those pertaining to the mdc similarly two shape parameters of any primary wetting curve are the same as those pertaining to the mwc kool and parker 1987 applied the scott et al 1983 model when using the three parameter form of the van genuchten 1980 formula and assuming the exponent of the capillary head ψ to be the same for wetting and drying curves however their model suffered from an artifact of a pumping effect producing unclosed scanning loops parker and lenhard 1987 followed by a series of publications lenhard 1992 lenhard and parker 1987 lenhard et al 1988 kaluarachchi and parker 1992 lenhard et al 1989 lenhard et al 1991 lenhard and parker 1992 dane and lenhard 2004 etc introduced the concept of apparent saturation defined as a sum of effective saturations of water and trapped air applying the scott et al 1983 scaling principle they proposed a hysteresis model based on the apparent saturation concept in this model the scaling technique was applied to the apparent saturation capillary head curves and air entrapment and release were described by a linear law as suggested in the mualem 1974 model this linear law is approximative with respect to the measured data of a number of soils and it is intended to give a reasonable description until developing a comprehensive conceptual model based on the water retention curve with possible accounting for the rate of process for estimation of the entrapped air content at completion points i e at ψ 0 of the primary wetting curves departing from the fdc parker and lenhard 1987 used the empirical formula of land 1968 they also enforced closure of scanning loops to eliminate the pumping effect of kool and parker 1987 dane and lenhard 2004 highly estimated the model of parker and lenhard 1987 and its air water version by lenhard et al 1991 noting the best available hysteresis model for air water relations is probably lenhard s however this conclusion is neither founded on sound theoretical analysis nor on any verification tests versus other models and experimental results our preliminary tests revealed that parker and lenhard s 1987 presumptions are not substantiated and according to their own apparent saturation model there should be no effect at all of the entrapped air on the final prediction of the effective saturation or water content within the main hysteretic loop these results cast doubts regarding their analysis and conclusions taking into account the multiple use of the apparent saturation concept in numerous publications including those concerned with relative permeability saturation relations e g lenhard and parker 1987 lenhard and parker 1992 dane and lenhard 2004 it is of theoretical and practical interest to thoroughly investigate this concept and derive physically and mathematically sound conclusions regarding its applicability while the linear law of air entrapment was used in several models e g mualem 1974 lenhard and parker 1987 lenhard et al 1989 observations were made regarding its common reliability particularly stonestrom and rubin 1989 obtained non linear water content dependence of the entrapped air content using an air pycnometer device they obtained reproducible hysteretic relationships between the water and entrapped air contents during the main wetting and drying processes however as we show hereafter fig 4 e a significant discrepancy is found between the measured fdc i e departing from the fully saturated state and that calculated using the air entrapment data obtained with the air pycnometer method this fact implies a necessity of physically based converting of the air pycnometer data the amount of entrapped air in wetting and drying processes has been linearly approximated in more recent studies e g finsterle et al 1998 dane and lenhard 2004 rudiyanto et al 2015 particularly the model of finsterle et al 1998 with built in air entrapment linear law was implemented in the inverse modeling module itough2 incorporated within the tough2 software package designed for simulating multiphase flow in fractured porous media in the past we have shown mualem and beriozkin 2009 that the similarity hypothesis of mualem 1974 implies shape similarity of all wetting curves regardless of their orders according to this similarity hypothesis the bivariate domain density distribution function f ψw ψd where ψw and ψd being the capillary head values of filling and emptying a domain respectively is represented as a product of two univariate functions l ψw and h ψd the feature of shape similarity of the wetting theoretical scans is valid not only when the independent domain model of mualem 1974 is applied but also holds valid when using the dependent domain models of mualem and dagan 1975 and mualem 1984 both of which account for the air entry blockage consequently all the wetting theoretical scans are described by the same unified normalized scaling equation however regarding the prediction of the drying scans from the given mdc mualem and beriozkin 2009 have shown that the use of scaling is not in accord with the domain theory and may yield large prediction errors for soils that exhibit significant blockage against air entry in the main drainage rudiyanto et al 2013 studied the hysteresis modeling with regard to the dual porosity soils and applied the kool and parker 1987 scaling model based on the van genuchten 1980 retention function to prediction of the wetting and drying scans rudiyanto et al 2013 suggested considering hysteresis only within the range of the macropore inter aggregate sub region whereas in the micropore intra aggregate sub region a non hysteretic retention relationship was assumed however if the measured hysteresis loop extends beyond the macropore sub region then ignoring the fact that in this case the most negative capillary head of this loop i e of the lower point of the loop closure is more negative than that of the inflection point between the two above sub regions will inevitably lead to errors in prediction by scaling method already in the stage of obtaining a primary drying curve in this case a predicted primary drying curve will intersect the mdc generally the lower point of the loop closure remains fixed under rescaling the mdc to primary drying curves thereby the adequate determination of the water content at this point is important since the study of topp et al 1967 it has been commonly acknowledged that the θ ψ relationships are determined not only by the wetting drying prehistory of the current state but also by the rate of change of the system capillary head in the modeling of transient dynamic flow events the use of water retention curves measured in the steady state conditions as well as of hysteresis models calibrated by these curves requires accounting for the rate of water saturation changes in time the necessary theoretical framework including non equilibrium hysteresis has been developed by hassanizadeh and grey 1993 beliaev and hassanizadeh 2001 and hassanizadeh et al 2002 who derived a rate dependent water saturation capillary head equation including a dynamic term with relaxation parameter τ these studies were followed by a series of contributions e g egorov et al 2003 nieber et al 2005 manthey 2006 sander et al 2008 milišić 2017 considering non equilibrium unsaturated flows a comprehensive data set of long term monitoring of hysteretic water content capillary head relationships measured under mainly transient non equilibrium conditions have been obtained in the study of hannes et al 2016 that has been carried out in the framework of the german soilcan lysimeter network tereno three hysteresis models parker and lenhard 1987 mualem 1984 and poulovassilis and kargas 2000 were examined on the subject of their ability to describe the observed behavior of different families of non equilibrium hysteresis curves the general regularity observed is that the faster the changes in ψ the more significant the difference between the measured transient θ ψ trajectories and the corresponding equilibrium ones and the faster the changes in ψ the more significant the difference between the measured transient θ ψ trajectories and the based on them model predicted hysteresis curves an additional finding of hannes et al 2016 is that different rates of wetting lead to different final amounts of entrapped air a forward looking approach to hysteresis modeling has been undertaken by lamorski et al 2017 who applied a machine learning based predictive approach for a representative amount of measured data they obtained the authors used the support vector machines algorithm for prediction of the mwc from the only measured mdc and obtained the better agreement between measured and estimated mwc than in the cases of using the one branch model of mualem 1977 and the one branch version of the kool and parker 1987 model the objectives of the present study are 1 to consider the role of the apparent saturation concept with regard to prediction of the soil water hysteresis and also address in this framework the consequences of applying the land 1968 formula of air entrapment 2 to check the mathematical and physical consistency of the predictive procedure as suggested by parker and lenhard 1987 and identify the relations of their model to the similarity approach of mualem 1974 and 3 to suggest a mathematically sound and experimentally verified predictive routine based on the domain theory with concise closed form formulae of the scanning curves in the complete hysteresis domain which also properly accounts for the air entrapment and release 2 theory the concept of apparent saturation defined as a sum of effective saturations of water and of trapped air was introduced by parker and lenhard 1987 in order to describe the hysteretic relationships by following the evolution of the wetting fluid continuous air interface their model incorporates a linear law of air entrapment in wetting processes and release of the entrapped air in drying processes except for the first drainage along with a scaling technique the predictive procedure suggested by parker and lenhard 1987 leads to prediction of a desired water content capillary head scan via a transitional prediction of its associated apparent saturation scan the section hereinafter systematically analyzes the nature of the operations constituting this predictive procedure as well as how the predicted scans are related to the corresponding scans derived by the mualem 1974 hysteresis model 2 1 definition and properties of scaling transformation generally one may consider the above operations to be mathematically equivalent to sequential scaling transformations to substantiate this statement let us relate to the basic definition of a scaling transformation let a xa ya and b xb yb be two points on the x y plane this pair of points uniquely define a scaling transformation q a b by which to any function f x with f xb f xa corresponds its image function q a b f that passes through points a and b and its derivative differs from df dx by a constant coefficient by this definition the scaling is a non linear transformation which has the form 1 a q a b f y b y b y a f x b f x a f x f x b or equivalently 1 b q a b f y a y b y a f x b f x a f x f x a thus if two functions f x and h x satisfy the relationship 2 h x λ f x over some interval x 1 x 2 with λ being some constant then transformation q a b where a x 1 h x 1 and b x 2 h x 2 implies h x q a b f now let q b c and q p r be two maps where xb xp xr xc then for any monotonous f x there exist images φ q b c f and g q p r φ according to 1 φ x and g x can be represented by φ x γ νf x and g x η λφ x where γ ν η and λ are certain constants which may be determined by 1 a or 1 b hence we have g x η λ γ ν f x η λ γ λ ν f x consequently g x λ ν f x therefore relation 2 is fulfilled for g x and f x and thus there exists a one step scaling transformation producing g x directly from f x and moreover it must be just q p r because g x passes through the points p and r namely 3 q p r q b c f q p r f accordingly relationship 3 can be further extended as follows let q a q q b c and q p r be maps where xa xb xp xr xc xq then their product is equivalent to the last one so that for any monotonous f x we have 3 a q p r q b c q a q f q p r f hereby an important property of scaling transformations is stated as follows the result of any series of sequential scaling transformations applied to a monotonous function f is equal to the last direct scaling transformation of the original function f 2 2 application of scaling transformation for describing air entrapment as defined by parker and lenhard 1987 the apparent saturation is a sum 5 s s s a t where 6 s θ θ r θ s θ r is the effective saturation of water and 7 s a t θ a t θ s θ r is the effective saturation of trapped air θ vw vt is the actual volumetric water content vt being a total volume θ a t v a t v t denotes the entrapped part of volumetric air content θ r and θ s are the residual and saturated water contents respectively fig 1 and vw and v a t are the volumes of water and entrapped air within the soil sample denote θ u to be the actual volumetric water content at the completion of the wetting process of an initially dry soil fig 1 when θ θ u and therefore s s u θ u θ r θ s θ r then quantity s a t takes on its maximum possible value θ s θ u θ s θ r in accord with these designations we denote s md ψ and s fd ψ to be the effective water saturation mdc and fdc respectively the difference s fd ψ s md ψ is the effective saturation of trapped air s a t during the main drainage i e 8 s md ψ s fd ψ obviously along the first drainage where s a t 0 there is no difference between the apparent and effective water saturations i e s fd ψ s fd ψ according to mualem s 1974 linear law of air entrapment mualem 1974 eqs 22 24 29 and 30 the amount of trapped air s a t in any process except the first drainage is described as 9 s a t 1 s pw f i n s pw f i n s fd ψ 1 δ s where s pw f i n denotes the effective saturation at the endpoint of the most recent primary wetting process departing from the first drainage at capillary head ψ1 δ s is the difference between the effective water saturation at a current state of the soil water air system s and that at the reversal from the first drainage to the most recent primary wetting process i e s fd ψ 1 in the limit case where the main wetting process plays a role of the most recent primary wetting process that branches from the first drainage i e s pw f i n s u s fd ψ 1 0 and δ s s eq 9 reduces as follows 9 a s a t 1 s u s u s this case relates to the mwc and mdc themselves as well as to any sequence of scans branching from the main boundary loop made up of the mwc and mdc denote δ s to be the difference between the apparent water saturation s at a current state of the soil water air system and that at the reversal from the first drainage to the most recent primary wetting process i e s fd ψ 1 ψ1 being the capillary head at the reversal substituting eq 5 into eq 9 leads to the following relation between s a t and δ s 10 s a t 1 s pw f i n 1 s fd ψ 1 δ s valid for any process except for the first drainage the obtained eq 10 like the above eq 9 reflects mualem s 1974 linear law of air entrapment conformably to a primary wetting process branching at ψ1 from the first drainage eq 10 reduces to eq 16 of parker and lenhard 1987 using eqs 9 and 10 the relation between δ s and δ s along any process except the first drainage takes the form 11 δ s ψ 1 s fd ψ 1 s pw f i n s fd ψ 1 δ s ψ when applied to the limit case in which the most recent primary wetting is the main wetting process i e s pw f i n s u s fd ψ 1 0 δ s s and δ s s the above eq 11 becomes as follows 11 a s s s u what means that functions s ψ and s ψ obey eq 2 consequently conversion of effective water saturation curve into the corresponding apparent water saturation curve and vice versa is equivalent to scaling transformation suppose we need to predict a water content primary wetting curve r 1 r 0 fig 1 b based on the input data of measured θ ψ points of the mdc mwc including θ u and θ r and the value of θs in this case the most recent primary wetting process departing from the first drainage is the main wetting process itself being the limit case according to the apparent saturation model of parker and lenhard 1987 the predictive procedure includes i conversion of the water content mwc and mdc i e θmw ψ and θmd ψ to the apparent saturation mwc and mdc i e s mw ψ and s md ψ respectively fig 2 this transition is realized by eqs 6 and 11 a ii obtainment of the apparent saturation primary wetting curve s pw ψ by rescaling the apparent saturation mwc s mw ψ to interpolate between two reversal points located on curve s md ψ at ψ ψ1 and ψ ψmax fig 2 this transition is realized by eq 1 a rewritten in the form 1 a s pw ψ 1 1 s md ψ 1 1 s mw ψ 1 1 s mw ψ iii conversion of the obtained apparent saturation primary wetting curve s pw ψ to the corresponding effective saturation primary wetting curve s pw ψ fig 2 followed by conversion of the latter to the desired water content primary wetting curve θpw ψ this transition is realized by eqs 5 10 and 6 where eq 10 reduces to s a t 1 s u s pw according to eqs 1 a b and 11 a the operations i and iii are tantamount to certain scaling transformations whereas the operation ii is by definition a scaling transformation then taking into account that intermediate transitions from θ to s and backwards are also equivalent to certain scaling transformations we eventually obtain a sequence of scaling transformations which in view of eq 3 a can be replaced by a single equivalent direct transformation of rescaling curve θmw ψ to interpolate between points r 1 and r 0 fig 1 b suppose now we need to predict a water content primary wetting curve q 1 q 0 fig 1 b based on the input data of measured water content fdc and mwc according to the parker and lenhard 1987 model the predictive procedure in this case includes i conversion of the measured water content mwc θmw ψ to the apparent saturation mwc s mw ψ fig 3 this transition is realized by eqs 6 and 11 a ii obtaining the apparent saturation primary wetting curve s pw ψ branching at ψ ψ1 from the effective saturation fdc s fd ψ fig 3 by rescaling the apparent saturation mwc s mw ψ to interpolate between the two reversal points located on curve s fd ψ at ψ ψ1 and ψ ψmax this transition is realized by eq 1 a iii conversion of the obtained apparent saturation primary wetting curve s pw ψ to the corresponding effective saturation primary wetting curve s pw ψ fig 3 followed by conversion of this s pw ψ to the desired water content primary wetting curve θpw ψ this transition is realized by eqs 5 10 and 6 while in eq 10 the difference s pw ψ s fd ψ 1 stands for δ s and s pw f i n is calculated by the land 1968 formula eq 12 hereinafter again all the above transitions are altogether tantamount to a single direct transformation of rescaling the measured water content mwc θmw ψ into the desired water content primary wetting curve θpw ψ that starts from point q 1 and ends at point q 0 fig 1 b in the model of parker and lenhard 1987 point q 0 is calculated by the land 1968 formula the problem of consistency of using land s formula jointly with applying the apparent saturation concept is considered in the following subsection from the viewpoint of the domain theory of mualem 1974 the two primary wetting processes r 1 r 0 and q 1 q 0 fig 1 b are parallel mualem 1974 eq 29 and therefore the water content at q 0 is θ u θfd ψ1 θmd ψ1 where according to 6 8 and 11 a 12 θ md ψ 1 θ r θ fd ψ 1 θ r θ u θ r θ s θ r the consideration similar to those conducted above with respect to the primary wetting processes r 1 r 0 and q 1 q 0 fig 1 b can be carried out analogously regarding the prediction of any sequential drying and wetting scanning curves it will lead to the same conclusion all scanning curves can be directly predicted from the measured θ ψ hysteresis boundary curves without the application of the apparent saturation concept since it leads to surplus operations that mutually cancel themselves and only create an erroneous impression of exploiting a real physical relationship 2 3 comparison of air entrapment relationships in the models of parker and lenhard 1987 and mualem 1974 to substantiate application of the apparent saturation approach lenhard et al 1991 reasoned to account for nonwetting fluid entrapment in s p relations we employ the concept of an apparent saturation to track movements of interfaces that separate wetting fluid from a continuous nonwetting phase the rationale behind the use of the apparent saturation approach is further explained in the paper of lenhard and parker 1992 as follows the use of apparent saturation has physical merit in that it indexes locations of interfaces which separate the wetting phase from the continuous nonwetting phase employing apparent saturations to model hysteretic permeability saturation capillary head relations that include effects of nonwetting fluid entrapment is thus physically more reasonable than employing effective or actual saturations in order to consider the consistency of this reasoning in the framework of the apparent saturation model of parker and lenhard 1987 we can track two primary wetting processes r 1 r 0 and q 1 q 0 fig 1 b point r 1 with water content θmd ψ1 uniquely corresponds to a certain particular configuration of the water continuous air interface which encompasses water phase together with entrapped bubbles of air imagine we replace air in those bubbles with water such replacement should not cause any change in the spatial configuration of water continuous air interface and therefore the capillary head would not be changed remaining as ψ1 the obtained soil water state is described by point q 1 on the first drainage fig 1 b with water content being θfd ψ1 suppose we increase the capillary head from ψ1 to some value ψ ψ ψ1 starting simultaneously from both points r 1 and q 1 reasoning from a deterministic viewpoint with regard to the water retention phenomenon one should state that in both primary wetting processes identical spatial configurations of water continuous air interface configurations should be attained at each ψ consequently transition from ψ1 to ψ along these two processes should be accompanied by the same increase in effective saturation or water content as well as by the same increase of amount of the entrapped air this implies that the above two primary wetting processes should be described by parallel effective saturation or water content capillary head curves s ψ or θ ψ this property of parallelism between such corresponding primary wetting curves as well as between the subsequent drying curves departing from points r 0 and q 0 shown in fig 1 b is substantiated in mualem s 1974 study see eqs 29 and 30 there furthermore based on mualem s 1974 model this conclusion can readily be extended to all pairs of corresponding to each other higher order scanning curves i e two secondary drying curves starting from points r 2 and q 2 two tertiary wetting curves starting from points r 3 and q 3 etc fig 1 b although the described property of parallelism equally follows from both the domain theory of hysteresis of mualem 1974 and the above cited physical rationale underlying the usage of the apparent saturation concept as explicated by lenhard et al 1991 and lenhard and parker 1992 the actual fact is that between two primary wetting curves r 1 r 0 and q 1 q 0 fig 1 b predicted by the parker and lenhard 1987 model no parallelism can be manifested due to employing the land 1968 air entrapment formula to show this consider again two primary wetting processes departing at capillary head ψ1 from points r 1 and q 1 fig 1 b the differences between final and initial effective water saturations for each of these two processes are s u s md ψ 1 for r 1 r 0 and s l s fd ψ 1 for q 1 q 0 s l being the final effective water saturation in this process defined by land s formula land 1968 eq 2 13 1 1 s l 1 1 s fd ψ 1 s u 1 s u on the other hand using eqs 8 and 11 a we obtain another version of eq 12 12 a s md ψ 1 s u s fd ψ 1 then combining eqs 13 and 12 a we have 14 s l s fd ψ 1 s u s md ψ 1 1 s fd ψ 1 1 s u s fd ψ 1 1 this means that the two considered primary wetting processes predicted by the parker and lenhard 1987 model both featured by the same evolution of the water continuous air interface configuration and hence by the common apparent saturation curve are described by non parallel effective saturation curves displaying different increments of water content during the same changes of capillary head thus beyond the practical aspect of using an available computational tool i e land s 1968 formula 13 parker and lenhard 1987 introduced inconsistency into the apparent saturation model 2 4 formulation of closed form scaling equations for scanning curves consider the prediction of scanning curves based on the measured mdc or fdc and mwc for soil with small difference between air entry value and ψmax fig 1 in this case rescaling of the mdc or fdc for predicting the drying scans should not lead to significant predictive errors mualem and beriozkin 2009 denote the effective water content by θ θ θ r and let ri ψ i θi be a reversal point from the i 1 th to the ith order scanning curve in a sequence of wetting and drying scanning processes let ψ md θ be the inverse function for θ md ψ if r 1 is on the mdc fig 1 b then we define r 0 to be a starting point of the mdc i e r 0 ψmax θu analogously if r 1 is on the mwc fig 1 a then we define r 0 to be a starting point of the mwc i e r 0 ψmin 0 now according to eq 1 a an ith wetting scan θ w ψ i ψ is written as 15 θ w ψ i ψ θ i 1 θ i 1 θ i θ mw ψ i 1 θ mw ψ i θ mw ψ θ mw ψ i 1 eq 6 mualem and beriozkin 2009 where on the left hand side enderby s 1955 notation is used analogously according to eq 1 b a jth drying scan θ w ψ j ψ is written as 16 θ d ψ j ψ θ j 1 θ j θ j 1 θ md ψ j θ md ψ j 1 θ md ψ θ md ψ j 1 the scaling relationships of the apparent saturation model parker and lenhard 1987 eqs 12 13 lenhard and parker 1992 eqs 8 9 dane and lenhard 2004 eqs 22 23 are mathematically analogous to the above eqs 15 and 16 however instead of direct use of water contents θ or effective saturations s they are written in terms of apparent saturations s expressed through the van genuchten 1980 equation now we can write the closed form equations for wetting and drying scans denote for short θ mw ψ1 θ mw1 θ md ψ1 θ md1 θ fd ψ1 θ fd1 etc for a sequence of scanning curves departing from the mdc the primary wetting curve is 17 θ w ψ md θ u ψ ψ 1 θ u θ u θ md 1 θ u θ mw 1 θ u θ mw ψ the secondary drying curve is 18 θ d ψ md θ u ψ 2 ψ 1 ψ θ md 1 θ u θ md 1 θ md 2 θ md 1 θ mw 2 θ mw 1 θ u θ mw 1 θ md ψ θ md 1 and the tertiary wetting curve is 19 θ w ψ md θ u ψ 2 ψ ψ 1 ψ 3 θ u θ u θ md 1 θ u θ mw 1 θ u θ mw 2 θ md 2 θ md 3 θ mw 2 θ mw 3 θ mw 2 θ mw 1 θ md 2 θ md 1 θ mw 2 θ mw ψ with these closed form direct formulas there is no need to calculate all the foregoing scanning curves a sequence of scans departing from the fdc can readily be obtained from the above eqs 17 18 and 19 by parallel shift e g by adding to each of them constant number θ fd1 θ md1 for a sequence of scanning curves departing from the mwc the primary drying curve is 20 θ d ψ 1 ψ m i n ψ θ 1 θ md 1 θ md ψ the secondary wetting curve is 21 θ w ψ 1 ψ ψ m i n ψ 2 θ 1 θ 1 θ md 1 θ md 2 θ 1 θ mw 2 θ 1 θ mw ψ θ md 1 and the tertiary drying curve is 22 θ d ψ 1 ψ 3 ψ m i n ψ 2 ψ θ 1 θ md 1 θ md 2 θ md 1 θ md 2 θ mw 3 θ mw 2 θ 1 θ mw 2 θ md 3 θ md 2 θ md ψ θ md 2 the wetting scans of the fourth order are readily obtained by rescaling the mwc to interpolate between two reversal points with prescribed capillary heads ψ4 and ψ3 both of these points lie on the foregoing tertiary drying scan given by eq 22 analogously the drying scans of the fourth order are readily obtained by rescaling the mdc or fdc to interpolate between two reversal points with prescribed capillary heads ψ4 and ψ3 both of these points lie on the foregoing tertiary wetting scan given by eq 19 the scans of any higher order than the fourth would be described by rather cumbrous direct formulas and so should be calculated in a few stages 3 results and discussion in the following the linear law of the air entrapment in wetting processes and of the release of trapped air in drying processes as introduced and substantiated in the mualem 1974 model along with the scaling principle that follows inherently from the idem model are tested against experimental data shown in fig 4 fig 4 a b c and d shows that the fdc predicted from the measured mdc and vice versa by using eq 12 a match quite well the corresponding experimental curves for four porous media measured by poulovassilis 1970a and 1970b and wanna etiem 1982 the prediction of the fdc for oakley sand fig 4 e is obtained by rescaling the mdc within interval 27 11 96 84 of capillary heads cm h2o where the point with ψ 27 11 cm h2o on the mdc is identified as the air entry value there are significant deviations of the fdc predicted by rescaling the measured mdc from the measured fdc and of the mdc predicted by rescaling the measured fdc from the measured mdc it indicates that the linear law of air entrapment is approximative and it does not work well in this case alongside with that a more significant discrepancy is observed between the measured fdc fig 4 e solid line and the fdc calculated using the air entrapment data measured by stonestrom and rubin 1989 with the air pycnometer method along the mdc fig 4 e solid squares the linear law of air entrapment is further implemented with respect to the prediction of scanning curves inside of the main hysteresis loop as well as outside of it namely in the whole domain between the mwc and fdc according to the above consideration subsection 2 3 any two primary wetting curves one of which departs from the mdc at some capillary head and another from the fdc at the same capillary head must be parallel to each other as substantiated in the mualem 1974 model see eqs 29 and 30 there fig 5 shows three primary wetting curves starting from the mdc which are predicted by a parallel shift of the corresponding measured primary wetting curves starting from the fdc the predicted curves all pass through the measured points indicating excellent accuracy mualem and beriozkin 2009 have shown that the prediction of a wetting curve of any order according to the domain theory mualem 1974 1977 and 1984 mualem and dagan 1975 mualem and miller 1979 is equivalent to rescaling the mwc fig 6 shows three primary wetting curves departing from the mdc predicted by the scaling technique for the porous medium measured by poulovassilis 1970b while in the case shown in fig 6 there is some systematic overestimation of the water content by the predicted primary wetting curves a more acceptable prediction of the primary wetting curve is obtained for the mie andisol rudiyanto et al 2013 as presented in fig 8 b application of the scaling technique for predicting the drying scans has become repeatedly used empirical method scott et al 1983 lenhard and parker 1987 huang et al 2005 and others in this case unlike the case of predicting the wetting scans application of the scaling technique for predicting the drying scans does not follow rigorously from the domain theory nevertheless the drying scans predicted by the scaling technique and those predicted by the independent domain version of the domain theory e g by the model of mualem 1974 do not differ significantly from each other fig 7 a b and fig 8 b therefore in the case of soils for which the independent domain concept is suitable with relatively low absolute value of air entry the use of the scaling approach for predicting the drying scans can hold acceptably as shown in fig 7 b caribou silt loam by topp 1971 and fig 8 b mie andisol by rudiyanto et al 2013 at the same time for the soils with a high degree of water blockage against air entry i e with relatively high absolute air entry value the use of the scaling would lead to very unsatisfactory results as shown in fig 7 a rubicon sandy loam by topp 1969 particularly with regard to the prediction of the primary scanning curves by scaling technique the knowledge of the water contents at both points of closure of the main loop is necessary because the point of closure with lower water content i e with more negative capillary head remains fixed under rescaling the mdc and the point of closure with higher water content remains fixed under rescaling the mwc this becomes important in cases when the water content at closure of the main hysteresis loop with more negative capillary head is higher than the residual water content a soil with dual porosity i e having bimodal pore size distribution can be one of such cases the prediction of the primary drying curve for the bimodal mie andisol fig 8 b is based on the lower closure point θ 0 329 cm3 cm3 ψ 19 0 cm h2o as a fixed point of scaling in the case of the mie andisol of rudiyanto et al 2013 the scaling technique was applied directly to the data points of the main processes to describe the primary wetting and drying processes after which the obtained points were fitted by an approximating polynomial of the sixth degree dotted line for the primary wetting and dashed line for the primary drying fig 8 b the data points of the main processes were fitted by an approximating polynomial of the sixth degree as well solid lines fig 8 b 4 summary and conclusions a thorough theoretical analysis of the apparent saturation model suggested by parker and lenhard 1987 followed by lenhard et al 1991 lenhard and parker 1992 and dane and lenhard 2004 with respect to prediction of hysteresis in the two phase air water system reveals that it is based on invalid presumptions the operations of converting the measured water content mwc and mdc into the corresponding apparent saturation mwc and mdc rescaling the apparent saturation mwc or mdc to describe the appropriate apparent saturation scan subject to be rescaled back to predict the desired effective saturation or water content scan are superfluous these operations together including also intermediate transition from the water content mwc and mdc to the effective saturation mwc and mdc are all just the same as direct scaling of a desired wetting scanning curve from the measured mwc or direct scaling of a desired drying scanning curve from the mdc or fdc thus the intermediate operations associated with implementation of the apparent saturation concept are mutually cancelled and therefore of no theoretical merit instead the use of one of the six direct scaling relationships eqs 17 22 provides the prediction of a desired scan up to the third order the scans of the fourth order can readily be scaled from the corresponding main curve to interpolate between two reversal points with prescribed capillary heads ψ4 and ψ3 both of these points lie on the preceding tertiary scan described by either eq 22 for predicting drying scan or by eq 19 for predicting wetting scan the scans of the fifth and higher orders can be calculated in a few stages with additional use of eqs 15 and 16 another consequence of this study is that the air entrapment does not affect the predicting procedure of the hysteretic scans within the main hysteretic loop our analysis shows see eq 14 that the use of the entrapped air formula of land 1968 implies non parallelism of any two primary wetting curves one of which departs from the mdc at some capillary head ψ1 and another from the fdc at the same ψ1 this introduces inconsistency into the apparent saturation model itself because according to the primal physical rationale underlying the usage of the apparent saturation concept as argued in subsection 2 3 lenhard et al 1991 lenhard and parker 1992 such two primary wetting curves have to be parallel this drawback is avoided when the domain theory of hysteresis of mualem 1974 is applied as stated above application of scott et al s 1983 scaling model for predicting the drying scans may result in significant errors for soils with a high degree of blockage against air entry e g fig 6 rubicon sandy loam on the other hand the method of predicting the wetting scans based on rescaling the mwc to pass through appropriate reversal points is not just an empirical one but has a sound physical basis that is the domain theory of hysteresis mualem and beriozkin 2009 have shown that the method of rescaling the mwc is inherent to the similarity model of mualem 1974 in which all wetting curves are pairwise shape similar over a common domain of definition of each pair independently of their orders as shown herein subsection 2 4 it has the significant advantage of allowing an explicit formulation for the primary secondary and tertiary wetting scans directly from the given mwc finally the scaling transformation is independent of the kind of functional relationships used to describe the soil water retention curves thereby the scaling transformation is applicable not only for the van genuchten 1980 formula and can be performed pointwise for measured data as well 
837,the collapse process of a submerged granular column is strongly affected by its initial packing previous models for particle response time which is used to quantify the drag force between the solid and liquid phases in rheology based two phase flow models have difficulty in simulating the collapse process of granular columns with different initial concentrations initial packing conditions this study introduces a new model for particle response time which enables us to satisfactorily model the drag force between the two phases for a wide range of volume concentration the present model can give satisfactory results for both loose and dense packing conditions the numerical results have shown that i the initial packing affects the occurrence of contractancy diltancy behavior during the collapse process ii the general buoyancy and drag force are strongly affected by the initial packing through contractancy and diltancy and iii the general buoyancy and drag force can destabilize the granular material in loose packing condition but stabilize the granular material in dense packing condition the results have shown that the collapse process of a densely packed granular column is more sensitive to particle response time than that of a loosely packed granular column keywords numerical simulation two phase flow model particle response time granular flow initial packing condition landslide 1 introduction submarine landslides may occur on continental margins and slopes masson et al 2006 the ability to accurately simulate submarine landslides has practical importance because the sediment volumes released by submarine landslides may damage submarine cables and other subsea facilities hsu et al 2008 to understand the fundamental physics involved in landslides on land or submarine landslides the collapse of a granular column has often been used in the past as an idealized model for studying landslides in both laboratory experiments lajeunesse et al 2004 2005 lube et al 2005 2007 2004 and discrete element simulations girolami et al 2012 lacaze et al 2008 zenit 2005 most of these studies focused on dry granular columns in either two dimensional 2d lajeunesse et al 2005 lube et al 2005 or axisymmetric lajeunesse et al 2004 2005 lube et al 2007 2004 geometries for landslides on land which involve the collapse of dry granular materials the granular flow is a solid air two phase flow in the laboratory experiment using a 2d geometry the granular material is initially confined by two vertical walls the collapse of the granular column starts when the front wall is suddenly removed in the laboratory experiment using an axisymmetric geometry the granular material is initially inside a standing cylinder and the collapse of the granular column starts when the cylinder is suddenly lifted up after the wall or the cylinder has been removed the granular material spreads out and eventually stops moving due to internal friction because the density of the air is about 1000 times smaller than the density of the granular material e g sand the particle particle interaction dominates the dynamics of the dry granular flow and the flow dynamics and the deposit morphology depend primarily on the initial aspect ratio of the granular column lajeunesse et al 2004 2005 lube et al 2005 2007 2004 the normalized runout has been found to be a power law function of the initial aspect ratio lajeunesse et al 2004 2005 lube et al 2005 2007 2004 for a 2d geometry the deposit morphology can be either triangular shaped or trapezoid shaped depending on the initial aspect ratio lajeunesse et al 2004 other factors such as basal and internal frictions play insignificant roles lube et al 2004 for the collapse of a submerged granular column the granular flow is a solid liquid two phase flow because the densities of the liquid e g water and granular material have the same order of magnitude the particle fluid interaction provides additional forces important to the dynamics of the granular flow the drag force between the particle and the fluid decreases the kinetic energy of the granular flow and the lubrication force rognon et al 2011 reduces the chance of surface contact among particles these two types of forces have significant effects on the rheological characteristics of submerged granular flows especially when a granular flow involves small particles boyer et al 2011 cassar et al 2005 trulsson et al 2012 this is because the variation of the pore pressure in the granular flow can either stabilize or destabilize the granular material iverson et al 2000 unlike in dry and dense granular flows where the initial volume fraction plays no significant role ionescu et al 2015 lagrée et al 2011 lee et al 2015b the initial volume fraction is very important for the collapse of submerged granular columns this is because the dilatancy if initially over consolidated or contractancy if initially under consolidated behavior campbell 2006 can induce a relative motion between the solid grains and the liquid which in turn can induce an additional force on the granular skeleton and affect the flow pailha et al 2008 for the collapse of a submerged granular column a previous study using a 2d discrete element method topin et al 2012 suggests that the combined effect of the drag and lubrication may either reduce or enhance the runout distance experiments bonnet et al 2010 rondon et al 2011 have found that the initial volume fraction has a significant effect on the collapse of a submerged granular column for an initially loose packing the collapse process is rapid and the deposition layer is thin and long for an initially dense packing the collapse process is slow and the runout distance is much shorter rondon et al 2011 rondon et al 2011 conjecture that the dilatancy or contractancy behavior plays an important role in the collapse process the conjecture of rondon et al 2011 is described below 1 for an initially loose packing the granular column first contracts locally when the column starts to collapse at the initial stage a high pore pressure zone forms inside the column causing some pore water to flow out which helps to destabilize the granular material near the surface 2 for an initially dense packing the granular column will first dilate when the granular column starts to collapse at the initial stage a low pore pressure zone forms inside the granular column causing the water to be absorbed into the granular material which helps to stabilize and the granular material near the surface however this conjecture has not been proved by either experimental measurements or numerical simulations it is also not clear how the dilatancy and contractancy behaviors affect the interfacial forces many continuum models ionescu et al 2015 lagrée et al 2011 lee et al 2015b have been proposed in the past to simulate the collapse of incompressible dry granular columns because the dilatancy and contractancy behaviors affect the pore pressure in the collapse process of a submerged granular column the existing models developed for dry granular materials may not be suitable for submerged granular columns meruane et al 2010 first developed a two phase model to simulate the collapse of a submerged granular column which was later extended by meruane et al 2012 to deal with granular flows of binary mixtures of particles however meruane et al 2010 2012 used a combination of coulomb friction and the kinetic theory to develop their constitutive model for solid phase stress which needs to be modified for high concentration flows furthermore meruane et al 2010 2012 did not study the effect of the initial volume fraction on the collapse savage et al 2014 proposed a mixture model to study the collapse of a submerged granular column and examined both the initially loose and dense packings however their model neglects the pore pressure and the interaction between the particles and interstitial fluid and thus cannot reproduce the flow behavior observed in the collapse of submerged granular columns we are not aware of any models in the literature that are suitable for simulating the collapse of submerged granular columns with different initial packing conditions using a new rheological characteristics for high concentration flows lee et al 2016 extended the model of lee et al 2015b which was developed for the collapse of dry granular columns to study solid liquid two phase flows where the packing of the solid phase is not dense we have tried to use the model of lee et al 2016 to simulate the collapse of submerged granular columns but the results for the initially dense packing are not satisfactory when compared with the experimental results of rondon et al 2011 we conjectured that the parametrization of particle response time adopted in lee et al 2016 might have contributed to the difference between the numerical and experimental results this is because the particle response time τp which is used to parametrize the drag force between the two phases affects the dissipation of high low pore pressure built up in the granular material das 2013 the particle response time in lee et al 2016 was computed using the terminal velocity of a particle with a concentration correction proposed by richardson and zaki 1954 however this model may not be suitable in very high concentration regions where the contact among particles prevents the particles to freely fall we have also tried to compute the particle response time based on the pressure drop in steady flows through a homogenous porous media engelund 1953 however this model cannot yield satisfactory results for initially dense packing condition as well for reference the collapse processes simulated by using the models of richardson and zaki 1954 and engelund 1953 are included in appendix a for very high concentrations camenen 2005 further modified the concentration correction of richardson and zaki 1954 but the model of camenen 2005 is singular close to the maximum concentration at which contact networks form in this study we introduce a new model for particle response time to compute the drag force in submerged granular flows the new model combines the concentration correction of camenen 2005 to the terminal velocity with a limiter derived from the model of engelund 1953 one of the main objectives of this study is to find a new model for particle response time that can work for both initially loose and dense packing conditions the performance of the new model is evaluated by comparing the numerical results obtained by the new model and two existing models with the experimental results of rondon et al 2011 2 model descriptions for completeness and later discussion the governing equations and main constitutive models are briefly presented first followed by a description of three models for particle response time 2 1 governing equations for the two phase model used in this study the equations governing the fluid and solid phases are obtained by taking two averages over the microscopic governing equations for each phase hsu et al 2003 the resulting equations governing the conservation of mass and momentum are 1 ρ f 1 c t ρ f 1 c u f 0 2 ρ f 1 c u f t ρ f 1 c u f u f ρ f 1 c g 1 c p f 1 c t f c ρ s u f u s τ p ρ s τ p 1 c ν f t σ c c for the fluid phase and 3 ρ s c t ρ s c u s 0 4 ρ s c u s t ρ s c u s u s ρ s c g c p f c p s c t s c ρ s u f u s τ p ρ s τ p 1 c ν f t σ c c for the solid phase in these equations ρf and ρs are the mass densities of the fluid and solid phases respectively c is the solid volume friction i e concentration u f and u s are the mean velocities of the fluid and solid phases respectively g is the acceleration due to gravity pf is the total pressure of the fluid phase or pore pressure in this study ps is the pressure of the solid phase t f and t s are the stresses of the fluid and solid phases respectively τp is the particle response time used to parameterize the inter phase drag force νft is the eddy viscosity of the fluid phase σc is the schmidt number the term c p f in eq 4 is the pressure force of the fluid phase and referred to as general buoyancy in the literature meruane et al 2010 the two terms in the curly brackets in eqs 2 and 4 are related to the inter phase momentum transfer a k ϵ model with a low reynolds number correction is adopted to compute t f lee et al 2016 the turbulence kinetic energy k and its dissipation rate ϵ are governed by 5 ρ f 1 c k t ρ f 1 c u f k 1 c t f u f ρ f 1 c ϵ ρ f ν ft σ ϵ 1 c k ρ s ρ f 1 c ν ft σ c c g 2 ρ s c 1 α k τ p and 6 ρ f 1 c ϵ t ρ f 1 c u f ϵ ϵ k c ϵ 1 f 1 1 c t f u f c ϵ 2 f 2 ρ f 1 c ϵ ρ f ν ft σ ϵ 1 c ϵ ϵ k c ϵ 3 ρ s ρ f 1 c ν ft σ c c g 2 ρ s c 1 α k τ p where c ϵ1 c ϵ2 σ ϵ σk f 1 and f 2 are model parameters the adopted values for these parameters are the same as those in the k ϵ model for clear fluid under low reynolds number conditions launder and sharma 1974 the two terms inside the curly brackets in eqs 5 and 6 account for the turbulence modulation due to the presence of particles the first term is associated with the general buoyancy and the second term is due to the correlation of the fluctuating velocities of solid sediment and fluid phases at present the value of c ϵ3 is not well understood and c ϵ 3 1 is adopted here as in the previous study lee et al 2016 a sensitivity analysis of the numerical results to c ϵ3 will be given later the parameter α reflects the correlation between the sediment and fluid turbulent motions and is given by 7 α 1 τ p min τ l τ c 1 with τ l 0 165 k ϵ being the time scale of the turbulent flow and τc the time scale of particle collisions lee et al 2016 strictly speaking the presence of sediment in turbulent flow may enhance for large particles or reduce for small particles the turbulence crowe 2000 but eqs 5 and 6 can only reflect the reduction of turbulence other turbulence models crowe 2000 lee et al 2015a include a term describing the enhancement of turbulence however we have found including that term in the present model may induce numerical instability 2 2 pressure and stress of the solid phase we follow lee et al 2016 to compute ps and t s in order to cover various sediment transport regimes lee et al 2016 combined the constitutive relations that are applicable to dilute flows dense flows and compact beds accordingly ps includes three components 8 p s p s t p s r p s e where pst accounts for the turbulent motion of sediment particles which is important for dilute flows psr reflects the rheological characteristics for dense flows and it includes the enduring contact particle inertial and fluid viscosity effects pse accounts for the elastic effect important when sediment is static in a compact bed the shear stress tensor for the sediment phase is computed by 9 t s 2 3 ρ s ν s u s 2 ρ s ν s d s where νs is the kinematic viscosity and d s the tensor of strain rate to consider both the turbulence behavior for dilute flows and the visco plastic behavior for dense flows and compact beds νs is divided into two components 10 ν s ν s t ν s v where νst and νsv represent the turbulence and visco plastic effects respectively an analysis of heavy and small particles in homogeneous steady turbulent flows hinze 1959 suggests that pst and νst can be expressed as eq 5 207 and eq 5 209 in hinze 1959 11 p s t 2 3 ρ s α k and 12 ν s t α ν f t for sediment in a compact bed the formula proposed by hsu et al 2004 is adopted to compute pse 13 p s e k max c c o 0 χ 1 sin max c c o c r c p c o 0 π π 2 where crcp random close packing fraction co k and χ are model parameters obviously k is associated with young s modulus and the other terms are related to material deformation for dense flows the visco plastic rheological characteristics highly depend on a combined dimensionless parameter i i v a i i 2 where iv is the viscous number ii is the inertial number and a is a constant trulsson et al 2012 the viscous number describes the ratio of the viscous stress to the quasi static shear stress associated with the weight resulting from the enduring contact and it is defined by i v 2 ρ f ν f d s c p s where νf the kinematic viscosity of the fluid ds the second invariant of the strain rate and d the particle diameter the inertial number defined by i i 2 d d s c p s ρ s describes the ratio of the inertial stress to the quasi static stress the relative importance of the inertial number to the viscous number in the dimensionless parameter i can be measured by the stokes number s t v i i 2 i ν some formulas have been proposed to describe c i and η i relationships where η t s p s with ts being the second invariant of t s trulsson et al 2012 proposed 14 η η 1 η 2 η 1 1 i o i where η 2 and io are constants and η 1 tan θ s with θs the angle of repose following the work of boyer et al 2011 lee et al 2016 assumed 15 c c c 1 b i 1 2 where cc is a critical concentration representing the maximum packing fraction of an homogeneously sheared assembly of frictional spheres boyer et al 2011 and b is a model parameter eq 15 implies that c must be smaller than cc at all time in two phase flow simulations which means that ci the volume fraction of the initial packing in the simulation must be smaller than cc in other words the granular material does not behave like a frictional flow before c is internally adjusted to a value slightly smaller than cc boyer et al 2011 have pointed out that cc significantly differs from the random close packing volume fraction and is not sensitive to the initial packing according to campbell 2006 cc can be either larger or smaller than that of the initial packing because of the way it is defined and measured based on eqs 14 and 15 lee et al 2016 suggested 16 p s r 2 b 2 c c c c 2 ρ f ν f 2 a ρ s d 2 d s d s where b is a constant and 17 ν s v p s r p s e η 2 ρ s d s eq 17 considers sediment in its static state as a very viscous fluid because eq 15 ensures that c is always smaller than cc there is no singularity in eq 16 caused by c c c in our two phase flow simulations 2 3 models for particle response time during the collapse process of a submerged granular column either a high or low pore pressure zone may occur inside the granular flow the duration of the presence of the high or low pore pressure is an important factor affecting the collapse process the drag force which is modeled through the particle response time τp may be responsible for the occurrence of the high or low pore pressure zone as in the consolidation of soil das 2013 when consolidating a soil a high fluid pressure zone occurs inside the soil the duration of the presence of the high pore pressure depends on the intrinsic permeability kp das 2013 and has an important influence on the consolidation because the particle response time τp can be related to the intrinsic permeability for dense two phase flows see appendix b we anticipate that computing τp accurately is crucial for liquid solid two phase flows three models for particle response time are examined in this study including a new model and two existing models the model of richardson and zaki 1954 and the model of engelund 1953 2 3 1 a model based on the sediment sedimentation in still water the first model uses the particle response time computed by the following expression pitman and le 2005 18 τ p ρ s ρ f ρ s w 1 c 2 g where w is the hindered velocity or sedimentation velocity of many particles the hindered velocity is smaller than the terminal velocity of a single particle ws due to the influence of sediment concentration richardson and zaki 1954 suggested 19 w w s 1 c n where n is given by 20 n 4 65 r e s 0 2 4 4 r e s 0 33 0 2 r e s 1 4 4 r e s 0 1 1 r e s 500 2 4 500 r e s with r e s w s d ν f the terminal velocity of a single particle is computed by 21 w s 4 d g 3 c d ρ s ρ f ρ f where cd is the drag coefficient for steady flows passing a small object chien and wan 1999 engelund 1953 for spheres white 2000 suggested 22 c d 24 r e p 6 1 r e p 0 4 where r e p u f u s d ν f eq 3 255 in white 2000 combing eqs 18 22 yields 23 τ p ρ s ρ f d 2 ν f 1 c n 2 18 4 5 1 r e p 0 3 r e p the model based on eq 23 with eq 20 is referred to as rz model in this study eq 22 can be replaced by other formulas if the particle is not spherical eq 19 is validated only for c 0 4 yin and koch 2007 when the concentration c is so high that contact networks form among particles w becomes zero when this happens eq 19 is not valid any more 2 3 2 a model based on the pressure drop in steady flows through a homogenous porous media the second model is based on the pressure drop in steady flows through a porous media according the study of engelund 1953 τp can be computed by 24 τ p ρ s d 2 ρ f ν f 1 a e c 2 b e r e p where ae and be are the model parameters depending on the composition of the solid phase see appendix b the parameter ae varies from 780 to 5000 or more and the parameter be varies from 1 8 to 3 6 or more burcharth and andersen 1995 higuera et al 2014 yin and koch 2007 the parameter ae is associated with kp see appendix b for d 2 10 4 m k p 10 10 10 11 m 2 das 2013 which gives ae 1 6 103 1 6 104 for c 0 5 in this study a e 5000 and b e 3 6 are taken the model based on eq 24 is referred to as engelund model in this study 2 3 3 a new model eq 19 is validated only for c 0 4 yin and koch 2007 to extend eq 19 to high concentration regions camenen 2005 modified eq 19 to 25 w w s 1 c n 1 max 1 c c m 0 c m where cm is the maximum concentration at which w 0 in this study c m c o is adopted because when c co contact networks can form in the granular material combining eqs 18 25 and 20 22 gives 26 τ p ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p we stress that c c m will lead to τ p 0 and thus an infinite drag force physically when the volumn concentration is greater than some critical value say cr eq 25 ceases to be valid and the engelund model should be used to avoid unnaturally large drag force between the two phases we propose the following model for particle response time 27 τ p ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p for c c r ρ s d 2 ρ f ν f 1 a e c 2 b e r e p for c c r where cr is the concentration at the intercept point of eqs 24 and 26 the transition from eq 26 to eq 24 is continuous at the intercept point where c c r the concentration at the point joining the two models cr is problem dependent and can be found in principle by solving the following equation 28 1 c r n 3 max 1 c r c m 0 c m 18 4 5 1 r e p 0 3 r e p 1 a e c r 2 b e r e p for given values of ae and be eq 28 implicitly defines cr as a function of rep we remark that it is not numerically efficient to solve eq 28 at every grid point for each time step in appendix c we present a more computationally efficient method to implement the new model in openfoam 2 3 4 model comparison the dimensionless particle response times τ p τ p ν f ρ f d 2 ρ s predicted by the aforementioned three models are presented in fig 1 as a function of either c or rep when using the rz and new models n 4 65 is adopted the collapse of a submerged granular column involves high concentration flows where rep is very small because the relative velocity is small in high concentration regions generally speaking τ p computed using these three models for low rep are not very sensitive to rep for a fixed c but decrease with increasing with c for a fixed rep when c 0 the new model reduces to the rz model for 0 064 c 0 54 the rz model gives the largest τ p but the engelund model gives the smallest one when c 0 064 when c 0 064 the particle response time given by the engelund model is much larger than those given by the other two models for example at c 0 01 the engelund model gives τ p 1 16 but the other two models give τ p 0 045 the particle response time τ p computed by the new model drops dramatically from that by rz model when c is close to 0 55 2 4 boundary conditions in the simulation of the sediment phase the no slip boundary condition was imposed at the bed but a slip boundary condition was imposed on the two lateral walls in the simulation of the fluid phase the wall function method was imposed at the bed and on the two lateral walls in view of the small size and the deep submergence of the granular column the small vertical displacement of the fluid surface was ignored and a rigid lid approximation was adopted in the simulation 2 5 summary of model parameters the rz and engelund models for particle response time have been implemented in the rheology based two phase model developed by lee et al 2016 which provides guidelines for choosing some of model parameters the model parameters used in this study are summarized in table 1 except for the parameters related to the low reynolds k ϵ model we treat the parameter b as a tuning parameter in this study other parameters are treated as non tuning parameters whose values are derived from the values reported in the literature for the non tuning parameters a 0 11 is suggested by lee et al 2016 for the sediment transport in the sheet flow condition i o 0 1 is obtained numerically by trulsson et al 2012 cassar et al 2005 suggested η 1 0 43 and η 2 0 82 for glass beads boyer et al 2011 suggested c c 0 585 c o 0 55 is the concentration for the loose packing granular column in the experiment of rondon et al 2011 lee et al 2015b suggested k 10 8 pa and χ 1 5 for numerical stability consideration in modeling collapse of a dry granular column the values of c ϵ3 and σc are the same as those used by lee et al 2016 the values of the two parameters are important for problems for sheet flows but not for the present problem for the tuning parameter b our numerical experiments found that the thickness of the flow front depended on the value of b and that b 2 could give better results 3 numerical schemes the equations in section 2 are solved by using openfoam an open source computational fluid dynamics cfd toolbox jasak 2009 when using a two phase model to simulate the collapse of a submerged granular column a challenge is to ensure the numerical stability when the concentration is high the pressure of the solid phase eqs 13 and 16 is sensitive to small changes in concentration a small fluctuation in concentration may lead to numerical instability the numerical instability issue has been addressed by lee et al 2016 who incorporated into the pimple scheme opencfd 2014 a perdition correction scheme proposed by lee et al 2015b the pimple scheme is a combination of the pressure implicit with splitting of operator scheme and the semi implicit method for pressure linked equations scheme in the numerical scheme of lee et al 2015b the discrete mass balance equation for the sediment phase eq 3 becomes an advection diffusion equation instead of an advection equation the diffusion behavior helps subdue the fluctuation in concentration and thus increases the numerical stability when the concentration is high 4 results and discussion the two phase model presented in the previous sections was used to simulate the collapse of a deeply submerged granular column as shown in fig 2 three cases were simulated and the detailed conditions are listed in table 2 which includes the properties of the fluid and sediment the initial height hi and the initial width li the new model for particle response time was used to compute τp for all the results presented in this section the results obtained by the other two models will be discussed together with the sensitivity analysis in section 4 6 case 1 simulates the collapse of a dry granular column cases 2 and 3 simulate the collapse of a granular column with an initially loose packing and an initially dense packing respectively these two cases have similar conditions except for the initial volume fraction ci case 2 has an initial volume fraction c i 0 553 while case 3 has an initial volume fraction ci 0 580 all three cases are used to verify the code and validate the present model case 1 is for the collapse of a dry granular column where the drag force is not important cases 2 and 3 are for the collapse of granular materials in a liquid where drag force is important in particular case 1 is used to show that the present model can automatically provide a near zero drag force for dry granular flows and thus reproduce the results given by the kinetic theory developed specifically for dry granular flows furthermore comparing the results of case 1 with those of cases 2 and 3 can illustrate the role of drag force in the collapse of granular columns the convergence tests were performed using case 2 a comparison of the flow front location obtained by using δ x 2 mm and δ x 1 mm showed that the difference was less than 0 1 therefore a grid size of δx 1 mm was used in all the simulations presented in this section for this grid size the relative variation of sediment mass was less than 10 5 during the entire collapse process in all numerical simulations courant friedrichs lewy cfl number did not exceed 0 1 in high concentration regions c 0 55 cfl number used in the simulations was smaller than 0 005 lee et al 2016 our simulations typically took a few hours for a physical time of 10 second using 8 threads on a workstation with two central processing units intel xeon r cpu e5 2660 v2 if high performance computing hpc systems are available the present model should be able to simulate large scale problems without the need to modify the code 1 1 we are in the process of implementing the model presented here on the tacc s stampede2 system managed by xsede towns et al 2014 in the experiment of rondon et al 2011 the collapse of the granular column was caused by suddenly lifting up the gate however the time series of the gate motion in the experiment were not provided in rondon et al 2011 the fast motion of the gate may result in a vertical fluid velocity on the interface between the granular material and the fluid in the numerical simulations the collapse of the granular column is caused by instantaneously removing the force holding the granular column in place it is expected that this vertical velocity has effects only at the early stage of the collapse process we have performed a simulation by imposing an initial upward velocity of 1 m s in the fluid near the column a comparison between the results obtained with and without this initial upward velocity has showed that the initial upward velocity has some influence at the initial stage of the collapse process t 0 1 s but the influence becomes insignificant at the later stage t 1 32 s we remark that the intermittency found in the experiment of rondon et al 2011 does not occur in our simulated collapse process regardless the presence of the vertical fluid velocity near the granular column 4 1 simulated collapse processes fig 3 shows the simulated collapse process of the dry granular column good agreement can be observed between the results of the present two phase model and those of lee et al 2015b which was developed specifically for dry granular columns using an extension of granular kinetic theory after the granular column collapses the dry granular material spreads through avalanching and eventually stops the collapse process is rapid and the final deposition profile is triangular shaped because the initial concentration has insignificant effect on the collapse process of dry granular columns lee et al 2015b only the results for the loose packing case are presented here fig 4 shows the simulated collapse process for the granular column with an initially loose packing case 2 and fig 5 for an initially dense packing case 3 the experimental results rondon et al 2011 are also included in these two figures for comparison comparing the collapse processes of the submerged columns figs 4 and 5 with that of the dray column fig 3 reveals that the collapse process deposition profile and the duration for the submerged granular columns significantly differ from those for the dry granular column unlike the dry granular column the collapse process of a submerged granular column is strongly affected by its initial packing the collapse process of the loose packing column case 2 is more rapid than that of the dense packing column the deposition profile for the loose packing is longer and thinner than that for the dense packing however the deposition profile for the dense packing is similar to that for the dry granular column the simulated collapse processes for both cases 2 and 3 are in general agreement with those observed in the experiment except for some minor discrepancies the computed runout distance slightly exceeds the measurement for the dense packing case the experiment video rondon et al 2011 showed that the collapse of the dense packing granular column was intermittent in the experiment i e the granular material flowed and stopped alternatively however the computed collapse process is continuous the simulation overestimates the runout distance for the dense packing case possibly because of the use of the wall function for the fluid phase the wall function method was proposed for clear water and no wall function applicable for a sediment fluid mixture is available in the literature another possible reason is the particle response time used in the simulation the hindered velocity changes sharply near c c o camenen 2005 so does the particle response time which makes the parameterization of particle response time near c c o a challenge strictly speaking the particle response time is also associated with the microscopic arrangements of particles yin and koch 2007 and affected by the presence of a wall as well chien and wan 1999 in our model for particle response time the effects of both the presence of wall and the microscopic arrangements are not considered we have also noted that the computed settling velocity near the flow front is slightly lower than that observed in the experiment video rondon et al 2011 fig 6 shows two examples of the computed velocity field of the sediment phase one for the loose packing case at t 0 66 s and the other for the dense packing case at t 3 s the loose packing granular material spreads much faster than the dense packing granular material does unlike in the loose packing case where the whole body of the granular mass is moving the region where the dense packing granular mass has noticeable motion is confined to the lower corner of the frontal region we remark that the values of ci used in the experiments were 0 55 for the loose packing and 0 6 for the dense packing the latter is smaller than the value of ci used in the simulation because c c 0 585 which is the maximum packing fraction of an homogeneously sheared assembly of frictional spheres boyer et al 2011 the granular material with the initially dense packing in the experiment will need to go through an internal adjustment under the shear action of the moving gate until the volume concentration reaches a value slightly smaller than cc before c cc is reached the granular material is not a frictional flow our choice of ci means that the internal adjustment process is not simulated by the two phase flow model 4 2 vertical distribution of fluid pressure to better show the deviation of the fluid pressure from the hydrostatic pressure vertical distributions of the fluid pressure at four locations are presented in fig 7 for t 1 32 s as shown in fig 4 at t 1 32 s the flow front defined by c 0 5 reaches the location of x 1 13 cm the flow front defined by c 0 1 reaches the location of x 1 20 cm at this time instant the flow front define by c 0 5 has not reached the location x 1 15 cm but the flow front defined by c 0 1 has passed this location referring to fig 7 the following conclusions can be drawn for the fluid pressure at these four locations 1 the fluid pressure at x 1 15 cm is very close to hydrostatic 2 an over pressure at the bed can be clearly observed at x 1 5 cm 7 5 cm and 10 0 cm and 3 a sub pressure at certain distance above the bed can be observed at x 1 7 5 cm or x 1 10 cm but not at x 1 5 0 cm which is too far from the flow front for the collapse of dry granular materials roche et al 2010 reported a sub pressure at the bed where the flow front passed which was followed by an over pressure at the bed we believe that the large viscosity of the fluid used in the experiment of rondon et al 2011 had prevented the sub pressure from penetrating down to the bed 4 3 contractancy and dilatancy shearing and volumetric strains are coupled during the deformation of a granular material it is well known in soil mechanics that shear deformations of sand often are accompanied by changes in volume loose sand has a tendency to contract to a smaller volume but densely packed sand cannot deform without expanding campbell 2006 the former phenomenon is called contractancy and the latter dilatancy accompanying with the change in volume of sand is a change in shear stress loose sand shows a gradual increase in shear stress while densely packed sand shows a decrease in shear stress both the loose and densely packed granular materials have a tendency to ultimately attain a critical state shear stress we have chosen to use the temporal variations of the maximum concentrations in both the initially loose and initially dense packing conditions to show the contractancy and dilatancy behaviors we have tried to show contractancy and dilatancy behaviors using the temporal variation of the total volume or mean concentration but the suspension of the granular material makes it difficult to define a clear interface between the fluid and granular material any interface defined based on a specified concentration will show a loss of granular mass a decrease increase of the maximum concentration indicates a dilatancy contractancy behavior it can be seen from fig 8 that the granular material with an initially loose packing undergoes a contracting process contractancy whiles the granular material with an initially dense packing goes through a dilatant process dilatancy our results shows that the rondon et al 2011 s conjecture about the dilatancy contractancy behavior is correct because increasing decreasing the volume concentration c increases decreases the pressure of the sediment phase ps the contractancy dilatancy found in both the experiment and simulation is related to the low high pressure of the sediment phase ps in the loosely densely packing column therefore how to compute ps is important for simulating the collapse of submerged granular columns in this study eqs 13 and 16 are used to compute ps eq 13 reflects the elastic effect and eq 16 reflects the rheological characteristic related to ds eq 13 says that a lower ci yields a lower pse if the force due to pse is not large enough to support the weight of solid phase the lower pse will induce contractancy on the other hand a higher ci will induce dilatancy eq 16 implies that a lower higher ci yields a lower higher for a certain ds however the above intuitive explanation based on eqs 13 and 16 does not consider the complex behavior of a granular flow near its static state due to the rearrangement of particles for the dense packing case it can be observed that the volume of the granular material slightly expands and cmax decreases from 0 58 to 0 565 within t 0 5 s this is due mainly to the large elastic energy in the granular material to check the influence of the expansion on the collapse process we have performed simulations using c i 0 565 0 58 and found that the results are not sensitive to changes in ci within this range 4 4 general buoyancy and drag force general buoyancy and drag are two important forces influencing the collapse process general buoyancy is directly related to the pressure of the fluid phase i e pore pressure and the drag force is directly related to the relative motion between the two phases referring to fig 4 a high pore pressure zone can be observed inside the granular flow with an initially loose packing and the high pore pressure dissipates with the spreading of the granular material however a low pore pressure zone can be observed inside the granular flow with an initially dense packing as shown in fig 5 and both the zone size and magnitude of the low pore pressure decrease gradually with the spreading of the granular material the gradient in the pore pressure field will produce a pressure force on the sediment phase called general buoyancy the dynamic components of the general buoyancy p f d where p f d p f ρ f g x 2 with g g are shown in fig 9 for cases 2 and 3 the rest part of the general buoyancy is always the constant ρfg for the loose packing case the general buoyancy points outward which helps to destabilize the granular mass for the dense packing the general buoyancy points inward which helps to stabilize the granular mass when contractancy dilatancy occurs the amount of fluid inside the granular material decreases increases resulting in a relative motion between the sediment and fluid phases near the surface of the granular mass fig 10 shows the relative velocity between the two phases for both the loose and dense packing cases although the relative velocities inside the granular material are very small the drag force can still be comparable to the dynamic component of the general buoyancy when the particle response time τp is small the drag forces for cases 2 and 3 are presented in fig 11 for the loose packing case the drag force points nearly vertically upward which helps to destabilize the granular mass for the dense packing case however the drag force points inward which helps to stabilize the granular mass it can be seen from figs 9 and 11 that the general buoyancy and the drag force have similar magnitudes and patterns except near the surface of the moving granular mass both the general buoyancy and drag force turn to destabilize the loosely packed granular mass but stabilize the densely packed granular mass 4 5 duration of the collapse process the durations of the collapse process for cases 2 and 3 are much longer than that for the dry column case 1 further comparing cases 2 and 3 shows that the duration for case 3 is one order of magnitude longer than that for case 2 for a deeply submerged granular column the drag force and the general buoyancy the third term on the right hand side of eq 4 both influence the collapse process the drag force dissipates the kinetic energy in the granular martial while the general buoyancy reduces the gravitational effect for the loose packing case case 2 the high pore pressure zone developed inside the granular material leads to an outward general buoyancy and the fluid flowing out near the surface yields another outward drag force acting on the solid phase both forces tend to further destabilize the loosely packed granular material leading to a rapid collapse process for the dense packing case case 3 however the low pore pressure zone developed inside the granular material yields an inward general buoyancy and the inward flow near the surface also yield an inward drag force both forces tend to stabilize the densely packed granular material leading to a slow collapse process 4 6 sensitivity analysis a sensitivity analysis has been performed to examine how sensitive the collapse process is to the key model parameters including the particle response times obtained using three models the ranges of these parameters used in the sensitivity analysis are summarized in table 3 and table 4 for the loose packing case the corresponding ranges of h and l at t 0 66 s are listed in table 3 for the dense packing case however only the ranges of l at t 9 s are listed in table 4 because the values of h for these cases are the same as those of hi except for the case where the engelund model is used to compute τp the ranges of the parameters tested in the sensitivity analysis are based on the following considerations 1 io pouliquen et al 2006 trulsson et al 2012 1 σc hsu et al 2003 lee et al 2015a and c ϵ3 lee et al 2016 cover the values reported in literature 2 the ranges of k χ and crcp are identical to those used in lee et al 2015b for simulating the collapse of a dry granular column 3 a varies from 0 01 to 1 in the literature chiodi et al 2014 lee et al 2016 trulsson et al 2012 we take a 0 0 5 for numerical stability considerations 4 the range of b reported in the literature varies from 0 75 to 1 boyer et al 2011 revil baudard and chauchat 2013 but b 1 3 was used in this sensitivity analysis because numerical instability occurred when b 1 5 we chose the ranges of cc and η 1 to cover the values reported in the literature cassar et al 2005 hanes and inman 1985 nielsen 1992 simons and albertson 1960 sperry and peirce 1995 i e c c 0 585 0 615 and η 1 0 43 0 73 which cover both glass beads and sand bear 1972 boyer et al 2011 6 since η 2 must be larger than or equal to η 1 η 2 0 43 0 82 were adopted in the analysis the three models rz engelund and the new model for particle response time τp were also compared in the sensitivity analysis it can be seen from table 3 that the parameters k and χ in eq 13 are the most important parameters affecting the collapse of a loose packing granular column the other two parameters b and cc in eq 16 are also important these four parameters k χ b and cc are needed to compute the pressure of the solid phase and thus the dilatancy or contractancy behavior relies on these four parameters in addition to the initial packing specified by ci furthermore these four parameters indirectly influence the friction in the solid phase the parameters η 1 η 2 and io in eq 14 and τp can also affect the collapse process but to a lesser extent it is a surprise to note that both σc and c ϵ3 have insignificant effects on the collapse process we remark that σc is associated with the turbulent dispersion of the sediment phase and c ϵ3 the turbulence modulation due to the presence of the sediment phase even though the turbulence modulation seems to have insignificant influence on the collapse process of a loose packing granular column studied here for other types of two phase flow problems such as sediment transport driven by turbulent flows σc and c ϵ3 are important for the collapse of a dense packing granular column table 4 shows that k χ b cc η 1 and η 2 are equally important however the particle response time τp becomes the most important parameter for the dense packing case to show this we compare the collapse processes simulated by using the rz fig a 1 model the engelund fig a 2 model and the new model fig 5 the collapse process given by the rz model is the most rapid one because the rz model gives the largest τp or the smallest drag force comparing the computed results obtained using the engelund model and the new model the new model shows a quicker deposition near flow front x 10 cm when t 9 s this is because the new model gives a smaller τp when c 0 54 a good agreement between the experimental results and the numerical results obtained by the new model can be observed in fig 5 which proves our hypothesis that modifying the rz model for high concentration and using a limiter for even higher concentration is important for correctly modeling the drag force in granular flows with an initially dense packing as mentioned in section 4 1 a high low pore pressure zone occurs in the granular flow with an initially dense loose packing and it strongly influences the collapse process fig 12 shows the variations of the minimum value of p f d for the dense packing case p m i n d and the maximum value for the loose packing case p m a x d it can be seen that p m i n d for the dense packing case is one order of magnitude larger than p m a x d for the loose packing case the model for τp has a significant effect on p f d for the dense packing case but has an insignificant effect for the loose packing case one explanation is that the dilatancy in dense packing case generates a relative velocity much larger than that generated by the contractancy in the loose packing case see fig 8 which makes the drag force in the dense packing granular material more much sensitive to the model for τp 5 conclusions using a continuum two phase flow approach this study introduced a new model for particle response time to simulate the collapse of a granular column deeply submerged in a fluid for both initially loose and dense packing conditions the two phase flow model with the new model for particle response time was able to simulate the collapse processes in general agreement with existing laboratory observations for both loose and dense packing conditions the numerical results showed that contractancy and dilatancy occur respectively for loose packing and dense packing during the collapse process validating rondon et al 2011 s conjecture about how initial volume fraction affect collapsing processes the general buoyancy and drag force were found to have similar directions and their magnitudes the contractancy induced a high pore pressure zone inside the loose packing granular material which generated an outward force on the sediment near the surface and helped to destabilize the granular mass the dilatancy induced a low pore pressure zone inside the dense packing granular material which produced an inward force on the sediment near the surface and helped to stabilize the granular mass a sensitivity analysis was performed by varying key model parameters involved in the computation of the sediment phase pressure because the contractancy or dilatancy of the granular material is related to the sediment phase pressure large relative velocities between the sediment and fluid phases were found near the surface of the moving granular mass for the dense packing condition it was concluded that the collapse process of a densely packed granular column was more sensitive to particle response time than that of a loosely packed granular column possible further research directions in two phase modeling of submarine granular flows include i plastic effect in the computation of the pressure of the solid phase ii near wall correction to the sedimentation velocity iii effect of sediment phase on the wall function for modeling fluid phase acknowledgements the material is based on work supported by the ministry of science and technology taiwan most 105 2218 e 032 001 and the national science foundation under grant no cbet 1706938 part of this work used the extreme science and engineering discovery environment xsede through a startup allocation oce170015 any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not necessarily reflect the views of the national science foundation this is soest contribution no 10286 appendix a the simulated collapse processes of granular columns by using particle response models of richardson and zaki 1954 and engelund 1953 fig a 1 shows the collapse processes of an initially dense packing column simulated by using the model of richardson and zaki 1954 referred to as rz in the figure fig a 2 shows the collapse processes of an initially dense packing column simulated by using the model of engelund 1953 referred to as engelund in the figure the measured results of rondon et al 2011 and the results obtained by using the new model are also superposed in these two figures for comparison as it can be seen from these two figures the agreement between the measurement and the numerical results obtained by using the rz and engelund models is not satisfactory the collapse process simulated by using the rz model is too fast granular suspension simulated by engelund model is too strong see the two lines indicating the concentrations of c 0 1 and c 0 5 the collapse processes of an initially loose packing column simulated by using the rz and engelund models are presented in figs a 3 and a 4 respectively the measured results of rondon et al 2011 and the results obtained by using the new model are also superposed in these two figures for comparison the agreement between the measurement and the numerical results obtained by using the rz model is reasonably well except that the rz model slightly over predict the height in the region close to x 0 the agreement between the measurement and the numerical results obtained by engelund model is less satisfactory the model over predicts the runout distance significantly appendix b a relationship between particle response time and permeability for a one dimensional problem of a steady flow through porous media the terms containing the stresses of fluid phase disappear and eq 2 reduces to b 1 p f x 1 c ρ s u 1 f 1 c τ p where the coordinate x 1 points in the direction of the flow for this problem forchheimer bear 1972 suggested b 2 p f x 1 a f ρ f 1 c u 1 f b f ρ f 1 c 2 u 1 f 2 where af and bf are two model parameters engelund 1953 suggested b 3 a f a e c 3 ν f 1 c 2 d 2 and b 4 b f b e c g 1 c 3 d where ae and be are two model parameters after comparing eqs b 1 and b 2 and using eqs b 3 and b 4 one can obtain b 5 τ p ρ s d 2 ρ f ν f 1 a e c 2 b e r e p according to darcys law for seepage bear 1972 the pressure gradient is b 6 p f x 1 ρ f ν f 1 c u 1 f k p where kp is the permeability when the flow is very slow eqs b 2 b 3 and b 6 suggest that b 7 a e d 2 k p 1 c 2 which means that the particle response time can be related to the permeability appendix c implementation of the new model for τp in openfoam for the problem studied here we have used a e 5000 and b e 3 6 and the dependence of cr on rep is weak the curve cr rep is shown in fig c 1 for 0 1 rep 10 the upper limit of rep is determined by assuming r e p r e s for the sand diameter used in our numerical simulations res 7 we remark that whenever there are two solutions for cr the one with the larger concentration should be taken there are two solutions when rep 8 2 but only one solution for rep 8 1 in any case the value of cr should be the one given by the upper curve which is not very sensitive to rep for the problem studied here referring to fig c 1 when c cr the engeland model should be used to calculate τp when 0 5 c cr the re model should be used to calculate τp when c 0 5 the re model should be used therefore in consideration of the computational efficiency and in view of fig c 1 the model described by eq 27 can be numerically implemented in openfoam by using following continuous piecewise function c 1 τ p ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p for c 0 5 max ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p ρ s d 2 ρ f ν f 1 a e c 2 b e r e p for c 0 5 which can avoid solving the equation for cr at every grid point for each time step and thus is more computationally efficient 
837,the collapse process of a submerged granular column is strongly affected by its initial packing previous models for particle response time which is used to quantify the drag force between the solid and liquid phases in rheology based two phase flow models have difficulty in simulating the collapse process of granular columns with different initial concentrations initial packing conditions this study introduces a new model for particle response time which enables us to satisfactorily model the drag force between the two phases for a wide range of volume concentration the present model can give satisfactory results for both loose and dense packing conditions the numerical results have shown that i the initial packing affects the occurrence of contractancy diltancy behavior during the collapse process ii the general buoyancy and drag force are strongly affected by the initial packing through contractancy and diltancy and iii the general buoyancy and drag force can destabilize the granular material in loose packing condition but stabilize the granular material in dense packing condition the results have shown that the collapse process of a densely packed granular column is more sensitive to particle response time than that of a loosely packed granular column keywords numerical simulation two phase flow model particle response time granular flow initial packing condition landslide 1 introduction submarine landslides may occur on continental margins and slopes masson et al 2006 the ability to accurately simulate submarine landslides has practical importance because the sediment volumes released by submarine landslides may damage submarine cables and other subsea facilities hsu et al 2008 to understand the fundamental physics involved in landslides on land or submarine landslides the collapse of a granular column has often been used in the past as an idealized model for studying landslides in both laboratory experiments lajeunesse et al 2004 2005 lube et al 2005 2007 2004 and discrete element simulations girolami et al 2012 lacaze et al 2008 zenit 2005 most of these studies focused on dry granular columns in either two dimensional 2d lajeunesse et al 2005 lube et al 2005 or axisymmetric lajeunesse et al 2004 2005 lube et al 2007 2004 geometries for landslides on land which involve the collapse of dry granular materials the granular flow is a solid air two phase flow in the laboratory experiment using a 2d geometry the granular material is initially confined by two vertical walls the collapse of the granular column starts when the front wall is suddenly removed in the laboratory experiment using an axisymmetric geometry the granular material is initially inside a standing cylinder and the collapse of the granular column starts when the cylinder is suddenly lifted up after the wall or the cylinder has been removed the granular material spreads out and eventually stops moving due to internal friction because the density of the air is about 1000 times smaller than the density of the granular material e g sand the particle particle interaction dominates the dynamics of the dry granular flow and the flow dynamics and the deposit morphology depend primarily on the initial aspect ratio of the granular column lajeunesse et al 2004 2005 lube et al 2005 2007 2004 the normalized runout has been found to be a power law function of the initial aspect ratio lajeunesse et al 2004 2005 lube et al 2005 2007 2004 for a 2d geometry the deposit morphology can be either triangular shaped or trapezoid shaped depending on the initial aspect ratio lajeunesse et al 2004 other factors such as basal and internal frictions play insignificant roles lube et al 2004 for the collapse of a submerged granular column the granular flow is a solid liquid two phase flow because the densities of the liquid e g water and granular material have the same order of magnitude the particle fluid interaction provides additional forces important to the dynamics of the granular flow the drag force between the particle and the fluid decreases the kinetic energy of the granular flow and the lubrication force rognon et al 2011 reduces the chance of surface contact among particles these two types of forces have significant effects on the rheological characteristics of submerged granular flows especially when a granular flow involves small particles boyer et al 2011 cassar et al 2005 trulsson et al 2012 this is because the variation of the pore pressure in the granular flow can either stabilize or destabilize the granular material iverson et al 2000 unlike in dry and dense granular flows where the initial volume fraction plays no significant role ionescu et al 2015 lagrée et al 2011 lee et al 2015b the initial volume fraction is very important for the collapse of submerged granular columns this is because the dilatancy if initially over consolidated or contractancy if initially under consolidated behavior campbell 2006 can induce a relative motion between the solid grains and the liquid which in turn can induce an additional force on the granular skeleton and affect the flow pailha et al 2008 for the collapse of a submerged granular column a previous study using a 2d discrete element method topin et al 2012 suggests that the combined effect of the drag and lubrication may either reduce or enhance the runout distance experiments bonnet et al 2010 rondon et al 2011 have found that the initial volume fraction has a significant effect on the collapse of a submerged granular column for an initially loose packing the collapse process is rapid and the deposition layer is thin and long for an initially dense packing the collapse process is slow and the runout distance is much shorter rondon et al 2011 rondon et al 2011 conjecture that the dilatancy or contractancy behavior plays an important role in the collapse process the conjecture of rondon et al 2011 is described below 1 for an initially loose packing the granular column first contracts locally when the column starts to collapse at the initial stage a high pore pressure zone forms inside the column causing some pore water to flow out which helps to destabilize the granular material near the surface 2 for an initially dense packing the granular column will first dilate when the granular column starts to collapse at the initial stage a low pore pressure zone forms inside the granular column causing the water to be absorbed into the granular material which helps to stabilize and the granular material near the surface however this conjecture has not been proved by either experimental measurements or numerical simulations it is also not clear how the dilatancy and contractancy behaviors affect the interfacial forces many continuum models ionescu et al 2015 lagrée et al 2011 lee et al 2015b have been proposed in the past to simulate the collapse of incompressible dry granular columns because the dilatancy and contractancy behaviors affect the pore pressure in the collapse process of a submerged granular column the existing models developed for dry granular materials may not be suitable for submerged granular columns meruane et al 2010 first developed a two phase model to simulate the collapse of a submerged granular column which was later extended by meruane et al 2012 to deal with granular flows of binary mixtures of particles however meruane et al 2010 2012 used a combination of coulomb friction and the kinetic theory to develop their constitutive model for solid phase stress which needs to be modified for high concentration flows furthermore meruane et al 2010 2012 did not study the effect of the initial volume fraction on the collapse savage et al 2014 proposed a mixture model to study the collapse of a submerged granular column and examined both the initially loose and dense packings however their model neglects the pore pressure and the interaction between the particles and interstitial fluid and thus cannot reproduce the flow behavior observed in the collapse of submerged granular columns we are not aware of any models in the literature that are suitable for simulating the collapse of submerged granular columns with different initial packing conditions using a new rheological characteristics for high concentration flows lee et al 2016 extended the model of lee et al 2015b which was developed for the collapse of dry granular columns to study solid liquid two phase flows where the packing of the solid phase is not dense we have tried to use the model of lee et al 2016 to simulate the collapse of submerged granular columns but the results for the initially dense packing are not satisfactory when compared with the experimental results of rondon et al 2011 we conjectured that the parametrization of particle response time adopted in lee et al 2016 might have contributed to the difference between the numerical and experimental results this is because the particle response time τp which is used to parametrize the drag force between the two phases affects the dissipation of high low pore pressure built up in the granular material das 2013 the particle response time in lee et al 2016 was computed using the terminal velocity of a particle with a concentration correction proposed by richardson and zaki 1954 however this model may not be suitable in very high concentration regions where the contact among particles prevents the particles to freely fall we have also tried to compute the particle response time based on the pressure drop in steady flows through a homogenous porous media engelund 1953 however this model cannot yield satisfactory results for initially dense packing condition as well for reference the collapse processes simulated by using the models of richardson and zaki 1954 and engelund 1953 are included in appendix a for very high concentrations camenen 2005 further modified the concentration correction of richardson and zaki 1954 but the model of camenen 2005 is singular close to the maximum concentration at which contact networks form in this study we introduce a new model for particle response time to compute the drag force in submerged granular flows the new model combines the concentration correction of camenen 2005 to the terminal velocity with a limiter derived from the model of engelund 1953 one of the main objectives of this study is to find a new model for particle response time that can work for both initially loose and dense packing conditions the performance of the new model is evaluated by comparing the numerical results obtained by the new model and two existing models with the experimental results of rondon et al 2011 2 model descriptions for completeness and later discussion the governing equations and main constitutive models are briefly presented first followed by a description of three models for particle response time 2 1 governing equations for the two phase model used in this study the equations governing the fluid and solid phases are obtained by taking two averages over the microscopic governing equations for each phase hsu et al 2003 the resulting equations governing the conservation of mass and momentum are 1 ρ f 1 c t ρ f 1 c u f 0 2 ρ f 1 c u f t ρ f 1 c u f u f ρ f 1 c g 1 c p f 1 c t f c ρ s u f u s τ p ρ s τ p 1 c ν f t σ c c for the fluid phase and 3 ρ s c t ρ s c u s 0 4 ρ s c u s t ρ s c u s u s ρ s c g c p f c p s c t s c ρ s u f u s τ p ρ s τ p 1 c ν f t σ c c for the solid phase in these equations ρf and ρs are the mass densities of the fluid and solid phases respectively c is the solid volume friction i e concentration u f and u s are the mean velocities of the fluid and solid phases respectively g is the acceleration due to gravity pf is the total pressure of the fluid phase or pore pressure in this study ps is the pressure of the solid phase t f and t s are the stresses of the fluid and solid phases respectively τp is the particle response time used to parameterize the inter phase drag force νft is the eddy viscosity of the fluid phase σc is the schmidt number the term c p f in eq 4 is the pressure force of the fluid phase and referred to as general buoyancy in the literature meruane et al 2010 the two terms in the curly brackets in eqs 2 and 4 are related to the inter phase momentum transfer a k ϵ model with a low reynolds number correction is adopted to compute t f lee et al 2016 the turbulence kinetic energy k and its dissipation rate ϵ are governed by 5 ρ f 1 c k t ρ f 1 c u f k 1 c t f u f ρ f 1 c ϵ ρ f ν ft σ ϵ 1 c k ρ s ρ f 1 c ν ft σ c c g 2 ρ s c 1 α k τ p and 6 ρ f 1 c ϵ t ρ f 1 c u f ϵ ϵ k c ϵ 1 f 1 1 c t f u f c ϵ 2 f 2 ρ f 1 c ϵ ρ f ν ft σ ϵ 1 c ϵ ϵ k c ϵ 3 ρ s ρ f 1 c ν ft σ c c g 2 ρ s c 1 α k τ p where c ϵ1 c ϵ2 σ ϵ σk f 1 and f 2 are model parameters the adopted values for these parameters are the same as those in the k ϵ model for clear fluid under low reynolds number conditions launder and sharma 1974 the two terms inside the curly brackets in eqs 5 and 6 account for the turbulence modulation due to the presence of particles the first term is associated with the general buoyancy and the second term is due to the correlation of the fluctuating velocities of solid sediment and fluid phases at present the value of c ϵ3 is not well understood and c ϵ 3 1 is adopted here as in the previous study lee et al 2016 a sensitivity analysis of the numerical results to c ϵ3 will be given later the parameter α reflects the correlation between the sediment and fluid turbulent motions and is given by 7 α 1 τ p min τ l τ c 1 with τ l 0 165 k ϵ being the time scale of the turbulent flow and τc the time scale of particle collisions lee et al 2016 strictly speaking the presence of sediment in turbulent flow may enhance for large particles or reduce for small particles the turbulence crowe 2000 but eqs 5 and 6 can only reflect the reduction of turbulence other turbulence models crowe 2000 lee et al 2015a include a term describing the enhancement of turbulence however we have found including that term in the present model may induce numerical instability 2 2 pressure and stress of the solid phase we follow lee et al 2016 to compute ps and t s in order to cover various sediment transport regimes lee et al 2016 combined the constitutive relations that are applicable to dilute flows dense flows and compact beds accordingly ps includes three components 8 p s p s t p s r p s e where pst accounts for the turbulent motion of sediment particles which is important for dilute flows psr reflects the rheological characteristics for dense flows and it includes the enduring contact particle inertial and fluid viscosity effects pse accounts for the elastic effect important when sediment is static in a compact bed the shear stress tensor for the sediment phase is computed by 9 t s 2 3 ρ s ν s u s 2 ρ s ν s d s where νs is the kinematic viscosity and d s the tensor of strain rate to consider both the turbulence behavior for dilute flows and the visco plastic behavior for dense flows and compact beds νs is divided into two components 10 ν s ν s t ν s v where νst and νsv represent the turbulence and visco plastic effects respectively an analysis of heavy and small particles in homogeneous steady turbulent flows hinze 1959 suggests that pst and νst can be expressed as eq 5 207 and eq 5 209 in hinze 1959 11 p s t 2 3 ρ s α k and 12 ν s t α ν f t for sediment in a compact bed the formula proposed by hsu et al 2004 is adopted to compute pse 13 p s e k max c c o 0 χ 1 sin max c c o c r c p c o 0 π π 2 where crcp random close packing fraction co k and χ are model parameters obviously k is associated with young s modulus and the other terms are related to material deformation for dense flows the visco plastic rheological characteristics highly depend on a combined dimensionless parameter i i v a i i 2 where iv is the viscous number ii is the inertial number and a is a constant trulsson et al 2012 the viscous number describes the ratio of the viscous stress to the quasi static shear stress associated with the weight resulting from the enduring contact and it is defined by i v 2 ρ f ν f d s c p s where νf the kinematic viscosity of the fluid ds the second invariant of the strain rate and d the particle diameter the inertial number defined by i i 2 d d s c p s ρ s describes the ratio of the inertial stress to the quasi static stress the relative importance of the inertial number to the viscous number in the dimensionless parameter i can be measured by the stokes number s t v i i 2 i ν some formulas have been proposed to describe c i and η i relationships where η t s p s with ts being the second invariant of t s trulsson et al 2012 proposed 14 η η 1 η 2 η 1 1 i o i where η 2 and io are constants and η 1 tan θ s with θs the angle of repose following the work of boyer et al 2011 lee et al 2016 assumed 15 c c c 1 b i 1 2 where cc is a critical concentration representing the maximum packing fraction of an homogeneously sheared assembly of frictional spheres boyer et al 2011 and b is a model parameter eq 15 implies that c must be smaller than cc at all time in two phase flow simulations which means that ci the volume fraction of the initial packing in the simulation must be smaller than cc in other words the granular material does not behave like a frictional flow before c is internally adjusted to a value slightly smaller than cc boyer et al 2011 have pointed out that cc significantly differs from the random close packing volume fraction and is not sensitive to the initial packing according to campbell 2006 cc can be either larger or smaller than that of the initial packing because of the way it is defined and measured based on eqs 14 and 15 lee et al 2016 suggested 16 p s r 2 b 2 c c c c 2 ρ f ν f 2 a ρ s d 2 d s d s where b is a constant and 17 ν s v p s r p s e η 2 ρ s d s eq 17 considers sediment in its static state as a very viscous fluid because eq 15 ensures that c is always smaller than cc there is no singularity in eq 16 caused by c c c in our two phase flow simulations 2 3 models for particle response time during the collapse process of a submerged granular column either a high or low pore pressure zone may occur inside the granular flow the duration of the presence of the high or low pore pressure is an important factor affecting the collapse process the drag force which is modeled through the particle response time τp may be responsible for the occurrence of the high or low pore pressure zone as in the consolidation of soil das 2013 when consolidating a soil a high fluid pressure zone occurs inside the soil the duration of the presence of the high pore pressure depends on the intrinsic permeability kp das 2013 and has an important influence on the consolidation because the particle response time τp can be related to the intrinsic permeability for dense two phase flows see appendix b we anticipate that computing τp accurately is crucial for liquid solid two phase flows three models for particle response time are examined in this study including a new model and two existing models the model of richardson and zaki 1954 and the model of engelund 1953 2 3 1 a model based on the sediment sedimentation in still water the first model uses the particle response time computed by the following expression pitman and le 2005 18 τ p ρ s ρ f ρ s w 1 c 2 g where w is the hindered velocity or sedimentation velocity of many particles the hindered velocity is smaller than the terminal velocity of a single particle ws due to the influence of sediment concentration richardson and zaki 1954 suggested 19 w w s 1 c n where n is given by 20 n 4 65 r e s 0 2 4 4 r e s 0 33 0 2 r e s 1 4 4 r e s 0 1 1 r e s 500 2 4 500 r e s with r e s w s d ν f the terminal velocity of a single particle is computed by 21 w s 4 d g 3 c d ρ s ρ f ρ f where cd is the drag coefficient for steady flows passing a small object chien and wan 1999 engelund 1953 for spheres white 2000 suggested 22 c d 24 r e p 6 1 r e p 0 4 where r e p u f u s d ν f eq 3 255 in white 2000 combing eqs 18 22 yields 23 τ p ρ s ρ f d 2 ν f 1 c n 2 18 4 5 1 r e p 0 3 r e p the model based on eq 23 with eq 20 is referred to as rz model in this study eq 22 can be replaced by other formulas if the particle is not spherical eq 19 is validated only for c 0 4 yin and koch 2007 when the concentration c is so high that contact networks form among particles w becomes zero when this happens eq 19 is not valid any more 2 3 2 a model based on the pressure drop in steady flows through a homogenous porous media the second model is based on the pressure drop in steady flows through a porous media according the study of engelund 1953 τp can be computed by 24 τ p ρ s d 2 ρ f ν f 1 a e c 2 b e r e p where ae and be are the model parameters depending on the composition of the solid phase see appendix b the parameter ae varies from 780 to 5000 or more and the parameter be varies from 1 8 to 3 6 or more burcharth and andersen 1995 higuera et al 2014 yin and koch 2007 the parameter ae is associated with kp see appendix b for d 2 10 4 m k p 10 10 10 11 m 2 das 2013 which gives ae 1 6 103 1 6 104 for c 0 5 in this study a e 5000 and b e 3 6 are taken the model based on eq 24 is referred to as engelund model in this study 2 3 3 a new model eq 19 is validated only for c 0 4 yin and koch 2007 to extend eq 19 to high concentration regions camenen 2005 modified eq 19 to 25 w w s 1 c n 1 max 1 c c m 0 c m where cm is the maximum concentration at which w 0 in this study c m c o is adopted because when c co contact networks can form in the granular material combining eqs 18 25 and 20 22 gives 26 τ p ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p we stress that c c m will lead to τ p 0 and thus an infinite drag force physically when the volumn concentration is greater than some critical value say cr eq 25 ceases to be valid and the engelund model should be used to avoid unnaturally large drag force between the two phases we propose the following model for particle response time 27 τ p ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p for c c r ρ s d 2 ρ f ν f 1 a e c 2 b e r e p for c c r where cr is the concentration at the intercept point of eqs 24 and 26 the transition from eq 26 to eq 24 is continuous at the intercept point where c c r the concentration at the point joining the two models cr is problem dependent and can be found in principle by solving the following equation 28 1 c r n 3 max 1 c r c m 0 c m 18 4 5 1 r e p 0 3 r e p 1 a e c r 2 b e r e p for given values of ae and be eq 28 implicitly defines cr as a function of rep we remark that it is not numerically efficient to solve eq 28 at every grid point for each time step in appendix c we present a more computationally efficient method to implement the new model in openfoam 2 3 4 model comparison the dimensionless particle response times τ p τ p ν f ρ f d 2 ρ s predicted by the aforementioned three models are presented in fig 1 as a function of either c or rep when using the rz and new models n 4 65 is adopted the collapse of a submerged granular column involves high concentration flows where rep is very small because the relative velocity is small in high concentration regions generally speaking τ p computed using these three models for low rep are not very sensitive to rep for a fixed c but decrease with increasing with c for a fixed rep when c 0 the new model reduces to the rz model for 0 064 c 0 54 the rz model gives the largest τ p but the engelund model gives the smallest one when c 0 064 when c 0 064 the particle response time given by the engelund model is much larger than those given by the other two models for example at c 0 01 the engelund model gives τ p 1 16 but the other two models give τ p 0 045 the particle response time τ p computed by the new model drops dramatically from that by rz model when c is close to 0 55 2 4 boundary conditions in the simulation of the sediment phase the no slip boundary condition was imposed at the bed but a slip boundary condition was imposed on the two lateral walls in the simulation of the fluid phase the wall function method was imposed at the bed and on the two lateral walls in view of the small size and the deep submergence of the granular column the small vertical displacement of the fluid surface was ignored and a rigid lid approximation was adopted in the simulation 2 5 summary of model parameters the rz and engelund models for particle response time have been implemented in the rheology based two phase model developed by lee et al 2016 which provides guidelines for choosing some of model parameters the model parameters used in this study are summarized in table 1 except for the parameters related to the low reynolds k ϵ model we treat the parameter b as a tuning parameter in this study other parameters are treated as non tuning parameters whose values are derived from the values reported in the literature for the non tuning parameters a 0 11 is suggested by lee et al 2016 for the sediment transport in the sheet flow condition i o 0 1 is obtained numerically by trulsson et al 2012 cassar et al 2005 suggested η 1 0 43 and η 2 0 82 for glass beads boyer et al 2011 suggested c c 0 585 c o 0 55 is the concentration for the loose packing granular column in the experiment of rondon et al 2011 lee et al 2015b suggested k 10 8 pa and χ 1 5 for numerical stability consideration in modeling collapse of a dry granular column the values of c ϵ3 and σc are the same as those used by lee et al 2016 the values of the two parameters are important for problems for sheet flows but not for the present problem for the tuning parameter b our numerical experiments found that the thickness of the flow front depended on the value of b and that b 2 could give better results 3 numerical schemes the equations in section 2 are solved by using openfoam an open source computational fluid dynamics cfd toolbox jasak 2009 when using a two phase model to simulate the collapse of a submerged granular column a challenge is to ensure the numerical stability when the concentration is high the pressure of the solid phase eqs 13 and 16 is sensitive to small changes in concentration a small fluctuation in concentration may lead to numerical instability the numerical instability issue has been addressed by lee et al 2016 who incorporated into the pimple scheme opencfd 2014 a perdition correction scheme proposed by lee et al 2015b the pimple scheme is a combination of the pressure implicit with splitting of operator scheme and the semi implicit method for pressure linked equations scheme in the numerical scheme of lee et al 2015b the discrete mass balance equation for the sediment phase eq 3 becomes an advection diffusion equation instead of an advection equation the diffusion behavior helps subdue the fluctuation in concentration and thus increases the numerical stability when the concentration is high 4 results and discussion the two phase model presented in the previous sections was used to simulate the collapse of a deeply submerged granular column as shown in fig 2 three cases were simulated and the detailed conditions are listed in table 2 which includes the properties of the fluid and sediment the initial height hi and the initial width li the new model for particle response time was used to compute τp for all the results presented in this section the results obtained by the other two models will be discussed together with the sensitivity analysis in section 4 6 case 1 simulates the collapse of a dry granular column cases 2 and 3 simulate the collapse of a granular column with an initially loose packing and an initially dense packing respectively these two cases have similar conditions except for the initial volume fraction ci case 2 has an initial volume fraction c i 0 553 while case 3 has an initial volume fraction ci 0 580 all three cases are used to verify the code and validate the present model case 1 is for the collapse of a dry granular column where the drag force is not important cases 2 and 3 are for the collapse of granular materials in a liquid where drag force is important in particular case 1 is used to show that the present model can automatically provide a near zero drag force for dry granular flows and thus reproduce the results given by the kinetic theory developed specifically for dry granular flows furthermore comparing the results of case 1 with those of cases 2 and 3 can illustrate the role of drag force in the collapse of granular columns the convergence tests were performed using case 2 a comparison of the flow front location obtained by using δ x 2 mm and δ x 1 mm showed that the difference was less than 0 1 therefore a grid size of δx 1 mm was used in all the simulations presented in this section for this grid size the relative variation of sediment mass was less than 10 5 during the entire collapse process in all numerical simulations courant friedrichs lewy cfl number did not exceed 0 1 in high concentration regions c 0 55 cfl number used in the simulations was smaller than 0 005 lee et al 2016 our simulations typically took a few hours for a physical time of 10 second using 8 threads on a workstation with two central processing units intel xeon r cpu e5 2660 v2 if high performance computing hpc systems are available the present model should be able to simulate large scale problems without the need to modify the code 1 1 we are in the process of implementing the model presented here on the tacc s stampede2 system managed by xsede towns et al 2014 in the experiment of rondon et al 2011 the collapse of the granular column was caused by suddenly lifting up the gate however the time series of the gate motion in the experiment were not provided in rondon et al 2011 the fast motion of the gate may result in a vertical fluid velocity on the interface between the granular material and the fluid in the numerical simulations the collapse of the granular column is caused by instantaneously removing the force holding the granular column in place it is expected that this vertical velocity has effects only at the early stage of the collapse process we have performed a simulation by imposing an initial upward velocity of 1 m s in the fluid near the column a comparison between the results obtained with and without this initial upward velocity has showed that the initial upward velocity has some influence at the initial stage of the collapse process t 0 1 s but the influence becomes insignificant at the later stage t 1 32 s we remark that the intermittency found in the experiment of rondon et al 2011 does not occur in our simulated collapse process regardless the presence of the vertical fluid velocity near the granular column 4 1 simulated collapse processes fig 3 shows the simulated collapse process of the dry granular column good agreement can be observed between the results of the present two phase model and those of lee et al 2015b which was developed specifically for dry granular columns using an extension of granular kinetic theory after the granular column collapses the dry granular material spreads through avalanching and eventually stops the collapse process is rapid and the final deposition profile is triangular shaped because the initial concentration has insignificant effect on the collapse process of dry granular columns lee et al 2015b only the results for the loose packing case are presented here fig 4 shows the simulated collapse process for the granular column with an initially loose packing case 2 and fig 5 for an initially dense packing case 3 the experimental results rondon et al 2011 are also included in these two figures for comparison comparing the collapse processes of the submerged columns figs 4 and 5 with that of the dray column fig 3 reveals that the collapse process deposition profile and the duration for the submerged granular columns significantly differ from those for the dry granular column unlike the dry granular column the collapse process of a submerged granular column is strongly affected by its initial packing the collapse process of the loose packing column case 2 is more rapid than that of the dense packing column the deposition profile for the loose packing is longer and thinner than that for the dense packing however the deposition profile for the dense packing is similar to that for the dry granular column the simulated collapse processes for both cases 2 and 3 are in general agreement with those observed in the experiment except for some minor discrepancies the computed runout distance slightly exceeds the measurement for the dense packing case the experiment video rondon et al 2011 showed that the collapse of the dense packing granular column was intermittent in the experiment i e the granular material flowed and stopped alternatively however the computed collapse process is continuous the simulation overestimates the runout distance for the dense packing case possibly because of the use of the wall function for the fluid phase the wall function method was proposed for clear water and no wall function applicable for a sediment fluid mixture is available in the literature another possible reason is the particle response time used in the simulation the hindered velocity changes sharply near c c o camenen 2005 so does the particle response time which makes the parameterization of particle response time near c c o a challenge strictly speaking the particle response time is also associated with the microscopic arrangements of particles yin and koch 2007 and affected by the presence of a wall as well chien and wan 1999 in our model for particle response time the effects of both the presence of wall and the microscopic arrangements are not considered we have also noted that the computed settling velocity near the flow front is slightly lower than that observed in the experiment video rondon et al 2011 fig 6 shows two examples of the computed velocity field of the sediment phase one for the loose packing case at t 0 66 s and the other for the dense packing case at t 3 s the loose packing granular material spreads much faster than the dense packing granular material does unlike in the loose packing case where the whole body of the granular mass is moving the region where the dense packing granular mass has noticeable motion is confined to the lower corner of the frontal region we remark that the values of ci used in the experiments were 0 55 for the loose packing and 0 6 for the dense packing the latter is smaller than the value of ci used in the simulation because c c 0 585 which is the maximum packing fraction of an homogeneously sheared assembly of frictional spheres boyer et al 2011 the granular material with the initially dense packing in the experiment will need to go through an internal adjustment under the shear action of the moving gate until the volume concentration reaches a value slightly smaller than cc before c cc is reached the granular material is not a frictional flow our choice of ci means that the internal adjustment process is not simulated by the two phase flow model 4 2 vertical distribution of fluid pressure to better show the deviation of the fluid pressure from the hydrostatic pressure vertical distributions of the fluid pressure at four locations are presented in fig 7 for t 1 32 s as shown in fig 4 at t 1 32 s the flow front defined by c 0 5 reaches the location of x 1 13 cm the flow front defined by c 0 1 reaches the location of x 1 20 cm at this time instant the flow front define by c 0 5 has not reached the location x 1 15 cm but the flow front defined by c 0 1 has passed this location referring to fig 7 the following conclusions can be drawn for the fluid pressure at these four locations 1 the fluid pressure at x 1 15 cm is very close to hydrostatic 2 an over pressure at the bed can be clearly observed at x 1 5 cm 7 5 cm and 10 0 cm and 3 a sub pressure at certain distance above the bed can be observed at x 1 7 5 cm or x 1 10 cm but not at x 1 5 0 cm which is too far from the flow front for the collapse of dry granular materials roche et al 2010 reported a sub pressure at the bed where the flow front passed which was followed by an over pressure at the bed we believe that the large viscosity of the fluid used in the experiment of rondon et al 2011 had prevented the sub pressure from penetrating down to the bed 4 3 contractancy and dilatancy shearing and volumetric strains are coupled during the deformation of a granular material it is well known in soil mechanics that shear deformations of sand often are accompanied by changes in volume loose sand has a tendency to contract to a smaller volume but densely packed sand cannot deform without expanding campbell 2006 the former phenomenon is called contractancy and the latter dilatancy accompanying with the change in volume of sand is a change in shear stress loose sand shows a gradual increase in shear stress while densely packed sand shows a decrease in shear stress both the loose and densely packed granular materials have a tendency to ultimately attain a critical state shear stress we have chosen to use the temporal variations of the maximum concentrations in both the initially loose and initially dense packing conditions to show the contractancy and dilatancy behaviors we have tried to show contractancy and dilatancy behaviors using the temporal variation of the total volume or mean concentration but the suspension of the granular material makes it difficult to define a clear interface between the fluid and granular material any interface defined based on a specified concentration will show a loss of granular mass a decrease increase of the maximum concentration indicates a dilatancy contractancy behavior it can be seen from fig 8 that the granular material with an initially loose packing undergoes a contracting process contractancy whiles the granular material with an initially dense packing goes through a dilatant process dilatancy our results shows that the rondon et al 2011 s conjecture about the dilatancy contractancy behavior is correct because increasing decreasing the volume concentration c increases decreases the pressure of the sediment phase ps the contractancy dilatancy found in both the experiment and simulation is related to the low high pressure of the sediment phase ps in the loosely densely packing column therefore how to compute ps is important for simulating the collapse of submerged granular columns in this study eqs 13 and 16 are used to compute ps eq 13 reflects the elastic effect and eq 16 reflects the rheological characteristic related to ds eq 13 says that a lower ci yields a lower pse if the force due to pse is not large enough to support the weight of solid phase the lower pse will induce contractancy on the other hand a higher ci will induce dilatancy eq 16 implies that a lower higher ci yields a lower higher for a certain ds however the above intuitive explanation based on eqs 13 and 16 does not consider the complex behavior of a granular flow near its static state due to the rearrangement of particles for the dense packing case it can be observed that the volume of the granular material slightly expands and cmax decreases from 0 58 to 0 565 within t 0 5 s this is due mainly to the large elastic energy in the granular material to check the influence of the expansion on the collapse process we have performed simulations using c i 0 565 0 58 and found that the results are not sensitive to changes in ci within this range 4 4 general buoyancy and drag force general buoyancy and drag are two important forces influencing the collapse process general buoyancy is directly related to the pressure of the fluid phase i e pore pressure and the drag force is directly related to the relative motion between the two phases referring to fig 4 a high pore pressure zone can be observed inside the granular flow with an initially loose packing and the high pore pressure dissipates with the spreading of the granular material however a low pore pressure zone can be observed inside the granular flow with an initially dense packing as shown in fig 5 and both the zone size and magnitude of the low pore pressure decrease gradually with the spreading of the granular material the gradient in the pore pressure field will produce a pressure force on the sediment phase called general buoyancy the dynamic components of the general buoyancy p f d where p f d p f ρ f g x 2 with g g are shown in fig 9 for cases 2 and 3 the rest part of the general buoyancy is always the constant ρfg for the loose packing case the general buoyancy points outward which helps to destabilize the granular mass for the dense packing the general buoyancy points inward which helps to stabilize the granular mass when contractancy dilatancy occurs the amount of fluid inside the granular material decreases increases resulting in a relative motion between the sediment and fluid phases near the surface of the granular mass fig 10 shows the relative velocity between the two phases for both the loose and dense packing cases although the relative velocities inside the granular material are very small the drag force can still be comparable to the dynamic component of the general buoyancy when the particle response time τp is small the drag forces for cases 2 and 3 are presented in fig 11 for the loose packing case the drag force points nearly vertically upward which helps to destabilize the granular mass for the dense packing case however the drag force points inward which helps to stabilize the granular mass it can be seen from figs 9 and 11 that the general buoyancy and the drag force have similar magnitudes and patterns except near the surface of the moving granular mass both the general buoyancy and drag force turn to destabilize the loosely packed granular mass but stabilize the densely packed granular mass 4 5 duration of the collapse process the durations of the collapse process for cases 2 and 3 are much longer than that for the dry column case 1 further comparing cases 2 and 3 shows that the duration for case 3 is one order of magnitude longer than that for case 2 for a deeply submerged granular column the drag force and the general buoyancy the third term on the right hand side of eq 4 both influence the collapse process the drag force dissipates the kinetic energy in the granular martial while the general buoyancy reduces the gravitational effect for the loose packing case case 2 the high pore pressure zone developed inside the granular material leads to an outward general buoyancy and the fluid flowing out near the surface yields another outward drag force acting on the solid phase both forces tend to further destabilize the loosely packed granular material leading to a rapid collapse process for the dense packing case case 3 however the low pore pressure zone developed inside the granular material yields an inward general buoyancy and the inward flow near the surface also yield an inward drag force both forces tend to stabilize the densely packed granular material leading to a slow collapse process 4 6 sensitivity analysis a sensitivity analysis has been performed to examine how sensitive the collapse process is to the key model parameters including the particle response times obtained using three models the ranges of these parameters used in the sensitivity analysis are summarized in table 3 and table 4 for the loose packing case the corresponding ranges of h and l at t 0 66 s are listed in table 3 for the dense packing case however only the ranges of l at t 9 s are listed in table 4 because the values of h for these cases are the same as those of hi except for the case where the engelund model is used to compute τp the ranges of the parameters tested in the sensitivity analysis are based on the following considerations 1 io pouliquen et al 2006 trulsson et al 2012 1 σc hsu et al 2003 lee et al 2015a and c ϵ3 lee et al 2016 cover the values reported in literature 2 the ranges of k χ and crcp are identical to those used in lee et al 2015b for simulating the collapse of a dry granular column 3 a varies from 0 01 to 1 in the literature chiodi et al 2014 lee et al 2016 trulsson et al 2012 we take a 0 0 5 for numerical stability considerations 4 the range of b reported in the literature varies from 0 75 to 1 boyer et al 2011 revil baudard and chauchat 2013 but b 1 3 was used in this sensitivity analysis because numerical instability occurred when b 1 5 we chose the ranges of cc and η 1 to cover the values reported in the literature cassar et al 2005 hanes and inman 1985 nielsen 1992 simons and albertson 1960 sperry and peirce 1995 i e c c 0 585 0 615 and η 1 0 43 0 73 which cover both glass beads and sand bear 1972 boyer et al 2011 6 since η 2 must be larger than or equal to η 1 η 2 0 43 0 82 were adopted in the analysis the three models rz engelund and the new model for particle response time τp were also compared in the sensitivity analysis it can be seen from table 3 that the parameters k and χ in eq 13 are the most important parameters affecting the collapse of a loose packing granular column the other two parameters b and cc in eq 16 are also important these four parameters k χ b and cc are needed to compute the pressure of the solid phase and thus the dilatancy or contractancy behavior relies on these four parameters in addition to the initial packing specified by ci furthermore these four parameters indirectly influence the friction in the solid phase the parameters η 1 η 2 and io in eq 14 and τp can also affect the collapse process but to a lesser extent it is a surprise to note that both σc and c ϵ3 have insignificant effects on the collapse process we remark that σc is associated with the turbulent dispersion of the sediment phase and c ϵ3 the turbulence modulation due to the presence of the sediment phase even though the turbulence modulation seems to have insignificant influence on the collapse process of a loose packing granular column studied here for other types of two phase flow problems such as sediment transport driven by turbulent flows σc and c ϵ3 are important for the collapse of a dense packing granular column table 4 shows that k χ b cc η 1 and η 2 are equally important however the particle response time τp becomes the most important parameter for the dense packing case to show this we compare the collapse processes simulated by using the rz fig a 1 model the engelund fig a 2 model and the new model fig 5 the collapse process given by the rz model is the most rapid one because the rz model gives the largest τp or the smallest drag force comparing the computed results obtained using the engelund model and the new model the new model shows a quicker deposition near flow front x 10 cm when t 9 s this is because the new model gives a smaller τp when c 0 54 a good agreement between the experimental results and the numerical results obtained by the new model can be observed in fig 5 which proves our hypothesis that modifying the rz model for high concentration and using a limiter for even higher concentration is important for correctly modeling the drag force in granular flows with an initially dense packing as mentioned in section 4 1 a high low pore pressure zone occurs in the granular flow with an initially dense loose packing and it strongly influences the collapse process fig 12 shows the variations of the minimum value of p f d for the dense packing case p m i n d and the maximum value for the loose packing case p m a x d it can be seen that p m i n d for the dense packing case is one order of magnitude larger than p m a x d for the loose packing case the model for τp has a significant effect on p f d for the dense packing case but has an insignificant effect for the loose packing case one explanation is that the dilatancy in dense packing case generates a relative velocity much larger than that generated by the contractancy in the loose packing case see fig 8 which makes the drag force in the dense packing granular material more much sensitive to the model for τp 5 conclusions using a continuum two phase flow approach this study introduced a new model for particle response time to simulate the collapse of a granular column deeply submerged in a fluid for both initially loose and dense packing conditions the two phase flow model with the new model for particle response time was able to simulate the collapse processes in general agreement with existing laboratory observations for both loose and dense packing conditions the numerical results showed that contractancy and dilatancy occur respectively for loose packing and dense packing during the collapse process validating rondon et al 2011 s conjecture about how initial volume fraction affect collapsing processes the general buoyancy and drag force were found to have similar directions and their magnitudes the contractancy induced a high pore pressure zone inside the loose packing granular material which generated an outward force on the sediment near the surface and helped to destabilize the granular mass the dilatancy induced a low pore pressure zone inside the dense packing granular material which produced an inward force on the sediment near the surface and helped to stabilize the granular mass a sensitivity analysis was performed by varying key model parameters involved in the computation of the sediment phase pressure because the contractancy or dilatancy of the granular material is related to the sediment phase pressure large relative velocities between the sediment and fluid phases were found near the surface of the moving granular mass for the dense packing condition it was concluded that the collapse process of a densely packed granular column was more sensitive to particle response time than that of a loosely packed granular column possible further research directions in two phase modeling of submarine granular flows include i plastic effect in the computation of the pressure of the solid phase ii near wall correction to the sedimentation velocity iii effect of sediment phase on the wall function for modeling fluid phase acknowledgements the material is based on work supported by the ministry of science and technology taiwan most 105 2218 e 032 001 and the national science foundation under grant no cbet 1706938 part of this work used the extreme science and engineering discovery environment xsede through a startup allocation oce170015 any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not necessarily reflect the views of the national science foundation this is soest contribution no 10286 appendix a the simulated collapse processes of granular columns by using particle response models of richardson and zaki 1954 and engelund 1953 fig a 1 shows the collapse processes of an initially dense packing column simulated by using the model of richardson and zaki 1954 referred to as rz in the figure fig a 2 shows the collapse processes of an initially dense packing column simulated by using the model of engelund 1953 referred to as engelund in the figure the measured results of rondon et al 2011 and the results obtained by using the new model are also superposed in these two figures for comparison as it can be seen from these two figures the agreement between the measurement and the numerical results obtained by using the rz and engelund models is not satisfactory the collapse process simulated by using the rz model is too fast granular suspension simulated by engelund model is too strong see the two lines indicating the concentrations of c 0 1 and c 0 5 the collapse processes of an initially loose packing column simulated by using the rz and engelund models are presented in figs a 3 and a 4 respectively the measured results of rondon et al 2011 and the results obtained by using the new model are also superposed in these two figures for comparison the agreement between the measurement and the numerical results obtained by using the rz model is reasonably well except that the rz model slightly over predict the height in the region close to x 0 the agreement between the measurement and the numerical results obtained by engelund model is less satisfactory the model over predicts the runout distance significantly appendix b a relationship between particle response time and permeability for a one dimensional problem of a steady flow through porous media the terms containing the stresses of fluid phase disappear and eq 2 reduces to b 1 p f x 1 c ρ s u 1 f 1 c τ p where the coordinate x 1 points in the direction of the flow for this problem forchheimer bear 1972 suggested b 2 p f x 1 a f ρ f 1 c u 1 f b f ρ f 1 c 2 u 1 f 2 where af and bf are two model parameters engelund 1953 suggested b 3 a f a e c 3 ν f 1 c 2 d 2 and b 4 b f b e c g 1 c 3 d where ae and be are two model parameters after comparing eqs b 1 and b 2 and using eqs b 3 and b 4 one can obtain b 5 τ p ρ s d 2 ρ f ν f 1 a e c 2 b e r e p according to darcys law for seepage bear 1972 the pressure gradient is b 6 p f x 1 ρ f ν f 1 c u 1 f k p where kp is the permeability when the flow is very slow eqs b 2 b 3 and b 6 suggest that b 7 a e d 2 k p 1 c 2 which means that the particle response time can be related to the permeability appendix c implementation of the new model for τp in openfoam for the problem studied here we have used a e 5000 and b e 3 6 and the dependence of cr on rep is weak the curve cr rep is shown in fig c 1 for 0 1 rep 10 the upper limit of rep is determined by assuming r e p r e s for the sand diameter used in our numerical simulations res 7 we remark that whenever there are two solutions for cr the one with the larger concentration should be taken there are two solutions when rep 8 2 but only one solution for rep 8 1 in any case the value of cr should be the one given by the upper curve which is not very sensitive to rep for the problem studied here referring to fig c 1 when c cr the engeland model should be used to calculate τp when 0 5 c cr the re model should be used to calculate τp when c 0 5 the re model should be used therefore in consideration of the computational efficiency and in view of fig c 1 the model described by eq 27 can be numerically implemented in openfoam by using following continuous piecewise function c 1 τ p ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p for c 0 5 max ρ s ρ f d 2 ν f 1 c n 3 max 1 c c m 0 c m 18 4 5 1 r e p 0 3 r e p ρ s d 2 ρ f ν f 1 a e c 2 b e r e p for c 0 5 which can avoid solving the equation for cr at every grid point for each time step and thus is more computationally efficient 
838,in river basin systems power asymmetry is often responsible of inefficient and unbalanced water allocations climate change and anthropogenic pressure will possibly exacerbate such disparities as the dominant party controls an increasingly limited shared resource in this context the deployment of cooperation mechanisms giving greater consideration to a balanced distribution of the benefits while improving system wide efficiency may be desirable this often implies the intervention of a third party e g the river basin water authority imposing normative constraints e g a minimum release on the party in the dominant position however this imposition will be more acceptable to the dominant party if coupled with some form of compensation for a public agency compensation may be burdensome especially when the allowance is triggered by natural events whose timing and magnitude are highly uncertain in this context index based insurance contracts may represent a viable alternative and reduce the cost of achieving socially desirable outcomes in this paper we develop a hybrid cooperation mechanism composed of i a direct normative constraint imposed by a regulator and ii an indirect financial tool an index based insurance contract to be used as a compensation measure the approach is developed for the lake como multi purpose water system italy a complex alpine river basin supporting several hydropower reservoirs and finally flowing into a regulated lake which supplies water to several downstream uses mostly irrigated agriculture the system is characterized by a manifest geographic power asymmetry the upstream hydropower companies are free to release their stored water in time irrespective of the timing of the downstream demands this situation can lead to financial losses by the downstream users and undesirable social outcomes results suggest that financial instruments may offer a reliable and relatively inexpensive alternative to other forms of compensation and thereby favor more balanced management of multi purpose water systems characterized by power asymmetry this finding is especially relevant in times when granting of licenses to use withdrawal water are often being reviewed with attention to environmental protection and equity issues keywords water management hydroeconomics index based insurance cooperation power asymmetry 1 introduction in many river basins different stakeholders depending on the same resource do not share equal power position when the resource is scarce or its use is competitive among multiple agents power distribution becomes pivotal in shaping water sharing policies espey and towfique 2004 song and whittington 2004 zawahri and gerlak 2009 zawahri and mitchell 2011 power asymmetry has been extensively studied in the water resources literature especially for international transboundary contexts daoudy 2009 dinar et al 2007 dinar 2009 zeitoun et al 2011 a commonly accepted definition of power is still debated evans and newnham 1998 yet generally it is viewed as encompassing different dimensions hard or structural power such as geographical location is distinguished from political soft power nye 2008 and sticky economic power mead 2004 nonetheless in both national and international cases geographic position and flow control together with vested water rights are intrinsically present and always play a role in upstream downstream water disputes kehl 2015 mandel 1992 for this reason particularly when water scarcity is exacerbated by climatic extremes or varying socio economic conditions e g drought and or increased water demands power asymmetry can be responsible for socially inequitable and inefficient water allocations zeitoun et al 2011 in these cases a third party in the form of a regulatory actor e g the river basin water authority may decide to intervene by restricting or controlling the behaviors of water users browder 2000 dinar and alemu 2000 dinar 2000 elhance 2000 however adopting direct regulation to enforce power balance and water redistribution may be highly controversial or infeasible due to resulting unilateral losses and vested water rights typically the imposed new regulatory regime favors one agent at the expense of another therefore to improve its acceptability some form of compensation is helpful dinar 2006 as far as different water uses are concerned the benefits generated by the constraint for one agent and the global system is often non transferable to the agent negatively affected by the constraint madani et al 2014 therefore improving system equality usually comes at a price for the public authority often in the form of direct monetary indemnity arjoon et al 2016 mitchell and keilbach 2001 this form of compensation can be burdensome especially when the allowance is triggered by natural events whose timing and magnitude are unknown in advance in this context index based insurance contracts may represent a viable option and offer a less expensive tool for achieving the desired presumably more balanced outcome index based or parametric insurance is a particular type of financial instrument in which the payout is not conditioned on actual losses but rather triggered by the value of an independent and transparent index goodwin 2001 the use of an index insurance contract in place of a traditional indemnity based contract reduces the risk of adverse selection i e asymmetric information between buyer and seller that leads to a contract more biased toward one sector given the buyer has no control on the index hazell and skees 2006 it also eliminates the need of skilled experts to assess the insured s actual losses and the information required to be set is limited barnett and mahul 2007 on the other hand index based insurance requires a high level of correlation between the index and actual losses as any significant deviation will lead to uncovered damages or unnecessary payouts a situation described as demonstrating high basis risk woodard and garcia 2008 recent years have witnessed an increased interest in index based contracts as mechanisms for sharing risks due to weather phenomena i e weather derivatives alderman and haque 2007 barnett et al 2008 brockett et al 2005 carter et al 2014 manfredo and richards 2009 turvey 2001 applications are numerous and diverse ranging from hedging solutions for the demand fluctuations in electricity martin et al 2001 to supporting agriculture in developing countries bryla tressler et al 2011 hess et al 2002 rao 2010 as far as water management is concerned index based insurance has been proposed as a tool to reduce water related fluctuations of revenues and costs for water utilities as well as hydropower companies foster et al 2015 zeff et al 2014 and to increase available funds for purchasing water from spot markets and option contracts brown and carriquiry 2007 leiva and skees 2008 or to support groundwater pumping costs kemeze et al 2016 state of the art examples of the adoption of financial tools as a compensation measure for water restrictions at the river basin level are relatively recent and mostly directed towards environmental issues in kern and characklis 2017 index based insurance contracts are used to compensate hydropower companies for ramp rate limitations aimed at obtaining more stable environmentally friendly water releases downstream a traditional drought insurance scheme is applied in pérez blanco and gómez gómez 2013 to prevent farmers from illegal groundwater abstractions in dry years in this paper we design a hybrid cooperation mechanism hcm for competing stakeholders in a river basin affected by geographic power asymmetry i e with upstream riparians taking advantage of their position by acting unilaterally at the expense of downstream users the hcm combines two different measures i a direct normative constraint imposed by a regulator on the upstream riparians and ii an indirect compensatory financial tool the hcm s ability to redistribute water rights and induce cooperation in upstream and downstream management as well as its feasibility and acceptability are evaluated and compared to a scenario with no insurance the methodology is developed for the lake como system in italy lake como is a complex alpine river basin whose topology can be divided into three parts a large upstream watershed where numerous hydropower plants exploit the varied terrain for electricity production a deep glacial regulated lake in the middle and several water users mostly farmers downstream the lake is regulated with the primary purpose of allocating water to the downstream irrigation districts while guaranteeing flood protection to the city of como the system is affected by a manifest geographic power asymmetry given the upstream hydropower companies are granted licenses to freely release their stored water in time irrespective of the timing of downstream users demands this conflicting situation is exacerbated during summer droughts when farmers may bear consistent financial losses while upstream hydropower reservoirs are still retaining their storage for winter electricity demands in 2003 and 2005 extremely dry circumstances led the regional water authority to impose forced releases on several upstream hydropower companies to relieve farmers water deficit the emergency measure brought little benefit to the crops but resulted in significant economic losses for the hydropower companies as a consequence they started a lawsuit that was later settled with the regional authority having to pay hydropower producers compensation given the release order was not compliant with the companies abstraction licenses anghileri et al 2012 in this context we design a hcm combining i a dynamic minimum release constraint and ii an index based insurance scheme the former is imposed by the third party i e the regional water authority on the upstream hydropower companies in order to provide basic water deficit relief to the downstream farmers in dry circumstances when the geographic power asymmetry tends to generate unbalanced situations we explored different release constraints of varying severity corresponding to different trade off solutions of a multi objective management problem differently balancing both upstream and downstream benefits concurrently the insurance scheme is designed to offset the upstream party loss by providing the hydropower companies with a tool for managing supply risk i e the financial risk associated with supply availability fluctuations which in this case are linked to hydrology water availability the hcm is finally evaluated in all its parts and compared to a direct form of compensation the paper is organized as follows section 2 describes the approach adopted to design the normative constraint and the index based financial contracts as parts of the hybrid cooperation mechanism section 3 introduces the application context as well as the model used to simulate and evaluate the hcm performance afterwards the numerical results are presented in section 4 where the index based contracts are also compared to other forms of compensation final conclusions are drawn in section 5 2 materials and methods we designed and evaluated a hybrid cooperation mechanism following the methodology reported in fig 1 where for the sake of clarity we assume competing agents who independently manage water storage on the same river under geographic power asymmetry conditions see the inner panel the upstream users operate their reservoirs as profit maximizers i e income from hydropower the downstream agent is also acting individually to attempt maximizing the benefit of water supply but conditionally based on the upstream users decisions a similar scheme is common to several water basins where a consumptive water use downstream is conditioned by the upstream individualistic release policies a conceptual model of the water system able to describe both the hydrological and the economic component see section 3 2 is employed under two different cooperation settings fully cooperative fc and uncooperative uc fully cooperative is intended as the situation in which the agents adopt the maximum level of cooperation as defined by watkins 2006 i e they take joint actions to pursue global efficiency this is equivalent to assuming the existence of a social planner who optimizes all the agents objectives at the same time i e pursue system wide efficiency by solving a multi objective problem at the other end of the spectrum the uncooperative scenario represents a situation in which each agent independently optimizes its own utility without interacting yet still possibly affecting the others specifically the downstream agents maximize their benefits by using inflows whose timing and magnitude are determined by the upstream agents self interested release decisions typically if the water system is affected by power asymmetry and the agents have conflicting interests the uc management scenario will determine a solution whose performance is strongly biased towards the most powerful agent zeitoun and warner 2006 on the other hand a fc management scenario will produce a set of pareto efficient yet ideal solutions fci whose performance vary depending on the adopted trade off among the conflicting agents interests giuliani et al 2015 in this respect the uc solution represents one of the extremes of the fc pareto front and as such is a pareto system wide efficient solution yet pareto efficiency does not imply equity as distributive justice corresponding to a more balanced and politically acceptable solution distributing the costs of droughts among all the stakeholders the design of a hybrid cooperation mechanism hcm has the role of finding a politically acceptable compromise alternative between an unbalanced uc solution and an unrealistically acceptable fc one the first component of the mechanism is a direct normative constraint on the upstream agents releases arrow 2 in fig 1 to shift the uc trade off towards the disadvantaged downstream agent imposing such a normative constraint in the uc scenario serves to counteract the uc power asymmetry and produces a new constrained cooperative solution cci and arrow 3 in fig 1 the potential revenue loss which is induced by the normative release restrictions on the upstream agents decisions is then addressed by the second component of the hcm arrow 4 in fig 1 in the form of a financial hedging contract e g an index based insurance the new compromise solution hc is expected to reduce power asymmetry by constraining the upstream agents decisions to favor the downstream performance while being accepted by the upstream agents thanks to the compensation provided by the insurance payouts in the next paragraphs the two components of a hybrid cooperation mechanism design are described in detail while the water system model and the optimization approach are presented in section 3 2 1 fully cooperative and uncooperative solutions given the presence of multiple agents a multi objective optimization algorithm is adopted in order to identify the optimal operating policies under different cooperative scenarios arrow 1 in fig 1 each cooperative scenario corresponds to an alternative solution fci to the multi objective fc problem and represents a different trade off between the agents a large and complex river basin is likely to be managed by many agents independently each one optimizing their local objectives madani 2010 tilmant and kinzelbach 2012 for this reason the current baseline is assumed to be the uncooperative alternative uc i e the optimal strategy emerging from the uc management scenario this uc solution is then benchmarked against the set of pareto efficient fc alternatives depending on the management context uc or fc a different problem or a combination of problems is solved to design the optimal operation for the upstream and downstream users in general the optimization problem consists in finding the best operating policy π such that 1 π arg min π j where the policy π is defined as a closed loop control policy castelletti et al 2008 that determines the release decision u t π d t x t at each time step t as dependent on the day of the year dt which informs on the natural and the anthropic time and the current state x t of the modeled system e g the lake reservoir level the release decision ut may differ from the actual release r t 1 in specific situations where normative and physical constraints may restrict the ability of the dam operator to subjectively regulate the system the objectives vector j to be minimized is defined for each problem based on the management configuration in fact while in an uc configuration each agent minimizes his individual management goals in a fc scenario a system wide multi objective perspective is adopted 2 2 the direct component dynamic minimum release constraint we adopt the approach proposed by anghileri et al 2012 to design a dynamic release constraint aimed at establishing a mutual influence among upstream and downstream users in place of the current one sided dependence the constraint imposes a forced minimum volume release to the upstream agents that is triggered and adjusted by downstream water availability e g the storage in the downstream reservoir the core of the constraint design is the analysis of the upstream downstream relationship that is observed in a fc management context unlike the uc policy where the upstream release decisions are indifferent to the downstream condition and can therefore assume whichever possible value a fully cooperative solution will only display a set of upstream decisions that are compatible with the given downstream target presumably in a fci solution corresponding to a trade off favoring the downstream performance when there is limited water available to meet downstream needs the upstream agents never release less than a given volume the constraint is designed in order to mimic this relationship in an uc context the dynamic minimum release rule is extracted from the analysis of the trajectories of the upstream releases and the corresponding downstream storage in a fci solution the minimum upstream release observed in association to each value of the downstream storage is set as the minimum release constraint to be imposed in the uc scenario a different rule can be extracted from each fci alternative to mimic different preference levels toward achieving the downstream goal 2 3 the indirect component index based insurance contract in cooperative game theory parrachino 2006 among the conditions for a new allocation scheme to be practicable is that the benefits of cooperation to any stakeholder are at least equal to what that stakeholder would obtain by acting independently i e individual rationality in this case we want to design a mechanism able to incentivize a shift from the current unbalanced equilibrium outcome to a more politically acceptable alternative this shift enforced by the first component of the hcm is made acceptable through an index based insurance contract the financial solution is offered to the upstream agents for covering the losses generated by the dynamic minimum release constraint in recent years increasing interest has been devoted to the use of index based derivatives as tools for managing risks related to climate and weather phenomena brockett et al 2005 manfredo and richards 2009 index based insurance is an alternative form of insurance in which the payout is triggered and based on the values measured from an index usually a weather or hydrologic variable as opposed to the assessed damage of each insurance buyer when the index is suitably selected it acts as a proxy for the losses offering some advantages over more traditional forms of insurance by eliminating the need of skilled experts required to assess the insured s actual losses index based derivatives are able to cut transaction costs a feature that made them suitable for the adoption in many international cooperation projects in the developing world barnett and mahul 2007 moreover since the payout is triggered by an independent weather parameter which cannot be influenced or manipulated by the buyer the use of an index insurance contract reduces the risk of adverse selection and moral hazard skees 2011 however being a relatively new concept in water related sectors the adoption of index based contracts requires education among the stakeholders in order to help them understanding the advantages and shortcomings of such financial products smith and watts 2009 prerequisites for a viable index based insurance scheme are data availability and reliability and a good correlation between the payout and the actual loss i e to avoid what is referred to as basis risk skees 2011 the practical steps to be followed in designing an index based insurance contract are briefly described in the next paragraphs a setting the index the most important and critical part of setting an insurance contract is the selection of an appropriate underlying index the index must be a measurable and transparent metric that correlates well with the financial loss that the insurance is covering when the index fails to describe losses the resulting basis risk is borne by either the buyer the index underestimates damage or the seller the index overestimates damage the index must also be free of concerns over manipulation to prevent moral hazard and insurance fraud miranda and vedenov 2001 while any good index based contract should aim at a low basis risk in some cases a trade off between the complexity of an index and its basis risk is observed in the literature the index is identified according to the nature of the covered financial loss the inflow foster 2013 foster et al 2015 zeff et al 2014 or a combination of the inflow and other external electricity peak price drivers e g natural gas prices being the least expensive peaking source after hydropower are one of these drivers kern et al 2015 are usually good at describing hydropower production losses rainfall giné et al 2008 temperature humidity hellmuth et al 2009 and remote sensed vegetation indices patankar 2011 typically correlate well with crop losses wind speed and tremor level are suitable in case of hurricane and earthquake losses bichara 2007 river levels are often used to describe flood related damage hellmuth et al 2009 b defining the payout function the payout function defines the conditions under which a contract buyer receives a payout as well as the magnitude of the payout according to the level of coverage desired by the insured party an index threshold or strike is set a payout is triggered each time the measured index crosses the strike and the magnitude of the payout is defined through a function based on the type of payout function different contract categories are defined in our application we designed insurance contracts in this case the payout is based on the difference between the strike s and the measured index i the farther the index value falls below the strike the higher the payout 2 p a m a x s i 0 if i s 0 otherwise where p is the payout and a is the slope of the linear portion of the payout function the strike and the slope can be determined in a variety of ways the former can be set as a random threshold or as a percentile of the index the latter should be an economic variable related to the index c pricing the contract a third party e g insurance company would set the contact price or premium p by estimating the expected payout e p from the payout distribution plus the loading l an additional amount reflective of concerns over the uncertain timing and magnitude of payouts i e the risk aversion of the insurer and to account for both administrative costs and the opportunity costs of maintaining the reserves necessary to make payouts smith and watts 2009 3 p e p l one method for computing the price of a contract in weather derivatives is the wang transform wang 2002 this approach converts the payout distribution to risk neutral using a distortion equation which more heavily weights the high end of the original payout pdf f p wang 2000 the risk adjusted payout function f p is determined as 4 f p ϕ ϕ 1 f p λ where ϕ is the standard cumulative distribution and λ is the sharpe ratio or the market price of risk wang 2002 large payouts that occur with low probability have larger capital and liquidity requirements and maintaining these reserves represents an opportunity cost for the insurer weighting these tail events more heavily increases the expected costs of the insurer to a value that accounts for both payouts to the policyholder and the contract loading the adjusted premium p p is defined as 5 p p p f p as a consequence as the variance of a payout distribution grows the difference between the premium and the expected value of payouts i e the loading increases d timing the contract timing is characterized by three stages 1 the contract terms are established and the premium paid at the execution date 2 the contract index starts to be measured on the effective date and 3 finishes on the maturity date when the payout is computed as specified by the index value on maturity date and the payout structure the time distance between the execution and the effective dates must guarantee that no prediction on the index is available to any party in the contract foster et al 2015 3 case study 3 1 system description lake como fig 2 is the third largest lake in italy with a total volume of 234 108 m3 of which 2 54 108 m3 are regulated through a dam on the outflowing adda river the river serves a dense network of downstream irrigation canals which convey water to four agricultural districts with a total surface of 1400 km2 mostly growing maize the same releases are also sufficient to feed eight run of river hydroelectric power plants the lake releases are managed from 1946 by the adda consortium with the twofold purpose of water allocation to the downstream users and flood protection along the lake s shoreline particularly in como city galelli and soncini sessa 2010 the lake is fed by a 4552 km2 alpine watershed characterized by a highly varied terrain elevation which provides a significant hydropower potential exploited through 26 small to medium artificial reservoirs operated by different power companies with a total storage of 5 45 108 m3 more than twice the active capacity of the lake the alpine reservoirs have a significant influence on the downstream streamflow and therefore on the lake water availability in time specifically the lake inflow regime is affected by the upstream reservoirs whose releases are moving water volumes through seasons the natural hydro meteorological regime is characterized by a double peak pattern one more pronounced peak corresponding to the snow melt season in late spring and another more variable produced by autumn rains for both the lake and the hydropower reservoirs the snow melt represents the main contribution to the creation of seasonal storage however the result of the combined upstream reservoirs release policies is often conflicting with the lake water allocation goals in summer when agricultural irrigation demand is at its maximum the upstream reservoirs filled with the contribution from the snow melt limit their releases to profit by higher electricity prices in winter this conflict has been exacerbated by the advent of renewables and particularly after 2009 when the italian government largely subsidized solar power production gse 2011 as a result hydropower production was extensively allocated to fill the sharpened electricity price peaks in winter further reducing summer releases even though most reservoirs were built after the 50s when downstream water rights were already in place hydropower companies are free to release at their discretion the result of this power asymmetry is exemplified by the dispute that arose during the extremely dry summers of 2003 2005 and 2006 on those occasions the regional authority imposed a forced release to the upstream hydropower companies in order to alleviate the drought conditions that were seriously threatening agricultural yields downstream riva 2010 the resulting hydropower revenue losses led to a court litigation and a judgment that finally granted damages to the companies at the expense of the regional authority anghileri 2014 similar events show how the current management configuration is unable to cope with increased climate uncertainty and weather extremes a recent study on the same area anghileri et al 2012 proved a central planner type of management dominates the current uncooperative global performance and suggests induced cooperation may be an effective and inexpensive adaptation measure for this application we consider a2a and enel companies which control more than 50 of the total upstream reservoir capacity as the upstream agents maximizing hydropower production red triangles in fig 2 and the adda consortium as the downstream agent whose local objective is ensuring adequate water supply flood protection is considered as a concurrent objective of the adda consortium but is then treated as a constraint assuming an historically acceptable threshold the regional water authority is the regulatory third party applying the hcm to the system 3 2 the system model the system model describes the operations of two upstream hydropower reservoirs run by a2a and enel companies respectively and lake como regulated by the consorzio dell adda we adopted a conceptual model assuming a 24 h decision time step while the hydropower price dynamic is modeled hourly the model was used to optimize the system operation under both uc and fc management configuration as detailed in section 2 2 the formulation of the objectives for each system component is given in the next paragraphs the lake dam operation as discussed in the above section the lake regulation aims at satisfying the two main objectives of flood control and water supply thus on the basis of previous works anghileri et al 2011 culley et al 2016 we formulate the following objectives computed over the evaluation horizon h flood control the annual average number of days day year when a flood occurs computed as 6 j f l o 1 n y t 0 h 1 g t 1 f l o where g t 1 f l o 1 if h t 1 h 0 otherwise where ht is the lake level ny is the number of years in the horizon and h is the flood level threshold equal to 1 24 m which determines the occurrence of a flood in como city water supply the average squared daily water deficit m3 s 2 computed as 7 j i r r 1 h t 0 h 1 g t 1 i r r where g t 1 i r r max w t r t 1 q e f 0 2 where wt is the daily water demand r t 1 is the release from the lake and qef is the environmental flow equal to 5 m3 s the square of the irrigation step cost accounts for crop vulnerability by penalizing higher shortages which are more likely to compromise the crop growth with respect to more frequent but smaller shortages which are less dangerous to the crops hashimoto et al 1982 hydropower reservoirs operation as a simplified version of the real system where a2a and enel combined operate four reservoirs and seven hydropower plants the model considers one equivalent reservoir and plant for each company the maximum flow qeq for an equivalent plant is set as the minimum between the maximum flows of each original plant and the equivalent energetic coefficient keq is the sum of the coefficient of the aggregated plants the model assumes that the daily energy produced by each plant at its maximum capacity is 8 g m k e q q e q 3600 in order to maximize their profit hydropower companies tend to release the maximum amount of water that can be generated by each plant qmax during the most profitable hours of the day according to the national electricity price pun determined by the italian energy market thus given the release r t 1 the number of functioning hours δ is uniquely determined for each plant as 9 δ r t 1 24 q m a x the aim of the operation for both a2a and enel is to maximize the yearly revenue therefore for each company c 1 2 we formulate the objective 10 j c h p 1 n y t 0 h 1 g t 1 c h p where g t 1 c h p g m c δ p e t 1 δ where p e t 1 δ is the sum of the first δ hourly energy prices for day t 1 3 3 experimental setting the experimental setting is characterized as follows optimization under uc and fc management scenario we modeled both the uncooperative and the fully cooperative policies assuming self interested agents maximizing their individual utility function i e individual rationality giuliani et al 2016b the uc solutions are the result of a two step procedure which first involves optimizing the upstream hydropower releases by two one for each hydropower company single objective problems i e problem 1 where j j c h p for enel and a2a respectively the release trajectories produced by the resulting policies are then set as inflows to the lake to solve a bi objective problem for lake como where j j f l o j i r r this procedure generates a set of uc solutions with varying flood irrigation trade offs the flood objective is later treated as a constraint to identify one single uc solution the fc solutions are obtained by solving problem 1 including all objectives at once in this case j j 1 h p j 2 h p j f l o j i r r this optimization produces a multi dimensional pareto front that is later sliced into a single plane by treating the flood objective as a constraint and considering j h p c 1 2 j c h p all problems are solved with the evolutionary multi objective direct policy search emodps method giuliani et al 2016a an approximate dynamic programming approach that combines direct policy search nonlinear approximating networks and multi objective evolutionary algorithms in particular we parameterized the operating policy as gaussian radial basis functions as they have been demonstrated to be effective in solving this type of multi objective policy design problems giuliani et al 2014a 2014b to perform the optimization we use the self adaptive borg multi objective evolutionary algorithm moea hadka and reed 2013 which has been shown to be highly robust in solving multi objective optimal control problems where it met or exceeded the performance of other state of the art moeas zatarain salazar et al 2016 each optimization was run for 1 million function evaluations over the evaluation horizon 2006 2014 the pun data we used refer to the period 2009 2015 because collected after the introduction of solar power subsidies and the economic crisis they are both internally homogeneous and able to reproduce the most recent winter price peak which is further challenging the upstream downstream relationship to improve solution diversity and filter out the randomness of both the initial population set and the optimization operators the solution set for each optimization is the result of 20 random optimization trials the final optimal policies for each experiment are defined as the set of non dominated solutions constraint design and application three dynamic minimum release constraints are designed for each of the two hydropower companies six in total a dynamic constraint is described by the pair minimum permitted release from a hydropower reservoir and associated lake storage the latter are discretized values the former are sampled from the release trajectories of three selected fully cooperative solutions fc 1 fc 3 and fc 5 for the two hydropower companies during the most critical months for irrigation august september anghileri et al 2012 typically a higher minimum release is associated with a lower lake storage the six constraints are then applied to the uc policies of each company during the agricultural season may september and evaluated over the simulation horizon 2006 2014 index based contracts design a setting the index since no historic revenue data is available we search for an index with high correlation to the historic energy production which can be drawn from the historic releases index correlation with the simulated historical revenues is also evaluated based on state of the art literature we evaluated the inflow to each of the two reservoirs a2a and enel s aggregated over different lag times weekly monthly seasonal and yearly the index with the highest correlation r 2 0 89 and 0 84 for a2a and enel respectively was the inflow volume over the hydrological year starting the 1st of april at the beginning of the snow melt season and reservoir recharge period alternative combined indexes including snow measurement the price of electricity and or the italian electricity demand were also evaluated but none of them produced a significant variation in r 2 correlation of the inflow volume over the current hydrological year with the simulated historical revenues confirmed the observed inflow power production correlations r 2 was 0 85 and 0 84 for a2a and enel respectively b defining the payout function we designed 8 insurance contracts i 1 8 each providing a different level of risk coverage the payout function parameters strikes and slopes are calibrated over the simulation horizon the strikes were set as percentiles of the index for the two companies in particular the strike s ranged from the 30th to the 70th percentile of the inflow in the insurance portfolio as in foster et al 2015 a fixed slope was computed as the ratio of average revenue in the contract period on average inflows c pricing the contract the wang transform method was used for pricing the contracts as described in section 2 3 as a commonly accepted value when pricing weather contracts foster et al 2015 kern et al 2015 wang 2000 we assumed a market price of risk value λ of 0 25 see eq 4 d timing we assume the hydrological year starts on the 1st of april at the beginning of the snow melt season while the yearly autocorrelation on the inflows was not relevant r 2 0 1 snow pack data available before the 1st of april are correlated to the next twelve months total inflow and therefore provides knowledge on the future payouts to avoid adverse selection and ensure that both the insurer and the insured have similar knowledge on future risks the execution date was set to precede the effective date of 5 months i e the 1st of october when most of snow deposition has yet to take place index based contracts evaluation the contracts adoption is simulated over the horizon 2006 2014 as well as over a 200 year synthetic inflow time series under three possible hcm agreements a a fully subsidized agreement where the water authority pays the entire premium for index based insurance covering both hydropower companies solution hca b a partly subsidized agreement where the water authority and the hydropower companies equally share the cost of the insurance premiums solution hcb c a non subsidized agreement where the hydropower companies contribute to the entire premium solution hcc the subsidized configurations hca and hcb are compared to a non insured scenario direct compensation the contracts are also evaluated through a series of financial metrics further detailed in appendix a synthetic time series the uncooperative and fully cooperative policies as well as the insurance mechanisms were also evaluated over a 200 year synthetic inflow time series to generate synthetic inflows to a2a and enel reservoirs and the residual inflow to lake como i e the inflow to the lake not influenced by the considered upstream hydropower reservoirs we used the k nearest neighbor knn algorithm nowak et al 2010 knn method is capable of generating a synthetic dataset that maintains the principal statistical characteristics of the historical data it is based on we first generated yearly spatially aggregated data through an annual ar 1 model and then disaggregated it in space and time based on the intra annual daily volumetric percentages observed in the historical record from the period 1996 2014 a different synthetic dataset generated from the same historic period was used for calibrating and validating the contracts 4 results 4 1 uc and fc policies identification the uncooperative and fully cooperative policies are modeled as detailed in section 3 3 results are displayed in figs 3 and 4 given the geographic system configuration the two equivalent hydropower reservoirs are always operated without interfering with each other this implies that even in the fully cooperative case their objectives are never conflicting therefore in our analysis the hydropower objective jhp aggregates the yearly revenues of the two hydropower companies moreover as mentioned in section 3 3 the flood objective is considered both in the uc and the fc optimization but is later treated as a constraint in order to better investigate the water supply hydropower trade off to this end we assumed the historically accepted threshold of about 6 days of flood in a year fig 3 compares the fully cooperative and uncooperative solutions on the same jhp vs jirr space which lies on the plane jflo 5 8 days year as expected the fc pareto front which is the performance of the pareto optimal set covers different alternative upstream downstream trade offs while the uc solution represents one of the extremes which maximizes the hydropower objective at the expense of the downstream water supply goal this result exemplifies the system power asymmetry these solutions are obtained from two separate optimization efforts one for the uc and one for the fc case which are presented in fig 4 panel 4a shows the performance of the pareto efficient fc alternatives fci the fc optimization solves a problem with four objectives j j 1 h p j 2 h p j f l o j i r r here we aggregated the non conflicting hydropower revenues of the two companies j h p c 1 2 j c h p to show a three dimensional pareto front the arrows indicate the direction of preference ideally we search for a solution minimizing the irrigation deficit horizontal axis and the yearly number of floodings vertical axis also indicated by degrading colors and bigger dimension for higher values while maximizing the hydropower revenue lateral axis not surprisingly we observe that the water supply hydropower trade off is less and less evident when the conditions on the flood objective are relaxed in other words reducing the conflict between the two objectives of the downstream agent enlarges the space for compromise solutions upstream and downstream this result indicates that if the lake regulation s only target was water allocation the downstream water demand would be satisfied almost independently from the hydropower releases therefore we selected the set of centralized solutions f c 1 5 equally performing with respect to the flood objective on the plane jflo 5 8 days year depicted in yellow in fig 4 which represents an historically acceptable value panel 4b shows the performance of the pareto efficient uncooperative alternatives as mentioned the value of the hydropower objective jhp aggregates the result of two independent single objective optimizations for this reason all uc solutions performance rests on the same plane depicted in yellow in fig 4 defined as j h p 1 483 10 8 year similarly to f c 1 5 the selected uc solution is the one satisfying the assumed condition on the flood objective of 5 8 days per year 4 2 dynamic minimum release constraints three dynamic minimum release constraints are derived from three fully cooperative solutions exploring different trade offs between hydropower production and water supply as described in section 2 2 for each hydropower company we considered the release trajectories of alternatives fc 1 fc 3 and fc 5 fig 5 shows the three constraints derived for company a2a in ascending order of severity each constraint is represented by the coupled values of minimum release and lake storage as sampled from the corresponding fci trajectory as can be noted from the plots in a fc solution a lower storage always implies a larger minimum release on the other hand a fc solution with a higher preference for irrigation benefits i e fc 1 over fc 3 over fc 5 produces a constraint that is active for higher lake storage values and requires larger release volumes fig 6 a depicts the simulated performance for both companies of the uc policy under the three constraints averaged over the evaluation horizon 2006 2014 i e cc 1 cc 3 and cc 5 the average yearly effect of the constraints is a general decrease in hydropower revenues the most severe constraint cc 1 leads to a revenue loss of 1 8 106 year equivalent to 1 2 of the yearly average revenue on the other hand the water supply deficit is reduced by 3 3 the effects of cc 3 and cc 5 are less evident leading to a jirr improvement of 0 9 and 0 1 respectively and smaller revenue losses 0 4 and 0 1 it is worth mentioning that despite these constraints negatively impact on the self interested hydropower operations producing significant revenue losses to the two companies the effect of these direct measures in terms of energy production is fairly negligible the yearly average revenue variation may not appear very large however if we consider the effect of the constraint on each year revenue panel 6b we can observe a significant change hydropower production is naturally prone to supply risk a form of financial risk linked to the availability of the supply source i e water and aggravated by hydrologic uncertainty the application of forced releases that are triggered by dry conditions downstream is likely to exacerbate such a financial risk for hydropower companies in dry years as a result we expect the constraints to cause a revenue loss whenever the inflow volume and its timing do not allow for both satisfying the imposed rule and optimizing power generation however the minimum release constraint can lead to higher hydropower revenues in wet years this positive difference is due to the stochastic optimization we used for designing the hydropower policy which in the presence of inflow uncertainty prefers to act conservatively and release less water to avoid the risk of emptying the reservoir however in wet conditions it would have been possible to release more and hence produce more as future higher than expected inflows are able to refill the reservoir the constraint is by chance forcing some releases in these days ultimately producing higher revenues the yearly mean value levels out the effect of the constraint since it averages both positive and negative variations panel 6 b exemplifies this concept by showing the effect of the forced release cc 1 on a2a revenues over the horizon 2006 2014 both 2006 and 2007 were fairly dry years nevertheless in 2006 the storage is enough to comply with the minimum release rule while still allocating water to the most profitable hours during the rest of the year however the effect of the constraint over the next two years results in a cumulative loss of about 21 million the next years illustrate a similar pattern with alternating wet dry conditions determining different and sometimes significant positive or negative financial outcomes the effect of the constraints on the two companies is similar though it is a lot less visible for enel which manages smaller water volumes 4 3 index based contracts to contrast the variability in revenue losses induced by the constraint we apply the 8 different index based insurance i 1 8 designed as described in section 3 3 to the cci solutions the effect of financial risk instruments is typically more evident when observing the revenue trajectories over a long time series as short time series have a high variance and therefore they show larger deviations from the mean i e the expected damage used to define the premium fig 7 shows both the revenue trajectories of the uninsured alternative cc 1 blue line and the insured alternative hcb red line for company a2a and contract i 2 this contract was chosen for this particular company and constraint combination because it provides the highest risk mitigation level for the lowest marginal cost for a detailed comparison see appendix a as a direct consequence of adopting a risk mitigation measure revenues are less vulnerable to the hydrologic uncertainty the red trajectory is visibly more constant the negative peaks are smothered by the large payouts received on dry years green areas in fig 7 while the yearly premium reduces the positive peaks red areas however the risk of a low or very low revenue due to scarce inflow i e supply risk is borne by the insurance company thus largely improving the worst case performance or revenue floor the red dashed lines in fig 7 these observations hold true for all designed contracts and independently from who will contribute to the insurance premium the last step of our methodology see fig 1 requires the adoption of a financial measure able to guarantee the constraint acceptability and the transition to a new equilibrium outcome therefore we simulated the adoption of different index based contracts under a fully subsidized hca a partially subsidized hcb and a non subsidized agreement hcc this approach is highly adjustable e g different levels of subsidies and contract combinations can be adopted therefore allowing for a flexible and negotiable measure fig 6a shows the performance of the three alternative hc agreements hca hcb and hcc under contract i 2 and constraint cc 1 over horizon 2006 2014 in yellow in all cases the companies receive a payout from the insurance whenever the index insurance is triggered by low inflow conditions i e yearly inflow volume lower than the s threshold it is relevant to note that the index which triggers the payout is decoupled from the conditions activating the constraint i e downstream storage values for each agreement scenario the resulting shift in yearly revenue performance is a combination of the received payouts and the respective premium share that is paid to the insurance company since yearly premiums are designed to exceed the expected payout value i e the loading principle solution hcc produces a negative shift in yearly revenue performance while a positive shift is observed when the regional water authority contributes to the premium solutions hca and hcb one should consider however that yearly revenue represents only one of the primary goals of hydropower companies which may include financial stability as well considered in this light solution hcc could still be a valid alternative to a non insured scenario cc 1 especially for mitigating the impacts of extreme events the jhp performance associated to hca and hcb exceed the uc solution by 4 7 and 0 29 million respectively in these cases the water authority has internalized the costs by contributing to the total insurance premium 8 9 million under hca or half of it under hcb these are just three possible agreement examples we can anticipate the final arrangement to emerge from a bargaining process possibly involving additional incentives e g license granting and being fine tuned to account for contingencies 4 4 comparison to a direct form of compensation subsidized index based contracts proved to be effective in restoring the hydropower revenues to the uc conditions the cost for the water authority could be contributing to paying the insurance premiums in full hca or in part an alternative form of compensation directly covering the revenue losses induced by the minimum release constraints has the main drawback of depending on uncertain hydrology and of being highly variable from year to year i e high financial risk fig 8 compares the costs for the water authority of solutions hca hcb i e the entire premium or half of it indicated by the red dashed lines with the direct compensation of constraint cc 1 for company a2a the brown negative bars in this case it is evident how the insurance solution i 2 offers compensation at more constant deferred prices maximum yearly cost is about 6 8 million for hca and 3 4 million for hcb compared to a maximum direct compensation cost of 15 9 million which is usually preferable and more practicable but generally at a higher average cost the yearly average cost is equal to the maximum average cost for both hca and hcb compared to an yearly average direct compensation cost of 4 9 million in this case the agreement hcb also provides for a cheaper alternative for the water authority this conclusion however is not equally straightforward or generalizable to other combinations of constraint company and contract the main reason for this is that while direct compensation varies according to the constraint the insurance premium is essentially independent of it in the case of enel which is less affected by the constraints than a2a a direct compensation may be the cheaper solution for the water authority on the other hand the hydropower companies are likely to prefer an indirect financial solution given the additional benefits offered by index based contracts reduced revenue fluctuations increased revenue floor this fact together with the high flexibility of insurance contracts could lead to fine tuned agreements between the water authority and the hydropower companies e g a different premium share combination 5 conclusion in power asymmetric water systems where the absence of reciprocal interdependency hinders a balanced water rights distribution cooperative actions may be induced via positive linkages e g side payments dinar 2006 mitchell and keilbach 2001 however practical and financial issues arise when the magnitude and timing of these payments depend on hardly predictable conditions e g future hydrology in this paper we propose the use of index based insurance contracts to mitigate the financial risk associated with uncertain side payments and concurrently provide a flexible tool for sharing externalities in a power asymmetric river basin more in detail we designed a hybrid cooperation mechanism to foster collective action in a water system with multiple agents characterized by geographic power asymmetry the approach is demonstrated in the lake como system where the upstream hydropower companies are granted licenses to freely release their stored water in time irrespective of the timing of downstream users demands in this context the intervention of a regulatory third party i e the regional water authority can enforce more balanced solutions the direct part of the hcm is a dynamic minimum release constraint imposed over upstream releases that is based on the downstream agent policy i e the lake storage this measure is able to improve downstream performance up to 3 3 by introducing a mutual upstream downstream relationship conversely the yearly hydropower revenue is reduced up to 1 2 on average however because it largely depends on hydrology this loss pattern displays relevant inter annual fluctuations with dry years resulting in significant revenue losses the constraint acceptability is therefore addressed by an instrument able to manage this variability an index based insurance contract which constitutes the indirect component of the hcm we have considered the cost of a similar measure for the regional authority under totally and partially subsidized premium agreements and observed that depending on the given case weather derivatives may provide a cheaper alternative with respect to a direct compensation however we should consider that the insurance would also provide further benefits to the hydropower companies financial stability in the form of supply risk mitigation and revenue floor improvement for this reason it is likely this solution would be preferred by the hydropower producers who may be willing to bear a substantial part of the premium this latter case is also preferable because it would further incentivize the companies to modify their release policies in order to adapt to the constraint and reduce its impact on their revenues finally contributing in paying the insurance premium might be an important aspect to be included in the incoming renegotiation of the water rights of the hydropower companies we consider the proposed hybrid approach to be readily transferable to larger and more complex systems similarly affected by geographic power asymmetry e g the zambezi gandolfi and togni 1997 giuliani and castelletti 2013 tilmant et al 2010 2012 and the euphrates tigris altinbilek 2004 kibaroglu and ünver 2000 moreover the use of insurance contracts as bargaining tools is applicable to many other different other contexts especially when a newly imposed condition is expected to generate a financial risk which is borne by only one party to the negotiating process future research efforts will focus on exploring alternative mechanism especially the possibility of introducing financial coverage for the downstream farmers yet this implies the adoption of a distributed model in space and time for the downstream users able to take into account the different crops with their phenology the resultant agricultural production and farmers revenues li et al 2017 this model would also allow comparing the premium paid by the hydropower companies or the regional authority with respect to the gain in terms of agricultural profit to conclude financial hedging tools offer a reliable and practicable alternative to favor a more balanced and politically acceptable management of multi purpose water systems characterized by power asymmetry such finding is relevant especially in times where granting of licenses is often being reviewed to include environmental protection and equity issues acknowledgment this work was partially supported by the sowatch project funded by fondazione cariplo grant number 2015 0220 appendix a weather derivatives evaluation to evaluate a contract many aspects have to be considered a risk mitigation tool provides a strategy for reducing inter annual variability and hedge large damages but the desired level of coverage depends on many factors including the buyer loss and risk aversion for this reason we considered a series of diverse measures to assess the index based portfolio designed for lake como case study the values for the designed insurance contracts i 1 8 are shown in table a 1 the first values to weigh are the contract premium p the expected payout e p and their difference or loading l the loading percentage on the expected value of payouts is particularly informative on the existing trade off between premium and loading concurrent minimization in fact the contract loading increases as the variance of a payout distribution grows if the strike value s is intended to cover the insured from the low frequency big events the contract loading will be high on a small premium on the other hand high frequency small events would be covered by insurances with a lower loading and a higher premium to compare the contracts with different strike levels the contract cost i e the portion of the premium that is not actually returned to the buyer in the form of payouts over the contract period is evaluated and expressed as a percentage on the yearly average revenue r a 1 c o s t p p r higher strikes provide a better coverage for a higher cost the already mentioned revenue floor is expressed in terms of risk mitigation level rml the ratio of minimum revenues r with and without insurance a 2 r m l min r i n s u r e d min r u n i n s u r e d it is also interesting to evaluate the revenue fluctuation computed as the standard deviation of the revenue throughout the whole period this metric is able to reflect the uncertainty related to the yearly hydropower income as already noted in fig 7 risk mitigation measures provide reduced revenue uncertainty and more constant income at the expense of a yearly premium the higher the value s the more pronounced the effect on variability in order to choose a contract for our application on company a2a and alternative cc 1 we considered the regional water authority point of view which is to find the cheapest alternative for mitigating the losses induced by the dynamic minimum release constraint taking into account the average yearly induced losses about 4 9 million a low coverage is appropriate to provide full compensation in this specific case we opted for the contract i 2 which offers the highest marginal rml for the lowest cost 
838,in river basin systems power asymmetry is often responsible of inefficient and unbalanced water allocations climate change and anthropogenic pressure will possibly exacerbate such disparities as the dominant party controls an increasingly limited shared resource in this context the deployment of cooperation mechanisms giving greater consideration to a balanced distribution of the benefits while improving system wide efficiency may be desirable this often implies the intervention of a third party e g the river basin water authority imposing normative constraints e g a minimum release on the party in the dominant position however this imposition will be more acceptable to the dominant party if coupled with some form of compensation for a public agency compensation may be burdensome especially when the allowance is triggered by natural events whose timing and magnitude are highly uncertain in this context index based insurance contracts may represent a viable alternative and reduce the cost of achieving socially desirable outcomes in this paper we develop a hybrid cooperation mechanism composed of i a direct normative constraint imposed by a regulator and ii an indirect financial tool an index based insurance contract to be used as a compensation measure the approach is developed for the lake como multi purpose water system italy a complex alpine river basin supporting several hydropower reservoirs and finally flowing into a regulated lake which supplies water to several downstream uses mostly irrigated agriculture the system is characterized by a manifest geographic power asymmetry the upstream hydropower companies are free to release their stored water in time irrespective of the timing of the downstream demands this situation can lead to financial losses by the downstream users and undesirable social outcomes results suggest that financial instruments may offer a reliable and relatively inexpensive alternative to other forms of compensation and thereby favor more balanced management of multi purpose water systems characterized by power asymmetry this finding is especially relevant in times when granting of licenses to use withdrawal water are often being reviewed with attention to environmental protection and equity issues keywords water management hydroeconomics index based insurance cooperation power asymmetry 1 introduction in many river basins different stakeholders depending on the same resource do not share equal power position when the resource is scarce or its use is competitive among multiple agents power distribution becomes pivotal in shaping water sharing policies espey and towfique 2004 song and whittington 2004 zawahri and gerlak 2009 zawahri and mitchell 2011 power asymmetry has been extensively studied in the water resources literature especially for international transboundary contexts daoudy 2009 dinar et al 2007 dinar 2009 zeitoun et al 2011 a commonly accepted definition of power is still debated evans and newnham 1998 yet generally it is viewed as encompassing different dimensions hard or structural power such as geographical location is distinguished from political soft power nye 2008 and sticky economic power mead 2004 nonetheless in both national and international cases geographic position and flow control together with vested water rights are intrinsically present and always play a role in upstream downstream water disputes kehl 2015 mandel 1992 for this reason particularly when water scarcity is exacerbated by climatic extremes or varying socio economic conditions e g drought and or increased water demands power asymmetry can be responsible for socially inequitable and inefficient water allocations zeitoun et al 2011 in these cases a third party in the form of a regulatory actor e g the river basin water authority may decide to intervene by restricting or controlling the behaviors of water users browder 2000 dinar and alemu 2000 dinar 2000 elhance 2000 however adopting direct regulation to enforce power balance and water redistribution may be highly controversial or infeasible due to resulting unilateral losses and vested water rights typically the imposed new regulatory regime favors one agent at the expense of another therefore to improve its acceptability some form of compensation is helpful dinar 2006 as far as different water uses are concerned the benefits generated by the constraint for one agent and the global system is often non transferable to the agent negatively affected by the constraint madani et al 2014 therefore improving system equality usually comes at a price for the public authority often in the form of direct monetary indemnity arjoon et al 2016 mitchell and keilbach 2001 this form of compensation can be burdensome especially when the allowance is triggered by natural events whose timing and magnitude are unknown in advance in this context index based insurance contracts may represent a viable option and offer a less expensive tool for achieving the desired presumably more balanced outcome index based or parametric insurance is a particular type of financial instrument in which the payout is not conditioned on actual losses but rather triggered by the value of an independent and transparent index goodwin 2001 the use of an index insurance contract in place of a traditional indemnity based contract reduces the risk of adverse selection i e asymmetric information between buyer and seller that leads to a contract more biased toward one sector given the buyer has no control on the index hazell and skees 2006 it also eliminates the need of skilled experts to assess the insured s actual losses and the information required to be set is limited barnett and mahul 2007 on the other hand index based insurance requires a high level of correlation between the index and actual losses as any significant deviation will lead to uncovered damages or unnecessary payouts a situation described as demonstrating high basis risk woodard and garcia 2008 recent years have witnessed an increased interest in index based contracts as mechanisms for sharing risks due to weather phenomena i e weather derivatives alderman and haque 2007 barnett et al 2008 brockett et al 2005 carter et al 2014 manfredo and richards 2009 turvey 2001 applications are numerous and diverse ranging from hedging solutions for the demand fluctuations in electricity martin et al 2001 to supporting agriculture in developing countries bryla tressler et al 2011 hess et al 2002 rao 2010 as far as water management is concerned index based insurance has been proposed as a tool to reduce water related fluctuations of revenues and costs for water utilities as well as hydropower companies foster et al 2015 zeff et al 2014 and to increase available funds for purchasing water from spot markets and option contracts brown and carriquiry 2007 leiva and skees 2008 or to support groundwater pumping costs kemeze et al 2016 state of the art examples of the adoption of financial tools as a compensation measure for water restrictions at the river basin level are relatively recent and mostly directed towards environmental issues in kern and characklis 2017 index based insurance contracts are used to compensate hydropower companies for ramp rate limitations aimed at obtaining more stable environmentally friendly water releases downstream a traditional drought insurance scheme is applied in pérez blanco and gómez gómez 2013 to prevent farmers from illegal groundwater abstractions in dry years in this paper we design a hybrid cooperation mechanism hcm for competing stakeholders in a river basin affected by geographic power asymmetry i e with upstream riparians taking advantage of their position by acting unilaterally at the expense of downstream users the hcm combines two different measures i a direct normative constraint imposed by a regulator on the upstream riparians and ii an indirect compensatory financial tool the hcm s ability to redistribute water rights and induce cooperation in upstream and downstream management as well as its feasibility and acceptability are evaluated and compared to a scenario with no insurance the methodology is developed for the lake como system in italy lake como is a complex alpine river basin whose topology can be divided into three parts a large upstream watershed where numerous hydropower plants exploit the varied terrain for electricity production a deep glacial regulated lake in the middle and several water users mostly farmers downstream the lake is regulated with the primary purpose of allocating water to the downstream irrigation districts while guaranteeing flood protection to the city of como the system is affected by a manifest geographic power asymmetry given the upstream hydropower companies are granted licenses to freely release their stored water in time irrespective of the timing of downstream users demands this conflicting situation is exacerbated during summer droughts when farmers may bear consistent financial losses while upstream hydropower reservoirs are still retaining their storage for winter electricity demands in 2003 and 2005 extremely dry circumstances led the regional water authority to impose forced releases on several upstream hydropower companies to relieve farmers water deficit the emergency measure brought little benefit to the crops but resulted in significant economic losses for the hydropower companies as a consequence they started a lawsuit that was later settled with the regional authority having to pay hydropower producers compensation given the release order was not compliant with the companies abstraction licenses anghileri et al 2012 in this context we design a hcm combining i a dynamic minimum release constraint and ii an index based insurance scheme the former is imposed by the third party i e the regional water authority on the upstream hydropower companies in order to provide basic water deficit relief to the downstream farmers in dry circumstances when the geographic power asymmetry tends to generate unbalanced situations we explored different release constraints of varying severity corresponding to different trade off solutions of a multi objective management problem differently balancing both upstream and downstream benefits concurrently the insurance scheme is designed to offset the upstream party loss by providing the hydropower companies with a tool for managing supply risk i e the financial risk associated with supply availability fluctuations which in this case are linked to hydrology water availability the hcm is finally evaluated in all its parts and compared to a direct form of compensation the paper is organized as follows section 2 describes the approach adopted to design the normative constraint and the index based financial contracts as parts of the hybrid cooperation mechanism section 3 introduces the application context as well as the model used to simulate and evaluate the hcm performance afterwards the numerical results are presented in section 4 where the index based contracts are also compared to other forms of compensation final conclusions are drawn in section 5 2 materials and methods we designed and evaluated a hybrid cooperation mechanism following the methodology reported in fig 1 where for the sake of clarity we assume competing agents who independently manage water storage on the same river under geographic power asymmetry conditions see the inner panel the upstream users operate their reservoirs as profit maximizers i e income from hydropower the downstream agent is also acting individually to attempt maximizing the benefit of water supply but conditionally based on the upstream users decisions a similar scheme is common to several water basins where a consumptive water use downstream is conditioned by the upstream individualistic release policies a conceptual model of the water system able to describe both the hydrological and the economic component see section 3 2 is employed under two different cooperation settings fully cooperative fc and uncooperative uc fully cooperative is intended as the situation in which the agents adopt the maximum level of cooperation as defined by watkins 2006 i e they take joint actions to pursue global efficiency this is equivalent to assuming the existence of a social planner who optimizes all the agents objectives at the same time i e pursue system wide efficiency by solving a multi objective problem at the other end of the spectrum the uncooperative scenario represents a situation in which each agent independently optimizes its own utility without interacting yet still possibly affecting the others specifically the downstream agents maximize their benefits by using inflows whose timing and magnitude are determined by the upstream agents self interested release decisions typically if the water system is affected by power asymmetry and the agents have conflicting interests the uc management scenario will determine a solution whose performance is strongly biased towards the most powerful agent zeitoun and warner 2006 on the other hand a fc management scenario will produce a set of pareto efficient yet ideal solutions fci whose performance vary depending on the adopted trade off among the conflicting agents interests giuliani et al 2015 in this respect the uc solution represents one of the extremes of the fc pareto front and as such is a pareto system wide efficient solution yet pareto efficiency does not imply equity as distributive justice corresponding to a more balanced and politically acceptable solution distributing the costs of droughts among all the stakeholders the design of a hybrid cooperation mechanism hcm has the role of finding a politically acceptable compromise alternative between an unbalanced uc solution and an unrealistically acceptable fc one the first component of the mechanism is a direct normative constraint on the upstream agents releases arrow 2 in fig 1 to shift the uc trade off towards the disadvantaged downstream agent imposing such a normative constraint in the uc scenario serves to counteract the uc power asymmetry and produces a new constrained cooperative solution cci and arrow 3 in fig 1 the potential revenue loss which is induced by the normative release restrictions on the upstream agents decisions is then addressed by the second component of the hcm arrow 4 in fig 1 in the form of a financial hedging contract e g an index based insurance the new compromise solution hc is expected to reduce power asymmetry by constraining the upstream agents decisions to favor the downstream performance while being accepted by the upstream agents thanks to the compensation provided by the insurance payouts in the next paragraphs the two components of a hybrid cooperation mechanism design are described in detail while the water system model and the optimization approach are presented in section 3 2 1 fully cooperative and uncooperative solutions given the presence of multiple agents a multi objective optimization algorithm is adopted in order to identify the optimal operating policies under different cooperative scenarios arrow 1 in fig 1 each cooperative scenario corresponds to an alternative solution fci to the multi objective fc problem and represents a different trade off between the agents a large and complex river basin is likely to be managed by many agents independently each one optimizing their local objectives madani 2010 tilmant and kinzelbach 2012 for this reason the current baseline is assumed to be the uncooperative alternative uc i e the optimal strategy emerging from the uc management scenario this uc solution is then benchmarked against the set of pareto efficient fc alternatives depending on the management context uc or fc a different problem or a combination of problems is solved to design the optimal operation for the upstream and downstream users in general the optimization problem consists in finding the best operating policy π such that 1 π arg min π j where the policy π is defined as a closed loop control policy castelletti et al 2008 that determines the release decision u t π d t x t at each time step t as dependent on the day of the year dt which informs on the natural and the anthropic time and the current state x t of the modeled system e g the lake reservoir level the release decision ut may differ from the actual release r t 1 in specific situations where normative and physical constraints may restrict the ability of the dam operator to subjectively regulate the system the objectives vector j to be minimized is defined for each problem based on the management configuration in fact while in an uc configuration each agent minimizes his individual management goals in a fc scenario a system wide multi objective perspective is adopted 2 2 the direct component dynamic minimum release constraint we adopt the approach proposed by anghileri et al 2012 to design a dynamic release constraint aimed at establishing a mutual influence among upstream and downstream users in place of the current one sided dependence the constraint imposes a forced minimum volume release to the upstream agents that is triggered and adjusted by downstream water availability e g the storage in the downstream reservoir the core of the constraint design is the analysis of the upstream downstream relationship that is observed in a fc management context unlike the uc policy where the upstream release decisions are indifferent to the downstream condition and can therefore assume whichever possible value a fully cooperative solution will only display a set of upstream decisions that are compatible with the given downstream target presumably in a fci solution corresponding to a trade off favoring the downstream performance when there is limited water available to meet downstream needs the upstream agents never release less than a given volume the constraint is designed in order to mimic this relationship in an uc context the dynamic minimum release rule is extracted from the analysis of the trajectories of the upstream releases and the corresponding downstream storage in a fci solution the minimum upstream release observed in association to each value of the downstream storage is set as the minimum release constraint to be imposed in the uc scenario a different rule can be extracted from each fci alternative to mimic different preference levels toward achieving the downstream goal 2 3 the indirect component index based insurance contract in cooperative game theory parrachino 2006 among the conditions for a new allocation scheme to be practicable is that the benefits of cooperation to any stakeholder are at least equal to what that stakeholder would obtain by acting independently i e individual rationality in this case we want to design a mechanism able to incentivize a shift from the current unbalanced equilibrium outcome to a more politically acceptable alternative this shift enforced by the first component of the hcm is made acceptable through an index based insurance contract the financial solution is offered to the upstream agents for covering the losses generated by the dynamic minimum release constraint in recent years increasing interest has been devoted to the use of index based derivatives as tools for managing risks related to climate and weather phenomena brockett et al 2005 manfredo and richards 2009 index based insurance is an alternative form of insurance in which the payout is triggered and based on the values measured from an index usually a weather or hydrologic variable as opposed to the assessed damage of each insurance buyer when the index is suitably selected it acts as a proxy for the losses offering some advantages over more traditional forms of insurance by eliminating the need of skilled experts required to assess the insured s actual losses index based derivatives are able to cut transaction costs a feature that made them suitable for the adoption in many international cooperation projects in the developing world barnett and mahul 2007 moreover since the payout is triggered by an independent weather parameter which cannot be influenced or manipulated by the buyer the use of an index insurance contract reduces the risk of adverse selection and moral hazard skees 2011 however being a relatively new concept in water related sectors the adoption of index based contracts requires education among the stakeholders in order to help them understanding the advantages and shortcomings of such financial products smith and watts 2009 prerequisites for a viable index based insurance scheme are data availability and reliability and a good correlation between the payout and the actual loss i e to avoid what is referred to as basis risk skees 2011 the practical steps to be followed in designing an index based insurance contract are briefly described in the next paragraphs a setting the index the most important and critical part of setting an insurance contract is the selection of an appropriate underlying index the index must be a measurable and transparent metric that correlates well with the financial loss that the insurance is covering when the index fails to describe losses the resulting basis risk is borne by either the buyer the index underestimates damage or the seller the index overestimates damage the index must also be free of concerns over manipulation to prevent moral hazard and insurance fraud miranda and vedenov 2001 while any good index based contract should aim at a low basis risk in some cases a trade off between the complexity of an index and its basis risk is observed in the literature the index is identified according to the nature of the covered financial loss the inflow foster 2013 foster et al 2015 zeff et al 2014 or a combination of the inflow and other external electricity peak price drivers e g natural gas prices being the least expensive peaking source after hydropower are one of these drivers kern et al 2015 are usually good at describing hydropower production losses rainfall giné et al 2008 temperature humidity hellmuth et al 2009 and remote sensed vegetation indices patankar 2011 typically correlate well with crop losses wind speed and tremor level are suitable in case of hurricane and earthquake losses bichara 2007 river levels are often used to describe flood related damage hellmuth et al 2009 b defining the payout function the payout function defines the conditions under which a contract buyer receives a payout as well as the magnitude of the payout according to the level of coverage desired by the insured party an index threshold or strike is set a payout is triggered each time the measured index crosses the strike and the magnitude of the payout is defined through a function based on the type of payout function different contract categories are defined in our application we designed insurance contracts in this case the payout is based on the difference between the strike s and the measured index i the farther the index value falls below the strike the higher the payout 2 p a m a x s i 0 if i s 0 otherwise where p is the payout and a is the slope of the linear portion of the payout function the strike and the slope can be determined in a variety of ways the former can be set as a random threshold or as a percentile of the index the latter should be an economic variable related to the index c pricing the contract a third party e g insurance company would set the contact price or premium p by estimating the expected payout e p from the payout distribution plus the loading l an additional amount reflective of concerns over the uncertain timing and magnitude of payouts i e the risk aversion of the insurer and to account for both administrative costs and the opportunity costs of maintaining the reserves necessary to make payouts smith and watts 2009 3 p e p l one method for computing the price of a contract in weather derivatives is the wang transform wang 2002 this approach converts the payout distribution to risk neutral using a distortion equation which more heavily weights the high end of the original payout pdf f p wang 2000 the risk adjusted payout function f p is determined as 4 f p ϕ ϕ 1 f p λ where ϕ is the standard cumulative distribution and λ is the sharpe ratio or the market price of risk wang 2002 large payouts that occur with low probability have larger capital and liquidity requirements and maintaining these reserves represents an opportunity cost for the insurer weighting these tail events more heavily increases the expected costs of the insurer to a value that accounts for both payouts to the policyholder and the contract loading the adjusted premium p p is defined as 5 p p p f p as a consequence as the variance of a payout distribution grows the difference between the premium and the expected value of payouts i e the loading increases d timing the contract timing is characterized by three stages 1 the contract terms are established and the premium paid at the execution date 2 the contract index starts to be measured on the effective date and 3 finishes on the maturity date when the payout is computed as specified by the index value on maturity date and the payout structure the time distance between the execution and the effective dates must guarantee that no prediction on the index is available to any party in the contract foster et al 2015 3 case study 3 1 system description lake como fig 2 is the third largest lake in italy with a total volume of 234 108 m3 of which 2 54 108 m3 are regulated through a dam on the outflowing adda river the river serves a dense network of downstream irrigation canals which convey water to four agricultural districts with a total surface of 1400 km2 mostly growing maize the same releases are also sufficient to feed eight run of river hydroelectric power plants the lake releases are managed from 1946 by the adda consortium with the twofold purpose of water allocation to the downstream users and flood protection along the lake s shoreline particularly in como city galelli and soncini sessa 2010 the lake is fed by a 4552 km2 alpine watershed characterized by a highly varied terrain elevation which provides a significant hydropower potential exploited through 26 small to medium artificial reservoirs operated by different power companies with a total storage of 5 45 108 m3 more than twice the active capacity of the lake the alpine reservoirs have a significant influence on the downstream streamflow and therefore on the lake water availability in time specifically the lake inflow regime is affected by the upstream reservoirs whose releases are moving water volumes through seasons the natural hydro meteorological regime is characterized by a double peak pattern one more pronounced peak corresponding to the snow melt season in late spring and another more variable produced by autumn rains for both the lake and the hydropower reservoirs the snow melt represents the main contribution to the creation of seasonal storage however the result of the combined upstream reservoirs release policies is often conflicting with the lake water allocation goals in summer when agricultural irrigation demand is at its maximum the upstream reservoirs filled with the contribution from the snow melt limit their releases to profit by higher electricity prices in winter this conflict has been exacerbated by the advent of renewables and particularly after 2009 when the italian government largely subsidized solar power production gse 2011 as a result hydropower production was extensively allocated to fill the sharpened electricity price peaks in winter further reducing summer releases even though most reservoirs were built after the 50s when downstream water rights were already in place hydropower companies are free to release at their discretion the result of this power asymmetry is exemplified by the dispute that arose during the extremely dry summers of 2003 2005 and 2006 on those occasions the regional authority imposed a forced release to the upstream hydropower companies in order to alleviate the drought conditions that were seriously threatening agricultural yields downstream riva 2010 the resulting hydropower revenue losses led to a court litigation and a judgment that finally granted damages to the companies at the expense of the regional authority anghileri 2014 similar events show how the current management configuration is unable to cope with increased climate uncertainty and weather extremes a recent study on the same area anghileri et al 2012 proved a central planner type of management dominates the current uncooperative global performance and suggests induced cooperation may be an effective and inexpensive adaptation measure for this application we consider a2a and enel companies which control more than 50 of the total upstream reservoir capacity as the upstream agents maximizing hydropower production red triangles in fig 2 and the adda consortium as the downstream agent whose local objective is ensuring adequate water supply flood protection is considered as a concurrent objective of the adda consortium but is then treated as a constraint assuming an historically acceptable threshold the regional water authority is the regulatory third party applying the hcm to the system 3 2 the system model the system model describes the operations of two upstream hydropower reservoirs run by a2a and enel companies respectively and lake como regulated by the consorzio dell adda we adopted a conceptual model assuming a 24 h decision time step while the hydropower price dynamic is modeled hourly the model was used to optimize the system operation under both uc and fc management configuration as detailed in section 2 2 the formulation of the objectives for each system component is given in the next paragraphs the lake dam operation as discussed in the above section the lake regulation aims at satisfying the two main objectives of flood control and water supply thus on the basis of previous works anghileri et al 2011 culley et al 2016 we formulate the following objectives computed over the evaluation horizon h flood control the annual average number of days day year when a flood occurs computed as 6 j f l o 1 n y t 0 h 1 g t 1 f l o where g t 1 f l o 1 if h t 1 h 0 otherwise where ht is the lake level ny is the number of years in the horizon and h is the flood level threshold equal to 1 24 m which determines the occurrence of a flood in como city water supply the average squared daily water deficit m3 s 2 computed as 7 j i r r 1 h t 0 h 1 g t 1 i r r where g t 1 i r r max w t r t 1 q e f 0 2 where wt is the daily water demand r t 1 is the release from the lake and qef is the environmental flow equal to 5 m3 s the square of the irrigation step cost accounts for crop vulnerability by penalizing higher shortages which are more likely to compromise the crop growth with respect to more frequent but smaller shortages which are less dangerous to the crops hashimoto et al 1982 hydropower reservoirs operation as a simplified version of the real system where a2a and enel combined operate four reservoirs and seven hydropower plants the model considers one equivalent reservoir and plant for each company the maximum flow qeq for an equivalent plant is set as the minimum between the maximum flows of each original plant and the equivalent energetic coefficient keq is the sum of the coefficient of the aggregated plants the model assumes that the daily energy produced by each plant at its maximum capacity is 8 g m k e q q e q 3600 in order to maximize their profit hydropower companies tend to release the maximum amount of water that can be generated by each plant qmax during the most profitable hours of the day according to the national electricity price pun determined by the italian energy market thus given the release r t 1 the number of functioning hours δ is uniquely determined for each plant as 9 δ r t 1 24 q m a x the aim of the operation for both a2a and enel is to maximize the yearly revenue therefore for each company c 1 2 we formulate the objective 10 j c h p 1 n y t 0 h 1 g t 1 c h p where g t 1 c h p g m c δ p e t 1 δ where p e t 1 δ is the sum of the first δ hourly energy prices for day t 1 3 3 experimental setting the experimental setting is characterized as follows optimization under uc and fc management scenario we modeled both the uncooperative and the fully cooperative policies assuming self interested agents maximizing their individual utility function i e individual rationality giuliani et al 2016b the uc solutions are the result of a two step procedure which first involves optimizing the upstream hydropower releases by two one for each hydropower company single objective problems i e problem 1 where j j c h p for enel and a2a respectively the release trajectories produced by the resulting policies are then set as inflows to the lake to solve a bi objective problem for lake como where j j f l o j i r r this procedure generates a set of uc solutions with varying flood irrigation trade offs the flood objective is later treated as a constraint to identify one single uc solution the fc solutions are obtained by solving problem 1 including all objectives at once in this case j j 1 h p j 2 h p j f l o j i r r this optimization produces a multi dimensional pareto front that is later sliced into a single plane by treating the flood objective as a constraint and considering j h p c 1 2 j c h p all problems are solved with the evolutionary multi objective direct policy search emodps method giuliani et al 2016a an approximate dynamic programming approach that combines direct policy search nonlinear approximating networks and multi objective evolutionary algorithms in particular we parameterized the operating policy as gaussian radial basis functions as they have been demonstrated to be effective in solving this type of multi objective policy design problems giuliani et al 2014a 2014b to perform the optimization we use the self adaptive borg multi objective evolutionary algorithm moea hadka and reed 2013 which has been shown to be highly robust in solving multi objective optimal control problems where it met or exceeded the performance of other state of the art moeas zatarain salazar et al 2016 each optimization was run for 1 million function evaluations over the evaluation horizon 2006 2014 the pun data we used refer to the period 2009 2015 because collected after the introduction of solar power subsidies and the economic crisis they are both internally homogeneous and able to reproduce the most recent winter price peak which is further challenging the upstream downstream relationship to improve solution diversity and filter out the randomness of both the initial population set and the optimization operators the solution set for each optimization is the result of 20 random optimization trials the final optimal policies for each experiment are defined as the set of non dominated solutions constraint design and application three dynamic minimum release constraints are designed for each of the two hydropower companies six in total a dynamic constraint is described by the pair minimum permitted release from a hydropower reservoir and associated lake storage the latter are discretized values the former are sampled from the release trajectories of three selected fully cooperative solutions fc 1 fc 3 and fc 5 for the two hydropower companies during the most critical months for irrigation august september anghileri et al 2012 typically a higher minimum release is associated with a lower lake storage the six constraints are then applied to the uc policies of each company during the agricultural season may september and evaluated over the simulation horizon 2006 2014 index based contracts design a setting the index since no historic revenue data is available we search for an index with high correlation to the historic energy production which can be drawn from the historic releases index correlation with the simulated historical revenues is also evaluated based on state of the art literature we evaluated the inflow to each of the two reservoirs a2a and enel s aggregated over different lag times weekly monthly seasonal and yearly the index with the highest correlation r 2 0 89 and 0 84 for a2a and enel respectively was the inflow volume over the hydrological year starting the 1st of april at the beginning of the snow melt season and reservoir recharge period alternative combined indexes including snow measurement the price of electricity and or the italian electricity demand were also evaluated but none of them produced a significant variation in r 2 correlation of the inflow volume over the current hydrological year with the simulated historical revenues confirmed the observed inflow power production correlations r 2 was 0 85 and 0 84 for a2a and enel respectively b defining the payout function we designed 8 insurance contracts i 1 8 each providing a different level of risk coverage the payout function parameters strikes and slopes are calibrated over the simulation horizon the strikes were set as percentiles of the index for the two companies in particular the strike s ranged from the 30th to the 70th percentile of the inflow in the insurance portfolio as in foster et al 2015 a fixed slope was computed as the ratio of average revenue in the contract period on average inflows c pricing the contract the wang transform method was used for pricing the contracts as described in section 2 3 as a commonly accepted value when pricing weather contracts foster et al 2015 kern et al 2015 wang 2000 we assumed a market price of risk value λ of 0 25 see eq 4 d timing we assume the hydrological year starts on the 1st of april at the beginning of the snow melt season while the yearly autocorrelation on the inflows was not relevant r 2 0 1 snow pack data available before the 1st of april are correlated to the next twelve months total inflow and therefore provides knowledge on the future payouts to avoid adverse selection and ensure that both the insurer and the insured have similar knowledge on future risks the execution date was set to precede the effective date of 5 months i e the 1st of october when most of snow deposition has yet to take place index based contracts evaluation the contracts adoption is simulated over the horizon 2006 2014 as well as over a 200 year synthetic inflow time series under three possible hcm agreements a a fully subsidized agreement where the water authority pays the entire premium for index based insurance covering both hydropower companies solution hca b a partly subsidized agreement where the water authority and the hydropower companies equally share the cost of the insurance premiums solution hcb c a non subsidized agreement where the hydropower companies contribute to the entire premium solution hcc the subsidized configurations hca and hcb are compared to a non insured scenario direct compensation the contracts are also evaluated through a series of financial metrics further detailed in appendix a synthetic time series the uncooperative and fully cooperative policies as well as the insurance mechanisms were also evaluated over a 200 year synthetic inflow time series to generate synthetic inflows to a2a and enel reservoirs and the residual inflow to lake como i e the inflow to the lake not influenced by the considered upstream hydropower reservoirs we used the k nearest neighbor knn algorithm nowak et al 2010 knn method is capable of generating a synthetic dataset that maintains the principal statistical characteristics of the historical data it is based on we first generated yearly spatially aggregated data through an annual ar 1 model and then disaggregated it in space and time based on the intra annual daily volumetric percentages observed in the historical record from the period 1996 2014 a different synthetic dataset generated from the same historic period was used for calibrating and validating the contracts 4 results 4 1 uc and fc policies identification the uncooperative and fully cooperative policies are modeled as detailed in section 3 3 results are displayed in figs 3 and 4 given the geographic system configuration the two equivalent hydropower reservoirs are always operated without interfering with each other this implies that even in the fully cooperative case their objectives are never conflicting therefore in our analysis the hydropower objective jhp aggregates the yearly revenues of the two hydropower companies moreover as mentioned in section 3 3 the flood objective is considered both in the uc and the fc optimization but is later treated as a constraint in order to better investigate the water supply hydropower trade off to this end we assumed the historically accepted threshold of about 6 days of flood in a year fig 3 compares the fully cooperative and uncooperative solutions on the same jhp vs jirr space which lies on the plane jflo 5 8 days year as expected the fc pareto front which is the performance of the pareto optimal set covers different alternative upstream downstream trade offs while the uc solution represents one of the extremes which maximizes the hydropower objective at the expense of the downstream water supply goal this result exemplifies the system power asymmetry these solutions are obtained from two separate optimization efforts one for the uc and one for the fc case which are presented in fig 4 panel 4a shows the performance of the pareto efficient fc alternatives fci the fc optimization solves a problem with four objectives j j 1 h p j 2 h p j f l o j i r r here we aggregated the non conflicting hydropower revenues of the two companies j h p c 1 2 j c h p to show a three dimensional pareto front the arrows indicate the direction of preference ideally we search for a solution minimizing the irrigation deficit horizontal axis and the yearly number of floodings vertical axis also indicated by degrading colors and bigger dimension for higher values while maximizing the hydropower revenue lateral axis not surprisingly we observe that the water supply hydropower trade off is less and less evident when the conditions on the flood objective are relaxed in other words reducing the conflict between the two objectives of the downstream agent enlarges the space for compromise solutions upstream and downstream this result indicates that if the lake regulation s only target was water allocation the downstream water demand would be satisfied almost independently from the hydropower releases therefore we selected the set of centralized solutions f c 1 5 equally performing with respect to the flood objective on the plane jflo 5 8 days year depicted in yellow in fig 4 which represents an historically acceptable value panel 4b shows the performance of the pareto efficient uncooperative alternatives as mentioned the value of the hydropower objective jhp aggregates the result of two independent single objective optimizations for this reason all uc solutions performance rests on the same plane depicted in yellow in fig 4 defined as j h p 1 483 10 8 year similarly to f c 1 5 the selected uc solution is the one satisfying the assumed condition on the flood objective of 5 8 days per year 4 2 dynamic minimum release constraints three dynamic minimum release constraints are derived from three fully cooperative solutions exploring different trade offs between hydropower production and water supply as described in section 2 2 for each hydropower company we considered the release trajectories of alternatives fc 1 fc 3 and fc 5 fig 5 shows the three constraints derived for company a2a in ascending order of severity each constraint is represented by the coupled values of minimum release and lake storage as sampled from the corresponding fci trajectory as can be noted from the plots in a fc solution a lower storage always implies a larger minimum release on the other hand a fc solution with a higher preference for irrigation benefits i e fc 1 over fc 3 over fc 5 produces a constraint that is active for higher lake storage values and requires larger release volumes fig 6 a depicts the simulated performance for both companies of the uc policy under the three constraints averaged over the evaluation horizon 2006 2014 i e cc 1 cc 3 and cc 5 the average yearly effect of the constraints is a general decrease in hydropower revenues the most severe constraint cc 1 leads to a revenue loss of 1 8 106 year equivalent to 1 2 of the yearly average revenue on the other hand the water supply deficit is reduced by 3 3 the effects of cc 3 and cc 5 are less evident leading to a jirr improvement of 0 9 and 0 1 respectively and smaller revenue losses 0 4 and 0 1 it is worth mentioning that despite these constraints negatively impact on the self interested hydropower operations producing significant revenue losses to the two companies the effect of these direct measures in terms of energy production is fairly negligible the yearly average revenue variation may not appear very large however if we consider the effect of the constraint on each year revenue panel 6b we can observe a significant change hydropower production is naturally prone to supply risk a form of financial risk linked to the availability of the supply source i e water and aggravated by hydrologic uncertainty the application of forced releases that are triggered by dry conditions downstream is likely to exacerbate such a financial risk for hydropower companies in dry years as a result we expect the constraints to cause a revenue loss whenever the inflow volume and its timing do not allow for both satisfying the imposed rule and optimizing power generation however the minimum release constraint can lead to higher hydropower revenues in wet years this positive difference is due to the stochastic optimization we used for designing the hydropower policy which in the presence of inflow uncertainty prefers to act conservatively and release less water to avoid the risk of emptying the reservoir however in wet conditions it would have been possible to release more and hence produce more as future higher than expected inflows are able to refill the reservoir the constraint is by chance forcing some releases in these days ultimately producing higher revenues the yearly mean value levels out the effect of the constraint since it averages both positive and negative variations panel 6 b exemplifies this concept by showing the effect of the forced release cc 1 on a2a revenues over the horizon 2006 2014 both 2006 and 2007 were fairly dry years nevertheless in 2006 the storage is enough to comply with the minimum release rule while still allocating water to the most profitable hours during the rest of the year however the effect of the constraint over the next two years results in a cumulative loss of about 21 million the next years illustrate a similar pattern with alternating wet dry conditions determining different and sometimes significant positive or negative financial outcomes the effect of the constraints on the two companies is similar though it is a lot less visible for enel which manages smaller water volumes 4 3 index based contracts to contrast the variability in revenue losses induced by the constraint we apply the 8 different index based insurance i 1 8 designed as described in section 3 3 to the cci solutions the effect of financial risk instruments is typically more evident when observing the revenue trajectories over a long time series as short time series have a high variance and therefore they show larger deviations from the mean i e the expected damage used to define the premium fig 7 shows both the revenue trajectories of the uninsured alternative cc 1 blue line and the insured alternative hcb red line for company a2a and contract i 2 this contract was chosen for this particular company and constraint combination because it provides the highest risk mitigation level for the lowest marginal cost for a detailed comparison see appendix a as a direct consequence of adopting a risk mitigation measure revenues are less vulnerable to the hydrologic uncertainty the red trajectory is visibly more constant the negative peaks are smothered by the large payouts received on dry years green areas in fig 7 while the yearly premium reduces the positive peaks red areas however the risk of a low or very low revenue due to scarce inflow i e supply risk is borne by the insurance company thus largely improving the worst case performance or revenue floor the red dashed lines in fig 7 these observations hold true for all designed contracts and independently from who will contribute to the insurance premium the last step of our methodology see fig 1 requires the adoption of a financial measure able to guarantee the constraint acceptability and the transition to a new equilibrium outcome therefore we simulated the adoption of different index based contracts under a fully subsidized hca a partially subsidized hcb and a non subsidized agreement hcc this approach is highly adjustable e g different levels of subsidies and contract combinations can be adopted therefore allowing for a flexible and negotiable measure fig 6a shows the performance of the three alternative hc agreements hca hcb and hcc under contract i 2 and constraint cc 1 over horizon 2006 2014 in yellow in all cases the companies receive a payout from the insurance whenever the index insurance is triggered by low inflow conditions i e yearly inflow volume lower than the s threshold it is relevant to note that the index which triggers the payout is decoupled from the conditions activating the constraint i e downstream storage values for each agreement scenario the resulting shift in yearly revenue performance is a combination of the received payouts and the respective premium share that is paid to the insurance company since yearly premiums are designed to exceed the expected payout value i e the loading principle solution hcc produces a negative shift in yearly revenue performance while a positive shift is observed when the regional water authority contributes to the premium solutions hca and hcb one should consider however that yearly revenue represents only one of the primary goals of hydropower companies which may include financial stability as well considered in this light solution hcc could still be a valid alternative to a non insured scenario cc 1 especially for mitigating the impacts of extreme events the jhp performance associated to hca and hcb exceed the uc solution by 4 7 and 0 29 million respectively in these cases the water authority has internalized the costs by contributing to the total insurance premium 8 9 million under hca or half of it under hcb these are just three possible agreement examples we can anticipate the final arrangement to emerge from a bargaining process possibly involving additional incentives e g license granting and being fine tuned to account for contingencies 4 4 comparison to a direct form of compensation subsidized index based contracts proved to be effective in restoring the hydropower revenues to the uc conditions the cost for the water authority could be contributing to paying the insurance premiums in full hca or in part an alternative form of compensation directly covering the revenue losses induced by the minimum release constraints has the main drawback of depending on uncertain hydrology and of being highly variable from year to year i e high financial risk fig 8 compares the costs for the water authority of solutions hca hcb i e the entire premium or half of it indicated by the red dashed lines with the direct compensation of constraint cc 1 for company a2a the brown negative bars in this case it is evident how the insurance solution i 2 offers compensation at more constant deferred prices maximum yearly cost is about 6 8 million for hca and 3 4 million for hcb compared to a maximum direct compensation cost of 15 9 million which is usually preferable and more practicable but generally at a higher average cost the yearly average cost is equal to the maximum average cost for both hca and hcb compared to an yearly average direct compensation cost of 4 9 million in this case the agreement hcb also provides for a cheaper alternative for the water authority this conclusion however is not equally straightforward or generalizable to other combinations of constraint company and contract the main reason for this is that while direct compensation varies according to the constraint the insurance premium is essentially independent of it in the case of enel which is less affected by the constraints than a2a a direct compensation may be the cheaper solution for the water authority on the other hand the hydropower companies are likely to prefer an indirect financial solution given the additional benefits offered by index based contracts reduced revenue fluctuations increased revenue floor this fact together with the high flexibility of insurance contracts could lead to fine tuned agreements between the water authority and the hydropower companies e g a different premium share combination 5 conclusion in power asymmetric water systems where the absence of reciprocal interdependency hinders a balanced water rights distribution cooperative actions may be induced via positive linkages e g side payments dinar 2006 mitchell and keilbach 2001 however practical and financial issues arise when the magnitude and timing of these payments depend on hardly predictable conditions e g future hydrology in this paper we propose the use of index based insurance contracts to mitigate the financial risk associated with uncertain side payments and concurrently provide a flexible tool for sharing externalities in a power asymmetric river basin more in detail we designed a hybrid cooperation mechanism to foster collective action in a water system with multiple agents characterized by geographic power asymmetry the approach is demonstrated in the lake como system where the upstream hydropower companies are granted licenses to freely release their stored water in time irrespective of the timing of downstream users demands in this context the intervention of a regulatory third party i e the regional water authority can enforce more balanced solutions the direct part of the hcm is a dynamic minimum release constraint imposed over upstream releases that is based on the downstream agent policy i e the lake storage this measure is able to improve downstream performance up to 3 3 by introducing a mutual upstream downstream relationship conversely the yearly hydropower revenue is reduced up to 1 2 on average however because it largely depends on hydrology this loss pattern displays relevant inter annual fluctuations with dry years resulting in significant revenue losses the constraint acceptability is therefore addressed by an instrument able to manage this variability an index based insurance contract which constitutes the indirect component of the hcm we have considered the cost of a similar measure for the regional authority under totally and partially subsidized premium agreements and observed that depending on the given case weather derivatives may provide a cheaper alternative with respect to a direct compensation however we should consider that the insurance would also provide further benefits to the hydropower companies financial stability in the form of supply risk mitigation and revenue floor improvement for this reason it is likely this solution would be preferred by the hydropower producers who may be willing to bear a substantial part of the premium this latter case is also preferable because it would further incentivize the companies to modify their release policies in order to adapt to the constraint and reduce its impact on their revenues finally contributing in paying the insurance premium might be an important aspect to be included in the incoming renegotiation of the water rights of the hydropower companies we consider the proposed hybrid approach to be readily transferable to larger and more complex systems similarly affected by geographic power asymmetry e g the zambezi gandolfi and togni 1997 giuliani and castelletti 2013 tilmant et al 2010 2012 and the euphrates tigris altinbilek 2004 kibaroglu and ünver 2000 moreover the use of insurance contracts as bargaining tools is applicable to many other different other contexts especially when a newly imposed condition is expected to generate a financial risk which is borne by only one party to the negotiating process future research efforts will focus on exploring alternative mechanism especially the possibility of introducing financial coverage for the downstream farmers yet this implies the adoption of a distributed model in space and time for the downstream users able to take into account the different crops with their phenology the resultant agricultural production and farmers revenues li et al 2017 this model would also allow comparing the premium paid by the hydropower companies or the regional authority with respect to the gain in terms of agricultural profit to conclude financial hedging tools offer a reliable and practicable alternative to favor a more balanced and politically acceptable management of multi purpose water systems characterized by power asymmetry such finding is relevant especially in times where granting of licenses is often being reviewed to include environmental protection and equity issues acknowledgment this work was partially supported by the sowatch project funded by fondazione cariplo grant number 2015 0220 appendix a weather derivatives evaluation to evaluate a contract many aspects have to be considered a risk mitigation tool provides a strategy for reducing inter annual variability and hedge large damages but the desired level of coverage depends on many factors including the buyer loss and risk aversion for this reason we considered a series of diverse measures to assess the index based portfolio designed for lake como case study the values for the designed insurance contracts i 1 8 are shown in table a 1 the first values to weigh are the contract premium p the expected payout e p and their difference or loading l the loading percentage on the expected value of payouts is particularly informative on the existing trade off between premium and loading concurrent minimization in fact the contract loading increases as the variance of a payout distribution grows if the strike value s is intended to cover the insured from the low frequency big events the contract loading will be high on a small premium on the other hand high frequency small events would be covered by insurances with a lower loading and a higher premium to compare the contracts with different strike levels the contract cost i e the portion of the premium that is not actually returned to the buyer in the form of payouts over the contract period is evaluated and expressed as a percentage on the yearly average revenue r a 1 c o s t p p r higher strikes provide a better coverage for a higher cost the already mentioned revenue floor is expressed in terms of risk mitigation level rml the ratio of minimum revenues r with and without insurance a 2 r m l min r i n s u r e d min r u n i n s u r e d it is also interesting to evaluate the revenue fluctuation computed as the standard deviation of the revenue throughout the whole period this metric is able to reflect the uncertainty related to the yearly hydropower income as already noted in fig 7 risk mitigation measures provide reduced revenue uncertainty and more constant income at the expense of a yearly premium the higher the value s the more pronounced the effect on variability in order to choose a contract for our application on company a2a and alternative cc 1 we considered the regional water authority point of view which is to find the cheapest alternative for mitigating the losses induced by the dynamic minimum release constraint taking into account the average yearly induced losses about 4 9 million a low coverage is appropriate to provide full compensation in this specific case we opted for the contract i 2 which offers the highest marginal rml for the lowest cost 
839,we model the subsurface hydrologic response to the 7 6 mw subduction zone earthquake that occurred on the plate interface beneath the nicoya peninsula in costa rica on september 5 2012 the regional scale poroelastic model of the overlying plate integrates seismologic geodetic and hydrologic data sets to predict the post seismic poroelastic response a representative two dimensional model shows that thrust earthquakes with a slip width less than a third of their depth produce complex multi lobed pressure perturbations in the shallow subsurface this leads to multiple poroelastic relaxation timescales that may overlap with the longer viscoelastic timescales in the three dimensional model the complex slip distribution of 2012 nicoya event and its small width to depth ratio lead to a pore pressure distribution comprising multiple trench parallel ridges of high and low pressure this leads to complex groundwater flow patterns non monotonic variations in predicted well water levels and poroelastic relaxation on multiple time scales the model also predicts significant tectonically driven submarine groundwater discharge off shore in the weeks following the earthquake the predicted net submarine groundwater discharge in the study area increases creating a 100 fold increase in net discharge relative to topography driven flow over the first 30 days our model suggests the hydrological response on land is more complex than typically acknowledged in tectonic studies this may complicate the interpretation of transient post seismic surface deformations combined tectonic hydrological observation networks have the potential to reduce such ambiguities 1 introduction 1 1 hydrologic effects of earthquakes earthquakes have long been known to produce a range of hydrological effects from short term responses such as liquefaction and eruption of mud volcanoes to long term changes in ground and surface water geochemistry temperature and pressure manga and wang 2007 miller 2012 wang and chia 2008 wang and manga 2010 in the near field within a few rupture lengths of the earthquake the hydrological effects are due to both static and dynamic stress changes while only dynamic stress changes can induce hydrologic responses over greater distances brodsky 2003 rojstaczer et al 1995 here we are interested in the hydrologic response to subduction zone earthquakes given their large rupture zones static stress changes extend over hundreds of kilometers the co seismic subsurface hydrologic response in the near field is often well correlated with the static poroelastic stresses akita and matsumoto 2004 quilty and roeloffs 1997 shi et al 2013 wakita 1975 near field post seismic transients in pore pressure surface deformation and fluid flux consistent with poroelastic behavior have been observed in various settings fialko 2004 jonsson et al 2003 labonte et al 2009 peltzer et al 1998 these observations suggest that the regional groundwater flow induced by quasi static stress changes is an important component of the hydrologic response to large subduction zone earthquakes while the complex effects of earthquakes on ground and surface water have received considerable attention mohr et al 2016 shi et al 2015 much less is known about the potential submarine groundwater discharge sgd associated with tectonic stresses this expulsion of fluids through the seafloor is expected from previous modeling studies given the compression of the forearc during subduction and due to thrust faulting events zhou and burbey 2014 such tectonic fluxes have been observed along the costa rica margin subduction zone due to compaction of pelagic sediments on the down going plate and compression from slow slip events near the trench labonte et al 2009 screaton and saffer 2005 these sgds occur in deep water close to the subduction trench shallow sgd near the coast has also been studied primarily due to its effect on the chemistry of the coastal ocean moore 1996 slomp and van cappellen 2004 this type of sgd derives in part from topography driven flow in aquifers that drain directly to the coast and are expelled close the shoreline sawyer et al 2016 as part of this study we investigate the possible impact of a large earthquake on the location and magnitude of sgd we use fully coupled poroelastic models to study tectonic driven sgd for a large subduction zone earthquake in costa rica that occurred beneath the nicoya peninsula in 2012 we have chosen this event because of the unique location of the nicoya peninsula above the slipping portion of the subduction zone interface this together with a dense network of high rate global positioning system gps stations provides excellent constraints on the co seismic deformation driving the groundwater flow however due to the absence of transient hydrological monitoring it is not possible to validate the predicted hydrologic response the aim of this manuscript is therefore to investigate the basic features of the large scale poroelastic relaxation following the 2012 costa rica earthquake to determine the significance of the tectonically driven groundwater flow we compare it to the standard model of topography driven flow both models have identical material properties and geometry but have different boundary conditions discussing the tectonic flow relative to the topographic flow mitigates the effect of highly uncertain parameter values such as the permeability 1 2 costa rica and the 2012 mw 7 6 earthquake along the pacific coast of costa rica the oceanic cocos plate derived from the east pacific rise and cocos nazca spreading center subducts along the middle america trench mat with a velocity of 8 5 9 cm yr demets et al 2010 feng et al 2012 as shown in fig 1 a the resulting volcanic arc extends from central costa rica north into mexico in the south the mat extends to the panama fracture zone a transform fault separating the cocos and nazca oceanic plates the suture within the cocos plate subducts directly beneath the nicoya peninsula on the northern side of this suture zone smoother older oceanic crust 25 30 ma derived from the east pacific rise is being subducted on the southern side slightly younger sea floor derived from the cocos nazca spreading center subducts underneath costa rica deshon et al 2006 on september 5 2012 a magnitude 7 6 earthquake ruptured the plate interface beneath the nicoya peninsula costa rica the epicenter was located 12 km offshore from the central nicoya coast at a depth of approximately 18 km fig 1 b the rupture spread outward along the plate interface to encompass 3000 km2 of the nicoya seismogenic zone yue et al 2013 the nicoya peninsula is positioned over the seismogenic zone of the subduction plate interface thus surface deformation measurements provide reliable information about deformation on the slab interface fig 1 b shows contours of the slip estimated from a combination of 21 campaign gps stations and 18 continuous stations deployed on the nicoya peninsula protti et al 2013 2 model setup 2 1 governing equations and boundary conditions to model the instantaneous and time dependent poroelastic response to the earthquake we use a fully coupled linear poroelastic model the slip distribution of the earthquake on the fault plane is applied as a boundary condition yue et al 2013 which initializes the co seismic pressures and displacements this instantaneous undrained response evolves as the pore pressure equilibrates the linear poroelastic theory developed by biot provides a system of equations that describes the coupling between the flow of pore fluids and the deformation of the rock matrix wang 2000 the governing equations combining the conservation of fluid mass for the evolution of pore fluid pressure p p x t and total momentum conservation of the porous medium for the quasi static solid displacement u u x t in a domain ω over the time interval 0 t are given by 1a s ϵ p α u t κ μ p 0 in ω 1b σ u α p i 0 in ω where t denotes the time derivative s ϵ is the specific storage κ x is the permeability μ is the fluid viscosity and α is the biot willis parameter in an elastic medium the stress tensor σ is related to displacement as follows 2 σ u g u u t g 2 ν 1 2 ν u where g and ν are the elastic shear modulus and drained poisson s ratio respectively the biot willis parameter α and the specific storage coefficient s ϵ can be written in terms of the elastic parameters as α 3 ν u ν b 1 ν u 1 2 ν s ϵ 3 α 1 2 ν 1 α b 2 g b 1 ν where b is skempton s pore pressure coefficient and ν and νu are the drained and undrained poisson s ratios respectively the poroelastic eq 1 require four independent material parameters to describe the undrained response as well as the magnitude of the relaxation ν νu g and b representing the drained poisson s ratio the undrained poisson s ratio the elastic shear modulus and skempton s coefficient respectively two additionally parameters κ and μ control the transient behavior of the pore fluid the models for the poroelastic response to an earthquake and topographic driven flow have different sets of boundary conditions the primary difference between the earthquake driven and topographic driven models is the pressure boundary condition on the land surface in the case of the earthquake driven flow the boundary representing the land surface is set as a no flow boundary condition the limitations of which are discussed in section 4 2 for the topographic flow model the land surface boundary is set with a spatially varying pressure field equal to a smooth subdued expression of the land surface representing the water table the boundary and initial conditions for the earthquake driven model are 3a p 0 u 0 0 in ω 3b p 0 on γ o c e a n 3c κ μ p n 0 on γ n o t o c e a n 3d σ u n 0 on γ s u r f a c e 3e u n 0 on γ r i g h t γ b o t t o m 3f u n 0 on γ s l a b 3g δ σ u n t u t u 0 on γ s l a b for the case of topographic driven flow the initial and boundary conditions are 4a p 0 u 0 0 in ω 4b p 0 on γ o c e a n 4c p p t o p o on γ l a n d 4d κ μ p n 0 on γ n o t s u r f a c e 4e σ u n 0 on γ s u r f a c e 4f u n 0 on γ r i g h t γ b o t t o m 4g u 0 on γ s l a b in both cases the overlying ocean applies a hydrostatic pressure at the seafloor which results in a zero pressure boundary condition as p represents the deviation of the pressure from hydrostatic our model ignores the effects of tides on the ocean bottom pressure due to the much shorter spatial and temporal scales on which tide induced pressure signals propagate into the seabed all other boundaries including the one representing the land surface are set as no flow boundaries the normal stress on both the ocean and the land surface is set to zero to allow for surface deformation on the slab interface the displacement is assumed to be only in the tangential directions and is prescribed by the inversion of geodetic data the magnitude of which is shown in fig 1b the vertical boundary opposite of the trench and the bottom boundary are set as roller boundaries to prevent a net rotation of the domain the mathematical formulation of these boundary conditions is given in appendix 1 2 2 model geometry the three dimensional 3d model surface comprises an area of 250 km by 250 km aligned with the trench and extending into the overriding continental plate the location of the model is shown on the map in fig 1a all locations and displacements are rotated into a trench perpendicular and trench parallel coordinate system the 3d model geometry in shown in fig 2 a and the trench perpendicular cross section used for the two dimensional 2d model is shown in fig 2b a simplified coastline is integrated into the mesh and divides the top boundary of the domain into two surfaces the seafloor is defined as a linear slope from the coast at 0 km depth to the trench at 4 km depth while the land topography is neglected the fault interface boundary of the model is fit to the smooth interface derived from seismic tomography and is assumed constant in the trench parallel direction deshon et al 2006 the model domain is truncated at 60 km depth in both 2d and 3d it is necessary to resolve the near surface such that the permeability decay with depth fig 3 a is adequately captured by the mesh in 2d this can be done with an unstructured tetrahedral mesh with an element size of 200 m at the surface and 3 km at depth resulting in approximately 60 000 elements in 3d this is done with an extruded layered mesh from 0 5 km depth comprising of 4 layers that increase in thickness with depth from 300 to 1 500 m overlaying an unstructured tetrahedral mesh with 3 4 km element size this allows the model to capture the permeability decay without meshing to a 300 m resolution in the x and y directions the 3d mesh contains approximately 140 000 elements we use a direct solver and only rebuild the factorization when the timestep changes to efficiently capture both rapid short term and slow long term behavior the timestep progresses from 15 min to one month all of the models were run on a workstation with run times ranging from 1 to 30 h the limitation on the number of elements used is the memory required to store the factorization 2 3 integration of field data the six parameters of the poroelastic model described above vary both laterally and with depth and potentially over many orders of magnitude they should therefore ideally be constrained by field data below we describe how parameter values throughout the domain have been derived from regional seismic and hydrogeologic data 2 3 1 elastic parameters and initial slip condition it is increasingly recognized that the spatial variation of the elastic parameters has a significant influence on the predicted co seismic displacements masterlark et al 2001 williams and wallace 2015 the elastic parameters of the model are constrained with vp vs seismic tomography data along with a 1d density model to create best fit functions that represent how the various elastic parameters change with depth deshon 2004 deshon et al 2006 fig 2b shows how the tomography derived shear modulus g varies within the domain the young s modulus is calculated from p wave velocity and density the p wave velocity vp and the bulk density ρb depth profile are used to calculate the p wave modulus m with depth using m ρ b v p 2 the p wave modulus and drained poisson s ratio ν are then used to derive the young s modulus e depth profile using the relationship e m 1 ν 1 2 ν 1 ν three parameters for a power function of the form e z a z b c were fit to the relationship between young s modulus and depth resulting in a best fit function of e 3 471 z 10 2 0 5157 5 324 10 4 where z is the depth in meters and e is given in mpa the shear modulus g used in the poroelastic equations is derived from young s modulus and poisson s ratio using the relationship g e 2 1 ν the slip boundary condition to drive the model is obtained by inverting the co seismic displacements measured by a network of gps stations here we use the co seismic displacements to infer slip on the overridding plate of the subduction interface the contour map of the slip solution is shown in fig 1b the co seismic horizontal surface displacement vectors at gps station locations from both gps measurements and the forward model are shown in appendix figure fig a 1 2 3 2 hydrogeologic data the timescale over which fluid induced deformation takes place is controlled by the three dimensional permeability field our model considers the variations in permeability that occur on two different length scales a general decline of permeability with depth on the crustal scale and large variations that occur over short lateral distances in the relatively permeable shallow crust on the crustal scale the permeability κ decreases exponentially with depth d z from the high permeability κs near the surface to the low residual background permeability lower in the crust κr as shown in fig 3a we use the parameterization of kuang and jiao 2014 given by 5 log 10 κ log 10 κ r log 10 κ s κ r 1 d a where a 0 8 is the dimensionless decay index we assume that κr is constant but allow κs to vary laterally as shown in fig 3b to constrain the surface permeability field κs of the study area we obtained pump test results of 520 groundwater wells from senara located throughout the state of guanacaste costa rica see si the pump test results were interpreted in terms of the transmissivity of the aquifer t if the aquifer thickness b is known the hydraulic conductivity is given by k t b here we assume that b is equal to the reported well depth this assumption tends to overestimate k if the well does not penetrate the entire depth of the aquifer the permeability required for 1a is given by κ k μ ρ g where ρ is the density of the pore fluid and g is the acceleration of gravity the permeabilites obtained this way should be seen as upper bound because of our assumption that the wells penetrate the entire aquifer the well data were interpolated using a kriging toolbox murphy 2014 in areas on land not covered by the well data the permeability reverts to the mean permeability of the well data set in absence of data about the spatial variation of seafloor permeability we assume it is constant and choose a value of 10 13 m2 based on previous studies becker and davis 2004 davis and villinger 2006 spinelli et al 2004 the resulting permeability map is shown in fig 3b the northwest and central portions of the nicoya peninsula have generally higher surface permeabilities whereas the southern and inland portions have much lower permeability comparison with the geological map in fig 3c shows that high permeability areas often associated with quaternary alluvial sediments while low permeability areas are primarily sea floor basalts the kriging variance in fig 3d shows that the permeability is highly uncertain away from the well data this is due to the short correlation length of the data evident from the semivariogram of the data in fig 3e for the kriging interpolation we have assumed an exponential variogram model with a nugget sill and range of 0 771 1 086 and 1 28 104 m respectively there is currently no well monitoring system in place of the nicoya peninsula therefore no quantitative records of the head changes during and after the earthquake exist however qualitative description of the response at an individual location has been reported and is discussed below 3 results for this study we used both 2d and 3d numerical models in section 3 1 we investigate more general trends in the poroelastic response in a 2d model of a subduction zone earthquake given different earthquake sizes and crustal permeability structures section 3 2 presents results of a 3d model results based on a fixed set of best fit parameters and the real earthquake slip data 3 1 two dimensional model results in order to gain a better understanding for which factors control both the co seismic and post seismic poroelastic response to a large earthquake we ran a number of simpler models in 2d the geometry is based on a representative trench perpendicular cross section through the center of the nicoya peninsula and the slip patch fig 2 these models use a constant surface permeability but retain the variation of permeability and young s modulus with depth first we discuss the geometry of the co seismic undrained elastic response in section 3 1 1 followed by a discussion of the time scales of the post seismic poroelastic relaxation in section 3 1 2 3 1 1 effects of earthquake size and depth on the undrained response to study the 2d instantaneous response to a subduction zone earthquake we use a synthetic gaussian slip distribution for a gaussian slip centered at a depth of 20 km with a rupture width of 100 km the co seismic displacement and the undrained pore pressure response are shown in fig 4 a and b respectively for a gaussian slip distribution the rupture width is defined as 4σslip where σslip is the variance of the gaussian function the simulation shows the expected increase in pore pressure due to compression of the forearc and decrease due to extension in the interior this simple pattern is observed when the width of the slip patch is large relative to the earthquake depth in this case pore pressure increases trenchward of the earthquake primarily offshore and decreases behind the earthquake on land however earthquakes with a smaller slip area relative to their depth produce a more complex pattern in co seismic displacement and the undrained pore pressure response fig 4c and d in the far field the pattern is similar but directly above the earthquake two additional pressure lobes appear near the surface a similar pattern of the instantaneous pore pressure field in response to a thrust earthquake was described in zhou and burbey 2014 fig 5 shows that the undrained pore pressure pattern is primarily a function of the ratio of slip extent to earthquake depth the four lobed pattern is observed when the slip width to depth ratio is equal to or less than three the elastic parameters have a very small effect on this geometry but if the young s modulus increases drastically with depth the pattern trends toward the simple two lobed case this four lobed pattern is conspicuous in the pore pressure response but is less obvious in the surface displacement fig 6 shows that the local pore pressure maximum is accompanied by some subsidence and a decrease in the magnitude of the trenchward displacement the local decrease in the amount of trenchward displacement results in an area directly above the earthquake that experiences less net displacement which results in local landward compression and trenchward expansion for earthquakes with small slip width to depth ratios fig 4c these local high and low pressure lenses dominate the local near surface hydrologic response displacement data from the nicoya peninsula projected onto the cross section show a pattern consistent with four lobed pressure response fig 6 the undrained pressure field sets up regional groundwater flows that relax the pressure gradients over time the timescale of the hydrological response is determined by the near surface permeability and mass specific storage in the 2d model the permeability only varies with depth and remains constant across the surface this allows us to look at the effect of different surface permeability values on the time dependent pore pressure response without the added complication of large scale preferential flow paths present in the 3d model to study the time dependent hydrological response we perform a 2d simulation with a slip distribution that is a gaussian approximation of the 2012 nicoya event a surface permeability of 10 11 m2 and a skempton s coefficient of 0 7 the undrained pressure distribution and the transient well head h p ρ g response at various locations on the surface are shown in fig 7 the slip width to depth ratio of the main slip patch of the 2012 nicoya event is approximately 2 1 and hence results in a four lobed instantaneous pore pressure response in the shallow crust 3 1 2 time dependent hydrological response the signature of the transient pore pressure relaxation after the earthquake varies significantly with distance from the trench fig 7 the response differs from what might be expected because the head response is complicated by the four lobed pattern that leads to a local head maximum above earthquake first we will discuss the change in the well response with distance from the coast and then consider the effect of the near surface permeability very close to the coast fig 7a shows an instantaneous rise followed by in most cases a drop below pre earthquake levels just two kilometers inland fig 7b shows a co seismic head drop followed in most cases by a continued decrease and then a recovery in the low pressure regions close to the coast and far inland fig 7c and f an instantaneous head drop is followed by a monotonic recovery in the center of the high pressure lens fig 7d an instantaneous head increase is followed by a monotonic relaxation to a head sometimes below the pre earthquake level the wells in the transition zones between high and low pressure regions show markedly different patterns of transient well response behind the high pressure lens a co seismic head drop is followed either by a recovery and drop or a small drop and recovery fig 7e the initial well response is due to the dissipation of the four lobed pressure pattern within the first twenty days after the dissipation of the local pressure maximum above the earthquake the entire onshore region is under pressured compared to pre earthquake pore pressures this induces a slow landward regional groundwater flow from the overpressured section offshore while well levels close to the coast recover quickly fig 7a the recovery further inland fig 7f may take months to years fig 7 also illustrates the effect of variations in surface permeability on the transient well head response fig 7c shows the expected delay in recovery with decreasing permeability however fig 7e shows that variations in permeability can also lead to fundamental changes in the pattern of well head response this particular well changes from a non monotonic head response to a monotonically decreasing response as the permeability decreases both panels illustrate that the instantaneous response is independent of permeability 3 1 3 submarine groundwater discharge sgd the offshore compression due to the earthquake leads to the expulsion of significant amounts of pore water through the seafloor it is interesting to compare this discharge to continuous sgd driven by topography and compression by subduction topography driven flow assumes that the water table is a subdued expression of the surface topography cherry and freeze 1979 toth 1962 and provides a simple estimate for the shallow environmental flows in the hydrological cycle gleeson et al 2015 sawyer et al 2016 an estimate of the topography driven sgd is shown in fig 8 a the representative cross section through the nicoya peninsula shows two mountain ranges separated by a central valley the elevated pressures underlying the topographic highs induce flows down gradient into the valleys and out to sea the insert of fig 8a shows the details of the flow field near the surface the streamlines illustrate that groundwater flow occurs in is confined to the upper most 500 m the sgd due to this shallow topography driven flow is therefore localized in the first few hundred meters off the coast assuming the water table varies between 25 and 75 of the land surface topography the total sgd per unit width is between 2000 6000 m3 m yr additionally subduction of the oceanic plate compresses the toe of the overriding plate and produces sgd on the order of 100 m3 m yr primarily near the trench the pattern of tectonic driven sgd differs significantly from the topography driven sgd following an earthquake compression offshore leads to sgd along most of the seafloor between the coast and the trench fig 8b unlike the topographic flow which induces mostly horizontal flow the tectonic driven flow is mostly vertical the total flux through the seafloor immediately following the earthquake is four orders of magnitude greater than the topographic flux fig 9 the tectonic contribution to sgd remains greater than the topographic contribution for approximately 3 months following the earthquake and remains elevated for a number of years the tectonically driven sgd due to smaller events such as slow slip events have been previously detected by fluid flux measurements offshore the nicoya peninsula jiang et al 2017 labonte et al 2009 our simulations show that that large events are likely to induce similar flows that significantly change the pattern and magnitude of sgd in the months following an earthquake 3 2 three dimensional model results the two dimensional results presented above are instructive but they lack the complex slip distribution of the earthquake and the spatial heterogeneity of permeability in the upper crust to address these effects we conduct a three dimensional simulation incorporating all of the available data to constrain the earthquake geometry and poroelastic parameters whereas the 2d model was used to investigate the effects of different parameters on the instantaneous and time dependent responses the 3d model uses a single set of best fit parameters for the nicoya peninsula and the 2012 earthquake table 1 summarizes the model parameters and the data used to constrain them unlike the 2d model where the slip distribution was assumed to be gaussian the 3d model incorporates the realistic slip distribution shown in fig 1b the most prominent feature of the instantaneous hydrologic response are the trench parallel ridges of high and low head in the shallow subsurface fig 10 a there are two possible reasons for this pattern 1 the width to depth ratio of the main slip region or 2 the horseshoe pattern of the slip distribution the pattern of high and low head changes on land occurs directly over the main slip patch of the earthquake the secondary slip area near the trench is too far away to affect the onshore subsurface head response the width of the main slip patch of the nicoya earthquake is 40 km fig 1b and the depth of the epicenter is 18 km the slip width to depth ratio is therefore less than 3 1 suggesting that this multi lobed head response in fig 10a d is the 3d manifestation of the modeled 2d response for earthquakes with small slip width to depth ratios fig 4c d while no formal well monitoring system is in place on the nicoya peninsula a well located at 10 06333n 85 26055w overflowed for several minutes during and after the earthquake in an area that subsided during the event protti 2015 this well lies behind the earthquake slip in an area that would be expected to exhibit a head drop after the earthquake however the 3d model predicts compression and an increase in well level at this location and is therefore consistent with this observation inelastic consolidation processes due to dynamic stresses are also commonly observed to induce increases in well levels the transient head responses in 3d at different locations in the shallow subsurface show many of the same features that are seen in the 2d model areas within the regional extrema exhibit generally monotonic behavior while locations in the transition zones between these extrema often undergo non monotonic transient head responses fig 10f h pressure dissipation in 3d like in 2d occurs over multiple timescales the local pressure maximum in fig 10g largely dissipates within 60 days while the regional pressure drop located mostly in a lower permeability region fig 10e requires up to 3 years to recover these timescales are affected by the permeability heterogeneity in the near surface for example lateral permeability variations result in the rapid dissipation of the high pressure region in the northwest of the nicoya peninsula versus the slower decline of the local pressure maximum in the center of the peninsula this also illustrates that there are significant trench parallel flows in the 3d model as opposed to only trench perpendicular flow in the 2d model fig 10a shows that the spatial pattern of fluid fluxes across the ocean floor in the 3d model is more complex than in 2d in particular we observe both positive and negative fluid fluxes across the ocean floor this is due to the complex horseshoe shaped slip distribution of the earthquake similar to the 2d simulation compression leads to a large region of positive sgd between the main slip patch and the trench however the complex slip geometry also leads to a trench parallel region of seawater intake 15 30 km off the coast additionally pore pressure decrease along the coast on the southern portion of the nicoya peninsula creates a region of seawater intake that persists for many months after the earthquake this feature may have resulted in seawater intrusion into coastal aquifers the temporal evolution of the net fluid exchange across the seafloor is shown in fig 11 a similar to the 2d case there is a spike in the simulated sgd immediately following the earthquake during and immediately after an earthquake pore water is rapidly driven out of the seafloor at a peak net rate of 3 1 107 m3 day and remains greater than topographic driven sgd for almost 2 months fig 11a in 3d this increased outflow drops off more rapidly than in 2d in the region of seawater intake the maximum linear vertical flow velocity is 6 7 cm day the sgd produced by a large earthquake can be compared to both sgd due to topography driven flow and sgd due to the continuous compression of the overriding plate by subduction elastic compression due to subduction drives fluid out of the crust and into the ocean through the seafloor at a rate of approximately 4 3 104 m3 day over the study area this estimate is a lower bound as it does not account for sediment compaction fig 11b shows the spatial distribution of sgd due to the topography of the nicoya peninsula as in 2d the topographically driven sgd occurs in narrow band just offshore and results in the discharge of 3 8 105 m3 day over the study area the topographic driven sgd modeled here amounts to less than 1 of the average rainfall received within the study area rainfall data was obtained from https crudata uea ac uk cru data harris et al 2014 in the 30 days after the earthquake approximately 1 18 109 m3 cubic meters of water are expelled through the seafloor of the model compared to 1 23 107 m3 attributed to topographic flow in the 3d simulation the increase in net sgd due to the earthquake is significant especially considering the large areas of seawater intake 4 discussion to our knowledge this is the first time a detailed model incorporating a broad range of data for the hydrologic response of a large subduction zone earthquake has been assembled we first discuss our results from the nicoya peninsula followed by a look at the limitations of the available data and the model finally we discuss some future research that may benefit from a combined hydrologic and tectonic approach 4 1 timescales of hydrologic response one of the interesting predictions of the poroelastic model is that the hydrologic response occurs over multiple distinct timescales the diffusive relaxation timescale is defined as t c l c 2 d where lc is the wavelength of the pressure perturbation and d κ μ s ϵ is the hydraulic diffusivity different timescales arise because the earthquake causes pressure perturbations with different wavelengths lc and the hydraulic diffusivity decays with depth this vertical diffusivity variation effectively creates a layered structure comprised of a shallow layer with a high hydraulic diffusivity du 200 m2 s overlying a lower crust with significantly lower diffusivity d l 8 10 5 m2 s in the shallow layer the four lobed instantaneous pressure distribution has two wavelengths of approximately 20 km and 100 km the relaxation timescale of the shorter wavelength perturbation is approximately 21 days while the larger wavelength relaxes over approximately one and a half years the well head evolution in fig 10e h shows these different timescales in the lower crust the characteristic length scale of the instantaneous pressure variation is approximately the rupture length of the earthquake 40 km given the assumed low hydraulic diffusivity in the lower crust the earthquake induced pressure perturbation decays on the order of 1 ma and may explain the persistence of overpressured regions in the lower crust that have been observed seismically chaves and schwartz 2016 therefore while poroelastic variations in the shallow crust decay in the weeks to years after an event pore pressure changes in the lower crust may persist and interact over many earthquake cycles pore pressure changes near the subduction zone interface may also help provide a mechanistic link between slow slip events both magnitude and spatial distribution and the main rupture both before dixon et al 2014 and after the earthquake voss et al 2017 4 2 limitations the assumption of linear poroelastic behavior means the model does not capture the effects of dynamic stress changes and other processes such as consolidation which occur during and immediately after an earthquake in the very shallow subsurface less than 50 m of depth where there is unconsolidated sediment these processes may dominate the response of pore pressure to an earthquake the appropriate pressure boundary condition for the land surface is not clear in all of the simulations shown here except for the case of topographic flow we have assumed a no flow boundary condition this boundary condition is appropriate in areas where the head drops but not where the head rises above the topography in those locations groundwater should discharge onto the surface and the head should equal the topographic elevation however since it is not known a priori where the induced head change will exceed the land surface elevation this is a non linear boundary condition that requires an iterative solution changes in the near surface permeability due to an earthquake have been observed and can be as large as an order of magnitude manga et al 2012 rojstaczer et al 1995 however they have been neglected in this model due to the lack of data constraints similarly the permeability in the lower crust close to the earthquake may increase due to fracturing as a result of induced pore pressure changes reducing the time for poroelastic relaxation additionally on the relaxation timescales of the lower crust viscoelastic relaxation may contribute to deformation and pressure changes 4 3 effect on post seismic deformation in the weeks and years following the earthquake continuous surface deformation was observed with gps monitoring malservisi et al 2015 this post seismic deformation may be due to after slip on the fault plane viscoelastic relaxation of the underlying crust and mantle and poroelastic deformation in the shallow crust in order to reliably infer the continued slip on the fault plane it is necessary to remove the viscoelastic and poroelastic contributions from the surface deformation signal in general shorter timescales on the order of days to several weeks are associated with poroelastic effects while longer timescales on the order of months to years are associated with viscous relaxation fialko 2004 hetland and hager 2006 jonsson et al 2003 after slip may occurs on timescales that overlap with both poro and viscoelastic relaxation helmstetter and shaw 2009 perfettini and avouac 2004 2007 however this study shows that post seismic poroelastic deformation can occur on multiple timescales and overlap with those currently linked to viscous relaxation attributing surface deformation to these different processes may therefore be more complicated than previously thought in particular the non monotonicity of the poroelastic response may create surface deformation that can be confused with additional slip on the fault interface it would therefore be useful if surface deformation networks could be complimented by well monitoring to provide additional constraints on the poroelastic component 5 conclusion we have modeled the complex dynamics of the quasi static poroelastic response to a large subduction zone earthquake and outlined broad hydrologic responses that arise solely due to static stress changes and poroelastic coupling for the 2012 nicoya event considered here the small extent of the slip area relative to the depth of the epicenter leads to a four lobed instantaneous pressure distribution and subsequent hydrological response this leads to complex groundwater flow patterns non monotonic variations in well head and poroelastic relaxation on multiple time scales the model also predicts significant tectonically driven submarine groundwater discharge in the weeks following the earthquake the tectonic discharge exceeds that due to topography driven flow and occurs farther off shore the hydrological response on land is more complex than typically acknowledged in tectonic studies and complicates the interpretation of transient post seismic surface deformations combined tectonic hydrological observation networks have the potential to reduce such ambiguities acknowledgments k a m was supported by the national science foundation graduate research fellowship under grant no dge 1110007 m a h was supported by nsf grant cbet cds e 1508713 this work has benefited from the data and insights provided by tim dixon rocco malservisi and the entire geodesy lab at the university of south florida as well as from the mathematical and computational expertise of omar ghattas and umberto villa at the institute for computational engineering and science at the university of texas at austin well data was provided by carlos romero at senara national service of groundwater irrigation and drainage in costa rica as well as marino protti the models used here were built using both fenics alnæs et al 2014 logg et al 2012 logg and wells 2010 and firedrake luporini et al 2017 rathgeber et al 2016 both collection of open source software components directed at the automated solution of differential equations by finite element method balay et al 2017a 2017b both 2d and 3d meshes were built using gmsh software geuzaine and remacle 2009 the generic mapping tools software was used to generate figures wessel and smith 1998 appendix a boundary conditions and constitutive equations the boundary and initial conditions are 6a p 0 p 0 in ω 6b p 0 on γ o c e a n 6c κ μ p n 0 on γ n o t o c e a n 6d σ u n 0 on γ s u r f a c e 6e u n 0 on γ r i g h t γ b o t t o m 6f u n 0 on γ s l a b 6g δ σ u n t u t u 0 on γ s l a b the finite element method is a numerical technique to calculate approximate solutions to boundary value problems governed by partial differential equations pde s it uses the variational form of the equation s to approximate the solution on a finite number of nodes within the domain to solve this boundary value problem for fault slip we need to define stress σ in terms of displacement u we use their relationship with the strain tensor to do this the elastic stress tensor is defined as 7 σ ϵ 2 g ϵ g 2 ν 1 2 ν t r ϵ i the elastic strain tensor in terms of displacement is 8 ϵ u 1 2 u u t thus defining stress only as a function of displacement gives us 9 σ u g u u t g 2 ν 1 2 ν u where g and ν are the shear modulus and poisson s ratio respectively in the fenics firedrake framework pde s are written in their weak form the weak form of the coupled set of poroelastic equations is 10a ω v σ α p i d x 0 10b ω q s ϵ p α u t κ μ p d x 0 applying green s identity and solving 6g for σn gives us the following formulation here we find u v u h 1 ω u 0 on γ d u n 0 on γ b o t t o m and p q p h 1 ω p 0 on γ o c e a n such that 11a ω σ u v α v p d x γ b δ 1 u t u 0 v t d x 0 11b ω s ϵ p q α u q t κ μ p q d x γ n κ μ p n q d x 0 the second term in 11a is the weakly imposed slip boundary condition representing the earthquake slip that occurs within the plane of the slab interface the second term in 11b represents imposed boundary flow for the time dependent terms we apply an implicit finite difference time stepping scheme 11a has no time derivative and remains the same while 11b becomes 12 ω s ϵ p k q α u k q κ μ d t p k q d x ω s ϵ p k 1 q α u k 1 q d x where k is the time level the timestep becomes larger as the model runs to efficiently capture both rapidly changing early time behavior and slow late time behavior to capture both rapid and slow post seismic processes we use timesteps of 15 min for one day 4 h for 20 days 2 days for 30 days and 30 days for 10 years in succession 
839,we model the subsurface hydrologic response to the 7 6 mw subduction zone earthquake that occurred on the plate interface beneath the nicoya peninsula in costa rica on september 5 2012 the regional scale poroelastic model of the overlying plate integrates seismologic geodetic and hydrologic data sets to predict the post seismic poroelastic response a representative two dimensional model shows that thrust earthquakes with a slip width less than a third of their depth produce complex multi lobed pressure perturbations in the shallow subsurface this leads to multiple poroelastic relaxation timescales that may overlap with the longer viscoelastic timescales in the three dimensional model the complex slip distribution of 2012 nicoya event and its small width to depth ratio lead to a pore pressure distribution comprising multiple trench parallel ridges of high and low pressure this leads to complex groundwater flow patterns non monotonic variations in predicted well water levels and poroelastic relaxation on multiple time scales the model also predicts significant tectonically driven submarine groundwater discharge off shore in the weeks following the earthquake the predicted net submarine groundwater discharge in the study area increases creating a 100 fold increase in net discharge relative to topography driven flow over the first 30 days our model suggests the hydrological response on land is more complex than typically acknowledged in tectonic studies this may complicate the interpretation of transient post seismic surface deformations combined tectonic hydrological observation networks have the potential to reduce such ambiguities 1 introduction 1 1 hydrologic effects of earthquakes earthquakes have long been known to produce a range of hydrological effects from short term responses such as liquefaction and eruption of mud volcanoes to long term changes in ground and surface water geochemistry temperature and pressure manga and wang 2007 miller 2012 wang and chia 2008 wang and manga 2010 in the near field within a few rupture lengths of the earthquake the hydrological effects are due to both static and dynamic stress changes while only dynamic stress changes can induce hydrologic responses over greater distances brodsky 2003 rojstaczer et al 1995 here we are interested in the hydrologic response to subduction zone earthquakes given their large rupture zones static stress changes extend over hundreds of kilometers the co seismic subsurface hydrologic response in the near field is often well correlated with the static poroelastic stresses akita and matsumoto 2004 quilty and roeloffs 1997 shi et al 2013 wakita 1975 near field post seismic transients in pore pressure surface deformation and fluid flux consistent with poroelastic behavior have been observed in various settings fialko 2004 jonsson et al 2003 labonte et al 2009 peltzer et al 1998 these observations suggest that the regional groundwater flow induced by quasi static stress changes is an important component of the hydrologic response to large subduction zone earthquakes while the complex effects of earthquakes on ground and surface water have received considerable attention mohr et al 2016 shi et al 2015 much less is known about the potential submarine groundwater discharge sgd associated with tectonic stresses this expulsion of fluids through the seafloor is expected from previous modeling studies given the compression of the forearc during subduction and due to thrust faulting events zhou and burbey 2014 such tectonic fluxes have been observed along the costa rica margin subduction zone due to compaction of pelagic sediments on the down going plate and compression from slow slip events near the trench labonte et al 2009 screaton and saffer 2005 these sgds occur in deep water close to the subduction trench shallow sgd near the coast has also been studied primarily due to its effect on the chemistry of the coastal ocean moore 1996 slomp and van cappellen 2004 this type of sgd derives in part from topography driven flow in aquifers that drain directly to the coast and are expelled close the shoreline sawyer et al 2016 as part of this study we investigate the possible impact of a large earthquake on the location and magnitude of sgd we use fully coupled poroelastic models to study tectonic driven sgd for a large subduction zone earthquake in costa rica that occurred beneath the nicoya peninsula in 2012 we have chosen this event because of the unique location of the nicoya peninsula above the slipping portion of the subduction zone interface this together with a dense network of high rate global positioning system gps stations provides excellent constraints on the co seismic deformation driving the groundwater flow however due to the absence of transient hydrological monitoring it is not possible to validate the predicted hydrologic response the aim of this manuscript is therefore to investigate the basic features of the large scale poroelastic relaxation following the 2012 costa rica earthquake to determine the significance of the tectonically driven groundwater flow we compare it to the standard model of topography driven flow both models have identical material properties and geometry but have different boundary conditions discussing the tectonic flow relative to the topographic flow mitigates the effect of highly uncertain parameter values such as the permeability 1 2 costa rica and the 2012 mw 7 6 earthquake along the pacific coast of costa rica the oceanic cocos plate derived from the east pacific rise and cocos nazca spreading center subducts along the middle america trench mat with a velocity of 8 5 9 cm yr demets et al 2010 feng et al 2012 as shown in fig 1 a the resulting volcanic arc extends from central costa rica north into mexico in the south the mat extends to the panama fracture zone a transform fault separating the cocos and nazca oceanic plates the suture within the cocos plate subducts directly beneath the nicoya peninsula on the northern side of this suture zone smoother older oceanic crust 25 30 ma derived from the east pacific rise is being subducted on the southern side slightly younger sea floor derived from the cocos nazca spreading center subducts underneath costa rica deshon et al 2006 on september 5 2012 a magnitude 7 6 earthquake ruptured the plate interface beneath the nicoya peninsula costa rica the epicenter was located 12 km offshore from the central nicoya coast at a depth of approximately 18 km fig 1 b the rupture spread outward along the plate interface to encompass 3000 km2 of the nicoya seismogenic zone yue et al 2013 the nicoya peninsula is positioned over the seismogenic zone of the subduction plate interface thus surface deformation measurements provide reliable information about deformation on the slab interface fig 1 b shows contours of the slip estimated from a combination of 21 campaign gps stations and 18 continuous stations deployed on the nicoya peninsula protti et al 2013 2 model setup 2 1 governing equations and boundary conditions to model the instantaneous and time dependent poroelastic response to the earthquake we use a fully coupled linear poroelastic model the slip distribution of the earthquake on the fault plane is applied as a boundary condition yue et al 2013 which initializes the co seismic pressures and displacements this instantaneous undrained response evolves as the pore pressure equilibrates the linear poroelastic theory developed by biot provides a system of equations that describes the coupling between the flow of pore fluids and the deformation of the rock matrix wang 2000 the governing equations combining the conservation of fluid mass for the evolution of pore fluid pressure p p x t and total momentum conservation of the porous medium for the quasi static solid displacement u u x t in a domain ω over the time interval 0 t are given by 1a s ϵ p α u t κ μ p 0 in ω 1b σ u α p i 0 in ω where t denotes the time derivative s ϵ is the specific storage κ x is the permeability μ is the fluid viscosity and α is the biot willis parameter in an elastic medium the stress tensor σ is related to displacement as follows 2 σ u g u u t g 2 ν 1 2 ν u where g and ν are the elastic shear modulus and drained poisson s ratio respectively the biot willis parameter α and the specific storage coefficient s ϵ can be written in terms of the elastic parameters as α 3 ν u ν b 1 ν u 1 2 ν s ϵ 3 α 1 2 ν 1 α b 2 g b 1 ν where b is skempton s pore pressure coefficient and ν and νu are the drained and undrained poisson s ratios respectively the poroelastic eq 1 require four independent material parameters to describe the undrained response as well as the magnitude of the relaxation ν νu g and b representing the drained poisson s ratio the undrained poisson s ratio the elastic shear modulus and skempton s coefficient respectively two additionally parameters κ and μ control the transient behavior of the pore fluid the models for the poroelastic response to an earthquake and topographic driven flow have different sets of boundary conditions the primary difference between the earthquake driven and topographic driven models is the pressure boundary condition on the land surface in the case of the earthquake driven flow the boundary representing the land surface is set as a no flow boundary condition the limitations of which are discussed in section 4 2 for the topographic flow model the land surface boundary is set with a spatially varying pressure field equal to a smooth subdued expression of the land surface representing the water table the boundary and initial conditions for the earthquake driven model are 3a p 0 u 0 0 in ω 3b p 0 on γ o c e a n 3c κ μ p n 0 on γ n o t o c e a n 3d σ u n 0 on γ s u r f a c e 3e u n 0 on γ r i g h t γ b o t t o m 3f u n 0 on γ s l a b 3g δ σ u n t u t u 0 on γ s l a b for the case of topographic driven flow the initial and boundary conditions are 4a p 0 u 0 0 in ω 4b p 0 on γ o c e a n 4c p p t o p o on γ l a n d 4d κ μ p n 0 on γ n o t s u r f a c e 4e σ u n 0 on γ s u r f a c e 4f u n 0 on γ r i g h t γ b o t t o m 4g u 0 on γ s l a b in both cases the overlying ocean applies a hydrostatic pressure at the seafloor which results in a zero pressure boundary condition as p represents the deviation of the pressure from hydrostatic our model ignores the effects of tides on the ocean bottom pressure due to the much shorter spatial and temporal scales on which tide induced pressure signals propagate into the seabed all other boundaries including the one representing the land surface are set as no flow boundaries the normal stress on both the ocean and the land surface is set to zero to allow for surface deformation on the slab interface the displacement is assumed to be only in the tangential directions and is prescribed by the inversion of geodetic data the magnitude of which is shown in fig 1b the vertical boundary opposite of the trench and the bottom boundary are set as roller boundaries to prevent a net rotation of the domain the mathematical formulation of these boundary conditions is given in appendix 1 2 2 model geometry the three dimensional 3d model surface comprises an area of 250 km by 250 km aligned with the trench and extending into the overriding continental plate the location of the model is shown on the map in fig 1a all locations and displacements are rotated into a trench perpendicular and trench parallel coordinate system the 3d model geometry in shown in fig 2 a and the trench perpendicular cross section used for the two dimensional 2d model is shown in fig 2b a simplified coastline is integrated into the mesh and divides the top boundary of the domain into two surfaces the seafloor is defined as a linear slope from the coast at 0 km depth to the trench at 4 km depth while the land topography is neglected the fault interface boundary of the model is fit to the smooth interface derived from seismic tomography and is assumed constant in the trench parallel direction deshon et al 2006 the model domain is truncated at 60 km depth in both 2d and 3d it is necessary to resolve the near surface such that the permeability decay with depth fig 3 a is adequately captured by the mesh in 2d this can be done with an unstructured tetrahedral mesh with an element size of 200 m at the surface and 3 km at depth resulting in approximately 60 000 elements in 3d this is done with an extruded layered mesh from 0 5 km depth comprising of 4 layers that increase in thickness with depth from 300 to 1 500 m overlaying an unstructured tetrahedral mesh with 3 4 km element size this allows the model to capture the permeability decay without meshing to a 300 m resolution in the x and y directions the 3d mesh contains approximately 140 000 elements we use a direct solver and only rebuild the factorization when the timestep changes to efficiently capture both rapid short term and slow long term behavior the timestep progresses from 15 min to one month all of the models were run on a workstation with run times ranging from 1 to 30 h the limitation on the number of elements used is the memory required to store the factorization 2 3 integration of field data the six parameters of the poroelastic model described above vary both laterally and with depth and potentially over many orders of magnitude they should therefore ideally be constrained by field data below we describe how parameter values throughout the domain have been derived from regional seismic and hydrogeologic data 2 3 1 elastic parameters and initial slip condition it is increasingly recognized that the spatial variation of the elastic parameters has a significant influence on the predicted co seismic displacements masterlark et al 2001 williams and wallace 2015 the elastic parameters of the model are constrained with vp vs seismic tomography data along with a 1d density model to create best fit functions that represent how the various elastic parameters change with depth deshon 2004 deshon et al 2006 fig 2b shows how the tomography derived shear modulus g varies within the domain the young s modulus is calculated from p wave velocity and density the p wave velocity vp and the bulk density ρb depth profile are used to calculate the p wave modulus m with depth using m ρ b v p 2 the p wave modulus and drained poisson s ratio ν are then used to derive the young s modulus e depth profile using the relationship e m 1 ν 1 2 ν 1 ν three parameters for a power function of the form e z a z b c were fit to the relationship between young s modulus and depth resulting in a best fit function of e 3 471 z 10 2 0 5157 5 324 10 4 where z is the depth in meters and e is given in mpa the shear modulus g used in the poroelastic equations is derived from young s modulus and poisson s ratio using the relationship g e 2 1 ν the slip boundary condition to drive the model is obtained by inverting the co seismic displacements measured by a network of gps stations here we use the co seismic displacements to infer slip on the overridding plate of the subduction interface the contour map of the slip solution is shown in fig 1b the co seismic horizontal surface displacement vectors at gps station locations from both gps measurements and the forward model are shown in appendix figure fig a 1 2 3 2 hydrogeologic data the timescale over which fluid induced deformation takes place is controlled by the three dimensional permeability field our model considers the variations in permeability that occur on two different length scales a general decline of permeability with depth on the crustal scale and large variations that occur over short lateral distances in the relatively permeable shallow crust on the crustal scale the permeability κ decreases exponentially with depth d z from the high permeability κs near the surface to the low residual background permeability lower in the crust κr as shown in fig 3a we use the parameterization of kuang and jiao 2014 given by 5 log 10 κ log 10 κ r log 10 κ s κ r 1 d a where a 0 8 is the dimensionless decay index we assume that κr is constant but allow κs to vary laterally as shown in fig 3b to constrain the surface permeability field κs of the study area we obtained pump test results of 520 groundwater wells from senara located throughout the state of guanacaste costa rica see si the pump test results were interpreted in terms of the transmissivity of the aquifer t if the aquifer thickness b is known the hydraulic conductivity is given by k t b here we assume that b is equal to the reported well depth this assumption tends to overestimate k if the well does not penetrate the entire depth of the aquifer the permeability required for 1a is given by κ k μ ρ g where ρ is the density of the pore fluid and g is the acceleration of gravity the permeabilites obtained this way should be seen as upper bound because of our assumption that the wells penetrate the entire aquifer the well data were interpolated using a kriging toolbox murphy 2014 in areas on land not covered by the well data the permeability reverts to the mean permeability of the well data set in absence of data about the spatial variation of seafloor permeability we assume it is constant and choose a value of 10 13 m2 based on previous studies becker and davis 2004 davis and villinger 2006 spinelli et al 2004 the resulting permeability map is shown in fig 3b the northwest and central portions of the nicoya peninsula have generally higher surface permeabilities whereas the southern and inland portions have much lower permeability comparison with the geological map in fig 3c shows that high permeability areas often associated with quaternary alluvial sediments while low permeability areas are primarily sea floor basalts the kriging variance in fig 3d shows that the permeability is highly uncertain away from the well data this is due to the short correlation length of the data evident from the semivariogram of the data in fig 3e for the kriging interpolation we have assumed an exponential variogram model with a nugget sill and range of 0 771 1 086 and 1 28 104 m respectively there is currently no well monitoring system in place of the nicoya peninsula therefore no quantitative records of the head changes during and after the earthquake exist however qualitative description of the response at an individual location has been reported and is discussed below 3 results for this study we used both 2d and 3d numerical models in section 3 1 we investigate more general trends in the poroelastic response in a 2d model of a subduction zone earthquake given different earthquake sizes and crustal permeability structures section 3 2 presents results of a 3d model results based on a fixed set of best fit parameters and the real earthquake slip data 3 1 two dimensional model results in order to gain a better understanding for which factors control both the co seismic and post seismic poroelastic response to a large earthquake we ran a number of simpler models in 2d the geometry is based on a representative trench perpendicular cross section through the center of the nicoya peninsula and the slip patch fig 2 these models use a constant surface permeability but retain the variation of permeability and young s modulus with depth first we discuss the geometry of the co seismic undrained elastic response in section 3 1 1 followed by a discussion of the time scales of the post seismic poroelastic relaxation in section 3 1 2 3 1 1 effects of earthquake size and depth on the undrained response to study the 2d instantaneous response to a subduction zone earthquake we use a synthetic gaussian slip distribution for a gaussian slip centered at a depth of 20 km with a rupture width of 100 km the co seismic displacement and the undrained pore pressure response are shown in fig 4 a and b respectively for a gaussian slip distribution the rupture width is defined as 4σslip where σslip is the variance of the gaussian function the simulation shows the expected increase in pore pressure due to compression of the forearc and decrease due to extension in the interior this simple pattern is observed when the width of the slip patch is large relative to the earthquake depth in this case pore pressure increases trenchward of the earthquake primarily offshore and decreases behind the earthquake on land however earthquakes with a smaller slip area relative to their depth produce a more complex pattern in co seismic displacement and the undrained pore pressure response fig 4c and d in the far field the pattern is similar but directly above the earthquake two additional pressure lobes appear near the surface a similar pattern of the instantaneous pore pressure field in response to a thrust earthquake was described in zhou and burbey 2014 fig 5 shows that the undrained pore pressure pattern is primarily a function of the ratio of slip extent to earthquake depth the four lobed pattern is observed when the slip width to depth ratio is equal to or less than three the elastic parameters have a very small effect on this geometry but if the young s modulus increases drastically with depth the pattern trends toward the simple two lobed case this four lobed pattern is conspicuous in the pore pressure response but is less obvious in the surface displacement fig 6 shows that the local pore pressure maximum is accompanied by some subsidence and a decrease in the magnitude of the trenchward displacement the local decrease in the amount of trenchward displacement results in an area directly above the earthquake that experiences less net displacement which results in local landward compression and trenchward expansion for earthquakes with small slip width to depth ratios fig 4c these local high and low pressure lenses dominate the local near surface hydrologic response displacement data from the nicoya peninsula projected onto the cross section show a pattern consistent with four lobed pressure response fig 6 the undrained pressure field sets up regional groundwater flows that relax the pressure gradients over time the timescale of the hydrological response is determined by the near surface permeability and mass specific storage in the 2d model the permeability only varies with depth and remains constant across the surface this allows us to look at the effect of different surface permeability values on the time dependent pore pressure response without the added complication of large scale preferential flow paths present in the 3d model to study the time dependent hydrological response we perform a 2d simulation with a slip distribution that is a gaussian approximation of the 2012 nicoya event a surface permeability of 10 11 m2 and a skempton s coefficient of 0 7 the undrained pressure distribution and the transient well head h p ρ g response at various locations on the surface are shown in fig 7 the slip width to depth ratio of the main slip patch of the 2012 nicoya event is approximately 2 1 and hence results in a four lobed instantaneous pore pressure response in the shallow crust 3 1 2 time dependent hydrological response the signature of the transient pore pressure relaxation after the earthquake varies significantly with distance from the trench fig 7 the response differs from what might be expected because the head response is complicated by the four lobed pattern that leads to a local head maximum above earthquake first we will discuss the change in the well response with distance from the coast and then consider the effect of the near surface permeability very close to the coast fig 7a shows an instantaneous rise followed by in most cases a drop below pre earthquake levels just two kilometers inland fig 7b shows a co seismic head drop followed in most cases by a continued decrease and then a recovery in the low pressure regions close to the coast and far inland fig 7c and f an instantaneous head drop is followed by a monotonic recovery in the center of the high pressure lens fig 7d an instantaneous head increase is followed by a monotonic relaxation to a head sometimes below the pre earthquake level the wells in the transition zones between high and low pressure regions show markedly different patterns of transient well response behind the high pressure lens a co seismic head drop is followed either by a recovery and drop or a small drop and recovery fig 7e the initial well response is due to the dissipation of the four lobed pressure pattern within the first twenty days after the dissipation of the local pressure maximum above the earthquake the entire onshore region is under pressured compared to pre earthquake pore pressures this induces a slow landward regional groundwater flow from the overpressured section offshore while well levels close to the coast recover quickly fig 7a the recovery further inland fig 7f may take months to years fig 7 also illustrates the effect of variations in surface permeability on the transient well head response fig 7c shows the expected delay in recovery with decreasing permeability however fig 7e shows that variations in permeability can also lead to fundamental changes in the pattern of well head response this particular well changes from a non monotonic head response to a monotonically decreasing response as the permeability decreases both panels illustrate that the instantaneous response is independent of permeability 3 1 3 submarine groundwater discharge sgd the offshore compression due to the earthquake leads to the expulsion of significant amounts of pore water through the seafloor it is interesting to compare this discharge to continuous sgd driven by topography and compression by subduction topography driven flow assumes that the water table is a subdued expression of the surface topography cherry and freeze 1979 toth 1962 and provides a simple estimate for the shallow environmental flows in the hydrological cycle gleeson et al 2015 sawyer et al 2016 an estimate of the topography driven sgd is shown in fig 8 a the representative cross section through the nicoya peninsula shows two mountain ranges separated by a central valley the elevated pressures underlying the topographic highs induce flows down gradient into the valleys and out to sea the insert of fig 8a shows the details of the flow field near the surface the streamlines illustrate that groundwater flow occurs in is confined to the upper most 500 m the sgd due to this shallow topography driven flow is therefore localized in the first few hundred meters off the coast assuming the water table varies between 25 and 75 of the land surface topography the total sgd per unit width is between 2000 6000 m3 m yr additionally subduction of the oceanic plate compresses the toe of the overriding plate and produces sgd on the order of 100 m3 m yr primarily near the trench the pattern of tectonic driven sgd differs significantly from the topography driven sgd following an earthquake compression offshore leads to sgd along most of the seafloor between the coast and the trench fig 8b unlike the topographic flow which induces mostly horizontal flow the tectonic driven flow is mostly vertical the total flux through the seafloor immediately following the earthquake is four orders of magnitude greater than the topographic flux fig 9 the tectonic contribution to sgd remains greater than the topographic contribution for approximately 3 months following the earthquake and remains elevated for a number of years the tectonically driven sgd due to smaller events such as slow slip events have been previously detected by fluid flux measurements offshore the nicoya peninsula jiang et al 2017 labonte et al 2009 our simulations show that that large events are likely to induce similar flows that significantly change the pattern and magnitude of sgd in the months following an earthquake 3 2 three dimensional model results the two dimensional results presented above are instructive but they lack the complex slip distribution of the earthquake and the spatial heterogeneity of permeability in the upper crust to address these effects we conduct a three dimensional simulation incorporating all of the available data to constrain the earthquake geometry and poroelastic parameters whereas the 2d model was used to investigate the effects of different parameters on the instantaneous and time dependent responses the 3d model uses a single set of best fit parameters for the nicoya peninsula and the 2012 earthquake table 1 summarizes the model parameters and the data used to constrain them unlike the 2d model where the slip distribution was assumed to be gaussian the 3d model incorporates the realistic slip distribution shown in fig 1b the most prominent feature of the instantaneous hydrologic response are the trench parallel ridges of high and low head in the shallow subsurface fig 10 a there are two possible reasons for this pattern 1 the width to depth ratio of the main slip region or 2 the horseshoe pattern of the slip distribution the pattern of high and low head changes on land occurs directly over the main slip patch of the earthquake the secondary slip area near the trench is too far away to affect the onshore subsurface head response the width of the main slip patch of the nicoya earthquake is 40 km fig 1b and the depth of the epicenter is 18 km the slip width to depth ratio is therefore less than 3 1 suggesting that this multi lobed head response in fig 10a d is the 3d manifestation of the modeled 2d response for earthquakes with small slip width to depth ratios fig 4c d while no formal well monitoring system is in place on the nicoya peninsula a well located at 10 06333n 85 26055w overflowed for several minutes during and after the earthquake in an area that subsided during the event protti 2015 this well lies behind the earthquake slip in an area that would be expected to exhibit a head drop after the earthquake however the 3d model predicts compression and an increase in well level at this location and is therefore consistent with this observation inelastic consolidation processes due to dynamic stresses are also commonly observed to induce increases in well levels the transient head responses in 3d at different locations in the shallow subsurface show many of the same features that are seen in the 2d model areas within the regional extrema exhibit generally monotonic behavior while locations in the transition zones between these extrema often undergo non monotonic transient head responses fig 10f h pressure dissipation in 3d like in 2d occurs over multiple timescales the local pressure maximum in fig 10g largely dissipates within 60 days while the regional pressure drop located mostly in a lower permeability region fig 10e requires up to 3 years to recover these timescales are affected by the permeability heterogeneity in the near surface for example lateral permeability variations result in the rapid dissipation of the high pressure region in the northwest of the nicoya peninsula versus the slower decline of the local pressure maximum in the center of the peninsula this also illustrates that there are significant trench parallel flows in the 3d model as opposed to only trench perpendicular flow in the 2d model fig 10a shows that the spatial pattern of fluid fluxes across the ocean floor in the 3d model is more complex than in 2d in particular we observe both positive and negative fluid fluxes across the ocean floor this is due to the complex horseshoe shaped slip distribution of the earthquake similar to the 2d simulation compression leads to a large region of positive sgd between the main slip patch and the trench however the complex slip geometry also leads to a trench parallel region of seawater intake 15 30 km off the coast additionally pore pressure decrease along the coast on the southern portion of the nicoya peninsula creates a region of seawater intake that persists for many months after the earthquake this feature may have resulted in seawater intrusion into coastal aquifers the temporal evolution of the net fluid exchange across the seafloor is shown in fig 11 a similar to the 2d case there is a spike in the simulated sgd immediately following the earthquake during and immediately after an earthquake pore water is rapidly driven out of the seafloor at a peak net rate of 3 1 107 m3 day and remains greater than topographic driven sgd for almost 2 months fig 11a in 3d this increased outflow drops off more rapidly than in 2d in the region of seawater intake the maximum linear vertical flow velocity is 6 7 cm day the sgd produced by a large earthquake can be compared to both sgd due to topography driven flow and sgd due to the continuous compression of the overriding plate by subduction elastic compression due to subduction drives fluid out of the crust and into the ocean through the seafloor at a rate of approximately 4 3 104 m3 day over the study area this estimate is a lower bound as it does not account for sediment compaction fig 11b shows the spatial distribution of sgd due to the topography of the nicoya peninsula as in 2d the topographically driven sgd occurs in narrow band just offshore and results in the discharge of 3 8 105 m3 day over the study area the topographic driven sgd modeled here amounts to less than 1 of the average rainfall received within the study area rainfall data was obtained from https crudata uea ac uk cru data harris et al 2014 in the 30 days after the earthquake approximately 1 18 109 m3 cubic meters of water are expelled through the seafloor of the model compared to 1 23 107 m3 attributed to topographic flow in the 3d simulation the increase in net sgd due to the earthquake is significant especially considering the large areas of seawater intake 4 discussion to our knowledge this is the first time a detailed model incorporating a broad range of data for the hydrologic response of a large subduction zone earthquake has been assembled we first discuss our results from the nicoya peninsula followed by a look at the limitations of the available data and the model finally we discuss some future research that may benefit from a combined hydrologic and tectonic approach 4 1 timescales of hydrologic response one of the interesting predictions of the poroelastic model is that the hydrologic response occurs over multiple distinct timescales the diffusive relaxation timescale is defined as t c l c 2 d where lc is the wavelength of the pressure perturbation and d κ μ s ϵ is the hydraulic diffusivity different timescales arise because the earthquake causes pressure perturbations with different wavelengths lc and the hydraulic diffusivity decays with depth this vertical diffusivity variation effectively creates a layered structure comprised of a shallow layer with a high hydraulic diffusivity du 200 m2 s overlying a lower crust with significantly lower diffusivity d l 8 10 5 m2 s in the shallow layer the four lobed instantaneous pressure distribution has two wavelengths of approximately 20 km and 100 km the relaxation timescale of the shorter wavelength perturbation is approximately 21 days while the larger wavelength relaxes over approximately one and a half years the well head evolution in fig 10e h shows these different timescales in the lower crust the characteristic length scale of the instantaneous pressure variation is approximately the rupture length of the earthquake 40 km given the assumed low hydraulic diffusivity in the lower crust the earthquake induced pressure perturbation decays on the order of 1 ma and may explain the persistence of overpressured regions in the lower crust that have been observed seismically chaves and schwartz 2016 therefore while poroelastic variations in the shallow crust decay in the weeks to years after an event pore pressure changes in the lower crust may persist and interact over many earthquake cycles pore pressure changes near the subduction zone interface may also help provide a mechanistic link between slow slip events both magnitude and spatial distribution and the main rupture both before dixon et al 2014 and after the earthquake voss et al 2017 4 2 limitations the assumption of linear poroelastic behavior means the model does not capture the effects of dynamic stress changes and other processes such as consolidation which occur during and immediately after an earthquake in the very shallow subsurface less than 50 m of depth where there is unconsolidated sediment these processes may dominate the response of pore pressure to an earthquake the appropriate pressure boundary condition for the land surface is not clear in all of the simulations shown here except for the case of topographic flow we have assumed a no flow boundary condition this boundary condition is appropriate in areas where the head drops but not where the head rises above the topography in those locations groundwater should discharge onto the surface and the head should equal the topographic elevation however since it is not known a priori where the induced head change will exceed the land surface elevation this is a non linear boundary condition that requires an iterative solution changes in the near surface permeability due to an earthquake have been observed and can be as large as an order of magnitude manga et al 2012 rojstaczer et al 1995 however they have been neglected in this model due to the lack of data constraints similarly the permeability in the lower crust close to the earthquake may increase due to fracturing as a result of induced pore pressure changes reducing the time for poroelastic relaxation additionally on the relaxation timescales of the lower crust viscoelastic relaxation may contribute to deformation and pressure changes 4 3 effect on post seismic deformation in the weeks and years following the earthquake continuous surface deformation was observed with gps monitoring malservisi et al 2015 this post seismic deformation may be due to after slip on the fault plane viscoelastic relaxation of the underlying crust and mantle and poroelastic deformation in the shallow crust in order to reliably infer the continued slip on the fault plane it is necessary to remove the viscoelastic and poroelastic contributions from the surface deformation signal in general shorter timescales on the order of days to several weeks are associated with poroelastic effects while longer timescales on the order of months to years are associated with viscous relaxation fialko 2004 hetland and hager 2006 jonsson et al 2003 after slip may occurs on timescales that overlap with both poro and viscoelastic relaxation helmstetter and shaw 2009 perfettini and avouac 2004 2007 however this study shows that post seismic poroelastic deformation can occur on multiple timescales and overlap with those currently linked to viscous relaxation attributing surface deformation to these different processes may therefore be more complicated than previously thought in particular the non monotonicity of the poroelastic response may create surface deformation that can be confused with additional slip on the fault interface it would therefore be useful if surface deformation networks could be complimented by well monitoring to provide additional constraints on the poroelastic component 5 conclusion we have modeled the complex dynamics of the quasi static poroelastic response to a large subduction zone earthquake and outlined broad hydrologic responses that arise solely due to static stress changes and poroelastic coupling for the 2012 nicoya event considered here the small extent of the slip area relative to the depth of the epicenter leads to a four lobed instantaneous pressure distribution and subsequent hydrological response this leads to complex groundwater flow patterns non monotonic variations in well head and poroelastic relaxation on multiple time scales the model also predicts significant tectonically driven submarine groundwater discharge in the weeks following the earthquake the tectonic discharge exceeds that due to topography driven flow and occurs farther off shore the hydrological response on land is more complex than typically acknowledged in tectonic studies and complicates the interpretation of transient post seismic surface deformations combined tectonic hydrological observation networks have the potential to reduce such ambiguities acknowledgments k a m was supported by the national science foundation graduate research fellowship under grant no dge 1110007 m a h was supported by nsf grant cbet cds e 1508713 this work has benefited from the data and insights provided by tim dixon rocco malservisi and the entire geodesy lab at the university of south florida as well as from the mathematical and computational expertise of omar ghattas and umberto villa at the institute for computational engineering and science at the university of texas at austin well data was provided by carlos romero at senara national service of groundwater irrigation and drainage in costa rica as well as marino protti the models used here were built using both fenics alnæs et al 2014 logg et al 2012 logg and wells 2010 and firedrake luporini et al 2017 rathgeber et al 2016 both collection of open source software components directed at the automated solution of differential equations by finite element method balay et al 2017a 2017b both 2d and 3d meshes were built using gmsh software geuzaine and remacle 2009 the generic mapping tools software was used to generate figures wessel and smith 1998 appendix a boundary conditions and constitutive equations the boundary and initial conditions are 6a p 0 p 0 in ω 6b p 0 on γ o c e a n 6c κ μ p n 0 on γ n o t o c e a n 6d σ u n 0 on γ s u r f a c e 6e u n 0 on γ r i g h t γ b o t t o m 6f u n 0 on γ s l a b 6g δ σ u n t u t u 0 on γ s l a b the finite element method is a numerical technique to calculate approximate solutions to boundary value problems governed by partial differential equations pde s it uses the variational form of the equation s to approximate the solution on a finite number of nodes within the domain to solve this boundary value problem for fault slip we need to define stress σ in terms of displacement u we use their relationship with the strain tensor to do this the elastic stress tensor is defined as 7 σ ϵ 2 g ϵ g 2 ν 1 2 ν t r ϵ i the elastic strain tensor in terms of displacement is 8 ϵ u 1 2 u u t thus defining stress only as a function of displacement gives us 9 σ u g u u t g 2 ν 1 2 ν u where g and ν are the shear modulus and poisson s ratio respectively in the fenics firedrake framework pde s are written in their weak form the weak form of the coupled set of poroelastic equations is 10a ω v σ α p i d x 0 10b ω q s ϵ p α u t κ μ p d x 0 applying green s identity and solving 6g for σn gives us the following formulation here we find u v u h 1 ω u 0 on γ d u n 0 on γ b o t t o m and p q p h 1 ω p 0 on γ o c e a n such that 11a ω σ u v α v p d x γ b δ 1 u t u 0 v t d x 0 11b ω s ϵ p q α u q t κ μ p q d x γ n κ μ p n q d x 0 the second term in 11a is the weakly imposed slip boundary condition representing the earthquake slip that occurs within the plane of the slab interface the second term in 11b represents imposed boundary flow for the time dependent terms we apply an implicit finite difference time stepping scheme 11a has no time derivative and remains the same while 11b becomes 12 ω s ϵ p k q α u k q κ μ d t p k q d x ω s ϵ p k 1 q α u k 1 q d x where k is the time level the timestep becomes larger as the model runs to efficiently capture both rapidly changing early time behavior and slow late time behavior to capture both rapid and slow post seismic processes we use timesteps of 15 min for one day 4 h for 20 days 2 days for 30 days and 30 days for 10 years in succession 
