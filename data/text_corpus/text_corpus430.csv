index,text
2150,dual permeability models are currently under active investigation for predicting the flow and transport of pollutant concentration in porous media the basic idea of these models is usually to separate the medium into two distinct flow regions with separate hydraulic and solute movement properties most of the dual permeability approaches presented to date assume the reaction terms to be independent of space for local reaction processes in soils however the depth effects are important and should be incorporated into the dual permeability models to reveal the transport phenomenon in such case the best way is to obtain an exact solution with a suitable analytical approach but it may be hard or even impossible for this general scenario as such this paper seeks an alternative method and propose a lattice boltzmann method for solute transport in dual permeability media the chapman enskog analysis shows that the present model can recover the governing equations correctly the capability and accuracy of this model is first verified by two problems the non reactive mass transfer in dual permeability porous media and the solute transport in a depth dependent soil with this model we further studied the contaminant transport in dual permeability soil with depth dependent reaction rates the numerical results show that when the exchange coefficient is relatively smaller there are usually two peaks for the breakthrough curves btcs whereas it degenerates to a single peak as the exchange coefficient increases in addition we note that the distributions of the concentration in different domains are nearly the same for a larger exchange coefficient as for the pore water velocity it is found that when the difference in the pore water velocity in the two domains is significant the btc exhibits a bimodal distribution however there is only one peak for the btcs when the above difference is insignificant further as compared with the constant reaction rate cases we observe that the btcs obtained for the media with depth dependent rates lie in the intermediate zone defined by the above two extremes finally we adopt the current approach to simulate the solute transport in an andisol and observe that the difference between the numerical and experimental results is insignificant indicating our approach is capable in modeling solute transport in porous media keywords lattice boltzmann method solute transport dual permeability depth dependent reaction data availability data will be made available on request 1 introduction with the growing concern about the environment and health the transport of contaminants such as residual pesticides and fertilizers waste permeate industrial effluents and radioactive substances in groundwater have attracted great interest from both academic and industrial mackay et al 1985 mccarthy and zachara 1989 karri et al 2021 in this setting the accurate prediction of the contaminant content concentration changes and transport patterns in the porous media are very important for controlling the migration of contaminants and pollution prevention gupta and ali 2013 over the past few decades researchers have proposed various mathematical models for simulating solute transport in porous media among them the most widely used model is the advection dispersion equation sun et al 2020 since the average displacement and the contaminant spreading in advection dispersion model are only described by a uniform effective velocity and a uniform dispersal rate this model is just adequate for simulating the equilibrium transport in homogeneous media however because the anomalous dispersion behavior is significant for the solute transport in heterogeneous media e g solid matrix the advection dispersion model is less sufficient to predict the non equilibrium transport in these medias beven 1991 to this end several multi domain models are developed to model the non equilibrium flow in heterogeneous media in 1964 coats and smith coats and smith 1964 developed a differential capacitance model to describe the dispersion in porous media by taking the dead end pore structure into account after that van genuchten and wierenga 1976 proposed a mobile immobile model for mass transfer in a sorbing porous media in 1976 in which the pore space consists of the mobile and the immobile regions it should be noted that the fluid flow in mobile immobile model is assume to occur in the mobile region whereas there is no flow in the immobile domain in such case advection and dispersion processes only occur in the mobile domain for the diffusive transport between these two regions it can be described by solving the fick s equation rappoldt 1990 van genuchten and dalton 1986 leij et al 2012 later leij et al 2012 extended the mobile immobile model to a more general scenario by considering the flow and dispersion in both regions and further proposed a dual advection dispersion equation in dual permeability media which can be seen as a generalized version of the traditional advection dispersion and the mobile immobile models with this model sciortino et al 2015 qualitative studied the solute transport in dual permeability media and the numerical results agree well with the experiment more recently xie et al 2019 developed another mobile mobile model for contaminant transport in dual permeability media unlike previous models the authors pointed out that due to the reaction process in soils is always related to the amount and type of organic matter and to the microbial activity which are strongly dependent on space flury et al 1998 gao et al 2013 the depth dependent reaction coefficients are considered in their model here the term depth dependent means that during the transport of contaminants through media the adsorption and degradation processes vary with depth which further affects the fate and transport behavior of contaminants in soils flury et al 1998 gao et al 2013 in this work we concentrate on the solute transport in dual permeability porous media with depth dependent reaction coefficients which is a more general model in predicting the fate and movement of contaminants in soils there is no doubt that the best way to revel the solute transport in this case is the analytical method however from a mathematical point of view since contaminants transport in dual permeability media is described by a system of convection diffusion equations with strong coupling it is not easy to obtain the corresponding analytical solutions if any they are often restricted to the simplified cases leij et al 2012 šimůnek and van genuchten 2008 therefore developing numerical schemes for the solution of contaminant transport in dual permeability porous media is desirable xie et al 2019 šimůnek and van genuchten 2008 as a kinetic based numerical method the lattice boltzmann lb method is nevertheless attractive for simulating fluid flows because it is easy to use for programming and is ability to handle complex geometry with the simple bounce back rule chen and doolen 1998 miller et al 1998 from early in its development the lb method has advanced as a promising tool for simulating flow through porous media in 2002 kang et al 2002 developed a lb model for simulation of the chemical dissolution in porous media subsequently ginzburg and d humieres 2003 analyzed the accuracy of the bounce back rule and proposed a multireflection boundary conditions for lb models almost at the same time guo and zhao 2002 propose a lb model for simulating incompressible porous media flow at macroscopic level afterward pan et al 2006 quantitatively evaluate the numerical performance of the lb method in modeling flow through porous media pan et al 2004 in addition miller et al 1998 also adopted the lb model to simulate the two phase flow in porous media at pore scale more recently ginzburg et al 2015 presented a detail analysis on the brinkman lb schemes and compared the results with that of the linear finite element method ju et al 2022 carried out a pore scale numerical simulation of the convective mixing process in geological storage on the other hand yang et al 2016 and zhao et al 2019 also conducted several comprehensive comparisons for different pore scale approaches in which the performance of the lb method is compared with some other pore scale models such as the pore network model and the smoothed particle hydrodynamics model these available works clearly demonstrate the effectiveness and accuracy of lb method in modeling flow through porous media unfortunately to the best of our knowledge there still no mature lb model that can be directly used to simulate solute transport in dual permeability media recently several groups have developed lb models for modeling solute transport in a variety of fields zhang et al 2002 zhou 2009 walsh and saar 2010 ginzburg 2005 peng et al 2011 yoshida and nagaoka 2010a liu et al 2015 ru et al 2021 however since the governing equation for solute transport in most of these works is described by a standard convection diffusion equation like ϕ t u ϕ υ ϕ f here ϕ is the solute concentration u is the fluid velocity υ is the diffusion coefficient and f is the source sink term the straightforward application of these developed lb models for simulating the solute transport in dual permeability media with depth dependent reaction coefficients may fail to capture the correct transport behavior the inherent difficulty stems from the fact that there exists a depth dependent retardation parameter in front of ϕ t for this complex dual permeability model which brings some additional difficulties in developing the lb method in this setting the present work aims to develop an effective lb method for solute transport in dual permeability porous media with depth dependent reaction coefficients in contrast to previous works zhang et al 2002 zhou 2009 walsh and saar 2010 ginzburg 2005 peng et al 2011 yoshida and nagaoka 2010a liu et al 2015 ru et al 2021 the convection term appeared in the governing equations is treated as a source term in the lb equation rather than being directly recovered by the evolution equation in addition in order to handle the depth dependent retardation parameter the collision process in our lb method is modified by adding another extra term as we shall see the governing equations can be recovered correctly with the present method through the chapman enskog analysis the paper is organized as follows in the next section we describe the physical problem and the governing equations initial and the boundary conditions in section 3 we present the lb equations for the solute transport in dual permeability media in section 4 the verification and the solution procedure is given in section 5 the numerical results and discussion are presented and discussed the practical application of the present lbm is illustrated in section 6 the conclusions are drawn in the last section 2 mathematical model 2 1 governing equations this work considers a more general model to describe the contaminant transport in dual permeability media along the vertical direction see fig 1 different from the aforementioned mobile immobile model the present model has two distinct differences for one thing the advection dispersion transport is applied to both domains leij et al 2012 and for another it includes the influence of the depth dependent reaction process gao et al 2013 in such a case the solute transport within the porous media through three distinct mechanisms i e convection dispersion and solute exchange between the domain with fast flow velocity and the domain with slow flow velocity besides we assume that the contaminant adsorption is characterized by a isotherm state and that the solute degradation in the system is the so called first order process in this setting the governing equations for the contaminant transport in dual permeability media can be given as xie et al 2019 1 ψ f h x f c f t ψ f d f 2 c f x 2 ψ f v f c f x ψ f μ x c f α c s c f 2 ψ s h x s c s t ψ s d s 2 c s x 2 ψ s v s c s x ψ s μ x c s α c f c s where the parameters in the fast and slow velocity domain are described by the subscript f and s respectively t is the time t x is the spatial coordinate l c f s is the solute concentration ψ f s is the volumetric water content in different regions per bulk volume l 3 l 3 and the total volumetric water content is then given as ψ ψ f ψ s v f s is the pore water velocity lt 1 and it is usually assumed that v f v s leij et al 2012 α is an effective coefficient for solute transport between the two aqueous regions t 1 μ x is the depth dependent degradation rate t 1 d f s denotes the dispersion coefficient relying on the pore water velocity which can be expressed as 3 d f λ f v f d 0 4 d s λ s v s d 0 in which d 0 represents the effective diffusion coefficient in the porous media l whose value is much smaller in contrast to λ v such that it is usually ignored in studying the problem of contaminant transport in dual permeability porous media li et al 2020 λ is the dispersivity in the porous media l 2 t 1 moreover h x f s is the retardation factor relying on the depth and it can be given by flury et al 1998 5 h x f 1 ρ k d x f ψ f 6 h x s 1 ρ k d x s ψ s with ρ and k d x being the density ml 3 and adsorption coefficients l 3 m 1 respectively according to previous work flury et al 1998 the depth dependent organic matter content microbial activity and clay minerals in soils have a significant influence on the solute adsorption and degradation rates and flury et al 1998 gao et al 2013 found that the expressions of these two rates can be defined as a sigmoidal form 7 k d x k 0 cosh 2 x x 0 8 μ x μ 0 cosh 2 x x 0 in which k 0 and μ 0 are constants and they denote the maximum values of k d x and μ x x 0 is the transition depth using to describe the reaction response rate for different depth specifically for a relatively smaller value of x 0 the reaction coefficient decreases significantly xie et al 2019 the governing equations described above is a general dual permeability model when the influence of the depth is ignored the equations degenerates into the traditional form 9 ψ f h c f t ψ f d f 2 c f x 2 ψ f v f c f x ψ f μ c f α c s c f 10 ψ s h c s t ψ s d s 2 c s x 2 ψ s v s c s x ψ s μ c s α c f c s where h and μ are the constant retardation and degradation factors to have a better understanding of the solute transport in dual permeability media a comparison between the case with and without the depth dependent reaction processes will also be discussed in this work 2 2 initial and boundary conditions to close the system we need to use appropriate boundary condition for the concentration this work deals with the solute transport in a system with finite volume and initially there is no solute in the medium genuchten and parker 1984 i e 11 c f s x 0 0 0 x r in addition a pulse type boundary condition is applied to the inlet while a zero gradient boundary condition is used at the exit which can be expressed as li et al 2020 12 c f s 0 t c 0 t t 0 0 t t 0 13 c f s x r t 0 where c 0 is the constant source concentration applied at the inlet r is system length and t 0 is the duration of injection 3 lattice boltzmann method 3 1 lattice boltzmann model based on the collision term the models used in the community of lb method can be classified into three kinds the bhatnagar gross krook model qian et al 1992 the two relaxation time model ginzburg et al 2008 and the multiple relaxation time model d humieres et al 2002 in this work we adopt the bhatnagar gross krook model for its simplicity and computational efficiency and its extension to the other model is straightforward essentially the governing equations for solute transport in dual permeability is a kind of convection diffusion equations see eqs 1 and 2 although various lb models for convection diffusion equations have been proposed in the past decades ginzburg 2005 rasin et al 2005 yoshida and nagaoka 2010b shi and guo 2009 wang et al 2015 huang and wu 2015 most of these lb models are confined to a standard convection diffusion equations making it can not be directly used to solve the governing equations of solute transport in dual permeability media after a careful examination we found that the main difficult arises from the depth dependent retardation h x f s appeared in the governing equation which must be incorporated into the lb equations inspired by the previous works huang and wu 2015 walsh and saar 2010 in the following we will construct a bhatnagar gross krook model for contaminant transport in dual permeability soil and show that the governing equations can be recovered correctly through the multi scale analysis since the governing equations in fast and slow velocity domain are expressed in a similar fashion here we just present the lattice model for the former case the evolution equation for the governing equation given by eq 1 is written as 14 ψ f h x f f i x c i δ t t δ t f i x t ψ f h x f 1 f i x c i δ t t 1 τ f i x t f i e q x t δ t f i where f i is the distribution function at position x and time t c i c e i is the set of possible discrete velocity direction with c δ x δ t here δ x and δ t are the lattice spacing and time step respectively being the discrete velocity for the one dimensional problem considered in this work the d1q3 3 velocity directions in 1 dimensional space lattice model is employed liu et al 2015 and it is defined as c i c 0 1 1 τ f is the dimensionless relaxation time and f i e q is the local equilibrium distribution function given by 15 f i e q w i c f where w i is the weight coefficient and the value of it in d1q3 model is taken as w 0 2 3 and w 1 2 1 6 to derive the correct macroscopic equation from the present model the discrete source term f i is expressed as 16 f i w i g with g ψ f v f c f x ψ f μ x c f α c s c f being the source term in addition the concentration c f is calculated by 17 c f i f i based on the evolution equation given by eq 1 one can find that different from standard lb equation a correction term of ψ f h x f 1 f i x c i δ t t is added in the evolution equation and the purpose of this treatment is to incorporate the effect of the depth dependent retardation without any modifying of the governing equation moreover according to the definition of the discrete forcing term we can see that the governing equation in our lbm is regarded as a pure diffusion equation with a corresponding source term and one major advantage of this handing is that it cloud directly kill the deviation term that may appeared in the macroscopic equation obtained by the multi scale analysis 3 2 the chapman enskog analysis in what follows we present a detailed analysis of derivation of the governing equations for solute transport in dual permeability media from the present lb model to make it clearer we first present the following conditions according to the definitions of f i e q and f i 18 i f i i f i e q c f i c i f i e q 0 i c i c i f i e q c s 2 c f i 19 i f i g i c i f i 0 where i is the unit matrix c s is the so call lattice speed satisfying c s 2 c 2 3 in addition the discrete velocity c i and the weight coefficient w i should obey the following relations 20 i w i 1 i c i w i 0 i c i c i w i c s 2 i applying the taylor expansion at second order in space ad first order in time to eq 14 we have 21 ψ f h x f f i δ t d i f i δ t 2 2 d i 2 f i f i 1 ψ f h x f f i δ t d i f i δ t 2 2 d i 2 f i 1 τ f f i f i e q δ t f i where d i t d i with d i c i in the chapman enskog analysis the time and space derivatives the distribution function and the source term can be expanded as 22 t ɛ t 1 ɛ 2 t 2 ɛ 1 23 f i n 0 ɛ n f i n f i ɛ f i 1 substituting the above two equations into eq 21 we can obtain the equations of eq 21 in different orders of ɛ as 24 o ɛ 0 f i 0 f i e q 25 o ɛ 1 ψ f h x f t 1 g i 0 d 1 i f i 0 1 τ f δ t f i 1 w i g 1 26 o ɛ 2 ψ f h x f d 1 i f i 1 ψ f h x f t 2 f i 0 ψ f h x f δ t 2 d 1 i 2 f i 0 1 ψ f h x f d 1 i f i 1 1 ψ f h x f δ t 2 d 1 i 2 f i 0 1 τ f δ t f i 2 since d 1 i t 1 d 1 i t 1 c i 1 eq 26 can be simplified as 27 ψ f h x f t 1 f i 1 d 1 i f i 1 ψ f h x f t 2 f i 0 ψ f h x f δ t 2 2 t 1 d 1 i f i 0 δ t 2 d 1 i 2 f i 0 1 τ f δ t f i 2 summing eqs 25 and 27 over i with the help of eq 20 and note that d 1 i 2 1 1 i we have 28 ψ f h x f t 1 c f g 1 29 1 i c i f i 1 ψ f h x f t 2 c f δ t 2 1 1 c s 2 c f i 0 in order to evaluate i c i f i 1 in eq 29 multiplying eq 25 by c i and taking summation over i we obtain 30 1 τ f δ t i c i f i 1 ψ f h x f t 1 i c i f i 0 1 i c i c i f i 0 i w i c i g 1 c s 2 1 c f thus eq 29 can be written as 31 ψ f h x f t 2 c f 1 τ f 1 2 δ t c s 2 1 c f based on the equations of eqs 28 and 31 we have 32 ψ f h x f t c f τ f 1 2 c s 2 δ t c f g comparing eq 32 with eq 1 the dimensionless relaxation time τ f is determined by ψ f d f c s 2 τ f 0 5 δ t from the above procedure it is clear that the governing equation for solute transport in dual permeability media can be recovered correctly from the present lb model without adopting any approximations in addition although there exists a space derivative in the discrete source term f i it can be realized locally by using eq 30 therefore the present method holds the main advantages of the standard lb model finally as is well known that the collision rule in lb model may become unstable when the dimensionless time τ f is close to its limit value of 0 5 d humieres et al 2002 to improve the stability of the present lb scheme a simple way is to normalize the governing equation by the average volumetric water contents ψ ψ f ψ s 2 then the relaxation parameter is obtained as ψ f d f c s 2 τ f 0 5 δ t ψ 4 verification in order to verify the present lb method two specific problems are simulated to begin with we consider a simplified case of the non reactive solute transport in a dual permeability porous media in leij et al 2012 by using the laplace transformation and matrix decomposition leij et al obtain an analytical solution for this problem base on the assumption of the same dispersivity in two domains in our simulations the boundary conditions are the same as that of leji et al s work and the simulations parameters are summarized in table 1 in addition the effluent concentration is used to determine the breakthrough curves btcs which is defined as leij et al 2012 33 c e q f c f q s c s q f q s where q f s θ f s v f s is the darcy velocity in the fast flow velocity domain or slow flow velocity domain lt 1 and q q f q s is the total darcy velocity further the volume averaged concentrations is also employed here for comparison which is give by 34 c v ψ f c f ψ s c s ψ f ψ s fig 2 shows the comparisons of the concentration profiles and the btcs between the present simulation results and the analytical solutions reported by leij et al 2012 where good agreement is obtained to further verify the numerical performance of the proposed lb method we also consider the solute transport in a soil with depth dependent reaction coefficients and the corresponding semi analytical solutions have been reported by gao et al 2013 with the numerical inverse laplace transform method note that the transport model adopted by gao et al 2013 is a special case of the present dual permeability model when ψ f ψ s q f q s 0 5 q and α the result are shown in fig 3 it can be seen clearly that the present numerical results are in good agreement with the corresponding semi analytical solutions the above two tests verify the applicability of the present lb method for contaminant transport in dual permeability media 5 results and discussion in this section we adopt the proposed lb approach to simulate the contaminant transport in dual permeability soil and the influences of the exchange coefficient pore velocity and depth dependent reaction rates on the concentration within each domain are investigate in detail by analyzing the btcs and the concentration curves besides unless otherwise stated the simulation parameters are presented in table 1 in which most of the above parameters have been widely used in some previous studies leij et al 2012 xie et al 2019 5 1 influence of mass exchange coefficient as is well known that the variation of the mass exchange rate α has a significant influence on the reversible transport process between slow and fast velocity domain in this subsection we intend to explore the effect of mass exchange coefficient on solute transport fig 4 illustrates the distributions of the dimensionless concentration in fast and slow velocity domain as well as the volume averaged solute at t 0 8 d under 0 5 d pulse input conditions for a relatively smaller mass exchange coefficient fig 4 a the solute transport in individual regions is relatively independent due to the limited solute exchange between the fast and slow velocity domain in addition it is noted that the combined volume averaged concentrations in such case have a clear bimodal behavior which can be described as a weighted sum of the concentrations in the two regions with increasing the mass exchange coefficient α the solute exchange between the two regions becomes significant such that slow velocity domain contains more solute near the entrance region 0 x 30 cm as a result the concentration profile in the fast velocity domain inclines to the left while it skews to the right side for the slow velocity domain moreover with the further increased of the mass exchange coefficient the bimodal phenomenon of volume averaged concentration becomes insignificant until it is disappeared as the exchange coefficient increases to 5 d 1 there exist a considerable solute transport and rapid exchange of solute masses between the dual permeability media domains leij et al 2012 causing the concentration curves in the two domains exhibit a similar pattern the btcs at x 50 cm is shown in fig 5 in which the parameters are the same as that used in fig 4 for a relatively lower exchange coefficient see fig 5 a due to the solute transport between the two domains is fairly weak such that the btc in the fast velocity domain is find to break through first and the peak value obtained for fast velocity domain is larger than that obtained for slow velocity domain we also find that the trailing phenomenon in the fast velocity domain is more distinct than that observed in slow velocity domain in addition the flux averaged effluent curve in such case shares a bimodal behavior when the exchange coefficient increases to 0 5 d 1 see fig 5 b there is more solute exchange in the dual permeability media causing the difference of the concentration profiles decreases and also we find that the bimodal behavior observed at α 0 05 d 1 in this condition is nearly disappeared the aforementioned phenomenon is more distinct when the mass exchange coefficient increases to 5 0 d 1 at which the btc has only a single peak and it shares a similar pattern with that of the concentration further the concentration difference in the two domains can be neglected as a result of the sufficient rapid exchange of the solute in the media 5 2 effect of pore water velocity we now turn to investigate the pore water velocity v f s effects based on its definition the pore water velocity is the ratio between the darcy flux and the volumetric water content where the darcy flux depends on the permeability and the volumetric area in the system and it denotes the amount of water and dissolved contaminants entering moving and leaving the media leij et al 2012 because the darcy flux and water content is relative to the whole bulk area the volumetric water content affects the rate of solute transport through the domain in this setting fig 6 illustrates the influence of the volumetric water content and the darcy flux in the contaminant breakthrough in which the total darcy flux and water content are set to be 15 cm d 1 and 0 5 respectively as shown in fig 6 a when the main flow and contaminant transport occur in the fast velocity domain one can observed a short rectangular peak in the high velocity domain together with a smooth smaller peak in the low velocity domain if we take the water contents in the two domains are the same but remain the setting of the darcy fluxes as fig 6 a it is noted that the double peaks observed in fig 6 a is disappeared instead of a single peak besides compared to that in fig 6 a the peak in high velocity domain appears later and its value is also found to be much smaller which an opposite phenomenon is observed in the slow velocity domain if the main flow and solute transport occur in slow velocity domain see fig 6 c it is found that the concentration pattern in slow velocity domain is similar to that observed in fig 6 b moreover we note that the occurrence time of the peak in fast velocity domain is a little bigger than that in fig 6 a which is caused by the fact that the residence times in this case is fairly small 5 3 effects of depth dependent reaction coefficients all the above simulation results are discussed by considering the influence of the depth dependent reaction coefficients in what follows we intend to conduct a comparison between the case with and without the depth dependent reaction processes for the sake of simplicity the lb models used for the case with contaminant transport in a finite system with constant and depth dependent effects are named as the lb fc model and the lb fd model respectively in addition in order to make the comparisons more complete we consider two constant reaction rates in the lb fc model the maximum reaction i e k d k 0 μ x μ 0 and the reaction rate at the observed depth x 0 i e k d k d x μ μ x fig 7 shows the btcs of effluent concentration c e between lb fc and lb fd for the observed depths of x 0 10 cm and x 0 40 cm it can be found from fig 7 that the bimodal behavior occurs for all cases of the current parameters however the btc obtained from lb fc at k d k 0 μ x μ 0 has the smallest concentrations at the early times in addition the occurrence time of the peak in this case is found to larger than the other two cases together with the smallest peak concentrations and this phenomenon is more distinct for when the observed depth increased from 20 cm to 120 cm in contrast we observe that the lb fc model with k d k d x μ μ x exhibits the earliest arrival of peak concentrations and also has the highest peak concentrations during the solute transport process finally when the depth dependent reaction coefficients are taken into account since the reaction coefficients in lb fd are between k d x μ d x and k 0 μ 0 the corresponding btcs are located in the transition region between the above two cases comparing the curves in this figure we note that the peak concentration obtained from the lb fd model decreases as x 0 increases from 10 cm to 40 cm 6 application of the proposed lb method to test the practical application of the proposed lb method the developed approach is used to simulate the solute transport in an andisol and the obtained numerical results are also compared with the experimental data generally andisols are developed from volcanic ash consisting of noncrystalline materials like allophone and ferrihydrite leij et al 2012 because they comprise 17 of the land in japan solute transport in andisols has drawn considerable interest from some researchers in 2012 leij et al 2012 conducted solute displacement experiments in different soil columns packed with an andisol in their experiments the solute is the cacl 2 and a peristaltic pump was used to establish a steady state saturation flow the concentration of cacl 2 at four positions along the column was monitored by determining the electrical conductivity of the soil solution with four probe sensors see leij et al 2012 for some details on their experiment the parameters used in the our simulations are presented in table 2 and they have also been adopted in previous works leij et al 2012 sciortino et al 2012 fig 8 depicts the btcs observed at four different depths in which the experimental data the numerical results obtained using advection dispersion model leij et al 2012 and mobile immobile model leij et al 2012 and the present lb method are all presented it can be clearly found that our numerical results are in good agreement with the experimental observations at four different depths in addition although the solution for advection dispersion and mobile immobile models could accurately describe the variation of solute concentration at the topsoil the concentration gradually shifts the experimental results with increasing depth it is particularly noteworthy that three inflection points of observed btcs are also accurately simulated by the numerical simulation and the bimodal behavior are clearly observed from the lb results based on these numerical results we can confident that the present lb approach is capable of accurately simulating the btcs in deep soil solute 7 conclusion this work proposes an lb approach for contaminant transport in dual permeability media and the multi scale analysis shows that the corresponding governing equations can be correctly recovered from the lb evolution equation the model accuracy is verified by simulating non reactive contaminant transport in dual permeability solid and solute transport in media with depth dependent reaction rates with this model the effects of exchange coefficient pore water velocity and depth dependent reaction rates on the solute concentration are then investigated in detail by analyzing the breakthrough and the concentration curves the results show that as the exchange coefficient increases the solute exchange rate between the two regions increases while the concentration difference gradually decreases and the solute curve and btc gradually change from a double peak to a single peak when the exchange coefficient is larger enough each solute particle experiences the same apparent velocity leading the distributions of the concentration in the two domains are almost the same in addition we find that the variation of the flow rates in the two domains has a great effect on the contaminant transport and specifically the single peak observed in the btcs changes to the double peak with increasing the volumetric water content further a comparison of the contaminant transport in dual permeability soil with and without depth dependent rates show that the btcs obtained from lb fd model lie in the transition zone between the two extreme cases of constant rate reactions at different depths and these observations are similar to previous work xie et al 2019 finally we adopt the present lb method to simulate solute transport in an andisol and the numerical results show that the present method could accurately describe the solute concentration at different depths and it is also capable of capturing the bimodal behavior of the btcs at different depths the present numerical results prove the feasibility of the proposed method in simulating contaminant transport in a dual permeability soil credit authorship contribution statement jiangxu huang methodology software investigation writing lei wang conceptualization supervision writing review editing xinyue liu supervision methodology declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests lei wang reports financial support was provided by the national natural science foundation of china grant no 12002320 and the fundamental research funds for the central universities grant no cugqt2023001 acknowledgments one of authors lei wang is grateful to shuang xie and zhang wen for their useful discussions we also would like to thank anonymous referees for their valuable comments which greatly improved the work this work is financially supported by the national natural science foundation of china grant no 12002320 
2150,dual permeability models are currently under active investigation for predicting the flow and transport of pollutant concentration in porous media the basic idea of these models is usually to separate the medium into two distinct flow regions with separate hydraulic and solute movement properties most of the dual permeability approaches presented to date assume the reaction terms to be independent of space for local reaction processes in soils however the depth effects are important and should be incorporated into the dual permeability models to reveal the transport phenomenon in such case the best way is to obtain an exact solution with a suitable analytical approach but it may be hard or even impossible for this general scenario as such this paper seeks an alternative method and propose a lattice boltzmann method for solute transport in dual permeability media the chapman enskog analysis shows that the present model can recover the governing equations correctly the capability and accuracy of this model is first verified by two problems the non reactive mass transfer in dual permeability porous media and the solute transport in a depth dependent soil with this model we further studied the contaminant transport in dual permeability soil with depth dependent reaction rates the numerical results show that when the exchange coefficient is relatively smaller there are usually two peaks for the breakthrough curves btcs whereas it degenerates to a single peak as the exchange coefficient increases in addition we note that the distributions of the concentration in different domains are nearly the same for a larger exchange coefficient as for the pore water velocity it is found that when the difference in the pore water velocity in the two domains is significant the btc exhibits a bimodal distribution however there is only one peak for the btcs when the above difference is insignificant further as compared with the constant reaction rate cases we observe that the btcs obtained for the media with depth dependent rates lie in the intermediate zone defined by the above two extremes finally we adopt the current approach to simulate the solute transport in an andisol and observe that the difference between the numerical and experimental results is insignificant indicating our approach is capable in modeling solute transport in porous media keywords lattice boltzmann method solute transport dual permeability depth dependent reaction data availability data will be made available on request 1 introduction with the growing concern about the environment and health the transport of contaminants such as residual pesticides and fertilizers waste permeate industrial effluents and radioactive substances in groundwater have attracted great interest from both academic and industrial mackay et al 1985 mccarthy and zachara 1989 karri et al 2021 in this setting the accurate prediction of the contaminant content concentration changes and transport patterns in the porous media are very important for controlling the migration of contaminants and pollution prevention gupta and ali 2013 over the past few decades researchers have proposed various mathematical models for simulating solute transport in porous media among them the most widely used model is the advection dispersion equation sun et al 2020 since the average displacement and the contaminant spreading in advection dispersion model are only described by a uniform effective velocity and a uniform dispersal rate this model is just adequate for simulating the equilibrium transport in homogeneous media however because the anomalous dispersion behavior is significant for the solute transport in heterogeneous media e g solid matrix the advection dispersion model is less sufficient to predict the non equilibrium transport in these medias beven 1991 to this end several multi domain models are developed to model the non equilibrium flow in heterogeneous media in 1964 coats and smith coats and smith 1964 developed a differential capacitance model to describe the dispersion in porous media by taking the dead end pore structure into account after that van genuchten and wierenga 1976 proposed a mobile immobile model for mass transfer in a sorbing porous media in 1976 in which the pore space consists of the mobile and the immobile regions it should be noted that the fluid flow in mobile immobile model is assume to occur in the mobile region whereas there is no flow in the immobile domain in such case advection and dispersion processes only occur in the mobile domain for the diffusive transport between these two regions it can be described by solving the fick s equation rappoldt 1990 van genuchten and dalton 1986 leij et al 2012 later leij et al 2012 extended the mobile immobile model to a more general scenario by considering the flow and dispersion in both regions and further proposed a dual advection dispersion equation in dual permeability media which can be seen as a generalized version of the traditional advection dispersion and the mobile immobile models with this model sciortino et al 2015 qualitative studied the solute transport in dual permeability media and the numerical results agree well with the experiment more recently xie et al 2019 developed another mobile mobile model for contaminant transport in dual permeability media unlike previous models the authors pointed out that due to the reaction process in soils is always related to the amount and type of organic matter and to the microbial activity which are strongly dependent on space flury et al 1998 gao et al 2013 the depth dependent reaction coefficients are considered in their model here the term depth dependent means that during the transport of contaminants through media the adsorption and degradation processes vary with depth which further affects the fate and transport behavior of contaminants in soils flury et al 1998 gao et al 2013 in this work we concentrate on the solute transport in dual permeability porous media with depth dependent reaction coefficients which is a more general model in predicting the fate and movement of contaminants in soils there is no doubt that the best way to revel the solute transport in this case is the analytical method however from a mathematical point of view since contaminants transport in dual permeability media is described by a system of convection diffusion equations with strong coupling it is not easy to obtain the corresponding analytical solutions if any they are often restricted to the simplified cases leij et al 2012 šimůnek and van genuchten 2008 therefore developing numerical schemes for the solution of contaminant transport in dual permeability porous media is desirable xie et al 2019 šimůnek and van genuchten 2008 as a kinetic based numerical method the lattice boltzmann lb method is nevertheless attractive for simulating fluid flows because it is easy to use for programming and is ability to handle complex geometry with the simple bounce back rule chen and doolen 1998 miller et al 1998 from early in its development the lb method has advanced as a promising tool for simulating flow through porous media in 2002 kang et al 2002 developed a lb model for simulation of the chemical dissolution in porous media subsequently ginzburg and d humieres 2003 analyzed the accuracy of the bounce back rule and proposed a multireflection boundary conditions for lb models almost at the same time guo and zhao 2002 propose a lb model for simulating incompressible porous media flow at macroscopic level afterward pan et al 2006 quantitatively evaluate the numerical performance of the lb method in modeling flow through porous media pan et al 2004 in addition miller et al 1998 also adopted the lb model to simulate the two phase flow in porous media at pore scale more recently ginzburg et al 2015 presented a detail analysis on the brinkman lb schemes and compared the results with that of the linear finite element method ju et al 2022 carried out a pore scale numerical simulation of the convective mixing process in geological storage on the other hand yang et al 2016 and zhao et al 2019 also conducted several comprehensive comparisons for different pore scale approaches in which the performance of the lb method is compared with some other pore scale models such as the pore network model and the smoothed particle hydrodynamics model these available works clearly demonstrate the effectiveness and accuracy of lb method in modeling flow through porous media unfortunately to the best of our knowledge there still no mature lb model that can be directly used to simulate solute transport in dual permeability media recently several groups have developed lb models for modeling solute transport in a variety of fields zhang et al 2002 zhou 2009 walsh and saar 2010 ginzburg 2005 peng et al 2011 yoshida and nagaoka 2010a liu et al 2015 ru et al 2021 however since the governing equation for solute transport in most of these works is described by a standard convection diffusion equation like ϕ t u ϕ υ ϕ f here ϕ is the solute concentration u is the fluid velocity υ is the diffusion coefficient and f is the source sink term the straightforward application of these developed lb models for simulating the solute transport in dual permeability media with depth dependent reaction coefficients may fail to capture the correct transport behavior the inherent difficulty stems from the fact that there exists a depth dependent retardation parameter in front of ϕ t for this complex dual permeability model which brings some additional difficulties in developing the lb method in this setting the present work aims to develop an effective lb method for solute transport in dual permeability porous media with depth dependent reaction coefficients in contrast to previous works zhang et al 2002 zhou 2009 walsh and saar 2010 ginzburg 2005 peng et al 2011 yoshida and nagaoka 2010a liu et al 2015 ru et al 2021 the convection term appeared in the governing equations is treated as a source term in the lb equation rather than being directly recovered by the evolution equation in addition in order to handle the depth dependent retardation parameter the collision process in our lb method is modified by adding another extra term as we shall see the governing equations can be recovered correctly with the present method through the chapman enskog analysis the paper is organized as follows in the next section we describe the physical problem and the governing equations initial and the boundary conditions in section 3 we present the lb equations for the solute transport in dual permeability media in section 4 the verification and the solution procedure is given in section 5 the numerical results and discussion are presented and discussed the practical application of the present lbm is illustrated in section 6 the conclusions are drawn in the last section 2 mathematical model 2 1 governing equations this work considers a more general model to describe the contaminant transport in dual permeability media along the vertical direction see fig 1 different from the aforementioned mobile immobile model the present model has two distinct differences for one thing the advection dispersion transport is applied to both domains leij et al 2012 and for another it includes the influence of the depth dependent reaction process gao et al 2013 in such a case the solute transport within the porous media through three distinct mechanisms i e convection dispersion and solute exchange between the domain with fast flow velocity and the domain with slow flow velocity besides we assume that the contaminant adsorption is characterized by a isotherm state and that the solute degradation in the system is the so called first order process in this setting the governing equations for the contaminant transport in dual permeability media can be given as xie et al 2019 1 ψ f h x f c f t ψ f d f 2 c f x 2 ψ f v f c f x ψ f μ x c f α c s c f 2 ψ s h x s c s t ψ s d s 2 c s x 2 ψ s v s c s x ψ s μ x c s α c f c s where the parameters in the fast and slow velocity domain are described by the subscript f and s respectively t is the time t x is the spatial coordinate l c f s is the solute concentration ψ f s is the volumetric water content in different regions per bulk volume l 3 l 3 and the total volumetric water content is then given as ψ ψ f ψ s v f s is the pore water velocity lt 1 and it is usually assumed that v f v s leij et al 2012 α is an effective coefficient for solute transport between the two aqueous regions t 1 μ x is the depth dependent degradation rate t 1 d f s denotes the dispersion coefficient relying on the pore water velocity which can be expressed as 3 d f λ f v f d 0 4 d s λ s v s d 0 in which d 0 represents the effective diffusion coefficient in the porous media l whose value is much smaller in contrast to λ v such that it is usually ignored in studying the problem of contaminant transport in dual permeability porous media li et al 2020 λ is the dispersivity in the porous media l 2 t 1 moreover h x f s is the retardation factor relying on the depth and it can be given by flury et al 1998 5 h x f 1 ρ k d x f ψ f 6 h x s 1 ρ k d x s ψ s with ρ and k d x being the density ml 3 and adsorption coefficients l 3 m 1 respectively according to previous work flury et al 1998 the depth dependent organic matter content microbial activity and clay minerals in soils have a significant influence on the solute adsorption and degradation rates and flury et al 1998 gao et al 2013 found that the expressions of these two rates can be defined as a sigmoidal form 7 k d x k 0 cosh 2 x x 0 8 μ x μ 0 cosh 2 x x 0 in which k 0 and μ 0 are constants and they denote the maximum values of k d x and μ x x 0 is the transition depth using to describe the reaction response rate for different depth specifically for a relatively smaller value of x 0 the reaction coefficient decreases significantly xie et al 2019 the governing equations described above is a general dual permeability model when the influence of the depth is ignored the equations degenerates into the traditional form 9 ψ f h c f t ψ f d f 2 c f x 2 ψ f v f c f x ψ f μ c f α c s c f 10 ψ s h c s t ψ s d s 2 c s x 2 ψ s v s c s x ψ s μ c s α c f c s where h and μ are the constant retardation and degradation factors to have a better understanding of the solute transport in dual permeability media a comparison between the case with and without the depth dependent reaction processes will also be discussed in this work 2 2 initial and boundary conditions to close the system we need to use appropriate boundary condition for the concentration this work deals with the solute transport in a system with finite volume and initially there is no solute in the medium genuchten and parker 1984 i e 11 c f s x 0 0 0 x r in addition a pulse type boundary condition is applied to the inlet while a zero gradient boundary condition is used at the exit which can be expressed as li et al 2020 12 c f s 0 t c 0 t t 0 0 t t 0 13 c f s x r t 0 where c 0 is the constant source concentration applied at the inlet r is system length and t 0 is the duration of injection 3 lattice boltzmann method 3 1 lattice boltzmann model based on the collision term the models used in the community of lb method can be classified into three kinds the bhatnagar gross krook model qian et al 1992 the two relaxation time model ginzburg et al 2008 and the multiple relaxation time model d humieres et al 2002 in this work we adopt the bhatnagar gross krook model for its simplicity and computational efficiency and its extension to the other model is straightforward essentially the governing equations for solute transport in dual permeability is a kind of convection diffusion equations see eqs 1 and 2 although various lb models for convection diffusion equations have been proposed in the past decades ginzburg 2005 rasin et al 2005 yoshida and nagaoka 2010b shi and guo 2009 wang et al 2015 huang and wu 2015 most of these lb models are confined to a standard convection diffusion equations making it can not be directly used to solve the governing equations of solute transport in dual permeability media after a careful examination we found that the main difficult arises from the depth dependent retardation h x f s appeared in the governing equation which must be incorporated into the lb equations inspired by the previous works huang and wu 2015 walsh and saar 2010 in the following we will construct a bhatnagar gross krook model for contaminant transport in dual permeability soil and show that the governing equations can be recovered correctly through the multi scale analysis since the governing equations in fast and slow velocity domain are expressed in a similar fashion here we just present the lattice model for the former case the evolution equation for the governing equation given by eq 1 is written as 14 ψ f h x f f i x c i δ t t δ t f i x t ψ f h x f 1 f i x c i δ t t 1 τ f i x t f i e q x t δ t f i where f i is the distribution function at position x and time t c i c e i is the set of possible discrete velocity direction with c δ x δ t here δ x and δ t are the lattice spacing and time step respectively being the discrete velocity for the one dimensional problem considered in this work the d1q3 3 velocity directions in 1 dimensional space lattice model is employed liu et al 2015 and it is defined as c i c 0 1 1 τ f is the dimensionless relaxation time and f i e q is the local equilibrium distribution function given by 15 f i e q w i c f where w i is the weight coefficient and the value of it in d1q3 model is taken as w 0 2 3 and w 1 2 1 6 to derive the correct macroscopic equation from the present model the discrete source term f i is expressed as 16 f i w i g with g ψ f v f c f x ψ f μ x c f α c s c f being the source term in addition the concentration c f is calculated by 17 c f i f i based on the evolution equation given by eq 1 one can find that different from standard lb equation a correction term of ψ f h x f 1 f i x c i δ t t is added in the evolution equation and the purpose of this treatment is to incorporate the effect of the depth dependent retardation without any modifying of the governing equation moreover according to the definition of the discrete forcing term we can see that the governing equation in our lbm is regarded as a pure diffusion equation with a corresponding source term and one major advantage of this handing is that it cloud directly kill the deviation term that may appeared in the macroscopic equation obtained by the multi scale analysis 3 2 the chapman enskog analysis in what follows we present a detailed analysis of derivation of the governing equations for solute transport in dual permeability media from the present lb model to make it clearer we first present the following conditions according to the definitions of f i e q and f i 18 i f i i f i e q c f i c i f i e q 0 i c i c i f i e q c s 2 c f i 19 i f i g i c i f i 0 where i is the unit matrix c s is the so call lattice speed satisfying c s 2 c 2 3 in addition the discrete velocity c i and the weight coefficient w i should obey the following relations 20 i w i 1 i c i w i 0 i c i c i w i c s 2 i applying the taylor expansion at second order in space ad first order in time to eq 14 we have 21 ψ f h x f f i δ t d i f i δ t 2 2 d i 2 f i f i 1 ψ f h x f f i δ t d i f i δ t 2 2 d i 2 f i 1 τ f f i f i e q δ t f i where d i t d i with d i c i in the chapman enskog analysis the time and space derivatives the distribution function and the source term can be expanded as 22 t ɛ t 1 ɛ 2 t 2 ɛ 1 23 f i n 0 ɛ n f i n f i ɛ f i 1 substituting the above two equations into eq 21 we can obtain the equations of eq 21 in different orders of ɛ as 24 o ɛ 0 f i 0 f i e q 25 o ɛ 1 ψ f h x f t 1 g i 0 d 1 i f i 0 1 τ f δ t f i 1 w i g 1 26 o ɛ 2 ψ f h x f d 1 i f i 1 ψ f h x f t 2 f i 0 ψ f h x f δ t 2 d 1 i 2 f i 0 1 ψ f h x f d 1 i f i 1 1 ψ f h x f δ t 2 d 1 i 2 f i 0 1 τ f δ t f i 2 since d 1 i t 1 d 1 i t 1 c i 1 eq 26 can be simplified as 27 ψ f h x f t 1 f i 1 d 1 i f i 1 ψ f h x f t 2 f i 0 ψ f h x f δ t 2 2 t 1 d 1 i f i 0 δ t 2 d 1 i 2 f i 0 1 τ f δ t f i 2 summing eqs 25 and 27 over i with the help of eq 20 and note that d 1 i 2 1 1 i we have 28 ψ f h x f t 1 c f g 1 29 1 i c i f i 1 ψ f h x f t 2 c f δ t 2 1 1 c s 2 c f i 0 in order to evaluate i c i f i 1 in eq 29 multiplying eq 25 by c i and taking summation over i we obtain 30 1 τ f δ t i c i f i 1 ψ f h x f t 1 i c i f i 0 1 i c i c i f i 0 i w i c i g 1 c s 2 1 c f thus eq 29 can be written as 31 ψ f h x f t 2 c f 1 τ f 1 2 δ t c s 2 1 c f based on the equations of eqs 28 and 31 we have 32 ψ f h x f t c f τ f 1 2 c s 2 δ t c f g comparing eq 32 with eq 1 the dimensionless relaxation time τ f is determined by ψ f d f c s 2 τ f 0 5 δ t from the above procedure it is clear that the governing equation for solute transport in dual permeability media can be recovered correctly from the present lb model without adopting any approximations in addition although there exists a space derivative in the discrete source term f i it can be realized locally by using eq 30 therefore the present method holds the main advantages of the standard lb model finally as is well known that the collision rule in lb model may become unstable when the dimensionless time τ f is close to its limit value of 0 5 d humieres et al 2002 to improve the stability of the present lb scheme a simple way is to normalize the governing equation by the average volumetric water contents ψ ψ f ψ s 2 then the relaxation parameter is obtained as ψ f d f c s 2 τ f 0 5 δ t ψ 4 verification in order to verify the present lb method two specific problems are simulated to begin with we consider a simplified case of the non reactive solute transport in a dual permeability porous media in leij et al 2012 by using the laplace transformation and matrix decomposition leij et al obtain an analytical solution for this problem base on the assumption of the same dispersivity in two domains in our simulations the boundary conditions are the same as that of leji et al s work and the simulations parameters are summarized in table 1 in addition the effluent concentration is used to determine the breakthrough curves btcs which is defined as leij et al 2012 33 c e q f c f q s c s q f q s where q f s θ f s v f s is the darcy velocity in the fast flow velocity domain or slow flow velocity domain lt 1 and q q f q s is the total darcy velocity further the volume averaged concentrations is also employed here for comparison which is give by 34 c v ψ f c f ψ s c s ψ f ψ s fig 2 shows the comparisons of the concentration profiles and the btcs between the present simulation results and the analytical solutions reported by leij et al 2012 where good agreement is obtained to further verify the numerical performance of the proposed lb method we also consider the solute transport in a soil with depth dependent reaction coefficients and the corresponding semi analytical solutions have been reported by gao et al 2013 with the numerical inverse laplace transform method note that the transport model adopted by gao et al 2013 is a special case of the present dual permeability model when ψ f ψ s q f q s 0 5 q and α the result are shown in fig 3 it can be seen clearly that the present numerical results are in good agreement with the corresponding semi analytical solutions the above two tests verify the applicability of the present lb method for contaminant transport in dual permeability media 5 results and discussion in this section we adopt the proposed lb approach to simulate the contaminant transport in dual permeability soil and the influences of the exchange coefficient pore velocity and depth dependent reaction rates on the concentration within each domain are investigate in detail by analyzing the btcs and the concentration curves besides unless otherwise stated the simulation parameters are presented in table 1 in which most of the above parameters have been widely used in some previous studies leij et al 2012 xie et al 2019 5 1 influence of mass exchange coefficient as is well known that the variation of the mass exchange rate α has a significant influence on the reversible transport process between slow and fast velocity domain in this subsection we intend to explore the effect of mass exchange coefficient on solute transport fig 4 illustrates the distributions of the dimensionless concentration in fast and slow velocity domain as well as the volume averaged solute at t 0 8 d under 0 5 d pulse input conditions for a relatively smaller mass exchange coefficient fig 4 a the solute transport in individual regions is relatively independent due to the limited solute exchange between the fast and slow velocity domain in addition it is noted that the combined volume averaged concentrations in such case have a clear bimodal behavior which can be described as a weighted sum of the concentrations in the two regions with increasing the mass exchange coefficient α the solute exchange between the two regions becomes significant such that slow velocity domain contains more solute near the entrance region 0 x 30 cm as a result the concentration profile in the fast velocity domain inclines to the left while it skews to the right side for the slow velocity domain moreover with the further increased of the mass exchange coefficient the bimodal phenomenon of volume averaged concentration becomes insignificant until it is disappeared as the exchange coefficient increases to 5 d 1 there exist a considerable solute transport and rapid exchange of solute masses between the dual permeability media domains leij et al 2012 causing the concentration curves in the two domains exhibit a similar pattern the btcs at x 50 cm is shown in fig 5 in which the parameters are the same as that used in fig 4 for a relatively lower exchange coefficient see fig 5 a due to the solute transport between the two domains is fairly weak such that the btc in the fast velocity domain is find to break through first and the peak value obtained for fast velocity domain is larger than that obtained for slow velocity domain we also find that the trailing phenomenon in the fast velocity domain is more distinct than that observed in slow velocity domain in addition the flux averaged effluent curve in such case shares a bimodal behavior when the exchange coefficient increases to 0 5 d 1 see fig 5 b there is more solute exchange in the dual permeability media causing the difference of the concentration profiles decreases and also we find that the bimodal behavior observed at α 0 05 d 1 in this condition is nearly disappeared the aforementioned phenomenon is more distinct when the mass exchange coefficient increases to 5 0 d 1 at which the btc has only a single peak and it shares a similar pattern with that of the concentration further the concentration difference in the two domains can be neglected as a result of the sufficient rapid exchange of the solute in the media 5 2 effect of pore water velocity we now turn to investigate the pore water velocity v f s effects based on its definition the pore water velocity is the ratio between the darcy flux and the volumetric water content where the darcy flux depends on the permeability and the volumetric area in the system and it denotes the amount of water and dissolved contaminants entering moving and leaving the media leij et al 2012 because the darcy flux and water content is relative to the whole bulk area the volumetric water content affects the rate of solute transport through the domain in this setting fig 6 illustrates the influence of the volumetric water content and the darcy flux in the contaminant breakthrough in which the total darcy flux and water content are set to be 15 cm d 1 and 0 5 respectively as shown in fig 6 a when the main flow and contaminant transport occur in the fast velocity domain one can observed a short rectangular peak in the high velocity domain together with a smooth smaller peak in the low velocity domain if we take the water contents in the two domains are the same but remain the setting of the darcy fluxes as fig 6 a it is noted that the double peaks observed in fig 6 a is disappeared instead of a single peak besides compared to that in fig 6 a the peak in high velocity domain appears later and its value is also found to be much smaller which an opposite phenomenon is observed in the slow velocity domain if the main flow and solute transport occur in slow velocity domain see fig 6 c it is found that the concentration pattern in slow velocity domain is similar to that observed in fig 6 b moreover we note that the occurrence time of the peak in fast velocity domain is a little bigger than that in fig 6 a which is caused by the fact that the residence times in this case is fairly small 5 3 effects of depth dependent reaction coefficients all the above simulation results are discussed by considering the influence of the depth dependent reaction coefficients in what follows we intend to conduct a comparison between the case with and without the depth dependent reaction processes for the sake of simplicity the lb models used for the case with contaminant transport in a finite system with constant and depth dependent effects are named as the lb fc model and the lb fd model respectively in addition in order to make the comparisons more complete we consider two constant reaction rates in the lb fc model the maximum reaction i e k d k 0 μ x μ 0 and the reaction rate at the observed depth x 0 i e k d k d x μ μ x fig 7 shows the btcs of effluent concentration c e between lb fc and lb fd for the observed depths of x 0 10 cm and x 0 40 cm it can be found from fig 7 that the bimodal behavior occurs for all cases of the current parameters however the btc obtained from lb fc at k d k 0 μ x μ 0 has the smallest concentrations at the early times in addition the occurrence time of the peak in this case is found to larger than the other two cases together with the smallest peak concentrations and this phenomenon is more distinct for when the observed depth increased from 20 cm to 120 cm in contrast we observe that the lb fc model with k d k d x μ μ x exhibits the earliest arrival of peak concentrations and also has the highest peak concentrations during the solute transport process finally when the depth dependent reaction coefficients are taken into account since the reaction coefficients in lb fd are between k d x μ d x and k 0 μ 0 the corresponding btcs are located in the transition region between the above two cases comparing the curves in this figure we note that the peak concentration obtained from the lb fd model decreases as x 0 increases from 10 cm to 40 cm 6 application of the proposed lb method to test the practical application of the proposed lb method the developed approach is used to simulate the solute transport in an andisol and the obtained numerical results are also compared with the experimental data generally andisols are developed from volcanic ash consisting of noncrystalline materials like allophone and ferrihydrite leij et al 2012 because they comprise 17 of the land in japan solute transport in andisols has drawn considerable interest from some researchers in 2012 leij et al 2012 conducted solute displacement experiments in different soil columns packed with an andisol in their experiments the solute is the cacl 2 and a peristaltic pump was used to establish a steady state saturation flow the concentration of cacl 2 at four positions along the column was monitored by determining the electrical conductivity of the soil solution with four probe sensors see leij et al 2012 for some details on their experiment the parameters used in the our simulations are presented in table 2 and they have also been adopted in previous works leij et al 2012 sciortino et al 2012 fig 8 depicts the btcs observed at four different depths in which the experimental data the numerical results obtained using advection dispersion model leij et al 2012 and mobile immobile model leij et al 2012 and the present lb method are all presented it can be clearly found that our numerical results are in good agreement with the experimental observations at four different depths in addition although the solution for advection dispersion and mobile immobile models could accurately describe the variation of solute concentration at the topsoil the concentration gradually shifts the experimental results with increasing depth it is particularly noteworthy that three inflection points of observed btcs are also accurately simulated by the numerical simulation and the bimodal behavior are clearly observed from the lb results based on these numerical results we can confident that the present lb approach is capable of accurately simulating the btcs in deep soil solute 7 conclusion this work proposes an lb approach for contaminant transport in dual permeability media and the multi scale analysis shows that the corresponding governing equations can be correctly recovered from the lb evolution equation the model accuracy is verified by simulating non reactive contaminant transport in dual permeability solid and solute transport in media with depth dependent reaction rates with this model the effects of exchange coefficient pore water velocity and depth dependent reaction rates on the solute concentration are then investigated in detail by analyzing the breakthrough and the concentration curves the results show that as the exchange coefficient increases the solute exchange rate between the two regions increases while the concentration difference gradually decreases and the solute curve and btc gradually change from a double peak to a single peak when the exchange coefficient is larger enough each solute particle experiences the same apparent velocity leading the distributions of the concentration in the two domains are almost the same in addition we find that the variation of the flow rates in the two domains has a great effect on the contaminant transport and specifically the single peak observed in the btcs changes to the double peak with increasing the volumetric water content further a comparison of the contaminant transport in dual permeability soil with and without depth dependent rates show that the btcs obtained from lb fd model lie in the transition zone between the two extreme cases of constant rate reactions at different depths and these observations are similar to previous work xie et al 2019 finally we adopt the present lb method to simulate solute transport in an andisol and the numerical results show that the present method could accurately describe the solute concentration at different depths and it is also capable of capturing the bimodal behavior of the btcs at different depths the present numerical results prove the feasibility of the proposed method in simulating contaminant transport in a dual permeability soil credit authorship contribution statement jiangxu huang methodology software investigation writing lei wang conceptualization supervision writing review editing xinyue liu supervision methodology declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests lei wang reports financial support was provided by the national natural science foundation of china grant no 12002320 and the fundamental research funds for the central universities grant no cugqt2023001 acknowledgments one of authors lei wang is grateful to shuang xie and zhang wen for their useful discussions we also would like to thank anonymous referees for their valuable comments which greatly improved the work this work is financially supported by the national natural science foundation of china grant no 12002320 
2151,countermeasures against seawater intrusion swi are critical to prevent coastal groundwater resources from deterioration subsurface dams have been recognized as one of effective approaches to prevent swi but most likely to produce residual saltwater at the landside of the dam understanding dynamic behaviors and removal mechanism of residual saltwater can facilitate aquifer desalinization especially under combined effect of subsurface dams and hydraulic controls little attention has been paid to synergistic impact on residual saltwater removal this study performed laboratory scale experiments and numerical simulations to investigate residual saltwater trapped in the storage area upon construction of a subsurface dam along with saltwater discharge freshwater recharge effects of subsurface dam designs aquifer properties as well as discharge and recharge rates on the flow and salinity transport process were explored and compared in a coastal aquifer two indexes including a reduction rate of residual saltwater length rrsl and removal rate of residual salt mass rrsm were introduced to quantify effectiveness of residual saltwater removal experimental and numerical results found that the subsurface dam needs a minimum effective height to achieve complete removal of residual saltwater moreover a shorter subsurface dam e g 9 cm in the experiment achieves a faster removal rate compared to a taller dam e g 15 cm particularly attenuation of relatively low concentration mixing zone between 10 and 50 isolines was a quite slow process saltwater discharge or freshwater recharge near the dam exhibits more effectiveness in desalinization than far from it furthermore extraction injection imposed more remarkable influences on saltwater removal than aquifer properties findings from the study have significant implications in better understanding of residual saltwater removal mechanism and timescale for nearshore groundwater systems keywords seawater intrusion subsurface dam saltwater removal laboratory experiment numerical simulation data availability data will be made available on request 1 introduction groundwater is an important freshwater resource in coastal aquifer with the increasing population water demand has exaggerated and led to fresh groundwater over exploitation in coastal areas marston et al 2015 walther et al 2017 inland groundwater levels fall below the sea level and seawater would flow landward resulting in serious deterioration of the inland aquifer in some cases seawater intrusion swi led to soil salinization and threaten water supplies and thereby reduced agricultural productivity li et al 2014 post and werner 2017 yin et al 2021 thus swi remediation turns to be critical for water utilization but highly challenging due to complex hydrogeological conditions and hydrodynamic processes physical barriers werner et al 2013 wu et al 2020 zheng et al 2020 as well as hydraulic controls ebeling et al 2019 masciopinto 2013 are two major groups of engineering approaches to prevent encroachment of seawater among them subsurface physical barriers such as subsurface dams or cutoff walls have shown to be effective measures in many countries owing to stable performance abdoulhalik and ahmed 2017a armanuos et al 2019 senthilkumar and elango 2011 subsurface dams are essentially impermeable walls constructed at the bottom of the aquifer leaving an opening at the top of the barrier for upstream fresh groundwater discharge cutoff walls cover the upper part of the aquifer while leaving an opening at the bottom wu et al 2020 these practical engineering solutions have artificially changed flow hydrodynamics in the aquifer by altering a portion of the system despite being relatively costly subsurface barriers have been constructed worldwide for swi control in 1988 the u s army corps of engineers built temporary underground barriers in new orleans which limited upstream swi from the gulf of mexico mcanally and pritchard 1997 since the 1990s eight physical barriers have been successfully installed for desalinizing the intruding seawater in yantai weihai and qingdao china gao et al 2021 sun et al 2019 these walls are 0 3 1 5 m thick and constructed using the rotary jet grouting technique studies on optimal designs of individual subsurface physical barriers were widely investigated to promote the cost effectiveness of the implementation chang et al 2019 proposed to use the dam with the minimum effective height to prevent saltwater intrusion and assessed environmental performance of the subsurface dam luyun 2010 investigated effect of the depth and position of cutoff walls on performance and concluded that cutoff wells performed better as they are set closer to the seaside within the area of the saline wedge mahesha and lakshmikant 2014 conducted 2d numerical studies based on the sharp interface theory to find optimal locations for freshwater withdrawals in the presence of a semipervious fully penetrating barrier insight into transient behaviors of saltwater after construction of physical barriers is of great significance for groundwater use in coastal aquifers abdoulhalik and ahmed 2017a examined performance of a mixed physical barrier which includes a semi permeable subsurface dam and a cutoff wall in controlling saltwater intrusion the study showed that the combination reduced the saltwater wedge more remarkably zheng et al 2022 explored the desalinization process of the intruding seawater after construction of cutoff walls but mentioned that the combined effect of pumping and cut off wall on desalinization were still not clear kaleris and ziogas 2013 calculated the maximum safe extraction before and after construction of a cutoff wall and assessed the influences of cutoff walls however previous research focused more on subsurface physical designs such as the height depth or location of the barriers abdoulhalik et al 2017 hasan basri 2002 zheng et al 2021 the dynamic behaviors and removal mechanism of the residual saltwater wedge subjected to both subsurface dams and hydraulic controls remained still unclear even fewer studies were conducted to investigate mixed effect of physical subsurface dams along with artificial discharge recharge especially using experimental methods compared to dam only cases more attention is imperative to response of seawater intrusion to synergistic influence of multiple countermeasures this study will contribute to comprehensive influences on groundwater flow and salinity distribution in this regard objectives of the study are to 1 explore the timescale and dynamic behaviors of residual saltwater removal at the landside of the subsurface dam near the shore considering dam designs and aquifer properties 2 elucidate the effectiveness and removal mechanism of residual saltwater considering combined effects of subsurface dams and hydraulic controls including saltwater extraction and freshwater injection 3 provide decisive guidance for the real world aquifer remediation design aimed at facilitating saltwater desalinization such as the longkou area in laizhou bay fig 1 a large amount of residual saltwater was detected at the landside of the huangshui river subsurface dam during the real site hydrogeological survey field scale experiments along the cross section area in fig 1 will be carried out to verify this study as a next step the current study conducted laboratory experiments and numerical simulations to investigate conjunctive impact of subsurface dams with extraction injection on the groundwater flow and salinity distribution removal effectiveness of residual saltwater was quantified analyzed and compared for both dam only and dam well systems sensitivities analysis of key factors was further carried out to clarify how these factors affect saltwater desalinization findings from this study would provide deeper insights into the feedback mechanism of seawater intrusion under joint influences of multiple countermeasures and thereby protect upstream groundwater from being polluted 2 methodology 2 1 experimental setup and procedure a laboratory experiment was conducted in a flow tank the experimental setup is shown in fig 2 a fig 3 demonstrates the photo of the experimental setup the flow tank is 1 2 m long 0 45 m high and 0 03 m wide the tank was segmented into three parts the seawater reservoir the porous medium chamber and the freshwater reservoir arranged left to right the porous medium chamber was filled with well sorted sand sediment sand 4 d50 0 60 1 25 mm the left side of the tank is seawater reservoir and the right side of the tank is freshwater reservoir separated by fine mesh screens two inlet pipes were used to recharge saltwater and freshwater respectively two peristaltic pipes were used in the outlets to extract saltwater and freshwater at constant rates constant seawater and freshwater heads were maintained to be 34 6 cm and 35 8 cm respectively seawater was colored with red food dyes and the salinity was kept constant at 35 g l by mixing commercial salt with tap water throughout the experiment salinity in the seawater reservoir was monitored and maintained by adding salt a slot was prepared for insertion of a physical barrier representing construction of the subsurface dam the slot was located in the porous medium chamber 35 cm away from the seawater reservoir the side of the subsurface dam was sealed to prevent leakage and two fine mesh screens prevent entry of sand into the slot to quantify well location effect two 0 5 cm diameter tubes perpendicular to the walls and spanning the entire width of the experimental flow tank ensured even flow and reduced flow disturbance at the lateral boundary luyun et al 2011 the tubes are located 37 5 cm and 47 5 cm from the seawater reservoir respectively and 2 cm from the bottom more details can be found in the supplementary material fig s1 the two tubes were used as inlet outlet for aquifer recharge discharge initially a shutoff wall was inserted into the left slot between the seawater reservoir and the tank seawater intrusion was initiated with the removal of the shutoff wall this study considered the setup equilibrated when change of the toe position was less than 1 mm within 30 min after the steady state condition was achieved a subsurface dam was inserted quickly but carefully into the slot to avoid prolonged disruption of the existing flow field during the installation process the movement and toe position of the residual saltwater wedge was recorded throughout the experiment photos were taken at various intervals using a high resolution digital camera for cross checking with recorded data in this study various experiments on controlling the swi using a shutoff wall along with saltwater discharge and freshwater recharge were performed three types of dam heights were analyzed for the experiment to examine saltwater control effect various groups of experiments were completed to compare the effect of either a separate subsurface dam or combined measures in different dam heights and discharge recharge settings the salinity transport and retreat behaviors were recorded under different scenarios 2 2 numerical modeling 2 2 1 governing equations and initial boundary conditions fig 2b demonstrates the conceptual model setup for numerical simulations the model domain was a homogeneous unconfined two dimensional vertical cross section with the size of 1 20 m by 0 35 m seawat 2000 guo and langevin 2002 was used to simulate the density dependent groundwater flow and chloride migration seawat 2000 is designed through combining a modified version of modflow harbaugh et al 2000 and mt3dms zheng and wang 1999 into a single program that takes into account density effect in the coupled flow and solute transport equations the governing equation for two dimensional variable density flow in terms of equivalent freshwater head is given as 1 ρ k f h f ρ ρ f ρ f z ρ s f h f t θ ρ c c t ρ s q s where z is vertical orthogonal coordinate axes consistent with the principal directions of permeability k f is the equivalent freshwater hydraulic conductivity lt 1 s f is the equivalent freshwater specific storage l 1 t is time t θ is effective porosity dimensionless c is the solute concentration ml 3 h f is the equivalent freshwater head ρ f is density of freshwater ml 3 ρ is the fluid density ml 3 ρ s is the fluid density at sources and sinks ml 3 and q s is the volumetric flow rate at sources and sinks per unit volume of aquifer t 1 the chloride mass is transported by advection molecular diffusion and mechanical dispersion this study does not consider chemical reaction chloride migration during seawater intrusion can be expressed using the following advection dispersion equation 2 c t d c ν c q s θ c s where d is the hydrodynamic dispersion tensor l2t 1 ν is the seepage velocity lt 1 c s is the concentration at sources and sinks ml 3 the effect of fluid pore pressure and temperature on density is assumed neglectable we did not consider chemical reaction in this study fluid density is predominantly affected by solute concentration the saltwater density can be approximated as an empirical function of concentration 3 ρ ρ f e c where e is a dimensionless constant having an approximate value of 0 7143 for saltwater concentrations ranging from zero to that of seawater 35 g l initial and boundary conditions are required to solve governing equations for flow eq 1 and transport eq 2 in the seawater intrusion process in this study two transient stress periods were set for simulations in the first stress period the starting groundwater heads were set equal to grid top elevation and initial freshwater concentration values are zero the simulated heads and salt concentrations from the first stress period were considered as initial conditions for the retreat process of residual saltwater for boundary conditions the lower part of the numerical model was defined as no flow boundary condition the left side seawater boundary was set to a constant head of 34 6 cm and the concentration was set to 35 g l the right side freshwater boundary was set to a constant head of 35 8 cm with concentration specified as 0 g l 2 2 2 simulations and model parameters the discretized grid resolution was 0 5 cm by 0 5 cm totally the model was discretized into 240 columns and 70 layers the first stress period covered 5 h and involved intrusion of the saltwater wedge until the equilibrium saltwater freshwater system was achieved then the groundwater head and salt concentration simulated from the first stress period was set as initial values for the second stress period the second desalinization period started with installation of an impermeable subsurface dam with a distance of 0 35 m from the sea boundary the portion of saltwater at the landside of the dam is defined as residual saltwater the second stress period was set long enough to cover time when residual saltwater was completely removed model parameters for the numerical simulations were adjusted using measured values from the laboratory experiment as given in table 1 the model layers in the simulation may convert from confined to unconfined conditions or vice versa as the water level in a cell falls below or rises above the top of the cell for unconfined conditions the values of specific yield will be used in the storage term during the simulation the porosity was obtained by oven drying saturated sand the hydraulic conductivity of the sand was determined by the constant head method shen et al 2022 the longitudinal dispersivity αl was acquired according to laboratory scale experiments of shen et al 2022 and zhang et al 2022 the transversal dispersivity αt was set to 10 of the longitudinal dispersivity αl the grid spacing and dispersivity satisfied the the péclet number criterion to ensure numerical stability voss and souza 1987 4 pe υ δ l d α l υ δ l α l 3 85 4 where δ l represents grid spacing d is molecular diffusion and α l denotes longitudinal dispersivity 2 3 evaluation index of saltwater removal effectiveness to evaluate effectiveness of residual saltwater removal with the subsurface dam two indexes are developed in the study the reduction rate of residual saltwater length rrsl and the removal rate of residual salt mass rrsm the rrsl is defined as 5 rrs l rrs l 0 r r s l rrs l 0 100 where rrs l 0 is the initial length of residual saltwater wedge behind the dam rrs l 0 is a constant for a subsurface dam at a fixed location rrsl is the distance between the residual saltwater toe and the subsurface dam in this study the toe location is determined by the 10 isoline of seawater salinity the dimensionless rrsm is defined as 6 rrs m rrs m 0 r r s m rrs m 0 100 where rrs m 0 is the initial total salt mass trapped behind the subsurface dam in the landward aquifer rrs m 0 is a constant for a dam at a fixed location rrsm is the residual salt mass in the landward aquifer comparing the above two definitions rrsl was applied to evaluate the situation with saltwater surrounded by the 10 isoline of seawater salinity while rrsm was used to assess the complete removal efficiency with these two indexes the dynamics and removal effectiveness of the residual saltwater under various scenarios can be quantitatively described and compared 3 results and discussion 3 1 saltwater removal timescale under different dam heights three different heights 7 cm 9 cm and 15 cm of subsurface dams were tested in this study as shown in fig 4 the dam lost its function of preventing saltwater intrusion when the height is lower than 9 cm such as the 7 cm case in this study the minimum effective dam height is 9 cm it is noteworthy that the effective dam height should be taller than the thickness of saltwater wedge at a specified position and the thickness of saltwater wedge can be determined through field monitoring as well as experimental and numerical modeling methods abdoulhalik and ahmed 2017b chang et al 2019 in addition the reference case and the 7 cm dam case fig 4a 4b revealed that fresh groundwater flowed over the mixing zone induced by the hydraulic difference between the freshwater and saltwater boundary when the dam height rose to 9 cm fig 4c the high flow velocity increased fresh groundwater discharge above the dam crest which thereby accelerated washing of residual saltwater fig 5 compared the results of saltwater freshwater interfaces in fig 4 using the 10 isolines as observed the height of the saltwater wedge under the 9 cm dam was the smallest as the dam went higher the seaside saltwater wedge rose obviously it is beneficial to effectively control swi and flush out residual saltwater fig 6 compared transient positions of residual saltwater using 9 cm and 15 cm subsurface dams in laboratory experiments the simulated transient behaviors and velocity vector distributions under different dam heights were presented in fig 7 the calculated root mean square error rmse and nash sutcliffe efficiency coefficient nse using saltwater wedge lengths at different timescales are 0 723 and 0 989 respectively generally the simulated results agreed well with experimental observations indicating the accuracy and reliability of the seawat model in the first process seawater intruded to the fresh aquifer and reached a steady state at the bottom using 2 78 h in absence of the subsurface dam the stable saltwater toe position was 62 5 cm away from the sea boundary fig 6a1 this result matched well with the calculated analytical solution of lu et al 2015 the subsurface dam was then installed at 35 cm from the sea boundary and installation of the dam was assumed to be instantaneous it was found that the toe position of residual saltwater slightly advances inland instantly after installing the 9 cm and 15 cm high subsurface dams fig 6a2 6b2 and then started to retreat seaward after 5 h of natural attenuation residual saltwater behind both dams was slightly reduced but a large amount of saltwater still retained in the fresh aquifer it was found that a high concentration saltwater wedge with a length of 21 5 cm existed behind the 9 cm dam while a length of 27 cm remained behind the 15 cm dam fig 6a3 6b3 18 h later residual saltwater was almost flushed out of the aquifer for the 9 cm dam in comparison a larger area of relatively low concentration saltwater isolines between 10 and 50 was still trapped behind the 15 cm dam at the bottom of the aquifer according to salinity distributions in fig 7 residual saltwater was totally flushed out using 22 1 h under the 9 cm dam case compared to 33 1 h under the 15 cm dam case as observed from both experimental and numerical results the timescale of residual saltwater removal was positively correlated with the height of the subsurface dam results confirmed that a shorter 9 cm subsurface dam exhibited faster removal of residual saltwater than a taller 15 cm subsurface dam this was attributed to increased height over which the dispersed residual saltwater must flow out besides the flow field existed in both saltwater and freshwater zone as shown in fig 8 the magnitude of velocity in the saltwater zone is much smaller than that of freshwater zone the low velocity area of the 15 cm dam case was larger than that of the 9 cm dam case which might be one reason why longer retreat time was needed for the 15 cm dam case we also provided specific velocity information for comparison in the data statement 3 2 synergistic effect of a subsurface dam along with hydraulic control in order to further promote removal efficiency of residual saltwater this study explored synergistic effect of the subsurface dam along with managed aquifer discharge recharge hydraulic control four cases of laboratory experiments were performed as shown in fig 9 the simulated saltwater removal process and velocity field were presented in fig 10 two testing locations were selected for well installation 2 5 cm l1 and 12 5 cm l2 away from the subsurface dam the locations were determined by the initial length of the residual saltwater wedge behind the dam l1 is set at about 10 of the rrsl 0 whereas l2 is about 45 the values of discharge and recharge rates were set to 0 2 cm3 s the initial freshwater flux resulting from the head gradient was measured from the outlet discharge through the system and the corresponding discharge recharge rates was computed of this value luyun et al 2011 changes of rrsl and rrsm versus time were presented in fig 11 results found that residual saltwater was easily discharged over the dam using 1 9 h with a discharge well installed at l1 fig 9a 10a at the moment much more saltwater was trapped behind the dam with a freshwater recharge well installed at l1 a circulation flow formed with a 21 cm length residual saltwater wedge fig 9b 10b it was evident from fig 11 that reduction rates of residual saltwater length rrsl in case 3 l1 discharge were always higher than those in case 4 l1 recharge the same situation applies to removal rates of residual salt mass rrsm compared to 1 9 h with saltwater discharge at l1 residual saltwater required a much longer period 9 5 h to retreat with freshwater recharge it was indicated that saltwater extraction enhanced the removal efficiency more significantly than freshwater injection at l1 this was attributed to differences in removal mechanism between freshwater recharge and saltwater extraction residual saltwater accumulating near the landward of the subsurface dam was directly pumped out through the outlet freshwater recharge desalinized the upstream aquifer by increasing the flow velocity and fresh groundwater discharge the high flow velocity increased fresh groundwater discharge above the dam crest after testing different cases this study found that the total removal time using a saltwater discharge well or a freshwater recharge well was almost equal when the distance between the well and the subsurface dam was 7 5 cm so saltwater discharge would be recommended when the distance was less than 7 5 cm otherwise freshwater recharge was a better choice on the other hand the residual saltwater was removed after 12 5 h with freshwater recharge at l2 fig 9d 10d at this moment a small area of saltwater still remained in the fresh aquifer fig 9c 10c with saltwater discharge at l2 it took 17 8 h to desalinize the upstream aquifer more important results from fig 11 found that values of rrsl and rrsm under the l2 discharge case 5 were higher than l2 recharge case 6 at the beginning thereafter values of case 5 turned into lower than case 6 it may imply that saltwater discharge would be recommended at the beginning of a period once the saltwater plume moved back to the l2 location freshwater recharge was preferred thereafter this was attributed to that more freshwater recharge would facilitate the saltwater retreat process and improve cleaning efficiency while saltwater discharge played a role of reverse traction and took more time to completely flush out these findings highlighted that well locations imposed significant impact on saltwater removal efficiency saltwater discharge or freshwater recharge near the dam exhibited more effectiveness in desalinization than far from it besides due to this widening mechanism of the mixing zone and the perturbance of injected water the toe of residual saltwater wedge initially advanced into the inland aquifer and reached maxima and then gradually retreated according to rrsl results from l1 recharge case l2 recharge case and 15 cm high dam case this phenomenon was also observed by luyun et al 2009 and zheng et al 2021 overall a combination of a subsurface dam and saltwater extraction or freshwater injection forced saltwater to retreat more quickly and achieved more effectiveness than a separate subsurface dam 3 3 sensitivity analysis aquifer properties as well as discharge and recharge rates can strongly influence dynamics and effectiveness of saltwater removal thus this study conducted various cases to respectively investigate effects of the hydraulic conductivity longitudinal dispersivity managed aquifer recharge rate and discharge rate on residual saltwater desalinization at the landside of the subsurface dam different hydraulic conductivities in the upstream aquifer of the dam were analyzed since land backfilling may be potential engineering measures against aquifer salinization in the upstream rrsm over time was presented in fig 12 to reflect the complete removal process under all cases for the hydraulic conductivity case fig 12a when k values were set to 6 5 10 3 1 3 10 2 and 2 6 10 2 m s the complete removal time was 50 8 29 4 and 12 1 h respectively it was found that removal of residual saltwater behind the dam were reduced significantly faster with higher hydraulic conductivity due to stronger convection to quantify effects of longitudinal dispersivity αl on removal of residual saltwater we calculated rrsm with αl of 1 3 10 3 6 5 10 3 and 1 3 10 2 m respectively it took respectively 29 4 22 2 and 16 4 h to completely flushed out of the landward aquifer fig 12b an increased longitudinal dispersivity would induce more efficient saltwater removal which was indicated by a higher rrsm the reason is that dispersion fluxes increased due to larger dispersivities moreover values of rrsm reached 50 after about 4 3 h while it took 16 4 h to reach 100 when the αl was set to 1 3 10 2 m fig 13 presented distributions of dispersive zone with three different dispersivities the margins between 10 and 90 isolines became wider for a larger dispersvity results also revealed that areas surrounded by the 10 isolines were obviously reduced with the increase of longitudinal dispersivity in comparison isolines of αl 1 3 10 2 m retreated more quickly for example after five hours the residual saltwater wedge of 50 isoline with αl 1 3 10 3 m has retreated to 58 cm to the seawater boundary fig 13a1 whereas 51 cm with the case of αl 1 3 10 2 m fig 13a3 more important the high concentration mixing zone above 90 isolines red lines was flushed out more quickly than the low concentration mixing zone for isolines between 10 and 50 besides it was found that longitudinal dispersivity greatly affected the total desalination time this study also investigated the mixed effect of a 15 cm subsurface dam along with artificial recharge discharge rates of 0 1 0 2 and 0 3 cm3 s respectively as revealed from fig 12c and fig 12d more recharge or discharge rates at l2 resulted in higher rrsm values and accelerated the removal process overall saltwater discharge spent more time to completely eliminate the residual saltwater than freshwater recharge at l2 however in the first one hour the rrsm values rose very quickly with increase of discharge rates and then went up slowly in the cases stated above it was found that changes of hydraulic conductivity longitudinal dispersivity artificial recharge and discharge can profoundly influence the residual saltwater removal process behind a subsurface dam the influences of freshwater recharge and saltwater discharge were even more significant these findings can provide decision makers practical guidance for coastal aquifer desalinization design 4 conclusions this study performed laboratory scale experiments and numerical simulations to investigate dynamic behaviors of residual saltwater trapped behind subsurface dams in the landward aquifer the separate and synergistic effects of subsurface dam designs aquifer properties as well as saltwater discharge and freshwater recharge on the flow and salinity transport process were quantified analyzed and compared in a laboratory scale nearshore aquifer key findings from the study can be summarized as follows 1 the timescale and removal mechanism of residual saltwater behind subsurface dams were clarified through both experimental and numerical studies more important saltwater retreat response to joint influences of subsurface dams and artificial controls including saltwater discharge and freshwater recharge were newly revealed from laboratory experiments the developed indexes rrsl and rrsm were proven to be effective to quantify the extent of residual saltwater removal 2 for subsurface dams a minimum height was needed to achieve complete removal of residual saltwater a shorter subsurface dam achieved a faster removal rate of residual saltwater compared to a taller dam with the increase of the dam height from 9 cm to 15 cm the total desalinization time extended from 22 1 h to 33 1 h particularly attenuation of the relatively low concentration saltwater was a slow process compared to high concentration saltwater 3 residual saltwater retreated more efficiently with combined countermeasures of a subsurface dam physical barrier and saltwater extraction or freshwater injection hydraulic control than a separate subsurface dam moreover saltwater extraction or freshwater injection near the dam exhibited more effectiveness in desalinization than far from it especially if the wells were installed at 12 5 cm l2 from the dam saltwater extraction would be recommended before saltwater plume retreated back to l2 freshwater injection was preferred thereafter 4 changes of the hydraulic conductivity longitudinal dispersivity artificial recharge and discharge rate profoundly affect the residual saltwater removal process behind a subsurface dam among them influences of freshwater recharge and saltwater discharge were even more significant particularly rrsm went up remarkably at the very beginning with saltwater discharge besides a higher hydraulic conductivity or longitudinal dispersivity of the aquifer can accelerate desalinization increase of recharge rates can enhance entire saltwater removal efficiency indicated by a higher rrsm value the above findings promote significant deep insights into the dynamic behaviors and removal mechanism of residual saltwater behind subsurface dams subjected to human activities also the research provides groundwater managers practical guidance for more effective mitigating coastal aquifer salinization however the limitation is that the study did not consider reactions such as cations exchange calcite dissolution which may have potential impacts in the future 3d models for real nearshore aquifers considering chemical reactions and complex heterogeneities can be further explored to better understand the response of along shore salinity transport data availability the velocity and concentration data of no dam and 9 cm dam cases can be found at https figshare com articles figure supplementary data and figure 21316509 other data will be made available upon request credit authorship contribution statement jina yin conceptualization data curation methodology funding acquisition validation formal analysis writing original draft ning wang conceptualization data curation methodology validation formal analysis writing original draft chunhui lu funding acquisition data curation methodology resources supervision validation writing review editing frank t c tsai conceptualization methodology resources validation writing review editing huawei chen resources validation writing review editing declaration of competing interest the authors declare that they have no known competing interests acknowledgments this research has been financially supported by the national natural science foundation of china no 52109080 national key research and development program no 2021yfc3200500 fundamental research funds for the central universities b220201013 and nanjing science and technology innovation project for researcher studying abroad b2104110 high performance computing hpc platform in hohai university is acknowledged for providing technique support appendix a supplementary data supplementary data supplementary figures to this study can be found in fig s1 to this article can be found online at https doi org 10 1016 j jhydrol 2023 129282 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary figures to this study can be found in fig s1 
2151,countermeasures against seawater intrusion swi are critical to prevent coastal groundwater resources from deterioration subsurface dams have been recognized as one of effective approaches to prevent swi but most likely to produce residual saltwater at the landside of the dam understanding dynamic behaviors and removal mechanism of residual saltwater can facilitate aquifer desalinization especially under combined effect of subsurface dams and hydraulic controls little attention has been paid to synergistic impact on residual saltwater removal this study performed laboratory scale experiments and numerical simulations to investigate residual saltwater trapped in the storage area upon construction of a subsurface dam along with saltwater discharge freshwater recharge effects of subsurface dam designs aquifer properties as well as discharge and recharge rates on the flow and salinity transport process were explored and compared in a coastal aquifer two indexes including a reduction rate of residual saltwater length rrsl and removal rate of residual salt mass rrsm were introduced to quantify effectiveness of residual saltwater removal experimental and numerical results found that the subsurface dam needs a minimum effective height to achieve complete removal of residual saltwater moreover a shorter subsurface dam e g 9 cm in the experiment achieves a faster removal rate compared to a taller dam e g 15 cm particularly attenuation of relatively low concentration mixing zone between 10 and 50 isolines was a quite slow process saltwater discharge or freshwater recharge near the dam exhibits more effectiveness in desalinization than far from it furthermore extraction injection imposed more remarkable influences on saltwater removal than aquifer properties findings from the study have significant implications in better understanding of residual saltwater removal mechanism and timescale for nearshore groundwater systems keywords seawater intrusion subsurface dam saltwater removal laboratory experiment numerical simulation data availability data will be made available on request 1 introduction groundwater is an important freshwater resource in coastal aquifer with the increasing population water demand has exaggerated and led to fresh groundwater over exploitation in coastal areas marston et al 2015 walther et al 2017 inland groundwater levels fall below the sea level and seawater would flow landward resulting in serious deterioration of the inland aquifer in some cases seawater intrusion swi led to soil salinization and threaten water supplies and thereby reduced agricultural productivity li et al 2014 post and werner 2017 yin et al 2021 thus swi remediation turns to be critical for water utilization but highly challenging due to complex hydrogeological conditions and hydrodynamic processes physical barriers werner et al 2013 wu et al 2020 zheng et al 2020 as well as hydraulic controls ebeling et al 2019 masciopinto 2013 are two major groups of engineering approaches to prevent encroachment of seawater among them subsurface physical barriers such as subsurface dams or cutoff walls have shown to be effective measures in many countries owing to stable performance abdoulhalik and ahmed 2017a armanuos et al 2019 senthilkumar and elango 2011 subsurface dams are essentially impermeable walls constructed at the bottom of the aquifer leaving an opening at the top of the barrier for upstream fresh groundwater discharge cutoff walls cover the upper part of the aquifer while leaving an opening at the bottom wu et al 2020 these practical engineering solutions have artificially changed flow hydrodynamics in the aquifer by altering a portion of the system despite being relatively costly subsurface barriers have been constructed worldwide for swi control in 1988 the u s army corps of engineers built temporary underground barriers in new orleans which limited upstream swi from the gulf of mexico mcanally and pritchard 1997 since the 1990s eight physical barriers have been successfully installed for desalinizing the intruding seawater in yantai weihai and qingdao china gao et al 2021 sun et al 2019 these walls are 0 3 1 5 m thick and constructed using the rotary jet grouting technique studies on optimal designs of individual subsurface physical barriers were widely investigated to promote the cost effectiveness of the implementation chang et al 2019 proposed to use the dam with the minimum effective height to prevent saltwater intrusion and assessed environmental performance of the subsurface dam luyun 2010 investigated effect of the depth and position of cutoff walls on performance and concluded that cutoff wells performed better as they are set closer to the seaside within the area of the saline wedge mahesha and lakshmikant 2014 conducted 2d numerical studies based on the sharp interface theory to find optimal locations for freshwater withdrawals in the presence of a semipervious fully penetrating barrier insight into transient behaviors of saltwater after construction of physical barriers is of great significance for groundwater use in coastal aquifers abdoulhalik and ahmed 2017a examined performance of a mixed physical barrier which includes a semi permeable subsurface dam and a cutoff wall in controlling saltwater intrusion the study showed that the combination reduced the saltwater wedge more remarkably zheng et al 2022 explored the desalinization process of the intruding seawater after construction of cutoff walls but mentioned that the combined effect of pumping and cut off wall on desalinization were still not clear kaleris and ziogas 2013 calculated the maximum safe extraction before and after construction of a cutoff wall and assessed the influences of cutoff walls however previous research focused more on subsurface physical designs such as the height depth or location of the barriers abdoulhalik et al 2017 hasan basri 2002 zheng et al 2021 the dynamic behaviors and removal mechanism of the residual saltwater wedge subjected to both subsurface dams and hydraulic controls remained still unclear even fewer studies were conducted to investigate mixed effect of physical subsurface dams along with artificial discharge recharge especially using experimental methods compared to dam only cases more attention is imperative to response of seawater intrusion to synergistic influence of multiple countermeasures this study will contribute to comprehensive influences on groundwater flow and salinity distribution in this regard objectives of the study are to 1 explore the timescale and dynamic behaviors of residual saltwater removal at the landside of the subsurface dam near the shore considering dam designs and aquifer properties 2 elucidate the effectiveness and removal mechanism of residual saltwater considering combined effects of subsurface dams and hydraulic controls including saltwater extraction and freshwater injection 3 provide decisive guidance for the real world aquifer remediation design aimed at facilitating saltwater desalinization such as the longkou area in laizhou bay fig 1 a large amount of residual saltwater was detected at the landside of the huangshui river subsurface dam during the real site hydrogeological survey field scale experiments along the cross section area in fig 1 will be carried out to verify this study as a next step the current study conducted laboratory experiments and numerical simulations to investigate conjunctive impact of subsurface dams with extraction injection on the groundwater flow and salinity distribution removal effectiveness of residual saltwater was quantified analyzed and compared for both dam only and dam well systems sensitivities analysis of key factors was further carried out to clarify how these factors affect saltwater desalinization findings from this study would provide deeper insights into the feedback mechanism of seawater intrusion under joint influences of multiple countermeasures and thereby protect upstream groundwater from being polluted 2 methodology 2 1 experimental setup and procedure a laboratory experiment was conducted in a flow tank the experimental setup is shown in fig 2 a fig 3 demonstrates the photo of the experimental setup the flow tank is 1 2 m long 0 45 m high and 0 03 m wide the tank was segmented into three parts the seawater reservoir the porous medium chamber and the freshwater reservoir arranged left to right the porous medium chamber was filled with well sorted sand sediment sand 4 d50 0 60 1 25 mm the left side of the tank is seawater reservoir and the right side of the tank is freshwater reservoir separated by fine mesh screens two inlet pipes were used to recharge saltwater and freshwater respectively two peristaltic pipes were used in the outlets to extract saltwater and freshwater at constant rates constant seawater and freshwater heads were maintained to be 34 6 cm and 35 8 cm respectively seawater was colored with red food dyes and the salinity was kept constant at 35 g l by mixing commercial salt with tap water throughout the experiment salinity in the seawater reservoir was monitored and maintained by adding salt a slot was prepared for insertion of a physical barrier representing construction of the subsurface dam the slot was located in the porous medium chamber 35 cm away from the seawater reservoir the side of the subsurface dam was sealed to prevent leakage and two fine mesh screens prevent entry of sand into the slot to quantify well location effect two 0 5 cm diameter tubes perpendicular to the walls and spanning the entire width of the experimental flow tank ensured even flow and reduced flow disturbance at the lateral boundary luyun et al 2011 the tubes are located 37 5 cm and 47 5 cm from the seawater reservoir respectively and 2 cm from the bottom more details can be found in the supplementary material fig s1 the two tubes were used as inlet outlet for aquifer recharge discharge initially a shutoff wall was inserted into the left slot between the seawater reservoir and the tank seawater intrusion was initiated with the removal of the shutoff wall this study considered the setup equilibrated when change of the toe position was less than 1 mm within 30 min after the steady state condition was achieved a subsurface dam was inserted quickly but carefully into the slot to avoid prolonged disruption of the existing flow field during the installation process the movement and toe position of the residual saltwater wedge was recorded throughout the experiment photos were taken at various intervals using a high resolution digital camera for cross checking with recorded data in this study various experiments on controlling the swi using a shutoff wall along with saltwater discharge and freshwater recharge were performed three types of dam heights were analyzed for the experiment to examine saltwater control effect various groups of experiments were completed to compare the effect of either a separate subsurface dam or combined measures in different dam heights and discharge recharge settings the salinity transport and retreat behaviors were recorded under different scenarios 2 2 numerical modeling 2 2 1 governing equations and initial boundary conditions fig 2b demonstrates the conceptual model setup for numerical simulations the model domain was a homogeneous unconfined two dimensional vertical cross section with the size of 1 20 m by 0 35 m seawat 2000 guo and langevin 2002 was used to simulate the density dependent groundwater flow and chloride migration seawat 2000 is designed through combining a modified version of modflow harbaugh et al 2000 and mt3dms zheng and wang 1999 into a single program that takes into account density effect in the coupled flow and solute transport equations the governing equation for two dimensional variable density flow in terms of equivalent freshwater head is given as 1 ρ k f h f ρ ρ f ρ f z ρ s f h f t θ ρ c c t ρ s q s where z is vertical orthogonal coordinate axes consistent with the principal directions of permeability k f is the equivalent freshwater hydraulic conductivity lt 1 s f is the equivalent freshwater specific storage l 1 t is time t θ is effective porosity dimensionless c is the solute concentration ml 3 h f is the equivalent freshwater head ρ f is density of freshwater ml 3 ρ is the fluid density ml 3 ρ s is the fluid density at sources and sinks ml 3 and q s is the volumetric flow rate at sources and sinks per unit volume of aquifer t 1 the chloride mass is transported by advection molecular diffusion and mechanical dispersion this study does not consider chemical reaction chloride migration during seawater intrusion can be expressed using the following advection dispersion equation 2 c t d c ν c q s θ c s where d is the hydrodynamic dispersion tensor l2t 1 ν is the seepage velocity lt 1 c s is the concentration at sources and sinks ml 3 the effect of fluid pore pressure and temperature on density is assumed neglectable we did not consider chemical reaction in this study fluid density is predominantly affected by solute concentration the saltwater density can be approximated as an empirical function of concentration 3 ρ ρ f e c where e is a dimensionless constant having an approximate value of 0 7143 for saltwater concentrations ranging from zero to that of seawater 35 g l initial and boundary conditions are required to solve governing equations for flow eq 1 and transport eq 2 in the seawater intrusion process in this study two transient stress periods were set for simulations in the first stress period the starting groundwater heads were set equal to grid top elevation and initial freshwater concentration values are zero the simulated heads and salt concentrations from the first stress period were considered as initial conditions for the retreat process of residual saltwater for boundary conditions the lower part of the numerical model was defined as no flow boundary condition the left side seawater boundary was set to a constant head of 34 6 cm and the concentration was set to 35 g l the right side freshwater boundary was set to a constant head of 35 8 cm with concentration specified as 0 g l 2 2 2 simulations and model parameters the discretized grid resolution was 0 5 cm by 0 5 cm totally the model was discretized into 240 columns and 70 layers the first stress period covered 5 h and involved intrusion of the saltwater wedge until the equilibrium saltwater freshwater system was achieved then the groundwater head and salt concentration simulated from the first stress period was set as initial values for the second stress period the second desalinization period started with installation of an impermeable subsurface dam with a distance of 0 35 m from the sea boundary the portion of saltwater at the landside of the dam is defined as residual saltwater the second stress period was set long enough to cover time when residual saltwater was completely removed model parameters for the numerical simulations were adjusted using measured values from the laboratory experiment as given in table 1 the model layers in the simulation may convert from confined to unconfined conditions or vice versa as the water level in a cell falls below or rises above the top of the cell for unconfined conditions the values of specific yield will be used in the storage term during the simulation the porosity was obtained by oven drying saturated sand the hydraulic conductivity of the sand was determined by the constant head method shen et al 2022 the longitudinal dispersivity αl was acquired according to laboratory scale experiments of shen et al 2022 and zhang et al 2022 the transversal dispersivity αt was set to 10 of the longitudinal dispersivity αl the grid spacing and dispersivity satisfied the the péclet number criterion to ensure numerical stability voss and souza 1987 4 pe υ δ l d α l υ δ l α l 3 85 4 where δ l represents grid spacing d is molecular diffusion and α l denotes longitudinal dispersivity 2 3 evaluation index of saltwater removal effectiveness to evaluate effectiveness of residual saltwater removal with the subsurface dam two indexes are developed in the study the reduction rate of residual saltwater length rrsl and the removal rate of residual salt mass rrsm the rrsl is defined as 5 rrs l rrs l 0 r r s l rrs l 0 100 where rrs l 0 is the initial length of residual saltwater wedge behind the dam rrs l 0 is a constant for a subsurface dam at a fixed location rrsl is the distance between the residual saltwater toe and the subsurface dam in this study the toe location is determined by the 10 isoline of seawater salinity the dimensionless rrsm is defined as 6 rrs m rrs m 0 r r s m rrs m 0 100 where rrs m 0 is the initial total salt mass trapped behind the subsurface dam in the landward aquifer rrs m 0 is a constant for a dam at a fixed location rrsm is the residual salt mass in the landward aquifer comparing the above two definitions rrsl was applied to evaluate the situation with saltwater surrounded by the 10 isoline of seawater salinity while rrsm was used to assess the complete removal efficiency with these two indexes the dynamics and removal effectiveness of the residual saltwater under various scenarios can be quantitatively described and compared 3 results and discussion 3 1 saltwater removal timescale under different dam heights three different heights 7 cm 9 cm and 15 cm of subsurface dams were tested in this study as shown in fig 4 the dam lost its function of preventing saltwater intrusion when the height is lower than 9 cm such as the 7 cm case in this study the minimum effective dam height is 9 cm it is noteworthy that the effective dam height should be taller than the thickness of saltwater wedge at a specified position and the thickness of saltwater wedge can be determined through field monitoring as well as experimental and numerical modeling methods abdoulhalik and ahmed 2017b chang et al 2019 in addition the reference case and the 7 cm dam case fig 4a 4b revealed that fresh groundwater flowed over the mixing zone induced by the hydraulic difference between the freshwater and saltwater boundary when the dam height rose to 9 cm fig 4c the high flow velocity increased fresh groundwater discharge above the dam crest which thereby accelerated washing of residual saltwater fig 5 compared the results of saltwater freshwater interfaces in fig 4 using the 10 isolines as observed the height of the saltwater wedge under the 9 cm dam was the smallest as the dam went higher the seaside saltwater wedge rose obviously it is beneficial to effectively control swi and flush out residual saltwater fig 6 compared transient positions of residual saltwater using 9 cm and 15 cm subsurface dams in laboratory experiments the simulated transient behaviors and velocity vector distributions under different dam heights were presented in fig 7 the calculated root mean square error rmse and nash sutcliffe efficiency coefficient nse using saltwater wedge lengths at different timescales are 0 723 and 0 989 respectively generally the simulated results agreed well with experimental observations indicating the accuracy and reliability of the seawat model in the first process seawater intruded to the fresh aquifer and reached a steady state at the bottom using 2 78 h in absence of the subsurface dam the stable saltwater toe position was 62 5 cm away from the sea boundary fig 6a1 this result matched well with the calculated analytical solution of lu et al 2015 the subsurface dam was then installed at 35 cm from the sea boundary and installation of the dam was assumed to be instantaneous it was found that the toe position of residual saltwater slightly advances inland instantly after installing the 9 cm and 15 cm high subsurface dams fig 6a2 6b2 and then started to retreat seaward after 5 h of natural attenuation residual saltwater behind both dams was slightly reduced but a large amount of saltwater still retained in the fresh aquifer it was found that a high concentration saltwater wedge with a length of 21 5 cm existed behind the 9 cm dam while a length of 27 cm remained behind the 15 cm dam fig 6a3 6b3 18 h later residual saltwater was almost flushed out of the aquifer for the 9 cm dam in comparison a larger area of relatively low concentration saltwater isolines between 10 and 50 was still trapped behind the 15 cm dam at the bottom of the aquifer according to salinity distributions in fig 7 residual saltwater was totally flushed out using 22 1 h under the 9 cm dam case compared to 33 1 h under the 15 cm dam case as observed from both experimental and numerical results the timescale of residual saltwater removal was positively correlated with the height of the subsurface dam results confirmed that a shorter 9 cm subsurface dam exhibited faster removal of residual saltwater than a taller 15 cm subsurface dam this was attributed to increased height over which the dispersed residual saltwater must flow out besides the flow field existed in both saltwater and freshwater zone as shown in fig 8 the magnitude of velocity in the saltwater zone is much smaller than that of freshwater zone the low velocity area of the 15 cm dam case was larger than that of the 9 cm dam case which might be one reason why longer retreat time was needed for the 15 cm dam case we also provided specific velocity information for comparison in the data statement 3 2 synergistic effect of a subsurface dam along with hydraulic control in order to further promote removal efficiency of residual saltwater this study explored synergistic effect of the subsurface dam along with managed aquifer discharge recharge hydraulic control four cases of laboratory experiments were performed as shown in fig 9 the simulated saltwater removal process and velocity field were presented in fig 10 two testing locations were selected for well installation 2 5 cm l1 and 12 5 cm l2 away from the subsurface dam the locations were determined by the initial length of the residual saltwater wedge behind the dam l1 is set at about 10 of the rrsl 0 whereas l2 is about 45 the values of discharge and recharge rates were set to 0 2 cm3 s the initial freshwater flux resulting from the head gradient was measured from the outlet discharge through the system and the corresponding discharge recharge rates was computed of this value luyun et al 2011 changes of rrsl and rrsm versus time were presented in fig 11 results found that residual saltwater was easily discharged over the dam using 1 9 h with a discharge well installed at l1 fig 9a 10a at the moment much more saltwater was trapped behind the dam with a freshwater recharge well installed at l1 a circulation flow formed with a 21 cm length residual saltwater wedge fig 9b 10b it was evident from fig 11 that reduction rates of residual saltwater length rrsl in case 3 l1 discharge were always higher than those in case 4 l1 recharge the same situation applies to removal rates of residual salt mass rrsm compared to 1 9 h with saltwater discharge at l1 residual saltwater required a much longer period 9 5 h to retreat with freshwater recharge it was indicated that saltwater extraction enhanced the removal efficiency more significantly than freshwater injection at l1 this was attributed to differences in removal mechanism between freshwater recharge and saltwater extraction residual saltwater accumulating near the landward of the subsurface dam was directly pumped out through the outlet freshwater recharge desalinized the upstream aquifer by increasing the flow velocity and fresh groundwater discharge the high flow velocity increased fresh groundwater discharge above the dam crest after testing different cases this study found that the total removal time using a saltwater discharge well or a freshwater recharge well was almost equal when the distance between the well and the subsurface dam was 7 5 cm so saltwater discharge would be recommended when the distance was less than 7 5 cm otherwise freshwater recharge was a better choice on the other hand the residual saltwater was removed after 12 5 h with freshwater recharge at l2 fig 9d 10d at this moment a small area of saltwater still remained in the fresh aquifer fig 9c 10c with saltwater discharge at l2 it took 17 8 h to desalinize the upstream aquifer more important results from fig 11 found that values of rrsl and rrsm under the l2 discharge case 5 were higher than l2 recharge case 6 at the beginning thereafter values of case 5 turned into lower than case 6 it may imply that saltwater discharge would be recommended at the beginning of a period once the saltwater plume moved back to the l2 location freshwater recharge was preferred thereafter this was attributed to that more freshwater recharge would facilitate the saltwater retreat process and improve cleaning efficiency while saltwater discharge played a role of reverse traction and took more time to completely flush out these findings highlighted that well locations imposed significant impact on saltwater removal efficiency saltwater discharge or freshwater recharge near the dam exhibited more effectiveness in desalinization than far from it besides due to this widening mechanism of the mixing zone and the perturbance of injected water the toe of residual saltwater wedge initially advanced into the inland aquifer and reached maxima and then gradually retreated according to rrsl results from l1 recharge case l2 recharge case and 15 cm high dam case this phenomenon was also observed by luyun et al 2009 and zheng et al 2021 overall a combination of a subsurface dam and saltwater extraction or freshwater injection forced saltwater to retreat more quickly and achieved more effectiveness than a separate subsurface dam 3 3 sensitivity analysis aquifer properties as well as discharge and recharge rates can strongly influence dynamics and effectiveness of saltwater removal thus this study conducted various cases to respectively investigate effects of the hydraulic conductivity longitudinal dispersivity managed aquifer recharge rate and discharge rate on residual saltwater desalinization at the landside of the subsurface dam different hydraulic conductivities in the upstream aquifer of the dam were analyzed since land backfilling may be potential engineering measures against aquifer salinization in the upstream rrsm over time was presented in fig 12 to reflect the complete removal process under all cases for the hydraulic conductivity case fig 12a when k values were set to 6 5 10 3 1 3 10 2 and 2 6 10 2 m s the complete removal time was 50 8 29 4 and 12 1 h respectively it was found that removal of residual saltwater behind the dam were reduced significantly faster with higher hydraulic conductivity due to stronger convection to quantify effects of longitudinal dispersivity αl on removal of residual saltwater we calculated rrsm with αl of 1 3 10 3 6 5 10 3 and 1 3 10 2 m respectively it took respectively 29 4 22 2 and 16 4 h to completely flushed out of the landward aquifer fig 12b an increased longitudinal dispersivity would induce more efficient saltwater removal which was indicated by a higher rrsm the reason is that dispersion fluxes increased due to larger dispersivities moreover values of rrsm reached 50 after about 4 3 h while it took 16 4 h to reach 100 when the αl was set to 1 3 10 2 m fig 13 presented distributions of dispersive zone with three different dispersivities the margins between 10 and 90 isolines became wider for a larger dispersvity results also revealed that areas surrounded by the 10 isolines were obviously reduced with the increase of longitudinal dispersivity in comparison isolines of αl 1 3 10 2 m retreated more quickly for example after five hours the residual saltwater wedge of 50 isoline with αl 1 3 10 3 m has retreated to 58 cm to the seawater boundary fig 13a1 whereas 51 cm with the case of αl 1 3 10 2 m fig 13a3 more important the high concentration mixing zone above 90 isolines red lines was flushed out more quickly than the low concentration mixing zone for isolines between 10 and 50 besides it was found that longitudinal dispersivity greatly affected the total desalination time this study also investigated the mixed effect of a 15 cm subsurface dam along with artificial recharge discharge rates of 0 1 0 2 and 0 3 cm3 s respectively as revealed from fig 12c and fig 12d more recharge or discharge rates at l2 resulted in higher rrsm values and accelerated the removal process overall saltwater discharge spent more time to completely eliminate the residual saltwater than freshwater recharge at l2 however in the first one hour the rrsm values rose very quickly with increase of discharge rates and then went up slowly in the cases stated above it was found that changes of hydraulic conductivity longitudinal dispersivity artificial recharge and discharge can profoundly influence the residual saltwater removal process behind a subsurface dam the influences of freshwater recharge and saltwater discharge were even more significant these findings can provide decision makers practical guidance for coastal aquifer desalinization design 4 conclusions this study performed laboratory scale experiments and numerical simulations to investigate dynamic behaviors of residual saltwater trapped behind subsurface dams in the landward aquifer the separate and synergistic effects of subsurface dam designs aquifer properties as well as saltwater discharge and freshwater recharge on the flow and salinity transport process were quantified analyzed and compared in a laboratory scale nearshore aquifer key findings from the study can be summarized as follows 1 the timescale and removal mechanism of residual saltwater behind subsurface dams were clarified through both experimental and numerical studies more important saltwater retreat response to joint influences of subsurface dams and artificial controls including saltwater discharge and freshwater recharge were newly revealed from laboratory experiments the developed indexes rrsl and rrsm were proven to be effective to quantify the extent of residual saltwater removal 2 for subsurface dams a minimum height was needed to achieve complete removal of residual saltwater a shorter subsurface dam achieved a faster removal rate of residual saltwater compared to a taller dam with the increase of the dam height from 9 cm to 15 cm the total desalinization time extended from 22 1 h to 33 1 h particularly attenuation of the relatively low concentration saltwater was a slow process compared to high concentration saltwater 3 residual saltwater retreated more efficiently with combined countermeasures of a subsurface dam physical barrier and saltwater extraction or freshwater injection hydraulic control than a separate subsurface dam moreover saltwater extraction or freshwater injection near the dam exhibited more effectiveness in desalinization than far from it especially if the wells were installed at 12 5 cm l2 from the dam saltwater extraction would be recommended before saltwater plume retreated back to l2 freshwater injection was preferred thereafter 4 changes of the hydraulic conductivity longitudinal dispersivity artificial recharge and discharge rate profoundly affect the residual saltwater removal process behind a subsurface dam among them influences of freshwater recharge and saltwater discharge were even more significant particularly rrsm went up remarkably at the very beginning with saltwater discharge besides a higher hydraulic conductivity or longitudinal dispersivity of the aquifer can accelerate desalinization increase of recharge rates can enhance entire saltwater removal efficiency indicated by a higher rrsm value the above findings promote significant deep insights into the dynamic behaviors and removal mechanism of residual saltwater behind subsurface dams subjected to human activities also the research provides groundwater managers practical guidance for more effective mitigating coastal aquifer salinization however the limitation is that the study did not consider reactions such as cations exchange calcite dissolution which may have potential impacts in the future 3d models for real nearshore aquifers considering chemical reactions and complex heterogeneities can be further explored to better understand the response of along shore salinity transport data availability the velocity and concentration data of no dam and 9 cm dam cases can be found at https figshare com articles figure supplementary data and figure 21316509 other data will be made available upon request credit authorship contribution statement jina yin conceptualization data curation methodology funding acquisition validation formal analysis writing original draft ning wang conceptualization data curation methodology validation formal analysis writing original draft chunhui lu funding acquisition data curation methodology resources supervision validation writing review editing frank t c tsai conceptualization methodology resources validation writing review editing huawei chen resources validation writing review editing declaration of competing interest the authors declare that they have no known competing interests acknowledgments this research has been financially supported by the national natural science foundation of china no 52109080 national key research and development program no 2021yfc3200500 fundamental research funds for the central universities b220201013 and nanjing science and technology innovation project for researcher studying abroad b2104110 high performance computing hpc platform in hohai university is acknowledged for providing technique support appendix a supplementary data supplementary data supplementary figures to this study can be found in fig s1 to this article can be found online at https doi org 10 1016 j jhydrol 2023 129282 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary figures to this study can be found in fig s1 
2152,accurate modeling of karst genesis is an important issue to understand the spatial and temporal evolutions of transport properties in karstified carbonate rocks the previous modeling about karst genesis in fracture networks is mainly based on the simplified 2d conduit fracture networks without considering wormhole formation on the scale of individual conduits or fractures in this study we simulated the karst genesis and wormhole formation i e the emergence of preferential flow pathways within individual fractures in carbonate joint networks using a dfn model fully discretized in 3d and compared its difference with the 2d models the results show that compared to the 2d modeling the breakthrough time time of the abrupt rise in flow rate in the 3d models may be much less sensitive to the network connectivity because of the flow focusing during wormhole formation on the scale of individual joints with a relatively low flow rate also the dimensions of dissolving networks as well as the position and the number of developed preferential pathways in the well connected networks may be altered when switching from 2d to 3d modeling we further provide detailed insights into the underlying mechanism governing the dynamics of wormhole formation based on two representative networks a critically connected network and a well connected network we observed that the generated incipient karst patterns are similar between 2d and 3d models if the initial flow rate is sufficiently large i e no flow focusing inside individual joints before breakthrough or small i e wormhole pathway is extremely localized but the breakthrough time is much overestimated if the initial flow rate falls within the transition range the dissolution dynamics are complicated and dominated by the combined effect of flow migration over the network and flow focusing on the scale of individual joints the magnitude of which depends on the fracture roughness this study highlights the importance of incorporating the third dimension in dfn for accurate predictions of karst network evolution keywords incipient karst genesis wormhole formation discrete fracture network breakthrough time dissolution patterns flow focusing data availability no data was used for the research described in the article 1 introduction karst genesis is an important physical and chemical process in controlling the evolution of the hydraulic properties of the carbonate aquifer when the co2 rich water recharged from rainfall and runoff infiltrates down the fractured carbonates the aggressive fluid dissolves the highly conductive fractures and the enhanced conductivity in return attracts more flux further increasing the dissolution rate consequently karstic conduits and caves gradually form under the positive feedback loop how to reasonably predict the evolution of karst aquifers becomes an important research issue since the underlying mechanism regarding reactive transport is not only related to underground water management cousquer and jourde 2022 but also to co2 sequestration ott and oedai 2015 and petroleum production enhancement such as reservoir acidification liu et al 2017 over the last two decades extensive research has been conducted on simulating karst genesis the earliest attempts to model speleogenesis began from the evolution of a single one dimensional 1d conduit dreybrodt 1996 1990 palmer 1991 the dissolution kinetics used in these modeling approaches considered a switch from linear regime to nonlinear when the calcium concentration with respect to calcite is close to saturation white 1977 which allows the unsaturated front to initially penetrate a long distance into the rock simplified 1d conduit models suggest that the early development of a karst system with a fixed head boundary condition first experiences a slow increase in flow rate as the penetration distance under the first order kinetics is limited then an abrupt rise in flow rate occurs after the region of first order kinetics breaks through into the outlet the time when the total flow rate exceeds one thousand times the initial flow i e q t 103 q 0 is typically defined as the breakthrough time bt dreybrodt 1996 subsequently the modeling of karst genesis was extended to a two dimensional 2d network scenario consisting of 1d conduits or pipes dreybrodt et al 2005 groves and howard 1994 kaufmann and braun 1999 the 2d conduit network modeling revealed more complex dissolution dynamics beyond 1d modeling where the flow focusing due to the emergence of preferential channels accelerates the breakthrough recently dreybrodt and gabrovšek 2019 provided a deep insight into the dynamics of karst genesis based on an extremely fine 2d grid of fractures they interpreted the accelerated breakthrough for a 2d model and further analyzed the effect of interactions between developing flow paths and the effect of initial aperture heterogeneity on the dissolution pattern although the representation by a network of 1d conduits pipes can help one to well understand at low computational cost how preferential karstic conduits initiate and evolve in particular for studying the effect of recharge conditions hubinger and birk 2011 kaufmann and romanov 2019 romanov et al 2003 the assumption of ignoring wormhole formation within individual fractures still may leave a large deviation with real systems especially in the prediction of breakthrough time the formation of highly localized flow paths i e wormholes has been extensively investigated from the perspective of laboratory experiments and numerical simulations in 2d single fractures detwiler et al 2003 detwiler and rajaram 2007 hanna and rajaram 1998 szymczak and ladd 2009 wang et al 2022 szymczak and ladd 2011 mathematically demonstrated the dissolution front in even a smooth fracture may quickly break up due to infinitesimal perturbation and the wavelength developed with instability depends on the reaction rate and flow flux moreover they confirmed the flow focusing caused by the breakup of the dissolution front is the prerequisite for the breakthrough acceleration instead of the non linear kinetic trigger mechanism subsequently upadhyay et al 2015 further found that the dissolution pattern and breakthrough time of a single fracture may be insensitive to the roughness and correlation length of initial aperture distribution when the fracture length is sufficiently larger than penetration length defined be the ratio of local flow rate to reactive kinetics i e q 2k in addition starchenko et al 2016 developed a novel three dimensional 3d reactive transport model for single fracture dissolution then based on this model starchenko and ladd 2018 reproduced four distinct dissolution patterns in single fractures including face uniform and two characteristic wormhole shapes i e compact and necked which are determined by the combined effect of péclet and damköhler numbers therefore a more realistic approach to model the karst genesis of fractured carbonates would be to represent each fracture using a fully discretized 2d aperture field recently li et al 2020 proposed a 3d hydrochemical modeling approach based on the embedded discrete fracture model which is able to simulate the wormhole formation and evolution of karst aquifers in a 3d fracture network our recent work also developed a 3d reactive transport model based on the discrete fracture network dfn approach and investigated the combined effect of the flow rate and the aperture contrast between the joints and bedding plane on the karst genesis in 3d jointed layered rocks jiang et al 2022 nevertheless how the wormhole formation within individual fractures impacts the overall dissolution patterns within a fracture network remains not well understood carbonated rocks are commonly stratified into beds with each layer saturated with bed normal joints e g belayneh cosgrove 2004 odling et al 1999 when the bedding planes are significantly compacted joint networks will dominate the flow and transport behaviors jiang et al 2022 jourde et al 2002b 2002a wang et al 2017 some of the previous speleogenesis simulations on the basis of natural carbonate outcrops only focused on the topological characteristics of the 2d joint networks in the horizontal plane while ignoring the effect of potential differences in incipient karst development behaviors along the third dimension aliouache et al 2019 wang et al 2021 in this work we aim to provide a detailed insight into the dynamics of wormhole formation in 3d joint networks note that the term wormhole formation in this paper represents the breakup of uniform dissolution front and the emergence of preferential flow pathways within individual fractures in order to compare the difference between 2d and 3d modeling we focus the research target on single layer joint networks that are strata bound and bed normal as frequently observed from the outcrops of jointed layered rocks hooker et al 2013 odling et al 1999 the term 3d modeling in this paper refers to the 3d computational domain and mesh discretization however the studied dfn geometries are pseudo 3d which makes it possible to compare with 2d modeling that is adopted frequently in previous investigations dreybrodt et al 2005 dreybrodt and gabrovšek 2019 by vertically extruding the 2d joint networks the explicit 3d computational domain allows one to capture the formation of wormholes within individual joints we attempt to answer the following questions compared to the 2d fracture network model to what extent does the wormhole formation inside the fractures affect the breakthrough time what are the consequences of wormhole formation on the overall dissolution process will it lead to an alteration in the geometry of the karstic conduit network how much does 3d modeling differ from 2d modeling when different fracture network geometries flow rates and fracture surface roughness are considered the remainder of the paper is organized around the research goal as follows in section 2 we introduce the methodology used in this study including a brief description of the reactive transport model developed in our previous work jiang et al 2022 the joint network generation method the quantitative characterization method and the numerical model setup the simulation results are presented and analyzed in section 3 eventually further discussion and conclusions are given in section 4 and section 5 respectively 2 methodology 2 1 reactive transport model we use the reactive transport model that has been developed and validated in the previous work jiang et al 2022 the numerical model can solve the coupled hydro chemical processes including fluid flow reactive transport of ca2 and dissolutional growth of fracture aperture based on the finite element method the rock matrix is assumed to be almost impermeable and flow through it can be neglected relative to the highly conductive fractures aliouache et al 2019 dreybrodt and gabrovšek 2019 the transport in rock matrix may play an important role in the long time scale because of the relatively slow advection and diffusion nevertheless 3d reactive transport simulation with matrix effects in dense fracture networks is almost not feasible due to the huge computational cost associated with the mesh discretization of the rock matrix thus we consider the computational domain only on the 3d discrete fracture networks where the individual fractures are represented by 2d planes the relevant governing equations of the reactive transport model are given as follows szymczak and ladd 2011 upadhyay et al 2015 assuming that the flow velocity v and ca2 concentration c are averaged along the fracture aperture the mass conservation equation for single phase steady state flow through a fracture and the convection diffusion equation are expressed respectively as 1 τ b ρ v 0 v ρ g b 2 12 μ τ h and 2 τ b v c τ b d τ c 2 r c where b is the fracture aperture m ρ is the fluid density kg m3 v is the velocity vector m s μ is the fluid dynamic viscosity pa s g is the gravity constant m s2 h is the hydraulic head m c is the ca2 concentration mol m3 and d is the diffusion coefficient m2 s τ means the gradient operator restricted to the fracture s tangential plane the gravitational effect is not considered as this study focuses on a karst generation process in horizontal flow regimes 2r c means the reactive flux from the dissolving calcite with the factor of two representing the contributions from the upper and lower fracture walls it is assumed that the dissolution on the two sides of fractures is symmetrical due to the reduced dimension modeling of fracture networks the assumption may become invalid for horizontal fractures as the buoyancy driven flow may lead to more dissolution on the top surface than on the bottom surface hu et al 2021 wang et al 2022 nevertheless the more detailed mechanism regarding gravitational diffusion is not considered in this study i e fluid density is assumed to be uniform and constant here we consider the linear reaction kinetics is sufficient for our modeling purposes as the high order kinetics has been demonstrated to be not the prerequisite for developing long conduits szymczak and ladd 2011 thus r c can be written as 3 r c k eff c eq c with 4 k eff k 1 2 k b dsh where k eff is the effective reaction rate coefficient m s c eq is equilibrium concentration mol m3 k is the reaction rate constant m s and sh is the sherwood coefficient k eff considers the jointed role of surface reactions and diffusion transport where the reaction rate under a large aperture is limited by surface reactions whereas under a small aperture by diffusion dreybrodt and gabrovšek 2019 then the growth of the fracture aperture can be updated based on the local reactive flux 5 c sol db dt 2 r c where c sol is the molar concentration of calcite mol m3 2 2 joint network generation in carbonate rocks many outcrop observations have shown the trace length of joints always follows a lognormal distribution with the spacing proportional to the layer thickness mcquillan 1973 odling et al 1999 therefore we use the lognormal distribution to model the lengths of each joint set in this study it has been confirmed from both laboratory experiments and numerical simulations that the spacing of the joints is essentially controlled by a mechanical interaction between the joints rives et al 1992 wu and pollard 1995 here we employ the joint network generator with the concept of stress shadow zone integrated to reproduce the joint interaction statistically josnin et al 2002 jourde 1999 jourde et al 2002a 2002b wang et al 2017 specifically a shadow zone is defined around each existing joint and a newly generated joint center is placed randomly but not in the shadow zones of existing joints once the location of the new joint is determined values of its orientation and length are sampled from the corresponding distribution models nevertheless the newly generated joint requires some geometric operations i e truncation extension and removal which are also determined by its position relative to the shadow zone of the old joints more details about the fracture network generation can be found in our recent paper sun et al 2021 a 3d joint network can be constructed by extruding a 2d joint network such that the geometric connectivity remains unchanged fig 1 b for a 2d fracture network the fracture intensity γ can be defined as the cumulative fracture length divided by the rock area 6 γ 1 l 2 n l where l is the size of the square domain m l is the fracture length m n is the fracture number the geometric connectivity can be characterized by the percolation parameter p 7 p 1 l 2 n l 2 which is applicable for a totally random non fractal fracture network bour and davy 1997 a higher p means higher connectivity of the network basically a connected network tends to form if p is larger than the percolation threshold p c 5 8 bour and davy 1997 for the 3d joint networks we further consider a nonuniform initial aperture field superimposed on each joint the nonuniform aperture is assumed to follow a random lognormal distribution with the mean value b 0 b t 0 the roughness σ is defined to characterize the amplitude of aperture heterogeneity which is given as upadhyay et al 2015 8 σ b 2 b 2 b 2 3 quantitative indices for analyzing characteristics of flow and dissolution the dissolution behaviors of the fractured carbonates always depend on the magnitude and heterogeneity of flow aliouache et al 2019 siemers and dreybrodt 1998 thus we adopt the equivalent permeability of rocks and flow channeling density indicator to quantitatively measure the overall flow capacity and the degree of flow localization respectively the equivalent permeability of a fractured rock κ eq m2 can be calculated based on darcy s law 9 κ eq μ q l a ρ g h in h out where q m3 s is the total flow rate through the outlet with a cross section area a m2 h in m and h out m are the hydraulic heads at the inlet and outlet boundaries respectively to quantify the channelization of flow field in 3d fracture networks we define the flow channeling density indicator d q which is modified from the original introduction by maillot et al 2016 10 d q 1 s s q d s 2 s q 2 d s where s is the fracture surface m2 q is the local flow rate m2 s i e vb the same definition in the form of participation ratio has been previously applied to quantify the degree of localization of the deformation in surface fractures davy et al 1995 sornette et al 1993 d q can measure the percentage of the total fracture surface that experiences a significant flow rate i e the fraction of active flowing area hyman 2020 the value of d q only depends on the relative flow distribution where a smaller d q corresponds to a more localized flow regime while d q 1 to a uniform the penetration length l p m is an important parameter to analyze the instability of dissolution front in an initially uniform fracture szymczak and ladd 2012 2011 l p denotes the distance over which undersaturation decays which is given as 11 l p q 2 k where q is the local flow rate m2 s and k is the reaction rate constant m s unlike the dissolution of porous matrix which is limited to the inlet region when the flow rate is significantly low according to the linear stability analysis szymczak and ladd 2013 the dissolution front of fractures is always unstable with the wavelength having the same scale of l p szymczak and ladd 2011 this is because there is no limit to the opening of fracture aperture thus although the dissolutional growth is slow with a low velocity eventually the front always breaks up upadhyay et al 2015 nevertheless if the flow rate is high enough to ensure the penetration length exceeds the dimensions of the system the front may remain uniform 2 4 model setup as shown in fig 1a we consider the joint networks consisting of two joint sets whose orientations follow a normal distribution with the mean being 0 and 60 respectively and the standard variation being 5 zambrano et al 2016 all the 2d joint networks are generated within a domain of 10 m 10 m and then are extruded by 1 m to create 3d dfns wang et al 2017 fig 1b the numerical simulation domain is assumed a representative element volume in a confined aquifer in the sequential analysis a dimensionless parameter defined by the ratio of average initial penetration length l p to the model length l is introduced to generalize the simulation results the joint lengths following a lognormal distribution have a mean of 3 m and a standard deviation of 0 3 siemers and dreybrodt 1998 have shown that different connectivity of fracture networks may lead to distinct dissolution behaviors based on 2d fracture networks with the assumption of uniform dissolution along each fracture this work attempts to extend the study into 3d scenarios thus we also consider four different fracture intensities γ 1 875 m 1 2 5 m 1 3 75 m 1 and 5 m 1 which corresponds to p 6 2 8 3 12 5 and 16 7 fig 1a as shown from the range of p the connectivities of the studied fracture networks cover from the critically connected i e p 5 8 to the well connected which can show the features of dissolution behaviors under different degrees of fracture geometrical connectivities here we only focus on the x direction reactive flow since the significant effect of network topology has been analyzed in the previous work aliouache et al 2019 fig 1a shows in red the geometries of flow backbones i e percolating fractures connecting inlet and outlet with respect to x direction flow for reactive transport simulations we directly extract the flow backbones as the computational domain since the non percolating fractures do not contribute to flow fig 1b we specify constant head conditions at the left inlet boundary x 0 m and the right outlet boundary x 10 m and assume all the other outer boundaries are impervious the calcium concentration of the inflow water is considered to be 0 mol m3 typical parameter values for calcite dissolution are adopted dreybrodt 1996 szymczak and ladd 2011 the equilibrium concentration is c eq 2 mol m3 the reaction rate constant is k 2 5 10 7 m s the sherwood number is sh 8 and the molar concentration of calcite is c sol 2 7 104 mol m3 the density and viscosity of fluid are ρ 1000 kg m3 and μ 1 10 3 pa s respectively temperature may affect the reaction kinetics and chemical equilibrium as well as the fluid properties palmer 1991 for simplification we assume the temperature of the fractured rocks is uniform and fixed such that the reaction rate constant is fixed the molecular diffusion constant is d 1 10 9 m2 s the gravity constant is g 9 81 m s2 all the fracture planes are discretized with the rectangular finite element mesh with the resolution in the horizontal direction i e parallel to x y plane being 0 05 m in the vertical z direction we distinguish between 2d and 3d modeling using different levels of mesh resolution as shown in fig 2 for 2d modeling only one layer of mesh is created in the vertical direction fig 2a which is equivalent to the simplified 2d conduit network modeling with the assumption of uniform dissolution within each conduit by contrast for 3d modeling a 20 layer grid is considered in the vertical discretization fig 2b which allows for the occurrence of non uniform dissolution fronts the numerical model for the geometry in fig 2b has around 172 000 rectangular mesh elements with the number of degrees of freedom to be solved over 1 million the adopted mesh resolution is sufficient for our research purposes since we have confirmed that a finer grid has a minor impact on the trend of the results but at a very high computational cost more detailed information about model implementation and verification can be found in our previous paper jiang et al 2022 for the setup of parameter sensitivity analysis in addition to network geometrical connectivity the effects of flow rate and fracture roughness are further analyzed these two parameters are the key factors to influence the instability of dissolution front in an initially uniform fracture according to the study of szymczak ladd 2011 penetration length i e l p q 2k eq 11 is a key parameter for characterizing the front instability thus we determined the effect of flow rate q and generalized the results by the penetration length q 2k which can also provide some implications for the effect of reaction kinetics k the specific parameters for the joint aperture and hydraulic gradient for the three subsection analysis are as follows 1 in section 3 1 the influence of network connectivity is studied to get a first insight into the difference between the 2d and 3d modeling we conducted the reactive transport simulations using all fracture networks with different connectivities fig 1a under the same hydraulic gradient i e 0 1 m m for each percolation parameter p 20 realizations of networks are generated the initial aperture field for 2d modeling is uniform which is b 0 0 1 mm while for 3d modeling a tiny variability roughness σ 0 0001 is superimposed i e max b 0 0 1 mm 50 nm similar as szymczak ladd 2011 2 in section 3 2 two representative fracture network geometry one is well connected and another is poorly connected is selected to study the influence of flow rate here a series of pressure gradients are considered corresponding to initial penetration length l p0 from 0 0005 to 0 1 while the roughness in the 3d models is still considered to be very small σ 0 0001 3 in section 3 3 the influence of roughness in 3d models is further studied σ 0 0001 0 001 0 01 and 0 1 in combination with the effect of flow rate i e l p0 from 0 0005 to 0 1 3 results and analysis 3 1 influence of network connectivity in the different dissolution behaviors between 2d and 3d modeling fig 3 a shows the variation of breakthrough time as a function of percolation parameter p based on two different dfn representative approaches fracture networks fully discretized in 3d 3d modeling and simplified 2d conduit pipe networks 2d modeling furthermore fig 4 exhibits the dissolution patterns at the breakthrough time using one example each to represent the corresponding p to explain the trend of breakthrough times the corresponding variations of the equivalent permeability κ eq the mean penetration length l p and the flow channeling density indicator d q at the initial time are further calculated and presented in fig 3b c and d respectively we have confirmed that the values of these three quantitative indices for 2d modeling are initially the same as those for 3d modeling as the fracture connectivity increases the equivalent permeability of the fractured rocks rises significantly meaning that the total flow rate before dissolution increases greatly under the same pressure difference fig 3b note that this trend is obtained based on the fractures with percolation parameters above the percolation threshold a similar trend of the relationship between the percolation parameter and permeability has been also observed in previous papers lei et al 2020 sun et al 2020 it is worth noting that the magnitudes of mean local flow rates are almost comparable where the initial values of l p are around 0 08 m fig 3c much smaller than the rock length i e 10 m for 2d modeling it is observed that the breakthrough time decreases significantly with the increase of p fig 3a the operating mechanism may be interpreted as follows first the initial l p increases with p which means a deeper penetration initially in each 1d joint conduit at the entrance although the increase of l p with p is small its effect may be amplified under the mechanism of the positive feedback loop dreybrodt 1996 second preferential flow paths tend to emerge due to the flow focusing siemers and dreybrodt 1998 and only one pathway gains an advantage for development eventually fig 4a d this means the total flux is gradually concentrated to one preferential pathway as the dissolution process proceeds more analysis about the evolution process can be seen in section 3 2 as a result a well connected network large p with a large equivalent permeability can allow a high flux focused into the preferential flow pathway eventually leading to a much deeper penetration along this pathway and early breakthrough the third reason may be related to the length of percolating pathways siemers and dreybrodt 1998 at low p the geometries of percolating pathways for different realizations are highly diverse due to poor connectivity consequently the short flow pathways are rarely created leading to a large breakthrough time with a large deviation fig 3a by contrast at high p high fracture intensity allows fractures to intersect each other to form short flow paths whose length is comparable to the domain length which greatly reduces the breakthrough time and its deviation however in 2d modeling it is worth noting that the decrease of the breakthrough time tends to become slow the slope decreases with higher p it may be attributed to the stronger competition among different flow paths which is quantified by the rising d q in the initial time fig 3d at low p d q is small such that the flow structure is highly localized which means the preferential flow pathway is always determined at the beginning see more details in section 3 2 thus the dissolution patterns are controlled by the highly irregular geometry of the flow backbone see fig 4a and b as the fracture intensity increases more fractures start to interconnect see p 12 5 in fig 1a and the flow structure becomes less channelized initially d q increases as a result there is a strong competition among the pathways with similar resistance which may retard the decline in breakthrough time with higher p fig 3a note that the increase of d q with p becomes slow meaning the network tends to become saturated and well interconnected in general the trend of breakthrough times and dissolution patterns with different network connectivities for karst genesis in 2d conduit networks is consistent with the study of siemers and dreybrodt 1998 for 3d modeling the karst genesis exhibits a large difference from 2d modeling especially at low p there is a significant reduction in breakthrough time for 3d modeling compared to 2d modeling fig 3a due to the wormhole formation within individual joints fig 4e the difference in breakthrough time between 2d and 3d models decreases with the increase of network connectivity more interestingly it seems that the breakthrough time for 3d modeling is insensitive to fracture network connectivity under the specific pressure difference in particular the breakthrough time even rises slightly when p increases from 12 5 to 16 7 moreover it is observed that a significant discrepancy between 2d and 3d modeling emerges in dissolution patterns fig 4 at low p the network structure of the developing karstic conduits for the 2d and 3d models are similar which are highly governed by the geometries of flow backbone as the joint network is critically connected however the vertical size of the karstic conduits is significantly reduced for 3d models due to the occurrence of wormhole formation inside the joints also the predicted aperture at breakthrough for 2d modeling is unreasonable actually greatly exceeds the color bar range for fig 4a and b because it takes too much time to break through at high p although the difference in breakthrough time between 2d and 3d modeling is reduced the dissolution patterns may become totally distinct in 3d models more dominant conduits may form fig 4g and even the location of the preferential channels could change fig 4h therefore from the above observations the importance of 3d discrete fracture network modeling is highlighted although the aperture variability in each joint is considered extremely small adding the dimension from 2d to 3d may lead to wormhole formation and flow focusing within individual joints which not only accelerates the breakthrough time but also alters the dissolution patterns to better understand the underlying mechanism causing the discrepancy between 2d and 3d modeling we provide detailed insights into the evolution process of karst genesis in the following section 3 2 influence of flow rate penetration length 3 2 1 role of flow rate in the different dissolution behaviors between 2d and 3d modeling the flow rate or equivalently the penetration length is an important parameter to control the formation of wormholes within single fractures according to the foundations of prior research szymczak and ladd 2012 2011 therefore we further adopt a series of pressure gradients to compare the difference between 2d and 3d modeling the roughness is still considered to be very small σ 0 0001 here we examine two representative joint networks as examples one for the critically connected network p 6 2 in fig 1a and another for the well connected network p 16 7 in fig 1a we define a dimensionless parameter to represent the pressure gradient level i e l p0 the ratio of average initial penetration length to domain length l p0 q 0 2k l jiang et al 2022 a large range of pressure gradients are explored which corresponds to l p0 from 0 0005 to 0 1 fig 5 shows the variations of breakthrough time as a function of l p0 for a critically connected joint network and a well connected network furthermore fig 6 exhibits the corresponding aperture distribution at breakthrough it is observed that if l p0 is large enough the 3d modeling of karst genesis in dfns can be simplified to a uniform dissolution process within conduit networks dashed lines overlap with solid lines in fig 5 and identical patterns are obtained for 2d and 3d modeling when l p0 0 04 in fig 6 if the joint network is critically connected although the dissolution patterns are very simple due to the geometrical constraint of the flow backbone the branches tend to be less developed with the decrease of l p0 fig 6a c vs e g compared to 2d models a pronounced difference in dissolution patterns for 3d models is the wormhole formation when l p0 0 013 furthermore the shape of the wormhole varies with the increase of l p0 such as a compact wormhole for l p0 0 0022 and a necked wormhole for l p0 0 0093 and 0 013 the trend of dissolution patterns responding to inflow rate magnitude is consistent with the single fracture simulations starchenko and ladd 2018 note that since the boundary condition considered in this study is constant head dissolution develops across the whole height of the joints around the outlet starchenko et al 2016 thus the wormholes exhibit the characteristic shapes i e compact or necked only around the inlet which is different from the scenarios of constant flow rate where the wormhole is highly localized along the outlet starchenko and ladd 2018 it is worth noting that a similar trend of the development of dissolution patterns can be also obtained with the increase of dissolution rate constant starchenko and ladd 2018 szymczak and ladd 2009 wang et al 2022 here we mainly focus on the effect of wormhole formation on the network scale dissolution of the fracture system but not on the condition for generating wormholes along a single fracture conclusions may also apply to the systems with different dissolution rates furthermore going beyond the previous simulations on single fractures a macroscopic network structure of karstic conduits can be captured in this study more interestingly the well developed branching pattern can be maintained until l p0 0 002 in 3d modeling see similar network patterns for the cases below the red dotted lines in fig 6 which is attributed to the enhanced penetration capability of dissolution front by flow focusing also the network expansion can be found in the cases of well connected network it indicates that without the consideration of wormhole formation the degree of branching network spreading may be underestimated on the other hand the prediction of dissolution pattern on the network scale based on 2d conduit networks may be instructive with a sufficiently low l p0 fig 6a e i and m this is because under the condition of low flow rate karst genesis is confined within a single linear pathway meaning that a high dimensional dissolution process in networks is reduced to a low dimensional process along a single conduit however the accuracy of the bt prediction is far from adequate for 2d modeling with a low flow rate therefore the wormhole formation caused by the added third dimension makes the dissolution behaviors more complex which can be also reflected from the curves of breakthrough time vs l p0 in fig 5 for 2d models karstic conduits at high l p0 develop in a network scale with uniform dissolution within individual joints in this dissolution scale the competition mechanism between different flow pathways plays an important role in controlling the breakthrough time secondary karstic conduits become more developed at large l p0 indicating a sustained competition aliouache et al 2019 with the decrease of l p0 the karst development tends to focus on the scale of a single and simple pathway with little effect of competition between different flow channels consequently it is observed that the bt varies with l p0 at different slopes for these two scales with a transition zone at around 0 02 for the critically connected cases and around 0 013 for the well connected cases for 3d models wormhole formation extends the range of the network dissolution scale as the flow focusing makes the dissolution front more aggressive as a result the threshold of l p0 for the dissolution scale transforming from a network scale to a single pathway scale is reduced more interestingly because of the wormhole formation in 3d modeling the breakthrough time of the critically connected case may be similar to that of the well connected case at the range of 0 009 l p0 0 012 by contrast the breakthrough time of the former in 2d modeling is always above the latter 3 2 2 detailed explanations for the different breakthrough times between 2d and 3d modeling fig 7 provides a visual insight into this phenomenon through the temporal and spatial evolutions of dissolution front using the representative cases with l p0 0 0094 furthermore fig 8 gives the corresponding evolutions of the flow channeling density d q at the early stage of karst development t 1a the dissolution fronts for both cases are quite planar because only a very tiny variability of the initial aperture field is considered fig 7a e i and m the d q evolution of the 2d and 3d models also shows the same behavior during this stage whereas there is a significant difference between the different connectivity networks fig 8 for the critically connected network the initial d q is much lower than that of the well connected one which indicates a higher channelized flow at the initial time thus the winning pathway is determined from the very beginning due to the high flow channelization subsequently the dissolution evolution seems to proceed as a dynamic in a single fracture since the flow supply from other pathways is significantly weak as a result if the network is represented by a 2d model the dissolution front propagation is concentrated on the highly channelized flow pathway and is very slow the slope of the d q evolution is small however if it is represented by a 3d model the wormhole formation and flow focusing inside the joints can significantly accelerate the dissolution progress which is quantified by a quick drop of d q once the dissolution front breaks up at 3 5 a fig 7f and fig 8 moreover the karst conduit of 3d modeling may develop with a length at 8a comparable to the one of 2d modeling at 70a fig 7d vs h by contrast for the well connected network the dissolution behaviors tend to follow a different mode it can be observed that a rapid dissolution development can form even with 2d modeling i e d q drops fast with a large slope with the breakthrough time reduced to 20 a fig 8 this is attributed to the strong flow focusing supported by numerous flow channels although the initial penetration length in each pathway is short the losing pathways gradually degrade dissolution fronts retreat during the development and are drained to the winning one where the penetration length is enhanced quickly we can see that the 2d well connected case can develop the same conduit length much earlier than the 2d critically connected case fig 7l vs d if the well connected network is represented by a 3d model the breakthrough time is further reduced by the superimposed flow focusing of the individual joints on that of the network fig 7o and p it is worth noting that the dissolution front at 3 5a of the 3d well connected case is more uniform than that of 3d critically connected case fig 7n vs f we can interpret the underlying mechanism of karst evolution in the 3d well connected network as follows before 3 5 a the flow reorganization with the dissolution growth of joints mainly occurs on the network scale i e between different flow pathways compared to the critically connected network more flow in the well connected network coming from the neighboring competing pathways can be focused on the main flow channel which then gains a larger penetration length szymczak and ladd 2011 demonstrated that the wavelength of the dissolution front which exhibits a sinusoidal mode during developing is proportional to the penetration length the larger wavelength of the dissolution front may lead to a uniform growth of the front and the flow focusing may stall especially when the joint height is lower than the wavelength therefore the wormhole in the critically connected network may form earlier than in the well critically connected network the separation point between the dashed and solid lines is earlier in fig 8 in addition the wormhole in the former is narrower than that in the latter due to the smaller wavelength fig 7g vs o leading to a stronger flow focusing along the joint profile thus the earlier timing of the wormhole formation provides an extra chance for the critically connected network to break through earlier which may also well explain why the breakthrough time tends to be insensitive to the fracture connectivity once the wormhole formation occurs in 3d modeling fig 3a 3 2 3 detailed explanations for the different dissolution patterns between 2d and 3d modeling another interesting phenomenon is that the wormhole formation in 3d modeling may lead to a more complex dissolution pattern compared to 2d modeling it is observed that more secondary karstic conduits may form due to the wormhole formation fig 7p and even the winning pathway may alter fig 6o to explore this deeper we compare the evolutions of dissolution patterns between 2d and 3d models of the well connected case with l p0 0 013 in fig 9 fig 10 further illustrates the corresponding evolutions of d q and the inflow rate into the inlets whose positions are marked in fig 9d for the 2d model pathway no 1 gains the advantage at the beginning compared to pathway no 2 fig 10b then pathway no 1 develops first fast but then much slowly after around 1 5 a this is inferred to result from the competition between outflow branches when the leading pathway passes the junctions fig 9b which makes the shorter pathways gain an extra chance to grow aliouache et al 2019 it is observed that the inflow rate of no 2 can exceed that of no 1 in a certain period but the above interruption mechanism can also take place on no 2 fig 9c meanwhile once the weak branch of the no 1 is abandoned its aggressive power will resume and then regain the leading position fig 10b by contrast for the 3d model the dissolution behaviors of these two pathways proceed in opposite manners after about 3 5 a as illustrated in fig 9f the dissolution front of no 2 has already broken up and the resulting flow focusing inside makes it more aggressive and competitive even d q is slightly larger than the 2d model during this period zoom in plot in fig 10a indicating a less localized flow field induced by the enhanced competition between pathways no 1 and no 2 as a result pathway no 2 gains an advantage eventually instead of being terminated by no 1 fig 10b note that compared to the case with l p0 0 0093 fig 7n the dissolution front of pathway no 1 in this case seems more uniform because of the higher initial flow rate also attributed to the more uniform dissolution of no 1 pathway no 2 may gain an extra chance to break up the dissolution front early and quickly benefits from the flow focusing 3 3 influence of fracture roughness 3 3 1 role of fracture roughness in the different dissolution behaviors between 2d and 3d modeling through the above analysis we understand the importance of the flow focusing during the formation of wormholes in the comparison we only used a tiny roughness to keep the 3d models close to the 2d models under this configuration of initial aperture the dissolution front is quite uniform at the beginning but still has instability to form wormholes dreybrodt and gabrovšek 2019 consequently we found the timing of the breakup of dissolution fronts within individual joints may influence the rate of karst development and the location of the main flow channels the previous analysis of linear instability is based on single fractures where the total flow rate or l p can be regarded as constant in the initial stage of dissolution when l p is much smaller than the fracture length szymczak and ladd 2011 our study further suggests that some of the conclusions drawn from the single fracture analysis may be not applicable to the fracture networks since the flow exchange among different pathways may lead to dynamic variations in l p within individual fractures for example the increased l p due to the flow focusing from the whole network may increase the potential wavelength of unstable dissolution front in the leading pathway and then delay or even avoid the wormhole formation before breakthrough this is also the reason why the threshold of the separation between the 2d model and 3d model curves of bt vs l p0 is shifted to the left for well connected networks fig 5 considering the important role of the timing of wormhole formation in dissolution behaviors we further explore the influence of roughness σ as shown in the curves of bt vs l p0 in fig 11 and the dissolution patterns at breakthrough in fig 12 here we take the well connected network as an example because of the large variability in aperture for the joints with high roughness the dissolution front can break up quickly i e a rapid formation of wormholes upadhyay et al 2015 consequently a high σ may lead to a fast breakthrough causing that the threshold of l p0 over which the 3d modeling is identical to 2d modeling moves to the right i e large values if l p0 is sufficiently small the breakthrough time tends to be insensitive to the roughness which is consistent with the observations of upadhyay et al 2015 the results confirm the scale dependence of breakthrough time on roughness also exists in the network system where bt decreases monotonically with σ in a small scale large l p0 hanna and rajaram 1998 whereas bt shows a large fluctuation a minimum in bt σ is expected with σ in a large scale small l p0 due to the interplay between flow focusing and branching at the wormhole tips cheung and rajaram 2002 upadhyay et al 2015 also for small l p0 the dissolution patterns are quite similar regardless of the roughness upadhyay et al 2015 where our simulation results based on the networks further show an insensitivity of the position of developed conduit and the degree of branch development to σ fig 12e and i with the increase of l p0 the dissolution pattern of high σ gradually exhibits a distinction from that of low σ for example two developed conduits may emerge for the case of σ 0 1 with l p0 0 013 fig 12g vs k as l p0 further increases although the main flow channels tend to dissolve uniformly and the breakthrough time converges with 2d model the secondary channels in the 3d model with high σ penetrate deeper downstream due to the highly focused flow and quick wormhole formation fig 12l vs h 3 3 2 detailed insights into the dissolution behaviors for cases with different fracture roughness to further explore the underlying mechanism of the joint network system with high σ we give the details of the karst evolution for the 3d well connected case with l p0 0 013 and σ 0 1 in figs 13 and 14 as illustrated in fig 13a the dissolution front is highly non uniform even at the initial time also the initial d q of σ 0 1 is lower than that of the case of σ 0 0001 fig 14a indicating a more channelized flow from the beginning as a result the unstable dissolution fronts break up quickly and at t 0 5 a basically a wormhole has formed in all the flow paths fig 13b then the karstic conduits develop very fast quantified by a dramatic drop in d q fig 14a from the inflow analysis in fig 14b we observe that the inflow rates in the different flow pathways are initially independent of the roughness whereas the rapid wormhole formation at high roughness leads to the earlier occurrence of the quick elevation of the flow it is worth noting that the acceleration of karst development i e the deviation point for curve σ 0 1 from curve σ 0 0001 in pathway no 1 occurs earlier than in pathway 2 when σ 0 1 this confirms again that flow migration on the network scale and flow magnitude inside individual fractures can affect the timing of wormhole formation nevertheless the relatively quick breakup of dissolution front for pathway no 1 leads to its competition with pathway no 2 instead of being terminated eventually two winning pathways may emerge at breakthrough fig 12k 3 3 3 combined effect of network connectivity and fracture roughness on breakthrough times back to fig 11 we notice that the breakthrough time increases monotonically with decreasing l p0 when σ 0 1 which is owed to the reduced effect of the timing difference of wormhole formation between different channels on the competition mechanism between them in other words the dissolution competition and flow migration may rapidly transform from between different joints to between different wormholes thus close to the 2d models the cases of σ 0 1 also show a monotonic behavior for bt vs l p0 furthermore we also examine the effect of network connectivity on breakthrough time using the 3d models with σ 0 1 as illustrated in fig 15 the results are all based on 20 realizations of networks for each percolation parameter the boundary conditions are consistent with those described in section 3 1 as expected the breakthrough times of 3d cases with σ 0 1 are reduced significantly due to the flow focusing during wormhole formation whereas the tread of breakthrough time with respect to network connectivity is similar to the 2d case where the rising of bt becomes faster with the decrease of p 4 discussion in this study we have conducted a large number of numerical simulations to compare the karst genesis in joint networks using fracture networks fully discretized in 3d and simplified 2d conduit pipe networks in the past the latter approach has been adopted extensively to study the incipient karst evolution of fractured limestone aquifers due to the less computational cost for network scale simulations aliouache et al 2019 kaufmann and romanov 2019 wang et al 2021 in this work we found an extremely fine mesh is usually necessary if one aims to accurately delineate the dynamics of dissolution front breakup within each fracture in some cases simplified 2d modeling may be a practical tool to help one understand the physical processes acting on the networks e g the competition mechanism among different pathways aliouache et al 2019 dreybrodt and gabrovšek 2019 in particular 2d modeling may still be valid if the penetration length is close to the outlet i e the system scale is small large l p0 because the dissolution front is stable before breakthrough the scale transversal to the flow direction i e the joint height in this study is another key parameter to determine whether wormholes may form before breakthrough although the joint height is not studied in depth here the dissolution front tends to be uniform if the joint height is considerably small which is essentially governed by a relatively large wavelength of the front eventually reflected in the role of penetration length szymczak and ladd 2011 although there are some advantages in the simplified 2d modeling its accuracy may be far from adequate to predict karstification in natural karst systems the main reasons may be summarized in the following two points first the scale of the natural karst systems is always much larger than the penetration length calculated by eq 11 usually 1 m for calcite and 10 m for dolomite this means the dissolution fronts in fractures are always unstable as the instability continues to grow even l p may be larger than the fracture width szymczak and ladd 2011 according to our observations if the scale of the system is sufficiently large i e small l p0 the dissolution pattern becomes extremely localized and independent of the roughness upadhyay et al 2015 in this scale the 2d modeling may be instructive for predicting the position of the dominating pathway however the predicted breakthrough time and the aperture enlargement may be significantly overestimated based on the 2d modeling especially for the critically connected fracture networks if the scale of the system is medium i e medium l p0 the flow focusing during wormhole formation may not only accelerate breakthrough but also alter the position of developed conduits in this scale we further found the propagation extent of the karstic conduit network may be greatly underestimated for the 2d modeling moreover the breakthrough time may be insensitive to the fracture network connectivity due to the different timing of breakup of the uniform dissolution fronts in the main flow pathways which is distinguished from the observations in 2d modeling siemers and dreybrodt 1998 second a real fracture surface is never even and always has a certain roughness our findings indicate that for a medium l p0 fracture roughness may also affect the dissolution patterns and breakthrough time a high roughness leads to a quick formation of wormholes and an early breakthrough as a result the threshold of l p0 over which 2d modeling is identical to 3d modeling increases which further narrows the applicability of 2d modeling moreover the uniform variability of aperture field in this paper is still very simplified while the realistic roughness may vary in different joint locations which also governs the mechanical aperture responses to the polyaxial in situ stresses lei et al 2017 therefore only the fully discretized 3d modeling is able to integrate the complexity of the fracture surfaces to achieve more accurate predictions of the evolution of karst aquifers in addition this study may also provide useful implications on how to design the controlling scheme for wormhole formation to enhance the influence area during acid treatment on fractured carbonate reservoirs in the petroleum industry note that our simulation model is based on some ideal assumptions where more complex mechanisms about the dynamics of wormhole formation from the pore scale perspective are not considered first our study emphasizes the effect of the timing of dissolution front breakup and the resulting flow focusing on the dissolution patterns on the network scale such as the position of preferential flow pathways and the dimensions of the dissolved conduit network thus only a simplified fracture roughness field is integrated into the network scale simulation framework however realistic heterogeneous aperture distributions may organize in a self similar or self affine structure deng et al 2018a moreover local flow circulations may form in the deep troughs of rough fracture surfaces which may trap the solute in the recirculation zones and further impact the dissolution process deng et al 2018a this phenomenon is relevant to high flow rates where darcy s law may break and the non darcian effects on the pore scale reactive transport may need to be considered second the gravitational effect is also important during the evolution of dissolution according to some recent advancements regarding radial dissolution experiments hu et al 2021 wang et al 2022 because of the density difference between the saturated and unsaturated solution buoyancy driven flow and gravitational diffusion may lead to more dissolution on the top surface than the bottom surface of a horizontal fracture and dissolution hotpots may emerge where advective transport is comparable to gravitational diffusion however the effect of gravitational diffusion is not considered in the numerical model since the density variation of caco3 solution under different co2 partial pressures is not well understood we have only focused in this study on the effect of aperture variation on the breakup of uniform dissolution fronts which adapts to fractures of different dips it is worth noting that for vertical fractures gravity diffusion may induce unsaturated fluid concentrated on the top of fractures oltéan et al 2013 which may further affect the timing of wormhole formation nevertheless this mechanism needs further experimental validation and numerical examination on calcite dissolution with carbonic acid in future works due to the low solubility of caco3 in addition the mineral composition is another key factor influencing the heterogeneity of karstification where fractures in low calcite carbonates and calcite rich shales may switch from uniform to wormhole dissolution with all other conditions held the same deng et al 2018b lastly although in nature the constant head recharge does exist before breakthrough especially in the phreatic zone the diversity of the cave patterns depends more on a variety of recharge types and also different geological structures e g the effect of bedding partings palmer 1991 thus more examinations need to be conducted to explore the influence of these factors in the 3d modeling context in the future to achieve better simulation of various cave patterns 5 conclusions to conclude we have simulated the incipient process of karst genesis in carbonate joint networks with different geometrical connectivities the joint networks are represented by two different modeling approaches a simplified 2d conduit network model that does not take into account the wormhole formation inside each joint and a dfn model fully discretized in 3d by comparing 2d with 3d modeling we found the breakthrough time in the 3d models may be much less sensitive to network connectivity than in the 2d models which is attributed to the flow focusing during wormhole formation also the position and number of the preferential flow pathways may be altered in 3d modeling of the well connected networks even only a very tiny aperture variability roughness of joint surfaces is considered to gain detailed insights into the underlying mechanism governing the karst genesis in 3d joint networks we have further investigated the combined effects of the initial flow rate or penetration length and roughness based on two representative networks a critically connected and a well connected results indicate that a large flow rate allows 2d modeling to be consistent with 3d modeling while the threshold is reduced for the well connected networks due to the strong flow focusing supported by the dense flow backbone if the flow rate is sufficiently small a very localized dissolution pattern is obtained where the position of the preferential flow pathway in the 3d model is the same as in the 2d model nevertheless the narrow wormholes in 3d joints can significantly accelerate the breakthrough roughness only has a minor effect on the evolving dissolution patterns of the wormhole networks the trunk and branches if the flow rate is medium dissolution patterns in 3d models exhibit a larger dimension of wormhole network than in 2d models the timing of wormhole formation may control the position of the preferential flow pathways in addition increasing roughness can lead to a quick breakup of dissolution front transforming the competition from between different joints into between different wormholes this may not only reduce the breakthrough time but also impact the final dissolution patterns this study has important implications for better understanding the wormhole formation in 3d fracture networks further promoting a more accurate prediction of the evolution of karst aquifers credit authorship contribution statement chuanyin jiang methodology formal analysis writing original draft xiaoguang wang conceptualization software formal analysis writing review editing shengyan pu software writing review editing hervé jourde resources supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments c j is supported by the china scholarship council csc from the ministry of education of p r china no 202006450151 x w is grateful for the support from national key research and development program of china grant no 2020yfc1808300 national natural science foundation of china grant no 42102300 science technology department of sichuan province grant nos 2021zycd004 2022yfsy0008 and state key laboratory of geohazard prevention and geoenvironment protection grant no sklgp2022k024 s p is grateful for the national natural science foundation of china grant no 41772264 the national key research and development program of china grant no 2020yfc1808300 and the research fund of state key laboratory of geohazard prevention and geoenvironment protection grant no sklgp2020z002 
2152,accurate modeling of karst genesis is an important issue to understand the spatial and temporal evolutions of transport properties in karstified carbonate rocks the previous modeling about karst genesis in fracture networks is mainly based on the simplified 2d conduit fracture networks without considering wormhole formation on the scale of individual conduits or fractures in this study we simulated the karst genesis and wormhole formation i e the emergence of preferential flow pathways within individual fractures in carbonate joint networks using a dfn model fully discretized in 3d and compared its difference with the 2d models the results show that compared to the 2d modeling the breakthrough time time of the abrupt rise in flow rate in the 3d models may be much less sensitive to the network connectivity because of the flow focusing during wormhole formation on the scale of individual joints with a relatively low flow rate also the dimensions of dissolving networks as well as the position and the number of developed preferential pathways in the well connected networks may be altered when switching from 2d to 3d modeling we further provide detailed insights into the underlying mechanism governing the dynamics of wormhole formation based on two representative networks a critically connected network and a well connected network we observed that the generated incipient karst patterns are similar between 2d and 3d models if the initial flow rate is sufficiently large i e no flow focusing inside individual joints before breakthrough or small i e wormhole pathway is extremely localized but the breakthrough time is much overestimated if the initial flow rate falls within the transition range the dissolution dynamics are complicated and dominated by the combined effect of flow migration over the network and flow focusing on the scale of individual joints the magnitude of which depends on the fracture roughness this study highlights the importance of incorporating the third dimension in dfn for accurate predictions of karst network evolution keywords incipient karst genesis wormhole formation discrete fracture network breakthrough time dissolution patterns flow focusing data availability no data was used for the research described in the article 1 introduction karst genesis is an important physical and chemical process in controlling the evolution of the hydraulic properties of the carbonate aquifer when the co2 rich water recharged from rainfall and runoff infiltrates down the fractured carbonates the aggressive fluid dissolves the highly conductive fractures and the enhanced conductivity in return attracts more flux further increasing the dissolution rate consequently karstic conduits and caves gradually form under the positive feedback loop how to reasonably predict the evolution of karst aquifers becomes an important research issue since the underlying mechanism regarding reactive transport is not only related to underground water management cousquer and jourde 2022 but also to co2 sequestration ott and oedai 2015 and petroleum production enhancement such as reservoir acidification liu et al 2017 over the last two decades extensive research has been conducted on simulating karst genesis the earliest attempts to model speleogenesis began from the evolution of a single one dimensional 1d conduit dreybrodt 1996 1990 palmer 1991 the dissolution kinetics used in these modeling approaches considered a switch from linear regime to nonlinear when the calcium concentration with respect to calcite is close to saturation white 1977 which allows the unsaturated front to initially penetrate a long distance into the rock simplified 1d conduit models suggest that the early development of a karst system with a fixed head boundary condition first experiences a slow increase in flow rate as the penetration distance under the first order kinetics is limited then an abrupt rise in flow rate occurs after the region of first order kinetics breaks through into the outlet the time when the total flow rate exceeds one thousand times the initial flow i e q t 103 q 0 is typically defined as the breakthrough time bt dreybrodt 1996 subsequently the modeling of karst genesis was extended to a two dimensional 2d network scenario consisting of 1d conduits or pipes dreybrodt et al 2005 groves and howard 1994 kaufmann and braun 1999 the 2d conduit network modeling revealed more complex dissolution dynamics beyond 1d modeling where the flow focusing due to the emergence of preferential channels accelerates the breakthrough recently dreybrodt and gabrovšek 2019 provided a deep insight into the dynamics of karst genesis based on an extremely fine 2d grid of fractures they interpreted the accelerated breakthrough for a 2d model and further analyzed the effect of interactions between developing flow paths and the effect of initial aperture heterogeneity on the dissolution pattern although the representation by a network of 1d conduits pipes can help one to well understand at low computational cost how preferential karstic conduits initiate and evolve in particular for studying the effect of recharge conditions hubinger and birk 2011 kaufmann and romanov 2019 romanov et al 2003 the assumption of ignoring wormhole formation within individual fractures still may leave a large deviation with real systems especially in the prediction of breakthrough time the formation of highly localized flow paths i e wormholes has been extensively investigated from the perspective of laboratory experiments and numerical simulations in 2d single fractures detwiler et al 2003 detwiler and rajaram 2007 hanna and rajaram 1998 szymczak and ladd 2009 wang et al 2022 szymczak and ladd 2011 mathematically demonstrated the dissolution front in even a smooth fracture may quickly break up due to infinitesimal perturbation and the wavelength developed with instability depends on the reaction rate and flow flux moreover they confirmed the flow focusing caused by the breakup of the dissolution front is the prerequisite for the breakthrough acceleration instead of the non linear kinetic trigger mechanism subsequently upadhyay et al 2015 further found that the dissolution pattern and breakthrough time of a single fracture may be insensitive to the roughness and correlation length of initial aperture distribution when the fracture length is sufficiently larger than penetration length defined be the ratio of local flow rate to reactive kinetics i e q 2k in addition starchenko et al 2016 developed a novel three dimensional 3d reactive transport model for single fracture dissolution then based on this model starchenko and ladd 2018 reproduced four distinct dissolution patterns in single fractures including face uniform and two characteristic wormhole shapes i e compact and necked which are determined by the combined effect of péclet and damköhler numbers therefore a more realistic approach to model the karst genesis of fractured carbonates would be to represent each fracture using a fully discretized 2d aperture field recently li et al 2020 proposed a 3d hydrochemical modeling approach based on the embedded discrete fracture model which is able to simulate the wormhole formation and evolution of karst aquifers in a 3d fracture network our recent work also developed a 3d reactive transport model based on the discrete fracture network dfn approach and investigated the combined effect of the flow rate and the aperture contrast between the joints and bedding plane on the karst genesis in 3d jointed layered rocks jiang et al 2022 nevertheless how the wormhole formation within individual fractures impacts the overall dissolution patterns within a fracture network remains not well understood carbonated rocks are commonly stratified into beds with each layer saturated with bed normal joints e g belayneh cosgrove 2004 odling et al 1999 when the bedding planes are significantly compacted joint networks will dominate the flow and transport behaviors jiang et al 2022 jourde et al 2002b 2002a wang et al 2017 some of the previous speleogenesis simulations on the basis of natural carbonate outcrops only focused on the topological characteristics of the 2d joint networks in the horizontal plane while ignoring the effect of potential differences in incipient karst development behaviors along the third dimension aliouache et al 2019 wang et al 2021 in this work we aim to provide a detailed insight into the dynamics of wormhole formation in 3d joint networks note that the term wormhole formation in this paper represents the breakup of uniform dissolution front and the emergence of preferential flow pathways within individual fractures in order to compare the difference between 2d and 3d modeling we focus the research target on single layer joint networks that are strata bound and bed normal as frequently observed from the outcrops of jointed layered rocks hooker et al 2013 odling et al 1999 the term 3d modeling in this paper refers to the 3d computational domain and mesh discretization however the studied dfn geometries are pseudo 3d which makes it possible to compare with 2d modeling that is adopted frequently in previous investigations dreybrodt et al 2005 dreybrodt and gabrovšek 2019 by vertically extruding the 2d joint networks the explicit 3d computational domain allows one to capture the formation of wormholes within individual joints we attempt to answer the following questions compared to the 2d fracture network model to what extent does the wormhole formation inside the fractures affect the breakthrough time what are the consequences of wormhole formation on the overall dissolution process will it lead to an alteration in the geometry of the karstic conduit network how much does 3d modeling differ from 2d modeling when different fracture network geometries flow rates and fracture surface roughness are considered the remainder of the paper is organized around the research goal as follows in section 2 we introduce the methodology used in this study including a brief description of the reactive transport model developed in our previous work jiang et al 2022 the joint network generation method the quantitative characterization method and the numerical model setup the simulation results are presented and analyzed in section 3 eventually further discussion and conclusions are given in section 4 and section 5 respectively 2 methodology 2 1 reactive transport model we use the reactive transport model that has been developed and validated in the previous work jiang et al 2022 the numerical model can solve the coupled hydro chemical processes including fluid flow reactive transport of ca2 and dissolutional growth of fracture aperture based on the finite element method the rock matrix is assumed to be almost impermeable and flow through it can be neglected relative to the highly conductive fractures aliouache et al 2019 dreybrodt and gabrovšek 2019 the transport in rock matrix may play an important role in the long time scale because of the relatively slow advection and diffusion nevertheless 3d reactive transport simulation with matrix effects in dense fracture networks is almost not feasible due to the huge computational cost associated with the mesh discretization of the rock matrix thus we consider the computational domain only on the 3d discrete fracture networks where the individual fractures are represented by 2d planes the relevant governing equations of the reactive transport model are given as follows szymczak and ladd 2011 upadhyay et al 2015 assuming that the flow velocity v and ca2 concentration c are averaged along the fracture aperture the mass conservation equation for single phase steady state flow through a fracture and the convection diffusion equation are expressed respectively as 1 τ b ρ v 0 v ρ g b 2 12 μ τ h and 2 τ b v c τ b d τ c 2 r c where b is the fracture aperture m ρ is the fluid density kg m3 v is the velocity vector m s μ is the fluid dynamic viscosity pa s g is the gravity constant m s2 h is the hydraulic head m c is the ca2 concentration mol m3 and d is the diffusion coefficient m2 s τ means the gradient operator restricted to the fracture s tangential plane the gravitational effect is not considered as this study focuses on a karst generation process in horizontal flow regimes 2r c means the reactive flux from the dissolving calcite with the factor of two representing the contributions from the upper and lower fracture walls it is assumed that the dissolution on the two sides of fractures is symmetrical due to the reduced dimension modeling of fracture networks the assumption may become invalid for horizontal fractures as the buoyancy driven flow may lead to more dissolution on the top surface than on the bottom surface hu et al 2021 wang et al 2022 nevertheless the more detailed mechanism regarding gravitational diffusion is not considered in this study i e fluid density is assumed to be uniform and constant here we consider the linear reaction kinetics is sufficient for our modeling purposes as the high order kinetics has been demonstrated to be not the prerequisite for developing long conduits szymczak and ladd 2011 thus r c can be written as 3 r c k eff c eq c with 4 k eff k 1 2 k b dsh where k eff is the effective reaction rate coefficient m s c eq is equilibrium concentration mol m3 k is the reaction rate constant m s and sh is the sherwood coefficient k eff considers the jointed role of surface reactions and diffusion transport where the reaction rate under a large aperture is limited by surface reactions whereas under a small aperture by diffusion dreybrodt and gabrovšek 2019 then the growth of the fracture aperture can be updated based on the local reactive flux 5 c sol db dt 2 r c where c sol is the molar concentration of calcite mol m3 2 2 joint network generation in carbonate rocks many outcrop observations have shown the trace length of joints always follows a lognormal distribution with the spacing proportional to the layer thickness mcquillan 1973 odling et al 1999 therefore we use the lognormal distribution to model the lengths of each joint set in this study it has been confirmed from both laboratory experiments and numerical simulations that the spacing of the joints is essentially controlled by a mechanical interaction between the joints rives et al 1992 wu and pollard 1995 here we employ the joint network generator with the concept of stress shadow zone integrated to reproduce the joint interaction statistically josnin et al 2002 jourde 1999 jourde et al 2002a 2002b wang et al 2017 specifically a shadow zone is defined around each existing joint and a newly generated joint center is placed randomly but not in the shadow zones of existing joints once the location of the new joint is determined values of its orientation and length are sampled from the corresponding distribution models nevertheless the newly generated joint requires some geometric operations i e truncation extension and removal which are also determined by its position relative to the shadow zone of the old joints more details about the fracture network generation can be found in our recent paper sun et al 2021 a 3d joint network can be constructed by extruding a 2d joint network such that the geometric connectivity remains unchanged fig 1 b for a 2d fracture network the fracture intensity γ can be defined as the cumulative fracture length divided by the rock area 6 γ 1 l 2 n l where l is the size of the square domain m l is the fracture length m n is the fracture number the geometric connectivity can be characterized by the percolation parameter p 7 p 1 l 2 n l 2 which is applicable for a totally random non fractal fracture network bour and davy 1997 a higher p means higher connectivity of the network basically a connected network tends to form if p is larger than the percolation threshold p c 5 8 bour and davy 1997 for the 3d joint networks we further consider a nonuniform initial aperture field superimposed on each joint the nonuniform aperture is assumed to follow a random lognormal distribution with the mean value b 0 b t 0 the roughness σ is defined to characterize the amplitude of aperture heterogeneity which is given as upadhyay et al 2015 8 σ b 2 b 2 b 2 3 quantitative indices for analyzing characteristics of flow and dissolution the dissolution behaviors of the fractured carbonates always depend on the magnitude and heterogeneity of flow aliouache et al 2019 siemers and dreybrodt 1998 thus we adopt the equivalent permeability of rocks and flow channeling density indicator to quantitatively measure the overall flow capacity and the degree of flow localization respectively the equivalent permeability of a fractured rock κ eq m2 can be calculated based on darcy s law 9 κ eq μ q l a ρ g h in h out where q m3 s is the total flow rate through the outlet with a cross section area a m2 h in m and h out m are the hydraulic heads at the inlet and outlet boundaries respectively to quantify the channelization of flow field in 3d fracture networks we define the flow channeling density indicator d q which is modified from the original introduction by maillot et al 2016 10 d q 1 s s q d s 2 s q 2 d s where s is the fracture surface m2 q is the local flow rate m2 s i e vb the same definition in the form of participation ratio has been previously applied to quantify the degree of localization of the deformation in surface fractures davy et al 1995 sornette et al 1993 d q can measure the percentage of the total fracture surface that experiences a significant flow rate i e the fraction of active flowing area hyman 2020 the value of d q only depends on the relative flow distribution where a smaller d q corresponds to a more localized flow regime while d q 1 to a uniform the penetration length l p m is an important parameter to analyze the instability of dissolution front in an initially uniform fracture szymczak and ladd 2012 2011 l p denotes the distance over which undersaturation decays which is given as 11 l p q 2 k where q is the local flow rate m2 s and k is the reaction rate constant m s unlike the dissolution of porous matrix which is limited to the inlet region when the flow rate is significantly low according to the linear stability analysis szymczak and ladd 2013 the dissolution front of fractures is always unstable with the wavelength having the same scale of l p szymczak and ladd 2011 this is because there is no limit to the opening of fracture aperture thus although the dissolutional growth is slow with a low velocity eventually the front always breaks up upadhyay et al 2015 nevertheless if the flow rate is high enough to ensure the penetration length exceeds the dimensions of the system the front may remain uniform 2 4 model setup as shown in fig 1a we consider the joint networks consisting of two joint sets whose orientations follow a normal distribution with the mean being 0 and 60 respectively and the standard variation being 5 zambrano et al 2016 all the 2d joint networks are generated within a domain of 10 m 10 m and then are extruded by 1 m to create 3d dfns wang et al 2017 fig 1b the numerical simulation domain is assumed a representative element volume in a confined aquifer in the sequential analysis a dimensionless parameter defined by the ratio of average initial penetration length l p to the model length l is introduced to generalize the simulation results the joint lengths following a lognormal distribution have a mean of 3 m and a standard deviation of 0 3 siemers and dreybrodt 1998 have shown that different connectivity of fracture networks may lead to distinct dissolution behaviors based on 2d fracture networks with the assumption of uniform dissolution along each fracture this work attempts to extend the study into 3d scenarios thus we also consider four different fracture intensities γ 1 875 m 1 2 5 m 1 3 75 m 1 and 5 m 1 which corresponds to p 6 2 8 3 12 5 and 16 7 fig 1a as shown from the range of p the connectivities of the studied fracture networks cover from the critically connected i e p 5 8 to the well connected which can show the features of dissolution behaviors under different degrees of fracture geometrical connectivities here we only focus on the x direction reactive flow since the significant effect of network topology has been analyzed in the previous work aliouache et al 2019 fig 1a shows in red the geometries of flow backbones i e percolating fractures connecting inlet and outlet with respect to x direction flow for reactive transport simulations we directly extract the flow backbones as the computational domain since the non percolating fractures do not contribute to flow fig 1b we specify constant head conditions at the left inlet boundary x 0 m and the right outlet boundary x 10 m and assume all the other outer boundaries are impervious the calcium concentration of the inflow water is considered to be 0 mol m3 typical parameter values for calcite dissolution are adopted dreybrodt 1996 szymczak and ladd 2011 the equilibrium concentration is c eq 2 mol m3 the reaction rate constant is k 2 5 10 7 m s the sherwood number is sh 8 and the molar concentration of calcite is c sol 2 7 104 mol m3 the density and viscosity of fluid are ρ 1000 kg m3 and μ 1 10 3 pa s respectively temperature may affect the reaction kinetics and chemical equilibrium as well as the fluid properties palmer 1991 for simplification we assume the temperature of the fractured rocks is uniform and fixed such that the reaction rate constant is fixed the molecular diffusion constant is d 1 10 9 m2 s the gravity constant is g 9 81 m s2 all the fracture planes are discretized with the rectangular finite element mesh with the resolution in the horizontal direction i e parallel to x y plane being 0 05 m in the vertical z direction we distinguish between 2d and 3d modeling using different levels of mesh resolution as shown in fig 2 for 2d modeling only one layer of mesh is created in the vertical direction fig 2a which is equivalent to the simplified 2d conduit network modeling with the assumption of uniform dissolution within each conduit by contrast for 3d modeling a 20 layer grid is considered in the vertical discretization fig 2b which allows for the occurrence of non uniform dissolution fronts the numerical model for the geometry in fig 2b has around 172 000 rectangular mesh elements with the number of degrees of freedom to be solved over 1 million the adopted mesh resolution is sufficient for our research purposes since we have confirmed that a finer grid has a minor impact on the trend of the results but at a very high computational cost more detailed information about model implementation and verification can be found in our previous paper jiang et al 2022 for the setup of parameter sensitivity analysis in addition to network geometrical connectivity the effects of flow rate and fracture roughness are further analyzed these two parameters are the key factors to influence the instability of dissolution front in an initially uniform fracture according to the study of szymczak ladd 2011 penetration length i e l p q 2k eq 11 is a key parameter for characterizing the front instability thus we determined the effect of flow rate q and generalized the results by the penetration length q 2k which can also provide some implications for the effect of reaction kinetics k the specific parameters for the joint aperture and hydraulic gradient for the three subsection analysis are as follows 1 in section 3 1 the influence of network connectivity is studied to get a first insight into the difference between the 2d and 3d modeling we conducted the reactive transport simulations using all fracture networks with different connectivities fig 1a under the same hydraulic gradient i e 0 1 m m for each percolation parameter p 20 realizations of networks are generated the initial aperture field for 2d modeling is uniform which is b 0 0 1 mm while for 3d modeling a tiny variability roughness σ 0 0001 is superimposed i e max b 0 0 1 mm 50 nm similar as szymczak ladd 2011 2 in section 3 2 two representative fracture network geometry one is well connected and another is poorly connected is selected to study the influence of flow rate here a series of pressure gradients are considered corresponding to initial penetration length l p0 from 0 0005 to 0 1 while the roughness in the 3d models is still considered to be very small σ 0 0001 3 in section 3 3 the influence of roughness in 3d models is further studied σ 0 0001 0 001 0 01 and 0 1 in combination with the effect of flow rate i e l p0 from 0 0005 to 0 1 3 results and analysis 3 1 influence of network connectivity in the different dissolution behaviors between 2d and 3d modeling fig 3 a shows the variation of breakthrough time as a function of percolation parameter p based on two different dfn representative approaches fracture networks fully discretized in 3d 3d modeling and simplified 2d conduit pipe networks 2d modeling furthermore fig 4 exhibits the dissolution patterns at the breakthrough time using one example each to represent the corresponding p to explain the trend of breakthrough times the corresponding variations of the equivalent permeability κ eq the mean penetration length l p and the flow channeling density indicator d q at the initial time are further calculated and presented in fig 3b c and d respectively we have confirmed that the values of these three quantitative indices for 2d modeling are initially the same as those for 3d modeling as the fracture connectivity increases the equivalent permeability of the fractured rocks rises significantly meaning that the total flow rate before dissolution increases greatly under the same pressure difference fig 3b note that this trend is obtained based on the fractures with percolation parameters above the percolation threshold a similar trend of the relationship between the percolation parameter and permeability has been also observed in previous papers lei et al 2020 sun et al 2020 it is worth noting that the magnitudes of mean local flow rates are almost comparable where the initial values of l p are around 0 08 m fig 3c much smaller than the rock length i e 10 m for 2d modeling it is observed that the breakthrough time decreases significantly with the increase of p fig 3a the operating mechanism may be interpreted as follows first the initial l p increases with p which means a deeper penetration initially in each 1d joint conduit at the entrance although the increase of l p with p is small its effect may be amplified under the mechanism of the positive feedback loop dreybrodt 1996 second preferential flow paths tend to emerge due to the flow focusing siemers and dreybrodt 1998 and only one pathway gains an advantage for development eventually fig 4a d this means the total flux is gradually concentrated to one preferential pathway as the dissolution process proceeds more analysis about the evolution process can be seen in section 3 2 as a result a well connected network large p with a large equivalent permeability can allow a high flux focused into the preferential flow pathway eventually leading to a much deeper penetration along this pathway and early breakthrough the third reason may be related to the length of percolating pathways siemers and dreybrodt 1998 at low p the geometries of percolating pathways for different realizations are highly diverse due to poor connectivity consequently the short flow pathways are rarely created leading to a large breakthrough time with a large deviation fig 3a by contrast at high p high fracture intensity allows fractures to intersect each other to form short flow paths whose length is comparable to the domain length which greatly reduces the breakthrough time and its deviation however in 2d modeling it is worth noting that the decrease of the breakthrough time tends to become slow the slope decreases with higher p it may be attributed to the stronger competition among different flow paths which is quantified by the rising d q in the initial time fig 3d at low p d q is small such that the flow structure is highly localized which means the preferential flow pathway is always determined at the beginning see more details in section 3 2 thus the dissolution patterns are controlled by the highly irregular geometry of the flow backbone see fig 4a and b as the fracture intensity increases more fractures start to interconnect see p 12 5 in fig 1a and the flow structure becomes less channelized initially d q increases as a result there is a strong competition among the pathways with similar resistance which may retard the decline in breakthrough time with higher p fig 3a note that the increase of d q with p becomes slow meaning the network tends to become saturated and well interconnected in general the trend of breakthrough times and dissolution patterns with different network connectivities for karst genesis in 2d conduit networks is consistent with the study of siemers and dreybrodt 1998 for 3d modeling the karst genesis exhibits a large difference from 2d modeling especially at low p there is a significant reduction in breakthrough time for 3d modeling compared to 2d modeling fig 3a due to the wormhole formation within individual joints fig 4e the difference in breakthrough time between 2d and 3d models decreases with the increase of network connectivity more interestingly it seems that the breakthrough time for 3d modeling is insensitive to fracture network connectivity under the specific pressure difference in particular the breakthrough time even rises slightly when p increases from 12 5 to 16 7 moreover it is observed that a significant discrepancy between 2d and 3d modeling emerges in dissolution patterns fig 4 at low p the network structure of the developing karstic conduits for the 2d and 3d models are similar which are highly governed by the geometries of flow backbone as the joint network is critically connected however the vertical size of the karstic conduits is significantly reduced for 3d models due to the occurrence of wormhole formation inside the joints also the predicted aperture at breakthrough for 2d modeling is unreasonable actually greatly exceeds the color bar range for fig 4a and b because it takes too much time to break through at high p although the difference in breakthrough time between 2d and 3d modeling is reduced the dissolution patterns may become totally distinct in 3d models more dominant conduits may form fig 4g and even the location of the preferential channels could change fig 4h therefore from the above observations the importance of 3d discrete fracture network modeling is highlighted although the aperture variability in each joint is considered extremely small adding the dimension from 2d to 3d may lead to wormhole formation and flow focusing within individual joints which not only accelerates the breakthrough time but also alters the dissolution patterns to better understand the underlying mechanism causing the discrepancy between 2d and 3d modeling we provide detailed insights into the evolution process of karst genesis in the following section 3 2 influence of flow rate penetration length 3 2 1 role of flow rate in the different dissolution behaviors between 2d and 3d modeling the flow rate or equivalently the penetration length is an important parameter to control the formation of wormholes within single fractures according to the foundations of prior research szymczak and ladd 2012 2011 therefore we further adopt a series of pressure gradients to compare the difference between 2d and 3d modeling the roughness is still considered to be very small σ 0 0001 here we examine two representative joint networks as examples one for the critically connected network p 6 2 in fig 1a and another for the well connected network p 16 7 in fig 1a we define a dimensionless parameter to represent the pressure gradient level i e l p0 the ratio of average initial penetration length to domain length l p0 q 0 2k l jiang et al 2022 a large range of pressure gradients are explored which corresponds to l p0 from 0 0005 to 0 1 fig 5 shows the variations of breakthrough time as a function of l p0 for a critically connected joint network and a well connected network furthermore fig 6 exhibits the corresponding aperture distribution at breakthrough it is observed that if l p0 is large enough the 3d modeling of karst genesis in dfns can be simplified to a uniform dissolution process within conduit networks dashed lines overlap with solid lines in fig 5 and identical patterns are obtained for 2d and 3d modeling when l p0 0 04 in fig 6 if the joint network is critically connected although the dissolution patterns are very simple due to the geometrical constraint of the flow backbone the branches tend to be less developed with the decrease of l p0 fig 6a c vs e g compared to 2d models a pronounced difference in dissolution patterns for 3d models is the wormhole formation when l p0 0 013 furthermore the shape of the wormhole varies with the increase of l p0 such as a compact wormhole for l p0 0 0022 and a necked wormhole for l p0 0 0093 and 0 013 the trend of dissolution patterns responding to inflow rate magnitude is consistent with the single fracture simulations starchenko and ladd 2018 note that since the boundary condition considered in this study is constant head dissolution develops across the whole height of the joints around the outlet starchenko et al 2016 thus the wormholes exhibit the characteristic shapes i e compact or necked only around the inlet which is different from the scenarios of constant flow rate where the wormhole is highly localized along the outlet starchenko and ladd 2018 it is worth noting that a similar trend of the development of dissolution patterns can be also obtained with the increase of dissolution rate constant starchenko and ladd 2018 szymczak and ladd 2009 wang et al 2022 here we mainly focus on the effect of wormhole formation on the network scale dissolution of the fracture system but not on the condition for generating wormholes along a single fracture conclusions may also apply to the systems with different dissolution rates furthermore going beyond the previous simulations on single fractures a macroscopic network structure of karstic conduits can be captured in this study more interestingly the well developed branching pattern can be maintained until l p0 0 002 in 3d modeling see similar network patterns for the cases below the red dotted lines in fig 6 which is attributed to the enhanced penetration capability of dissolution front by flow focusing also the network expansion can be found in the cases of well connected network it indicates that without the consideration of wormhole formation the degree of branching network spreading may be underestimated on the other hand the prediction of dissolution pattern on the network scale based on 2d conduit networks may be instructive with a sufficiently low l p0 fig 6a e i and m this is because under the condition of low flow rate karst genesis is confined within a single linear pathway meaning that a high dimensional dissolution process in networks is reduced to a low dimensional process along a single conduit however the accuracy of the bt prediction is far from adequate for 2d modeling with a low flow rate therefore the wormhole formation caused by the added third dimension makes the dissolution behaviors more complex which can be also reflected from the curves of breakthrough time vs l p0 in fig 5 for 2d models karstic conduits at high l p0 develop in a network scale with uniform dissolution within individual joints in this dissolution scale the competition mechanism between different flow pathways plays an important role in controlling the breakthrough time secondary karstic conduits become more developed at large l p0 indicating a sustained competition aliouache et al 2019 with the decrease of l p0 the karst development tends to focus on the scale of a single and simple pathway with little effect of competition between different flow channels consequently it is observed that the bt varies with l p0 at different slopes for these two scales with a transition zone at around 0 02 for the critically connected cases and around 0 013 for the well connected cases for 3d models wormhole formation extends the range of the network dissolution scale as the flow focusing makes the dissolution front more aggressive as a result the threshold of l p0 for the dissolution scale transforming from a network scale to a single pathway scale is reduced more interestingly because of the wormhole formation in 3d modeling the breakthrough time of the critically connected case may be similar to that of the well connected case at the range of 0 009 l p0 0 012 by contrast the breakthrough time of the former in 2d modeling is always above the latter 3 2 2 detailed explanations for the different breakthrough times between 2d and 3d modeling fig 7 provides a visual insight into this phenomenon through the temporal and spatial evolutions of dissolution front using the representative cases with l p0 0 0094 furthermore fig 8 gives the corresponding evolutions of the flow channeling density d q at the early stage of karst development t 1a the dissolution fronts for both cases are quite planar because only a very tiny variability of the initial aperture field is considered fig 7a e i and m the d q evolution of the 2d and 3d models also shows the same behavior during this stage whereas there is a significant difference between the different connectivity networks fig 8 for the critically connected network the initial d q is much lower than that of the well connected one which indicates a higher channelized flow at the initial time thus the winning pathway is determined from the very beginning due to the high flow channelization subsequently the dissolution evolution seems to proceed as a dynamic in a single fracture since the flow supply from other pathways is significantly weak as a result if the network is represented by a 2d model the dissolution front propagation is concentrated on the highly channelized flow pathway and is very slow the slope of the d q evolution is small however if it is represented by a 3d model the wormhole formation and flow focusing inside the joints can significantly accelerate the dissolution progress which is quantified by a quick drop of d q once the dissolution front breaks up at 3 5 a fig 7f and fig 8 moreover the karst conduit of 3d modeling may develop with a length at 8a comparable to the one of 2d modeling at 70a fig 7d vs h by contrast for the well connected network the dissolution behaviors tend to follow a different mode it can be observed that a rapid dissolution development can form even with 2d modeling i e d q drops fast with a large slope with the breakthrough time reduced to 20 a fig 8 this is attributed to the strong flow focusing supported by numerous flow channels although the initial penetration length in each pathway is short the losing pathways gradually degrade dissolution fronts retreat during the development and are drained to the winning one where the penetration length is enhanced quickly we can see that the 2d well connected case can develop the same conduit length much earlier than the 2d critically connected case fig 7l vs d if the well connected network is represented by a 3d model the breakthrough time is further reduced by the superimposed flow focusing of the individual joints on that of the network fig 7o and p it is worth noting that the dissolution front at 3 5a of the 3d well connected case is more uniform than that of 3d critically connected case fig 7n vs f we can interpret the underlying mechanism of karst evolution in the 3d well connected network as follows before 3 5 a the flow reorganization with the dissolution growth of joints mainly occurs on the network scale i e between different flow pathways compared to the critically connected network more flow in the well connected network coming from the neighboring competing pathways can be focused on the main flow channel which then gains a larger penetration length szymczak and ladd 2011 demonstrated that the wavelength of the dissolution front which exhibits a sinusoidal mode during developing is proportional to the penetration length the larger wavelength of the dissolution front may lead to a uniform growth of the front and the flow focusing may stall especially when the joint height is lower than the wavelength therefore the wormhole in the critically connected network may form earlier than in the well critically connected network the separation point between the dashed and solid lines is earlier in fig 8 in addition the wormhole in the former is narrower than that in the latter due to the smaller wavelength fig 7g vs o leading to a stronger flow focusing along the joint profile thus the earlier timing of the wormhole formation provides an extra chance for the critically connected network to break through earlier which may also well explain why the breakthrough time tends to be insensitive to the fracture connectivity once the wormhole formation occurs in 3d modeling fig 3a 3 2 3 detailed explanations for the different dissolution patterns between 2d and 3d modeling another interesting phenomenon is that the wormhole formation in 3d modeling may lead to a more complex dissolution pattern compared to 2d modeling it is observed that more secondary karstic conduits may form due to the wormhole formation fig 7p and even the winning pathway may alter fig 6o to explore this deeper we compare the evolutions of dissolution patterns between 2d and 3d models of the well connected case with l p0 0 013 in fig 9 fig 10 further illustrates the corresponding evolutions of d q and the inflow rate into the inlets whose positions are marked in fig 9d for the 2d model pathway no 1 gains the advantage at the beginning compared to pathway no 2 fig 10b then pathway no 1 develops first fast but then much slowly after around 1 5 a this is inferred to result from the competition between outflow branches when the leading pathway passes the junctions fig 9b which makes the shorter pathways gain an extra chance to grow aliouache et al 2019 it is observed that the inflow rate of no 2 can exceed that of no 1 in a certain period but the above interruption mechanism can also take place on no 2 fig 9c meanwhile once the weak branch of the no 1 is abandoned its aggressive power will resume and then regain the leading position fig 10b by contrast for the 3d model the dissolution behaviors of these two pathways proceed in opposite manners after about 3 5 a as illustrated in fig 9f the dissolution front of no 2 has already broken up and the resulting flow focusing inside makes it more aggressive and competitive even d q is slightly larger than the 2d model during this period zoom in plot in fig 10a indicating a less localized flow field induced by the enhanced competition between pathways no 1 and no 2 as a result pathway no 2 gains an advantage eventually instead of being terminated by no 1 fig 10b note that compared to the case with l p0 0 0093 fig 7n the dissolution front of pathway no 1 in this case seems more uniform because of the higher initial flow rate also attributed to the more uniform dissolution of no 1 pathway no 2 may gain an extra chance to break up the dissolution front early and quickly benefits from the flow focusing 3 3 influence of fracture roughness 3 3 1 role of fracture roughness in the different dissolution behaviors between 2d and 3d modeling through the above analysis we understand the importance of the flow focusing during the formation of wormholes in the comparison we only used a tiny roughness to keep the 3d models close to the 2d models under this configuration of initial aperture the dissolution front is quite uniform at the beginning but still has instability to form wormholes dreybrodt and gabrovšek 2019 consequently we found the timing of the breakup of dissolution fronts within individual joints may influence the rate of karst development and the location of the main flow channels the previous analysis of linear instability is based on single fractures where the total flow rate or l p can be regarded as constant in the initial stage of dissolution when l p is much smaller than the fracture length szymczak and ladd 2011 our study further suggests that some of the conclusions drawn from the single fracture analysis may be not applicable to the fracture networks since the flow exchange among different pathways may lead to dynamic variations in l p within individual fractures for example the increased l p due to the flow focusing from the whole network may increase the potential wavelength of unstable dissolution front in the leading pathway and then delay or even avoid the wormhole formation before breakthrough this is also the reason why the threshold of the separation between the 2d model and 3d model curves of bt vs l p0 is shifted to the left for well connected networks fig 5 considering the important role of the timing of wormhole formation in dissolution behaviors we further explore the influence of roughness σ as shown in the curves of bt vs l p0 in fig 11 and the dissolution patterns at breakthrough in fig 12 here we take the well connected network as an example because of the large variability in aperture for the joints with high roughness the dissolution front can break up quickly i e a rapid formation of wormholes upadhyay et al 2015 consequently a high σ may lead to a fast breakthrough causing that the threshold of l p0 over which the 3d modeling is identical to 2d modeling moves to the right i e large values if l p0 is sufficiently small the breakthrough time tends to be insensitive to the roughness which is consistent with the observations of upadhyay et al 2015 the results confirm the scale dependence of breakthrough time on roughness also exists in the network system where bt decreases monotonically with σ in a small scale large l p0 hanna and rajaram 1998 whereas bt shows a large fluctuation a minimum in bt σ is expected with σ in a large scale small l p0 due to the interplay between flow focusing and branching at the wormhole tips cheung and rajaram 2002 upadhyay et al 2015 also for small l p0 the dissolution patterns are quite similar regardless of the roughness upadhyay et al 2015 where our simulation results based on the networks further show an insensitivity of the position of developed conduit and the degree of branch development to σ fig 12e and i with the increase of l p0 the dissolution pattern of high σ gradually exhibits a distinction from that of low σ for example two developed conduits may emerge for the case of σ 0 1 with l p0 0 013 fig 12g vs k as l p0 further increases although the main flow channels tend to dissolve uniformly and the breakthrough time converges with 2d model the secondary channels in the 3d model with high σ penetrate deeper downstream due to the highly focused flow and quick wormhole formation fig 12l vs h 3 3 2 detailed insights into the dissolution behaviors for cases with different fracture roughness to further explore the underlying mechanism of the joint network system with high σ we give the details of the karst evolution for the 3d well connected case with l p0 0 013 and σ 0 1 in figs 13 and 14 as illustrated in fig 13a the dissolution front is highly non uniform even at the initial time also the initial d q of σ 0 1 is lower than that of the case of σ 0 0001 fig 14a indicating a more channelized flow from the beginning as a result the unstable dissolution fronts break up quickly and at t 0 5 a basically a wormhole has formed in all the flow paths fig 13b then the karstic conduits develop very fast quantified by a dramatic drop in d q fig 14a from the inflow analysis in fig 14b we observe that the inflow rates in the different flow pathways are initially independent of the roughness whereas the rapid wormhole formation at high roughness leads to the earlier occurrence of the quick elevation of the flow it is worth noting that the acceleration of karst development i e the deviation point for curve σ 0 1 from curve σ 0 0001 in pathway no 1 occurs earlier than in pathway 2 when σ 0 1 this confirms again that flow migration on the network scale and flow magnitude inside individual fractures can affect the timing of wormhole formation nevertheless the relatively quick breakup of dissolution front for pathway no 1 leads to its competition with pathway no 2 instead of being terminated eventually two winning pathways may emerge at breakthrough fig 12k 3 3 3 combined effect of network connectivity and fracture roughness on breakthrough times back to fig 11 we notice that the breakthrough time increases monotonically with decreasing l p0 when σ 0 1 which is owed to the reduced effect of the timing difference of wormhole formation between different channels on the competition mechanism between them in other words the dissolution competition and flow migration may rapidly transform from between different joints to between different wormholes thus close to the 2d models the cases of σ 0 1 also show a monotonic behavior for bt vs l p0 furthermore we also examine the effect of network connectivity on breakthrough time using the 3d models with σ 0 1 as illustrated in fig 15 the results are all based on 20 realizations of networks for each percolation parameter the boundary conditions are consistent with those described in section 3 1 as expected the breakthrough times of 3d cases with σ 0 1 are reduced significantly due to the flow focusing during wormhole formation whereas the tread of breakthrough time with respect to network connectivity is similar to the 2d case where the rising of bt becomes faster with the decrease of p 4 discussion in this study we have conducted a large number of numerical simulations to compare the karst genesis in joint networks using fracture networks fully discretized in 3d and simplified 2d conduit pipe networks in the past the latter approach has been adopted extensively to study the incipient karst evolution of fractured limestone aquifers due to the less computational cost for network scale simulations aliouache et al 2019 kaufmann and romanov 2019 wang et al 2021 in this work we found an extremely fine mesh is usually necessary if one aims to accurately delineate the dynamics of dissolution front breakup within each fracture in some cases simplified 2d modeling may be a practical tool to help one understand the physical processes acting on the networks e g the competition mechanism among different pathways aliouache et al 2019 dreybrodt and gabrovšek 2019 in particular 2d modeling may still be valid if the penetration length is close to the outlet i e the system scale is small large l p0 because the dissolution front is stable before breakthrough the scale transversal to the flow direction i e the joint height in this study is another key parameter to determine whether wormholes may form before breakthrough although the joint height is not studied in depth here the dissolution front tends to be uniform if the joint height is considerably small which is essentially governed by a relatively large wavelength of the front eventually reflected in the role of penetration length szymczak and ladd 2011 although there are some advantages in the simplified 2d modeling its accuracy may be far from adequate to predict karstification in natural karst systems the main reasons may be summarized in the following two points first the scale of the natural karst systems is always much larger than the penetration length calculated by eq 11 usually 1 m for calcite and 10 m for dolomite this means the dissolution fronts in fractures are always unstable as the instability continues to grow even l p may be larger than the fracture width szymczak and ladd 2011 according to our observations if the scale of the system is sufficiently large i e small l p0 the dissolution pattern becomes extremely localized and independent of the roughness upadhyay et al 2015 in this scale the 2d modeling may be instructive for predicting the position of the dominating pathway however the predicted breakthrough time and the aperture enlargement may be significantly overestimated based on the 2d modeling especially for the critically connected fracture networks if the scale of the system is medium i e medium l p0 the flow focusing during wormhole formation may not only accelerate breakthrough but also alter the position of developed conduits in this scale we further found the propagation extent of the karstic conduit network may be greatly underestimated for the 2d modeling moreover the breakthrough time may be insensitive to the fracture network connectivity due to the different timing of breakup of the uniform dissolution fronts in the main flow pathways which is distinguished from the observations in 2d modeling siemers and dreybrodt 1998 second a real fracture surface is never even and always has a certain roughness our findings indicate that for a medium l p0 fracture roughness may also affect the dissolution patterns and breakthrough time a high roughness leads to a quick formation of wormholes and an early breakthrough as a result the threshold of l p0 over which 2d modeling is identical to 3d modeling increases which further narrows the applicability of 2d modeling moreover the uniform variability of aperture field in this paper is still very simplified while the realistic roughness may vary in different joint locations which also governs the mechanical aperture responses to the polyaxial in situ stresses lei et al 2017 therefore only the fully discretized 3d modeling is able to integrate the complexity of the fracture surfaces to achieve more accurate predictions of the evolution of karst aquifers in addition this study may also provide useful implications on how to design the controlling scheme for wormhole formation to enhance the influence area during acid treatment on fractured carbonate reservoirs in the petroleum industry note that our simulation model is based on some ideal assumptions where more complex mechanisms about the dynamics of wormhole formation from the pore scale perspective are not considered first our study emphasizes the effect of the timing of dissolution front breakup and the resulting flow focusing on the dissolution patterns on the network scale such as the position of preferential flow pathways and the dimensions of the dissolved conduit network thus only a simplified fracture roughness field is integrated into the network scale simulation framework however realistic heterogeneous aperture distributions may organize in a self similar or self affine structure deng et al 2018a moreover local flow circulations may form in the deep troughs of rough fracture surfaces which may trap the solute in the recirculation zones and further impact the dissolution process deng et al 2018a this phenomenon is relevant to high flow rates where darcy s law may break and the non darcian effects on the pore scale reactive transport may need to be considered second the gravitational effect is also important during the evolution of dissolution according to some recent advancements regarding radial dissolution experiments hu et al 2021 wang et al 2022 because of the density difference between the saturated and unsaturated solution buoyancy driven flow and gravitational diffusion may lead to more dissolution on the top surface than the bottom surface of a horizontal fracture and dissolution hotpots may emerge where advective transport is comparable to gravitational diffusion however the effect of gravitational diffusion is not considered in the numerical model since the density variation of caco3 solution under different co2 partial pressures is not well understood we have only focused in this study on the effect of aperture variation on the breakup of uniform dissolution fronts which adapts to fractures of different dips it is worth noting that for vertical fractures gravity diffusion may induce unsaturated fluid concentrated on the top of fractures oltéan et al 2013 which may further affect the timing of wormhole formation nevertheless this mechanism needs further experimental validation and numerical examination on calcite dissolution with carbonic acid in future works due to the low solubility of caco3 in addition the mineral composition is another key factor influencing the heterogeneity of karstification where fractures in low calcite carbonates and calcite rich shales may switch from uniform to wormhole dissolution with all other conditions held the same deng et al 2018b lastly although in nature the constant head recharge does exist before breakthrough especially in the phreatic zone the diversity of the cave patterns depends more on a variety of recharge types and also different geological structures e g the effect of bedding partings palmer 1991 thus more examinations need to be conducted to explore the influence of these factors in the 3d modeling context in the future to achieve better simulation of various cave patterns 5 conclusions to conclude we have simulated the incipient process of karst genesis in carbonate joint networks with different geometrical connectivities the joint networks are represented by two different modeling approaches a simplified 2d conduit network model that does not take into account the wormhole formation inside each joint and a dfn model fully discretized in 3d by comparing 2d with 3d modeling we found the breakthrough time in the 3d models may be much less sensitive to network connectivity than in the 2d models which is attributed to the flow focusing during wormhole formation also the position and number of the preferential flow pathways may be altered in 3d modeling of the well connected networks even only a very tiny aperture variability roughness of joint surfaces is considered to gain detailed insights into the underlying mechanism governing the karst genesis in 3d joint networks we have further investigated the combined effects of the initial flow rate or penetration length and roughness based on two representative networks a critically connected and a well connected results indicate that a large flow rate allows 2d modeling to be consistent with 3d modeling while the threshold is reduced for the well connected networks due to the strong flow focusing supported by the dense flow backbone if the flow rate is sufficiently small a very localized dissolution pattern is obtained where the position of the preferential flow pathway in the 3d model is the same as in the 2d model nevertheless the narrow wormholes in 3d joints can significantly accelerate the breakthrough roughness only has a minor effect on the evolving dissolution patterns of the wormhole networks the trunk and branches if the flow rate is medium dissolution patterns in 3d models exhibit a larger dimension of wormhole network than in 2d models the timing of wormhole formation may control the position of the preferential flow pathways in addition increasing roughness can lead to a quick breakup of dissolution front transforming the competition from between different joints into between different wormholes this may not only reduce the breakthrough time but also impact the final dissolution patterns this study has important implications for better understanding the wormhole formation in 3d fracture networks further promoting a more accurate prediction of the evolution of karst aquifers credit authorship contribution statement chuanyin jiang methodology formal analysis writing original draft xiaoguang wang conceptualization software formal analysis writing review editing shengyan pu software writing review editing hervé jourde resources supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments c j is supported by the china scholarship council csc from the ministry of education of p r china no 202006450151 x w is grateful for the support from national key research and development program of china grant no 2020yfc1808300 national natural science foundation of china grant no 42102300 science technology department of sichuan province grant nos 2021zycd004 2022yfsy0008 and state key laboratory of geohazard prevention and geoenvironment protection grant no sklgp2022k024 s p is grateful for the national natural science foundation of china grant no 41772264 the national key research and development program of china grant no 2020yfc1808300 and the research fund of state key laboratory of geohazard prevention and geoenvironment protection grant no sklgp2020z002 
2153,groundwater nitrate poses a health risk to humans and monitoring groundwater quality is time consuming and expensive to improve the efficiency and reduce the costs of monitoring groundwater nitrate a parsimonious model was developed using easily accessible predictors and small datasets based on random forest rf neural network nn and support vector machine svm algorithms groundwater no3 n concentrations of 1196 groundwater samples from intensive agricultural areas along with data on 13 predictors were obtained for the construction of prediction models r2 and rmse metrics were used to evaluate the models with an emphasis on a minimal number of predictors and a low data size the results showed that even with few readily available predictors conductivity ec chemical nitrogen fertilization rate nf and precipitation ppt and a small dataset 260 700 observations the three models achieved good precision with r2 and rmse values of 0 70 0 80 and 6 87 8 13 respectively in these prediction models ec was the primary predictor acting as an intrinsic factor nf acted as a loading factor to supplement the blind area of ec for no3 n prediction and ppt was introduced because of its accessibility to improve predictive performance the final predictors applied in this study link the two currently dominant prediction methods by combining the high predictive accuracy of the intrinsic predictor with the accessibility of the extrinsic predictor and the results demonstrate the practicability and applicability advantages of this model in groundwater no3 n prediction this model provides technical support for the rapid and low cost realization of the online monitoring of no3 n pollution in shallow groundwater in intensive agricultural areas keywords shallow groundwater no3 n prediction machine learning intensive agricultural area data availability data will be made available on request 1 introduction groundwater nitrate pollution has become a global issue with no3 n concentrations in many aquifers exceeding the maximum acceptable potable water standards of 20 mg l 1 in china 11 3 mg l 1 in the eu and 10 mg l 1 in the usa zhang et al 2022 this nitrate pollution threatens human health and groundwater quality and exacerbates the worldwide water resource crisis isaza et al 2020 the serious groundwater nitrate contamination around the world is caused by the excessive application of nitrogen more than 30 of the chemical fertilizers applied globally are applied to arable land in china which represents 9 of the world s total yu et al 2019 this application causes large amounts of nitrogen to be discharged into surface water and to accumulate in soil where it becomes an important source of no3 n in groundwater the contribution of cropland soil nitrogen to groundwater no3 n pollution has reached more than 40 cui et al 2020 gu et al 2013 resulting in 54 of shallow groundwater systems and 37 of deep groundwater systems in china having no3 n concentrations that exceed the water quality standard of class iii gb t 14848 2017 han et al 2016 no3 n is the most important nitrogen pollutant in groundwater accounting for more than 60 of the total nitrogen present li et al 2022 in the erhai lake watershed the proportion may be as high as 80 chen et al 2018 accordingly no3 n concentration is the key indicator of shallow groundwater quality the prediction of groundwater no3 n concentrations has become important for understanding no3 n spatiotemporal variation providing early warning for groundwater nitrogen pollution and effectively managing groundwater systems at present the main models applied in the field of groundwater no3 n prediction are divided into three categories process models index models and statistical models process models including swat and modflow are typically built on expert knowledge of processes and hydrogeological conditions they are limited in that their development requires extensive information and a long calculation time and that they achieve lower predictive accuracy than statistical models koycegiz and buyukyildiz 2019 pradhan et al 2020 the main limitation of index models such as drastic god and sintacs is that the assignment of weights and rates of parameters is subjective and not informed by data voutchkova et al 2021 busico et al 2017 he et al 2019 due to their capacity to model complex nonlinear systems statistical methods such as machine learning ml have emerged as powerful alternatives to physically based models ml models such as support vector machine svm sajedi hosseini et al 2018 artificial neural network ann boosting ordinary least squares ols and regression have been successfully employed worldwide for the prediction of groundwater no3 n concentrations at the regional scale sajedi hosseini et al 2018 nolan et al 2015 islam et al 2021 koh et al 2020 this successful use is due to their high accuracy and robustness as well as their ability to address nonlinear problems with no restrictions on the type and number of inputs however a limitation of ml is that it requires a large number of predictors and strong data support generally ml models for predicting no3 n in groundwater can be divided into two main types in terms of the predictors used the first type called the extrinsic model employs extrinsic predictors influencing groundwater no3 n typically including hydrogeological features e g hydrochemical properties hydraulic conductivity and net recharge and discharge land use type e g arable land pasture forest or meadow external inputs e g fertilization rainfall and irrigation soil conditions and topography surdyk et al 2021 medici et al 2021 koh et al 2020 knoll et al 2019 rahmati et al 2019 the second type called the intrinsic model uses the concentrations of various ions in groundwater samples as predictors ortmeyer et al 2021 bui et al 2020 singha et al 2021 however both extrinsic and intrinsic models involve several challenges in groundwater no3 n prediction extrinsic models typically require larger predictor categories on a large scale which makes sample collection time consuming and expensive tiyasha et al 2020 for intrinsic models predictor measurements anion and cation hydrochemistry are even more expensive than no3 n medici et al 2021 zhang et al 2021 additionally both types require a large number of predictors for application in an operational context this greatly reduces the practicality of a model both in terms of data collection and application scope to tackle these issues a practical and cost efficient approach for the quick and accurate prediction of groundwater no3 n concentrations is needed the application of ml techniques using few easily accessible indicators and small sample sizes can be an effective approach many studies aimed at predicting groundwater no3 n concentration over areas cover different land uses e g arable pasture grassland forest urban and rural areas which increases the complexity of the prediction model used messier et al 2019 knoll et al 2019 however compared with those in other areas groundwater no3 n concentrations in intensive agricultural areas mainly cropland and rural areas are more influenced by anthropogenic factors e g fertilizer application irrigation and distribution of residential areas this provides favourable conditions for the use of simple prediction approaches that require fewer predictors and observations to construct the model also the predictors used in the final models are easy to obtain and real time update in particular ec can be obtained economically and efficiently by placing a real time monitor in the shallow aquifer nitrogen fertilization can be used as a background parameter with an annual update meteorological departments can provide real time updates on precipitation data the model prediction in this study is different from time series prediction and spatial prediction the time series prediction requires long term high frequency sampling at individual sites with sampling time being the primary predictor el amri et al 2022 the spatial prediction allows the model trained in the study area to be applied to other areas to achieve the prediction of other areas messier et al 2019 prediction in this study means using predictors obtained in real time to predict the nitrate concentrations in the time series of the individual locations where ec probes have been installed and the spatial prediction depends on obtaining the spatial distribution of predictors this parsimonious model was able to 1 be developed based on easily accessible predictors and small sample sizes 2 minimize prediction costs and improve the practicality and applicability of model application without significantly reducing predictive accuracy and 3 predict future no3 n concentrations for any monitoring site where an ec probe is installed this work provides new insights regarding groundwater no3 n prediction and we expect it to be useful for stakeholders and policy decisions 2 materials and methods 2 1 study area the study area is located in the 8 lake basins on the yunnan guizhou plateau southwest china 97 31 e 106 11 e 21 8 n 29 15 n and includes the 8 intensive agricultural areas around dianchi lake erhai lake fuxian lake xingyun lake qilu lake yilong lake yangzonghai lake and chenghai lake fig 1 this area has a subtropical monsoon climate typical of a low latitude plateau the average annual temperature in the area is 16 7 c the annual precipitation is 932 mm but precipitation is unevenly distributed with more than 85 of precipitation occurring from june to november the 8 lakes are important freshwater reserves in china and represent nearly 5 of china s freshwater resources the total basin area of the 8 lakes approaches 8 300 km2 the basin areas of dianchi lake erhai lake and fuxian lake are each more than 1000 km2 while those of the other five lake basin areas are less than 500 km2 table s1 the 8 lake basins are intensive agricultural areas with abundant crops and a large number of farm animals the total cultivated area of the basins is nearly 98 103 hm2 with paddy soil and red soil being the dominant soil types table s1 the intensive agricultural areas are mainly concentrated in the areas around the lakes which contain towns villages and croplands the towns and villages are scattered around the lakes and surrounded by cropland the intensive agricultural areas can be divided into 4 categories based on crop planting intensity open field vegetables yilong lake xingyun lake qilu lake and some areas around erhai lake field crops chenghai lake and some areas around erhai lake facility agriculture dianchi lake and cropland fallow and field crops fuxian lake and yangzonghai lake multiple types of crops are planted in the study area and include vegetables rice maize tobacco potato and flowers the average multiple cropping index of open field vegetables field crops and facility vegetables are 3 2 and 5 crops per year respectively the application rate of chemical nitrogen fertilizer in the qilu lake dianchi lake yilong lake xingyun lake chenghai lake and erhai lake basins are 405 285 240 240 255 and 165 kg hm 2 per season respectively the farm animals raised in the basins include pigs cattle and poultry with total breeding volumes of 6 86 105 1 27 105 and 1 35 107 respectively pigs and cattle are mainly raised in scattered small scale farms and poultry are mainly raised in large scale farming shallow groundwater is one of the main sources of agricultural irrigation and domestic water in the 8 intensive agricultural areas a combination of factors including a shallow groundwater table and large seasonal fluctuations high intensity fertilization and irrigation and frequent sewage discharge has caused serious nitrogen pollution of shallow groundwater and threatens the quality of lake water 2 2 data acquisition for model prediction 2 2 1 data structure a total of 1196 groundwater samples and 13 predictor variables were used for model training and testing in this study the predictors were classified into groundwater physicochemical indicators soil physicochemical indicators exogenous nitrogen input indicators and hydraulic drive indicators groundwater physicochemical indicators included temperature t ph conductivity ec dissolved oxygen do oxidation reduction potential orp and shallow groundwater table sgt the distance from the groundwater surface to the ground surface soil physicochemical indicators reflecting the nitrogen interception and retention capacity of soil included soil texture clay silt or sand soil no3 n sn and soil organic carbon soc chemical nitrogen fertilization nf was investigated as an exogenous nitrogen input indicator precipitation ppt data over the four years were collected as the hydraulic drive indicator a statistical distribution of the predictors and groundwater no3 n across the datasets is shown in fig s2 a matrix of scatterplots of the correlations between all predictors and between the predictors and the target variable nitrate concentration in groundwater is shown in fig s3 2 2 2 sample collection and analysis the groundwater samples were collected in 2018 2021 with 225 551 224 and 196 samples collected each year approximately three quarters of the samples are from the erhai lake area the major aquifer type in the sampling area is pore water of loose rock groundwater samples were collected from 277 agricultural wells located in croplands and 127 drinking wells located in residential areas with 59 wells 34 agricultural wells and 25 drinking wells sampled for 9 consecutive months and the remaining 345 wells sampled for 4 consecutive years covering 4 months per year april may august october and sampled 1 4 times sampling structure is displayed in detail in fig s1 each groundwater sample was collected using a sampling instrument installed 50 cm below the groundwater surface a 200 ml sample from each sampling well was collected poured into a polyethylene bottle placed in an incubator returned to the laboratory and stored in a refrigerator at 4 c for subsequent chemical analyses samples were tested within 1 week after sampling t ph ec do and orp were measured in situ using a ysl pro plus water quality meter ysi incorporated usa sgt was measured by a steel tape measure a bran luebbe aa3 continuous flow analyser germany was applied to analyse no3 n a total of 120 soil profile samples were collected from cropland around irrigation wells according to the soil and crop types the 0 100 cm soil profile was sampled at 0 30 cm 30 60 cm and 60 100 cm and soil texture sn and soc were calculated as the average values of the three layers of soil sn was measured by a bran luebbe aa3 continuous flow analyser soc was measured by a total organic carbon analyser multi n c 3100 germany soil texture was determined by the hydrometer method based on stokes law nf was determined from detailed interviews of farmers in each planting area between 2019 and 2021 precipitation data were collected from the local meteorological department the soil samples and nf data were matched with the groundwater samples based on the locations of the sampling wells to analyse the relationships between the main ions and ec in groundwater samples and the contributions of ion levels to the no3 n prediction model 276 water samples were randomly selected from among the 1196 water samples from the 8 lakes table s3 the levels of k na ca2 mg2 hco3 so4 2 and cl were analysed by ion chromatography using a dionex dx 120 ion chromatograph redundancy analysis rda was applied to illustrate the contributions of ions and ec to no3 n 2 3 prediction methodology 2 3 1 prediction procedures the methodology in the present study involved four main phases 1 data collection and pre processing 2 feature selection 3 variable set based model evaluation and 4 data size based model evaluation the workflow of the prediction methodology is shown in fig 2 the models used in steps 2 4 were nn rf and svm models detailed description of the prediction procedures was available in section s1 of the supplementary materials 2 3 2 prediction models as ml models that are commonly used in groundwater no3 n prediction neural network nn random forest rf and svm models were selected all three models were deployed in r software using the caret package root mean squared error rmse was used to select the optimal model using the smallest value in tuning procedures for all models for the nn the model average method applied with the avnnet function of the nnet package was used for all procedures the parameter decay was set at 0 1 for feature selection 0 0 01 and 0 1 for variable set based model evaluation and 0 01 for size based model evaluation respectively the parameter size was set at 2 1 10 and 8 for each procedure respectively for the rf model the parameter m try i e randomly selected variable numbers at each split point was optimized with the objective function of rmse the parameters ntrees i e number of bootstrap samples and maxnodes were set at 1500 and 100 respectively for all procedures for the svm model the radial basis function called radial svm in the r package was implemented with the kernlab package meyer et al 2020 the parameter tunelength was set to 10 and the tuning parameters sigma and cost were both automatically estimated using the default method during all procedures 2 3 3 uncertainty assessment the quantile regression qr method was used to assess the epistemic uncertainty in the rf model predictions via the package quantregforest the prediction interval width and coverage were used as metrics in this study the prediction interval width was calculated at a probability coverage of 90 with lower and upper quantiles of 5 and 95 respectively for a quantile prediction with some level 0 α less than 1 a coverage of 100 α with observations is expected in the case study the empirical coverage of observations based on prediction was calculated at quantiles 1 5 10 25 50 75 90 95 and 99 the empirical quantiles were plotted against the theoretical quantiles to evaluate uncertainty 3 results 3 1 feature selection fig 3 depicts the effects of predictor number 1 to 13 on model performance metrics for nn rf and svm models the results showed that when the number of predictors increased from 1 to 2 the model r2 value greatly increased nn from 0 46 to 0 70 rf from 0 41 to 0 73 and svm from 0 46 to 0 73 and rmse greatly decreased nn from 11 17 to 8 19 rf from 11 71 to 7 84 and svm from 11 48 to 8 06 regardless of the model type the curves of r2 improvement and rmse reduction remained approximately flat as the number of variables increased from 2 to 13 r2 from 0 70 to 0 72 0 73 to 0 80 and 0 73 to 0 77 rmse from 8 19 to 8 09 7 84 to 6 82 and 8 06 to 7 36 for nn rf and svm respectively the top screened predictors across different variable sets 1 13 with the nn rf and svm models are detailed in fig 3 the results indicated that both ec and nf were screened predictors for all three models when the predictor number was set at 2 regarding the order of the other predictors the nn and svm models yielded the same results with the predictors ranked from highest to lowest importance in the order soc clay silt do orp sand ph sn wl ppt and t the rf model yielded a different order with predictors from highest to lowest as follows orp do ppt sn soc silt wl sand clay ph and t 3 2 variable set based model evaluation to build models with fewer predictors while achieving better prediction results we choose three variable sets to retrain the model based on the feature selection parameter tuning was included in the training procedure and performance was measured via nested cv fig 4 the predictive performance of models built with ap all predictors mp minimal predictors and ep easily accessible predictors was comparable among the three models the validation results of the nn model included r2 values of 0 71 0 68 and 0 70 and rmse values of 8 21 8 35 and 8 25 for ap mp and ep respectively similarly the rf model showed r2 values of 0 80 0 75 and 0 81 and rmse values of 6 74 7 63 and 6 68 for ap mp and ep respectively the svm model yielded r2 values of 0 77 0 72 and 0 75 and rmse values of 7 34 8 06 and 7 78 for ap mp and ep respectively furthermore the metrics for the three models showed similar trends from ap to mp to ep r2 decreased from ap to mp and increased from mp to ep whereas rmse showed the opposite pattern these results indicated that the predictive ability of the model constructed with ep was improved over that of the model constructed with mp i e after adding the predictor ppt model performance and parameters for 10 outside folds under different models and variables are detailed in table s2 3 3 meanings of the screened predictors in the model the variables ec and nf had key contributions to the no3 n prediction models fig 5 depicts the relationships among groundwater ions ec and nf in contributing to no3 n specifically ec and no3 n are distributed on the right side of the vertical axis aligned with ca2 mg2 so4 2 and cl indicating that these ions were the main contributors to the correspondence between ec and no3 n in contrast ec and no3 n are distributed on both sides of the horizontal axis while k and hco3 in groundwater are loaded more on the lower side of the vertical axis and aligned with ec but opposite to no3 n explaining why k and hco3 were the contributors to the differences between ec and no3 n groundwater no3 n could not be fully characterized by ec especially when hco3 and k concentrations were high and nf may compensate for this limitation nf was weakly correlated with ec and each ion but was more strongly correlated with no3 n and its distribution on the vertical axis exhibits an opposite trend to the distributions of k and hco3 fig 5 these findings indicate that nf can be used as a complement to ec for no3 n prediction of blind spots correcting for the unfavourable contribution of ec to no3 n prediction 3 4 data size based model evaluation the easily accessible variables ec nf and ppt were chosen to test the models prediction performance on different data sizes fig 6 depicts a learning curve of model performance over datasets with 50 990 observations the results showed that model performance improved continuously with increasing data size for all three models however the increases were much greater for smaller data sizes with very weak increases observed at larger data sizes the cv results showed that r2 increased sharply from 0 58 to 0 70 0 64 to 0 80 and 0 51 to 0 73 as data size increased from 50 to 260 690 or 700 for nn rf and svm respectively while it increased only slightly from 0 70 to 0 71 0 80 to 0 81 and 0 73 to 0 75 as data size increased from 260 690 or 700 to 990 similarly cv rmse was 10 21 8 13 and 8 30 at data sizes of 50 260 and 990 respectively for the nn model 9 37 6 87 and 6 70 at data sizes of 50 690 and 990 respectively for the rf model and 11 01 7 88 and 7 78 at data sizes of 50 700 and 990 respectively for the svm model the performance results for the training sets showed trends similar to those of the cv results no3 n density plots of the testing and training sets at data sizes of 200 400 600 and 800 are presented in fig s4 and show that the no3 n distribution was consistent across different data sizes the results indicated that even with a relatively small dataset 260 690 or 700 observations the nn rf and svm models achieved acceptable predictive performance predictive efficacy received a large boost with increases in data volume within the range of smaller datasets but increases thereafter yielded limited improvements in r2 or rmse 3 5 uncertainty of the rf model epistemic uncertainty and aleatoric uncertainty are two major types of uncertainty in ml models the former encompasses the uncertainty in the predictors and model parameters used and the latter is related to the noise inherent in the dataset epistemic uncertainty is more relevant to the present study when considering the applicability of the prediction method given that the three models used in this study had comparable prediction effects which reflected the robustness of the model epistemic uncertainty may arise mainly from the predictors used rather than the model parameters quantile regression was used to quantify the epistemic uncertainty in the rf model the plot of prediction interval coverage at 90 5 95 probability is shown in fig 7 a the empirical quantiles are very close to the theoretical quantiles which indicates that the quantile predictions generated by rf are valid furthermore the quantile regression results showed that the length of the predictive interval varied little as no3 n increased suggesting that the relative size of the prediction interval decreased as no3 n increased fig 7b the reason for the difference in uncertainty between levels of no3 n may be that higher nf and ec may result in lower no3 n for example when the groundwater contains higher concentrations of other ions whereas higher no3 n generally corresponds to higher nf and ec as higher no3 n must increase the nf and ec values of the groundwater therefore the larger uncertainty under lower no3 n may come from the low coverage of the predictors where ec and nf cannot predict no3 n with complete accuracy the uncertainty may be reduced by adding predictors including those considered but not ultimately selected for model inclusion in this study such as groundwater temperature ph do orp sgt and soil texture sn and soc however given the principle that the model should have applicability it is equally important to consider whether the inclusion of such factors is sufficiently cost effective i e that it increases prediction accuracy with minimum acquisition cost 4 discussion 4 1 robustness of the predictive method to different model types the nn rf and svm models showed consistent predictive performance to one another across different predictor numbers and data sizes overall the rf algorithm performed best for models based on the easily accessible predictors ec nf and ppt and a smaller data size 690 with the highest r2 value of 0 80 and the lowest rmse value of 6 87 in cv in general compared to boosted regression tree brt k nearest neighbour knn etc rf produces more accurate results and is significantly free of overfitting issues messier et al 2019 knoll et al 2019 because it applies random variable selection at each split point on the basis of bootstrapping breiman 2001 however rf may underestimate high values and overestimate low values fail to predict beyond the range of response values and contain the greatest uncertainty among ml models rahmati et al 2019 the predictive performance of the svm model in this study was good and comparable to that of the rf model with the application of a sensitive critical value sigma the svm model could reduce the effect of data with small residuals usually low no3 n values but emphasize that with large residuals on the model in addition the svm model used the absolute value of the residuals rather than the square as the contribution to the model this approach reduced the effect of better simulated observations on the model while simultaneously limiting the negative effect of large outliers on the regression equation thus the svm algorithm was more suitable than the rf algorithm for groundwater no3 n prediction especially in intensive agricultural areas the no3 n concentration varied greatly between monitoring points ranging from 0 to 72 03 mg l 1 with a mean of 12 92 mg l 1 and a standard deviation of 15 17 mg l 1 also observations with no3 n values far above the average accounted for a relatively high proportion of the total samples with no3 n 30 mg l 1 accounted for 15 in this case the contribution of this part of the data to the model was controlled which increased model stability the nn model showed worse performance than the rf and svm models this result can be attributed to the inability of this type of model to extrapolate beyond the data used for training due to overfitting nafouanti et al 2021 estimating this model requires more parameters because hidden neurons in an nn have multiple linear and nonlinear combinations with both predictor and response variables anders and korn 1999 the model averaging method and weight decay method were used in this study to reduce model instability and control overfitting but the optimization effect may have been limited different models are likely to produce different predictions from the same data due to differences in algorithm the degree of matching of the algorithm with the data structure predictors data size etc rahmati et al 2019 however in previous studies on no3 n prediction different ml models have performed similarly ortmeyer et al 2021 knoll et al 2019 as observed in this study this observation implies that ml models do not differ much in no3 n prediction fig s5 in addition no3 n concentration is influenced by a few factors in homogeneous regions such as climate location land use and soil type models constructed with fewer variables also tend to show similar performance among different models this finding also demonstrates that in constructing models for use in intensive agricultural areas the results are not strongly dependent on the choice of model type 4 2 effect of using few easily available and minimal predictors on model accuracy the minimum set of predictors ec and nf provided good prediction results r2 0 7 0 8 and rmse 7 8 which were further improved by adding the easily accessible indicator ppt r2 0 8 and rmse 7 adding additional predictors beyond the above three did little to improve the model the summary information from literature related to ml prediction of groundwater no3 n showed that table s4 compared with extrinsic models intrinsic models can achieve better prediction performance with fewer predictor types and sample sizes this is because compared with the extrinsic models the predictors used in intrinsic models have a more direct and close relationship with no3 n meanwhile land use types soil properties and nitrogen fertilizer application have been found to be the most important predictors of no3 n in extrinsic models boy roura et al 2013 kim et al 2019 ouedraogo et al 2019 in this context by considering the predictors of intrinsic and extrinsic models it can reduce costs and improve accuracy this model includes four main factors ec nf ppt and soil conditions where nf is the surface nitrogen load and ec and soil conditions are the intrinsic and extrinsic hydrogeological conditions respectively in addition ppt was added as a driving factor for nitrogen transport from the soil surface into groundwater ec is rarely considered as a predictor in groundwater no3 n prediction in either intrinsic or extrinsic models however it was shown to play an important role in groundwater no3 n prediction in zhang s study zhang et al 2022 our results suggested that ec may be more informative than expected for groundwater no3 n prediction as shown in fig 5 one advantage of ec as a predictor is that it is an intrinsic chemical characteristic of groundwater and is thus more directly related to groundwater no3 n than extrinsic predictors such as hydraulic conductivity and aquifer texture which only indirectly affect no3 n ortmeyer et al 2021 knoll et al 2019 in fact many intrinsic models using ions such as k na ca2 mg2 so4 2 and cl in groundwater to predict no3 n have achieved good prediction results islam et al 2021 singha et al 2021 however these methods require expensive detection efforts and long periods of time another advantage of ec is that it can comprehensively reflect the levels of these ions although some information is lost our results showed that ca2 mg2 so4 2 and cl were positively correlated with both no3 n and ec concentration fig 5 which indicated that ec has the potential to replace multiple groundwater ions as a predictor lowering no3 n prediction costs and enabling real time prediction with field monitoring of ec nitrogen fertilizer application is the main source of no3 n in groundwater especially in intensive agricultural areas excessive nitrogen fertilizer input leads to high nitrogen accumulation in soil huang et al 2018 and leaching into groundwater perego et al 2012 therefore the amount of applied nitrogen fertilizer is a key factor in predicting groundwater no3 n however the process of nitrogen migration from the soil surface to groundwater is extremely complex this complexity increases the uncertainty of using nitrogen application to predict groundwater no3 n while ec can partially explain no3 n by characterizing ion concentrations in groundwater some ions e g hco3 and k may play negative roles however the rda results show that fertilization rate can correct for errors caused by these ions filling the gap between ec and no3 n fig 5 although this study points out the possible role of fertilizer in this model this role needs to be further quantified especially in other regions do and orp are critical indicators for determining n transformation higher do and orp levels tend to correspond to more nitrification which raises nitrate concentrations in groundwater mayer et al 2010 lower do and orp levels on the other hand cause significant denitrification and thus nitrate removal from shallow groundwater rivett et al 2008 in this study do and orp were ranked just below ec and nf in feature importance under the rf model this finding demonstrates their importance in the predictive model and is consistent with our previous findings zhang et al 2022 however the results in fig 3 show that adding other predictors such as do and orp beyond the ec and nf predictors to the model has a limited effect on model performance improving it only slightly furthermore there are significant limitations to do monitoring in the field the most widely used electrochemical detection process consumes oxygen and sensors based on this principle must be calibrated and maintained on a regular basis trivellin et al 2018 these two limitations significantly reduce the applicability of do and orp in terms of cost and efficiency and are inconsistent with a more user friendly model precipitation is an important driver linking the soil surface nitrogen load to groundwater nitrogen khan et al 2019 it has been demonstrated that an increase in precipitation may reduce no3 n accumulation and increase no3 n leaching hess et al 2020 although ppt did not play as significant a role in the model as ec and nf it did improve model performance with r2 increasing from 0 68 to 0 70 0 75 to 0 81 and 0 72 to 0 75 after ppt addition for nn rf and svm respectively mp to ep in fig 4 while theoretical effects of ppt on groundwater no3 n are plausible the extent to which they actually occur remains largely unknown more detailed rainfall data including data on the frequency and intensity of precipitation events are needed to quantify the role of precipitation in the model congreves et al 2016 soil is the medium through which nitrogen originating from anthropogenic fertilization nitrogen deposition etc enters groundwater it also acts as a nitrogen reservoir being itself an important source of nitrogen in groundwater the soil nitrogen pool directly affects the input of groundwater nitrogen and soil conditions which include texture and soc affect nitrogen adsorption desorption and biotransformation and thus the amount of leachable no3 n isaza et al 2020 in areas with high soil heterogeneity the amount of nitrogen entering the groundwater may be very variable even under the same n input and rainfall wick et al 2012 therefore the prediction of groundwater nitrogen in such areas requires the consideration of complex soil factors although the soil types in intensive agricultural areas are diverse intensive land use attenuates the effect of soil heterogeneity on groundwater no3 n prediction which benefits prediction by reducing the number of soil predictors required and increasing model simplicity 4 3 effect of data size on model accuracy as determined with the minimum number of predictors data size is also an important factor affecting model accuracy the results showed that the model can achieve good prediction from a small dataset 260 690 and 700 observations for nn rf and svm respectively when using ec nf and ppt as predictors fig 6 after a certain point increasing the data volume resulted in very few changes in any of the three models a consensus view regarding model prediction is that more data always improves the performance of a model zhang and ling 2018 however this is not always true if sufficient important features that are strong predictors of the target are included good performance can be obtained even with few data observations bailly et al 2022 according to regression theory the lower the number of predictors is the fewer data that are needed and the higher model accuracy is chapelle et al 2000 as a result lowering the number of predictors lowers the sample size requirement for example models for predicting nitrogen concentration from chemical elements in water that included approximately 10 predictor variables have required relatively few samples with sample sizes of 300 or fewer in most studies and can achieve r2 values of 0 8 or more ortmeyer et al 2021 bui et al 2020 singha et al 2021 in contrast models that use a wider range of factors as predictors including hydrological features and land use and soil conditions require much larger training sample sizes usually over 10 000 observations but achieve r2 values less than 0 5 table s4 the majority of current models for predicting groundwater no3 n are based on extensive collection of predictors and extensive training datasets large numbers of predictors and training samples increase prediction costs in terms of sample collection and detection as well as model overfitting uncertainty and training time which limit the operational applicability of the model therefore selecting few variables and using a small number of samples with good predictive performance is the key to improving model utility in the present study the intensive agricultural areas were homogeneous regions with similar land uses and locations but various fertilization rates and soil types as shown in fig 1 and table s1 this scenario enabled the development of groundwater no3 n prediction models for this type of area based on few factors and thus required few training samples 4 4 the capability of real time prediction the real time acquisition of these predictors enables the real time prediction of no3 n the models in this study focus on fitting the relationship between no3 n concentration and predictors rather than the relationship between no3 n concentration and sampling time in fact the predictors used already contain information on temporal dynamics this study ensures that all samples on the timeline are covered even though it doesn t achieve continuous high frequency sampling at each monitoring site as the time series prediction model does fig s1 in intensive agricultural areas groundwater no3 n concentrations are influenced by anthropogenic fertilization and climatic factors which vary dynamically over longer time scales the monthly sampling frequency ensures that the ml model captures the dynamic pattern of no3 n the current model has been validated by the test samples covering different monitoring points and time points indicating that the model is feasible to predict at different time points however future samples haven t been predicted and validated which will be the focus of the further research a prediction model based on a minimum number of variables and small datasets has great advantages in terms of costs practical application and generalizability for groundwater no3 n prediction in an intensive agricultural area we suggest that at least 500 observations considering test samples including no3 n ec nf and ppt data should be used to build the base model additional readily available indicators can be added to improve model performance and achieve real production referenced prediction with minimum cost model applicability is increased by lowering the monitoring cost while sacrificing some accuracy 5 conclusion in this study 1196 groundwater samples from intensive agricultural areas along with data on 13 predictors were collected and used to develop a parsimonious groundwater no3 n prediction model based on rf nn and svm the results showed that good predictive performance r2 0 70 0 80 rmse 6 87 8 13 could be achieved even with only a few easily accessible predictors nf ec and ppt and a small dataset 260 700 observations the primary predictor ec served as an intrinsic factor while nf served as a loading factor to compensate for ec s blind area in no3 n prediction and ppt was introduced because of its accessibility to improve predictive performance the final predictors applied in this study link the two currently dominant prediction methods by combining the high predictive accuracy of the intrinsic predictor and the accessibility of the extrinsic predictor data acquisition for all predictors was achieved through low cost real time monitoring and surveys the practical prediction model in this work can be adopted into the regional online monitoring of groundwater no3 n pollution in terms of cost control practical application and generalizability however the applicability of this model in other intensive agricultural areas needs validation and model calibration for other areas is necessary credit authorship contribution statement panlei wang data curation writing original draft dan zhang investigation writing review editing funding acquisition xiang tao investigation wanli hu investigation bin fu investigation hui yan investigation yanhua pan writing review editing anqiang chen funding acquisition conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china 41977319 42067052 the xingdian talent project of yunnan province china 202305as350013 the yunnan science and technology talents and platform projects 2019hb033 202105am070034 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129356 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2153,groundwater nitrate poses a health risk to humans and monitoring groundwater quality is time consuming and expensive to improve the efficiency and reduce the costs of monitoring groundwater nitrate a parsimonious model was developed using easily accessible predictors and small datasets based on random forest rf neural network nn and support vector machine svm algorithms groundwater no3 n concentrations of 1196 groundwater samples from intensive agricultural areas along with data on 13 predictors were obtained for the construction of prediction models r2 and rmse metrics were used to evaluate the models with an emphasis on a minimal number of predictors and a low data size the results showed that even with few readily available predictors conductivity ec chemical nitrogen fertilization rate nf and precipitation ppt and a small dataset 260 700 observations the three models achieved good precision with r2 and rmse values of 0 70 0 80 and 6 87 8 13 respectively in these prediction models ec was the primary predictor acting as an intrinsic factor nf acted as a loading factor to supplement the blind area of ec for no3 n prediction and ppt was introduced because of its accessibility to improve predictive performance the final predictors applied in this study link the two currently dominant prediction methods by combining the high predictive accuracy of the intrinsic predictor with the accessibility of the extrinsic predictor and the results demonstrate the practicability and applicability advantages of this model in groundwater no3 n prediction this model provides technical support for the rapid and low cost realization of the online monitoring of no3 n pollution in shallow groundwater in intensive agricultural areas keywords shallow groundwater no3 n prediction machine learning intensive agricultural area data availability data will be made available on request 1 introduction groundwater nitrate pollution has become a global issue with no3 n concentrations in many aquifers exceeding the maximum acceptable potable water standards of 20 mg l 1 in china 11 3 mg l 1 in the eu and 10 mg l 1 in the usa zhang et al 2022 this nitrate pollution threatens human health and groundwater quality and exacerbates the worldwide water resource crisis isaza et al 2020 the serious groundwater nitrate contamination around the world is caused by the excessive application of nitrogen more than 30 of the chemical fertilizers applied globally are applied to arable land in china which represents 9 of the world s total yu et al 2019 this application causes large amounts of nitrogen to be discharged into surface water and to accumulate in soil where it becomes an important source of no3 n in groundwater the contribution of cropland soil nitrogen to groundwater no3 n pollution has reached more than 40 cui et al 2020 gu et al 2013 resulting in 54 of shallow groundwater systems and 37 of deep groundwater systems in china having no3 n concentrations that exceed the water quality standard of class iii gb t 14848 2017 han et al 2016 no3 n is the most important nitrogen pollutant in groundwater accounting for more than 60 of the total nitrogen present li et al 2022 in the erhai lake watershed the proportion may be as high as 80 chen et al 2018 accordingly no3 n concentration is the key indicator of shallow groundwater quality the prediction of groundwater no3 n concentrations has become important for understanding no3 n spatiotemporal variation providing early warning for groundwater nitrogen pollution and effectively managing groundwater systems at present the main models applied in the field of groundwater no3 n prediction are divided into three categories process models index models and statistical models process models including swat and modflow are typically built on expert knowledge of processes and hydrogeological conditions they are limited in that their development requires extensive information and a long calculation time and that they achieve lower predictive accuracy than statistical models koycegiz and buyukyildiz 2019 pradhan et al 2020 the main limitation of index models such as drastic god and sintacs is that the assignment of weights and rates of parameters is subjective and not informed by data voutchkova et al 2021 busico et al 2017 he et al 2019 due to their capacity to model complex nonlinear systems statistical methods such as machine learning ml have emerged as powerful alternatives to physically based models ml models such as support vector machine svm sajedi hosseini et al 2018 artificial neural network ann boosting ordinary least squares ols and regression have been successfully employed worldwide for the prediction of groundwater no3 n concentrations at the regional scale sajedi hosseini et al 2018 nolan et al 2015 islam et al 2021 koh et al 2020 this successful use is due to their high accuracy and robustness as well as their ability to address nonlinear problems with no restrictions on the type and number of inputs however a limitation of ml is that it requires a large number of predictors and strong data support generally ml models for predicting no3 n in groundwater can be divided into two main types in terms of the predictors used the first type called the extrinsic model employs extrinsic predictors influencing groundwater no3 n typically including hydrogeological features e g hydrochemical properties hydraulic conductivity and net recharge and discharge land use type e g arable land pasture forest or meadow external inputs e g fertilization rainfall and irrigation soil conditions and topography surdyk et al 2021 medici et al 2021 koh et al 2020 knoll et al 2019 rahmati et al 2019 the second type called the intrinsic model uses the concentrations of various ions in groundwater samples as predictors ortmeyer et al 2021 bui et al 2020 singha et al 2021 however both extrinsic and intrinsic models involve several challenges in groundwater no3 n prediction extrinsic models typically require larger predictor categories on a large scale which makes sample collection time consuming and expensive tiyasha et al 2020 for intrinsic models predictor measurements anion and cation hydrochemistry are even more expensive than no3 n medici et al 2021 zhang et al 2021 additionally both types require a large number of predictors for application in an operational context this greatly reduces the practicality of a model both in terms of data collection and application scope to tackle these issues a practical and cost efficient approach for the quick and accurate prediction of groundwater no3 n concentrations is needed the application of ml techniques using few easily accessible indicators and small sample sizes can be an effective approach many studies aimed at predicting groundwater no3 n concentration over areas cover different land uses e g arable pasture grassland forest urban and rural areas which increases the complexity of the prediction model used messier et al 2019 knoll et al 2019 however compared with those in other areas groundwater no3 n concentrations in intensive agricultural areas mainly cropland and rural areas are more influenced by anthropogenic factors e g fertilizer application irrigation and distribution of residential areas this provides favourable conditions for the use of simple prediction approaches that require fewer predictors and observations to construct the model also the predictors used in the final models are easy to obtain and real time update in particular ec can be obtained economically and efficiently by placing a real time monitor in the shallow aquifer nitrogen fertilization can be used as a background parameter with an annual update meteorological departments can provide real time updates on precipitation data the model prediction in this study is different from time series prediction and spatial prediction the time series prediction requires long term high frequency sampling at individual sites with sampling time being the primary predictor el amri et al 2022 the spatial prediction allows the model trained in the study area to be applied to other areas to achieve the prediction of other areas messier et al 2019 prediction in this study means using predictors obtained in real time to predict the nitrate concentrations in the time series of the individual locations where ec probes have been installed and the spatial prediction depends on obtaining the spatial distribution of predictors this parsimonious model was able to 1 be developed based on easily accessible predictors and small sample sizes 2 minimize prediction costs and improve the practicality and applicability of model application without significantly reducing predictive accuracy and 3 predict future no3 n concentrations for any monitoring site where an ec probe is installed this work provides new insights regarding groundwater no3 n prediction and we expect it to be useful for stakeholders and policy decisions 2 materials and methods 2 1 study area the study area is located in the 8 lake basins on the yunnan guizhou plateau southwest china 97 31 e 106 11 e 21 8 n 29 15 n and includes the 8 intensive agricultural areas around dianchi lake erhai lake fuxian lake xingyun lake qilu lake yilong lake yangzonghai lake and chenghai lake fig 1 this area has a subtropical monsoon climate typical of a low latitude plateau the average annual temperature in the area is 16 7 c the annual precipitation is 932 mm but precipitation is unevenly distributed with more than 85 of precipitation occurring from june to november the 8 lakes are important freshwater reserves in china and represent nearly 5 of china s freshwater resources the total basin area of the 8 lakes approaches 8 300 km2 the basin areas of dianchi lake erhai lake and fuxian lake are each more than 1000 km2 while those of the other five lake basin areas are less than 500 km2 table s1 the 8 lake basins are intensive agricultural areas with abundant crops and a large number of farm animals the total cultivated area of the basins is nearly 98 103 hm2 with paddy soil and red soil being the dominant soil types table s1 the intensive agricultural areas are mainly concentrated in the areas around the lakes which contain towns villages and croplands the towns and villages are scattered around the lakes and surrounded by cropland the intensive agricultural areas can be divided into 4 categories based on crop planting intensity open field vegetables yilong lake xingyun lake qilu lake and some areas around erhai lake field crops chenghai lake and some areas around erhai lake facility agriculture dianchi lake and cropland fallow and field crops fuxian lake and yangzonghai lake multiple types of crops are planted in the study area and include vegetables rice maize tobacco potato and flowers the average multiple cropping index of open field vegetables field crops and facility vegetables are 3 2 and 5 crops per year respectively the application rate of chemical nitrogen fertilizer in the qilu lake dianchi lake yilong lake xingyun lake chenghai lake and erhai lake basins are 405 285 240 240 255 and 165 kg hm 2 per season respectively the farm animals raised in the basins include pigs cattle and poultry with total breeding volumes of 6 86 105 1 27 105 and 1 35 107 respectively pigs and cattle are mainly raised in scattered small scale farms and poultry are mainly raised in large scale farming shallow groundwater is one of the main sources of agricultural irrigation and domestic water in the 8 intensive agricultural areas a combination of factors including a shallow groundwater table and large seasonal fluctuations high intensity fertilization and irrigation and frequent sewage discharge has caused serious nitrogen pollution of shallow groundwater and threatens the quality of lake water 2 2 data acquisition for model prediction 2 2 1 data structure a total of 1196 groundwater samples and 13 predictor variables were used for model training and testing in this study the predictors were classified into groundwater physicochemical indicators soil physicochemical indicators exogenous nitrogen input indicators and hydraulic drive indicators groundwater physicochemical indicators included temperature t ph conductivity ec dissolved oxygen do oxidation reduction potential orp and shallow groundwater table sgt the distance from the groundwater surface to the ground surface soil physicochemical indicators reflecting the nitrogen interception and retention capacity of soil included soil texture clay silt or sand soil no3 n sn and soil organic carbon soc chemical nitrogen fertilization nf was investigated as an exogenous nitrogen input indicator precipitation ppt data over the four years were collected as the hydraulic drive indicator a statistical distribution of the predictors and groundwater no3 n across the datasets is shown in fig s2 a matrix of scatterplots of the correlations between all predictors and between the predictors and the target variable nitrate concentration in groundwater is shown in fig s3 2 2 2 sample collection and analysis the groundwater samples were collected in 2018 2021 with 225 551 224 and 196 samples collected each year approximately three quarters of the samples are from the erhai lake area the major aquifer type in the sampling area is pore water of loose rock groundwater samples were collected from 277 agricultural wells located in croplands and 127 drinking wells located in residential areas with 59 wells 34 agricultural wells and 25 drinking wells sampled for 9 consecutive months and the remaining 345 wells sampled for 4 consecutive years covering 4 months per year april may august october and sampled 1 4 times sampling structure is displayed in detail in fig s1 each groundwater sample was collected using a sampling instrument installed 50 cm below the groundwater surface a 200 ml sample from each sampling well was collected poured into a polyethylene bottle placed in an incubator returned to the laboratory and stored in a refrigerator at 4 c for subsequent chemical analyses samples were tested within 1 week after sampling t ph ec do and orp were measured in situ using a ysl pro plus water quality meter ysi incorporated usa sgt was measured by a steel tape measure a bran luebbe aa3 continuous flow analyser germany was applied to analyse no3 n a total of 120 soil profile samples were collected from cropland around irrigation wells according to the soil and crop types the 0 100 cm soil profile was sampled at 0 30 cm 30 60 cm and 60 100 cm and soil texture sn and soc were calculated as the average values of the three layers of soil sn was measured by a bran luebbe aa3 continuous flow analyser soc was measured by a total organic carbon analyser multi n c 3100 germany soil texture was determined by the hydrometer method based on stokes law nf was determined from detailed interviews of farmers in each planting area between 2019 and 2021 precipitation data were collected from the local meteorological department the soil samples and nf data were matched with the groundwater samples based on the locations of the sampling wells to analyse the relationships between the main ions and ec in groundwater samples and the contributions of ion levels to the no3 n prediction model 276 water samples were randomly selected from among the 1196 water samples from the 8 lakes table s3 the levels of k na ca2 mg2 hco3 so4 2 and cl were analysed by ion chromatography using a dionex dx 120 ion chromatograph redundancy analysis rda was applied to illustrate the contributions of ions and ec to no3 n 2 3 prediction methodology 2 3 1 prediction procedures the methodology in the present study involved four main phases 1 data collection and pre processing 2 feature selection 3 variable set based model evaluation and 4 data size based model evaluation the workflow of the prediction methodology is shown in fig 2 the models used in steps 2 4 were nn rf and svm models detailed description of the prediction procedures was available in section s1 of the supplementary materials 2 3 2 prediction models as ml models that are commonly used in groundwater no3 n prediction neural network nn random forest rf and svm models were selected all three models were deployed in r software using the caret package root mean squared error rmse was used to select the optimal model using the smallest value in tuning procedures for all models for the nn the model average method applied with the avnnet function of the nnet package was used for all procedures the parameter decay was set at 0 1 for feature selection 0 0 01 and 0 1 for variable set based model evaluation and 0 01 for size based model evaluation respectively the parameter size was set at 2 1 10 and 8 for each procedure respectively for the rf model the parameter m try i e randomly selected variable numbers at each split point was optimized with the objective function of rmse the parameters ntrees i e number of bootstrap samples and maxnodes were set at 1500 and 100 respectively for all procedures for the svm model the radial basis function called radial svm in the r package was implemented with the kernlab package meyer et al 2020 the parameter tunelength was set to 10 and the tuning parameters sigma and cost were both automatically estimated using the default method during all procedures 2 3 3 uncertainty assessment the quantile regression qr method was used to assess the epistemic uncertainty in the rf model predictions via the package quantregforest the prediction interval width and coverage were used as metrics in this study the prediction interval width was calculated at a probability coverage of 90 with lower and upper quantiles of 5 and 95 respectively for a quantile prediction with some level 0 α less than 1 a coverage of 100 α with observations is expected in the case study the empirical coverage of observations based on prediction was calculated at quantiles 1 5 10 25 50 75 90 95 and 99 the empirical quantiles were plotted against the theoretical quantiles to evaluate uncertainty 3 results 3 1 feature selection fig 3 depicts the effects of predictor number 1 to 13 on model performance metrics for nn rf and svm models the results showed that when the number of predictors increased from 1 to 2 the model r2 value greatly increased nn from 0 46 to 0 70 rf from 0 41 to 0 73 and svm from 0 46 to 0 73 and rmse greatly decreased nn from 11 17 to 8 19 rf from 11 71 to 7 84 and svm from 11 48 to 8 06 regardless of the model type the curves of r2 improvement and rmse reduction remained approximately flat as the number of variables increased from 2 to 13 r2 from 0 70 to 0 72 0 73 to 0 80 and 0 73 to 0 77 rmse from 8 19 to 8 09 7 84 to 6 82 and 8 06 to 7 36 for nn rf and svm respectively the top screened predictors across different variable sets 1 13 with the nn rf and svm models are detailed in fig 3 the results indicated that both ec and nf were screened predictors for all three models when the predictor number was set at 2 regarding the order of the other predictors the nn and svm models yielded the same results with the predictors ranked from highest to lowest importance in the order soc clay silt do orp sand ph sn wl ppt and t the rf model yielded a different order with predictors from highest to lowest as follows orp do ppt sn soc silt wl sand clay ph and t 3 2 variable set based model evaluation to build models with fewer predictors while achieving better prediction results we choose three variable sets to retrain the model based on the feature selection parameter tuning was included in the training procedure and performance was measured via nested cv fig 4 the predictive performance of models built with ap all predictors mp minimal predictors and ep easily accessible predictors was comparable among the three models the validation results of the nn model included r2 values of 0 71 0 68 and 0 70 and rmse values of 8 21 8 35 and 8 25 for ap mp and ep respectively similarly the rf model showed r2 values of 0 80 0 75 and 0 81 and rmse values of 6 74 7 63 and 6 68 for ap mp and ep respectively the svm model yielded r2 values of 0 77 0 72 and 0 75 and rmse values of 7 34 8 06 and 7 78 for ap mp and ep respectively furthermore the metrics for the three models showed similar trends from ap to mp to ep r2 decreased from ap to mp and increased from mp to ep whereas rmse showed the opposite pattern these results indicated that the predictive ability of the model constructed with ep was improved over that of the model constructed with mp i e after adding the predictor ppt model performance and parameters for 10 outside folds under different models and variables are detailed in table s2 3 3 meanings of the screened predictors in the model the variables ec and nf had key contributions to the no3 n prediction models fig 5 depicts the relationships among groundwater ions ec and nf in contributing to no3 n specifically ec and no3 n are distributed on the right side of the vertical axis aligned with ca2 mg2 so4 2 and cl indicating that these ions were the main contributors to the correspondence between ec and no3 n in contrast ec and no3 n are distributed on both sides of the horizontal axis while k and hco3 in groundwater are loaded more on the lower side of the vertical axis and aligned with ec but opposite to no3 n explaining why k and hco3 were the contributors to the differences between ec and no3 n groundwater no3 n could not be fully characterized by ec especially when hco3 and k concentrations were high and nf may compensate for this limitation nf was weakly correlated with ec and each ion but was more strongly correlated with no3 n and its distribution on the vertical axis exhibits an opposite trend to the distributions of k and hco3 fig 5 these findings indicate that nf can be used as a complement to ec for no3 n prediction of blind spots correcting for the unfavourable contribution of ec to no3 n prediction 3 4 data size based model evaluation the easily accessible variables ec nf and ppt were chosen to test the models prediction performance on different data sizes fig 6 depicts a learning curve of model performance over datasets with 50 990 observations the results showed that model performance improved continuously with increasing data size for all three models however the increases were much greater for smaller data sizes with very weak increases observed at larger data sizes the cv results showed that r2 increased sharply from 0 58 to 0 70 0 64 to 0 80 and 0 51 to 0 73 as data size increased from 50 to 260 690 or 700 for nn rf and svm respectively while it increased only slightly from 0 70 to 0 71 0 80 to 0 81 and 0 73 to 0 75 as data size increased from 260 690 or 700 to 990 similarly cv rmse was 10 21 8 13 and 8 30 at data sizes of 50 260 and 990 respectively for the nn model 9 37 6 87 and 6 70 at data sizes of 50 690 and 990 respectively for the rf model and 11 01 7 88 and 7 78 at data sizes of 50 700 and 990 respectively for the svm model the performance results for the training sets showed trends similar to those of the cv results no3 n density plots of the testing and training sets at data sizes of 200 400 600 and 800 are presented in fig s4 and show that the no3 n distribution was consistent across different data sizes the results indicated that even with a relatively small dataset 260 690 or 700 observations the nn rf and svm models achieved acceptable predictive performance predictive efficacy received a large boost with increases in data volume within the range of smaller datasets but increases thereafter yielded limited improvements in r2 or rmse 3 5 uncertainty of the rf model epistemic uncertainty and aleatoric uncertainty are two major types of uncertainty in ml models the former encompasses the uncertainty in the predictors and model parameters used and the latter is related to the noise inherent in the dataset epistemic uncertainty is more relevant to the present study when considering the applicability of the prediction method given that the three models used in this study had comparable prediction effects which reflected the robustness of the model epistemic uncertainty may arise mainly from the predictors used rather than the model parameters quantile regression was used to quantify the epistemic uncertainty in the rf model the plot of prediction interval coverage at 90 5 95 probability is shown in fig 7 a the empirical quantiles are very close to the theoretical quantiles which indicates that the quantile predictions generated by rf are valid furthermore the quantile regression results showed that the length of the predictive interval varied little as no3 n increased suggesting that the relative size of the prediction interval decreased as no3 n increased fig 7b the reason for the difference in uncertainty between levels of no3 n may be that higher nf and ec may result in lower no3 n for example when the groundwater contains higher concentrations of other ions whereas higher no3 n generally corresponds to higher nf and ec as higher no3 n must increase the nf and ec values of the groundwater therefore the larger uncertainty under lower no3 n may come from the low coverage of the predictors where ec and nf cannot predict no3 n with complete accuracy the uncertainty may be reduced by adding predictors including those considered but not ultimately selected for model inclusion in this study such as groundwater temperature ph do orp sgt and soil texture sn and soc however given the principle that the model should have applicability it is equally important to consider whether the inclusion of such factors is sufficiently cost effective i e that it increases prediction accuracy with minimum acquisition cost 4 discussion 4 1 robustness of the predictive method to different model types the nn rf and svm models showed consistent predictive performance to one another across different predictor numbers and data sizes overall the rf algorithm performed best for models based on the easily accessible predictors ec nf and ppt and a smaller data size 690 with the highest r2 value of 0 80 and the lowest rmse value of 6 87 in cv in general compared to boosted regression tree brt k nearest neighbour knn etc rf produces more accurate results and is significantly free of overfitting issues messier et al 2019 knoll et al 2019 because it applies random variable selection at each split point on the basis of bootstrapping breiman 2001 however rf may underestimate high values and overestimate low values fail to predict beyond the range of response values and contain the greatest uncertainty among ml models rahmati et al 2019 the predictive performance of the svm model in this study was good and comparable to that of the rf model with the application of a sensitive critical value sigma the svm model could reduce the effect of data with small residuals usually low no3 n values but emphasize that with large residuals on the model in addition the svm model used the absolute value of the residuals rather than the square as the contribution to the model this approach reduced the effect of better simulated observations on the model while simultaneously limiting the negative effect of large outliers on the regression equation thus the svm algorithm was more suitable than the rf algorithm for groundwater no3 n prediction especially in intensive agricultural areas the no3 n concentration varied greatly between monitoring points ranging from 0 to 72 03 mg l 1 with a mean of 12 92 mg l 1 and a standard deviation of 15 17 mg l 1 also observations with no3 n values far above the average accounted for a relatively high proportion of the total samples with no3 n 30 mg l 1 accounted for 15 in this case the contribution of this part of the data to the model was controlled which increased model stability the nn model showed worse performance than the rf and svm models this result can be attributed to the inability of this type of model to extrapolate beyond the data used for training due to overfitting nafouanti et al 2021 estimating this model requires more parameters because hidden neurons in an nn have multiple linear and nonlinear combinations with both predictor and response variables anders and korn 1999 the model averaging method and weight decay method were used in this study to reduce model instability and control overfitting but the optimization effect may have been limited different models are likely to produce different predictions from the same data due to differences in algorithm the degree of matching of the algorithm with the data structure predictors data size etc rahmati et al 2019 however in previous studies on no3 n prediction different ml models have performed similarly ortmeyer et al 2021 knoll et al 2019 as observed in this study this observation implies that ml models do not differ much in no3 n prediction fig s5 in addition no3 n concentration is influenced by a few factors in homogeneous regions such as climate location land use and soil type models constructed with fewer variables also tend to show similar performance among different models this finding also demonstrates that in constructing models for use in intensive agricultural areas the results are not strongly dependent on the choice of model type 4 2 effect of using few easily available and minimal predictors on model accuracy the minimum set of predictors ec and nf provided good prediction results r2 0 7 0 8 and rmse 7 8 which were further improved by adding the easily accessible indicator ppt r2 0 8 and rmse 7 adding additional predictors beyond the above three did little to improve the model the summary information from literature related to ml prediction of groundwater no3 n showed that table s4 compared with extrinsic models intrinsic models can achieve better prediction performance with fewer predictor types and sample sizes this is because compared with the extrinsic models the predictors used in intrinsic models have a more direct and close relationship with no3 n meanwhile land use types soil properties and nitrogen fertilizer application have been found to be the most important predictors of no3 n in extrinsic models boy roura et al 2013 kim et al 2019 ouedraogo et al 2019 in this context by considering the predictors of intrinsic and extrinsic models it can reduce costs and improve accuracy this model includes four main factors ec nf ppt and soil conditions where nf is the surface nitrogen load and ec and soil conditions are the intrinsic and extrinsic hydrogeological conditions respectively in addition ppt was added as a driving factor for nitrogen transport from the soil surface into groundwater ec is rarely considered as a predictor in groundwater no3 n prediction in either intrinsic or extrinsic models however it was shown to play an important role in groundwater no3 n prediction in zhang s study zhang et al 2022 our results suggested that ec may be more informative than expected for groundwater no3 n prediction as shown in fig 5 one advantage of ec as a predictor is that it is an intrinsic chemical characteristic of groundwater and is thus more directly related to groundwater no3 n than extrinsic predictors such as hydraulic conductivity and aquifer texture which only indirectly affect no3 n ortmeyer et al 2021 knoll et al 2019 in fact many intrinsic models using ions such as k na ca2 mg2 so4 2 and cl in groundwater to predict no3 n have achieved good prediction results islam et al 2021 singha et al 2021 however these methods require expensive detection efforts and long periods of time another advantage of ec is that it can comprehensively reflect the levels of these ions although some information is lost our results showed that ca2 mg2 so4 2 and cl were positively correlated with both no3 n and ec concentration fig 5 which indicated that ec has the potential to replace multiple groundwater ions as a predictor lowering no3 n prediction costs and enabling real time prediction with field monitoring of ec nitrogen fertilizer application is the main source of no3 n in groundwater especially in intensive agricultural areas excessive nitrogen fertilizer input leads to high nitrogen accumulation in soil huang et al 2018 and leaching into groundwater perego et al 2012 therefore the amount of applied nitrogen fertilizer is a key factor in predicting groundwater no3 n however the process of nitrogen migration from the soil surface to groundwater is extremely complex this complexity increases the uncertainty of using nitrogen application to predict groundwater no3 n while ec can partially explain no3 n by characterizing ion concentrations in groundwater some ions e g hco3 and k may play negative roles however the rda results show that fertilization rate can correct for errors caused by these ions filling the gap between ec and no3 n fig 5 although this study points out the possible role of fertilizer in this model this role needs to be further quantified especially in other regions do and orp are critical indicators for determining n transformation higher do and orp levels tend to correspond to more nitrification which raises nitrate concentrations in groundwater mayer et al 2010 lower do and orp levels on the other hand cause significant denitrification and thus nitrate removal from shallow groundwater rivett et al 2008 in this study do and orp were ranked just below ec and nf in feature importance under the rf model this finding demonstrates their importance in the predictive model and is consistent with our previous findings zhang et al 2022 however the results in fig 3 show that adding other predictors such as do and orp beyond the ec and nf predictors to the model has a limited effect on model performance improving it only slightly furthermore there are significant limitations to do monitoring in the field the most widely used electrochemical detection process consumes oxygen and sensors based on this principle must be calibrated and maintained on a regular basis trivellin et al 2018 these two limitations significantly reduce the applicability of do and orp in terms of cost and efficiency and are inconsistent with a more user friendly model precipitation is an important driver linking the soil surface nitrogen load to groundwater nitrogen khan et al 2019 it has been demonstrated that an increase in precipitation may reduce no3 n accumulation and increase no3 n leaching hess et al 2020 although ppt did not play as significant a role in the model as ec and nf it did improve model performance with r2 increasing from 0 68 to 0 70 0 75 to 0 81 and 0 72 to 0 75 after ppt addition for nn rf and svm respectively mp to ep in fig 4 while theoretical effects of ppt on groundwater no3 n are plausible the extent to which they actually occur remains largely unknown more detailed rainfall data including data on the frequency and intensity of precipitation events are needed to quantify the role of precipitation in the model congreves et al 2016 soil is the medium through which nitrogen originating from anthropogenic fertilization nitrogen deposition etc enters groundwater it also acts as a nitrogen reservoir being itself an important source of nitrogen in groundwater the soil nitrogen pool directly affects the input of groundwater nitrogen and soil conditions which include texture and soc affect nitrogen adsorption desorption and biotransformation and thus the amount of leachable no3 n isaza et al 2020 in areas with high soil heterogeneity the amount of nitrogen entering the groundwater may be very variable even under the same n input and rainfall wick et al 2012 therefore the prediction of groundwater nitrogen in such areas requires the consideration of complex soil factors although the soil types in intensive agricultural areas are diverse intensive land use attenuates the effect of soil heterogeneity on groundwater no3 n prediction which benefits prediction by reducing the number of soil predictors required and increasing model simplicity 4 3 effect of data size on model accuracy as determined with the minimum number of predictors data size is also an important factor affecting model accuracy the results showed that the model can achieve good prediction from a small dataset 260 690 and 700 observations for nn rf and svm respectively when using ec nf and ppt as predictors fig 6 after a certain point increasing the data volume resulted in very few changes in any of the three models a consensus view regarding model prediction is that more data always improves the performance of a model zhang and ling 2018 however this is not always true if sufficient important features that are strong predictors of the target are included good performance can be obtained even with few data observations bailly et al 2022 according to regression theory the lower the number of predictors is the fewer data that are needed and the higher model accuracy is chapelle et al 2000 as a result lowering the number of predictors lowers the sample size requirement for example models for predicting nitrogen concentration from chemical elements in water that included approximately 10 predictor variables have required relatively few samples with sample sizes of 300 or fewer in most studies and can achieve r2 values of 0 8 or more ortmeyer et al 2021 bui et al 2020 singha et al 2021 in contrast models that use a wider range of factors as predictors including hydrological features and land use and soil conditions require much larger training sample sizes usually over 10 000 observations but achieve r2 values less than 0 5 table s4 the majority of current models for predicting groundwater no3 n are based on extensive collection of predictors and extensive training datasets large numbers of predictors and training samples increase prediction costs in terms of sample collection and detection as well as model overfitting uncertainty and training time which limit the operational applicability of the model therefore selecting few variables and using a small number of samples with good predictive performance is the key to improving model utility in the present study the intensive agricultural areas were homogeneous regions with similar land uses and locations but various fertilization rates and soil types as shown in fig 1 and table s1 this scenario enabled the development of groundwater no3 n prediction models for this type of area based on few factors and thus required few training samples 4 4 the capability of real time prediction the real time acquisition of these predictors enables the real time prediction of no3 n the models in this study focus on fitting the relationship between no3 n concentration and predictors rather than the relationship between no3 n concentration and sampling time in fact the predictors used already contain information on temporal dynamics this study ensures that all samples on the timeline are covered even though it doesn t achieve continuous high frequency sampling at each monitoring site as the time series prediction model does fig s1 in intensive agricultural areas groundwater no3 n concentrations are influenced by anthropogenic fertilization and climatic factors which vary dynamically over longer time scales the monthly sampling frequency ensures that the ml model captures the dynamic pattern of no3 n the current model has been validated by the test samples covering different monitoring points and time points indicating that the model is feasible to predict at different time points however future samples haven t been predicted and validated which will be the focus of the further research a prediction model based on a minimum number of variables and small datasets has great advantages in terms of costs practical application and generalizability for groundwater no3 n prediction in an intensive agricultural area we suggest that at least 500 observations considering test samples including no3 n ec nf and ppt data should be used to build the base model additional readily available indicators can be added to improve model performance and achieve real production referenced prediction with minimum cost model applicability is increased by lowering the monitoring cost while sacrificing some accuracy 5 conclusion in this study 1196 groundwater samples from intensive agricultural areas along with data on 13 predictors were collected and used to develop a parsimonious groundwater no3 n prediction model based on rf nn and svm the results showed that good predictive performance r2 0 70 0 80 rmse 6 87 8 13 could be achieved even with only a few easily accessible predictors nf ec and ppt and a small dataset 260 700 observations the primary predictor ec served as an intrinsic factor while nf served as a loading factor to compensate for ec s blind area in no3 n prediction and ppt was introduced because of its accessibility to improve predictive performance the final predictors applied in this study link the two currently dominant prediction methods by combining the high predictive accuracy of the intrinsic predictor and the accessibility of the extrinsic predictor data acquisition for all predictors was achieved through low cost real time monitoring and surveys the practical prediction model in this work can be adopted into the regional online monitoring of groundwater no3 n pollution in terms of cost control practical application and generalizability however the applicability of this model in other intensive agricultural areas needs validation and model calibration for other areas is necessary credit authorship contribution statement panlei wang data curation writing original draft dan zhang investigation writing review editing funding acquisition xiang tao investigation wanli hu investigation bin fu investigation hui yan investigation yanhua pan writing review editing anqiang chen funding acquisition conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was supported by the national natural science foundation of china 41977319 42067052 the xingdian talent project of yunnan province china 202305as350013 the yunnan science and technology talents and platform projects 2019hb033 202105am070034 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129356 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2154,global circulation models gcms provide important insights into future climate change bias correction of downscaled gcm output is integral to any hydrological investigations of climate change due to discrepancies between the statistics of downscaled gcm simulations and observations many bias correction techniques have been developed to support hydrological applications however there have been few comparisons of the sensitivity of hydrological simulations to different bias correction assumptions this paper investigates the importance of two common assumptions i simultaneously correcting bias at multiple time scales and ii explicitly handling rainfall autocorrelation in quantile mapping of downscaled gcm rainfall data for hydrological simulation four quantile mapping methods are applied to correct bias in dynamically downscaled reanalysis and historical gcm simulations of rainfall for 11 catchments in south eastern australia and the performance of bias corrected rainfall and streamflow simulations is evaluated all quantile mapping methods investigated can effectively eliminate bias in monthly and annual rainfall totals quantile mapping methods that consider differences in the temporal dependence autocorrelation structure of downscaled gcm and observed rainfall are most effective in reducing bias in rainfall sequencing statistics such as probability of consecutive wet or dry days streamflow simulations of mean and high streamflow percentiles are underestimated when generated using rainfall that is corrected using quantile mapping methods that do not consider differences in the temporal dependence structure of downscaled gcm and observed rainfall future hydrological investigations of climate change should therefore adopt methods that explicitly consider the temporal dependence structures of downscaled gcm and observed rainfall keywords climate change bias correction hydrological simulation hydroclimate data availability data will be made available on request 1 introduction global circulation models gcms generate important input to hydrological modelling investigations of the impacts of future climate change chiew et al 2009 zheng et al 2018 hydrological processes are highly sensitive to rainfall chiew 2006 sankarasubramanian et al 2001 and therefore hydrological model simulations are designed to be similarly sensitive to the distribution of forcing data fu et al 2007 however the coarse spatial resolution of gcms means that model output particularly precipitation simulations can have very different characteristics to observations and therefore cannot be directly used for hydrological applications charles et al 2020 potter et al 2020 downscaling methods are commonly applied to increase the spatial resolution of climate projections maraun 2016 a range of downscaling techniques have been applied including empirical statistical and dynamical methods dynamical downscaling uses regional climate models forced by gcms to generate climate simulations and projections at finer spatial scales and has recently been shown to add value to projections from gcms particularly precipitation projections and in areas of complex topography di virgilio et al 2020 while dynamical downscaling can add value to projections discrepancies still remain between distributional characteristics of downscaled gcm based simulations and ground based observations that are used to establish hydrological models charles et al 2020 ekström et al 2015 potter et al 2020 many methods have been proposed to correct distributional errors or bias in downscaled gcm data maraun 2016 scaling approaches pragmatically adjust historical time series to reflect climate changes projected by gcms chiew et al 2009 mitchell 2003 the limitation of these methods is that scaling adjusts the magnitude of historical time series therefore future climate sequences will not reflect any change to the spatial or temporal patterns maraun 2016 a range of bias correction methods also exist that create a mapping between the distributions of raw and downscaled gcm data and observations johnson and sharma 2012 maraun 2016 mehrotra and sharma 2016 mehrotra and sharma 2021 teng et al 2015 such methods use empirical or parametric descriptions of the distribution of gcm and observed climate variables and assume that the quantile of a gcm or downscaled projection can be mapped directly to an identical quantile in the observed distribution a significant limitation of many quantile based bias correction methods is that quantile mapping occurs separately for each location time step and variable and therefore does not guarantee the resultant time series reproduces important spatial temporal or inter variable characteristics mehrotra and sharma 2016 for hydrological modelling applications that integrate over time and space this can lead to underestimation of extreme streamflow events and bias in aggregate flow statistics such as the mean annual flow bennett et al 2012 charles et al 2020 inter variable correlations between temperature and precipitation have been found to be particularly important in regions and seasons where precipitation falls as a mixture of snow and rain chen et al 2018 seo et al 2019 a limited number of bias correction methods exist that consider spatial and temporal correlations in time series johnson and sharma 2012 introduced an approach to correct bias in monthly rainfall projections that considers autocorrelation and applies corrections at multiple nested time scales their approach seeks to address issues related to both high and low frequency variability in gcm output they adopt a lag one autoregressive model to characterise the temporal persistence and while it is argued that a more sophisticated time series model could be used the use of such models has not yet been reported in the literature for hydrological applications the ability to apply corrections over multiple temporal scales reduces the chance that streamflow simulations generated using bias corrected rainfall will be biased however the johnson and sharma 2012 formulation of the bias correction and the parameter inference methods adopted means the approach is not able to be applied to daily data and does not necessarily correct conditional biases over all time scales mehrotra and sharma 2012 extensions of the johnson and sharma 2012 approach have introduced the ability to handle daily rainfall data represent spatial and inter variable correlation mehrotra and sharma 2015 mehrotra and sharma 2016 mehrotra and sharma 2021 while the formulation of the nested bias correction algorithm is hierarchical mehrotra and sharma 2012 moment estimates of parameters are used and therefore conditional dependencies between parameters at different scales are neglected neglecting these conditional dependencies requires recursive implementation of the nested bias correction to minimise bias in projections over all time scales and therefore an algorithm that is complex to implement mehrotra and sharma 2019 also introduced an alternative bias correction approach that seeks to correct the spatial temporal and inter variable correlations through the use of an empirical copula coupling method that is analogous to the schaake shuffle that is applied for precipitation forecast calibration for hydrological applications clark et al 2004 the method reorders bias corrected projections so that the lag 1 year autocorrelation of normalised projections reflects the observed autocorrelation adjusted for the different between the historical and future gcm autocorrelation the approach is applied separately to each calendar day across years meaning that there is no guarantee that the between day correlation for future periods is adequately described in addition when applied to precipitation the effect of zero values on correlation estimates is ignored meaning that autocorrelation estimates are potentially in error smith et al 2010 and potentially leading to poorer performance of the reordering method relative to non bounded variables such as temperature parametric methods to correct inter variable and spatial correlation have also been introduced into bias correction methods bárdossy and pegram 2012 bürger et al 2011 cannon 2016 cannon 2018 these methods establish correlation matrices for both gcm and observed time series and adjust the correlation of bias corrected data using a matrix decomposition of the correlation matrices as the matrix decomposition methods assume a multivariate gaussian dependence structure in some instance a recursive procedure is required where spatial or intervariable dependence structures differ from multivariate gaussian cannon 2016 while these methods have been applied to correct inter variable and spatial correlations conceptually an identical approach could be taken to handle temporal correlation as well while numerous bias correction methods have been developed to address the limitations of univariate quantile mapping very few studies demonstrate their effectiveness for hydrological applications in this paper we introduce a univariate bias correction method and developed it to i simultaneously correct bias at daily and aggregate time steps and ii handle differences in the autocorrelation structures of downscaled gcm and observed rainfall using a consistent statistical framework that allows the effects of method extension to be explored the developments of the bias correction methods are designed to address the limitations of univariate bias correction for hydrological applications identified by potter et al 2020 and charles et al 2020 the methods build on the concepts of johnson and sharma 2012 and mehrotra and sharma 2016 but seeks to address some of their limitations by adopting the parametric statistical models previously used to post process rainfall forecasts for hydrological applications and likelihood based parameter estimation techniques robertson et al 2013 we then contrast the ability of the methods to reproduce rainfall statistics critical for hydrological simulation and also illustrate their impact on streamflow simulations for 11 catchments in south eastern australia the paper is structured as follows section 2 introduces the bias correction methods building from a basic univariate mapping method commonly applied to include corrections at multiple time scales and allowing for autocorrelation section 3 describes methods adopted to evaluate the performance of the bias correction methods with respect to the rainfall characteristics and streamflow simulations section 4 presents result of the evaluation and discusses the implications for hydroclimate projections under a changing climate we summarise our key findings and conclusions in section 5 2 quantile mapping bias correction method quantile mapping is an approach to bias correction that involves adjusting a set of climate projections according to the relationship between the quantiles of a set of historical gcm simulations and corresponding observations the quantile relationship is obtained by fitting cumulative distribution functions independently to the historical gcm simulations and observations both empirical and parametric forms of the cumulative distribution function have been used as the basis of quantile mapping teng et al 2015 here we firstly introduce our basic univariate approach to quantile mapping and then extend the approach to jointly model multiple temporal scales and autocorrelation structure of rainfall 2 1 basic univariate quantile mapping for our base approach to quantile mapping we independently map daily values as is commonly practice bennett et al 2012 charles et al 2020 potter et al 2020 teng et al 2015 we adopt a parametric description of the marginal distribution that has previously been applied to calibration of rainfall forecasts at hourly robertson et al 2013 shrestha et al 2015 daily wang et al 2012 and seasonal schepen et al 2014 time scales to allow for seasonal rainfall distribution we use different marginal distributions for each calendar month 2 1 1 parametric distribution the distribution of daily rainfall for a given month is assumed to follow a transformed normal distribution here we adopt a log sinh transformation wang et al 2012 but any appropriate transformation can be used the log sinh transformation is given by 1 z 1 b log sinh a b x where x 5 x max x is a scaled version of the observed rainfall x to support similar parameter ranges across different locations and data types the transformed rainfall data is assumed to follow a normal distribution with zero values treated as censored data the censoring treatment allows for a single continuous distribution to be used to describe what would otherwise require a mixed discrete continuous distribution to describe the probability of zero rainfall and distribution of non zero rainfall amounts the censoring treatment assumes that distribution of transformed rainfall continues below zero but the precise negative values are unknown resulting in a point mass equivalent to the probability of zero rainfall the distribution of transformed rainfall data is given by 2 z n μ m σ m 2 where μ m is the mean daily rainfall for the given month m and σ m 2 the variance 2 1 2 parameter inference the marginal distribution of rainfall for each month m is described by four parameters a m b m μ m σ m for clarity of the subsequent formulations we drop the subscript m from all parameters and data a maximum a posteriori estimate of these parameters is obtained by optimisation the posterior density function is given by 3 p a b μ σ x p a b μ σ t 1 t p x t a b μ σ where the likelihood function is given by 4 p x t a b μ σ j z t x t ϕ z t μ σ z t z c φ z c μ σ z t z c where j z t x t coth a b x t is the jacobian of the transformation ϕ y t μ σ is the probability density function of the normal distribution and φ z c μ σ is the cumulative density function and z c the transformed value of a generic censor threshold set to zero in this case the prior distribution of parameters is given by 5 p a b μ σ p a p b p μ p σ 6 p a 1 a 1 p log b n 0 1 p μ 1 p log σ 1 the prior distributions are lightly informative encouraging small variances and weak transformations unless the data suggest otherwise 2 1 3 quantile mapping once the marginal distributions of downscaled gcm and observed rainfall are obtained they can be applied for quantile mapping in the transformed space the cumulative density function cdf of daily downscaled gcm simulated rainfall is given by 7 f p z p μ p σ p and the cdf of daily observed rainfall is given by 8 f o z o μ o σ o combining equations 7 and 8 quantile mapping can be described by 9 z o f o 1 f p z p μ p σ p μ o σ o the quantile mapped rainfall can be obtained by applying the back transforming z o using the following 10 x 1 b o arg sinh exp z b a o the censoring assumption means that when z p z c the precise value of f p z p μ p σ p is unknown in this case an estimate of the cdf value is obtained using the following 11 f p z p μ p σ p u f p z c μ p σ p where u is sampled from a standard uniform distribution 2 2 hierarchical quantile mapping the basic daily quantile mapping approach has known limitations including the ability to reproduce multi day rainfall totals potter et al 2020 here we introduce a hierarchical approach to quantile mapping to concurrently model and adjust the average rainfall over multi day periods and daily anomalies about the multi day rainfall averages the assumption is that a hierarchical approach to quantile mapping can ensure that the quantiles of multi day accumulations through the mean daily rainfall over a multi day period which are believed to influence hydrological simulations are corrected in addition to just the daily rainfall totals for this study we introduce the approach by modelling between year variations in the mean daily rainfall for each month however other configurations of the hierarchy are also possible the approach adopted is similar in nature to the nested bias correction introduce by johnson and sharma 2012 the hierarchical description of the marginal distribution assumes that after transformation daily rainfall observations follow a normal distribution 12 z n μ y σ d 2 μ y n μ σ y 2 where μ y is the mean daily rainfall for year y σ d 2 the variance of the daily anomalies about μ y and σ y 2 the variance of μ y about the global mean μ combining the distributions in yields 13 z n μ σ d 2 σ y 2 which is equivalent to equation 2 where σ 2 σ d 2 σ y 2 2 2 1 parameter inference due to the hierarchical nature of the model estimation of the model parameters needs to be undertaken in stages the first stage involves fitting the global parameters a b μ σ d σ y a maximum a posteriori estimate of these parameters is obtained by optimisation the posterior density function is given by 14 p a b μ σ y σ d x p a b μ σ y σ d y 1 y μ y i 1 i p x y i μ y σ d p μ y μ σ y d μ y where x y i is the transformed rainfall for i th day of year y the likelihood function p x y i μ y σ d is given by equation 4 and the prior distributions 15 p a b μ σ d σ y p a p b p μ p σ d p σ y 16 p a 1 a 1 p log b n 0 1 p μ 1 p log σ d 1 p σ y 2 1 σ y 2 0 5 2 σ y 2 0 0 where a half cauchy prior on σ y 2 is recommended by gelman 2006 for hierarchical variances and the remaining priors are consistent with the non hierarchical model computation of the posterior density function requires the integration over μ y for every set of parameters given that μ y follows a normal distribution gauss hermite integration can be used to efficiently compute the integrand using a small number of samples of μ y for given values of a b μ σ y σ d once the global parameters are obtained the values of μ y for each year can be estimated using the following likelihood 17 p μ y μ σ y σ d x y p x y μ y σ d p μ y μ σ y i 1 i p x y i μ y σ d p μ y μ σ y 2 2 2 quantile mapping procedure the above formulation can be used for a two stage quantile mapping technique where mapping is initially applied to the monthly mean and subsequently applied to the daily anomalies about that mean in the transformed space the cdf of mean monthly downscaled gcm simulated rainfall is given by 18 f u p μ y p μ p σ y p and the cdf of daily anomalies of downscaled gcm simulations by 19 f d p z p μ y p σ d p similarly for transformed observations the cdf of mean monthly rainfall is given by 20 f μ o μ y o μ o σ y o and the cdf of daily observed anomalies by 21 f o d z o μ y o σ d o combining equations 18 21 quantile mapping can be described by 22 z o f d o 1 f d p z p μ y p σ d o f μ o 1 f μ p μ y p μ p σ y p μ o σ y o σ d o effectively this is a two stages process where stage 1 involves quantile mapping the mean monthly rainfall 23 μ y o f μ o 1 f μ p μ y p μ p σ y p μ o σ y o stage 2 involves quantile mapping the daily anomaly 24 z o f d o 1 f d p z p μ m p σ d o μ m o σ d o 2 3 dealing with autocorrelation both the base and hierarchical approaches to quantile mapping do not make allowance for there being different correlation structures in the downscaled gcm simulations and observations cannon 2016 proposed a multivariate bias correction approach which uses a multivariate normal distribution to model the joint distribution of several different climate variables autocorrelation of rainfall within a multi day period can be considered as a multivariate problem where each day in the period has an identical marginal distribution we extend our base and hierarchical descriptions of the marginal distribution of rainfall by assuming that the joint distribution of transformed rainfall within a calendar month can be described using a multivariate normal distribution for bias correction applications ar1 models have previously been assumed for monthly and annual data e g johnson and sharma 2012 mehrotra and sharma 2012 mehrotra and sharma 2016 methods used for generating stochastic rainfall data at shorter time steps tend to embed higher order autocorrelation functions obeysekera et al 1987 in this study we assume that the autocorrelation of transformed rainfall can be described using an arma 2 1 model with parameters ρ 1 m ρ 2 m η 1 m using this strategy transformed rainfall for a calendar month are assumed to follow a multivariate normal distribution 25 z y m n μ y m 1 i y m σ y m 2 r m where z y m is a vector of transformed rainfall for calendar month m and year y 1 i y m is a vector of ones with the same length as z y m and r m a matrix representing the autocorrelation function the theoretical autocorrelation function for an arma model at lag τ can be derived using the method described by brockwell and davis 1991 the matrix r m is populated with the theoretical autocorrelation function using lag computed from the difference between the column and row index 2 3 1 parameter inference parameter inference follows the almost identically for the cases that ignore the autocorrelation except for the likelihood function the computation of the likelihood function for the multivariate distribution follows the method of wang and robertson 2011 the rainfall vector is separated into two subvectors 26 x y x y m x y n where x y m consists of days where rainfall is above the censor threshold and x y n are less than or equal to the censor threshold the likelihood function for a set of parameters θ μ σ ρ 1 ρ 2 η 1 is then given by 27 p x y θ p x y m x y n x c θ p x y m θ p x y n x c n x y m θ where 28 p x y m i 1 i m j z m i x m i p x y m θ 29 p x y n x c x y m θ p z y n z c n z y m θ z c n p z y n z y m θ d z y n i m is the dimension of x y m and z c n a vector of transformed censor thresholds the size of x y n the conditional distribution p z y n z y m θ is multivariate normal and the computation of the mean vector and covariance matrix can be found in standard statistical texts gelman et al 1995 the rannrm algorithm of genz 1993 are used to perform the numerical integration of the multivariate normal distribution 2 3 2 quantile mapping the approach to quantile mapping when autocorrelation is modelled follows that described by cannon 2018 the steps of the quantile mapping are 1 transform the vector of downscaled gcm rainfall for a given month using the transformation parameters a p b p inferred using the downscaled gcm data 2 augment any censored values using a gibbs sampler see wang and robertson 2011 for details 3 standardise the augmented vector of transformed downscaled gcm rainfall from step 2 to give a vector of correlated standard normal variates by subtracting by the mean μ y p and dividing by the standard deviation σ y p inferred using the downscaled gcm data 4 rotate the correlated standard normal variates from step 3 using the inverse of the cholesky decomposition of the matrix r p for the downscaled gcm rainfall to give a vector of uncorrelated standard normal variates 5 rotate the uncorrelated standard normal variates from step 4 using the cholesky decomposition of the matrix r o for the observed rainfall to give a vector of correlated standard normal variates following the correlation structure of the observations 6 unstandardise the vector of correlated standard normal variates from step 5 by multiplying by the standard deviation σ y o and adding the mean μ y o inferred using the observations 7 back transform the output of step 6 using the transformation parameters a o b o inferred using the observations 8 set negative values in the output of step 7 to zero 3 assessment of quantile mapping methods the previous section describes four possible approaches to quantile mapping 1 basic daily quantile mapping neglecting autocorrelation 2 hierarchical quantile mapping neglecting autocorrelation 3 basic daily quantile mapping allowing for autocorrelation 4 hierarchical quantile mapping allowing for autocorrelation our motivation in developing the more sophisticated quantile mapping methods is to address limitations of simpler approaches for hydrological simulation applications we therefore assess the performance of the different approaches for with respect to bias corrected rainfall and also for hydrological simulations 3 1 rainfall we assess the efficacy of the four bias correction methods in a cross validation mode an interwoven two fold cross validation scheme is adopted similar to that applied adopted by corney et al 2013 to assess the out of sample performance of the quantile mapping schemes under this cross validation scheme the available data set is separated into two subsets one used for fitting the quantile mapping distributions and one used to evaluate the quantile mapped data the two subsets are then swapped and the statistical characteristics of the entire quantile mapped dataset are evaluated for this study the subsetting strategy is to use every second year so that any long term trends or step changes in either the gcm or observed data are present in both the fitting and evaluation subsets this strategy seeks to address the many limitations of cross validation identified by maraun 2016 we firstly evaluate the ability of the parametric distributions to describe the marginal distribution of observed and downscaled gcm rainfall using the approach described by robertson et al 2013 the best fit distribution parameters are obtained using the methods described in the previous section and all available data a set of samples equal in length to the number of observations used to fit the model is drawn from the fitted distribution the set of samples represents one realisation of the cumulative marginal distribution to represent the sampling uncertainty associated with taking a limited set of samples from the marginal distribution multiple 1000 realisations of the cumulative distribution are generated and summarised using the median and the 0 025 0 975 quantile ranges for each percentile graphical comparisons of the marginal distributions are compared to the observations in a probability plot we compare the efficacy of the four bias corrections methods by computing a range of metrics that reflect the bias in the annual and monthly mean rainfall and also in metrics relevant for hydrological modelling including the length of wet and dry spells the magnitude of three day rainfall totals and the persistence of daily rainfall specifically the lag one autocorrelation dry dry day probability and wet wet day probability 3 2 hydrological simulations hydrological modelling was undertaken using the gr4j rainfall runoff model perrin et al 2003 model parameters were calibrated for each catchment using the shuffled complex evolution algorithm duan et al 1994 duan et al 1993 by optimising a compound objective function the adopted objective function is 30 of 1 n s e 5 log 1 b i a s 2 5 where 31 nse 1 t 1 t q s t q o t 2 t 1 t q o t q o 2 32 bias q s q o q o and nse is the nash sutcliffe efficiency nash and sutcliffe 1970 q s t is the simulated streamflow for time step t q o t is the observed streamflow q s is the mean simulated streamflow q o is the mean observes streamflow and t the total number of time steps streamflow simulations are generated using a hydrological model calibrated to observed streamflow see supplementary material for calibration performance assessment absolute bias in streamflow simulations is computed by comparing the streamflow simulations generated using the bias corrected rainfall generated in fitting mode to streamflow simulations generated using observed forcing by computing bias using this approach the ability of the hydrological model to represent observed streamflow is disregarded we also focus our efforts on assessing the sensitivity of hydrological modelling to assumptions in rainfall bias correction methods and therefore we use the observed pe data for all streamflow simulations the impact of rainfall bias correction methods on streamflow simulations are assessed by computing the bias of the mean daily streamflow and for a range of daily streamflow percentiles as we are investigating bias correction methods that modify the persistence in rainfall we also assess biases in measures of streamflow persistence particularly the length of simulated low and high flow periods and percentiles of streamflow accumulations over 3 and 10 day periods and also accumulations over periods of 1 3 6 and 12 months 3 3 catchments and data eleven catchments in south eastern australia are used in this study fig 1 table 1 the catchments are important for sources of irrigation or urban water supply and all but one have previously been used by charles et al 2020 and potter et al 2020 where they demonstrated the limitations of many existing simple bias correction schemes rainfall and potential evaporation pe data for the study catchments is derived from the gridded analysis produced by the australian water availability project awap jones et al 2009 raupach et al 2008 streamflow observations for the catchments are obtained from the victorian government hydrological data archives https data water vic gov au bias correction methods are applied to readily available dynamically downscaled simulations from the narclim new south wales and act regional climate modelling project https www ccrc unsw edu au sites default files narclim index html the narclim project adopted 3 configurations of the wrf weather research and forecasting regional climate model to two different reanalysis products ncep ncar reanalysis and era interim and four gcms cccm3 1 csiro mk3 0 echam5 and miroc3 2 from the coupled model intercomparison project phase 3 cmip3 detailed descriptions of the downscaling methods are described by evans et al 2014 in this study only the historical simulations of the downscaled gcm rainfall data are considered and analysis of the performance of the bias correction methods is performed separately for the downscaled reanalysis and gcm simulations all analysis uses data for the period 1990 2009 inclusive 4 results 4 1 fit of marginal distributions the daily marginal distributions fitted using the hierarchical and non hierarchical methods with and without allowing for autocorrelation display few differences fig 2 and fig 3 the high daily rainfall values are better fitted for the observed rainfall than the downscaled rainfall for the example shown but this is not always the case the large rainfall values of the distributions fitted using autocorrelation tend to be slightly smaller than those where autocorrelation is neglected in all cases nearly all the observations lie within the 95 uncertainty intervals of the fitted distributions and the probability of zero rainfall is well matched on occasion the largest rainfall observation does fall outside the 95 uncertainty interval not shown this can be expected as the probability of largest values within the limited 20 years used in this study is highly uncertain in general the fitted parametric distribution does describe the key features of the marginal distribution of the observations and would therefore appear to be adequate for quantile mapping purposes however the fit of the parametric distribution is not perfect for either the gcm or observed rainfall and as a result bias corrections performed using the fitted distributions for quantile mapping may not totally eliminate all bias differences in methods for fitting the marginal distribution emerge in the distributions of total monthly rainfall fig 4 and fig 5 derived from the daily distributions presented in fig 2 and fig 3 the variance of monthly rainfall totals derived from data generated using the non hierarchical parametric distribution that does not consider autocorrelation is considerably lower than for the other methods fig 4 the lower variance of monthly rainfall totals is illustrated by the flatter blue lines in fig 4 that poorly describe the highest and lowest monthly totals this limitation arises because the sampled daily rainfall is purely random adopting a hierarchical method or allowing for autocorrelation in the fitted marginal distribution induces structure in the sampled daily rainfall and improves the ability to describe the distribution of monthly rainfall totals the distributions of monthly rainfall totals derived using the combination of the hierarchical method and allowing for autocorrelation tend to better characterise the highest and lowest monthly rainfall values 4 2 evaluation of bias corrected rainfall quantile mapping reduces the large biases of annual and monthly rainfall in both downscaled gcm and reanalysis rainfall to nearly zero fig 6 for all months the interquartile range of bias is smaller than 10 but in some months the bias after quantile mapping for a small number of catchments gcm and downscaling can be as high as 20 as indicated by the whiskers of the box plots these residual biases are likely to be an indication that the parametric description of the marginal distribution is inadequate in some instances differences in the annual and monthly bias between the quantile mapping approaches are small and can be considered inconsequential fig 6 however differences between the quantile mapping approaches do become evident when evaluating rainfall sequencing metrics fig 7 quantile mapping approaches that ignore differences in autocorrelation between the observed and downscaled gcm data display residual bias in many of the rainfall sequencing metrics these biases are practically eliminated using approaches that consider autocorrelation for bias correction of downscaled outputs from both reanalyses and host gcm this is particularly evident for the mean dry spell length mean wet spell length lag one autocorrelation and consecutive wet and dry day probabilities pww and pdd respectively bias correction methods that ignore autocorrelation appear to increase bias of some rainfall sequencing metrics relative to the raw downscaled gcm data for example the lag one autocorrelation and mean wet spell length differences in the bias of rainfall sequencing metrics between the hierarchical and non hierarchical mapping methods tend to be very small where there are differences there is no clear pattern as to which is the better performing method with the hierarchical method displaying smaller and less variable bias for some metrics and the non hierarchical method displaying similar characteristic for other metrics this suggests that the effects of between year variations in rainfall are likely to vary considerably between catchments fig 6 and fig 7 also highlight there are differences in the bias characteristics of the raw downscaled reanalysis and historical gcm simulations the raw downscaled reanalysis tends to have lower bias in monthly and annual means and also in many rainfall sequencing metrics than the downscaled gcm data the bias corrected reanalysis also tends to display smaller and less variable residual bias than the bias corrected historical gcm simulation this suggests the bias correction methods are likely to perform more consistently when the correcting smaller biases 4 3 evaluation of streamflow simulations streamflow simulations generated using bias corrected rainfall are considerably less biased than those generated using the raw downscaled gcm and reanalysis rainfall and the variability of the bias is considerably smaller fig 8 a median negative bias of approximately 0 1 mm day 10 exists in mean streamflow simulations generated using bias corrected rainfall and the bias correction methods that consider autocorrelation reduce this bias by up to 2 of the mean daily streamflow however the bias does not manifest equally across all flow percentiles for all bias correction methods the bias correction methods that do not consider autocorrelation tend to produce streamflow with smaller bias for low streamflow percentiles and much larger bias for the highest streamflow percentiles compare to those that do consider autocorrelation for the low streamflow percentiles while there are substantial differences in between the bias correction methods in percentage terms in absolute terms there are very small however for the high streamflow percentiles both the large differences between the bias correction methods in percentage terms do manifest in large difference in absolute terms as well this suggests the smaller bias in mean daily flow as a result of considering the autocorrelation in the rainfall bias correction is primarily due to the lower bias in the high streamflow percentiles biases in the streamflow simulations generated using the bias corrected gcm rainfall are also typically larger than the simulations generated using bias corrected reanalysis rainfall when autocorrelation in rainfall is not considered while they behave similarly when autocorrelation is considered in the temperate catchments considered in this study high percentile streamflow predominantly results from multi day wet sequences that refill catchment water stores therefore the ability of a bias correction method to produce multi day wet sequences in bias corrected time series will influence the bias in high percentile streamflow simulations our results indicate that the multi day wet sequences and high percentile streamflow simulations can only be realistically reproduced using bias correction methods that consider autocorrelation the importance of multi day sequences of rainfall to produce high streamflow percentiles may also explain why when autocorrelation is not considered biases in streamflow simulations produced using the bias corrected reanalysis rainfall are smaller than those produced using the bias corrected gcm as reanalysis products are generated by assimilating atmospheric observations after downscaling they are more likely to reflect actual temporal climate sequences than uninitialized gcms however even though the downscaled reanalysis is more likely to reproduce realistic temporal climate sequences bias in high percentiles of streamflow simulations is likely to still be present unless bias correction methods consider autocorrelation we further illustrate the effects of allowing for autocorrelation in the rainfall bias correction method by examining its effects on the bias in the high percentile flow accumulations over 3 and 10 day periods and the length of low and high flow sequences fig 9 differences between the rainfall bias correction methods are minimal for the 90th percentile 3 and 10 day streamflow accumulations this is also true for lower percentiles not shown however for the 95th and 99th percentile 3 and 10 day streamflow accumulations the rainfall bias correction methods that consider autocorrelation do display lower bias those that neglect autocorrelation these very high percentile 3 and 10 day streamflow accumulations require multi day sequences high rainfall amounts to occur which seems only to be possible if autocorrelation is considered in the bias correction method however accumulations for the 90th and lower percentile streamflow accumulations could possibly occur as a result of a multi day rainfall sequence or during the recession following a very high streamflow event when effects of rainfall on streamflow are reduced and therefore the effects of including autocorrelation in the bias correction method are minimal bias correcting rainfall forcing reduces bias in the length of simulated high and low flow periods bias in the length of both high and low flow periods is also influenced by the bias correction method with the methods considering autocorrelation displaying lower bias that those that don t the hierarchical bias correction methods also display lower bias than the non hierarchical method for the low flow periods the bias correction methods that consider autocorrelation produce close to zero bias particularly for the simulations produce using bias corrected gcm data however for the high flow periods the negative biases of the simulations generated using raw downscaled translate into positive biases for the simulations using bias corrected rainfall albeit of a smaller magnitude this suggests that order of the arma model adopted for the bias correction may be too high for the actual rainfall observations projections of streamflow are often used to assess the adequacy of a range of water resources management strategies including reservoir reliability analyses that are sensitive to streamflow accumulations over periods of months and years we assess the impact of the different bias correction methods on the multi month streamflow accumulations fig 10 at all timescales the bias of streamflow simulations generated using bias corrected rainfall is lower than the bias of simulations generated using the raw downscaled gcm and reanalysis rainfall as with the 3 and 10 day accumulations differences between the bias correction methods are small for the 90th percentile 1 3 6 and 12 month streamflow accumulations differences do exist for the 95th and 99th percentile accumulations with the bias correction methods that consider autocorrelation displaying biases that are closer to zero than those that don t consider autocorrelation 5 discussion here we have described modifications to standard quantile quantile matching methods that can address the limitations in using bias corrected rainfall for streamflow simulation charles et al 2020 teng et al 2015 teutschbein and seibert 2012 the modifications involve applying quantile mapping simultaneously to daily and multi day in this paper monthly rainfall and by explicitly accounting for differences in the autocorrelation structures of observed and downscaled gcm rainfall our result show that allowing for difference in autocorrelation improve rainfall sequencing metrics and that under cross validation the hierarchical approach produces slightly smaller bias in mean rainfall than simple daily quantile quantile mapping the study of charles et al 2020 found that bias corrected rainfall led to under estimation of simulated mean annual streamflow and in high flow percentiles our results produced using a standard quantile quantile method demonstrate similar under estimation of mean streamflow and of high flow percentiles reported by charles et al 2020 while our results show that the under estimation of streamflow particularly high flow percentiles is reduced by both modifications to standard quantile mapping we introduce the greatest improvement arises from allowing for differences in rainfall autocorrelation between observed and downscaled gcm rainfall in the catchments considered in this study streamflow dynamics are strongly influenced by high and low frequency climate variability our results suggest that inadequate representation of high frequency variability as characterised by rainfall autocorrelation leads to underestimation of high streamflow percentiles and overall negative bias in streamflow simulations therefore methods for correcting bias in climate change projections for hydrological applications require rainfall autocorrelation to be corrected in addition to the properties of the daily rainfall distribution conceptually the hierarchical quantile mapping approach also allows for corrections to be made to the amplitude of low frequency variability evaluation of the benefits of the hierarchical approach to quantile mapping for correcting low frequency variability will be investigated in a future study in this study we have evaluated the effects of our bias correction approaches applied to downscaled gcm simulations and reanalysis for historical periods the most common application of bias correction methods is in the assessment of the impacts of future climate change hydrological climate change studies typically characterise the changes in streamflow simulations between a historical and future period using the same downscaled gcm product therefore the ability to reduce bias in a gcm forced streamflow simulations for historical periods relative to the simulations forced by observed climate data may not necessarily result in materially different conclusions on the effects of climate change investigations into the sensitivity of climate change projections will be reported in a future study this study has applied bias correction methods that adjust the mean variance and skewness of the marginal distribution and temporal correlation structure the methods have been evaluated using an application to correct downscaled gcm and reanalysis for historical periods with concurrent but assumed asynchronous observations to correct bias in downscaled gcm projections of climate changes requires assumptions to be made about the consistency of the parameters of the bias corrections between historical and future periods one approach is to assume that the parameters inferred using historical observations and gcm simulations can be applied to future periods charles et al 2020 potter et al 2020 if the change between the historical and future periods is large this approach is potentially limited by the ability of the parametric marginal distribution to extrapolate beyond the range of data used in parameter estimation it also assumes that the autocorrelation of downscaled gcm simulations and observations in the transformed space does not change an alternative approach is to preserve some or all changes in distributional characteristics between historical and future downscaled gcm projections in the distribution of the observations and apply quantile mapping using modified marginal distributions this approach has been used to preserve changes in the mean cannon 2018 mehrotra and sharma 2016 and temporal or spatial correlation bárdossy and pegram 2012 mehrotra and sharma 2016 or full marginal cumulative density function robin et al 2019 between historical and future downscaled gcm projections as a part of a quantile mapping algorithm the potential limitation with this approach particularly if parametric descriptions of marginal distributions are adopted is that parameters can be conditionally dependent meaning that the process of adjustment of individual properties is not straightforward further investigation is needed to establish the most appropriate approach to apply quantile mapping to future projections when changes between the historical and future periods are large such an investigation would require historical data with changes similar in magnitude to be able to validate any findings the hierarchical approach to bias correction introduced in this paper adopted a two level hierarchy extension of the hierarchical structure to more than two levels may be desirable to better represent variability at different temporal scales or to handle seasonal effects in a single model while extension of the hierarchical structure is possible as the number of levels in the hierarchy increases parameter estimation becomes increasingly challenging each additional layer in the hierarchy requires an additional numerical integration in the computation of the likelihood function therefore even when computationally efficient numerical integration methods are used parameter estimation may become computationally infeasible from a practical perspective in the current study parameter estimation for the two level hierarchical approach required considerably more computational time than the non hierarchical equivalent and therefore even using a three layer model may be computationally prohibitive in this study we apply bias correction to a single variable at a single location hydrological applications are likely to also require coherent bias corrected gcm data for multiple variables and or locations the approach used here to consider temporal correlations as a part of the bias correction adapts approaches used to model spatial and inter variable correlation structure bárdossy and pegram 2012 cannon 2018 therefore generating bias corrected data that display appropriate spatial and intervariable correlations is a direct extension of the bias correction described here however increasing the number of correlation dimensions considered can induce instability in some analogous bias correction methods and ultimately degrade desired statistical features e g spatial correlations primarily due to the limited data available to estimate high dimension correlation structures françois et al 2020 extending the approach described here to consider spatial and inter variable correlation would therefore require investigation to mitigate against potential instabilities which may include parameterized correlation structures or other methods to reduce the number of effective dimensions several authors argue that stochastic bias corrections are necessary to overcome the inability of many gcm and rcm models to reproduce the fine scale spatial and temporal variability mao et al 2015 maraun 2016 robin et al 2019 yuan et al 2019 an element of stochasticity can be generated using the bias correction methods introduced in this paper that consider autocorrelation and all similar methods step 4 of the bias correction procedure in the methods that allow for autocorrelation rotates standard normal variates to remove any correlation before step 5 applies a different rotation to instil correlations that reflect the observations theoretically after step 4 the resultant variates are independent in this study we maintain the order of the independent variates between steps 4 and 5 however as they are independent these variates could be reordered to introduce an element of stochasticity in the bias corrected data this stochasticity would primarily be different of climate sequences that all follow the transformed marginal distribution of the observations the catchments we have investigated in this study are limited to the temperate zones of south eastern australia while the catchments do have diverse hydrological characteristics including one catchment that is intermittent the rainfall characteristics are broadly similar for all catchments these catchments display cool wet winters where rainfall is primarily from extra tropical frontal weather systems and warm dry summers therefore the benefits of including autocorrelation in rainfall bias correction methods may be limited to similar temperate regions further work is required to investigate the efficacy of the bias correction methods introduced in this manuscript regions with differing rainfall seasonality and processes for example in tropical and monsoonal regions where rainfall persistence may be better represented in the downscaled gcm and reanalysis products or of lessor importance for streamflow simulation finally in this study we used dynamically downscaled simulations from a subset of host cmip3 gcms to demonstrate our method cmip5 and cmip6 provide more recent climate simulation and projection data with newer generations of climate models that are higher resolution and improved parameterizations bias in the raw gcm rainfall output from all cmip experiments tends to be very large and therefore for this study we used dynamically downscaled simulations dynamical downscaling of gcm output can add value by reducing bias particularly in areas of complex topography di virgilio et al 2020 since commencing this work new downscaled gcm data forced by cmip5 models has been released nishant et al 2021 while these new simulations show reduced bias and improved seasonal patterns in precipitation biases remain large requiring the correction for hydrological applications nishant et al 2021 therefore bias correction methods such as those introduced here will continue to be required for hydrological impact modelling 6 conclusions global climate models provide important insights into future climate change however inconsistencies between the statistics of downscaled gcm simulations and observations mean that bias correction is an integral part of any assessment of the hydrological consequences of climate change while a wide range of techniques have been developed to correct bias in different aspects of gcm simulations extending from simple univariate methods to approaches that explicitly consider spatial temporal and inter variable dependence structures there are few comparisons of the impact of different bias correction assumptions on hydrological simulations this paper uses a consistent statistical framework to investigate the importance of i simultaneously correcting bias at multiple time scales and ii explicitly handling rainfall autocorrelation in quantile mapping of gcm rainfall for hydrological simulation four quantile mapping methods are applied to correct bias in dynamically downscaled reanalysis and historical gcm projections of rainfall for 11 catchments in south eastern australia and the performance of bias corrected rainfall and streamflow simulations is evaluated all quantile mapping methods investigated can effectively eliminate bias in monthly and annual rainfall totals quantile mapping methods that consider differences in the temporal dependence autocorrelation structure of gcm and observed rainfall are most effective in reducing bias in rainfall sequencing statistics such as probability of consecutive wet or dry days for streamflow simulations mean and high streamflow percentiles over multiple time periods are underestimated when generated using rainfall that is corrected with quantile mapping methods that do not consider differences in the temporal dependence structure of gcm and observed rainfall rainfall forcing generated using quantile mapping methods that correct temporal dependence autocorrelation structures produce in streamflow simulations with lower often close to zero bias in mean and high percentiles estimates across time period of days to months in this study we investigated alternative bias correction methods for historical periods further investigations will assess the sensitivity of future projections to bias correction methods including the importance of explicitly preserving changes in some or all the distributional characteristics of gcm simulations between future and historical periods given our findings on the importance of explicitly handling rainfall autocorrelation in quantile mapping for hydrological applications future work will also investigate the most appropriate methods to characterise temporal and where necessary spatial and inter variable dependence structures credit authorship contribution statement david e robertson conceptualization methodology software formal analysis investigation validation writing original draft writing review editing francis h s chiew conceptualization funding acquisition investigation methodology writing review editing nicholas potter conceptualization data curation investigation writing review editing declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests david e robertson reports financial support was provided by victoria department of environment land water and planning francis chiew reports financial support was provided by victoria department of environment land water and planning nick potter reports financial support was provided by victoria department of environment land water and planning acknowledgements this work was conducted on the traditional lands of the boonwurrung wurundjeri peoples of the kulin nation and also the ngunnawal and ngambri peoples we acknowledge their continuing custodianship of these lands and the rivers that flow through them and pay our respects to their elders past and present we also acknowledge the traditional custodians of the catchments and rivers used in this study this research has been supported by the victorian water and climate initiative we thank hongxing zheng and steve charles both csiro for supplying the catchment data an r package used for bias correction is available on request license conditions apply appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129322 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2154,global circulation models gcms provide important insights into future climate change bias correction of downscaled gcm output is integral to any hydrological investigations of climate change due to discrepancies between the statistics of downscaled gcm simulations and observations many bias correction techniques have been developed to support hydrological applications however there have been few comparisons of the sensitivity of hydrological simulations to different bias correction assumptions this paper investigates the importance of two common assumptions i simultaneously correcting bias at multiple time scales and ii explicitly handling rainfall autocorrelation in quantile mapping of downscaled gcm rainfall data for hydrological simulation four quantile mapping methods are applied to correct bias in dynamically downscaled reanalysis and historical gcm simulations of rainfall for 11 catchments in south eastern australia and the performance of bias corrected rainfall and streamflow simulations is evaluated all quantile mapping methods investigated can effectively eliminate bias in monthly and annual rainfall totals quantile mapping methods that consider differences in the temporal dependence autocorrelation structure of downscaled gcm and observed rainfall are most effective in reducing bias in rainfall sequencing statistics such as probability of consecutive wet or dry days streamflow simulations of mean and high streamflow percentiles are underestimated when generated using rainfall that is corrected using quantile mapping methods that do not consider differences in the temporal dependence structure of downscaled gcm and observed rainfall future hydrological investigations of climate change should therefore adopt methods that explicitly consider the temporal dependence structures of downscaled gcm and observed rainfall keywords climate change bias correction hydrological simulation hydroclimate data availability data will be made available on request 1 introduction global circulation models gcms generate important input to hydrological modelling investigations of the impacts of future climate change chiew et al 2009 zheng et al 2018 hydrological processes are highly sensitive to rainfall chiew 2006 sankarasubramanian et al 2001 and therefore hydrological model simulations are designed to be similarly sensitive to the distribution of forcing data fu et al 2007 however the coarse spatial resolution of gcms means that model output particularly precipitation simulations can have very different characteristics to observations and therefore cannot be directly used for hydrological applications charles et al 2020 potter et al 2020 downscaling methods are commonly applied to increase the spatial resolution of climate projections maraun 2016 a range of downscaling techniques have been applied including empirical statistical and dynamical methods dynamical downscaling uses regional climate models forced by gcms to generate climate simulations and projections at finer spatial scales and has recently been shown to add value to projections from gcms particularly precipitation projections and in areas of complex topography di virgilio et al 2020 while dynamical downscaling can add value to projections discrepancies still remain between distributional characteristics of downscaled gcm based simulations and ground based observations that are used to establish hydrological models charles et al 2020 ekström et al 2015 potter et al 2020 many methods have been proposed to correct distributional errors or bias in downscaled gcm data maraun 2016 scaling approaches pragmatically adjust historical time series to reflect climate changes projected by gcms chiew et al 2009 mitchell 2003 the limitation of these methods is that scaling adjusts the magnitude of historical time series therefore future climate sequences will not reflect any change to the spatial or temporal patterns maraun 2016 a range of bias correction methods also exist that create a mapping between the distributions of raw and downscaled gcm data and observations johnson and sharma 2012 maraun 2016 mehrotra and sharma 2016 mehrotra and sharma 2021 teng et al 2015 such methods use empirical or parametric descriptions of the distribution of gcm and observed climate variables and assume that the quantile of a gcm or downscaled projection can be mapped directly to an identical quantile in the observed distribution a significant limitation of many quantile based bias correction methods is that quantile mapping occurs separately for each location time step and variable and therefore does not guarantee the resultant time series reproduces important spatial temporal or inter variable characteristics mehrotra and sharma 2016 for hydrological modelling applications that integrate over time and space this can lead to underestimation of extreme streamflow events and bias in aggregate flow statistics such as the mean annual flow bennett et al 2012 charles et al 2020 inter variable correlations between temperature and precipitation have been found to be particularly important in regions and seasons where precipitation falls as a mixture of snow and rain chen et al 2018 seo et al 2019 a limited number of bias correction methods exist that consider spatial and temporal correlations in time series johnson and sharma 2012 introduced an approach to correct bias in monthly rainfall projections that considers autocorrelation and applies corrections at multiple nested time scales their approach seeks to address issues related to both high and low frequency variability in gcm output they adopt a lag one autoregressive model to characterise the temporal persistence and while it is argued that a more sophisticated time series model could be used the use of such models has not yet been reported in the literature for hydrological applications the ability to apply corrections over multiple temporal scales reduces the chance that streamflow simulations generated using bias corrected rainfall will be biased however the johnson and sharma 2012 formulation of the bias correction and the parameter inference methods adopted means the approach is not able to be applied to daily data and does not necessarily correct conditional biases over all time scales mehrotra and sharma 2012 extensions of the johnson and sharma 2012 approach have introduced the ability to handle daily rainfall data represent spatial and inter variable correlation mehrotra and sharma 2015 mehrotra and sharma 2016 mehrotra and sharma 2021 while the formulation of the nested bias correction algorithm is hierarchical mehrotra and sharma 2012 moment estimates of parameters are used and therefore conditional dependencies between parameters at different scales are neglected neglecting these conditional dependencies requires recursive implementation of the nested bias correction to minimise bias in projections over all time scales and therefore an algorithm that is complex to implement mehrotra and sharma 2019 also introduced an alternative bias correction approach that seeks to correct the spatial temporal and inter variable correlations through the use of an empirical copula coupling method that is analogous to the schaake shuffle that is applied for precipitation forecast calibration for hydrological applications clark et al 2004 the method reorders bias corrected projections so that the lag 1 year autocorrelation of normalised projections reflects the observed autocorrelation adjusted for the different between the historical and future gcm autocorrelation the approach is applied separately to each calendar day across years meaning that there is no guarantee that the between day correlation for future periods is adequately described in addition when applied to precipitation the effect of zero values on correlation estimates is ignored meaning that autocorrelation estimates are potentially in error smith et al 2010 and potentially leading to poorer performance of the reordering method relative to non bounded variables such as temperature parametric methods to correct inter variable and spatial correlation have also been introduced into bias correction methods bárdossy and pegram 2012 bürger et al 2011 cannon 2016 cannon 2018 these methods establish correlation matrices for both gcm and observed time series and adjust the correlation of bias corrected data using a matrix decomposition of the correlation matrices as the matrix decomposition methods assume a multivariate gaussian dependence structure in some instance a recursive procedure is required where spatial or intervariable dependence structures differ from multivariate gaussian cannon 2016 while these methods have been applied to correct inter variable and spatial correlations conceptually an identical approach could be taken to handle temporal correlation as well while numerous bias correction methods have been developed to address the limitations of univariate quantile mapping very few studies demonstrate their effectiveness for hydrological applications in this paper we introduce a univariate bias correction method and developed it to i simultaneously correct bias at daily and aggregate time steps and ii handle differences in the autocorrelation structures of downscaled gcm and observed rainfall using a consistent statistical framework that allows the effects of method extension to be explored the developments of the bias correction methods are designed to address the limitations of univariate bias correction for hydrological applications identified by potter et al 2020 and charles et al 2020 the methods build on the concepts of johnson and sharma 2012 and mehrotra and sharma 2016 but seeks to address some of their limitations by adopting the parametric statistical models previously used to post process rainfall forecasts for hydrological applications and likelihood based parameter estimation techniques robertson et al 2013 we then contrast the ability of the methods to reproduce rainfall statistics critical for hydrological simulation and also illustrate their impact on streamflow simulations for 11 catchments in south eastern australia the paper is structured as follows section 2 introduces the bias correction methods building from a basic univariate mapping method commonly applied to include corrections at multiple time scales and allowing for autocorrelation section 3 describes methods adopted to evaluate the performance of the bias correction methods with respect to the rainfall characteristics and streamflow simulations section 4 presents result of the evaluation and discusses the implications for hydroclimate projections under a changing climate we summarise our key findings and conclusions in section 5 2 quantile mapping bias correction method quantile mapping is an approach to bias correction that involves adjusting a set of climate projections according to the relationship between the quantiles of a set of historical gcm simulations and corresponding observations the quantile relationship is obtained by fitting cumulative distribution functions independently to the historical gcm simulations and observations both empirical and parametric forms of the cumulative distribution function have been used as the basis of quantile mapping teng et al 2015 here we firstly introduce our basic univariate approach to quantile mapping and then extend the approach to jointly model multiple temporal scales and autocorrelation structure of rainfall 2 1 basic univariate quantile mapping for our base approach to quantile mapping we independently map daily values as is commonly practice bennett et al 2012 charles et al 2020 potter et al 2020 teng et al 2015 we adopt a parametric description of the marginal distribution that has previously been applied to calibration of rainfall forecasts at hourly robertson et al 2013 shrestha et al 2015 daily wang et al 2012 and seasonal schepen et al 2014 time scales to allow for seasonal rainfall distribution we use different marginal distributions for each calendar month 2 1 1 parametric distribution the distribution of daily rainfall for a given month is assumed to follow a transformed normal distribution here we adopt a log sinh transformation wang et al 2012 but any appropriate transformation can be used the log sinh transformation is given by 1 z 1 b log sinh a b x where x 5 x max x is a scaled version of the observed rainfall x to support similar parameter ranges across different locations and data types the transformed rainfall data is assumed to follow a normal distribution with zero values treated as censored data the censoring treatment allows for a single continuous distribution to be used to describe what would otherwise require a mixed discrete continuous distribution to describe the probability of zero rainfall and distribution of non zero rainfall amounts the censoring treatment assumes that distribution of transformed rainfall continues below zero but the precise negative values are unknown resulting in a point mass equivalent to the probability of zero rainfall the distribution of transformed rainfall data is given by 2 z n μ m σ m 2 where μ m is the mean daily rainfall for the given month m and σ m 2 the variance 2 1 2 parameter inference the marginal distribution of rainfall for each month m is described by four parameters a m b m μ m σ m for clarity of the subsequent formulations we drop the subscript m from all parameters and data a maximum a posteriori estimate of these parameters is obtained by optimisation the posterior density function is given by 3 p a b μ σ x p a b μ σ t 1 t p x t a b μ σ where the likelihood function is given by 4 p x t a b μ σ j z t x t ϕ z t μ σ z t z c φ z c μ σ z t z c where j z t x t coth a b x t is the jacobian of the transformation ϕ y t μ σ is the probability density function of the normal distribution and φ z c μ σ is the cumulative density function and z c the transformed value of a generic censor threshold set to zero in this case the prior distribution of parameters is given by 5 p a b μ σ p a p b p μ p σ 6 p a 1 a 1 p log b n 0 1 p μ 1 p log σ 1 the prior distributions are lightly informative encouraging small variances and weak transformations unless the data suggest otherwise 2 1 3 quantile mapping once the marginal distributions of downscaled gcm and observed rainfall are obtained they can be applied for quantile mapping in the transformed space the cumulative density function cdf of daily downscaled gcm simulated rainfall is given by 7 f p z p μ p σ p and the cdf of daily observed rainfall is given by 8 f o z o μ o σ o combining equations 7 and 8 quantile mapping can be described by 9 z o f o 1 f p z p μ p σ p μ o σ o the quantile mapped rainfall can be obtained by applying the back transforming z o using the following 10 x 1 b o arg sinh exp z b a o the censoring assumption means that when z p z c the precise value of f p z p μ p σ p is unknown in this case an estimate of the cdf value is obtained using the following 11 f p z p μ p σ p u f p z c μ p σ p where u is sampled from a standard uniform distribution 2 2 hierarchical quantile mapping the basic daily quantile mapping approach has known limitations including the ability to reproduce multi day rainfall totals potter et al 2020 here we introduce a hierarchical approach to quantile mapping to concurrently model and adjust the average rainfall over multi day periods and daily anomalies about the multi day rainfall averages the assumption is that a hierarchical approach to quantile mapping can ensure that the quantiles of multi day accumulations through the mean daily rainfall over a multi day period which are believed to influence hydrological simulations are corrected in addition to just the daily rainfall totals for this study we introduce the approach by modelling between year variations in the mean daily rainfall for each month however other configurations of the hierarchy are also possible the approach adopted is similar in nature to the nested bias correction introduce by johnson and sharma 2012 the hierarchical description of the marginal distribution assumes that after transformation daily rainfall observations follow a normal distribution 12 z n μ y σ d 2 μ y n μ σ y 2 where μ y is the mean daily rainfall for year y σ d 2 the variance of the daily anomalies about μ y and σ y 2 the variance of μ y about the global mean μ combining the distributions in yields 13 z n μ σ d 2 σ y 2 which is equivalent to equation 2 where σ 2 σ d 2 σ y 2 2 2 1 parameter inference due to the hierarchical nature of the model estimation of the model parameters needs to be undertaken in stages the first stage involves fitting the global parameters a b μ σ d σ y a maximum a posteriori estimate of these parameters is obtained by optimisation the posterior density function is given by 14 p a b μ σ y σ d x p a b μ σ y σ d y 1 y μ y i 1 i p x y i μ y σ d p μ y μ σ y d μ y where x y i is the transformed rainfall for i th day of year y the likelihood function p x y i μ y σ d is given by equation 4 and the prior distributions 15 p a b μ σ d σ y p a p b p μ p σ d p σ y 16 p a 1 a 1 p log b n 0 1 p μ 1 p log σ d 1 p σ y 2 1 σ y 2 0 5 2 σ y 2 0 0 where a half cauchy prior on σ y 2 is recommended by gelman 2006 for hierarchical variances and the remaining priors are consistent with the non hierarchical model computation of the posterior density function requires the integration over μ y for every set of parameters given that μ y follows a normal distribution gauss hermite integration can be used to efficiently compute the integrand using a small number of samples of μ y for given values of a b μ σ y σ d once the global parameters are obtained the values of μ y for each year can be estimated using the following likelihood 17 p μ y μ σ y σ d x y p x y μ y σ d p μ y μ σ y i 1 i p x y i μ y σ d p μ y μ σ y 2 2 2 quantile mapping procedure the above formulation can be used for a two stage quantile mapping technique where mapping is initially applied to the monthly mean and subsequently applied to the daily anomalies about that mean in the transformed space the cdf of mean monthly downscaled gcm simulated rainfall is given by 18 f u p μ y p μ p σ y p and the cdf of daily anomalies of downscaled gcm simulations by 19 f d p z p μ y p σ d p similarly for transformed observations the cdf of mean monthly rainfall is given by 20 f μ o μ y o μ o σ y o and the cdf of daily observed anomalies by 21 f o d z o μ y o σ d o combining equations 18 21 quantile mapping can be described by 22 z o f d o 1 f d p z p μ y p σ d o f μ o 1 f μ p μ y p μ p σ y p μ o σ y o σ d o effectively this is a two stages process where stage 1 involves quantile mapping the mean monthly rainfall 23 μ y o f μ o 1 f μ p μ y p μ p σ y p μ o σ y o stage 2 involves quantile mapping the daily anomaly 24 z o f d o 1 f d p z p μ m p σ d o μ m o σ d o 2 3 dealing with autocorrelation both the base and hierarchical approaches to quantile mapping do not make allowance for there being different correlation structures in the downscaled gcm simulations and observations cannon 2016 proposed a multivariate bias correction approach which uses a multivariate normal distribution to model the joint distribution of several different climate variables autocorrelation of rainfall within a multi day period can be considered as a multivariate problem where each day in the period has an identical marginal distribution we extend our base and hierarchical descriptions of the marginal distribution of rainfall by assuming that the joint distribution of transformed rainfall within a calendar month can be described using a multivariate normal distribution for bias correction applications ar1 models have previously been assumed for monthly and annual data e g johnson and sharma 2012 mehrotra and sharma 2012 mehrotra and sharma 2016 methods used for generating stochastic rainfall data at shorter time steps tend to embed higher order autocorrelation functions obeysekera et al 1987 in this study we assume that the autocorrelation of transformed rainfall can be described using an arma 2 1 model with parameters ρ 1 m ρ 2 m η 1 m using this strategy transformed rainfall for a calendar month are assumed to follow a multivariate normal distribution 25 z y m n μ y m 1 i y m σ y m 2 r m where z y m is a vector of transformed rainfall for calendar month m and year y 1 i y m is a vector of ones with the same length as z y m and r m a matrix representing the autocorrelation function the theoretical autocorrelation function for an arma model at lag τ can be derived using the method described by brockwell and davis 1991 the matrix r m is populated with the theoretical autocorrelation function using lag computed from the difference between the column and row index 2 3 1 parameter inference parameter inference follows the almost identically for the cases that ignore the autocorrelation except for the likelihood function the computation of the likelihood function for the multivariate distribution follows the method of wang and robertson 2011 the rainfall vector is separated into two subvectors 26 x y x y m x y n where x y m consists of days where rainfall is above the censor threshold and x y n are less than or equal to the censor threshold the likelihood function for a set of parameters θ μ σ ρ 1 ρ 2 η 1 is then given by 27 p x y θ p x y m x y n x c θ p x y m θ p x y n x c n x y m θ where 28 p x y m i 1 i m j z m i x m i p x y m θ 29 p x y n x c x y m θ p z y n z c n z y m θ z c n p z y n z y m θ d z y n i m is the dimension of x y m and z c n a vector of transformed censor thresholds the size of x y n the conditional distribution p z y n z y m θ is multivariate normal and the computation of the mean vector and covariance matrix can be found in standard statistical texts gelman et al 1995 the rannrm algorithm of genz 1993 are used to perform the numerical integration of the multivariate normal distribution 2 3 2 quantile mapping the approach to quantile mapping when autocorrelation is modelled follows that described by cannon 2018 the steps of the quantile mapping are 1 transform the vector of downscaled gcm rainfall for a given month using the transformation parameters a p b p inferred using the downscaled gcm data 2 augment any censored values using a gibbs sampler see wang and robertson 2011 for details 3 standardise the augmented vector of transformed downscaled gcm rainfall from step 2 to give a vector of correlated standard normal variates by subtracting by the mean μ y p and dividing by the standard deviation σ y p inferred using the downscaled gcm data 4 rotate the correlated standard normal variates from step 3 using the inverse of the cholesky decomposition of the matrix r p for the downscaled gcm rainfall to give a vector of uncorrelated standard normal variates 5 rotate the uncorrelated standard normal variates from step 4 using the cholesky decomposition of the matrix r o for the observed rainfall to give a vector of correlated standard normal variates following the correlation structure of the observations 6 unstandardise the vector of correlated standard normal variates from step 5 by multiplying by the standard deviation σ y o and adding the mean μ y o inferred using the observations 7 back transform the output of step 6 using the transformation parameters a o b o inferred using the observations 8 set negative values in the output of step 7 to zero 3 assessment of quantile mapping methods the previous section describes four possible approaches to quantile mapping 1 basic daily quantile mapping neglecting autocorrelation 2 hierarchical quantile mapping neglecting autocorrelation 3 basic daily quantile mapping allowing for autocorrelation 4 hierarchical quantile mapping allowing for autocorrelation our motivation in developing the more sophisticated quantile mapping methods is to address limitations of simpler approaches for hydrological simulation applications we therefore assess the performance of the different approaches for with respect to bias corrected rainfall and also for hydrological simulations 3 1 rainfall we assess the efficacy of the four bias correction methods in a cross validation mode an interwoven two fold cross validation scheme is adopted similar to that applied adopted by corney et al 2013 to assess the out of sample performance of the quantile mapping schemes under this cross validation scheme the available data set is separated into two subsets one used for fitting the quantile mapping distributions and one used to evaluate the quantile mapped data the two subsets are then swapped and the statistical characteristics of the entire quantile mapped dataset are evaluated for this study the subsetting strategy is to use every second year so that any long term trends or step changes in either the gcm or observed data are present in both the fitting and evaluation subsets this strategy seeks to address the many limitations of cross validation identified by maraun 2016 we firstly evaluate the ability of the parametric distributions to describe the marginal distribution of observed and downscaled gcm rainfall using the approach described by robertson et al 2013 the best fit distribution parameters are obtained using the methods described in the previous section and all available data a set of samples equal in length to the number of observations used to fit the model is drawn from the fitted distribution the set of samples represents one realisation of the cumulative marginal distribution to represent the sampling uncertainty associated with taking a limited set of samples from the marginal distribution multiple 1000 realisations of the cumulative distribution are generated and summarised using the median and the 0 025 0 975 quantile ranges for each percentile graphical comparisons of the marginal distributions are compared to the observations in a probability plot we compare the efficacy of the four bias corrections methods by computing a range of metrics that reflect the bias in the annual and monthly mean rainfall and also in metrics relevant for hydrological modelling including the length of wet and dry spells the magnitude of three day rainfall totals and the persistence of daily rainfall specifically the lag one autocorrelation dry dry day probability and wet wet day probability 3 2 hydrological simulations hydrological modelling was undertaken using the gr4j rainfall runoff model perrin et al 2003 model parameters were calibrated for each catchment using the shuffled complex evolution algorithm duan et al 1994 duan et al 1993 by optimising a compound objective function the adopted objective function is 30 of 1 n s e 5 log 1 b i a s 2 5 where 31 nse 1 t 1 t q s t q o t 2 t 1 t q o t q o 2 32 bias q s q o q o and nse is the nash sutcliffe efficiency nash and sutcliffe 1970 q s t is the simulated streamflow for time step t q o t is the observed streamflow q s is the mean simulated streamflow q o is the mean observes streamflow and t the total number of time steps streamflow simulations are generated using a hydrological model calibrated to observed streamflow see supplementary material for calibration performance assessment absolute bias in streamflow simulations is computed by comparing the streamflow simulations generated using the bias corrected rainfall generated in fitting mode to streamflow simulations generated using observed forcing by computing bias using this approach the ability of the hydrological model to represent observed streamflow is disregarded we also focus our efforts on assessing the sensitivity of hydrological modelling to assumptions in rainfall bias correction methods and therefore we use the observed pe data for all streamflow simulations the impact of rainfall bias correction methods on streamflow simulations are assessed by computing the bias of the mean daily streamflow and for a range of daily streamflow percentiles as we are investigating bias correction methods that modify the persistence in rainfall we also assess biases in measures of streamflow persistence particularly the length of simulated low and high flow periods and percentiles of streamflow accumulations over 3 and 10 day periods and also accumulations over periods of 1 3 6 and 12 months 3 3 catchments and data eleven catchments in south eastern australia are used in this study fig 1 table 1 the catchments are important for sources of irrigation or urban water supply and all but one have previously been used by charles et al 2020 and potter et al 2020 where they demonstrated the limitations of many existing simple bias correction schemes rainfall and potential evaporation pe data for the study catchments is derived from the gridded analysis produced by the australian water availability project awap jones et al 2009 raupach et al 2008 streamflow observations for the catchments are obtained from the victorian government hydrological data archives https data water vic gov au bias correction methods are applied to readily available dynamically downscaled simulations from the narclim new south wales and act regional climate modelling project https www ccrc unsw edu au sites default files narclim index html the narclim project adopted 3 configurations of the wrf weather research and forecasting regional climate model to two different reanalysis products ncep ncar reanalysis and era interim and four gcms cccm3 1 csiro mk3 0 echam5 and miroc3 2 from the coupled model intercomparison project phase 3 cmip3 detailed descriptions of the downscaling methods are described by evans et al 2014 in this study only the historical simulations of the downscaled gcm rainfall data are considered and analysis of the performance of the bias correction methods is performed separately for the downscaled reanalysis and gcm simulations all analysis uses data for the period 1990 2009 inclusive 4 results 4 1 fit of marginal distributions the daily marginal distributions fitted using the hierarchical and non hierarchical methods with and without allowing for autocorrelation display few differences fig 2 and fig 3 the high daily rainfall values are better fitted for the observed rainfall than the downscaled rainfall for the example shown but this is not always the case the large rainfall values of the distributions fitted using autocorrelation tend to be slightly smaller than those where autocorrelation is neglected in all cases nearly all the observations lie within the 95 uncertainty intervals of the fitted distributions and the probability of zero rainfall is well matched on occasion the largest rainfall observation does fall outside the 95 uncertainty interval not shown this can be expected as the probability of largest values within the limited 20 years used in this study is highly uncertain in general the fitted parametric distribution does describe the key features of the marginal distribution of the observations and would therefore appear to be adequate for quantile mapping purposes however the fit of the parametric distribution is not perfect for either the gcm or observed rainfall and as a result bias corrections performed using the fitted distributions for quantile mapping may not totally eliminate all bias differences in methods for fitting the marginal distribution emerge in the distributions of total monthly rainfall fig 4 and fig 5 derived from the daily distributions presented in fig 2 and fig 3 the variance of monthly rainfall totals derived from data generated using the non hierarchical parametric distribution that does not consider autocorrelation is considerably lower than for the other methods fig 4 the lower variance of monthly rainfall totals is illustrated by the flatter blue lines in fig 4 that poorly describe the highest and lowest monthly totals this limitation arises because the sampled daily rainfall is purely random adopting a hierarchical method or allowing for autocorrelation in the fitted marginal distribution induces structure in the sampled daily rainfall and improves the ability to describe the distribution of monthly rainfall totals the distributions of monthly rainfall totals derived using the combination of the hierarchical method and allowing for autocorrelation tend to better characterise the highest and lowest monthly rainfall values 4 2 evaluation of bias corrected rainfall quantile mapping reduces the large biases of annual and monthly rainfall in both downscaled gcm and reanalysis rainfall to nearly zero fig 6 for all months the interquartile range of bias is smaller than 10 but in some months the bias after quantile mapping for a small number of catchments gcm and downscaling can be as high as 20 as indicated by the whiskers of the box plots these residual biases are likely to be an indication that the parametric description of the marginal distribution is inadequate in some instances differences in the annual and monthly bias between the quantile mapping approaches are small and can be considered inconsequential fig 6 however differences between the quantile mapping approaches do become evident when evaluating rainfall sequencing metrics fig 7 quantile mapping approaches that ignore differences in autocorrelation between the observed and downscaled gcm data display residual bias in many of the rainfall sequencing metrics these biases are practically eliminated using approaches that consider autocorrelation for bias correction of downscaled outputs from both reanalyses and host gcm this is particularly evident for the mean dry spell length mean wet spell length lag one autocorrelation and consecutive wet and dry day probabilities pww and pdd respectively bias correction methods that ignore autocorrelation appear to increase bias of some rainfall sequencing metrics relative to the raw downscaled gcm data for example the lag one autocorrelation and mean wet spell length differences in the bias of rainfall sequencing metrics between the hierarchical and non hierarchical mapping methods tend to be very small where there are differences there is no clear pattern as to which is the better performing method with the hierarchical method displaying smaller and less variable bias for some metrics and the non hierarchical method displaying similar characteristic for other metrics this suggests that the effects of between year variations in rainfall are likely to vary considerably between catchments fig 6 and fig 7 also highlight there are differences in the bias characteristics of the raw downscaled reanalysis and historical gcm simulations the raw downscaled reanalysis tends to have lower bias in monthly and annual means and also in many rainfall sequencing metrics than the downscaled gcm data the bias corrected reanalysis also tends to display smaller and less variable residual bias than the bias corrected historical gcm simulation this suggests the bias correction methods are likely to perform more consistently when the correcting smaller biases 4 3 evaluation of streamflow simulations streamflow simulations generated using bias corrected rainfall are considerably less biased than those generated using the raw downscaled gcm and reanalysis rainfall and the variability of the bias is considerably smaller fig 8 a median negative bias of approximately 0 1 mm day 10 exists in mean streamflow simulations generated using bias corrected rainfall and the bias correction methods that consider autocorrelation reduce this bias by up to 2 of the mean daily streamflow however the bias does not manifest equally across all flow percentiles for all bias correction methods the bias correction methods that do not consider autocorrelation tend to produce streamflow with smaller bias for low streamflow percentiles and much larger bias for the highest streamflow percentiles compare to those that do consider autocorrelation for the low streamflow percentiles while there are substantial differences in between the bias correction methods in percentage terms in absolute terms there are very small however for the high streamflow percentiles both the large differences between the bias correction methods in percentage terms do manifest in large difference in absolute terms as well this suggests the smaller bias in mean daily flow as a result of considering the autocorrelation in the rainfall bias correction is primarily due to the lower bias in the high streamflow percentiles biases in the streamflow simulations generated using the bias corrected gcm rainfall are also typically larger than the simulations generated using bias corrected reanalysis rainfall when autocorrelation in rainfall is not considered while they behave similarly when autocorrelation is considered in the temperate catchments considered in this study high percentile streamflow predominantly results from multi day wet sequences that refill catchment water stores therefore the ability of a bias correction method to produce multi day wet sequences in bias corrected time series will influence the bias in high percentile streamflow simulations our results indicate that the multi day wet sequences and high percentile streamflow simulations can only be realistically reproduced using bias correction methods that consider autocorrelation the importance of multi day sequences of rainfall to produce high streamflow percentiles may also explain why when autocorrelation is not considered biases in streamflow simulations produced using the bias corrected reanalysis rainfall are smaller than those produced using the bias corrected gcm as reanalysis products are generated by assimilating atmospheric observations after downscaling they are more likely to reflect actual temporal climate sequences than uninitialized gcms however even though the downscaled reanalysis is more likely to reproduce realistic temporal climate sequences bias in high percentiles of streamflow simulations is likely to still be present unless bias correction methods consider autocorrelation we further illustrate the effects of allowing for autocorrelation in the rainfall bias correction method by examining its effects on the bias in the high percentile flow accumulations over 3 and 10 day periods and the length of low and high flow sequences fig 9 differences between the rainfall bias correction methods are minimal for the 90th percentile 3 and 10 day streamflow accumulations this is also true for lower percentiles not shown however for the 95th and 99th percentile 3 and 10 day streamflow accumulations the rainfall bias correction methods that consider autocorrelation do display lower bias those that neglect autocorrelation these very high percentile 3 and 10 day streamflow accumulations require multi day sequences high rainfall amounts to occur which seems only to be possible if autocorrelation is considered in the bias correction method however accumulations for the 90th and lower percentile streamflow accumulations could possibly occur as a result of a multi day rainfall sequence or during the recession following a very high streamflow event when effects of rainfall on streamflow are reduced and therefore the effects of including autocorrelation in the bias correction method are minimal bias correcting rainfall forcing reduces bias in the length of simulated high and low flow periods bias in the length of both high and low flow periods is also influenced by the bias correction method with the methods considering autocorrelation displaying lower bias that those that don t the hierarchical bias correction methods also display lower bias than the non hierarchical method for the low flow periods the bias correction methods that consider autocorrelation produce close to zero bias particularly for the simulations produce using bias corrected gcm data however for the high flow periods the negative biases of the simulations generated using raw downscaled translate into positive biases for the simulations using bias corrected rainfall albeit of a smaller magnitude this suggests that order of the arma model adopted for the bias correction may be too high for the actual rainfall observations projections of streamflow are often used to assess the adequacy of a range of water resources management strategies including reservoir reliability analyses that are sensitive to streamflow accumulations over periods of months and years we assess the impact of the different bias correction methods on the multi month streamflow accumulations fig 10 at all timescales the bias of streamflow simulations generated using bias corrected rainfall is lower than the bias of simulations generated using the raw downscaled gcm and reanalysis rainfall as with the 3 and 10 day accumulations differences between the bias correction methods are small for the 90th percentile 1 3 6 and 12 month streamflow accumulations differences do exist for the 95th and 99th percentile accumulations with the bias correction methods that consider autocorrelation displaying biases that are closer to zero than those that don t consider autocorrelation 5 discussion here we have described modifications to standard quantile quantile matching methods that can address the limitations in using bias corrected rainfall for streamflow simulation charles et al 2020 teng et al 2015 teutschbein and seibert 2012 the modifications involve applying quantile mapping simultaneously to daily and multi day in this paper monthly rainfall and by explicitly accounting for differences in the autocorrelation structures of observed and downscaled gcm rainfall our result show that allowing for difference in autocorrelation improve rainfall sequencing metrics and that under cross validation the hierarchical approach produces slightly smaller bias in mean rainfall than simple daily quantile quantile mapping the study of charles et al 2020 found that bias corrected rainfall led to under estimation of simulated mean annual streamflow and in high flow percentiles our results produced using a standard quantile quantile method demonstrate similar under estimation of mean streamflow and of high flow percentiles reported by charles et al 2020 while our results show that the under estimation of streamflow particularly high flow percentiles is reduced by both modifications to standard quantile mapping we introduce the greatest improvement arises from allowing for differences in rainfall autocorrelation between observed and downscaled gcm rainfall in the catchments considered in this study streamflow dynamics are strongly influenced by high and low frequency climate variability our results suggest that inadequate representation of high frequency variability as characterised by rainfall autocorrelation leads to underestimation of high streamflow percentiles and overall negative bias in streamflow simulations therefore methods for correcting bias in climate change projections for hydrological applications require rainfall autocorrelation to be corrected in addition to the properties of the daily rainfall distribution conceptually the hierarchical quantile mapping approach also allows for corrections to be made to the amplitude of low frequency variability evaluation of the benefits of the hierarchical approach to quantile mapping for correcting low frequency variability will be investigated in a future study in this study we have evaluated the effects of our bias correction approaches applied to downscaled gcm simulations and reanalysis for historical periods the most common application of bias correction methods is in the assessment of the impacts of future climate change hydrological climate change studies typically characterise the changes in streamflow simulations between a historical and future period using the same downscaled gcm product therefore the ability to reduce bias in a gcm forced streamflow simulations for historical periods relative to the simulations forced by observed climate data may not necessarily result in materially different conclusions on the effects of climate change investigations into the sensitivity of climate change projections will be reported in a future study this study has applied bias correction methods that adjust the mean variance and skewness of the marginal distribution and temporal correlation structure the methods have been evaluated using an application to correct downscaled gcm and reanalysis for historical periods with concurrent but assumed asynchronous observations to correct bias in downscaled gcm projections of climate changes requires assumptions to be made about the consistency of the parameters of the bias corrections between historical and future periods one approach is to assume that the parameters inferred using historical observations and gcm simulations can be applied to future periods charles et al 2020 potter et al 2020 if the change between the historical and future periods is large this approach is potentially limited by the ability of the parametric marginal distribution to extrapolate beyond the range of data used in parameter estimation it also assumes that the autocorrelation of downscaled gcm simulations and observations in the transformed space does not change an alternative approach is to preserve some or all changes in distributional characteristics between historical and future downscaled gcm projections in the distribution of the observations and apply quantile mapping using modified marginal distributions this approach has been used to preserve changes in the mean cannon 2018 mehrotra and sharma 2016 and temporal or spatial correlation bárdossy and pegram 2012 mehrotra and sharma 2016 or full marginal cumulative density function robin et al 2019 between historical and future downscaled gcm projections as a part of a quantile mapping algorithm the potential limitation with this approach particularly if parametric descriptions of marginal distributions are adopted is that parameters can be conditionally dependent meaning that the process of adjustment of individual properties is not straightforward further investigation is needed to establish the most appropriate approach to apply quantile mapping to future projections when changes between the historical and future periods are large such an investigation would require historical data with changes similar in magnitude to be able to validate any findings the hierarchical approach to bias correction introduced in this paper adopted a two level hierarchy extension of the hierarchical structure to more than two levels may be desirable to better represent variability at different temporal scales or to handle seasonal effects in a single model while extension of the hierarchical structure is possible as the number of levels in the hierarchy increases parameter estimation becomes increasingly challenging each additional layer in the hierarchy requires an additional numerical integration in the computation of the likelihood function therefore even when computationally efficient numerical integration methods are used parameter estimation may become computationally infeasible from a practical perspective in the current study parameter estimation for the two level hierarchical approach required considerably more computational time than the non hierarchical equivalent and therefore even using a three layer model may be computationally prohibitive in this study we apply bias correction to a single variable at a single location hydrological applications are likely to also require coherent bias corrected gcm data for multiple variables and or locations the approach used here to consider temporal correlations as a part of the bias correction adapts approaches used to model spatial and inter variable correlation structure bárdossy and pegram 2012 cannon 2018 therefore generating bias corrected data that display appropriate spatial and intervariable correlations is a direct extension of the bias correction described here however increasing the number of correlation dimensions considered can induce instability in some analogous bias correction methods and ultimately degrade desired statistical features e g spatial correlations primarily due to the limited data available to estimate high dimension correlation structures françois et al 2020 extending the approach described here to consider spatial and inter variable correlation would therefore require investigation to mitigate against potential instabilities which may include parameterized correlation structures or other methods to reduce the number of effective dimensions several authors argue that stochastic bias corrections are necessary to overcome the inability of many gcm and rcm models to reproduce the fine scale spatial and temporal variability mao et al 2015 maraun 2016 robin et al 2019 yuan et al 2019 an element of stochasticity can be generated using the bias correction methods introduced in this paper that consider autocorrelation and all similar methods step 4 of the bias correction procedure in the methods that allow for autocorrelation rotates standard normal variates to remove any correlation before step 5 applies a different rotation to instil correlations that reflect the observations theoretically after step 4 the resultant variates are independent in this study we maintain the order of the independent variates between steps 4 and 5 however as they are independent these variates could be reordered to introduce an element of stochasticity in the bias corrected data this stochasticity would primarily be different of climate sequences that all follow the transformed marginal distribution of the observations the catchments we have investigated in this study are limited to the temperate zones of south eastern australia while the catchments do have diverse hydrological characteristics including one catchment that is intermittent the rainfall characteristics are broadly similar for all catchments these catchments display cool wet winters where rainfall is primarily from extra tropical frontal weather systems and warm dry summers therefore the benefits of including autocorrelation in rainfall bias correction methods may be limited to similar temperate regions further work is required to investigate the efficacy of the bias correction methods introduced in this manuscript regions with differing rainfall seasonality and processes for example in tropical and monsoonal regions where rainfall persistence may be better represented in the downscaled gcm and reanalysis products or of lessor importance for streamflow simulation finally in this study we used dynamically downscaled simulations from a subset of host cmip3 gcms to demonstrate our method cmip5 and cmip6 provide more recent climate simulation and projection data with newer generations of climate models that are higher resolution and improved parameterizations bias in the raw gcm rainfall output from all cmip experiments tends to be very large and therefore for this study we used dynamically downscaled simulations dynamical downscaling of gcm output can add value by reducing bias particularly in areas of complex topography di virgilio et al 2020 since commencing this work new downscaled gcm data forced by cmip5 models has been released nishant et al 2021 while these new simulations show reduced bias and improved seasonal patterns in precipitation biases remain large requiring the correction for hydrological applications nishant et al 2021 therefore bias correction methods such as those introduced here will continue to be required for hydrological impact modelling 6 conclusions global climate models provide important insights into future climate change however inconsistencies between the statistics of downscaled gcm simulations and observations mean that bias correction is an integral part of any assessment of the hydrological consequences of climate change while a wide range of techniques have been developed to correct bias in different aspects of gcm simulations extending from simple univariate methods to approaches that explicitly consider spatial temporal and inter variable dependence structures there are few comparisons of the impact of different bias correction assumptions on hydrological simulations this paper uses a consistent statistical framework to investigate the importance of i simultaneously correcting bias at multiple time scales and ii explicitly handling rainfall autocorrelation in quantile mapping of gcm rainfall for hydrological simulation four quantile mapping methods are applied to correct bias in dynamically downscaled reanalysis and historical gcm projections of rainfall for 11 catchments in south eastern australia and the performance of bias corrected rainfall and streamflow simulations is evaluated all quantile mapping methods investigated can effectively eliminate bias in monthly and annual rainfall totals quantile mapping methods that consider differences in the temporal dependence autocorrelation structure of gcm and observed rainfall are most effective in reducing bias in rainfall sequencing statistics such as probability of consecutive wet or dry days for streamflow simulations mean and high streamflow percentiles over multiple time periods are underestimated when generated using rainfall that is corrected with quantile mapping methods that do not consider differences in the temporal dependence structure of gcm and observed rainfall rainfall forcing generated using quantile mapping methods that correct temporal dependence autocorrelation structures produce in streamflow simulations with lower often close to zero bias in mean and high percentiles estimates across time period of days to months in this study we investigated alternative bias correction methods for historical periods further investigations will assess the sensitivity of future projections to bias correction methods including the importance of explicitly preserving changes in some or all the distributional characteristics of gcm simulations between future and historical periods given our findings on the importance of explicitly handling rainfall autocorrelation in quantile mapping for hydrological applications future work will also investigate the most appropriate methods to characterise temporal and where necessary spatial and inter variable dependence structures credit authorship contribution statement david e robertson conceptualization methodology software formal analysis investigation validation writing original draft writing review editing francis h s chiew conceptualization funding acquisition investigation methodology writing review editing nicholas potter conceptualization data curation investigation writing review editing declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests david e robertson reports financial support was provided by victoria department of environment land water and planning francis chiew reports financial support was provided by victoria department of environment land water and planning nick potter reports financial support was provided by victoria department of environment land water and planning acknowledgements this work was conducted on the traditional lands of the boonwurrung wurundjeri peoples of the kulin nation and also the ngunnawal and ngambri peoples we acknowledge their continuing custodianship of these lands and the rivers that flow through them and pay our respects to their elders past and present we also acknowledge the traditional custodians of the catchments and rivers used in this study this research has been supported by the victorian water and climate initiative we thank hongxing zheng and steve charles both csiro for supplying the catchment data an r package used for bias correction is available on request license conditions apply appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2023 129322 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
