index,text
2680,this study assesses future projections of flood hazards across the italian river basins for this purpose sub daily river discharge for the entire italian territory was simulated with the cetemps hydrological model chym using as climate forcing both observational datasets and regional climate simulations completed with the ictp regional climate model regcm4 first simulated precipitation and river discharge were evaluated against observational products showing both models good performance in simulating italian precipitation and discharge characteristics then projections of these variables were explored for two time slices near 2020 2049 and far 2070 2099 future under the rcp8 5 emission scenario with regcm4 driven by output from a global climate model projection the regcm4 outputs were also bias adjusted by means of the n dimension multivariate bias correction mbcn method we found that although the bias correction leads to a benefit in capturing mean precipitation the improvement is less clear for extreme precipitation in terms of discharge however bias correction has a noticeable impact on mean discharge as well as average yearly peak flow and hourly peak flow at return periods of 10 50 and 100 years nevertheless for a large part of the italian territory projected changes in mean precipitation and discharge do not show significant differences when bias correction is applied while for extreme events only 30 of river points show significant sensitivity to bias correction under the rcp8 5 scenario an increase in yearly peak flow is evident over most of the italian peninsula with values increasing from 30 to more than 100 for the mid and far time slices respectively especially over the po river and along the eastern coasts of italy similar conclusions are found for the hourly peak flows of 10 50 and 100 year return periods these indicators thus suggest a general increase in flood hazard expected over the region keywords chym model regcm4 model climate change floods extreme river discharge data availability data will be made available on request 1 introduction flood is one of the most devastating natural disasters leading to severe impacts on society and ecosystems according to the centre for research on the epidemiology of disasters cred 2021 only in 2020 over 33 million people worldwide were affected by floods and 6171 people died italy is prone to natural disasters due to its complex topography and climate variability according to mysiak et al 2013 30 of the italian territory is highly vulnerable to landslide and flood events both separately and in combination in particular from 2000 to 2019 flood occurrences in italy resulted in economic damages of almost 18 5 billion em dat 2022 flood hazard estimation is therefore an essential tool for developing reliable adaptation strategies in recent decades many studies have focused on the assessment of the impacts of climate change on precipitation from these studies one can conclude that there is a relatively robust agreement that extreme precipitation is mostly projected to increase both in frequency and intensity under global warming conditions e g christensen and christensen 2007 nikulin et al 2011 pendergrass and hartmann 2014 coppola et al 2021 nevertheless how changes in atmospheric variables will affect river discharge is still under investigation particularly when focusing on extreme events at regional scales andersen and marshall shepherd 2013 flooding is expected to be strongly affected by changes in climatic patterns as an increase in extreme precipitation is likely to lead to enhanced flood generating processes whitfield 2012 however the link between extreme precipitation and the occurrence of flood events is not necessarily linear in that flood occurrence also depends on complex relationships between snow accumulation and melting underground water flow and local channel characteristics for this reason the assessment of the interplay between the spatiotemporal patterns of changes in precipitation and discharge is a research topic of great interest assessments of the future flood hazard over large basins are commonly performed by coupling global climate models gcms with land surface schemes and hydrological models e g alkama et al 2013 arnell and gosling 2016 dankers et al 2014 prudhomme et al 2003 sperna weiland et al 2012 the low resolution of gcms however prevents similar assessments for small regional scale river basins in this case an increased resolution is required huang et al 2019 especially for capturing extreme events such as floods therefore regional climate models rcms have become increasingly popular because they can describe regional climates by considering sub gcm grid scale forcings e g local topography coastlines or land cover distribution and dynamical processes occurring at high spatial resolution of roughly 10 50 km giorgi 2019 the increase in temporal resolution is also important for correctly representing flood peaks especially for small catchments zhu et al 2018 this is because small catchments due to their low storage capacity and fast reaction time to water displacements are more vulnerable to the occurrence of short duration storms authors such as yang et al 2016 studied the impact of the temporal resolution of climate data used as input to hydrological models and found that hydrological simulations driven by sub daily climate variables can capture much better the peak flow values compared to models driven by daily climate input several studies using rcm outputs to drive hydrological models for the european continent e g alfieri et al 2018 2015 dankers and feyen 2009 feyen et al 2012 prudhomme et al 2003 generally find increasing flood hazards mostly over the central european region and especially in terms of higher frequency of occurrence alfieri et al 2015 small river catchments in central and southern europe would be more affected by an increase in flood magnitude associated with an increase in extreme convective precipitation events in contrast over the northeast european region snow melting is the main driver of the major floods and a decrease in snow accumulation during the snow season would lead to a decrease in flood magnitude this is observed in particular for large river catchments di sante et al 2021 vautard et al 2021 since climate models are often affected by systematic model biases bias correction is considered a crucial step in using model outputs for impact studies e g casanueva et al 2016 christensen et al 2008 piani et al 2010 however this method is not free of controversy in particular when dealing with extreme value correction for example ehret et al 2012 pointed out that bias correction must be performed with caution since it introduces new sources of uncertainty that occasionally can become large climate change impact assessments therefore should be performed considering both raw and bias corrected climate model data a large number of bias correction approaches have been proposed in recent years e g boé et al 2007 cannon 2018 cannon et al 2015 gómez navarro et al 2018 kim et al 2021 piani et al 2010 several authors investigated the ability of these procedures to correct different climate variables using a wide range of evaluation methods argüeso et al 2013 fang et al 2015 gudmundsson et al 2012 gutjahr and heinemann 2013 lafon et al 2013 maraun 2016 themeβl et al 2012 2011 however most studies focus on analyzing climate data at a daily scale and therefore how the correction modifies sub daily simulated values and the resulting effect on sub daily discharge remains not well understood despite the fact that the italian region is frequently affected by severe inundation events scientific studies concerning flood hazard estimation over this region are few moreover most of these studies focus on limited areas or small basins di salvo et al 2017 marchesini et al 2016 morelli et al 2014 sole et al 2008 specific past events amadio et al 2013 marchi et al 2010 masoero et al 2013 norbiato et al 2007 santo et al 2012 or target flood risk rather than hazard albano et al 2017 dottori et al 2016 salvati et al 2010 therefore in this study we aim to assess the current state and future evolution of flood hazards throughout the entire italian territory towards this goal river discharge for the italian territory was simulated using the cetemps hydrological model chym coppola et al 2007 by feeding it with climate data from both high resolution observational datasets and two rcm simulations specifically we use output from the ictp regional climate model regcm4 giorgi et al 2012 at 12 km spatial resolution to resolve the spatial and temporal climate detail within the river catchments analyzed gosling et al 2011 whitfield 2012 furthermore we investigate the impact of using bias corrected climate outputs at a sub daily temporal scale for both present and future conditions under an increased greenhouse gas concentration scenario the paper is structured as follows in section 2 we describe the data and methods used section 3 presents the results obtained and section 4 discusses and highlights the main findings of this work 2 data and methods 2 1 observations precipitation is the main atmospheric component controlling the hydrological response in catchments and thus plays a critical role in hydrological simulations chiew et al 2009 ly et al 2013 obled et al 1994 however it is also one of the most challenging variables to characterize due to its high spatiotemporal variability hence the use of different precipitation products is highly recommended when evaluating climate models particularly at the regional scale prein and gobiet 2017 table 1 lists the observed precipitation gridded products we have used to evaluate regcm4 the alpine precipitation dataset euro4m apgd isotta et al 2014 and the northern central italy daily precipitation dataset arcis pavan et al 2019 are high resolution high quality station based gridded products developed from dense observation networks across the alps and north central italian regions respectively e obs haylock et al 2008 is a set of european wide observations that have been widely applied for model evaluation purposes in this study the daily precipitation version 20 0e was used cornes et al 2018 we also consider the hirlam mesan reanalysis hmr landelius et al 2016 a european regional reanalysis based on downscaling and data assimilation techniques finally the recently developed high resolution gridded italian precipitation hourly observations dataset gripho fantini 2019 fantini et al 2022 is used to feed chym and to bias correct the simulated precipitation values to evaluate the hydrological model observation datasets of river discharge from two sources were collected table 2 hourly discharge datasets encompassing the po river the upper po river and the entire italian territory were provided by the university of l aquila in addition we use the long term daily discharge data from the european water archive ewa ewa 2014 finally the era5 reanalysis product from the european centre for medium range weather forecasts ecmwf reanalysis hersbach et al 2020 is used as a reference dataset to correct the regcm4 temperature data this selection was based on data availability as this reanalysis provides hourly outputs with a grid resolution of 31 km and is a product with an accurate representation of temperature tarek et al 2020 2 2 climate simulations the regcm4 model version 4 6 1 was used to complete two regional climate simulations covering the entire european region according to the euro cordex domain specifications jacob et al 2014 with a spatial resolution of 12 km on a lambert conformal conic projection both simulations were carried out with the same configuration and differ only in the initial and lateral boundary conditions lbcs in the first the ecmwf era interim reanalysis product dee et al 2011 provides the lbcs hereafter referred to as regcm era for the period 1979 to 2016 the second simulation completed as part of the producing regional climate projections leading to european services project principles https www gerics de science projects detail 071974 index php en is driven by the met office hadley centre hadgem2 es cmip5 gcm hadgem2 es collins et al 2011 hereafter referred to as regcm had for the period 1971 2099 for the latter the period from 2006 to 2099 was completed under the representative concentration pathway 8 5 rcp8 5 moss et al 2008 riahi et al 2007 2 3 bias correction here we use the n dimension multivariate bias correction mbcn algorithm developed by cannon 2018 to correct sub daily precipitation and temperature outputs from both regcm era hereafter referred to as regcm era bc and regcm had hereafter referred to as regcm had bc this method combines a correction of climate simulation outputs via quantile delta mapping qdm cannon et al 2015 with the adjustment of dependency structures using an n dimensional probability density function transform algorithm pitié et al 2007 2005 mbcn thus preserves the projected changes in the simulated quantiles by using qdm which has proven to represent well extreme values in future projections cannon et al 2015 and yields more physically consistent data accounting for inter variable dependencies françois et al 2020 the algorithm utilizes a multi step process in which the original datasets are multiplied by random orthogonal matrices before being corrected then the resulting datasets are rotated back to obtain the final bias corrected data this multi step process is applied iteratively until the multivariate distributions of bias corrected data and the observed distributions converge three hourly precipitation and temperature outputs from regcm4 were extracted and bias corrected based on the observations from gripho for precipitation and era5 for temperature using the mbc r package cannon 2020 mbcn was calibrated using observations from 2001 to 2016 which corresponds to the entire gripho period because the observations have an hourly frequency they were transformed from 1 hour to 3 hour data hence 3 hourly precipitation corresponds to the average over the three hours at the end of a given time step i e 00 03 06 09 12 15 18 and 21 conversely temperature is the instantaneous value at the same three hourly interval an mbcn with 30 iterations was applied for each month separately using three month windows centered on each calendar month for precipitation the dry days threshold was set to 0 05 mm according to cannon 2018 2 4 hydrological model the chym model version 6 07 was used to simulate hourly streamflow over the entire italian territory chym is a spatially distributed grid based hydrological model initially developed by the center of excellence in telesensing of the environment and model prediction system cetemps of the university of l aquila it was specially designed for flood prediction tomassetti et al 2005 verdecchia et al 2008 but it has been also applied in hydro climatological studies over different regions of italy europe and south asia coppola et al 2014 di sante et al 2021 2019 fantini 2019 sangelantoni et al 2019 moreover its routing scheme was employed as the hydrological component in the regional earth system model resm regcm es di sante et al 2019 chym simulates hydrological processes i e surface runoff evapotranspiration percolation infiltration melting and return flow discharge and using a digital elevation model dem recreates an eight flow direction river network employing a cellular automata ca theory based algorithm coppola et al 2007 2006 the surface routing is performed according to the kinematic shallow water approximation from lighthill and whitham 1955 we used the hydrosheds hydrologically conditioned dem with roughly 90 m spatial resolution https www hydrosheds org lehner et al 2008 as this dataset was specifically designed for hydrological applications chym is based on a fortran90 code and runs in a parallel computer architecture using the mpi standard more details of this hydrological model can be found in coppola et al 2007 the italian territory was divided into nine sub regions fig 1 a based on the operational domains used by cetemps for flood forecasting these sub regions defined using stress indices have been demonstrated to be effective in establishing a reliable and feasible river network for the entire italian territory tomassetti et al 2005 verdecchia et al 2008 the nine domains are the po basin liguria north eastern italy central northern italy central italy central southern italy calabria sicily and sardinia the simulations were completed using a specific configuration for each domain with spatial resolution ranging from roughly 300 m for the liguria calabria sicily and sardinia domains to 900 m for the po basin depending on the catchment size orography and administrative boundaries with time steps from 50 s to 400 s the hydrological model parameters were established according to coppola et al 2014 who calibrated the chym model in the upper po basin for climatological application purposes in terms of river dynamics the po basin which has the longest flow discharge time series among the italian rivers can be considered representative of many european rivers thus the same parameters were used for all domains sangelantoni et al 2019 different climate sources were used to run the chym model as shown in table 3 to evaluate the hydrology model performance one simulation fed with observed climate data was completed chym obs at hourly time aggregation for this purpose we used the gripho precipitation dataset and observed near surface temperature data from thermometer networks cima 2014 to fill the gaps in gripho due to missing data daily weather forecasts carried out with the mesoscale model 5 mm5 grell et al 1994 were used following the same procedure adopted for real time weather forecasting by cetemps colaiuda et al 2020 then for each domain two additional simulations were completed in which the chym model was fed with 3 hourly climate outputs from regcm era hereafter referred to as chym era and regcm had chym had see section 2 2 for further details additionally bias corrected climate outputs were also used to simulate the river discharge chym era bc and chym had bc for simulations forced by regcm era bc and regcm had bc respectively different time slices were used depending on data availability for the recent past the chym obs simulations spanned the period 2000 to 2016 and the chym era simulations the period 1979 to 2016 for the chym had simulations three periods were considered the reference period from 1975 to 2005 and two future time slices 2019 2049 near future and 2069 2099 far future for all hydrological simulations the first year was considered as spin up time and therefore it was discarded from the statistical analyses 2 5 evaluation of the climate and hydrological simulations firstly we evaluate the precipitation outputs of the regcm4 simulations and the river discharge from the chym simulations the regcm results are compared to the different observational products in terms of annual cycle mean seasonal precipitation and extreme r99ptot precipitation the latter is computed using only precipitation on wet days pr 1 mm day and represents for each grid point the percentage of precipitation above the 99th percentile the comparison is carried out either by aggregating grid point values over four different homogeneous climate regions fig 1b or by directly comparing grid point values for these analyses the period of each observation dataset varies depending on data availability table 1 but they all cover at least a 30 year period except for gripho whose precipitation time series span from 2001 to 2016 the chym performance is assessed by comparing daily discharge from chym obs to station datasets using the kling gupta efficiency kge skill score metric gupta et al 2009 kling et al 2012 table 4 a similar evaluation is carried out for chym era to assess the coupled regcm chym performance the kge measures the model performance by considering errors in the correlation r bias β and variability α between simulated qsim and observed qobs discharge in this metric r is the pearson s r coefficient β is the bias between simulated q sim and observed mean q obs and α is the ratio between the standard deviation in simulations σsim and observations σobs furthermore each component of the kge is investigated separately allowing model errors to be directly attributed to either correlation bias or variability terms therefore a β value greater lower than 1 indicates an overestimation underestimation of the mean with respect to observations similarly a value of α lower higher than 1 indicates that the simulated daily variability is underestimated overestimated towner et al 2019 in order to assess the potential benefit of using bias correction to simulate the daily river discharge we use the following metric towner et al 2019 1 i ss s s c s s r 1 s s r where ssc represents the different skill score metrics i e kge r α and β computed from the chym simulations fed with bias corrected climate data and ssr those from raw data when iss is positive negative mbcn is considered to provide a better worse skill than the raw data to assess the role of bias correction in terms of extreme values we compare the chym obs simulations with those forced by the regcm4 using both raw and bias corrected outputs the maximum discharge or yearly peak flow for each year and river point is extracted to compute metrics such as the average yearly peak flow q y max the hourly peak flow for different return periods qrps and the annual empirical frequency of events above qrps to that end the yearly peak flows are fitted to a gumbel distribution using a simple maximum likelihood method alfieri et al 2015 di sante et al 2021 fantini 2019 maione et al 2003 and the analytical qrps are estimated then a peak over threshold pot method is applied to the hourly time series of the modeled river flow to determine the annual empirical frequency of extreme discharge a declustering approach is adopted to ensure the independence of events with a time interval between two consecutive flood events determined by the basin area hu et al 2020 2 dt 5 2 59 log a where dt represents the time interval and a is the catchment area in square kilometers 2 6 projections in precipitation and river discharge changes in precipitation and discharge are explored by comparing historical simulations 1976 2005 with those from the two future time slices the near 2020 2049 and the far 2070 2099 future in relative terms analogously to the evaluation the results with and without bias correction are also intercompared for the pot analysis qrps from historical distributions are used as thresholds also for the future 3 results 3 1 validation of the regcm simulations fig 2 compares the annual cycle of precipitation for observations and regcm4 simulations over the four macroregions in general the raw regcm4 data regcm era regcm had accurately capture the shape of the annual precipitation cycle in the four macroregions although with some discrepancies compared to observations regcm4 tends to overestimate spring precipitation especially in the northern and central italian regions while it underestimates autumn precipitation in the north in particular regcm had overestimates precipitation in summer over the central islands and southern regions as expected when the bias correction is applied to the regcm4 outputs these model biases are considerably improved see results from regcm era bc and regcm had bc for seasonal mean precipitation fig 3 regcm era and regcm had accurately reproduce the autumn and winter precipitation peaks observed in gripho and hmr over the southwestern coasts of italy these simulations successfully capture the precipitation peaks over the alps found in all observation datasets in the spring summer and autumn but they tend to produce isolated hot spots particularly in the summer both raw simulations moreover produce similar italian precipitation climatologies suggesting that independently of the driving data regcm4 is able to correctly reproduce the main precipitation climatological features over italy however the raw simulations also show underestimated precipitation values during winter over the gulf of genoa liguria and the po plain when compared to hmr e obs and gripho with values up to 5 and 8 mm day for simulated and observed precipitation respectively in contrast summer precipitation is overestimated over most of sardinia particularly when compared to hmr and e obs bias corrected precipitation shows significantly better spatial agreement with observations fig 3 moreover the results clearly demonstrate the influence of the dataset used as reference for example the bias corrected precipitation outputs and gripho exhibit higher precipitation values compared to the other observational datasets in the winter over calabria fig 4 reports the extreme r99ptot for both observations and simulations overall extreme precipitation from the raw simulations compares well with observations although the model slightly overestimates high values especially when driven by era interim this is particularly true in high altitude regions such as the alps pre alpine areas of northeastern italy and the central part of the apennines it should be kept in mind that observational gridded products tend to underestimate precipitation amounts over mountainous areas prein and gobiet 2017 a shortcoming that might be even more evident when metrics such as the r99ptot are examined in contrast regcm4 underestimates extreme precipitation in the puglia region of southeastern italy and over most of sicily and the eastern part of sardinia when compared to gripho the results also show that while mbcn is able to correct mean precipitation it is less successful in correcting extreme values for example the bias correction successfully improves r99ptot values in northeastern italy and eastern sardinia but produces more extreme precipitation amounts than observed particularly over flat areas such as the po plain this behavior appears to be more evident in regions where gripho presents more missing values sicily island and puglia region suggesting that the adequacy of the correction depends on the length and quality of the observation time series 3 2 validation of the chym simulations for the hydrological model evaluation we compare simulated discharge from chym obs and chym era with station based observed discharge this analysis is limited by the availability of observation datasets in both number of stations and time series length over most domains containing few or no discharge observations therefore the validation is reported only for those domains in which there are stations i e the po basin and central italy river basins fig 5 shows the results from the kge over the po panels a and b and central italy river basins panels d and e considering hydrological simulations driven by both the observation data and model raw simulation the benefit of using bias corrected precipitation to feed the chym model iss are shown in panels c and f the simulation chym obs has an overall good skill in simulating the daily flows in both domains values up to 0 75 in both domains the latter is supported by the pearson s r values fig s1 which are up to 0 80 and 0 82 for the po and central italy river basins respectively however this behavior is not spatially homogeneous across all basins for example for the po basin fig 5a while most of the evaluated points reach kge values above 0 25 some headwater stations in the west and north of the basin fall below 0 the stations with the minimum values for this metric coincide with those with the lowest pearson s r fig s1a moreover the results indicate that the best skills are for those stations with the longest time series the results for the central italy river basins fig 5d are even more heterogeneous for the tevere river basin located in the north central part of the domain which is the primary basin in the region the daily simulated discharge presents a good agreement with the observed kge values around 0 7 however in other small watersheds mainly in the eastern and southern regions of the domain values below 1 are found suggesting that chym even when using observed precipitation has some deficiencies in capturing daily river discharge there even though chym era shows less skill than chym obs the results are still acceptable in both domains kge values up to 0 44 for the po and up to 0 34 for central italy basins the lower performance compared to chym obs is expected due to the error propagation from the rcm to the hydrological model it should be noted that even when driven by the reanalysis the timing and intensity of high precipitation critical for a proper representation of discharge might differ significantly from reality in the rcms this is evident in the po main river channel which due to its size is less sensitive to precipitation timing and reproduces well the daily river flows when compared to other smaller river basins in the central italian domain concerning the potential benefit of using the bias correction for simulating daily discharge small relative differences iss can be found between the kge values for chym era bc and chym era in the po basin fig 5c for this domain iss is in the range of 0 37 to 0 45 with just a few headwater stations in the west achieving a relative improvement in their kge values after bias correction in this basin the average standard deviation iss for all stations is 0 08 0 15 suggesting a very minor improvement when bias corrected inputs are used the benefit is even more unclear in the central italy river basins fig 5f where some stations show a skill reduction after bias correction similarly the pearson s r shows variation among the stations within 0 1 fig s1c and fig s1f the results from the different terms of kge r α and β provide additional information regarding the impact of using bias correction on the simulated daily discharge for the po basin stations with poor skill kge 0 41 knoben et al 2019 also exhibit a substantial overestimation of the mean fig s2a b and variability fig s3a b for these stations the use of mbcn generally increases the kge fig 5c the hydrological simulation with bias corrected climate inputs also appears to reproduce daily flows more accurately in headwater stations on the south bank of the po river fig 5c in this case the mbcn generates more accurate streamflow values especially in terms of the mean bias fig s2c and variability fig s3c in the central italy basins part of the worse performance in chym era bc occurs for stations where chym obs already presented a poor skill fig 5d in these stations chym fed with gripho data leads to overestimations in the mean that are greater than in chym era fig s2d e evidently the correction made using gripho provides less skill in capturing the mean in contrast in those stations where chym underestimates the mean discharge volume more in chym era than in chym obs the bias correction leads to simulated discharge with a slight improvement in the bias in addition the bias correction appears to increase the daily flow variability and therefore for those points where variability is underestimated fig s3e in chym era the skill is improved after bias correction fig s3f in contrast stations with overestimated variability in chym era show a degradation of results the average yearly peak flow for chym obs along with the percent bias for hydrological simulations fed with regcm4 when compared to chym obs are displayed in fig 6 in this figure only the major rivers in each of the nine domains are plotted to prevent overlaps similarly the average seasonal mean flow is reported in fig s4 the hydrological simulations fed with raw regcm4 outputs i e chym era and chym had produce mean fig s4 and extreme fig 6 values with biases ranging from 50 to 30 when compared to chym obs nonetheless there is a clear tendency to underestimate q y max in general and especially for chym had an overestimation is seen in the northern part of the po basin around 30 and some watersheds over the central southern italy and calabria when climate data are bias corrected the differences with chym obs are generally reduced for both peak flow and mean discharge figs 6 and s5 with bias values between 20 and 20 nonetheless for parts of the central italy and central northern italy watersheds e g the reno and arno rivers the mbcn produces higher peak flows than the raw data turning underestimations in chym era and chym had into overestimations in chym era bc and chym had bc this behavior is probably related to the worsening of the bias correction method when dealing with extreme precipitation as discussed in section 3 1 fig 7 shows the hourly peak flows with return periods of 10 50 and 100 years q10 q50 and q100 for chym obs along with the percent bias in the regcm4 forced hydrological simulations these indicate the amount of discharge expected in an event that has the probability of occurring on average every 10 50 and 100 years respectively hourly peak flows for the different rps show biases with similar spatial patterns which are similar to those observed for the average yearly peak flow however both underestimations and overestimations appear to be slightly greater in magnitude than in q y max especially for simulations having as input the bias corrected values and more marked for chym era bc at higher return periods additionally the annual average frequency of events with peak flows greater than q10 q50 and q100 are assessed in fig s5 compared to chym obs the regcm4 driven chym simulations with and without bias correction slightly overestimate the annual frequency of events greater than q10 q50 and q100 especially for higher return periods 3 3 projected changes in precipitations fig 8 shows the r99ptot for the regcm had simulation in the historical period 1976 2005 along with the relative changes for the near 2020 2049 and far 2070 2099 future compared to the annual mean precipitation changes in the range of 40 and 40 for the near future fig s6 annual relative changes in the regcm had r99ptot show both increases up to 80 and decreases up to 30 for this simulation the puglia region appears to be the most affected by an increase in extreme precipitation whereas reductions are found especially in northeast italy and sardinia increases in extreme precipitation however are expected to be widespread across italy for the far future the highest r99ptot increases are found in the po valley and along the eastern coast where changes higher than 160 are reached in terms of mean changes western italy exhibits a slight negative signal in annual precipitation caused by a precipitation reduction mainly during the summer and spring fig s6 in general raw and bias corrected precipitation outputs present similar change signals for both the near and far future periods in terms of both mean and extreme values however the use of raw precipitation slightly amplifies the dry change signal whereas the bias corrected positive precipitation changes are higher compared to those using the raw data fig s6 the probability density functions pdfs of daily precipitation fig s7 also show a shift in precipitation distributions toward higher values in all regions as for previous analyses trends in raw and bias corrected precipitation are similar however the presence of extreme values is more noticeable in the bias corrected outputs where higher precipitation peaks occur not only in the future but also in the historical period 3 4 changes in discharge the mean discharge in the chym had simulations in general shows a predominant increased mean flow for the near future fig s8 for this simulation a positive signal is clearly found during the winter when mean flows increase by more than 30 mainly in the northern side of the po basin and the puglia region for the autumn mean flow a slight increase is projected mainly over the west of the po basin and in watersheds of the calabria sicily sardinia and southern italian regions in contrast there is a clear negative change signal in the summer especially in central italy and sardinia and autumn for north eastern italy sardinia po and central italy when reductions reach 20 the results from simulations fed with raw and bias corrected climate outputs show similar change patterns for the near future period in mean values except for summer when chym had bc exhibits a stronger dry signal at the annual scale changes in mean flow are likely to be moderate with values ranging from about 10 to 10 fig s8 however the yearly average peak flows show greater changes compared to the changes in mean discharge fig 9 for the near future the sardinia basins present the largest dry signal changes below 20 and the puglia region shows the maximum wet one with increases above 80 also in this case the differences in projections with and without bias correction are small with chym had showing a slightly stronger dry signal than chym had bc for the far future in our simulations the dominant mean flow signal is an increase throughout most of italy fig s8 with exceptions in summer for parts of the po river north eastern italy central northern italy calabria and sicily regions where a mean flow reduction up to 20 is found compared to the historical period it is worth noting that for this period the direction of change exhibits greater discrepancies between mean precipitation and discharge this is clearly evident in the autumn when precipitation changes are characterized by slight negative signals over most of italy fig s6 and mean flows indicate a generalized slight increase fig s8 after the bias correction the results remain similar though the signal of change in mean values is slightly increased the latter is particularly true during the summer when chym had bc projects an increase above 80 covering a larger area than chym had in central italy the change signal is stronger in terms of the yearly peak flow when nearly all of italy experiences an increase in q y max with values exceeding 80 fig 9 the eastern coasts of central italy and the puglia region which are characterized by a predominance of small catchments show increases of more than 120 during this period compared to chym had chym had bc exhibits a greater magnitude of changes in q y max albeit more than half of the river points still indicate variations between chym had bc and chym had in the range of 20 table 5 changes in the 10 50 and 100 year return periods of peak flows for chym had and chym had bc are reported in figs 10 and 11 respectively overall chym had and chym had bc again project a signal of change with similar spatial patterns however after bias correction the wet signal is amplified especially in the far future for chym had bc more than 20 of river points present greater than 20 differences in the magnitude of the changes compared to chym had table 5 in any case both simulations show moderate changes for the near future which are similar in spatial patterns to those simulated for q y max the signal of change is stronger for hourly peak flows especially in the puglia region where an increase of up to 120 is reached for q10 q50 and q100 compared to the historical period whereas q y max indicates an increase of around 80 the increase in hourly peak flow is seen everywhere in the far future except for part of calabria where a few basins show a decreasing signal values of up to 20 for both periods the patterns of change for 10 50 and 100 year return periods of peak flows are almost identical in the raw and bias corrected runs changes in the average yearly frequency of events occurring above the historical q10 q50 and q100 thresholds are assessed in fig 12 as for previous analyses there are few differences between chym had and chym had bc in the change direction with increases over a large part of italy in the frequency of extreme discharges by the end of the century the differences between return period frequencies show how less frequent events exhibit a greater magnitude of the change signal both increases and decreases of frequency are found in the near future when peak flows with a return period greater than q10 are simulated to double in frequency over regions in the po basin southern italy and sicily in contrast parts of sardinia and central italy present decreases in frequency reaching values of up to 60 the patterns of change are similar but larger in magnitude for events with a return period greater than q50 and q100 for these latter thresholds both chym had and chym had bc show increases in the number of events above q50 and q100 by more than 1200 over the main segment of the po river in the near future in the far future the increase is seen everywhere with changes on average around 200 for q10 over most of italy the frequency increases even more for the 50 and 100 year thresholds when twelvefold increases of frequency appear across many watersheds especially in the po basin and in the northeast and south of italy 4 discussion and conclusions our study focuses on flood hazard assessment in italy a region frequently affected by inundations hydrological simulations were completed with the chym hydrological model for the recent past and future conditions sub daily climate forcings from both observations and simulations with the regcm4 rcm were used to simulate extreme discharge patterns over this region which is characterized by the presence of small catchments note that only a few studies have dealt with climate change projections for sub daily extreme discharge owing to a lack of reliable long term observation data to validate both climate and hydrological simulations here we used the recently developed high resolution station based observed hourly precipitation dataset gripho the regcm4 precipitation was first evaluated by comparison with different observed precipitation products the spatiotemporal patterns of both mean and extreme precipitation over italy were generally reproduced demonstrating that the regcm4 outputs are suitable for use as climatological inputs of the hydrological model the ability of chym to reproduce daily flow over italy using different climate inputs was then investigated in general chym fed with observed data chym obs showed a good skill in reproducing daily discharge when compared to station data however the model performance was not uniform showing a better skill over the po basin than in the smaller central italy basins where discharge observations are affected by the presence of substantial numbers of missing values and inhomogeneities also the quality of the results is influenced by human activities on hydrological systems which are known to modify natural flow rivers magilligan and nislow 2005 in this regard italian rivers have undergone significant modifications in the last century moccia et al 2020 which is expected to have an impact on model evaluations also chym was able to capture the main patterns of mean and extreme discharge using the rcm climate forcing though it tended to underestimate the discharge when compared to chym obs in contrast we found overestimations of the annual average frequency of extreme discharge events particularly for higher return periods it is still debatable whether the application of bias correction is adequate and needed when looking at changes in streamflow especially when extreme values are concerned our findings indicate that the n dimension multivariate bias correction using 3 hourly data was capable of satisfactorily correcting biases in seasonal mean precipitation also improving the representation of the overall shapes of the annual cycle however the method was not able to reduce the errors in extreme precipitation these findings agree with other studies on the performance of bias correction methods gudmundsson et al 2012 gutjahr and heinemann 2013 huang et al 2014 our results moreover suggest that the bias correction is highly dependent on the observations used to correct the data and the period selected for calibration lafon et al 2013 we used a 16 year calibration period limited by the length of gripho and indeed this limited length of available data presents a great challenge for example huang et al 2014 pointed out that the characterization of future flood hazards by using bias corrected climate outputs requires a long calibration period to avoid problems in generating transfer functions furthermore observed and simulated precipitation can differ in timing and intensity of extreme events for different reasons on the one hand precipitation measurements are not error free angulo martínez et al 2018 especially on the sub daily scale on the other hand convection is parameterized in our climate simulations which could lead to errors in capturing extreme sub daily precipitation hohenegger et al 2008 klein et al 2013 the latter may cause an effect on the transfer functions developed for correcting data thereby causing a misrepresentation of precipitation peaks faghigh et al 2022 since bias correction is a post processing technique created for correcting simulation statistics such as mean variability or high quantiles it cannot correct single events responsible for floods therefore if the rcm has problems capturing physical processes that lead to flooding conditions it is unlikely that bias correction can provide an actual improvement of this problem huang et al 2014 in this sense the use of climate outputs from convection permitting simulations could be beneficial as they can better represent fine scale details of precipitation patterns in both frequency and intensity at the sub daily scale pichelli et al 2021 which could have a substantial impact on the evaluation of future flood risks we also investigated the effect of bias corrected climate outputs on river discharge and found that the bias correction leads to a better overall agreement with chym obs in capturing the seasonal mean flows and the average yearly peak flows however in some regions the use of corrected forcings resulted in higher discharge values than in chym obs suggesting that the method does not always suitably correct sub daily discharge moreover the comparison with observed discharge data using the kge skill score metric highlighted that the bias correction is unlikely to provide better daily flow compared to the simulation fed with raw data our findings partially agree with other studies assessing the effect of bias correction methods on seasonal precipitation and discharge simulations crochemore et al 2016 tiwari et al 2021 which found a benefit in using bias correction for precipitation but not for streamflow projections with and without bias correction showed similar patterns of change in both mean precipitation and discharge for extremes although the sign of the change signal is similar in the two approaches its magnitude is amplified in some parts of italy especially at the end of the century in any case both bias corrected and raw simulations exhibited a prevailing positive change signal over italy with increases in the annual mean river flow of about 30 by the end of the century under the rcp8 5 scenario our results show that the increase in mean flow is more evident during the winter when changes of up to 120 may be amplified by enhanced snowmelt in areas such as the po basin coppola et al 2014 moreover the results from raw and bias corrected climate inputs indicated a ubiquitous increase in extreme precipitation coppola et al 2021 and discharge with a consequent increase in flood hazard these findings are consistent with those from huang et al 2014 who found that approximately 75 of the change signal for daily peak flows of the 50 year return period was the same using raw and bias corrected climate data in hydrological simulations over catchments in germany extreme discharge changes were shown to agree with other studies conducted over the european region for example alfieri et al 2015 using an ensemble of euro cordex simulations to feed the lisflood hydrological model concluded that extreme discharge is likely to increase over the po basin with q100 increasing by more than 40 by the end of the century similarly rojas et al 2012 who used 12 simulations conducted within the ensembles project found an increase in flood hazards in northern italy more recently di sante et al 2021 analyzed river flood projections in europe using runoff from three ensembles of climate simulations to feed the chym model and found significant increases in q100 over italy mainly over the po basin and the puglia region in that study the authors pointed out that the increases in extreme discharge will most likely be caused by significant increases in extreme precipitation which is consistent with our results although this study is based on a single model and scenario simulation it still shows how i hydrological model simulations driven by rcm outputs both in perfect lbc and scenario simulations are able to reproduce the climatology of discharge over the italian river network when compared to available observations ii bias correction is not necessary neither recommended when long term mean change signals are investigated and its added value is generally not obvious especially in terms of extremes repeating the study from a multi model ensemble perspective would give more robustness to these conclusions credit authorship contribution statement matilde garcía valdecasas ojeda conceptualization methodology investigation software validation formal analysis visualization writing original draft writing review editing fabio di sante conceptualization investigation methodology software writing review editing erika coppola conceptualization investigation writing original draft writing review editing supervision project administration resources funding acquisition adriano fantini conceptualization methodology investigation software validation formal analysis data curation rita nogherotto conceptualization investigation writing review editing visualization francesca raffaele conceptualization investigation writing original draft visualization filippo giorgi writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments first author was supported by ogs and cineca under hpc tres program award number 2020 02 and at present is supported by feder junta de andalucía consejería de transformación económica industria conocimiento y universidades project p20 00035 we thank the cetemps and dr marco verdecchia for data support we thank the anonymous reviewers for their valuable comments that helped to improve this work appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128628 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2680,this study assesses future projections of flood hazards across the italian river basins for this purpose sub daily river discharge for the entire italian territory was simulated with the cetemps hydrological model chym using as climate forcing both observational datasets and regional climate simulations completed with the ictp regional climate model regcm4 first simulated precipitation and river discharge were evaluated against observational products showing both models good performance in simulating italian precipitation and discharge characteristics then projections of these variables were explored for two time slices near 2020 2049 and far 2070 2099 future under the rcp8 5 emission scenario with regcm4 driven by output from a global climate model projection the regcm4 outputs were also bias adjusted by means of the n dimension multivariate bias correction mbcn method we found that although the bias correction leads to a benefit in capturing mean precipitation the improvement is less clear for extreme precipitation in terms of discharge however bias correction has a noticeable impact on mean discharge as well as average yearly peak flow and hourly peak flow at return periods of 10 50 and 100 years nevertheless for a large part of the italian territory projected changes in mean precipitation and discharge do not show significant differences when bias correction is applied while for extreme events only 30 of river points show significant sensitivity to bias correction under the rcp8 5 scenario an increase in yearly peak flow is evident over most of the italian peninsula with values increasing from 30 to more than 100 for the mid and far time slices respectively especially over the po river and along the eastern coasts of italy similar conclusions are found for the hourly peak flows of 10 50 and 100 year return periods these indicators thus suggest a general increase in flood hazard expected over the region keywords chym model regcm4 model climate change floods extreme river discharge data availability data will be made available on request 1 introduction flood is one of the most devastating natural disasters leading to severe impacts on society and ecosystems according to the centre for research on the epidemiology of disasters cred 2021 only in 2020 over 33 million people worldwide were affected by floods and 6171 people died italy is prone to natural disasters due to its complex topography and climate variability according to mysiak et al 2013 30 of the italian territory is highly vulnerable to landslide and flood events both separately and in combination in particular from 2000 to 2019 flood occurrences in italy resulted in economic damages of almost 18 5 billion em dat 2022 flood hazard estimation is therefore an essential tool for developing reliable adaptation strategies in recent decades many studies have focused on the assessment of the impacts of climate change on precipitation from these studies one can conclude that there is a relatively robust agreement that extreme precipitation is mostly projected to increase both in frequency and intensity under global warming conditions e g christensen and christensen 2007 nikulin et al 2011 pendergrass and hartmann 2014 coppola et al 2021 nevertheless how changes in atmospheric variables will affect river discharge is still under investigation particularly when focusing on extreme events at regional scales andersen and marshall shepherd 2013 flooding is expected to be strongly affected by changes in climatic patterns as an increase in extreme precipitation is likely to lead to enhanced flood generating processes whitfield 2012 however the link between extreme precipitation and the occurrence of flood events is not necessarily linear in that flood occurrence also depends on complex relationships between snow accumulation and melting underground water flow and local channel characteristics for this reason the assessment of the interplay between the spatiotemporal patterns of changes in precipitation and discharge is a research topic of great interest assessments of the future flood hazard over large basins are commonly performed by coupling global climate models gcms with land surface schemes and hydrological models e g alkama et al 2013 arnell and gosling 2016 dankers et al 2014 prudhomme et al 2003 sperna weiland et al 2012 the low resolution of gcms however prevents similar assessments for small regional scale river basins in this case an increased resolution is required huang et al 2019 especially for capturing extreme events such as floods therefore regional climate models rcms have become increasingly popular because they can describe regional climates by considering sub gcm grid scale forcings e g local topography coastlines or land cover distribution and dynamical processes occurring at high spatial resolution of roughly 10 50 km giorgi 2019 the increase in temporal resolution is also important for correctly representing flood peaks especially for small catchments zhu et al 2018 this is because small catchments due to their low storage capacity and fast reaction time to water displacements are more vulnerable to the occurrence of short duration storms authors such as yang et al 2016 studied the impact of the temporal resolution of climate data used as input to hydrological models and found that hydrological simulations driven by sub daily climate variables can capture much better the peak flow values compared to models driven by daily climate input several studies using rcm outputs to drive hydrological models for the european continent e g alfieri et al 2018 2015 dankers and feyen 2009 feyen et al 2012 prudhomme et al 2003 generally find increasing flood hazards mostly over the central european region and especially in terms of higher frequency of occurrence alfieri et al 2015 small river catchments in central and southern europe would be more affected by an increase in flood magnitude associated with an increase in extreme convective precipitation events in contrast over the northeast european region snow melting is the main driver of the major floods and a decrease in snow accumulation during the snow season would lead to a decrease in flood magnitude this is observed in particular for large river catchments di sante et al 2021 vautard et al 2021 since climate models are often affected by systematic model biases bias correction is considered a crucial step in using model outputs for impact studies e g casanueva et al 2016 christensen et al 2008 piani et al 2010 however this method is not free of controversy in particular when dealing with extreme value correction for example ehret et al 2012 pointed out that bias correction must be performed with caution since it introduces new sources of uncertainty that occasionally can become large climate change impact assessments therefore should be performed considering both raw and bias corrected climate model data a large number of bias correction approaches have been proposed in recent years e g boé et al 2007 cannon 2018 cannon et al 2015 gómez navarro et al 2018 kim et al 2021 piani et al 2010 several authors investigated the ability of these procedures to correct different climate variables using a wide range of evaluation methods argüeso et al 2013 fang et al 2015 gudmundsson et al 2012 gutjahr and heinemann 2013 lafon et al 2013 maraun 2016 themeβl et al 2012 2011 however most studies focus on analyzing climate data at a daily scale and therefore how the correction modifies sub daily simulated values and the resulting effect on sub daily discharge remains not well understood despite the fact that the italian region is frequently affected by severe inundation events scientific studies concerning flood hazard estimation over this region are few moreover most of these studies focus on limited areas or small basins di salvo et al 2017 marchesini et al 2016 morelli et al 2014 sole et al 2008 specific past events amadio et al 2013 marchi et al 2010 masoero et al 2013 norbiato et al 2007 santo et al 2012 or target flood risk rather than hazard albano et al 2017 dottori et al 2016 salvati et al 2010 therefore in this study we aim to assess the current state and future evolution of flood hazards throughout the entire italian territory towards this goal river discharge for the italian territory was simulated using the cetemps hydrological model chym coppola et al 2007 by feeding it with climate data from both high resolution observational datasets and two rcm simulations specifically we use output from the ictp regional climate model regcm4 giorgi et al 2012 at 12 km spatial resolution to resolve the spatial and temporal climate detail within the river catchments analyzed gosling et al 2011 whitfield 2012 furthermore we investigate the impact of using bias corrected climate outputs at a sub daily temporal scale for both present and future conditions under an increased greenhouse gas concentration scenario the paper is structured as follows in section 2 we describe the data and methods used section 3 presents the results obtained and section 4 discusses and highlights the main findings of this work 2 data and methods 2 1 observations precipitation is the main atmospheric component controlling the hydrological response in catchments and thus plays a critical role in hydrological simulations chiew et al 2009 ly et al 2013 obled et al 1994 however it is also one of the most challenging variables to characterize due to its high spatiotemporal variability hence the use of different precipitation products is highly recommended when evaluating climate models particularly at the regional scale prein and gobiet 2017 table 1 lists the observed precipitation gridded products we have used to evaluate regcm4 the alpine precipitation dataset euro4m apgd isotta et al 2014 and the northern central italy daily precipitation dataset arcis pavan et al 2019 are high resolution high quality station based gridded products developed from dense observation networks across the alps and north central italian regions respectively e obs haylock et al 2008 is a set of european wide observations that have been widely applied for model evaluation purposes in this study the daily precipitation version 20 0e was used cornes et al 2018 we also consider the hirlam mesan reanalysis hmr landelius et al 2016 a european regional reanalysis based on downscaling and data assimilation techniques finally the recently developed high resolution gridded italian precipitation hourly observations dataset gripho fantini 2019 fantini et al 2022 is used to feed chym and to bias correct the simulated precipitation values to evaluate the hydrological model observation datasets of river discharge from two sources were collected table 2 hourly discharge datasets encompassing the po river the upper po river and the entire italian territory were provided by the university of l aquila in addition we use the long term daily discharge data from the european water archive ewa ewa 2014 finally the era5 reanalysis product from the european centre for medium range weather forecasts ecmwf reanalysis hersbach et al 2020 is used as a reference dataset to correct the regcm4 temperature data this selection was based on data availability as this reanalysis provides hourly outputs with a grid resolution of 31 km and is a product with an accurate representation of temperature tarek et al 2020 2 2 climate simulations the regcm4 model version 4 6 1 was used to complete two regional climate simulations covering the entire european region according to the euro cordex domain specifications jacob et al 2014 with a spatial resolution of 12 km on a lambert conformal conic projection both simulations were carried out with the same configuration and differ only in the initial and lateral boundary conditions lbcs in the first the ecmwf era interim reanalysis product dee et al 2011 provides the lbcs hereafter referred to as regcm era for the period 1979 to 2016 the second simulation completed as part of the producing regional climate projections leading to european services project principles https www gerics de science projects detail 071974 index php en is driven by the met office hadley centre hadgem2 es cmip5 gcm hadgem2 es collins et al 2011 hereafter referred to as regcm had for the period 1971 2099 for the latter the period from 2006 to 2099 was completed under the representative concentration pathway 8 5 rcp8 5 moss et al 2008 riahi et al 2007 2 3 bias correction here we use the n dimension multivariate bias correction mbcn algorithm developed by cannon 2018 to correct sub daily precipitation and temperature outputs from both regcm era hereafter referred to as regcm era bc and regcm had hereafter referred to as regcm had bc this method combines a correction of climate simulation outputs via quantile delta mapping qdm cannon et al 2015 with the adjustment of dependency structures using an n dimensional probability density function transform algorithm pitié et al 2007 2005 mbcn thus preserves the projected changes in the simulated quantiles by using qdm which has proven to represent well extreme values in future projections cannon et al 2015 and yields more physically consistent data accounting for inter variable dependencies françois et al 2020 the algorithm utilizes a multi step process in which the original datasets are multiplied by random orthogonal matrices before being corrected then the resulting datasets are rotated back to obtain the final bias corrected data this multi step process is applied iteratively until the multivariate distributions of bias corrected data and the observed distributions converge three hourly precipitation and temperature outputs from regcm4 were extracted and bias corrected based on the observations from gripho for precipitation and era5 for temperature using the mbc r package cannon 2020 mbcn was calibrated using observations from 2001 to 2016 which corresponds to the entire gripho period because the observations have an hourly frequency they were transformed from 1 hour to 3 hour data hence 3 hourly precipitation corresponds to the average over the three hours at the end of a given time step i e 00 03 06 09 12 15 18 and 21 conversely temperature is the instantaneous value at the same three hourly interval an mbcn with 30 iterations was applied for each month separately using three month windows centered on each calendar month for precipitation the dry days threshold was set to 0 05 mm according to cannon 2018 2 4 hydrological model the chym model version 6 07 was used to simulate hourly streamflow over the entire italian territory chym is a spatially distributed grid based hydrological model initially developed by the center of excellence in telesensing of the environment and model prediction system cetemps of the university of l aquila it was specially designed for flood prediction tomassetti et al 2005 verdecchia et al 2008 but it has been also applied in hydro climatological studies over different regions of italy europe and south asia coppola et al 2014 di sante et al 2021 2019 fantini 2019 sangelantoni et al 2019 moreover its routing scheme was employed as the hydrological component in the regional earth system model resm regcm es di sante et al 2019 chym simulates hydrological processes i e surface runoff evapotranspiration percolation infiltration melting and return flow discharge and using a digital elevation model dem recreates an eight flow direction river network employing a cellular automata ca theory based algorithm coppola et al 2007 2006 the surface routing is performed according to the kinematic shallow water approximation from lighthill and whitham 1955 we used the hydrosheds hydrologically conditioned dem with roughly 90 m spatial resolution https www hydrosheds org lehner et al 2008 as this dataset was specifically designed for hydrological applications chym is based on a fortran90 code and runs in a parallel computer architecture using the mpi standard more details of this hydrological model can be found in coppola et al 2007 the italian territory was divided into nine sub regions fig 1 a based on the operational domains used by cetemps for flood forecasting these sub regions defined using stress indices have been demonstrated to be effective in establishing a reliable and feasible river network for the entire italian territory tomassetti et al 2005 verdecchia et al 2008 the nine domains are the po basin liguria north eastern italy central northern italy central italy central southern italy calabria sicily and sardinia the simulations were completed using a specific configuration for each domain with spatial resolution ranging from roughly 300 m for the liguria calabria sicily and sardinia domains to 900 m for the po basin depending on the catchment size orography and administrative boundaries with time steps from 50 s to 400 s the hydrological model parameters were established according to coppola et al 2014 who calibrated the chym model in the upper po basin for climatological application purposes in terms of river dynamics the po basin which has the longest flow discharge time series among the italian rivers can be considered representative of many european rivers thus the same parameters were used for all domains sangelantoni et al 2019 different climate sources were used to run the chym model as shown in table 3 to evaluate the hydrology model performance one simulation fed with observed climate data was completed chym obs at hourly time aggregation for this purpose we used the gripho precipitation dataset and observed near surface temperature data from thermometer networks cima 2014 to fill the gaps in gripho due to missing data daily weather forecasts carried out with the mesoscale model 5 mm5 grell et al 1994 were used following the same procedure adopted for real time weather forecasting by cetemps colaiuda et al 2020 then for each domain two additional simulations were completed in which the chym model was fed with 3 hourly climate outputs from regcm era hereafter referred to as chym era and regcm had chym had see section 2 2 for further details additionally bias corrected climate outputs were also used to simulate the river discharge chym era bc and chym had bc for simulations forced by regcm era bc and regcm had bc respectively different time slices were used depending on data availability for the recent past the chym obs simulations spanned the period 2000 to 2016 and the chym era simulations the period 1979 to 2016 for the chym had simulations three periods were considered the reference period from 1975 to 2005 and two future time slices 2019 2049 near future and 2069 2099 far future for all hydrological simulations the first year was considered as spin up time and therefore it was discarded from the statistical analyses 2 5 evaluation of the climate and hydrological simulations firstly we evaluate the precipitation outputs of the regcm4 simulations and the river discharge from the chym simulations the regcm results are compared to the different observational products in terms of annual cycle mean seasonal precipitation and extreme r99ptot precipitation the latter is computed using only precipitation on wet days pr 1 mm day and represents for each grid point the percentage of precipitation above the 99th percentile the comparison is carried out either by aggregating grid point values over four different homogeneous climate regions fig 1b or by directly comparing grid point values for these analyses the period of each observation dataset varies depending on data availability table 1 but they all cover at least a 30 year period except for gripho whose precipitation time series span from 2001 to 2016 the chym performance is assessed by comparing daily discharge from chym obs to station datasets using the kling gupta efficiency kge skill score metric gupta et al 2009 kling et al 2012 table 4 a similar evaluation is carried out for chym era to assess the coupled regcm chym performance the kge measures the model performance by considering errors in the correlation r bias β and variability α between simulated qsim and observed qobs discharge in this metric r is the pearson s r coefficient β is the bias between simulated q sim and observed mean q obs and α is the ratio between the standard deviation in simulations σsim and observations σobs furthermore each component of the kge is investigated separately allowing model errors to be directly attributed to either correlation bias or variability terms therefore a β value greater lower than 1 indicates an overestimation underestimation of the mean with respect to observations similarly a value of α lower higher than 1 indicates that the simulated daily variability is underestimated overestimated towner et al 2019 in order to assess the potential benefit of using bias correction to simulate the daily river discharge we use the following metric towner et al 2019 1 i ss s s c s s r 1 s s r where ssc represents the different skill score metrics i e kge r α and β computed from the chym simulations fed with bias corrected climate data and ssr those from raw data when iss is positive negative mbcn is considered to provide a better worse skill than the raw data to assess the role of bias correction in terms of extreme values we compare the chym obs simulations with those forced by the regcm4 using both raw and bias corrected outputs the maximum discharge or yearly peak flow for each year and river point is extracted to compute metrics such as the average yearly peak flow q y max the hourly peak flow for different return periods qrps and the annual empirical frequency of events above qrps to that end the yearly peak flows are fitted to a gumbel distribution using a simple maximum likelihood method alfieri et al 2015 di sante et al 2021 fantini 2019 maione et al 2003 and the analytical qrps are estimated then a peak over threshold pot method is applied to the hourly time series of the modeled river flow to determine the annual empirical frequency of extreme discharge a declustering approach is adopted to ensure the independence of events with a time interval between two consecutive flood events determined by the basin area hu et al 2020 2 dt 5 2 59 log a where dt represents the time interval and a is the catchment area in square kilometers 2 6 projections in precipitation and river discharge changes in precipitation and discharge are explored by comparing historical simulations 1976 2005 with those from the two future time slices the near 2020 2049 and the far 2070 2099 future in relative terms analogously to the evaluation the results with and without bias correction are also intercompared for the pot analysis qrps from historical distributions are used as thresholds also for the future 3 results 3 1 validation of the regcm simulations fig 2 compares the annual cycle of precipitation for observations and regcm4 simulations over the four macroregions in general the raw regcm4 data regcm era regcm had accurately capture the shape of the annual precipitation cycle in the four macroregions although with some discrepancies compared to observations regcm4 tends to overestimate spring precipitation especially in the northern and central italian regions while it underestimates autumn precipitation in the north in particular regcm had overestimates precipitation in summer over the central islands and southern regions as expected when the bias correction is applied to the regcm4 outputs these model biases are considerably improved see results from regcm era bc and regcm had bc for seasonal mean precipitation fig 3 regcm era and regcm had accurately reproduce the autumn and winter precipitation peaks observed in gripho and hmr over the southwestern coasts of italy these simulations successfully capture the precipitation peaks over the alps found in all observation datasets in the spring summer and autumn but they tend to produce isolated hot spots particularly in the summer both raw simulations moreover produce similar italian precipitation climatologies suggesting that independently of the driving data regcm4 is able to correctly reproduce the main precipitation climatological features over italy however the raw simulations also show underestimated precipitation values during winter over the gulf of genoa liguria and the po plain when compared to hmr e obs and gripho with values up to 5 and 8 mm day for simulated and observed precipitation respectively in contrast summer precipitation is overestimated over most of sardinia particularly when compared to hmr and e obs bias corrected precipitation shows significantly better spatial agreement with observations fig 3 moreover the results clearly demonstrate the influence of the dataset used as reference for example the bias corrected precipitation outputs and gripho exhibit higher precipitation values compared to the other observational datasets in the winter over calabria fig 4 reports the extreme r99ptot for both observations and simulations overall extreme precipitation from the raw simulations compares well with observations although the model slightly overestimates high values especially when driven by era interim this is particularly true in high altitude regions such as the alps pre alpine areas of northeastern italy and the central part of the apennines it should be kept in mind that observational gridded products tend to underestimate precipitation amounts over mountainous areas prein and gobiet 2017 a shortcoming that might be even more evident when metrics such as the r99ptot are examined in contrast regcm4 underestimates extreme precipitation in the puglia region of southeastern italy and over most of sicily and the eastern part of sardinia when compared to gripho the results also show that while mbcn is able to correct mean precipitation it is less successful in correcting extreme values for example the bias correction successfully improves r99ptot values in northeastern italy and eastern sardinia but produces more extreme precipitation amounts than observed particularly over flat areas such as the po plain this behavior appears to be more evident in regions where gripho presents more missing values sicily island and puglia region suggesting that the adequacy of the correction depends on the length and quality of the observation time series 3 2 validation of the chym simulations for the hydrological model evaluation we compare simulated discharge from chym obs and chym era with station based observed discharge this analysis is limited by the availability of observation datasets in both number of stations and time series length over most domains containing few or no discharge observations therefore the validation is reported only for those domains in which there are stations i e the po basin and central italy river basins fig 5 shows the results from the kge over the po panels a and b and central italy river basins panels d and e considering hydrological simulations driven by both the observation data and model raw simulation the benefit of using bias corrected precipitation to feed the chym model iss are shown in panels c and f the simulation chym obs has an overall good skill in simulating the daily flows in both domains values up to 0 75 in both domains the latter is supported by the pearson s r values fig s1 which are up to 0 80 and 0 82 for the po and central italy river basins respectively however this behavior is not spatially homogeneous across all basins for example for the po basin fig 5a while most of the evaluated points reach kge values above 0 25 some headwater stations in the west and north of the basin fall below 0 the stations with the minimum values for this metric coincide with those with the lowest pearson s r fig s1a moreover the results indicate that the best skills are for those stations with the longest time series the results for the central italy river basins fig 5d are even more heterogeneous for the tevere river basin located in the north central part of the domain which is the primary basin in the region the daily simulated discharge presents a good agreement with the observed kge values around 0 7 however in other small watersheds mainly in the eastern and southern regions of the domain values below 1 are found suggesting that chym even when using observed precipitation has some deficiencies in capturing daily river discharge there even though chym era shows less skill than chym obs the results are still acceptable in both domains kge values up to 0 44 for the po and up to 0 34 for central italy basins the lower performance compared to chym obs is expected due to the error propagation from the rcm to the hydrological model it should be noted that even when driven by the reanalysis the timing and intensity of high precipitation critical for a proper representation of discharge might differ significantly from reality in the rcms this is evident in the po main river channel which due to its size is less sensitive to precipitation timing and reproduces well the daily river flows when compared to other smaller river basins in the central italian domain concerning the potential benefit of using the bias correction for simulating daily discharge small relative differences iss can be found between the kge values for chym era bc and chym era in the po basin fig 5c for this domain iss is in the range of 0 37 to 0 45 with just a few headwater stations in the west achieving a relative improvement in their kge values after bias correction in this basin the average standard deviation iss for all stations is 0 08 0 15 suggesting a very minor improvement when bias corrected inputs are used the benefit is even more unclear in the central italy river basins fig 5f where some stations show a skill reduction after bias correction similarly the pearson s r shows variation among the stations within 0 1 fig s1c and fig s1f the results from the different terms of kge r α and β provide additional information regarding the impact of using bias correction on the simulated daily discharge for the po basin stations with poor skill kge 0 41 knoben et al 2019 also exhibit a substantial overestimation of the mean fig s2a b and variability fig s3a b for these stations the use of mbcn generally increases the kge fig 5c the hydrological simulation with bias corrected climate inputs also appears to reproduce daily flows more accurately in headwater stations on the south bank of the po river fig 5c in this case the mbcn generates more accurate streamflow values especially in terms of the mean bias fig s2c and variability fig s3c in the central italy basins part of the worse performance in chym era bc occurs for stations where chym obs already presented a poor skill fig 5d in these stations chym fed with gripho data leads to overestimations in the mean that are greater than in chym era fig s2d e evidently the correction made using gripho provides less skill in capturing the mean in contrast in those stations where chym underestimates the mean discharge volume more in chym era than in chym obs the bias correction leads to simulated discharge with a slight improvement in the bias in addition the bias correction appears to increase the daily flow variability and therefore for those points where variability is underestimated fig s3e in chym era the skill is improved after bias correction fig s3f in contrast stations with overestimated variability in chym era show a degradation of results the average yearly peak flow for chym obs along with the percent bias for hydrological simulations fed with regcm4 when compared to chym obs are displayed in fig 6 in this figure only the major rivers in each of the nine domains are plotted to prevent overlaps similarly the average seasonal mean flow is reported in fig s4 the hydrological simulations fed with raw regcm4 outputs i e chym era and chym had produce mean fig s4 and extreme fig 6 values with biases ranging from 50 to 30 when compared to chym obs nonetheless there is a clear tendency to underestimate q y max in general and especially for chym had an overestimation is seen in the northern part of the po basin around 30 and some watersheds over the central southern italy and calabria when climate data are bias corrected the differences with chym obs are generally reduced for both peak flow and mean discharge figs 6 and s5 with bias values between 20 and 20 nonetheless for parts of the central italy and central northern italy watersheds e g the reno and arno rivers the mbcn produces higher peak flows than the raw data turning underestimations in chym era and chym had into overestimations in chym era bc and chym had bc this behavior is probably related to the worsening of the bias correction method when dealing with extreme precipitation as discussed in section 3 1 fig 7 shows the hourly peak flows with return periods of 10 50 and 100 years q10 q50 and q100 for chym obs along with the percent bias in the regcm4 forced hydrological simulations these indicate the amount of discharge expected in an event that has the probability of occurring on average every 10 50 and 100 years respectively hourly peak flows for the different rps show biases with similar spatial patterns which are similar to those observed for the average yearly peak flow however both underestimations and overestimations appear to be slightly greater in magnitude than in q y max especially for simulations having as input the bias corrected values and more marked for chym era bc at higher return periods additionally the annual average frequency of events with peak flows greater than q10 q50 and q100 are assessed in fig s5 compared to chym obs the regcm4 driven chym simulations with and without bias correction slightly overestimate the annual frequency of events greater than q10 q50 and q100 especially for higher return periods 3 3 projected changes in precipitations fig 8 shows the r99ptot for the regcm had simulation in the historical period 1976 2005 along with the relative changes for the near 2020 2049 and far 2070 2099 future compared to the annual mean precipitation changes in the range of 40 and 40 for the near future fig s6 annual relative changes in the regcm had r99ptot show both increases up to 80 and decreases up to 30 for this simulation the puglia region appears to be the most affected by an increase in extreme precipitation whereas reductions are found especially in northeast italy and sardinia increases in extreme precipitation however are expected to be widespread across italy for the far future the highest r99ptot increases are found in the po valley and along the eastern coast where changes higher than 160 are reached in terms of mean changes western italy exhibits a slight negative signal in annual precipitation caused by a precipitation reduction mainly during the summer and spring fig s6 in general raw and bias corrected precipitation outputs present similar change signals for both the near and far future periods in terms of both mean and extreme values however the use of raw precipitation slightly amplifies the dry change signal whereas the bias corrected positive precipitation changes are higher compared to those using the raw data fig s6 the probability density functions pdfs of daily precipitation fig s7 also show a shift in precipitation distributions toward higher values in all regions as for previous analyses trends in raw and bias corrected precipitation are similar however the presence of extreme values is more noticeable in the bias corrected outputs where higher precipitation peaks occur not only in the future but also in the historical period 3 4 changes in discharge the mean discharge in the chym had simulations in general shows a predominant increased mean flow for the near future fig s8 for this simulation a positive signal is clearly found during the winter when mean flows increase by more than 30 mainly in the northern side of the po basin and the puglia region for the autumn mean flow a slight increase is projected mainly over the west of the po basin and in watersheds of the calabria sicily sardinia and southern italian regions in contrast there is a clear negative change signal in the summer especially in central italy and sardinia and autumn for north eastern italy sardinia po and central italy when reductions reach 20 the results from simulations fed with raw and bias corrected climate outputs show similar change patterns for the near future period in mean values except for summer when chym had bc exhibits a stronger dry signal at the annual scale changes in mean flow are likely to be moderate with values ranging from about 10 to 10 fig s8 however the yearly average peak flows show greater changes compared to the changes in mean discharge fig 9 for the near future the sardinia basins present the largest dry signal changes below 20 and the puglia region shows the maximum wet one with increases above 80 also in this case the differences in projections with and without bias correction are small with chym had showing a slightly stronger dry signal than chym had bc for the far future in our simulations the dominant mean flow signal is an increase throughout most of italy fig s8 with exceptions in summer for parts of the po river north eastern italy central northern italy calabria and sicily regions where a mean flow reduction up to 20 is found compared to the historical period it is worth noting that for this period the direction of change exhibits greater discrepancies between mean precipitation and discharge this is clearly evident in the autumn when precipitation changes are characterized by slight negative signals over most of italy fig s6 and mean flows indicate a generalized slight increase fig s8 after the bias correction the results remain similar though the signal of change in mean values is slightly increased the latter is particularly true during the summer when chym had bc projects an increase above 80 covering a larger area than chym had in central italy the change signal is stronger in terms of the yearly peak flow when nearly all of italy experiences an increase in q y max with values exceeding 80 fig 9 the eastern coasts of central italy and the puglia region which are characterized by a predominance of small catchments show increases of more than 120 during this period compared to chym had chym had bc exhibits a greater magnitude of changes in q y max albeit more than half of the river points still indicate variations between chym had bc and chym had in the range of 20 table 5 changes in the 10 50 and 100 year return periods of peak flows for chym had and chym had bc are reported in figs 10 and 11 respectively overall chym had and chym had bc again project a signal of change with similar spatial patterns however after bias correction the wet signal is amplified especially in the far future for chym had bc more than 20 of river points present greater than 20 differences in the magnitude of the changes compared to chym had table 5 in any case both simulations show moderate changes for the near future which are similar in spatial patterns to those simulated for q y max the signal of change is stronger for hourly peak flows especially in the puglia region where an increase of up to 120 is reached for q10 q50 and q100 compared to the historical period whereas q y max indicates an increase of around 80 the increase in hourly peak flow is seen everywhere in the far future except for part of calabria where a few basins show a decreasing signal values of up to 20 for both periods the patterns of change for 10 50 and 100 year return periods of peak flows are almost identical in the raw and bias corrected runs changes in the average yearly frequency of events occurring above the historical q10 q50 and q100 thresholds are assessed in fig 12 as for previous analyses there are few differences between chym had and chym had bc in the change direction with increases over a large part of italy in the frequency of extreme discharges by the end of the century the differences between return period frequencies show how less frequent events exhibit a greater magnitude of the change signal both increases and decreases of frequency are found in the near future when peak flows with a return period greater than q10 are simulated to double in frequency over regions in the po basin southern italy and sicily in contrast parts of sardinia and central italy present decreases in frequency reaching values of up to 60 the patterns of change are similar but larger in magnitude for events with a return period greater than q50 and q100 for these latter thresholds both chym had and chym had bc show increases in the number of events above q50 and q100 by more than 1200 over the main segment of the po river in the near future in the far future the increase is seen everywhere with changes on average around 200 for q10 over most of italy the frequency increases even more for the 50 and 100 year thresholds when twelvefold increases of frequency appear across many watersheds especially in the po basin and in the northeast and south of italy 4 discussion and conclusions our study focuses on flood hazard assessment in italy a region frequently affected by inundations hydrological simulations were completed with the chym hydrological model for the recent past and future conditions sub daily climate forcings from both observations and simulations with the regcm4 rcm were used to simulate extreme discharge patterns over this region which is characterized by the presence of small catchments note that only a few studies have dealt with climate change projections for sub daily extreme discharge owing to a lack of reliable long term observation data to validate both climate and hydrological simulations here we used the recently developed high resolution station based observed hourly precipitation dataset gripho the regcm4 precipitation was first evaluated by comparison with different observed precipitation products the spatiotemporal patterns of both mean and extreme precipitation over italy were generally reproduced demonstrating that the regcm4 outputs are suitable for use as climatological inputs of the hydrological model the ability of chym to reproduce daily flow over italy using different climate inputs was then investigated in general chym fed with observed data chym obs showed a good skill in reproducing daily discharge when compared to station data however the model performance was not uniform showing a better skill over the po basin than in the smaller central italy basins where discharge observations are affected by the presence of substantial numbers of missing values and inhomogeneities also the quality of the results is influenced by human activities on hydrological systems which are known to modify natural flow rivers magilligan and nislow 2005 in this regard italian rivers have undergone significant modifications in the last century moccia et al 2020 which is expected to have an impact on model evaluations also chym was able to capture the main patterns of mean and extreme discharge using the rcm climate forcing though it tended to underestimate the discharge when compared to chym obs in contrast we found overestimations of the annual average frequency of extreme discharge events particularly for higher return periods it is still debatable whether the application of bias correction is adequate and needed when looking at changes in streamflow especially when extreme values are concerned our findings indicate that the n dimension multivariate bias correction using 3 hourly data was capable of satisfactorily correcting biases in seasonal mean precipitation also improving the representation of the overall shapes of the annual cycle however the method was not able to reduce the errors in extreme precipitation these findings agree with other studies on the performance of bias correction methods gudmundsson et al 2012 gutjahr and heinemann 2013 huang et al 2014 our results moreover suggest that the bias correction is highly dependent on the observations used to correct the data and the period selected for calibration lafon et al 2013 we used a 16 year calibration period limited by the length of gripho and indeed this limited length of available data presents a great challenge for example huang et al 2014 pointed out that the characterization of future flood hazards by using bias corrected climate outputs requires a long calibration period to avoid problems in generating transfer functions furthermore observed and simulated precipitation can differ in timing and intensity of extreme events for different reasons on the one hand precipitation measurements are not error free angulo martínez et al 2018 especially on the sub daily scale on the other hand convection is parameterized in our climate simulations which could lead to errors in capturing extreme sub daily precipitation hohenegger et al 2008 klein et al 2013 the latter may cause an effect on the transfer functions developed for correcting data thereby causing a misrepresentation of precipitation peaks faghigh et al 2022 since bias correction is a post processing technique created for correcting simulation statistics such as mean variability or high quantiles it cannot correct single events responsible for floods therefore if the rcm has problems capturing physical processes that lead to flooding conditions it is unlikely that bias correction can provide an actual improvement of this problem huang et al 2014 in this sense the use of climate outputs from convection permitting simulations could be beneficial as they can better represent fine scale details of precipitation patterns in both frequency and intensity at the sub daily scale pichelli et al 2021 which could have a substantial impact on the evaluation of future flood risks we also investigated the effect of bias corrected climate outputs on river discharge and found that the bias correction leads to a better overall agreement with chym obs in capturing the seasonal mean flows and the average yearly peak flows however in some regions the use of corrected forcings resulted in higher discharge values than in chym obs suggesting that the method does not always suitably correct sub daily discharge moreover the comparison with observed discharge data using the kge skill score metric highlighted that the bias correction is unlikely to provide better daily flow compared to the simulation fed with raw data our findings partially agree with other studies assessing the effect of bias correction methods on seasonal precipitation and discharge simulations crochemore et al 2016 tiwari et al 2021 which found a benefit in using bias correction for precipitation but not for streamflow projections with and without bias correction showed similar patterns of change in both mean precipitation and discharge for extremes although the sign of the change signal is similar in the two approaches its magnitude is amplified in some parts of italy especially at the end of the century in any case both bias corrected and raw simulations exhibited a prevailing positive change signal over italy with increases in the annual mean river flow of about 30 by the end of the century under the rcp8 5 scenario our results show that the increase in mean flow is more evident during the winter when changes of up to 120 may be amplified by enhanced snowmelt in areas such as the po basin coppola et al 2014 moreover the results from raw and bias corrected climate inputs indicated a ubiquitous increase in extreme precipitation coppola et al 2021 and discharge with a consequent increase in flood hazard these findings are consistent with those from huang et al 2014 who found that approximately 75 of the change signal for daily peak flows of the 50 year return period was the same using raw and bias corrected climate data in hydrological simulations over catchments in germany extreme discharge changes were shown to agree with other studies conducted over the european region for example alfieri et al 2015 using an ensemble of euro cordex simulations to feed the lisflood hydrological model concluded that extreme discharge is likely to increase over the po basin with q100 increasing by more than 40 by the end of the century similarly rojas et al 2012 who used 12 simulations conducted within the ensembles project found an increase in flood hazards in northern italy more recently di sante et al 2021 analyzed river flood projections in europe using runoff from three ensembles of climate simulations to feed the chym model and found significant increases in q100 over italy mainly over the po basin and the puglia region in that study the authors pointed out that the increases in extreme discharge will most likely be caused by significant increases in extreme precipitation which is consistent with our results although this study is based on a single model and scenario simulation it still shows how i hydrological model simulations driven by rcm outputs both in perfect lbc and scenario simulations are able to reproduce the climatology of discharge over the italian river network when compared to available observations ii bias correction is not necessary neither recommended when long term mean change signals are investigated and its added value is generally not obvious especially in terms of extremes repeating the study from a multi model ensemble perspective would give more robustness to these conclusions credit authorship contribution statement matilde garcía valdecasas ojeda conceptualization methodology investigation software validation formal analysis visualization writing original draft writing review editing fabio di sante conceptualization investigation methodology software writing review editing erika coppola conceptualization investigation writing original draft writing review editing supervision project administration resources funding acquisition adriano fantini conceptualization methodology investigation software validation formal analysis data curation rita nogherotto conceptualization investigation writing review editing visualization francesca raffaele conceptualization investigation writing original draft visualization filippo giorgi writing review editing supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments first author was supported by ogs and cineca under hpc tres program award number 2020 02 and at present is supported by feder junta de andalucía consejería de transformación económica industria conocimiento y universidades project p20 00035 we thank the cetemps and dr marco verdecchia for data support we thank the anonymous reviewers for their valuable comments that helped to improve this work appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128628 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
2681,this study proposes to test the hypothesis that theory guided machine learning model can be effectively applied to model the behavior of a real aquifer for this purpose a theory guided multilayer perceptron model tgmlp for real aquifers was developed to simulate groundwater flow dynamics a comparison of the performance of the tgmlp with that of a numerical model nummod and a traditional multilayer perceptron model mlp was performed the ability of these three models to capture the spatiotemporal dynamics of groundwater was evaluated the degree of pde violation of the tgmlp model was also assessed and the applicability of these three models in a real world setting was discussed the saint honoré unconfined aquifer quebec canada which has been extensively monitored over the last few years was used as an experimental laboratory for this study historical groundwater levels recharge precipitation mean temperature and streamflow data were used to calibrate train validate and test the models the results show that the performance of the tgmlp far exceeds that of the numerical and traditional mlp models that the mlp model is a good interpolator but is unable to extrapolate and that only the numerical and tgmlp models are able to capture the spatiotemporal dynamics of groundwater flow and represent the dominant flow direction in the aquifer it was found that the tgmlp model better approximates the solution of the pde at 70 of the locations these results support the hypothesis that tgmlp is effective in modeling the spatiotemporal dynamics of groundwater in a real aquifer even if improvements are needed although the tgmlp model is capable of representing groundwater flow dynamics to some degree its implementation requires much higher computational costs than a numerical model however these can be reduced with the use of a gpu to speed up the calculations keywords theory guided machine learning numerical modelling groundwater flow statistical modelling optimization data availability we shared our data and codes on mendeley data the link is specified in the paper section 2 2 1 introduction studying the workings of groundwater systems involves a number of traditional tools and techniques to determine the nature of the terrain through which groundwater flows and the physical properties that control this flow such characterization also requires determining how these systems are supplied where they discharge their physical boundaries and their interaction with neighboring hydrogeologic systems all this information can be used to formulate a so called conceptual model of a hydrogeological system the conceptual model can be defined as the set of assumptions made to describe the understanding of a groundwater system enemark et al 2019 based on the conceptual model a numerical model can be constructed to simulate and eventually predict how the hydrogeological system functions when it undergoes disturbances the numerical model is a tool commonly used in hydrogeology its purpose is to solve a discrete form of the equations that describe the groundwater flow under the assumptions that constitute the conceptual model feng et al 2011 for example developed a feeflow numerical groundwater model to simulate regional flow variations under different water management scenarios the results of their study showed a continuous decline in groundwater levels over time under the management conditions prevailing at the time of the study vu et al 2021 used an integrated method of overlaying a modified version of the drastic index and a modflow numerical model to predict the vulnerability and sustainability of groundwater under various climatic conditions and anthropogenic activities the results of their study showed that variations in future climate conditions exerted little influence on the variations in vulnerability of the studied basin but based on the analysis of sustainability indicators the groundwater resource system was in a critical condition of high vulnerability although numerical models are an effective tool for studying groundwater systems the assumptions on which they are built are a major source of structural uncertainty and can affect the accuracy of the model to address the issue of uncertainty and model accuracy the multi model approach which consists in developing plausible alternative conceptual models and evaluating them through numerical modelling is one of the traditional possible solutions enemark et al 2019 however the multi model approach can be time consuming which limits its practical use since the popularization of artificial intelligence in the 1980 s barr et al 1981 machine learning ml a branch of artificial intelligence is increasingly used in various scientific fields machine learning relies on a sufficient set of data to approximate any non linear function between some input and output variables in hydrogeology ml algorithms are used with a good level of satisfaction to perform specific modeling tasks such as mapping the spatial distribution of groundwater salinity sahour et al 2020 mosavi et al 2021 tran et al 2021 uncertainty quantification gadd et al 2019 song et al 2020 lykkegaard et al 2021 improving the accuracy of groundwater level prediction banadkooki et al 2020 cai et al 2021 groundwater potential mapping kalantar et al 2019 lee et al 2020 kumar et al 2021 or determination of physical parameters of aquifers tayfur et al 2014 hou et al 2021 for example banadkooki et al 2020 investigated the impact of different input variables on the accuracy of groundwater level prediction of hybrid machine learning models the algorithms used were neural network with radial basis function whale algorithm multilayer perception and genetic programming precipitation mean temperatures and their time shifted equivalents combined in various ways were used as inputs the results show that the algorithm that generates the best performing model depends on the combinations of input variables used tayfur et al 2014 used sugeno fuzzy logic mamdani fuzzy logic multilayer perceptron neural network neuro fuzzy algorithms and an ensemble algorithm that combines the predictions of the previous algorithms to determine the best model for hydraulic conductivity estimation for a heterogeneous aquifer in their study using hydrogeological and geoelectric data it was found that the best model was the one generated by the ensemble aggregation algorithm machine learning algorithms in their traditional form are effective tools for learning any non linear relationship between a set of inputs and a set of outputs with a high level of accuracy and a relatively short computation time however machine learning algorithms generally have poor explanatory power and therefore are not as useful as physics based modelling to improve our understanding of the physical phenomena in many contexts this black box aspect limits the operational applicability of traditional machine learning techniques recently raissi et al 2019 popularized a new paradigm by incorporating during training certain constraints related to the physics governing the phenomenon under study so that the algorithm not only learns from the data but also refrains from deviating too far from the known governing laws of physics this paradigm is commonly referred to as theory guided machine learning wagner and rondinelli 2016 karpatne et al 2017 esterhuizen et al 2020 adombi et al 2021 wang et al 2020 compared the predictive performance of a deep neural network dnn model against that of a theory guided dnn tgdnn model to do this they used simple idealized two dimensional hydrogeological configurations for spatio temporal modelling of groundwater levels using time series of groundwater levels synthetically generated by a numerical model as reference data the results showed that the tgdnn model achieves much better predictability reliability and generalization than the dnn models tartakovsky et al 2020 used a theory guided deep neural network to estimate hydraulic conductivity in saturated and unsaturated flows governed by darcy s law in idealized synthetic hydrogeological settings the results show that the model is well suited for hydraulic conductivity estimation unlike traditional machine learning to our knowledge theory guided machine learning has never been applied to a real world hydrogeological setting in such a setting aquifer geometry can affect groundwater flow the spatial distribution of observation wells is sparse hydrodynamic properties are known only at a few points within the study area and many uncertainties are pervasive such as partial knowledge of the geology studies in idealized synthetic hydrogeological settings have shown some interest in applying theory guided machine learning but do not document its effectiveness and limitations in real world applications considering the inherent difficulties in assessing aquifer systems and the necessity of representing these invisible systems by conceptual models theory guided machine learning could be a useful tool to be integrated in the toolbox of hydrogeologists to assess these systems with a higher degree of confidence this study proposes to test the hypothesis that a theory guided machine learning model can be effectively applied for inverse modeling of the groundwater dynamics of a real aquifer to verify this hypothesis we built and used a theory guided machine learning model to simulate groundwater dynamics and compare it both to observations and to other commonly used tools such as numerical modelling and traditional machine learning our starting hypothesis is based on the fact that theory guided machine learning considers the actual behavior of an aquifer and not solely on its hydrogeological properties which are assessed by hydrogeologists with a generally high degree of uncertainty and poor confidence we posit that this approach could be effective in a real world case study in this study the inverse modeling of the spatiotemporal dynamics of groundwater in a real aquifer is investigated and compared using three methods a numerical model nummod a multilayer perceptron mlp and a theory guided multilayer perceptron tgmlp the saint honoré aquifer quebec canada constitutes a good experimental laboratory for this study because of the significant extent of knowledge previously acquired at this site e g tremblay 2005 parent and occhietti 2007 boumaiza 2008 labrecque et al 2019 boumaiza et al 2020 boumaiza et al 2021 this unconfined granular aquifer has been equipped with a sufficient number of piezometers that are continuously monitored and has been well characterized over time in terms of geology hydrodynamic properties and hydraulic limits in this study the temporal extrapolation ability of the different models is not investigated this study is therefore limited to the following objectives compare the performance of nummod tgmlp and mlp for the inverse modeling of gwl dynamics evaluate the ability of the three models to capture the spatiotemporal dynamics of gwl evaluate the effect of partial differential equation pde violation by the tgmlp model discuss the applicability of the three models in a real world setting 2 study area and data 2 1 study area the saint honoré aquifer belongs to the saguenay lac saint jean slsj region of quebec canada fig 1 the portion of the aquifer considered as the study area is located near the saint honoré airport between the caribou river ungauged to the west and the valin river gauged to the east and covers approximately 36 7 km2 in addition to pumping wells streams constitute the discharge sites of the aquifer while the primary source of recharge of the aquifer is precipitation tremblay 2005 precipitation is estimated to average 930 mm per year boumaiza et al 2021 during most of a given year three directions of groundwater flow are observed southwestward northwestward and westward but the southwestward flow is dominant tremblay 2005 the development of the saint honoré unconfined aquifer can be traced back to the last glacial event in the slsj area between 85 000 and 7 000 years ago when the overlying glacier retreated to form a discontinuous and heterogeneous layer of geologic materials including glaciolacustrine and glaciofluvial deposits and till parent and occhietti 2007 a marine invasion subsequently occurred causing the deposition of fine clay like sediments a marine regression then followed and these sediments were covered by deltaic granular sediments that constitute the saint honoré aquifer boumaiza et al 2021 the granular sediments are up to 50 m thick in the study area and consist mainly of sands and silts in some parts of the study area the granular sediments are directly underlain by precambrian crystalline bedrock belonging to the canadian shield and in other parts they are underlain by clays or till the northern boundary of the study area is marked by an outcrop of precambrian bedrock the western boundary by an outcrop of a clay layer with the presence of the caribou river a little further south all along the eastern boundary outcrops of the bedrock or till layers are found the portion of the saint honoré aquifer considered in this study has been represented in tremblay 2005 as a succession of four stratigraphic units each composed of several hydrogeologic layers that are homogeneous and isotropic in their hydrodynamic properties fig 2 illustrates the layout of the stratigraphic units s units and their hydrogeological layers and also locates the wells and the monitored piezometers 2 2 data the models in this study were developed using hydrogeological hydrological and meteorological variables the data including the processed input data and raw and processed results algorithms numerical model and software used for numerical modeling are available on mendeley data https doi org 10 17632 87fkztgbbh 1 specifically the data used are daily gwl at the six continuously monitored piezometers daily precipitation and mean temperature daily recharge rate monthly pumping rates at the seven wells in the aquifer and stream flow measurements taken between 2001 and 2004 by tremblay 2005 the groundwater levels data were measured automatically between 09 11 2016 and 30 11 2017 at 15 minute time steps and then processed into daily time series daily precipitation and mean temperature were provided in the form of 0 1 x 0 1 weather grids by the info climat service of quebec s ministère de l environnement et de la lutte contre les changements climatiques melcc since the study area was intersected by six weather grids a spatial average of precipitation and that of the mean temperature were calculated pumping rate data were obtained through direct communication with the institutions in charge of their management niobec mine and municipality of saint honoré monthly pumping rates were also transformed into daily data for the numerical and tgmlp models the topographic surface and bedrock elevations were retrieved from the programme d acquisition des connaissances sur les eaux souterraines paces database of the melcc the sequence of stratigraphic units used in this paper is based primarily on the interpretation of the stratigraphy proposed by tremblay 2005 the hydrodynamic property ranges of the hydrogeological layers of the stratigraphic units were compiled from the data in tremblay 2005 but also from the paces database the ranges of values for hydrodynamic properties are shown in table 1 the daily recharge series was inferred by the water table fluctuation wtf method over the period 09 11 2016 to 30 12 2017 at piezometer pz 18 data produced by labrecque et al 2019 the recharge time series at pz 18 is considered to be representative of recharge dynamics over the entire aquifer 3 methods and models in groundwater dynamics modeling the inverse problem is resolved in two steps the first step is to identify the model that most appropriately describes the groundwater flow in the aquifer under study this involves for example determining the governing equations boundary conditions or heterogeneities in the aquifer this leads to the establishment of a conceptual model the second step is then to estimate or calibrate the model parameters such as hydrodynamic parameters recharge and boundary conditions in order to reproduce field observations such as groundwater levels as closely as possible because the saint honoré aquifer has been extensively characterized we assume that the conceptual model already established for this aquifer see tremblay 2005 and summarized in section 3 1 and fig 3 has a high degree of representativity therefore the inverse problem of the numerical model will be to calibrate the hydrodynamic parameters of the aquifer for the tgmlp model the hydrodynamic parameters calibrated by the numerical model will be provided as prior knowledge and the inverse problem will then consist in estimating the neural network parameters finally for the mlp the inverse problem will also be to calibrate the neural network parameters 3 1 numerical model the numerical groundwater flow simulation model was built using the free version of the marthe software developed by the french geological survey thiéry 1990 the free version of marthe can be downloaded at https www brgm fr fr logiciel marthe logiciel modelisation ecoulements souterrains marthe solves a 3d form of the groundwater equation of continuity using the finite volume method with initial and boundary conditions more details on the equations and approximation methods can be found in thiéry 1990 the finite volume method consists in approximating the groundwater equation by discretizing the groundwater flow system into finite volumes and the simulation time into discrete time steps at each time step the input data recharge and pumping rates is considered invariant marthe is able to couple groundwater flow with stream exchanges through a water balance equation that considers exchanges between groundwater and streams runoff source sink terms and possibly a storage term it is also possible to model the interaction between saturated and unsaturated zones given the strong non linearity of the coupling with the unsaturated zone marthe exploits the notion of pseudo vadose zone the pseudo vadose zone is used to simulate the water flows in the unsaturated zone without having to provide retention and permeability laws the details of the pseudo vadose zone concept are given in thiéry 1990 the marthe model built in this paper is a 3d groundwater flow model coupled with groundwater stream exchanges and a pseudo vadose zone the study area was discretized along both the x y and z axes and the time dimension t in the horizontal plane the mesh is square with side δx δy 100 m the vertical mesh consists of four model layers representing the stratigraphic units of the saint honoré aquifer the vertical mesh is made so that at each point the stratigraphic units have approximately the same thickness the vertical mesh was created based on the surface and bedrock elevation maps of the saint honoré aquifer time was discretized into a finite number of daily intervals corresponding to the available gwl time series i e 387 daily time steps the lateral hydraulic boundaries of the aquifer were chosen to coincide with the natural boundaries see section 2 1 thus everywhere on the lateral boundary of the aquifer except at the border of the caribou river a no flow boundary was defined as it corresponds either to a clay barrier or to the outcrop of the precambrian bedrock or till the caribou river and its tributaries in the study area are defined as cauchy boundaries doctor lake is considered a constant groundwater level boundary wells are represented as flow imposed boundaries the upper aquifer boundary is considered a flux imposed boundary with the flux corresponding to the recharge rate finally the aquifer lower boundary is considered a no flow boundary this is because the aquifer is underlain by bedrock which is considered impermeable fig 3 presents the synthesis of the conceptual model of the aquifer a steady state calibration performed on 09 11 2016 allowed an initial adjustment of the hydraulic conductivity of the different hydrogeological layers of the model the physical properties of the streams hydraulic conductivity and bed thickness were also calibrated in order to ensure that the stream flows remained within the range of values of the discontinuous flows measured over the period 2001 2004 indeed due to the absence of flow measurements in the caribou river over the period investigated in this study it was assumed that the average stream flows measured over the period 2001 2004 are not significantly different from those that would have been measured over the period of investigation i e from 09 11 2016 to 30 11 2017 next a transient calibration was performed using the groundwater level time series from four of the available piezometers in the study area as a calibration quality criterion to adjust the storage coefficient values and improve the hydraulic conductivity calibration these piezometers are la 2 pz 16 pz 1 pz 20 see fig 2 they were selected to ensure approximately one piezometer per hydrogeological layer the initial groundwater levels used for transient calibration were those obtained after steady state calibration the final model selected is the one for which not only the values of the storage coefficient and hydraulic conductivity remain within the ranges of values specific to the saint honoré aquifer see table 1 but also for which the simulated groundwater level series follow the same dynamics and present an acceptable accuracy compared to the observations the other two piezometers are used for testing these are the piezometers pz 18 and pz 21 see fig 2 initially the calibration of the numerical model was performed automatically using the optimization algorithms integrated into the marthe software and the ranges of values in table 1 however the values of the calibrated hydrodynamic parameters and their spatial distribution were not in agreement with the hydrogeology of the terrain this is why we then opted for a manual calibration the simulated groundwater levels following this manual calibration are very close to those of the automatic calibration but provide a better agreement with the hydrogeology of the terrain furthermore the values of the manual calibration parameters and their spatial distribution support those of previous numerical modeling studies performed in the study area e g tremblay 2005 in addition the pumping tests a field experiment whose purpose is to evaluate the physical properties of the medium with a certain level of uncertainty support the results of the manual calibration field data remain a reference even if they are measured in a punctual way and with a certain level of uncertainty 3 2 machine learning models 3 2 1 multilayer perceptron the multilayer perceptron mlp is an algorithmic structure belonging to the family of feedforward artificial neural networks considered as universal approximators of any continuous function cybenko 1989 hornik 1991 a mlp is composed of an input layer an output layer and one or more hidden layers the number of hidden layers defines the depth of the network beyond one hidden layer the network can be qualified as deep each layer is made of a given number of neurons neurons in two given contiguous layers of the mlp are fully interconnected and each of the connections is represented by the parameter θ w b where w and b are the weight and bias parameters respectively data from a given layer is aggregated using weights and biases before being transformed by a nonlinear activation function and then passed on to the next layer one by one the input data undergoes transformations through the hidden layers until it reaches the output layer to ensure that each input variable is given equal weight they are normalized between 1 and 1 this reduces the effect of the differences in magnitude between the range of different input variables on the model approximation using a back propagation algorithm data transmitted from the input layer to the output layer is analyzed to iteratively adjust the network parameters until the outputs minimize a predefined cost function the process of transmitting data from the input layer to the output layer followed by backpropagation is repeated on small batches of data over a number of iterations called epochs or until certain values of the selected stopping criteria are met it is important to note that an epoch is composed of a certain number of sub iterations defined in particular by the number of batches of data to be used per sub iteration the mean square error between the observed outputs and the outputs simulated by the mlp model is often used as a cost function l obs θ to constrain its learning the update of the neural network parameters by the backpropagation algorithm is done according to equation 1 1 θ i θ i 1 λ l obs θ θ i 1 and θ i represent respectively the previous and the updated value of θ λ is a hyperparameter of the network to be defined and is called the learning rate l obs θ is the gradient of the cost function l obs with respect to θ in contrast to the numerical model the spatial and temporal simulation of groundwater dynamics with the mlp is two dimensional fig 4 a illustrates the mlp architecture and summarizes the learning process 3 2 2 theory guided multilayer perceptron the tgmlp is a mlp whose learning is constrained not only by the observed data but also by the theory governing the phenomenon under study in this study the equation governing the groundwater flow as well as the boundary and initial conditions are used as additional constraints to the l obs cost function mse used for the traditional mlp as with the mlp the spatiotemporal simulation of groundwater dynamics with tgmlp is two dimensional and only the flow in the saturated zone is considered the general partial differential equation pde describing such a system is given by equation 2 2 s aq φ t x t x φ x y t y φ y q x y ω t 0 t x and t y are the transmissivity values m 2 d along the x and y coordinate axes m φ is the groundwater level m q represents the water source and or sink term m d with q 0 for flow out of the groundwater system and q 0 for flow into the system s aq denotes the storage coefficient t is time d ω denotes the internal aquifer domain transmissivity is given by the product of hydraulic conductivity and saturated water thickness for an unconfined aquifer the saturated water thickness can be defined as the difference between the gwl and the aquifer bottom elevation thus equation 2 is rewritten as equation 3 3 s aq φ t x k x φ z b φ x y k y φ z b φ y q x y ω t 0 where k x an k y are the hydraulic conductivity m d along the x and y coordinate axes z b represents the aquifer bottom elevation m because the tgmlp model is a 2d model we chose stratigraphic unit 3 as representative of the current knowledge available about the aquifer as mentioned in section 2 1 the stratigraphic units are considered as a succession of homogeneous and isotropic hydrogeological layers therefore the hydraulic conductivities are independent of the x y coordinates for a given hydrogeological layer in addition according to the conceptual model summarized in fig 3 the aquifer is composed of cauchy boundaries represented by the rivers a dirichlet boundary represented by doctor lake imposed flow boundaries represented by recharge and pumping and finally a zero flow boundary represented by the edges of the aquifer other than the caribou river thus the final pde that represents the aquifer according to the conceptual model defined earlier is given by equations 4 to 7 4 s aq φ t k x φ z b φ x y φ z b φ y r δ w q w δ x 2 δ s q s x y ω t 0 5 φ t x y φ ini t x y x y ω ω d ω n t 0 6 φ t x y φ dir t x y x y ω d t 0 7 φ n t x y 0 x y ω n t 0 where φ ini and φ dir are respectively the gwls at the initial time and the gwls imposed as the dirichlet condition q s is the exchange flux between the sections of rivers and the aquifer ω ω d and ω n denote the internal aquifer domain dirichlet and neuman boundary condition domains of the study area n is the direction normal to the neumann boundary domain δ x is the distance between two points in the or y direction δ w and δ s are equal to 1 if the point where the equation is applied is respectively a well or a section of river otherwise δ w and δ s are equal to 0 the training is performed by forcing the tgmlp model not only to fit the gwls observations but also to approximate the solution of the pde defined by equation 4 to achieve this the training consists in minimizing the difference between the observed and simulated gwls as well as the residuals of equations 4 to 7 thus the total cost function to be minimized is given by equation 8 8 l tot l obs l ini l dir l neu l pde where l pde l ini l dir and l neu are the cost functions related to the residual of the equations 4 to 7 respectively to evaluate the derivatives in equations 4 to 7 one can use the automatic differentiation ad method wang et al 2020 or traditional methods such as the finite difference method fdm e g tartakovsky et al 2020 wang et al 2021 the fdm was considered in this study because of the advantage of computational cost and the weak nonlinearity of equation 4 which reduces the approximation error fdm is 1 411 to 1 562 times faster than ad using a gpu for computational acceleration this difference appears to be minor as it corresponds to a gain of 31 to 42 min in this study on the other hand without the use of a gpu the time difference would increase corresponding to more than 3 1 to 4 2 h in addition the applicability of the tgmlp model in a real world setting discussed here includes the issue of computational time this is also one of the reasons why the least time consuming derivation method fdm was presented in this study in problems with very strong nonlinearity or involving pde of an order greater than or equal to 3 it would be more advantageous to use automatic differentiation which provides an exact derivative consider the tgmlp model represented by equation 9 9 φ sim t g m l p t x y θ each term of the total cost function obtained by the fdm with the introduction of dummy points at the boundaries of the study domain for the neumann condition is defined in equations 10 to 14 10 l dir 1 m dir m b i 1 m dir j 1 m b φ sim ij φ ini ij 2 11 l ini 1 m ini i 1 m ini φ sim ij φ ini ij 2 12 l neu 1 m neux m b i 1 m neux j 1 m b φ sim e i j φ sim w i j 2 δ x 2 1 m neuy m b i 1 m neuy j 1 m b φ sim n i j φ sim s i j 2 δ x 2 13 l pde 1 m pde m b i 1 m pde j 1 m b f pde ij 2 with 14 f pde s aq p δ t φ sim t p φ sim t δ t p k p φ sim t p z b p δ x 2 φ sim t e φ sim t w 4 φ sim t p φ sim t n φ sim t s r t p δ w q w t p δ x 2 δ s k s p e s φ ref t p φ sim t p φ sim t p φ sim t e φ sim t w φ sim t n φ sim t s represents the gwl at location p and the gwl of its eastern e western w northern n southern s neighbors respectively at time t δ x is the width of the square mesh δ t is the length of a time step s aq p and k p are the storage coefficient and the hydraulic conductivity at p respectively z b p is the aquifer bottom elevation at p k s p is the hydraulic conductivity of the bed of the stream section and φ ref t p is the elevation of the water level in the stream at p q w t p is the pumping rate r t p is the recharge rate m dir m ini m neux m neuy m pde are respectively the number of locations sampled to evaluate the cost functions related to the dirichlet condition l dir doctor lake ω d the initial condition l ini entire domain ω ω d ω n the no flow boundary condition l neu external boundaries of the study area except the caribou river ω n and the governing equation l pde internal domain ω m b is the number of time steps batch size used for a given training epoch fig 4b illustrates the tgmlp architecture and summarizes the learning process the methodology used for numerical model calibration training and validation of machine learning models and their testing is summarized in fig 5 3 2 3 conditions for stopping the training the training of ml models consists in adjusting their parameters in order to make the cost function tend towards a minimum value considered satisfactory to stop the training in this study to follow the evolution of the training two metrics were used for the mlp and a third metric was added for the tgmlp the first metric is the root mean square error between the observed and simulated gwls rmse the second is the interpolation capacity ic and the third is the mean residual of the pde mrp the ic is defined by equation 15 15 ic rmse v a l i d a t i o n d a t a rmse t r a i n i n g d a t a the perfect model is the one with rmse 0 ic 1 and mrp 0 in this study training is stopped when rmse a ic 1 b and mrp c the fixed values of a b and c are presented in section 3 2 4 3 2 4 architecture development the ml models were developed in python with the tensorflow library and run in the google colab pro environment with computational acceleration using a tesla p100 pcie 16 gb gpu the number of neurons in the input and output layers is known and depends on the number of dimensions of the input and output data in this study time t spatial coordinates x and y the moving average of precipitation p m a 30 and mean temperature t m a 30 30 day window are the inputs of the mlp model i e five neurons whereas only t x and y are the inputs of the tgmlp model i e three neurons groundwater levels are the only output variable i e one neuron for both models the choice of the variables t x y makes it possible to consider the spatial and temporal character of the problem studied for the mlp and tgmlp models moreover these variables are useful to evaluate the physics related cost functions equations 12 and 13 during the training of tgmlp since recharge is incorporated directly into the total cost function it was not considered useful to include it as an input variable for tgmlp the reason for choosing the moving average of precipitation and that of the mean temperature as mlp input variables is that gwl dynamics in the saint honoré aquifer are determined in part by precipitation and evapotranspiration the latter is partly related to temperature to facilitate the training of the mlp it is advisable to choose variables that are independent but correlated with the output variable after several tests it was found that the 30 day moving average of precipitation and mean temperature showed the highest correlation with groundwater elevations in all piezometers in the study area table 2 summarizes the cross correlation results the hyperbolic tangent activation function was applied to the hidden layer neurons while the linear function was applied to the output layer neurons the number of hidden layers and the number of their neurons were determined by a trial and error procedure the procedure starts with one hidden layer at the beginning and increases up to 10 hidden layers with a step of 1 at each trial for a given trial the number of neurons varies with steps of 5 starting from 10 neurons to a maximum of 50 neurons for each trial representing a given number of hidden layers and neurons the mlp is trained to minimize the mean square error between observations and simulated values this means that only points where piezometric observations exist were used for training validation i e in four piezometers chosen so that there is approximately one piezometer per hydrogeological layer these piezometers are the same as those used for the calibration of the numerical model the other two piezometers of a total of six were used for the test stage for each of the training validation piezometers a temporal sampling was performed in particular the duration of the simulation defined by the length of the gwl time series of the piezometers was discretized and then randomly sampled at 70 for training the remaining 30 was used to evaluate the interpolation capacity ic of the model at each training epoch in the validation stage training tgmlp consists in optimizing its parameters by minimizing the total cost function equation 8 to evaluate the physics related cost functions in equation 8 spatial sampling of locations was performed in the different hydrogeologic layers of stratigraphic unit 3 using the spatial points generated by the numerical model discretization then for each of the locations the same time sampling as performed for the mlp was applied the piezometers used for numerical model calibration or mlp model training validation are the same as those used for tgmlp model training validation the same applies to the test piezometers the values of the hydrodynamic parameters of the aquifer and the physical properties of the stream bed used in the tgmlp method are those obtained after the calibration step of the numerical model unlike for the numerical model streams and wells are considered as source sink terms and are directly incorporated into the governing equation see equation 4 the initial groundwater levels used for tgmlp training validation are those observed at the 6 piezometers at date zero 09 11 2016 the adam optimization algorithm was used to appropriately adjust the values of the weight and bias parameters for the mlp and tgmlp the goal is to build machine learning models that are as parsimonious as possible while showing good interpolation ability thus the stopping criterion for mlp learning is to achieve a ic equal to 1 2 and a rmse in the training stage lower than 0 05 m the mlp model that meets these two criteria with the lowest density structure is selected as the final model the stopping criterion for tgmlp training is not only to achieve a ic equal to 1 2 and an rmse in the training stage lower than 0 05 m but also to present a residual of the pde lower than 0 0125 m d a value justified by the desired degree of physical consistency for tgmlp models this value corresponds to a physical inconsistency of approximately 0 05 m the tgmlp model that meets all these criteria and presents the lowest density structure is selected as the final model the learning rate and batch size used are respectively 5 10 4 and 2 for both mlp and tgmlp 3 3 performance assessment metrics the performance of the different models was evaluated using the nash sutcliffe efficiency nse and the percentage of normalized rmse hereafter called nrmse nrmse is defined by equation 16 16 nrmse 100 rmse φ obs max φ obs min with φ obs max and φ obs min the minimum and maximum values of the time series of the observations m nse is used to evaluate the simulation ability of a model a perfect model is one whose simulation ability is 1 the nrmse quantifies the accuracy of a model with values ranging from 0 to infinity a model with perfect accuracy will have a value of nrmse equal to 0 while values further increasing from 0 will indicate decreasing model accuracy 4 results the results of the calibration training validation are presented in section 4 1 the results obtained with the test data set are presented in section 4 2 nrmse and nse values were used to evaluate the performance of the models both in the calibration training validation stage and the test stage a comparison of the spatial distribution of the gwl field is performed between the different models to evaluate their ability to capture the groundwater flow dynamics in section 4 3 finally the degree of pde violation by the tgmlp model is examined in section 4 4 4 1 model calibration training validation the numerical model was calibrated using daily data from 09 11 2016 to 30 11 2017 drawn from the four piezometers mentioned in section 3 1 and to a lesser extent stream flow measured at specific timepoints over the period 2001 2004 the final numerical model was chosen so that the simulation would match the observed gwls as closely as possible the determination of the mlp and tgmlp architectures was performed as described in section 3 2 4 for the implementation of the mlp and tgmlp models the observed gwls of the four piezometers were randomly subdivided according to the temporal component into a training set and a validation set the mlp model that best satisfies all stopping criteria is composed of 3 hidden layers of 25 neurons each results not shown as for the tgmlp model it is composed of 7 hidden layers of 40 neurons results not shown fig 6 shows the convergence of cost functions for the two selected architectures during training as a function of epochs for the mlp and tgmlp models fig 7 shows the comparison between observed gwls and gwls simulated by the different models in the four piezometers and fig 8 summarizes the results for the performance criteria in the calibration training validation stage for all piezometers we observe that the nrmse values fig 8a decrease from the numerical model to the tgmlp model and the nse values increase from the numerical model to the tgmlp model fig 8b nrmse values for tgmlp are less than 4 for all piezometers nearly 4 times less than the lowest nrmse value from the numerical model the nrmse values for mlp range from just over 11 to nearly 2 as for the nse value it is very close to 1 for the tgmlp model the nse is greater than 0 7 for all piezometers for the mlp model while its value is very mixed for the numerical model all this means that the accuracy and simulation ability of the tgmlp model are higher than those of the mlp model which in turn are higher than those of the numerical model referring to the la 2 and pz 16 piezometers it can be observed that the nrmse values of the numerical model are all above 30 and the nse values are close to 0 or negative all this clearly indicates that the numerical model has a low accuracy and its simulation ability is at most equal to the average groundwater level observed in these piezometers the poor simulation ability of the numerical model for la 2 and pz 16 can also be explained visually by the time lag seen between the observed and simulated series fig 7 the time lag of the simulated series compared to those observed at the la 2 and pz 16 piezometers may be due to several factors the first factor is the diffusivity of the aquifer in the vicinity of the two piezometers an increase in diffusivity in the vicinity of la 2 and a decrease in diffusivity in the vicinity of pz 16 could improve the fit of the simulations to observations this would probably require a review of the initial conceptual model by introducing heterogeneity around the two piezometers the second factor is related to the thickness of the pseudo vadose zone which if reduced around la 2 and increased around pz 16 could also improve the fit the third factor may correspond to phenomena not considered in the conceptual model that would influence gwls around the piezometers such as private wells and various small lakes around la 2 fig 2 as mentioned above the investigation of all these factors requires proposing an alternative conceptual model based on the acquisition of new data these are currently not available but may be interesting for future studies at pz 1 and pz 20 the nse values fig 8b greater than 0 5 show that the numerical model demonstrates a certain simulation ability for both piezometers however the simulation ability of the numerical model remains low compared to those of the mlp and tgmlp models for which the nse value tends to approach 1 in summary for the calibration training validation stage it can be concluded that the tgmlp model is much more accurate than the mlp model and that both are much more accurate than the numerical model the simulation ability of the tgmlp model and the mlp model are very high with the tgmlp being superior in addition the simulation ability of the tgmlp and mlp models is far superior to that of the numerical model which has an average simulation ability 4 2 model testing testing of the different models was performed using the gwls time series at the two remaining piezometers i e pz 18 and pz 21 fig 9 shows the comparison between the gwls at test stage fig 10 summarizes the performance criteria values of the different models at piezometer pz 18 the value of nrmse fig 9a of the mlp model which exceeds 100 and reaches almost 7 times that of the numerical model and more than 11 times that of the tgmlp model expresses the fact that the accuracy of the numerical and tgmlp models is much better than that of the mlp the nse value fig 9b which is well below 0 shows that the mlp has a low simulation ability compared to both the numerical and tgmlp models for which the nse value is greater than 0 3 the nse of the tgmlp is twice as high as that of the numerical model showing that its simulation ability is much higher than that of the numerical model although the nse value of the numerical model is low it expresses an acceptable simulation ability at piezometer pz 21 all models have good accuracy and simulation ability with the tgmlp model being superior to the mlp model which is also superior to the numerical model in terms of nrmse fig 9a and nse fig 9b values however the better accuracy and simulation ability of the mlp model compared to the numerical model is not surprising since the pz 21 test and pz 20 training piezometers are close of each other with a very similar piezometric signature and it is certainly the spatial interpolation ability of the mlp that has been brought into play in this case in summary the performance of the tgmlp model in the test stage which also expresses its extrapolation ability exceeds that of the numerical model similarly the performance of the numerical model is superior to that of the mlp 4 3 capture of groundwater dynamics by the models the numerical model is purely physics based and has acceptable simulation ability it is designed to capture the groundwater flow dynamics within the accuracy limit of the conceptual model thus the examination of the ability of ml models to capture groundwater flow dynamics is evaluated with respect to the numerical model fig 11 and fig 12 show the results for two different dates as illustration while fig 13 provides more detail on the differences between the ml models with respect to the numerical model in capturing groundwater dynamics it can be seen both visually and statistically that the tgmlp model is the closest to the numerical model moreover from one date to another the statistics of the differences remain constant for the tgmlp model in contrast to the mlp model on average the difference between the numerical and tgmlp simulations is 1 m with a standard deviation of 3 14 m in addition the dominant flow direction of the gwl field simulated by the tgmlp model is toward the southwest and agrees with the conceptual aquifer model since the southwestward flow is dominant tremblay 2005 in contrast the flow direction proposed by the mlp model is toward the southeast which is the opposite direction to that proposed by the conceptual model fig 14 shows the gwl field simulated by the tgmlp model over a great number of time points to illustrate the spatial consistency of this field with the conceptual model these results mean that only the numerical model and the tgmlp model are capable of capturing the spatial and temporal dynamics of groundwater levels also these results mean that the numerical model and the tgmlp model represent two parallel versions of the modeled aquifer system 4 4 effects of pde violation by the tgmlp model a tgmlp model that perfectly approximates the pde is a model that provides a zero physical inconsistency in reality it is not possible to reach the zero limit for this reason we set a physical inconsistency limit of 0 0125 m d this means that the tgmlp violates the pde on a number of locations to assess the degree of pde violation by tgmlp we plotted the distribution of the pde residual given the gwls simulated by tgmlp at different dates and we displayed the proportion of points where the pde residual is below the threshold of 0 0125 m day fig 15 fig 15 shows that the tgmlp model correctly approximates the solution to the pde depending on the threshold set at a rate of about 70 from one date to another the tgmlp model fails to correctly approximate the pde nearly 30 of the time fig 16 shows the set of unobserved locations where the effects of pde violation were examined for illustration and fig 17 shows the gwls simulated and the absolute mean value of the pde residual at these locations at locations a through f the pde residual is below threshold and the same piezometric signatures as the observation piezometers are obtained for locations h to l where the pde residual is below the threshold or for location g and locations m to p where the pde residual is above the threshold the piezometer signatures do not match the observed piezometers in section 4 3 it was shown that from date to date the tgmlp model produced gwl fields that were spatially consistent with the conceptual model the fact that there are locations where the pde is not violated but which have particular piezometric signatures could mean that these signatures are the result of a strong influence of the source sink terms or neumann conditions near which they are located similarly at locations where the pde is violated the shape of the piezometric signatures may be explained by a poor model constraint on the source sink terms and neumann conditions thus propagating the effect of the pde violation to other locations in the aquifer this remains a hypothesis to be explored and it would be interesting to test this hypothesis in a future investigation for such a study it would probably be more interesting to separate each source sink term into its own equation to better constrain the tgmlp model the particular piezometric signature found could also be due to the fact that the boundary conditions of the conceptual model are incomplete forcing the model to display an undesired behavior it would probably be worthwhile for future investigations to consider the identification of the boundary conditions and the identification of the sink terms for the rivers as part of the inverse problem indeed despite the level of confidence that one may develop concerning a conceptual model such a model will always remain an approximation of reality and will maintain a certain degree of uncertainty that must be taken into account in the modeling process 5 discussion the study conducted in this paper aimed to test the hypothesis that theory guided machine learning can be effectively applied to model groundwater dynamics in a real aquifer the methodology used was to conceptualize and build a theory guided multilayer perceptron tgmlp model suitable for real porous aquifers use it to simulate groundwater dynamics and compare it to observations a numerical model nummod and a multilayer perceptron model mlp with emphasis on applicability to practical hydrogeology the analysis of the results shows that the performance of the tgmlp model outperforms the mlp model which in turn outperforms the numerical model in the calibration training stage however in the test stage the mlp model is unable to extrapolate based on data that it has never encountered before unlike the numerical and tgmlp models therefore the reliability of the numerical and tgmlp models is higher than that of the mlp model also in the test stage the performance of the tgmlp is superior to that of the numerical model in addition the lack of physical constraints in the mlp training resulted in the systematic inability of the mlp to capture groundwater flow dynamics unlike the numerical and tgmlp models the superior performance of the tgmlp model over the numerical model at observation points is probably due to the fact that the tgmlp model was built to learn the physics of groundwater flow in the aquifer and to provide optimal fidelity to observations constraining learning from physics and data probably allows the tgmlp model to benefit from the advantages of both numerical models and traditional multilayer perceptron models which justifies its high performance at these observation points these results confirm the basic hypothesis of this study however it was found that the tgmlp model approximates the pde solution with only 70 of success the poor approximation in 30 of the locations could be due to an effect of pde violation at the sources sinks or in the vicinity of the neumann conditions thus an improvement in the approximation of the pde solution could be achieved by separating the pde cost function into sub cost functions corresponding to the different source sink terms or by considering the source sink terms and boundary conditions as part of the inverse problem this is a hypothesis that remains to be explored it is also interesting to note that because during training the main unknown parameters that determine the accuracy of the model and its physical consistency are the weight bias θ parameter of the neural network the tgmlp paradigm opens up a new way to give physical meaning to θ and thus reduce the black box nature that is usually attributed to artificial neural networks the study of the physical meaning of the θ parameters is beyond the scope of this study but it would be interesting for future works to address this issue especially in the context of the new branch of artificial intelligence called explainable artificial intelligence xai xai aims to design and implement methods to understand what is going on in the black box adombi et al 2021 the use of physics to constrain learning may in certain ways limits some of the traditional advantages of machine learning algorithms such as mlp one of the main characteristics of the mlp is its ability to model any nonlinear relationship between inputs and outputs but this can come at the cost of creating a black box model machine learning lends itself well to large scale and hydrogeological applications where spatial data remain scarce and expensive and can be replaced by easy to access data such as satellite data thus using physics to constrain learning is to reconsider machine learning problems as boundary problems therefore tgmlp can only be applied to terrains for which at least partial information on boundary conditions exist karniadakis et al 2021 and for which physical properties have been estimated as in the process of setting up numerical models another point concerns the computational costs required to implement tgmlp models indeed the optimization process requires a very large number of iterations to converge towards an acceptable solution in the present case at least 1800 epochs of 135 iterations per epoch were required i e 243 000 iterations in total to reach a result satisfying the stopping criteria without computation acceleration using a gpu that performed the computations at a speed of about one epoch per 2 5 s or 75 min the computations would have required about 450 min with an intel r core tm i7 10510u processor 1 80 ghz 2 30 ghz 16 gb ram even though unlike mlp the number of possible solutions models that tgmlp can produce is drastically reduced four possible patterns in the present study obtaining the one pattern for which the stopping criteria are all met may not be achieved on the first try the 450 min that would have been required for the tgmlp training without gpu correspond to 10 2 times the time required for a simulation with the marthe numerical model over the entire study period for the mlp model the training took only 9 4 min this corresponds to 2351 epochs of 135 iterations per epoch or 317 385 iterations in total 6 conclusion in this paper a theory guided multilayer perceptron model tgmlp was developed to test its effectiveness in simulating groundwater flow dynamics in a real world setting the performance of the tgmlp was compared against that of a numerical model nummod and a traditional multilayer perceptron model mlp in addition the ability of these three models to capture the spatiotemporal dynamics of groundwater was evaluated the degree of pde violation of the tgmlp model was also assessed finally the applicability of these three models in a real world setting was discussed the saint honoré unconfined aquifer quebec canada was used as an experimental laboratory for this study because of the extent of the knowledge and data acquired on this aquifer historical groundwater levels recharge precipitation mean temperature and qualitatively streamflow data were used to calibrate train validate and test the models the results show that the tgmlp demonstrates the best performance and far outperforms the traditional numerical and mlp models that the mlp model is a good interpolator but is unable to extrapolate and that only the numerical and tgmlp models are reliable because they are the only ones able to capture the spatiotemporal dynamics of groundwater flow and represent the dominant flow direction in the aquifer however it was found that the tgmlp model successfully approximates the pde solution only 70 of the time the poor approximation in 30 of the locations could be due to an effect of pde violation at the sources sinks or at the neumann conditions treating each source sink term as an independent term of the total cost function should be explored to assess how much this improves the approximation of the pde solution it may also be interesting to consider the source sink terms and boundary conditions as part of the inverse problem beyond that the tgml paradigm opens a new way to make physical sense of the parameters of artificial neural networks and thus reduce the black box nature that has usually been attributed to artificial neural network models also the computational cost of tgmlp training is high but can be reduced using gpu acceleration the results of this study may be useful to practitioners and researchers in selecting a model for their hydrogeological investigations funding sources this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank niobec mine and the municipality of saint honoré for providing data on pumping rates for wells in the study area 
2681,this study proposes to test the hypothesis that theory guided machine learning model can be effectively applied to model the behavior of a real aquifer for this purpose a theory guided multilayer perceptron model tgmlp for real aquifers was developed to simulate groundwater flow dynamics a comparison of the performance of the tgmlp with that of a numerical model nummod and a traditional multilayer perceptron model mlp was performed the ability of these three models to capture the spatiotemporal dynamics of groundwater was evaluated the degree of pde violation of the tgmlp model was also assessed and the applicability of these three models in a real world setting was discussed the saint honoré unconfined aquifer quebec canada which has been extensively monitored over the last few years was used as an experimental laboratory for this study historical groundwater levels recharge precipitation mean temperature and streamflow data were used to calibrate train validate and test the models the results show that the performance of the tgmlp far exceeds that of the numerical and traditional mlp models that the mlp model is a good interpolator but is unable to extrapolate and that only the numerical and tgmlp models are able to capture the spatiotemporal dynamics of groundwater flow and represent the dominant flow direction in the aquifer it was found that the tgmlp model better approximates the solution of the pde at 70 of the locations these results support the hypothesis that tgmlp is effective in modeling the spatiotemporal dynamics of groundwater in a real aquifer even if improvements are needed although the tgmlp model is capable of representing groundwater flow dynamics to some degree its implementation requires much higher computational costs than a numerical model however these can be reduced with the use of a gpu to speed up the calculations keywords theory guided machine learning numerical modelling groundwater flow statistical modelling optimization data availability we shared our data and codes on mendeley data the link is specified in the paper section 2 2 1 introduction studying the workings of groundwater systems involves a number of traditional tools and techniques to determine the nature of the terrain through which groundwater flows and the physical properties that control this flow such characterization also requires determining how these systems are supplied where they discharge their physical boundaries and their interaction with neighboring hydrogeologic systems all this information can be used to formulate a so called conceptual model of a hydrogeological system the conceptual model can be defined as the set of assumptions made to describe the understanding of a groundwater system enemark et al 2019 based on the conceptual model a numerical model can be constructed to simulate and eventually predict how the hydrogeological system functions when it undergoes disturbances the numerical model is a tool commonly used in hydrogeology its purpose is to solve a discrete form of the equations that describe the groundwater flow under the assumptions that constitute the conceptual model feng et al 2011 for example developed a feeflow numerical groundwater model to simulate regional flow variations under different water management scenarios the results of their study showed a continuous decline in groundwater levels over time under the management conditions prevailing at the time of the study vu et al 2021 used an integrated method of overlaying a modified version of the drastic index and a modflow numerical model to predict the vulnerability and sustainability of groundwater under various climatic conditions and anthropogenic activities the results of their study showed that variations in future climate conditions exerted little influence on the variations in vulnerability of the studied basin but based on the analysis of sustainability indicators the groundwater resource system was in a critical condition of high vulnerability although numerical models are an effective tool for studying groundwater systems the assumptions on which they are built are a major source of structural uncertainty and can affect the accuracy of the model to address the issue of uncertainty and model accuracy the multi model approach which consists in developing plausible alternative conceptual models and evaluating them through numerical modelling is one of the traditional possible solutions enemark et al 2019 however the multi model approach can be time consuming which limits its practical use since the popularization of artificial intelligence in the 1980 s barr et al 1981 machine learning ml a branch of artificial intelligence is increasingly used in various scientific fields machine learning relies on a sufficient set of data to approximate any non linear function between some input and output variables in hydrogeology ml algorithms are used with a good level of satisfaction to perform specific modeling tasks such as mapping the spatial distribution of groundwater salinity sahour et al 2020 mosavi et al 2021 tran et al 2021 uncertainty quantification gadd et al 2019 song et al 2020 lykkegaard et al 2021 improving the accuracy of groundwater level prediction banadkooki et al 2020 cai et al 2021 groundwater potential mapping kalantar et al 2019 lee et al 2020 kumar et al 2021 or determination of physical parameters of aquifers tayfur et al 2014 hou et al 2021 for example banadkooki et al 2020 investigated the impact of different input variables on the accuracy of groundwater level prediction of hybrid machine learning models the algorithms used were neural network with radial basis function whale algorithm multilayer perception and genetic programming precipitation mean temperatures and their time shifted equivalents combined in various ways were used as inputs the results show that the algorithm that generates the best performing model depends on the combinations of input variables used tayfur et al 2014 used sugeno fuzzy logic mamdani fuzzy logic multilayer perceptron neural network neuro fuzzy algorithms and an ensemble algorithm that combines the predictions of the previous algorithms to determine the best model for hydraulic conductivity estimation for a heterogeneous aquifer in their study using hydrogeological and geoelectric data it was found that the best model was the one generated by the ensemble aggregation algorithm machine learning algorithms in their traditional form are effective tools for learning any non linear relationship between a set of inputs and a set of outputs with a high level of accuracy and a relatively short computation time however machine learning algorithms generally have poor explanatory power and therefore are not as useful as physics based modelling to improve our understanding of the physical phenomena in many contexts this black box aspect limits the operational applicability of traditional machine learning techniques recently raissi et al 2019 popularized a new paradigm by incorporating during training certain constraints related to the physics governing the phenomenon under study so that the algorithm not only learns from the data but also refrains from deviating too far from the known governing laws of physics this paradigm is commonly referred to as theory guided machine learning wagner and rondinelli 2016 karpatne et al 2017 esterhuizen et al 2020 adombi et al 2021 wang et al 2020 compared the predictive performance of a deep neural network dnn model against that of a theory guided dnn tgdnn model to do this they used simple idealized two dimensional hydrogeological configurations for spatio temporal modelling of groundwater levels using time series of groundwater levels synthetically generated by a numerical model as reference data the results showed that the tgdnn model achieves much better predictability reliability and generalization than the dnn models tartakovsky et al 2020 used a theory guided deep neural network to estimate hydraulic conductivity in saturated and unsaturated flows governed by darcy s law in idealized synthetic hydrogeological settings the results show that the model is well suited for hydraulic conductivity estimation unlike traditional machine learning to our knowledge theory guided machine learning has never been applied to a real world hydrogeological setting in such a setting aquifer geometry can affect groundwater flow the spatial distribution of observation wells is sparse hydrodynamic properties are known only at a few points within the study area and many uncertainties are pervasive such as partial knowledge of the geology studies in idealized synthetic hydrogeological settings have shown some interest in applying theory guided machine learning but do not document its effectiveness and limitations in real world applications considering the inherent difficulties in assessing aquifer systems and the necessity of representing these invisible systems by conceptual models theory guided machine learning could be a useful tool to be integrated in the toolbox of hydrogeologists to assess these systems with a higher degree of confidence this study proposes to test the hypothesis that a theory guided machine learning model can be effectively applied for inverse modeling of the groundwater dynamics of a real aquifer to verify this hypothesis we built and used a theory guided machine learning model to simulate groundwater dynamics and compare it both to observations and to other commonly used tools such as numerical modelling and traditional machine learning our starting hypothesis is based on the fact that theory guided machine learning considers the actual behavior of an aquifer and not solely on its hydrogeological properties which are assessed by hydrogeologists with a generally high degree of uncertainty and poor confidence we posit that this approach could be effective in a real world case study in this study the inverse modeling of the spatiotemporal dynamics of groundwater in a real aquifer is investigated and compared using three methods a numerical model nummod a multilayer perceptron mlp and a theory guided multilayer perceptron tgmlp the saint honoré aquifer quebec canada constitutes a good experimental laboratory for this study because of the significant extent of knowledge previously acquired at this site e g tremblay 2005 parent and occhietti 2007 boumaiza 2008 labrecque et al 2019 boumaiza et al 2020 boumaiza et al 2021 this unconfined granular aquifer has been equipped with a sufficient number of piezometers that are continuously monitored and has been well characterized over time in terms of geology hydrodynamic properties and hydraulic limits in this study the temporal extrapolation ability of the different models is not investigated this study is therefore limited to the following objectives compare the performance of nummod tgmlp and mlp for the inverse modeling of gwl dynamics evaluate the ability of the three models to capture the spatiotemporal dynamics of gwl evaluate the effect of partial differential equation pde violation by the tgmlp model discuss the applicability of the three models in a real world setting 2 study area and data 2 1 study area the saint honoré aquifer belongs to the saguenay lac saint jean slsj region of quebec canada fig 1 the portion of the aquifer considered as the study area is located near the saint honoré airport between the caribou river ungauged to the west and the valin river gauged to the east and covers approximately 36 7 km2 in addition to pumping wells streams constitute the discharge sites of the aquifer while the primary source of recharge of the aquifer is precipitation tremblay 2005 precipitation is estimated to average 930 mm per year boumaiza et al 2021 during most of a given year three directions of groundwater flow are observed southwestward northwestward and westward but the southwestward flow is dominant tremblay 2005 the development of the saint honoré unconfined aquifer can be traced back to the last glacial event in the slsj area between 85 000 and 7 000 years ago when the overlying glacier retreated to form a discontinuous and heterogeneous layer of geologic materials including glaciolacustrine and glaciofluvial deposits and till parent and occhietti 2007 a marine invasion subsequently occurred causing the deposition of fine clay like sediments a marine regression then followed and these sediments were covered by deltaic granular sediments that constitute the saint honoré aquifer boumaiza et al 2021 the granular sediments are up to 50 m thick in the study area and consist mainly of sands and silts in some parts of the study area the granular sediments are directly underlain by precambrian crystalline bedrock belonging to the canadian shield and in other parts they are underlain by clays or till the northern boundary of the study area is marked by an outcrop of precambrian bedrock the western boundary by an outcrop of a clay layer with the presence of the caribou river a little further south all along the eastern boundary outcrops of the bedrock or till layers are found the portion of the saint honoré aquifer considered in this study has been represented in tremblay 2005 as a succession of four stratigraphic units each composed of several hydrogeologic layers that are homogeneous and isotropic in their hydrodynamic properties fig 2 illustrates the layout of the stratigraphic units s units and their hydrogeological layers and also locates the wells and the monitored piezometers 2 2 data the models in this study were developed using hydrogeological hydrological and meteorological variables the data including the processed input data and raw and processed results algorithms numerical model and software used for numerical modeling are available on mendeley data https doi org 10 17632 87fkztgbbh 1 specifically the data used are daily gwl at the six continuously monitored piezometers daily precipitation and mean temperature daily recharge rate monthly pumping rates at the seven wells in the aquifer and stream flow measurements taken between 2001 and 2004 by tremblay 2005 the groundwater levels data were measured automatically between 09 11 2016 and 30 11 2017 at 15 minute time steps and then processed into daily time series daily precipitation and mean temperature were provided in the form of 0 1 x 0 1 weather grids by the info climat service of quebec s ministère de l environnement et de la lutte contre les changements climatiques melcc since the study area was intersected by six weather grids a spatial average of precipitation and that of the mean temperature were calculated pumping rate data were obtained through direct communication with the institutions in charge of their management niobec mine and municipality of saint honoré monthly pumping rates were also transformed into daily data for the numerical and tgmlp models the topographic surface and bedrock elevations were retrieved from the programme d acquisition des connaissances sur les eaux souterraines paces database of the melcc the sequence of stratigraphic units used in this paper is based primarily on the interpretation of the stratigraphy proposed by tremblay 2005 the hydrodynamic property ranges of the hydrogeological layers of the stratigraphic units were compiled from the data in tremblay 2005 but also from the paces database the ranges of values for hydrodynamic properties are shown in table 1 the daily recharge series was inferred by the water table fluctuation wtf method over the period 09 11 2016 to 30 12 2017 at piezometer pz 18 data produced by labrecque et al 2019 the recharge time series at pz 18 is considered to be representative of recharge dynamics over the entire aquifer 3 methods and models in groundwater dynamics modeling the inverse problem is resolved in two steps the first step is to identify the model that most appropriately describes the groundwater flow in the aquifer under study this involves for example determining the governing equations boundary conditions or heterogeneities in the aquifer this leads to the establishment of a conceptual model the second step is then to estimate or calibrate the model parameters such as hydrodynamic parameters recharge and boundary conditions in order to reproduce field observations such as groundwater levels as closely as possible because the saint honoré aquifer has been extensively characterized we assume that the conceptual model already established for this aquifer see tremblay 2005 and summarized in section 3 1 and fig 3 has a high degree of representativity therefore the inverse problem of the numerical model will be to calibrate the hydrodynamic parameters of the aquifer for the tgmlp model the hydrodynamic parameters calibrated by the numerical model will be provided as prior knowledge and the inverse problem will then consist in estimating the neural network parameters finally for the mlp the inverse problem will also be to calibrate the neural network parameters 3 1 numerical model the numerical groundwater flow simulation model was built using the free version of the marthe software developed by the french geological survey thiéry 1990 the free version of marthe can be downloaded at https www brgm fr fr logiciel marthe logiciel modelisation ecoulements souterrains marthe solves a 3d form of the groundwater equation of continuity using the finite volume method with initial and boundary conditions more details on the equations and approximation methods can be found in thiéry 1990 the finite volume method consists in approximating the groundwater equation by discretizing the groundwater flow system into finite volumes and the simulation time into discrete time steps at each time step the input data recharge and pumping rates is considered invariant marthe is able to couple groundwater flow with stream exchanges through a water balance equation that considers exchanges between groundwater and streams runoff source sink terms and possibly a storage term it is also possible to model the interaction between saturated and unsaturated zones given the strong non linearity of the coupling with the unsaturated zone marthe exploits the notion of pseudo vadose zone the pseudo vadose zone is used to simulate the water flows in the unsaturated zone without having to provide retention and permeability laws the details of the pseudo vadose zone concept are given in thiéry 1990 the marthe model built in this paper is a 3d groundwater flow model coupled with groundwater stream exchanges and a pseudo vadose zone the study area was discretized along both the x y and z axes and the time dimension t in the horizontal plane the mesh is square with side δx δy 100 m the vertical mesh consists of four model layers representing the stratigraphic units of the saint honoré aquifer the vertical mesh is made so that at each point the stratigraphic units have approximately the same thickness the vertical mesh was created based on the surface and bedrock elevation maps of the saint honoré aquifer time was discretized into a finite number of daily intervals corresponding to the available gwl time series i e 387 daily time steps the lateral hydraulic boundaries of the aquifer were chosen to coincide with the natural boundaries see section 2 1 thus everywhere on the lateral boundary of the aquifer except at the border of the caribou river a no flow boundary was defined as it corresponds either to a clay barrier or to the outcrop of the precambrian bedrock or till the caribou river and its tributaries in the study area are defined as cauchy boundaries doctor lake is considered a constant groundwater level boundary wells are represented as flow imposed boundaries the upper aquifer boundary is considered a flux imposed boundary with the flux corresponding to the recharge rate finally the aquifer lower boundary is considered a no flow boundary this is because the aquifer is underlain by bedrock which is considered impermeable fig 3 presents the synthesis of the conceptual model of the aquifer a steady state calibration performed on 09 11 2016 allowed an initial adjustment of the hydraulic conductivity of the different hydrogeological layers of the model the physical properties of the streams hydraulic conductivity and bed thickness were also calibrated in order to ensure that the stream flows remained within the range of values of the discontinuous flows measured over the period 2001 2004 indeed due to the absence of flow measurements in the caribou river over the period investigated in this study it was assumed that the average stream flows measured over the period 2001 2004 are not significantly different from those that would have been measured over the period of investigation i e from 09 11 2016 to 30 11 2017 next a transient calibration was performed using the groundwater level time series from four of the available piezometers in the study area as a calibration quality criterion to adjust the storage coefficient values and improve the hydraulic conductivity calibration these piezometers are la 2 pz 16 pz 1 pz 20 see fig 2 they were selected to ensure approximately one piezometer per hydrogeological layer the initial groundwater levels used for transient calibration were those obtained after steady state calibration the final model selected is the one for which not only the values of the storage coefficient and hydraulic conductivity remain within the ranges of values specific to the saint honoré aquifer see table 1 but also for which the simulated groundwater level series follow the same dynamics and present an acceptable accuracy compared to the observations the other two piezometers are used for testing these are the piezometers pz 18 and pz 21 see fig 2 initially the calibration of the numerical model was performed automatically using the optimization algorithms integrated into the marthe software and the ranges of values in table 1 however the values of the calibrated hydrodynamic parameters and their spatial distribution were not in agreement with the hydrogeology of the terrain this is why we then opted for a manual calibration the simulated groundwater levels following this manual calibration are very close to those of the automatic calibration but provide a better agreement with the hydrogeology of the terrain furthermore the values of the manual calibration parameters and their spatial distribution support those of previous numerical modeling studies performed in the study area e g tremblay 2005 in addition the pumping tests a field experiment whose purpose is to evaluate the physical properties of the medium with a certain level of uncertainty support the results of the manual calibration field data remain a reference even if they are measured in a punctual way and with a certain level of uncertainty 3 2 machine learning models 3 2 1 multilayer perceptron the multilayer perceptron mlp is an algorithmic structure belonging to the family of feedforward artificial neural networks considered as universal approximators of any continuous function cybenko 1989 hornik 1991 a mlp is composed of an input layer an output layer and one or more hidden layers the number of hidden layers defines the depth of the network beyond one hidden layer the network can be qualified as deep each layer is made of a given number of neurons neurons in two given contiguous layers of the mlp are fully interconnected and each of the connections is represented by the parameter θ w b where w and b are the weight and bias parameters respectively data from a given layer is aggregated using weights and biases before being transformed by a nonlinear activation function and then passed on to the next layer one by one the input data undergoes transformations through the hidden layers until it reaches the output layer to ensure that each input variable is given equal weight they are normalized between 1 and 1 this reduces the effect of the differences in magnitude between the range of different input variables on the model approximation using a back propagation algorithm data transmitted from the input layer to the output layer is analyzed to iteratively adjust the network parameters until the outputs minimize a predefined cost function the process of transmitting data from the input layer to the output layer followed by backpropagation is repeated on small batches of data over a number of iterations called epochs or until certain values of the selected stopping criteria are met it is important to note that an epoch is composed of a certain number of sub iterations defined in particular by the number of batches of data to be used per sub iteration the mean square error between the observed outputs and the outputs simulated by the mlp model is often used as a cost function l obs θ to constrain its learning the update of the neural network parameters by the backpropagation algorithm is done according to equation 1 1 θ i θ i 1 λ l obs θ θ i 1 and θ i represent respectively the previous and the updated value of θ λ is a hyperparameter of the network to be defined and is called the learning rate l obs θ is the gradient of the cost function l obs with respect to θ in contrast to the numerical model the spatial and temporal simulation of groundwater dynamics with the mlp is two dimensional fig 4 a illustrates the mlp architecture and summarizes the learning process 3 2 2 theory guided multilayer perceptron the tgmlp is a mlp whose learning is constrained not only by the observed data but also by the theory governing the phenomenon under study in this study the equation governing the groundwater flow as well as the boundary and initial conditions are used as additional constraints to the l obs cost function mse used for the traditional mlp as with the mlp the spatiotemporal simulation of groundwater dynamics with tgmlp is two dimensional and only the flow in the saturated zone is considered the general partial differential equation pde describing such a system is given by equation 2 2 s aq φ t x t x φ x y t y φ y q x y ω t 0 t x and t y are the transmissivity values m 2 d along the x and y coordinate axes m φ is the groundwater level m q represents the water source and or sink term m d with q 0 for flow out of the groundwater system and q 0 for flow into the system s aq denotes the storage coefficient t is time d ω denotes the internal aquifer domain transmissivity is given by the product of hydraulic conductivity and saturated water thickness for an unconfined aquifer the saturated water thickness can be defined as the difference between the gwl and the aquifer bottom elevation thus equation 2 is rewritten as equation 3 3 s aq φ t x k x φ z b φ x y k y φ z b φ y q x y ω t 0 where k x an k y are the hydraulic conductivity m d along the x and y coordinate axes z b represents the aquifer bottom elevation m because the tgmlp model is a 2d model we chose stratigraphic unit 3 as representative of the current knowledge available about the aquifer as mentioned in section 2 1 the stratigraphic units are considered as a succession of homogeneous and isotropic hydrogeological layers therefore the hydraulic conductivities are independent of the x y coordinates for a given hydrogeological layer in addition according to the conceptual model summarized in fig 3 the aquifer is composed of cauchy boundaries represented by the rivers a dirichlet boundary represented by doctor lake imposed flow boundaries represented by recharge and pumping and finally a zero flow boundary represented by the edges of the aquifer other than the caribou river thus the final pde that represents the aquifer according to the conceptual model defined earlier is given by equations 4 to 7 4 s aq φ t k x φ z b φ x y φ z b φ y r δ w q w δ x 2 δ s q s x y ω t 0 5 φ t x y φ ini t x y x y ω ω d ω n t 0 6 φ t x y φ dir t x y x y ω d t 0 7 φ n t x y 0 x y ω n t 0 where φ ini and φ dir are respectively the gwls at the initial time and the gwls imposed as the dirichlet condition q s is the exchange flux between the sections of rivers and the aquifer ω ω d and ω n denote the internal aquifer domain dirichlet and neuman boundary condition domains of the study area n is the direction normal to the neumann boundary domain δ x is the distance between two points in the or y direction δ w and δ s are equal to 1 if the point where the equation is applied is respectively a well or a section of river otherwise δ w and δ s are equal to 0 the training is performed by forcing the tgmlp model not only to fit the gwls observations but also to approximate the solution of the pde defined by equation 4 to achieve this the training consists in minimizing the difference between the observed and simulated gwls as well as the residuals of equations 4 to 7 thus the total cost function to be minimized is given by equation 8 8 l tot l obs l ini l dir l neu l pde where l pde l ini l dir and l neu are the cost functions related to the residual of the equations 4 to 7 respectively to evaluate the derivatives in equations 4 to 7 one can use the automatic differentiation ad method wang et al 2020 or traditional methods such as the finite difference method fdm e g tartakovsky et al 2020 wang et al 2021 the fdm was considered in this study because of the advantage of computational cost and the weak nonlinearity of equation 4 which reduces the approximation error fdm is 1 411 to 1 562 times faster than ad using a gpu for computational acceleration this difference appears to be minor as it corresponds to a gain of 31 to 42 min in this study on the other hand without the use of a gpu the time difference would increase corresponding to more than 3 1 to 4 2 h in addition the applicability of the tgmlp model in a real world setting discussed here includes the issue of computational time this is also one of the reasons why the least time consuming derivation method fdm was presented in this study in problems with very strong nonlinearity or involving pde of an order greater than or equal to 3 it would be more advantageous to use automatic differentiation which provides an exact derivative consider the tgmlp model represented by equation 9 9 φ sim t g m l p t x y θ each term of the total cost function obtained by the fdm with the introduction of dummy points at the boundaries of the study domain for the neumann condition is defined in equations 10 to 14 10 l dir 1 m dir m b i 1 m dir j 1 m b φ sim ij φ ini ij 2 11 l ini 1 m ini i 1 m ini φ sim ij φ ini ij 2 12 l neu 1 m neux m b i 1 m neux j 1 m b φ sim e i j φ sim w i j 2 δ x 2 1 m neuy m b i 1 m neuy j 1 m b φ sim n i j φ sim s i j 2 δ x 2 13 l pde 1 m pde m b i 1 m pde j 1 m b f pde ij 2 with 14 f pde s aq p δ t φ sim t p φ sim t δ t p k p φ sim t p z b p δ x 2 φ sim t e φ sim t w 4 φ sim t p φ sim t n φ sim t s r t p δ w q w t p δ x 2 δ s k s p e s φ ref t p φ sim t p φ sim t p φ sim t e φ sim t w φ sim t n φ sim t s represents the gwl at location p and the gwl of its eastern e western w northern n southern s neighbors respectively at time t δ x is the width of the square mesh δ t is the length of a time step s aq p and k p are the storage coefficient and the hydraulic conductivity at p respectively z b p is the aquifer bottom elevation at p k s p is the hydraulic conductivity of the bed of the stream section and φ ref t p is the elevation of the water level in the stream at p q w t p is the pumping rate r t p is the recharge rate m dir m ini m neux m neuy m pde are respectively the number of locations sampled to evaluate the cost functions related to the dirichlet condition l dir doctor lake ω d the initial condition l ini entire domain ω ω d ω n the no flow boundary condition l neu external boundaries of the study area except the caribou river ω n and the governing equation l pde internal domain ω m b is the number of time steps batch size used for a given training epoch fig 4b illustrates the tgmlp architecture and summarizes the learning process the methodology used for numerical model calibration training and validation of machine learning models and their testing is summarized in fig 5 3 2 3 conditions for stopping the training the training of ml models consists in adjusting their parameters in order to make the cost function tend towards a minimum value considered satisfactory to stop the training in this study to follow the evolution of the training two metrics were used for the mlp and a third metric was added for the tgmlp the first metric is the root mean square error between the observed and simulated gwls rmse the second is the interpolation capacity ic and the third is the mean residual of the pde mrp the ic is defined by equation 15 15 ic rmse v a l i d a t i o n d a t a rmse t r a i n i n g d a t a the perfect model is the one with rmse 0 ic 1 and mrp 0 in this study training is stopped when rmse a ic 1 b and mrp c the fixed values of a b and c are presented in section 3 2 4 3 2 4 architecture development the ml models were developed in python with the tensorflow library and run in the google colab pro environment with computational acceleration using a tesla p100 pcie 16 gb gpu the number of neurons in the input and output layers is known and depends on the number of dimensions of the input and output data in this study time t spatial coordinates x and y the moving average of precipitation p m a 30 and mean temperature t m a 30 30 day window are the inputs of the mlp model i e five neurons whereas only t x and y are the inputs of the tgmlp model i e three neurons groundwater levels are the only output variable i e one neuron for both models the choice of the variables t x y makes it possible to consider the spatial and temporal character of the problem studied for the mlp and tgmlp models moreover these variables are useful to evaluate the physics related cost functions equations 12 and 13 during the training of tgmlp since recharge is incorporated directly into the total cost function it was not considered useful to include it as an input variable for tgmlp the reason for choosing the moving average of precipitation and that of the mean temperature as mlp input variables is that gwl dynamics in the saint honoré aquifer are determined in part by precipitation and evapotranspiration the latter is partly related to temperature to facilitate the training of the mlp it is advisable to choose variables that are independent but correlated with the output variable after several tests it was found that the 30 day moving average of precipitation and mean temperature showed the highest correlation with groundwater elevations in all piezometers in the study area table 2 summarizes the cross correlation results the hyperbolic tangent activation function was applied to the hidden layer neurons while the linear function was applied to the output layer neurons the number of hidden layers and the number of their neurons were determined by a trial and error procedure the procedure starts with one hidden layer at the beginning and increases up to 10 hidden layers with a step of 1 at each trial for a given trial the number of neurons varies with steps of 5 starting from 10 neurons to a maximum of 50 neurons for each trial representing a given number of hidden layers and neurons the mlp is trained to minimize the mean square error between observations and simulated values this means that only points where piezometric observations exist were used for training validation i e in four piezometers chosen so that there is approximately one piezometer per hydrogeological layer these piezometers are the same as those used for the calibration of the numerical model the other two piezometers of a total of six were used for the test stage for each of the training validation piezometers a temporal sampling was performed in particular the duration of the simulation defined by the length of the gwl time series of the piezometers was discretized and then randomly sampled at 70 for training the remaining 30 was used to evaluate the interpolation capacity ic of the model at each training epoch in the validation stage training tgmlp consists in optimizing its parameters by minimizing the total cost function equation 8 to evaluate the physics related cost functions in equation 8 spatial sampling of locations was performed in the different hydrogeologic layers of stratigraphic unit 3 using the spatial points generated by the numerical model discretization then for each of the locations the same time sampling as performed for the mlp was applied the piezometers used for numerical model calibration or mlp model training validation are the same as those used for tgmlp model training validation the same applies to the test piezometers the values of the hydrodynamic parameters of the aquifer and the physical properties of the stream bed used in the tgmlp method are those obtained after the calibration step of the numerical model unlike for the numerical model streams and wells are considered as source sink terms and are directly incorporated into the governing equation see equation 4 the initial groundwater levels used for tgmlp training validation are those observed at the 6 piezometers at date zero 09 11 2016 the adam optimization algorithm was used to appropriately adjust the values of the weight and bias parameters for the mlp and tgmlp the goal is to build machine learning models that are as parsimonious as possible while showing good interpolation ability thus the stopping criterion for mlp learning is to achieve a ic equal to 1 2 and a rmse in the training stage lower than 0 05 m the mlp model that meets these two criteria with the lowest density structure is selected as the final model the stopping criterion for tgmlp training is not only to achieve a ic equal to 1 2 and an rmse in the training stage lower than 0 05 m but also to present a residual of the pde lower than 0 0125 m d a value justified by the desired degree of physical consistency for tgmlp models this value corresponds to a physical inconsistency of approximately 0 05 m the tgmlp model that meets all these criteria and presents the lowest density structure is selected as the final model the learning rate and batch size used are respectively 5 10 4 and 2 for both mlp and tgmlp 3 3 performance assessment metrics the performance of the different models was evaluated using the nash sutcliffe efficiency nse and the percentage of normalized rmse hereafter called nrmse nrmse is defined by equation 16 16 nrmse 100 rmse φ obs max φ obs min with φ obs max and φ obs min the minimum and maximum values of the time series of the observations m nse is used to evaluate the simulation ability of a model a perfect model is one whose simulation ability is 1 the nrmse quantifies the accuracy of a model with values ranging from 0 to infinity a model with perfect accuracy will have a value of nrmse equal to 0 while values further increasing from 0 will indicate decreasing model accuracy 4 results the results of the calibration training validation are presented in section 4 1 the results obtained with the test data set are presented in section 4 2 nrmse and nse values were used to evaluate the performance of the models both in the calibration training validation stage and the test stage a comparison of the spatial distribution of the gwl field is performed between the different models to evaluate their ability to capture the groundwater flow dynamics in section 4 3 finally the degree of pde violation by the tgmlp model is examined in section 4 4 4 1 model calibration training validation the numerical model was calibrated using daily data from 09 11 2016 to 30 11 2017 drawn from the four piezometers mentioned in section 3 1 and to a lesser extent stream flow measured at specific timepoints over the period 2001 2004 the final numerical model was chosen so that the simulation would match the observed gwls as closely as possible the determination of the mlp and tgmlp architectures was performed as described in section 3 2 4 for the implementation of the mlp and tgmlp models the observed gwls of the four piezometers were randomly subdivided according to the temporal component into a training set and a validation set the mlp model that best satisfies all stopping criteria is composed of 3 hidden layers of 25 neurons each results not shown as for the tgmlp model it is composed of 7 hidden layers of 40 neurons results not shown fig 6 shows the convergence of cost functions for the two selected architectures during training as a function of epochs for the mlp and tgmlp models fig 7 shows the comparison between observed gwls and gwls simulated by the different models in the four piezometers and fig 8 summarizes the results for the performance criteria in the calibration training validation stage for all piezometers we observe that the nrmse values fig 8a decrease from the numerical model to the tgmlp model and the nse values increase from the numerical model to the tgmlp model fig 8b nrmse values for tgmlp are less than 4 for all piezometers nearly 4 times less than the lowest nrmse value from the numerical model the nrmse values for mlp range from just over 11 to nearly 2 as for the nse value it is very close to 1 for the tgmlp model the nse is greater than 0 7 for all piezometers for the mlp model while its value is very mixed for the numerical model all this means that the accuracy and simulation ability of the tgmlp model are higher than those of the mlp model which in turn are higher than those of the numerical model referring to the la 2 and pz 16 piezometers it can be observed that the nrmse values of the numerical model are all above 30 and the nse values are close to 0 or negative all this clearly indicates that the numerical model has a low accuracy and its simulation ability is at most equal to the average groundwater level observed in these piezometers the poor simulation ability of the numerical model for la 2 and pz 16 can also be explained visually by the time lag seen between the observed and simulated series fig 7 the time lag of the simulated series compared to those observed at the la 2 and pz 16 piezometers may be due to several factors the first factor is the diffusivity of the aquifer in the vicinity of the two piezometers an increase in diffusivity in the vicinity of la 2 and a decrease in diffusivity in the vicinity of pz 16 could improve the fit of the simulations to observations this would probably require a review of the initial conceptual model by introducing heterogeneity around the two piezometers the second factor is related to the thickness of the pseudo vadose zone which if reduced around la 2 and increased around pz 16 could also improve the fit the third factor may correspond to phenomena not considered in the conceptual model that would influence gwls around the piezometers such as private wells and various small lakes around la 2 fig 2 as mentioned above the investigation of all these factors requires proposing an alternative conceptual model based on the acquisition of new data these are currently not available but may be interesting for future studies at pz 1 and pz 20 the nse values fig 8b greater than 0 5 show that the numerical model demonstrates a certain simulation ability for both piezometers however the simulation ability of the numerical model remains low compared to those of the mlp and tgmlp models for which the nse value tends to approach 1 in summary for the calibration training validation stage it can be concluded that the tgmlp model is much more accurate than the mlp model and that both are much more accurate than the numerical model the simulation ability of the tgmlp model and the mlp model are very high with the tgmlp being superior in addition the simulation ability of the tgmlp and mlp models is far superior to that of the numerical model which has an average simulation ability 4 2 model testing testing of the different models was performed using the gwls time series at the two remaining piezometers i e pz 18 and pz 21 fig 9 shows the comparison between the gwls at test stage fig 10 summarizes the performance criteria values of the different models at piezometer pz 18 the value of nrmse fig 9a of the mlp model which exceeds 100 and reaches almost 7 times that of the numerical model and more than 11 times that of the tgmlp model expresses the fact that the accuracy of the numerical and tgmlp models is much better than that of the mlp the nse value fig 9b which is well below 0 shows that the mlp has a low simulation ability compared to both the numerical and tgmlp models for which the nse value is greater than 0 3 the nse of the tgmlp is twice as high as that of the numerical model showing that its simulation ability is much higher than that of the numerical model although the nse value of the numerical model is low it expresses an acceptable simulation ability at piezometer pz 21 all models have good accuracy and simulation ability with the tgmlp model being superior to the mlp model which is also superior to the numerical model in terms of nrmse fig 9a and nse fig 9b values however the better accuracy and simulation ability of the mlp model compared to the numerical model is not surprising since the pz 21 test and pz 20 training piezometers are close of each other with a very similar piezometric signature and it is certainly the spatial interpolation ability of the mlp that has been brought into play in this case in summary the performance of the tgmlp model in the test stage which also expresses its extrapolation ability exceeds that of the numerical model similarly the performance of the numerical model is superior to that of the mlp 4 3 capture of groundwater dynamics by the models the numerical model is purely physics based and has acceptable simulation ability it is designed to capture the groundwater flow dynamics within the accuracy limit of the conceptual model thus the examination of the ability of ml models to capture groundwater flow dynamics is evaluated with respect to the numerical model fig 11 and fig 12 show the results for two different dates as illustration while fig 13 provides more detail on the differences between the ml models with respect to the numerical model in capturing groundwater dynamics it can be seen both visually and statistically that the tgmlp model is the closest to the numerical model moreover from one date to another the statistics of the differences remain constant for the tgmlp model in contrast to the mlp model on average the difference between the numerical and tgmlp simulations is 1 m with a standard deviation of 3 14 m in addition the dominant flow direction of the gwl field simulated by the tgmlp model is toward the southwest and agrees with the conceptual aquifer model since the southwestward flow is dominant tremblay 2005 in contrast the flow direction proposed by the mlp model is toward the southeast which is the opposite direction to that proposed by the conceptual model fig 14 shows the gwl field simulated by the tgmlp model over a great number of time points to illustrate the spatial consistency of this field with the conceptual model these results mean that only the numerical model and the tgmlp model are capable of capturing the spatial and temporal dynamics of groundwater levels also these results mean that the numerical model and the tgmlp model represent two parallel versions of the modeled aquifer system 4 4 effects of pde violation by the tgmlp model a tgmlp model that perfectly approximates the pde is a model that provides a zero physical inconsistency in reality it is not possible to reach the zero limit for this reason we set a physical inconsistency limit of 0 0125 m d this means that the tgmlp violates the pde on a number of locations to assess the degree of pde violation by tgmlp we plotted the distribution of the pde residual given the gwls simulated by tgmlp at different dates and we displayed the proportion of points where the pde residual is below the threshold of 0 0125 m day fig 15 fig 15 shows that the tgmlp model correctly approximates the solution to the pde depending on the threshold set at a rate of about 70 from one date to another the tgmlp model fails to correctly approximate the pde nearly 30 of the time fig 16 shows the set of unobserved locations where the effects of pde violation were examined for illustration and fig 17 shows the gwls simulated and the absolute mean value of the pde residual at these locations at locations a through f the pde residual is below threshold and the same piezometric signatures as the observation piezometers are obtained for locations h to l where the pde residual is below the threshold or for location g and locations m to p where the pde residual is above the threshold the piezometer signatures do not match the observed piezometers in section 4 3 it was shown that from date to date the tgmlp model produced gwl fields that were spatially consistent with the conceptual model the fact that there are locations where the pde is not violated but which have particular piezometric signatures could mean that these signatures are the result of a strong influence of the source sink terms or neumann conditions near which they are located similarly at locations where the pde is violated the shape of the piezometric signatures may be explained by a poor model constraint on the source sink terms and neumann conditions thus propagating the effect of the pde violation to other locations in the aquifer this remains a hypothesis to be explored and it would be interesting to test this hypothesis in a future investigation for such a study it would probably be more interesting to separate each source sink term into its own equation to better constrain the tgmlp model the particular piezometric signature found could also be due to the fact that the boundary conditions of the conceptual model are incomplete forcing the model to display an undesired behavior it would probably be worthwhile for future investigations to consider the identification of the boundary conditions and the identification of the sink terms for the rivers as part of the inverse problem indeed despite the level of confidence that one may develop concerning a conceptual model such a model will always remain an approximation of reality and will maintain a certain degree of uncertainty that must be taken into account in the modeling process 5 discussion the study conducted in this paper aimed to test the hypothesis that theory guided machine learning can be effectively applied to model groundwater dynamics in a real aquifer the methodology used was to conceptualize and build a theory guided multilayer perceptron tgmlp model suitable for real porous aquifers use it to simulate groundwater dynamics and compare it to observations a numerical model nummod and a multilayer perceptron model mlp with emphasis on applicability to practical hydrogeology the analysis of the results shows that the performance of the tgmlp model outperforms the mlp model which in turn outperforms the numerical model in the calibration training stage however in the test stage the mlp model is unable to extrapolate based on data that it has never encountered before unlike the numerical and tgmlp models therefore the reliability of the numerical and tgmlp models is higher than that of the mlp model also in the test stage the performance of the tgmlp is superior to that of the numerical model in addition the lack of physical constraints in the mlp training resulted in the systematic inability of the mlp to capture groundwater flow dynamics unlike the numerical and tgmlp models the superior performance of the tgmlp model over the numerical model at observation points is probably due to the fact that the tgmlp model was built to learn the physics of groundwater flow in the aquifer and to provide optimal fidelity to observations constraining learning from physics and data probably allows the tgmlp model to benefit from the advantages of both numerical models and traditional multilayer perceptron models which justifies its high performance at these observation points these results confirm the basic hypothesis of this study however it was found that the tgmlp model approximates the pde solution with only 70 of success the poor approximation in 30 of the locations could be due to an effect of pde violation at the sources sinks or in the vicinity of the neumann conditions thus an improvement in the approximation of the pde solution could be achieved by separating the pde cost function into sub cost functions corresponding to the different source sink terms or by considering the source sink terms and boundary conditions as part of the inverse problem this is a hypothesis that remains to be explored it is also interesting to note that because during training the main unknown parameters that determine the accuracy of the model and its physical consistency are the weight bias θ parameter of the neural network the tgmlp paradigm opens up a new way to give physical meaning to θ and thus reduce the black box nature that is usually attributed to artificial neural networks the study of the physical meaning of the θ parameters is beyond the scope of this study but it would be interesting for future works to address this issue especially in the context of the new branch of artificial intelligence called explainable artificial intelligence xai xai aims to design and implement methods to understand what is going on in the black box adombi et al 2021 the use of physics to constrain learning may in certain ways limits some of the traditional advantages of machine learning algorithms such as mlp one of the main characteristics of the mlp is its ability to model any nonlinear relationship between inputs and outputs but this can come at the cost of creating a black box model machine learning lends itself well to large scale and hydrogeological applications where spatial data remain scarce and expensive and can be replaced by easy to access data such as satellite data thus using physics to constrain learning is to reconsider machine learning problems as boundary problems therefore tgmlp can only be applied to terrains for which at least partial information on boundary conditions exist karniadakis et al 2021 and for which physical properties have been estimated as in the process of setting up numerical models another point concerns the computational costs required to implement tgmlp models indeed the optimization process requires a very large number of iterations to converge towards an acceptable solution in the present case at least 1800 epochs of 135 iterations per epoch were required i e 243 000 iterations in total to reach a result satisfying the stopping criteria without computation acceleration using a gpu that performed the computations at a speed of about one epoch per 2 5 s or 75 min the computations would have required about 450 min with an intel r core tm i7 10510u processor 1 80 ghz 2 30 ghz 16 gb ram even though unlike mlp the number of possible solutions models that tgmlp can produce is drastically reduced four possible patterns in the present study obtaining the one pattern for which the stopping criteria are all met may not be achieved on the first try the 450 min that would have been required for the tgmlp training without gpu correspond to 10 2 times the time required for a simulation with the marthe numerical model over the entire study period for the mlp model the training took only 9 4 min this corresponds to 2351 epochs of 135 iterations per epoch or 317 385 iterations in total 6 conclusion in this paper a theory guided multilayer perceptron model tgmlp was developed to test its effectiveness in simulating groundwater flow dynamics in a real world setting the performance of the tgmlp was compared against that of a numerical model nummod and a traditional multilayer perceptron model mlp in addition the ability of these three models to capture the spatiotemporal dynamics of groundwater was evaluated the degree of pde violation of the tgmlp model was also assessed finally the applicability of these three models in a real world setting was discussed the saint honoré unconfined aquifer quebec canada was used as an experimental laboratory for this study because of the extent of the knowledge and data acquired on this aquifer historical groundwater levels recharge precipitation mean temperature and qualitatively streamflow data were used to calibrate train validate and test the models the results show that the tgmlp demonstrates the best performance and far outperforms the traditional numerical and mlp models that the mlp model is a good interpolator but is unable to extrapolate and that only the numerical and tgmlp models are reliable because they are the only ones able to capture the spatiotemporal dynamics of groundwater flow and represent the dominant flow direction in the aquifer however it was found that the tgmlp model successfully approximates the pde solution only 70 of the time the poor approximation in 30 of the locations could be due to an effect of pde violation at the sources sinks or at the neumann conditions treating each source sink term as an independent term of the total cost function should be explored to assess how much this improves the approximation of the pde solution it may also be interesting to consider the source sink terms and boundary conditions as part of the inverse problem beyond that the tgml paradigm opens a new way to make physical sense of the parameters of artificial neural networks and thus reduce the black box nature that has usually been attributed to artificial neural network models also the computational cost of tgmlp training is high but can be reduced using gpu acceleration the results of this study may be useful to practitioners and researchers in selecting a model for their hydrogeological investigations funding sources this research did not receive any specific grant from funding agencies in the public commercial or not for profit sectors declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors would like to thank niobec mine and the municipality of saint honoré for providing data on pumping rates for wells in the study area 
2682,vegetation growth is critical in characterizing ecosystem carbon sequestration water availability profoundly affects the interaction between climate change and vegetation dynamics in drylands however the associations of the precipitation vegetation index pre vi and temperature vegetation index tem vi as well as whether and how the soil moisture modulates pre vi and tem vi are still unclear precipitation contributed substantially much more to vegetation dynamics than temperature and pre vi associations were greater in the southern hemisphere than those in the northern hemisphere in global drylands the traceability effects of soil moisture on pre vi and tem vi were investigated and a convex shape was observed for pre vi as soil moisture increased but not significant trend for tem vi it showed that moderate soil moisture enhanced pre vi associations through the maintenance of reasonable surface atmosphere feedback to counteract the balance of plant growth and energy collocation in the past three decades pre vi associations decreased with the increase in soil moisture suggesting the consistency of the spatial and temporal pattern of the effect of soil moisture on pre vi associations in water limited ecosystems our results implied that changes in soil moisture reflect changes in climate vegetation associations and can guide nature based solutions to improve ecosystem carbon sink keywords soil moisture climate change vegetation index precipitation drylands carbon uptake variability data availability data will be made available on request 1 introduction vegetation dynamics play a critical role in the variability of terrestrial carbon uptake and are controlled by water availability in drylands green et al 2019 jiao et al 2021 it is well known that the association between climate change and vegetation dynamics is modulated by the biogeochemical cycle and biogeophysical feedback windisch et al 2021 zhao et al 2017 vegetation growth is regulated by the precipitation pattern fang et al 2005 maurer et al 2020 meanwhile plant activity impacts climate change through altering evapotranspiration and albedo and further energy budget of land surface betts 2000 bonan 2008 the association between climatic factors with vegetation dynamics is vital for predicting the ecosystem carbon cycle but its temporal spatial pattern is currently unclear in global drylands the association between climate change and vegetation dynamics can be enhanced or weakened depending on the climatology and vegetation type as a result of regional biochemical cycles and local bio geophysical feedbacks windisch et al 2021 vegetation growth may differ even under the same amount of rainfall if there are different environmental constraints in two places the response of grassland carbon exchange to climate change is markedly different between the tibetan plateau and inner mongolia as moisture and thermal conditions are the dominant constraints of vegetation activity in the two regions respectively liu et al 2018 furthermore from 1982 to 2012 owing to global warming the association between temperature and vegetation cover declined leading to the reduction of the area where vegetation growth is constrained by temperature in the cold regions of the world and this situation will likely be sustained until 2100 keenan and riley 2018 the association between climate change and vegetation dynamics obviously changes in spatial and temporal patterns with the climatology belt and global warming generally vegetation dynamics are thought to have a high correlation with dominant climatic factors however the dominant climatic factors and vegetation growth may be decoupled when the correlation is low zhao et al 2021 this indicates that in a water limited ecosystem an increase in precipitation can promote vegetation growth only when the correlation between precipitation and vegetation is enough high therefore determining the threshold is challenging because the association of climatic factors with vegetation dynamics are spatially heterogeneous and evolve with time long time series climate and vegetation index data are needed to determine these correlations exploring whether proxy indicators could track the trajectory of the association between climate change and vegetation dynamics is important for predicting ecosystem carbon uptake soil moisture atmosphere feedback markedly influences surface water availability zhou et al 2021b and controls the carbon uptake variability of terrestrial ecosystems humphrey et al 2021 sustained soil moisture deficits induced by negative precipitation anomalies can cause extreme drought events hirschi et al 2011 miralles wilhelm 2022 and may affect plant growth and phenology reichstein et al 2002 gross primary productivity can decrease by up to 40 because of a decline in soil moisture in dryland ecosystems stocker et al 2018 soil moisture modulates the association between precipitation and vegetation activity via land atmosphere feedbacks moreover it is reported that regions with low average soil moisture exhibit low vegetation cover as a result of few precipitation and consequently a relatively narrow range of ecological soil water requirement ter braak and gremmen 1987 chi et al 2018 the required soil moisture by vegetation is first low then high and finally low again as precipitation increases this is in line with shelford s law of tolerance as illustrated by a bell shaped curve that shows the favorability for species or populations erofeeva 2021 correspondingly the association between climate change and vegetation dynamics change with water availability thus soil moisture has the potential to be used for tracking the pattern of temporal and spatial changes in vegetation growth in this study we aimed to 1 investigate the inter annual variability in the association between climate change and vegetation in global drylands and 2 explore whether and how soil moisture regulates precipitation vegetation and temperature vegetation index pre vi and tem vi respectively associations our findings are significant for determining variations in climate vegetation associations and can contribute to carbon uptake predictions 2 materials and methods 2 1 datasets data on global drylands are available at http millenniumassessment org en graphicresources html the database follows the world atlas of desertification middleton and thomas 1997 and defines drylands as areas with an aridity index value 0 65 we used the normalized difference vegetation index ndvi and near infrared reflectance of terrestrial vegetation nirv as proxies of vegetation dynamics in this study ndvi is a good proxy of surface vegetation cover fensholt and proud 2012 and nirv provides a robust physical interpretation and approximates the proportion of near infrared nir light reflected by vegetation badgley et al 2019 and improves the understanding of photosynthesis badgley et al 2017 the annual maximum ndvi during 1982 2015 obtained from gimms3g with savitzky golay filtering was used to characterize the interannual vegetation dynamics grids with ndvi 0 1 in any year were selected as available units nirv data were derived from the advanced very high resolution radiometer avhrr with red and nir band reflectance he et al 2021 from 1982 to 2015 the annual maximum value of the nirv was used in this study datasets were aggregated to a spatial resolution of 0 5 0 5 to match the climate dataset yearly average air temperature and total precipitation data were obtained from the climatic research unit high resolution gridded datasets version 3 24 cru 3 24 harris et al 2014 by averaging the monthly temperature and summing the monthly rainfall values at a spatial resolution of 0 5 0 5 during 1982 2015 the standardized precipitation evapotranspiration index spei was first proposed by vicente serrano et al 2010 as an improved drought index to estimate the effect of global warming on drought severity spei 12 month data were obtained from http digital csic es handle 10261 153475 spei base v2 5 at a spatial resolution of 0 5 we used the yearly soil moisture data available from the european space agency s climate change initiative esa cci which were derived from multiple active and passive microwave sensors and generally agree well with the spatial and temporal patterns estimated by land surface models dorigo et al 2017 soil moisture affects energy partitioning at the surface and influences the water and energy cycle esa cci sm products provide remotely sensed surface soil moisture content data at a spatial resolution of 25 km we obtained yearly values by averaging the monthly data from 1982 to 2015 and aggregated them to a spatial resolution of 0 5 2 2 data analysis the geodetector model gdm was used to quantify the association between climatic variables namely precipitation pre and temperature tem and the interannual variation iav in vegetation index ndvi or nirv variability in global drylands the gdm does not require a linear hypothesis to identify the explanatory power behind stratified heterogeneity and has been widely applied in studies on ecological processes and geographic applications wang et al 2016 using the k means classification algorithm we discretized the numerical variables into categorical groups as the stratum of the vegetation index and climatic factors in the gdm then the explanatory power of each climatic variable x for the iav of the vegetation index was quantified using the indicator q as follows 1 q x 1 i 1 m n i σ i 2 n σ 2 1 ssw sst where qx 0 1 is the explanatory power of the climatic factor x i 1 m is the stratum category of ndvi or nirv for the climatic factor x ni and n are the total sample numbers of stratum i and the overall period 1982 2015 respectively σi2 and σ2 are the variances in ndvi or nirv in stratum i and the overall period respectively and ssw and sst are the within sum of squares ssw for stratum i and the total sum of squares sst in the overall period respectively in this study spei 1 denotes spei 1 0 5 spei 2 denotes spei 0 5 0 spei 3 denotes spei 0 0 5 spei 4 denotes spei 0 5 1 we then identified the critical characteristics in the associations of climatic variables and vegetation dynamic with the pattern of soil moisture content with the spei intervals and the pattern of spei with the soil moisture intervals pre vi and tem vi associations trend along soil moisture changed were investigated using spei from 1 to 1 at intervals of 0 5 pre vi and tem vi associations trend were investigated using spei from 1 to 1 at intervals of 0 5 lastly to maintain high significant values long time sliding window for as many years as possible and to ensure a sufficient number of groups to detect the trends in soil moisture in the study period we chose a 20 year sliding window from 1982 to 2015 with 15 groups to detect the temporal changes in soil moisture and the relationship of soil moisture to climate vegetation association correlations climate change and the vegetation index variability are assessed in terms of time period with decades we calculated the average soil moisture value changes of 15 group from 1982 to 2015 as well as 15 groups of association correlations for pre vi and tem vi at a grid scale to explore the traceability effects of soil moisture with respect to its temporal and spatial characteristics 3 results and discussion 3 1 spatial heterogeneity in pre vi and tem vi associations we investigated the association between climate variables precipitation pre and temperature tem and vegetation index vi variability as well as their spatial patterns over each continent and latitude in global drylands our results showed that the mean pre vi association was 0 14 0 12 which was higher than that of tem vi 0 11 0 10 the area with a high association coefficient 0 15 for pre vi accounted for 36 of the global drylands being higher than that of tem vi 27 fig 1 vegetation dynamics were associated with precipitation changes in drylands which is consistent with previous findings that indicate that the above ground net primary productivity of grasslands is determined by variations in precipitation amount swemmer et al 2007 and water availability zhao et al 2020 fig 1 shows the association coefficient averages of pre vi and tem vi along the latitude at a 0 5 interval the zonal pattern showed an enhancement trend from north to south for pre vi associations but not for tem vi associations highlight hence that an agreement in the high pre vi associations in drylands in the southern hemisphere and in a large percentage of areas with a monsoonal climate as well as frequent precipitation variations over the past 30 years owing to frequent turbulent monsoon circulation devaraju et al 2015 hsu et al 2012 the difference δ between pre vi and tem vi associations was investigated to identify the regions where the yearly vegetation growth was most associated with precipitation and temperature in global drylands a positive δ represents stronger pre vi association than tem vi association and a negative δ denotes stronger tem vi association than pre vi association fig 2 regions with a positive δ were observed accounting for 56 of all areas whereas a negative δ region accounting for 44 of all areas indicating that in drylands areas with predominant pre vi associations are larger than those with predominant tem vi associations this was an overall prevalent phenomenon in drylands at each spei bin except in asia and europe this is because primary production is highly sensitive to precipitation moreover the soil water atmosphere feedback through the regulation of evapotranspiration affects the atmospheric water content maurer et al 2020 zhou et al 2021b the areas of the slight association difference with the δ value ranging from 0 1 to 0 1 accounted for 55 suggesting that the pre vi and tem vi associations were highly similar in more than half of the drylands furthermore the large association difference with the δ values 0 1 and 0 1 accounted for 17 6 and 27 3 respectively area with high absolute δ value 0 1 or 0 1 27 3 minus 17 6 is 9 7 dominated the overall area with pre vi and tem vi associations difference 56 minus 44 is 12 this indicated that changes of the climate or vegetation dynamics happened in the region with a high absolute δ value 0 1 or 0 1 may have a large effect on the shift of the determinant factors and the carbon cycle predictions identifying regions with a large absolute δ and then exploring the corresponding indicator of the ecological environment which could present the association between climate change and vegetation dynamics and then would promote the prediction in the terrestrial carbon uptake in drylands regions with positive δ values for spei 3 and spei 4 were larger than those for spei 1 and spei 2 thereby supporting the notion that vegetation in relatively wet regions in drylands is more sensitive to precipitation maurer et al 2020 meanwhile the soil moisture atmosphere feedback is much more intense in such areas because of energy budget changes owing to altered vegetation cover zhou et al 2021b 3 2 spatial pattern of pre vi and tem vi associations with soil moisture change results demonstrated that the pre vi association presented a convex shape p 0 0001 both for ndvi and nirv but tem vi association showed a slight change p 0 0004 for ndvi and p 0 1087 for nirv along with an increase in soil moisture which both were averaged at each 0 5 spei interval from 1 to 1 moderate soil moisture enhanced the pre vi association but not the tem vi association meanwhile the pre vi and tem vi associations did not show a significant pattern along the aridity index gradient of the spei at each soil moisture interval fig s3 the fitting curves showed that the pre vi association first increased and then decreased with an increase of soil moisture with a turning point of 0 147 mm3 mm 3 for ndvi and 0 176 mm3 mm 3 for nirv soil moisture showed a consistent pattern of pre vi associations at different spei levels and provided robust traceability to characterize the synergy between climate change and vegetation dynamics in drylands moderate soil moisture was compounded by the high association with pre vi this implies that when soil is too wet or too dry the pre vi association weakens owing to the low water availability for vegetation growth resulting from evaporation runoff or deep infiltration deficits it has generally been interpreted that soil moisture regulates atmospheric circulation and mitigates low water availability in drylands zhou et al 2021b this highlights the need to account for the soil moisture atmosphere feedback cox et al 2013 piao et al 2020 which dominates the land carbon uptake variability humphrey et al 2021 soil moisture has an effective traceable effect on the pre vi association in global drylands the regression lines comprised a convex up curve and were nearly flat along the soil moisture increasing for the pre vi and tem vi associations respectively when the soil was too wet or too dry the tem vi showed a higher association than pre vi fig 3 therefore two intersecting points of soil moisture were 0 067 and 0 26 mm3 mm 3 for ndvi and 0 065 and 0 28 mm3 mm 3 for nirv between the pre vi and tem vi fitting curves respectively fig 3 in detail the pre vi association was greater than the tem vi association when it was within the aforementioned range of soil moisture otherwise the opposite trend was observed beyond the range interestingly a similar soil moisture range was obtained when using ndvi and nirv implying that the traceability of soil moisture is consistent when clarifying the association between vegetation dynamics and climate change independent of the vegetation index in drylands previous studies have indicated that an increased association between climate change and vegetation index variation promotes the coupling of critical factors and vegetation growth zhao et al 2021 thus the maintenance of the soil moisture level plays an important role in the association between precipitation and vegetation growth the monitoring and inversion of changes in soil moisture facilitate the prediction of the pre vi association and the carbon flux estimation under climate change compared with the changes in the pre vi and tem vi association in terms of soil moisture no significant pattern was found for the association in pre vi and tem vi changes along the spei at an interval of 0 1 with a soil moisture gradient from 0 to 0 4 mm3 mm 3 at an interval of 0 1 mm3 mm 3 fig s3 soil moisture is more robust than spei in terms of the traceability of elements indicating changes in the association between climate change and vegetation dynamics in drylands this is probably because spei indicates meteorological drought associated with evapotranspiration and precipitation beguería et al 2014 while soil moisture mediates the relationship between precipitation and vegetation growth seneviratne et al 2010 especially in drylands with strong surface atmospheric feedbacks zhou et al 2021b soil moisture mediates the association between precipitation and vegetation dynamics in drylands first soil hydraulic physical properties e g texture structure and particle size distribution are intrinsically determined by the soil forming process cosby et al 1984 water retention and holding capacity quan et al 2019 in a given region there is an optimum average soil moisture that is determined by the soil formation conditions and environment representing the balance between water supply and use changes in soil moisture reflect the imbalance between precipitation and the requirement for water in ecosystems to a certain extent which is delivered by surface energy exchange and plant photosynthesis second precipitation regulates the vegetation activities through the soil parameters of water duration and water storage capacity moon et al 2019 generally lower average soil moisture results in lower vegetation cover therefore the effects of precipitation deficit on suppressing plant growth are much stronger in a low soil moisture region than those in a high soil moisture region owing to the higher water use efficiency maurer et al 2020 furthermore changes in the pre vi association with soil water link precipitation and vegetation growth through soil moisture precipitation feedback moon et al 2019 and soil moisture carbon coupling quan et al 2019 the increased evaporation owing to the low vegetation cover decreases the corresponding surface temperature hindering vegetation growth and subsequently leading to a low pre ai association as the average soil moisture increases to the optimal levels changes in soil moisture can promote vegetation growth and surface physical feedback when soil moisture was increases above the optimum level instead of promoting plant growth precipitation cam result in runoff or groundwater infiltration thereby weakening the surface atmosphere feedback and energy flow variability resulting in a low pre ai association the asymmetrical nonlinear relationship of ppt anpp above ground net primary productivity in drylands knapp et al 2017 has a pivotal effect on the global carbon cycle ahlström et al 2015 our findings shed light on the identification of pre vi to predict abrupt ecosystem changes in carbon flux and facilitate investigations of potential critical thresholds to forecast carbon cycle under climate change 3 3 temporal pattern of pre vi and tem vi associations in terms of soil moisture we next examined the average soil moisture variation using a 20 year sliding window during 1982 2015 to determine how the pre vi and tem vi associations varied with change of soil moisture over time the results demonstrated that average soil moisture increased from 1982 to 2015 and that there was a turning point at 0 168 mm3 mm 3 during 1988 2007 soil moisture increased more moderately at a rate of 5 10 3 mm3 mm 3 decade 1 after 1988 2007 stage t2 compared with the value of 4 10 2 mm3 mm 3 decade 1 before 1988 2007 stage t1 fig 4 furthermore the pre vi association showed a considerable decrease of 16 03 per mm3 mm 3 in stage t2 compared with 3 44 per mm3 mm 3 in stage t1 with soil moisture increasing based on ndvi and the rate of decrease was 5 4 per mm3 mm 3 based on nirv in stage t2 the pre vi association significantly decreased p 0 05 with an increase in soil moisture during t1 and t2 except for that based on nirv in stage t1 fig 4 overall pre vi associations decreased as soil moisture increased whereas tem vi associations did not present significant trend in the past three decades notably the turning point for the relationship between soil moisture and pre vi associations from positive to negative was lower for ndvi than that for nirv it probably resulted that the the divergent trend between pre ndvi and pre nirv were detected during the same period t1 soil moisture records are fundamental for interpreting the long term dynamics of water carbon cycle coupling between the land surface and atmosphere dorigo et al 2017 plant roots and soil texture regulate rainfall infiltration and soil water flux fan et al 2017 and plant transpiration relies on precipitation 70 from the current month and 18 from past precipitation stores in deeper soils miguez macho and fan 2021 which probably resulted in uncertainties regarding the changes in pre vi associations with soil moisture in areas with limited soil water availability dorigo et al 2017 indeed the temporal pattern of pre vi associations agreed with the spatial pattern of soil moisture changes in drylands in the past three decades decreasing as soil moisture increased because the average soil moisture was above the value of the transition point therefore an increase in soil moisture strengthened the pre vi association below the turning point and weakened the pre vi association above this point soil moisture dynamics have traceable effects on the pre vi association in drylands therefore quantifying the temporal spatial patterns of soil moisture variations may reduce the uncertainties surrounding the coupling of precipitation and vegetation growth and the estimation of the carbon cycle with increasing precipitation variability soil moisture has received extensive attention as it is the core of the carbon climate interaction that functions by regulating the biogeochemical cycle and bio geophysical feedback humphrey et al 2021 regional soil moisture data have been acquired to improve the spatio temporal resolution and accuracy of soil moisture data inversions dorigo et al 2017 zhou et al 2021a allowing large scale soil moisture traceability and mechanistic research on climate vegetation feedbacks soil moisture forms the nexus of multiple physical and biological processes martínez fernández et al 2021 and it can constrain plant physiological processes in water limited ecosystems by regulating energy and material exchange via land atmosphere feedbacks berg et al 2016 seneviratne et al 2010 zhou et al 2019 soil water stress influences stomatal functions and plant water use efficiency lavergne et al 2020 whereas vegetation growth regulates water availability mankin et al 2019 soil moisture maintains the homeostasis of the soil plant atmosphere continuum in all climatology zones our findings suggested that soil moisture modulated the pre vi association for the carbon climate feedback in water limited ecosystems water plays a crucial role in the ecosystem structure material function and energy flux exchange in different forms e g rainfall soil moisture and leaf water content insights on the dynamic traceability effects of soil moisture on the pre vi association are essential to understand carbon uptake variability in drylands which is vital for predicting the coupling of climate change and vegetation activity 4 implications and conclusions we found that the dynamic traceable effects of soil moisture were effective as a reference indicator to infer the pre vi association spatially and could be used to interpret the decrease in pre vi association owing to the increasing soil moisture in the past three decades a schematic diagram of the impact of soil moisture on the dryland carbon sink through the traceability effect is presented in fig 5 generally soil moisture is stable in a given region and period and it regulates the association between vegetation dynamics and climate change thus soil moisture variations may signify pre vi association changes thereby affecting vegetation climate coupling zhao et al 2021 the coupling of vegetation growth and precipitation substantially affects dryland carbon sequestration which is determined by the effective pre vi association sufficiently high correlation coefficient our results showed that the degree and area of the pre vi association were greater than those of the tem vi association and the association of δ showed a spatially heterogeneous pattern with a much more positive value in the southern hemisphere than that in the northern hemisphere probably owing to the influence of monsoonal climate regions importantly the pre vi association in the southern hemisphere played a stronger role in the coupling of precipitation and vegetation growth than that in the northern hemisphere under global warming and precipitation oscillation conditions moderate soil moisture enhanced the pre vi association in drylands our results indicated a convex type trend for pre vi but not for tem vi as soil moisture increased the pre vi association strengthened or weakened as soil moisture increased in drylands when the soil moisture was below or above the turning point threshold respectively this supports the spatial heterogeneity of the climate vegetation interaction and improves our understanding of the effect of soil moisture pathways on dryland carbon sequestration the effects of soil moisture include but are not limited to regulating soil water storage capacity and its memory function martínez fernández et al 2021 controlling water availability through evapotranspiration and influencing atmospheric moisture inflow zhou et al 2021b and vegetation dynamics humphrey et al 2021 which ultimately affect the pre vi association the association is closely related to vegetation cover and the topography series index özkan and gökbulak 2017 specifically low soil moisture cannot meet the demand for plant growth owing to strong evaporation weakening the pre vi association high soil moisture generally supports dense vegetation coverage decreasing the evaporation capacity and potentially resulting in runoff and a weak pre vi association moreover moderate soil moisture can maintain reasonable surface atmosphere feedback to counteract the balance of plant growth and energy collocation strengthening the pre vi association this study assessed the long term soil moisture impact on the pre vi and tem vi associations using a 20 year sliding window suggesting that the pre vi association was weakened as soil moisture in global drylands increased from 1982 to 2015 this was because the increased soil moisture exceeded its previous normal multi year average value enhancing the soil moisture atmosphere feedback humphrey et al 2021 and indirectly suppressing anomalies in precipitation and plant growth interactions thereby indicating a shift in the dynamic balance from a steady state to an unsteady state ryo et al 2019 the weakened pre vi association provided an effective profile for predicting how vegetation dynamics are associated with precipitation changes indicating a close relation to potential soil moisture variations it should be noted that the pattern of pre vi associations with yearly soil moisture variations was not absolutely compatible with that in seasonal or monthly soil moisture thus requiring further consideration nevertheless soil moisture regulation is significant for predicting vegetation dynamics under climate change conditions and should receive more attention for ecosystem carbon sink management excessively dry or wet soil moisture conditions can weaken the association between vegetation dynamics and precipitation therefore maintaining a reasonable soil moisture range in an area can improve the estimation accuracy of the effect of natural or human disturbances such as extreme climate events deforestation and afforestation on climate change and vegetation dynamics in drylands to the best of our knowledge this is the first up to date proposal related to how soil moisture modifies the coupling of climate change and vegetation dynamics by regulating their association degree tracing changes in soil moisture can guide the development of climate vegetation association models and is profoundly important for predicting the impact of climate change on future vegetation owing to the convex shape of the response of the pre vi association to soil moisture the direction of vegetation growth is dependent on the average soil moisture and the trend direction when soil moisture is lower than the turning point value pre vi associations increase as soil moisture increases thereby promoting the coupling of precipitation and vegetation growth however when soil moisture is higher than the turning point value precipitation vegetation coupling weakens then precipitation increasing inhibiting vegetation growth with an increase in soil moisture and potentially altering the ecosystem structure over a long time in future studies increasing co2 and n deposition should be considered because they also interaction with climate accompany affect vegetation growth the soil moisture parameter modules should be added to the terrestrial ecosystem model to reduce key uncertainties in terrestrial carbon uptake variability simulations in future projections of global drylands with the development and progress of remote sensing and radar observation technology studies on the qualitative and quantitative effects of soil moisture on the regulation of land atmosphere interactions through direct and indirect effects are increasing such as studies using model simulations and big data calculations xu et al 2021 multi pathway approaches have been used to explore the critical links to reduce the uncertainty in carbon imbalances in the earth system here a framework diagram for the traceable effects of soil moisture on pre vi associations was proposed wherein climate vegetation interaction could be clearly represented by soil moisture or parameters derived from equations related to soil moisture field experiments and a reanalysis of more soil texture related data need to be conducted to quantify these parameters credit authorship contribution statement wei zhao formal analysis validation writing original draft xiubo yu conceptualization project administration funding acquisition chengdong xu methodology software investigation shenggong li writing review editing supervision genan wu writing review editing wenping yuan validation data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the international partnership program of chinese academy of sciences grant no 121311kysb20170004 and china postdoctoral science foundation grant no 2020m670439 appendix a supplementary material supplementary material to this article can be found online at https doi org 10 1016 j jhydrol 2022 128645 appendix a supplementary material the following are the supplementary material to this article supplementary data 1 
2682,vegetation growth is critical in characterizing ecosystem carbon sequestration water availability profoundly affects the interaction between climate change and vegetation dynamics in drylands however the associations of the precipitation vegetation index pre vi and temperature vegetation index tem vi as well as whether and how the soil moisture modulates pre vi and tem vi are still unclear precipitation contributed substantially much more to vegetation dynamics than temperature and pre vi associations were greater in the southern hemisphere than those in the northern hemisphere in global drylands the traceability effects of soil moisture on pre vi and tem vi were investigated and a convex shape was observed for pre vi as soil moisture increased but not significant trend for tem vi it showed that moderate soil moisture enhanced pre vi associations through the maintenance of reasonable surface atmosphere feedback to counteract the balance of plant growth and energy collocation in the past three decades pre vi associations decreased with the increase in soil moisture suggesting the consistency of the spatial and temporal pattern of the effect of soil moisture on pre vi associations in water limited ecosystems our results implied that changes in soil moisture reflect changes in climate vegetation associations and can guide nature based solutions to improve ecosystem carbon sink keywords soil moisture climate change vegetation index precipitation drylands carbon uptake variability data availability data will be made available on request 1 introduction vegetation dynamics play a critical role in the variability of terrestrial carbon uptake and are controlled by water availability in drylands green et al 2019 jiao et al 2021 it is well known that the association between climate change and vegetation dynamics is modulated by the biogeochemical cycle and biogeophysical feedback windisch et al 2021 zhao et al 2017 vegetation growth is regulated by the precipitation pattern fang et al 2005 maurer et al 2020 meanwhile plant activity impacts climate change through altering evapotranspiration and albedo and further energy budget of land surface betts 2000 bonan 2008 the association between climatic factors with vegetation dynamics is vital for predicting the ecosystem carbon cycle but its temporal spatial pattern is currently unclear in global drylands the association between climate change and vegetation dynamics can be enhanced or weakened depending on the climatology and vegetation type as a result of regional biochemical cycles and local bio geophysical feedbacks windisch et al 2021 vegetation growth may differ even under the same amount of rainfall if there are different environmental constraints in two places the response of grassland carbon exchange to climate change is markedly different between the tibetan plateau and inner mongolia as moisture and thermal conditions are the dominant constraints of vegetation activity in the two regions respectively liu et al 2018 furthermore from 1982 to 2012 owing to global warming the association between temperature and vegetation cover declined leading to the reduction of the area where vegetation growth is constrained by temperature in the cold regions of the world and this situation will likely be sustained until 2100 keenan and riley 2018 the association between climate change and vegetation dynamics obviously changes in spatial and temporal patterns with the climatology belt and global warming generally vegetation dynamics are thought to have a high correlation with dominant climatic factors however the dominant climatic factors and vegetation growth may be decoupled when the correlation is low zhao et al 2021 this indicates that in a water limited ecosystem an increase in precipitation can promote vegetation growth only when the correlation between precipitation and vegetation is enough high therefore determining the threshold is challenging because the association of climatic factors with vegetation dynamics are spatially heterogeneous and evolve with time long time series climate and vegetation index data are needed to determine these correlations exploring whether proxy indicators could track the trajectory of the association between climate change and vegetation dynamics is important for predicting ecosystem carbon uptake soil moisture atmosphere feedback markedly influences surface water availability zhou et al 2021b and controls the carbon uptake variability of terrestrial ecosystems humphrey et al 2021 sustained soil moisture deficits induced by negative precipitation anomalies can cause extreme drought events hirschi et al 2011 miralles wilhelm 2022 and may affect plant growth and phenology reichstein et al 2002 gross primary productivity can decrease by up to 40 because of a decline in soil moisture in dryland ecosystems stocker et al 2018 soil moisture modulates the association between precipitation and vegetation activity via land atmosphere feedbacks moreover it is reported that regions with low average soil moisture exhibit low vegetation cover as a result of few precipitation and consequently a relatively narrow range of ecological soil water requirement ter braak and gremmen 1987 chi et al 2018 the required soil moisture by vegetation is first low then high and finally low again as precipitation increases this is in line with shelford s law of tolerance as illustrated by a bell shaped curve that shows the favorability for species or populations erofeeva 2021 correspondingly the association between climate change and vegetation dynamics change with water availability thus soil moisture has the potential to be used for tracking the pattern of temporal and spatial changes in vegetation growth in this study we aimed to 1 investigate the inter annual variability in the association between climate change and vegetation in global drylands and 2 explore whether and how soil moisture regulates precipitation vegetation and temperature vegetation index pre vi and tem vi respectively associations our findings are significant for determining variations in climate vegetation associations and can contribute to carbon uptake predictions 2 materials and methods 2 1 datasets data on global drylands are available at http millenniumassessment org en graphicresources html the database follows the world atlas of desertification middleton and thomas 1997 and defines drylands as areas with an aridity index value 0 65 we used the normalized difference vegetation index ndvi and near infrared reflectance of terrestrial vegetation nirv as proxies of vegetation dynamics in this study ndvi is a good proxy of surface vegetation cover fensholt and proud 2012 and nirv provides a robust physical interpretation and approximates the proportion of near infrared nir light reflected by vegetation badgley et al 2019 and improves the understanding of photosynthesis badgley et al 2017 the annual maximum ndvi during 1982 2015 obtained from gimms3g with savitzky golay filtering was used to characterize the interannual vegetation dynamics grids with ndvi 0 1 in any year were selected as available units nirv data were derived from the advanced very high resolution radiometer avhrr with red and nir band reflectance he et al 2021 from 1982 to 2015 the annual maximum value of the nirv was used in this study datasets were aggregated to a spatial resolution of 0 5 0 5 to match the climate dataset yearly average air temperature and total precipitation data were obtained from the climatic research unit high resolution gridded datasets version 3 24 cru 3 24 harris et al 2014 by averaging the monthly temperature and summing the monthly rainfall values at a spatial resolution of 0 5 0 5 during 1982 2015 the standardized precipitation evapotranspiration index spei was first proposed by vicente serrano et al 2010 as an improved drought index to estimate the effect of global warming on drought severity spei 12 month data were obtained from http digital csic es handle 10261 153475 spei base v2 5 at a spatial resolution of 0 5 we used the yearly soil moisture data available from the european space agency s climate change initiative esa cci which were derived from multiple active and passive microwave sensors and generally agree well with the spatial and temporal patterns estimated by land surface models dorigo et al 2017 soil moisture affects energy partitioning at the surface and influences the water and energy cycle esa cci sm products provide remotely sensed surface soil moisture content data at a spatial resolution of 25 km we obtained yearly values by averaging the monthly data from 1982 to 2015 and aggregated them to a spatial resolution of 0 5 2 2 data analysis the geodetector model gdm was used to quantify the association between climatic variables namely precipitation pre and temperature tem and the interannual variation iav in vegetation index ndvi or nirv variability in global drylands the gdm does not require a linear hypothesis to identify the explanatory power behind stratified heterogeneity and has been widely applied in studies on ecological processes and geographic applications wang et al 2016 using the k means classification algorithm we discretized the numerical variables into categorical groups as the stratum of the vegetation index and climatic factors in the gdm then the explanatory power of each climatic variable x for the iav of the vegetation index was quantified using the indicator q as follows 1 q x 1 i 1 m n i σ i 2 n σ 2 1 ssw sst where qx 0 1 is the explanatory power of the climatic factor x i 1 m is the stratum category of ndvi or nirv for the climatic factor x ni and n are the total sample numbers of stratum i and the overall period 1982 2015 respectively σi2 and σ2 are the variances in ndvi or nirv in stratum i and the overall period respectively and ssw and sst are the within sum of squares ssw for stratum i and the total sum of squares sst in the overall period respectively in this study spei 1 denotes spei 1 0 5 spei 2 denotes spei 0 5 0 spei 3 denotes spei 0 0 5 spei 4 denotes spei 0 5 1 we then identified the critical characteristics in the associations of climatic variables and vegetation dynamic with the pattern of soil moisture content with the spei intervals and the pattern of spei with the soil moisture intervals pre vi and tem vi associations trend along soil moisture changed were investigated using spei from 1 to 1 at intervals of 0 5 pre vi and tem vi associations trend were investigated using spei from 1 to 1 at intervals of 0 5 lastly to maintain high significant values long time sliding window for as many years as possible and to ensure a sufficient number of groups to detect the trends in soil moisture in the study period we chose a 20 year sliding window from 1982 to 2015 with 15 groups to detect the temporal changes in soil moisture and the relationship of soil moisture to climate vegetation association correlations climate change and the vegetation index variability are assessed in terms of time period with decades we calculated the average soil moisture value changes of 15 group from 1982 to 2015 as well as 15 groups of association correlations for pre vi and tem vi at a grid scale to explore the traceability effects of soil moisture with respect to its temporal and spatial characteristics 3 results and discussion 3 1 spatial heterogeneity in pre vi and tem vi associations we investigated the association between climate variables precipitation pre and temperature tem and vegetation index vi variability as well as their spatial patterns over each continent and latitude in global drylands our results showed that the mean pre vi association was 0 14 0 12 which was higher than that of tem vi 0 11 0 10 the area with a high association coefficient 0 15 for pre vi accounted for 36 of the global drylands being higher than that of tem vi 27 fig 1 vegetation dynamics were associated with precipitation changes in drylands which is consistent with previous findings that indicate that the above ground net primary productivity of grasslands is determined by variations in precipitation amount swemmer et al 2007 and water availability zhao et al 2020 fig 1 shows the association coefficient averages of pre vi and tem vi along the latitude at a 0 5 interval the zonal pattern showed an enhancement trend from north to south for pre vi associations but not for tem vi associations highlight hence that an agreement in the high pre vi associations in drylands in the southern hemisphere and in a large percentage of areas with a monsoonal climate as well as frequent precipitation variations over the past 30 years owing to frequent turbulent monsoon circulation devaraju et al 2015 hsu et al 2012 the difference δ between pre vi and tem vi associations was investigated to identify the regions where the yearly vegetation growth was most associated with precipitation and temperature in global drylands a positive δ represents stronger pre vi association than tem vi association and a negative δ denotes stronger tem vi association than pre vi association fig 2 regions with a positive δ were observed accounting for 56 of all areas whereas a negative δ region accounting for 44 of all areas indicating that in drylands areas with predominant pre vi associations are larger than those with predominant tem vi associations this was an overall prevalent phenomenon in drylands at each spei bin except in asia and europe this is because primary production is highly sensitive to precipitation moreover the soil water atmosphere feedback through the regulation of evapotranspiration affects the atmospheric water content maurer et al 2020 zhou et al 2021b the areas of the slight association difference with the δ value ranging from 0 1 to 0 1 accounted for 55 suggesting that the pre vi and tem vi associations were highly similar in more than half of the drylands furthermore the large association difference with the δ values 0 1 and 0 1 accounted for 17 6 and 27 3 respectively area with high absolute δ value 0 1 or 0 1 27 3 minus 17 6 is 9 7 dominated the overall area with pre vi and tem vi associations difference 56 minus 44 is 12 this indicated that changes of the climate or vegetation dynamics happened in the region with a high absolute δ value 0 1 or 0 1 may have a large effect on the shift of the determinant factors and the carbon cycle predictions identifying regions with a large absolute δ and then exploring the corresponding indicator of the ecological environment which could present the association between climate change and vegetation dynamics and then would promote the prediction in the terrestrial carbon uptake in drylands regions with positive δ values for spei 3 and spei 4 were larger than those for spei 1 and spei 2 thereby supporting the notion that vegetation in relatively wet regions in drylands is more sensitive to precipitation maurer et al 2020 meanwhile the soil moisture atmosphere feedback is much more intense in such areas because of energy budget changes owing to altered vegetation cover zhou et al 2021b 3 2 spatial pattern of pre vi and tem vi associations with soil moisture change results demonstrated that the pre vi association presented a convex shape p 0 0001 both for ndvi and nirv but tem vi association showed a slight change p 0 0004 for ndvi and p 0 1087 for nirv along with an increase in soil moisture which both were averaged at each 0 5 spei interval from 1 to 1 moderate soil moisture enhanced the pre vi association but not the tem vi association meanwhile the pre vi and tem vi associations did not show a significant pattern along the aridity index gradient of the spei at each soil moisture interval fig s3 the fitting curves showed that the pre vi association first increased and then decreased with an increase of soil moisture with a turning point of 0 147 mm3 mm 3 for ndvi and 0 176 mm3 mm 3 for nirv soil moisture showed a consistent pattern of pre vi associations at different spei levels and provided robust traceability to characterize the synergy between climate change and vegetation dynamics in drylands moderate soil moisture was compounded by the high association with pre vi this implies that when soil is too wet or too dry the pre vi association weakens owing to the low water availability for vegetation growth resulting from evaporation runoff or deep infiltration deficits it has generally been interpreted that soil moisture regulates atmospheric circulation and mitigates low water availability in drylands zhou et al 2021b this highlights the need to account for the soil moisture atmosphere feedback cox et al 2013 piao et al 2020 which dominates the land carbon uptake variability humphrey et al 2021 soil moisture has an effective traceable effect on the pre vi association in global drylands the regression lines comprised a convex up curve and were nearly flat along the soil moisture increasing for the pre vi and tem vi associations respectively when the soil was too wet or too dry the tem vi showed a higher association than pre vi fig 3 therefore two intersecting points of soil moisture were 0 067 and 0 26 mm3 mm 3 for ndvi and 0 065 and 0 28 mm3 mm 3 for nirv between the pre vi and tem vi fitting curves respectively fig 3 in detail the pre vi association was greater than the tem vi association when it was within the aforementioned range of soil moisture otherwise the opposite trend was observed beyond the range interestingly a similar soil moisture range was obtained when using ndvi and nirv implying that the traceability of soil moisture is consistent when clarifying the association between vegetation dynamics and climate change independent of the vegetation index in drylands previous studies have indicated that an increased association between climate change and vegetation index variation promotes the coupling of critical factors and vegetation growth zhao et al 2021 thus the maintenance of the soil moisture level plays an important role in the association between precipitation and vegetation growth the monitoring and inversion of changes in soil moisture facilitate the prediction of the pre vi association and the carbon flux estimation under climate change compared with the changes in the pre vi and tem vi association in terms of soil moisture no significant pattern was found for the association in pre vi and tem vi changes along the spei at an interval of 0 1 with a soil moisture gradient from 0 to 0 4 mm3 mm 3 at an interval of 0 1 mm3 mm 3 fig s3 soil moisture is more robust than spei in terms of the traceability of elements indicating changes in the association between climate change and vegetation dynamics in drylands this is probably because spei indicates meteorological drought associated with evapotranspiration and precipitation beguería et al 2014 while soil moisture mediates the relationship between precipitation and vegetation growth seneviratne et al 2010 especially in drylands with strong surface atmospheric feedbacks zhou et al 2021b soil moisture mediates the association between precipitation and vegetation dynamics in drylands first soil hydraulic physical properties e g texture structure and particle size distribution are intrinsically determined by the soil forming process cosby et al 1984 water retention and holding capacity quan et al 2019 in a given region there is an optimum average soil moisture that is determined by the soil formation conditions and environment representing the balance between water supply and use changes in soil moisture reflect the imbalance between precipitation and the requirement for water in ecosystems to a certain extent which is delivered by surface energy exchange and plant photosynthesis second precipitation regulates the vegetation activities through the soil parameters of water duration and water storage capacity moon et al 2019 generally lower average soil moisture results in lower vegetation cover therefore the effects of precipitation deficit on suppressing plant growth are much stronger in a low soil moisture region than those in a high soil moisture region owing to the higher water use efficiency maurer et al 2020 furthermore changes in the pre vi association with soil water link precipitation and vegetation growth through soil moisture precipitation feedback moon et al 2019 and soil moisture carbon coupling quan et al 2019 the increased evaporation owing to the low vegetation cover decreases the corresponding surface temperature hindering vegetation growth and subsequently leading to a low pre ai association as the average soil moisture increases to the optimal levels changes in soil moisture can promote vegetation growth and surface physical feedback when soil moisture was increases above the optimum level instead of promoting plant growth precipitation cam result in runoff or groundwater infiltration thereby weakening the surface atmosphere feedback and energy flow variability resulting in a low pre ai association the asymmetrical nonlinear relationship of ppt anpp above ground net primary productivity in drylands knapp et al 2017 has a pivotal effect on the global carbon cycle ahlström et al 2015 our findings shed light on the identification of pre vi to predict abrupt ecosystem changes in carbon flux and facilitate investigations of potential critical thresholds to forecast carbon cycle under climate change 3 3 temporal pattern of pre vi and tem vi associations in terms of soil moisture we next examined the average soil moisture variation using a 20 year sliding window during 1982 2015 to determine how the pre vi and tem vi associations varied with change of soil moisture over time the results demonstrated that average soil moisture increased from 1982 to 2015 and that there was a turning point at 0 168 mm3 mm 3 during 1988 2007 soil moisture increased more moderately at a rate of 5 10 3 mm3 mm 3 decade 1 after 1988 2007 stage t2 compared with the value of 4 10 2 mm3 mm 3 decade 1 before 1988 2007 stage t1 fig 4 furthermore the pre vi association showed a considerable decrease of 16 03 per mm3 mm 3 in stage t2 compared with 3 44 per mm3 mm 3 in stage t1 with soil moisture increasing based on ndvi and the rate of decrease was 5 4 per mm3 mm 3 based on nirv in stage t2 the pre vi association significantly decreased p 0 05 with an increase in soil moisture during t1 and t2 except for that based on nirv in stage t1 fig 4 overall pre vi associations decreased as soil moisture increased whereas tem vi associations did not present significant trend in the past three decades notably the turning point for the relationship between soil moisture and pre vi associations from positive to negative was lower for ndvi than that for nirv it probably resulted that the the divergent trend between pre ndvi and pre nirv were detected during the same period t1 soil moisture records are fundamental for interpreting the long term dynamics of water carbon cycle coupling between the land surface and atmosphere dorigo et al 2017 plant roots and soil texture regulate rainfall infiltration and soil water flux fan et al 2017 and plant transpiration relies on precipitation 70 from the current month and 18 from past precipitation stores in deeper soils miguez macho and fan 2021 which probably resulted in uncertainties regarding the changes in pre vi associations with soil moisture in areas with limited soil water availability dorigo et al 2017 indeed the temporal pattern of pre vi associations agreed with the spatial pattern of soil moisture changes in drylands in the past three decades decreasing as soil moisture increased because the average soil moisture was above the value of the transition point therefore an increase in soil moisture strengthened the pre vi association below the turning point and weakened the pre vi association above this point soil moisture dynamics have traceable effects on the pre vi association in drylands therefore quantifying the temporal spatial patterns of soil moisture variations may reduce the uncertainties surrounding the coupling of precipitation and vegetation growth and the estimation of the carbon cycle with increasing precipitation variability soil moisture has received extensive attention as it is the core of the carbon climate interaction that functions by regulating the biogeochemical cycle and bio geophysical feedback humphrey et al 2021 regional soil moisture data have been acquired to improve the spatio temporal resolution and accuracy of soil moisture data inversions dorigo et al 2017 zhou et al 2021a allowing large scale soil moisture traceability and mechanistic research on climate vegetation feedbacks soil moisture forms the nexus of multiple physical and biological processes martínez fernández et al 2021 and it can constrain plant physiological processes in water limited ecosystems by regulating energy and material exchange via land atmosphere feedbacks berg et al 2016 seneviratne et al 2010 zhou et al 2019 soil water stress influences stomatal functions and plant water use efficiency lavergne et al 2020 whereas vegetation growth regulates water availability mankin et al 2019 soil moisture maintains the homeostasis of the soil plant atmosphere continuum in all climatology zones our findings suggested that soil moisture modulated the pre vi association for the carbon climate feedback in water limited ecosystems water plays a crucial role in the ecosystem structure material function and energy flux exchange in different forms e g rainfall soil moisture and leaf water content insights on the dynamic traceability effects of soil moisture on the pre vi association are essential to understand carbon uptake variability in drylands which is vital for predicting the coupling of climate change and vegetation activity 4 implications and conclusions we found that the dynamic traceable effects of soil moisture were effective as a reference indicator to infer the pre vi association spatially and could be used to interpret the decrease in pre vi association owing to the increasing soil moisture in the past three decades a schematic diagram of the impact of soil moisture on the dryland carbon sink through the traceability effect is presented in fig 5 generally soil moisture is stable in a given region and period and it regulates the association between vegetation dynamics and climate change thus soil moisture variations may signify pre vi association changes thereby affecting vegetation climate coupling zhao et al 2021 the coupling of vegetation growth and precipitation substantially affects dryland carbon sequestration which is determined by the effective pre vi association sufficiently high correlation coefficient our results showed that the degree and area of the pre vi association were greater than those of the tem vi association and the association of δ showed a spatially heterogeneous pattern with a much more positive value in the southern hemisphere than that in the northern hemisphere probably owing to the influence of monsoonal climate regions importantly the pre vi association in the southern hemisphere played a stronger role in the coupling of precipitation and vegetation growth than that in the northern hemisphere under global warming and precipitation oscillation conditions moderate soil moisture enhanced the pre vi association in drylands our results indicated a convex type trend for pre vi but not for tem vi as soil moisture increased the pre vi association strengthened or weakened as soil moisture increased in drylands when the soil moisture was below or above the turning point threshold respectively this supports the spatial heterogeneity of the climate vegetation interaction and improves our understanding of the effect of soil moisture pathways on dryland carbon sequestration the effects of soil moisture include but are not limited to regulating soil water storage capacity and its memory function martínez fernández et al 2021 controlling water availability through evapotranspiration and influencing atmospheric moisture inflow zhou et al 2021b and vegetation dynamics humphrey et al 2021 which ultimately affect the pre vi association the association is closely related to vegetation cover and the topography series index özkan and gökbulak 2017 specifically low soil moisture cannot meet the demand for plant growth owing to strong evaporation weakening the pre vi association high soil moisture generally supports dense vegetation coverage decreasing the evaporation capacity and potentially resulting in runoff and a weak pre vi association moreover moderate soil moisture can maintain reasonable surface atmosphere feedback to counteract the balance of plant growth and energy collocation strengthening the pre vi association this study assessed the long term soil moisture impact on the pre vi and tem vi associations using a 20 year sliding window suggesting that the pre vi association was weakened as soil moisture in global drylands increased from 1982 to 2015 this was because the increased soil moisture exceeded its previous normal multi year average value enhancing the soil moisture atmosphere feedback humphrey et al 2021 and indirectly suppressing anomalies in precipitation and plant growth interactions thereby indicating a shift in the dynamic balance from a steady state to an unsteady state ryo et al 2019 the weakened pre vi association provided an effective profile for predicting how vegetation dynamics are associated with precipitation changes indicating a close relation to potential soil moisture variations it should be noted that the pattern of pre vi associations with yearly soil moisture variations was not absolutely compatible with that in seasonal or monthly soil moisture thus requiring further consideration nevertheless soil moisture regulation is significant for predicting vegetation dynamics under climate change conditions and should receive more attention for ecosystem carbon sink management excessively dry or wet soil moisture conditions can weaken the association between vegetation dynamics and precipitation therefore maintaining a reasonable soil moisture range in an area can improve the estimation accuracy of the effect of natural or human disturbances such as extreme climate events deforestation and afforestation on climate change and vegetation dynamics in drylands to the best of our knowledge this is the first up to date proposal related to how soil moisture modifies the coupling of climate change and vegetation dynamics by regulating their association degree tracing changes in soil moisture can guide the development of climate vegetation association models and is profoundly important for predicting the impact of climate change on future vegetation owing to the convex shape of the response of the pre vi association to soil moisture the direction of vegetation growth is dependent on the average soil moisture and the trend direction when soil moisture is lower than the turning point value pre vi associations increase as soil moisture increases thereby promoting the coupling of precipitation and vegetation growth however when soil moisture is higher than the turning point value precipitation vegetation coupling weakens then precipitation increasing inhibiting vegetation growth with an increase in soil moisture and potentially altering the ecosystem structure over a long time in future studies increasing co2 and n deposition should be considered because they also interaction with climate accompany affect vegetation growth the soil moisture parameter modules should be added to the terrestrial ecosystem model to reduce key uncertainties in terrestrial carbon uptake variability simulations in future projections of global drylands with the development and progress of remote sensing and radar observation technology studies on the qualitative and quantitative effects of soil moisture on the regulation of land atmosphere interactions through direct and indirect effects are increasing such as studies using model simulations and big data calculations xu et al 2021 multi pathway approaches have been used to explore the critical links to reduce the uncertainty in carbon imbalances in the earth system here a framework diagram for the traceable effects of soil moisture on pre vi associations was proposed wherein climate vegetation interaction could be clearly represented by soil moisture or parameters derived from equations related to soil moisture field experiments and a reanalysis of more soil texture related data need to be conducted to quantify these parameters credit authorship contribution statement wei zhao formal analysis validation writing original draft xiubo yu conceptualization project administration funding acquisition chengdong xu methodology software investigation shenggong li writing review editing supervision genan wu writing review editing wenping yuan validation data curation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the international partnership program of chinese academy of sciences grant no 121311kysb20170004 and china postdoctoral science foundation grant no 2020m670439 appendix a supplementary material supplementary material to this article can be found online at https doi org 10 1016 j jhydrol 2022 128645 appendix a supplementary material the following are the supplementary material to this article supplementary data 1 
2683,hydrological extreme events are characterized by several correlated variables for a better associated risk assessment the dependence structure between these variables must be taken into account by considering copulas on the other hand extreme events are generated from different phenomena in such cases the margins and or copula may be affected hence mixture copula should be considered recently there have been an increasing number of studies dealing with the parameter estimation of mixture copula however existing methods have several drawbacks to overcome these drawbacks we propose a new parameter estimation approach for the mixture copula models based on the maximum pseudo likelihood using a metaheuristic algorithm a simulation study is conducted to evaluate the performance of the proposed method and to compare it with those of the widely used existing method results indicate that the proposed method estimates more accurately the parameters even with small sample sizes compared to the existing ones an application to a real data set is also provided and validated with the available data keywords mixture copulas estimation genetic algorithm maximum pseudo likelihood simulations data availability data will be made available on request 1 introduction accurate estimation of quantile associated to extreme hydrologic events is of high importance since these events have significant risks to human beings and environment e g benameur et al 2017 durocher et al 2016 han et al 2014 hydrological frequency analysis hfa has been carried out widely for the prediction and risk assessment associated with hydrometeorological variables e g rao hamed 2000 traditionally hfa is based on homogeneity as one of the fundamental assumptions assuming that all observations are homogenous and thus belong to the same population e g buishand et al 2013 willems 2013 yue et al 1999 however in a changing climate and due to human activities such as river regulations and land use change this assumption is not always fulfilled where the data series are heterogeneous e g das umamahesh 2017 jiang et al 2015 sadegh et al 2015 heterogeneities in hydrological processes may be the result of a number of factors including variations in regional weather patterns natural and anthropogenic modifications of river systems antecedent basin soil moisture e g evin et al 2011 singh et al 2005 furthermore a number of researchers found that hydrometeorological data are often the result of multiple sources or different physical generating mechanisms such as different types of flood producing storms rainfall and snowmelt floods inundations and floodplain flow e g shin et al 2015 smith et al 2011 accordingly analysis under the non fulfilled homogeneity assumption cannot fully characterize the extreme events and may lead to inaccurate risk estimation therefore to take into account the heterogeneity of hydrometeorological variables the use of mixture distributions in hfa is suggested by many authors e g evin et al 2011 shin et al 2016 smith et al 2011 yan et al 2016 all these studies have the common conclusion that mixture models can provide good fit to multi source regimes and are essential for hydrology design under changing climate the aforementioned studies and similar ones even though highlighting the importance of considering the heterogeneity in hfa modeling they focused on the univariate context considering only one single variable of a given hydrological event such as annual flood peak or minimum flow however it has been showed over the last years that extreme hydrologic events can be characterized by the joint behaviour of several dependent variables chebana ouarda 2011 de michele et al 2013 santhosh srinivas 2013 hence univariate hfa does not procure a reliable assessment of the associated risk e g salvadori et al 2016 volpi fiori 2014 therefore the multivariate framework is becoming established in hfa studies in multivariate hfa copulas are a key statistical tool and have been widely used in hydrology e g kao govindaraju 2008 requena et al 2013 zhang singh 2006 to analyze data using a copula its parameters should be estimated for this purpose several methods were proposed in the literature many authors support the use of the maximum pseudo likelihood method mpl because of estimating the copula parameter independently from the marginal distributions furthermore the mpl estimation method is much more generally applicable than the other methods since it does not require the dependence parameter to be real the main advantage of the maximum likelihood method is related to the small variance of parameters that the method provides reason because of being considered the most efficient method for a general review of copula theory and applications the reader can refer to joe 2014 genest and chebana 2017 and singh and zhang 2018 while copulas have been largely applied in hfa their use in the lack of homogeneity is rarely studied especially in hfa studies however at the best of our knowledge the concept of heterogeneous multivariate hydrological series is not yet investigated in hfa in order to take into account the presence of the heterogeneity in the multivariate hfa modeling mixture copula is an appropriate tool they started to receive considerable attention and were carried out in several fields in finance nguyen et al 2016 and hu 2006 examined complex dependencies between stock markets and gold prices using mixture copulas vrac et al 2012 applied mixture copulas for climatic data clustering yu et al 2013 modeled wind speed prediction using a gaussian mixture copula despite all this diversity and progress in the mixture copula literature little attention was devoted to this approach in water resources and hfa proposed mixture copula models in the literature are limited to homogeneous mixture copula i e the two components represent the same copula particularly gaussian copula with different parameter values it is based on the assumption that the different sources of data have an identical dependence structure even though with different dependence strength e g bilgrau et al 2016 yu et al 2013 however hydrometeorological variables are often the results of multiple sources and it might be more rational to assume that individual sources follow different multivariate distribution e g fan et al 2016 khan et al 2019 heterogeneous mixture copulas the two components represent two different copulas are more general and more realistic their application in hfa is promising and may lead to a more accurate estimation of multivariate extreme events note that in the univariate context heterogeneous mixture distributions have been used with great success for the modeling hydrometeorological variables e g calenda et al 2009 hundecha et al 2009 shin et al 2016 vrac naveau 2007 note that in some multivariate hfa studies the terminology of mixture refers to the marginal distributions and not to the multivariate distribution or copula e g li et al 2013 khan et al 2019 and fan et al 2016 in a preliminary step of a multivariate hfa the homogeneity of the data should be tested in cases where the data are homogenous there would be no need to employ models that are more complicated in the literature different tests were proposed for multivariate homogeneity see e g ben nasr and chebana 2019 kojadinovic et al 2016 and quessy et al 2013 if the homogeneity is rejected the flood series can be considered as results of distinct flood generating mechanisms or mixed populations to analyze data using a mixture model its parameters should be estimated the estimation of the parameters can be performed through different methods including the pseudo likelihood method among others the expectation maximization em algorithm has been widely used as optimization algorithm to maximize the log likelihood in estimating parameters of mixture models in both univariate and multivariate contexts e g bilgrau et al 2016 e g ding song 2016 dou et al 2016 vrac et al 2012 despite its popularity the em algorithm suffers from several drawbacks such as divergence and poor accuracy especially when dealing with small or moderate sample sizes e g ding song 2016 dou et al 2016 the conventional methods may require several approximations simplifications or derivative information on functions of the model and they may converge to local optimal solutions thus there is a greater necessity to explore and apply new optimization methods to obtain optimal solutions in the univariate case the use of a meta heuristic algorithms for the maximization of the likelihood function mh is a good alternative to tackle limitations of the em method e g shin et al 2014 song singh 2010 during the past years a variety of mh algorithms has been proposed in the literature such as genetic algorithm ga particle swarm optimizations and harmony searches e g reca et al 2008 among the existing mh algorithms the ga has been widely applied in a variety of engineering applications such as in water resources e g joshi et al 2015 karahan et al 2007 reca et al 2008 the ga method is selected based on its practical advantages indeed ga algorithm requires only objective function values no information about the gradient of the objective function is necessary despite strong evidence concerning the non homogeneity of hydrological data these approaches have not yet been considered in hydrology and specifically in a multivariate context in table 1 the aforementioned estimations methods are summarised including their advantages and drawbacks in the current study for the multivariate setting we propose a class of estimation methods for mixture copulas which combine ga algorithms with maximum pseudo likelihood ga mpl in the univariate context there are few studies considering ga to estimate parameters of flood frequency distributions e g shin et al 2014 shin et al 2015 however despite its popularity ga has not yet been used as an optimization algorithm in estimating parameters in multivariate mixture models and in particular in hfa applications the remainder of this paper is organized as follows section 2 briefly reviews the theoretical background on mixture copulas section 3 deals with parameter estimation methods in mixture copulas then the simulation study is presented in section 4 conclusions are given in section 5 2 copula and mixture of copulas this section provides an overview of the main concepts about copula and mixture models 2 1 copula model copulas are proposed as a flexible tool for constructing multivariate distributions and modeling the dependence structure between correlated variables and widely used in hydrology e g genest chebana 2017 hao singh 2016 the theory of copulas is based on the sklar s theorem sklar 1959 which in the case of a bivariate case can be represented as 1 h x y c f x g y x y r where h x y is the joint cumulative distribution function of the random variables x and y f x and g y are the marginal distribution functions of x and y respectively and the mapping function c 0 1 2 0 1 is the copula function accordingly the density function of the copula c can be defined as 2 c u v 2 c u v u v a large variety of families of copulas are available to model multivariate dependencies overall there are two families of copulas that are widely applied in hfa the extreme value copulas and the archimedean copulas e g chebana ouarda 2009 requena et al 2013 salvadori de michele 2010 indeed these copulas present several desirable properties the popularity of the archimedean family stems from several desirable properties 1 can be easily generated 2 are symmetric and associative and 3 include a large variety of copulas clayton and frank copulas are the most used ones to characterise the dependence structure between hydrological variables meanwhile given their importance in modeling catastrophic events extreme value ev copulas have been extensively used in recent years e g kao govindaraju 2008 salvadori michele 2011 a large number of studies considered the gumbel copula as the ev copula that best represents the relation between hydrological variables e g lee salas 2011 zhang singh 2006 2 2 mixture copula models the modeling of a mixture of distributions has long been restricted upon gaussian distributions and it is only recently that researchers have started to study broader general models e g khan et al 2019 yu et al 2013 among these extensions models featuring copulas are still rare but certainly promising for the sake of completeness since the focus is on the dependence structure the basic definitions and interpretations of the multivariate mixture are briefly described as follows let x y be a bivariate random vector with a sample of size n from a finite mixture model with two components the bivariate cumulative distribution function cdf can be expressed as e g qu lu 2019 vrac et al 2005 3 h x y ω h 1 x y θ 1 1 ω h 2 x y θ 2 ω 0 1 therefore from sklar s theorem in equation 1 there exists a copula c such that 4 h x y ω c 1 f 1 x g 1 y θ 1 1 ω c 2 f 2 x g 2 y θ 2 ω 0 1 where ω is the mixture ratio f k and g k are univariate marginal distributions of the univariate data x and y and θ k is the dependence parameter of the copula corresponding to the mixture component we note that u i r i n 1 u n i f 0 1 and v i s i n 1 u n i f 0 1 for i 1 n such that r i is the rank of x i among x i x n and s i is the rank of y i among y i y n e g nelsen 2013 then when it exists the probability density function pdf h of the mixture model is defined as 5 h x y ω c 1 u 1 v 1 θ 1 f 1 x g 1 y 1 ω c 2 u 1 v 1 θ 2 f 2 x g 2 y where c k is the pdf of the copula c k θ k is the parameter of the copula and f k g k are the marginal pdfs note that all the above densities exist since usually in hfa the variables to study are continuous consequently following thongkairat et al 2019 and vrac et al 2012 the two components mixture copula as well as the corresponding pdf are given by 6 c mix u v ω θ ω c 1 u v θ 1 1 ω c 2 u v θ 2 7 c mix u v ω θ 2 c mix u v ω c 1 u v θ 1 1 ω c 2 u v θ 2 the assumption used in conventional mixture models is that the two copulas c 1 and c 2 belong to the same family e g bilgrau et al 2016 bonanomi et al 2019 yu et al 2013 in this case the model is referred as homogenous mixture however under heterogeneity assumption not only the statistical parameters but also the type of copula could be changing hence single copula is unable to convey the hydrological behaviour comprehensively especially regarding the tail dependence this complex behaviour suggests that the data can be described as a realization of a heterogeneous mixture allowing different shapes for c 1 and c 2 despite previous research efforts regarding multivariate mixture models it is important to mention that heterogeneous multivariate mixture models have been rarely considered e g christensen et al 2019 vrac et al 2012 and not yet been considered in hfa context since the focus is mainly on extreme events the main advantage of using heterogeneous mixture copulas is that we can create a copula with different characteristics especially in the upper and lower the tails for example if the two copulas in the mixture have opposite tail dependence structures such that the clayton and gumbel copulas the resulting mixture copula accounts for both upper and lower tail dependencies supporting this point bonanomi et al 2019 and christensen et al 2019 showed that the mixture copula inherits characteristics from its component copulas particularly the upper and lower tail dependence coefficients can be estimated by e g bonanomi et al 2019 8 λ u mix ω λ u c 1 1 ω λ u c 2 9 λ l mix ω λ l c 1 1 ω λ l c 2 where λ u c k and λ l c k are the upper and lower tail dependence coefficients of the copula c k k 1 2 3 parameter estimation methods the estimation of the parameters of the mixture model that best fits the data can be performed through different methods in the following a brief description of the used methods in the present study is presented 3 1 expectation maximization em algorithm the em algorithm is an iterative method initially conceived to compute the maximum likelihood estimates of parameters of a model when some observations are missing the em algorithm has dominated the literature on maximum likelihood estimation of mixture models in both univariate and multivariate setting e g ding song 2016 dou et al 2016 hu 2006 shin et al 2015 yan et al 2016 throughout this paper since the focus is on the dependence structure the following em algorithm is applied to maximize the pseudo likelihood function instead of the complete likelihood in which the empirical marginal distributions are used instead of the parametric marginal distributions e g genest et al 1995 hence the marginal distributions are estimated as f n x 1 n 1 i 1 n 1 x i x and g n y 1 n 1 i 1 n 1 y i y therefore the corresponding density functions f and g are estimated using kernel density estimators e g adamowski 1985 lall 1995 santhosh srinivas 2013 the em algorithm consists mainly in two steps firstly in the e step the posterior probability of the ith observation belonging to the kth component is estimated by e step 10 π ik l 1 ω k l f k x i g k y i c k u i v i θ k l k 1 2 ω k l f k x i g k y i c k u i v i θ k l i 1 n k 1 2 then in the m steps the parameter estimates are updated using the estimated probabilities obtained in the e step as given by m step 1 set 11 ω k l 1 1 n i 1 n π ik l 1 m step 2 update 12 θ k l 1 arg max θ i 1 n log k 1 2 π ik l 1 c k u i v i θ k l the algorithm iterates between the e step and the m steps until some convergence criterion is satisfied in this paper the algorithm is considered to converge when the change of parameter values is less than a predefined small threshold value 3 2 genetic algorithm maximum pseudo likelihood method although the em algorithm is a popular method to estimate parameters of mixture univariate and multivariate distribution this method has some limitations see table 1 especially it does not converge when dealing with small sized samples e g ding song 2016 liu et al 2019 which is typically encountered in hydrology furthermore the convergence of the em algorithm to the global maximizer depends on the starting point of the algorithm to overcome these drawbacks we propose the mpl method combined with genetic algorithm for the optimization of the parameters noted as ga mpl this choice is motivated by the presence of a significant number of publications that indicated that the ga provides a good performance in the estimation of the parameters of non mixture and mixture univariate distributions e g hassanzadeh et al 2011 the mixed copula is fitted to data by maximizing the logarithmic pseudo likelihood function defined by 13 ll ω θ i 1 n log k 1 2 ω k c k u i v i θ k a key concept in the ga is the chromosome a chromosome contains a group of numbers that completely specifies a candidate during the optimization process ga starts with a random population of trial solutions the fitness value called objective function associated with each chromosome is evaluated then the new population for the next generation is obtained using three genetic operations namely crossover mutation and reproduction in the current study the crossover probability is set to 0 85 implying that 85 of the chromosomes in a generation are allowed to crossover the maximum and minimum mutation probability is set to 0 05 and 0 005 respectively in our case the fitness function to be optimized corresponds to the pseudo likelihood equation 13 individuals with high fitness values give birth to a child that resembles its parents to choose a pair we employ the rank selection meaning that the parents are randomly chosen from individuals those with high fitness values are chosen more often than those with low fitness values then two children are obtained by exchanging the genes of the pairs through the unimodal normal distribution crossover technique different steps of the ga are summarised in fig 1 in order to escape local maxima and for individuals to visit various points in the parameter space a perturbation is applied every generation that is each parameter x is replaced with x 0 05δx where δx is a normally distributed random vector with the zero mean and the variance of which is equal to one and where x ω θ1 or θ 2 natural evolution of the population continues until a predetermined number of generations or the convergence of the fitness function is reached this means that the ll values equation 13 of succeeding iterations ll g 1 a n d ll g satisfied the condition ll g 1 ll g l l g 10 6 in the current study the population size and the maximum generation number in the ga are taken equal to 500 which is considered large enough to obtain robust estimators e g song singh 2010 the proposed ga mpl method has several advantages indeed it can reach the global optimum without requiring initial values for the parameters of the mixture copulas e g song singh 2010 furthermore this approach is efficient in estimating parameters for small sized samples moreover as supported by reca et al 2008 ga algorithm does not require derivatives of the objective function and can hence be applied to solve complex and discontinuous optimization problems therefore it can be appropriate to various kinds of mixture model with different component copulas including situations where derivate of 13 does not have explicit form further the ga mpl method can overcome the problem of trapping at local optima which is common in some classical gradient based methods it is also interesting to mention that due to its considerable flexibility the proposed ga mpl method can be considered also for the estimation of non mixture copula for instance it has been successfully applied in the estimation of the one parameter copula further reddy and singh 2014 showed that the ga mpl is more accurate than classical methods for estimating the parameter of the copula 4 evaluation of estimation methods via simulation the aim of the simulation study is twofold first we evaluate the performance of the proposed estimation method in the hydrological context second we compare the performance of the ga mpl and em methods to this end we consider practical situations commonly encountered in hydrological applications 4 1 simulations design a monte carlo simulation was conducted to evaluate the performance of a parameter estimation method by generating and analysing samples from various models with known parameters generally a flood event is characterized by three main features peak q volume v and duration d it was pointed out in the available literature on flood events that generally q and d are not significantly dependent whereas the most correlated variables are q and v e g aissia et al 2012 fu butler 2014 hence these two variables are considered in this simulation study three different copulas are used to model the dependence structure between q and v namely clayton frank and gumbel copulas from a representative copula commonly used in hfa the mixing ratios ω 0 2 0 3 0 5 are considered for building the mixture copula model it is worth noting that these copulas are considered under different scenarios to generate heterogeneous data hereafter the considered scenarios are a homogenous mixture model clayton clayton cc frank frank f f and gumbel gumbel g g b heterogeneous mixture model clayton frank c f clayton gumbel c g frank gumbel f g since the dependence between two variables is described by both the dependence type copula family and the dependence strength different value of kendall τ are used in this study therefore three values of τ 0 2 0 6 0 8 are considered corresponding to weak moderate and strong dependence respectively these values are selected on the basis of situations commonly encountered in hfa e g requena et al 2013 zhang singh 2007 the true parameter of each component copula is defined to match the corresponding range of dependence and is estimated using kendall s tau inversion method e g nelsen 2013 besides the dependence strength sample size is a relevant factor for the performance of a parameter estimation method hence a sensitivity analysis of the performance of aforementioned methods is performed regarding the sample size since hydrological series are typically characterised by small sized samples the assessment of the behaviour of each method was performed under n 30 50 100 the values of n are selected on the basis of cases frequently occurred in practical situations see for examples series in barth et al 2017 and santhosh and srinivas 2013 for each combination of mixture copula sample size and kendall τ we generate m 1000 synthetic series through monte carlo simulations to generate synthetic data from a given mixture copula we applied the procedure proposed by nelsen 2013 based on the conditional distribution method a diagram of the simulation study is shown in fig 2 in order to evaluate the performance of each estimation method and to compare them the relative error re relative root mean square error rrmse and the relative bias rbias are calculated from the true parameters and the estimated ones as 14 r e j θ j i θ j θ j 100 15 rrms e j 100 1 m i 1 m θ j i θ j θ j 2 16 rbia s j 1 m i 1 m θ j i θ j θ j 100 where m is the number of monte carlo samples θj is the true parameter and θj i is the estimated parameter from sample i of each simulation 4 2 simulations results to compare the performance of the two methods they were applied to synthetic series then different performance criteria were computed the first step of the assessment of the performance of an estimator is the analysis of the effect of the sample size on its behaviour the corresponding results are presented in table 2 from this table one can see that overall rrmse and rbias decrease when the sample size n increases for both em and ga mpl approaches as an example when estimating the weight ratio ω in the case of the frank gumbel mixture copula for the ga mpl estimators the rrmse and rbias decrease from 31 3 to 11 and from 12 9 to 4 7 respectively when the sample size n increases from 30 to 100 and for a dependence level τ 1 τ 2 0 8 0 8 the same results hold true when estimating copulas parameter θ1and θ2 table 2 these findings are consistent with other studies dealing with copula parameter estimation e g genest et al 1995 from table 2 it is also found that em estimators show larger variability in terms of rbias and rrmse especially when n 100 the em method seems to suffer from large biases and large rrmses for smaller samples sizes yielding extremely inaccurate estimates for example when estimating the weight ratio ω of the clayton frank model for n 30 the rrmses are 67 3 and 30 5 for the em and ga mpl methods respectively furthermore the em estimation method does not behave correctly neither for n 30 nor n 50 indeed in these cases the em method leads to a large underestimation negative rbias of the parameters of the mixture model for instance the rbias associated to the em estimates of the copulas parameter θ 1 and θ 2 are equal to 27 4 and 36 9 when n 30 however the ga mpl estimates appear to suffer slightly less under reduced sample size than the em ones indeed for the six considered mixture models the rbias associated to the ga mpl method is smaller by a factor of two or more than the rbias of the em estimator this agrees with similar findings by shin et al 2014 when dealing with univariate mixture models in the same vein kim et al 2013 and arakelian and karlis 2014 provided also simulation results of the performance of the em method in the context of mixture copula models based on their results they reached the same conclusion that the em method is not recommended for situations with small sample sizes n 150 in order to provide a visual support of the behaviour of each estimation methods boxplots of re are presented in fig 3 as expected the minimum sample size required to have a reliable estimation in the case of the ga mpl method is less than that needed for the em method actually the ga mpl method always has the smallest re while the em method always has the largest re regardless of the sample size these findings holds for the estimation of the weight ratio ω as well as the copulas parameter θ 1 and θ 2 in all cases both the median value of em estimators and its variability represented by the height of the box are the largest in conclusion the ga mpl method is more accurate in detecting the characteristics of the mixture model than the em method regardless of sample size and mixture copulas besides the sample size the dependence strength as described by kendall τ is a relevant factor to the performance of an estimation method results of the effect of varying kendall τ are presented on table 3 in order to avoid the interference of the sample size n and the weight ratio ω in the assessment of the performance of different estimation methods theses factors are taken to be equal to n 150 and ω 0 5 respectively it can be seen from table 3 that for a given method the estimation of the weight ratio ω is not affected by the dependence level of each mixture component indeed both estimation method provides similar results regarding the rbias and rrmse when kendall τ increases from 0 2 0 6 to 0 6 0 8 for instance in the case of the ga mpl method the rbias and rrmse are around 1 8 and 7 3 for the frank gumbel mixture regardless of the dependence level as can be seen from table 3 when estimating the weight ratio ω for homogenous mixture copulas there is a noteworthy difference in rbias criteria between the two estimation method regardless the dependence strength as described by kendall τ furthermore this difference increases to about 65 for estimating the heterogeneous mixture copulas moreover the same trend is observed concerning the difference in rrmse once again such a difference becomes slightly larger for heterogeneous mixture copulas accordingly the ga mpl method consistently outperforms the em method in estimating the weight ratio these results agree with the findings of other studies dealing with univariate mixture models which found a significant improvement in the performance of the ga mpl method as compared with the em algorithm e g shin et al 2014 results from table 3 highlight also the effect of the dependence level on the estimation of the copulas parameter overall the performance of the two approaches regarding the estimation of copulas parameter θ 1 and θ 2 is better when the dependence level is stronger for instance the rbias and rrmse are larger for small dependence level as expected for example in the case of the clayton gumbel mixture the absolute value of the rbias of the ga mpl estimator decreases from 7 2 to 1 9 for the first parameter θ1 and from 3 4 to 1 8 for the second parameter θ2 when the dependence level increases from τ 1 τ 2 0 2 0 6 to τ 1 τ 2 0 6 0 8 this finding is also valid for the rrmse where a smaller value of dependence level is associated to larger rrmse these results are consistent with those of other studies dealing with estimation of non mixture copula parameters such as genest et al 1995 and brahimi and necir 2012 who showed that an estimation method has a better performance for stronger dependence level additionally when estimating θ 1 for homogenous mixture copulas the difference in rbias between ga mpl and em method is about 25 for τ 1 τ 2 0 2 0 6 again this difference increases as the dependence strength increases to reach 50 when τ 1 τ 2 0 6 0 8 these results support the robustness of the ga mpl when estimating copulas parameter its performance is not highly affected even for low dependently data this finding is in agreement with the findings in kim et al 2007 which showed that in the case of non mixture copula the mpl method is more suitable for the estimation of the copula parameter with low dependence strength moreover the relative rmse seem to be considerably higher for the em method when estimating copulas parameter meanwhile previous discussion about comparison of em and ga mpl results regarding the rbias also holds for the rrmse these results are likely to be related to the fact that the convergence of the em algorithm to the global maximizer depends on the starting point of the algorithm this might be also explained by the fact that the two component copulas in the mixture model get further away from each other when the kendall τ increase since both em and ga mpl estimators improve with increasing dependence strength and in order to identify the best recommended one for hydrological applications a deeper analysis is carried out to compare the two approaches for this purpose in order to show complete information and to present an overview of the results boxplots of the effect of kendall τ on the relative errors are provided in fig 4 several conclusions can be drawn from these boxplots from fig 4a it is found that the estimate of ω is not affected by the dependence level in fact for the ga mpl method the median value line inside the box is almost the same for the three dependence level combination the same holds for em method regardless the dependence level it is also found that in comparison to the em method ga mpl method has an overall better behavior indeed em estimators show higher median value this highlights the low ability of the em method to estimate correctly the weight ratio ω in certain circumstances note that although the median is the value considered to assess the performance of each method the variability in the results i e the height of the boxes should also be considered in the decision process as it refers to the uncertainty in the results given by the estimation method as a result of taking into account all the information provided by these criteria the ga mpl method was identified as the best in terms of estimating the weight ratio as both the median value and its variability are the smallest several conclusions can be drawn from these boxplots from fig 4a it is found that the estimate of ω is not affected by the dependence level in fact for the ga mpl method the median value line inside the box is almost the same for the three dependence level combination the same holds for em method regardless the dependence level it is also found that in comparison to the em method ga mpl method has an overall better behavior indeed em estimators show higher median value this highlights the low ability of the em method to estimate correctly the weight ratio ω in certain circumstances note that although the median is the value considered to assess the performance of each method the variability in the results i e the height of the boxes should also be considered in the decision process as it refers to the uncertainty in the results given by the estimation method as a result of taking into account all the information provided by these criteria the ga mpl method was identified as the best in terms of estimating the weight ratio as both the median value and its variability are the smallest we can see from fig 4b and 4c that as expected as the dependence gets stronger the re decrease for the two estimation methods this observed finding mirrors those of the previous studies that have examined different estimation method for non mixture copulas e g brahimi necir 2012 capéraà et al 1997 however although the performance of parameter estimates from the two methods show similar patterns the ga mpl method leads to better results when estimating copulas parameter indeed regardless the dependence level the reduction in the re of the ga mpl method is remarkable the re from the ga mpl method is about 20 smaller than that from the em method beyond confirming the obvious dominance of the ga mpl estimator and the poor performance of the em estimator the results in fig 4b and 4c indicate that the em method lead to larger uncertainty especially for low dependent data τ 0 2 the mixing proportion ω is of primary interest results regarding the effect of the weight ratio ω on the performance of each estimation method are displayed in table 4 to discard the effect of the sample size and the dependence level we analyse the effect of ω when n 150 and τ 1 τ 2 0 6 0 8 as it can be seen from table 4 the performance trends for the ga mpl and em methods are similar in the sense that rbiais and rrmse of the two methods get better as ω increases from 0 2 to 0 5 for example when estimating the first copula parameter θ 1 in the frank gumbel mixture copula using ga mpl method the rbias decreases from 13 to 3 2 when ω increases from 0 2 to 0 5 this result is likely to be related to the fact that when ω is small the mixture model contains increasing information about one component but decreasing information about the other component indeed a low mixing probability implies that the sampled data from the mixed model are close to the one component model these results are in agreement with fu et al 2019 s findings which showed that in the case of multivariate mixture distribution an estimation method have a better performance when ω lies in the middle than on the boundaries of its space however it is also worth noting that the two methods exhibit noteworthy differences especially under small ω indeed in this case the ga mpl method leads to the best results with the minimum values of absolute rbias and rrmse for example for the clayton frank mixture model the mean absolute rbias for the ga mpl and em methods are 19 1 and 11 7 respectively when estimating θ 1 for ω 0 2 these results imply that the ga mpl estimates are closer to the true values of the parameters than those of the em method accordingly the ga mpl method accurately estimates the parameters for low mixing probabilities ω and outperforms the em method for both homogenous and heterogeneous mixture copulas moreover according to fig 5 results reveal that ga mpl method yields more accurate estimates of the copulas parameter θ 1 and θ 2 indeed in all cases ga mpl method is characterised by smaller variability compared to em method 5 application to real world hydrological data after evaluating and comparing the proposed estimation methods on simulated data in this section we apply these methods on real world hydrological data the purpose of these applications is to assess the appropriateness of the proposed methods for practical use the most significant characteristics of a flood event are the flood peak q flood volume v and flood duration d as mentioned in the introduction the most correlated variables are q and v to scrutinize the impact of length of data on the performance of the estimation methods we use two flood peak q m3 s and volume v m3 data series the first data series correspond to the romaine station with natural flow regimes located in the cote nord region of the province of quebec canada n 55 it is considered previously for change point studies by chebana et al 2016 the second data series correspond to the ankang hydrological station at the upper hanjiang river china n 62 the same series is used on the paper of xiong et al 2015 who demonstrated the existence of a change on the copula parameter for each station flood characteristics q and v are extracted from daily streamflow series aissia et al 2012 since the focus of the study is on the dependence structure the choice of marginal distributions is performed but not presented in detail the gumbel marginal distribution often represents well extreme events such as flood peak and volume e g yue et al 1999 it is also shown in the present study that the gumbel mixture model can be selected as a marginal distribution for both peak and volume for each univariate series the five parameters of the gumbel mixture model were estimated using maximum likelihood method for the parameter of each individual gumbel distribution results are presented in table 5 the main advantage provided by the copula approach is the selection of an appropriate dependence structure independently of the choice of the marginals the parameters of four mixture copulas models as used in the simulation study are estimated for to data using em mpl and ga mpl methods then their fitting was tested using the cramer von mises test based on the comparison between the empirical and theoretical copula genest et al 2009 in order to select the best fitting copula among those accepted by different gof tests the model selection criterion aic is considered sadegh et al 2017 results are summarized in table 6 overall mixture copulas models using the ga mpl approach perform significantly better than the corresponding models using the em mpl approach in general we do not observe a big difference in the performances for the ankang station in this case according to the em mpl and ga mpl methods the best fitting model is the mixture of clayton and gumbel copulas however for smaller sample size which is the case of for the romaine station all mixture copulas models fitted using the em mpl approach are rejected at the significance level 5 this might be explained by the inconsistency of the em mpl method for small sized sample the overall best model is obtained with ga mpl method this highlights the advantage of using the ga mpl method for fitting mixture copulas when dealing with small sample size in the following only analysis regarding ankang data are presented and discussed since for the romaine data all fitted copula with the em mpl method are rejected as presented in fig 6 the bivariate quantile is a curve hence the usual performance evaluation criteria do not apply and should be adapted since the focus is on the evaluation of quantiles the event x x y y is of special interest to evaluate the performance of the two estimation methods regarding the quantile we used the upper and lower bound of the quantile curve developed by volpi and fiori 2012 results of the empirical and theoretical bounds are presented in table 7 it can be seen from table 7 that the estimated events of the ga mpl fitted model and that of the empirical model are almost similar the fitted em mpl model results have smaller flood volume and smaller flood peak than the empirical model it is therefore concluded that the model fitted using ga mpl method is suitable for representing the joint distribution of flood peaks and volumes however the frank gumbel copula fitted using the em mpl method underestimates the risk associated to the joint return periods t 100 hence this analysis supports the fact that model misspecification in joint extreme events modelling can lead to an underestimation of the risk 6 conclusion the main objective of the current study is to investigate the applicability of mixture copulas to model extreme events of hydrometeorological variables once the copula model and the associated marginal distributions are selected parameter estimation is the key step a novel contribution in mixture copula and in flood frequency analysis has been provided by proposing a new parameter estimation method this proposed approach denoted as ga mpl is based on the idea of estimating parameters by maximizing the log pseudo likelihood function using a meta heuristic algorithm a simulation study is carried out in order to evaluate the proposed method and to compare the performances with the widely used em method the obtained results show that the proposed ga mpl method is more appropriate than the em method in terms of rrmse and rbias especially for small sample sizes moreover the effectiveness of the ga mpl method in dealing with weakly dependent data makes it particularly suitable for some hydrological applications the applications show in a practical and complimentary way to the simulation results the advantage of using the new proposed method especially when dealing with small sample size in the current study because of the associated advantages the genetic algorithm is used for the optimization of the mpl future investigations will deal with other metaheuristic algorithms such the particle swarm optimization or by using a hybridization between two or several meta heuristic algorithms in addition the extension of our approach to mixtures with more than two components is valuable and interesting for further research efforts credit authorship contribution statement i ben nasr conceptualization methodology writing review editing f chebana conceptualization methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements none 
2683,hydrological extreme events are characterized by several correlated variables for a better associated risk assessment the dependence structure between these variables must be taken into account by considering copulas on the other hand extreme events are generated from different phenomena in such cases the margins and or copula may be affected hence mixture copula should be considered recently there have been an increasing number of studies dealing with the parameter estimation of mixture copula however existing methods have several drawbacks to overcome these drawbacks we propose a new parameter estimation approach for the mixture copula models based on the maximum pseudo likelihood using a metaheuristic algorithm a simulation study is conducted to evaluate the performance of the proposed method and to compare it with those of the widely used existing method results indicate that the proposed method estimates more accurately the parameters even with small sample sizes compared to the existing ones an application to a real data set is also provided and validated with the available data keywords mixture copulas estimation genetic algorithm maximum pseudo likelihood simulations data availability data will be made available on request 1 introduction accurate estimation of quantile associated to extreme hydrologic events is of high importance since these events have significant risks to human beings and environment e g benameur et al 2017 durocher et al 2016 han et al 2014 hydrological frequency analysis hfa has been carried out widely for the prediction and risk assessment associated with hydrometeorological variables e g rao hamed 2000 traditionally hfa is based on homogeneity as one of the fundamental assumptions assuming that all observations are homogenous and thus belong to the same population e g buishand et al 2013 willems 2013 yue et al 1999 however in a changing climate and due to human activities such as river regulations and land use change this assumption is not always fulfilled where the data series are heterogeneous e g das umamahesh 2017 jiang et al 2015 sadegh et al 2015 heterogeneities in hydrological processes may be the result of a number of factors including variations in regional weather patterns natural and anthropogenic modifications of river systems antecedent basin soil moisture e g evin et al 2011 singh et al 2005 furthermore a number of researchers found that hydrometeorological data are often the result of multiple sources or different physical generating mechanisms such as different types of flood producing storms rainfall and snowmelt floods inundations and floodplain flow e g shin et al 2015 smith et al 2011 accordingly analysis under the non fulfilled homogeneity assumption cannot fully characterize the extreme events and may lead to inaccurate risk estimation therefore to take into account the heterogeneity of hydrometeorological variables the use of mixture distributions in hfa is suggested by many authors e g evin et al 2011 shin et al 2016 smith et al 2011 yan et al 2016 all these studies have the common conclusion that mixture models can provide good fit to multi source regimes and are essential for hydrology design under changing climate the aforementioned studies and similar ones even though highlighting the importance of considering the heterogeneity in hfa modeling they focused on the univariate context considering only one single variable of a given hydrological event such as annual flood peak or minimum flow however it has been showed over the last years that extreme hydrologic events can be characterized by the joint behaviour of several dependent variables chebana ouarda 2011 de michele et al 2013 santhosh srinivas 2013 hence univariate hfa does not procure a reliable assessment of the associated risk e g salvadori et al 2016 volpi fiori 2014 therefore the multivariate framework is becoming established in hfa studies in multivariate hfa copulas are a key statistical tool and have been widely used in hydrology e g kao govindaraju 2008 requena et al 2013 zhang singh 2006 to analyze data using a copula its parameters should be estimated for this purpose several methods were proposed in the literature many authors support the use of the maximum pseudo likelihood method mpl because of estimating the copula parameter independently from the marginal distributions furthermore the mpl estimation method is much more generally applicable than the other methods since it does not require the dependence parameter to be real the main advantage of the maximum likelihood method is related to the small variance of parameters that the method provides reason because of being considered the most efficient method for a general review of copula theory and applications the reader can refer to joe 2014 genest and chebana 2017 and singh and zhang 2018 while copulas have been largely applied in hfa their use in the lack of homogeneity is rarely studied especially in hfa studies however at the best of our knowledge the concept of heterogeneous multivariate hydrological series is not yet investigated in hfa in order to take into account the presence of the heterogeneity in the multivariate hfa modeling mixture copula is an appropriate tool they started to receive considerable attention and were carried out in several fields in finance nguyen et al 2016 and hu 2006 examined complex dependencies between stock markets and gold prices using mixture copulas vrac et al 2012 applied mixture copulas for climatic data clustering yu et al 2013 modeled wind speed prediction using a gaussian mixture copula despite all this diversity and progress in the mixture copula literature little attention was devoted to this approach in water resources and hfa proposed mixture copula models in the literature are limited to homogeneous mixture copula i e the two components represent the same copula particularly gaussian copula with different parameter values it is based on the assumption that the different sources of data have an identical dependence structure even though with different dependence strength e g bilgrau et al 2016 yu et al 2013 however hydrometeorological variables are often the results of multiple sources and it might be more rational to assume that individual sources follow different multivariate distribution e g fan et al 2016 khan et al 2019 heterogeneous mixture copulas the two components represent two different copulas are more general and more realistic their application in hfa is promising and may lead to a more accurate estimation of multivariate extreme events note that in the univariate context heterogeneous mixture distributions have been used with great success for the modeling hydrometeorological variables e g calenda et al 2009 hundecha et al 2009 shin et al 2016 vrac naveau 2007 note that in some multivariate hfa studies the terminology of mixture refers to the marginal distributions and not to the multivariate distribution or copula e g li et al 2013 khan et al 2019 and fan et al 2016 in a preliminary step of a multivariate hfa the homogeneity of the data should be tested in cases where the data are homogenous there would be no need to employ models that are more complicated in the literature different tests were proposed for multivariate homogeneity see e g ben nasr and chebana 2019 kojadinovic et al 2016 and quessy et al 2013 if the homogeneity is rejected the flood series can be considered as results of distinct flood generating mechanisms or mixed populations to analyze data using a mixture model its parameters should be estimated the estimation of the parameters can be performed through different methods including the pseudo likelihood method among others the expectation maximization em algorithm has been widely used as optimization algorithm to maximize the log likelihood in estimating parameters of mixture models in both univariate and multivariate contexts e g bilgrau et al 2016 e g ding song 2016 dou et al 2016 vrac et al 2012 despite its popularity the em algorithm suffers from several drawbacks such as divergence and poor accuracy especially when dealing with small or moderate sample sizes e g ding song 2016 dou et al 2016 the conventional methods may require several approximations simplifications or derivative information on functions of the model and they may converge to local optimal solutions thus there is a greater necessity to explore and apply new optimization methods to obtain optimal solutions in the univariate case the use of a meta heuristic algorithms for the maximization of the likelihood function mh is a good alternative to tackle limitations of the em method e g shin et al 2014 song singh 2010 during the past years a variety of mh algorithms has been proposed in the literature such as genetic algorithm ga particle swarm optimizations and harmony searches e g reca et al 2008 among the existing mh algorithms the ga has been widely applied in a variety of engineering applications such as in water resources e g joshi et al 2015 karahan et al 2007 reca et al 2008 the ga method is selected based on its practical advantages indeed ga algorithm requires only objective function values no information about the gradient of the objective function is necessary despite strong evidence concerning the non homogeneity of hydrological data these approaches have not yet been considered in hydrology and specifically in a multivariate context in table 1 the aforementioned estimations methods are summarised including their advantages and drawbacks in the current study for the multivariate setting we propose a class of estimation methods for mixture copulas which combine ga algorithms with maximum pseudo likelihood ga mpl in the univariate context there are few studies considering ga to estimate parameters of flood frequency distributions e g shin et al 2014 shin et al 2015 however despite its popularity ga has not yet been used as an optimization algorithm in estimating parameters in multivariate mixture models and in particular in hfa applications the remainder of this paper is organized as follows section 2 briefly reviews the theoretical background on mixture copulas section 3 deals with parameter estimation methods in mixture copulas then the simulation study is presented in section 4 conclusions are given in section 5 2 copula and mixture of copulas this section provides an overview of the main concepts about copula and mixture models 2 1 copula model copulas are proposed as a flexible tool for constructing multivariate distributions and modeling the dependence structure between correlated variables and widely used in hydrology e g genest chebana 2017 hao singh 2016 the theory of copulas is based on the sklar s theorem sklar 1959 which in the case of a bivariate case can be represented as 1 h x y c f x g y x y r where h x y is the joint cumulative distribution function of the random variables x and y f x and g y are the marginal distribution functions of x and y respectively and the mapping function c 0 1 2 0 1 is the copula function accordingly the density function of the copula c can be defined as 2 c u v 2 c u v u v a large variety of families of copulas are available to model multivariate dependencies overall there are two families of copulas that are widely applied in hfa the extreme value copulas and the archimedean copulas e g chebana ouarda 2009 requena et al 2013 salvadori de michele 2010 indeed these copulas present several desirable properties the popularity of the archimedean family stems from several desirable properties 1 can be easily generated 2 are symmetric and associative and 3 include a large variety of copulas clayton and frank copulas are the most used ones to characterise the dependence structure between hydrological variables meanwhile given their importance in modeling catastrophic events extreme value ev copulas have been extensively used in recent years e g kao govindaraju 2008 salvadori michele 2011 a large number of studies considered the gumbel copula as the ev copula that best represents the relation between hydrological variables e g lee salas 2011 zhang singh 2006 2 2 mixture copula models the modeling of a mixture of distributions has long been restricted upon gaussian distributions and it is only recently that researchers have started to study broader general models e g khan et al 2019 yu et al 2013 among these extensions models featuring copulas are still rare but certainly promising for the sake of completeness since the focus is on the dependence structure the basic definitions and interpretations of the multivariate mixture are briefly described as follows let x y be a bivariate random vector with a sample of size n from a finite mixture model with two components the bivariate cumulative distribution function cdf can be expressed as e g qu lu 2019 vrac et al 2005 3 h x y ω h 1 x y θ 1 1 ω h 2 x y θ 2 ω 0 1 therefore from sklar s theorem in equation 1 there exists a copula c such that 4 h x y ω c 1 f 1 x g 1 y θ 1 1 ω c 2 f 2 x g 2 y θ 2 ω 0 1 where ω is the mixture ratio f k and g k are univariate marginal distributions of the univariate data x and y and θ k is the dependence parameter of the copula corresponding to the mixture component we note that u i r i n 1 u n i f 0 1 and v i s i n 1 u n i f 0 1 for i 1 n such that r i is the rank of x i among x i x n and s i is the rank of y i among y i y n e g nelsen 2013 then when it exists the probability density function pdf h of the mixture model is defined as 5 h x y ω c 1 u 1 v 1 θ 1 f 1 x g 1 y 1 ω c 2 u 1 v 1 θ 2 f 2 x g 2 y where c k is the pdf of the copula c k θ k is the parameter of the copula and f k g k are the marginal pdfs note that all the above densities exist since usually in hfa the variables to study are continuous consequently following thongkairat et al 2019 and vrac et al 2012 the two components mixture copula as well as the corresponding pdf are given by 6 c mix u v ω θ ω c 1 u v θ 1 1 ω c 2 u v θ 2 7 c mix u v ω θ 2 c mix u v ω c 1 u v θ 1 1 ω c 2 u v θ 2 the assumption used in conventional mixture models is that the two copulas c 1 and c 2 belong to the same family e g bilgrau et al 2016 bonanomi et al 2019 yu et al 2013 in this case the model is referred as homogenous mixture however under heterogeneity assumption not only the statistical parameters but also the type of copula could be changing hence single copula is unable to convey the hydrological behaviour comprehensively especially regarding the tail dependence this complex behaviour suggests that the data can be described as a realization of a heterogeneous mixture allowing different shapes for c 1 and c 2 despite previous research efforts regarding multivariate mixture models it is important to mention that heterogeneous multivariate mixture models have been rarely considered e g christensen et al 2019 vrac et al 2012 and not yet been considered in hfa context since the focus is mainly on extreme events the main advantage of using heterogeneous mixture copulas is that we can create a copula with different characteristics especially in the upper and lower the tails for example if the two copulas in the mixture have opposite tail dependence structures such that the clayton and gumbel copulas the resulting mixture copula accounts for both upper and lower tail dependencies supporting this point bonanomi et al 2019 and christensen et al 2019 showed that the mixture copula inherits characteristics from its component copulas particularly the upper and lower tail dependence coefficients can be estimated by e g bonanomi et al 2019 8 λ u mix ω λ u c 1 1 ω λ u c 2 9 λ l mix ω λ l c 1 1 ω λ l c 2 where λ u c k and λ l c k are the upper and lower tail dependence coefficients of the copula c k k 1 2 3 parameter estimation methods the estimation of the parameters of the mixture model that best fits the data can be performed through different methods in the following a brief description of the used methods in the present study is presented 3 1 expectation maximization em algorithm the em algorithm is an iterative method initially conceived to compute the maximum likelihood estimates of parameters of a model when some observations are missing the em algorithm has dominated the literature on maximum likelihood estimation of mixture models in both univariate and multivariate setting e g ding song 2016 dou et al 2016 hu 2006 shin et al 2015 yan et al 2016 throughout this paper since the focus is on the dependence structure the following em algorithm is applied to maximize the pseudo likelihood function instead of the complete likelihood in which the empirical marginal distributions are used instead of the parametric marginal distributions e g genest et al 1995 hence the marginal distributions are estimated as f n x 1 n 1 i 1 n 1 x i x and g n y 1 n 1 i 1 n 1 y i y therefore the corresponding density functions f and g are estimated using kernel density estimators e g adamowski 1985 lall 1995 santhosh srinivas 2013 the em algorithm consists mainly in two steps firstly in the e step the posterior probability of the ith observation belonging to the kth component is estimated by e step 10 π ik l 1 ω k l f k x i g k y i c k u i v i θ k l k 1 2 ω k l f k x i g k y i c k u i v i θ k l i 1 n k 1 2 then in the m steps the parameter estimates are updated using the estimated probabilities obtained in the e step as given by m step 1 set 11 ω k l 1 1 n i 1 n π ik l 1 m step 2 update 12 θ k l 1 arg max θ i 1 n log k 1 2 π ik l 1 c k u i v i θ k l the algorithm iterates between the e step and the m steps until some convergence criterion is satisfied in this paper the algorithm is considered to converge when the change of parameter values is less than a predefined small threshold value 3 2 genetic algorithm maximum pseudo likelihood method although the em algorithm is a popular method to estimate parameters of mixture univariate and multivariate distribution this method has some limitations see table 1 especially it does not converge when dealing with small sized samples e g ding song 2016 liu et al 2019 which is typically encountered in hydrology furthermore the convergence of the em algorithm to the global maximizer depends on the starting point of the algorithm to overcome these drawbacks we propose the mpl method combined with genetic algorithm for the optimization of the parameters noted as ga mpl this choice is motivated by the presence of a significant number of publications that indicated that the ga provides a good performance in the estimation of the parameters of non mixture and mixture univariate distributions e g hassanzadeh et al 2011 the mixed copula is fitted to data by maximizing the logarithmic pseudo likelihood function defined by 13 ll ω θ i 1 n log k 1 2 ω k c k u i v i θ k a key concept in the ga is the chromosome a chromosome contains a group of numbers that completely specifies a candidate during the optimization process ga starts with a random population of trial solutions the fitness value called objective function associated with each chromosome is evaluated then the new population for the next generation is obtained using three genetic operations namely crossover mutation and reproduction in the current study the crossover probability is set to 0 85 implying that 85 of the chromosomes in a generation are allowed to crossover the maximum and minimum mutation probability is set to 0 05 and 0 005 respectively in our case the fitness function to be optimized corresponds to the pseudo likelihood equation 13 individuals with high fitness values give birth to a child that resembles its parents to choose a pair we employ the rank selection meaning that the parents are randomly chosen from individuals those with high fitness values are chosen more often than those with low fitness values then two children are obtained by exchanging the genes of the pairs through the unimodal normal distribution crossover technique different steps of the ga are summarised in fig 1 in order to escape local maxima and for individuals to visit various points in the parameter space a perturbation is applied every generation that is each parameter x is replaced with x 0 05δx where δx is a normally distributed random vector with the zero mean and the variance of which is equal to one and where x ω θ1 or θ 2 natural evolution of the population continues until a predetermined number of generations or the convergence of the fitness function is reached this means that the ll values equation 13 of succeeding iterations ll g 1 a n d ll g satisfied the condition ll g 1 ll g l l g 10 6 in the current study the population size and the maximum generation number in the ga are taken equal to 500 which is considered large enough to obtain robust estimators e g song singh 2010 the proposed ga mpl method has several advantages indeed it can reach the global optimum without requiring initial values for the parameters of the mixture copulas e g song singh 2010 furthermore this approach is efficient in estimating parameters for small sized samples moreover as supported by reca et al 2008 ga algorithm does not require derivatives of the objective function and can hence be applied to solve complex and discontinuous optimization problems therefore it can be appropriate to various kinds of mixture model with different component copulas including situations where derivate of 13 does not have explicit form further the ga mpl method can overcome the problem of trapping at local optima which is common in some classical gradient based methods it is also interesting to mention that due to its considerable flexibility the proposed ga mpl method can be considered also for the estimation of non mixture copula for instance it has been successfully applied in the estimation of the one parameter copula further reddy and singh 2014 showed that the ga mpl is more accurate than classical methods for estimating the parameter of the copula 4 evaluation of estimation methods via simulation the aim of the simulation study is twofold first we evaluate the performance of the proposed estimation method in the hydrological context second we compare the performance of the ga mpl and em methods to this end we consider practical situations commonly encountered in hydrological applications 4 1 simulations design a monte carlo simulation was conducted to evaluate the performance of a parameter estimation method by generating and analysing samples from various models with known parameters generally a flood event is characterized by three main features peak q volume v and duration d it was pointed out in the available literature on flood events that generally q and d are not significantly dependent whereas the most correlated variables are q and v e g aissia et al 2012 fu butler 2014 hence these two variables are considered in this simulation study three different copulas are used to model the dependence structure between q and v namely clayton frank and gumbel copulas from a representative copula commonly used in hfa the mixing ratios ω 0 2 0 3 0 5 are considered for building the mixture copula model it is worth noting that these copulas are considered under different scenarios to generate heterogeneous data hereafter the considered scenarios are a homogenous mixture model clayton clayton cc frank frank f f and gumbel gumbel g g b heterogeneous mixture model clayton frank c f clayton gumbel c g frank gumbel f g since the dependence between two variables is described by both the dependence type copula family and the dependence strength different value of kendall τ are used in this study therefore three values of τ 0 2 0 6 0 8 are considered corresponding to weak moderate and strong dependence respectively these values are selected on the basis of situations commonly encountered in hfa e g requena et al 2013 zhang singh 2007 the true parameter of each component copula is defined to match the corresponding range of dependence and is estimated using kendall s tau inversion method e g nelsen 2013 besides the dependence strength sample size is a relevant factor for the performance of a parameter estimation method hence a sensitivity analysis of the performance of aforementioned methods is performed regarding the sample size since hydrological series are typically characterised by small sized samples the assessment of the behaviour of each method was performed under n 30 50 100 the values of n are selected on the basis of cases frequently occurred in practical situations see for examples series in barth et al 2017 and santhosh and srinivas 2013 for each combination of mixture copula sample size and kendall τ we generate m 1000 synthetic series through monte carlo simulations to generate synthetic data from a given mixture copula we applied the procedure proposed by nelsen 2013 based on the conditional distribution method a diagram of the simulation study is shown in fig 2 in order to evaluate the performance of each estimation method and to compare them the relative error re relative root mean square error rrmse and the relative bias rbias are calculated from the true parameters and the estimated ones as 14 r e j θ j i θ j θ j 100 15 rrms e j 100 1 m i 1 m θ j i θ j θ j 2 16 rbia s j 1 m i 1 m θ j i θ j θ j 100 where m is the number of monte carlo samples θj is the true parameter and θj i is the estimated parameter from sample i of each simulation 4 2 simulations results to compare the performance of the two methods they were applied to synthetic series then different performance criteria were computed the first step of the assessment of the performance of an estimator is the analysis of the effect of the sample size on its behaviour the corresponding results are presented in table 2 from this table one can see that overall rrmse and rbias decrease when the sample size n increases for both em and ga mpl approaches as an example when estimating the weight ratio ω in the case of the frank gumbel mixture copula for the ga mpl estimators the rrmse and rbias decrease from 31 3 to 11 and from 12 9 to 4 7 respectively when the sample size n increases from 30 to 100 and for a dependence level τ 1 τ 2 0 8 0 8 the same results hold true when estimating copulas parameter θ1and θ2 table 2 these findings are consistent with other studies dealing with copula parameter estimation e g genest et al 1995 from table 2 it is also found that em estimators show larger variability in terms of rbias and rrmse especially when n 100 the em method seems to suffer from large biases and large rrmses for smaller samples sizes yielding extremely inaccurate estimates for example when estimating the weight ratio ω of the clayton frank model for n 30 the rrmses are 67 3 and 30 5 for the em and ga mpl methods respectively furthermore the em estimation method does not behave correctly neither for n 30 nor n 50 indeed in these cases the em method leads to a large underestimation negative rbias of the parameters of the mixture model for instance the rbias associated to the em estimates of the copulas parameter θ 1 and θ 2 are equal to 27 4 and 36 9 when n 30 however the ga mpl estimates appear to suffer slightly less under reduced sample size than the em ones indeed for the six considered mixture models the rbias associated to the ga mpl method is smaller by a factor of two or more than the rbias of the em estimator this agrees with similar findings by shin et al 2014 when dealing with univariate mixture models in the same vein kim et al 2013 and arakelian and karlis 2014 provided also simulation results of the performance of the em method in the context of mixture copula models based on their results they reached the same conclusion that the em method is not recommended for situations with small sample sizes n 150 in order to provide a visual support of the behaviour of each estimation methods boxplots of re are presented in fig 3 as expected the minimum sample size required to have a reliable estimation in the case of the ga mpl method is less than that needed for the em method actually the ga mpl method always has the smallest re while the em method always has the largest re regardless of the sample size these findings holds for the estimation of the weight ratio ω as well as the copulas parameter θ 1 and θ 2 in all cases both the median value of em estimators and its variability represented by the height of the box are the largest in conclusion the ga mpl method is more accurate in detecting the characteristics of the mixture model than the em method regardless of sample size and mixture copulas besides the sample size the dependence strength as described by kendall τ is a relevant factor to the performance of an estimation method results of the effect of varying kendall τ are presented on table 3 in order to avoid the interference of the sample size n and the weight ratio ω in the assessment of the performance of different estimation methods theses factors are taken to be equal to n 150 and ω 0 5 respectively it can be seen from table 3 that for a given method the estimation of the weight ratio ω is not affected by the dependence level of each mixture component indeed both estimation method provides similar results regarding the rbias and rrmse when kendall τ increases from 0 2 0 6 to 0 6 0 8 for instance in the case of the ga mpl method the rbias and rrmse are around 1 8 and 7 3 for the frank gumbel mixture regardless of the dependence level as can be seen from table 3 when estimating the weight ratio ω for homogenous mixture copulas there is a noteworthy difference in rbias criteria between the two estimation method regardless the dependence strength as described by kendall τ furthermore this difference increases to about 65 for estimating the heterogeneous mixture copulas moreover the same trend is observed concerning the difference in rrmse once again such a difference becomes slightly larger for heterogeneous mixture copulas accordingly the ga mpl method consistently outperforms the em method in estimating the weight ratio these results agree with the findings of other studies dealing with univariate mixture models which found a significant improvement in the performance of the ga mpl method as compared with the em algorithm e g shin et al 2014 results from table 3 highlight also the effect of the dependence level on the estimation of the copulas parameter overall the performance of the two approaches regarding the estimation of copulas parameter θ 1 and θ 2 is better when the dependence level is stronger for instance the rbias and rrmse are larger for small dependence level as expected for example in the case of the clayton gumbel mixture the absolute value of the rbias of the ga mpl estimator decreases from 7 2 to 1 9 for the first parameter θ1 and from 3 4 to 1 8 for the second parameter θ2 when the dependence level increases from τ 1 τ 2 0 2 0 6 to τ 1 τ 2 0 6 0 8 this finding is also valid for the rrmse where a smaller value of dependence level is associated to larger rrmse these results are consistent with those of other studies dealing with estimation of non mixture copula parameters such as genest et al 1995 and brahimi and necir 2012 who showed that an estimation method has a better performance for stronger dependence level additionally when estimating θ 1 for homogenous mixture copulas the difference in rbias between ga mpl and em method is about 25 for τ 1 τ 2 0 2 0 6 again this difference increases as the dependence strength increases to reach 50 when τ 1 τ 2 0 6 0 8 these results support the robustness of the ga mpl when estimating copulas parameter its performance is not highly affected even for low dependently data this finding is in agreement with the findings in kim et al 2007 which showed that in the case of non mixture copula the mpl method is more suitable for the estimation of the copula parameter with low dependence strength moreover the relative rmse seem to be considerably higher for the em method when estimating copulas parameter meanwhile previous discussion about comparison of em and ga mpl results regarding the rbias also holds for the rrmse these results are likely to be related to the fact that the convergence of the em algorithm to the global maximizer depends on the starting point of the algorithm this might be also explained by the fact that the two component copulas in the mixture model get further away from each other when the kendall τ increase since both em and ga mpl estimators improve with increasing dependence strength and in order to identify the best recommended one for hydrological applications a deeper analysis is carried out to compare the two approaches for this purpose in order to show complete information and to present an overview of the results boxplots of the effect of kendall τ on the relative errors are provided in fig 4 several conclusions can be drawn from these boxplots from fig 4a it is found that the estimate of ω is not affected by the dependence level in fact for the ga mpl method the median value line inside the box is almost the same for the three dependence level combination the same holds for em method regardless the dependence level it is also found that in comparison to the em method ga mpl method has an overall better behavior indeed em estimators show higher median value this highlights the low ability of the em method to estimate correctly the weight ratio ω in certain circumstances note that although the median is the value considered to assess the performance of each method the variability in the results i e the height of the boxes should also be considered in the decision process as it refers to the uncertainty in the results given by the estimation method as a result of taking into account all the information provided by these criteria the ga mpl method was identified as the best in terms of estimating the weight ratio as both the median value and its variability are the smallest several conclusions can be drawn from these boxplots from fig 4a it is found that the estimate of ω is not affected by the dependence level in fact for the ga mpl method the median value line inside the box is almost the same for the three dependence level combination the same holds for em method regardless the dependence level it is also found that in comparison to the em method ga mpl method has an overall better behavior indeed em estimators show higher median value this highlights the low ability of the em method to estimate correctly the weight ratio ω in certain circumstances note that although the median is the value considered to assess the performance of each method the variability in the results i e the height of the boxes should also be considered in the decision process as it refers to the uncertainty in the results given by the estimation method as a result of taking into account all the information provided by these criteria the ga mpl method was identified as the best in terms of estimating the weight ratio as both the median value and its variability are the smallest we can see from fig 4b and 4c that as expected as the dependence gets stronger the re decrease for the two estimation methods this observed finding mirrors those of the previous studies that have examined different estimation method for non mixture copulas e g brahimi necir 2012 capéraà et al 1997 however although the performance of parameter estimates from the two methods show similar patterns the ga mpl method leads to better results when estimating copulas parameter indeed regardless the dependence level the reduction in the re of the ga mpl method is remarkable the re from the ga mpl method is about 20 smaller than that from the em method beyond confirming the obvious dominance of the ga mpl estimator and the poor performance of the em estimator the results in fig 4b and 4c indicate that the em method lead to larger uncertainty especially for low dependent data τ 0 2 the mixing proportion ω is of primary interest results regarding the effect of the weight ratio ω on the performance of each estimation method are displayed in table 4 to discard the effect of the sample size and the dependence level we analyse the effect of ω when n 150 and τ 1 τ 2 0 6 0 8 as it can be seen from table 4 the performance trends for the ga mpl and em methods are similar in the sense that rbiais and rrmse of the two methods get better as ω increases from 0 2 to 0 5 for example when estimating the first copula parameter θ 1 in the frank gumbel mixture copula using ga mpl method the rbias decreases from 13 to 3 2 when ω increases from 0 2 to 0 5 this result is likely to be related to the fact that when ω is small the mixture model contains increasing information about one component but decreasing information about the other component indeed a low mixing probability implies that the sampled data from the mixed model are close to the one component model these results are in agreement with fu et al 2019 s findings which showed that in the case of multivariate mixture distribution an estimation method have a better performance when ω lies in the middle than on the boundaries of its space however it is also worth noting that the two methods exhibit noteworthy differences especially under small ω indeed in this case the ga mpl method leads to the best results with the minimum values of absolute rbias and rrmse for example for the clayton frank mixture model the mean absolute rbias for the ga mpl and em methods are 19 1 and 11 7 respectively when estimating θ 1 for ω 0 2 these results imply that the ga mpl estimates are closer to the true values of the parameters than those of the em method accordingly the ga mpl method accurately estimates the parameters for low mixing probabilities ω and outperforms the em method for both homogenous and heterogeneous mixture copulas moreover according to fig 5 results reveal that ga mpl method yields more accurate estimates of the copulas parameter θ 1 and θ 2 indeed in all cases ga mpl method is characterised by smaller variability compared to em method 5 application to real world hydrological data after evaluating and comparing the proposed estimation methods on simulated data in this section we apply these methods on real world hydrological data the purpose of these applications is to assess the appropriateness of the proposed methods for practical use the most significant characteristics of a flood event are the flood peak q flood volume v and flood duration d as mentioned in the introduction the most correlated variables are q and v to scrutinize the impact of length of data on the performance of the estimation methods we use two flood peak q m3 s and volume v m3 data series the first data series correspond to the romaine station with natural flow regimes located in the cote nord region of the province of quebec canada n 55 it is considered previously for change point studies by chebana et al 2016 the second data series correspond to the ankang hydrological station at the upper hanjiang river china n 62 the same series is used on the paper of xiong et al 2015 who demonstrated the existence of a change on the copula parameter for each station flood characteristics q and v are extracted from daily streamflow series aissia et al 2012 since the focus of the study is on the dependence structure the choice of marginal distributions is performed but not presented in detail the gumbel marginal distribution often represents well extreme events such as flood peak and volume e g yue et al 1999 it is also shown in the present study that the gumbel mixture model can be selected as a marginal distribution for both peak and volume for each univariate series the five parameters of the gumbel mixture model were estimated using maximum likelihood method for the parameter of each individual gumbel distribution results are presented in table 5 the main advantage provided by the copula approach is the selection of an appropriate dependence structure independently of the choice of the marginals the parameters of four mixture copulas models as used in the simulation study are estimated for to data using em mpl and ga mpl methods then their fitting was tested using the cramer von mises test based on the comparison between the empirical and theoretical copula genest et al 2009 in order to select the best fitting copula among those accepted by different gof tests the model selection criterion aic is considered sadegh et al 2017 results are summarized in table 6 overall mixture copulas models using the ga mpl approach perform significantly better than the corresponding models using the em mpl approach in general we do not observe a big difference in the performances for the ankang station in this case according to the em mpl and ga mpl methods the best fitting model is the mixture of clayton and gumbel copulas however for smaller sample size which is the case of for the romaine station all mixture copulas models fitted using the em mpl approach are rejected at the significance level 5 this might be explained by the inconsistency of the em mpl method for small sized sample the overall best model is obtained with ga mpl method this highlights the advantage of using the ga mpl method for fitting mixture copulas when dealing with small sample size in the following only analysis regarding ankang data are presented and discussed since for the romaine data all fitted copula with the em mpl method are rejected as presented in fig 6 the bivariate quantile is a curve hence the usual performance evaluation criteria do not apply and should be adapted since the focus is on the evaluation of quantiles the event x x y y is of special interest to evaluate the performance of the two estimation methods regarding the quantile we used the upper and lower bound of the quantile curve developed by volpi and fiori 2012 results of the empirical and theoretical bounds are presented in table 7 it can be seen from table 7 that the estimated events of the ga mpl fitted model and that of the empirical model are almost similar the fitted em mpl model results have smaller flood volume and smaller flood peak than the empirical model it is therefore concluded that the model fitted using ga mpl method is suitable for representing the joint distribution of flood peaks and volumes however the frank gumbel copula fitted using the em mpl method underestimates the risk associated to the joint return periods t 100 hence this analysis supports the fact that model misspecification in joint extreme events modelling can lead to an underestimation of the risk 6 conclusion the main objective of the current study is to investigate the applicability of mixture copulas to model extreme events of hydrometeorological variables once the copula model and the associated marginal distributions are selected parameter estimation is the key step a novel contribution in mixture copula and in flood frequency analysis has been provided by proposing a new parameter estimation method this proposed approach denoted as ga mpl is based on the idea of estimating parameters by maximizing the log pseudo likelihood function using a meta heuristic algorithm a simulation study is carried out in order to evaluate the proposed method and to compare the performances with the widely used em method the obtained results show that the proposed ga mpl method is more appropriate than the em method in terms of rrmse and rbias especially for small sample sizes moreover the effectiveness of the ga mpl method in dealing with weakly dependent data makes it particularly suitable for some hydrological applications the applications show in a practical and complimentary way to the simulation results the advantage of using the new proposed method especially when dealing with small sample size in the current study because of the associated advantages the genetic algorithm is used for the optimization of the mpl future investigations will deal with other metaheuristic algorithms such the particle swarm optimization or by using a hybridization between two or several meta heuristic algorithms in addition the extension of our approach to mixtures with more than two components is valuable and interesting for further research efforts credit authorship contribution statement i ben nasr conceptualization methodology writing review editing f chebana conceptualization methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements none 
2684,the study proposes a new mathematical method referred to as spectral combination to downscale gravity recovery and climate experiment grace observations the goal is to improve the spatial resolution of grace from 1 to 0 25 based upon available hydrological variables first a new approach based upon condition adjustment is proposed to estimate uncertainties related to hydrological variables second a spectral spatial estimator is developed to derive downscaled total water storage anomalies twsa by optimally combining grace models and hydrological variables last groundwater storage anomalies gwsa are derived from the downscaled twsa the proposed spectral combination approach was tested over the canadian prairies by considering grace data and required global land data assimilation system gldas variables for february 2003 to december 2016 the results reveal greater details in twsa after spatial downscaling quantitatively retrieved downscaled gwsa were validated using 75 unconfined in situ piezometric wells that were distributed across the province of alberta a correlation of 0 80 with an rmse of 11 mm was obtained after downscaling with all wells over the validation area these results are better than those obtained before downscaling correlation of 0 42 with an rmse of 21 4 mm demonstrating that the proposed approach is successful graphical abstract unlabelled image keywords spectral combination grace satellite spatial downscaling groundwater storage variations data availability data will be made available on request 1 introduction the gravity recovery and climate experiment grace is a satellite mission with twin satellites for precise determination of spatial and temporal variations in the earth s gravity field the products of this mission are monthly global gravity models containing the spherical harmonic coefficients and their errors these grace models can be used for estimating terrestrial water storage tws variations across the globe at large scales thereby offering a new opportunity for surface and groundwater storage gws assessments long et al 2017 sun et al 2020 chao et al 2021 hu et al 2021 yet the ability of grace to monitor changes at smaller scales is too limited for local water management authorities this is largely due to the low spatial and temporal resolutions of its models 200 000 km2 and one month respectively several researchers and hydrogeologists have noted these drawbacks famiglietti 2014 alley and konikow 2015 high resolution grace data products would substantially enrich information that is needed by local scale decision makers while offering novel data for the regions that are lacking adequate in situ monitoring networks including northern parts of canada li et al 2016 fatolazadeh and goïta 2021 such products could eventually be obtained through downscaling the process of downscaling refers to a reconstruction of the variation in values at a specific better scale under the assumption that the values recorded at the larger scale are the average of those at the smaller scale becker and braun 1999 many downscaling techniques have been proposed so far they can be roughly classified into two groups including deterministic dynamical and statistical downscaling the former which includes data assimilation approaches typically utilizes a limited area with a high resolution model compared to grace a global climate model or general circulation model which is driven by lateral boundary conditions to derive smaller scale information zaitchik et al 2008 forootan et al 2014 gemitzi et al 2021 despite the strong advantage of being physically consistent this method requires tremendous computational time thereby limiting its applicability schoof 2013 the latter methods use statistical relationships between small scale and large scale parameters to predict the small scale details wilby et al 1998 the application of these methods is straightforward due to their flexibility in using various spatiotemporal datasets and the possibility of estimating uncertainties in model outputs a variety of statistical techniques have been applied and studied in the downscaling literature including classification based methods empirical and statistical regression models ning et al 2014 vishwakarma et al 2021 correlative relation methods yin et al 2018 and markov chains over the past few years statistical inversion in the form of machine learning algorithms has been widely used to downscale grace observations milewski et al 2019 seyoum et al 2019 ali et al 2021 chen et al 2021 he et al 2021 it includes random forest chen et al 2019a zuo et al 2021 artificial neural network lavado et al 2006 seyoum and milewski 2017 miro and famiglietti 2018 support vector machine shang et al 2019 and multiple linear regression sahour et al 2020 models yet statistical methods require access to large datasets and are based upon the assumptions that the observed data and small scale information capture the dynamics of the system under study and that these dynamics are valid beyond the observation period wilby et al 2004 in a newer approach the iterative adjustment method has been widely used in downscaling grace data zhong et al 2021a used this method spatially based upon a self calibrating variance component model to downscale original coarse resolution grace observations 300 km to a high resolution of 5 km their method was able to estimate uncertainties in high resolution tws and gws variations recently zhong et al 2021b developed a promising iterative adjustment method to downscale grace derived tws both spatially and temporally indeed they produced higher spatiotemporal resolution tws variations from original coarse resolution of grace in two steps first spatially from 3 degree spherical cap 300 km to 5 km and second temporally from monthly to daily due to the lack of accurate and comparable observations the quality of the model s performance needs to be further confirmed in this article spectral combination theory sjöberg 1980 1981 wenzel 1982 is applied to downscaling grace models this theory has been successfully developed and applied by different researchers including sjöberg and eshagh 2012 eshagh 2011 2012 and pitoňák et al 2018 mainly for gravity field modelling the main difference with respect to the existing methods that are presented is that the combination or downscaling is performed in the spectral domain in this study the estimator in spectral form is considered in such a way that both grace and hydrological models and their uncertainties which are in spectral form are used throughout it furthermore the uncertainties of the gldas model are estimated by proposing a new condition adjustment approach that does not use extra information the parameters of the estimator are determined so that the global mean square error of the estimator is minimized in a least squares sense the main contribution and originality of this research is the development and application of spectral combination theory to downscaling of the grace models this is a novel solution that has not been previously explored in hydrological applications in contrast to previous studies the approach works on both low and high signal frequencies of grace and gldas system 2 materials and methods in this section the materials are presented that are used in the study i e the data products and measurements that were considered in testing the proposed approach section 2 1 this section is followed by the theoretical presentation of the method section 2 2 2 1 materials to test our downscaling approach that is based upon the spectral combination theory we considered a study area covering the canadian prairies which consists of three provinces alberta saskatchewan and manitoba several reasons justify the choice of this vast region which is subject to frequent drought episodes indeed about one third of the population of the region is dependent upon groundwater the intensive agricultural and industrial activities impose great pressure on both surface and groundwater supplies kromm 1993 larocque and broda 2016 this situation when combined with climate change and surface water shortages is the main reason for groundwater depletion in the area gan 2000 the availability of high resolution grace based gws products would contribute to rigorous management of water resources in the region downscaling grace models is not possible without using additional data and information containing higher spatial and temporal frequencies than are present in the grace models otherwise the mathematical and statistical methods would simply play the role of interpolators without adding meaningful high frequency signals in this study grace models are used together with simulated hydrological products from the global land data assimilation system gldas as detailed below monthly gravity models of grace release 06 containing the spherical harmonic coefficients shcs and their errors to degree and order 60 were considered in the study these were obtained from the center for space research university of texas at austin utcsr for the period february 2003 to december 2016 all necessary corrections were applied to the models prior to using them this included replacing degrees 1 and 2 cheng et al 2011 determining leakage errors implementing glacial isostatic adjustment gia determining de stripping error and filling the monthly gaps between monthly grace models details of the required corrections are not provided here but can be found in fatolazadeh and goïta 2022 the processed gravity models were applied to estimate tws and gws anomalies during the testing phase of the method the gldas hydrological system contains various effective hydrological variables including soil moisture sm snow water equivalent swe canopy water can gws and tws anomalies among others for our study we considered gldas products that were based upon the catchment land surface model l4 daily 0 25 0 25 gldas clsm025 da1 d 2 2 these are high spatial resolution products 0 25 0 25 compared to grace 3 3 they are also high temporal resolution products daily versus monthly for grace furthermore it should be noted that the land surface model considered in this study is the only gldas lsm that contains gws variable so far gldas daily data need to be averaged out monthly to be consistent with the grace model temporal resolution it should be noted that gldas products do not include surface water body variables for reconstructing water balance equations in a comprehensive manner in addition to grace and gldas data we used in situ measurements to validate the results that were obtained following the application of the approach for instance 75 active unconfined piezometric wells were used to validate our downscaled grace gws anomalies validation was limited to the province of alberta based upon the wells that were available fig 1a shows the location of the wells across alberta we also divided the area into eight zones of 2 2 for a different level of validation fig 1b 2 2 methodology to achieve the main objective of this study viz the spatial downscaling of grace models we propose spectral combination theory where the errors on shcs play significant roles first a method for optimal estimation of error spectra of the gldas hydrological models is developed second a twsa estimator is presented for the spectral combination of gldas and grace models 2 2 1 error estimation of gldas and grace models it is known in hydrology that the tws total water storage is 1 t tws t sm t swe t can t gw t sw where t tws stands for the tws signal and t sm t swe t can t sw and t gw are respectively the signals from soil moisture sm snow water equivalent swe canopy water can surface water sw and groundwater storage gws eq 1 is a condition which should be fulfilled when the hydrological model contains all these variables given the presence of errors that are associated with in situ measurement networks and other data sources that were being considered eq 1 is seldom satisfied it must be noted that current gldas products contain no information on uncertainties resulting from comparisons with external data to estimate the internal quality of these variables let us rewrite eq 1 in the following form 2 t sm t swe t can t gw t sw t tws c where c 0 but satisfying this condition is not the case in practice eq 2 can be written in matrix form as 3 bε w with e ε 0 and e εε t σ 0 2 i where e stands for statistical expectation σ 0 2 is a priori variance factor i is an identity matrix with dimension of six as expressed in eq 3 b is the coefficient matrix and εis a vector of ε sm ε swe ε can ε gw ε sw and ε tws which are errors of t sm t swe t can t gw t sw and t tws respectively furthermore t is the transposition operator w is the misclosure of the equation and l is the vector of variables i e t sm t swe t can t gw t sw and t tws the vectors of eq 3 are 4 b 1 1 1 1 1 1 ε ε sm ε swe ε can ε gw ε sw ε tws t and 5 w c bl with l t sm t swe t can t gw t sw t tws t the minimum norm solution of eq 3 is 6 ε ε sm ε swe ε can ε gw ε sw ε tws b t bb t 1 w w 6 1 1 1 1 1 1 the error of each variable is estimated in a least squares sense given that no information regarding the quality of individual variables is given they are equally weighted in the adjustment process the posteriori variance factor of this adjustment model will be 7 σ 0 2 w t bb t 1 w w t w 6 here σ 0 2 is an overall estimate of variance for all variables therefore its square root can be considered as the error of each variable including tws in order to estimate the error spectra of tws anomalies from the gldas model the following spherical harmonic expansion is considered eshagh 2020 8 t tws θ λ n 1 m n n t nm tws y nm θ λ where θ λ is a pair of geographical positions of a point with colatitudes θ and longitude λand y nm θ λ are the spherical harmonic functions of degree n and order m with arguments θ λ t nm tws represents the shcs of t tws which can be derived based upon the orthogonality property of the spherical harmonics by 9 t nm tws 1 4 π ω t tws θ λ y nm θ λ dω where ωis the unit sphere over which the integration is taken and dωis the surface integration element in order to derive t nm tws a global grid of t tws with a specific resolution is needed for each degree n and order m of spherical harmonics the corresponding frequency of t tws of the same degree and order t nm tws is computed vectorization is a good method for computing t nm tws in this case we can write the vectorized model as follows 10 t nm tws b nm t tws eq 10 means that the integral eq 9 is discretized and converted to multiplication of two vectors b nm is a vector that is obtained after discretization of the integral eq 9 and contains the surface integration element and spherical harmonics the gridded data of t tws are converted to a column vector of t tws the advantage of writing eq 9 in vector form eq 10 is that the error propagation law of random errors can be simply applied to this vectorized model 11 σ nm tws h 2 b nm c tws b nm t where c tws is the diagonal variance covariance matrix of t tws having the estimated variances of t tws using eq 11 along its diagonal elements σ nm tws is the error of t nm tws this error can be estimated without knowledge of external information or comparisons with other sources the uncertainties of grace models are computed directly from derived tws more precisely the grace gravity models also can be converted to tws by the following spherical harmonic expression cf eshagh 2020 12 t tws g θ λ 1 4 πgrγ n 0 n 2 n 1 1 k n m n n v nm grace y nm θ λ where g 6 67 10 11 n m 2 kg 2 is the newtonian gravitational constant r is the radius of the spherical earth γ is the normal gravity k n is the love number of degree n v nm grace is the shc of the gravitational potential and σ v nm grace is determined from the grace models which are available in the monthly grace gravity model form to a maximum degree of n 60 according to the error propagation law of random errors and eq 12 the error of shcs of t tws g σ nm tws g and σ v nm grace have the following relationship 13 σ nm tws g 1 4 πgrγ 2 n 1 1 k n σ v nm grace 2 2 2 spectral combination for downscaling grace models the errors of the shcs in the gldas and grace models play a significant role when the two types of signals are combined for instance shcs having smaller errors should have higher weights in the combination process than those having larger errors to take this into account the following estimator is proposed for optimal combination of shcs from grace and gldas tws models 14 t n 0 a n t n h n 0 n b n t n g where a n and b n are spectral coefficients of the estimator which should be optimally estimated and 15 t n i m n n t nm i y nm θ λ i h g where h stands for hydrology or gldas and g for grace to shorten the mathematical derivations we considered t nm h t nm tws h and t nm g t nm tws g the error of the estimator eq 14 is 16 δ t n 0 n a n ε n h n 0 n b n ε n g n 0 n a n b n 1 t n for n n 60 17 δ t n n 1 a n ε n h n n 1 a n 1 t n for n n 60 these expressions indicate that differences between the spectra t n of grace and gldas system are solely due to the random errors ε n h and ε n g the first and second terms of eq 16 are the contributions of random errors in the tws signals from gldas and grace respectively the last term is the bias similarly the first term of eq 17 is the random part while the second term represents the bias the estimator eq 14 is divided into two parts in eqs 16 and 17 given that gldas variable fields have higher frequencies than those of grace this estimator combines the lower frequencies of both signals and performs filtering on the gldas signal for the higher frequencies we assume that the error spectra of the two models are not correlated i e e ε n h ε n g 0 and the error spectra are not correlated with the signal e ε n h t n 0 and e ε n g t n 0 further variance spectra are defined by e ε n h ε n h σ n 2 h e ε n g ε n g σ n 2 g in squaring eq 16 taking the statistical expectation and applying the mean value theorem over a unit sphere bring about further simplifications consequently the global mean square error mse of the estimator can be written as 18 mse t 1 4 π ω e δ t 2 dω n 0 n a n 2 σ n 2 h n 0 n b n 2 σ n 2 g n 0 n a n b n 1 2 c n where 19 σ n 2 h or g m n n σ nm 2 h or g and c n m n n t nm 2 taking the derivative of mse t with respect to a n and b n reads 20 mse t a n 2 n 0 n a n σ n 2 h 2 n 0 n a n b n 1 c n 21 mse t b n 2 n 0 n b n σ n 2 g 2 n 0 n a n b n 1 c n equating eqs 20 and 21 to zero and writing the equations in spectral form leads to 22 a n σ n 2 h c n b n c n c n a n c n b n σ n 2 g c n c n solving the system for a n and b n yields the following estimates 23 a n c n σ n 2 g c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g and b n c n σ n 2 h c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g this procedure is likewise applied to eq 17 in this case the mse of the estimator will be 24 mse δ t n n 1 a n 2 σ n 2 h n n 1 a n 1 2 c n taking derivative of eq 24 with respect to a n leads to 25 mse δ t a n 2 n n 1 a n σ n 2 h 2 n n 1 a n 1 c n by equating eq 25 to zero and solving for a n we obtain 26 a n c n c n σ n 2 h given that the spectral coefficients of our estimators have been estimated optimally according to the quality of the shcs the coefficients could be inserted in eq 14 which is our estimator the final formula combines grace and gldas data consequently the expanded form of the estimator eq 14 could be written as 27 t θ λ n 0 m n n a n t nm h b n t nm g y nm θ λ where 28 a n c n σ n 2 g c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g n n c n c n σ n 2 h n n and 29 b n c n σ n 2 h c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g n n 0 n n as indicated in eqs 28 the spectral coefficient a n has two different formulas for degrees less than n and for those that are greater indeed this coefficient is applied to gldas models which have both lower and higher degrees in eqs 29 the coefficient b n is zero for degrees greater than n given that the grace models are limited to degree n in other words the estimator combines the low degrees of both grace and gldas variables according to their weights while filtering the higher frequency signals according to errors of the models the filtering process is performed through coefficient a n only for gldas models of degrees greater than n t shows the optimal estimator of the combined grace and gldas that produces a high spatial resolution downscaled grace tws anomalies the spatial resolution of the output is completely dependent upon the hydrological model it means that this estimator can be used for any study area and also with any hydrological model in combination with grace the spatial resolution of the hydrological model would limit the final resolution of the downscaled results given that the spatial resolution of the gldas was 0 25 0 25 the resolution of the downscaled grace tws anomalies is also limited to 0 25 0 25 it means that depending upon the spatial resolution of the hydrological model it is possible to produce better resolutions than 0 25 once downscaled tws anomalies are produced the corresponding downscaled grace based gws anomalies can be derived at the same spatial resolution long et al 2013 singh et al 2017 bhanja et al 2018 feng et al 2018 chen et al 2019b frappart et al 2019 rateb et al 2020 wang et al 2020 this is determined by deducing the different hydrological components from estimated variations in grace tws by our method 2 2 3 validation of the approach as mentioned in section 2 1 validation of the approach was performed using 75 in situ observation wells that were available over the province of alberta we performed the validation at three different spatiotemporal levels to illustrate the success of the downscaling approach because the target of the downscaling was to produce gws anomalies monthly at a spatial resolution of 0 25 the first level of the validation was implemented at this spatial scale therefore for each downscaled grace grid cell at 0 25 containing a well we compared grace based gws anomalies to equivalent in situ data during the study period given that the downscaled grace gws anomalies were produced in increments of 0 25 the comparison is performed for each grid cell of 0 25 0 25 containing a well in addition we also combined together the estimated monthly grace gwsa data for all grid cells at the 0 25 resolution during the study period and computed the correlation and rmse with the corresponding in situ data in the second level of validation we partitioned the area into 8 grid zones of 2 2 see fig 1b this artificial division was only meant to have zones containing several wells since the wells do not cover the whole province and are mainly distributed in the southern part of the province validation was performed in each zone based upon the average of the wells that they contain in the third and final validation level the monthly averages of all 0 25 0 25 grid cells containing all wells were validated against the corresponding monthly averages of the data from the 75 wells during the study period note that gwsas from the wells are available on a daily basis therefore they must be averaged monthly to the same temporal resolution as the downscaled grace based gwsas from february 2003 to the end of 2016 3 results in this section errors of the gldas model are presented followed by the global mean square errors of the estimator the downscaled results tws and gws anomalies are then presented in order not to place an undue burden on the reader we have limited graphical presentation to four selected representative months the final part of the section is about the validation 3 1 errors associated with the gldas land surface scheme to illustrate the applicability of the error estimation method that is presented in section 2 2 1 the condition adjustment model eq 1 was first used after performing the adjustment process a posteriori variance factor was estimated using eq 7 after which the error of the model was computed by taking the global square root of this variance as summarized in section 2 2 1 this process has been applied individually to all gldas products that were considered in the study the computation was performed for all months in the study period between 2003 and 2016 only results that were related to tws are shown here since the latter is the final variable of interest from the gldas model to simplify their presentation the results are graphically illustrated for four selected months i e may 2004 november 2006 july 2010 and october 2015 fig 2 these months were selected for the following reasons we wanted to demonstrate that our approach could work in any year therefore we selected different years between the early and ending periods of grace by selecting different months within the year we wanted to show that our approach is not dependent upon season in these four months that were selected for illustration the maximum errors of gldas tws anomalies are about 4 mm 5 mm 8 mm and 7 mm respectively these values are equivalent to respectively 4 4 9 and 4 of gldas tws for the different months considered generally errors are smaller over the southern and northwestern parts of the area but large errors are mainly seen in the northeast except in july 2010 where errors are larger in the north central part and in october 2015 with larger errors in the west it should be stated that the purpose of presenting fig 2 is to indicate the patterns of uncertainty over the area and to show that they do not follow a clear specific pattern the comparison of the errors in gldas and grace shows a sinusoidal behaviour with an uncertain temporal pattern in gldas errors figure not shown here however the reader can consult fatolazadeh and goïta 2022 for more details the error in grace tws increases towards the end of the twin satellite mission the maximum error found for gldas was 24 mm which is slightly lower that of grace about 29 mm in the four months that were considered grace tws errors varied from 14 mm to 20 mm and were significantly higher than those of gldas 3 2 global root mean square error of estimator the global root mean square error rmse of the estimator eq 27 is presented for degrees 60 by eq 18 and for 60 by eq 23 in fig 3 the rmse uniformly decreases with increasing degree as expected indeed the inclusion of more degrees in the estimator adds more information to the optimization problem while reducing the truncation error of the estimator based on the least squares principle the error should decrease when more data are used and this plot confirms the appropriateness of estimator performance it also shows that rmse is about 50 mm which decreases to about 5 mm when the signal is considered to degree 360 3 3 downscaled grace twsa fig 4 shows the map of gldas twsa a1 b1 c1 and d1 grace twsa a2 b2 c2 and d2 before downscaling and grace twsa a3 b3 c3 and d3 after downscaling at a resolution of 0 25 0 25 using the spectral integral estimator over the canadian prairies results are illustrated only for the selected four months it must be noted that the spherical harmonic analysis and filtering were applied to gldas variables to extract twsa consistent with grace twsa before downscaling our goal here is to show that the method is successful and could deliver the expected spatial variability hydrological interpretations are beyond the scope of this study in may 2004 gldas twsa fig 4a1 shows some pattern similarities with both grace twsa before fig 4a2 and after downscaling fig 4a3 in manitoba and from the centre to the north in saskatchewan as well as the south in alberta however there is a clear difference between gldas and grace in northern alberta overall downscaled grace twsa exhibits a lower positive range maximum about 63 mm compared to both grace before downscaling and gldas maximum 110 mm the comparison of grace twsa maps before and after downscaling fig 4a2 and 4a3 in may 2004 shows that more detailed information is visible in the downscaled tws anomalies generally negative twsa values are seen in the southwest while higher positive values are observed over the northern part of the region after downscaling some high anomalies are seen around 50 n and 97 w and 58 n and 105 w which were also evident in the grace twsa prior to downscaling in november 2006 the spatial patterns that were found with gldas fig 4b1 grace before downscaling fig 4b2 and grace after downscaling fig 4b3 have several similarities the value ranges in all cases are quite comparable 59 mm to 57 mm for gldas 82 mm to 67 mm for grace before downscaling and 70 mm to 50 mm after downscaling the major differences occur in northern alberta where gldas values are all positive in this area the downscaled grace twsa map exhibits also some positive patterns and is visually in better agreement with gldas contrary to the grace map before downscaling more interestingly specific patterns were revealed by the downscaling process fig 4b3 for instance higher values are seen around 53 n and 116 w after downscaling which were not previously visible in july 2010 the correspondence between gldas twsa fig 4c1 and grace twsa before downscaling fig 4c2 is quite remarkable with a north south gradient showing negative values concentrated in the north changing gradually to positive values in the south the downscaled twsa fig 4c3 also shows similar patterns especially in the southern part however greater variability can be seen moving northward contrary to the homogeneous negative tendency that is shown in fig 4c1 and 4c2 quantitatively all three products have very similar value ranges in october 2015 high positive values of grace twsa are concentrated towards the west before the downscaling fig 4d2 a roughly similar pattern can be observed following downscaling but there is greater variation in the east fig 4d3 the similarities between grace twsa fig 4d2 fig 4d3 and gldas twsa fig 4d1 patterns can be observed in saskatchewan and to a lesser extent in manitoba however there is a significant difference between grace and gldas in alberta particularly from the centre to the north where gldas shows only negative values while grace indicates the opposite 3 4 downscaled grace derived gwsa determination of groundwater anomalies from the downscaled twsa can be achieved by employing eq 1 and solving for t gw in other words the signals for sm t sm swe t swe and can t can are removed from the downscaled t tws fig 5 shows the results of gwsa over the study area for the purposes of illustration the results are shown for the four months selected before solving for t gw i e may 2004 fig 5a november 2006 fig 5b july 2010 fig 5c and october 2015 fig 5d the patterns that are visible on the map of gwsa for may 2004 fig 5a are quite similar to those on the corresponding twsa map fig 4a3 although positive gwsa values 50 mm are more strongly pronounced in the eastern part of the area fig 5b and its correspondent fig 4b3 show that in november 2006 positive gws and tws anomalies are present in central saskatchewan maximum about 20 and 40 mm respectively and in northern manitoba yet negative values are dominant in western alberta 90 and 60 mm respectively in july the patterns of twsa fig 4c3 and gwsa fig 5c are different gwsa displays weak values 20 mm over alberta and southern saskatchewan overall twsa ranges from 80 to 40 mm fig 4c3 while gwsa varies from 30 to about 120 mm fig 5c this shows the influence of the total effect of soil moisture snow water equivalent and canopy water on leaf on conditions in october 2015 twsa has large and positive values in the western portion of the prairies fig 4d3 the corresponding gwsa also shows positive patterns in that region but appear to be mostly negative in the east fig 5d overall the spatial output maps of gwsa mainly show a decline in the southern portions of the prairies i e the cold semi arid steppe region known as palliser s triangle about 50 mm 30 mm and 10 mm in may 2004 november 2006 and july 2010 respectively groundwater depletion in the area is due to the arid conditions and dry climate resulting from frequent droughts which in turn affect crop production mondal 2021 morgan et al 2021 3 5 validation to validate downscaled grace gws anomalies and to demonstrate the successful performance of our estimator 75 in situ wells across alberta were used in each validation level we used pearson correlations and rmse metrics in the validation process in the first stage the comparison was done at the resolution of 0 25 to be consistent with our downscaling results in each grid cell of 0 25 containing a well the validation was done by comparing the estimated gws anomalies to the equivalent well data see section 2 2 3 since we cannot show all 75 time series for each piezometric well location only statistical metrics of the comparison are presented in table 1 significant correlations at 95 confidence level varying from p 10 4 to 0 04 were found between grace derived gwsa and in situ data for 71 of 75 well locations i e 95 of the wells the range of rmse that was found is between 18 mm and 29 mm in contrast correlations between gldas gws anomalies and in situ wells data appear to be mostly non significant for 88 of the well locations with a greater rmse range from 25 mm to 60 mm statistical metrics showed that our method performed better than gldas and had greater consistency across wells table 1 this performance was also confirmed when all the data from all the individual grid cells at 0 25 resolution containing wells during the study period were combined together to compute the statistical metrics as explained in section 2 2 3 indeed a significant correlation r 0 52 and rmse 24 3 mm were found in this analysis which was based on a total of 12 525 data points these metrics are significantly better than the corresponding results with gldas r 0 39 rmse 35 2 mm as shown in the bottom of table 1 in the second level of validation the average values of the wells in each of the 8 grid zones that were considered are compared to those from the grace gwsa before downscaling by subtracting gldas sm swe and can from original grace twsa the downscaled grace gws and gldas gws anomalies see explanation in section 2 2 3 fig 6 shows gwsa temporal variations before and after downscaling with the corresponding gldas and monthly averaged piezometric wells over the eight zones during the study period the statistical metrics of the comparison are shown in table 2 correlations that were found by comparing the downscaled grace gws anomalies to well data vary between 0 53 and 0 84 and all are significant at 95 for all zones accordingly rmse was between 14 mm and 23 mm lower correlations were obtained in zone 1 zone 4 and zone 7 0 53 0 66 and 0 55 respectively the low correlation in zone 1 could be due to the limited number of wells that were available over the area only 2 wells in zone 4 and zone 7 the presence of the rocky mountains and the dominant brunisol and regosol soil types in this area could explain the low correlations the remaining zones display higher correlations and low rmse r 0 70 rmse 18 mm the large number of wells that were available in these zones may partly explain the better metrics that were found interestingly the statistical metrics found when downscaled gwsa are compared to in situ data are far better than those obtained in comparing gwsa before downscaling to in situ wells see table 2 both in terms of correlations 0 53 to 0 84 versus 0 34 to 0 77 and rmse value range 14 mm to 23 mm versus 21 mm to 37 mm these results further indicate the effectiveness of the downscaling process the comparison between wells and gldas gws anomalies shows correlations and rmse ranging between 0 01 and 0 89 and 17 mm and 34 mm respectively there is no correlation between the gldas gwsa variations with those of wells in zone 1 given the insufficient number of wells low correlations were also obtained in zones 2 and 4 with highest rmse 31 mm for half of the zones the metrics that were found with gldas are comparable to those found with downscaled grace based gwsa the lack of agreement with gldas may be due to the deficiency in input and calibration data model structure and variables in the last validation level the comparison was performed between the averages of all 75 wells and respectively the averages of the gridded 0 25 0 25 grace gws before the downscaling the averages after the downscaling and the averages of gldas gws anomalies across alberta fig 7 shows the time series of these variations in contrast to grace a pattern of low consistency can be seen between gldas and wells especially at the beginning 2003 2006 and end 2015 of the period the statistical metrics are summarized in table 2 last row results of downscaled grace based gwsa are significantly correlated with well data r 0 80 p 0 0004 at 95 confidence compared to grace gwsa before downscaling r 0 42 and gldas gwsa r 0 41 rmses that were found with grace before downscaling and gldas are nearly double the value with downscaled grace 21 24 mm versus 11 mm these compelling metrics give us confidence in our proposed spectral combination method for downscaling grace data 4 discussion possessing knowledge of data quality and uncertainties associated with the given variable fields that were provided by the hydrological models gldas in our case is tremendously important when our spatio spectral twsa estimator is used fortunately the approach that is presented in section 2 could be a suitable method for estimating the internal quality of these models thus the method is applicable to all types of hydrological models containing tws information the greatest computational challenge is related to the spherical harmonic sh analysis of errors for the gldas variables which should be done for each degree and order individually nevertheless a proper vectorization algorithm could substantially reduce the computational time briefly uncertainties in the gldas model could be due to different problems for instance difficulties in modelling the process of water circulation in areas with frozen soil discrepancies in the amplitudes of the individual hydrological variables ablation at near freezing temperatures and difficulties in modelling biological processes that characterize the plant canopy long et al 2014 bi and ma 2015 kim et al 2015 han et al 2021 the estimator variables i e eqs 28 and 29 can be simply determined from errors of the shcs of grace and those that were computed by the condition adjustment method in section 2 in addition the true degree variance of the hydrological signal is required given that the estimator uses it to filter the noise in the tws in this case each hydrological variable can be used in the land surface schemes over the study period our estimator combines the low frequencies of grace and gldas that are optimally based on their error degree variance and high frequencies are removed from the gldas land surface models after filtering out their noise based upon signal to noise ratios in the spectral domain the spatial resolution of the downscaled twsa depends upon the resolution of the gldas model i e 0 25 0 25 this corresponds to the degree and order of 720 in the sh expansion a maximum degree of 360 has been considered for these models in our computations due to the tremendous computational burdens that are imposed by the errors in the shcs consequently it introduced a limitation to effectively completing high frequency and simulating ultra short wavelength parts of regional hydrological variables lu et al 2000 the most substantial difference between our proposed approach and artificial neural network methods can be seen when optimizing the errors more precisely in previous methods lavado et al 2006 seyoum and milewski 2017 miro and famiglietti 2018 the closest and minimum error between grace and other input data are found by changing the input variables randomly the input model requires initial values for optimization processing yet there is no unique answer among these kinds of approaches in contrast our proposed method focuses on low and high frequencies of the input variables in combination with grace frequencies to find the optimum errors therefore it is a unique method that can be used with any input data or initial data moreover our proposed approach is not dependent upon location and can be potentially applied to different areas of the world with different climate and topographic conditions we applied the proposed method to all monthly data that were available during the study period which were considered in the canadian prairies yet visual performance of the approach is illustrated only for four months to limit space requirements july 2004 november 2006 july 2010 and october 2015 see figs 2 4 and 5 other months could have been shown as well in most months a pattern was observed for palliser s triangle which is the driest part of the canadian prairies brown soil zone parkland and mixed grassland ecoregion marchildon et al 2016 gwsa can be obtained simply by subtracting the signals of soil moisture snow water equivalent and canopy water from the downscaled twsas that were estimated by our method fig 5 a major limitation in using gldas is the absence of a surface water component goddard earth sciences data and information services center ges disc this component is taken into account during the theoretical development of the approach section 2 due to the lack of data in the gldas land surface model that was used in this study we neglected it during the application phase of the approach therefore the lakes and rivers that are situated in the canadian prairies have no data and were allocated nan value see figs 2 4 and 5 our previous studies indicate that surface water component is nearly negligible over most parts of the canadian prairies fatolazadeh and goïta 2022 especially over the province of alberta where the downscaled gwsa were validated the most dominant factors defining tws in the region remain soil moisture snow water equivalent and groundwater despite the different limitations correlations that were found with in situ wells are significant at 95 confidence 0 53 0 84 in the different validation zones that were considered figs 6 7 table 2 as shown in table 2 the correlation r 0 80 that was found over the province of alberta by considering all downscaled grace cells with their corresponding monthly well data is quite convincing especially the associated low rmse of 11 mm in contrast metrics found with gldas are low r 0 41 rmse 23 7 mm this could be due to the phase difference between well station measurements and model estimates rzepecka and birylo 2020 it should be noted that wells are not uniformly distributed over the province they are concentrated mainly towards the south further work is required for a broader validation of the proposed approach 5 conclusion in this study a new approach was introduced and employed to retrieve downscaled terrestrial water storage tws and groundwater storage gws anomalies using grace and gldas data for the period between february 2003 and december 2016 a new condition adjustment method was developed to estimate uncertainties of gldas data without requiring extra information estimated uncertainties reached a maximum about 10 mm during the entire period of the study particularly in the southern canadian prairies a twsa estimator was developed based upon spectral combination theory to weight spectrally both grace and gldas models and to combine them optimally this approach permits retrieval of downscaled gwsa from twsa with a spatial resolution 0 25 0 25 compared to 3 3 for original grace data visually maps of downscaled gwsa revealed greater detail and variability as expected indicating that the approach successfully captured high frequencies significant higher correlations and low rmse values were found during quantitative validation of the downscaled gwsa compared to in situ well piezometric data confirming success of the spectral combination method that was proposed application of the approach using other hydrological models together with further validation with more well data in different environments is envisaged for future research data availability spherical harmonic coefficients of release 06 grace are available at http icgem gfz potsdam de series 01 grace csr csr 20release 2006 hydrological variables of the gldas clsm025 da1 d 2 2 can be downloaded from https disc gsfc nasa gov datasets gldas clsm025 da1 d 2 2 summary keywords gldas information on in situ observation wells located in alberta can be downloaded from https www alberta ca lookup groundwater observation well network aspx credit authorship contribution statement farzam fatolazadeh conceptualization software writing original draft mehdi eshagh methodology writing original draft kalifa goïta writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was funded by the université de sherbrooke excellence scholarship program and the natural sciences and engineering research council of canada nserc discovery grant number rgpin 2018 06101 nserc create grant 543360 2020 we thank all data and products providers university of texas at austin natural resources canada and the goddard earth sciences data and information services center we gratefully thank for all valuable suggestions from two reviewers and joh editorial team which help us improve the manuscript significantly we thank w f j parsons for correcting the english 
2684,the study proposes a new mathematical method referred to as spectral combination to downscale gravity recovery and climate experiment grace observations the goal is to improve the spatial resolution of grace from 1 to 0 25 based upon available hydrological variables first a new approach based upon condition adjustment is proposed to estimate uncertainties related to hydrological variables second a spectral spatial estimator is developed to derive downscaled total water storage anomalies twsa by optimally combining grace models and hydrological variables last groundwater storage anomalies gwsa are derived from the downscaled twsa the proposed spectral combination approach was tested over the canadian prairies by considering grace data and required global land data assimilation system gldas variables for february 2003 to december 2016 the results reveal greater details in twsa after spatial downscaling quantitatively retrieved downscaled gwsa were validated using 75 unconfined in situ piezometric wells that were distributed across the province of alberta a correlation of 0 80 with an rmse of 11 mm was obtained after downscaling with all wells over the validation area these results are better than those obtained before downscaling correlation of 0 42 with an rmse of 21 4 mm demonstrating that the proposed approach is successful graphical abstract unlabelled image keywords spectral combination grace satellite spatial downscaling groundwater storage variations data availability data will be made available on request 1 introduction the gravity recovery and climate experiment grace is a satellite mission with twin satellites for precise determination of spatial and temporal variations in the earth s gravity field the products of this mission are monthly global gravity models containing the spherical harmonic coefficients and their errors these grace models can be used for estimating terrestrial water storage tws variations across the globe at large scales thereby offering a new opportunity for surface and groundwater storage gws assessments long et al 2017 sun et al 2020 chao et al 2021 hu et al 2021 yet the ability of grace to monitor changes at smaller scales is too limited for local water management authorities this is largely due to the low spatial and temporal resolutions of its models 200 000 km2 and one month respectively several researchers and hydrogeologists have noted these drawbacks famiglietti 2014 alley and konikow 2015 high resolution grace data products would substantially enrich information that is needed by local scale decision makers while offering novel data for the regions that are lacking adequate in situ monitoring networks including northern parts of canada li et al 2016 fatolazadeh and goïta 2021 such products could eventually be obtained through downscaling the process of downscaling refers to a reconstruction of the variation in values at a specific better scale under the assumption that the values recorded at the larger scale are the average of those at the smaller scale becker and braun 1999 many downscaling techniques have been proposed so far they can be roughly classified into two groups including deterministic dynamical and statistical downscaling the former which includes data assimilation approaches typically utilizes a limited area with a high resolution model compared to grace a global climate model or general circulation model which is driven by lateral boundary conditions to derive smaller scale information zaitchik et al 2008 forootan et al 2014 gemitzi et al 2021 despite the strong advantage of being physically consistent this method requires tremendous computational time thereby limiting its applicability schoof 2013 the latter methods use statistical relationships between small scale and large scale parameters to predict the small scale details wilby et al 1998 the application of these methods is straightforward due to their flexibility in using various spatiotemporal datasets and the possibility of estimating uncertainties in model outputs a variety of statistical techniques have been applied and studied in the downscaling literature including classification based methods empirical and statistical regression models ning et al 2014 vishwakarma et al 2021 correlative relation methods yin et al 2018 and markov chains over the past few years statistical inversion in the form of machine learning algorithms has been widely used to downscale grace observations milewski et al 2019 seyoum et al 2019 ali et al 2021 chen et al 2021 he et al 2021 it includes random forest chen et al 2019a zuo et al 2021 artificial neural network lavado et al 2006 seyoum and milewski 2017 miro and famiglietti 2018 support vector machine shang et al 2019 and multiple linear regression sahour et al 2020 models yet statistical methods require access to large datasets and are based upon the assumptions that the observed data and small scale information capture the dynamics of the system under study and that these dynamics are valid beyond the observation period wilby et al 2004 in a newer approach the iterative adjustment method has been widely used in downscaling grace data zhong et al 2021a used this method spatially based upon a self calibrating variance component model to downscale original coarse resolution grace observations 300 km to a high resolution of 5 km their method was able to estimate uncertainties in high resolution tws and gws variations recently zhong et al 2021b developed a promising iterative adjustment method to downscale grace derived tws both spatially and temporally indeed they produced higher spatiotemporal resolution tws variations from original coarse resolution of grace in two steps first spatially from 3 degree spherical cap 300 km to 5 km and second temporally from monthly to daily due to the lack of accurate and comparable observations the quality of the model s performance needs to be further confirmed in this article spectral combination theory sjöberg 1980 1981 wenzel 1982 is applied to downscaling grace models this theory has been successfully developed and applied by different researchers including sjöberg and eshagh 2012 eshagh 2011 2012 and pitoňák et al 2018 mainly for gravity field modelling the main difference with respect to the existing methods that are presented is that the combination or downscaling is performed in the spectral domain in this study the estimator in spectral form is considered in such a way that both grace and hydrological models and their uncertainties which are in spectral form are used throughout it furthermore the uncertainties of the gldas model are estimated by proposing a new condition adjustment approach that does not use extra information the parameters of the estimator are determined so that the global mean square error of the estimator is minimized in a least squares sense the main contribution and originality of this research is the development and application of spectral combination theory to downscaling of the grace models this is a novel solution that has not been previously explored in hydrological applications in contrast to previous studies the approach works on both low and high signal frequencies of grace and gldas system 2 materials and methods in this section the materials are presented that are used in the study i e the data products and measurements that were considered in testing the proposed approach section 2 1 this section is followed by the theoretical presentation of the method section 2 2 2 1 materials to test our downscaling approach that is based upon the spectral combination theory we considered a study area covering the canadian prairies which consists of three provinces alberta saskatchewan and manitoba several reasons justify the choice of this vast region which is subject to frequent drought episodes indeed about one third of the population of the region is dependent upon groundwater the intensive agricultural and industrial activities impose great pressure on both surface and groundwater supplies kromm 1993 larocque and broda 2016 this situation when combined with climate change and surface water shortages is the main reason for groundwater depletion in the area gan 2000 the availability of high resolution grace based gws products would contribute to rigorous management of water resources in the region downscaling grace models is not possible without using additional data and information containing higher spatial and temporal frequencies than are present in the grace models otherwise the mathematical and statistical methods would simply play the role of interpolators without adding meaningful high frequency signals in this study grace models are used together with simulated hydrological products from the global land data assimilation system gldas as detailed below monthly gravity models of grace release 06 containing the spherical harmonic coefficients shcs and their errors to degree and order 60 were considered in the study these were obtained from the center for space research university of texas at austin utcsr for the period february 2003 to december 2016 all necessary corrections were applied to the models prior to using them this included replacing degrees 1 and 2 cheng et al 2011 determining leakage errors implementing glacial isostatic adjustment gia determining de stripping error and filling the monthly gaps between monthly grace models details of the required corrections are not provided here but can be found in fatolazadeh and goïta 2022 the processed gravity models were applied to estimate tws and gws anomalies during the testing phase of the method the gldas hydrological system contains various effective hydrological variables including soil moisture sm snow water equivalent swe canopy water can gws and tws anomalies among others for our study we considered gldas products that were based upon the catchment land surface model l4 daily 0 25 0 25 gldas clsm025 da1 d 2 2 these are high spatial resolution products 0 25 0 25 compared to grace 3 3 they are also high temporal resolution products daily versus monthly for grace furthermore it should be noted that the land surface model considered in this study is the only gldas lsm that contains gws variable so far gldas daily data need to be averaged out monthly to be consistent with the grace model temporal resolution it should be noted that gldas products do not include surface water body variables for reconstructing water balance equations in a comprehensive manner in addition to grace and gldas data we used in situ measurements to validate the results that were obtained following the application of the approach for instance 75 active unconfined piezometric wells were used to validate our downscaled grace gws anomalies validation was limited to the province of alberta based upon the wells that were available fig 1a shows the location of the wells across alberta we also divided the area into eight zones of 2 2 for a different level of validation fig 1b 2 2 methodology to achieve the main objective of this study viz the spatial downscaling of grace models we propose spectral combination theory where the errors on shcs play significant roles first a method for optimal estimation of error spectra of the gldas hydrological models is developed second a twsa estimator is presented for the spectral combination of gldas and grace models 2 2 1 error estimation of gldas and grace models it is known in hydrology that the tws total water storage is 1 t tws t sm t swe t can t gw t sw where t tws stands for the tws signal and t sm t swe t can t sw and t gw are respectively the signals from soil moisture sm snow water equivalent swe canopy water can surface water sw and groundwater storage gws eq 1 is a condition which should be fulfilled when the hydrological model contains all these variables given the presence of errors that are associated with in situ measurement networks and other data sources that were being considered eq 1 is seldom satisfied it must be noted that current gldas products contain no information on uncertainties resulting from comparisons with external data to estimate the internal quality of these variables let us rewrite eq 1 in the following form 2 t sm t swe t can t gw t sw t tws c where c 0 but satisfying this condition is not the case in practice eq 2 can be written in matrix form as 3 bε w with e ε 0 and e εε t σ 0 2 i where e stands for statistical expectation σ 0 2 is a priori variance factor i is an identity matrix with dimension of six as expressed in eq 3 b is the coefficient matrix and εis a vector of ε sm ε swe ε can ε gw ε sw and ε tws which are errors of t sm t swe t can t gw t sw and t tws respectively furthermore t is the transposition operator w is the misclosure of the equation and l is the vector of variables i e t sm t swe t can t gw t sw and t tws the vectors of eq 3 are 4 b 1 1 1 1 1 1 ε ε sm ε swe ε can ε gw ε sw ε tws t and 5 w c bl with l t sm t swe t can t gw t sw t tws t the minimum norm solution of eq 3 is 6 ε ε sm ε swe ε can ε gw ε sw ε tws b t bb t 1 w w 6 1 1 1 1 1 1 the error of each variable is estimated in a least squares sense given that no information regarding the quality of individual variables is given they are equally weighted in the adjustment process the posteriori variance factor of this adjustment model will be 7 σ 0 2 w t bb t 1 w w t w 6 here σ 0 2 is an overall estimate of variance for all variables therefore its square root can be considered as the error of each variable including tws in order to estimate the error spectra of tws anomalies from the gldas model the following spherical harmonic expansion is considered eshagh 2020 8 t tws θ λ n 1 m n n t nm tws y nm θ λ where θ λ is a pair of geographical positions of a point with colatitudes θ and longitude λand y nm θ λ are the spherical harmonic functions of degree n and order m with arguments θ λ t nm tws represents the shcs of t tws which can be derived based upon the orthogonality property of the spherical harmonics by 9 t nm tws 1 4 π ω t tws θ λ y nm θ λ dω where ωis the unit sphere over which the integration is taken and dωis the surface integration element in order to derive t nm tws a global grid of t tws with a specific resolution is needed for each degree n and order m of spherical harmonics the corresponding frequency of t tws of the same degree and order t nm tws is computed vectorization is a good method for computing t nm tws in this case we can write the vectorized model as follows 10 t nm tws b nm t tws eq 10 means that the integral eq 9 is discretized and converted to multiplication of two vectors b nm is a vector that is obtained after discretization of the integral eq 9 and contains the surface integration element and spherical harmonics the gridded data of t tws are converted to a column vector of t tws the advantage of writing eq 9 in vector form eq 10 is that the error propagation law of random errors can be simply applied to this vectorized model 11 σ nm tws h 2 b nm c tws b nm t where c tws is the diagonal variance covariance matrix of t tws having the estimated variances of t tws using eq 11 along its diagonal elements σ nm tws is the error of t nm tws this error can be estimated without knowledge of external information or comparisons with other sources the uncertainties of grace models are computed directly from derived tws more precisely the grace gravity models also can be converted to tws by the following spherical harmonic expression cf eshagh 2020 12 t tws g θ λ 1 4 πgrγ n 0 n 2 n 1 1 k n m n n v nm grace y nm θ λ where g 6 67 10 11 n m 2 kg 2 is the newtonian gravitational constant r is the radius of the spherical earth γ is the normal gravity k n is the love number of degree n v nm grace is the shc of the gravitational potential and σ v nm grace is determined from the grace models which are available in the monthly grace gravity model form to a maximum degree of n 60 according to the error propagation law of random errors and eq 12 the error of shcs of t tws g σ nm tws g and σ v nm grace have the following relationship 13 σ nm tws g 1 4 πgrγ 2 n 1 1 k n σ v nm grace 2 2 2 spectral combination for downscaling grace models the errors of the shcs in the gldas and grace models play a significant role when the two types of signals are combined for instance shcs having smaller errors should have higher weights in the combination process than those having larger errors to take this into account the following estimator is proposed for optimal combination of shcs from grace and gldas tws models 14 t n 0 a n t n h n 0 n b n t n g where a n and b n are spectral coefficients of the estimator which should be optimally estimated and 15 t n i m n n t nm i y nm θ λ i h g where h stands for hydrology or gldas and g for grace to shorten the mathematical derivations we considered t nm h t nm tws h and t nm g t nm tws g the error of the estimator eq 14 is 16 δ t n 0 n a n ε n h n 0 n b n ε n g n 0 n a n b n 1 t n for n n 60 17 δ t n n 1 a n ε n h n n 1 a n 1 t n for n n 60 these expressions indicate that differences between the spectra t n of grace and gldas system are solely due to the random errors ε n h and ε n g the first and second terms of eq 16 are the contributions of random errors in the tws signals from gldas and grace respectively the last term is the bias similarly the first term of eq 17 is the random part while the second term represents the bias the estimator eq 14 is divided into two parts in eqs 16 and 17 given that gldas variable fields have higher frequencies than those of grace this estimator combines the lower frequencies of both signals and performs filtering on the gldas signal for the higher frequencies we assume that the error spectra of the two models are not correlated i e e ε n h ε n g 0 and the error spectra are not correlated with the signal e ε n h t n 0 and e ε n g t n 0 further variance spectra are defined by e ε n h ε n h σ n 2 h e ε n g ε n g σ n 2 g in squaring eq 16 taking the statistical expectation and applying the mean value theorem over a unit sphere bring about further simplifications consequently the global mean square error mse of the estimator can be written as 18 mse t 1 4 π ω e δ t 2 dω n 0 n a n 2 σ n 2 h n 0 n b n 2 σ n 2 g n 0 n a n b n 1 2 c n where 19 σ n 2 h or g m n n σ nm 2 h or g and c n m n n t nm 2 taking the derivative of mse t with respect to a n and b n reads 20 mse t a n 2 n 0 n a n σ n 2 h 2 n 0 n a n b n 1 c n 21 mse t b n 2 n 0 n b n σ n 2 g 2 n 0 n a n b n 1 c n equating eqs 20 and 21 to zero and writing the equations in spectral form leads to 22 a n σ n 2 h c n b n c n c n a n c n b n σ n 2 g c n c n solving the system for a n and b n yields the following estimates 23 a n c n σ n 2 g c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g and b n c n σ n 2 h c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g this procedure is likewise applied to eq 17 in this case the mse of the estimator will be 24 mse δ t n n 1 a n 2 σ n 2 h n n 1 a n 1 2 c n taking derivative of eq 24 with respect to a n leads to 25 mse δ t a n 2 n n 1 a n σ n 2 h 2 n n 1 a n 1 c n by equating eq 25 to zero and solving for a n we obtain 26 a n c n c n σ n 2 h given that the spectral coefficients of our estimators have been estimated optimally according to the quality of the shcs the coefficients could be inserted in eq 14 which is our estimator the final formula combines grace and gldas data consequently the expanded form of the estimator eq 14 could be written as 27 t θ λ n 0 m n n a n t nm h b n t nm g y nm θ λ where 28 a n c n σ n 2 g c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g n n c n c n σ n 2 h n n and 29 b n c n σ n 2 h c n σ n 2 h σ n 2 g σ n 2 h σ n 2 g n n 0 n n as indicated in eqs 28 the spectral coefficient a n has two different formulas for degrees less than n and for those that are greater indeed this coefficient is applied to gldas models which have both lower and higher degrees in eqs 29 the coefficient b n is zero for degrees greater than n given that the grace models are limited to degree n in other words the estimator combines the low degrees of both grace and gldas variables according to their weights while filtering the higher frequency signals according to errors of the models the filtering process is performed through coefficient a n only for gldas models of degrees greater than n t shows the optimal estimator of the combined grace and gldas that produces a high spatial resolution downscaled grace tws anomalies the spatial resolution of the output is completely dependent upon the hydrological model it means that this estimator can be used for any study area and also with any hydrological model in combination with grace the spatial resolution of the hydrological model would limit the final resolution of the downscaled results given that the spatial resolution of the gldas was 0 25 0 25 the resolution of the downscaled grace tws anomalies is also limited to 0 25 0 25 it means that depending upon the spatial resolution of the hydrological model it is possible to produce better resolutions than 0 25 once downscaled tws anomalies are produced the corresponding downscaled grace based gws anomalies can be derived at the same spatial resolution long et al 2013 singh et al 2017 bhanja et al 2018 feng et al 2018 chen et al 2019b frappart et al 2019 rateb et al 2020 wang et al 2020 this is determined by deducing the different hydrological components from estimated variations in grace tws by our method 2 2 3 validation of the approach as mentioned in section 2 1 validation of the approach was performed using 75 in situ observation wells that were available over the province of alberta we performed the validation at three different spatiotemporal levels to illustrate the success of the downscaling approach because the target of the downscaling was to produce gws anomalies monthly at a spatial resolution of 0 25 the first level of the validation was implemented at this spatial scale therefore for each downscaled grace grid cell at 0 25 containing a well we compared grace based gws anomalies to equivalent in situ data during the study period given that the downscaled grace gws anomalies were produced in increments of 0 25 the comparison is performed for each grid cell of 0 25 0 25 containing a well in addition we also combined together the estimated monthly grace gwsa data for all grid cells at the 0 25 resolution during the study period and computed the correlation and rmse with the corresponding in situ data in the second level of validation we partitioned the area into 8 grid zones of 2 2 see fig 1b this artificial division was only meant to have zones containing several wells since the wells do not cover the whole province and are mainly distributed in the southern part of the province validation was performed in each zone based upon the average of the wells that they contain in the third and final validation level the monthly averages of all 0 25 0 25 grid cells containing all wells were validated against the corresponding monthly averages of the data from the 75 wells during the study period note that gwsas from the wells are available on a daily basis therefore they must be averaged monthly to the same temporal resolution as the downscaled grace based gwsas from february 2003 to the end of 2016 3 results in this section errors of the gldas model are presented followed by the global mean square errors of the estimator the downscaled results tws and gws anomalies are then presented in order not to place an undue burden on the reader we have limited graphical presentation to four selected representative months the final part of the section is about the validation 3 1 errors associated with the gldas land surface scheme to illustrate the applicability of the error estimation method that is presented in section 2 2 1 the condition adjustment model eq 1 was first used after performing the adjustment process a posteriori variance factor was estimated using eq 7 after which the error of the model was computed by taking the global square root of this variance as summarized in section 2 2 1 this process has been applied individually to all gldas products that were considered in the study the computation was performed for all months in the study period between 2003 and 2016 only results that were related to tws are shown here since the latter is the final variable of interest from the gldas model to simplify their presentation the results are graphically illustrated for four selected months i e may 2004 november 2006 july 2010 and october 2015 fig 2 these months were selected for the following reasons we wanted to demonstrate that our approach could work in any year therefore we selected different years between the early and ending periods of grace by selecting different months within the year we wanted to show that our approach is not dependent upon season in these four months that were selected for illustration the maximum errors of gldas tws anomalies are about 4 mm 5 mm 8 mm and 7 mm respectively these values are equivalent to respectively 4 4 9 and 4 of gldas tws for the different months considered generally errors are smaller over the southern and northwestern parts of the area but large errors are mainly seen in the northeast except in july 2010 where errors are larger in the north central part and in october 2015 with larger errors in the west it should be stated that the purpose of presenting fig 2 is to indicate the patterns of uncertainty over the area and to show that they do not follow a clear specific pattern the comparison of the errors in gldas and grace shows a sinusoidal behaviour with an uncertain temporal pattern in gldas errors figure not shown here however the reader can consult fatolazadeh and goïta 2022 for more details the error in grace tws increases towards the end of the twin satellite mission the maximum error found for gldas was 24 mm which is slightly lower that of grace about 29 mm in the four months that were considered grace tws errors varied from 14 mm to 20 mm and were significantly higher than those of gldas 3 2 global root mean square error of estimator the global root mean square error rmse of the estimator eq 27 is presented for degrees 60 by eq 18 and for 60 by eq 23 in fig 3 the rmse uniformly decreases with increasing degree as expected indeed the inclusion of more degrees in the estimator adds more information to the optimization problem while reducing the truncation error of the estimator based on the least squares principle the error should decrease when more data are used and this plot confirms the appropriateness of estimator performance it also shows that rmse is about 50 mm which decreases to about 5 mm when the signal is considered to degree 360 3 3 downscaled grace twsa fig 4 shows the map of gldas twsa a1 b1 c1 and d1 grace twsa a2 b2 c2 and d2 before downscaling and grace twsa a3 b3 c3 and d3 after downscaling at a resolution of 0 25 0 25 using the spectral integral estimator over the canadian prairies results are illustrated only for the selected four months it must be noted that the spherical harmonic analysis and filtering were applied to gldas variables to extract twsa consistent with grace twsa before downscaling our goal here is to show that the method is successful and could deliver the expected spatial variability hydrological interpretations are beyond the scope of this study in may 2004 gldas twsa fig 4a1 shows some pattern similarities with both grace twsa before fig 4a2 and after downscaling fig 4a3 in manitoba and from the centre to the north in saskatchewan as well as the south in alberta however there is a clear difference between gldas and grace in northern alberta overall downscaled grace twsa exhibits a lower positive range maximum about 63 mm compared to both grace before downscaling and gldas maximum 110 mm the comparison of grace twsa maps before and after downscaling fig 4a2 and 4a3 in may 2004 shows that more detailed information is visible in the downscaled tws anomalies generally negative twsa values are seen in the southwest while higher positive values are observed over the northern part of the region after downscaling some high anomalies are seen around 50 n and 97 w and 58 n and 105 w which were also evident in the grace twsa prior to downscaling in november 2006 the spatial patterns that were found with gldas fig 4b1 grace before downscaling fig 4b2 and grace after downscaling fig 4b3 have several similarities the value ranges in all cases are quite comparable 59 mm to 57 mm for gldas 82 mm to 67 mm for grace before downscaling and 70 mm to 50 mm after downscaling the major differences occur in northern alberta where gldas values are all positive in this area the downscaled grace twsa map exhibits also some positive patterns and is visually in better agreement with gldas contrary to the grace map before downscaling more interestingly specific patterns were revealed by the downscaling process fig 4b3 for instance higher values are seen around 53 n and 116 w after downscaling which were not previously visible in july 2010 the correspondence between gldas twsa fig 4c1 and grace twsa before downscaling fig 4c2 is quite remarkable with a north south gradient showing negative values concentrated in the north changing gradually to positive values in the south the downscaled twsa fig 4c3 also shows similar patterns especially in the southern part however greater variability can be seen moving northward contrary to the homogeneous negative tendency that is shown in fig 4c1 and 4c2 quantitatively all three products have very similar value ranges in october 2015 high positive values of grace twsa are concentrated towards the west before the downscaling fig 4d2 a roughly similar pattern can be observed following downscaling but there is greater variation in the east fig 4d3 the similarities between grace twsa fig 4d2 fig 4d3 and gldas twsa fig 4d1 patterns can be observed in saskatchewan and to a lesser extent in manitoba however there is a significant difference between grace and gldas in alberta particularly from the centre to the north where gldas shows only negative values while grace indicates the opposite 3 4 downscaled grace derived gwsa determination of groundwater anomalies from the downscaled twsa can be achieved by employing eq 1 and solving for t gw in other words the signals for sm t sm swe t swe and can t can are removed from the downscaled t tws fig 5 shows the results of gwsa over the study area for the purposes of illustration the results are shown for the four months selected before solving for t gw i e may 2004 fig 5a november 2006 fig 5b july 2010 fig 5c and october 2015 fig 5d the patterns that are visible on the map of gwsa for may 2004 fig 5a are quite similar to those on the corresponding twsa map fig 4a3 although positive gwsa values 50 mm are more strongly pronounced in the eastern part of the area fig 5b and its correspondent fig 4b3 show that in november 2006 positive gws and tws anomalies are present in central saskatchewan maximum about 20 and 40 mm respectively and in northern manitoba yet negative values are dominant in western alberta 90 and 60 mm respectively in july the patterns of twsa fig 4c3 and gwsa fig 5c are different gwsa displays weak values 20 mm over alberta and southern saskatchewan overall twsa ranges from 80 to 40 mm fig 4c3 while gwsa varies from 30 to about 120 mm fig 5c this shows the influence of the total effect of soil moisture snow water equivalent and canopy water on leaf on conditions in october 2015 twsa has large and positive values in the western portion of the prairies fig 4d3 the corresponding gwsa also shows positive patterns in that region but appear to be mostly negative in the east fig 5d overall the spatial output maps of gwsa mainly show a decline in the southern portions of the prairies i e the cold semi arid steppe region known as palliser s triangle about 50 mm 30 mm and 10 mm in may 2004 november 2006 and july 2010 respectively groundwater depletion in the area is due to the arid conditions and dry climate resulting from frequent droughts which in turn affect crop production mondal 2021 morgan et al 2021 3 5 validation to validate downscaled grace gws anomalies and to demonstrate the successful performance of our estimator 75 in situ wells across alberta were used in each validation level we used pearson correlations and rmse metrics in the validation process in the first stage the comparison was done at the resolution of 0 25 to be consistent with our downscaling results in each grid cell of 0 25 containing a well the validation was done by comparing the estimated gws anomalies to the equivalent well data see section 2 2 3 since we cannot show all 75 time series for each piezometric well location only statistical metrics of the comparison are presented in table 1 significant correlations at 95 confidence level varying from p 10 4 to 0 04 were found between grace derived gwsa and in situ data for 71 of 75 well locations i e 95 of the wells the range of rmse that was found is between 18 mm and 29 mm in contrast correlations between gldas gws anomalies and in situ wells data appear to be mostly non significant for 88 of the well locations with a greater rmse range from 25 mm to 60 mm statistical metrics showed that our method performed better than gldas and had greater consistency across wells table 1 this performance was also confirmed when all the data from all the individual grid cells at 0 25 resolution containing wells during the study period were combined together to compute the statistical metrics as explained in section 2 2 3 indeed a significant correlation r 0 52 and rmse 24 3 mm were found in this analysis which was based on a total of 12 525 data points these metrics are significantly better than the corresponding results with gldas r 0 39 rmse 35 2 mm as shown in the bottom of table 1 in the second level of validation the average values of the wells in each of the 8 grid zones that were considered are compared to those from the grace gwsa before downscaling by subtracting gldas sm swe and can from original grace twsa the downscaled grace gws and gldas gws anomalies see explanation in section 2 2 3 fig 6 shows gwsa temporal variations before and after downscaling with the corresponding gldas and monthly averaged piezometric wells over the eight zones during the study period the statistical metrics of the comparison are shown in table 2 correlations that were found by comparing the downscaled grace gws anomalies to well data vary between 0 53 and 0 84 and all are significant at 95 for all zones accordingly rmse was between 14 mm and 23 mm lower correlations were obtained in zone 1 zone 4 and zone 7 0 53 0 66 and 0 55 respectively the low correlation in zone 1 could be due to the limited number of wells that were available over the area only 2 wells in zone 4 and zone 7 the presence of the rocky mountains and the dominant brunisol and regosol soil types in this area could explain the low correlations the remaining zones display higher correlations and low rmse r 0 70 rmse 18 mm the large number of wells that were available in these zones may partly explain the better metrics that were found interestingly the statistical metrics found when downscaled gwsa are compared to in situ data are far better than those obtained in comparing gwsa before downscaling to in situ wells see table 2 both in terms of correlations 0 53 to 0 84 versus 0 34 to 0 77 and rmse value range 14 mm to 23 mm versus 21 mm to 37 mm these results further indicate the effectiveness of the downscaling process the comparison between wells and gldas gws anomalies shows correlations and rmse ranging between 0 01 and 0 89 and 17 mm and 34 mm respectively there is no correlation between the gldas gwsa variations with those of wells in zone 1 given the insufficient number of wells low correlations were also obtained in zones 2 and 4 with highest rmse 31 mm for half of the zones the metrics that were found with gldas are comparable to those found with downscaled grace based gwsa the lack of agreement with gldas may be due to the deficiency in input and calibration data model structure and variables in the last validation level the comparison was performed between the averages of all 75 wells and respectively the averages of the gridded 0 25 0 25 grace gws before the downscaling the averages after the downscaling and the averages of gldas gws anomalies across alberta fig 7 shows the time series of these variations in contrast to grace a pattern of low consistency can be seen between gldas and wells especially at the beginning 2003 2006 and end 2015 of the period the statistical metrics are summarized in table 2 last row results of downscaled grace based gwsa are significantly correlated with well data r 0 80 p 0 0004 at 95 confidence compared to grace gwsa before downscaling r 0 42 and gldas gwsa r 0 41 rmses that were found with grace before downscaling and gldas are nearly double the value with downscaled grace 21 24 mm versus 11 mm these compelling metrics give us confidence in our proposed spectral combination method for downscaling grace data 4 discussion possessing knowledge of data quality and uncertainties associated with the given variable fields that were provided by the hydrological models gldas in our case is tremendously important when our spatio spectral twsa estimator is used fortunately the approach that is presented in section 2 could be a suitable method for estimating the internal quality of these models thus the method is applicable to all types of hydrological models containing tws information the greatest computational challenge is related to the spherical harmonic sh analysis of errors for the gldas variables which should be done for each degree and order individually nevertheless a proper vectorization algorithm could substantially reduce the computational time briefly uncertainties in the gldas model could be due to different problems for instance difficulties in modelling the process of water circulation in areas with frozen soil discrepancies in the amplitudes of the individual hydrological variables ablation at near freezing temperatures and difficulties in modelling biological processes that characterize the plant canopy long et al 2014 bi and ma 2015 kim et al 2015 han et al 2021 the estimator variables i e eqs 28 and 29 can be simply determined from errors of the shcs of grace and those that were computed by the condition adjustment method in section 2 in addition the true degree variance of the hydrological signal is required given that the estimator uses it to filter the noise in the tws in this case each hydrological variable can be used in the land surface schemes over the study period our estimator combines the low frequencies of grace and gldas that are optimally based on their error degree variance and high frequencies are removed from the gldas land surface models after filtering out their noise based upon signal to noise ratios in the spectral domain the spatial resolution of the downscaled twsa depends upon the resolution of the gldas model i e 0 25 0 25 this corresponds to the degree and order of 720 in the sh expansion a maximum degree of 360 has been considered for these models in our computations due to the tremendous computational burdens that are imposed by the errors in the shcs consequently it introduced a limitation to effectively completing high frequency and simulating ultra short wavelength parts of regional hydrological variables lu et al 2000 the most substantial difference between our proposed approach and artificial neural network methods can be seen when optimizing the errors more precisely in previous methods lavado et al 2006 seyoum and milewski 2017 miro and famiglietti 2018 the closest and minimum error between grace and other input data are found by changing the input variables randomly the input model requires initial values for optimization processing yet there is no unique answer among these kinds of approaches in contrast our proposed method focuses on low and high frequencies of the input variables in combination with grace frequencies to find the optimum errors therefore it is a unique method that can be used with any input data or initial data moreover our proposed approach is not dependent upon location and can be potentially applied to different areas of the world with different climate and topographic conditions we applied the proposed method to all monthly data that were available during the study period which were considered in the canadian prairies yet visual performance of the approach is illustrated only for four months to limit space requirements july 2004 november 2006 july 2010 and october 2015 see figs 2 4 and 5 other months could have been shown as well in most months a pattern was observed for palliser s triangle which is the driest part of the canadian prairies brown soil zone parkland and mixed grassland ecoregion marchildon et al 2016 gwsa can be obtained simply by subtracting the signals of soil moisture snow water equivalent and canopy water from the downscaled twsas that were estimated by our method fig 5 a major limitation in using gldas is the absence of a surface water component goddard earth sciences data and information services center ges disc this component is taken into account during the theoretical development of the approach section 2 due to the lack of data in the gldas land surface model that was used in this study we neglected it during the application phase of the approach therefore the lakes and rivers that are situated in the canadian prairies have no data and were allocated nan value see figs 2 4 and 5 our previous studies indicate that surface water component is nearly negligible over most parts of the canadian prairies fatolazadeh and goïta 2022 especially over the province of alberta where the downscaled gwsa were validated the most dominant factors defining tws in the region remain soil moisture snow water equivalent and groundwater despite the different limitations correlations that were found with in situ wells are significant at 95 confidence 0 53 0 84 in the different validation zones that were considered figs 6 7 table 2 as shown in table 2 the correlation r 0 80 that was found over the province of alberta by considering all downscaled grace cells with their corresponding monthly well data is quite convincing especially the associated low rmse of 11 mm in contrast metrics found with gldas are low r 0 41 rmse 23 7 mm this could be due to the phase difference between well station measurements and model estimates rzepecka and birylo 2020 it should be noted that wells are not uniformly distributed over the province they are concentrated mainly towards the south further work is required for a broader validation of the proposed approach 5 conclusion in this study a new approach was introduced and employed to retrieve downscaled terrestrial water storage tws and groundwater storage gws anomalies using grace and gldas data for the period between february 2003 and december 2016 a new condition adjustment method was developed to estimate uncertainties of gldas data without requiring extra information estimated uncertainties reached a maximum about 10 mm during the entire period of the study particularly in the southern canadian prairies a twsa estimator was developed based upon spectral combination theory to weight spectrally both grace and gldas models and to combine them optimally this approach permits retrieval of downscaled gwsa from twsa with a spatial resolution 0 25 0 25 compared to 3 3 for original grace data visually maps of downscaled gwsa revealed greater detail and variability as expected indicating that the approach successfully captured high frequencies significant higher correlations and low rmse values were found during quantitative validation of the downscaled gwsa compared to in situ well piezometric data confirming success of the spectral combination method that was proposed application of the approach using other hydrological models together with further validation with more well data in different environments is envisaged for future research data availability spherical harmonic coefficients of release 06 grace are available at http icgem gfz potsdam de series 01 grace csr csr 20release 2006 hydrological variables of the gldas clsm025 da1 d 2 2 can be downloaded from https disc gsfc nasa gov datasets gldas clsm025 da1 d 2 2 summary keywords gldas information on in situ observation wells located in alberta can be downloaded from https www alberta ca lookup groundwater observation well network aspx credit authorship contribution statement farzam fatolazadeh conceptualization software writing original draft mehdi eshagh methodology writing original draft kalifa goïta writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was funded by the université de sherbrooke excellence scholarship program and the natural sciences and engineering research council of canada nserc discovery grant number rgpin 2018 06101 nserc create grant 543360 2020 we thank all data and products providers university of texas at austin natural resources canada and the goddard earth sciences data and information services center we gratefully thank for all valuable suggestions from two reviewers and joh editorial team which help us improve the manuscript significantly we thank w f j parsons for correcting the english 
