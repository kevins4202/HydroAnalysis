index,text
22710,in this paper a novel method is presented for detecting anomalies in ocean fixed point observing time series which combines wavelet neural network wnn classifying threshold and two detecting strategies the wnn was developed without any labeled training data to simulate the non anomalous behaviors for next step prediction the classifying threshold was constructed according to the estimated distribution of long term historical residual errors the observation strategy os and prediction strategy ps were designed to detect new unknown anomalies two types of marine observing time series from a buoy deployed at the national ocean test site of china were selected for verifying the method the results show that 99 of classifying confidence level is adequate to provide a reasonable trade off between the false negative and false positive by using the two detecting strategies and selecting proper estimated distribution of the threshold the method is efficient for identifying the anomalous points and patterns which were caused by the natural factors or equipment failures compared with traditional ann and wavelet ann the wnn based method is more tolerant to noise and more sensitive to anomalies with temporal dependencies furthermore this approach introduced here can work in a real time way and will help ocean engineering managers to obtain informed decisions keywords ocean observing series anomaly detection wavelet neural network wnn ocean engineering 1 introduction ocean engineering is vulnerable to the effects of wind current wave internal wave and other environmental factors the design and site selection stage of ocean engineering projects requires analyzing long term historical ocean observations and subsequent construction and operation stage needs real time monitoring on the surrounding marine environment ocean observing system oos is an important means for acquiring marine data in which in situ ocean sensors and instruments operate under harsh conditions including high humidity salt fog and vibration wang et al 2015 besides the acquired data must be transmitted via communication networks koack and clark 2013 thus the data series can easily become corrupted and cause anomaly there is no universally accepted definition for an anomaly kanarachos et al 2017 generally anomalies can be categorized into two types outliers data points that differ greatly from others in the data set hawkins 1980 and anomaly patterns a small fraction of data which are different from the majority others such as special fluctuations shapes and trends due to different generation mechanisms which always provide more information than the single points ren et al 2017 in ocean observing system anomaly refers to specific observing data that do not conform with the normal behaviors which may derive from the marine environment or oceanic phenomena beltrami 2011 or may be caused by equipment failure hassani et al 2018 therefore it is very important to detect anomalies in oos as early as possible to avoid big losses from total machine failure or even natural disasters traditionally anomaly detection has been implemented manually relying on visualization tools whereas artificial methods are only suitable for finding extreme points and swings in data stream and inconvenient in real time checking hill and minsker 2010 mechanism models are also employed to detection anomalies cho et al 2018 however the marine system is characterized by complex interactions among different dynamical and random processes so there still lacks the mechanism models that can accurately describe the behavior of the system therefore a number of data driven methods capable of using and handling the historical observing data baldacci et al 2016 habeeb et al 2019 have been widely applied to anomaly detection in recent decades data driven anomaly detecting approaches can be roughly classified into two types statistical techniques and machine learning methods the statistical type usually develops statistical model based on the given data that assumed to be normal and then applies the hypothesis test to detect whether a data belongs to this model or not wu et al 2018 the statistical techniques usually contain parametric and non parametric methods parametric methods estimate the model parameters by the given data because they suppose the normal data follow an underlying distribution then the anomaly score can be estimated by deviations ye and chen 2001 or error residuals bianco et al 2001 akouemo and povinelli 2016 on the contrary non parametric methods just construct the model based on the given data merkl and holzapfel 2018 for instances a histogram based anomaly score method builds a histogram using the feature values of training data and then checks all bins if a data fall in goldstein and dengel 2012 the statistical anomaly detection techniques can provide a statistically significant solution and has the ability to detect unseen patterns nevertheless they commonly require large amounts of data and do not perform well when the predefined distribution does not hold true when directly used for anomaly detection machine learning methods typically develop classification model based on the training data marked anomalous or non anomalous the model can classify a new data into anomalous class or not landauer et al 2018 there are various of prominent classifier algorithms such as k nearest neighbors tran et al 2019 decision tree benkercha and moulahoum 2018 support vector machine tian et al 2018 and artificial neural network mekki et al 2016 the classification methods can classify the anomalous class accurately if there are enough training flagged data however in the cases of ocean observing system few or even no anomaly label is available in the historical data because it is probably not to mark enormous amount of points in the streaming data furthermore new unknown anomalies may emerge in marine system so there is no such type of labeled training data besides some classifier models e g distance based knn or one class svm may be difficult to detect periodic and seasonal anomalies since they cannot capture the temporal dependencies across different time steps to incorporate time series characteristics there exist many temporal prediction based anomaly detection methods they usually do not assume the properties of the data distribution and not need labeled data in this type autoregressive integrated moving average arima is a typical model to perform anomaly detection with temporal dependency for example arumugam and saranya 2018 presented an arima based anomaly detection technique for monthly rainfall data yu et al 2016 proposed a technique for traffic control in wireless sensor networks which identified the anomalies by comparing the actual and the predicted signals by arima model yaacob et al 2010 introduced a diagnostic procedure for early detecting network attacks by arima errors however these models are sensitive to noise thus probably increasing false positive results when the noise is severe to address such an issue wavelet techniques were employed and integrated with neural networks for analyzing variations and periodicities of the time series in recent years the main type of anomaly detection applications is wavelet reconstruction method which applies wavelet basis functions wbf as preprocessing tool to decompose the original dataset at multiple scales and then the sub components are analyzed by different neural networks for instances mandrikova et al 2017 presented a hybrid anomaly detecting system based on a combination of wavelets and neural networks different scale components of ionospheric data series were analyzed by regression neural network models and results proved the joint method could detect long periods of disturbances in the typical variation of ionospheric parameters kanarachos et al 2017 proposed an abnormal patterns detecting method that combined wavelets neural networks and hilbert transform after wavelet decomposition for each scale subset a standard artificial neural network ann is trained for identifying the temporal structure of the signal detail sanz et al 2007 combined the capability of wavelet transform to treat transient signals with the ability of auto associative neural network for diagnosing faults of rotating machinery despite the noises in both cases the method can be a good alternative as a diagnosis tool shi et al 2018 applied wavelet ann model for detecting water quality anomalies after wavelet decomposition and de noise a low frequency signal was imported into ann for one step prediction to identify the major features of water quality variations vahidi et al 2010 also presented a hybrid approach using artificial neural networks and the discrete wavelet transform dwt for detecting high impedance faults dwt was used to decompose the distorted signal and to extract its useful information feature vectors were created and applied in training the ann in general the advantages of wavelet reconstruction methods are obvious the training process of anns or the latter detecting process become easier because the signal s short and long term temporal structure at different scales are more significant than the complete series however wavelet reconstruction methods may be difficult to work online because they usually need to train anns for the selected appropriate components and then combine them which are labor intensive and time consuming even though some scales are not informative in many real world applications another type is based on wavelet neural network wnn which employs the wavelet basis functions wbf as a transformation function in the hidden layer of standard ann model zhang and benveniste 1992 this type used wnn as the above mentioned classifier in many anomaly detection domains such as civil infrastructure condition assessment turkan et al 2018 and network intrusion detection alarcon aquino et al 2014 huang et al 2017 liu and liu 2009 on the other hand many studies have emphasized that the wnn as a regression model takes the advantage of the self organizing of ann and time frequency properties of wbf qi et al 2016 santhosh et al 2018 tealab 2018 and performs better than conventional ann wang et al 2013 using wnn as a predictor is becoming a new research branch in the field of anomaly detection for example wan et al 2018 proposed a wnn based approach for detecting cyber intrusions and anomalies in industrial function control process the wnn was developed to simulate the normal function control behaviors and then was applied to calculate the detection threshold and predict the time related function control characteristics the approach demonstrated the wnn could use raw data and had adequate real time capability in many real world applications although observing systems acquire data continuously using automatic sensors the full benefits of real time observation would not be achieved without real time analysis ahmad et al 2017 shi et al 2018 ocean observing system oos also needs fast anomaly detecting methods besides the time series of some marine parameters are probably non stationary veltcheva and soares 2015 thus the wnn based method is given priority to study ocean observing time series the main contributions of this paper are a novel wnn based method is formulated for detecting anomalies in ocean fixed point observing time series which is capable of identifying anomalous points and patterns that are caused by the natural factors or equipment failures we simulate the normal behaviors of ocean observing system in which anomalies are rare so no labeled training data are needed besides the anomalies classifying threshold is determined by the distribution of historical residuals to find new unknown anomalies two detecting strategies i e observation and prediction strategy are designed and the proposed method is can work in real time the rest of paper is organized as follows firstly we present an identifying framework that combines the wnn classifying threshold and two detecting strategies then the application of the method in the case of national marine test site of china is described furthermore results are analyzed and discussed in the aspects of detecting strategies prediction levels and reliability of prediction finally conclusions are drawn 2 methods 2 1 framework for identifying anomalies in ocean observing data series the proposed anomaly detection method of ocean parameter observing series mainly includes the following four steps beginning at time t shown in fig 1 step 1 for a marine variable e g surface current speed salinity water temperature etc series a moving window of related l time delay points is analyzed and determined denoted as w l t x t l x t 1 x t x t is the observed value in time t then a wnn based one step ahead prediction model is developed and w l t is used as input to predict xp t 1 the expected value of the sensor measurement at time t 1 step 2 the residual error sequence r h re t n re t 1 re t between historical observations x t and model predictions xp t is calculated then the probability distribution of r h is estimated and the corresponding confidence level e g 95 threshold for classifying anomalies is constructed step 3 upcoming observing value xp t 1 is predicted from the wnn model in a real time manner when the observation x t 1 at the time t 1 arrives from ocean instruments the residual error re t 1 is compared to the threshold and the point x t 1 is classified as anomalous if the re t 1 exceeds the threshold otherwise it is identified as non anomalous step 4 under the observation strategy os w l t is modified by removing x t l from the back of the slide window and adding x t 1 to the front of the w l t to generate w l t 1 under the prediction strategy ps if the observed x t 1 is flagged as anomalous w l t 1 is iterated by removing x t l and adding xp t 1 to the front of the w l t then step 3 and step 4 are repeated 2 2 wavelet neural network prediction model for ocean observing time series 2 2 1 model structure wavelet neural network wnn applies wavelet basis function wbf as the activation functions in the hidden layer of the ann the traditional artificial neural network ann model is essentially a feed forward multilayer perceptron ann is generally comprised of three distinctive layers i e input hidden and output and the neurons in each layer are disconnected from each other but the neurons from one layer are connected to all nodes in the adjacent layers and only affect the state of neurons in the next layer similar to ann the model structure of typical three layers wnn is shown in fig 2 the input signal is processed layer by layer from the input layer to the output layer then the output x t can be calculated by eq 1 1 x t j 1 j w j k ψ i 1 i w i j w l t 1 i b i b j where w ij is the connection weight between the ith node of input layer and the jth node of hidden layer and w jk is the weight between the jth node of hidden layer and the kth node of output neuron x t is the output value and b is the bias i and j are the respective number of neurons in input and hidden layers and w l t 1 i is the model input variable ψ is the wavelet basis function in the hidden layer wbf is effective to analyze the non stationary time series and a series of wavelets ψ a b can be computed by eq 2 2 ψ a b x a 1 2 ψ x k a where a is the scale parameter representing expansion a 1 or compression a 1 k is the shift parameter for wavelet function ψ is the mother wavelet i e wbf 2 2 2 choice of the mother wavelet there are several types of wbfs available with different characteristics such as morlet mexican hat and daubenhies the choice of the wavelet mostly depends on the particular application one has in mind to study signal representation classification and feature extraction of time series there are three sensible ways i e peak frequency energy frequency and central instantaneous frequency to convert wavelet scales into frequencies aguiar conraria and soares 2010 the morlet wavelets have widely used in recent decades because in the case of the morlet wavelet these ways are all equal facilitating the conversion from scales to frequencies besides the morlet wavelet has optimal joint time frequency concentration mezghani et al 2011 and the time radius and the frequency radius are equal therefore this wavelet represents the best compromise between time and frequency concentration the mexican hat eq 3 and a central symmetric wavelet eq 4 to compare with the morlet wavelet eq 5 and the results demonstrate that the morlet wavelet has better performance in the proposed method for predicting ocean observing series see supplementary materials part i 3 ψ t e t 2 2 1 t 2 4 ψ t t e t 2 2 5 ψ t e t 2 2 cos c t according to szu et al 1992 and wan et al 2018 c is 1 75 but the c 5 is recommended by daubechies 1994 2 2 3 inputs and outputs as shown in fig 2 the expected measuring value xp t 1 in time t 1 is the output and the input is the moving window w l t which is comprised of some related time delay points of x t 1 sudheer et al 2002 suggested that the statistical approach depending on cross correlation autocorrelation acf and partial autocorrelation pacf of the observed time series data is a good alternative to the trial and error method in identifying model inputs the statistical method was also successfully employed to various applications kisi 2008 tiwari and chatterjee 2010 wu et al 2009 wang et al 2013 the essence of this method is to examine the dependence between the input and output data series according to this method for ocean observing time series the acf and pacf are used to determine the potential time lags as input variables in w l t 2 2 4 model training method typical back propagation bp algorithm is used to train the model the signal is transmitted forward from the input layer to output layer and the error back propagation will occur if the expected output cannot be obtained then the gradient descent with momentum algorithm is applied to modify all parameters of wnn which are computed as 6 λ r 1 α λ r η e g λ r 7 e g 1 2 n 1 n x p t x t 2 where the λ represents the parameters e g w ij w jk a k of the wnn model xp t and x t are the model output and the object values n is the number of samples in training datasets and r α η is the iteration time momentum and learning rate of train process respectively the error goal of target training is set to 10 5 and the maximum number of epochs is 1000 training stops when any of the two conditions occurs there are total five training parameters tuned in relation to the available training data see table 1 the training parameters are selected based on the experiences of previous neural network studies and determined by trial and error 2 3 classifying threshold based on residual error distribution the performance of forecasting model can be analyzed by residual error between predictions and original observations hypothesis testing is used to determine the maximum likelihood distribution of residuals generally residual error sequence r h follows a certain distribution e g normal logistic gamma etc and the probability distribution of r h can be estimated by the goodness of fitting approach then the corresponding prediction level threshold for classifying anomalies can be constructed by eq 8 note that eq 8 is mainly designed for the two parameter distributions the threshold is used to distinguish whether the ocean observing observations belong to the background interval or are abnormal 8 t h r e s h 1 2 μ ln p up 1 p up s μ ln p down 1 p down s where μ and s are the parameters of distribution for instance μ and s are the mean and scale factor for logistic distribution in addition p up represents the classifying level e g 95 99 99 5 etc and p up p down 1 2 4 detection strategy to find new unknown anomalies two detecting strategies i e observation strategy and prediction strategy are designed that the proposed method can work in an unsupervised setting once an anomalous data point is classified two alternative detection strategies i e observation strategy and prediction strategy for updating new moving widow are compared the purpose of os is to keep the objectivity of data sequence so the os simply proceeds to forecast the next chronological data point using the newly observations as model input even though these observations are marked as anomalous due to the wnn developed to simulate the normal behaviors of the system another strategy ps proceeding to forecast the next chronological data point using the predictions of data driven model as input is designed to avoid the collapse of detection system caused by long term continuous observation anomalies actually the faults of measuring sensors or instruments may have the characteristics of graduality and irreversibility such as drift biological attachment aging power instability venkatesan et al 2016 2 5 study area and data ocean buoys are widely used in fixed point observation for they could obtain data for longer periods wang et al 2015 met ocean data buoy deployed at the national ocean test site of china was selected for testing the anomaly detection method see fig 3 two kinds of ocean parameters datasets from the buoy were selected to conduct research surface salinity ss was measured using the ctd manufactured by the seabird company and surface current speed scp was collected by nortek s aquadopp for each parameter there are in total 7500 samples collected within a time interval of half an hour the data set was divided into two subsets the training dataset 5000 samples from 11 30 january 24th to 8 30 may 22nd including training data and cross validation data was applied as the background to train the wnn great care was taken so that no anomalies were included in the training set the rest samples from 9 00 may 22nd to 3 30 july 17th and from 17 00 june 26th to 6 00 july 31st were used for testing the proposed method 3 results and discussion the acf and pacf of the two ocean observing parameters are shown in fig 4 fig 4a shows that the pacf within the confidence band occurs at lag 3 and lag 7 for ss series so the t 1 and t 2 in addition to the t 4 t 5 and t 6 are selected as the main relevant lags note that some more relevant lags such as t 9 or t 14 are rejected because they can reduce large amount of training data samples thus the moving window for ss is determined to w ss t 1 x t 6 x t 5 x t 4 x t 2 x t 1 similarly the main relevant lags are t 1 t 3 t 4 and t 5 for scp see fig 4b correspondingly the moving window for scp is set as w scp t 1 x t 5 x t 4 x t 3 x t 1 afterwards the wnn was trained from 2 to 15 hidden neurons and a better model structure was obtained with the minimum training error eg three confidence levels the 95 99 and 99 5 were selected for residual error distribution to classifying anomalies and the fitting of residual error sequence r h between the 5000 historical observations and model predictions was implemented by using normal distribution nd and logistic distribution ld the results of abnormal detection for ss and scp observing series under two detection strategies i e os and ps are shown in table 2 false negative fn means the actual anomaly observations identified as normal by the proposed method and false positive fp represents non anomalous points estimated as anomalous 3 1 influence of detection strategies for ss series some sudden changes in residual error re series can be detected under both two strategies see fig 5 while the false positive rate are lower with os than with ps see table 2 note that the res of ss are bigger than the threshold value near the time 22 00 in may 29th and 21 00 in july 13th actually the weather was a shower on may 29th and rainstorm on july 12th in 2015 nmic 2019 it is probably that the rain caused a drop in the value of surface salinity for a short time generally the ss value trends gradually decreased from may to july because of the increasing precipitation during summer the abnormal salinity values caused by short term heavy rainfall did not exceed the minimum of the whole observation sequence ranging from 30 34 to 31 68 which means that they cannot be effectively identified with traditional statistical methods this type of anomaly can be detected because the anomalous data caused by natural factors e g rainstorm have the characteristics of drastic change and recoverability i e most natural abnormal events occur sporadically and last for a short time in this type the observations are returning to normal in a short time under os just a few untrained error measurements have been added to the inputs into the wnn model for the next step prediction afterwards the input window w l would gradually consist of all non anomalous observations and the residual error decreases within the threshold zone see fig 5c when using ps the input w l t x t l x t 1 x t consists of non anomalous observations before abnormal alarm triggered see fig 1 and the model performed well see fig 5b therefore the trained wnn model is prone to represent the normal behaviors of the system correspondingly the w l t is used to predict xp t 1 which is supposed to be non anomalous and the wnn predictions are also supposed to be non anomalous in a short period thus these suddenly decreased observations can be detected due to residual errors exceeding the threshold the os and the ps can both effectively classify the anomalies caused by natural factors with sporadic and restorative features for scp series the false negative rate by the proposed method has been greatly reduced by using ps compared with applying os see table 2 as shown in fig 6 the scp sequence began to become smaller in june 28th and then maintained a lower level which can be attributed to serious adhesion of marine organisms to the sensor in summer a phenomenon found during the maintenance period the persistent anomalies caused by equipment failure cannot be identified by os and the anomalies detected by os some time earlier may be caused by natural factors or false positives because the anomalous data from equipment failures e g power supply instability instrument aging drift generally has the characteristics of irreversibility and often lasts for a period of time after gradual or sudden change venkatesan et al 2016 when using os for detecting these persistent anomalies it would inevitably affect the accuracy of prediction and induce a negative impact on the classification of anomalies due to introducing untrained error measurements as inputs into the wnn model for the next step prediction once the error measurements are judged as normal points errors will accumulate continuously with sustained input of anomalies i e error measurements for anomalous sequence caused by equipment failure the predicted value using ps is more accordant with the non anomalous sequence before the failure occurs so the residuals with series of measurements accumulate rapidly after the beginning of the anomaly and then rise to a relatively stable interval with small oscillation see fig 6d which represents the significant difference between the sequence with equipment failure and that with no failure therefore wnn ps can effectively identify the anomalies caused by equipment failure in comparison with wnn os from an overall view os can be adopted to appropriately reduce the false positive rate of abnormal detection for both sequences occasional anomalies caused by natural factors such as the case of ss series can be identified better by using os while applying ps is better for identifying the persistent anomalies caused by equipment factors such as the case of scp series using model predicted value as the model input ps may lead to time series smoothing toward the center which is more apt to occur especially when the anomaly lasts for a long time and then the sliding window is assumed to be all predicted values rather than actual measurements however it will not significantly affect the detection results and may reduce the false negative rate of persistent abnormal detection caused by equipment failures in scp sequence 3 2 influence of classifying levels the false positive rate decreases when the classifying level increases from 95 to 99 5 while the false negative rate increases see table 2 indicating that 99 of the classifying level may provide a reasonable trade off between false negative and false positive the advantage of using p instead of user defined threshold is to provide a guidance to determine thresholds in the form of predictive levels without requiring any experiential knowledge or parameter measurements based on the wnn model and measurement errors the p classifying level indicates the probability with at least p to accurately predict the sensor s measurement value correspondingly it is expected that 100 p of the non anomalous data will be misclassified as anomalies in practical application actual anomaly observations whose prediction residual errors are larger than the threshold value are more important to classify correctly than those smaller than the threshold anomaly detecting methods by threshold can often easily misclassify both the abnormal value with smaller deviation from the threshold value and the normal value with larger deviation however the results demonstrate that the classifying threshold derived from model prediction can describe the boundary between the normal value and abnormal data take the 99 classifying level with ps as example the logistic error distribution of ss has a mean value μ 0 0004 and a scale parameter of s 0 0092 and for scp μ 0 0037 s 0 0575 then the respective thresholds thresh ss 0 0422 and thresh scp 0 2595 are correspondingly computed according to eq 6 fig 7 shows the residual distribution of both observing time series it can be seen that the logistic distribution is narrower and more centered on the mean than the normal distribution the false positive rate decreases by using normal distribution to ss sequence and important natural factor anomalies can be identified effectively see fig 5c and d so the classifying threshold of normal distribution is suggested when the target is to identify natural anomalies and minimize interference however the classifying threshold of logistic distribution is more effective for small persistent sequence anomalies caused by equipment failures see fig 6d and should be used if events with more abundant variables are need to be identified 3 3 reliability analysis the roc curve has been widely used to evaluate the quality and reliability of algorithms for anomaly detection the coordinate system of roc is composed of abscissa with false alarm rate far and ordinate with probability of detection pd pd is a function of true positive and false negative so the bigger is the better in contrast far is a function of false positive and true negative the smaller is the better the performance of the wnn model is compared with the traditional ann and a wa ann method applying wavelet analysis as a denoising tool of the original observed time series see supplementary materials part ii and fig 8 for detecting ss series the areas under the roc curve of the ann wa ann and wnn are 0 9223 0 9322 and 0 9514 respectively similarly the areas under roc curve are 0 9103 0 9504 and 0 9814 for scp series the results indicate that wnn has the ability to deal with time series with non stationary characteristics and can improve the accuracy of anomaly detection by increasing pd and reducing far in order to verify the performance of anomaly detection the surface water temperature sequence is further analyzed in supplementary materials part iii which shows that the proposed algorithm can effectively recognize such abnormal events comparisons of wnn prediction performance in different observing periods are presented in supplementary materials part iv the wnn model produces good performance over three different time spans but short period of data records may lead to misclassification due to insufficient training dataset for the wnn prediction model besides this method has spatial particularity so the needed historical data to construct the classifying threshold may vary with different spatial locations 3 4 discussion this method can be adopted in many applications including but not limited to marine disaster warning marine engineering and fault prediction of marine observing equipment natural processes like climatic conditions marine environment and equipment factors such as power supply instability instrument aging and drifting can affect ocean observing sequence some new unknown anomalies may emerge at any time so it is more challenging to detect anomalies in ocean observation sequence with appropriate strategies firstly the accuracy of the model has remarkable effect on anomaly detection non stationary data should be adopted when data driven prediction models are used in marine environmental data series i e no change of data intrinsic patterns even though wnn is capable of dealing with non stationary time series well the training dataset of wnn model is needed to be updated periodically because most marine environmental variables might change significantly during a period of time e g 1 day 7 days 30 days or even 90 days model updating can be achieved by periodic retraining that a 30 day to 3 month period may be suitable for training wnn for anomaly detection in routine applications however the data measured by different sensors at different locations should be analyzed to match the training frequencies according to dynamic changes of the sequence note that training wnn requires time consuming calibration of model parameters in real time forecasting scenarios in addition sensor measuring data from the buoy are usually transmitted in small batches rather than one at a time so the retraining only has to be shorter than the interval time of data transmission e g the retaining interval time is less than 30 min in this case on the other hand when the model is relatively complex and requires time consuming a dual backup approach could be considered which means training a new model while the previously developed model can be used for anomaly detection secondly there are uncertainties in the anomaly detection process mainly derived from the model structure training dataset and calibrating parameters beck 1987 indicating that there is also a corresponding confidence level for wnn predictions moreover the function of residual distribution is related to different marine variables and the classifying confidence level p should be suggested based on the trade off between false negative and false positive therefore the anomalies classifying threshold with confidence level p is correlated to the wnn prediction confidence level residual distribution function and historical sequence the classifying threshold can be further optimized with the characteristics of seasonal variation and should be robust and less vulnerable to data fluctuations finally the marine system is characterized by complicated interactions among different dynamical and random processes so there must be some associations between various marine variables in this sense it is very important to systematically study the relationships among multiple marine observing series at one position and the relations between adjacent spatial correlated observing sequences however this paper concentrates on single observation sequence in a fixed site the multi sequence research and more applications studies will be conducted in the near future compared with traditional detection methods including manual visualization expert consultation enhanced safety monitoring and routine fault inspection this method has the advantages of shorter average detection time and lower costs therefore it has great potential value in many applications such as marine disaster warning marine engineering and fault prediction of marine observing equipment 4 conclusions this paper presents a novel method for detecting anomalies in ocean fixed point observing time series wavelet neural network wnn next step prediction model classifying threshold and two detecting strategies are combined wnn is used to simulate the non anomalous behaviors based on the normal variations in ocean observing series two detecting strategies i e observation strategy and prediction strategy are designed to find new unknown anomalies the classifying threshold is determined by the estimated distribution of historical residuals the proposed method is verified by the case of national marine test site of china it is found that the 99 of classifying confidence level is adequate to provide a reasonable trade off between the false negative and false positive by using the two detecting strategies and selecting the proper estimated distribution of classifying threshold the method is efficient for identifying the anomalous points and patterns which were caused by the natural factors or equipment failures the wnn is developed without any labeled training data so the proposed method can work in an unsupervised setting besides compared with traditional ann and wa ann the wnn based method is more tolerant to noise and more sensitive to anomalies with temporal dependencies besides the method performs well over three different periods which demonstrates the reliability of the method however its spatial particularity and short period of data records may lead to misclassification we are working to evaluate the method on multivariate marine variable series and more prediction models and more applications studies will be conducted in the future acknowledgements this study is supported by the national natural science foundation of china grant no 41606118 and also funded by the ministry of natural resources mnr of china we also thank the editor and the previous anonymous reviewers for their constructive comments and recommendations which have significantly improved the quality of this work appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j oceaneng 2019 106129 
22710,in this paper a novel method is presented for detecting anomalies in ocean fixed point observing time series which combines wavelet neural network wnn classifying threshold and two detecting strategies the wnn was developed without any labeled training data to simulate the non anomalous behaviors for next step prediction the classifying threshold was constructed according to the estimated distribution of long term historical residual errors the observation strategy os and prediction strategy ps were designed to detect new unknown anomalies two types of marine observing time series from a buoy deployed at the national ocean test site of china were selected for verifying the method the results show that 99 of classifying confidence level is adequate to provide a reasonable trade off between the false negative and false positive by using the two detecting strategies and selecting proper estimated distribution of the threshold the method is efficient for identifying the anomalous points and patterns which were caused by the natural factors or equipment failures compared with traditional ann and wavelet ann the wnn based method is more tolerant to noise and more sensitive to anomalies with temporal dependencies furthermore this approach introduced here can work in a real time way and will help ocean engineering managers to obtain informed decisions keywords ocean observing series anomaly detection wavelet neural network wnn ocean engineering 1 introduction ocean engineering is vulnerable to the effects of wind current wave internal wave and other environmental factors the design and site selection stage of ocean engineering projects requires analyzing long term historical ocean observations and subsequent construction and operation stage needs real time monitoring on the surrounding marine environment ocean observing system oos is an important means for acquiring marine data in which in situ ocean sensors and instruments operate under harsh conditions including high humidity salt fog and vibration wang et al 2015 besides the acquired data must be transmitted via communication networks koack and clark 2013 thus the data series can easily become corrupted and cause anomaly there is no universally accepted definition for an anomaly kanarachos et al 2017 generally anomalies can be categorized into two types outliers data points that differ greatly from others in the data set hawkins 1980 and anomaly patterns a small fraction of data which are different from the majority others such as special fluctuations shapes and trends due to different generation mechanisms which always provide more information than the single points ren et al 2017 in ocean observing system anomaly refers to specific observing data that do not conform with the normal behaviors which may derive from the marine environment or oceanic phenomena beltrami 2011 or may be caused by equipment failure hassani et al 2018 therefore it is very important to detect anomalies in oos as early as possible to avoid big losses from total machine failure or even natural disasters traditionally anomaly detection has been implemented manually relying on visualization tools whereas artificial methods are only suitable for finding extreme points and swings in data stream and inconvenient in real time checking hill and minsker 2010 mechanism models are also employed to detection anomalies cho et al 2018 however the marine system is characterized by complex interactions among different dynamical and random processes so there still lacks the mechanism models that can accurately describe the behavior of the system therefore a number of data driven methods capable of using and handling the historical observing data baldacci et al 2016 habeeb et al 2019 have been widely applied to anomaly detection in recent decades data driven anomaly detecting approaches can be roughly classified into two types statistical techniques and machine learning methods the statistical type usually develops statistical model based on the given data that assumed to be normal and then applies the hypothesis test to detect whether a data belongs to this model or not wu et al 2018 the statistical techniques usually contain parametric and non parametric methods parametric methods estimate the model parameters by the given data because they suppose the normal data follow an underlying distribution then the anomaly score can be estimated by deviations ye and chen 2001 or error residuals bianco et al 2001 akouemo and povinelli 2016 on the contrary non parametric methods just construct the model based on the given data merkl and holzapfel 2018 for instances a histogram based anomaly score method builds a histogram using the feature values of training data and then checks all bins if a data fall in goldstein and dengel 2012 the statistical anomaly detection techniques can provide a statistically significant solution and has the ability to detect unseen patterns nevertheless they commonly require large amounts of data and do not perform well when the predefined distribution does not hold true when directly used for anomaly detection machine learning methods typically develop classification model based on the training data marked anomalous or non anomalous the model can classify a new data into anomalous class or not landauer et al 2018 there are various of prominent classifier algorithms such as k nearest neighbors tran et al 2019 decision tree benkercha and moulahoum 2018 support vector machine tian et al 2018 and artificial neural network mekki et al 2016 the classification methods can classify the anomalous class accurately if there are enough training flagged data however in the cases of ocean observing system few or even no anomaly label is available in the historical data because it is probably not to mark enormous amount of points in the streaming data furthermore new unknown anomalies may emerge in marine system so there is no such type of labeled training data besides some classifier models e g distance based knn or one class svm may be difficult to detect periodic and seasonal anomalies since they cannot capture the temporal dependencies across different time steps to incorporate time series characteristics there exist many temporal prediction based anomaly detection methods they usually do not assume the properties of the data distribution and not need labeled data in this type autoregressive integrated moving average arima is a typical model to perform anomaly detection with temporal dependency for example arumugam and saranya 2018 presented an arima based anomaly detection technique for monthly rainfall data yu et al 2016 proposed a technique for traffic control in wireless sensor networks which identified the anomalies by comparing the actual and the predicted signals by arima model yaacob et al 2010 introduced a diagnostic procedure for early detecting network attacks by arima errors however these models are sensitive to noise thus probably increasing false positive results when the noise is severe to address such an issue wavelet techniques were employed and integrated with neural networks for analyzing variations and periodicities of the time series in recent years the main type of anomaly detection applications is wavelet reconstruction method which applies wavelet basis functions wbf as preprocessing tool to decompose the original dataset at multiple scales and then the sub components are analyzed by different neural networks for instances mandrikova et al 2017 presented a hybrid anomaly detecting system based on a combination of wavelets and neural networks different scale components of ionospheric data series were analyzed by regression neural network models and results proved the joint method could detect long periods of disturbances in the typical variation of ionospheric parameters kanarachos et al 2017 proposed an abnormal patterns detecting method that combined wavelets neural networks and hilbert transform after wavelet decomposition for each scale subset a standard artificial neural network ann is trained for identifying the temporal structure of the signal detail sanz et al 2007 combined the capability of wavelet transform to treat transient signals with the ability of auto associative neural network for diagnosing faults of rotating machinery despite the noises in both cases the method can be a good alternative as a diagnosis tool shi et al 2018 applied wavelet ann model for detecting water quality anomalies after wavelet decomposition and de noise a low frequency signal was imported into ann for one step prediction to identify the major features of water quality variations vahidi et al 2010 also presented a hybrid approach using artificial neural networks and the discrete wavelet transform dwt for detecting high impedance faults dwt was used to decompose the distorted signal and to extract its useful information feature vectors were created and applied in training the ann in general the advantages of wavelet reconstruction methods are obvious the training process of anns or the latter detecting process become easier because the signal s short and long term temporal structure at different scales are more significant than the complete series however wavelet reconstruction methods may be difficult to work online because they usually need to train anns for the selected appropriate components and then combine them which are labor intensive and time consuming even though some scales are not informative in many real world applications another type is based on wavelet neural network wnn which employs the wavelet basis functions wbf as a transformation function in the hidden layer of standard ann model zhang and benveniste 1992 this type used wnn as the above mentioned classifier in many anomaly detection domains such as civil infrastructure condition assessment turkan et al 2018 and network intrusion detection alarcon aquino et al 2014 huang et al 2017 liu and liu 2009 on the other hand many studies have emphasized that the wnn as a regression model takes the advantage of the self organizing of ann and time frequency properties of wbf qi et al 2016 santhosh et al 2018 tealab 2018 and performs better than conventional ann wang et al 2013 using wnn as a predictor is becoming a new research branch in the field of anomaly detection for example wan et al 2018 proposed a wnn based approach for detecting cyber intrusions and anomalies in industrial function control process the wnn was developed to simulate the normal function control behaviors and then was applied to calculate the detection threshold and predict the time related function control characteristics the approach demonstrated the wnn could use raw data and had adequate real time capability in many real world applications although observing systems acquire data continuously using automatic sensors the full benefits of real time observation would not be achieved without real time analysis ahmad et al 2017 shi et al 2018 ocean observing system oos also needs fast anomaly detecting methods besides the time series of some marine parameters are probably non stationary veltcheva and soares 2015 thus the wnn based method is given priority to study ocean observing time series the main contributions of this paper are a novel wnn based method is formulated for detecting anomalies in ocean fixed point observing time series which is capable of identifying anomalous points and patterns that are caused by the natural factors or equipment failures we simulate the normal behaviors of ocean observing system in which anomalies are rare so no labeled training data are needed besides the anomalies classifying threshold is determined by the distribution of historical residuals to find new unknown anomalies two detecting strategies i e observation and prediction strategy are designed and the proposed method is can work in real time the rest of paper is organized as follows firstly we present an identifying framework that combines the wnn classifying threshold and two detecting strategies then the application of the method in the case of national marine test site of china is described furthermore results are analyzed and discussed in the aspects of detecting strategies prediction levels and reliability of prediction finally conclusions are drawn 2 methods 2 1 framework for identifying anomalies in ocean observing data series the proposed anomaly detection method of ocean parameter observing series mainly includes the following four steps beginning at time t shown in fig 1 step 1 for a marine variable e g surface current speed salinity water temperature etc series a moving window of related l time delay points is analyzed and determined denoted as w l t x t l x t 1 x t x t is the observed value in time t then a wnn based one step ahead prediction model is developed and w l t is used as input to predict xp t 1 the expected value of the sensor measurement at time t 1 step 2 the residual error sequence r h re t n re t 1 re t between historical observations x t and model predictions xp t is calculated then the probability distribution of r h is estimated and the corresponding confidence level e g 95 threshold for classifying anomalies is constructed step 3 upcoming observing value xp t 1 is predicted from the wnn model in a real time manner when the observation x t 1 at the time t 1 arrives from ocean instruments the residual error re t 1 is compared to the threshold and the point x t 1 is classified as anomalous if the re t 1 exceeds the threshold otherwise it is identified as non anomalous step 4 under the observation strategy os w l t is modified by removing x t l from the back of the slide window and adding x t 1 to the front of the w l t to generate w l t 1 under the prediction strategy ps if the observed x t 1 is flagged as anomalous w l t 1 is iterated by removing x t l and adding xp t 1 to the front of the w l t then step 3 and step 4 are repeated 2 2 wavelet neural network prediction model for ocean observing time series 2 2 1 model structure wavelet neural network wnn applies wavelet basis function wbf as the activation functions in the hidden layer of the ann the traditional artificial neural network ann model is essentially a feed forward multilayer perceptron ann is generally comprised of three distinctive layers i e input hidden and output and the neurons in each layer are disconnected from each other but the neurons from one layer are connected to all nodes in the adjacent layers and only affect the state of neurons in the next layer similar to ann the model structure of typical three layers wnn is shown in fig 2 the input signal is processed layer by layer from the input layer to the output layer then the output x t can be calculated by eq 1 1 x t j 1 j w j k ψ i 1 i w i j w l t 1 i b i b j where w ij is the connection weight between the ith node of input layer and the jth node of hidden layer and w jk is the weight between the jth node of hidden layer and the kth node of output neuron x t is the output value and b is the bias i and j are the respective number of neurons in input and hidden layers and w l t 1 i is the model input variable ψ is the wavelet basis function in the hidden layer wbf is effective to analyze the non stationary time series and a series of wavelets ψ a b can be computed by eq 2 2 ψ a b x a 1 2 ψ x k a where a is the scale parameter representing expansion a 1 or compression a 1 k is the shift parameter for wavelet function ψ is the mother wavelet i e wbf 2 2 2 choice of the mother wavelet there are several types of wbfs available with different characteristics such as morlet mexican hat and daubenhies the choice of the wavelet mostly depends on the particular application one has in mind to study signal representation classification and feature extraction of time series there are three sensible ways i e peak frequency energy frequency and central instantaneous frequency to convert wavelet scales into frequencies aguiar conraria and soares 2010 the morlet wavelets have widely used in recent decades because in the case of the morlet wavelet these ways are all equal facilitating the conversion from scales to frequencies besides the morlet wavelet has optimal joint time frequency concentration mezghani et al 2011 and the time radius and the frequency radius are equal therefore this wavelet represents the best compromise between time and frequency concentration the mexican hat eq 3 and a central symmetric wavelet eq 4 to compare with the morlet wavelet eq 5 and the results demonstrate that the morlet wavelet has better performance in the proposed method for predicting ocean observing series see supplementary materials part i 3 ψ t e t 2 2 1 t 2 4 ψ t t e t 2 2 5 ψ t e t 2 2 cos c t according to szu et al 1992 and wan et al 2018 c is 1 75 but the c 5 is recommended by daubechies 1994 2 2 3 inputs and outputs as shown in fig 2 the expected measuring value xp t 1 in time t 1 is the output and the input is the moving window w l t which is comprised of some related time delay points of x t 1 sudheer et al 2002 suggested that the statistical approach depending on cross correlation autocorrelation acf and partial autocorrelation pacf of the observed time series data is a good alternative to the trial and error method in identifying model inputs the statistical method was also successfully employed to various applications kisi 2008 tiwari and chatterjee 2010 wu et al 2009 wang et al 2013 the essence of this method is to examine the dependence between the input and output data series according to this method for ocean observing time series the acf and pacf are used to determine the potential time lags as input variables in w l t 2 2 4 model training method typical back propagation bp algorithm is used to train the model the signal is transmitted forward from the input layer to output layer and the error back propagation will occur if the expected output cannot be obtained then the gradient descent with momentum algorithm is applied to modify all parameters of wnn which are computed as 6 λ r 1 α λ r η e g λ r 7 e g 1 2 n 1 n x p t x t 2 where the λ represents the parameters e g w ij w jk a k of the wnn model xp t and x t are the model output and the object values n is the number of samples in training datasets and r α η is the iteration time momentum and learning rate of train process respectively the error goal of target training is set to 10 5 and the maximum number of epochs is 1000 training stops when any of the two conditions occurs there are total five training parameters tuned in relation to the available training data see table 1 the training parameters are selected based on the experiences of previous neural network studies and determined by trial and error 2 3 classifying threshold based on residual error distribution the performance of forecasting model can be analyzed by residual error between predictions and original observations hypothesis testing is used to determine the maximum likelihood distribution of residuals generally residual error sequence r h follows a certain distribution e g normal logistic gamma etc and the probability distribution of r h can be estimated by the goodness of fitting approach then the corresponding prediction level threshold for classifying anomalies can be constructed by eq 8 note that eq 8 is mainly designed for the two parameter distributions the threshold is used to distinguish whether the ocean observing observations belong to the background interval or are abnormal 8 t h r e s h 1 2 μ ln p up 1 p up s μ ln p down 1 p down s where μ and s are the parameters of distribution for instance μ and s are the mean and scale factor for logistic distribution in addition p up represents the classifying level e g 95 99 99 5 etc and p up p down 1 2 4 detection strategy to find new unknown anomalies two detecting strategies i e observation strategy and prediction strategy are designed that the proposed method can work in an unsupervised setting once an anomalous data point is classified two alternative detection strategies i e observation strategy and prediction strategy for updating new moving widow are compared the purpose of os is to keep the objectivity of data sequence so the os simply proceeds to forecast the next chronological data point using the newly observations as model input even though these observations are marked as anomalous due to the wnn developed to simulate the normal behaviors of the system another strategy ps proceeding to forecast the next chronological data point using the predictions of data driven model as input is designed to avoid the collapse of detection system caused by long term continuous observation anomalies actually the faults of measuring sensors or instruments may have the characteristics of graduality and irreversibility such as drift biological attachment aging power instability venkatesan et al 2016 2 5 study area and data ocean buoys are widely used in fixed point observation for they could obtain data for longer periods wang et al 2015 met ocean data buoy deployed at the national ocean test site of china was selected for testing the anomaly detection method see fig 3 two kinds of ocean parameters datasets from the buoy were selected to conduct research surface salinity ss was measured using the ctd manufactured by the seabird company and surface current speed scp was collected by nortek s aquadopp for each parameter there are in total 7500 samples collected within a time interval of half an hour the data set was divided into two subsets the training dataset 5000 samples from 11 30 january 24th to 8 30 may 22nd including training data and cross validation data was applied as the background to train the wnn great care was taken so that no anomalies were included in the training set the rest samples from 9 00 may 22nd to 3 30 july 17th and from 17 00 june 26th to 6 00 july 31st were used for testing the proposed method 3 results and discussion the acf and pacf of the two ocean observing parameters are shown in fig 4 fig 4a shows that the pacf within the confidence band occurs at lag 3 and lag 7 for ss series so the t 1 and t 2 in addition to the t 4 t 5 and t 6 are selected as the main relevant lags note that some more relevant lags such as t 9 or t 14 are rejected because they can reduce large amount of training data samples thus the moving window for ss is determined to w ss t 1 x t 6 x t 5 x t 4 x t 2 x t 1 similarly the main relevant lags are t 1 t 3 t 4 and t 5 for scp see fig 4b correspondingly the moving window for scp is set as w scp t 1 x t 5 x t 4 x t 3 x t 1 afterwards the wnn was trained from 2 to 15 hidden neurons and a better model structure was obtained with the minimum training error eg three confidence levels the 95 99 and 99 5 were selected for residual error distribution to classifying anomalies and the fitting of residual error sequence r h between the 5000 historical observations and model predictions was implemented by using normal distribution nd and logistic distribution ld the results of abnormal detection for ss and scp observing series under two detection strategies i e os and ps are shown in table 2 false negative fn means the actual anomaly observations identified as normal by the proposed method and false positive fp represents non anomalous points estimated as anomalous 3 1 influence of detection strategies for ss series some sudden changes in residual error re series can be detected under both two strategies see fig 5 while the false positive rate are lower with os than with ps see table 2 note that the res of ss are bigger than the threshold value near the time 22 00 in may 29th and 21 00 in july 13th actually the weather was a shower on may 29th and rainstorm on july 12th in 2015 nmic 2019 it is probably that the rain caused a drop in the value of surface salinity for a short time generally the ss value trends gradually decreased from may to july because of the increasing precipitation during summer the abnormal salinity values caused by short term heavy rainfall did not exceed the minimum of the whole observation sequence ranging from 30 34 to 31 68 which means that they cannot be effectively identified with traditional statistical methods this type of anomaly can be detected because the anomalous data caused by natural factors e g rainstorm have the characteristics of drastic change and recoverability i e most natural abnormal events occur sporadically and last for a short time in this type the observations are returning to normal in a short time under os just a few untrained error measurements have been added to the inputs into the wnn model for the next step prediction afterwards the input window w l would gradually consist of all non anomalous observations and the residual error decreases within the threshold zone see fig 5c when using ps the input w l t x t l x t 1 x t consists of non anomalous observations before abnormal alarm triggered see fig 1 and the model performed well see fig 5b therefore the trained wnn model is prone to represent the normal behaviors of the system correspondingly the w l t is used to predict xp t 1 which is supposed to be non anomalous and the wnn predictions are also supposed to be non anomalous in a short period thus these suddenly decreased observations can be detected due to residual errors exceeding the threshold the os and the ps can both effectively classify the anomalies caused by natural factors with sporadic and restorative features for scp series the false negative rate by the proposed method has been greatly reduced by using ps compared with applying os see table 2 as shown in fig 6 the scp sequence began to become smaller in june 28th and then maintained a lower level which can be attributed to serious adhesion of marine organisms to the sensor in summer a phenomenon found during the maintenance period the persistent anomalies caused by equipment failure cannot be identified by os and the anomalies detected by os some time earlier may be caused by natural factors or false positives because the anomalous data from equipment failures e g power supply instability instrument aging drift generally has the characteristics of irreversibility and often lasts for a period of time after gradual or sudden change venkatesan et al 2016 when using os for detecting these persistent anomalies it would inevitably affect the accuracy of prediction and induce a negative impact on the classification of anomalies due to introducing untrained error measurements as inputs into the wnn model for the next step prediction once the error measurements are judged as normal points errors will accumulate continuously with sustained input of anomalies i e error measurements for anomalous sequence caused by equipment failure the predicted value using ps is more accordant with the non anomalous sequence before the failure occurs so the residuals with series of measurements accumulate rapidly after the beginning of the anomaly and then rise to a relatively stable interval with small oscillation see fig 6d which represents the significant difference between the sequence with equipment failure and that with no failure therefore wnn ps can effectively identify the anomalies caused by equipment failure in comparison with wnn os from an overall view os can be adopted to appropriately reduce the false positive rate of abnormal detection for both sequences occasional anomalies caused by natural factors such as the case of ss series can be identified better by using os while applying ps is better for identifying the persistent anomalies caused by equipment factors such as the case of scp series using model predicted value as the model input ps may lead to time series smoothing toward the center which is more apt to occur especially when the anomaly lasts for a long time and then the sliding window is assumed to be all predicted values rather than actual measurements however it will not significantly affect the detection results and may reduce the false negative rate of persistent abnormal detection caused by equipment failures in scp sequence 3 2 influence of classifying levels the false positive rate decreases when the classifying level increases from 95 to 99 5 while the false negative rate increases see table 2 indicating that 99 of the classifying level may provide a reasonable trade off between false negative and false positive the advantage of using p instead of user defined threshold is to provide a guidance to determine thresholds in the form of predictive levels without requiring any experiential knowledge or parameter measurements based on the wnn model and measurement errors the p classifying level indicates the probability with at least p to accurately predict the sensor s measurement value correspondingly it is expected that 100 p of the non anomalous data will be misclassified as anomalies in practical application actual anomaly observations whose prediction residual errors are larger than the threshold value are more important to classify correctly than those smaller than the threshold anomaly detecting methods by threshold can often easily misclassify both the abnormal value with smaller deviation from the threshold value and the normal value with larger deviation however the results demonstrate that the classifying threshold derived from model prediction can describe the boundary between the normal value and abnormal data take the 99 classifying level with ps as example the logistic error distribution of ss has a mean value μ 0 0004 and a scale parameter of s 0 0092 and for scp μ 0 0037 s 0 0575 then the respective thresholds thresh ss 0 0422 and thresh scp 0 2595 are correspondingly computed according to eq 6 fig 7 shows the residual distribution of both observing time series it can be seen that the logistic distribution is narrower and more centered on the mean than the normal distribution the false positive rate decreases by using normal distribution to ss sequence and important natural factor anomalies can be identified effectively see fig 5c and d so the classifying threshold of normal distribution is suggested when the target is to identify natural anomalies and minimize interference however the classifying threshold of logistic distribution is more effective for small persistent sequence anomalies caused by equipment failures see fig 6d and should be used if events with more abundant variables are need to be identified 3 3 reliability analysis the roc curve has been widely used to evaluate the quality and reliability of algorithms for anomaly detection the coordinate system of roc is composed of abscissa with false alarm rate far and ordinate with probability of detection pd pd is a function of true positive and false negative so the bigger is the better in contrast far is a function of false positive and true negative the smaller is the better the performance of the wnn model is compared with the traditional ann and a wa ann method applying wavelet analysis as a denoising tool of the original observed time series see supplementary materials part ii and fig 8 for detecting ss series the areas under the roc curve of the ann wa ann and wnn are 0 9223 0 9322 and 0 9514 respectively similarly the areas under roc curve are 0 9103 0 9504 and 0 9814 for scp series the results indicate that wnn has the ability to deal with time series with non stationary characteristics and can improve the accuracy of anomaly detection by increasing pd and reducing far in order to verify the performance of anomaly detection the surface water temperature sequence is further analyzed in supplementary materials part iii which shows that the proposed algorithm can effectively recognize such abnormal events comparisons of wnn prediction performance in different observing periods are presented in supplementary materials part iv the wnn model produces good performance over three different time spans but short period of data records may lead to misclassification due to insufficient training dataset for the wnn prediction model besides this method has spatial particularity so the needed historical data to construct the classifying threshold may vary with different spatial locations 3 4 discussion this method can be adopted in many applications including but not limited to marine disaster warning marine engineering and fault prediction of marine observing equipment natural processes like climatic conditions marine environment and equipment factors such as power supply instability instrument aging and drifting can affect ocean observing sequence some new unknown anomalies may emerge at any time so it is more challenging to detect anomalies in ocean observation sequence with appropriate strategies firstly the accuracy of the model has remarkable effect on anomaly detection non stationary data should be adopted when data driven prediction models are used in marine environmental data series i e no change of data intrinsic patterns even though wnn is capable of dealing with non stationary time series well the training dataset of wnn model is needed to be updated periodically because most marine environmental variables might change significantly during a period of time e g 1 day 7 days 30 days or even 90 days model updating can be achieved by periodic retraining that a 30 day to 3 month period may be suitable for training wnn for anomaly detection in routine applications however the data measured by different sensors at different locations should be analyzed to match the training frequencies according to dynamic changes of the sequence note that training wnn requires time consuming calibration of model parameters in real time forecasting scenarios in addition sensor measuring data from the buoy are usually transmitted in small batches rather than one at a time so the retraining only has to be shorter than the interval time of data transmission e g the retaining interval time is less than 30 min in this case on the other hand when the model is relatively complex and requires time consuming a dual backup approach could be considered which means training a new model while the previously developed model can be used for anomaly detection secondly there are uncertainties in the anomaly detection process mainly derived from the model structure training dataset and calibrating parameters beck 1987 indicating that there is also a corresponding confidence level for wnn predictions moreover the function of residual distribution is related to different marine variables and the classifying confidence level p should be suggested based on the trade off between false negative and false positive therefore the anomalies classifying threshold with confidence level p is correlated to the wnn prediction confidence level residual distribution function and historical sequence the classifying threshold can be further optimized with the characteristics of seasonal variation and should be robust and less vulnerable to data fluctuations finally the marine system is characterized by complicated interactions among different dynamical and random processes so there must be some associations between various marine variables in this sense it is very important to systematically study the relationships among multiple marine observing series at one position and the relations between adjacent spatial correlated observing sequences however this paper concentrates on single observation sequence in a fixed site the multi sequence research and more applications studies will be conducted in the near future compared with traditional detection methods including manual visualization expert consultation enhanced safety monitoring and routine fault inspection this method has the advantages of shorter average detection time and lower costs therefore it has great potential value in many applications such as marine disaster warning marine engineering and fault prediction of marine observing equipment 4 conclusions this paper presents a novel method for detecting anomalies in ocean fixed point observing time series wavelet neural network wnn next step prediction model classifying threshold and two detecting strategies are combined wnn is used to simulate the non anomalous behaviors based on the normal variations in ocean observing series two detecting strategies i e observation strategy and prediction strategy are designed to find new unknown anomalies the classifying threshold is determined by the estimated distribution of historical residuals the proposed method is verified by the case of national marine test site of china it is found that the 99 of classifying confidence level is adequate to provide a reasonable trade off between the false negative and false positive by using the two detecting strategies and selecting the proper estimated distribution of classifying threshold the method is efficient for identifying the anomalous points and patterns which were caused by the natural factors or equipment failures the wnn is developed without any labeled training data so the proposed method can work in an unsupervised setting besides compared with traditional ann and wa ann the wnn based method is more tolerant to noise and more sensitive to anomalies with temporal dependencies besides the method performs well over three different periods which demonstrates the reliability of the method however its spatial particularity and short period of data records may lead to misclassification we are working to evaluate the method on multivariate marine variable series and more prediction models and more applications studies will be conducted in the future acknowledgements this study is supported by the national natural science foundation of china grant no 41606118 and also funded by the ministry of natural resources mnr of china we also thank the editor and the previous anonymous reviewers for their constructive comments and recommendations which have significantly improved the quality of this work appendix a supplementary data the following are the supplementary data to this article multimedia component 1 multimedia component 1 multimedia component 2 multimedia component 2 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j oceaneng 2019 106129 
22711,extreme cyclic loading and pitting are unavoidable damage factors for steel offshore platforms the degradation of mechanical properties of steel caused by such double damage cannot be obtained by a simple addition of degradation caused by a single damage in order to analyze the above problems the high strength steel nv d36 commonly used in offshore platforms was selected as an experimental specimen different degrees of pitting damage were generated by laboratory electrochemical accelerated corrosion seven typical cyclic loading programs were designed based on the real extreme cyclic loads that offshore platform may be subjected to the cyclic loads were applied to the specimens to obtain the hysteretic properties of healthy and pitting specimen under cyclic loading the stiffness and the strength of steel were strengthened in contrast pitting damage could cause local volume loss and local stress concentration which result in degradation of stiffness and strength of steel generalized yield strength and generalized young s modulus of steel were gradually degraded with the deepening of pitting damage the cyclic hardening coefficient linearly degenerated with the pitting volume loss rate and the degree of degradation was almost irrelevant to the cyclic loading program the cyclic hardening exponent was almost unaffected by pitting damage keywords high strength steel pitting damage extreme cyclic loading damage degradation 1 introduction the coupling effects of temperature humidity salinity ph and marine life in the marine environment can easily lead to corrosion of the offshore platform structure corrosion can be divided into general corrosion and local corrosion according to the corrosion form local corrosion mainly includes pitting corrosion galvanic corrosion crevice corrosion and stress corrosion etc among them pitting corrosion is the most common local corrosion chaves and melchers 2014 pitting parameters such as pitting depth pitting diameter pitting distribution and pitting morphology as shown in fig 1 affect the mechanical properties of the structure in varying degrees melchers 2004 valor et al 2007 the influence of pitting on the structure is generally operated by reducing the design plate thickness in the design of offshore platforms dunbar et al 2004 ok et al 2007 however the reduction of design plate thickness only can reflect the influence of pitting depth on the structure and it is impossible to measure the mechanical properties of other pitting parameters in addition offshore platforms are used in hostile marine environments and often subjected to cyclic loads such as wind waves currents and earthquakes wang et al 2006 therefore offshore platform structure and members suffer from different degrees of alternating stress the stress level of structural members is low when the structure is subjected to mild cyclic loads such as wind waves and currents the structural members under numerous cyclic loading about 104 times will cause high cycle fatigue damage instead when the structure is subjected to extreme cyclic loads the stress level of the structural members is high the structural members under cyclic loading about 102 104 times will result in low cycle fatigue damage when the structure is subjected to more extreme cyclic loads such as earthquakes hurricanes and tsunamis the structural members will be deformed in a short time the working state of structural members is quickly entered the plastic phase from the elastic phase resulting in a higher stress level of the structure and members in this case the ordinary structure can be damaged by ultra low cycle fatigue in 2 10 cycles kuroda 2002 nip et al 2010 compared with extreme cyclic loads offshore platforms are more common in encountering mild cyclic loads naturally there are many theoretical and experimental studies on high cycle fatigue caused by mild cyclic loading but there are relatively few studies on low cycle fatigue caused by severe cyclic loads abs 2014 dnvgl rp c203 2016 however due to the particularity of the service environment of the offshore platform the structural members subjected to pitting damage and ultra low cycle loads cannot be avoided therefore it is necessary to study the change law of mechanical properties of structure when it suffers from pitting damage and severe cyclic loads scholars have conducted many studies on pitting damage and cyclic loading of different material structures and members nakai et al 2004a b 2006 conducted a bending test on the typical members of bulk carriers with pitting damage by means of mechanical drilling and analyzed the bearing capacity and buckling behavior of the members zhang et al 2016 2017 studied the mechanical properties of uniaxial compression and shear buckling strength of hull plates with pitting damage qin et al 2016 studied the degradation laws of mechanical properties of q235 steel plates with corrosion and found that all the mechanical property index significantly decreases when the corrosion rate is over 15 imperatore et al 2017 conducted an experimental study on the monotonic mechanical properties degradation relationship of reinforcing steel bars with corrosion and developed degradation relationship for the main mechanical properties zhang et al 2012 conducted a study on the monotonic tensile loading properties and fatigue properties of corrosive reinforcing steel bars it is concluded that the ultimate strength and yield strength of steel degraded with the increase of corrosion damage similarly the fatigue life of steel sharply decreases with the increase of corrosion damage but the fatigue properties is more serious than the monotonic loading properties xu and qiu 2013 conducted a fatigue test on pitting specimens of q235 steel which shows that the presence of pitting corrosion can significantly reduce the fatigue life of the steel fernandez et al 2015 studied the monotonic loading mechanical properties and cyclic loading mechanical properties of reinforcing steel bars and established the relationship between monotonic loading mechanical properties and pitting loss rate and analyzed the impact of pitting geometry on fatigue life of reinforcing steel bars apostolopoulos and papadopoulos 2007 studied the monotonic properties and ultra low cycle fatigue properties of pitting specimens of s400 steel pointing out that the monotonic properties and the degradation of ultra low cycle fatigue characteristics are closely related to the degree of pitting damage caprili and salvatore 2015 investigated the low cycle loading mechanical properties of healthy and pitting specimen of steel reinforcing bars and analyzed the residual mechanical properties and energy dissipation capacity of the steel reinforcing bars in addition some scholars have carried out cyclic loading tests on healthy without pitting ordinary steel high strength steel and stainless steel respectively analyzed their monotonic performance and hysteretic performance respectively that obtained steels are hardened under cyclic loading nip et al 2010 shi et al 2012 wang et al 2017 ma et al 2018 the strength and energy dissipation of the steel is hardened under the cyclic loading however local stress concentration and cyclic cumulative damage may occur in the steel when the steel encounters both pitting damage and ultra low cycle loading which lead to serious degradation of the mechanical properties of the steel unfortunately due to the strong randomness of pitting damage and cyclic loading the related research is still relatively lacking it is difficult to analyze the degradation of mechanical properties of steel caused by pitting damage and cyclic loading theoretically therefore it is almost certain that experimental research is a relatively reliable analytical method currently specifically the reasonable preparation of pitting damage on the structural members and the appropriate design of ultra low cycle loading test are the key to obtain the change law of mechanical properties of steel in addition to the real test method the accelerated test method is a widely used for preparing pitting damage nakai et al 2004a b and okamoto et al 2010 also confirmed that the pitting damage prepared by the accelerated test method can well reflect the real pitting damage effect fig 2 shows the measured seismic acceleration velocity spectrum from the peer database yang et al 2017 which fully demonstrate the stochastic properties of extreme cyclic loading it also shows that the cyclic loading mechanical properties of the material not only depend on the material s characteristics but also on the characteristics of the cyclic load in the above literature nip et al 2010 shi et al 2012 ma et al 2018 the form of cyclic load is triangular waveform like real cyclic loads but loading amplitude loading history and loading time are different therefore certain types cyclic loading program should be designed in the cyclic loading test to reflect the characteristics of material itself and extreme cyclic loads based on the above analysis this paper selected the high strength steel nv d36 commonly used in offshore platforms to design healthy without pitting test specimens and then the pre pitting of healthy specimens was carried out by the constant current electric method to obtain pitting specimens with different damage degrees it is worth noting that in order to obtain the change of the mechanical properties of the component as clearly as possible the pitting test specimen does not consider the effects of the pitting distribution and the coupling between the pitting therefore the pitting corrosion of the specimen was set to single pitting subsequently different types of cyclic loading systems were designed according to the monotonic mechanical properties of the steel and the characteristics of the extreme cyclic loads to carry out the cyclic loading test eventually we analyzed and discussed the degradation law of monotonic properties and hysteresis properties of the steel with experimental results 2 material and experimental arrangements 2 1 material and specimen design the specimen was taken from the high strength steel nv d36 certificated by dnv classification society commonly used in offshore platforms the carbon content of the steel is about 0 11 and the other chemical elements are shown in table 1 the yield strength and tensile strength of the steel are about 430 mpa and 553 mpa respectively the elongation is about 26 due to the difference of test conditions between laboratory and steel mill the mechanical properties of the steel provided by the steel mill are only for reference in this paper the steel was subjected to a monotonic loading test to obtain its basic mechanical properties according to the astm test standard astm 2012 and considering the characteristics of the cyclic loading system the specimen was designed as a plate therefore in order to avoid buckling of the specimen under a large cyclic compress loading the aspect ratio of the specimen was slightly smaller than the recommended value of the astm test standard the specimen consists of three parts parallel test area curved transition area and end clamping area details of shape and dimensions of the specimen are shown in fig 3 in addition in order to decrease the error caused by the test equipment same type specimen was used for the monotonic loading test and the cyclic loading test 2 2 pitting test 2 2 1 pitting test setup pitting specimen was obtained by healthy specimen without pitting that use accelerated test method for the preparation of pitting corrosion damage unlike the pitting damage prepared by mechanical drilling method adopted by nakai et al 2004a b 2006 this paper used the constant current electric method to electrochemically corrode steel specimen to obtain pitting specimen on the one hand the principle of constant current electric test was the same as that of real pitting damage szklarska smialowska and mankowski 1972 on the other hand the geometric characteristic parameters of the pitting damage obtained by the preparation have random distribution characteristics which also reflect the pitting damage characteristics of the real structure pitting test setup mainly includes ps 603d constant current source plastic container inert electrode and nacl solution with a mass fraction of 5 the inert electrode placed in the electrolyte solution and the reserved area of the test piece were connected to the positive and negative pole of the power source respectively and then a constant intensity current was applied to the entire test system the healthy specimen without pitting as the anode of the electrolytic cell was oxidized and dissolved and then pitting specimens with different degrees of damage were obtained the electrochemical accelerated corrosion test system is shown in fig 4 2 2 2 pitting damage evaluation index pitting depth and pitting diameter were generally used as evaluation indexes of pitting damage degree in practical applications however pitting damage had many geometrical parameters such as pitting depth pitting diameter pitting distribution pitting shape cross sectional area loss and volume loss paik et al 2004 valor et al 2007 therefore a single pitting characteristic parameter cannot fully reflect the geometric characteristics of pitting damage in order to consider the influence of pitting damage on the mechanical properties of steel comprehensively this paper selected the volume loss as the evaluation index to measure the damage degree of pitting in the electrochemical accelerated corrosion test the pitting characteristic parameters such as pitting depth h and pitting diameter d of each specimen have some randomness due to random factors such as material properties and current the cross sectional shape of the specimen at the pitting is irregular which brings certain difficulties to the measurement of actual pitting cross sectional area relatively speaking it is more convenient and practical to use the volume loss rate as the evaluation parameter of pitting damage degree to characterize the influence of pitting moreover the pitting volume loss also can comprehensively reflect the joint effect of pitting depth h pitting diameter d pitting distribution ψ and pitting shape φ and other geometric parameters the above geometric parameters can be considered as a function of the pitting loss volume as shown in eq 1 furtherly compared the pitting volume loss with the original volume the volume loss rate that measures the degree of pitting damage can be obtained as shown in eq 2 1 δ v h d ϕ ψ 2 η v δ v v c 2 2 3 specimen type and naming rule pitting specimen derived by constant current electric method was shown in fig 5 the pitting depth and diameter were the average of two measurements the pitting depth was divided into five categories 0 mm 1 mm 1 5 mm 2 mm and 2 5 mm and each type with 7 specimens the pitting shape was between semi spherical and conical and ratio of pitting depth to pitting diameter was about 4 1 10 1 which basically conforms to the real statistical law of pitting damage paik et al 2004 the details of pitting damage were shown in table 2 all test specimens were named in the format of x yl z where x represents the pitting depth of the specimen which can be taken as 0 0 mm 1 0 mm 1 5 mm 2 0 mm and 2 5 mm yl stands for loading mode which represents the monotonic loading ml and cyclic loading cl respectively z stands for cyclic loading system number which can be taken as 1 7 monotonic loading specimens not have this number for instance 0 0 ml represents a monotonic loading specimen with a pitting depth of 0 0 mm 1 5 cl 4 represents a cyclic loading specimen with a pitting depth of 1 5 mm and the cyclic loading program was cl 4 2 3 monotonic cyclic loading test 2 3 1 loading setup both the monotonic loading test and the cyclic loading test were carried out with an instron8801 servo hydraulic fatigue tester with a dynamic load capacity of 100 kn the strain in the parallel test area of specimen was measured by a tensile and compression extensometer the gauge length of the tensile and compression extensometer was 12 5 mm and the strain measurement range was 35 therefore the strain more than 35 only can be obtained by conversion of displacement recorded by the machine in addition the input and output data of tensile and compressive loads displacements and strains were collected in real time by a static strain test system with a data acquisition frequency of 50 hz the physical diagram and schematic diagram of the hydraulic fatigue tester and the tensile and compression extensometer were shown in fig 6 2 3 2 loading program 2 3 2 1 monotonic loading program according to the test standard iso 6892 1 2009 five pitting specimens with different damage degrees were subjected to monotonic loading test to obtain the monotonic loading mechanical properties of the steel 2 3 2 2 cyclic loading program based on the characteristics of monotonic loading of the steel and the extreme cyclic loads of offshore platforms a variety of cyclic loading program were designed to investigate the change of monotonic properties damage degradation cyclic hardening and energy dissipation of the steel with pitting damage ma et al 2018 cl 1 cyclic loading program mainly analyzed the influence of constant amplitude cyclic loading on the damage degradation and energy consumption of the steel the loading program corresponds to the common cyclic loads such as wind wave and current in marine environment cl 2 and cl 6 cyclic loading programs mainly studied the change of backbone curve and energy dissipation of the steel under increasing amplitude step by step cyclic loading and stepwise reduction cyclic loading respectively the two cyclic loading programs correspond to the initial stage and end stage of extreme cyclic loading cl 3 and cl 4 cyclic loading programs mainly investigated the backbone curve and energy dissipation capacity of steel when the structure was in different plastic work stage cl 5 cyclic loading program mainly analyzed the energy dissipation of the steel under cyclic loading with the relative value of the cyclic loading amplitude was a constant but the loading peak gradually increased cl 7 cyclic loading program mainly studied the energy dissipation of steel under random cyclic loading the details of the cyclic loading programs were shown in fig 7 it should be noted that the cyclic loading test is shown as strain control and essentially belongs to displacement control in fig 7 a complete tension and compression loading like between two red dots in fig 7 a is recorded as one cycle of cyclic loading δε represents the strain increment of the variable amplitude cyclic loading which means the peak value of the cyclic loading of the latter cycle increases by δε with respect to the previous cycle high strain rate will cause an increase in the temperature of specimen during monotonic and cyclic loading test in order to reduce the influence of strain rate on the test results the strain rate is taken as 0 05 hz astm 2012 besides all loading tests were carried out at room temperature 3 analysis of test results healthy specimens no pitting and pitting specimens were subjected to monotonic loading and cyclic loading test respectively and then the monotonic loading curves and the hysteresis curves were obtained as shown in fig 8 and fig 18 the stress and strain marked in the figure were generalized stress and generalized strain calculated by eq 3 and eq 4 the stress and strain of the pitting specimen are called generalized stress and generalized strain because they are calculated from the original cross sectional area and the original length of test area respectively this treatment can not only facilitate the calculation of the stress of the specimen but also clearly obtain the influence of pitting damage on the mechanical properties of the steel it can be seen from fig 8 that the monotonic behaviors and hysteresis behaviors of the steel deteriorate to varying degrees as the pitting damage increased 3 ε ε g e n δ l l 0 4 σ σ g e n f a 0 where σ gen and ε gen are the generalized stress and generalized strain of the steel respectively δl is the displacement of the parallel test area of specimen l 0 is the initial length of the parallel test area of specimen f is the tensile or compressive load a 0 is the initial cross section area of the parallel test area of specimen 3 1 damage degradation characteristics of specimen compared the hysteresis curves of the cl 1 cl 2 and cl 6 series of specimens in fig 8 it is easy to obtain that the strength and stiffness of the nv d36 steel hardly deteriorate whether it suffers from constant amplitude cyclic loading or variable amplitude cyclic loading moreover the strain amplitude of the cyclic loading corresponds to the elastic or plastic loading state of specimen does not cause significant cyclic cumulative damage fig 9 shows the stress and strain under each cycle of the cl 1 cyclic loading program in detail it can be seen from the partial enlarged view of fig 9 b that the nv d36 steel with four pitting damage degrees after 10 times of constant amplitude cyclic loading the stress strain curves of each group can almost coincide this shows that there is no significant strength and stiffness degradation in the steel however it is worth noting that shi et al 2011 conducted a low cycle loading study on the healthy specimens without pitting of q235 steel and q345 steel and found that these steels appeared different degrees of cyclic cumulative damage during cyclic loading although the cyclic loading program used in the cyclic loading test is the same as that used by shi et al 2011 the cyclic cumulative damage of the nv d36 steel healthy specimens is relatively small and almost can be neglected therefore the above analysis can show that the cyclic cumulative damage of nv d36 steel in both healthy and pitting damage is relatively small and the degree of cyclic cumulative damage is related to the type of steel the low cycle loading studies of healthy specimens of nv d36 steel have been completed in the author s previous work ma et al 2018 however the presence of pitting damage can lead to a significant decrease in the strength and stiffness of the steel which is reflected in all cyclic loading programs as shown in fig 8 moreover the damage to mechanical properties of the steel deteriorate more serious as the pitting damage deepens fig 9 shows the effect of pitting damage on the strength and stiffness of the steel under cl 1 cyclic loading program in detail cyclic loading test was immediately stopped once the specimen has local buckling therefore the deterioration of mechanical properties caused by local buckling of the specimen can be eliminated compared the hysteresis curves of the specimen under each cyclic loading program it can be concluded that the cyclic cumulative damage of the steel can be neglected under the cyclic loading but the pitting damage cause the steel strength and stiffness degraded seriously 3 2 monotonic behavior analysis the elastic stage of the hysteresis curve was in the initial stage of cyclic loading therefore the generalized yield strength and generalized young s modulus of the steel can be analyzed by the elastic section of the hysteresis curve 3 2 1 relationship between generalized yield strength and degree of pitting damage fig 10 a shows the hysteresis curve of the cl 1 loading system series specimen from the partial enlargement of the circle in fig 10 b oscillation of yielding platform of the steel became weaken gradually as the degree of pitting damage increases the place of the specimen where pitting damage exist in was at a higher stress level when pitting specimen under monotonic loading as the pitting damage was deepened volume loss at the pitting damage gradually increased which resulting in the stress concentration at the pitting damage deepening gradually and stress redistribution was not obvious furtherly resulting in uneven stress distribution at the same cross section therefore the local and whole of pitting specimen cannot yield at the same time which lead to the steel enters the yielding state ahead of time and the upper yielding point and the lower yielding point are gradually closer as shown in fig 10 b as the loads continues to act on the specimen the yield state of the steel lasts for a short time which caused the steel quickly cross the yielding stage and enter the hardening stage the existence of pitting damage not only lead to the gradual disappearance of the yield platform of the steel but also caused different degrees of degradation of the generalized yield strength of the steel fig 11 shows the degradation of the generalized yield strength of all specimens with the pitting volume loss rate the generalized yield strength degradation ratio was as high as 19 1 when the maximum volume loss rate about 6 7 was reached mathematical fitting of the data points showed that the generalized yield strength is linearly degenerate and the degradation rate was about 2 8 in addition the goodness of fit of the degradation relationship was 0 975 which indicating the two factors above have a high relativity therefore it can be considered that the volume loss of the pitting damage was an important factor lead to the decrease of the generalized yield strength of the steel similarly the pitting volume loss rate can be used as an important index to evaluate the degradation of steel generalized yield strength in addition it is found that the generalized yield strength degradation degree of the steel was relatively uniform and the degree of dispersion of the data was small when the pitting volume loss rate was small however when the pitting volume loss rate was more than 5 the dispersion of steel generalized yield strength data increased which also indicates that as the degree of pitting damage gradually deepens the steel has an unstable yield process under monotonic loading 3 2 2 relationship between generalized young s modulus and degree of pitting damage the deepening of the pitting damage will not only lead to the degradation of the generalized yield strength of the steel but also the deterioration of the generalized young s modulus of the steel fig 10 b shows the degradation of the generalized young s modulus of the cl 1 series of specimens it can be seen that the degree of pitting damage increases the same but the degree of degradation was not the same the relationship between the generalized young s modulus of all specimens and the pitting volume loss rate was shown in fig 12 under certain volume loss rate the degree of degradation of generalized young s modulus of different specimens was not consistent when the maximum volume loss rate about 6 7 is reached the generalized young s modulus will be seriously degraded and the degradation rate was as high as 31 1 moreover the dispersion of the data was higher than generalized yield strength data of the steel mathematical fitting of the data points in fig 12 revealed that the degradation of generalized young s modulus and pitting volume loss rate was also linear and the degradation rate was about 4 6 in addition the goodness of fit of the degenerate relationship was about 0 781 which indicate that the relativity between the two factors above was insignificant and indicate that the pitting loss volume has an insignificant contributes to the degradation of generalized young s modulus maybe other pitting parameters were more relevant to the degradation of generalized young s modulus 3 3 hysteretic behavior analysis 3 3 1 backbone curve analysis the internal structure of the steel was dislocated and blocked under cyclic loading which lead to the strength of the steel was cyclically hardened the ultimate strength after cyclic loading was increased by about 5 27 compared with the monotonic loading as shown in fig 13 however due to the existence of pitting damage the strength of the steel was degraded as the degree of pitting damage deepens the proportion of steel strength degradation exceeds the degree of cyclic hardening which result in the strength of the steel was even lower than that of the healthy specimen without pitting as shown in figs 15 figs 16 and 17 therefore in order to quantitatively study the influence of pitting damage on the strength of steel the backbone curve of steel was analyzed the backbone curve was an envelope curve obtained by sequentially connecting the extreme points of the tensile or compression direction on the hysteresis curve which can reflect the stress strain relationship of the steel under cyclic loading fig 14 shows the bidirectional backbone curve of the cl 3 loading program series specimen apart from the deterioration of the generalized yield strength of the steel the backbone curve also showed a different degree of degrade with the deepening of the pitting damage besides the stress strain relationship in the compression direction was more degraded and more sensitive to pitting damage in order to more intuitively analyze the influence of pitting damage on the steel backbone curve the forward backbone curves of cl 2 cl 3 and cl 4 cyclic loading program series specimen were mathematically fitted the forward backbone curve fitting model used the ramberg osgood model ramberg and osgood 1943 and the ramberg osgood model was shown in eq 5 5 δ ε 2 δ ε e 2 δ ε p 2 δ σ 2 e δ σ 2 k 1 n where δε is the total strain amplitude δε e is the elastic strain amplitude δε p is the plastic strain amplitude δσ is the stabilized stress amplitude at half of number of cycles e is the young s module k is the cyclic hardening coefficient and n is the cyclic hardening exponent which were parameters need to be fitted the fitting results are shown in fig 15 fig 16 and fig 17 it can be seen that ramberg osgood model can fit the backbone curve of nv d36 steel very well quantitative analysis of the parameters to be fitted of the above backbone curve was carried out to obtain a relationship between the cycle hardening exponent n and the cycle hardening coefficient k and the pitting volume rate loss as shown in fig 18 the cyclic hardening exponent was highly correlated with the cyclic loading program specifically the cyclic hardening exponent rely on loading amplitude of steel and the cyclic loading history but for the same cyclic loading program the cyclic hardening exponent hardly change with the pitting volume loss rate as shown in fig 18 a similarly the cyclic hardening coefficient was also highly correlated with the cyclic loading program but unlike the cyclic hardening exponent the cyclic hardening coefficient and the pitting loss rate were linearly degraded when the maximum volume loss rate about 6 7 was reached the degradation ratio of the cycle hardening coefficient was as high as 18 8 in addition the quantitative degradation relationships between cyclic hardening coefficient and pitting volume rate loss were obtained by mathematical fitting as shown in fig 18 b it can be easily seen that the degradation rate of the cyclic hardening coefficient under each cyclic loading program was almost the same which indicate the effect of cyclic loading program on degradation rate of the cyclic hardening coefficient was relatively small 3 3 2 energy dissipation analysis the above analysis showed that the mechanical properties such as strength and stiffness of the steel caused by pitting damage were more serious than the cumulative damage caused by the cyclic loading of the steel itself in order to study the comprehensive influence of pitting damage on the above mechanical properties of steel the energy dissipation of steel was analyzed the area enclosed by the hysteresis curve indicates the energy consumption of the steel as shown in fig 19 which can comprehensively measure the mechanical properties such as strength stiffness and cyclic hardening of the steel the energy dissipation coefficient of steel was usually evaluated by the energy dissipation coefficient the formula for calculating the energy dissipation coefficient was shown in eq 6 6 e e s a c g s e c g s δ a o b s δ e o f where s acg and s ecg are the area of the hysteresis curves in the upper and lower parts of the horizontal axis respectively s δaob 和s δeof are the area of the triangle in the upper and lower parts of the horizontal axis respectively the area of each part was shown in fig 19 fig 20 shows the change process of steel energy dissipation coefficient under different cyclic loading programs it is easy to see that nv d36 steel has strong energy dissipation capacity but the energy dissipation capacity of steel deteriorates with the deepening of pitting damage the specific analysis results are as follows 1 the energy dissipation coefficient of the specimens in the plastic working stage whether pitting exists or not was between 3 0 and 3 4 closing to the maximum value e emax that is equal to 4 0 the maximum energy dissipation coefficient of q345b steel was about 3 0 wang et al 2017 which indicates nv d36 steel have a relatively good energy dissipation capacity 2 the trend of steel energy dissipation coefficient almost unaffected by pitting damage was only related to the cyclic loading amplitude when the cyclic loading strain was in the elastic range the energy dissipation coefficient rapidly changes but once the cyclic loading strain entered the plastic range the energy dissipation coefficient changes little and tends to be stable 3 cl 1 series specimens were subjected to constant amplitude cyclic loading and the energy dissipation coefficient was only degraded with pitting damage and almost does not change with the cycles of cyclic loadings besides the degradation ratio was about 4 5 when the maximum volume loss rate about 6 7 was reached 4 cl 2 cl 3 and cl 4 series specimens are subjected to variable amplitude cyclic loading it can be seen from the change process of energy dissipation coefficient that the effect of pitting damage on the energy dissipation capacity of elastic cyclic loading stage of the steel was more than plastic cycle loading stage 4 conclusions based on high strength steel nv d36 the mechanical properties of steel commonly used in offshore platforms under the action of pitting damage and extreme cyclic loading were studied the degradation law of the steel mechanical properties under the double damage was obtained the main conclusions are as follows 1 due to the local stress concentration of the steel caused by pitting the stress at the place of pitting damage is redistributed and as the degree of pitting damage deepens the oscillating degree of the steel yielding platform gradually decrease at the same time the generalized yield strength and ultimate strength of the steel degrade as the pitting volume loss rate increases 2 cyclic loading can strengthen the cyclic stress and strain of the steel but pitting damage lead to degradation of the cyclic stress and strain of the steel ramberg osgood model can well fit the backbone curve of the specimens with different pitting damage degrees specifically the cyclic hardening coefficient linearly degrades with the pitting volume loss rate and the degradation rate is almost irrelevant to the cyclic loading program however the cyclic hardening exponent is almost unaffected by pitting damage 3 the nv d36 steel has relatively good energy dissipation capacity regardless of whether there is pitting damage in steel the trend of the energy dissipation coefficient of steel is only related to the cyclic loading amplitude and is almost unaffected by pitting damage under constant amplitude cyclic loading the energy dissipation degradation almost does not change with the cycles of cyclic loading it is only related to pitting damage under variable amplitude cyclic loading the pitting damage has a great influence on the energy dissipation capacity of elastic cyclic loading stage of the steel and relatively small impact on the plastic cyclic loading stage of the steel 
22711,extreme cyclic loading and pitting are unavoidable damage factors for steel offshore platforms the degradation of mechanical properties of steel caused by such double damage cannot be obtained by a simple addition of degradation caused by a single damage in order to analyze the above problems the high strength steel nv d36 commonly used in offshore platforms was selected as an experimental specimen different degrees of pitting damage were generated by laboratory electrochemical accelerated corrosion seven typical cyclic loading programs were designed based on the real extreme cyclic loads that offshore platform may be subjected to the cyclic loads were applied to the specimens to obtain the hysteretic properties of healthy and pitting specimen under cyclic loading the stiffness and the strength of steel were strengthened in contrast pitting damage could cause local volume loss and local stress concentration which result in degradation of stiffness and strength of steel generalized yield strength and generalized young s modulus of steel were gradually degraded with the deepening of pitting damage the cyclic hardening coefficient linearly degenerated with the pitting volume loss rate and the degree of degradation was almost irrelevant to the cyclic loading program the cyclic hardening exponent was almost unaffected by pitting damage keywords high strength steel pitting damage extreme cyclic loading damage degradation 1 introduction the coupling effects of temperature humidity salinity ph and marine life in the marine environment can easily lead to corrosion of the offshore platform structure corrosion can be divided into general corrosion and local corrosion according to the corrosion form local corrosion mainly includes pitting corrosion galvanic corrosion crevice corrosion and stress corrosion etc among them pitting corrosion is the most common local corrosion chaves and melchers 2014 pitting parameters such as pitting depth pitting diameter pitting distribution and pitting morphology as shown in fig 1 affect the mechanical properties of the structure in varying degrees melchers 2004 valor et al 2007 the influence of pitting on the structure is generally operated by reducing the design plate thickness in the design of offshore platforms dunbar et al 2004 ok et al 2007 however the reduction of design plate thickness only can reflect the influence of pitting depth on the structure and it is impossible to measure the mechanical properties of other pitting parameters in addition offshore platforms are used in hostile marine environments and often subjected to cyclic loads such as wind waves currents and earthquakes wang et al 2006 therefore offshore platform structure and members suffer from different degrees of alternating stress the stress level of structural members is low when the structure is subjected to mild cyclic loads such as wind waves and currents the structural members under numerous cyclic loading about 104 times will cause high cycle fatigue damage instead when the structure is subjected to extreme cyclic loads the stress level of the structural members is high the structural members under cyclic loading about 102 104 times will result in low cycle fatigue damage when the structure is subjected to more extreme cyclic loads such as earthquakes hurricanes and tsunamis the structural members will be deformed in a short time the working state of structural members is quickly entered the plastic phase from the elastic phase resulting in a higher stress level of the structure and members in this case the ordinary structure can be damaged by ultra low cycle fatigue in 2 10 cycles kuroda 2002 nip et al 2010 compared with extreme cyclic loads offshore platforms are more common in encountering mild cyclic loads naturally there are many theoretical and experimental studies on high cycle fatigue caused by mild cyclic loading but there are relatively few studies on low cycle fatigue caused by severe cyclic loads abs 2014 dnvgl rp c203 2016 however due to the particularity of the service environment of the offshore platform the structural members subjected to pitting damage and ultra low cycle loads cannot be avoided therefore it is necessary to study the change law of mechanical properties of structure when it suffers from pitting damage and severe cyclic loads scholars have conducted many studies on pitting damage and cyclic loading of different material structures and members nakai et al 2004a b 2006 conducted a bending test on the typical members of bulk carriers with pitting damage by means of mechanical drilling and analyzed the bearing capacity and buckling behavior of the members zhang et al 2016 2017 studied the mechanical properties of uniaxial compression and shear buckling strength of hull plates with pitting damage qin et al 2016 studied the degradation laws of mechanical properties of q235 steel plates with corrosion and found that all the mechanical property index significantly decreases when the corrosion rate is over 15 imperatore et al 2017 conducted an experimental study on the monotonic mechanical properties degradation relationship of reinforcing steel bars with corrosion and developed degradation relationship for the main mechanical properties zhang et al 2012 conducted a study on the monotonic tensile loading properties and fatigue properties of corrosive reinforcing steel bars it is concluded that the ultimate strength and yield strength of steel degraded with the increase of corrosion damage similarly the fatigue life of steel sharply decreases with the increase of corrosion damage but the fatigue properties is more serious than the monotonic loading properties xu and qiu 2013 conducted a fatigue test on pitting specimens of q235 steel which shows that the presence of pitting corrosion can significantly reduce the fatigue life of the steel fernandez et al 2015 studied the monotonic loading mechanical properties and cyclic loading mechanical properties of reinforcing steel bars and established the relationship between monotonic loading mechanical properties and pitting loss rate and analyzed the impact of pitting geometry on fatigue life of reinforcing steel bars apostolopoulos and papadopoulos 2007 studied the monotonic properties and ultra low cycle fatigue properties of pitting specimens of s400 steel pointing out that the monotonic properties and the degradation of ultra low cycle fatigue characteristics are closely related to the degree of pitting damage caprili and salvatore 2015 investigated the low cycle loading mechanical properties of healthy and pitting specimen of steel reinforcing bars and analyzed the residual mechanical properties and energy dissipation capacity of the steel reinforcing bars in addition some scholars have carried out cyclic loading tests on healthy without pitting ordinary steel high strength steel and stainless steel respectively analyzed their monotonic performance and hysteretic performance respectively that obtained steels are hardened under cyclic loading nip et al 2010 shi et al 2012 wang et al 2017 ma et al 2018 the strength and energy dissipation of the steel is hardened under the cyclic loading however local stress concentration and cyclic cumulative damage may occur in the steel when the steel encounters both pitting damage and ultra low cycle loading which lead to serious degradation of the mechanical properties of the steel unfortunately due to the strong randomness of pitting damage and cyclic loading the related research is still relatively lacking it is difficult to analyze the degradation of mechanical properties of steel caused by pitting damage and cyclic loading theoretically therefore it is almost certain that experimental research is a relatively reliable analytical method currently specifically the reasonable preparation of pitting damage on the structural members and the appropriate design of ultra low cycle loading test are the key to obtain the change law of mechanical properties of steel in addition to the real test method the accelerated test method is a widely used for preparing pitting damage nakai et al 2004a b and okamoto et al 2010 also confirmed that the pitting damage prepared by the accelerated test method can well reflect the real pitting damage effect fig 2 shows the measured seismic acceleration velocity spectrum from the peer database yang et al 2017 which fully demonstrate the stochastic properties of extreme cyclic loading it also shows that the cyclic loading mechanical properties of the material not only depend on the material s characteristics but also on the characteristics of the cyclic load in the above literature nip et al 2010 shi et al 2012 ma et al 2018 the form of cyclic load is triangular waveform like real cyclic loads but loading amplitude loading history and loading time are different therefore certain types cyclic loading program should be designed in the cyclic loading test to reflect the characteristics of material itself and extreme cyclic loads based on the above analysis this paper selected the high strength steel nv d36 commonly used in offshore platforms to design healthy without pitting test specimens and then the pre pitting of healthy specimens was carried out by the constant current electric method to obtain pitting specimens with different damage degrees it is worth noting that in order to obtain the change of the mechanical properties of the component as clearly as possible the pitting test specimen does not consider the effects of the pitting distribution and the coupling between the pitting therefore the pitting corrosion of the specimen was set to single pitting subsequently different types of cyclic loading systems were designed according to the monotonic mechanical properties of the steel and the characteristics of the extreme cyclic loads to carry out the cyclic loading test eventually we analyzed and discussed the degradation law of monotonic properties and hysteresis properties of the steel with experimental results 2 material and experimental arrangements 2 1 material and specimen design the specimen was taken from the high strength steel nv d36 certificated by dnv classification society commonly used in offshore platforms the carbon content of the steel is about 0 11 and the other chemical elements are shown in table 1 the yield strength and tensile strength of the steel are about 430 mpa and 553 mpa respectively the elongation is about 26 due to the difference of test conditions between laboratory and steel mill the mechanical properties of the steel provided by the steel mill are only for reference in this paper the steel was subjected to a monotonic loading test to obtain its basic mechanical properties according to the astm test standard astm 2012 and considering the characteristics of the cyclic loading system the specimen was designed as a plate therefore in order to avoid buckling of the specimen under a large cyclic compress loading the aspect ratio of the specimen was slightly smaller than the recommended value of the astm test standard the specimen consists of three parts parallel test area curved transition area and end clamping area details of shape and dimensions of the specimen are shown in fig 3 in addition in order to decrease the error caused by the test equipment same type specimen was used for the monotonic loading test and the cyclic loading test 2 2 pitting test 2 2 1 pitting test setup pitting specimen was obtained by healthy specimen without pitting that use accelerated test method for the preparation of pitting corrosion damage unlike the pitting damage prepared by mechanical drilling method adopted by nakai et al 2004a b 2006 this paper used the constant current electric method to electrochemically corrode steel specimen to obtain pitting specimen on the one hand the principle of constant current electric test was the same as that of real pitting damage szklarska smialowska and mankowski 1972 on the other hand the geometric characteristic parameters of the pitting damage obtained by the preparation have random distribution characteristics which also reflect the pitting damage characteristics of the real structure pitting test setup mainly includes ps 603d constant current source plastic container inert electrode and nacl solution with a mass fraction of 5 the inert electrode placed in the electrolyte solution and the reserved area of the test piece were connected to the positive and negative pole of the power source respectively and then a constant intensity current was applied to the entire test system the healthy specimen without pitting as the anode of the electrolytic cell was oxidized and dissolved and then pitting specimens with different degrees of damage were obtained the electrochemical accelerated corrosion test system is shown in fig 4 2 2 2 pitting damage evaluation index pitting depth and pitting diameter were generally used as evaluation indexes of pitting damage degree in practical applications however pitting damage had many geometrical parameters such as pitting depth pitting diameter pitting distribution pitting shape cross sectional area loss and volume loss paik et al 2004 valor et al 2007 therefore a single pitting characteristic parameter cannot fully reflect the geometric characteristics of pitting damage in order to consider the influence of pitting damage on the mechanical properties of steel comprehensively this paper selected the volume loss as the evaluation index to measure the damage degree of pitting in the electrochemical accelerated corrosion test the pitting characteristic parameters such as pitting depth h and pitting diameter d of each specimen have some randomness due to random factors such as material properties and current the cross sectional shape of the specimen at the pitting is irregular which brings certain difficulties to the measurement of actual pitting cross sectional area relatively speaking it is more convenient and practical to use the volume loss rate as the evaluation parameter of pitting damage degree to characterize the influence of pitting moreover the pitting volume loss also can comprehensively reflect the joint effect of pitting depth h pitting diameter d pitting distribution ψ and pitting shape φ and other geometric parameters the above geometric parameters can be considered as a function of the pitting loss volume as shown in eq 1 furtherly compared the pitting volume loss with the original volume the volume loss rate that measures the degree of pitting damage can be obtained as shown in eq 2 1 δ v h d ϕ ψ 2 η v δ v v c 2 2 3 specimen type and naming rule pitting specimen derived by constant current electric method was shown in fig 5 the pitting depth and diameter were the average of two measurements the pitting depth was divided into five categories 0 mm 1 mm 1 5 mm 2 mm and 2 5 mm and each type with 7 specimens the pitting shape was between semi spherical and conical and ratio of pitting depth to pitting diameter was about 4 1 10 1 which basically conforms to the real statistical law of pitting damage paik et al 2004 the details of pitting damage were shown in table 2 all test specimens were named in the format of x yl z where x represents the pitting depth of the specimen which can be taken as 0 0 mm 1 0 mm 1 5 mm 2 0 mm and 2 5 mm yl stands for loading mode which represents the monotonic loading ml and cyclic loading cl respectively z stands for cyclic loading system number which can be taken as 1 7 monotonic loading specimens not have this number for instance 0 0 ml represents a monotonic loading specimen with a pitting depth of 0 0 mm 1 5 cl 4 represents a cyclic loading specimen with a pitting depth of 1 5 mm and the cyclic loading program was cl 4 2 3 monotonic cyclic loading test 2 3 1 loading setup both the monotonic loading test and the cyclic loading test were carried out with an instron8801 servo hydraulic fatigue tester with a dynamic load capacity of 100 kn the strain in the parallel test area of specimen was measured by a tensile and compression extensometer the gauge length of the tensile and compression extensometer was 12 5 mm and the strain measurement range was 35 therefore the strain more than 35 only can be obtained by conversion of displacement recorded by the machine in addition the input and output data of tensile and compressive loads displacements and strains were collected in real time by a static strain test system with a data acquisition frequency of 50 hz the physical diagram and schematic diagram of the hydraulic fatigue tester and the tensile and compression extensometer were shown in fig 6 2 3 2 loading program 2 3 2 1 monotonic loading program according to the test standard iso 6892 1 2009 five pitting specimens with different damage degrees were subjected to monotonic loading test to obtain the monotonic loading mechanical properties of the steel 2 3 2 2 cyclic loading program based on the characteristics of monotonic loading of the steel and the extreme cyclic loads of offshore platforms a variety of cyclic loading program were designed to investigate the change of monotonic properties damage degradation cyclic hardening and energy dissipation of the steel with pitting damage ma et al 2018 cl 1 cyclic loading program mainly analyzed the influence of constant amplitude cyclic loading on the damage degradation and energy consumption of the steel the loading program corresponds to the common cyclic loads such as wind wave and current in marine environment cl 2 and cl 6 cyclic loading programs mainly studied the change of backbone curve and energy dissipation of the steel under increasing amplitude step by step cyclic loading and stepwise reduction cyclic loading respectively the two cyclic loading programs correspond to the initial stage and end stage of extreme cyclic loading cl 3 and cl 4 cyclic loading programs mainly investigated the backbone curve and energy dissipation capacity of steel when the structure was in different plastic work stage cl 5 cyclic loading program mainly analyzed the energy dissipation of the steel under cyclic loading with the relative value of the cyclic loading amplitude was a constant but the loading peak gradually increased cl 7 cyclic loading program mainly studied the energy dissipation of steel under random cyclic loading the details of the cyclic loading programs were shown in fig 7 it should be noted that the cyclic loading test is shown as strain control and essentially belongs to displacement control in fig 7 a complete tension and compression loading like between two red dots in fig 7 a is recorded as one cycle of cyclic loading δε represents the strain increment of the variable amplitude cyclic loading which means the peak value of the cyclic loading of the latter cycle increases by δε with respect to the previous cycle high strain rate will cause an increase in the temperature of specimen during monotonic and cyclic loading test in order to reduce the influence of strain rate on the test results the strain rate is taken as 0 05 hz astm 2012 besides all loading tests were carried out at room temperature 3 analysis of test results healthy specimens no pitting and pitting specimens were subjected to monotonic loading and cyclic loading test respectively and then the monotonic loading curves and the hysteresis curves were obtained as shown in fig 8 and fig 18 the stress and strain marked in the figure were generalized stress and generalized strain calculated by eq 3 and eq 4 the stress and strain of the pitting specimen are called generalized stress and generalized strain because they are calculated from the original cross sectional area and the original length of test area respectively this treatment can not only facilitate the calculation of the stress of the specimen but also clearly obtain the influence of pitting damage on the mechanical properties of the steel it can be seen from fig 8 that the monotonic behaviors and hysteresis behaviors of the steel deteriorate to varying degrees as the pitting damage increased 3 ε ε g e n δ l l 0 4 σ σ g e n f a 0 where σ gen and ε gen are the generalized stress and generalized strain of the steel respectively δl is the displacement of the parallel test area of specimen l 0 is the initial length of the parallel test area of specimen f is the tensile or compressive load a 0 is the initial cross section area of the parallel test area of specimen 3 1 damage degradation characteristics of specimen compared the hysteresis curves of the cl 1 cl 2 and cl 6 series of specimens in fig 8 it is easy to obtain that the strength and stiffness of the nv d36 steel hardly deteriorate whether it suffers from constant amplitude cyclic loading or variable amplitude cyclic loading moreover the strain amplitude of the cyclic loading corresponds to the elastic or plastic loading state of specimen does not cause significant cyclic cumulative damage fig 9 shows the stress and strain under each cycle of the cl 1 cyclic loading program in detail it can be seen from the partial enlarged view of fig 9 b that the nv d36 steel with four pitting damage degrees after 10 times of constant amplitude cyclic loading the stress strain curves of each group can almost coincide this shows that there is no significant strength and stiffness degradation in the steel however it is worth noting that shi et al 2011 conducted a low cycle loading study on the healthy specimens without pitting of q235 steel and q345 steel and found that these steels appeared different degrees of cyclic cumulative damage during cyclic loading although the cyclic loading program used in the cyclic loading test is the same as that used by shi et al 2011 the cyclic cumulative damage of the nv d36 steel healthy specimens is relatively small and almost can be neglected therefore the above analysis can show that the cyclic cumulative damage of nv d36 steel in both healthy and pitting damage is relatively small and the degree of cyclic cumulative damage is related to the type of steel the low cycle loading studies of healthy specimens of nv d36 steel have been completed in the author s previous work ma et al 2018 however the presence of pitting damage can lead to a significant decrease in the strength and stiffness of the steel which is reflected in all cyclic loading programs as shown in fig 8 moreover the damage to mechanical properties of the steel deteriorate more serious as the pitting damage deepens fig 9 shows the effect of pitting damage on the strength and stiffness of the steel under cl 1 cyclic loading program in detail cyclic loading test was immediately stopped once the specimen has local buckling therefore the deterioration of mechanical properties caused by local buckling of the specimen can be eliminated compared the hysteresis curves of the specimen under each cyclic loading program it can be concluded that the cyclic cumulative damage of the steel can be neglected under the cyclic loading but the pitting damage cause the steel strength and stiffness degraded seriously 3 2 monotonic behavior analysis the elastic stage of the hysteresis curve was in the initial stage of cyclic loading therefore the generalized yield strength and generalized young s modulus of the steel can be analyzed by the elastic section of the hysteresis curve 3 2 1 relationship between generalized yield strength and degree of pitting damage fig 10 a shows the hysteresis curve of the cl 1 loading system series specimen from the partial enlargement of the circle in fig 10 b oscillation of yielding platform of the steel became weaken gradually as the degree of pitting damage increases the place of the specimen where pitting damage exist in was at a higher stress level when pitting specimen under monotonic loading as the pitting damage was deepened volume loss at the pitting damage gradually increased which resulting in the stress concentration at the pitting damage deepening gradually and stress redistribution was not obvious furtherly resulting in uneven stress distribution at the same cross section therefore the local and whole of pitting specimen cannot yield at the same time which lead to the steel enters the yielding state ahead of time and the upper yielding point and the lower yielding point are gradually closer as shown in fig 10 b as the loads continues to act on the specimen the yield state of the steel lasts for a short time which caused the steel quickly cross the yielding stage and enter the hardening stage the existence of pitting damage not only lead to the gradual disappearance of the yield platform of the steel but also caused different degrees of degradation of the generalized yield strength of the steel fig 11 shows the degradation of the generalized yield strength of all specimens with the pitting volume loss rate the generalized yield strength degradation ratio was as high as 19 1 when the maximum volume loss rate about 6 7 was reached mathematical fitting of the data points showed that the generalized yield strength is linearly degenerate and the degradation rate was about 2 8 in addition the goodness of fit of the degradation relationship was 0 975 which indicating the two factors above have a high relativity therefore it can be considered that the volume loss of the pitting damage was an important factor lead to the decrease of the generalized yield strength of the steel similarly the pitting volume loss rate can be used as an important index to evaluate the degradation of steel generalized yield strength in addition it is found that the generalized yield strength degradation degree of the steel was relatively uniform and the degree of dispersion of the data was small when the pitting volume loss rate was small however when the pitting volume loss rate was more than 5 the dispersion of steel generalized yield strength data increased which also indicates that as the degree of pitting damage gradually deepens the steel has an unstable yield process under monotonic loading 3 2 2 relationship between generalized young s modulus and degree of pitting damage the deepening of the pitting damage will not only lead to the degradation of the generalized yield strength of the steel but also the deterioration of the generalized young s modulus of the steel fig 10 b shows the degradation of the generalized young s modulus of the cl 1 series of specimens it can be seen that the degree of pitting damage increases the same but the degree of degradation was not the same the relationship between the generalized young s modulus of all specimens and the pitting volume loss rate was shown in fig 12 under certain volume loss rate the degree of degradation of generalized young s modulus of different specimens was not consistent when the maximum volume loss rate about 6 7 is reached the generalized young s modulus will be seriously degraded and the degradation rate was as high as 31 1 moreover the dispersion of the data was higher than generalized yield strength data of the steel mathematical fitting of the data points in fig 12 revealed that the degradation of generalized young s modulus and pitting volume loss rate was also linear and the degradation rate was about 4 6 in addition the goodness of fit of the degenerate relationship was about 0 781 which indicate that the relativity between the two factors above was insignificant and indicate that the pitting loss volume has an insignificant contributes to the degradation of generalized young s modulus maybe other pitting parameters were more relevant to the degradation of generalized young s modulus 3 3 hysteretic behavior analysis 3 3 1 backbone curve analysis the internal structure of the steel was dislocated and blocked under cyclic loading which lead to the strength of the steel was cyclically hardened the ultimate strength after cyclic loading was increased by about 5 27 compared with the monotonic loading as shown in fig 13 however due to the existence of pitting damage the strength of the steel was degraded as the degree of pitting damage deepens the proportion of steel strength degradation exceeds the degree of cyclic hardening which result in the strength of the steel was even lower than that of the healthy specimen without pitting as shown in figs 15 figs 16 and 17 therefore in order to quantitatively study the influence of pitting damage on the strength of steel the backbone curve of steel was analyzed the backbone curve was an envelope curve obtained by sequentially connecting the extreme points of the tensile or compression direction on the hysteresis curve which can reflect the stress strain relationship of the steel under cyclic loading fig 14 shows the bidirectional backbone curve of the cl 3 loading program series specimen apart from the deterioration of the generalized yield strength of the steel the backbone curve also showed a different degree of degrade with the deepening of the pitting damage besides the stress strain relationship in the compression direction was more degraded and more sensitive to pitting damage in order to more intuitively analyze the influence of pitting damage on the steel backbone curve the forward backbone curves of cl 2 cl 3 and cl 4 cyclic loading program series specimen were mathematically fitted the forward backbone curve fitting model used the ramberg osgood model ramberg and osgood 1943 and the ramberg osgood model was shown in eq 5 5 δ ε 2 δ ε e 2 δ ε p 2 δ σ 2 e δ σ 2 k 1 n where δε is the total strain amplitude δε e is the elastic strain amplitude δε p is the plastic strain amplitude δσ is the stabilized stress amplitude at half of number of cycles e is the young s module k is the cyclic hardening coefficient and n is the cyclic hardening exponent which were parameters need to be fitted the fitting results are shown in fig 15 fig 16 and fig 17 it can be seen that ramberg osgood model can fit the backbone curve of nv d36 steel very well quantitative analysis of the parameters to be fitted of the above backbone curve was carried out to obtain a relationship between the cycle hardening exponent n and the cycle hardening coefficient k and the pitting volume rate loss as shown in fig 18 the cyclic hardening exponent was highly correlated with the cyclic loading program specifically the cyclic hardening exponent rely on loading amplitude of steel and the cyclic loading history but for the same cyclic loading program the cyclic hardening exponent hardly change with the pitting volume loss rate as shown in fig 18 a similarly the cyclic hardening coefficient was also highly correlated with the cyclic loading program but unlike the cyclic hardening exponent the cyclic hardening coefficient and the pitting loss rate were linearly degraded when the maximum volume loss rate about 6 7 was reached the degradation ratio of the cycle hardening coefficient was as high as 18 8 in addition the quantitative degradation relationships between cyclic hardening coefficient and pitting volume rate loss were obtained by mathematical fitting as shown in fig 18 b it can be easily seen that the degradation rate of the cyclic hardening coefficient under each cyclic loading program was almost the same which indicate the effect of cyclic loading program on degradation rate of the cyclic hardening coefficient was relatively small 3 3 2 energy dissipation analysis the above analysis showed that the mechanical properties such as strength and stiffness of the steel caused by pitting damage were more serious than the cumulative damage caused by the cyclic loading of the steel itself in order to study the comprehensive influence of pitting damage on the above mechanical properties of steel the energy dissipation of steel was analyzed the area enclosed by the hysteresis curve indicates the energy consumption of the steel as shown in fig 19 which can comprehensively measure the mechanical properties such as strength stiffness and cyclic hardening of the steel the energy dissipation coefficient of steel was usually evaluated by the energy dissipation coefficient the formula for calculating the energy dissipation coefficient was shown in eq 6 6 e e s a c g s e c g s δ a o b s δ e o f where s acg and s ecg are the area of the hysteresis curves in the upper and lower parts of the horizontal axis respectively s δaob 和s δeof are the area of the triangle in the upper and lower parts of the horizontal axis respectively the area of each part was shown in fig 19 fig 20 shows the change process of steel energy dissipation coefficient under different cyclic loading programs it is easy to see that nv d36 steel has strong energy dissipation capacity but the energy dissipation capacity of steel deteriorates with the deepening of pitting damage the specific analysis results are as follows 1 the energy dissipation coefficient of the specimens in the plastic working stage whether pitting exists or not was between 3 0 and 3 4 closing to the maximum value e emax that is equal to 4 0 the maximum energy dissipation coefficient of q345b steel was about 3 0 wang et al 2017 which indicates nv d36 steel have a relatively good energy dissipation capacity 2 the trend of steel energy dissipation coefficient almost unaffected by pitting damage was only related to the cyclic loading amplitude when the cyclic loading strain was in the elastic range the energy dissipation coefficient rapidly changes but once the cyclic loading strain entered the plastic range the energy dissipation coefficient changes little and tends to be stable 3 cl 1 series specimens were subjected to constant amplitude cyclic loading and the energy dissipation coefficient was only degraded with pitting damage and almost does not change with the cycles of cyclic loadings besides the degradation ratio was about 4 5 when the maximum volume loss rate about 6 7 was reached 4 cl 2 cl 3 and cl 4 series specimens are subjected to variable amplitude cyclic loading it can be seen from the change process of energy dissipation coefficient that the effect of pitting damage on the energy dissipation capacity of elastic cyclic loading stage of the steel was more than plastic cycle loading stage 4 conclusions based on high strength steel nv d36 the mechanical properties of steel commonly used in offshore platforms under the action of pitting damage and extreme cyclic loading were studied the degradation law of the steel mechanical properties under the double damage was obtained the main conclusions are as follows 1 due to the local stress concentration of the steel caused by pitting the stress at the place of pitting damage is redistributed and as the degree of pitting damage deepens the oscillating degree of the steel yielding platform gradually decrease at the same time the generalized yield strength and ultimate strength of the steel degrade as the pitting volume loss rate increases 2 cyclic loading can strengthen the cyclic stress and strain of the steel but pitting damage lead to degradation of the cyclic stress and strain of the steel ramberg osgood model can well fit the backbone curve of the specimens with different pitting damage degrees specifically the cyclic hardening coefficient linearly degrades with the pitting volume loss rate and the degradation rate is almost irrelevant to the cyclic loading program however the cyclic hardening exponent is almost unaffected by pitting damage 3 the nv d36 steel has relatively good energy dissipation capacity regardless of whether there is pitting damage in steel the trend of the energy dissipation coefficient of steel is only related to the cyclic loading amplitude and is almost unaffected by pitting damage under constant amplitude cyclic loading the energy dissipation degradation almost does not change with the cycles of cyclic loading it is only related to pitting damage under variable amplitude cyclic loading the pitting damage has a great influence on the energy dissipation capacity of elastic cyclic loading stage of the steel and relatively small impact on the plastic cyclic loading stage of the steel 
22712,this paper gives a review of the experimental methods developed in the towing tank of the pprime institute of the university of poitiers france for the characterization of ship wakes and drag forces in confined waters different waterway configurations in calm water and in the presence of a current are reproduced in the experimental facility and small scale ship models of different block coefficients are considered stereoscopic optical methods have been developed in the laboratory for the measurement of the free surface deformation around the ship the full wake generated by the ship is fully characterized and its hydraulic and undulatory properties are analyzed in both real space and spectral domain in addition a system for the measurement of the ship drag force has been set up and visualizations of the wakes have been performed in parallel with a high speed camera to relate the ship resistance crisis with its visual footprint in the wake nomenclature α b banks inclination angle a fft normalized amplitude of the fast fourier transform of the ship wake a 1 normalized amplitude of the transverse waves in calm water a 2 normalized amplitude of the transverse waves in counter current b beam width of the ship hull m c b block coefficient of the ship hull c d drag coefficient of the ship hull d draft of the ship hull m f h1 critical froude number sub trans f h2 critical froude number trans sup f h s froude depth number of the ship f l s froude length number of the ship f x axial component of ship resistance n g gravitational acceleration m s 2 h height of the ship hull m h water depth m h b height of the inclined bank m h bottom height of the double bottom m i expanded uncertainty k 2 of the ship resistance measurement n k x y wavenumber along the x longitudinal or y transversal axis m 1 l s length of the ship m l c length of the canal m l 1 normalized length of the wash zone in calm water l 2 normalized length of the wash zone in counter current λ t 1 normalized wavelength of the transverse waves in calm water λ t 2 normalized wavelength of the transverse waves in counter current m blockage ratio of the waterway ρ density of water kg m3 s w wetted surface area of the ship m2 u s ship speed m s 1 u c velocity of the river current m s 1 u r velocity of the return current m s 1 w large width of the waterway m w small width of the waterway m w b width of the inclined bank m x longitudinal dimension of the wake m δx spatial resolution along the x axis m y transversal dimension of the wake m δy spatial resolution along the y axis m z vertical dimension of the wake m δz spatial resolution along the z axis m 1 introduction when a ship progresses in a confined waterway such as a river a canal or an estuary it faces an increase in the advancing resistance and also experiences various phenomena in the waterway there is a lowering of the water level combined with the generation of a return current around the ship hull the waves generated in its wake interact with the current of the waterway and reflect on the river banks causing erosion and sediment transport issues to prevent their appearance in the waterway for both economical reduce fuel consumption and ecological reduce bank erosion reasons many numerical studies are performed linde et al 2017 pacuraru and domnisoru 2017 razgallah et al 2019 terziev et al 2018 however the specific properties of the confined water wakes are not completely described numerically or theoretically experimental investigations are still necessary to understand the generation and the propagation of the waves and the flow with respect to the functional and geometrical parameters of the ship and the waterway this path of research has been investigated in the past few years by the hydrodynamic and environmental flows team of the pprime institute of the university of poitiers in france a configuration of confined waterway with a presence of current has been reproduced in the towing tank of the laboratory several experimental methods have been developed for the measurement of the ship resistance the characterization of the return current around the hull the study of the wave reflections and the full field characterization of the generated ship wake to investigate the properties of the waves generated by the hulls a fine characterization of the free surface is indispensable to lead the analysis in the spectral domain on the basis of the theory of the waves generated by a uniformly moving source established by ekman 1906 and crapper 1964 and the recent review of the geometrical properties of the emitted patterns in the real and spectral spaces by carusotto and rousseaux 2013 a spectral analysis method of ship wakes has been developed such spectral analysis methods have been proposed by mckenzie 1970 and lighthill 1979 griffin et al 1996 and arnold bos et al 2007 have used them to estimate the velocity of a ship or the shape of its hull from synthetic aperture radar sar images or high resolution optical images of the wake however these methods have never been validated experimentally in the field of ship wakes measured in the laboratory in the first part of the paper the waterway configuration set up in the towing tank of the pprime institute is presented and the small scale ship models representative of maritime and river ships are introduced in the second part the experimental measurement methods are detailed and the spectral analysis method is detailed then the main results of the studies are presented and finally research perspectives will be exposed with the future project of development of the canal 2 the towing tank and the ship models 2 1 the waterway fig 1 represents the cross section of the towing tank of the pprime institute it is composed of a bottom trapezoidal section of small width w 1 10 m and large width w 1 50 m and a top rectangular section of same width the inclination of the banks is α b 45 and their width and height are w b h b 0 20 m a double bottom of height h bottom 0 38 m can be installed in the towing tank to reduce the water depth to reproduce a shallow waterway of rectangular cross section of depth h the water depth has been set up to h 0 103 m for the experiments the rail mounted towing carriage displaces the ship hull at a speed u s up to 2 35 m s 1 along the canal of length l c 20 m the double bottom gives also the possibility to generate a current by placing a circulator in the lower section and two honeycombs structures at the extremities of the canal to laminarize the flow the current can be generated in both directions with respect to the ship motion co or counter current the canal is equipped with bottom and lateral windows to perform optical measurements and visualizations 2 2 the small scale ship models in order to compare the experimental results with numerical calculations of ship wakes and ship resistance two generic ship hulls of parabolic shape have been considered they are based on the wigley 1926 hull form with a rectangular cross section mathematically defined by eq 1 with n 2 for a classical wigley hull 1 y f x b 2 1 2 x l s n as the block coefficient of such a wigley hull is c b 0 67 another wigley based ship hull with an exponent n 8 giving a block coefficient c b 0 89 has been considered caplier et al 2019 these two ship hulls noted wh2 and wh8 because of their n coefficients are then representative of maritime and river ships in terms of block coefficients the ship hulls dimensions are l s 1 20 m b 0 18 m and h 0 15 m and their draft is set up to d 0 075 m for the experiments they are shown on fig 2 as regards the effects of scale the ship speeds for the experiments are set high enough to avoid capillary effects less than 5 in this range of ship speeds the effects of the scale on the flow characteristics are limited gomit et al 2015 3 the measurement and the analysis of the shallow water ship wake 3 1 measurement of the free surface deformation the free surface deformation is measured with a stereoscopic measurement method based on the principle of refraction of light rays through the surface of water that is developed in our laboratory gomit et al 2013 the setup is represented on fig 3 it is composed of two dantec speedsense 1040 cameras that deliver a resolution of 2320 1726 px mounted with nikkor af 28 mm 1 2 8 lenses they focus on the same zone with an opposite angle of 15 with respect to the longitudinal axis of the canal and 35 with respect to the vertical axis the common field covered by the cameras forms a rectangle of dimensions 0 75 0 90 m2 corresponding to the half width of the canal the stereoscopic system is calibrated by translating a dotted calibration plate and using a distortion model a speckle pattern is placed at the bottom of the canal and its image with the water surface at rest is recorded on the cameras for the reference then the ship is launched and the images of the pattern deformed by the free surface deformations are recorded on both cameras at a frequency of 10 frames per second with an exposure time of 10 ms each run is performed three times to check the repeatability of the measurement the image pairs are then processed with a reconstruction algorithm written in c and based on the slip library tremblais et al 2010 that computes the free surface deformation at each time step then the whole wake is reconstructed around the ship hull with a dedicated reconstruction program with a spatial resolution δx δy 10 mm and a precision δz 0 1 mm on the water level 3 2 analysis in the real space an example of the wakes measured in calm water and in the presence of a counter current with the stereo refraction measurement method are shown on fig 4 caplier et al 2015 these wakes are generated by the wh2 hull for a ship speed u s 0 45 m s 1 and a water depth h 0 103 m giving a froude depth number f h s u s gh 1 2 0 45 and a froude length number f l s u s gl s 1 2 0 13 the wake on the bottom of the figure is generated in a calm water configuration whereas the top one is generated in the presence of a counter current of velocity u c 0 20 m s 1 corresponding to an effective froude depth number in the referential of the laboratory f h s u s u c gh 1 2 0 65 caplier et al 2015 a qualitative analysis of these wakes in the real space shows that the transverse wavelength and amplitude are increasing in the presence of the counter current the waves generated by the ship in its wake are convected by the current that results in a widening of the wash zone at the banks of the canal for a quantitative comparison of the wakes longitudinal or transverse cuts can be made in the wave fields fig 5 represents the longitudinal cuts performed for the calm water and counter current wakes for the same ship speed the length of the wash zone increases from 0 9l s to 2l s l s 1 2 m is the ship length with the counter current representing more than a doubling of its length the transverse waves amplitude and wavelengths at the river banks respectively grows from a 1 0 012h to a 2 0 059h h 0 103 m is the initial water depth and from λ t 1 0 1l s to λ t 2 0 3l s an increase of nearly 500 of the amplitude and 30 of the wavelength 3 3 spectral analysis of ship wakes the stereo refraction measurement method gives a full detailed and fine reconstruction of the ship wake then it is possible to proceed the analysis in the spectral space by computing the bidimensional fast fourier transform fft of the wake the method has been introduced by carusotto and rousseaux 2013 developed by gomit et al 2014 for the analysis of ship wakes in deep water and then adapted by caplier et al 2016 for the analysis of ship wakes generated in shallow water an example of the spectrum of the wake generated by the wh8 hull for a ship speed u s 0 80 m s 1 and a water depth h 0 103 m giving a froude depth number f h s u s gh 1 2 0 80 and a froude length number f l s u s gl s 1 2 0 23 is given on the right of fig 6 caplier et al 2016 the color on the spectrum represents the spectral repartition of the normalized amplitude of the fft along the different wave lengths and directions in the wake the high pass or low pass filtering of the spectrum and its reconstruction in the real space by computing an inverse bidimensional fft allows to separate the hydraulic and undulatory components of the wake gomit et al 2014 caplier et al 2016 3 4 measurement of the return current the stereoscopic system can also be used to measure the return current generated around the hull by computing the displacements of floating particles placed at the surface of the water the images of these markers can then be processed by a stereo piv algorithm to calculate the flow velocity chatellier et al 2013 the result is given on fig 7 on which the return current is measured around the wh2 hull for a ship speed u s 0 70 m s 1 and a water depth h 0 103 m giving a froude depth number f h s u s gh 1 2 0 70 and a froude length number f l s u s gl s 1 2 0 20 the return current is calculated in the whole field around the hull it reaches its maximum of amplitude 30 of the ship speed at the middle of the hull and extends along the whole width of the waterway then its direction alternates between the crests and troughs of the transverse waves and its amplitude decreases slowly 4 the ship resistance and its visual footprint resistance trials have been carried out in the towing tank of the pprime institute the measurement of the ship drag force is performed with a kistler 9272 multi component dynamometer installed between the ship hull and the towing mast fig 8 the six component piezoelectric sensor measures the axial forces in each direction as well as the torques the ship resistance is taken as the axial force f x opposed to the motion of the ship the maximum measured amplitude is f x 20 n and the uncertainty is i 0 80 n caplier 2015 then the non dimensional drag coefficient c d can be derived with equation 2 where s w is the wetted surface area of the ship 2 c d f x 1 2 ρ s w u s 2 fig 9 represents the drag coefficients of the wh2 and wh8 hulls measured in a shallow water configuration h 0 103 m at different ship speeds the froude depth number of the ship f h s is between 0 60 and 1 31 and the froude length number of the ship f l s is between 0 18 and 1 38 the evolution of the ship resistance is bounded by the critical froude depth numbers f h1 and f h2 calculated by schijf s theory schijf 1949 these critical froude depth numbers are calculated by equations 3 and 4 3 f h 1 2 s i n a r c s i n 1 m 3 3 2 4 f h 2 2 s i n π a r c s i n 1 m 3 3 2 they depend on the blockage ratio m cross section of the ship to cross section of the canal in the present experiments m 0 087 a sudden increase of the drag coefficient is observed for f h s fh1 0 64 for both hulls this increase referred as the resistance crisis appears at the boundary between the sub critical and the transcritical regime finally there is a decrease of the ship resistance at the entrance in the supercritical regime for f h s fh2 1 37 parallel visualizations have been made during the resistance trials with a high speed camera photron fastcam sa1 of resolution 1024 1024 px equipped with a sigma 28 mm f1 8 dg asp lens fig 8 the camera is installed on the side of the canal and captures images of the wave amplitudes at the window during the passage of the ship at a frequency of 125 fps then a dedicated algorithm assembles the images to give a picture like representation of the wave amplitudes fig 10 represents the visualizations performed during the transition between the subcritical and transcritical regime froude depth number f h s from 0 60 to 0 85 and froude length number f l s from 0 19 to 0 22 these visualizations highlight an increase of the transverse wavelength and amplitude at the boundary between the subcritical and transcritical regimes a wave breaking is also visible on some waves so when a ship navigates in a confined waterway it experiences a sudden increase of its fuel consumption and the waves that it generates grow break and reflect on the river banks that process is destructive for the river banks and needs to be investigated in a future work to prevent its appearance and to design appropriate bank protections 5 conclusions and perspectives during the past few years several experimental studies have been made in the towing tank of the pprime institute to investigate the effects of confinement on ships wakes and drag and to understand interaction between the ship and the waterway measurement methods have been developed and adapted for this topic to obtain a full and detailed measurement of the ship wake and to determine the drag forces applying on the hull these methods give high quality results that allow to perform a fine analysis of the wave properties in both real and spectral spaces the hydrodynamic effects appearing in the waterway can also be quantified and analyzed the comparison of the resistance diagrams with the visualizations of the wakes allows to identify the visual footprint of the crisis of ship resistance the towing tank of the pprime institute is currently under work and will be lengthened of one third of its actual length to reach 30 m the towing carriage and the current generation will also be improved these great improvements on the facility will open the way to future experimental studies in order to continue the investigations on this path of research 
22712,this paper gives a review of the experimental methods developed in the towing tank of the pprime institute of the university of poitiers france for the characterization of ship wakes and drag forces in confined waters different waterway configurations in calm water and in the presence of a current are reproduced in the experimental facility and small scale ship models of different block coefficients are considered stereoscopic optical methods have been developed in the laboratory for the measurement of the free surface deformation around the ship the full wake generated by the ship is fully characterized and its hydraulic and undulatory properties are analyzed in both real space and spectral domain in addition a system for the measurement of the ship drag force has been set up and visualizations of the wakes have been performed in parallel with a high speed camera to relate the ship resistance crisis with its visual footprint in the wake nomenclature α b banks inclination angle a fft normalized amplitude of the fast fourier transform of the ship wake a 1 normalized amplitude of the transverse waves in calm water a 2 normalized amplitude of the transverse waves in counter current b beam width of the ship hull m c b block coefficient of the ship hull c d drag coefficient of the ship hull d draft of the ship hull m f h1 critical froude number sub trans f h2 critical froude number trans sup f h s froude depth number of the ship f l s froude length number of the ship f x axial component of ship resistance n g gravitational acceleration m s 2 h height of the ship hull m h water depth m h b height of the inclined bank m h bottom height of the double bottom m i expanded uncertainty k 2 of the ship resistance measurement n k x y wavenumber along the x longitudinal or y transversal axis m 1 l s length of the ship m l c length of the canal m l 1 normalized length of the wash zone in calm water l 2 normalized length of the wash zone in counter current λ t 1 normalized wavelength of the transverse waves in calm water λ t 2 normalized wavelength of the transverse waves in counter current m blockage ratio of the waterway ρ density of water kg m3 s w wetted surface area of the ship m2 u s ship speed m s 1 u c velocity of the river current m s 1 u r velocity of the return current m s 1 w large width of the waterway m w small width of the waterway m w b width of the inclined bank m x longitudinal dimension of the wake m δx spatial resolution along the x axis m y transversal dimension of the wake m δy spatial resolution along the y axis m z vertical dimension of the wake m δz spatial resolution along the z axis m 1 introduction when a ship progresses in a confined waterway such as a river a canal or an estuary it faces an increase in the advancing resistance and also experiences various phenomena in the waterway there is a lowering of the water level combined with the generation of a return current around the ship hull the waves generated in its wake interact with the current of the waterway and reflect on the river banks causing erosion and sediment transport issues to prevent their appearance in the waterway for both economical reduce fuel consumption and ecological reduce bank erosion reasons many numerical studies are performed linde et al 2017 pacuraru and domnisoru 2017 razgallah et al 2019 terziev et al 2018 however the specific properties of the confined water wakes are not completely described numerically or theoretically experimental investigations are still necessary to understand the generation and the propagation of the waves and the flow with respect to the functional and geometrical parameters of the ship and the waterway this path of research has been investigated in the past few years by the hydrodynamic and environmental flows team of the pprime institute of the university of poitiers in france a configuration of confined waterway with a presence of current has been reproduced in the towing tank of the laboratory several experimental methods have been developed for the measurement of the ship resistance the characterization of the return current around the hull the study of the wave reflections and the full field characterization of the generated ship wake to investigate the properties of the waves generated by the hulls a fine characterization of the free surface is indispensable to lead the analysis in the spectral domain on the basis of the theory of the waves generated by a uniformly moving source established by ekman 1906 and crapper 1964 and the recent review of the geometrical properties of the emitted patterns in the real and spectral spaces by carusotto and rousseaux 2013 a spectral analysis method of ship wakes has been developed such spectral analysis methods have been proposed by mckenzie 1970 and lighthill 1979 griffin et al 1996 and arnold bos et al 2007 have used them to estimate the velocity of a ship or the shape of its hull from synthetic aperture radar sar images or high resolution optical images of the wake however these methods have never been validated experimentally in the field of ship wakes measured in the laboratory in the first part of the paper the waterway configuration set up in the towing tank of the pprime institute is presented and the small scale ship models representative of maritime and river ships are introduced in the second part the experimental measurement methods are detailed and the spectral analysis method is detailed then the main results of the studies are presented and finally research perspectives will be exposed with the future project of development of the canal 2 the towing tank and the ship models 2 1 the waterway fig 1 represents the cross section of the towing tank of the pprime institute it is composed of a bottom trapezoidal section of small width w 1 10 m and large width w 1 50 m and a top rectangular section of same width the inclination of the banks is α b 45 and their width and height are w b h b 0 20 m a double bottom of height h bottom 0 38 m can be installed in the towing tank to reduce the water depth to reproduce a shallow waterway of rectangular cross section of depth h the water depth has been set up to h 0 103 m for the experiments the rail mounted towing carriage displaces the ship hull at a speed u s up to 2 35 m s 1 along the canal of length l c 20 m the double bottom gives also the possibility to generate a current by placing a circulator in the lower section and two honeycombs structures at the extremities of the canal to laminarize the flow the current can be generated in both directions with respect to the ship motion co or counter current the canal is equipped with bottom and lateral windows to perform optical measurements and visualizations 2 2 the small scale ship models in order to compare the experimental results with numerical calculations of ship wakes and ship resistance two generic ship hulls of parabolic shape have been considered they are based on the wigley 1926 hull form with a rectangular cross section mathematically defined by eq 1 with n 2 for a classical wigley hull 1 y f x b 2 1 2 x l s n as the block coefficient of such a wigley hull is c b 0 67 another wigley based ship hull with an exponent n 8 giving a block coefficient c b 0 89 has been considered caplier et al 2019 these two ship hulls noted wh2 and wh8 because of their n coefficients are then representative of maritime and river ships in terms of block coefficients the ship hulls dimensions are l s 1 20 m b 0 18 m and h 0 15 m and their draft is set up to d 0 075 m for the experiments they are shown on fig 2 as regards the effects of scale the ship speeds for the experiments are set high enough to avoid capillary effects less than 5 in this range of ship speeds the effects of the scale on the flow characteristics are limited gomit et al 2015 3 the measurement and the analysis of the shallow water ship wake 3 1 measurement of the free surface deformation the free surface deformation is measured with a stereoscopic measurement method based on the principle of refraction of light rays through the surface of water that is developed in our laboratory gomit et al 2013 the setup is represented on fig 3 it is composed of two dantec speedsense 1040 cameras that deliver a resolution of 2320 1726 px mounted with nikkor af 28 mm 1 2 8 lenses they focus on the same zone with an opposite angle of 15 with respect to the longitudinal axis of the canal and 35 with respect to the vertical axis the common field covered by the cameras forms a rectangle of dimensions 0 75 0 90 m2 corresponding to the half width of the canal the stereoscopic system is calibrated by translating a dotted calibration plate and using a distortion model a speckle pattern is placed at the bottom of the canal and its image with the water surface at rest is recorded on the cameras for the reference then the ship is launched and the images of the pattern deformed by the free surface deformations are recorded on both cameras at a frequency of 10 frames per second with an exposure time of 10 ms each run is performed three times to check the repeatability of the measurement the image pairs are then processed with a reconstruction algorithm written in c and based on the slip library tremblais et al 2010 that computes the free surface deformation at each time step then the whole wake is reconstructed around the ship hull with a dedicated reconstruction program with a spatial resolution δx δy 10 mm and a precision δz 0 1 mm on the water level 3 2 analysis in the real space an example of the wakes measured in calm water and in the presence of a counter current with the stereo refraction measurement method are shown on fig 4 caplier et al 2015 these wakes are generated by the wh2 hull for a ship speed u s 0 45 m s 1 and a water depth h 0 103 m giving a froude depth number f h s u s gh 1 2 0 45 and a froude length number f l s u s gl s 1 2 0 13 the wake on the bottom of the figure is generated in a calm water configuration whereas the top one is generated in the presence of a counter current of velocity u c 0 20 m s 1 corresponding to an effective froude depth number in the referential of the laboratory f h s u s u c gh 1 2 0 65 caplier et al 2015 a qualitative analysis of these wakes in the real space shows that the transverse wavelength and amplitude are increasing in the presence of the counter current the waves generated by the ship in its wake are convected by the current that results in a widening of the wash zone at the banks of the canal for a quantitative comparison of the wakes longitudinal or transverse cuts can be made in the wave fields fig 5 represents the longitudinal cuts performed for the calm water and counter current wakes for the same ship speed the length of the wash zone increases from 0 9l s to 2l s l s 1 2 m is the ship length with the counter current representing more than a doubling of its length the transverse waves amplitude and wavelengths at the river banks respectively grows from a 1 0 012h to a 2 0 059h h 0 103 m is the initial water depth and from λ t 1 0 1l s to λ t 2 0 3l s an increase of nearly 500 of the amplitude and 30 of the wavelength 3 3 spectral analysis of ship wakes the stereo refraction measurement method gives a full detailed and fine reconstruction of the ship wake then it is possible to proceed the analysis in the spectral space by computing the bidimensional fast fourier transform fft of the wake the method has been introduced by carusotto and rousseaux 2013 developed by gomit et al 2014 for the analysis of ship wakes in deep water and then adapted by caplier et al 2016 for the analysis of ship wakes generated in shallow water an example of the spectrum of the wake generated by the wh8 hull for a ship speed u s 0 80 m s 1 and a water depth h 0 103 m giving a froude depth number f h s u s gh 1 2 0 80 and a froude length number f l s u s gl s 1 2 0 23 is given on the right of fig 6 caplier et al 2016 the color on the spectrum represents the spectral repartition of the normalized amplitude of the fft along the different wave lengths and directions in the wake the high pass or low pass filtering of the spectrum and its reconstruction in the real space by computing an inverse bidimensional fft allows to separate the hydraulic and undulatory components of the wake gomit et al 2014 caplier et al 2016 3 4 measurement of the return current the stereoscopic system can also be used to measure the return current generated around the hull by computing the displacements of floating particles placed at the surface of the water the images of these markers can then be processed by a stereo piv algorithm to calculate the flow velocity chatellier et al 2013 the result is given on fig 7 on which the return current is measured around the wh2 hull for a ship speed u s 0 70 m s 1 and a water depth h 0 103 m giving a froude depth number f h s u s gh 1 2 0 70 and a froude length number f l s u s gl s 1 2 0 20 the return current is calculated in the whole field around the hull it reaches its maximum of amplitude 30 of the ship speed at the middle of the hull and extends along the whole width of the waterway then its direction alternates between the crests and troughs of the transverse waves and its amplitude decreases slowly 4 the ship resistance and its visual footprint resistance trials have been carried out in the towing tank of the pprime institute the measurement of the ship drag force is performed with a kistler 9272 multi component dynamometer installed between the ship hull and the towing mast fig 8 the six component piezoelectric sensor measures the axial forces in each direction as well as the torques the ship resistance is taken as the axial force f x opposed to the motion of the ship the maximum measured amplitude is f x 20 n and the uncertainty is i 0 80 n caplier 2015 then the non dimensional drag coefficient c d can be derived with equation 2 where s w is the wetted surface area of the ship 2 c d f x 1 2 ρ s w u s 2 fig 9 represents the drag coefficients of the wh2 and wh8 hulls measured in a shallow water configuration h 0 103 m at different ship speeds the froude depth number of the ship f h s is between 0 60 and 1 31 and the froude length number of the ship f l s is between 0 18 and 1 38 the evolution of the ship resistance is bounded by the critical froude depth numbers f h1 and f h2 calculated by schijf s theory schijf 1949 these critical froude depth numbers are calculated by equations 3 and 4 3 f h 1 2 s i n a r c s i n 1 m 3 3 2 4 f h 2 2 s i n π a r c s i n 1 m 3 3 2 they depend on the blockage ratio m cross section of the ship to cross section of the canal in the present experiments m 0 087 a sudden increase of the drag coefficient is observed for f h s fh1 0 64 for both hulls this increase referred as the resistance crisis appears at the boundary between the sub critical and the transcritical regime finally there is a decrease of the ship resistance at the entrance in the supercritical regime for f h s fh2 1 37 parallel visualizations have been made during the resistance trials with a high speed camera photron fastcam sa1 of resolution 1024 1024 px equipped with a sigma 28 mm f1 8 dg asp lens fig 8 the camera is installed on the side of the canal and captures images of the wave amplitudes at the window during the passage of the ship at a frequency of 125 fps then a dedicated algorithm assembles the images to give a picture like representation of the wave amplitudes fig 10 represents the visualizations performed during the transition between the subcritical and transcritical regime froude depth number f h s from 0 60 to 0 85 and froude length number f l s from 0 19 to 0 22 these visualizations highlight an increase of the transverse wavelength and amplitude at the boundary between the subcritical and transcritical regimes a wave breaking is also visible on some waves so when a ship navigates in a confined waterway it experiences a sudden increase of its fuel consumption and the waves that it generates grow break and reflect on the river banks that process is destructive for the river banks and needs to be investigated in a future work to prevent its appearance and to design appropriate bank protections 5 conclusions and perspectives during the past few years several experimental studies have been made in the towing tank of the pprime institute to investigate the effects of confinement on ships wakes and drag and to understand interaction between the ship and the waterway measurement methods have been developed and adapted for this topic to obtain a full and detailed measurement of the ship wake and to determine the drag forces applying on the hull these methods give high quality results that allow to perform a fine analysis of the wave properties in both real and spectral spaces the hydrodynamic effects appearing in the waterway can also be quantified and analyzed the comparison of the resistance diagrams with the visualizations of the wakes allows to identify the visual footprint of the crisis of ship resistance the towing tank of the pprime institute is currently under work and will be lengthened of one third of its actual length to reach 30 m the towing carriage and the current generation will also be improved these great improvements on the facility will open the way to future experimental studies in order to continue the investigations on this path of research 
22713,an experimental study of the wave behavior in the sheltered area of a segmented detached rubble mound zero freeboard breakwater zfb on a steep beach is presented six regular and one irregular incident wave cases were considered it was deduced that the wave height distribution in the sheltered area of the zfb was influenced a in the region near the symmetry axis normal to the zfb mainly by wave transmission over the zfb crest and b in the region shoreward of the gaps between the segments of the zfb mainly by wave diffraction from the gaps the average wave heights in the sheltered area of the zfb normalized to the incident wave height increase with increasing incident wave period and decreasing incident wave height the wave setup distribution in the sheltered area of the zfb was influenced both by wave breaking on the structure and the development of currents wave setup increases with increasing incident wave height the transmission of waves over the zfb induces transfer of energy to higher frequencies of the power spectrum this transfer is sustained in the sheltered area of the zfb and it increases with increasing incident wave period or height keywords segmented detached rubble mound zero freeboard breakwater steep beach wave reflection transmission diffraction refraction spectral change 1 introduction coastal protection measures against the effect of environmental loads waves currents etc frequently include the construction of segmented detached low crested breakwaters lcb which contribute to coastal sediment transport control by reducing the wave energy transmitted to their leeside mangor et al 2017 lcbs allow enough water exchange between offshore and sheltered area to sustain water renewal in coasts of high environmental and recreational value usually these structures are of the emerged type i e their crest is above the still water level swl but in recent years interest has been directed towards submerged ones due to their reduced construction cost and their harmonization with the natural environment since detached lcbs are structures mostly used for shore protection their main operation is to dissipate part of the wave energy by inducing wave breaking but their presence drastically affects as well wave dynamics hydrodynamic circulation and sediment transport in their vicinity the related wave phenomena include reflection from the lcb breaking on the lcb transmission above the crest and through the core of the lcb diffraction from the gaps of a segmented lcb and around its heads refraction setup and beach reflection in the sheltered area of the lcb hence the wave reflection k r and transmission k t coefficients of lcbs as well as the wave setup δ and wave transformation in the sheltered area of detached lcbs are important design parameters diskin et al 1970 performed several 2d laboratory tests of wave setup in the sheltered area of lcbs and developed an empirical formula for δ as a function of r c h i where r c is the structure freeboard and h i is the incident wave height at the lcb toe seelig 1980 performed several 2d laboratory tests of wave transmission over lcbs with 17 different types of breakwaters most of them being rubble mound ones with and without permeable core but also some smooth ones he showed that wave transmission was related to breakwater characteristics such as freeboard and crest width and to wave runup the study also included the presentation of an empirical formula to predict k t for nonbreaking breaking monochromatic and irregular wave conditions van der meer and daemen 1994 reanalyzed most available preceded datasets of wave transmission over rubble mound lcbs for random waves and taking into consideration crest height and width and wave height and steepness they proposed an empirical formula for k t as a function of r c d n50 h i d n50 b d n50 and s op where b is the crest width d n50 is the nominal diameter of the rock armor and s op h i λ p is the incident wave steepness where λ p gt p 2 2π and t p is the incident wave peak period d angremond at al 1996 also reanalyzed existing datasets of wave transmission and derived an improved empirical formula relating k t to r c h i b h i and ξ where ξ tana λ p h i 1 2 is the iribarren number and tana is the breakwater seaward slope loveless et al 1998 performed 2d laboratory tests of wave setup in the sheltered area of lcbs and developed an empirical formula for δ as a function of the incident wave parameters and r c h c where h c is the structure height seabrook and hall 1998 performed 2d laboratory tests of submerged and zero freeboard rubble mound breakwaters under a wide range of design conditions and developed an empirical formula for k t with emphasis on the effect of large crest width on wave transmission van der meer et al 2000 investigated experimentally the spectral change of irregular waves transmitted over low crested dams and they found that the peak period t p of the transmitted waves remained practically equal to the peak period of the incident waves while the wave mean period t m02 m 0 m 2 1 2 where m 0 and m 2 are the zeroth and second moments of the wave power spectrum respectively goda 2000 reduced to about 0 65 of the incident wave mean period van der meer et al 2005 considered results from the laboratory tests in seabrook and hall 1998 calabrese et al 2002 and kramer et al 2005 in addition to the datasets considered in d angremond at al 1996 and they concluded that the empirical formula for k t in d angremond at al 1996 should be used for b h i 8 while they proposed a new empirical formula for k t to be used for b h i 12 and a linear interpolation between the two for 8 b h i 12 moreover a new empirical formula for the reflection coefficient k r was developed by modification of the empirical formulae in the rock manual ciria cur 1991 to account for overtopping results from the laboratory tests described in kramer et al 2005 related to waves and currents in the sheltered region of a configuration of detached lcbs were presented in zanuttigh and lamberti 2006 where among other results the wave height and setup were measured near the seaward and leeward toes of the lcbs for 5 incident wave cases buccino and calabrese 2007 presented a conceptual approach for the derivation of an empirical formula for k t based on the energy balance of wave transmission over lcbs the empirical formula was calibrated based on the experimental dataset in seabrook and hall 1998 zanuttigh and van der meer 2008 analyzed existing experimental datasets of wave reflection from lcbs and developed an empirical formula for k r which is consistent with the roughness parameter γ f found in overtopping research and depends on r c h t where h t is the transmitted wave height vicinanza et al 2009 studied experimentally the combined transmission diffraction effect on wave transformation and induced currents in the sheltered area of a single detached lcb the study included a definition for the global transmission coefficient k gt based on the combination of existing analytical and empirical formulae for wave transmission and diffraction and comparison of its predictions to the measured data zanuttigh and martinelli 2008 analyzed datasets of wave transmission over 2d and 3d permeable low crested breakwaters and specifically for the cases where overtopping was dominant over filtration they found that the reduction of the wave mean period after transmission was similar to the one in van der meer et al 2000 soldini et al 2009 compared the empirical formulae for δ developed by diskin et al 1970 loveless et al 1998 bellotti 2004 and calabrese et al 2008 based on their performance in one 2d overtopping only and three 3d overtopping and rip current laboratory datasets for cases of submerged breakwaters bars note that the formulae by diskin et al 1970 and loveless et al 1998 were based on 2d lcbs while the ones by bellotti 2004 and calabrese et al 2008 were based on 2d and 3d respectively strictly submerged barriers in the present work the interaction of incident waves with a segmented detached rubble mound zero freeboard breakwater zfb on a steep beach was studied experimentally with emphasis on the wave behavior in the sheltered area of the zfb this behavior depends on the incident wave parameters wave height wave period and angle of wave incidence the geometry and location of the zfb breakwater length gap length crest width breakwater slope armour size and water depth and the beach slope in the present study a physical model of a particular segmented detached rubble mound zfb on a beach of constant slope 1 15 was used while the effect of incident wave height and period was targeted by considering seven 7 cases of normally incident waves the main objectives were to a compute the reflection and transmission coefficients of the segmented detached zfb and b offer an assessment of trends in the behavior of wave height wave setup and wave spectral change in the sheltered area of the zfb the resulting dataset of the measurements is also suitable as a benchmark for numerical or theoretical models 2 experimental modeling experiments were conducted in the wave basin of the hydraulic engineering laboratory department of civil engineering university of patras the wave basin has surface area 12 7 m2 and water depth 1 05 m while it is equipped with a paddle wavemaker that can reproduce regular stokes cnoidal or solitary irregular linear or second order or recorded time series of waves the paddle operation is controlled by an active wave absorption control system schäffer and hyllested 1999 for wave generation with concurrent absorption of the reflected waves returning to the wave paddle opposite to the wavemaker a physical model of a beach with constant slope 1 15 was constructed and a physical model of a segmented detached rubble mound zfb was placed between water depths d s 18 cm seaward toe and d l 12 5 cm leeward toe figs 1 and 2 the zfb length at crest level was l b 2 60 m its crest width was b 20 cm while both its seaward and leeward slopes were tana 1 2 the permeable armor layer of the zfb consisted of two rows of rocks with nominal diameter d n50 4 cm while the core of the zfb was impermeable as it was formed by a framed steel sheet the weight of the rocks of the armor layer was computed using the corresponding formula in van der meer 1990 for the design wave height of 0 12 m wave guide walls at 4 m apart were also placed in the wave basin fig 1 in order to model a hypothetical prototype segmented detached zfb each wave guide corresponds to the symmetry plane in the middle of the gap between zfb segments therefore the gap length at crest level was l g 1 4 m resulting to l g l b 0 54 while the ratio of the zfb length over its distance from the shoreline was equal to 1 2 this setup is suited only for cases of normal shore incident waves indeed during the experiments no reflections were observed by the guide walls seaward of the zfb ensuring that normal shore wave conditions were achieved in the sheltered area of the zfb the wave guides acted nicely as symmetry planes and no wave distortion was observed in their vicinity any reflection off the guide walls of waves diffracted from the zfb head is properly modeling the waves diffracted from the head of the hypothetical neighboring zfb segment photographs of the configuration without and with water are shown in fig 3 in the present study seven incident wave conditions were considered six regular stokes wave cases and one irregular jonswap spectrum wave case the parameters of the wave cases are summarized in table 1 where h is the wave height at the wavemaker and h i is the incident wave height which was measured at the depth d s of the seaward toe of the zfb but on the unprotected beach before the installation of the zfb the incident wave conditions were chosen so that the h i values cover the range between 40 and 93 of the zfb design wave height of 0 12 cm and the wave steepness 2πh i gt 2 values cover the range between 1 and 5 these values are representative of operational wave loads given the particular zfb free surface elevation measurements were performed using wave gauges of the resistance type i e measurements are based on the variation of conductivity between two parallel electrodes partly immersed into water for each wave gauge the sampling frequency was fixed at 100 hz while the duration of the recorded signal was at least 300 consecutive wave periods surface elevation recording was initiated after quasi steady wave conditions were established inside the wave tank i e after the passage of at least 80 150 wave cycles depending on the wave case tested each wave case was repeated ten times in order to obtain ensemble averaged results free surface elevation measurements were obtained at several locations in the sheltered area of the zfb using an array of eight wave gauges during these measurements a ninth wave gauge g9 was placed at the intersection of the seaward toe and the symmetry axis y 0 of the zfb the eight wave gauges in the sheltered area of the zfb were placed in an array transverse to the direction of wave propagation with horizontal distance 0 25 m between them wave gauge g1 was placed at the symmetry axis of the zfb opposite to gauge g9 while gauge g8 was located 0 25 m away from the wave guide wall the array was successively displaced 0 15 m shoreward to obtain the grid of measurement points shown in fig 1 surface elevation measurements in the zfb sheltered area were performed at seven 7 positions in the direction of wave propagation from water depth d 0 125 m to d 0 065 m the measurement locations are summarized in table 2 in the sheltered area of the zfb the global transmission coefficient k gt at each location of the grid in fig 1 was defined as 1 k g t h g h i where h g is the wave height at each location while h i is the incident wave height at the seaward toe of the zfb but on the unprotected beach before the installation of the zfb for the regular wave cases the wave heights were computed as h g i 8m 0 1 2 while for the irregular wave case as h g i 4 m 0 1 2 where m 0 was the zeroth order moment of the power spectrum of the signal recorded by the corresponding wave gauge in all cases the wave period t corresponds to the spectrum peak period the global transmission coefficient is a measure of the combined effect of wave transmission diffraction refraction and beach reflection in the sheltered area of the zfb in eq 1 the use of the wave height on the unprotected beach instead of the corresponding one with the zfb present was selected because this definition of wave transmission is not distorted by the influence of wave reflection from the zfb this definition has also more practical meaning in the design process of a zfb as a shore protection structure the wave climate of the unprotected beach is known and the desired wave behavior in the sheltered area of the zfb is prescribed by the design objective while the resulted wave characteristics at the seaward toe of the zfb are a priori unknown free surface elevation measurements were also obtained by an array of three wave gauges in the offshore area of the zfb as shown schematically in figs 1 and 2 in order to calculate the reflection coefficient k r the distance between these gauges was set according to the recommendations of the least squares method for incident and reflected spectra separation proposed in mansard and funke 1980 and the corresponding wave gauge locations for each wave case are given in table 3 the calculation of k r was facilitated by the use of the commercial code mike ws wave analysis tools reflection analysis module of dhi 2017 which implements the least squares three point method proposed in mansard and funke 1980 1987 and extended in zelt and skjelbreia 1992 it is noted that since the zfb was placed on a beach slope linear theory was used to account for changes in wave characteristics amplitude and phase due to shoaling between the spatially separated wave gauges locations the resulting values of k r are shown in table 3 while they are also plotted in fig 4 as a function of ξ in comparison to the predictions of the empirical formula in zanuttigh and van der meer 2008 which for a 2d zfb takes the form 2 k r 0 67 tanh a ξ b where a 0 14 and b 0 90 are the calibration parameters for rock breakwaters with impermeable core the empirical formula demonstrates the increase of k r with increasing ξ while the scatter of the measured values with respect to the empirical formula predictions is similar to the one shown in zanuttigh and van der meer 2008 for the data that were used to develop eq 2 in any case due to the small number of incident wave cases no decisive conclusion can be drawn on the behavior of k r for the zfb of the present study 3 results 3 1 global wave transmission in order to facilitate the presentation of the results the sheltered area of the zfb is divided into four regions fig 1 i adjacent to the gap ii adjacent to the leeward toe of the zfb iii between region ii and the shoreline and iv between region i and the shoreline results for the distribution of the global transmission coefficient k gt in the sheltered area of the zfb for the regular incident wave cases with height h 0 10 m and periods t 1 1 5 and 2 s are shown in fig 5 it is observed that the values of k gt vary substantially with y in regions i and iv specifically in the areas with y 1 2 m for w c 1 y 1 0 m for w c 2 and y 0 8 m for w c 3 the k gt values have a weak variation with y and are more or less constant in regions ii and iii apart from the local area of region iii with y 0 2 mm where the k gt values have again a strong variation with y it is recognized that the wave behavior in the zfb sheltered area is influenced by a combination of complex processes including transmission over the zfb crest diffraction from the gaps refraction setup currents and beach reflection k r 0 1 was measured for the beach without the zfb it may be higher for the reflection of the zfb transmitted waves due to their lower wave steepness it was beyond the scope of this study to identify the contribution of each underlying process to the behavior of k gt so a trend assessment was attempted on the contribution of the two major processes transmission over the zfb crest and diffraction from the zfb gaps therefore it is postulated that wave diffraction from the zfb gaps has a strong effect on k gt in regions i and iv and this effect is getting stronger with increasing incident wave period according to the observed movement of the interface between regions i iv and ii iii to smaller y values particularly for region i as the wave period increases the behavior of k gt is possibly related to the stronger diffraction from the gap due to the wavelength increase and the generated rip current the strong diffraction from the gap is also the reason why k gt 1 in region i for some cases it is also observed that k gt in general increases in regions ii and iii of the zfb sheltered area with increasing incident wave period this is attributed to the fact that during breaking of waves on the seaward slope and transmission of waves over the crest of lcbs energy is dissipated more effectively for short waves compared to long waves van der meer and daemen 1994 lorenzoni et al 2016 finally the local increase of k gt in the area of region iii close to the symmetry axis y 0 of the zfb is attributed to the effect of the generated cross shore current towards the zfb in this area cáceres et al 2005 zanuttigh and lamberti 2006 vicinanza et al 2009 the current velocity is opposite to the wave propagation in this area of region iii and therefore causes an increase of the wave height jonsson 1990 in comparison to the wave height in region ii where the corresponding current velocity is weaker cáceres et al 2005 zanuttigh and lamberti 2006 vicinanza et al 2009 results for the distribution of the global transmission coefficient k gt in the sheltered area of the zfb for the regular incident wave cases with period t 1 5 s and heights h 0 08 0 10 and 0 12 m are shown in fig 6 here the interface between regions i iv and ii iii remains more or less constant at about y 1 m independently of the incident wave height increase since the wavelength of the incident waves does not change in regions i k gt decreases with increasing incident wave height and this is attributed mostly to the fact that for the same incident wavelength the wave steepness increases resulting in wave breaking at larger water depths offshore of the zfb gaps and smaller wave heights at the gap entrance in regions ii and iii k gt seems to decrease very weakly though with increasing incident wave height and this is possibly attributed to the more intense wave breaking on the zfb seaward slope as the wave steepness increases which results into less energy transported over the zfb crest in the area of region iii close to the symmetry axis y 0 of the zfb the local effect on k gt by the generated cross shore current towards the zfb is also observed again it is stressed that other processes may be involved but their identification was beyond the scope of this study results for the distribution of the global transmission coefficient k gt in the sheltered area of the zfb for the regular incident wave case with height h 0 06 m period t 1 s and the irregular incident wave case generated according to the jonswap spectrum with peak enhancement factor γ 3 3 h m0 0 085 m h rms 2 1 2 h m0 0 06 m and peak spectral period t p 1 3 s are shown in fig 7 the irregular wave case w c 7 was selected to have the same wave energy density and the same mean period with the regular wave case w c 6 i e h rms h 0 06 m and t m02 t 1 s comparison of the distribution of k gt in the sheltered area of the zfb between the regular w c 6 and the irregular w c 7 wave cases with the same wave energy density reveals a similar behavior albeit with an important difference in regions i and iv where the penetration of the regular waves is stronger as mentioned in the introduction seelig 1980 seabrook and hall 1998 van der meer et al 2005 and buccino and calabrese 2007 developed empirical formulae for the prediction of k t based on a large number of experiments of wave transmission over 2d lcbs which included cases of zfbs for zfbs in particular where r c 0 the corresponding formulae take the following form seelig 1980 seabrook and hall 1998 van der meer et al 2005 buccino and calabrese 2007 3 k t 0 51 0 11 b d s 1 exp 1 09 h i b 0 64 b h i 0 31 1 exp 0 5 ξ for b h i 8 min 0 74 0 62 ξ 0 17 0 25 min 2 2 b h i λ 2 the range of the dimensionless parameters in the experiments in the literature whose data of transmission coefficient over rubble mound lcbs were used to develop the empirical formulae of eq 3 as well as the ones of the present experiments is shown in table 4 the comparison between the measured k gt at the intersection of the leeward toe and the symmetry axis y 0 of the zfb and the predictions of eq 3 is shown in table 5 and fig 8 it should be emphasized here that the empirical formulae are mostly based on transmission over 2d lcbs both permeable and impermeable while in the present study the zfb had an impermeable core and the local transmission at the intersection of the leeward toe and the symmetry axis y 0 of the zfb was also influenced by the wave generated currents in the sheltered area of the zfb due to the 3d geometry of the configuration another difference is that mostly regular wave cases were examined in the present study nevertheless the comparison shows that the best agreement was obtained by the empirical formulae in van der meer et al 2005 and buccino and calabrese 2007 with maximum deviation 30 from the measurements 3 2 wave setup results for the distribution of the induced wave setup i e the mean water level in the sheltered area of the zfb for the regular incident wave cases with height h 0 10 m and periods t 1 1 5 and 2 s are shown in fig 9 as highlighted in bellotti 2004 and soldini et al 2009 the magnitude of wave setup in the sheltered area of detached breakwaters is influenced partially by the strength of wave breaking on the structure and partially by the development of longshore and cross shore currents in the sheltered area and rip current through the gaps of the zfb these currents are related to the generation of macrovortices in the sheltered area of the zfb kennedy et al 2006 and they counterbalance the mass of water that overtops above the zfb crest indeed it can be seen in fig 9 that the wave setup in the sheltered area is larger for the incident wave with period t 1 5 s which presents strong wave breaking on the zfb crest fig 10 a for the shorter t 1 s and longer t 2 s incident waves incipient breaking occurred not on the zfb crest but on the zfb seaward slope fig 10b due to smaller h i heights table 1 thus reducing its strength during overtopping results for the distribution of the wave setup in the sheltered area of the zfb for the regular incident wave cases with period t 1 5 s and heights h 0 08 0 10 and 0 12 m are shown in fig 11 for cases with the same wavelength wave setup increases since breaking and overtopping get stronger as the height h i of the incident waves increases as mentioned in the introduction diskin et al 1970 and loveless et al 1998 developed empirical formulae for the prediction of δ based on a large number of experiments of wave transmission over 2d permeable lcbs which clearly included cases of zfbs as shown in table 4 bellotti 2004 developed an empirical formula for the prediction of δ over 3d segmented barriers based on a conceptual model which included the effect of overtopping and rip currents for zfbs in particular where r c 0 the corresponding formulae take the following form diskin et al 1970 loveless et al 1998 bellotti 2004 4 δ 0 6 h i exp 0 7 2 b h i λ p 2 8 g d n 50 d s t 2 3 16 h i 2 1 k t 2 d l d m c v d s l g l b 2 d l 2 d s where in the bellotti 2004 formula d m is a measure of the thickness of the water volume over the breakwater which in the present case is d m 0 021 m and c v is the discharge coefficient of the rip current which is used as a tuning parameter the comparison between the measured δ at the intersection of the leeward toe and the symmetry axis y 0 of the zfb and the predictions of eq 4 is shown in table 6 the empirical formulae of diskin et al 1970 and loveless et al 1998 are mostly based on overtopping over 2d permeable lcbs while in the present study the wave setup in the sheltered area of a segmented zfb with an impermeable core was also influenced by the development of currents therefore it is of no surprise that the predicted values are about one order of magnitude larger than the measured ones although the relevant contribution to this deviation by the permeability difference and the development of currents was not deduced on the other hand the predictions by the empirical formula of bellotti 2004 which is based on a 3d segmented configuration like the present one are much closer to the measured values in fact the best agreement with standard deviation σ 0 3 cm between measured and predicted δ was achieved for c v 0 9 in the bellotti 2004 formula 3 3 wave harmonics the power spectra of the surface elevation time series recorded at the seaward and leeward toes of the zfb were generated in order to identify and quantify the spectral change of the waves transmitted in the sheltered area of the zfb typical spectra for the incident wave case w c 5 are shown in fig 12 at the seaward toe the peak period of the waves is practically identical to the one introduced by the wavemaker but substantial wave energy exists also in the second harmonic due to the wave nonlinearity at the leeward toe the relative wave energy in the higher harmonics increases mainly due to wave breaking and overtopping van der meer et al 2000 2005 zanuttigh and martinelli 2008 this energy shift is typical of all wave cases and it is best demonstrated by computing the mean wave period t m02 at both the seaward and leeward toes of the zfb table 7 the value of the ratio t m02 t p is representative of the fraction of wave energy in the higher harmonics t m02 t p 1 means that 100 of the wave energy is in the carrier frequency while as the ratio t m02 t p decreases the fraction of wave energy in the higher harmonics increases the ratio t m02 t p is always smaller at the leeward toe than at the seaward one due to the transfer of energy to higher frequencies of the spectrum induced by wave transmission over the zfb focusing on the leeward toe it is observed that for the regular incident waves with the same height h 0 10 m the fraction of wave energy in higher frequencies increases t m02 t p decreases as the period of the incident waves increases while for the regular incident waves with the same period t 1 5 s the fraction of wave energy in higher frequencies increases t m02 t p decreases as the height of the incident waves increases contour plots of the ratio t m02 t p in the sheltered area of the zfb for the regular incident wave cases with height h 0 10 m and periods t 1 1 5 and 2 s and for the regular incident wave cases with period t 1 5 s and heights h 0 08 0 10 and 0 12 m are presented in figs 13 and 14 respectively the value of the ratio retains values in the range 0 3 t m02 t p 0 6 note the value 0 65 reported in van der meer et al 2000 which means that the transfer of energy to higher frequencies induced by the wave transmission over the zfb crest is sustained and characterizes the waves in the whole sheltered area of the zfb and not only near the leeward toe of the zfb 4 conclusions an experimental study was undertaken in a physical model of a segmented detached rubble mound zfb on a steep beach specifically the distribution of wave height and setup and the wave energy shift to higher wave harmonics in the sheltered area of the zfb were examined six regular and one irregular incident wave cases were considered the detached zfb was in the outer coastal zone for all wave cases which classified it as a coastal breakwater according to mangor et al 2017 the wave behavior in the zfb sheltered area is influenced by a combination of complex processes including transmission over the zfb crest diffraction from the gaps refraction setup currents and beach reflection here an assessment of the contribution of the two major processes transmission over the zfb crest and diffraction from the zfb gaps was deduced the average global transmission coefficient k gt in the sheltered area of the zfb increases with increasing incident wave period and decreasing incident wave height along the symmetry axis y 0 of the zfb the global transmission coefficient k gt is also influenced by the generated cross shore current towards the zfb and it increases with increasing incident wave period and decreasing incident wave height the wave setup distribution in the sheltered area of the zfb is influenced both by wave breaking on the structure and development of longshore and rip currents in general wave setup increases as the wave height increases while the predictions of the empirical formula in bellotti 2004 for the wave setup at the leeward toe of the zfb were found to be in reasonable agreement with our measurements finally it was found that the fraction of wave energy transferred to higher harmonics as the waves transmit over the zfb crest is sustained in the whole sheltered area of the zfb and it increases as the period or the height of the incident waves increase acknowledgments this paper is part of the research project aristeia i 1718 implemented within the framework of the programme education and lifelong learning and co financed by the european union european social fund and hellenic republic funds 
22713,an experimental study of the wave behavior in the sheltered area of a segmented detached rubble mound zero freeboard breakwater zfb on a steep beach is presented six regular and one irregular incident wave cases were considered it was deduced that the wave height distribution in the sheltered area of the zfb was influenced a in the region near the symmetry axis normal to the zfb mainly by wave transmission over the zfb crest and b in the region shoreward of the gaps between the segments of the zfb mainly by wave diffraction from the gaps the average wave heights in the sheltered area of the zfb normalized to the incident wave height increase with increasing incident wave period and decreasing incident wave height the wave setup distribution in the sheltered area of the zfb was influenced both by wave breaking on the structure and the development of currents wave setup increases with increasing incident wave height the transmission of waves over the zfb induces transfer of energy to higher frequencies of the power spectrum this transfer is sustained in the sheltered area of the zfb and it increases with increasing incident wave period or height keywords segmented detached rubble mound zero freeboard breakwater steep beach wave reflection transmission diffraction refraction spectral change 1 introduction coastal protection measures against the effect of environmental loads waves currents etc frequently include the construction of segmented detached low crested breakwaters lcb which contribute to coastal sediment transport control by reducing the wave energy transmitted to their leeside mangor et al 2017 lcbs allow enough water exchange between offshore and sheltered area to sustain water renewal in coasts of high environmental and recreational value usually these structures are of the emerged type i e their crest is above the still water level swl but in recent years interest has been directed towards submerged ones due to their reduced construction cost and their harmonization with the natural environment since detached lcbs are structures mostly used for shore protection their main operation is to dissipate part of the wave energy by inducing wave breaking but their presence drastically affects as well wave dynamics hydrodynamic circulation and sediment transport in their vicinity the related wave phenomena include reflection from the lcb breaking on the lcb transmission above the crest and through the core of the lcb diffraction from the gaps of a segmented lcb and around its heads refraction setup and beach reflection in the sheltered area of the lcb hence the wave reflection k r and transmission k t coefficients of lcbs as well as the wave setup δ and wave transformation in the sheltered area of detached lcbs are important design parameters diskin et al 1970 performed several 2d laboratory tests of wave setup in the sheltered area of lcbs and developed an empirical formula for δ as a function of r c h i where r c is the structure freeboard and h i is the incident wave height at the lcb toe seelig 1980 performed several 2d laboratory tests of wave transmission over lcbs with 17 different types of breakwaters most of them being rubble mound ones with and without permeable core but also some smooth ones he showed that wave transmission was related to breakwater characteristics such as freeboard and crest width and to wave runup the study also included the presentation of an empirical formula to predict k t for nonbreaking breaking monochromatic and irregular wave conditions van der meer and daemen 1994 reanalyzed most available preceded datasets of wave transmission over rubble mound lcbs for random waves and taking into consideration crest height and width and wave height and steepness they proposed an empirical formula for k t as a function of r c d n50 h i d n50 b d n50 and s op where b is the crest width d n50 is the nominal diameter of the rock armor and s op h i λ p is the incident wave steepness where λ p gt p 2 2π and t p is the incident wave peak period d angremond at al 1996 also reanalyzed existing datasets of wave transmission and derived an improved empirical formula relating k t to r c h i b h i and ξ where ξ tana λ p h i 1 2 is the iribarren number and tana is the breakwater seaward slope loveless et al 1998 performed 2d laboratory tests of wave setup in the sheltered area of lcbs and developed an empirical formula for δ as a function of the incident wave parameters and r c h c where h c is the structure height seabrook and hall 1998 performed 2d laboratory tests of submerged and zero freeboard rubble mound breakwaters under a wide range of design conditions and developed an empirical formula for k t with emphasis on the effect of large crest width on wave transmission van der meer et al 2000 investigated experimentally the spectral change of irregular waves transmitted over low crested dams and they found that the peak period t p of the transmitted waves remained practically equal to the peak period of the incident waves while the wave mean period t m02 m 0 m 2 1 2 where m 0 and m 2 are the zeroth and second moments of the wave power spectrum respectively goda 2000 reduced to about 0 65 of the incident wave mean period van der meer et al 2005 considered results from the laboratory tests in seabrook and hall 1998 calabrese et al 2002 and kramer et al 2005 in addition to the datasets considered in d angremond at al 1996 and they concluded that the empirical formula for k t in d angremond at al 1996 should be used for b h i 8 while they proposed a new empirical formula for k t to be used for b h i 12 and a linear interpolation between the two for 8 b h i 12 moreover a new empirical formula for the reflection coefficient k r was developed by modification of the empirical formulae in the rock manual ciria cur 1991 to account for overtopping results from the laboratory tests described in kramer et al 2005 related to waves and currents in the sheltered region of a configuration of detached lcbs were presented in zanuttigh and lamberti 2006 where among other results the wave height and setup were measured near the seaward and leeward toes of the lcbs for 5 incident wave cases buccino and calabrese 2007 presented a conceptual approach for the derivation of an empirical formula for k t based on the energy balance of wave transmission over lcbs the empirical formula was calibrated based on the experimental dataset in seabrook and hall 1998 zanuttigh and van der meer 2008 analyzed existing experimental datasets of wave reflection from lcbs and developed an empirical formula for k r which is consistent with the roughness parameter γ f found in overtopping research and depends on r c h t where h t is the transmitted wave height vicinanza et al 2009 studied experimentally the combined transmission diffraction effect on wave transformation and induced currents in the sheltered area of a single detached lcb the study included a definition for the global transmission coefficient k gt based on the combination of existing analytical and empirical formulae for wave transmission and diffraction and comparison of its predictions to the measured data zanuttigh and martinelli 2008 analyzed datasets of wave transmission over 2d and 3d permeable low crested breakwaters and specifically for the cases where overtopping was dominant over filtration they found that the reduction of the wave mean period after transmission was similar to the one in van der meer et al 2000 soldini et al 2009 compared the empirical formulae for δ developed by diskin et al 1970 loveless et al 1998 bellotti 2004 and calabrese et al 2008 based on their performance in one 2d overtopping only and three 3d overtopping and rip current laboratory datasets for cases of submerged breakwaters bars note that the formulae by diskin et al 1970 and loveless et al 1998 were based on 2d lcbs while the ones by bellotti 2004 and calabrese et al 2008 were based on 2d and 3d respectively strictly submerged barriers in the present work the interaction of incident waves with a segmented detached rubble mound zero freeboard breakwater zfb on a steep beach was studied experimentally with emphasis on the wave behavior in the sheltered area of the zfb this behavior depends on the incident wave parameters wave height wave period and angle of wave incidence the geometry and location of the zfb breakwater length gap length crest width breakwater slope armour size and water depth and the beach slope in the present study a physical model of a particular segmented detached rubble mound zfb on a beach of constant slope 1 15 was used while the effect of incident wave height and period was targeted by considering seven 7 cases of normally incident waves the main objectives were to a compute the reflection and transmission coefficients of the segmented detached zfb and b offer an assessment of trends in the behavior of wave height wave setup and wave spectral change in the sheltered area of the zfb the resulting dataset of the measurements is also suitable as a benchmark for numerical or theoretical models 2 experimental modeling experiments were conducted in the wave basin of the hydraulic engineering laboratory department of civil engineering university of patras the wave basin has surface area 12 7 m2 and water depth 1 05 m while it is equipped with a paddle wavemaker that can reproduce regular stokes cnoidal or solitary irregular linear or second order or recorded time series of waves the paddle operation is controlled by an active wave absorption control system schäffer and hyllested 1999 for wave generation with concurrent absorption of the reflected waves returning to the wave paddle opposite to the wavemaker a physical model of a beach with constant slope 1 15 was constructed and a physical model of a segmented detached rubble mound zfb was placed between water depths d s 18 cm seaward toe and d l 12 5 cm leeward toe figs 1 and 2 the zfb length at crest level was l b 2 60 m its crest width was b 20 cm while both its seaward and leeward slopes were tana 1 2 the permeable armor layer of the zfb consisted of two rows of rocks with nominal diameter d n50 4 cm while the core of the zfb was impermeable as it was formed by a framed steel sheet the weight of the rocks of the armor layer was computed using the corresponding formula in van der meer 1990 for the design wave height of 0 12 m wave guide walls at 4 m apart were also placed in the wave basin fig 1 in order to model a hypothetical prototype segmented detached zfb each wave guide corresponds to the symmetry plane in the middle of the gap between zfb segments therefore the gap length at crest level was l g 1 4 m resulting to l g l b 0 54 while the ratio of the zfb length over its distance from the shoreline was equal to 1 2 this setup is suited only for cases of normal shore incident waves indeed during the experiments no reflections were observed by the guide walls seaward of the zfb ensuring that normal shore wave conditions were achieved in the sheltered area of the zfb the wave guides acted nicely as symmetry planes and no wave distortion was observed in their vicinity any reflection off the guide walls of waves diffracted from the zfb head is properly modeling the waves diffracted from the head of the hypothetical neighboring zfb segment photographs of the configuration without and with water are shown in fig 3 in the present study seven incident wave conditions were considered six regular stokes wave cases and one irregular jonswap spectrum wave case the parameters of the wave cases are summarized in table 1 where h is the wave height at the wavemaker and h i is the incident wave height which was measured at the depth d s of the seaward toe of the zfb but on the unprotected beach before the installation of the zfb the incident wave conditions were chosen so that the h i values cover the range between 40 and 93 of the zfb design wave height of 0 12 cm and the wave steepness 2πh i gt 2 values cover the range between 1 and 5 these values are representative of operational wave loads given the particular zfb free surface elevation measurements were performed using wave gauges of the resistance type i e measurements are based on the variation of conductivity between two parallel electrodes partly immersed into water for each wave gauge the sampling frequency was fixed at 100 hz while the duration of the recorded signal was at least 300 consecutive wave periods surface elevation recording was initiated after quasi steady wave conditions were established inside the wave tank i e after the passage of at least 80 150 wave cycles depending on the wave case tested each wave case was repeated ten times in order to obtain ensemble averaged results free surface elevation measurements were obtained at several locations in the sheltered area of the zfb using an array of eight wave gauges during these measurements a ninth wave gauge g9 was placed at the intersection of the seaward toe and the symmetry axis y 0 of the zfb the eight wave gauges in the sheltered area of the zfb were placed in an array transverse to the direction of wave propagation with horizontal distance 0 25 m between them wave gauge g1 was placed at the symmetry axis of the zfb opposite to gauge g9 while gauge g8 was located 0 25 m away from the wave guide wall the array was successively displaced 0 15 m shoreward to obtain the grid of measurement points shown in fig 1 surface elevation measurements in the zfb sheltered area were performed at seven 7 positions in the direction of wave propagation from water depth d 0 125 m to d 0 065 m the measurement locations are summarized in table 2 in the sheltered area of the zfb the global transmission coefficient k gt at each location of the grid in fig 1 was defined as 1 k g t h g h i where h g is the wave height at each location while h i is the incident wave height at the seaward toe of the zfb but on the unprotected beach before the installation of the zfb for the regular wave cases the wave heights were computed as h g i 8m 0 1 2 while for the irregular wave case as h g i 4 m 0 1 2 where m 0 was the zeroth order moment of the power spectrum of the signal recorded by the corresponding wave gauge in all cases the wave period t corresponds to the spectrum peak period the global transmission coefficient is a measure of the combined effect of wave transmission diffraction refraction and beach reflection in the sheltered area of the zfb in eq 1 the use of the wave height on the unprotected beach instead of the corresponding one with the zfb present was selected because this definition of wave transmission is not distorted by the influence of wave reflection from the zfb this definition has also more practical meaning in the design process of a zfb as a shore protection structure the wave climate of the unprotected beach is known and the desired wave behavior in the sheltered area of the zfb is prescribed by the design objective while the resulted wave characteristics at the seaward toe of the zfb are a priori unknown free surface elevation measurements were also obtained by an array of three wave gauges in the offshore area of the zfb as shown schematically in figs 1 and 2 in order to calculate the reflection coefficient k r the distance between these gauges was set according to the recommendations of the least squares method for incident and reflected spectra separation proposed in mansard and funke 1980 and the corresponding wave gauge locations for each wave case are given in table 3 the calculation of k r was facilitated by the use of the commercial code mike ws wave analysis tools reflection analysis module of dhi 2017 which implements the least squares three point method proposed in mansard and funke 1980 1987 and extended in zelt and skjelbreia 1992 it is noted that since the zfb was placed on a beach slope linear theory was used to account for changes in wave characteristics amplitude and phase due to shoaling between the spatially separated wave gauges locations the resulting values of k r are shown in table 3 while they are also plotted in fig 4 as a function of ξ in comparison to the predictions of the empirical formula in zanuttigh and van der meer 2008 which for a 2d zfb takes the form 2 k r 0 67 tanh a ξ b where a 0 14 and b 0 90 are the calibration parameters for rock breakwaters with impermeable core the empirical formula demonstrates the increase of k r with increasing ξ while the scatter of the measured values with respect to the empirical formula predictions is similar to the one shown in zanuttigh and van der meer 2008 for the data that were used to develop eq 2 in any case due to the small number of incident wave cases no decisive conclusion can be drawn on the behavior of k r for the zfb of the present study 3 results 3 1 global wave transmission in order to facilitate the presentation of the results the sheltered area of the zfb is divided into four regions fig 1 i adjacent to the gap ii adjacent to the leeward toe of the zfb iii between region ii and the shoreline and iv between region i and the shoreline results for the distribution of the global transmission coefficient k gt in the sheltered area of the zfb for the regular incident wave cases with height h 0 10 m and periods t 1 1 5 and 2 s are shown in fig 5 it is observed that the values of k gt vary substantially with y in regions i and iv specifically in the areas with y 1 2 m for w c 1 y 1 0 m for w c 2 and y 0 8 m for w c 3 the k gt values have a weak variation with y and are more or less constant in regions ii and iii apart from the local area of region iii with y 0 2 mm where the k gt values have again a strong variation with y it is recognized that the wave behavior in the zfb sheltered area is influenced by a combination of complex processes including transmission over the zfb crest diffraction from the gaps refraction setup currents and beach reflection k r 0 1 was measured for the beach without the zfb it may be higher for the reflection of the zfb transmitted waves due to their lower wave steepness it was beyond the scope of this study to identify the contribution of each underlying process to the behavior of k gt so a trend assessment was attempted on the contribution of the two major processes transmission over the zfb crest and diffraction from the zfb gaps therefore it is postulated that wave diffraction from the zfb gaps has a strong effect on k gt in regions i and iv and this effect is getting stronger with increasing incident wave period according to the observed movement of the interface between regions i iv and ii iii to smaller y values particularly for region i as the wave period increases the behavior of k gt is possibly related to the stronger diffraction from the gap due to the wavelength increase and the generated rip current the strong diffraction from the gap is also the reason why k gt 1 in region i for some cases it is also observed that k gt in general increases in regions ii and iii of the zfb sheltered area with increasing incident wave period this is attributed to the fact that during breaking of waves on the seaward slope and transmission of waves over the crest of lcbs energy is dissipated more effectively for short waves compared to long waves van der meer and daemen 1994 lorenzoni et al 2016 finally the local increase of k gt in the area of region iii close to the symmetry axis y 0 of the zfb is attributed to the effect of the generated cross shore current towards the zfb in this area cáceres et al 2005 zanuttigh and lamberti 2006 vicinanza et al 2009 the current velocity is opposite to the wave propagation in this area of region iii and therefore causes an increase of the wave height jonsson 1990 in comparison to the wave height in region ii where the corresponding current velocity is weaker cáceres et al 2005 zanuttigh and lamberti 2006 vicinanza et al 2009 results for the distribution of the global transmission coefficient k gt in the sheltered area of the zfb for the regular incident wave cases with period t 1 5 s and heights h 0 08 0 10 and 0 12 m are shown in fig 6 here the interface between regions i iv and ii iii remains more or less constant at about y 1 m independently of the incident wave height increase since the wavelength of the incident waves does not change in regions i k gt decreases with increasing incident wave height and this is attributed mostly to the fact that for the same incident wavelength the wave steepness increases resulting in wave breaking at larger water depths offshore of the zfb gaps and smaller wave heights at the gap entrance in regions ii and iii k gt seems to decrease very weakly though with increasing incident wave height and this is possibly attributed to the more intense wave breaking on the zfb seaward slope as the wave steepness increases which results into less energy transported over the zfb crest in the area of region iii close to the symmetry axis y 0 of the zfb the local effect on k gt by the generated cross shore current towards the zfb is also observed again it is stressed that other processes may be involved but their identification was beyond the scope of this study results for the distribution of the global transmission coefficient k gt in the sheltered area of the zfb for the regular incident wave case with height h 0 06 m period t 1 s and the irregular incident wave case generated according to the jonswap spectrum with peak enhancement factor γ 3 3 h m0 0 085 m h rms 2 1 2 h m0 0 06 m and peak spectral period t p 1 3 s are shown in fig 7 the irregular wave case w c 7 was selected to have the same wave energy density and the same mean period with the regular wave case w c 6 i e h rms h 0 06 m and t m02 t 1 s comparison of the distribution of k gt in the sheltered area of the zfb between the regular w c 6 and the irregular w c 7 wave cases with the same wave energy density reveals a similar behavior albeit with an important difference in regions i and iv where the penetration of the regular waves is stronger as mentioned in the introduction seelig 1980 seabrook and hall 1998 van der meer et al 2005 and buccino and calabrese 2007 developed empirical formulae for the prediction of k t based on a large number of experiments of wave transmission over 2d lcbs which included cases of zfbs for zfbs in particular where r c 0 the corresponding formulae take the following form seelig 1980 seabrook and hall 1998 van der meer et al 2005 buccino and calabrese 2007 3 k t 0 51 0 11 b d s 1 exp 1 09 h i b 0 64 b h i 0 31 1 exp 0 5 ξ for b h i 8 min 0 74 0 62 ξ 0 17 0 25 min 2 2 b h i λ 2 the range of the dimensionless parameters in the experiments in the literature whose data of transmission coefficient over rubble mound lcbs were used to develop the empirical formulae of eq 3 as well as the ones of the present experiments is shown in table 4 the comparison between the measured k gt at the intersection of the leeward toe and the symmetry axis y 0 of the zfb and the predictions of eq 3 is shown in table 5 and fig 8 it should be emphasized here that the empirical formulae are mostly based on transmission over 2d lcbs both permeable and impermeable while in the present study the zfb had an impermeable core and the local transmission at the intersection of the leeward toe and the symmetry axis y 0 of the zfb was also influenced by the wave generated currents in the sheltered area of the zfb due to the 3d geometry of the configuration another difference is that mostly regular wave cases were examined in the present study nevertheless the comparison shows that the best agreement was obtained by the empirical formulae in van der meer et al 2005 and buccino and calabrese 2007 with maximum deviation 30 from the measurements 3 2 wave setup results for the distribution of the induced wave setup i e the mean water level in the sheltered area of the zfb for the regular incident wave cases with height h 0 10 m and periods t 1 1 5 and 2 s are shown in fig 9 as highlighted in bellotti 2004 and soldini et al 2009 the magnitude of wave setup in the sheltered area of detached breakwaters is influenced partially by the strength of wave breaking on the structure and partially by the development of longshore and cross shore currents in the sheltered area and rip current through the gaps of the zfb these currents are related to the generation of macrovortices in the sheltered area of the zfb kennedy et al 2006 and they counterbalance the mass of water that overtops above the zfb crest indeed it can be seen in fig 9 that the wave setup in the sheltered area is larger for the incident wave with period t 1 5 s which presents strong wave breaking on the zfb crest fig 10 a for the shorter t 1 s and longer t 2 s incident waves incipient breaking occurred not on the zfb crest but on the zfb seaward slope fig 10b due to smaller h i heights table 1 thus reducing its strength during overtopping results for the distribution of the wave setup in the sheltered area of the zfb for the regular incident wave cases with period t 1 5 s and heights h 0 08 0 10 and 0 12 m are shown in fig 11 for cases with the same wavelength wave setup increases since breaking and overtopping get stronger as the height h i of the incident waves increases as mentioned in the introduction diskin et al 1970 and loveless et al 1998 developed empirical formulae for the prediction of δ based on a large number of experiments of wave transmission over 2d permeable lcbs which clearly included cases of zfbs as shown in table 4 bellotti 2004 developed an empirical formula for the prediction of δ over 3d segmented barriers based on a conceptual model which included the effect of overtopping and rip currents for zfbs in particular where r c 0 the corresponding formulae take the following form diskin et al 1970 loveless et al 1998 bellotti 2004 4 δ 0 6 h i exp 0 7 2 b h i λ p 2 8 g d n 50 d s t 2 3 16 h i 2 1 k t 2 d l d m c v d s l g l b 2 d l 2 d s where in the bellotti 2004 formula d m is a measure of the thickness of the water volume over the breakwater which in the present case is d m 0 021 m and c v is the discharge coefficient of the rip current which is used as a tuning parameter the comparison between the measured δ at the intersection of the leeward toe and the symmetry axis y 0 of the zfb and the predictions of eq 4 is shown in table 6 the empirical formulae of diskin et al 1970 and loveless et al 1998 are mostly based on overtopping over 2d permeable lcbs while in the present study the wave setup in the sheltered area of a segmented zfb with an impermeable core was also influenced by the development of currents therefore it is of no surprise that the predicted values are about one order of magnitude larger than the measured ones although the relevant contribution to this deviation by the permeability difference and the development of currents was not deduced on the other hand the predictions by the empirical formula of bellotti 2004 which is based on a 3d segmented configuration like the present one are much closer to the measured values in fact the best agreement with standard deviation σ 0 3 cm between measured and predicted δ was achieved for c v 0 9 in the bellotti 2004 formula 3 3 wave harmonics the power spectra of the surface elevation time series recorded at the seaward and leeward toes of the zfb were generated in order to identify and quantify the spectral change of the waves transmitted in the sheltered area of the zfb typical spectra for the incident wave case w c 5 are shown in fig 12 at the seaward toe the peak period of the waves is practically identical to the one introduced by the wavemaker but substantial wave energy exists also in the second harmonic due to the wave nonlinearity at the leeward toe the relative wave energy in the higher harmonics increases mainly due to wave breaking and overtopping van der meer et al 2000 2005 zanuttigh and martinelli 2008 this energy shift is typical of all wave cases and it is best demonstrated by computing the mean wave period t m02 at both the seaward and leeward toes of the zfb table 7 the value of the ratio t m02 t p is representative of the fraction of wave energy in the higher harmonics t m02 t p 1 means that 100 of the wave energy is in the carrier frequency while as the ratio t m02 t p decreases the fraction of wave energy in the higher harmonics increases the ratio t m02 t p is always smaller at the leeward toe than at the seaward one due to the transfer of energy to higher frequencies of the spectrum induced by wave transmission over the zfb focusing on the leeward toe it is observed that for the regular incident waves with the same height h 0 10 m the fraction of wave energy in higher frequencies increases t m02 t p decreases as the period of the incident waves increases while for the regular incident waves with the same period t 1 5 s the fraction of wave energy in higher frequencies increases t m02 t p decreases as the height of the incident waves increases contour plots of the ratio t m02 t p in the sheltered area of the zfb for the regular incident wave cases with height h 0 10 m and periods t 1 1 5 and 2 s and for the regular incident wave cases with period t 1 5 s and heights h 0 08 0 10 and 0 12 m are presented in figs 13 and 14 respectively the value of the ratio retains values in the range 0 3 t m02 t p 0 6 note the value 0 65 reported in van der meer et al 2000 which means that the transfer of energy to higher frequencies induced by the wave transmission over the zfb crest is sustained and characterizes the waves in the whole sheltered area of the zfb and not only near the leeward toe of the zfb 4 conclusions an experimental study was undertaken in a physical model of a segmented detached rubble mound zfb on a steep beach specifically the distribution of wave height and setup and the wave energy shift to higher wave harmonics in the sheltered area of the zfb were examined six regular and one irregular incident wave cases were considered the detached zfb was in the outer coastal zone for all wave cases which classified it as a coastal breakwater according to mangor et al 2017 the wave behavior in the zfb sheltered area is influenced by a combination of complex processes including transmission over the zfb crest diffraction from the gaps refraction setup currents and beach reflection here an assessment of the contribution of the two major processes transmission over the zfb crest and diffraction from the zfb gaps was deduced the average global transmission coefficient k gt in the sheltered area of the zfb increases with increasing incident wave period and decreasing incident wave height along the symmetry axis y 0 of the zfb the global transmission coefficient k gt is also influenced by the generated cross shore current towards the zfb and it increases with increasing incident wave period and decreasing incident wave height the wave setup distribution in the sheltered area of the zfb is influenced both by wave breaking on the structure and development of longshore and rip currents in general wave setup increases as the wave height increases while the predictions of the empirical formula in bellotti 2004 for the wave setup at the leeward toe of the zfb were found to be in reasonable agreement with our measurements finally it was found that the fraction of wave energy transferred to higher harmonics as the waves transmit over the zfb crest is sustained in the whole sheltered area of the zfb and it increases as the period or the height of the incident waves increase acknowledgments this paper is part of the research project aristeia i 1718 implemented within the framework of the programme education and lifelong learning and co financed by the european union european social fund and hellenic republic funds 
22714,ship domain plays a critical role in ship traffic risk assessment and safe navigation today the widely available ais data makes it possible to capture the diverse behaviors of navigators and navigational conditions by vessel trajectories in practice we propose the novel concept of probabilistic ship domain which depicts the ship domain boundary as the vague value rather than the crisp value with a forbidden boundary and a desired boundary we also develop an effective big ais data driven approach to determine the probabilistic ship domain we further investigate how to use the probabilistic ship domain to assess ship collision risk finally a few case studies from the singapore strait are conducted to show the merits of the probabilistic ship domain and the big ais data driven approach keywords probabilistic ship domain big ais data ship collision risk assessment 1 introduction ship domain is one of the unique features of ship traffic in the restricted water areas such as straits canals as well as port waters it has been widely used in ship collision risk assessment goerlandt and montewka 2015 weng and yang 2015 zhang et al 2016 ship collision avoidance analysis zhao et al 1993 debnath and chin 2010 szlapczynski et al 2018 lu et al 2018 near miss detection szlapczynski and niksa rynkiewicz 2018 and ship traffic simulation development goerlandt and kujala 2011 hsu 2014 kang et al 2019a since the ship domain was first proposed by fujii and tanaka 1971 in the 1960s a large number of ship domains have been developed differentiating from their shape and factors considered zhao et al 1993 wang et al 2010 smierzchalski and michalewicz 2000 szlapczynski and szlapczynska 2017 ship domains are related to factors such as ship size ship maneuverability hydrological conditions meteorological conditions ship velocity traffic intensity the knowledge of navigator zhao et al 1993 dinh and im 2016 based on the methodology to determine the ship domain and factors taken into account ship domains can be generally classified into three categories namely empirical domain knowledge based domain and analytical domain szlapczynski and niksa rynkiewicz 2018 dinh and im 2016 it should be noted that these three groups are not mutually exclusive these ship domains are developed for different purposes whose complexity domain determine method and factors considered are different empirical ship domains are the domain models determined empirically based on the field data the earliest work to determine the ship domain using field data can be traced back to the study by fujii and tanaka 1971 that used the real radar data in the recent years ais data is increasingly used to determine the ship domains because of the installation of as per the regulation of international maritime organization imo goerlandt et al 2017 pietrzykowski and uriasz 2009 pietrzykowski and magaj 2016 2017 for example hansen et al 2013 estimated the ship domain using a visualization method by plotting the ship traffic density based on the data from danish waters the results show that the empirical ship domain is roughly in accordance with that of fujii and tanaka 1971 and coldwell 1983 wang and chin 2016 proposed a free form asymmetrical polygon domain with the assumption that the domain size is a function of the ship length and speed this domain model is calibrated using the ga algorithm based on the ais data of singapore port and singapore strait wang and chin 2016 knowledge based ship domains are determined based on the experts knowledge such as the survey of the navigators neural network and fuzzy logic are two widely used methods to model the knowledge based ship domain zhao et al 1993 zhu et al 2001 szlapczynski and szlapczynska 2017 zhu et al 2001 developed a three layer back propagation neural network which is trained using the survey data collected from the navigators this ship domain model can take into account the ship length local visibility and manoeuvrability zhu et al 2001 the fuzzy domain can also take into account various factors which are described by the membership functions using linguistic variables dinh and im 2016 pietrzykowski 2008 pietrzykowski et al 2018 wang 2010 developed a fuzzy quaternion ship domain fqsd which was introduced to estimate the spatial collision risk pietrzykowski 2008 developed a fuzzy domain in restricted water areas considering navigational safety level the risk level is represented as the function of the risk impact factors such as distance to the fairway course deviation and rate of turn which is modeled using artificial intelligence and calibrated based on relevant navigators knowledge it is found that the ship domain area is an exponential function of the safety level and there is the same relationship between the domain boundary and the navigational safety level similarly a fuzzy ship domain for the open sea area was also developed which investigated the impact of the length of both own ship and target ship pietrzykowski and uriasz 2009 this study found that smaller ships usually adjust their domains when encountering large ships as the fuzzy domain is capable of taking into account multiple risk factors it is suitable for risk analysis for example the fuzzy ship domain is successfully applied to safe trajectory determination pietrzykowski 2005 wang 2010 pietrzykowski and magaj 2014 the analytical ship domain uses mathematical formulas and variables to model the domain boundary zhao et al 1993 wang et al 2010 for example wang et al 2010 proposed a quaternion ship domain qsd with four radii and the domain shape is modeled with five parameters which are functions of ship speed length and manoeuvrability then this domain has been extended by regarding the boundary as a fuzzy one resulting in the fuzzy ship domain another extension of qsd is to take into account the domain shape parameters as a function of impact factors including navigational environment human factors and ship manoeuvrability wang 2013 several other studies developed analytical ship domains for particular water areas for example rawson et al 2014 developed a ship domain for one area of the river thames in central london whose shape is a function of ship speed and ship type another region specific ship domain model has been developed for capacity analysis in restricted channels between tianjin and beijing which has a shape of ellipse with the semi axes parameters determined in an analytical way based on a specific problem for the discussed water region liu et al 2016 these three types of ship domains have their own advantages and limitations the empirical ship domains are determined based on the trajectory data such as ais data which are currently widely accessible however they are usually simple and for certain water area with specific navigational conditions since empirical data make it hard to isolate the impact of multiple parameters the analytical ship domains and knowledge based ship domains can take into account multiple impact factors szlapczynski and niksa rynkiewicz 2018 szlapczynski and szlapczynska 2017 however these two types of ship domains usually depend on the expertise knowledge szlapczynski and szlapczynska 2017 for example the determination of knowledge based ship domains is obviously heavily dependent on the choice of surveyed navigators even experts judgments are subjective szlapczynski and szlapczynska 2017 subjectivity is also the problem of analytical domains because the assumptions and formula for the analytical domains depend on the expertise of the researchers the contemporary ship domains tend to combine the features of different types of ship domains and use big ais data for domain determination the ship domain developed by wang and chin 2016 is an example which has the features of both analytical ship domains and empirical ship domains as aforementioned the fuzzy domain has many advantages and can depict the boundary as a vague value rather than a crisp value using fuzzy set which makes it suitable for risk evaluation probability is another tool to describe vague information which can be calibrated using sampling data rather than the subjective human judgment today ais is widely available and records the real navigational behavior of navigators with respect to the navigational environments e g kang et al 2019b kang et al 2018 this study thus aims to i define the probabilistic ship domain in a given restricted water area because it can well describe the navigational behavior of captains ii develop an effective big ais data driven approach to determine the probabilistic ship domain and iii quantitatively assess the ship collision risk by using the probabilistic ship domain the rest of the paper is organized as follows the definition and formulation of the probabilistic domain are presented in section 2 followed by the big ais data driven approach to determine the probabilistic ship domain subsequently we investigate the application of the probabilistic ship domain to assess ship collision risk finally a few case studies from the singapore strait are conducted which numerically compare the probabilistic ship domain with two traditional ship domains and then show the application of probabilistic ship domain in ship collision risk assessment 2 probabilistic ship domain 2 1 the definition of probabilistic ship domain given a restricted water area denoted by ω there are many different types of ship sailing in the restricted water area at any time instance any two adjacent sailing ships in the restricted water area should keep a certain distance to avoid the possible ship collision or near miss fujii and tanaka 1971 and goodwin 1975 defined the domain of a ship as follows an effective area around a ship in which a navigator would like to keep free with respect to other ships in this ship domain it is supposed that the water area around the ship is divided into two sub areas namely the risk area and safe area shown in fig 1 a the captains keep the risk area clean such that they have sufficient reaction time and space to take the necessary actions operations avoiding possible ship collisions in reality the boundary between the risk and safe areas is vague and uncertain because of the different navigational behaviors of captains as shown in fig 1 b the risk area can be precisely divided into two sub areas forbidden and risk sub areas other than the own ship there will be no other ships sailing in the forbidden area nevertheless another ship would probably enter the risk sub area the probability of which depends on the behavior of navigators sailing speeds ship types as well as the navigational conditions of the restricted water areas this probability increases when the distance to the own ship surpasses the boundary of the forbidden sub area because of the low ship collision risk gucma and marcjan 2012 proposed a similar probabilistic model of minimal passing distances the field data analysis in singapore port confirms the minimal distances with long tailed distribution named as ship safety distance zhang et al 2015 as shown in fig 1 b the length defined by δ θ r θ r min θ can be formulated as a continuous random variable for any given polar angle θ where r m i n θ is the distance from the own ship to the boundary of the forbidden area r θ is the distance between the target ship and own ship it can be seen that δ θ is the distance from the boundary of the forbidden area to the target ship in sector θ let f δ θ x denote the probability density function of the continuous random variable δ θ defined in the sample space 0 l θ for a given angle θ namely the ship domain probability function l θ is a given non negative value and it is set to 2 nm which is the safe distance beyond which the target ship is not considered as a threat from the perspective of ship collision dinh and im 2016 the probabilistic ship domain with the probability of 0 α 1 which is referred to as α ship domain is mathematically defined by 1 s α r min θ δ θ θ 0 δ θ f δ θ ω d ω α 0 δ θ l θ r m i n θ 0 0 θ 360 0 as illustrated in fig 2 given different values of α the ship domain can be depicted by a series of contours which is called the α boundary the a boundary is expressed by 2 r α r min θ δ θ θ 0 δ θ f δ θ ω d ω α 0 δ θ l θ r m i n θ 0 0 θ 360 0 when α is zero the corresponding boundary is identical to the boundary of the forbidden sub area and it is named as the forbidden boundary that illustrates the water area of the highest risk around the own ship 2 2 probabilistic ship domain vs deterministic and fuzzy ship domains we now investigate the similarities and differences among the probabilistic ship domain deterministic ship domains and fuzzy ship domains 2 2 1 probabilistic domain vs deterministic domain the significant difference between the α domain and deterministic ship domain is the way to describe the boundary between the safe and risk areas around the own ship the deterministic ship domains consider the boundary between the safe and risk areas as the crisp numeric value in the α domain model the ship domain boundary is considered as the probabilistic value based on the distribution of the target ships the distribution of the distance to the target ships is affected by many factors such as the navigational behavior of the captains and the navigational environments the deterministic ship domains can be regarded as a special case of the α domain as shown in fig 3 the ship density in a small area around the own ship with the width of 2 δ h at the distance r is 3 ρ r δ h n r δ h r δ h f δ θ ω d ω 1 m π r δ h 2 1 m π r δ h 2 m n r δ h r δ h f δ θ ω d ω 4 π r δ h where r is the distance to the own ship δ h is the small distance around r and m is the number of sectors let δ h 0 and ξ r δ h r δ h we have the lim ξ r according to the mean value theorem of integrals the limit of formula 3 is 4 lim δ h 0 ρ r δ h lim δ h 0 m n f δ θ ξ 2 δ h 4 π r δ h m n f δ θ r 2 π r k f δ θ r r where n is the sample number and k m n 2 π it can be easily seen that the ship density equals the probability of ships per unit arc length multiplies a constant value k thus in a small area at the distance of r the ship density can be calculated by 5 ρ r m n f δ θ r 2 π r m n 2 π f δ θ r r let ρ r be the maximum value of ρ r then r is the position of the maximum ship density from own ship in other words r composes the boundary at which the ship density reaches the maximum this boundary is defined as the desired boundary the desired boundary indicates the distances that the captains are more likely to keep when two ships sailing alongside each other this is the same as the definition of the boundary in the classical ship domains models which is defined as the distance at which the ship density is the highest fujii and tanaka 1971 goodwin 1975 2 2 2 probabilistic domain vs fuzzy ship domains the α domain and fuzzy domain has similarities in depicting the boundary as the vague value which can reflect the diversity of the behaviors of navigators moreover both of the α domain and fuzzy domain are related to the risk level which makes them suitable for risk analysis however the rationale to characterize the uncertainty is totally different probability is associated with events and not facts and those events will either occur or not occur there is nothing fuzzy about it however fuzzy logic is all about the degree of truth pietrzykowski uriasz 2009 used the member function of the fuzzy ship domain by learning from the navigators knowledge using the artificial neural networks with fuzzy logic when the fuzzy ship domains are applied to the ship collision risk assessment by different people the membership function may not be the same which leads to the inconsistent assessment results for the α domain the uncertainty of the captains navigational behavior is quantified based on the frequency of the target ships at different distances which can be determined by the historical ship trajectories it should be noted that the probabilistic domain is heavily dependent on the set of ais data while the fuzzy domain depends on the knowledge of the experts such as navigators 3 big ais data driven approach to determine the probabilistic ship domain to determine the probabilistic ship domain we have to define the critical ship safety distance cssd between the own and its neighboring ships as illustrated in fig 4 as shown in fig 4 a the ship safety distance ssd is defined as the minimum distance from own ship to a number of ships around the own ship at the given time instance t 1 during a period the ssd changes over time and the minimum ssd occurred at time instance t 2 is called the cssd for example during the ship overtaking process the ssd is large at first and then the ssd decreases which results in the rise in the collision risk the captain changes the course to keep the distance above the minimum distance which is the boundary between the risk area and safe area it should be noted that the captain of the own ship only cares about the status of the nearest ship in one direction which is the most serious threat to its safety as a data driven ship domain although the probabilistic domain does not explicitly take into account the impact factor variable as fuzzy domain it can consider the impact factors by categorizing the input ais data into different groups under different scenarios in each category the impact factors are similar such as the same ship type ship speed and navigation environment for example we can determine the ship domain for a certain type of ship in a specific water area the own ship speed can be categorized into different levels such as low speed normal speed and high speed then the ship domains determined based on the data in certain category implicitly consider the impact factors of the corresponding scenario fig 5 depicts the flowchart of the big ais data driven approach to determine the probabilistic ship domain it includes four steps step 1 ais data cleansing and interpolation step 2 the cssd data calculation step 3 abnormal cssd data elimination and step 4 the α domain determination these four steps are elaborated in the following 4 sub sections there are some similarities between this approach and the study by hansen et al 2013 both studies determine the ship domain based on the amount of time during which another ship is observed at the given position relative to the own ship which is presented as the frequency of the distance from the own ship to the target ship however our study differs from the study by hansen et al 2013 as follows firstly the distances used to determine the ship domain in the study by hansen et al 2013 include all the distances at different time while in our study we only use the critical ship safety distance cssd which is defined based on the smallest distance during the encounter of two ships moreover in our study we developed a data cleansing algorithm to remove the noise data in cssd data 3 1 step 1 ais data cleansing and interpolation the ais data should be cleaned and interpolated in the time domain the raw ais data are not immune to errors occurring during collection and transmission which thus need cleanness to eliminate the possible noises the raw ais data are sent at different times randomly to get the snapshot of ship dynamics the ais data must be interpolated with a predefined time interval the procedure proposed by qu et al 2011 is adopted to cleanse the ais data noise which is based on the fundamental physical law of the vessel movement in order to get the snapshot of ship status the ais data should be interpolated with a predefined time interval in this study a linear interpolation method proposed by zhang et al 2015 is used for data interpolation and the predefined time interval is set to 30 s 3 2 step 2 critical ship safety distance calculation the cssd is calculated using the cleaned and interpolated ais data generated in step 1 and ship characteristic data the generated ais data contains information of ship mmsi latitude longitude course of ground speed of ground ship draught ship type and time stamp the ship characteristics data provides the information of ship length and ship type we first calculate the distances between all pairs of ships with the computational complexity of n 2 where n is the number of ships at a given time instance to improve the computation efficiency we only iterate the ships within a given distance denoted by d u p the minimum distance between the own ship and target ship during a time span in sector θ is calculated as one record of cssd the cssd calculation method is presented below image 1 fig 6 plots the cssd data calculated for two container ships sailing in the two water areas of singapore strait by using one week ais data from october 2 2013 to october 8 2013 according to fig 6 it can be found that around the own ship there is an area in which no ship enters it can be also seen that the ship density around the dotted circle is much higher than the other areas 3 3 step 3 critical ship safety distance data cleansing the cssd data cannot be used directly for the probabilistic ship domain determination without abnormal data elimination because there are abnormal cssd data generated by or exceptional navigational behavior such as accidents caused by human errors for example as shown in fig 6 near the own ship there are some data points with extremely low density which would be the ships invading the ship domain accidently to eliminate these abnormal cssd data we develop the abnormal cssa data elimination algorithm inspired by the low frequency noise elimination algorithm for the salt and pepper data noise in image processing firstly we convert the cssd data into an image by taking each cssd as a pixel the height m and width n of the image depend on the spatial resolution in the row and column directions of δ x and δ y respectively let i 1 2 n be the index of the cssd data r i and θ i be the polar radius and polar angle of the cssd data i m and n are then calculated by 6 m max r i sin θ i min r i sin θ i δ y 7 n max r i cos θ i min r i cos θ i δ x where x is the math operator to get the smallest integer larger than x the position of the own ship is calculated by x 0 y 0 min r i cos θ i min r i sin θ i the value of the pixel i j is the number of the cssd data located in the grid of i j fig 7 a and c show two examples of the image created based on the raw cssd data it can be seen clearly that there is salt and pepper noise marked with the circle once the image has been created we eliminate the pixels around which the total number of the nonzero value pixels is below the predefined threshold ξ n e i g h b o r the larger ξ n e i g h b o r is the more pixels will be eliminated as the noise data the neighbor area of the pixel i j is defined as 8 d i j δ h d x y i δ h x i δ h j δ h y j δ h 0 x m 0 y n where δ h is the width of the neighbor area the abnormal cssd data elimination algorithm is presented as follows image 2 fig 7 shows the results of the abnormal cssd data cleansing as an image it can be seen that the abnormal data marked with circles in fig 7 a and c are removed by the proposed algorithm as shown in fig 7 b and 7 d respectively 3 4 step 4 α domain determination according to the definition of α domain the domain probability function f δ θ x is determined by the probability density function of the random variable δ θ the cssd data are the sample of random variable δ θ which can be used to identify the probability density function of δ θ using the kernel density estimation the cssd data in sector θ i are grouped by the set c s s d x θ i a n g l e x θ i 1 i 1 n where a n g l e x is the polar angle of the cssd x the pdf of δ θ is given by 9 g x 1 k j 1 k ϕ h x x j 1 k h j 1 k ϕ h x x j h where ϕ is a 1 d kernel function that satisfies ϕ x 0 and r ϕ x d x 1 in the real number field r h is a bandwidth parameter larger than 0 k is the number of elements in the set to be investigated within the window bandwidth h in this paper the gaussian kernel is adopted to calculate the probability density function the probability density function of δ θ can be illustrated by a real world example shown in fig 8 this example uses the one week ais data in the singapore strait in fig 8 a we can observe the forbidden area and boundary of the ship domain in fig 8 b there is a maximum peak value of the pdf of δ θ and the value increases with the rise of the cssd before the pdf reaches the peak value after the pdf of δ θ approaches the peak the value of this function decreases when cssd becomes larger the α domain is composed of forbidden area boundary and the ship domain probability functions with cssd data the probability density function of δ θ can be determined using the kernel density estimation method given any risk level 1 α the α boundary can be determined the α boundary is similar to the α cut of fuzzy ship domain where the value α represents the safety level pietrzykowski and magaj 2017 pietrzykowski 2008 moreover both the probabilistic domain and fuzzy domain model the boundary of the ship domain as the vague value rather than the crisp value using probability and fuzzy set respectively the α ship domain can be determined according to the following steps first fetch all cssd data in every sector θ and then calculate the forbidden boundary using the cleansed cssd then the distribution of the cssd in every sector is calculated using the kernel density estimation method subsequently the boundary of the α domain can be calculated according to each given safe level finally the desired boundary of the α domain can be determined by the local maximum value of the kernel density function the details of the algorithm to determine the α ship domain is illustrated as follows image 3 4 ship collision risk assessment using the probabilistic ship domain for ship collision risk assessment the traditional ship domains are used as thresholds to judge whether there is collision risk more specifically there is no collision risk if the target ship is outside of the ship domain of the own ship otherwise there is collision risk debnath and chin 2010 the probabilistic ship domain can not only evaluate whether there is collision risk but also calculate the risk level by the probability of δ θ which can be measured by the frequency of the critical ship safe distance at the position θ r the ship collision risk is defined by 10 r θ r 1 0 r r m i n θ 1 0 r r m i n f δ θ ω d ω r min θ r l θ where r is the distance to the own ship r m i n θ is on the boundary of the forbidden area in sector θ and f δ θ x is the probability density function of δ θ at the distance x it can be easily seen that 0 r θ r 1 the ship collision risk defined by equation 10 has significant implications the larger probability of the presence of the target ships indicates the lower collision risk on the contrary the lower probability of the presence of the target ships shows that quite few ships dare to navigate at this position considering the high collision risk in the forbidden area this probability decreases to zero and the collision risk increases to the largest value of one the risk level in the probabilistic domain whose α value is set to α is higher than 1 α in other words given a risk level β there is a corresponding probabilistic domain with the α value of 1 β the probabilistic ship domain is suitable for quantitative safety evaluation and navigation operation first in the α domain the risk level is a continuous value which is quantitatively determined by the probability of the presence of the target ships in the traditional ship domain models such as fujii s domain and the goodwin s domain there are only two risk levels risk level or safe level in reality the risk level increases continuously with the decrease of the safety distance which cannot be captured by the traditional deterministic ship domain models moreover the α domain model can be effectively calibrated by calculating the domain probability function hence the ship collision risk assessment results are more robust because it does not rely on the experts knowledge required by the fuzzy ship domain 5 case studies to compare the impact of the navigational conditions in different water areas on the probabilistic ship domain we select three channel segments with different widths in the singapore straight shown in fig 9 to establish the probabilistic ship domains in these three channel segments for container ships we use one week ais data in the singapore straight from october 2 2013 to october 8 2013 the one week ais data contains the information of maritime mobile service identity mmsi vessel position time speed course draught cargo destination short safety message and etc the vessel information is retrieved from a commercial database with the characteristics of 70 509 ships including the maritime mobile service identity number type of vessel length beam and etc the one week ais data consist of 1 257 860 records generated by 2618 different ships the average sailing speed of these ships is 7 41 knots and the average length is 155 56 m the most frequent ships are general cargo ships container ships oil tankers and lng ships whose occupations are 18 58 16 47 14 10 and 12 09 respectively the big ais data driven approach for probabilistic ship domain determination is implemented using python2 7 as the plugins of a maritime traffic simulation platform named as stss http stss maritime github io this platform has the functions of the ais data visualization and the basic gis functions to manage both nautical chart and the ais data we also develop a cssd data checking module using the ais data visualization method on the platform of stss after checking the extremely small cssd values we found that the cssd of several types of ships must be removed from the dataset for the probabilistic ship domain determination these ship types include tug ships pilot ships and tender ships which supply services for commercial ships such as container ships and oil tankers during the service time these ships are close adjacent to the own ship and thus the cssd data with the service providing ships involved does not reflect the normal sailing behavior from the perspective of the navigation safety as the one week ais data include 1 257 860 ais records the amount of ssd data is much larger because each ship has many target ships at any time instance by calculating the cssd rather than the ssd the numbers of the records in the three areas shown in fig 9 are respectively 60 301 57 190 and 84 143 which are quite small compared with the size of the ais data 5 1 probabilistic ship domain determination the ais data should be categorized into different groups to determine the ship domains under different scenarios because ship domain is affected by many factors such as the ship type ship speed and navigation environment fig 10 shows the established α domains for container ships in the water area 1 with different sailing speeds the sailing speeds are categorized into three groups a the slow speed below 10 knots b the medium speed between 10 knots and 12 knots and c the high speed above 12 knots the reason that we choose 12 knots as the threshold value between the high speed and medium speed is that the speed limit in singapore strait is 12 knots as shown in fig 10 a the α domain is represented by dashed contours of various collision risks or the domain probabilities in fig 10 a the forbidden boundary and the desired boundary are marked with the solid blue and the black lines respectively the α value of the dashed contour represents the probabilities of the ships presenting within that contour in fig 10 we can see that the probability values of one desired boundary are a bit different from each other roughly around 0 4 to 0 5 the area inside the forbidden boundary is extremely dangerous and the probability of target ships navigating in is zero in fig 10 b it can be seen that the distribution of the risk level around a ship looks like a cowboy hat the risk level in the water area far from the own ship is quite small and the risk increases when the target ship approaches the own ship when the target ship enters the forbidden area the risk level reaches the highest value of one as shown in fig 10 some part of the domain boundary is not convex which does not exist in the ship domains with the assumption of convex boundaries such as circular elliptical or polygonal boundaries in this study we do not model the ship domain with the assumption of the convex boundary instead the boundary is modeled separately in every small sector θ as shown in fig 2 which is called free form ship domain by wang and chin 2016 the non convex ship domain is also found in the studies of hansen et al 2013 wang and chin 2016 and pietrzykowski 2008 one reason would be that with the increase of the amount of the sectors the sample size in each sector decreases another reason is that ais data is always suffered from data noise problems zhang et al 2017 2018 thus there would be some bias in the probability function estimation which could possibly result in the non convex part of the ship boundary curve in fig 10 we can find that the ship domain is significantly affected by the ship speed by comparing the desired boundary and the forbidden boundary of the ship domain to compare the radii of different ship domains y we analyze the forbidden and desired radii in three directions names starboard port and astern these three directions are defined as a starboard side is the angle from 0 to 112 5 b astern side is the angle from 112 5 to 247 5 and c port side is the angle from 247 5 to 360 it should be noted that the zero degree is the ship head direction and the angle increases in the clockwise direction as shown in table 1 the average values of the forbidden boundary and that of the desired boundary are quite different for the forbidden boundary the radius increases with the increase of the ship speed nevertheless no similar trend is found for the desired boundary to further investigate the impact of the water area features we calibrate the proposed ship domains in three different water areas two strait segments without crossing and one segment with crossing as shown in fig 9 areas 1 and 3 are strait segments without crossing whose widths are 1 942 km and 2 546 km respectively area 2 has the crossing vessel traffic entering or leaving the singapore port for the demonstration purpose the ship domains in these three different areas are only calibrated for ships with high speed which is above 12 knots the established probabilistic ship domains in these three water areas are shown in fig 11 which look quite different from each other first it can be found that the ship domain in water area 1 is more like a symmetrical geometry compared with area 2 and area 3 the ship domain of area 3 seems to rotate a small angle in the anti clockwise direction this would be caused by the turning vessel traffic flow in the westbound of area 3 moreover the boundary radii of ship domain in different areas vary greatly from each other as can be seen in table 2 the average radius length of the forbidden boundary of the ship domain in area 2 is significantly smaller than that in the other two areas whereas for the desired boundary the radii are similar in all the three water areas 5 2 numerical comparisons with the two traditional ship domains we compare the probabilistic ship domain with the traditional ship domains including fujii s domain fujii and tanaka 1971 goodwin s domain goodwin 1975 and an empirical ship domain based on ais data hansen et al 2013 fujii s domain and goodwin s domain depend on the ship length without considering the sailing speed we compare these two ship domains with the probabilistic ship domains established in the water areas 2 and 3 with the high speed ships exceeding 12 knots the ship length is supposed to be 200 m for both fujii s domain and goodwin s domain fig 12 shows the comparison results between the classical ship domains and the probabilistic ship domains as shown in fig 12 the gray area is surrounded by the desired boundary and the forbidden boundary of the α domain it can be seen that the desired boundary of the α domain roughly matches the goodwin s domain and fujii s domain in some sectors specifically the desired boundary of the proposed domain approximately matches the fujii s model on the starboard side and port side while it is quite different from each other in the astern sector for the astern sector the α domain roughly matches the goodwin s domain however the differences between the α domain and the classical ship domains are also significant the probabilistic domain provides the probability information of the threshold between the safe area and risk area which is more reasonable to depict the uncertainty of the human perception second the area of the forbidden boundary of the probabilistic ship domain is much smaller than both fujii s domain and goodwin s domain it is quite straightforward because the forbidden boundary of the proposed domain only contains the area with the highest risk furthermore the probabilistic domain is of free form while the classical ship domains have assumptions of the geometry of the ship domain such as circle or ellipse moreover the goodwin s ship domain is much larger than the desired boundary of the α domain on both port and starboard sides while fujii s ship domain matches much better the empirical ship domain by hansen et al 2013 is supposed to be an ellipse named with the comfort ellipse it has the same meaning as the desired boundary of the probabilistic domain proposed in this paper this empirical ship domain is determined in several water areas the length of the comfort ellipse is about 8 ship lengths 4 5 ship lengths in front of the ship and 3 5 ship lengths behind the ship the width of the comfort ellipse is 1 4 1 8 ship lengths for the comparison purpose we set the value of the ellipse width to 1 8 ship lengths as shown in fig 12 it can be seen that in area 2 the forbidden boundary is similar to the empirical domain which is the smallest of the four ship domains in area 3 the empirical ship domain is smaller than the forbidden boundary of the probabilistic domain one possible reason would be the different navigational condition in different water areas for example one water area used for empirical domain determination is only 300m wide which is much narrower than the singapore strait 5 3 probabilistic ship domain based ship collision risk assessment ship collision risk assessment is one of the important components in the formal safety assessment zhang et al 2019 wu et al 2015 yip et al 2015 to apply the probabilistic ship domain for ship collision assessment a case study is conducted to compare it with the fujii s domain and the goodwin s domain which have been widely used in ship collision assessment wang et al 2009 suppose a target ship approaches the own ship from the direction of 15 and 75 respectively the length of the own ship is 200 m the parameters of the fujii s domain and the goodwin s domain are determined according to the references fujii and tanaka 1971 goodwin 1975 zhao et al 1993 the α domain is calibrated in area 2 and 3 for the container ships with the speed above 12 knots as shown in the previous section fig 13 shows the spatial distributions of the collision risk around the own ship as shown in fig 13 a and b according to the definition of fujii s ship domain or goodwin s ship domain the own ship is in the risk status once its ship domain is invaded by the target ship or it is in the safe status however in reality the risk level increases continuously with the decrease of the safety distance rather than jump from safe status to risk status at a certain distance the α domain model can address this problem as can be seen in fig 13 c and d the proposed domain can quantitatively depict the change of the risk level with the increase of the safety distance we further elaborate how the proposed ship domain can be used for evaluating the collision risk level the α domain for the demonstration purpose is the one in area 2 the safety levels evaluated with different ship domains at different distances are shown in table 3 it can be found that the fujii s model and goodwin s model can only give the results of two risk status risk or safe status on the contrary the proposed ship domain can give the risk level in the form of continuous values which are more accurate more importantly in the α domain this risk value is determined by the probability of the presence of the target ships around the own ship calculated with the large ais data rather than determined only according to the experiences of the experts 6 conclusions we have proposed the novel probabilistic ship domain named α domain which can be estimated by the critical ship safety distance cssd data the probabilisitc ship domain can capture the diversity of the navigationavdl behaviors we have also shown that the traditional ship domains such as fujii s model and goodwin s models are the special case of the α domain a big ais data driven approach to effectively determine the α domain was also developed including four steps ais data cleansing and interpolation the cssd data calculation abnormal cssd data elimination and the α domain determination subsequently we investigated how to use the α domain to assess ship collision risk a few case studies from the singapore strait have been carried out we numerically compared the α domain with the two traditional ship domain fujii s domain and goodwin s domain it was found that the desired boundary of the α domain model approximately matches fujii s ship domain on the port side and starboard side and matches goodwin s ship domains on the aft side the case study also showed that the forbidden boundary of the α domain is significantly impacted by the sailing speed while the desired boundary keeps roughly stable more specifically the forbidden boundary of the α domain increases greatly with the rise of the sailing speed it was also found that the ship domain is quite different in different water areas in details in the small or narrow constrained water areas the ship domains are smaller we applied the α domain for the quantitative ship collision risk evaluation to conclude compared with the traditional ship domains the proposed α domain has several advantages first it considers the boundary between the safe and risk water area around the own ship as an area with probability information rather than a fixed value and thus can capture the diversity of the navigational behavior and the vagueness of the human perception of risk second the α domain is formulated based on the probability density function which can be efficiently estimated by the cssd data generated from the big ais data more importantly the α domain is intrinsically suitable for ship collision risk evaluation acknowledgments we are grateful to the two anonymous reviewers for their valuable comments and constructive suggestions on the early version of this study this study is supported by the research project tugboat scheduling for large container ports grant no r726000003646 funded by the ministry of education singapore via the institute of operations research and analytics at national university of singapore 
22714,ship domain plays a critical role in ship traffic risk assessment and safe navigation today the widely available ais data makes it possible to capture the diverse behaviors of navigators and navigational conditions by vessel trajectories in practice we propose the novel concept of probabilistic ship domain which depicts the ship domain boundary as the vague value rather than the crisp value with a forbidden boundary and a desired boundary we also develop an effective big ais data driven approach to determine the probabilistic ship domain we further investigate how to use the probabilistic ship domain to assess ship collision risk finally a few case studies from the singapore strait are conducted to show the merits of the probabilistic ship domain and the big ais data driven approach keywords probabilistic ship domain big ais data ship collision risk assessment 1 introduction ship domain is one of the unique features of ship traffic in the restricted water areas such as straits canals as well as port waters it has been widely used in ship collision risk assessment goerlandt and montewka 2015 weng and yang 2015 zhang et al 2016 ship collision avoidance analysis zhao et al 1993 debnath and chin 2010 szlapczynski et al 2018 lu et al 2018 near miss detection szlapczynski and niksa rynkiewicz 2018 and ship traffic simulation development goerlandt and kujala 2011 hsu 2014 kang et al 2019a since the ship domain was first proposed by fujii and tanaka 1971 in the 1960s a large number of ship domains have been developed differentiating from their shape and factors considered zhao et al 1993 wang et al 2010 smierzchalski and michalewicz 2000 szlapczynski and szlapczynska 2017 ship domains are related to factors such as ship size ship maneuverability hydrological conditions meteorological conditions ship velocity traffic intensity the knowledge of navigator zhao et al 1993 dinh and im 2016 based on the methodology to determine the ship domain and factors taken into account ship domains can be generally classified into three categories namely empirical domain knowledge based domain and analytical domain szlapczynski and niksa rynkiewicz 2018 dinh and im 2016 it should be noted that these three groups are not mutually exclusive these ship domains are developed for different purposes whose complexity domain determine method and factors considered are different empirical ship domains are the domain models determined empirically based on the field data the earliest work to determine the ship domain using field data can be traced back to the study by fujii and tanaka 1971 that used the real radar data in the recent years ais data is increasingly used to determine the ship domains because of the installation of as per the regulation of international maritime organization imo goerlandt et al 2017 pietrzykowski and uriasz 2009 pietrzykowski and magaj 2016 2017 for example hansen et al 2013 estimated the ship domain using a visualization method by plotting the ship traffic density based on the data from danish waters the results show that the empirical ship domain is roughly in accordance with that of fujii and tanaka 1971 and coldwell 1983 wang and chin 2016 proposed a free form asymmetrical polygon domain with the assumption that the domain size is a function of the ship length and speed this domain model is calibrated using the ga algorithm based on the ais data of singapore port and singapore strait wang and chin 2016 knowledge based ship domains are determined based on the experts knowledge such as the survey of the navigators neural network and fuzzy logic are two widely used methods to model the knowledge based ship domain zhao et al 1993 zhu et al 2001 szlapczynski and szlapczynska 2017 zhu et al 2001 developed a three layer back propagation neural network which is trained using the survey data collected from the navigators this ship domain model can take into account the ship length local visibility and manoeuvrability zhu et al 2001 the fuzzy domain can also take into account various factors which are described by the membership functions using linguistic variables dinh and im 2016 pietrzykowski 2008 pietrzykowski et al 2018 wang 2010 developed a fuzzy quaternion ship domain fqsd which was introduced to estimate the spatial collision risk pietrzykowski 2008 developed a fuzzy domain in restricted water areas considering navigational safety level the risk level is represented as the function of the risk impact factors such as distance to the fairway course deviation and rate of turn which is modeled using artificial intelligence and calibrated based on relevant navigators knowledge it is found that the ship domain area is an exponential function of the safety level and there is the same relationship between the domain boundary and the navigational safety level similarly a fuzzy ship domain for the open sea area was also developed which investigated the impact of the length of both own ship and target ship pietrzykowski and uriasz 2009 this study found that smaller ships usually adjust their domains when encountering large ships as the fuzzy domain is capable of taking into account multiple risk factors it is suitable for risk analysis for example the fuzzy ship domain is successfully applied to safe trajectory determination pietrzykowski 2005 wang 2010 pietrzykowski and magaj 2014 the analytical ship domain uses mathematical formulas and variables to model the domain boundary zhao et al 1993 wang et al 2010 for example wang et al 2010 proposed a quaternion ship domain qsd with four radii and the domain shape is modeled with five parameters which are functions of ship speed length and manoeuvrability then this domain has been extended by regarding the boundary as a fuzzy one resulting in the fuzzy ship domain another extension of qsd is to take into account the domain shape parameters as a function of impact factors including navigational environment human factors and ship manoeuvrability wang 2013 several other studies developed analytical ship domains for particular water areas for example rawson et al 2014 developed a ship domain for one area of the river thames in central london whose shape is a function of ship speed and ship type another region specific ship domain model has been developed for capacity analysis in restricted channels between tianjin and beijing which has a shape of ellipse with the semi axes parameters determined in an analytical way based on a specific problem for the discussed water region liu et al 2016 these three types of ship domains have their own advantages and limitations the empirical ship domains are determined based on the trajectory data such as ais data which are currently widely accessible however they are usually simple and for certain water area with specific navigational conditions since empirical data make it hard to isolate the impact of multiple parameters the analytical ship domains and knowledge based ship domains can take into account multiple impact factors szlapczynski and niksa rynkiewicz 2018 szlapczynski and szlapczynska 2017 however these two types of ship domains usually depend on the expertise knowledge szlapczynski and szlapczynska 2017 for example the determination of knowledge based ship domains is obviously heavily dependent on the choice of surveyed navigators even experts judgments are subjective szlapczynski and szlapczynska 2017 subjectivity is also the problem of analytical domains because the assumptions and formula for the analytical domains depend on the expertise of the researchers the contemporary ship domains tend to combine the features of different types of ship domains and use big ais data for domain determination the ship domain developed by wang and chin 2016 is an example which has the features of both analytical ship domains and empirical ship domains as aforementioned the fuzzy domain has many advantages and can depict the boundary as a vague value rather than a crisp value using fuzzy set which makes it suitable for risk evaluation probability is another tool to describe vague information which can be calibrated using sampling data rather than the subjective human judgment today ais is widely available and records the real navigational behavior of navigators with respect to the navigational environments e g kang et al 2019b kang et al 2018 this study thus aims to i define the probabilistic ship domain in a given restricted water area because it can well describe the navigational behavior of captains ii develop an effective big ais data driven approach to determine the probabilistic ship domain and iii quantitatively assess the ship collision risk by using the probabilistic ship domain the rest of the paper is organized as follows the definition and formulation of the probabilistic domain are presented in section 2 followed by the big ais data driven approach to determine the probabilistic ship domain subsequently we investigate the application of the probabilistic ship domain to assess ship collision risk finally a few case studies from the singapore strait are conducted which numerically compare the probabilistic ship domain with two traditional ship domains and then show the application of probabilistic ship domain in ship collision risk assessment 2 probabilistic ship domain 2 1 the definition of probabilistic ship domain given a restricted water area denoted by ω there are many different types of ship sailing in the restricted water area at any time instance any two adjacent sailing ships in the restricted water area should keep a certain distance to avoid the possible ship collision or near miss fujii and tanaka 1971 and goodwin 1975 defined the domain of a ship as follows an effective area around a ship in which a navigator would like to keep free with respect to other ships in this ship domain it is supposed that the water area around the ship is divided into two sub areas namely the risk area and safe area shown in fig 1 a the captains keep the risk area clean such that they have sufficient reaction time and space to take the necessary actions operations avoiding possible ship collisions in reality the boundary between the risk and safe areas is vague and uncertain because of the different navigational behaviors of captains as shown in fig 1 b the risk area can be precisely divided into two sub areas forbidden and risk sub areas other than the own ship there will be no other ships sailing in the forbidden area nevertheless another ship would probably enter the risk sub area the probability of which depends on the behavior of navigators sailing speeds ship types as well as the navigational conditions of the restricted water areas this probability increases when the distance to the own ship surpasses the boundary of the forbidden sub area because of the low ship collision risk gucma and marcjan 2012 proposed a similar probabilistic model of minimal passing distances the field data analysis in singapore port confirms the minimal distances with long tailed distribution named as ship safety distance zhang et al 2015 as shown in fig 1 b the length defined by δ θ r θ r min θ can be formulated as a continuous random variable for any given polar angle θ where r m i n θ is the distance from the own ship to the boundary of the forbidden area r θ is the distance between the target ship and own ship it can be seen that δ θ is the distance from the boundary of the forbidden area to the target ship in sector θ let f δ θ x denote the probability density function of the continuous random variable δ θ defined in the sample space 0 l θ for a given angle θ namely the ship domain probability function l θ is a given non negative value and it is set to 2 nm which is the safe distance beyond which the target ship is not considered as a threat from the perspective of ship collision dinh and im 2016 the probabilistic ship domain with the probability of 0 α 1 which is referred to as α ship domain is mathematically defined by 1 s α r min θ δ θ θ 0 δ θ f δ θ ω d ω α 0 δ θ l θ r m i n θ 0 0 θ 360 0 as illustrated in fig 2 given different values of α the ship domain can be depicted by a series of contours which is called the α boundary the a boundary is expressed by 2 r α r min θ δ θ θ 0 δ θ f δ θ ω d ω α 0 δ θ l θ r m i n θ 0 0 θ 360 0 when α is zero the corresponding boundary is identical to the boundary of the forbidden sub area and it is named as the forbidden boundary that illustrates the water area of the highest risk around the own ship 2 2 probabilistic ship domain vs deterministic and fuzzy ship domains we now investigate the similarities and differences among the probabilistic ship domain deterministic ship domains and fuzzy ship domains 2 2 1 probabilistic domain vs deterministic domain the significant difference between the α domain and deterministic ship domain is the way to describe the boundary between the safe and risk areas around the own ship the deterministic ship domains consider the boundary between the safe and risk areas as the crisp numeric value in the α domain model the ship domain boundary is considered as the probabilistic value based on the distribution of the target ships the distribution of the distance to the target ships is affected by many factors such as the navigational behavior of the captains and the navigational environments the deterministic ship domains can be regarded as a special case of the α domain as shown in fig 3 the ship density in a small area around the own ship with the width of 2 δ h at the distance r is 3 ρ r δ h n r δ h r δ h f δ θ ω d ω 1 m π r δ h 2 1 m π r δ h 2 m n r δ h r δ h f δ θ ω d ω 4 π r δ h where r is the distance to the own ship δ h is the small distance around r and m is the number of sectors let δ h 0 and ξ r δ h r δ h we have the lim ξ r according to the mean value theorem of integrals the limit of formula 3 is 4 lim δ h 0 ρ r δ h lim δ h 0 m n f δ θ ξ 2 δ h 4 π r δ h m n f δ θ r 2 π r k f δ θ r r where n is the sample number and k m n 2 π it can be easily seen that the ship density equals the probability of ships per unit arc length multiplies a constant value k thus in a small area at the distance of r the ship density can be calculated by 5 ρ r m n f δ θ r 2 π r m n 2 π f δ θ r r let ρ r be the maximum value of ρ r then r is the position of the maximum ship density from own ship in other words r composes the boundary at which the ship density reaches the maximum this boundary is defined as the desired boundary the desired boundary indicates the distances that the captains are more likely to keep when two ships sailing alongside each other this is the same as the definition of the boundary in the classical ship domains models which is defined as the distance at which the ship density is the highest fujii and tanaka 1971 goodwin 1975 2 2 2 probabilistic domain vs fuzzy ship domains the α domain and fuzzy domain has similarities in depicting the boundary as the vague value which can reflect the diversity of the behaviors of navigators moreover both of the α domain and fuzzy domain are related to the risk level which makes them suitable for risk analysis however the rationale to characterize the uncertainty is totally different probability is associated with events and not facts and those events will either occur or not occur there is nothing fuzzy about it however fuzzy logic is all about the degree of truth pietrzykowski uriasz 2009 used the member function of the fuzzy ship domain by learning from the navigators knowledge using the artificial neural networks with fuzzy logic when the fuzzy ship domains are applied to the ship collision risk assessment by different people the membership function may not be the same which leads to the inconsistent assessment results for the α domain the uncertainty of the captains navigational behavior is quantified based on the frequency of the target ships at different distances which can be determined by the historical ship trajectories it should be noted that the probabilistic domain is heavily dependent on the set of ais data while the fuzzy domain depends on the knowledge of the experts such as navigators 3 big ais data driven approach to determine the probabilistic ship domain to determine the probabilistic ship domain we have to define the critical ship safety distance cssd between the own and its neighboring ships as illustrated in fig 4 as shown in fig 4 a the ship safety distance ssd is defined as the minimum distance from own ship to a number of ships around the own ship at the given time instance t 1 during a period the ssd changes over time and the minimum ssd occurred at time instance t 2 is called the cssd for example during the ship overtaking process the ssd is large at first and then the ssd decreases which results in the rise in the collision risk the captain changes the course to keep the distance above the minimum distance which is the boundary between the risk area and safe area it should be noted that the captain of the own ship only cares about the status of the nearest ship in one direction which is the most serious threat to its safety as a data driven ship domain although the probabilistic domain does not explicitly take into account the impact factor variable as fuzzy domain it can consider the impact factors by categorizing the input ais data into different groups under different scenarios in each category the impact factors are similar such as the same ship type ship speed and navigation environment for example we can determine the ship domain for a certain type of ship in a specific water area the own ship speed can be categorized into different levels such as low speed normal speed and high speed then the ship domains determined based on the data in certain category implicitly consider the impact factors of the corresponding scenario fig 5 depicts the flowchart of the big ais data driven approach to determine the probabilistic ship domain it includes four steps step 1 ais data cleansing and interpolation step 2 the cssd data calculation step 3 abnormal cssd data elimination and step 4 the α domain determination these four steps are elaborated in the following 4 sub sections there are some similarities between this approach and the study by hansen et al 2013 both studies determine the ship domain based on the amount of time during which another ship is observed at the given position relative to the own ship which is presented as the frequency of the distance from the own ship to the target ship however our study differs from the study by hansen et al 2013 as follows firstly the distances used to determine the ship domain in the study by hansen et al 2013 include all the distances at different time while in our study we only use the critical ship safety distance cssd which is defined based on the smallest distance during the encounter of two ships moreover in our study we developed a data cleansing algorithm to remove the noise data in cssd data 3 1 step 1 ais data cleansing and interpolation the ais data should be cleaned and interpolated in the time domain the raw ais data are not immune to errors occurring during collection and transmission which thus need cleanness to eliminate the possible noises the raw ais data are sent at different times randomly to get the snapshot of ship dynamics the ais data must be interpolated with a predefined time interval the procedure proposed by qu et al 2011 is adopted to cleanse the ais data noise which is based on the fundamental physical law of the vessel movement in order to get the snapshot of ship status the ais data should be interpolated with a predefined time interval in this study a linear interpolation method proposed by zhang et al 2015 is used for data interpolation and the predefined time interval is set to 30 s 3 2 step 2 critical ship safety distance calculation the cssd is calculated using the cleaned and interpolated ais data generated in step 1 and ship characteristic data the generated ais data contains information of ship mmsi latitude longitude course of ground speed of ground ship draught ship type and time stamp the ship characteristics data provides the information of ship length and ship type we first calculate the distances between all pairs of ships with the computational complexity of n 2 where n is the number of ships at a given time instance to improve the computation efficiency we only iterate the ships within a given distance denoted by d u p the minimum distance between the own ship and target ship during a time span in sector θ is calculated as one record of cssd the cssd calculation method is presented below image 1 fig 6 plots the cssd data calculated for two container ships sailing in the two water areas of singapore strait by using one week ais data from october 2 2013 to october 8 2013 according to fig 6 it can be found that around the own ship there is an area in which no ship enters it can be also seen that the ship density around the dotted circle is much higher than the other areas 3 3 step 3 critical ship safety distance data cleansing the cssd data cannot be used directly for the probabilistic ship domain determination without abnormal data elimination because there are abnormal cssd data generated by or exceptional navigational behavior such as accidents caused by human errors for example as shown in fig 6 near the own ship there are some data points with extremely low density which would be the ships invading the ship domain accidently to eliminate these abnormal cssd data we develop the abnormal cssa data elimination algorithm inspired by the low frequency noise elimination algorithm for the salt and pepper data noise in image processing firstly we convert the cssd data into an image by taking each cssd as a pixel the height m and width n of the image depend on the spatial resolution in the row and column directions of δ x and δ y respectively let i 1 2 n be the index of the cssd data r i and θ i be the polar radius and polar angle of the cssd data i m and n are then calculated by 6 m max r i sin θ i min r i sin θ i δ y 7 n max r i cos θ i min r i cos θ i δ x where x is the math operator to get the smallest integer larger than x the position of the own ship is calculated by x 0 y 0 min r i cos θ i min r i sin θ i the value of the pixel i j is the number of the cssd data located in the grid of i j fig 7 a and c show two examples of the image created based on the raw cssd data it can be seen clearly that there is salt and pepper noise marked with the circle once the image has been created we eliminate the pixels around which the total number of the nonzero value pixels is below the predefined threshold ξ n e i g h b o r the larger ξ n e i g h b o r is the more pixels will be eliminated as the noise data the neighbor area of the pixel i j is defined as 8 d i j δ h d x y i δ h x i δ h j δ h y j δ h 0 x m 0 y n where δ h is the width of the neighbor area the abnormal cssd data elimination algorithm is presented as follows image 2 fig 7 shows the results of the abnormal cssd data cleansing as an image it can be seen that the abnormal data marked with circles in fig 7 a and c are removed by the proposed algorithm as shown in fig 7 b and 7 d respectively 3 4 step 4 α domain determination according to the definition of α domain the domain probability function f δ θ x is determined by the probability density function of the random variable δ θ the cssd data are the sample of random variable δ θ which can be used to identify the probability density function of δ θ using the kernel density estimation the cssd data in sector θ i are grouped by the set c s s d x θ i a n g l e x θ i 1 i 1 n where a n g l e x is the polar angle of the cssd x the pdf of δ θ is given by 9 g x 1 k j 1 k ϕ h x x j 1 k h j 1 k ϕ h x x j h where ϕ is a 1 d kernel function that satisfies ϕ x 0 and r ϕ x d x 1 in the real number field r h is a bandwidth parameter larger than 0 k is the number of elements in the set to be investigated within the window bandwidth h in this paper the gaussian kernel is adopted to calculate the probability density function the probability density function of δ θ can be illustrated by a real world example shown in fig 8 this example uses the one week ais data in the singapore strait in fig 8 a we can observe the forbidden area and boundary of the ship domain in fig 8 b there is a maximum peak value of the pdf of δ θ and the value increases with the rise of the cssd before the pdf reaches the peak value after the pdf of δ θ approaches the peak the value of this function decreases when cssd becomes larger the α domain is composed of forbidden area boundary and the ship domain probability functions with cssd data the probability density function of δ θ can be determined using the kernel density estimation method given any risk level 1 α the α boundary can be determined the α boundary is similar to the α cut of fuzzy ship domain where the value α represents the safety level pietrzykowski and magaj 2017 pietrzykowski 2008 moreover both the probabilistic domain and fuzzy domain model the boundary of the ship domain as the vague value rather than the crisp value using probability and fuzzy set respectively the α ship domain can be determined according to the following steps first fetch all cssd data in every sector θ and then calculate the forbidden boundary using the cleansed cssd then the distribution of the cssd in every sector is calculated using the kernel density estimation method subsequently the boundary of the α domain can be calculated according to each given safe level finally the desired boundary of the α domain can be determined by the local maximum value of the kernel density function the details of the algorithm to determine the α ship domain is illustrated as follows image 3 4 ship collision risk assessment using the probabilistic ship domain for ship collision risk assessment the traditional ship domains are used as thresholds to judge whether there is collision risk more specifically there is no collision risk if the target ship is outside of the ship domain of the own ship otherwise there is collision risk debnath and chin 2010 the probabilistic ship domain can not only evaluate whether there is collision risk but also calculate the risk level by the probability of δ θ which can be measured by the frequency of the critical ship safe distance at the position θ r the ship collision risk is defined by 10 r θ r 1 0 r r m i n θ 1 0 r r m i n f δ θ ω d ω r min θ r l θ where r is the distance to the own ship r m i n θ is on the boundary of the forbidden area in sector θ and f δ θ x is the probability density function of δ θ at the distance x it can be easily seen that 0 r θ r 1 the ship collision risk defined by equation 10 has significant implications the larger probability of the presence of the target ships indicates the lower collision risk on the contrary the lower probability of the presence of the target ships shows that quite few ships dare to navigate at this position considering the high collision risk in the forbidden area this probability decreases to zero and the collision risk increases to the largest value of one the risk level in the probabilistic domain whose α value is set to α is higher than 1 α in other words given a risk level β there is a corresponding probabilistic domain with the α value of 1 β the probabilistic ship domain is suitable for quantitative safety evaluation and navigation operation first in the α domain the risk level is a continuous value which is quantitatively determined by the probability of the presence of the target ships in the traditional ship domain models such as fujii s domain and the goodwin s domain there are only two risk levels risk level or safe level in reality the risk level increases continuously with the decrease of the safety distance which cannot be captured by the traditional deterministic ship domain models moreover the α domain model can be effectively calibrated by calculating the domain probability function hence the ship collision risk assessment results are more robust because it does not rely on the experts knowledge required by the fuzzy ship domain 5 case studies to compare the impact of the navigational conditions in different water areas on the probabilistic ship domain we select three channel segments with different widths in the singapore straight shown in fig 9 to establish the probabilistic ship domains in these three channel segments for container ships we use one week ais data in the singapore straight from october 2 2013 to october 8 2013 the one week ais data contains the information of maritime mobile service identity mmsi vessel position time speed course draught cargo destination short safety message and etc the vessel information is retrieved from a commercial database with the characteristics of 70 509 ships including the maritime mobile service identity number type of vessel length beam and etc the one week ais data consist of 1 257 860 records generated by 2618 different ships the average sailing speed of these ships is 7 41 knots and the average length is 155 56 m the most frequent ships are general cargo ships container ships oil tankers and lng ships whose occupations are 18 58 16 47 14 10 and 12 09 respectively the big ais data driven approach for probabilistic ship domain determination is implemented using python2 7 as the plugins of a maritime traffic simulation platform named as stss http stss maritime github io this platform has the functions of the ais data visualization and the basic gis functions to manage both nautical chart and the ais data we also develop a cssd data checking module using the ais data visualization method on the platform of stss after checking the extremely small cssd values we found that the cssd of several types of ships must be removed from the dataset for the probabilistic ship domain determination these ship types include tug ships pilot ships and tender ships which supply services for commercial ships such as container ships and oil tankers during the service time these ships are close adjacent to the own ship and thus the cssd data with the service providing ships involved does not reflect the normal sailing behavior from the perspective of the navigation safety as the one week ais data include 1 257 860 ais records the amount of ssd data is much larger because each ship has many target ships at any time instance by calculating the cssd rather than the ssd the numbers of the records in the three areas shown in fig 9 are respectively 60 301 57 190 and 84 143 which are quite small compared with the size of the ais data 5 1 probabilistic ship domain determination the ais data should be categorized into different groups to determine the ship domains under different scenarios because ship domain is affected by many factors such as the ship type ship speed and navigation environment fig 10 shows the established α domains for container ships in the water area 1 with different sailing speeds the sailing speeds are categorized into three groups a the slow speed below 10 knots b the medium speed between 10 knots and 12 knots and c the high speed above 12 knots the reason that we choose 12 knots as the threshold value between the high speed and medium speed is that the speed limit in singapore strait is 12 knots as shown in fig 10 a the α domain is represented by dashed contours of various collision risks or the domain probabilities in fig 10 a the forbidden boundary and the desired boundary are marked with the solid blue and the black lines respectively the α value of the dashed contour represents the probabilities of the ships presenting within that contour in fig 10 we can see that the probability values of one desired boundary are a bit different from each other roughly around 0 4 to 0 5 the area inside the forbidden boundary is extremely dangerous and the probability of target ships navigating in is zero in fig 10 b it can be seen that the distribution of the risk level around a ship looks like a cowboy hat the risk level in the water area far from the own ship is quite small and the risk increases when the target ship approaches the own ship when the target ship enters the forbidden area the risk level reaches the highest value of one as shown in fig 10 some part of the domain boundary is not convex which does not exist in the ship domains with the assumption of convex boundaries such as circular elliptical or polygonal boundaries in this study we do not model the ship domain with the assumption of the convex boundary instead the boundary is modeled separately in every small sector θ as shown in fig 2 which is called free form ship domain by wang and chin 2016 the non convex ship domain is also found in the studies of hansen et al 2013 wang and chin 2016 and pietrzykowski 2008 one reason would be that with the increase of the amount of the sectors the sample size in each sector decreases another reason is that ais data is always suffered from data noise problems zhang et al 2017 2018 thus there would be some bias in the probability function estimation which could possibly result in the non convex part of the ship boundary curve in fig 10 we can find that the ship domain is significantly affected by the ship speed by comparing the desired boundary and the forbidden boundary of the ship domain to compare the radii of different ship domains y we analyze the forbidden and desired radii in three directions names starboard port and astern these three directions are defined as a starboard side is the angle from 0 to 112 5 b astern side is the angle from 112 5 to 247 5 and c port side is the angle from 247 5 to 360 it should be noted that the zero degree is the ship head direction and the angle increases in the clockwise direction as shown in table 1 the average values of the forbidden boundary and that of the desired boundary are quite different for the forbidden boundary the radius increases with the increase of the ship speed nevertheless no similar trend is found for the desired boundary to further investigate the impact of the water area features we calibrate the proposed ship domains in three different water areas two strait segments without crossing and one segment with crossing as shown in fig 9 areas 1 and 3 are strait segments without crossing whose widths are 1 942 km and 2 546 km respectively area 2 has the crossing vessel traffic entering or leaving the singapore port for the demonstration purpose the ship domains in these three different areas are only calibrated for ships with high speed which is above 12 knots the established probabilistic ship domains in these three water areas are shown in fig 11 which look quite different from each other first it can be found that the ship domain in water area 1 is more like a symmetrical geometry compared with area 2 and area 3 the ship domain of area 3 seems to rotate a small angle in the anti clockwise direction this would be caused by the turning vessel traffic flow in the westbound of area 3 moreover the boundary radii of ship domain in different areas vary greatly from each other as can be seen in table 2 the average radius length of the forbidden boundary of the ship domain in area 2 is significantly smaller than that in the other two areas whereas for the desired boundary the radii are similar in all the three water areas 5 2 numerical comparisons with the two traditional ship domains we compare the probabilistic ship domain with the traditional ship domains including fujii s domain fujii and tanaka 1971 goodwin s domain goodwin 1975 and an empirical ship domain based on ais data hansen et al 2013 fujii s domain and goodwin s domain depend on the ship length without considering the sailing speed we compare these two ship domains with the probabilistic ship domains established in the water areas 2 and 3 with the high speed ships exceeding 12 knots the ship length is supposed to be 200 m for both fujii s domain and goodwin s domain fig 12 shows the comparison results between the classical ship domains and the probabilistic ship domains as shown in fig 12 the gray area is surrounded by the desired boundary and the forbidden boundary of the α domain it can be seen that the desired boundary of the α domain roughly matches the goodwin s domain and fujii s domain in some sectors specifically the desired boundary of the proposed domain approximately matches the fujii s model on the starboard side and port side while it is quite different from each other in the astern sector for the astern sector the α domain roughly matches the goodwin s domain however the differences between the α domain and the classical ship domains are also significant the probabilistic domain provides the probability information of the threshold between the safe area and risk area which is more reasonable to depict the uncertainty of the human perception second the area of the forbidden boundary of the probabilistic ship domain is much smaller than both fujii s domain and goodwin s domain it is quite straightforward because the forbidden boundary of the proposed domain only contains the area with the highest risk furthermore the probabilistic domain is of free form while the classical ship domains have assumptions of the geometry of the ship domain such as circle or ellipse moreover the goodwin s ship domain is much larger than the desired boundary of the α domain on both port and starboard sides while fujii s ship domain matches much better the empirical ship domain by hansen et al 2013 is supposed to be an ellipse named with the comfort ellipse it has the same meaning as the desired boundary of the probabilistic domain proposed in this paper this empirical ship domain is determined in several water areas the length of the comfort ellipse is about 8 ship lengths 4 5 ship lengths in front of the ship and 3 5 ship lengths behind the ship the width of the comfort ellipse is 1 4 1 8 ship lengths for the comparison purpose we set the value of the ellipse width to 1 8 ship lengths as shown in fig 12 it can be seen that in area 2 the forbidden boundary is similar to the empirical domain which is the smallest of the four ship domains in area 3 the empirical ship domain is smaller than the forbidden boundary of the probabilistic domain one possible reason would be the different navigational condition in different water areas for example one water area used for empirical domain determination is only 300m wide which is much narrower than the singapore strait 5 3 probabilistic ship domain based ship collision risk assessment ship collision risk assessment is one of the important components in the formal safety assessment zhang et al 2019 wu et al 2015 yip et al 2015 to apply the probabilistic ship domain for ship collision assessment a case study is conducted to compare it with the fujii s domain and the goodwin s domain which have been widely used in ship collision assessment wang et al 2009 suppose a target ship approaches the own ship from the direction of 15 and 75 respectively the length of the own ship is 200 m the parameters of the fujii s domain and the goodwin s domain are determined according to the references fujii and tanaka 1971 goodwin 1975 zhao et al 1993 the α domain is calibrated in area 2 and 3 for the container ships with the speed above 12 knots as shown in the previous section fig 13 shows the spatial distributions of the collision risk around the own ship as shown in fig 13 a and b according to the definition of fujii s ship domain or goodwin s ship domain the own ship is in the risk status once its ship domain is invaded by the target ship or it is in the safe status however in reality the risk level increases continuously with the decrease of the safety distance rather than jump from safe status to risk status at a certain distance the α domain model can address this problem as can be seen in fig 13 c and d the proposed domain can quantitatively depict the change of the risk level with the increase of the safety distance we further elaborate how the proposed ship domain can be used for evaluating the collision risk level the α domain for the demonstration purpose is the one in area 2 the safety levels evaluated with different ship domains at different distances are shown in table 3 it can be found that the fujii s model and goodwin s model can only give the results of two risk status risk or safe status on the contrary the proposed ship domain can give the risk level in the form of continuous values which are more accurate more importantly in the α domain this risk value is determined by the probability of the presence of the target ships around the own ship calculated with the large ais data rather than determined only according to the experiences of the experts 6 conclusions we have proposed the novel probabilistic ship domain named α domain which can be estimated by the critical ship safety distance cssd data the probabilisitc ship domain can capture the diversity of the navigationavdl behaviors we have also shown that the traditional ship domains such as fujii s model and goodwin s models are the special case of the α domain a big ais data driven approach to effectively determine the α domain was also developed including four steps ais data cleansing and interpolation the cssd data calculation abnormal cssd data elimination and the α domain determination subsequently we investigated how to use the α domain to assess ship collision risk a few case studies from the singapore strait have been carried out we numerically compared the α domain with the two traditional ship domain fujii s domain and goodwin s domain it was found that the desired boundary of the α domain model approximately matches fujii s ship domain on the port side and starboard side and matches goodwin s ship domains on the aft side the case study also showed that the forbidden boundary of the α domain is significantly impacted by the sailing speed while the desired boundary keeps roughly stable more specifically the forbidden boundary of the α domain increases greatly with the rise of the sailing speed it was also found that the ship domain is quite different in different water areas in details in the small or narrow constrained water areas the ship domains are smaller we applied the α domain for the quantitative ship collision risk evaluation to conclude compared with the traditional ship domains the proposed α domain has several advantages first it considers the boundary between the safe and risk water area around the own ship as an area with probability information rather than a fixed value and thus can capture the diversity of the navigational behavior and the vagueness of the human perception of risk second the α domain is formulated based on the probability density function which can be efficiently estimated by the cssd data generated from the big ais data more importantly the α domain is intrinsically suitable for ship collision risk evaluation acknowledgments we are grateful to the two anonymous reviewers for their valuable comments and constructive suggestions on the early version of this study this study is supported by the research project tugboat scheduling for large container ports grant no r726000003646 funded by the ministry of education singapore via the institute of operations research and analytics at national university of singapore 
