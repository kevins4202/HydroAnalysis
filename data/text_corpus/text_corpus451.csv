index,text
2255,in this work three variant time domain random walk tdrw algorithms were developed for the problem of solute transport in a single fracture matrix system where an arbitrary inlet boundary condition can be applied one approach performs an additional evaluation of integral in terms of injection boundary and the solution to a dirac delta case one method makes use of two functions dependent on specific boundary conditions to estimate the particle arrival time the other additionally introduces the concept of solute injection time resulting from the injection boundary into the calculation of particle arrival time to validate the developed variant algorithms two benchmark cases are considered with respect to a general dirichlet injection mode and a robin injection boundary respectively the results from three approaches all make a good agreement with those of inverse laplace transform method however the monte carlo nature of the tdrw algorithm implies that the accuracy of the computational result is highly dependent on the number of particles applied in the simulation keywords variant time domain random walk algorithms boundary conditions statistical interpretation convolution cumulative distribution function data availability data will be made available on request nomenclature d f dispersion coefficient in the fracture l 2 t 1 d p pore diffusion coefficient in the matrix l 2 t 1 e defined function l 1 f cumulative distribution function of solute advection time p i n cumulative distribution function of solute injection time g cumulative distribution function of the solute residence time in the porous rock matrix h heaviside step function n total number of particles injected in the system n i the number of particles falling in each bin n s total number of particles for collected at a specific time p i n cumulative distribution function of solute injection time p e péclet number r f surface retardation factor in the fracture r p retardation factor in the matrix u random number y random number z random number b half aperture l c 0 the concentration at the inlet of the fracture m l 3 c 1 c 2 constants m l 3 c f solute concentration in the fracture m l 3 c f δ solute concentration in the fracture for a dirac delta boundary condition m l 3 c f solute concentration in the fracture in the laplace domain m t l 3 c i n injected solute concentration at the inlet of the fracture m l 3 c i n injected solute concentration at the inlet of the fracture in the laplace domain m t l 3 f impulse response function in a fracture only system involving no surface retardation or probability density function of the solute advection time t 1 g impulse response function of the fracture matrix system or probability density function of the solute residence time in the porous rock matrix t 1 p i n probability density function of solute injection time t 1 s laplace transform variable t 1 t time t t i n solute injection time t t p solute residence time in the porous matrix t t s particle arrival time t t w water residence time t δ t 1 δ t 2 δ t 3 constants t u flow velocity l t 1 x distance along the flow direction from the origin of fracture l z distance into the rock matrix l δ dirac delta function t 1 ε p porosity ξ integral variable t τ solute advection time t ϕ normalized time ω constant t 1 φ diffusive mass transfer parameter t 1 2 1 introduction numerous computation tools based on either channel network model cnm gylling et al 1999 selroos et al 2002 shahkarami et al 2018 2016 or discrete fracture network dfn model alghalandis 2017 dershowitz et al 1998 hyman et al 2015 junkin et al 2018 have been developed to aid the safety and performance assessment pa of deep geological repositories for spent nuclear fuel both models aim to address the problem of water flow and nuclide transport in fractured crystalline rocks under the conditions of repositories and conceptualize the crystalline rocks as a network of fractures dershowitz et al 1998 gylling et al 1999 as a basic building block of the network the single fracture matrix system therefore has been studied over many years liu et al 2022 2018 meng et al 2018 neretnieks 1980 sudicky and frind 1982 tang et al 1981 the solute transport in the fracture can be described by a classical advection dispersion equation berkowitz 2002 while fick s second law is generally applied to account for the effect of molecular diffusion into the matrix and linear sorption on the retardation of solutes neretnieks 1980 tang et al 1981 these two equations are then coupled by a term describing the mass transfer at the fracture matrix interface and solved analytically where analytical solutions are obtained liu et al 2018 meng et al 2018 sudicky and frind 1982 tang et al 1981 the inverse laplace transform approach performs a numerical inverse laplace transform on the solution in the laplace domain and gives the most accurate result liu et al 2022 it can readily be implemented and used in a channel or fracture network system along each of the transport paths the surrounding media having constant geological properties mahmoudzadeh et al 2014 however it cannot be applicable to the cases where geological properties of the channels or surrounding media suddenly change painter et al 2020 by contrast the gaussian quadrature method as discussed in liu et al 2022 tries to solve the analytical solution directly it can be applied to a single fracture matrix system but difficult for a complicated case e g a transport path composed of numerous channels compared with the other two approaches monte carlo methods solve the coupled governing equations in a different way the solute plume in these approaches is considered as numerous particles which move in a manner that closely mimic the underlying physical processes of advection hydrodynamic dispersion and matrix diffusion etc the number of particles arriving at a point of observation downstream the fracture provides then an estimate of the breakthrough curve of the solute in a statistical way it should be noted that any type of boundary condition compared with numerical algorithms such as finite element approach can readily be applied in monte carlo methods meng and pfingsten 2016 for this reason many efforts over the years have been made in the development of monte carlo methods in terms of discretization either in space e g random walk particle tracking rwpt method delay et al 2005 meng and pfingsten 2016 noetinger et al 2016 salamon et al 2006 tompson and gelhar 1990 or in time e g time domain random walk tdrw method banton et al 1997 delay and bodin 2001 painter et al 2008 liu et al 2022 painter et al 2020 yamashita and kimura 1990 to be specific the spatial displacement of a particle in tdrw method is fixed while the travel time of the particle over that distance is either deterministic for purely advective transport case or stochastic if hydrodynamic dispersion is considered banton et al 1997 delay and bodin 2001 painter et al 2008 liu et al 2022 painter et al 2020 yamashita and kimura 1990 therefore a single step of space in the tdrw approach can be made use of to move all particles through the fracture which significantly reduces the computation burden in addition the tdrw algorithm as compared with rwpt method is free of numerical dispersion and capable of accounting for the speciation of the aqueous solution and ionic equilibrium while the increase of computational burden is limited painter et al 2020 roche and dentz 2022 more importantly the algorithm can readily be applied to the cases where the geological properties of the channels or surrounding media suddenly change due to e g glacial rebound and climate change painter et al 2020 owing to these advantages more and more efforts have been made recently to accommodate the tdrw method into different problems the tdrw algorithm became the focus of the study already as far back as the 90s of last century in particular banton et al 1997 proposed a tdrw algorithm for estimating the solute concentration in a fracture only system and later delay and bodin 2001 extended this approach for a fracture matrix system in which both hydrodynamic dispersion and matrix diffusion and sorption were accounted for but treated only in an approximate manner by comparison yamashita and kimura 1990 developed an algorithm that handled dispersion rigorously and additionally considered the contribution of radioactive decay where the solute residence times in the fracture and matrix were estimated from two cumulative distribution functions and used for the approximation of the breakthrough curve this algorithm was then utilized in the channel network model by moreno and neretnieks 1993 painter et al 2008 further extended the algorithm of yamashita and kimura 1990 into a more general case where radioactive decay chain and time dependent flow fields were both accounted for the improved approach was further extended by liu et al 2022 for the case of different first order rate constants in the fracture and matrix additionally liu et al 2022 clearly interpreted the underlying physics of tdrw algorithm and found that the applied cumulative distribution functions were f and g which relate to f and g functions in the derived analytical solution respectively all these efforts have made great contributions in the implementation of the tdrw algorithm and paved the way for further development of the method that may consider heterogeneity in e g rock matrix however we notice that the available algorithms can deal only with the cases of either dirac delta injection or heaviside step injection while no efforts have been made to address the issue of solute transport in fractured porous media with an arbitrary injection boundary e g dirichlet or robin type applied to address this problem three variant tdrw algorithms based on different concepts are developed in this work the first variant algorithm denoted as tdrw g can be directly applied for a certain boundary condition provided that f and g functions in that case are analytically available however the two functions cannot always be derived analytically to overcome this difficulty the second variant algorithm i e tdrw c can be used instead by performing a convolution of the specific boundary condition and the impulse response numerically alternatively the problem can be addressed by additionally introducing the concept of solute injection time the distribution of which is described by a probability density function related to the injection boundary into the estimation of the particle arrival time this algorithm is denoted as tdrw i in this contribution to demonstrate the accuracy and efficacy of the three variants of tdrw algorithms two benchmark cases are considered for general dirichlet and robin injection boundaries respectively it is found that the results from three algorithms all make a good agreement with those of inverse laplace transform method while the accuracy is observed to be closely related to the number of particles applied in the simulation due to the nature of the tdrw algorithm the remainder of this paper is organized as follows in section 2 we will revisit the model of tang et al 1981 or liu et al 2018 with the development of general transient solution for solute transport in a fracture matrix system considering a dirichlet or a robin type boundary condition in the next section we first introduce the tdrw algorithm for dirac delta and heaviside step case briefly including a comparison of two different methods in approximation of the breakthrough curves from the distribution of particle arrival times then the variants of the tdrw algorithm based on the statistical interpretation of the analytical solution are proposed afterwards the focus is however on the accuracy and efficacy of the developed variant algorithms against the numerical solution of the inverse laplace transform method a comparison of these methods is made concluding remarks are then given in section 4 2 mathematical derivation 2 1 conceptual model and equations the focus of this study is to deal with implementation of different boundary conditions in tdrw algorithm the strategy presented is quite general that can be applied to any system for solute transport in fractured porous media for simplicity however we consider only the simple system as that conceptualized by tang et al 1981 and liu et al 2018 as schematically illustrated in fig 1 it is composed of a single fracture represented by two smooth parallel plates with a constant aperture 2 b embedded in a semi infinite and homogeneously porous rock the water velocity in the fracture i e u is assumed to be constant in addition we do not consider the effect of radioactive decay on solute transport for the moment because the inclusion of this mechanism into the model or into the solution is trivial liu et al 2018 meng et al 2018 as detailed in tang et al 1981 and liu et al 2018 the solute transport in such a system can be described by two coupled one dimensional equations of continuity which can be written respectively as 1 r f c f t u c f x d f 2 c f x 2 d p ε p b c p z z b and 2 r p c p t d p 2 c p z 2 along with the initial and boundary conditions for solute transport through the fracture 3 c f x 0 0 4 c f t 0 and in the porous matrix 5 c p x z 0 0 6 c p x b t c f x t 7 c p x t 0 where the subscripts f and p refer to the fracture and pore space of the rock matrix respectively x and z are the coordinates along and perpendicular to the fracture plane respectively t is the time c denotes the concentration of the solute r indicates retardation coefficient d f represents the dispersion coefficient in the fracture d p indicates the pore diffusion coefficient in the homogeneous matrix ε p indicates the porosity for ease of reference a complete list of symbols and dimensions is also given at the beginning of the paper 2 2 dirichlet type boundary at the inlet when the boundary condition at the inlet of the fracture is of the dirichlet type i e if the tracer is injected with a concentration of c i n t i e c f 0 t c i n t an analytical solution is available to describe the breakthrough curves in particular the solute concentration at the outlet of the fracture in the laplace domain i e c f can generally be written as liu et al 2022 2018 tang et al 1981 8 c f c in exp pe 2 exp pe 2 1 4 pe t w φ s r f s where φ denotes the diffusive mass transfer parameter mahmoudzadeh et al 2013 2016 liu et al 2018 meng et al 2018 defined as φ ε p r p d p b p e represents the péclet number p e ux d f t w denotes the water residence time meng et al 2018 t w x u s indicates the laplace transform variable this result suggests that once c i n is known the solute concentration c f x t can readily be obtained by performing inverse laplace transform of eq 8 numerically by use of e g de hoog algorithm de hoog et al 1982 more importantly liu et al 2018 found that the inverse laplace transform of c f can be made in some simple cases to give the analytical solution of c f in the time domain it takes a form of convolution given by 9 c f x t m 0 0 f x τ g t r f τ φ τ d τ where m 0 is a characteristic entity that is determined by the injection condition the unit of which is case dependent in the case of dirac delta injection with c i n t m 0 δ t m 0 is the ratio between the mass injected and the volumetric flow rate through the fracture in the case of heaviside step injection with c i n t c 0 h t m 0 becomes the concentration c 0 for different injection conditions f and g functions may be different but generally describe the statistical properties of solute residence time in a fracture only system with r f 1 and a fracture matrix system with d f 0 respectively liu et al 2022 2018 in both cases of dirac delta injection and heaviside step injection the f function takes the same form given by 10 f x τ 1 2 π d f τ x τ exp x u τ 2 4 d f τ as an impulse response function of a fracture only system in the special case of no surface retardation the f function can also be seen as a probability density function of τ i e the solute advection time in a fracture matrix system liu et al 2022 meng et al 2018 the g function is however boundary dependent in the dirac delta injection it can be regarded as the impulse response function of the fracture matrix system in the case of a plug flow involving advection matrix diffusion and sorption but no hydrodynamic dispersion liu et al 2022 2018 meng et al 2018 11 g t r f τ φ τ φ τ 2 π t r f τ 3 exp φ τ 2 4 t r f τ h t r f τ it can also be seen as a probability density function of t p t r f τ the solute residence time in the rock matrix with a given τ liu et al 2022 meng et al 2018 in the case of heaviside step injection it becomes the cumulative distribution function of t p and is given by 12 g t p φ τ erfc φ τ 2 t p h t p where we use g instead of g to emphasize the cumulative nature of the g function 2 3 robin type boundary at the inlet it should however be noticed that tang et al 1981 and liu et al 2022 2018 considered originally only the case of dirichlet injection boundaries nevertheless the results they obtained are also applicable to the case of robin injection boundaries i e a constant flux injection defined by moreno and rasmuson 1986 13 u c f 0 t d f c f x t x x 0 u c 0 where c 0 is the concentration at the inlet of the fracture in this case eq 8 also holds with the laplace transform of c i n t given by moreno and rasmuson 1986 14 c in 2 1 e c 0 s with e defined as 15 e 1 4 pe t w φ s r f s as a result eq 9 is also valid with m 0 c 0 the f function now becomes 16 f x τ u π d f τ exp x u τ 2 4 d f τ u 2 2 d f exp ux d f erfc x u τ 2 d f τ it also describes the probability density function of τ due to the fact that 0 f x τ d τ 1 the difference between eqs 10 and 16 suggests that the f function is generally boundary dependent as illustrated in fig 2 the f function behaves differently only in small p e cases when p e has been increased to be large enough such as p e 100 the difference between f function in different cases would become marginal this is however not surprising because at large p e values the injection condition of robin type will be reduced to that of dirichlet 2 4 a list of functions to summarize we present in table 1 the probability density functions i e f as well as their cumulative distribution functions i e f for different injection cases by comparison the g function now becomes the cumulative distribution function if it is normalized by c 0 i e g c 0 g as given in eq 12 3 tdrw algorithm tdrw algorithm falls into the category of monte carlo simulations which considers the solute plume as an ensemble of particles bodin et al 2003 delay and bodin 2001 it was developed by way of a statistical interpretation of the fokker plank equation within the framework of lagrange method delay and bodin 2001 or a statistical interpretation of eq 9 that convolves the f and g functions liu et al 2022 however to the best of our knowledge the available tdrw algorithms deal only with the case of either dirac delta injection or heaviside step injection delay and bodin 2001 painter et al 2008 liu et al 2022 in this study we will extend the tdrw algorithm to address the problems involving both dirichlet and robin injection boundaries for solute transport in fractured porous media 3 1 dirac delta and heaviside step injections for the system under consideration the general idea of tdrw algorithms is to inject solute particles at the inlet of the fracture and then determine the travel time of each particle i e t s to reach the outlet of the fracture in the case of both dirac delta and heaviside step injections the solute particles are all injected simultaneously at time of t i n 0 the difference between the results of both cases lies solely in the way of statistical treatment of the t s distributions banton et al 1997 delay and bodin 2001 painter et al 2008 liu et al 2022 painter et al 2020 yamashita and kimura 1990 the core of the tdrw algorithm can be summarized as following 1 denote a unit mass of solute with n particles all particles are injected simultaneously at the time of t i n 0 2 sample a random number z from a uniform distribution between 0 and 1 and then determine solute advection time τ from the f function to give τ f 1 z for each particle 3 sample a random number u from a uniform distribution between 0 and 1 and then determine the particle residence time t p in the matrix from the g function to give t p g 1 u with the use of τ obtained in step 2 4 calculate the particle arrival time t s r f τ t p 5 repeat from step 2 to 4 a total of n times 6 collect the data of t s for all particles and then perform a statistical treatment to obtain the breakthrough curves of interest as can be seen the tdrw algorithms split the travel time t s of each particle into two parts one is the particle residence time in the fracture i e r f τ and the other is the residence time in the matrix t p l painter et al 2008 liu et al 2022 however depending on injection conditions the statistical treatment in step 6 is somewhat different in the case of heaviside step injection we only need to find all particles with t s smaller than a specific observation time t the total number of these particles n s is then determined the result of n s n for a series of observation times gives thus the cumulative distribution function of t s when multiplied with c 0 i e the solute concentration at the inlet of the fracture it becomes the breakthrough curve of interest this algorithm is referred to as tdrw g the suffix of which emphasizes the fact that the g function in eq 9 now has a nature of cumulative distribution function becoming g in our terminology given by eq 12 in addition it should be stressed that the f function used in the calculations in the cases of dirichlet injection boundaries is always given by eq t2 in table 1 in the case of dirac delta injection a simple method is to construct a histogram that group the data of t s into bins it requires predefinition of a series of observation times and then determines the bins accordingly the number of particles falling in each bin i e n i can readily be counted and then the results of n i n over the bins give an approximate representation of the probability density function of t s when multiplied with m 0 i e the ratio between the mass injected and the volumetric flow rate through the fracture it becomes the breakthrough curve of relevant this algorithm is referred to as tdrw h the suffix of which emphasizes the fact that we have used a histogram to approximate the results in the case of dirac delta injection it is easy to be implemented but has many drawbacks inherent in the construction of histograms to overcome this problem liu et al 2022 proposed a more advanced algorithm this algorithm denoted as tdrw k consists of two steps of statistical treatments the first step is to construct the breakthrough curve of heaviside step injection as discussed above the second step is to apply the algorithm of e g the adaptive kernel density estimation botev et al 2010 to differentiate numerically the breakthrough curve of heaviside step injection with respect to time giving the results in the case of dirac delta injection to emphasize the fact that we have adopted a kernel density estimator to approximate the impulse response the name of the algorithm is suffixed by k the advantage of this approach is that it offers a far greater flexibility in modeling a given dataset that represents a probability density function and is not affected by specification bias botev et al 2010 it serves as an advanced filter that polishes the breakthrough curves obtained in the tdrw h algorithm to compare the performance of the tdrw h and tdrw k algorithms a simulation was performed with the parameters given by x 50 m b 100 μm u 0 5 m yr d f 6 6 10 9 m2 s r f 1 d p 9 0 10 11 m2 s ε p 0 005 r p 1 as presented in fig 3 the simulation results of tdrw k agree excellently with the numerical solution obtained by inverse laplace transform of c f given in eq 8 by use of de hoog algorithm de hoog et al 1982 it does not scatter at all around the accurate solution as exhibited by the tdrw h algorithm more importantly it is found that the computation time of the tdrw k algorithm is nearly identical to that of the inverse laplace transform approach with the use of 10000 particles it gives a much more accurate representation of the breakthrough curve and runs much faster than that of the tdrw h algorithm which applies 30000 particles but still yields poorer results the bad performance of tdrw h is caused mainly by the lack of sufficient particles and the proper choice of bin width as shown in fig 3 one issue with the tdrw h algorithm is that the resulting breakthrough curve is not smooth another issue with the tdrw h algorithm is that the choice of bin width and bin transition locations can significantly affect the results the bin width is an intrinsic limit on resolution and the story may change depending on how we select width and boundaries of the bins using wider bins where the density of the underlying data points is low reduces noise due to sampling randomness using narrower bins where the density is high so the signal drowns the noise gives greater precision to the density estimation therefore there is not best number of bins and different bin widths may reveal different features of the resulting breakthrough curves to show the influence of bin width on the results a group of simulations were also made where the bin width is changed from 20 yr 200 yr used in fig 3 to 2000 yr with a fixed number of particles of 30000 as shown in fig 4 the decrease of bin width from 200 yr to 20 yr results in more noises of the breakthrough curve to improve the accuracy of the results one may either increase the number of applied particles or make use of additional filtering method to smooth densities over the bins such as the method of non linear least square regression li et al 2011 meng et al 2020 wolberg 2006 or the levenberg marquardt algorithm within the framework of artificial neural network adeloye and munari 2006 çelik et al 2016 the price we pay is however to increase the computation burden by contrast the use of wider bin width e g 2000 yr reduces noise significantly however it is generally difficult to determine a proper bin width and bin transition locations a priori especially when the number of applied particles is not large enough as a result the tdrw h algorithm is not recommended to be used in practical applications the tdrw k algorithm is certainly superior to the tdrw h algorithm in that it not only gives a smooth breakthrough curve without any noise but also keeps the features of the breakthrough curve unchanged the reason for this is attributed to the fact that the kernel density estimator we applied has local adaptivity resulting in a less sensitivity to outliers and a good performance in the mass botev et al 2010 more importantly the use of tdrw k algorithm significantly reduces the computation burden because it requires considerably less particles to be applied in the calculations on an equal footing with the tdrw h algorithm to further show the influence of the applied particle amount n on the accuracy of the results from tdrw k algorithm a group of simulations were also performed where n varies from 100 1000 10000 used in fig 3 to 20000 as presented in fig 5 the increase of n from 100 to 10000 significantly improves the accuracy of the simulation results and the root mean squared error rmse of the breakthrough curves between two adjacent n values reduce from 7 11 10 8 to 3 53 10 8 the variation of which is obvious i e 3 10 8 by contrast the rmse values calculated from the results of n 20000 and 10000 becomes 3 19 10 8 and the variation of rmse is now insignificant i e 1 10 8 whereas the computation time almost triples this suggests that an increase in the number of particles for improving the accuracy of the results may become unworthy to make a balance between the accuracy and the computation workload one can determine a proper value of n by comparing the variation of rmse of the breakthrough curves at different applied particle amounts once the variation is lower than a specific value e g 1 10 8 the corresponding n can then be regarded as the proper particle amount applied in the algorithm noticeably this method can be extended to other parameters in simulations e g the number of subdivisions of c i n t which will be introduced in next section 3 2 general dirichlet injection boundaries in more general cases of dirichlet boundary conditions c i n t can be an arbitrarily shaped function with a limited duration of injection to address these cases two algorithms of tdrw can be applied the first one is based on the idea that meng et al 2018 17 c f x t 1 m 0 0 c in t ξ c f x ξ δ d ξ where ξ is an integral variable and c f δ is an impulse response of the fracture matrix system under consideration this formula implies that one only needs to first evaluate the impulse response accurately by applying the tdrw k algorithm and then performs a convolution of c i n t and c f x t δ numerically this algorithm is referred to as tdrw c the suffix of which emphasizes the fact that the convolution in eq 17 is the core of the approach it is therefore a combination of tdrw k algorithm and a quadrature approach such as adaptive gauss kronrod method kronrod 1965 the second algorithm is based on the recognition that the difference between the case of general dirichlet injection and the case of dirac delta injection lies only in the way of how to inject solute particles as discussed above all particles are injected simultaneously in the latter case in the former case however the injection of particles should follow the probability density function p i n t that is congruent with the c i n t function given by 18 p in t c in t 0 c in t d t this algorithm is referred to as tdrw i the suffix of which implies that the distribution of the solute injection time t i n is now described by p i n t it differs from the tdrw k algorithm mainly in the first step discussed in section 3 1 which should be modified as 1 denote a unit mass of solute with n particles the injection time of each particle t i n should follow the probability density function of p i n t this can be done by sampling a random number y from a uniform distribution between 0 and 1 for each particle and then determine the solute injection time t i n from the cumulative distribution function p i n t that complies with p i n t to give t i n p i n 1 y the arrival time for each of the particles should now be calculated as t s t i n r f τ t p as a result the tdrw i algorithm is essentially identical to the tdrw k algorithm except that t i n 0 and that m 0 0 c i n t d t to explore the different behaviors of tdrw c and tdrw i algorithms we now consider a case where c i n t is given by 19 c in t c 0 sin ω t h t h t δ t where ω is a constant with a unit of reciprocal of time the parameters used in the simulations are x 200 m b 100 μm u 2 m yr d f 6 6 10 13 m2 s r f 5 d p 9 0 10 11 m2 s ε p 0 005 r p 10 c 0 2 mol m3 ω 1 5 π yr 1 and the solute injection duration δ t is 5 yr as shown in fig 6 the results obtained by tdrw i make an excellent agreement with the breakthrough curve of the inverse laplace transform solution and so does the results of tdrw c the computation time for tdrw i algorithm is nearly identical to that of the inverse laplace transform approach but much shorter than that of tdrw c algorithm the longer time of tdrw c algorithm is caused mainly by the requirement of an additional evaluation of the integral in eq 17 even though the amounts of applied particles in both tdrw c and tdrw i algorithms are identical to further compare the accuracy of the developed tdrw algorithms we considered a more complicated case involving dirichlet injection boundary defined by 20 c in t c 1 sin ω t h t h t δ t 1 c 2 h t δ t 2 h t δ t 2 δ t 3 where c 1 and c 2 are two constants with the unit of concentration δ t 1 δ t 2 and δ t 3 are three constants with the unit of time this simulation is performed with the condition x 200 m b 100 μm u 2 m yr d f 6 6 10 9 m2 s r f 1 d p 3 7 10 12 m2 s ε p 0 005 r p 1 c 1 10 mol m3 c 2 20 mol m3 ω 1 4000 yr 1 δ t 1 4000 π yr δ t 2 3500 π yr and δ t 3 10000 yr as can be seen in fig 7 the agreement between the results of the three approaches is still excellent the breakthrough curve consists of two separate sections and the shape of each section resembles the corresponding part of the injection curve additionally we found that each section has its individual peak value while a translation of the peak time of the injection curve can be observed for those of the breakthrough curve this time delay results mainly from the effect of advection while the influence of matrix diffusion on solute transport in this case is insignificant however we should note that the applied effective diffusion coefficient is 1 8 10 14 m2 s i e the value for the intact wall rock in mahmoudzadeh et al 2014 and this coefficient is smaller than those of the altered rock cataclasite to further investigate the influence of matrix diffusion on the behavior of the breakthrough curve we performed a new simulation where the effective diffusion coefficient identical to that used in tang et al 1981 becomes 4 5 10 13 m2 s i e d p 9 0 10 11 m2 s as illustrated in fig 7 the results calculated by the use of tdrw c and i algorithms also make an excellent agreement with the breakthrough curve of inverse laplace transform solution nevertheless the new breakthrough curve unlike that of the lower d p case does not resemble the injection curve at all it has only one peak the value of which becomes much lower while a larger translation of the peak time can also be found this difference in performance as discussed in meng et al 2018 is mainly caused by the increase of pore diffusion coefficient or equivalently the larger diffusive mass transfer parameter value and a higher value indicates a more important effect of matrix diffusion in retarding the solute transport in other words the change of matrix properties will significantly influence the behavior of the breakthrough curve e g peak value and time liu et al 2018 meng et al 2018 in addition we found that the computation time of tdrw i is also nearly identical to that of the inverse laplace transform solution but much shorter than that of the tdrw c algorithm for this simulation case the disadvantage of tdrw c originates actually from the fact that we have applied the adaptive gauss kronrod quadrature approach kronrod 1965 to evaluate the convolution in eq 17 it requires the use of more gauss points to obtain more accurate results the number of which increases with the time t and therefore becomes time consuming in general however it is difficult to justify which of the two tdrw algorithms has advantage over the other one in some cases the tdrw i algorithm may require a smaller number of particles than the number of c i n t subdivisions of the tdrw c algorithm and therefore reduces the computation time to a noticeable extent on an equal footing of accuracy in other cases the opposite is true where the tdrw c algorithm is more advantageous we recommended however the application of tdrw c algorithm in the first place because it is easy to be implemented and works well in most cases involving dirichlet injection boundaries with the application of either tdrw c or tdrw i algorithm one can also estimate the distribution profile e g d p 9 0 10 11 m2 s of the solute along the fracture at a specified time of observation e g t 3 10 4 yr towards that end a simple and quick way is to apply a linear interpolation method based on the breakthrough curves obtained at a series of points downstream the fracture to illustrate the robustness of this methodology we show in fig 8 the simulation results for the same case as in fig 7 clearly the application of both tdrw c and tdrw i algorithms yields equally well and satisfactory results compared to the solution obtained from the inverse laplace transform method the difference in the computation time is the main character that may be used to judge the pros and cons of the algorithm as discussed above the number of particles in the tdrw i algorithm is equivalent to the number of subdivisions of c i n t in the tdrw c algorithm times the number of particles in the tdrw k algorithm therefore both tdrw c and tdrw i algorithms may result in the same accuracy of the simulations if their workloads are identical this implies that a tradeoff has to be made between the accuracy of the results and the workload of computations for both algorithms by adjusting the number of either applied particles or the subdivisions of c i n t as performed in tdrw k algorithm however due to its easy implementation the tdrw c algorithm is more favorable in practical applications 3 3 robin injection boundaries as discussed by moreno and rasmuson 1986 the robin injection boundary or the constant flux boundary is commonly used in the simulations of tracer tests in situ to investigate solute transport in a fractured porous rock in this case the tdrw g algorithm is still applicable with however the f function given by eq t4 in table 1 the reason for this is because the robin injection boundaries are similar to heaviside step injection boundaries in that the solute particles are constantly injected into the system as a result the g function in eq 9 also has a nature of cumulative distribution function as required by the tdrw g algorithm alternatively one can also apply both tdrw c and tdrw i algorithms in the simulations if the injection boundary of the problem can be transformed to the type of dirichlet this requires us to perform an inverse laplace transform on eq 14 with the use of de hoog algorithm de hoog et al 1982 the result gives c i n t numerically as a function of time that covers in principle from 0 to infinity since only the early part of the c i n t curve is relevant for the simulations of both tdrw c and tdrw i algorithms a truncation of the curve must be performed to make c i n t limited in the duration of solute injection to demonstrate the applicability of these three tdrw algorithms a simulation is performed with the condition x 100 m b 100 μm u 40 m yr d f 6 6 10 8 m2 s r f 1 d p 9 0 10 11 m2 s ε p 0 005 r p 5 c 0 100 mol m3 as can be seen in fig 9 the agreements between the results obtained from the three variants of the tdrw algorithms and the inverse laplace transform solution are all excellent nevertheless the cumulative nature of the breakthrough curve often requires much less particles to be used in the tdrw g algorithm it can be applied only to cases of constant injection where the f and g functions are analytically available by comparison both tdrw c and tdrw i algorithms have a broader applicability in that they can deal with the problems involving not only dirichlet but also robin injection boundaries the implicit use of the tdrw k method in these two algorithms requires however much more particles to reduce noise of the breakthrough curves as a result these two algorithms bear the burden of an enormous computational workload compared to the tdrw g algorithm in addition it should be stressed that when applying both tdrw c and tdrw i algorithms to deal with the robin injection boundaries the improper truncation of the c i n t curve may influence the accuracy of the results significantly the longer the duration of the truncated c i n t curve the more the particles would be required making the breakthrough curve more accurate otherwise the simulations would have a poor accuracy of the results even though less particles can be applied to further show the applicability tdrw c and tdrw i algorithms we can consider a more complicated injection boundary of the robin type e g eq 21 even though it might be impossible in practice 21 u c f 0 t d f c f x t x x 0 u c 0 exp ω t for the new boundary condition c 0 as shown in eq 21 becomes time dependent nevertheless eq 8 still holds and the laplace transform of c i n t similar to that of the constant flux injection can be given by 22 c in 2 1 e c 0 s ω the new simulation based on eq 22 is performed and the input parameters are identical to those of fig 9 with ω equal to 6 9 10 6 yr 1 as can be seen in fig 10 the result of tdrw c algorithm makes an excellent agreement with that of the inverse laplace transform solution by contrast the performance of the curve of tdrw i algorithm is not as good as those of other two approaches nevertheless a larger number of applied particles as discussed will apparently increase the accuracy of the result while a longer computation can be expected 3 4 a list of tdrw algorithms to summarize we highlight in table 2 the applicability of different tdrw algorithms developed in this study together with their interrelationships clearly the tdrw g algorithm is the core of all other variants of tdrw algorithms based on the results of tdrw g the tdrw k algorithm performs an additional step of differentiation to obtain the impulse response this becomes the central part of both tdrw c and tdrw i algorithms the tdrw c algorithm further performs a convolution of c i n t and the impulse response c f x t δ to obtain the breakthrough curve of interest the tdrw i algorithm can be regarded as an extension of the tdrw k algorithm where t i n 0 for each of the particles and the t i n distribution should be described by p i n t according to eq 18 4 conclusion in this work three variants of the tdrw algorithms i e tdrw g tdrw c and tdrw i are developed to address the problems of solute transport in fractured porous media where different boundary conditions e g dirichlet and robin types are applied the tdrw g algorithm can always be used once the f and g functions are analytically available considering that this is not the case we may on one hand perform a convolution of c i n t and the impulse response of the fracture matrix system numerically i e tdrw c algorithm on the other hand one can make use of the tdrw i algorithm in which the particles unlike tdrw k algorithm are assumed to be injected at different times i e t i n to demonstrate the accuracy and efficacy of the three variants of tdrw algorithms two benchmark cases are considered for general dirichlet and robin injection boundaries respectively it is found that the results from the three algorithms all make an excellent agreement with those obtained from the inverse laplace transform solution method nevertheless more particles are applied in tdrw c and tdrw i algorithms to reduce noise of the breakthrough curves by comparison the cumulative nature of the breakthrough curve often requires much less particles in the tdrw g algorithm we note additionally that the developed tdrw algorithm can also be applied in a more complicated system e g a transport path with the rock matrix composed of several geological layers with different properties mahmoudzadeh et al 2013 or account for the influence of radioactive decay chain mahmoudzadeh et al 2014 shahkarami et al 2015 these will be made in the near future credit authorship contribution statement shuo meng conceptualization data curation formal analysis methodology software validation writing original draft writing review editing longcheng liu conceptualization formal analysis funding acquisition methodology software supervision validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the encouragement and financial support of university of south china the first author also acknowledges the financial support of the excellent youth project of scientific research fund of hunan provincial education department no 22b0405 and the scientific research foundation of university of south china no 210xqd006 the second author gratefully acknowledges the encouragement and financial support of beijing research institute of chemical engineering and metallurgy 
2255,in this work three variant time domain random walk tdrw algorithms were developed for the problem of solute transport in a single fracture matrix system where an arbitrary inlet boundary condition can be applied one approach performs an additional evaluation of integral in terms of injection boundary and the solution to a dirac delta case one method makes use of two functions dependent on specific boundary conditions to estimate the particle arrival time the other additionally introduces the concept of solute injection time resulting from the injection boundary into the calculation of particle arrival time to validate the developed variant algorithms two benchmark cases are considered with respect to a general dirichlet injection mode and a robin injection boundary respectively the results from three approaches all make a good agreement with those of inverse laplace transform method however the monte carlo nature of the tdrw algorithm implies that the accuracy of the computational result is highly dependent on the number of particles applied in the simulation keywords variant time domain random walk algorithms boundary conditions statistical interpretation convolution cumulative distribution function data availability data will be made available on request nomenclature d f dispersion coefficient in the fracture l 2 t 1 d p pore diffusion coefficient in the matrix l 2 t 1 e defined function l 1 f cumulative distribution function of solute advection time p i n cumulative distribution function of solute injection time g cumulative distribution function of the solute residence time in the porous rock matrix h heaviside step function n total number of particles injected in the system n i the number of particles falling in each bin n s total number of particles for collected at a specific time p i n cumulative distribution function of solute injection time p e péclet number r f surface retardation factor in the fracture r p retardation factor in the matrix u random number y random number z random number b half aperture l c 0 the concentration at the inlet of the fracture m l 3 c 1 c 2 constants m l 3 c f solute concentration in the fracture m l 3 c f δ solute concentration in the fracture for a dirac delta boundary condition m l 3 c f solute concentration in the fracture in the laplace domain m t l 3 c i n injected solute concentration at the inlet of the fracture m l 3 c i n injected solute concentration at the inlet of the fracture in the laplace domain m t l 3 f impulse response function in a fracture only system involving no surface retardation or probability density function of the solute advection time t 1 g impulse response function of the fracture matrix system or probability density function of the solute residence time in the porous rock matrix t 1 p i n probability density function of solute injection time t 1 s laplace transform variable t 1 t time t t i n solute injection time t t p solute residence time in the porous matrix t t s particle arrival time t t w water residence time t δ t 1 δ t 2 δ t 3 constants t u flow velocity l t 1 x distance along the flow direction from the origin of fracture l z distance into the rock matrix l δ dirac delta function t 1 ε p porosity ξ integral variable t τ solute advection time t ϕ normalized time ω constant t 1 φ diffusive mass transfer parameter t 1 2 1 introduction numerous computation tools based on either channel network model cnm gylling et al 1999 selroos et al 2002 shahkarami et al 2018 2016 or discrete fracture network dfn model alghalandis 2017 dershowitz et al 1998 hyman et al 2015 junkin et al 2018 have been developed to aid the safety and performance assessment pa of deep geological repositories for spent nuclear fuel both models aim to address the problem of water flow and nuclide transport in fractured crystalline rocks under the conditions of repositories and conceptualize the crystalline rocks as a network of fractures dershowitz et al 1998 gylling et al 1999 as a basic building block of the network the single fracture matrix system therefore has been studied over many years liu et al 2022 2018 meng et al 2018 neretnieks 1980 sudicky and frind 1982 tang et al 1981 the solute transport in the fracture can be described by a classical advection dispersion equation berkowitz 2002 while fick s second law is generally applied to account for the effect of molecular diffusion into the matrix and linear sorption on the retardation of solutes neretnieks 1980 tang et al 1981 these two equations are then coupled by a term describing the mass transfer at the fracture matrix interface and solved analytically where analytical solutions are obtained liu et al 2018 meng et al 2018 sudicky and frind 1982 tang et al 1981 the inverse laplace transform approach performs a numerical inverse laplace transform on the solution in the laplace domain and gives the most accurate result liu et al 2022 it can readily be implemented and used in a channel or fracture network system along each of the transport paths the surrounding media having constant geological properties mahmoudzadeh et al 2014 however it cannot be applicable to the cases where geological properties of the channels or surrounding media suddenly change painter et al 2020 by contrast the gaussian quadrature method as discussed in liu et al 2022 tries to solve the analytical solution directly it can be applied to a single fracture matrix system but difficult for a complicated case e g a transport path composed of numerous channels compared with the other two approaches monte carlo methods solve the coupled governing equations in a different way the solute plume in these approaches is considered as numerous particles which move in a manner that closely mimic the underlying physical processes of advection hydrodynamic dispersion and matrix diffusion etc the number of particles arriving at a point of observation downstream the fracture provides then an estimate of the breakthrough curve of the solute in a statistical way it should be noted that any type of boundary condition compared with numerical algorithms such as finite element approach can readily be applied in monte carlo methods meng and pfingsten 2016 for this reason many efforts over the years have been made in the development of monte carlo methods in terms of discretization either in space e g random walk particle tracking rwpt method delay et al 2005 meng and pfingsten 2016 noetinger et al 2016 salamon et al 2006 tompson and gelhar 1990 or in time e g time domain random walk tdrw method banton et al 1997 delay and bodin 2001 painter et al 2008 liu et al 2022 painter et al 2020 yamashita and kimura 1990 to be specific the spatial displacement of a particle in tdrw method is fixed while the travel time of the particle over that distance is either deterministic for purely advective transport case or stochastic if hydrodynamic dispersion is considered banton et al 1997 delay and bodin 2001 painter et al 2008 liu et al 2022 painter et al 2020 yamashita and kimura 1990 therefore a single step of space in the tdrw approach can be made use of to move all particles through the fracture which significantly reduces the computation burden in addition the tdrw algorithm as compared with rwpt method is free of numerical dispersion and capable of accounting for the speciation of the aqueous solution and ionic equilibrium while the increase of computational burden is limited painter et al 2020 roche and dentz 2022 more importantly the algorithm can readily be applied to the cases where the geological properties of the channels or surrounding media suddenly change due to e g glacial rebound and climate change painter et al 2020 owing to these advantages more and more efforts have been made recently to accommodate the tdrw method into different problems the tdrw algorithm became the focus of the study already as far back as the 90s of last century in particular banton et al 1997 proposed a tdrw algorithm for estimating the solute concentration in a fracture only system and later delay and bodin 2001 extended this approach for a fracture matrix system in which both hydrodynamic dispersion and matrix diffusion and sorption were accounted for but treated only in an approximate manner by comparison yamashita and kimura 1990 developed an algorithm that handled dispersion rigorously and additionally considered the contribution of radioactive decay where the solute residence times in the fracture and matrix were estimated from two cumulative distribution functions and used for the approximation of the breakthrough curve this algorithm was then utilized in the channel network model by moreno and neretnieks 1993 painter et al 2008 further extended the algorithm of yamashita and kimura 1990 into a more general case where radioactive decay chain and time dependent flow fields were both accounted for the improved approach was further extended by liu et al 2022 for the case of different first order rate constants in the fracture and matrix additionally liu et al 2022 clearly interpreted the underlying physics of tdrw algorithm and found that the applied cumulative distribution functions were f and g which relate to f and g functions in the derived analytical solution respectively all these efforts have made great contributions in the implementation of the tdrw algorithm and paved the way for further development of the method that may consider heterogeneity in e g rock matrix however we notice that the available algorithms can deal only with the cases of either dirac delta injection or heaviside step injection while no efforts have been made to address the issue of solute transport in fractured porous media with an arbitrary injection boundary e g dirichlet or robin type applied to address this problem three variant tdrw algorithms based on different concepts are developed in this work the first variant algorithm denoted as tdrw g can be directly applied for a certain boundary condition provided that f and g functions in that case are analytically available however the two functions cannot always be derived analytically to overcome this difficulty the second variant algorithm i e tdrw c can be used instead by performing a convolution of the specific boundary condition and the impulse response numerically alternatively the problem can be addressed by additionally introducing the concept of solute injection time the distribution of which is described by a probability density function related to the injection boundary into the estimation of the particle arrival time this algorithm is denoted as tdrw i in this contribution to demonstrate the accuracy and efficacy of the three variants of tdrw algorithms two benchmark cases are considered for general dirichlet and robin injection boundaries respectively it is found that the results from three algorithms all make a good agreement with those of inverse laplace transform method while the accuracy is observed to be closely related to the number of particles applied in the simulation due to the nature of the tdrw algorithm the remainder of this paper is organized as follows in section 2 we will revisit the model of tang et al 1981 or liu et al 2018 with the development of general transient solution for solute transport in a fracture matrix system considering a dirichlet or a robin type boundary condition in the next section we first introduce the tdrw algorithm for dirac delta and heaviside step case briefly including a comparison of two different methods in approximation of the breakthrough curves from the distribution of particle arrival times then the variants of the tdrw algorithm based on the statistical interpretation of the analytical solution are proposed afterwards the focus is however on the accuracy and efficacy of the developed variant algorithms against the numerical solution of the inverse laplace transform method a comparison of these methods is made concluding remarks are then given in section 4 2 mathematical derivation 2 1 conceptual model and equations the focus of this study is to deal with implementation of different boundary conditions in tdrw algorithm the strategy presented is quite general that can be applied to any system for solute transport in fractured porous media for simplicity however we consider only the simple system as that conceptualized by tang et al 1981 and liu et al 2018 as schematically illustrated in fig 1 it is composed of a single fracture represented by two smooth parallel plates with a constant aperture 2 b embedded in a semi infinite and homogeneously porous rock the water velocity in the fracture i e u is assumed to be constant in addition we do not consider the effect of radioactive decay on solute transport for the moment because the inclusion of this mechanism into the model or into the solution is trivial liu et al 2018 meng et al 2018 as detailed in tang et al 1981 and liu et al 2018 the solute transport in such a system can be described by two coupled one dimensional equations of continuity which can be written respectively as 1 r f c f t u c f x d f 2 c f x 2 d p ε p b c p z z b and 2 r p c p t d p 2 c p z 2 along with the initial and boundary conditions for solute transport through the fracture 3 c f x 0 0 4 c f t 0 and in the porous matrix 5 c p x z 0 0 6 c p x b t c f x t 7 c p x t 0 where the subscripts f and p refer to the fracture and pore space of the rock matrix respectively x and z are the coordinates along and perpendicular to the fracture plane respectively t is the time c denotes the concentration of the solute r indicates retardation coefficient d f represents the dispersion coefficient in the fracture d p indicates the pore diffusion coefficient in the homogeneous matrix ε p indicates the porosity for ease of reference a complete list of symbols and dimensions is also given at the beginning of the paper 2 2 dirichlet type boundary at the inlet when the boundary condition at the inlet of the fracture is of the dirichlet type i e if the tracer is injected with a concentration of c i n t i e c f 0 t c i n t an analytical solution is available to describe the breakthrough curves in particular the solute concentration at the outlet of the fracture in the laplace domain i e c f can generally be written as liu et al 2022 2018 tang et al 1981 8 c f c in exp pe 2 exp pe 2 1 4 pe t w φ s r f s where φ denotes the diffusive mass transfer parameter mahmoudzadeh et al 2013 2016 liu et al 2018 meng et al 2018 defined as φ ε p r p d p b p e represents the péclet number p e ux d f t w denotes the water residence time meng et al 2018 t w x u s indicates the laplace transform variable this result suggests that once c i n is known the solute concentration c f x t can readily be obtained by performing inverse laplace transform of eq 8 numerically by use of e g de hoog algorithm de hoog et al 1982 more importantly liu et al 2018 found that the inverse laplace transform of c f can be made in some simple cases to give the analytical solution of c f in the time domain it takes a form of convolution given by 9 c f x t m 0 0 f x τ g t r f τ φ τ d τ where m 0 is a characteristic entity that is determined by the injection condition the unit of which is case dependent in the case of dirac delta injection with c i n t m 0 δ t m 0 is the ratio between the mass injected and the volumetric flow rate through the fracture in the case of heaviside step injection with c i n t c 0 h t m 0 becomes the concentration c 0 for different injection conditions f and g functions may be different but generally describe the statistical properties of solute residence time in a fracture only system with r f 1 and a fracture matrix system with d f 0 respectively liu et al 2022 2018 in both cases of dirac delta injection and heaviside step injection the f function takes the same form given by 10 f x τ 1 2 π d f τ x τ exp x u τ 2 4 d f τ as an impulse response function of a fracture only system in the special case of no surface retardation the f function can also be seen as a probability density function of τ i e the solute advection time in a fracture matrix system liu et al 2022 meng et al 2018 the g function is however boundary dependent in the dirac delta injection it can be regarded as the impulse response function of the fracture matrix system in the case of a plug flow involving advection matrix diffusion and sorption but no hydrodynamic dispersion liu et al 2022 2018 meng et al 2018 11 g t r f τ φ τ φ τ 2 π t r f τ 3 exp φ τ 2 4 t r f τ h t r f τ it can also be seen as a probability density function of t p t r f τ the solute residence time in the rock matrix with a given τ liu et al 2022 meng et al 2018 in the case of heaviside step injection it becomes the cumulative distribution function of t p and is given by 12 g t p φ τ erfc φ τ 2 t p h t p where we use g instead of g to emphasize the cumulative nature of the g function 2 3 robin type boundary at the inlet it should however be noticed that tang et al 1981 and liu et al 2022 2018 considered originally only the case of dirichlet injection boundaries nevertheless the results they obtained are also applicable to the case of robin injection boundaries i e a constant flux injection defined by moreno and rasmuson 1986 13 u c f 0 t d f c f x t x x 0 u c 0 where c 0 is the concentration at the inlet of the fracture in this case eq 8 also holds with the laplace transform of c i n t given by moreno and rasmuson 1986 14 c in 2 1 e c 0 s with e defined as 15 e 1 4 pe t w φ s r f s as a result eq 9 is also valid with m 0 c 0 the f function now becomes 16 f x τ u π d f τ exp x u τ 2 4 d f τ u 2 2 d f exp ux d f erfc x u τ 2 d f τ it also describes the probability density function of τ due to the fact that 0 f x τ d τ 1 the difference between eqs 10 and 16 suggests that the f function is generally boundary dependent as illustrated in fig 2 the f function behaves differently only in small p e cases when p e has been increased to be large enough such as p e 100 the difference between f function in different cases would become marginal this is however not surprising because at large p e values the injection condition of robin type will be reduced to that of dirichlet 2 4 a list of functions to summarize we present in table 1 the probability density functions i e f as well as their cumulative distribution functions i e f for different injection cases by comparison the g function now becomes the cumulative distribution function if it is normalized by c 0 i e g c 0 g as given in eq 12 3 tdrw algorithm tdrw algorithm falls into the category of monte carlo simulations which considers the solute plume as an ensemble of particles bodin et al 2003 delay and bodin 2001 it was developed by way of a statistical interpretation of the fokker plank equation within the framework of lagrange method delay and bodin 2001 or a statistical interpretation of eq 9 that convolves the f and g functions liu et al 2022 however to the best of our knowledge the available tdrw algorithms deal only with the case of either dirac delta injection or heaviside step injection delay and bodin 2001 painter et al 2008 liu et al 2022 in this study we will extend the tdrw algorithm to address the problems involving both dirichlet and robin injection boundaries for solute transport in fractured porous media 3 1 dirac delta and heaviside step injections for the system under consideration the general idea of tdrw algorithms is to inject solute particles at the inlet of the fracture and then determine the travel time of each particle i e t s to reach the outlet of the fracture in the case of both dirac delta and heaviside step injections the solute particles are all injected simultaneously at time of t i n 0 the difference between the results of both cases lies solely in the way of statistical treatment of the t s distributions banton et al 1997 delay and bodin 2001 painter et al 2008 liu et al 2022 painter et al 2020 yamashita and kimura 1990 the core of the tdrw algorithm can be summarized as following 1 denote a unit mass of solute with n particles all particles are injected simultaneously at the time of t i n 0 2 sample a random number z from a uniform distribution between 0 and 1 and then determine solute advection time τ from the f function to give τ f 1 z for each particle 3 sample a random number u from a uniform distribution between 0 and 1 and then determine the particle residence time t p in the matrix from the g function to give t p g 1 u with the use of τ obtained in step 2 4 calculate the particle arrival time t s r f τ t p 5 repeat from step 2 to 4 a total of n times 6 collect the data of t s for all particles and then perform a statistical treatment to obtain the breakthrough curves of interest as can be seen the tdrw algorithms split the travel time t s of each particle into two parts one is the particle residence time in the fracture i e r f τ and the other is the residence time in the matrix t p l painter et al 2008 liu et al 2022 however depending on injection conditions the statistical treatment in step 6 is somewhat different in the case of heaviside step injection we only need to find all particles with t s smaller than a specific observation time t the total number of these particles n s is then determined the result of n s n for a series of observation times gives thus the cumulative distribution function of t s when multiplied with c 0 i e the solute concentration at the inlet of the fracture it becomes the breakthrough curve of interest this algorithm is referred to as tdrw g the suffix of which emphasizes the fact that the g function in eq 9 now has a nature of cumulative distribution function becoming g in our terminology given by eq 12 in addition it should be stressed that the f function used in the calculations in the cases of dirichlet injection boundaries is always given by eq t2 in table 1 in the case of dirac delta injection a simple method is to construct a histogram that group the data of t s into bins it requires predefinition of a series of observation times and then determines the bins accordingly the number of particles falling in each bin i e n i can readily be counted and then the results of n i n over the bins give an approximate representation of the probability density function of t s when multiplied with m 0 i e the ratio between the mass injected and the volumetric flow rate through the fracture it becomes the breakthrough curve of relevant this algorithm is referred to as tdrw h the suffix of which emphasizes the fact that we have used a histogram to approximate the results in the case of dirac delta injection it is easy to be implemented but has many drawbacks inherent in the construction of histograms to overcome this problem liu et al 2022 proposed a more advanced algorithm this algorithm denoted as tdrw k consists of two steps of statistical treatments the first step is to construct the breakthrough curve of heaviside step injection as discussed above the second step is to apply the algorithm of e g the adaptive kernel density estimation botev et al 2010 to differentiate numerically the breakthrough curve of heaviside step injection with respect to time giving the results in the case of dirac delta injection to emphasize the fact that we have adopted a kernel density estimator to approximate the impulse response the name of the algorithm is suffixed by k the advantage of this approach is that it offers a far greater flexibility in modeling a given dataset that represents a probability density function and is not affected by specification bias botev et al 2010 it serves as an advanced filter that polishes the breakthrough curves obtained in the tdrw h algorithm to compare the performance of the tdrw h and tdrw k algorithms a simulation was performed with the parameters given by x 50 m b 100 μm u 0 5 m yr d f 6 6 10 9 m2 s r f 1 d p 9 0 10 11 m2 s ε p 0 005 r p 1 as presented in fig 3 the simulation results of tdrw k agree excellently with the numerical solution obtained by inverse laplace transform of c f given in eq 8 by use of de hoog algorithm de hoog et al 1982 it does not scatter at all around the accurate solution as exhibited by the tdrw h algorithm more importantly it is found that the computation time of the tdrw k algorithm is nearly identical to that of the inverse laplace transform approach with the use of 10000 particles it gives a much more accurate representation of the breakthrough curve and runs much faster than that of the tdrw h algorithm which applies 30000 particles but still yields poorer results the bad performance of tdrw h is caused mainly by the lack of sufficient particles and the proper choice of bin width as shown in fig 3 one issue with the tdrw h algorithm is that the resulting breakthrough curve is not smooth another issue with the tdrw h algorithm is that the choice of bin width and bin transition locations can significantly affect the results the bin width is an intrinsic limit on resolution and the story may change depending on how we select width and boundaries of the bins using wider bins where the density of the underlying data points is low reduces noise due to sampling randomness using narrower bins where the density is high so the signal drowns the noise gives greater precision to the density estimation therefore there is not best number of bins and different bin widths may reveal different features of the resulting breakthrough curves to show the influence of bin width on the results a group of simulations were also made where the bin width is changed from 20 yr 200 yr used in fig 3 to 2000 yr with a fixed number of particles of 30000 as shown in fig 4 the decrease of bin width from 200 yr to 20 yr results in more noises of the breakthrough curve to improve the accuracy of the results one may either increase the number of applied particles or make use of additional filtering method to smooth densities over the bins such as the method of non linear least square regression li et al 2011 meng et al 2020 wolberg 2006 or the levenberg marquardt algorithm within the framework of artificial neural network adeloye and munari 2006 çelik et al 2016 the price we pay is however to increase the computation burden by contrast the use of wider bin width e g 2000 yr reduces noise significantly however it is generally difficult to determine a proper bin width and bin transition locations a priori especially when the number of applied particles is not large enough as a result the tdrw h algorithm is not recommended to be used in practical applications the tdrw k algorithm is certainly superior to the tdrw h algorithm in that it not only gives a smooth breakthrough curve without any noise but also keeps the features of the breakthrough curve unchanged the reason for this is attributed to the fact that the kernel density estimator we applied has local adaptivity resulting in a less sensitivity to outliers and a good performance in the mass botev et al 2010 more importantly the use of tdrw k algorithm significantly reduces the computation burden because it requires considerably less particles to be applied in the calculations on an equal footing with the tdrw h algorithm to further show the influence of the applied particle amount n on the accuracy of the results from tdrw k algorithm a group of simulations were also performed where n varies from 100 1000 10000 used in fig 3 to 20000 as presented in fig 5 the increase of n from 100 to 10000 significantly improves the accuracy of the simulation results and the root mean squared error rmse of the breakthrough curves between two adjacent n values reduce from 7 11 10 8 to 3 53 10 8 the variation of which is obvious i e 3 10 8 by contrast the rmse values calculated from the results of n 20000 and 10000 becomes 3 19 10 8 and the variation of rmse is now insignificant i e 1 10 8 whereas the computation time almost triples this suggests that an increase in the number of particles for improving the accuracy of the results may become unworthy to make a balance between the accuracy and the computation workload one can determine a proper value of n by comparing the variation of rmse of the breakthrough curves at different applied particle amounts once the variation is lower than a specific value e g 1 10 8 the corresponding n can then be regarded as the proper particle amount applied in the algorithm noticeably this method can be extended to other parameters in simulations e g the number of subdivisions of c i n t which will be introduced in next section 3 2 general dirichlet injection boundaries in more general cases of dirichlet boundary conditions c i n t can be an arbitrarily shaped function with a limited duration of injection to address these cases two algorithms of tdrw can be applied the first one is based on the idea that meng et al 2018 17 c f x t 1 m 0 0 c in t ξ c f x ξ δ d ξ where ξ is an integral variable and c f δ is an impulse response of the fracture matrix system under consideration this formula implies that one only needs to first evaluate the impulse response accurately by applying the tdrw k algorithm and then performs a convolution of c i n t and c f x t δ numerically this algorithm is referred to as tdrw c the suffix of which emphasizes the fact that the convolution in eq 17 is the core of the approach it is therefore a combination of tdrw k algorithm and a quadrature approach such as adaptive gauss kronrod method kronrod 1965 the second algorithm is based on the recognition that the difference between the case of general dirichlet injection and the case of dirac delta injection lies only in the way of how to inject solute particles as discussed above all particles are injected simultaneously in the latter case in the former case however the injection of particles should follow the probability density function p i n t that is congruent with the c i n t function given by 18 p in t c in t 0 c in t d t this algorithm is referred to as tdrw i the suffix of which implies that the distribution of the solute injection time t i n is now described by p i n t it differs from the tdrw k algorithm mainly in the first step discussed in section 3 1 which should be modified as 1 denote a unit mass of solute with n particles the injection time of each particle t i n should follow the probability density function of p i n t this can be done by sampling a random number y from a uniform distribution between 0 and 1 for each particle and then determine the solute injection time t i n from the cumulative distribution function p i n t that complies with p i n t to give t i n p i n 1 y the arrival time for each of the particles should now be calculated as t s t i n r f τ t p as a result the tdrw i algorithm is essentially identical to the tdrw k algorithm except that t i n 0 and that m 0 0 c i n t d t to explore the different behaviors of tdrw c and tdrw i algorithms we now consider a case where c i n t is given by 19 c in t c 0 sin ω t h t h t δ t where ω is a constant with a unit of reciprocal of time the parameters used in the simulations are x 200 m b 100 μm u 2 m yr d f 6 6 10 13 m2 s r f 5 d p 9 0 10 11 m2 s ε p 0 005 r p 10 c 0 2 mol m3 ω 1 5 π yr 1 and the solute injection duration δ t is 5 yr as shown in fig 6 the results obtained by tdrw i make an excellent agreement with the breakthrough curve of the inverse laplace transform solution and so does the results of tdrw c the computation time for tdrw i algorithm is nearly identical to that of the inverse laplace transform approach but much shorter than that of tdrw c algorithm the longer time of tdrw c algorithm is caused mainly by the requirement of an additional evaluation of the integral in eq 17 even though the amounts of applied particles in both tdrw c and tdrw i algorithms are identical to further compare the accuracy of the developed tdrw algorithms we considered a more complicated case involving dirichlet injection boundary defined by 20 c in t c 1 sin ω t h t h t δ t 1 c 2 h t δ t 2 h t δ t 2 δ t 3 where c 1 and c 2 are two constants with the unit of concentration δ t 1 δ t 2 and δ t 3 are three constants with the unit of time this simulation is performed with the condition x 200 m b 100 μm u 2 m yr d f 6 6 10 9 m2 s r f 1 d p 3 7 10 12 m2 s ε p 0 005 r p 1 c 1 10 mol m3 c 2 20 mol m3 ω 1 4000 yr 1 δ t 1 4000 π yr δ t 2 3500 π yr and δ t 3 10000 yr as can be seen in fig 7 the agreement between the results of the three approaches is still excellent the breakthrough curve consists of two separate sections and the shape of each section resembles the corresponding part of the injection curve additionally we found that each section has its individual peak value while a translation of the peak time of the injection curve can be observed for those of the breakthrough curve this time delay results mainly from the effect of advection while the influence of matrix diffusion on solute transport in this case is insignificant however we should note that the applied effective diffusion coefficient is 1 8 10 14 m2 s i e the value for the intact wall rock in mahmoudzadeh et al 2014 and this coefficient is smaller than those of the altered rock cataclasite to further investigate the influence of matrix diffusion on the behavior of the breakthrough curve we performed a new simulation where the effective diffusion coefficient identical to that used in tang et al 1981 becomes 4 5 10 13 m2 s i e d p 9 0 10 11 m2 s as illustrated in fig 7 the results calculated by the use of tdrw c and i algorithms also make an excellent agreement with the breakthrough curve of inverse laplace transform solution nevertheless the new breakthrough curve unlike that of the lower d p case does not resemble the injection curve at all it has only one peak the value of which becomes much lower while a larger translation of the peak time can also be found this difference in performance as discussed in meng et al 2018 is mainly caused by the increase of pore diffusion coefficient or equivalently the larger diffusive mass transfer parameter value and a higher value indicates a more important effect of matrix diffusion in retarding the solute transport in other words the change of matrix properties will significantly influence the behavior of the breakthrough curve e g peak value and time liu et al 2018 meng et al 2018 in addition we found that the computation time of tdrw i is also nearly identical to that of the inverse laplace transform solution but much shorter than that of the tdrw c algorithm for this simulation case the disadvantage of tdrw c originates actually from the fact that we have applied the adaptive gauss kronrod quadrature approach kronrod 1965 to evaluate the convolution in eq 17 it requires the use of more gauss points to obtain more accurate results the number of which increases with the time t and therefore becomes time consuming in general however it is difficult to justify which of the two tdrw algorithms has advantage over the other one in some cases the tdrw i algorithm may require a smaller number of particles than the number of c i n t subdivisions of the tdrw c algorithm and therefore reduces the computation time to a noticeable extent on an equal footing of accuracy in other cases the opposite is true where the tdrw c algorithm is more advantageous we recommended however the application of tdrw c algorithm in the first place because it is easy to be implemented and works well in most cases involving dirichlet injection boundaries with the application of either tdrw c or tdrw i algorithm one can also estimate the distribution profile e g d p 9 0 10 11 m2 s of the solute along the fracture at a specified time of observation e g t 3 10 4 yr towards that end a simple and quick way is to apply a linear interpolation method based on the breakthrough curves obtained at a series of points downstream the fracture to illustrate the robustness of this methodology we show in fig 8 the simulation results for the same case as in fig 7 clearly the application of both tdrw c and tdrw i algorithms yields equally well and satisfactory results compared to the solution obtained from the inverse laplace transform method the difference in the computation time is the main character that may be used to judge the pros and cons of the algorithm as discussed above the number of particles in the tdrw i algorithm is equivalent to the number of subdivisions of c i n t in the tdrw c algorithm times the number of particles in the tdrw k algorithm therefore both tdrw c and tdrw i algorithms may result in the same accuracy of the simulations if their workloads are identical this implies that a tradeoff has to be made between the accuracy of the results and the workload of computations for both algorithms by adjusting the number of either applied particles or the subdivisions of c i n t as performed in tdrw k algorithm however due to its easy implementation the tdrw c algorithm is more favorable in practical applications 3 3 robin injection boundaries as discussed by moreno and rasmuson 1986 the robin injection boundary or the constant flux boundary is commonly used in the simulations of tracer tests in situ to investigate solute transport in a fractured porous rock in this case the tdrw g algorithm is still applicable with however the f function given by eq t4 in table 1 the reason for this is because the robin injection boundaries are similar to heaviside step injection boundaries in that the solute particles are constantly injected into the system as a result the g function in eq 9 also has a nature of cumulative distribution function as required by the tdrw g algorithm alternatively one can also apply both tdrw c and tdrw i algorithms in the simulations if the injection boundary of the problem can be transformed to the type of dirichlet this requires us to perform an inverse laplace transform on eq 14 with the use of de hoog algorithm de hoog et al 1982 the result gives c i n t numerically as a function of time that covers in principle from 0 to infinity since only the early part of the c i n t curve is relevant for the simulations of both tdrw c and tdrw i algorithms a truncation of the curve must be performed to make c i n t limited in the duration of solute injection to demonstrate the applicability of these three tdrw algorithms a simulation is performed with the condition x 100 m b 100 μm u 40 m yr d f 6 6 10 8 m2 s r f 1 d p 9 0 10 11 m2 s ε p 0 005 r p 5 c 0 100 mol m3 as can be seen in fig 9 the agreements between the results obtained from the three variants of the tdrw algorithms and the inverse laplace transform solution are all excellent nevertheless the cumulative nature of the breakthrough curve often requires much less particles to be used in the tdrw g algorithm it can be applied only to cases of constant injection where the f and g functions are analytically available by comparison both tdrw c and tdrw i algorithms have a broader applicability in that they can deal with the problems involving not only dirichlet but also robin injection boundaries the implicit use of the tdrw k method in these two algorithms requires however much more particles to reduce noise of the breakthrough curves as a result these two algorithms bear the burden of an enormous computational workload compared to the tdrw g algorithm in addition it should be stressed that when applying both tdrw c and tdrw i algorithms to deal with the robin injection boundaries the improper truncation of the c i n t curve may influence the accuracy of the results significantly the longer the duration of the truncated c i n t curve the more the particles would be required making the breakthrough curve more accurate otherwise the simulations would have a poor accuracy of the results even though less particles can be applied to further show the applicability tdrw c and tdrw i algorithms we can consider a more complicated injection boundary of the robin type e g eq 21 even though it might be impossible in practice 21 u c f 0 t d f c f x t x x 0 u c 0 exp ω t for the new boundary condition c 0 as shown in eq 21 becomes time dependent nevertheless eq 8 still holds and the laplace transform of c i n t similar to that of the constant flux injection can be given by 22 c in 2 1 e c 0 s ω the new simulation based on eq 22 is performed and the input parameters are identical to those of fig 9 with ω equal to 6 9 10 6 yr 1 as can be seen in fig 10 the result of tdrw c algorithm makes an excellent agreement with that of the inverse laplace transform solution by contrast the performance of the curve of tdrw i algorithm is not as good as those of other two approaches nevertheless a larger number of applied particles as discussed will apparently increase the accuracy of the result while a longer computation can be expected 3 4 a list of tdrw algorithms to summarize we highlight in table 2 the applicability of different tdrw algorithms developed in this study together with their interrelationships clearly the tdrw g algorithm is the core of all other variants of tdrw algorithms based on the results of tdrw g the tdrw k algorithm performs an additional step of differentiation to obtain the impulse response this becomes the central part of both tdrw c and tdrw i algorithms the tdrw c algorithm further performs a convolution of c i n t and the impulse response c f x t δ to obtain the breakthrough curve of interest the tdrw i algorithm can be regarded as an extension of the tdrw k algorithm where t i n 0 for each of the particles and the t i n distribution should be described by p i n t according to eq 18 4 conclusion in this work three variants of the tdrw algorithms i e tdrw g tdrw c and tdrw i are developed to address the problems of solute transport in fractured porous media where different boundary conditions e g dirichlet and robin types are applied the tdrw g algorithm can always be used once the f and g functions are analytically available considering that this is not the case we may on one hand perform a convolution of c i n t and the impulse response of the fracture matrix system numerically i e tdrw c algorithm on the other hand one can make use of the tdrw i algorithm in which the particles unlike tdrw k algorithm are assumed to be injected at different times i e t i n to demonstrate the accuracy and efficacy of the three variants of tdrw algorithms two benchmark cases are considered for general dirichlet and robin injection boundaries respectively it is found that the results from the three algorithms all make an excellent agreement with those obtained from the inverse laplace transform solution method nevertheless more particles are applied in tdrw c and tdrw i algorithms to reduce noise of the breakthrough curves by comparison the cumulative nature of the breakthrough curve often requires much less particles in the tdrw g algorithm we note additionally that the developed tdrw algorithm can also be applied in a more complicated system e g a transport path with the rock matrix composed of several geological layers with different properties mahmoudzadeh et al 2013 or account for the influence of radioactive decay chain mahmoudzadeh et al 2014 shahkarami et al 2015 these will be made in the near future credit authorship contribution statement shuo meng conceptualization data curation formal analysis methodology software validation writing original draft writing review editing longcheng liu conceptualization formal analysis funding acquisition methodology software supervision validation writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge the encouragement and financial support of university of south china the first author also acknowledges the financial support of the excellent youth project of scientific research fund of hunan provincial education department no 22b0405 and the scientific research foundation of university of south china no 210xqd006 the second author gratefully acknowledges the encouragement and financial support of beijing research institute of chemical engineering and metallurgy 
2256,with rapid urbanization and climate change water consumption and land use pattern has dramatically changed resulting in altered eco hydrological processes and high ecological water requirements in megacities however the water uptake strategies may differ in urban and natural environment and which remains largely unknown therefore this study investigated the water use patterns of two greening plants species ficus concinna and ligustrum vicaryi and their responses to rainfall events in a megacity of subtropical china using the stable isotope methods the results indicated that the two greening plants species showed different water use strategies f concinna mainly absorbed water from the shallower soil layer 0 20 cm 56 29 in the wet season and deeper soil water 30 50 cm 41 13 in the dry season whereas l vicaryi mainly relied on the shallower soil water 0 20 cm 48 28 throughout the whole year l vicaryi absorbed water from the shallower soil layer 0 20 cm before rainfall events and changed into deeper soil water 30 50 cm after rainfall events in both dry and wet season on the contrary f concinna did not show these dynamics throughout the year these results suggested that the water use pattern of f concinna showed more ecological plasticity facilitating the adaptation of the plant to seasonal drought and other environment fluctuations in subtropical china urban areas keywords water uptake patterns urban greening plants stable water isotopies mixsiar model subtropical megacity data availability data will be made available on request 1 introduction with the rising population in cities ensuring the sustainability of water demand becomes increasingly important in the face of climate change and urbanization dilling et al 2019 hering et al 2013 since 2000 many cities have been experiencing water shortages and urban areas are anticipated to bear the brunt of the effects of climate change ray and shaw 2019 water consumption and land use patterns during urbanization have a significant impact on urban hydrological processes and can cause a significant increase in floods and droughts which are aggravated by climate change cai et al 2018 severe droughts and several lengthy water deficit spells have occurred in recent years in the pearl river basin deng et al 2018 chen et al 2016 droughts of short duration have also become increasingly common particularly in the pearl river delta zhang et al 2012 therefore assessing the urban plant water uptake strategy and understanding its interaction mechanism with the urbanized environment is significant to water management in the urban greenspace see fig 1 in particular urban soils are severely afflicted by human activities such as compaction landfilling and mixing egerer et al 2019 montgomery et al 2016 pouyat et al 2007 lorenz and kandeler 2005 evans et al 2000 de kimpe and morel 2000 effland and pouyat 1997 and which resulting in the majority of urban soils in greenspace losing their original morphological properties jim 1998 particularly impermeable surfaces and soil compaction associated with urbanization have a direct impact on urban soil moisture status resulting in reduced soil permeability xie et al 2020 carter et al 2018 neris et al 2012 craul 1992 for instance a previous study in shenzhen found that the soil bulk density in urban greenspace was higher than it in suburban areas but the soil porosity and maximum water holding capacity were significantly lower than it in suburban areas zhang et al 2012 the water uptake strategies may differ in the urban and natural environments when considering different water availability and soil characteristics however many studies have been conducted on the changing soil characteristics in urban environments montgomery et al 2016 pouyat et al 2007 but few have focused on the impact of urban and natural environments on plant water uptake xie et al 2020 the traditionally common method to conduct plant water uptake involves investigating the root systems ahmed et al 2018 oswald et al 2008 with the development of the stable isotope technique stable isotopes of hydrogen and oxygen have been widely utilized as a natural tracer in the studies of water movement penna et al 2018 zhao et al 2018 renée brooks et al 2010 it has been proved that the stable water isotopes can be utilized to determine plant source because no fractionation occurs during water absorption and transit from roots to stem except for a few xerophytes or halophytes do fractionate hydrogen isotopes during water uptake barbeta et al 2015 ellsworth and williams 2007 lin and sternberg 1993 therefore several studies have used stable isotopes of hydrogen and oxygen to achieve water traceability in various ecosystems and areas rothfuss and javaux 2017 ma and song 2016 shen et al 2015 eggemeyer et al 2009 west et al 2012 but most of which were undertaken in dry or semi arid regions with only a few studies on the subtropical areas nie et al 2019 yang et al 2015 liu et al 2010 previous studies demonstrated that greenspace plantings use 40 70 of the water in urban areas hartin et al 2018 haley et al 2007 however there is a lack of understanding about the sources of water used by plants in subtropical urban conditions making it difficult to determine if the water used by plants is sustainable to overcome the increasing urban water challenges it is necessary to investigate plant water sources and their response to extreme climates such as storm rain and drought in subtropical urban greenspace which is crucial to urban hydrology water resource management and particularly urban greening water planning therefore the aim of the study is to assess the water uptake strategies of two different greening plant species in an urban situation and the objectives of this study were to i identify the seasonal variations of water uptake strategies of a tree f concinna and a shrub l vicaryi and ii explore the responses to rainfall events by these two plants water uptake strategies 2 materials and methods 2 1 study area the study site is located in xili university town approximately 22 35 40 n 113 58 20 e 17 m above the sea level shenzhen guangdong province fig 1 shenzhen is the most densely populated sub tropical megacity in china with long summers and short winters a mild climate abundant sunshine and abundant rainfall the annual average 1991 2020 temperature is 23 3 c with the lowest average temperature in january 15 7 c and the highest in july 29 0 c and the mean annual precipitation is 1932 9 mm qiu et al 2021 vegetation covers almost 50 of the study area and typical vegetation includes trees ficus concinna and shrubs ligustrum vicaryi f concinna is a native and universal tree species that is commonly cultivated in subtropical areas e g guangdong guangxi guizhou taiwan and yunnan provinces chinese academy of science flora of china editorial board 1998 because it has fine adaptability to the local environment a fast growth rate strong wind resistance and low cultivation and maintenance cost it has been widely used in the greening of subtropical cities hayat et al 2022 qiu et al 2020 in addition there was sufficient solar exposure and air exchange with no shelter from other trees or structures surrounding the plant l vicaryi is a commonly used green garden shrub that is cultivated in tropical and subtropical areas e g southern china india nepal flora flora reipublicae popularis sinicae 1992 due to its ornamental effect and golden color in the growing season l vicaryi has fine adaptability to the local environment with its strong stems and broad leaves and does not require fertilizers it is often used in the greenspace or as decoration in personal yards the soil of the study area was changed following greening works refilled and mixed with building rubbles and garbage to refresh an urban landscape for detail according to the standard for soil backfilling of greenspace construction in shenzhen shenzhen construction project cost management station 2017 the silt humus soil ground soil cultivated soil and soil with an organic matter content 5 shall not be used as backfill materials and the maximum particle size of a pebble gravel boulders or other materials shall not exceed 200 mm in the compacted layers and it shall not exceed 400 mm in the tamped layers the soil in the study area also has a landfill layer composed of construction waste that is common in the underlying surface of the city jim 1998 greinert 2015 and then the water circulation in the urban greenspace will be altered theoretically ren et al 2020 in addition previous studies also show that the soil bulk density was higher li 2019 than in suburban areas with a 1 56 g cm 3 average in the urban greenspace of shenzhen zhang et al 2012 and the soil total porosity capillary porosity aeration porosity and maximum water holding capacity were lower than in suburban areas with an average of 41 06 39 78 1 27 and 24 3 in urban greenspace in shenzhen respectively zhang et al 2012 it is obvious that the soil in the study area was different from it in the natural environment or suburban area 2 2 environmental monitoring meteorological variables had been measured at a nearby weather station 500 m from the selected plantation plots since 2008 a suite of micrometeorological sensors was installed including those of net radiation model cnr 1 kipp zonen inc air temperature model hmp45c vaisala inc soil water content model cs615 l campbell scientific inc relative humidity vaisala hmp45d vaisala helsinki finland and precipitation model 52203 rm young inc which provided half hourly measurements their values were stored in a cr1000 datalogger campbell scientific inc logan ut usa a bowen ratio system was set up near the plant in the greenspace measurements included net radiation air temperature relative humidity wind speed and ground heat flux all data were sampled every 1 min and every 10 min average was recorded by cr1000 data logger campbell scientific usa from july 2014 the volumetric soil water contents were measured at depths of 3 10 20 30 40 and 50 cm using six time domain reflectometry probes sm300 uk which were installed at about 1 5 m and 2 m from the f concinna and l vicaryi respectively the data were sampled every 1 min and every 10 min average was recorded by cr1000 data logger campbell scientific usa from july 2017 to december 2018 2 3 sample collection and isotopic analyses during the study precipitation soil water and xylem water were all sampled for stable isotope analyses from july 1 2017 to december 31 2018 to reduce evaporation during rainfall a rain collector made out of a polyethylene bottle and funnel was set outside with a ping pong ball placed at the funnel mouth wang et al 2012 rainwater was collected after each occurrence of a rainstorm and quickly transferred to a bottle then sealed in a glass vial and stored two individuals of f concinna and thirty individuals of l vicaryi were selected as a plant sample and three replicates were collected from one plant sample every 2 3 days the average height diameter at the breast height and crown area of f concinna were 8 m 22 cm and 28 m2 respectively the average height of l vicaryi was 0 5 m each plant sample of f concinna and l vicaryi was collected from side branches of the canopy wang et al 2017 at a height of approximately 300 cm and 50 cm above the ground respectively according to the isotope steady state assumption welp et al 2010 the difference between the isotopic composition of vegetative transpiration and that of the xylem of branches is neglectable between 13 00 15 00 every plant sample was cut into about 4 cm segments xylem samples then the outer bark and phloem tissue were removed from xylem samples which were then promptly sealed in glass vials with parafilm and maintained frozen 20 c for isotopic analysis yang et al 2018 wang et al 2017 soil samples were collected in the meantime and three replicates of soil samples were collected at depths of 0 2 2 5 5 10 10 15 15 20 20 25 25 30 30 35 35 40 40 45 cm and 45 50 cm were collected in each sampling day then every soil samples were stored in a similar way with xylem samples for isotopic analysis the xylem of branches and soil samples were extracted by a cryogenic vacuum distillation system li 2100 lica beijing china the δ2h and δ18o of the xylem water and soil water were measured by a liquid water isotope analyzer lwia 912 0008 los gatos research mountain view usa after filtering with a 0 45 µm filter the precision of the liquid water isotope analyzer was 0 3 for 2h and 0 1 for 18o the abnormal value was eliminated using the analytical software lwia post analysis v 3 1 0 9 to determine the isotopic values of hydrogen and oxygen organic materials in the extracted plant may cause spectral interference and lead to isotopic value errors schultz et al 2011 dai et al 2020 therefore the lwia post analysis software was used to identify and quantify spectral contamination and the correction was carried out according to meng et al 2012 and luo et al 2019 2 4 water source portioning methods based on isotopic mass conservation theory the mixsiar bayesian mixing model framework was used to calculate the most likely contribution proportion of water sources for plants moore and semmens 2008 stock and semmens 2016 the parameters of mixsiar include uncertainties related to various isotope characteristics available sources and discrimination variables wang et al 2017 the xylem isotope values δ2h and δ18o of two plant species were used as mixture data inputs into mixsiar the averages and standard errors of isotope compositions both δ2h and δ18o of xylem water and various soils depths 0 2 2 5 5 10 10 15 15 20 20 25 25 30 30 35 35 40 40 45 and 45 50 cm were utilized as source data and entered the mixsiar the graphical user interface of mixsiar was used with the markov chain monte carlo parameter mcmc run length was set to long chain length 300000 burn in 200000 thin 100 chains 3 and the error options was set to residual only account for other agents of sources variability then to determine if the model converged or not the diagnostic tests of gelman rubin and geweke were used stock and semmens 2016 after checking the isospace plot the estimated median 50 quantiles ratio was regarded as the contribution of the potential water sources to two plant species to reduce experimental error and improve calculation accuracy in this study the model was used to investigate the δ2h and δ18o values of five potential xylem water sources 0 10 10 20 20 30 30 40 and 40 50 cm deng et al 2021 3 results 3 1 site environmental conditions 3 1 1 meteorological characteristics the daily relative humidity rh was 40 and rh 70 was observed for 280 days every year fig 2 a the average rainfall accounted for 92 85 1822 25 mm during the wet season and 7 15 140 25 mm during the dry season fig 2b besides light rain 10 mm day 1 was observed for nearly 60 of all precipitation days but the heavy rain 25 49 9 mm day 1 and the storm rain 50 99 9 mm day 1 contributed to 59 of average annual precipitation the daily net radiation shows significant seasonal variations and peaked at 180 w m 2 around june july then rapidly decreased to 30 w m 2 at december january fig 2b meanwhile the daily net radiation was highly variable ranging from 5 w m 2 during winter to 180 w m 2 during summer the dynamic of the air temperature was influenced distinctly by the net radiation with seasonal nature fig 2a the average temperature was 27 2 in the wet season from april to october and 18 6 in the dry season from november to march the annual average temperature in 2017 24 01 and 2018 23 45 was close with the lowest temperature in january 7 53 and the highest in june 32 26 3 1 2 soil water content the soil water content swc also showed a significant seasonal trend fig 3 a and was significantly higher in the wet season than in the dry season the average swc for 0 50 cm was 17 from november to april and it was 27 from may to october moreover from may to october the highest swc was 10 cm and the lowest was 20 cm in particular the soil water content of the 20 cm layer was significantly less than other soil layers during the studies periods and its swc ranged from 0 05 to 0 25 fig 3a it is obvious that the swc of the 15 25 cm layer was smaller than other soil layers especially in the dry season fig 3b to further explore the permeability of various soil layers the coefficient of variation cv of swc was used the cv of swc in the 0 15 cm layer was much larger than that in the 15 25 cm layer during the period of low swc which occurred from november to april furthermore the cv of swc in 0 15 cm and 25 50 cm layers were often smaller than that in the other layers during the period of high soil water content the cv of swc in the 0 15 cm layer was significantly lower than that in the 15 25 cm layer from april to november in general the cv of swc in the 15 25 cm layer showed the most considerable change compared with that in the other depths implying that the 20 25 cm soil layer is a discontinuous and weak permeable layer in the urban greenspace 3 2 isotopic compositions and variation of the soil and xylem water 3 2 1 isotopic compositions of precipitation soil water and xylem water during the study period we collected precipitation samples from each precipitation event and found that the δ18o of precipitation ranged from 14 00 to 0 51 with a mean value of 6 24 and the δ2h of precipitation ranged from 100 00 to 1 40 with a mean value of 40 92 the local meteoric water line lmwl δ2h 7 48 δ18o 5 81 r2 0 96 n 131 was then obtained and the intercept and slope were both lower than those of the global meteoric water line gmwl δ2h 8δ18o 10 fig 4 the soil water isotopic values fluctuated greatly during the sampling periods ranging from 11 00 to 0 23 with a mean value of 5 62 for δ18o and from 15 00 to 85 00 with a mean value of 44 06 for δ2h the δ2h and δ18o values of soil water and xylem water were both below the lmwl fig 4 indicating that due to evaporation throughout the raindrop process soil water had varying degrees of fractionation for isotopic compositions the isotopic values in xylem water varied among plant species fig 4 the isotopes value in xylem water of f concinna ranged from 9 40 to 2 90 averagely 5 82 for δ18o and from 67 90 to 22 60 averagely 43 94 for δ2h and the isotopic values in xylem water of l vicaryi ranged from 8 25 to 4 14 averagely 5 80 for δ18o and from 55 99 to 37 04 averagely 46 95 for δ2h although the variation in isotopic values was smaller in xylem water than in soil water 3 2 2 isotopic variation in dry and wet seasons table 1 shows the mean standard error sd maximum max and minimum min isotopic composition for soil water precipitation and xylem water during the dry and wet seasons the line fitting between δ2h and δ18o in precipitation are δ2h 7 44 δ18o 5 42 r2 0 96 n 123 p 0 001 and δ2h 8 23 δ18o 11 12 r2 0 98 n 8 p 0 001 in the wet and dry season respectively fig 4 all stable isotopes of soil water both fall to the right side of the lmwl and the line fitting between δ2h and δ18o in soil water are δ2h 6 30 δ18o 8 64 r2 0 94 n 450 p 0 001 and δ2h 5 35 δ18o 14 12 r2 0 93 n 65 p 0 001 in the wet and dry season respectively which is caused by greater impact of evaporation on soil water in the dry season than in the wet season the stable isotopes of xylem water of f concinna xylem and l vicaryi fall around the fitting line of soil water the line fitting between δ2h and δ18o in f concinna xylem water are δ2h 7 35 δ18o 1 08 r2 0 92 n 92 p 0 001 and δ2h 6 77 δ18o 5 15 r2 0 94 n 13 p 0 001 in the wet and dry seasons respectively the line fitting between δ2h and δ18o in l vicaryi xylem water are δ2h 6 54 δ18o 9 71 r2 0 90 n 17 p 0 005 and δ2h 5 75 δ18o 10 38 r2 0 65 n 7 p 0 05 in wet and dry season respectively indicating that the xylem water of f concinna and l vicaryi originates from soil water 3 3 variations in the contribution to potential water sources of f concinna and l vicaryi as shown in fig 6 a and b the mixsiar method shows that f concinna absorbs mostly the surface soil water from 0 to 20 cm at mean values of 49 06 and 42 26 respectively and it absorbs the least soil water from 30 to 40 cm at 15 76 and 18 14 for δ2h and δ18o respectively in particular the contributions of potential water sources for f concinna based on δ2h fig 6a and δ18o fig 6b both indicate that the shallower layer 0 20 cm was the most important source 56 29 from april to september but the soil at 30 50 cm layer was the most important source 41 13 from october to december moreover the water sources of f concinna gradually turned from shallow soil water to deeper soil water these findings indicate that the potential water sources for f concinna have significant seasonal variability during the study period fig 6c and 6d indicate the contributions of potential water sources for l vicaryi as determined by the mixsiar model the results generally showed that l vicaryi absorbed mostly the surface soil water from 0 to 10 cm at mean values of 30 81 and 32 73 respectively and absorbed the least soil water from 30 to 40 cm at mean values of 15 17 and 13 70 for δ2h and δ18o respectively specifically the results of the mixsiar method based on δ2h fig 6c demonstrated that the surface soil water from 0 to 20 cm stably made the highest contribution with an average of 48 28 during the study period from july to december however the water from the 30 50 cm layer fluctuated significantly and peaked at 65 25 in november it averaged 49 09 in the wet season from july to september and increased to an average of 54 21 in the dry season from october to december in comparison the results of the mixsiar method based on δ 18o fig 6d shows that l vicaryi mainly relied on the 0 20 cm average of 48 28 shallower soil during the study period and the water contribution from the 40 50 cm soil layer also gradually increased 3 4 effect of rainfall events on the contribution to potential water sources of f concinna and l vicaryi to explore the response of water sources to the different rainfall events in urban greenspace the changes in the contribution of potential water sources before and after a torrential rain event precipitation range from 100 mm to 249 9 mm during 24 h in the wet season and a heavy rain event precipitation range from 25 mm to 49 9 mm during 24 h in the dry season were studied 3 4 1 variations in plants potential water sources after torrential rainfall event a typhoon named mangkhut dumped torrential rainfall 173 5 mm on september 16 and storm rain 52 0 mm on september 17 fig 7 in the wet season the highest precipitation was observed on the 16th from morning to night and the wind and rain diminished during the day on the 17th until early morning on the 18th with no precipitation between the 19th and 21st in this study the proportion of plant water uptake during september 11 14 and september 15 18 were regarded as potential water source contributions before and after the rain event respectively besides there was 1 5 mm 0 1 mm and 7 2 mm light rain of precipitation on september 13 15 and 18 respectively fig 7 shows the effect of the torrential rain event on the water uptake from all layers 0 10 cm 10 20 cm 20 30 cm 30 40 cm and 40 50 cm for f concinna and l vicaryi in the wet season before the torrential rain all layers contributed equally to f concinna water uptake fig 7a ranging from 18 30 to 23 80 on september 11 with the biggest contributions coming from the 40 50 cm layer 23 80 within 1 day after the light rain events the variance in the contribution from 0 to 20 cm layer was 0 5 showing that the contribution of surface soil was hardly affected by the light rain on september 14 however the 15 91 increase from 42 10 to 48 80 in the contribution from the 30 50 cm layer suggests the considerable influence of the little rain within 1 day after the torrential rain and storm rain events the contribution of all the layers became close ranging from 15 20 to 22 10 on september 18 possibly due to soil washing caused by a large amount of rain 225 50 mm three days after rain the most significant change was in the contribution of the 40 50 cm layer soil which increased from 15 90 to 37 70 for l vicaryi the contribution of 0 10 cm layer soil water changed from 23 30 on september 11 to 37 20 on september 14 after a light rain fig 7b demonstrating that the surface soil water contribution was prominently influenced by the light rain within 1 day after the torrential rain and storm rain events the contribution of the 30 50 cm layer soil water reached 62 7 on september 18 suggesting that the main contribution of l vicaryi water uptake was converted into 30 50 cm layer soil water after the torrential rain following three days after rain the contribution of the 0 20 cm layer soil water grew quickly to 49 60 on september 21 and nearly returned to the level it was on september 14 the variation in l vicaryi water uptake before and after rainfall events is consistent with the results of previous studies sekiya and yano 2002 zegada lizarazu et al 2007 yang et al 2015 yang et al 2018 indicating that plant water sources always respond to irrigation or excessive rainfall in general the potential water sources of f concinna and l vicaryi were dramatically different in response to rainfall events during the wet season the potential water source for f concinna was mainly the 30 50 cm layer soil water before the rainfall with equal contribution from all layers after a massive rainfall three days after rainfall it returned to its previous level before the massive rainfall the potential water source for l vicaryi was primarily the 0 20 cm layer before the rainfall and the contribution by the 0 10 cm layer was considerably affected by the light rain the source changed to the 30 50 cm layer after the rainfall and after 3 days the 0 20 cm layer soil layer became the main source by comparison the impact of a rainfall event on the supply of water by surface soil for l vicaryi was greater than for f concinna 3 4 2 variations in plants potential water sources after heavy rainfall event a continuous rain event with an intensity of 23 6 mm moderate rain and 25 8 mm heavy rain occurred on november 25 and 26 respectively in the dry season fig 8 there was also 0 9 mm 6 5 mm 0 1 mm and 0 1 mm light rain of precipitation on november 27 28 and 29 and december 7 respectively with no precipitation on december 10 14 in this study the proportion of plant water uptake on the 10th and 24th of september was treated as the potential water sources contribution before the rain event and that on november 30 and december 7 and 14 were treated as a contribution after the rain event fig 8 shows the effect of the heavy rain event on the water uptake from all layers 0 10 cm 10 20 cm 20 30 cm 30 40 cm and 40 50 cm for f concinna and l vicaryi in the dry season in the dry season the main contribution to f concinna water uptake came from the 30 50 cm layer soil 42 during the before rain period fig 8a and the contribution of the 40 50 cm layer soil water increased from 13 40 to 22 70 from november 10 to 24 a day after the heavy rain the contribution of the 30 50 cm layer soil increased quickly reaching 68 90 on november 30 and dropping rapidly on december 7 indicating that the main contribution of l vicaryi water uptake was from the 30 50 cm layer after rainfall with the proportion increasing significantly after 11 days of heavy rain it returned to its previous level before the rain furthermore after the rain occurred on december 7 the fluctuation in the contribution from the 0 10 cm layer suggests that light rain had little effect on the surface soil contribution for l vicaryi the highest contribution before the rain event was from the 0 20 cm layer soil at 55 10 on november 10 fig 8b which changed to 47 50 on november 24 while the contribution of the 40 50 cm layer soil increased from 18 40 to 22 80 indicating that the main water source before the rain was surface soil water and the contribution from the 40 50 cm layer soil gradually increased the contribution of the 30 50 cm layer dramatically increased from 36 80 to 50 20 on november 30 1 day after heavy rain eleven days after heavy rain the contribution of the 0 10 cm layer soil increased from 18 60 to 51 70 after the light rain fig 8 on december 7 the contribution then dropped to 28 30 for 0 10 cm layer soil and increased from 12 80 to 38 00 for 30 50 cm layer soil on december 14 generally after heavy rain in the dry season the main contribution changed from surface soil 0 20 cm to deeper soil 30 50 cm and returned to surface soil after 18 days of heavy rain besides the light rain had a major impact on the contribution of surface soil for l vicaryi during the dry season the main water source of f concinna was the deeper soil both before and after the rain event however the contribution from the deeper soil increased significantly immediately after the rain event and after 11 days the soil water returned to the level it was before the rain in comparison the main water source of l vicaryi changed from surface soil to deeper soil as a result of the rain event and after 18 days the source changed back to the level it was before the rain in addition light rain had an impact on the contribution of surface soil to l vicaryi but not on f concinna besides both f concinna and l vicaryi largely used the 30 50 cm layer soil water 42 70 and 38 00 respectively implying that f concinna and l vicaryi compete for deeper soil water 4 discussion 4 1 temporal variation in different water isotopic values the isotopic compositions of precipitation were affected by environmental factors such as air temperature precipitation amounts etc yamanaka et al 2007 froehlich et al 2008 liu et al 2010 2014 there were large differences in precipitation isotopes between the wet and dry seasons table 1 in the study area and the slope of lmwl was respectively 7 44 and 8 23 during wet and dry seasons fig 5 implying that the primary water source for the environment differed greatly between the two seasons similarly the isotopic composition of soil water and xylem water that was affected by the precipitation whether directly or indirectly also show a significant distinction between the dry and wet season fig 5 in addition the plot of δ2h and δ18o for xylem water were mostly located between the lmwl and the swl implying that both xylem water of f concinna and l vicaryi were absorbed from precipitation and soil water yang et al 2015 however the slope gap between lmwl and xwl in the dry season was both greater than that in the wet season fig 5 indicating fractionation had a greater influence on the water sources of f concinna and l vicaryi in the dry season than in the wet season remarkably whether dry season or wet season the slope of xwltree f concinna was higher than that of xwlshrub l vicaryi suggesting that the water source of l vicaryi is more impacted by isotope fractionation than that of f concinna yang et al 2015 however the slope of swl was smaller than that of xwltree and larger than that of xwlshrub in the whole period while the slopes of xwltree and xwlshrub were both larger than that of swl in the dry and wet seasons these differences could imply that the water sources of the f concinna and l vicaryi changed as the wet and dry seasons progressed which is consistent with the previous study deng et al 2021 4 2 differences in water uptake strategy of tree and shrub in urban greenspace our results suggest that the water use strategy of f concinna is different from that of l vicaryi and these strategies can change seasonally in this study the water use strategy of the two plants mainly absorbed the soil water at the 0 20 cm layer during the wet season from march to september during the dry season from july to december f concinna mainly absorbed the soil water at the 30 50 cm layer whereas l vicaryi mainly absorbed the soil water at the 0 20 cm layer previous studies demonstrated that the plant water use pattern is likely related to its root distribution zhao et al 2021 matheny et al 2017 in this study the maximum root systems of f concinna and l vicaryi were both mainly distributed in the shallow layer lv et al 2022 yang et al 2021 li et al 2020 in the greenspace and the root depths were 0 60 cm and 0 50 cm respectively these similarities in rooting depths suggested that the difference in the water sources could be due to contrasting rooting morphologies between the two species vega grau et al 2021 on visual inspection during the sampling collection process f concinna appeared to have several lateral and horizontal roots whereas l vicaryi appeared to have finer roots fig 6a and b exhibit that trees often depended on the deeper layers of water to withstand seasonal droughts which was consistent with the previous studies barbeta et al 2015 otieno et al 2017 the results of many studies showed that some plants species have a dimorphic root system with a zone of lateral roots and the ability to switch water absorption zones between shallower and deeper soil layers when its main water source is unavailable dawson and pate 1996 nie et al 2012 yang et al 2015 which is consistent with the findings of this study wang et al 2009 found that ficus tinctorial which is in the same genus as f concinna absorbed shallower soil water in the dry season and from different layers in the wet season f concinna might also have an extended lateral root system as its water source varies seasonally beyer et al 2018 furthermore the ability to exploit different water sources makes it possible for some plants to survive long periods without rain or to overcome seasonal water shortages yang et al 2011 zencich et al 2002 therefore the ability of f concinna to switch water uptake zones may be related to its dimorphic root system and f concinna showed greater ecological plasticity and seasonal adaptation level to the environment than l vicaryi moreover some soil characteristics might enable plant species to show specific water uptake patterns in a specific environment liu et al 2019 nie et al 2019 2012 rong et al 2011 for instance the shallow soil covered by abundant rock fractures in the karst region results in weak soil water retaining capacity and large percolation capacity which further affects plant water uptake 4 3 water uptake strategy of tree and shrub in response to rainfall events mixsiar demonstrated that the water uptake strategies of f concinna and l vicaryi in response to rainfall events are different and vary following the rainfall events before and after rainfall events the main water source of f concinna was at the deeper soil layer regardless of the season and the amount of precipitation in particular the contribution from other layers after rainfall events increased during the wet season while the deeper soil layer had the same rise during the dry season unlike the tree the main water source for l vicaryi before the rainfall events was the shallower soil layer which changed to a deeper soil layer after rainfall events indicating that the main water source for l vicaryi was more responsive to rainfall events than f concinna a previous study maurel and nacry 2020 reported that water uptake is not only dependent on root growth but also critically influenced by a plant s hydraulics and water excess reduces root hydraulic conductivity in most plant species in our study there was significant subtropical wet and dry season with seasonal change in rainfall resulting in seasonal fluctuation in the availability of soil water deng et al 2021 which indirectly influenced plant water uptake patterns wang et al 2017 besides the water source of f concinna showed no response to increased water in the surface layer after light rainfall events although it exhibited seasonal water uptake plasticity and stronger adaptation which is consistent with the report of quercus alba asbjornsen et al 2008 this may be attributed to the lateral root system of these two species and trees tend to derive water from deeper soil layers wu et al 2016 in contrast the main water source of l vicaryi exhibited a significant response to light rainfall events indicating its main water sources are largely affected by rainfall events patterns as demonstrated in a previous study zhao and wang 2018 l vicaryi was more sensitive to rainfall events compared with f concinna and showed a significant response to increased water in the surface layer after light rainfall events this was consistent with a previous report that the level of water obtainable from each soil layer is determined by the number of fine roots in the plant ellsworth and sternberg 2015 and it has been reported that the root morphology of l vicaryi is characterized by taproot and more dense root hairs schenk and jackson 2005 meanwhile the water use patterns of trees and shrubs have a complementary relationship in the wet season and a competitive relationship for deeper soil in the dry season with or without rain there are two major potential limitations in this study that could be addressed in future research first the study focused on two greening plants water uptake patterns with basing on sampling collection there are therefore subject to limited sample size and plant species that may have influenced our research however the widely distributed native tree f concinna and shrub l vicaryi plant species were selected and the corresponding sample size was two individuals and thirty individuals to avoid the negative influence as much as possible second the contribution proportion of two greening plants potential water source was estimated from the mixsiar model with uncertainties including from multiple sources and discrimination factors nevertheless the mixsiar model s shortcomings cannot be ignored such as insensitivity to possible effects of 2h 1h fractionation barbeta et al 2018 evaristo et al 2017 and sensitivity to the choice of discrimination factors stock et al 2018 therefore it deserves to be further studied in terms of the following aspects this study could explore more plant species and not only one greenspace besides the stable isotope technique can also be coupled with stem relative water content to determine when performing stem water cryogenic extraction chen et al 2020 5 conclusion the stable isotopic method and mixsiar model were employed to assess the season variations of the water uptake strategies of urban tree f concinna and shrub l vicaryi in a megacity s greenspace of subtropical china firstly the isotopic composition of precipitation soil water xylem water and hydrometeorological characteristics shows significant differences between dry and wet seasons secondly f concinna mainly absorbed water from the shallower soil layer 0 20 cm in the wet season and changed to deeper soil water 30 50 cm in the dry season while l vicaryi s didn t show such a seasonal change this was mainly attributed to the dimorphic root system finally l vicaryi absorbed water from the shallower soil layer 0 20 cm before rainfall events and changed into deeper soil water 30 50 cm after rainfall events which showed greater flexibility in response to rainfall events but f concinna didn t exhibit such a response the flexible water uptake patterns of f concinna make it more adaptable to the changeable environment than l vicaryi this study found that the ecological plasticity shown by f concinna regarding its water use pattern can facilitate its adaptation to seasonal drought and other environmental fluctuations and the research results will be significant for urban greening water planning in the megacity credit authorship contribution statement bei wang investigation data curation visualization writing original draft writing review editing chunhua yan writing review editing supervision zhe shi writing review editing jinshan ding writing review editing tengran zhang writing review editing longjun qin guo yu qiu conceptualization methodology resources supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the science technology and innovation commission of shenzhen municipality jcyj20180504165440088 the authors would like to express their great thanks to elsevier language editing for their efforts to improve the manuscript 
2256,with rapid urbanization and climate change water consumption and land use pattern has dramatically changed resulting in altered eco hydrological processes and high ecological water requirements in megacities however the water uptake strategies may differ in urban and natural environment and which remains largely unknown therefore this study investigated the water use patterns of two greening plants species ficus concinna and ligustrum vicaryi and their responses to rainfall events in a megacity of subtropical china using the stable isotope methods the results indicated that the two greening plants species showed different water use strategies f concinna mainly absorbed water from the shallower soil layer 0 20 cm 56 29 in the wet season and deeper soil water 30 50 cm 41 13 in the dry season whereas l vicaryi mainly relied on the shallower soil water 0 20 cm 48 28 throughout the whole year l vicaryi absorbed water from the shallower soil layer 0 20 cm before rainfall events and changed into deeper soil water 30 50 cm after rainfall events in both dry and wet season on the contrary f concinna did not show these dynamics throughout the year these results suggested that the water use pattern of f concinna showed more ecological plasticity facilitating the adaptation of the plant to seasonal drought and other environment fluctuations in subtropical china urban areas keywords water uptake patterns urban greening plants stable water isotopies mixsiar model subtropical megacity data availability data will be made available on request 1 introduction with the rising population in cities ensuring the sustainability of water demand becomes increasingly important in the face of climate change and urbanization dilling et al 2019 hering et al 2013 since 2000 many cities have been experiencing water shortages and urban areas are anticipated to bear the brunt of the effects of climate change ray and shaw 2019 water consumption and land use patterns during urbanization have a significant impact on urban hydrological processes and can cause a significant increase in floods and droughts which are aggravated by climate change cai et al 2018 severe droughts and several lengthy water deficit spells have occurred in recent years in the pearl river basin deng et al 2018 chen et al 2016 droughts of short duration have also become increasingly common particularly in the pearl river delta zhang et al 2012 therefore assessing the urban plant water uptake strategy and understanding its interaction mechanism with the urbanized environment is significant to water management in the urban greenspace see fig 1 in particular urban soils are severely afflicted by human activities such as compaction landfilling and mixing egerer et al 2019 montgomery et al 2016 pouyat et al 2007 lorenz and kandeler 2005 evans et al 2000 de kimpe and morel 2000 effland and pouyat 1997 and which resulting in the majority of urban soils in greenspace losing their original morphological properties jim 1998 particularly impermeable surfaces and soil compaction associated with urbanization have a direct impact on urban soil moisture status resulting in reduced soil permeability xie et al 2020 carter et al 2018 neris et al 2012 craul 1992 for instance a previous study in shenzhen found that the soil bulk density in urban greenspace was higher than it in suburban areas but the soil porosity and maximum water holding capacity were significantly lower than it in suburban areas zhang et al 2012 the water uptake strategies may differ in the urban and natural environments when considering different water availability and soil characteristics however many studies have been conducted on the changing soil characteristics in urban environments montgomery et al 2016 pouyat et al 2007 but few have focused on the impact of urban and natural environments on plant water uptake xie et al 2020 the traditionally common method to conduct plant water uptake involves investigating the root systems ahmed et al 2018 oswald et al 2008 with the development of the stable isotope technique stable isotopes of hydrogen and oxygen have been widely utilized as a natural tracer in the studies of water movement penna et al 2018 zhao et al 2018 renée brooks et al 2010 it has been proved that the stable water isotopes can be utilized to determine plant source because no fractionation occurs during water absorption and transit from roots to stem except for a few xerophytes or halophytes do fractionate hydrogen isotopes during water uptake barbeta et al 2015 ellsworth and williams 2007 lin and sternberg 1993 therefore several studies have used stable isotopes of hydrogen and oxygen to achieve water traceability in various ecosystems and areas rothfuss and javaux 2017 ma and song 2016 shen et al 2015 eggemeyer et al 2009 west et al 2012 but most of which were undertaken in dry or semi arid regions with only a few studies on the subtropical areas nie et al 2019 yang et al 2015 liu et al 2010 previous studies demonstrated that greenspace plantings use 40 70 of the water in urban areas hartin et al 2018 haley et al 2007 however there is a lack of understanding about the sources of water used by plants in subtropical urban conditions making it difficult to determine if the water used by plants is sustainable to overcome the increasing urban water challenges it is necessary to investigate plant water sources and their response to extreme climates such as storm rain and drought in subtropical urban greenspace which is crucial to urban hydrology water resource management and particularly urban greening water planning therefore the aim of the study is to assess the water uptake strategies of two different greening plant species in an urban situation and the objectives of this study were to i identify the seasonal variations of water uptake strategies of a tree f concinna and a shrub l vicaryi and ii explore the responses to rainfall events by these two plants water uptake strategies 2 materials and methods 2 1 study area the study site is located in xili university town approximately 22 35 40 n 113 58 20 e 17 m above the sea level shenzhen guangdong province fig 1 shenzhen is the most densely populated sub tropical megacity in china with long summers and short winters a mild climate abundant sunshine and abundant rainfall the annual average 1991 2020 temperature is 23 3 c with the lowest average temperature in january 15 7 c and the highest in july 29 0 c and the mean annual precipitation is 1932 9 mm qiu et al 2021 vegetation covers almost 50 of the study area and typical vegetation includes trees ficus concinna and shrubs ligustrum vicaryi f concinna is a native and universal tree species that is commonly cultivated in subtropical areas e g guangdong guangxi guizhou taiwan and yunnan provinces chinese academy of science flora of china editorial board 1998 because it has fine adaptability to the local environment a fast growth rate strong wind resistance and low cultivation and maintenance cost it has been widely used in the greening of subtropical cities hayat et al 2022 qiu et al 2020 in addition there was sufficient solar exposure and air exchange with no shelter from other trees or structures surrounding the plant l vicaryi is a commonly used green garden shrub that is cultivated in tropical and subtropical areas e g southern china india nepal flora flora reipublicae popularis sinicae 1992 due to its ornamental effect and golden color in the growing season l vicaryi has fine adaptability to the local environment with its strong stems and broad leaves and does not require fertilizers it is often used in the greenspace or as decoration in personal yards the soil of the study area was changed following greening works refilled and mixed with building rubbles and garbage to refresh an urban landscape for detail according to the standard for soil backfilling of greenspace construction in shenzhen shenzhen construction project cost management station 2017 the silt humus soil ground soil cultivated soil and soil with an organic matter content 5 shall not be used as backfill materials and the maximum particle size of a pebble gravel boulders or other materials shall not exceed 200 mm in the compacted layers and it shall not exceed 400 mm in the tamped layers the soil in the study area also has a landfill layer composed of construction waste that is common in the underlying surface of the city jim 1998 greinert 2015 and then the water circulation in the urban greenspace will be altered theoretically ren et al 2020 in addition previous studies also show that the soil bulk density was higher li 2019 than in suburban areas with a 1 56 g cm 3 average in the urban greenspace of shenzhen zhang et al 2012 and the soil total porosity capillary porosity aeration porosity and maximum water holding capacity were lower than in suburban areas with an average of 41 06 39 78 1 27 and 24 3 in urban greenspace in shenzhen respectively zhang et al 2012 it is obvious that the soil in the study area was different from it in the natural environment or suburban area 2 2 environmental monitoring meteorological variables had been measured at a nearby weather station 500 m from the selected plantation plots since 2008 a suite of micrometeorological sensors was installed including those of net radiation model cnr 1 kipp zonen inc air temperature model hmp45c vaisala inc soil water content model cs615 l campbell scientific inc relative humidity vaisala hmp45d vaisala helsinki finland and precipitation model 52203 rm young inc which provided half hourly measurements their values were stored in a cr1000 datalogger campbell scientific inc logan ut usa a bowen ratio system was set up near the plant in the greenspace measurements included net radiation air temperature relative humidity wind speed and ground heat flux all data were sampled every 1 min and every 10 min average was recorded by cr1000 data logger campbell scientific usa from july 2014 the volumetric soil water contents were measured at depths of 3 10 20 30 40 and 50 cm using six time domain reflectometry probes sm300 uk which were installed at about 1 5 m and 2 m from the f concinna and l vicaryi respectively the data were sampled every 1 min and every 10 min average was recorded by cr1000 data logger campbell scientific usa from july 2017 to december 2018 2 3 sample collection and isotopic analyses during the study precipitation soil water and xylem water were all sampled for stable isotope analyses from july 1 2017 to december 31 2018 to reduce evaporation during rainfall a rain collector made out of a polyethylene bottle and funnel was set outside with a ping pong ball placed at the funnel mouth wang et al 2012 rainwater was collected after each occurrence of a rainstorm and quickly transferred to a bottle then sealed in a glass vial and stored two individuals of f concinna and thirty individuals of l vicaryi were selected as a plant sample and three replicates were collected from one plant sample every 2 3 days the average height diameter at the breast height and crown area of f concinna were 8 m 22 cm and 28 m2 respectively the average height of l vicaryi was 0 5 m each plant sample of f concinna and l vicaryi was collected from side branches of the canopy wang et al 2017 at a height of approximately 300 cm and 50 cm above the ground respectively according to the isotope steady state assumption welp et al 2010 the difference between the isotopic composition of vegetative transpiration and that of the xylem of branches is neglectable between 13 00 15 00 every plant sample was cut into about 4 cm segments xylem samples then the outer bark and phloem tissue were removed from xylem samples which were then promptly sealed in glass vials with parafilm and maintained frozen 20 c for isotopic analysis yang et al 2018 wang et al 2017 soil samples were collected in the meantime and three replicates of soil samples were collected at depths of 0 2 2 5 5 10 10 15 15 20 20 25 25 30 30 35 35 40 40 45 cm and 45 50 cm were collected in each sampling day then every soil samples were stored in a similar way with xylem samples for isotopic analysis the xylem of branches and soil samples were extracted by a cryogenic vacuum distillation system li 2100 lica beijing china the δ2h and δ18o of the xylem water and soil water were measured by a liquid water isotope analyzer lwia 912 0008 los gatos research mountain view usa after filtering with a 0 45 µm filter the precision of the liquid water isotope analyzer was 0 3 for 2h and 0 1 for 18o the abnormal value was eliminated using the analytical software lwia post analysis v 3 1 0 9 to determine the isotopic values of hydrogen and oxygen organic materials in the extracted plant may cause spectral interference and lead to isotopic value errors schultz et al 2011 dai et al 2020 therefore the lwia post analysis software was used to identify and quantify spectral contamination and the correction was carried out according to meng et al 2012 and luo et al 2019 2 4 water source portioning methods based on isotopic mass conservation theory the mixsiar bayesian mixing model framework was used to calculate the most likely contribution proportion of water sources for plants moore and semmens 2008 stock and semmens 2016 the parameters of mixsiar include uncertainties related to various isotope characteristics available sources and discrimination variables wang et al 2017 the xylem isotope values δ2h and δ18o of two plant species were used as mixture data inputs into mixsiar the averages and standard errors of isotope compositions both δ2h and δ18o of xylem water and various soils depths 0 2 2 5 5 10 10 15 15 20 20 25 25 30 30 35 35 40 40 45 and 45 50 cm were utilized as source data and entered the mixsiar the graphical user interface of mixsiar was used with the markov chain monte carlo parameter mcmc run length was set to long chain length 300000 burn in 200000 thin 100 chains 3 and the error options was set to residual only account for other agents of sources variability then to determine if the model converged or not the diagnostic tests of gelman rubin and geweke were used stock and semmens 2016 after checking the isospace plot the estimated median 50 quantiles ratio was regarded as the contribution of the potential water sources to two plant species to reduce experimental error and improve calculation accuracy in this study the model was used to investigate the δ2h and δ18o values of five potential xylem water sources 0 10 10 20 20 30 30 40 and 40 50 cm deng et al 2021 3 results 3 1 site environmental conditions 3 1 1 meteorological characteristics the daily relative humidity rh was 40 and rh 70 was observed for 280 days every year fig 2 a the average rainfall accounted for 92 85 1822 25 mm during the wet season and 7 15 140 25 mm during the dry season fig 2b besides light rain 10 mm day 1 was observed for nearly 60 of all precipitation days but the heavy rain 25 49 9 mm day 1 and the storm rain 50 99 9 mm day 1 contributed to 59 of average annual precipitation the daily net radiation shows significant seasonal variations and peaked at 180 w m 2 around june july then rapidly decreased to 30 w m 2 at december january fig 2b meanwhile the daily net radiation was highly variable ranging from 5 w m 2 during winter to 180 w m 2 during summer the dynamic of the air temperature was influenced distinctly by the net radiation with seasonal nature fig 2a the average temperature was 27 2 in the wet season from april to october and 18 6 in the dry season from november to march the annual average temperature in 2017 24 01 and 2018 23 45 was close with the lowest temperature in january 7 53 and the highest in june 32 26 3 1 2 soil water content the soil water content swc also showed a significant seasonal trend fig 3 a and was significantly higher in the wet season than in the dry season the average swc for 0 50 cm was 17 from november to april and it was 27 from may to october moreover from may to october the highest swc was 10 cm and the lowest was 20 cm in particular the soil water content of the 20 cm layer was significantly less than other soil layers during the studies periods and its swc ranged from 0 05 to 0 25 fig 3a it is obvious that the swc of the 15 25 cm layer was smaller than other soil layers especially in the dry season fig 3b to further explore the permeability of various soil layers the coefficient of variation cv of swc was used the cv of swc in the 0 15 cm layer was much larger than that in the 15 25 cm layer during the period of low swc which occurred from november to april furthermore the cv of swc in 0 15 cm and 25 50 cm layers were often smaller than that in the other layers during the period of high soil water content the cv of swc in the 0 15 cm layer was significantly lower than that in the 15 25 cm layer from april to november in general the cv of swc in the 15 25 cm layer showed the most considerable change compared with that in the other depths implying that the 20 25 cm soil layer is a discontinuous and weak permeable layer in the urban greenspace 3 2 isotopic compositions and variation of the soil and xylem water 3 2 1 isotopic compositions of precipitation soil water and xylem water during the study period we collected precipitation samples from each precipitation event and found that the δ18o of precipitation ranged from 14 00 to 0 51 with a mean value of 6 24 and the δ2h of precipitation ranged from 100 00 to 1 40 with a mean value of 40 92 the local meteoric water line lmwl δ2h 7 48 δ18o 5 81 r2 0 96 n 131 was then obtained and the intercept and slope were both lower than those of the global meteoric water line gmwl δ2h 8δ18o 10 fig 4 the soil water isotopic values fluctuated greatly during the sampling periods ranging from 11 00 to 0 23 with a mean value of 5 62 for δ18o and from 15 00 to 85 00 with a mean value of 44 06 for δ2h the δ2h and δ18o values of soil water and xylem water were both below the lmwl fig 4 indicating that due to evaporation throughout the raindrop process soil water had varying degrees of fractionation for isotopic compositions the isotopic values in xylem water varied among plant species fig 4 the isotopes value in xylem water of f concinna ranged from 9 40 to 2 90 averagely 5 82 for δ18o and from 67 90 to 22 60 averagely 43 94 for δ2h and the isotopic values in xylem water of l vicaryi ranged from 8 25 to 4 14 averagely 5 80 for δ18o and from 55 99 to 37 04 averagely 46 95 for δ2h although the variation in isotopic values was smaller in xylem water than in soil water 3 2 2 isotopic variation in dry and wet seasons table 1 shows the mean standard error sd maximum max and minimum min isotopic composition for soil water precipitation and xylem water during the dry and wet seasons the line fitting between δ2h and δ18o in precipitation are δ2h 7 44 δ18o 5 42 r2 0 96 n 123 p 0 001 and δ2h 8 23 δ18o 11 12 r2 0 98 n 8 p 0 001 in the wet and dry season respectively fig 4 all stable isotopes of soil water both fall to the right side of the lmwl and the line fitting between δ2h and δ18o in soil water are δ2h 6 30 δ18o 8 64 r2 0 94 n 450 p 0 001 and δ2h 5 35 δ18o 14 12 r2 0 93 n 65 p 0 001 in the wet and dry season respectively which is caused by greater impact of evaporation on soil water in the dry season than in the wet season the stable isotopes of xylem water of f concinna xylem and l vicaryi fall around the fitting line of soil water the line fitting between δ2h and δ18o in f concinna xylem water are δ2h 7 35 δ18o 1 08 r2 0 92 n 92 p 0 001 and δ2h 6 77 δ18o 5 15 r2 0 94 n 13 p 0 001 in the wet and dry seasons respectively the line fitting between δ2h and δ18o in l vicaryi xylem water are δ2h 6 54 δ18o 9 71 r2 0 90 n 17 p 0 005 and δ2h 5 75 δ18o 10 38 r2 0 65 n 7 p 0 05 in wet and dry season respectively indicating that the xylem water of f concinna and l vicaryi originates from soil water 3 3 variations in the contribution to potential water sources of f concinna and l vicaryi as shown in fig 6 a and b the mixsiar method shows that f concinna absorbs mostly the surface soil water from 0 to 20 cm at mean values of 49 06 and 42 26 respectively and it absorbs the least soil water from 30 to 40 cm at 15 76 and 18 14 for δ2h and δ18o respectively in particular the contributions of potential water sources for f concinna based on δ2h fig 6a and δ18o fig 6b both indicate that the shallower layer 0 20 cm was the most important source 56 29 from april to september but the soil at 30 50 cm layer was the most important source 41 13 from october to december moreover the water sources of f concinna gradually turned from shallow soil water to deeper soil water these findings indicate that the potential water sources for f concinna have significant seasonal variability during the study period fig 6c and 6d indicate the contributions of potential water sources for l vicaryi as determined by the mixsiar model the results generally showed that l vicaryi absorbed mostly the surface soil water from 0 to 10 cm at mean values of 30 81 and 32 73 respectively and absorbed the least soil water from 30 to 40 cm at mean values of 15 17 and 13 70 for δ2h and δ18o respectively specifically the results of the mixsiar method based on δ2h fig 6c demonstrated that the surface soil water from 0 to 20 cm stably made the highest contribution with an average of 48 28 during the study period from july to december however the water from the 30 50 cm layer fluctuated significantly and peaked at 65 25 in november it averaged 49 09 in the wet season from july to september and increased to an average of 54 21 in the dry season from october to december in comparison the results of the mixsiar method based on δ 18o fig 6d shows that l vicaryi mainly relied on the 0 20 cm average of 48 28 shallower soil during the study period and the water contribution from the 40 50 cm soil layer also gradually increased 3 4 effect of rainfall events on the contribution to potential water sources of f concinna and l vicaryi to explore the response of water sources to the different rainfall events in urban greenspace the changes in the contribution of potential water sources before and after a torrential rain event precipitation range from 100 mm to 249 9 mm during 24 h in the wet season and a heavy rain event precipitation range from 25 mm to 49 9 mm during 24 h in the dry season were studied 3 4 1 variations in plants potential water sources after torrential rainfall event a typhoon named mangkhut dumped torrential rainfall 173 5 mm on september 16 and storm rain 52 0 mm on september 17 fig 7 in the wet season the highest precipitation was observed on the 16th from morning to night and the wind and rain diminished during the day on the 17th until early morning on the 18th with no precipitation between the 19th and 21st in this study the proportion of plant water uptake during september 11 14 and september 15 18 were regarded as potential water source contributions before and after the rain event respectively besides there was 1 5 mm 0 1 mm and 7 2 mm light rain of precipitation on september 13 15 and 18 respectively fig 7 shows the effect of the torrential rain event on the water uptake from all layers 0 10 cm 10 20 cm 20 30 cm 30 40 cm and 40 50 cm for f concinna and l vicaryi in the wet season before the torrential rain all layers contributed equally to f concinna water uptake fig 7a ranging from 18 30 to 23 80 on september 11 with the biggest contributions coming from the 40 50 cm layer 23 80 within 1 day after the light rain events the variance in the contribution from 0 to 20 cm layer was 0 5 showing that the contribution of surface soil was hardly affected by the light rain on september 14 however the 15 91 increase from 42 10 to 48 80 in the contribution from the 30 50 cm layer suggests the considerable influence of the little rain within 1 day after the torrential rain and storm rain events the contribution of all the layers became close ranging from 15 20 to 22 10 on september 18 possibly due to soil washing caused by a large amount of rain 225 50 mm three days after rain the most significant change was in the contribution of the 40 50 cm layer soil which increased from 15 90 to 37 70 for l vicaryi the contribution of 0 10 cm layer soil water changed from 23 30 on september 11 to 37 20 on september 14 after a light rain fig 7b demonstrating that the surface soil water contribution was prominently influenced by the light rain within 1 day after the torrential rain and storm rain events the contribution of the 30 50 cm layer soil water reached 62 7 on september 18 suggesting that the main contribution of l vicaryi water uptake was converted into 30 50 cm layer soil water after the torrential rain following three days after rain the contribution of the 0 20 cm layer soil water grew quickly to 49 60 on september 21 and nearly returned to the level it was on september 14 the variation in l vicaryi water uptake before and after rainfall events is consistent with the results of previous studies sekiya and yano 2002 zegada lizarazu et al 2007 yang et al 2015 yang et al 2018 indicating that plant water sources always respond to irrigation or excessive rainfall in general the potential water sources of f concinna and l vicaryi were dramatically different in response to rainfall events during the wet season the potential water source for f concinna was mainly the 30 50 cm layer soil water before the rainfall with equal contribution from all layers after a massive rainfall three days after rainfall it returned to its previous level before the massive rainfall the potential water source for l vicaryi was primarily the 0 20 cm layer before the rainfall and the contribution by the 0 10 cm layer was considerably affected by the light rain the source changed to the 30 50 cm layer after the rainfall and after 3 days the 0 20 cm layer soil layer became the main source by comparison the impact of a rainfall event on the supply of water by surface soil for l vicaryi was greater than for f concinna 3 4 2 variations in plants potential water sources after heavy rainfall event a continuous rain event with an intensity of 23 6 mm moderate rain and 25 8 mm heavy rain occurred on november 25 and 26 respectively in the dry season fig 8 there was also 0 9 mm 6 5 mm 0 1 mm and 0 1 mm light rain of precipitation on november 27 28 and 29 and december 7 respectively with no precipitation on december 10 14 in this study the proportion of plant water uptake on the 10th and 24th of september was treated as the potential water sources contribution before the rain event and that on november 30 and december 7 and 14 were treated as a contribution after the rain event fig 8 shows the effect of the heavy rain event on the water uptake from all layers 0 10 cm 10 20 cm 20 30 cm 30 40 cm and 40 50 cm for f concinna and l vicaryi in the dry season in the dry season the main contribution to f concinna water uptake came from the 30 50 cm layer soil 42 during the before rain period fig 8a and the contribution of the 40 50 cm layer soil water increased from 13 40 to 22 70 from november 10 to 24 a day after the heavy rain the contribution of the 30 50 cm layer soil increased quickly reaching 68 90 on november 30 and dropping rapidly on december 7 indicating that the main contribution of l vicaryi water uptake was from the 30 50 cm layer after rainfall with the proportion increasing significantly after 11 days of heavy rain it returned to its previous level before the rain furthermore after the rain occurred on december 7 the fluctuation in the contribution from the 0 10 cm layer suggests that light rain had little effect on the surface soil contribution for l vicaryi the highest contribution before the rain event was from the 0 20 cm layer soil at 55 10 on november 10 fig 8b which changed to 47 50 on november 24 while the contribution of the 40 50 cm layer soil increased from 18 40 to 22 80 indicating that the main water source before the rain was surface soil water and the contribution from the 40 50 cm layer soil gradually increased the contribution of the 30 50 cm layer dramatically increased from 36 80 to 50 20 on november 30 1 day after heavy rain eleven days after heavy rain the contribution of the 0 10 cm layer soil increased from 18 60 to 51 70 after the light rain fig 8 on december 7 the contribution then dropped to 28 30 for 0 10 cm layer soil and increased from 12 80 to 38 00 for 30 50 cm layer soil on december 14 generally after heavy rain in the dry season the main contribution changed from surface soil 0 20 cm to deeper soil 30 50 cm and returned to surface soil after 18 days of heavy rain besides the light rain had a major impact on the contribution of surface soil for l vicaryi during the dry season the main water source of f concinna was the deeper soil both before and after the rain event however the contribution from the deeper soil increased significantly immediately after the rain event and after 11 days the soil water returned to the level it was before the rain in comparison the main water source of l vicaryi changed from surface soil to deeper soil as a result of the rain event and after 18 days the source changed back to the level it was before the rain in addition light rain had an impact on the contribution of surface soil to l vicaryi but not on f concinna besides both f concinna and l vicaryi largely used the 30 50 cm layer soil water 42 70 and 38 00 respectively implying that f concinna and l vicaryi compete for deeper soil water 4 discussion 4 1 temporal variation in different water isotopic values the isotopic compositions of precipitation were affected by environmental factors such as air temperature precipitation amounts etc yamanaka et al 2007 froehlich et al 2008 liu et al 2010 2014 there were large differences in precipitation isotopes between the wet and dry seasons table 1 in the study area and the slope of lmwl was respectively 7 44 and 8 23 during wet and dry seasons fig 5 implying that the primary water source for the environment differed greatly between the two seasons similarly the isotopic composition of soil water and xylem water that was affected by the precipitation whether directly or indirectly also show a significant distinction between the dry and wet season fig 5 in addition the plot of δ2h and δ18o for xylem water were mostly located between the lmwl and the swl implying that both xylem water of f concinna and l vicaryi were absorbed from precipitation and soil water yang et al 2015 however the slope gap between lmwl and xwl in the dry season was both greater than that in the wet season fig 5 indicating fractionation had a greater influence on the water sources of f concinna and l vicaryi in the dry season than in the wet season remarkably whether dry season or wet season the slope of xwltree f concinna was higher than that of xwlshrub l vicaryi suggesting that the water source of l vicaryi is more impacted by isotope fractionation than that of f concinna yang et al 2015 however the slope of swl was smaller than that of xwltree and larger than that of xwlshrub in the whole period while the slopes of xwltree and xwlshrub were both larger than that of swl in the dry and wet seasons these differences could imply that the water sources of the f concinna and l vicaryi changed as the wet and dry seasons progressed which is consistent with the previous study deng et al 2021 4 2 differences in water uptake strategy of tree and shrub in urban greenspace our results suggest that the water use strategy of f concinna is different from that of l vicaryi and these strategies can change seasonally in this study the water use strategy of the two plants mainly absorbed the soil water at the 0 20 cm layer during the wet season from march to september during the dry season from july to december f concinna mainly absorbed the soil water at the 30 50 cm layer whereas l vicaryi mainly absorbed the soil water at the 0 20 cm layer previous studies demonstrated that the plant water use pattern is likely related to its root distribution zhao et al 2021 matheny et al 2017 in this study the maximum root systems of f concinna and l vicaryi were both mainly distributed in the shallow layer lv et al 2022 yang et al 2021 li et al 2020 in the greenspace and the root depths were 0 60 cm and 0 50 cm respectively these similarities in rooting depths suggested that the difference in the water sources could be due to contrasting rooting morphologies between the two species vega grau et al 2021 on visual inspection during the sampling collection process f concinna appeared to have several lateral and horizontal roots whereas l vicaryi appeared to have finer roots fig 6a and b exhibit that trees often depended on the deeper layers of water to withstand seasonal droughts which was consistent with the previous studies barbeta et al 2015 otieno et al 2017 the results of many studies showed that some plants species have a dimorphic root system with a zone of lateral roots and the ability to switch water absorption zones between shallower and deeper soil layers when its main water source is unavailable dawson and pate 1996 nie et al 2012 yang et al 2015 which is consistent with the findings of this study wang et al 2009 found that ficus tinctorial which is in the same genus as f concinna absorbed shallower soil water in the dry season and from different layers in the wet season f concinna might also have an extended lateral root system as its water source varies seasonally beyer et al 2018 furthermore the ability to exploit different water sources makes it possible for some plants to survive long periods without rain or to overcome seasonal water shortages yang et al 2011 zencich et al 2002 therefore the ability of f concinna to switch water uptake zones may be related to its dimorphic root system and f concinna showed greater ecological plasticity and seasonal adaptation level to the environment than l vicaryi moreover some soil characteristics might enable plant species to show specific water uptake patterns in a specific environment liu et al 2019 nie et al 2019 2012 rong et al 2011 for instance the shallow soil covered by abundant rock fractures in the karst region results in weak soil water retaining capacity and large percolation capacity which further affects plant water uptake 4 3 water uptake strategy of tree and shrub in response to rainfall events mixsiar demonstrated that the water uptake strategies of f concinna and l vicaryi in response to rainfall events are different and vary following the rainfall events before and after rainfall events the main water source of f concinna was at the deeper soil layer regardless of the season and the amount of precipitation in particular the contribution from other layers after rainfall events increased during the wet season while the deeper soil layer had the same rise during the dry season unlike the tree the main water source for l vicaryi before the rainfall events was the shallower soil layer which changed to a deeper soil layer after rainfall events indicating that the main water source for l vicaryi was more responsive to rainfall events than f concinna a previous study maurel and nacry 2020 reported that water uptake is not only dependent on root growth but also critically influenced by a plant s hydraulics and water excess reduces root hydraulic conductivity in most plant species in our study there was significant subtropical wet and dry season with seasonal change in rainfall resulting in seasonal fluctuation in the availability of soil water deng et al 2021 which indirectly influenced plant water uptake patterns wang et al 2017 besides the water source of f concinna showed no response to increased water in the surface layer after light rainfall events although it exhibited seasonal water uptake plasticity and stronger adaptation which is consistent with the report of quercus alba asbjornsen et al 2008 this may be attributed to the lateral root system of these two species and trees tend to derive water from deeper soil layers wu et al 2016 in contrast the main water source of l vicaryi exhibited a significant response to light rainfall events indicating its main water sources are largely affected by rainfall events patterns as demonstrated in a previous study zhao and wang 2018 l vicaryi was more sensitive to rainfall events compared with f concinna and showed a significant response to increased water in the surface layer after light rainfall events this was consistent with a previous report that the level of water obtainable from each soil layer is determined by the number of fine roots in the plant ellsworth and sternberg 2015 and it has been reported that the root morphology of l vicaryi is characterized by taproot and more dense root hairs schenk and jackson 2005 meanwhile the water use patterns of trees and shrubs have a complementary relationship in the wet season and a competitive relationship for deeper soil in the dry season with or without rain there are two major potential limitations in this study that could be addressed in future research first the study focused on two greening plants water uptake patterns with basing on sampling collection there are therefore subject to limited sample size and plant species that may have influenced our research however the widely distributed native tree f concinna and shrub l vicaryi plant species were selected and the corresponding sample size was two individuals and thirty individuals to avoid the negative influence as much as possible second the contribution proportion of two greening plants potential water source was estimated from the mixsiar model with uncertainties including from multiple sources and discrimination factors nevertheless the mixsiar model s shortcomings cannot be ignored such as insensitivity to possible effects of 2h 1h fractionation barbeta et al 2018 evaristo et al 2017 and sensitivity to the choice of discrimination factors stock et al 2018 therefore it deserves to be further studied in terms of the following aspects this study could explore more plant species and not only one greenspace besides the stable isotope technique can also be coupled with stem relative water content to determine when performing stem water cryogenic extraction chen et al 2020 5 conclusion the stable isotopic method and mixsiar model were employed to assess the season variations of the water uptake strategies of urban tree f concinna and shrub l vicaryi in a megacity s greenspace of subtropical china firstly the isotopic composition of precipitation soil water xylem water and hydrometeorological characteristics shows significant differences between dry and wet seasons secondly f concinna mainly absorbed water from the shallower soil layer 0 20 cm in the wet season and changed to deeper soil water 30 50 cm in the dry season while l vicaryi s didn t show such a seasonal change this was mainly attributed to the dimorphic root system finally l vicaryi absorbed water from the shallower soil layer 0 20 cm before rainfall events and changed into deeper soil water 30 50 cm after rainfall events which showed greater flexibility in response to rainfall events but f concinna didn t exhibit such a response the flexible water uptake patterns of f concinna make it more adaptable to the changeable environment than l vicaryi this study found that the ecological plasticity shown by f concinna regarding its water use pattern can facilitate its adaptation to seasonal drought and other environmental fluctuations and the research results will be significant for urban greening water planning in the megacity credit authorship contribution statement bei wang investigation data curation visualization writing original draft writing review editing chunhua yan writing review editing supervision zhe shi writing review editing jinshan ding writing review editing tengran zhang writing review editing longjun qin guo yu qiu conceptualization methodology resources supervision funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was supported by the science technology and innovation commission of shenzhen municipality jcyj20180504165440088 the authors would like to express their great thanks to elsevier language editing for their efforts to improve the manuscript 
2257,high quality precipitation data are crucial for hydrological analyses water resource management and drought monitoring merging precipitation products from different sensors and algorithms provides more reliable spatial information and can obtain high quality precipitation data to obtain high spatiotemporal resolution precipitation in this study we proposed a method to merge multisource precipitation products by downscaling coarse resolution products geographically weighted regression gwr algorithm and then eliminating biases in individual datasets stacking algorithm and finally merging the bias adjusted precipitation by weighted average the ensemble model output statistics censored shifted gamma emos csg algorithm the multisource precipitation products included the tropical rainfall measuring mission trmm multisatellite precipitation 3b42 in real time tmpa 3b42rt climate precipitation center morphing technique cmorph global satellite mapping of precipitation near real time gsmap nrt and precipitation estimation from remotely sensed information using artificial neural networks persiann products the merging method was applied to the beimiaoji basin from april to october in the 2016 2019 period the precipitation observations at 38 gauges were spatially and randomly divided into two parts 28 gauges were used for the training while the other for the performance evaluations the results showed that 1 the daily merged precipitation product had a better performance than the original satellite products in terms of the six considered statistical indexes with the lowest root mean square error rmse at 4 33 mm and the highest correlation coefficient cc at 0 64 2 the utilized merging method not only increased the spatial resolution to 1 km but also captured more detailed precipitation distribution information and 3 considering the influence of the gauge density the performance of the merged product was still improving after the number of gauge stations exceeds 16 but the improvement was not significant keywords multisatellite precipitation merging stacking emos csg gauge density data availability data will be made available on request 1 introduction precipitation plays an important role in hydrological models zhao et al 2015 flood and drought monitoring breugem et al 2020 and water resource management yang et al 2017 however due to the strong spatiotemporal variability in precipitation and climate change li et al 2021 xie et al 2019 accurately obtaining high quality precipitation information remains a serious challenge precipitation data can be obtained in four ways from gauges weather radar satellites and reanalysis products each of these products has its strengths and weaknesses gauge precipitation information can provide accurate long sequence data but the sparse density of gauges cannot capture the spatiotemporal distribution of precipitation verdin et al 2015 yin et al 2021 weather radar can capture precipitation information at a high spatiotemporal resolution but the resulting precipitation information is subjected to large biases due to the influence of complex terrain and climate conditions wehbe et al 2020 with the rapid development of remote sensing technology satellite products can ensure near global coverage especially in gauge sparse regions chao et al 2018 compared to weather radar the public can freely obtain satellite products such as the tropical rainfall measuring mission trmm multisatellite precipitation analysis tmpa precipitation estimation from remotely sensed information using artificial neural networks persiann integrated multisatellite retrievals for global precipitation measurement imerg and climate precipitation center morphing technique cmorph products duan et al 2016 xiao et al 2022 gao et al 2020 sui et al 2020 however the accuracy of satellite derived precipitation information is highly constrained by the utilized retrieval algorithm cloud properties and sensors chen et al 2020 reanalysis products e g the european centre for medium range weather forecasts ecmwf reanalysis v5 product era5 tarek et al 2020 ma et al 2022b that combine ground and high altitude observation data with historical atmospheric results through data assimilation techniques can provide high spatiotemporal resolution historical datasets with continuous long term series but systematic error may constrain the performances of these datasets to improve the accuracy of precipitation estimates and obtain realistic spatial distribution characteristics merging precipitation datasets from different sources has become a common approach over the past few decades beck et al 2017 xu et al 2020 traditional precipitation merging methods can be divided into three categories spatial interpolation bias correction and weighted average zhu et al 2022 spatial interpolation methods mainly include kriging with external drift goudenhoofdt and delobbe 2009 and the optimal interpolation technique xie and xiong 2011 bias correction methods mainly include the daily spatio temporal disaggregation calibration algorithm dstdca ma et al 2020b and the mean bias correction nerini et al 2015 for instance ma et al 2020b introduced the dstdca algorithm to calibrate the gpm era imerg at a daily scale and produced a new asian precipitation dataset aimerg weighted average methods mainly include the dynamic clustered bayesian model averaging dcba rahman et al 2020a ma et al 2018a weighted average least square wals rahman et al 2020b generalized three cornered hat tch xu et al 2020 the triple collocation tc lyu et al 2021 and morphology based adaptive spatio temporal merging algorithm mastma zhu et al 2022 for example zhu et al 2022 introduced the morphology theory to comprehensively consider the influences from both rain events and rain rates and allocated the spatiotemporal merging weights according to the precipitation reliabilities from multisources i e cpc u gsmap mvk imerg lr and era5 land in addition to the above traditional merging methods machine learning ml algorithms which have the advantages of strong self learning abilities and can deal with nonlinear problems have been widely used in precipitation merging common algorithms include random forest rf support vector machine svm artificial neural network ann and extreme gradient boosting xgb algorithms zhang et al 2021 developed a novel double machine learning dml method to merge four satellite products with gauge observations based on rf ann svm and extreme learning machine elm methods and then compared the performances of these different ml algorithms wu et al 2020 employed a convolutional neural network cnn and long short term memory network lstm to obtain high spatiotemporal resolution precipitation data in china by merging a trmm 3b42 v7 satellite product with gauge data overall it is feasible to filter out the best algorithm from a variety of ml algorithms or adopt a new algorithm for merging though great efforts have been made to merge multi source precipitation products there are still some limitations firstly the relatively coarse resolution products are not sufficient for hydrological or meteorological applications especially for distributed hydrological models statistical downscaling is an effective way to solve the problem and common methods include gwr geographically moving window weight disaggregation analysis gmwwda and cnn chen et al 2020 ma et al 2018b ma et al 2020a pan et al 2019 among them the gwr method can reflect the spatial nonstationary relationships between precipitation and its influencing factors and be widely used for precipitation downscaling secondly the performance of ml algorithms may vary with the dataset types and research basin no algorithm has been shown to be superior to all others in every situation stacking is an integrated machine learning technology that can couple the advantages of multiple machine learning algorithms and there are few applications in merging multisource precipitation zandi et al 2022 thirdly due to the continuous and discrete nature of precipitation it is difficult to find a suitable parameter distribution for zero precipitation making precipitation more complex to merge than temperature and wind speed the emos csg method can describe zero and positive precipitation by constructing a censored shifted gamma function which is more suitable for the skewed distribution characteristics of precipitation in addition the method effectively utilizes the information of multi model integration and can be used to merge multisource precipitation therefore we proposed a merging method to integrate four satellite precipitation products by adopting gwr stacking and emos csg algorithms gwr was used to downscale the satellite products then the stacking was used to eliminate biases in individual downscaled satellite products finally the emos csg algorithm was used to merge the four bias adjusted satellite products the proposed method was then adopted to evaluate the product merging performance in the beimiaoji basin during the 2016 2019 period from april to october each year using six statistical indexes in addition we tried to assess the impact of the gauge density on the resulting merged products 2 study area and data the beimiaoji basin is located in the upper reaches of the huaihe river and has an area of 1711 km2 the topography of this basin transitions from high mountains in the south to hilly areas in the north the basin is located in a transitional zone from a subtropical climate to a temperate monsoon climate and the average annual rainfall exceeds 1000 mm most precipitation is mainly concentrated in summer due to the influence of weather systems and topography precipitation is unevenly distributed in space a ground network of 38 gauges with available data from april to october in the 2016 2019 period was utilized in this study this network provided daily precipitation observations and was considered to provide true values for this merging research among these stations those denoted by green dots in fig 1 were used for training and those indicated with red five pointed stars were used for testing fig 1 four satellite products covering quasiglobal precipitation were used in this study the tmpa 3b42 in real time tmpa 3b42rt product was merged with multichannel microwave and infrared ir data from all available satellites to produce optimal satellite precipitation estimates huffman et al 2007 choubin et al 2019 cmorph was developed by using ir imagery to create motion vectors then the cloud motion vectors were applied to passive microwave pmw data to generate global precipitation information joyce et al 2004 the global satellite mapping of precipitation gsmap group was devoted to producing precipitation datasets with high precision kubota et al 2007 the near real time product gsmap nrt produced by this group adopted a forward only cloud advection technique and a kalman filter to generate precipitation qi et al 2021 persiann was generated through the use of artificial neural networks anns to obtain rainfall rates from longwave ir brightness temperature images and parameters updated through pmw observations nguyen et al 2019 ashouri et al 2015 ren et al 2018 due to the inconsistent temporal resolutions among these four satellite products the hourly precipitation information was averaged to the daily scale for the subsequent merging research the spatiotemporal resolutions and data sources of the four satellite precipitation products can be found in table 1 in addition to satellite products topographic and meteorological variables closely related to precipitation were used in this study normalized difference vegetation index ndvi information was obtained from the mod13a3 dataset of the national aeronautics and space administration nasa soil moisture came from the soil moisture active passive smap dataset of nasa the digital elevation model dem dataset was downloaded from the geospatial data cloud of china and arcgis software was used to further extract topographic variables such as the latitude longitude elevation slope and aspect considering that there were no weather stations in the analyzed basin meteorological variables such as temperature atmospheric pressure wind speed and direction data were obtained from the era5 land reanalysis dataset of the european centre for medium range weather forecasts ecmwc soil moisture and meteorological variables with observation intervals shorter than 1 day were averaged to the daily scale the above variables were resampled to the same spatial resolutions with the bilinear interpolation technique 3 methods a flowchart elucidating the merging method was presented in fig 2 this method was mainly divided into two processes downscaling and merging the downscaling process was used to get the 1 km resolution satellite precipitation by the geographically weighted regression gwr model the merging process was divided into three steps in the first step six base learners of stacking algorithm were adopted to correct the bias in four satellite downscaled products i e tmpa 3b42rt1 cmorph1 gsmap nrt1 and persiann1 each downscaled product produced six different correction results in the second step the corresponding six correction results were integrated by a secondary learner in the stacking algorithm for each product and we could get the bias adjusted precipitation in the third step we merged the four bias adjusted results i e tmpa 3b42rt2 cmorph2 gsmap nrt2 and persiann2 using the emos csg algorithm and produced a final precipitation dataset at the daily 1 km spatiotemporal resolution 3 1 geographically weighted regression gwr the gwr model developed by brunsdon et al 1996 is a typical local multiple regression analysis method this gwr method not only can effectively describe the spatial heterogeneity of dependent variables by calculating the spatial weights of adjacent points and local regression coefficients but also comprehensively considers the spatial autocorrelation of dependent variables and the correlation between dependent variables and explanatory variables wang et al 2022 therefore we adopted the method to downscale the four original satellite products the gwr method can be expressed as followed 1 y i a i 0 k 1 n a ik x ik ε i where y i is the dependent variable at location i ε i is the residual a i 0 is the constant regression coefficient at location i a ik is the k t h constant regression coefficient at location i x ik is the k t h explanatory variable at location i n is the number of explanatory variables a i 0 and a ik can be estimated as follows 2 a i x t w i x 1 x t w i y where x is the explanatory variable matrix w i is the diagonal weights matrix for prediction location i y is the vector of the dependent variable longitude latitude ndvi elevation slope and aspect which are closely related to rainfall were selected as explanatory variables considering that vegetation can affect precipitation by changing the temperature and moisture of the air in the growing season ndvi can be used to downscale precipitation on a monthly time scale xu et al 2015 therefore we first build the gwr model based on formula 1 to downscale the monthly satellite precipitation and then disaggregate the downscaled satellite monthly precipitation into daily precipitation through their proportional relationship given the limited space the specific operation steps can be found in chen et al 2020 3 2 stacking algorithm stacking algorithm is a multimodel fusion technology that is commonly used in the field of machine learning the algorithm is essentially a two layer model breiman 1996 sun and trevor 2018 compared with traditional machine learning models the stacking method can not only exploit the potential of machine learning sub models but also perform better than all individual base models particularly the stacking structure is flexible and can be incorporated into more advanced machine learning algorithms therefore we adopt the method to merge the downscaled precipitation as the core of the stacking algorithm base learners machine learning algorithms play an important role in precipitation merging and each learner has its own advantages rf algorithm with has high computational efficiencies and low costs can effectively solve the problem of overfitting breiman 2001 k nearest neighborhood knn algorithm is more effective in dealing with sample datasets with unbalanced spatial distributions hart 1968 xgb algorithm which has strong generalization abilities and extensive portability characteristics is commonly used in data science competitions e g kaggle chen and guestrin 2016 light gradient boosting lgb algorithm can handle missing values with high precision fast convergence and parallel computing performances ke et al 2017 categorical boosting catboost algorithm can overcome model overfitting and handle categorical features huang et al 2019 gradient boosting machine gbm algorithm is based on decision trees and has the advantage of strong robustness friedman 2001 since latitude longitude elevation slope and aspect information are time invariant using them as explanatory variables will result in data redundancy and decreases the merging skill therefore meteorological variables i e temperature atmospheric pressure and wind speed and direction and soil moisture variables which change over time are selected as explanatory variables in this study considering the importance of spatial location information latitude and longitude are also used to the explanatory variables we select the persiann satellite product as an example to illustrate the calibration procedure of the stacking model and the main steps are shown as follows 1 base learner calibration for base learners the explanatory variables also include downscaled satellite derived precipitation persiann1 1 km the output variable is the gauge precipitation since the true precipitation is based on the gauge scale 28 gauges dataset are used for building and training 6 base learner models and 10 gauges dataset are used for testing after obtaining the best model parameters all grid 1719 explanatory variables with the 1 km spatial resolution are used as input of different base learner models to obtain the corrected precipitation 1 km 2 secondary learner calibration rf is regarded as the secondly learner and the corrected precipitation by the base learners is taken as the model input similar to the previous step precipitation at the 28 gauge points is used for training and precipitation at 10 gauge points is used for testing the design of the second step is to decrease the uncertainty of a single machine learning algorithm and get the bias adjusted precipitation 3 the remaining three downscaled satellite products can get the bias adjusted precipitation by repeating steps 1 and 2 3 3 emos csg algorithm gneiting et al 2005 proposed the ensemble model output statistics emos method in 2005 this method is also known as nonhomogeneous regression based on the emos method the distribution function of rainfall can be fitted by introducing a censored shifted gamma csg function to perform a postprocessing rainfall correction baran and nemoda 2016 javanshiri et al 2021 compared with the emos method the emos csg method can capture the skewed distribution characteristics of precipitation by constructing a censored shifted gamma function and then we can adopt a unified distribution function to describe zero precipitation and positive precipitation in addition the method can fully consider the performance difference of a single model and effectively utilize the information of multi model integration based on the above advantages we introduced this method into the precipitation merging process the probability density function pdf of the original gamma distribution can be expressed as follows 3 g k θ x x k 1 e x p x θ θ k γ k x 0 0 x 0 where γ k represents the value of the gamma function at k the conversion relationships among the shape k scale θ mean μ and variance σ 2 values of the gamma distribution can be expressed as follows 4 k μ 2 σ 2 θ σ 2 μ the mean and variance in the gamma distribution and in each satellite precipitation member f 1 f n are connected as follows 5 μ a 0 a 1 f 1 a n f n σ 2 b 0 b 1 f where f refers to the mean value of the satellite precipitation members a 0 a n denote the mean parameter values and b 0 and b 1 represent the variance parameters which can be calculated using the continuous ranked probability score crps gneiting and raftery 2007 the cumulative distribution function g k θ δ 0 of the csg can be expressed as follows 6 g k θ δ 0 x g k θ x δ x 0 0 x 0 where g k θ x δ is the cumulative distribution function of the original gamma distribution and δ indicates the offset to the left the pdf g k θ δ 0 can be estimated as follows 7 g k θ δ 0 x π x 0 g k θ δ π x 0 1 g k θ δ g k θ x δ where π a denotes an indicator function of a and if a 1 π x 0 1 otherwise π x 0 1 then the mean λ of csg can be calculated as follows 8 λ θ k 1 g k θ δ 1 g k 1 θ δ δ 1 g k θ δ 2 the quantile q p of p in formula 6 is equal to 0 if p g k θ δ otherwise q p can be calculated by g k θ q p δ p the main steps of the emos csg are shown as follows 1 based on the four bias adjusted satellite precipitation the gamma distribution parameters of k and θ can be obtained by formulas 4 and 5 in addition we calibrate the parameter of δ by minimizing crps as the objective function the calibrated parameters can link the pdf of satellite precipitation with the pdf of gauge precipitation and then can calibrate the satellite precipitation to the gauge value effectively eliminating the underestimation or overestimation of satellite precipitation furthermore after parameter optimization each satellite product obtains an optimal weight coefficient and the larger the weight coefficient the greater the contribution of the product to the final merging precipitation 2 after obtaining these three parameters we can determine the conditional distribution of precipitation and then we can get the corrected mean precipitation by formula 8 considering that emos csg is calculated in grid units the sparse rain gauge network is interpolated to 1 km grids using ordinary kriging then we obtain daily merged precipitation datasets at a 1 km spatial resolution by merging the stacked results i e tmpa 3b42rt2 cmorph2 gsmap nrt2 and persiann2 3 4 evaluation index to quantitatively evaluate the performance of the proposed merging method the dataset from 38 rain gauges was spatially and randomly divided into training and test sets 28 rain gauges were used for the training 10 rain gauges were used to evaluate the final merging precipitation in the result section particularly in the process of randomly selecting gauge stations we tried to make the test gauge stations evenly distributed fig 1 so that the validation results could truly reflect the overall merging performance of the watershed to evaluate the performance of the merging results six statistical indexes were selected including the root mean square error rmse correlation coefficient cc mean absolute error mae probability of detection pod false alarm ratio far and critical success index csi these indexes were calculated as follows 9 rmse i 1 n p i o i 2 n 10 cc i 1 n p i p o i o i 1 n p i p 2 i 1 n o i o 2 11 mae i 1 n p i o i n 12 pod n 11 n 11 n 01 13 far n 10 n 11 n 10 14 csi n 11 n 11 n 10 n 01 where p i and o i represent the satellite and gauge derived precipitation totals at the i t h point respectively p and o denote the average satellite and gauge derived precipitation totals respectively n is the number of samples n 11 represents the number of times that both the gauge and satellite detected rainfall n 10 denotes the number of times that only the satellite rather than the gauge detected rainfall and n 01 is the number of times that only the gauge rather than the satellite detected rainfall if the rmse mae and far values are close to 0 and the cc pod and csi values are close to 1 the merging effect is better it is informative to note that a scatter plot should be used to determine whether the dot pitch is distributed around the 45 line when the cc is adopted as a statistical index in order to discover whether the considered satellites provide systematically overestimated or underestimated data 4 results and discussion 4 1 performance of original and downscaled satellite precipitation products due to the influence of the analyzed terrain retrieval algorithms and sensors the accuracies of different satellite products may be different table 2 summarizes the evaluation statistics for the test set obtained from the original and downscaled satellite precipitation products we found that the rmse mae pod far and sci values of the four original satellite products did not differ extensively the persiann product had the lowest cc of 0 13 compared to the other three products and the tmpa 3b42rt product had the lowest pod csi value of 0 63 0 55 overall the performances of the four satellite products revealed little differences within the analyzed basin and no single product was significantly better than the other products this finding was consistent with the research results reported by mei et al 2014 and sun et al 2018 compared to the original products the accuracies of the downscaled products were improved but these improvements were not obvious this result was related to the necessary residual correction step in the downscaling process the objective function of the residual correction process was the satellite products instead of the gauges leading to the limited accuracy improvements furthermore the smaller cc 0 18 0 25 and larger rmse 12 03 12 47 mm values obtained indicated that substantial errors existed in the original and downscaled satellite precipitation products thus it was necessary to integrate gauge information to reduce these deviations 4 2 performance assessments of merging products to test the effectiveness of the utilized merging method we evaluated the accuracy of the analyzed satellite products at three different stages during the merging process the evaluation statistics are listed in table 3 only for test set first base learners machine learning algorithms significantly improved the satellite derived precipitation accuracy for instance when ml algorithms were used the maes decreased to 3 55 5 08 mm at a decreasing rate of 50 67 compared to the downscaled products the rmses decreased to 4 78 6 40 mm by 47 62 the ccs improved to 0 44 0 60 and the pods csis increased to 0 77 0 87 0 69 0 79 all the above results demonstrated that ml algorithms could effectively reduce biases in satellite derived precipitation products among the six ml algorithms lgb performed the best overall providing the highest cc of 0 60 and the lowest mae of 3 55 mm followed by catboost xgb rf knn and gbm furthermore the three best performing ml algorithms were all based on the improved gradient boosting tree algorithm indicating that these algorithms have certain advantages for merging precipitation in the analyzed basin after the first merging step a secondary learner of stacking algorithm was employed to integrate the six ml results this learner provided better scores than any of the ml algorithms discussed above in addition persiann showed the best performance among the four satellite products with the highest cc pod at 0 62 0 90 and the smallest mae and rmse values at 3 31 and 4 53 mm respectively in terms of the correction effect the stacking algorithm greatly decreased the bias in the results and avoided the uncertainty caused by using a single algorithm additionally the secondary learner integrated the advantages of the base learners and generated better correction results furthermore the accuracy of the final merging product obtained by the third stage emos csg method was further improved compared to the stacking results the above results demonstrated that the multisatellite precipitation merging method based on stacking and emos csg was effective and feasible as they are the core of the precipitation merging method the utilized ml algorithms must effectively decrease the bias in satellite derived precipitation products in this work we also attempted to use other ml algorithms including decision tree support vector machine svm logistic regression extreme learning machine elm and back propagation bp network finally the machine learning methods with the best merging effects among the methods listed above were selected as the base learners in the stacking algorithm in terms of the algorithm structure the stacking and emos csg processes integrated different datasets through weight optimization processes in the stacking process weights were assigned to six machine learning results while the emos csg method applied weights to the four satellite products i e tmpa 3b42rt2 cmorph2 gsmap nrt2 and persiann2 fig 3 displays the weights of the six machine learning algorithms applied to each product in the secondary learner step the lgb algorithm accounted for the largest weights over 23 for each product followed by the catboost 20 22 xgb 16 20 rf 16 18 knn 13 15 and gbm 3 4 algorithms these results were consistent with the machine learning correction performance observed during the first merging stage table 3 in addition to evaluate the sensitivities of topographic and meteorological variables to the base learner we estimated the relative weight of each variable using an rf as an example as shown in fig 4 all variables contributed valuable information the satellite derived precipitation variable accounted for the highest weight indicating that this variable provided useful information for the precipitation merging process temperature had the second highest weight this may have been related to the strong response of precipitation to temperature the wind speed and direction may cause changes in atmospheric moisture and the soil moisture signature can last a few hours to several days after a rain event maggioni and massari 2018 thus these variables showed similar performances in the rf algorithm although latitude and longitude provide important spatial location information these variables have the characteristics of not changing with time causing them to show the lowest weights in the precipitation merging process overall the final merging result has been greatly improved compared to the original satellite products for the following reasons firstly base learners greatly reduce the bias of downscaling satellite products by introducing meteorological factors as the explanatory variables secondly the secondly learner rf can integrate the advantages of the base learners and improve upon the generalization accuracy of the base learners by assigning weights thirdly the emos csg model can consider the performance difference of a single bias adjusted satellite product and assign a higher weight to a superior product which further improves the performance of the merging results furthermore the flexible merging framework described herein can not only select new ml algorithms e g lstm as the base learners in the stacking process but can also add other satellite products e g imerg fy4qpe msa and peca fy4a zhu et al 2021 ma et al 2022a zhu and ma 2022 and datasets from different sources e g reanalysis or weather radar datasets to capture more rainfall information 4 3 assessment of the spatial distribution of precipitation fig 5 presents the spatial distributions of the downscaled satellite derived products and the final merging product on june 20 2017 fig 6 displays the corresponding scatter plots according to the ribbon at the bottom of fig 5 the precipitation totals of tmpa 3b42rt cmorph gsmap nrt persiann and the gauge network were mainly 16 40 mm 32 64 mm 48 80 mm 10 45 mm and 100 220 mm respectively these values indicated that the four downscaled satellite precipitation products had obvious underestimations and large systematic errors the same conclusion can be obtained from fig 6a d where the dot pitches of the corresponding scatter plots were below the 45 line after merging the four satellite products the underestimation and mutation of the precipitation were significantly improved the cc of the final merging product increased to 0 94 and the dot pitch was evenly distributed around the 45 line fig 6e in addition the distribution of the merged precipitation product was consistent with that of the gauge observations especially in the southern and central parts of the analyzed basin fig 5e f this comparison further illustrated that the merging method had a good performance when estimating the spatial characteristics of precipitation 4 4 sensitivity analysis of the gauge density the gauge density not only has an impact on the spatial pattern of the merged results but also affects the local deviation adjustment of satellite derived precipitation products wang and lin 2015 bai et al 2019 nerini et al 2015 in this study the number of gauge stations in the training dataset was randomly reduced to 24 20 16 12 8 and 4 while the test dataset remained unchanged then we repeated the merging method with these different training dataset sizes and analyzed the gauge density sensitivity fig 7 plots the change trends of the six analyzed statistical indexes under different gauge densities as the gauge station density increased the quality of the merged precipitation product improved particularly the increasing performance trend of the merged product began to significantly slow down when the number of gauges reached 16 stations for example when the gauge stations increased from 4 to 16 the rmse mae far decreased by 2 25 mm 1 72 mm 0 05 in contrast the rmse mae far decreased by only 0 33 mm 0 20 mm 0 005 when the number of stations increased from 16 to 28 fig 7a 7c 7e these significant discrepancies indicated that after the number of gauge stations exceeds 16 in beimiaoji basin further increasing the density of station network can improve the merged product performance but the improvement effect was not significant 4 5 discussion despite the optimal performance of the merging method some limitations in the process still require further study first we selected some topographic and meteorological variables as the explanatory variables in the gwr and ml algorithms according to previous studies however the rationality of these explanatory variables and the introduction of other new variables e g cloud properties sharifi et al 2019 require further analyses for example the introduction of the satellite derived soil moisture variable may have generated increased uncertainty due to the systematic errors present in soil products second the four satellite products considered in this study adopted space borne sensors that use inversion algorithms to obtain precipitation information while the reanalysis datasets e g era5 xu et al 2022 were mainly obtained through data assimilation techniques the use of two types of products generated based on different algorithms may result in more reliable precipitation spatial pattern estimates so a reanalysis dataset could be added to the merging method to improve the quality of the merged product third we only preliminarily studied the influence of the rainfall station density on the merging effect considering the small watershed area and relatively dense gauge stations in the study area the gauge density threshold of 16 may not be suitable for other watersheds with sparse stations e g those in western china in addition due to the limited number of stations only 28 stations were adopted to explore the gauge density sensitivity and this value may have impacted the accuracy of the threshold results further efforts are thus needed to explore the gauge density threshold in different basins with more gauge stations 5 conclusions in this study we proposed a method to merge multisatellite precipitation products i e tmpa 3b42rt cmorph gsmap nrt and persiann by downscaling coarse resolution products gwr algorithm and then eliminating biases in individual datasets stacking algorithm and finally merging the bias adjusted precipitation by weighted average emos csg algorithm the merging method was applied to the beimiaoji basin from april to october during the 2016 2019 the key findings of the study are as follows 1 the performance difference of the four original satellite precipitation products is small in terms of the six statistical indexes although the spatial resolution of the satellite products increased to 1 km by the gwr model further calibration procedures are required to reduce bias due to smaller cc 0 18 0 25 and larger rmse 12 03 12 47 2 the merging method could integrate the advantages of multisource precipitation and achieve higher accuracy than original products for example the rmse of final merging precipitation decreased to 4 33 mm and the cc improved to 0 64 compared to the four original satellite products rmse 12 45 mm and cc 0 20 in addition the final merging product showed better spatial consistency with the gauge precipitation 3 the stacking model could wisely integrate the advantages of the base learners and greatly decrease the biases of the downscaled satellite products in addition the emos csg model merged the information of four bias corrected satellite precipitation and further improved the performance of final merging product 4 increasing the gauge density could decrease the bias and improve the performance of the merged precipitation product however the improvement of the merged product performance was not significant after the number of gauge stations surpassed 16 overall the proposed method is a promising and applicable way for the merging of multisource precipitation products further investigations should be carried out to assess the applicability of this method in other watersheds and compare the method with other existing merging methods declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was support by the national natural science foundation of china grant no 41730750 and national natural science foundation of china grant no 41877147 
2257,high quality precipitation data are crucial for hydrological analyses water resource management and drought monitoring merging precipitation products from different sensors and algorithms provides more reliable spatial information and can obtain high quality precipitation data to obtain high spatiotemporal resolution precipitation in this study we proposed a method to merge multisource precipitation products by downscaling coarse resolution products geographically weighted regression gwr algorithm and then eliminating biases in individual datasets stacking algorithm and finally merging the bias adjusted precipitation by weighted average the ensemble model output statistics censored shifted gamma emos csg algorithm the multisource precipitation products included the tropical rainfall measuring mission trmm multisatellite precipitation 3b42 in real time tmpa 3b42rt climate precipitation center morphing technique cmorph global satellite mapping of precipitation near real time gsmap nrt and precipitation estimation from remotely sensed information using artificial neural networks persiann products the merging method was applied to the beimiaoji basin from april to october in the 2016 2019 period the precipitation observations at 38 gauges were spatially and randomly divided into two parts 28 gauges were used for the training while the other for the performance evaluations the results showed that 1 the daily merged precipitation product had a better performance than the original satellite products in terms of the six considered statistical indexes with the lowest root mean square error rmse at 4 33 mm and the highest correlation coefficient cc at 0 64 2 the utilized merging method not only increased the spatial resolution to 1 km but also captured more detailed precipitation distribution information and 3 considering the influence of the gauge density the performance of the merged product was still improving after the number of gauge stations exceeds 16 but the improvement was not significant keywords multisatellite precipitation merging stacking emos csg gauge density data availability data will be made available on request 1 introduction precipitation plays an important role in hydrological models zhao et al 2015 flood and drought monitoring breugem et al 2020 and water resource management yang et al 2017 however due to the strong spatiotemporal variability in precipitation and climate change li et al 2021 xie et al 2019 accurately obtaining high quality precipitation information remains a serious challenge precipitation data can be obtained in four ways from gauges weather radar satellites and reanalysis products each of these products has its strengths and weaknesses gauge precipitation information can provide accurate long sequence data but the sparse density of gauges cannot capture the spatiotemporal distribution of precipitation verdin et al 2015 yin et al 2021 weather radar can capture precipitation information at a high spatiotemporal resolution but the resulting precipitation information is subjected to large biases due to the influence of complex terrain and climate conditions wehbe et al 2020 with the rapid development of remote sensing technology satellite products can ensure near global coverage especially in gauge sparse regions chao et al 2018 compared to weather radar the public can freely obtain satellite products such as the tropical rainfall measuring mission trmm multisatellite precipitation analysis tmpa precipitation estimation from remotely sensed information using artificial neural networks persiann integrated multisatellite retrievals for global precipitation measurement imerg and climate precipitation center morphing technique cmorph products duan et al 2016 xiao et al 2022 gao et al 2020 sui et al 2020 however the accuracy of satellite derived precipitation information is highly constrained by the utilized retrieval algorithm cloud properties and sensors chen et al 2020 reanalysis products e g the european centre for medium range weather forecasts ecmwf reanalysis v5 product era5 tarek et al 2020 ma et al 2022b that combine ground and high altitude observation data with historical atmospheric results through data assimilation techniques can provide high spatiotemporal resolution historical datasets with continuous long term series but systematic error may constrain the performances of these datasets to improve the accuracy of precipitation estimates and obtain realistic spatial distribution characteristics merging precipitation datasets from different sources has become a common approach over the past few decades beck et al 2017 xu et al 2020 traditional precipitation merging methods can be divided into three categories spatial interpolation bias correction and weighted average zhu et al 2022 spatial interpolation methods mainly include kriging with external drift goudenhoofdt and delobbe 2009 and the optimal interpolation technique xie and xiong 2011 bias correction methods mainly include the daily spatio temporal disaggregation calibration algorithm dstdca ma et al 2020b and the mean bias correction nerini et al 2015 for instance ma et al 2020b introduced the dstdca algorithm to calibrate the gpm era imerg at a daily scale and produced a new asian precipitation dataset aimerg weighted average methods mainly include the dynamic clustered bayesian model averaging dcba rahman et al 2020a ma et al 2018a weighted average least square wals rahman et al 2020b generalized three cornered hat tch xu et al 2020 the triple collocation tc lyu et al 2021 and morphology based adaptive spatio temporal merging algorithm mastma zhu et al 2022 for example zhu et al 2022 introduced the morphology theory to comprehensively consider the influences from both rain events and rain rates and allocated the spatiotemporal merging weights according to the precipitation reliabilities from multisources i e cpc u gsmap mvk imerg lr and era5 land in addition to the above traditional merging methods machine learning ml algorithms which have the advantages of strong self learning abilities and can deal with nonlinear problems have been widely used in precipitation merging common algorithms include random forest rf support vector machine svm artificial neural network ann and extreme gradient boosting xgb algorithms zhang et al 2021 developed a novel double machine learning dml method to merge four satellite products with gauge observations based on rf ann svm and extreme learning machine elm methods and then compared the performances of these different ml algorithms wu et al 2020 employed a convolutional neural network cnn and long short term memory network lstm to obtain high spatiotemporal resolution precipitation data in china by merging a trmm 3b42 v7 satellite product with gauge data overall it is feasible to filter out the best algorithm from a variety of ml algorithms or adopt a new algorithm for merging though great efforts have been made to merge multi source precipitation products there are still some limitations firstly the relatively coarse resolution products are not sufficient for hydrological or meteorological applications especially for distributed hydrological models statistical downscaling is an effective way to solve the problem and common methods include gwr geographically moving window weight disaggregation analysis gmwwda and cnn chen et al 2020 ma et al 2018b ma et al 2020a pan et al 2019 among them the gwr method can reflect the spatial nonstationary relationships between precipitation and its influencing factors and be widely used for precipitation downscaling secondly the performance of ml algorithms may vary with the dataset types and research basin no algorithm has been shown to be superior to all others in every situation stacking is an integrated machine learning technology that can couple the advantages of multiple machine learning algorithms and there are few applications in merging multisource precipitation zandi et al 2022 thirdly due to the continuous and discrete nature of precipitation it is difficult to find a suitable parameter distribution for zero precipitation making precipitation more complex to merge than temperature and wind speed the emos csg method can describe zero and positive precipitation by constructing a censored shifted gamma function which is more suitable for the skewed distribution characteristics of precipitation in addition the method effectively utilizes the information of multi model integration and can be used to merge multisource precipitation therefore we proposed a merging method to integrate four satellite precipitation products by adopting gwr stacking and emos csg algorithms gwr was used to downscale the satellite products then the stacking was used to eliminate biases in individual downscaled satellite products finally the emos csg algorithm was used to merge the four bias adjusted satellite products the proposed method was then adopted to evaluate the product merging performance in the beimiaoji basin during the 2016 2019 period from april to october each year using six statistical indexes in addition we tried to assess the impact of the gauge density on the resulting merged products 2 study area and data the beimiaoji basin is located in the upper reaches of the huaihe river and has an area of 1711 km2 the topography of this basin transitions from high mountains in the south to hilly areas in the north the basin is located in a transitional zone from a subtropical climate to a temperate monsoon climate and the average annual rainfall exceeds 1000 mm most precipitation is mainly concentrated in summer due to the influence of weather systems and topography precipitation is unevenly distributed in space a ground network of 38 gauges with available data from april to october in the 2016 2019 period was utilized in this study this network provided daily precipitation observations and was considered to provide true values for this merging research among these stations those denoted by green dots in fig 1 were used for training and those indicated with red five pointed stars were used for testing fig 1 four satellite products covering quasiglobal precipitation were used in this study the tmpa 3b42 in real time tmpa 3b42rt product was merged with multichannel microwave and infrared ir data from all available satellites to produce optimal satellite precipitation estimates huffman et al 2007 choubin et al 2019 cmorph was developed by using ir imagery to create motion vectors then the cloud motion vectors were applied to passive microwave pmw data to generate global precipitation information joyce et al 2004 the global satellite mapping of precipitation gsmap group was devoted to producing precipitation datasets with high precision kubota et al 2007 the near real time product gsmap nrt produced by this group adopted a forward only cloud advection technique and a kalman filter to generate precipitation qi et al 2021 persiann was generated through the use of artificial neural networks anns to obtain rainfall rates from longwave ir brightness temperature images and parameters updated through pmw observations nguyen et al 2019 ashouri et al 2015 ren et al 2018 due to the inconsistent temporal resolutions among these four satellite products the hourly precipitation information was averaged to the daily scale for the subsequent merging research the spatiotemporal resolutions and data sources of the four satellite precipitation products can be found in table 1 in addition to satellite products topographic and meteorological variables closely related to precipitation were used in this study normalized difference vegetation index ndvi information was obtained from the mod13a3 dataset of the national aeronautics and space administration nasa soil moisture came from the soil moisture active passive smap dataset of nasa the digital elevation model dem dataset was downloaded from the geospatial data cloud of china and arcgis software was used to further extract topographic variables such as the latitude longitude elevation slope and aspect considering that there were no weather stations in the analyzed basin meteorological variables such as temperature atmospheric pressure wind speed and direction data were obtained from the era5 land reanalysis dataset of the european centre for medium range weather forecasts ecmwc soil moisture and meteorological variables with observation intervals shorter than 1 day were averaged to the daily scale the above variables were resampled to the same spatial resolutions with the bilinear interpolation technique 3 methods a flowchart elucidating the merging method was presented in fig 2 this method was mainly divided into two processes downscaling and merging the downscaling process was used to get the 1 km resolution satellite precipitation by the geographically weighted regression gwr model the merging process was divided into three steps in the first step six base learners of stacking algorithm were adopted to correct the bias in four satellite downscaled products i e tmpa 3b42rt1 cmorph1 gsmap nrt1 and persiann1 each downscaled product produced six different correction results in the second step the corresponding six correction results were integrated by a secondary learner in the stacking algorithm for each product and we could get the bias adjusted precipitation in the third step we merged the four bias adjusted results i e tmpa 3b42rt2 cmorph2 gsmap nrt2 and persiann2 using the emos csg algorithm and produced a final precipitation dataset at the daily 1 km spatiotemporal resolution 3 1 geographically weighted regression gwr the gwr model developed by brunsdon et al 1996 is a typical local multiple regression analysis method this gwr method not only can effectively describe the spatial heterogeneity of dependent variables by calculating the spatial weights of adjacent points and local regression coefficients but also comprehensively considers the spatial autocorrelation of dependent variables and the correlation between dependent variables and explanatory variables wang et al 2022 therefore we adopted the method to downscale the four original satellite products the gwr method can be expressed as followed 1 y i a i 0 k 1 n a ik x ik ε i where y i is the dependent variable at location i ε i is the residual a i 0 is the constant regression coefficient at location i a ik is the k t h constant regression coefficient at location i x ik is the k t h explanatory variable at location i n is the number of explanatory variables a i 0 and a ik can be estimated as follows 2 a i x t w i x 1 x t w i y where x is the explanatory variable matrix w i is the diagonal weights matrix for prediction location i y is the vector of the dependent variable longitude latitude ndvi elevation slope and aspect which are closely related to rainfall were selected as explanatory variables considering that vegetation can affect precipitation by changing the temperature and moisture of the air in the growing season ndvi can be used to downscale precipitation on a monthly time scale xu et al 2015 therefore we first build the gwr model based on formula 1 to downscale the monthly satellite precipitation and then disaggregate the downscaled satellite monthly precipitation into daily precipitation through their proportional relationship given the limited space the specific operation steps can be found in chen et al 2020 3 2 stacking algorithm stacking algorithm is a multimodel fusion technology that is commonly used in the field of machine learning the algorithm is essentially a two layer model breiman 1996 sun and trevor 2018 compared with traditional machine learning models the stacking method can not only exploit the potential of machine learning sub models but also perform better than all individual base models particularly the stacking structure is flexible and can be incorporated into more advanced machine learning algorithms therefore we adopt the method to merge the downscaled precipitation as the core of the stacking algorithm base learners machine learning algorithms play an important role in precipitation merging and each learner has its own advantages rf algorithm with has high computational efficiencies and low costs can effectively solve the problem of overfitting breiman 2001 k nearest neighborhood knn algorithm is more effective in dealing with sample datasets with unbalanced spatial distributions hart 1968 xgb algorithm which has strong generalization abilities and extensive portability characteristics is commonly used in data science competitions e g kaggle chen and guestrin 2016 light gradient boosting lgb algorithm can handle missing values with high precision fast convergence and parallel computing performances ke et al 2017 categorical boosting catboost algorithm can overcome model overfitting and handle categorical features huang et al 2019 gradient boosting machine gbm algorithm is based on decision trees and has the advantage of strong robustness friedman 2001 since latitude longitude elevation slope and aspect information are time invariant using them as explanatory variables will result in data redundancy and decreases the merging skill therefore meteorological variables i e temperature atmospheric pressure and wind speed and direction and soil moisture variables which change over time are selected as explanatory variables in this study considering the importance of spatial location information latitude and longitude are also used to the explanatory variables we select the persiann satellite product as an example to illustrate the calibration procedure of the stacking model and the main steps are shown as follows 1 base learner calibration for base learners the explanatory variables also include downscaled satellite derived precipitation persiann1 1 km the output variable is the gauge precipitation since the true precipitation is based on the gauge scale 28 gauges dataset are used for building and training 6 base learner models and 10 gauges dataset are used for testing after obtaining the best model parameters all grid 1719 explanatory variables with the 1 km spatial resolution are used as input of different base learner models to obtain the corrected precipitation 1 km 2 secondary learner calibration rf is regarded as the secondly learner and the corrected precipitation by the base learners is taken as the model input similar to the previous step precipitation at the 28 gauge points is used for training and precipitation at 10 gauge points is used for testing the design of the second step is to decrease the uncertainty of a single machine learning algorithm and get the bias adjusted precipitation 3 the remaining three downscaled satellite products can get the bias adjusted precipitation by repeating steps 1 and 2 3 3 emos csg algorithm gneiting et al 2005 proposed the ensemble model output statistics emos method in 2005 this method is also known as nonhomogeneous regression based on the emos method the distribution function of rainfall can be fitted by introducing a censored shifted gamma csg function to perform a postprocessing rainfall correction baran and nemoda 2016 javanshiri et al 2021 compared with the emos method the emos csg method can capture the skewed distribution characteristics of precipitation by constructing a censored shifted gamma function and then we can adopt a unified distribution function to describe zero precipitation and positive precipitation in addition the method can fully consider the performance difference of a single model and effectively utilize the information of multi model integration based on the above advantages we introduced this method into the precipitation merging process the probability density function pdf of the original gamma distribution can be expressed as follows 3 g k θ x x k 1 e x p x θ θ k γ k x 0 0 x 0 where γ k represents the value of the gamma function at k the conversion relationships among the shape k scale θ mean μ and variance σ 2 values of the gamma distribution can be expressed as follows 4 k μ 2 σ 2 θ σ 2 μ the mean and variance in the gamma distribution and in each satellite precipitation member f 1 f n are connected as follows 5 μ a 0 a 1 f 1 a n f n σ 2 b 0 b 1 f where f refers to the mean value of the satellite precipitation members a 0 a n denote the mean parameter values and b 0 and b 1 represent the variance parameters which can be calculated using the continuous ranked probability score crps gneiting and raftery 2007 the cumulative distribution function g k θ δ 0 of the csg can be expressed as follows 6 g k θ δ 0 x g k θ x δ x 0 0 x 0 where g k θ x δ is the cumulative distribution function of the original gamma distribution and δ indicates the offset to the left the pdf g k θ δ 0 can be estimated as follows 7 g k θ δ 0 x π x 0 g k θ δ π x 0 1 g k θ δ g k θ x δ where π a denotes an indicator function of a and if a 1 π x 0 1 otherwise π x 0 1 then the mean λ of csg can be calculated as follows 8 λ θ k 1 g k θ δ 1 g k 1 θ δ δ 1 g k θ δ 2 the quantile q p of p in formula 6 is equal to 0 if p g k θ δ otherwise q p can be calculated by g k θ q p δ p the main steps of the emos csg are shown as follows 1 based on the four bias adjusted satellite precipitation the gamma distribution parameters of k and θ can be obtained by formulas 4 and 5 in addition we calibrate the parameter of δ by minimizing crps as the objective function the calibrated parameters can link the pdf of satellite precipitation with the pdf of gauge precipitation and then can calibrate the satellite precipitation to the gauge value effectively eliminating the underestimation or overestimation of satellite precipitation furthermore after parameter optimization each satellite product obtains an optimal weight coefficient and the larger the weight coefficient the greater the contribution of the product to the final merging precipitation 2 after obtaining these three parameters we can determine the conditional distribution of precipitation and then we can get the corrected mean precipitation by formula 8 considering that emos csg is calculated in grid units the sparse rain gauge network is interpolated to 1 km grids using ordinary kriging then we obtain daily merged precipitation datasets at a 1 km spatial resolution by merging the stacked results i e tmpa 3b42rt2 cmorph2 gsmap nrt2 and persiann2 3 4 evaluation index to quantitatively evaluate the performance of the proposed merging method the dataset from 38 rain gauges was spatially and randomly divided into training and test sets 28 rain gauges were used for the training 10 rain gauges were used to evaluate the final merging precipitation in the result section particularly in the process of randomly selecting gauge stations we tried to make the test gauge stations evenly distributed fig 1 so that the validation results could truly reflect the overall merging performance of the watershed to evaluate the performance of the merging results six statistical indexes were selected including the root mean square error rmse correlation coefficient cc mean absolute error mae probability of detection pod false alarm ratio far and critical success index csi these indexes were calculated as follows 9 rmse i 1 n p i o i 2 n 10 cc i 1 n p i p o i o i 1 n p i p 2 i 1 n o i o 2 11 mae i 1 n p i o i n 12 pod n 11 n 11 n 01 13 far n 10 n 11 n 10 14 csi n 11 n 11 n 10 n 01 where p i and o i represent the satellite and gauge derived precipitation totals at the i t h point respectively p and o denote the average satellite and gauge derived precipitation totals respectively n is the number of samples n 11 represents the number of times that both the gauge and satellite detected rainfall n 10 denotes the number of times that only the satellite rather than the gauge detected rainfall and n 01 is the number of times that only the gauge rather than the satellite detected rainfall if the rmse mae and far values are close to 0 and the cc pod and csi values are close to 1 the merging effect is better it is informative to note that a scatter plot should be used to determine whether the dot pitch is distributed around the 45 line when the cc is adopted as a statistical index in order to discover whether the considered satellites provide systematically overestimated or underestimated data 4 results and discussion 4 1 performance of original and downscaled satellite precipitation products due to the influence of the analyzed terrain retrieval algorithms and sensors the accuracies of different satellite products may be different table 2 summarizes the evaluation statistics for the test set obtained from the original and downscaled satellite precipitation products we found that the rmse mae pod far and sci values of the four original satellite products did not differ extensively the persiann product had the lowest cc of 0 13 compared to the other three products and the tmpa 3b42rt product had the lowest pod csi value of 0 63 0 55 overall the performances of the four satellite products revealed little differences within the analyzed basin and no single product was significantly better than the other products this finding was consistent with the research results reported by mei et al 2014 and sun et al 2018 compared to the original products the accuracies of the downscaled products were improved but these improvements were not obvious this result was related to the necessary residual correction step in the downscaling process the objective function of the residual correction process was the satellite products instead of the gauges leading to the limited accuracy improvements furthermore the smaller cc 0 18 0 25 and larger rmse 12 03 12 47 mm values obtained indicated that substantial errors existed in the original and downscaled satellite precipitation products thus it was necessary to integrate gauge information to reduce these deviations 4 2 performance assessments of merging products to test the effectiveness of the utilized merging method we evaluated the accuracy of the analyzed satellite products at three different stages during the merging process the evaluation statistics are listed in table 3 only for test set first base learners machine learning algorithms significantly improved the satellite derived precipitation accuracy for instance when ml algorithms were used the maes decreased to 3 55 5 08 mm at a decreasing rate of 50 67 compared to the downscaled products the rmses decreased to 4 78 6 40 mm by 47 62 the ccs improved to 0 44 0 60 and the pods csis increased to 0 77 0 87 0 69 0 79 all the above results demonstrated that ml algorithms could effectively reduce biases in satellite derived precipitation products among the six ml algorithms lgb performed the best overall providing the highest cc of 0 60 and the lowest mae of 3 55 mm followed by catboost xgb rf knn and gbm furthermore the three best performing ml algorithms were all based on the improved gradient boosting tree algorithm indicating that these algorithms have certain advantages for merging precipitation in the analyzed basin after the first merging step a secondary learner of stacking algorithm was employed to integrate the six ml results this learner provided better scores than any of the ml algorithms discussed above in addition persiann showed the best performance among the four satellite products with the highest cc pod at 0 62 0 90 and the smallest mae and rmse values at 3 31 and 4 53 mm respectively in terms of the correction effect the stacking algorithm greatly decreased the bias in the results and avoided the uncertainty caused by using a single algorithm additionally the secondary learner integrated the advantages of the base learners and generated better correction results furthermore the accuracy of the final merging product obtained by the third stage emos csg method was further improved compared to the stacking results the above results demonstrated that the multisatellite precipitation merging method based on stacking and emos csg was effective and feasible as they are the core of the precipitation merging method the utilized ml algorithms must effectively decrease the bias in satellite derived precipitation products in this work we also attempted to use other ml algorithms including decision tree support vector machine svm logistic regression extreme learning machine elm and back propagation bp network finally the machine learning methods with the best merging effects among the methods listed above were selected as the base learners in the stacking algorithm in terms of the algorithm structure the stacking and emos csg processes integrated different datasets through weight optimization processes in the stacking process weights were assigned to six machine learning results while the emos csg method applied weights to the four satellite products i e tmpa 3b42rt2 cmorph2 gsmap nrt2 and persiann2 fig 3 displays the weights of the six machine learning algorithms applied to each product in the secondary learner step the lgb algorithm accounted for the largest weights over 23 for each product followed by the catboost 20 22 xgb 16 20 rf 16 18 knn 13 15 and gbm 3 4 algorithms these results were consistent with the machine learning correction performance observed during the first merging stage table 3 in addition to evaluate the sensitivities of topographic and meteorological variables to the base learner we estimated the relative weight of each variable using an rf as an example as shown in fig 4 all variables contributed valuable information the satellite derived precipitation variable accounted for the highest weight indicating that this variable provided useful information for the precipitation merging process temperature had the second highest weight this may have been related to the strong response of precipitation to temperature the wind speed and direction may cause changes in atmospheric moisture and the soil moisture signature can last a few hours to several days after a rain event maggioni and massari 2018 thus these variables showed similar performances in the rf algorithm although latitude and longitude provide important spatial location information these variables have the characteristics of not changing with time causing them to show the lowest weights in the precipitation merging process overall the final merging result has been greatly improved compared to the original satellite products for the following reasons firstly base learners greatly reduce the bias of downscaling satellite products by introducing meteorological factors as the explanatory variables secondly the secondly learner rf can integrate the advantages of the base learners and improve upon the generalization accuracy of the base learners by assigning weights thirdly the emos csg model can consider the performance difference of a single bias adjusted satellite product and assign a higher weight to a superior product which further improves the performance of the merging results furthermore the flexible merging framework described herein can not only select new ml algorithms e g lstm as the base learners in the stacking process but can also add other satellite products e g imerg fy4qpe msa and peca fy4a zhu et al 2021 ma et al 2022a zhu and ma 2022 and datasets from different sources e g reanalysis or weather radar datasets to capture more rainfall information 4 3 assessment of the spatial distribution of precipitation fig 5 presents the spatial distributions of the downscaled satellite derived products and the final merging product on june 20 2017 fig 6 displays the corresponding scatter plots according to the ribbon at the bottom of fig 5 the precipitation totals of tmpa 3b42rt cmorph gsmap nrt persiann and the gauge network were mainly 16 40 mm 32 64 mm 48 80 mm 10 45 mm and 100 220 mm respectively these values indicated that the four downscaled satellite precipitation products had obvious underestimations and large systematic errors the same conclusion can be obtained from fig 6a d where the dot pitches of the corresponding scatter plots were below the 45 line after merging the four satellite products the underestimation and mutation of the precipitation were significantly improved the cc of the final merging product increased to 0 94 and the dot pitch was evenly distributed around the 45 line fig 6e in addition the distribution of the merged precipitation product was consistent with that of the gauge observations especially in the southern and central parts of the analyzed basin fig 5e f this comparison further illustrated that the merging method had a good performance when estimating the spatial characteristics of precipitation 4 4 sensitivity analysis of the gauge density the gauge density not only has an impact on the spatial pattern of the merged results but also affects the local deviation adjustment of satellite derived precipitation products wang and lin 2015 bai et al 2019 nerini et al 2015 in this study the number of gauge stations in the training dataset was randomly reduced to 24 20 16 12 8 and 4 while the test dataset remained unchanged then we repeated the merging method with these different training dataset sizes and analyzed the gauge density sensitivity fig 7 plots the change trends of the six analyzed statistical indexes under different gauge densities as the gauge station density increased the quality of the merged precipitation product improved particularly the increasing performance trend of the merged product began to significantly slow down when the number of gauges reached 16 stations for example when the gauge stations increased from 4 to 16 the rmse mae far decreased by 2 25 mm 1 72 mm 0 05 in contrast the rmse mae far decreased by only 0 33 mm 0 20 mm 0 005 when the number of stations increased from 16 to 28 fig 7a 7c 7e these significant discrepancies indicated that after the number of gauge stations exceeds 16 in beimiaoji basin further increasing the density of station network can improve the merged product performance but the improvement effect was not significant 4 5 discussion despite the optimal performance of the merging method some limitations in the process still require further study first we selected some topographic and meteorological variables as the explanatory variables in the gwr and ml algorithms according to previous studies however the rationality of these explanatory variables and the introduction of other new variables e g cloud properties sharifi et al 2019 require further analyses for example the introduction of the satellite derived soil moisture variable may have generated increased uncertainty due to the systematic errors present in soil products second the four satellite products considered in this study adopted space borne sensors that use inversion algorithms to obtain precipitation information while the reanalysis datasets e g era5 xu et al 2022 were mainly obtained through data assimilation techniques the use of two types of products generated based on different algorithms may result in more reliable precipitation spatial pattern estimates so a reanalysis dataset could be added to the merging method to improve the quality of the merged product third we only preliminarily studied the influence of the rainfall station density on the merging effect considering the small watershed area and relatively dense gauge stations in the study area the gauge density threshold of 16 may not be suitable for other watersheds with sparse stations e g those in western china in addition due to the limited number of stations only 28 stations were adopted to explore the gauge density sensitivity and this value may have impacted the accuracy of the threshold results further efforts are thus needed to explore the gauge density threshold in different basins with more gauge stations 5 conclusions in this study we proposed a method to merge multisatellite precipitation products i e tmpa 3b42rt cmorph gsmap nrt and persiann by downscaling coarse resolution products gwr algorithm and then eliminating biases in individual datasets stacking algorithm and finally merging the bias adjusted precipitation by weighted average emos csg algorithm the merging method was applied to the beimiaoji basin from april to october during the 2016 2019 the key findings of the study are as follows 1 the performance difference of the four original satellite precipitation products is small in terms of the six statistical indexes although the spatial resolution of the satellite products increased to 1 km by the gwr model further calibration procedures are required to reduce bias due to smaller cc 0 18 0 25 and larger rmse 12 03 12 47 2 the merging method could integrate the advantages of multisource precipitation and achieve higher accuracy than original products for example the rmse of final merging precipitation decreased to 4 33 mm and the cc improved to 0 64 compared to the four original satellite products rmse 12 45 mm and cc 0 20 in addition the final merging product showed better spatial consistency with the gauge precipitation 3 the stacking model could wisely integrate the advantages of the base learners and greatly decrease the biases of the downscaled satellite products in addition the emos csg model merged the information of four bias corrected satellite precipitation and further improved the performance of final merging product 4 increasing the gauge density could decrease the bias and improve the performance of the merged precipitation product however the improvement of the merged product performance was not significant after the number of gauge stations surpassed 16 overall the proposed method is a promising and applicable way for the merging of multisource precipitation products further investigations should be carried out to assess the applicability of this method in other watersheds and compare the method with other existing merging methods declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was support by the national natural science foundation of china grant no 41730750 and national natural science foundation of china grant no 41877147 
2258,a coupled surface water and variably saturated groundwater model is developed for a coastal salt marsh nueces delta texas usa to evaluate the relative impacts of common model simplifications the new model is compared against a prior salinity transport model that neglects evaporation and groundwater coupling both marsh scale at coarse grid resolution and bank scale at fine grid resolution simulations are used to examine the flux mechanisms in the intertidal zone where soil moisture evaporation and groundwater fluxes contribute to hypersalinity new numerical methods provide the groundwater surface water coupling mechanisms necessary for practical marsh scale simulations using the two dimensional 2d shallow water equations for surface water and the density dependent 3d richards equation for groundwater an asynchronous surface subsurface coupling scheme is shown to significantly reduce the computational cost of marsh scale simulations comparison of marsh scale and bank scale results indicates that a coarse model grid can represent the mechanisms of surface subsurface salinity flux in the intertidal zone but likely misrepresents the inundation effects of topography smaller than the model grid due to relatively weak tidal amplitudes at the study site surface water evaporation is a stronger driver of hypersalinity than surface subsurface exchange induced by soil moisture evaporation the combination of evaporation and groundwater exchange creates small hypersalinity hot spots that do not appear in the simulations neglecting these processes however including these processes has only a marginal impact on comparisons with field data previously collected in the marsh both types of simulations have good agreement for surface water volumetric transport as evidenced by water surface levels but the remaining model field disagreement in salinity appears to be dominated by biases in salinity transport for oscillatory tidal wind driven fluxes through narrow channels keywords surface subsurface exchange shallow coastal wetland hypersalinity numerical modeling data availability data will be made available on request 1 introduction salt marshes serve important ecological functions xin et al 2022 but can be threatened by hypersalinity that damages a marsh ecosystem and affects survivability of aquatic species ritter et al 2005 bighash and murgulet 2015 stachelek and dunton 2013 wilson and dunton 2018 the evolution of salinity in a coastal marsh is affected by multiple environmental forces including tide wind precipitation evaporation and surface subsurface exchange guimond and tamborski 2021 the complex interactions among these factors lead to widely varying spatial and temporal patterns of salinity which necessitates extensive field observations and detailed numerical modeling to evaluate driving processes a critical question is the relative importance of surface water evaporation versus soil moisture evaporation on the development of surface water hypersalinity the creation of porewater hypersalinity through soil moisture evaporation is a product of successive wetting drying processes in the intertidal zone and is inherently tied to near subsurface transport as yet the overall importance of porewater hypersalinity to surface water salinity is not understood but is likely dependent on both marsh topological structure and environmental forcing the challenge for understanding hypersalinity development is that it arguably requires a coupled surface subsurface model to correctly capture porewater hypersalinity in the intertidal zone in this study we explore this idea using a coupled surface and subsurface water numerical model to investigate mechanisms developing hypersalinity in the upper nueces river delta texas usa which is also known as the rincon bayou this saltwater marsh has been the subject of a number of studies and management interventions including creating artificial channels and providing additional freshwater pumping into the upper reaches riera et al 2000 ward et al 2002 montagna et al 2002 palmer et al 2002 buyukates and roelke 2005 montagna et al 2017 in shallow marshes surface water evaporation directly increases salinity of ponded water in the system as the evaporation rate is relatively uniform over a body of ponded water its effect is necessarily felt by creating higher salinities in shallower water which may be subsequently mixed through the system by inflows winds and tides soil moisture evaporation plays a key role in porewater and the near surface groundwater after tide retreats leading to reduced soil moisture that amplifies subsequent surface subsurface exchange for intertidal zones li and hodges 2021 as the soil moisture decreases porewater becomes hypersaline murgulet et al 2016 stachelek and dunton 2013 the balance between pore capillarity and gravity could form a stable saline layer in the subsurface zheng et al 2022 when dry or hypersaline pores are later flooded the stored salt is a potential source of salinity for the surface water bighash and murgulet 2015 shen et al 2018 evapotranspiration from marsh vegetation can also enhance porewater hypersalinity e g hughes et al 2012 furthermore hypersaline pore water could precipitate forming efflorescence or subflorescence that block the hydraulic connection in the pores e g zhang et al 2014 however these two mechanisms are neglected in the present study due to the lack of data and mature mathematical models the likely consequences of this and other limitations are discussed in section 4 4 prior modeling studies have examined the surface subsurface exchange across the coastal margin typically with a focus on understanding how tidal variations affect the subsurface transport common test problems use a two dimensional 2d vertical plane through the surface and subsurface with one dimensional 1d land topography that represents a simple beach slope or river bank e g abarca et al 2013 lenkopane et al 2009 heiss and michael 2014 kuan et al 2019 robinson et al 2014 shen et al 2018 xiao et al 2019 xin et al 2017 yang et al 2018 yu et al 2019 the surface flow in these models is typically a simple tidal rise and fall that provides the surface pressure influencing subsurface fluxes these 1d 2d models are appropriate for examining surface subsurface exchange between ocean and the near shore aquifer where tidal forcing is dominant robinson et al 2007 but inherently neglect the complex multi scale topography that attenuates tidal intrusion in a salt marsh and controls the local surface subsurface exchange xu et al 2021 torres and styles 2007 recent research has shown that surface subsurface exchange is sensitive to topography and varies with the distance from the river channels chen et al 2018 liu et al 2022 xin et al 2017 xu et al 2021 yu et al 2016 thus to fully understand the fate of salt in a marsh a coupled surface subsurface model needs to simulate 2d flow through complex surface topography and 3d flow through the subsurface cantelon et al 2022 xin et al 2022 extending coupled surface subsurface models from 1d 2d to 2d 3d inevitably increases the computational cost with the rapid development of parallel computing technology several coupled 2d 3d models have emerged in hydrology including parflow kollet and maxwell 2006 hydrogeosphere brunner and simmons 2012 hwang et al 2014 pihm kumar et al 2009 paws shen and phanikumar 2010 and pflotran wu et al 2021 field scale studies have also examined the transport of solute across surface subsurface regimes liggett et al 2015 daneshmand et al 2019 unfortunately large catchment scale models in hydrology often treat surface flow with the kinematic or the diffusive wave approximations which reduce the fidelity of the surface water physics this approach might be suitable for well sloped uplands but creates problems for coastal marshes where upland inflows meet the tide li and hodges 2021 showed that coastal marshes require the full shallow water equations swe to correctly model the interaction mechanics of tidally driven flow and surface subsurface exchange for complex topography the computational challenge is that fine horizontal grid resolution δ x δ y and a small time step δ t are required for the swe in the surface domain to capture fluxes through the maze of channels in a marsh in general reducing the surface water grid δ x δ y by a factor of 1 2 n results in an 8 n increase in computational cost for the surface water model which can quickly overwhelm available computational power on the other hand the 3d subsurface domain is computationally demanding because it requires 3d rather than 2d grid cells but the spatial and temporal scales of subsurface processes can be reasonably represented at much coarser grid resolution and larger time steps the residence time of subsurface salinity is often years to decades lenkopane et al 2009 which theoretically permits the use of a nonconforming and asynchronous surface subsurface coupling scheme to reduce computational cost in practice however such schemes inevitably introduce coupling errors fiorentini et al 2015 in addition the subsurface grid cells still need to be refined near the river channels because much of the surface subsurface exchange is affected by processes within a few meters of the channels gardner 2005 xin et al 2017 furthermore the vertical grid resolution δ z in a subsurface model also needs to be refined in the unsaturated region due to strong nonlinearity of processes near the surface mao et al 2021 finally the shallow pore water near the surface subsurface interface evolves at tidal time scale guimond and tamborski 2021 which constrains the time step for the subsurface simulation with these limitations it remains challenging to achieve a reasonable computational cost for coupled 2d surface and 3d subsurface marsh simulations prior models have made compromises in the physics represented to constrain computational costs such as assuming fully saturated subsurface domain langevin et al 2005 spanoudaki et al 2009 or using simple synthetic topography xin et al 2011 xu et al 2021 as a further limitation of the state of the art prior 3d coastal simulations have generally focused on hydrology and hydrodynamics neglecting the density driven transport of salinity guimond et al 2020 moffett et al 2012 xin et al 2022 xu et al 2021 zhang et al 2018 in this work we seek to step beyond the compromises of prior models herein a coupled surface subsurface model named frehg is developed section 2 applied to a shallow coastal salt marsh section 3 and model results are compared to field observations to investigate salt dynamics section 4 the previous version of frehg presented in li and hodges 2021 featured i solutions of the full swe for 2d surface flow ii the richards equation for 3d variably saturated subsurface flow and iii the ability to model evaporation and precipitation for both open water and dry unsaturated ground new to the present work are i a density driven salinity transport module to model the flux of salt in the surface water and the near surface unsaturated zone ii a terrain following mesh system that better represents marsh topography iii an asynchronous surface subsurface coupling scheme and iv incorporation of a subgrid topography model li and hodges 2019b the latter two methods are used to enhance computational speed for practical computation of marsh scale systems the coupling error caused by the asynchronous coupling is quantitatively analyzed and controlled sections 2 5 and 3 4 to evaluate the effects of using coarse grid resolution for full marsh scale simulations a fine resolution model using a 1d surface and 2d subsurface approach is also performed for a smaller domain along the marsh bank the structure of the frehg model and its application in the present study has been summarized in fig 1 the three goals of this study are i exploring how surface water evaporation soil moisture evaporation and surface subsurface exchange contribute to hypersalinity in a south texas marsh ii investigating whether the small scale processes revealed from the fine resolution simulation are reasonably represented in a coarse resolution large scale model and iii evaluating the efficacy of a spatial temporal upscaling approach subgrid model with asynchronous coupling in reducing the computational cost of coupled 2d surface and 3d subsurface marsh simulations this study confronts and is limited by a common question how to make effective use of field data that were expensive to collect but are inherently limited in scope the original field study in the nueces delta was focused on surface fluxes of salinity driven by freshwater pumping and neglected time space varying data for a wide range of secondary processes that affect salinity e g rainfall small scale topographic variability vegetation root zone dynamics transpiration soil heterogeneity subsurface salinity and precipitation mobilization of dissolved porewater salt although models for all such effects can be proposed introducing them into a comprehensive model at this time leads to the number of parameters overrunning the available data herein we claim only a modest step forward in modeling some of the mechanics involved in the complex salinity behaviors of a coastal marsh specifically to the coupling of surface subsurface salinity fluxes with evaporation in an existing surface water salinity transport model the validation of our modeling methods is necessarily limited to simplified theoretical and experimental data sets that exclude the neglected salinity processes for marsh scale systems we examine the relative effect of groundwater coupling and evaporation through model model comparisons and examine whether model data agreement is improved by adding the additional processes we revisit the issues of neglected processes in field data comparisons in section 4 4 and discuss the next steps needed for modeling and collecting field data in coastal marshes 2 methods 2 1 overview the fine resolution environmental hydrodynamics and groundwater model frehg couples a 2d hydrodynamic model with a 3d variably saturated groundwater model li and hodges 2021 in frehg the surface and the subsurface domains solve their own system of equations fig 1 as discussed in sections 2 2 and 2 3 the pressure head and flux across the domain interface are used as boundary conditions salinity transport is outlined in section 2 4 frehg is designed to allow either domain to be run in isolation or coupled together using asynchronous methods which are discussed in detail in section 2 5 validation of the new method against a benchmark case is provided in section 2 6 2 2 surface hydrodynamics the surface flow module of frehg is a 2d version of an existing 3d hydrodynamic model frehd hodges 2014 hutschenreuter et al 2019 li and hodges 2019a with additional functions that parametrize subgrid scale topography li and hodges 2019b 2020 in the surface domain frehg solves the 2d depth integrated navier stokes equations i e the swe the integral form of the swe can be written as 1 t ω η d ω γ u n d γ q s 0 2 v u t u n u x d v γ g η n d γ γ τ ν n d γ ω τ w τ b d ω where η is the free surface elevation u u v t are depth averaged velocities x x y t are the corresponding cartesian axes g 0 0 g t is the gravity vector n is the normal unit vector to a cell edge τ ν is the viscous stress τ w and τ b are the surface wind and the bottom stresses whose expanded forms can be found in li and hodges 2019a b q s is a volumetric source sink term that could represent evaporation rainfall and or inflow d v is an infinitesimal volume inside a grid cell d γ and d ω are the infinitesimal side and top face areas of a grid cell unlike common swe that uses depth and flow rates as primary variables eq 1 and 2 use η and u which are consistent with the frehg codes the density of surface water is assumed to be a constant more details on the discretization scheme and the constraints on time step can be found in li and hodges 2019a 2021 and citations therein to enhance computational efficiency frehg is designed to operate on a cartesian grid at coarse resolution e g 30 m as used herein relative to the scales of channels and obstructions that appear in high resolution 1 m topographic data as described and demonstrated in li and hodges 2019b a subgrid topography model can be used to upscale the hydraulic effects of small scale features apparent in high resolution lidar data obtained at low tide this approach enables coarse resolution hydrodynamic simulation without losing the important water blocking features hodges 2015 and the fluxes in the narrow river channels 2 3 variably saturated subsurface flow in the subsurface domain frehg solves the density dependent 3d richards equation boufadel et al 1999 geng and boufadel 2015a here to be consistent with the finite volume discretization used in frehg the generalized richards equation is written in the integral form 3 v β s s θ ϕ ψ t β θ t θ β t d v γ q n d γ where ψ is pressure head θ is water content ϕ is porosity s s is specific storage v and γ represent the volume and surface area of a grid cell n is the normal vector and q is the flux vector whose components represent the darcy flux between grid cells 4 q j β δ k ψ cos ω ψ x j β g j g sin ω where j 1 2 3 k ψ is the hydraulic conductivity ω is the angle between the connection of two cell centers and the horizontal axis maxwell 2013 the use of ω guarantees that the fluxes are calculated correctly in a terrain following mesh fig 2 which provides more flexibility when complex topography exists in the vertical direction j 3 no horizontal component is needed when estimating the flux thus eq 4 returns to its original form which is equivalent to forcing cos ω and sin ω to 1 and 0 respectively note that unlike surface cells for a subsurface cell eq 4 is applied to all 6 faces so the side face γ and the top face ω do not need to be distinguished β and δ are the density and viscosity ratios that can be related to the salinity c 5 β 1 ϵ c 6 δ 1 ζ c in the present study the above fitting parameters take values ϵ 7 63 1 0 4 m2 kg and ζ 1 566 1 0 3 m3 kg frehg solves the 3d richards equation using the predictor corrector allocation pca scheme the pca scheme is non iterative which guarantees the error bounded by the underlying discretization scheme li et al 2020 li and hodges 2021 the nonlinear relationships between k and ψ θ and ψ are estimated with the mualem van genuchten model mualem 1976 van genuchten 1980 7 s ψ 1 α ψ n m 8 θ ψ θ r ϕ θ r s ψ 9 k ψ k s s ψ 1 2 1 1 s ψ 1 m m 2 where s is the saturation k s is the saturated hydraulic conductivity θ r is the residual water content α and n are the soil parameters and m 1 1 n frehg provides options to model evaporation and or rainfall in both surface and subsurface domains evaporation and rainfall rates are introduced either as constants or time dependent inputs to frehg for exposed dry lands an alternative option is to estimate evaporation rate from the subsurface using a bulk aerodynamic model which represents evaporation flux as a function of the water content more details on the bulk aerodynamic model can be found in geng and boufadel 2015b and li and hodges 2021 in the subsurface domain without overlying surface water the evaporation and rainfall rates are applied as flux boundary conditions on the topmost subsurface layer 2 4 salinity transport in the surface domain the transport of salinity or any conserved passive scalar is modeled using the 2d advection diffusion equation 10 c t u j c x j x j κ c x j where c is the salt concentration kg m 3 and κ is the turbulent diffusivity it has been shown that the modeled salinity is not sensitive to the horizontal turbulent diffusivity wang et al 2009 so κ is set to a constant in frehg eq 10 is discretized fully explicitly in time the advection term is discretized using the total variation diminishing tvd scheme with roe s superbee limiter to suppress numerical diffusion gross et al 1999 with the density dependent richards equation eq 3 3d salinity transport in the subsurface domain can be modeled using the 3d advection diffusion equation 11 θ c t q j c x j β x j θ d c x j where d is the dispersion tensor whose components are functions of the longitudinal dispersion coefficient α l the transverse dispersion coefficient α t and the molecular diffusivity d m bear 1972 geng and boufadel 2015b the expanded forms of d 11 and d 12 can be found in eq 12 13 as an illustration similar to the surface domain eq 11 for the subsurface domain is solved with an explicit finite volume scheme the tvd method is used for the advection term 12 d 11 α l q 1 2 α t q 2 2 α t q 3 2 q θ d m 13 d 12 α l α t q 1 q 2 q 2 5 asynchronous coupling the coupling between the surface and the subsurface domains is illustrated in fig 2 on the top boundary of the subsurface domain if the corresponding surface cell is wet i e h 0 water depth is used as the boundary condition for ψ in eq 3 if the corresponding surface cell is dry the boundary head is set to zero but only exfiltration is allowed because there is no surface water available to infiltrate with the subsurface boundary head equals the surface water depth the flux across the surface subsurface interface can be estimated as 14 q s s β δ k ψ t o p h δ z 2 β where q s s is the vertical exchange flux ψ t o p is the pressure head at the topmost subsurface cell in the surface domain the exchange flux q s s is converted into an equivalent increase decrease of the free surface and is added subtracted to the current surface elevation salinity transport at the surface subsurface interface is implemented in a similar approach for the subsurface domain surface salinity is enforced on the topmost cells as dirichlet type boundary conditions and the numerical calculation follows eq 11 for the surface domain since no boundary condition exists in the vertical direction the advective diffusive salt flux is treated as a source term of eq 10 for example the salinity across the interface over one time step is estimated as 15 c s s q s s c u p β j s s where c s s is the salinity flux in k g m 2 s across the surface subsurface interface c u p is the salinity of the upwind cell and j s s is the longitudinal vertical dispersive flux transverse dispersion is neglected because the exchange flux q s s only exists in the vertical direction eq 15 is essentially a simplified and discretized version of eq 11 surface water hydrodynamic simulations typically require smaller time step δ t s for stability whereas groundwater simulations allow greater time step δ t g asynchronous coupling exploits this difference to improve computational efficiency by allowing the surface and subsurface domains to follow their own timelines e g spanoudaki et al 2009 yuan et al 2011 by default the surface time t s equals the global time t of the frehg model asynchronous coupling is achieved by adding a simple conditional statement in the codes such that the subsurface solver is only executed while the subsurface time t g δ t g t fig 3 note that the subsurface simulation uses adaptive δ t g li et al 2020 so it is possible that δ t g δ t s in rare situations when this happens frehg will simply perform multiple subsurface steps per surface step which is more flexible and robust compared with setting a fixed ratio between δ t g and δ t s unfortunately asynchronous coupling introduces another error source in the exchange flux in the frehg coupling scheme when the subsurface model is executed the subsurface time is typically δ t g behind the surface time following eq 14 the surface subsurface exchange flux is then 16 q s s async t g β δ k ψ t o p t g h t g δ t g δ z 2 β where the superscripts represent the time level assuming that β δ and k vary slowly in time such that their time dependency can be ignored and that eq 16 can be linearized then using first order taylor expansion the exchange flux can be further rewritten as 17 q s s async t g β δ k ψ t o p t g h t g δ z 2 β β δ k δ t g δ z 2 h t where the first term on the right hand side is the true flux when the two domains are synchronous q s s sync t g and the second term on the right hand side is the coupling error ideally the coupling error should be negligible compared with q s s sync t g this can be mathematically expressed by defining an error ratio for the exchange flux r q 18 r q q s s sync t g δ z 2 β δ k δ t g h t 1 1 eq 18 is an indicator of the coupling error associated with asynchronous coupling of the exchange flux however according to eq 10 and 11 the transport of salinity is governed by both advection and dispersion the error in the exchange flux affects the advective transport of salinity but if dispersive transport is dominant the error in flux could be unimportant to analyze this problem an error ratio for the dispersive flux r d can be defined similar to eq 18 19 r d j s s sync t g δ z 2 β δ d z z δ t g c s t 1 1 where j s s sync is the longitudinal dispersive flux across the surface subsurface interface d z z is the longitudinal dispersion coefficient in the vertical direction and c s is the salinity of the surface water finally the péclet number can be used to assess the relative importance of advection versus dispersion 20 p e q s s δ z α l q s s 2 q d m the constraints on asynchronous coupling can be evaluated using eq 18 20 the péclet number is estimated first to determine if advection or dispersion dominates surface subsurface salinity exchange depending on the péclet number r q and or r d is calculated to examine if the coupling error is small enough to be neglected if not δ t g needs to be reduced to constrain the coupling error 2 6 validation against benchmark case the original frehg model without density dependency and salinity transport has been validated in li and hodges 2021 using benchmark problems that focus on surface runoff and surface subsurface exchange in this section we focus on validating the density driven scalar transport functions and the asynchronous coupling scheme that are newly developed for frehg validation of the model for full scale application is provided in section 3 4 the validation problem is designed to reproduce the seawater intrusion experiment by kuan et al 2019 the computational domain approximates a typical beach slope with dimensions and boundary conditions illustrated in fig 4 the soil properties and other related parameters can be found in table 1 two types of surface boundary conditions are tested steady free surface ss and sinusoidal tidal oscillation td for each boundary type three scenarios are performed which are i synchronous coupling both δ t s and δ t g are 0 05 s ii asynchronous coupling with a maximum δ t g 0 5 s and iii asynchronous coupling with a maximum δ t g 1 s for each scenario the simulation is performed for 10 h fig 5 shows the mean salinity profiles of each simulation averaged from 8 to 10 h it can be seen that with synchronous coupling both ss and td produce good model data agreements with a steady free surface the simulation results are not sensitive to δ t g that is both synchronous and asynchronous coupling generate similar model predictions when tide is introduced however frehg underestimates subsurface salinity when δ t g and δ t s are asynchronous the predicted intrusion distance of sea water is also shorter to quantitatively understand the difference between the ss and td scenarios the error ratios are examined as shown in table 2 the r q values are much greater than 1 for ss but less than 1 for td these results indicate that the flux error is negligible for the ss scenarios but is important for the td scenarios the péclet numbers for both scenarios are greater than 1 indicating a dominant role of advective transport thus as observed in fig 5 the large flux error for td has a direct impact on the predicted salinity this result shows that the error ratio and the péclet number together can be used as the criteria to constrain the time steps with asynchronous coupling 3 model application 3 1 overview this section describes the application of frehg to the upper nueces delta located along the gulf of mexico coast of texas usa near the city of corpus christi as illustrated in fig 1 model application includes a marsh scale coupled 2d hydrodynamic and 3d subsurface simulation complemented by a high resolution coupled 1d hydrodynamic and 2d subsurface simulation the former is designed to understand the interactions of different environmental processes at marsh scales whereas the latter examines the details of salinity transport in a typical intertidal zone where substantial surface subsurface exchange occurs the following subsections illustrate the study site model configuration and validation 3 2 study site the nueces delta is a shallow marshland located northwest of nueces bay as part of the corpus christi bay and estuary system the nueces delta experiences episodic hypersalinity as a result of decreased freshwater inflow and insufficient tidal flushing del rosario and montagna 2018 hill et al 2015 to reduce salinity and restore the marsh ecosystem a pump station was built to provide a source of freshwater from upstream of the first weir on the nueces river into the upper end of the rincon bayou see fig 6 the pumping station has been in occasional use since 2007 to moderate episodes of hypersalinity in the delta prior hydrodynamic simulations of the entire nueces delta li and hodges 2019a showed good model data agreements for salinity in the lower nueces delta where tidal force is dominant in the upper nueces delta where complex topography weakens the tidal intrusion the model generally underestimated salinity the simplest hypothesis for model error is the neglect of evaporation and surface subsurface exchange in the work of li and hodges 2019a evidence in the literature supports this hypothesis for example alexander and dunton 2002 performed field measurements to confirm the correlation between salinity in the surface water and the hypersaline pore water of the upper nueces delta further studies found that both evaporation and surface subsurface exchange are important processes that cause hypersalinity in south texas marshes bighash and murgulet 2015 murgulet et al 2016 3 3 configuration marsh scale simulation the bathymetry of the marsh scale computational domain for the present work is shown in fig 6 a which was developed from the 1 m resolution lidar data of the nueces delta following upscaling and subgrid modeling approaches developed in hodges 2015 li and hodges 2019a b in the full nueces delta as modeled in li and hodges 2019a the rincon bayou extends through the right boundary of fig 6 a providing a connection to the lower nueces delta nueces bay corpus christi bay and the gulf of mexico not shown in this study to reduce computational cost we follow the approach of li and hodges 2019b in replacing the lower nueces delta with an artificial bay and boundary conditions that mimic the hydraulic influence of the lower section of the tidally driven marsh system as illustrated by field data presented in li and hodges 2019a the tidal elevation in the lower marsh closely tracks the tidal elevation in nueces bay and the salinity tends to be spatially homogeneous which is not the case for the upper delta in fig 6 a the upper nueces delta consists of three regions the main stem of the rincon bayou referred to herein as the river the relatively isolated west lake the lagoon and the deep artificial bay the bay that represents the lower delta the three regions are connected by narrow twisted channels sites l1 l7 are the locations of monitoring stations at which time dependent water level and salinity data were collected from 2012 to 2013 at 15 min intervals by the texas water development board the data are extensively illustrated in li and hodges 2019a sites xs1 and xs2 are the cross sections at which modeled subsurface salinity and flow field from the marsh scale simulations are examined in detail site topo1d near l5 is the location where the high resolution 1d topography displayed in fig 6b is used for the small scale fine resolution study section 3 5 to efficiently simulate the upper nueces delta the horizontal grid resolution is set to 30 m across the entire domain the prior modeling study of the upper nueces delta li and hodges 2019b showed the subgrid model at this resolution provides a reasonable representation of the hydraulic connectivity and salinity fluxes when compared with higher resolution modeling the subsurface domain extends to z bot 6 5 m navd88 downward using n layer 10 vertical layers the vertical grid resolution is calculated through eq 21 δ z i j 0 b i j z bot k 0 n layer r z k 21 δ z i j k 1 r z δ z i j k where i j k are the zero based grid indices in the x y z directions b i j is the bottom elevation of the ground surface and r z is the ratio of increment for δ z which is 1 4 in the present study applying eq 21 results a variable vertical grid resolution in the subsurface ranging from about 0 1 to 3 m increasing with depth in the upper nueces delta a horizontal 120 m buffer zone is delineated around the permanently and partially wet zones grid cells outside the buffer zones are marked inactive and do not participate in the computation in this way the total number of active surface and subsurface grid cells is reduced to 156222 from the 266200 cells implied by the full domain in fig 6 a all simulations were performed in serial mode on a macbook pro laptop with an intel core i9 processor a constant δ t s of 15 s was used for the surface hydrodynamic simulations the subsurface flow is modeled with a maximum δ t g of 120 s it has been previously shown that coupled surface subsurface simulations are sensitive to the hydraulic conductivity of the subsurface domain guimond et al 2020 for the present study unfortunately the soil properties and the initial states of the subsurface were not collected as part of the 2012 2013 field campaign which focused on surface water salinity lacking such data separate model runs were configured with different subsurface properties to examine the model sensitivity to uncertain parameters the simulation scenarios are summarized in table 3 where s represents the reference scenario that models surface water only which is similar to li and hodges 2019b a scenario sg60 is configured with an isotropic saturated conductivity of 1 1 0 6 m s and a uniform initial salinity of 60 psu in the subsurface two additional scenarios sg60k sg20 were constructed by increasing the hydraulic conductivity and decreasing the initial salinity respectively for the baseline cases evaporation is enabled for both surface and subsurface domains to evaluate the importance of surface evaporation each of the scenarios in table 3 were repeated with surface evaporation turned off these cases are denoted as e g sg20 no evap table 4 lists the model parameters that were kept constant in all scenarios of table 3 a spin up simulation was performed from april 1st to may 15th of 2013 to create reasonable initial states see appendix in li and hodges 2019a the testing simulations were executed from model days may 15th to july 14th of 2013 the water level and salinity observed at l7 are uniformly applied along the open boundary of the bay fig 7a all other side boundaries of the surface domain are closed all side and bottom boundaries of the subsurface domain are impervious except the left inland boundary where a fixed water table at 0 5 m navd88 is enforced this upland water table has weak influence on the simulation results due to the relatively large spatial scale and short simulation time the wind stress is uniformly applied to the surface domain with wind data obtained from the nueces delta weather station tcoon 2013 the pumping data for flow into the upper end of the river fig 7b is obtained from the website of the nueces river authority nueces river authority 2013 a constant evaporation rate of 4 1 0 8 m s is applied uniformly on the surface water which was estimated from the monthly evaporation data of texaset 2022 for the subsurface domain the bulk aerodynamic model is used to estimate soil moisture evaporation when the ground surface is dry rainfall transpiration antecedent soil porewater composition and precipitation mobilization of salt are processes affecting salinity that are neglected in the model as discussed in section 1 and revisited in section 4 4 3 4 validation of coupling scheme for marsh scale model the asynchronous coupling scheme has been validated for the upper nueces delta by comparing asynchronous against synchronous model results the frehg model sg60 scenario was executed in fully synchronous mode δ t s δ t g 15 s for 1 day and compared to the sg60 asynchronous model with δ t g 120 s the error ratios r q r d and péclet number p e of eqs 18 19 and 20 are used for validation at the six field monitoring sites as presented in table 5 it can be seen that at l2 l5 the péclet numbers are all much less than 1 and the r d ratios are all much greater than 1 these results imply the salinity transport across the surface subsurface interface is dominated by dispersion and the coupling errors in the dispersive flux are negligible at l1 and l6 the péclet numbers are around 0 5 meaning that both advective and dispersive processes are important in this situation both r q and r d need to be examined since they are both much greater than 1 at these two locations it is safe to assert that the error due to asynchronous coupling is negligible at all six locations in terms of computational cost the wall clock times are 164 and 31 min for the 1 day synchronous and asynchronous simulations respectively thus applying asynchronous coupling results in an 81 decrease in the total simulation time 3 5 configuration small scale simulation the high resolution small scale simulations with 1d surface water and 2d subsurface are designed to investigate surface subsurface exchange in the intertidal zone at the small length scales that cannot be captured at the coarser grid resolution of the marsh scale simulation our goals are i to simulate the subsurface fluxes at higher resolution to provide insight into the results of the marsh scale model and ii to evaluate whether the surface subsurface exchange at small scales in the intertidal zone can significantly impact the salinity of the adjacent perpetually flooded zone for these simulations the bottom topography is extracted from the intertidal zone near sensor l5 topo1d in fig 6a the domain for all the small scale simulations is shown in fig 6 b the surface domain has a length of 150 m which is discretized at a grid resolution δ x 1 m the vertical discretization is same as the marsh scale simulation as described above the surface and the subsurface domains are synchronous with δ t s δ t g 1 s all other parameters are same as in table 3 four scenarios are used for these simulations with different water surface elevations enforced at the tidal boundary to examine the role of the intertidal range on small scale salinity exchange the baseline scenario base uses measured water level data from sensor l5 for the tidal elevation this scenario includes model processes for both soil moisture evaporation and surface evaporation the second scenario is labeled as basex3 to indicate the tidal amplitude is increased by a factor of three while the mean tidal level is held constant similar to the marsh scale simulation two additional scenarios are created by turning off surface evaporation e g base no evap all scenarios are modeled for eight days from june 1st to 8th of 2013 the initial pressure and moisture of the subsurface domain are obtained from a 15 day spin up simulation of the base scenario all scenarios use a constant initial salinity of 40 psu in the surface domain the subsurface domain and as the downstream boundary condition 4 results and discussion 4 1 overview the results for the simulation of the upper nueces delta are provided in section 4 2 with a focus on model model comparisons that illustrate how inclusion of evaporation and groundwater coupling affect salinity predictions relative to the previous surface water only model the available field data are provided to illustrate the scale of model field differences that existed in prior work li and hodges 2019a b and are not significantly ameliorated by inclusion of evaporation and groundwater coupling in section 4 3 we examine higher resolution simulation of salinity fluxes at the intertidal exchange to see if the coarse resolution of our marsh scale simulation is likely to cause underprediction of groundwater coupling impacts in section 4 4 we provide a synthesis of our observations on the state of the art for modeling salinity in coastal marshes a discussion of neglected processes and the requirements for comprehensive field data collection to support future modeling note that model validation is presented against benchmark data in section 2 6 and for the marsh scale surface groundwater coupling in section 3 4 4 2 marsh scale simulation the left column of fig 8 shows the evolution of surface elevation at l1 l6 during the 60 day simulation period it can be seen that the trends of the modeled surface elevation generally match the measured data site l2 is anomalous in that there is an initial period from 145 170 days relative to 2013 1 1 where the model underpredicts the surface elevation by 0 3 m but follows the same trends a similar effect was seen at this gage in li and hodges 2019a the abrupt change of this gage on day 170 might indicate that the gage was moved and the recorded vertical reference datum was valid only for the final period of record note that for surface water elevation the results of all the scenarios are essentially identical including the no exchange sg60 case which indicates that surface evaporation and surface subsurface exchange have no significant effect on water levels the right column of fig 8 provides the salinity results in the surface water the two major freshwater pumping events pe1 pe2 are marked in fig 8 b which corresponds to the decline of salinity in most of the monitoring stations before pumping begins at the upstream end of the river the field measured salinity is above typical ocean salinity 35 psu at all monitored locations indicating the combined effects of evaporation and potentially surface subsurface exchange with hypersaline pore water when the pumps are first turned on pe1 the salinity decreases almost simultaneously across all stations except l4 which is in the middle of the tidal flats in the lagoon where the ponded water has poor connections to both the river and the bay station l1 l2 and l3 exhibit similar patterns where the salinity drops to zero during pumping and soon rises again when pumping stops stations l5 and l6 are closer to the open boundary and are affected by tidally driven exchange and mixing with downstream water retaining the initial salinity levels of the bay the interaction between pump flow and tidal flow leads to sub daily oscillations from nearly fresh to oceanic salinity as the mixing zone is tidally advected across the lower part of the river at l5 and l6 station l4 is again anomalous in that field data indicates it is almost hydraulically isolated i e the observed salinity only decline modestly after pumping begins and it soon returns to its previous level when pumping stops we believe this is due to the strong spatial gradients from freshwater to hypersaline that exist across the lagoon during pumping which cannot be resolved at 30 m grid resolution despite the subgrid model of li and hodges 2019b although the decline of salinity during pe1 is well captured at all except l4 as discussed above the rebound in the interregnum between pe1 and pe2 is only well captured at l3 l5 and l6 the stations that connect the lagoon with the lower river and bay in the upper river at l1 and l2 the modeled salinity rebound is almost negligible but is clearly evident in the observations we believe this indicates the challenges of capturing the correct subgrid model connectivity through the narrow channels near l3 and l5 the subgrid model performs well through these connections with marsh scale downstream fluxes e g as during the pe1 pumping event but have difficulty capturing the smaller net upstream tidal flux when the downstream flow is eliminated note that model discrepancy caused by bathymetry and grid resolution is not the focus of the present study they have been thoroughly discussed in li and hodges 2019a b the introduction of evaporation has a noticeable effect on salinity at sites l3 l4 l5 and l6 unsuprisingly in all cases the simulations with evaporation have slightly higher salinities than the simulations without in comparing models with surface subsurface exchange sg to models without s in fig 8 we see that the differences at the measurement sites are small especially when compared to the overall model data disagreement the only place with notable differences between the sg and s simulations at the field data sites is in the initial salinity increase at l1 the most upstream station that is most strongly affected by the upland boundary condition to examine the effects and uncertainties associated with the interaction of model parameters in more detail the index of agreement or skill score proposed by willmott 1981 where 1 indicates perfect model data agreement is used in table 6 along with the standard deviation to evaluate each of the simulations against the observed data xiao et al 2017 from table 6 the six monitoring stations can be grouped as follows l3 and l6 have the highest skill scores 0 8 and the lowest standard deviations indicating excellent model data agreement l2 and l5 have moderate model data agreement skill score between 0 6 and 0 8 whereas l1 and l4 have poor agreements skill score 0 6 in particular l4 has the largest standard deviation and the smallest index of agreement among the stations indicating that neither the magnitudes nor the trend of salinity is reproduced at l4 it should be noted that the lower standard deviation at l1 relatively to l5 does not indicate a better agreement because both the modeled and the measured salinity are zero at l1 during the pumping events fig 8b which tends to produce a lower standard deviation for both metrics the differences between the eight testing scenarios are subtle however the effects of evaporation are visible as a slightly lower index of agreement when evaporation is neglected at l4 l5 and l6 in contrast results with and without evaporation are indistinguishable at l1 and l3 l2 shows negligible influence of evaporation when considering surface flow alone the s scenario but adding surface subsurface exchange leads to lower skill scores for the no evap scenarios it indicates that the effects of evaporation and surface subsurface on salinity are complex which will be analyzed in more detail together with figs 9 11 below these results are consistent with l4 l6 being connected to large surface areas where evaporation is important whereas fluxes in l1 l3 are dominated by advection in the river particularly during pumping periods the key observations from these results are i the model data agreement is dominated by spatial location rather than by model parameters and ii the inclusion of groundwater appears to be relatively unimportant in the marsh scale prediction of salinity in the upper nueces delta the former issue indicates that improving model data agreement likely requires addressing underlying errors and uncertainty of bathymetry salinity advection and perhaps some of the neglected salinity processes as discussed in section 4 4 the relative importance of groundwater is discussed immediately below we should not take the above analysis as proof that groundwater coupling is unimportant but rather that errors and uncertainties in modeled surface advection are likely to dominate effects of groundwater for the present state of the science to provide further insight fig 9 compares the spatial distribution of salinity for the s no evap s sg60 and the sg20 scenarios before the first pumping event day 151 which corresponds to 2013 5 31 it can be seen that before pumping the salinity in the upper nueces delta is relatively uniform and hypersaline when evaporation is included for surface water fig 9b the overall inundated area in upper reaches of the lagoon shrinks and the salinity increases notably we see the emergence of hot spots of extreme hypersalinity dark red pixels that indicate isolated pockets with ineffective salinity exchange with the surroundings this basin of the nueces delta is only weakly affected by tidal fluxes hence evaporation plays a greater role at its margins the further addition of surface groundwater exchange fig 9 c introduces changes in the distribution of the hypersalinity hot spots and dry pixels but has little impact on the overall salinity distribution across the system comparing fig 9 b and c the sg60 scenario shows fewer dry cells inside the marsh i e white pixels surrounded by water and fewer isolated wet cells outside the marsh i e water pixels surrounded by white thus an effect of groundwater coupling is that cells inside the marsh are less likely to completely dry out through evaporation as the subsurface connection provides a water source similarly outside the marsh isolated pockets of surface water will infiltrate the subsurface to replenish the lost soil moisture due to soil moisture evaporation making it less likely to maintain isolated pockets of surface water when groundwater is included in a model these processes are illustrated in more detail with fig 11 discussed further below for the sg20 scenario fig 9d with lower initial groundwater salinity than sg60 fig 9c the hypersalinity in the lagoon is slightly reduced by the fresher subsurface water a few isolated wet cells inside the marsh show much lower salinity than their surroundings indicating locations where surface subsurface exchange is strong however the overall salinity of sg20 remains higher than s no evap indicating surface subsurface exchange is relatively insignificant compared with evaporation for the large scale salinity balance across the marsh fig 10 compares the spatial distribution of salinity for the s no evap s and sg60 scenarios during and after the first pumping event when pumping starts fig 10a c e the river fills with freshwater which enters the lagoon through two narrow channels the upstream channel fills the lagoon while the downstream channel pushes water towards the bay a region of hypersaline water is initially trapped between the freshwater from the channels in the lower lagoon and a second region of trapped hypersaline water is evident near the entrance to the bay the movement of mixing fronts in these regions is likely the cause of the salinity oscillations seen at the l5 and l6 locations in fig 8 j and l the overall behaviors are similar in all the scenarios although the water trapped in the lower lagoon is of higher salinity for evaporation cases similar to the conditions before pumping evaporation during pumping fig 10c results in more interior dry locations but these are somewhat ameliorated by the coupling of groundwater fig 10e importantly the groundwater coupling creates local hot spots that are sources of hypersalinity although these hypersaline hot spots do not appear to affect the overall salt balance they have the potential to significantly distort the perceived meaning of field data e g a field sensor located at a place that is strongly influenced by hypersaline groundwater will not provide a signal that is indicative of the broader salinity behavior in the nearby region arguably the field sensor l4 might be located near a hypersaline hot spot that is displaced from the model sensor which would explain the field model discrepancy in fig 8 h after the pumping is finished fig 10b d f the s no evap scenario has significantly fresher water than the s and sg60 cases with evaporation however none of the models can directly explain the field data at sites l1 and l2 in fig 8 b d beginning around day 170 when higher salinity water is observed in the upstream river as l2 has a stronger salinity signal than l1 this is clearly a tidal transport from downstream to upstream from the field observations the likely transport path for this water is through the lower connecting channel between the river and the lagoon at l5 fig 8j the upper channel is unlikely to be the salt transport path as l3 would be expected to have higher salinity than l2 which is not the case the l1 and l2 field model discrepancies are probably related to the effectiveness of the modeled tidal fluxes on salinity advection at l5 tidal salinity oscillations are strong after the pumping event in both field and model data but at l1 and l2 the model oscillations are much smaller than those observed these results indicate the modeled channel is effective at handling the strong unidirectional flux of a river inflow from l2 through l5 but is biased against an oscillating tidal flux that leads to upstream salinity transport from l5 to l2 an important conclusion is that the good representation of the daily water surface levels as shown in fig 8 is not sufficient to presume similar accuracy in modeling salinity the key point is that the net salinity transport is affected by the bias between upstream flux on the ebb tide and downstream flux on the flood tide to complete our analysis for marsh scale simulations of the effects of combined evaporation and groundwater coupling on hot spots as noted above a key impact of evaporation and groundwater fig 11 shows the subsurface salinity and the flow fields in the cross sections xs1 and xs2 at day 151 which is before pe1 cross section xs1 is located on the upper edge of the lagoon as shown in fig 6 a which is a typical location at the edge of inundation and hypersalinity for the lagoon from fig 11 a it can be seen there is a thin layer of surface water in an isolated wet cell y 220 m which is in the process of infiltrating into the subsurface and moving laterally to replenish the lost soil moisture due to evaporation in adjacent unsaturated soil also in fig 11 a a similar flow pattern is seen on the rim of the inundated lagoon at y 350 m the second example cross section xs2 is located in the continuum between the river and the bay that is the primary channel see fig 6a for downstream and tidal exchange fig 11 b shows that xs2 lies across two cells isolated by subgrid topography as indicated by the thin layer of surface water compared to their surroundings with surface subsurface exchange the surrounding wet cells provide water that keeps these isolated cells wet thus fig 11 illustrates the mechanisms that leads to the effects discussed in reference to figs 9 and 10 where introduction of the surface subsurface exchange tends to dry out wet cells that are isolated in a dry area while maintaining some surface water in cells surrounded by water that would become dry land without a groundwater source along the intertidal zone the subsurface flow is mostly uni directional from wet to dry regions thus the hypersalinity in dry pores from soil moisture evaporation does not have a subsurface lateral transport path to surface water it follows that hypersalinity is only diluted when tides winds or upstream inflows cause episodic or periodic flooding over the dry pores capturing wetting drying processes in numerical models is a notorious challenge e g caviedes voullieme et al 2020 garcia navarro et al 2019 medeiros and hagen 2013 the task is particularly difficult for the nueces system due to its small overall daily tidal range typically 0 5 m complex tide patterns ward 1997 and shallow depth to provide further insight on the effects of wetting drying fine resolution simulations are used to further understand the transport of salinity in the intertidal zone in section 4 3 below 4 3 small scale high resolution simulations from the marsh scale simulation results section 4 2 salinity of the surface water is affected by evaporation but does not appear sensitive to surface subsurface exchange however the coarse grid resolution for the marsh scale simulation cannot resolve detailed exchange processes near the river channels which is the focus of our small scale simulation approach using 1 m resolution as outlined in section 3 5 the key results for these simulations are provided in fig 12 which is a combined view of the subsurface salinity fields and fluxes for the base no evap and basex3 no evap scenarios that neglect surface evaporation but include soil moisture evaporation note that the additional scenarios including surface evaporation not shown are not significantly different in the mechanisms driving surface subsurface exchange in both cases illustrated in fig 12 lateral and vertical fluxes are strong underneath the intertidal zone 32 x 37 m and the lateral flow is generally from this moist intertidal zone to the dry upland regions x 32 m this is consistent with the 30 m model shown in fig 11 at low tide in the higher amplitude test case fig 12d a lateral subsurface flux flows down the topographic gradient but the magnitude is weak compared to the lateral upland fluxes on higher tides areas that are routinely uncovered by the tides see higher porewater salinity due to evaporation which is apparent by comparing the salinity from 34 x 37 m in fig 12 g and h the former belongs to the immersed zone and the latter is part of the intertidal zone these results imply that the key to model surface subsurface salt flux is the ability to correctly capture soil evaporation and wetting drying in the intertidal zone this is particularly challenging for the 30 m coarse grid model of the nueces delta because of its mild tidal range table 7 lists the mean salinity in the surface domain at the selected times shown in fig 12 together with the corresponding tidal elevation at the open boundary including surface evaporation base and increasing tidal amplitude basex3 creates a greater increase of the surface salinity relative to the trivial salinity increase of the base no evap scenario the increased tidal amplitude in the x3 scenarios causes more salt to be released from the subsurface in the intertidal zone but also increases the exchange flux at the boundary which is held at 40 psu for inflowing tides hence the net effect is somewhat variable when taken together fig 12 and table 7 illustrate that the local increase of surface salinity in the intertidal zone near the river bank is caused by an iteration of two mechanisms i soil moisture evaporation from dry uplands that leads to porewater hypersalinity and ii release of porewater salt into the surface water during tidal inundation however for the present case the flux of high salinity water from the intertidal zone into the ponded water is dwarfed by the effect of evaporative fluxes in the ponded water itself these results are similar to those from the marsh scale simulation section 4 2 confirming that surface subsurface exchange is relatively unimportant in perpetually submerged regions of the nueces delta 4 4 synthesis and future directions taken together the marsh scale and small scale simulations show that surface evaporation is more important than surface groundwater exchange in the evolution of hypersalinity for the upper nueces delta however the groundwater exchange does affect development of the hypersaline hot spots hence neglect of groundwater exchange will alter the modeled distribution and intensity of hot spots note that these hot spots are created through pore water evaporation and affect surface water salinity through episodic wetting drying however the small tidal range in this system provides limited opportunity for this mechanism overall both evaporation and surface groundwater exchange have marginal impact on marsh scale salinity patterns during the period modeled in the nueces delta longer simulations might show whether such wetting drying porewater exchange introduces a significant long term source of hypersalinity or if it is merely washed out in large rainstorms unfortunately such speculation cannot be confirmed or rebutted without inclusion of other neglected salinity processes that might be of equal importance our model neglects a range of processes including rainfall small scale topographic variability vegetation root zone dynamics transpiration soil heterogeneity and precipitation mobilization of dissolved porewater salt arguably two of the most important neglected processes are rainfall and transpiration which have been neglected for similar reasons we lack sufficient data to create robust models admittedly we could have easily included observed rainfall over the delta which would cause dilution of salinity throughout however in hypersaline systems the real world rainfall on dry land can mobilize hypersaline porewaters and previously precipitated salt in extreme cases the rainfall can cause a net increase in salinity if the mobilization of stored salts exceeds the rain s diluting effect thus including rainfall without also including antecedent porewater conditions and precipitation mobilization is to introduce a dilution bias in the model furthermore if rainfall during the 2 month simulation period had a significant impact we would expect to see a correlation between observed surface salinities at the six measurement stations and rainfall events the total rainfall during the 2 month simulation period was only 8 cm distributed over small storms and their timing showed no correlations with either salinity decreases or increases in the absence of a strong observable signal and lacking data for a reasonable model of antecedent conditions and precipitation mobilization of salt we believe neglecting rainfall is the best approach for the present work focusing on effects of including neglecting evaporation and groundwater unlike rainfall transpiration from delta vegetation is a one way process that should increase salinities modeling transpiration is relatively straightforward for continually immersed vegetation where the transpired moisture is directly linked to the surface water however in a wetting drying marsh system with groundwater the source of transpired moisture groundwater surface water or a combination depends on the depth of the root structure and the wetting drying processes we do not have sufficient data in plant distribution plant size root depths and mobilization of root zone hypersalinity to build a mechanistic model of transpiration for the upper nueces delta although transpiration is undoubtedly important over longer time scales in the delta as a contributor to hypersalinity it seems unlikely that it could be the primary driver of model data disagreement for the two months of this study e g fig 8 the unexpected development of hypersaline hot spots through the combination of evaporation and groundwater coupling presents challenges for future field data collection previously it has been considered sufficient to install individual sensors spread widely throughout a marsh arguably the model prediction of localized hypersaline hot spots requires deployment of a group of sensors at each location for example four sensors placed at corners of 60 60 m box twice the present model s grid resolution would be helpful in distinguishing a hypersaline signal representing the large scale salinity evolution from a hot spot in the long term a complete mechanistic model of salinity in a coastal marsh requires inclusion of all the salinity processes neglected herein in particular enabling salt precipitation in the pores and integrating hydrodynamics with the evolution of plant communities transpiration and root zone porewater salinization dunton et al 2001 alexander and dunton 2002 hughes et al 2012 rasser et al 2013 however we believe the present work shows that a major difficulties in accurately modeling hypersalinity in the upper nueces delta are i getting the correct accumulated tidally driven salt fluxes through narrow channels and ii obtaining field data that is sufficiently robust to spatial hot spots of hypersalinity we contend that the major disagreements between measured and observed salinity in fig 8 are unlikely to be addressed by the introduction of more salinity processes which are unlikely to be larger than the introduction of evaporation that was modeled herein despite the neglected salinity processes in our modeling the present work successfully i built and tested a marsh salinity model with asynchronous surface groundwater coupling and ii explained the mechanisms how surface groundwater exchange affects marsh hypersalinity i e through soil evaporation during drying followed by release during flooding rather than through lateral subsurface transport with the mature surface groundwater salinity simulation framework developed herein future studies should focus on improving the subgrid topography model to obtain better prediction of net salinity fluxes driven by wind and oscillating tides 5 conclusions a coupled hydrodynamic and variably saturated subsurface flow model frehg is developed and applied to simulate the evolution of salinity in a shallow coastal marsh frehg solves the full shallow water equations in the surface domain and the density dependent 3d richards equation in the variably saturated subsurface domain the frehg model is validated using benchmark problems in the literature and applied to the upper nueces delta in texas usa to investigate relationships between surface and soil moisture evaporation surface subsurface exchange and observed hypersalinity a subgrid approach and asynchronous surface subsurface coupling are used to create a model that can simulate a large scale region without requiring supercomputer resources the salinity of the upper nueces delta is modeled at two different scales i a marsh scale 2d surface and 3d subsurface simulation that addresses spatial variability over complex topography and ii a fine resolution 1d surface and 2d subsurface simulation that focuses on the wetting drying of the intertidal zone from a computational viewpoint the present work demonstrates that asynchronous coupling between the surface and the subsurface domains significantly reduces computational cost by over 80 the coupling error can be quantified with three dimensionless parameters the error ratio of exchange flux eq 18 the error ratio of dispersive flux eq 19 and the péclet number eq 20 these parameters can serve as the criteria to optimize the selection of subsurface time step δ t g the study illustrates two key mechanisms through which surface subsurface coupling affects the model results in the large scale simulation specifically 1 as soil moisture evaporation removes porewater surface water in the nearby inundated regions will infiltrate through the subsurface and move laterally to replenish the lost soil moisture as a result including surface subsurface exchange leads to fewer isolated dry cells in the marsh interior and fewer isolated wet cells outside the ponded area 2 the subsurface flux is primarily from moist to dry regions which pushes near surface groundwater up the topographic gradient in the model resolved topography of the intertidal zone thus hypersaline porewater does not have a subsurface flux path back into ponded surface water instead the surface subsurface exchange is dominated by tidal inundation of the pores a key observation is that heterogeneity in the wetting drying tidal fluxes leads to the development of isolated hot spots of hypersalinity however the fine resolution simulation reveals that surface subsurface exchange in the intertidal zone is driven by micro topography that may not be well represented in a marsh scale coarse grid model soil moisture evaporation enhances pore salinity as the tide retreats and the accumulated salt enters the surface water during subsequent flooding this process only occurs close to the wetting drying front a large tidal amplitude can extend the range of the intertidal zone and enhance this salinity exchange for the shallow micro tidal upper nueces delta evaporation and surface subsurface exchange do not explain the majority of the discrepancies between modeled and measured salinity instead topographic features below the grid resolution are likely responsible for biases in the modeled water and salt fluxes through narrow channels to address these issues future studies should include i collecting high resolution field data and ii developing more robust numerical techniques to handle subgrid scale topography credit authorship contribution statement zhi li conceptualization methodology software validation formal analysis resources writing original draft visualization project administration funding acquisition ben r hodges formal analysis resources writing review editing xia shen writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by the fundamental research funds for the central universities china the national natural science foundation of china grant no 52109101 and the key research and development projects of shannxi province china grant no 2022sf 443 the authors would like to thank the texas water development board for providing the field data for surface elevation and salinity at the nueces delta open research software for this research i e the frehg model is under development at https github com zli90 frehg the version used in this manuscript together with the input data of the test problems are available at https github com zli90 frehg tests last accessed on june 18th of 2022 
2258,a coupled surface water and variably saturated groundwater model is developed for a coastal salt marsh nueces delta texas usa to evaluate the relative impacts of common model simplifications the new model is compared against a prior salinity transport model that neglects evaporation and groundwater coupling both marsh scale at coarse grid resolution and bank scale at fine grid resolution simulations are used to examine the flux mechanisms in the intertidal zone where soil moisture evaporation and groundwater fluxes contribute to hypersalinity new numerical methods provide the groundwater surface water coupling mechanisms necessary for practical marsh scale simulations using the two dimensional 2d shallow water equations for surface water and the density dependent 3d richards equation for groundwater an asynchronous surface subsurface coupling scheme is shown to significantly reduce the computational cost of marsh scale simulations comparison of marsh scale and bank scale results indicates that a coarse model grid can represent the mechanisms of surface subsurface salinity flux in the intertidal zone but likely misrepresents the inundation effects of topography smaller than the model grid due to relatively weak tidal amplitudes at the study site surface water evaporation is a stronger driver of hypersalinity than surface subsurface exchange induced by soil moisture evaporation the combination of evaporation and groundwater exchange creates small hypersalinity hot spots that do not appear in the simulations neglecting these processes however including these processes has only a marginal impact on comparisons with field data previously collected in the marsh both types of simulations have good agreement for surface water volumetric transport as evidenced by water surface levels but the remaining model field disagreement in salinity appears to be dominated by biases in salinity transport for oscillatory tidal wind driven fluxes through narrow channels keywords surface subsurface exchange shallow coastal wetland hypersalinity numerical modeling data availability data will be made available on request 1 introduction salt marshes serve important ecological functions xin et al 2022 but can be threatened by hypersalinity that damages a marsh ecosystem and affects survivability of aquatic species ritter et al 2005 bighash and murgulet 2015 stachelek and dunton 2013 wilson and dunton 2018 the evolution of salinity in a coastal marsh is affected by multiple environmental forces including tide wind precipitation evaporation and surface subsurface exchange guimond and tamborski 2021 the complex interactions among these factors lead to widely varying spatial and temporal patterns of salinity which necessitates extensive field observations and detailed numerical modeling to evaluate driving processes a critical question is the relative importance of surface water evaporation versus soil moisture evaporation on the development of surface water hypersalinity the creation of porewater hypersalinity through soil moisture evaporation is a product of successive wetting drying processes in the intertidal zone and is inherently tied to near subsurface transport as yet the overall importance of porewater hypersalinity to surface water salinity is not understood but is likely dependent on both marsh topological structure and environmental forcing the challenge for understanding hypersalinity development is that it arguably requires a coupled surface subsurface model to correctly capture porewater hypersalinity in the intertidal zone in this study we explore this idea using a coupled surface and subsurface water numerical model to investigate mechanisms developing hypersalinity in the upper nueces river delta texas usa which is also known as the rincon bayou this saltwater marsh has been the subject of a number of studies and management interventions including creating artificial channels and providing additional freshwater pumping into the upper reaches riera et al 2000 ward et al 2002 montagna et al 2002 palmer et al 2002 buyukates and roelke 2005 montagna et al 2017 in shallow marshes surface water evaporation directly increases salinity of ponded water in the system as the evaporation rate is relatively uniform over a body of ponded water its effect is necessarily felt by creating higher salinities in shallower water which may be subsequently mixed through the system by inflows winds and tides soil moisture evaporation plays a key role in porewater and the near surface groundwater after tide retreats leading to reduced soil moisture that amplifies subsequent surface subsurface exchange for intertidal zones li and hodges 2021 as the soil moisture decreases porewater becomes hypersaline murgulet et al 2016 stachelek and dunton 2013 the balance between pore capillarity and gravity could form a stable saline layer in the subsurface zheng et al 2022 when dry or hypersaline pores are later flooded the stored salt is a potential source of salinity for the surface water bighash and murgulet 2015 shen et al 2018 evapotranspiration from marsh vegetation can also enhance porewater hypersalinity e g hughes et al 2012 furthermore hypersaline pore water could precipitate forming efflorescence or subflorescence that block the hydraulic connection in the pores e g zhang et al 2014 however these two mechanisms are neglected in the present study due to the lack of data and mature mathematical models the likely consequences of this and other limitations are discussed in section 4 4 prior modeling studies have examined the surface subsurface exchange across the coastal margin typically with a focus on understanding how tidal variations affect the subsurface transport common test problems use a two dimensional 2d vertical plane through the surface and subsurface with one dimensional 1d land topography that represents a simple beach slope or river bank e g abarca et al 2013 lenkopane et al 2009 heiss and michael 2014 kuan et al 2019 robinson et al 2014 shen et al 2018 xiao et al 2019 xin et al 2017 yang et al 2018 yu et al 2019 the surface flow in these models is typically a simple tidal rise and fall that provides the surface pressure influencing subsurface fluxes these 1d 2d models are appropriate for examining surface subsurface exchange between ocean and the near shore aquifer where tidal forcing is dominant robinson et al 2007 but inherently neglect the complex multi scale topography that attenuates tidal intrusion in a salt marsh and controls the local surface subsurface exchange xu et al 2021 torres and styles 2007 recent research has shown that surface subsurface exchange is sensitive to topography and varies with the distance from the river channels chen et al 2018 liu et al 2022 xin et al 2017 xu et al 2021 yu et al 2016 thus to fully understand the fate of salt in a marsh a coupled surface subsurface model needs to simulate 2d flow through complex surface topography and 3d flow through the subsurface cantelon et al 2022 xin et al 2022 extending coupled surface subsurface models from 1d 2d to 2d 3d inevitably increases the computational cost with the rapid development of parallel computing technology several coupled 2d 3d models have emerged in hydrology including parflow kollet and maxwell 2006 hydrogeosphere brunner and simmons 2012 hwang et al 2014 pihm kumar et al 2009 paws shen and phanikumar 2010 and pflotran wu et al 2021 field scale studies have also examined the transport of solute across surface subsurface regimes liggett et al 2015 daneshmand et al 2019 unfortunately large catchment scale models in hydrology often treat surface flow with the kinematic or the diffusive wave approximations which reduce the fidelity of the surface water physics this approach might be suitable for well sloped uplands but creates problems for coastal marshes where upland inflows meet the tide li and hodges 2021 showed that coastal marshes require the full shallow water equations swe to correctly model the interaction mechanics of tidally driven flow and surface subsurface exchange for complex topography the computational challenge is that fine horizontal grid resolution δ x δ y and a small time step δ t are required for the swe in the surface domain to capture fluxes through the maze of channels in a marsh in general reducing the surface water grid δ x δ y by a factor of 1 2 n results in an 8 n increase in computational cost for the surface water model which can quickly overwhelm available computational power on the other hand the 3d subsurface domain is computationally demanding because it requires 3d rather than 2d grid cells but the spatial and temporal scales of subsurface processes can be reasonably represented at much coarser grid resolution and larger time steps the residence time of subsurface salinity is often years to decades lenkopane et al 2009 which theoretically permits the use of a nonconforming and asynchronous surface subsurface coupling scheme to reduce computational cost in practice however such schemes inevitably introduce coupling errors fiorentini et al 2015 in addition the subsurface grid cells still need to be refined near the river channels because much of the surface subsurface exchange is affected by processes within a few meters of the channels gardner 2005 xin et al 2017 furthermore the vertical grid resolution δ z in a subsurface model also needs to be refined in the unsaturated region due to strong nonlinearity of processes near the surface mao et al 2021 finally the shallow pore water near the surface subsurface interface evolves at tidal time scale guimond and tamborski 2021 which constrains the time step for the subsurface simulation with these limitations it remains challenging to achieve a reasonable computational cost for coupled 2d surface and 3d subsurface marsh simulations prior models have made compromises in the physics represented to constrain computational costs such as assuming fully saturated subsurface domain langevin et al 2005 spanoudaki et al 2009 or using simple synthetic topography xin et al 2011 xu et al 2021 as a further limitation of the state of the art prior 3d coastal simulations have generally focused on hydrology and hydrodynamics neglecting the density driven transport of salinity guimond et al 2020 moffett et al 2012 xin et al 2022 xu et al 2021 zhang et al 2018 in this work we seek to step beyond the compromises of prior models herein a coupled surface subsurface model named frehg is developed section 2 applied to a shallow coastal salt marsh section 3 and model results are compared to field observations to investigate salt dynamics section 4 the previous version of frehg presented in li and hodges 2021 featured i solutions of the full swe for 2d surface flow ii the richards equation for 3d variably saturated subsurface flow and iii the ability to model evaporation and precipitation for both open water and dry unsaturated ground new to the present work are i a density driven salinity transport module to model the flux of salt in the surface water and the near surface unsaturated zone ii a terrain following mesh system that better represents marsh topography iii an asynchronous surface subsurface coupling scheme and iv incorporation of a subgrid topography model li and hodges 2019b the latter two methods are used to enhance computational speed for practical computation of marsh scale systems the coupling error caused by the asynchronous coupling is quantitatively analyzed and controlled sections 2 5 and 3 4 to evaluate the effects of using coarse grid resolution for full marsh scale simulations a fine resolution model using a 1d surface and 2d subsurface approach is also performed for a smaller domain along the marsh bank the structure of the frehg model and its application in the present study has been summarized in fig 1 the three goals of this study are i exploring how surface water evaporation soil moisture evaporation and surface subsurface exchange contribute to hypersalinity in a south texas marsh ii investigating whether the small scale processes revealed from the fine resolution simulation are reasonably represented in a coarse resolution large scale model and iii evaluating the efficacy of a spatial temporal upscaling approach subgrid model with asynchronous coupling in reducing the computational cost of coupled 2d surface and 3d subsurface marsh simulations this study confronts and is limited by a common question how to make effective use of field data that were expensive to collect but are inherently limited in scope the original field study in the nueces delta was focused on surface fluxes of salinity driven by freshwater pumping and neglected time space varying data for a wide range of secondary processes that affect salinity e g rainfall small scale topographic variability vegetation root zone dynamics transpiration soil heterogeneity subsurface salinity and precipitation mobilization of dissolved porewater salt although models for all such effects can be proposed introducing them into a comprehensive model at this time leads to the number of parameters overrunning the available data herein we claim only a modest step forward in modeling some of the mechanics involved in the complex salinity behaviors of a coastal marsh specifically to the coupling of surface subsurface salinity fluxes with evaporation in an existing surface water salinity transport model the validation of our modeling methods is necessarily limited to simplified theoretical and experimental data sets that exclude the neglected salinity processes for marsh scale systems we examine the relative effect of groundwater coupling and evaporation through model model comparisons and examine whether model data agreement is improved by adding the additional processes we revisit the issues of neglected processes in field data comparisons in section 4 4 and discuss the next steps needed for modeling and collecting field data in coastal marshes 2 methods 2 1 overview the fine resolution environmental hydrodynamics and groundwater model frehg couples a 2d hydrodynamic model with a 3d variably saturated groundwater model li and hodges 2021 in frehg the surface and the subsurface domains solve their own system of equations fig 1 as discussed in sections 2 2 and 2 3 the pressure head and flux across the domain interface are used as boundary conditions salinity transport is outlined in section 2 4 frehg is designed to allow either domain to be run in isolation or coupled together using asynchronous methods which are discussed in detail in section 2 5 validation of the new method against a benchmark case is provided in section 2 6 2 2 surface hydrodynamics the surface flow module of frehg is a 2d version of an existing 3d hydrodynamic model frehd hodges 2014 hutschenreuter et al 2019 li and hodges 2019a with additional functions that parametrize subgrid scale topography li and hodges 2019b 2020 in the surface domain frehg solves the 2d depth integrated navier stokes equations i e the swe the integral form of the swe can be written as 1 t ω η d ω γ u n d γ q s 0 2 v u t u n u x d v γ g η n d γ γ τ ν n d γ ω τ w τ b d ω where η is the free surface elevation u u v t are depth averaged velocities x x y t are the corresponding cartesian axes g 0 0 g t is the gravity vector n is the normal unit vector to a cell edge τ ν is the viscous stress τ w and τ b are the surface wind and the bottom stresses whose expanded forms can be found in li and hodges 2019a b q s is a volumetric source sink term that could represent evaporation rainfall and or inflow d v is an infinitesimal volume inside a grid cell d γ and d ω are the infinitesimal side and top face areas of a grid cell unlike common swe that uses depth and flow rates as primary variables eq 1 and 2 use η and u which are consistent with the frehg codes the density of surface water is assumed to be a constant more details on the discretization scheme and the constraints on time step can be found in li and hodges 2019a 2021 and citations therein to enhance computational efficiency frehg is designed to operate on a cartesian grid at coarse resolution e g 30 m as used herein relative to the scales of channels and obstructions that appear in high resolution 1 m topographic data as described and demonstrated in li and hodges 2019b a subgrid topography model can be used to upscale the hydraulic effects of small scale features apparent in high resolution lidar data obtained at low tide this approach enables coarse resolution hydrodynamic simulation without losing the important water blocking features hodges 2015 and the fluxes in the narrow river channels 2 3 variably saturated subsurface flow in the subsurface domain frehg solves the density dependent 3d richards equation boufadel et al 1999 geng and boufadel 2015a here to be consistent with the finite volume discretization used in frehg the generalized richards equation is written in the integral form 3 v β s s θ ϕ ψ t β θ t θ β t d v γ q n d γ where ψ is pressure head θ is water content ϕ is porosity s s is specific storage v and γ represent the volume and surface area of a grid cell n is the normal vector and q is the flux vector whose components represent the darcy flux between grid cells 4 q j β δ k ψ cos ω ψ x j β g j g sin ω where j 1 2 3 k ψ is the hydraulic conductivity ω is the angle between the connection of two cell centers and the horizontal axis maxwell 2013 the use of ω guarantees that the fluxes are calculated correctly in a terrain following mesh fig 2 which provides more flexibility when complex topography exists in the vertical direction j 3 no horizontal component is needed when estimating the flux thus eq 4 returns to its original form which is equivalent to forcing cos ω and sin ω to 1 and 0 respectively note that unlike surface cells for a subsurface cell eq 4 is applied to all 6 faces so the side face γ and the top face ω do not need to be distinguished β and δ are the density and viscosity ratios that can be related to the salinity c 5 β 1 ϵ c 6 δ 1 ζ c in the present study the above fitting parameters take values ϵ 7 63 1 0 4 m2 kg and ζ 1 566 1 0 3 m3 kg frehg solves the 3d richards equation using the predictor corrector allocation pca scheme the pca scheme is non iterative which guarantees the error bounded by the underlying discretization scheme li et al 2020 li and hodges 2021 the nonlinear relationships between k and ψ θ and ψ are estimated with the mualem van genuchten model mualem 1976 van genuchten 1980 7 s ψ 1 α ψ n m 8 θ ψ θ r ϕ θ r s ψ 9 k ψ k s s ψ 1 2 1 1 s ψ 1 m m 2 where s is the saturation k s is the saturated hydraulic conductivity θ r is the residual water content α and n are the soil parameters and m 1 1 n frehg provides options to model evaporation and or rainfall in both surface and subsurface domains evaporation and rainfall rates are introduced either as constants or time dependent inputs to frehg for exposed dry lands an alternative option is to estimate evaporation rate from the subsurface using a bulk aerodynamic model which represents evaporation flux as a function of the water content more details on the bulk aerodynamic model can be found in geng and boufadel 2015b and li and hodges 2021 in the subsurface domain without overlying surface water the evaporation and rainfall rates are applied as flux boundary conditions on the topmost subsurface layer 2 4 salinity transport in the surface domain the transport of salinity or any conserved passive scalar is modeled using the 2d advection diffusion equation 10 c t u j c x j x j κ c x j where c is the salt concentration kg m 3 and κ is the turbulent diffusivity it has been shown that the modeled salinity is not sensitive to the horizontal turbulent diffusivity wang et al 2009 so κ is set to a constant in frehg eq 10 is discretized fully explicitly in time the advection term is discretized using the total variation diminishing tvd scheme with roe s superbee limiter to suppress numerical diffusion gross et al 1999 with the density dependent richards equation eq 3 3d salinity transport in the subsurface domain can be modeled using the 3d advection diffusion equation 11 θ c t q j c x j β x j θ d c x j where d is the dispersion tensor whose components are functions of the longitudinal dispersion coefficient α l the transverse dispersion coefficient α t and the molecular diffusivity d m bear 1972 geng and boufadel 2015b the expanded forms of d 11 and d 12 can be found in eq 12 13 as an illustration similar to the surface domain eq 11 for the subsurface domain is solved with an explicit finite volume scheme the tvd method is used for the advection term 12 d 11 α l q 1 2 α t q 2 2 α t q 3 2 q θ d m 13 d 12 α l α t q 1 q 2 q 2 5 asynchronous coupling the coupling between the surface and the subsurface domains is illustrated in fig 2 on the top boundary of the subsurface domain if the corresponding surface cell is wet i e h 0 water depth is used as the boundary condition for ψ in eq 3 if the corresponding surface cell is dry the boundary head is set to zero but only exfiltration is allowed because there is no surface water available to infiltrate with the subsurface boundary head equals the surface water depth the flux across the surface subsurface interface can be estimated as 14 q s s β δ k ψ t o p h δ z 2 β where q s s is the vertical exchange flux ψ t o p is the pressure head at the topmost subsurface cell in the surface domain the exchange flux q s s is converted into an equivalent increase decrease of the free surface and is added subtracted to the current surface elevation salinity transport at the surface subsurface interface is implemented in a similar approach for the subsurface domain surface salinity is enforced on the topmost cells as dirichlet type boundary conditions and the numerical calculation follows eq 11 for the surface domain since no boundary condition exists in the vertical direction the advective diffusive salt flux is treated as a source term of eq 10 for example the salinity across the interface over one time step is estimated as 15 c s s q s s c u p β j s s where c s s is the salinity flux in k g m 2 s across the surface subsurface interface c u p is the salinity of the upwind cell and j s s is the longitudinal vertical dispersive flux transverse dispersion is neglected because the exchange flux q s s only exists in the vertical direction eq 15 is essentially a simplified and discretized version of eq 11 surface water hydrodynamic simulations typically require smaller time step δ t s for stability whereas groundwater simulations allow greater time step δ t g asynchronous coupling exploits this difference to improve computational efficiency by allowing the surface and subsurface domains to follow their own timelines e g spanoudaki et al 2009 yuan et al 2011 by default the surface time t s equals the global time t of the frehg model asynchronous coupling is achieved by adding a simple conditional statement in the codes such that the subsurface solver is only executed while the subsurface time t g δ t g t fig 3 note that the subsurface simulation uses adaptive δ t g li et al 2020 so it is possible that δ t g δ t s in rare situations when this happens frehg will simply perform multiple subsurface steps per surface step which is more flexible and robust compared with setting a fixed ratio between δ t g and δ t s unfortunately asynchronous coupling introduces another error source in the exchange flux in the frehg coupling scheme when the subsurface model is executed the subsurface time is typically δ t g behind the surface time following eq 14 the surface subsurface exchange flux is then 16 q s s async t g β δ k ψ t o p t g h t g δ t g δ z 2 β where the superscripts represent the time level assuming that β δ and k vary slowly in time such that their time dependency can be ignored and that eq 16 can be linearized then using first order taylor expansion the exchange flux can be further rewritten as 17 q s s async t g β δ k ψ t o p t g h t g δ z 2 β β δ k δ t g δ z 2 h t where the first term on the right hand side is the true flux when the two domains are synchronous q s s sync t g and the second term on the right hand side is the coupling error ideally the coupling error should be negligible compared with q s s sync t g this can be mathematically expressed by defining an error ratio for the exchange flux r q 18 r q q s s sync t g δ z 2 β δ k δ t g h t 1 1 eq 18 is an indicator of the coupling error associated with asynchronous coupling of the exchange flux however according to eq 10 and 11 the transport of salinity is governed by both advection and dispersion the error in the exchange flux affects the advective transport of salinity but if dispersive transport is dominant the error in flux could be unimportant to analyze this problem an error ratio for the dispersive flux r d can be defined similar to eq 18 19 r d j s s sync t g δ z 2 β δ d z z δ t g c s t 1 1 where j s s sync is the longitudinal dispersive flux across the surface subsurface interface d z z is the longitudinal dispersion coefficient in the vertical direction and c s is the salinity of the surface water finally the péclet number can be used to assess the relative importance of advection versus dispersion 20 p e q s s δ z α l q s s 2 q d m the constraints on asynchronous coupling can be evaluated using eq 18 20 the péclet number is estimated first to determine if advection or dispersion dominates surface subsurface salinity exchange depending on the péclet number r q and or r d is calculated to examine if the coupling error is small enough to be neglected if not δ t g needs to be reduced to constrain the coupling error 2 6 validation against benchmark case the original frehg model without density dependency and salinity transport has been validated in li and hodges 2021 using benchmark problems that focus on surface runoff and surface subsurface exchange in this section we focus on validating the density driven scalar transport functions and the asynchronous coupling scheme that are newly developed for frehg validation of the model for full scale application is provided in section 3 4 the validation problem is designed to reproduce the seawater intrusion experiment by kuan et al 2019 the computational domain approximates a typical beach slope with dimensions and boundary conditions illustrated in fig 4 the soil properties and other related parameters can be found in table 1 two types of surface boundary conditions are tested steady free surface ss and sinusoidal tidal oscillation td for each boundary type three scenarios are performed which are i synchronous coupling both δ t s and δ t g are 0 05 s ii asynchronous coupling with a maximum δ t g 0 5 s and iii asynchronous coupling with a maximum δ t g 1 s for each scenario the simulation is performed for 10 h fig 5 shows the mean salinity profiles of each simulation averaged from 8 to 10 h it can be seen that with synchronous coupling both ss and td produce good model data agreements with a steady free surface the simulation results are not sensitive to δ t g that is both synchronous and asynchronous coupling generate similar model predictions when tide is introduced however frehg underestimates subsurface salinity when δ t g and δ t s are asynchronous the predicted intrusion distance of sea water is also shorter to quantitatively understand the difference between the ss and td scenarios the error ratios are examined as shown in table 2 the r q values are much greater than 1 for ss but less than 1 for td these results indicate that the flux error is negligible for the ss scenarios but is important for the td scenarios the péclet numbers for both scenarios are greater than 1 indicating a dominant role of advective transport thus as observed in fig 5 the large flux error for td has a direct impact on the predicted salinity this result shows that the error ratio and the péclet number together can be used as the criteria to constrain the time steps with asynchronous coupling 3 model application 3 1 overview this section describes the application of frehg to the upper nueces delta located along the gulf of mexico coast of texas usa near the city of corpus christi as illustrated in fig 1 model application includes a marsh scale coupled 2d hydrodynamic and 3d subsurface simulation complemented by a high resolution coupled 1d hydrodynamic and 2d subsurface simulation the former is designed to understand the interactions of different environmental processes at marsh scales whereas the latter examines the details of salinity transport in a typical intertidal zone where substantial surface subsurface exchange occurs the following subsections illustrate the study site model configuration and validation 3 2 study site the nueces delta is a shallow marshland located northwest of nueces bay as part of the corpus christi bay and estuary system the nueces delta experiences episodic hypersalinity as a result of decreased freshwater inflow and insufficient tidal flushing del rosario and montagna 2018 hill et al 2015 to reduce salinity and restore the marsh ecosystem a pump station was built to provide a source of freshwater from upstream of the first weir on the nueces river into the upper end of the rincon bayou see fig 6 the pumping station has been in occasional use since 2007 to moderate episodes of hypersalinity in the delta prior hydrodynamic simulations of the entire nueces delta li and hodges 2019a showed good model data agreements for salinity in the lower nueces delta where tidal force is dominant in the upper nueces delta where complex topography weakens the tidal intrusion the model generally underestimated salinity the simplest hypothesis for model error is the neglect of evaporation and surface subsurface exchange in the work of li and hodges 2019a evidence in the literature supports this hypothesis for example alexander and dunton 2002 performed field measurements to confirm the correlation between salinity in the surface water and the hypersaline pore water of the upper nueces delta further studies found that both evaporation and surface subsurface exchange are important processes that cause hypersalinity in south texas marshes bighash and murgulet 2015 murgulet et al 2016 3 3 configuration marsh scale simulation the bathymetry of the marsh scale computational domain for the present work is shown in fig 6 a which was developed from the 1 m resolution lidar data of the nueces delta following upscaling and subgrid modeling approaches developed in hodges 2015 li and hodges 2019a b in the full nueces delta as modeled in li and hodges 2019a the rincon bayou extends through the right boundary of fig 6 a providing a connection to the lower nueces delta nueces bay corpus christi bay and the gulf of mexico not shown in this study to reduce computational cost we follow the approach of li and hodges 2019b in replacing the lower nueces delta with an artificial bay and boundary conditions that mimic the hydraulic influence of the lower section of the tidally driven marsh system as illustrated by field data presented in li and hodges 2019a the tidal elevation in the lower marsh closely tracks the tidal elevation in nueces bay and the salinity tends to be spatially homogeneous which is not the case for the upper delta in fig 6 a the upper nueces delta consists of three regions the main stem of the rincon bayou referred to herein as the river the relatively isolated west lake the lagoon and the deep artificial bay the bay that represents the lower delta the three regions are connected by narrow twisted channels sites l1 l7 are the locations of monitoring stations at which time dependent water level and salinity data were collected from 2012 to 2013 at 15 min intervals by the texas water development board the data are extensively illustrated in li and hodges 2019a sites xs1 and xs2 are the cross sections at which modeled subsurface salinity and flow field from the marsh scale simulations are examined in detail site topo1d near l5 is the location where the high resolution 1d topography displayed in fig 6b is used for the small scale fine resolution study section 3 5 to efficiently simulate the upper nueces delta the horizontal grid resolution is set to 30 m across the entire domain the prior modeling study of the upper nueces delta li and hodges 2019b showed the subgrid model at this resolution provides a reasonable representation of the hydraulic connectivity and salinity fluxes when compared with higher resolution modeling the subsurface domain extends to z bot 6 5 m navd88 downward using n layer 10 vertical layers the vertical grid resolution is calculated through eq 21 δ z i j 0 b i j z bot k 0 n layer r z k 21 δ z i j k 1 r z δ z i j k where i j k are the zero based grid indices in the x y z directions b i j is the bottom elevation of the ground surface and r z is the ratio of increment for δ z which is 1 4 in the present study applying eq 21 results a variable vertical grid resolution in the subsurface ranging from about 0 1 to 3 m increasing with depth in the upper nueces delta a horizontal 120 m buffer zone is delineated around the permanently and partially wet zones grid cells outside the buffer zones are marked inactive and do not participate in the computation in this way the total number of active surface and subsurface grid cells is reduced to 156222 from the 266200 cells implied by the full domain in fig 6 a all simulations were performed in serial mode on a macbook pro laptop with an intel core i9 processor a constant δ t s of 15 s was used for the surface hydrodynamic simulations the subsurface flow is modeled with a maximum δ t g of 120 s it has been previously shown that coupled surface subsurface simulations are sensitive to the hydraulic conductivity of the subsurface domain guimond et al 2020 for the present study unfortunately the soil properties and the initial states of the subsurface were not collected as part of the 2012 2013 field campaign which focused on surface water salinity lacking such data separate model runs were configured with different subsurface properties to examine the model sensitivity to uncertain parameters the simulation scenarios are summarized in table 3 where s represents the reference scenario that models surface water only which is similar to li and hodges 2019b a scenario sg60 is configured with an isotropic saturated conductivity of 1 1 0 6 m s and a uniform initial salinity of 60 psu in the subsurface two additional scenarios sg60k sg20 were constructed by increasing the hydraulic conductivity and decreasing the initial salinity respectively for the baseline cases evaporation is enabled for both surface and subsurface domains to evaluate the importance of surface evaporation each of the scenarios in table 3 were repeated with surface evaporation turned off these cases are denoted as e g sg20 no evap table 4 lists the model parameters that were kept constant in all scenarios of table 3 a spin up simulation was performed from april 1st to may 15th of 2013 to create reasonable initial states see appendix in li and hodges 2019a the testing simulations were executed from model days may 15th to july 14th of 2013 the water level and salinity observed at l7 are uniformly applied along the open boundary of the bay fig 7a all other side boundaries of the surface domain are closed all side and bottom boundaries of the subsurface domain are impervious except the left inland boundary where a fixed water table at 0 5 m navd88 is enforced this upland water table has weak influence on the simulation results due to the relatively large spatial scale and short simulation time the wind stress is uniformly applied to the surface domain with wind data obtained from the nueces delta weather station tcoon 2013 the pumping data for flow into the upper end of the river fig 7b is obtained from the website of the nueces river authority nueces river authority 2013 a constant evaporation rate of 4 1 0 8 m s is applied uniformly on the surface water which was estimated from the monthly evaporation data of texaset 2022 for the subsurface domain the bulk aerodynamic model is used to estimate soil moisture evaporation when the ground surface is dry rainfall transpiration antecedent soil porewater composition and precipitation mobilization of salt are processes affecting salinity that are neglected in the model as discussed in section 1 and revisited in section 4 4 3 4 validation of coupling scheme for marsh scale model the asynchronous coupling scheme has been validated for the upper nueces delta by comparing asynchronous against synchronous model results the frehg model sg60 scenario was executed in fully synchronous mode δ t s δ t g 15 s for 1 day and compared to the sg60 asynchronous model with δ t g 120 s the error ratios r q r d and péclet number p e of eqs 18 19 and 20 are used for validation at the six field monitoring sites as presented in table 5 it can be seen that at l2 l5 the péclet numbers are all much less than 1 and the r d ratios are all much greater than 1 these results imply the salinity transport across the surface subsurface interface is dominated by dispersion and the coupling errors in the dispersive flux are negligible at l1 and l6 the péclet numbers are around 0 5 meaning that both advective and dispersive processes are important in this situation both r q and r d need to be examined since they are both much greater than 1 at these two locations it is safe to assert that the error due to asynchronous coupling is negligible at all six locations in terms of computational cost the wall clock times are 164 and 31 min for the 1 day synchronous and asynchronous simulations respectively thus applying asynchronous coupling results in an 81 decrease in the total simulation time 3 5 configuration small scale simulation the high resolution small scale simulations with 1d surface water and 2d subsurface are designed to investigate surface subsurface exchange in the intertidal zone at the small length scales that cannot be captured at the coarser grid resolution of the marsh scale simulation our goals are i to simulate the subsurface fluxes at higher resolution to provide insight into the results of the marsh scale model and ii to evaluate whether the surface subsurface exchange at small scales in the intertidal zone can significantly impact the salinity of the adjacent perpetually flooded zone for these simulations the bottom topography is extracted from the intertidal zone near sensor l5 topo1d in fig 6a the domain for all the small scale simulations is shown in fig 6 b the surface domain has a length of 150 m which is discretized at a grid resolution δ x 1 m the vertical discretization is same as the marsh scale simulation as described above the surface and the subsurface domains are synchronous with δ t s δ t g 1 s all other parameters are same as in table 3 four scenarios are used for these simulations with different water surface elevations enforced at the tidal boundary to examine the role of the intertidal range on small scale salinity exchange the baseline scenario base uses measured water level data from sensor l5 for the tidal elevation this scenario includes model processes for both soil moisture evaporation and surface evaporation the second scenario is labeled as basex3 to indicate the tidal amplitude is increased by a factor of three while the mean tidal level is held constant similar to the marsh scale simulation two additional scenarios are created by turning off surface evaporation e g base no evap all scenarios are modeled for eight days from june 1st to 8th of 2013 the initial pressure and moisture of the subsurface domain are obtained from a 15 day spin up simulation of the base scenario all scenarios use a constant initial salinity of 40 psu in the surface domain the subsurface domain and as the downstream boundary condition 4 results and discussion 4 1 overview the results for the simulation of the upper nueces delta are provided in section 4 2 with a focus on model model comparisons that illustrate how inclusion of evaporation and groundwater coupling affect salinity predictions relative to the previous surface water only model the available field data are provided to illustrate the scale of model field differences that existed in prior work li and hodges 2019a b and are not significantly ameliorated by inclusion of evaporation and groundwater coupling in section 4 3 we examine higher resolution simulation of salinity fluxes at the intertidal exchange to see if the coarse resolution of our marsh scale simulation is likely to cause underprediction of groundwater coupling impacts in section 4 4 we provide a synthesis of our observations on the state of the art for modeling salinity in coastal marshes a discussion of neglected processes and the requirements for comprehensive field data collection to support future modeling note that model validation is presented against benchmark data in section 2 6 and for the marsh scale surface groundwater coupling in section 3 4 4 2 marsh scale simulation the left column of fig 8 shows the evolution of surface elevation at l1 l6 during the 60 day simulation period it can be seen that the trends of the modeled surface elevation generally match the measured data site l2 is anomalous in that there is an initial period from 145 170 days relative to 2013 1 1 where the model underpredicts the surface elevation by 0 3 m but follows the same trends a similar effect was seen at this gage in li and hodges 2019a the abrupt change of this gage on day 170 might indicate that the gage was moved and the recorded vertical reference datum was valid only for the final period of record note that for surface water elevation the results of all the scenarios are essentially identical including the no exchange sg60 case which indicates that surface evaporation and surface subsurface exchange have no significant effect on water levels the right column of fig 8 provides the salinity results in the surface water the two major freshwater pumping events pe1 pe2 are marked in fig 8 b which corresponds to the decline of salinity in most of the monitoring stations before pumping begins at the upstream end of the river the field measured salinity is above typical ocean salinity 35 psu at all monitored locations indicating the combined effects of evaporation and potentially surface subsurface exchange with hypersaline pore water when the pumps are first turned on pe1 the salinity decreases almost simultaneously across all stations except l4 which is in the middle of the tidal flats in the lagoon where the ponded water has poor connections to both the river and the bay station l1 l2 and l3 exhibit similar patterns where the salinity drops to zero during pumping and soon rises again when pumping stops stations l5 and l6 are closer to the open boundary and are affected by tidally driven exchange and mixing with downstream water retaining the initial salinity levels of the bay the interaction between pump flow and tidal flow leads to sub daily oscillations from nearly fresh to oceanic salinity as the mixing zone is tidally advected across the lower part of the river at l5 and l6 station l4 is again anomalous in that field data indicates it is almost hydraulically isolated i e the observed salinity only decline modestly after pumping begins and it soon returns to its previous level when pumping stops we believe this is due to the strong spatial gradients from freshwater to hypersaline that exist across the lagoon during pumping which cannot be resolved at 30 m grid resolution despite the subgrid model of li and hodges 2019b although the decline of salinity during pe1 is well captured at all except l4 as discussed above the rebound in the interregnum between pe1 and pe2 is only well captured at l3 l5 and l6 the stations that connect the lagoon with the lower river and bay in the upper river at l1 and l2 the modeled salinity rebound is almost negligible but is clearly evident in the observations we believe this indicates the challenges of capturing the correct subgrid model connectivity through the narrow channels near l3 and l5 the subgrid model performs well through these connections with marsh scale downstream fluxes e g as during the pe1 pumping event but have difficulty capturing the smaller net upstream tidal flux when the downstream flow is eliminated note that model discrepancy caused by bathymetry and grid resolution is not the focus of the present study they have been thoroughly discussed in li and hodges 2019a b the introduction of evaporation has a noticeable effect on salinity at sites l3 l4 l5 and l6 unsuprisingly in all cases the simulations with evaporation have slightly higher salinities than the simulations without in comparing models with surface subsurface exchange sg to models without s in fig 8 we see that the differences at the measurement sites are small especially when compared to the overall model data disagreement the only place with notable differences between the sg and s simulations at the field data sites is in the initial salinity increase at l1 the most upstream station that is most strongly affected by the upland boundary condition to examine the effects and uncertainties associated with the interaction of model parameters in more detail the index of agreement or skill score proposed by willmott 1981 where 1 indicates perfect model data agreement is used in table 6 along with the standard deviation to evaluate each of the simulations against the observed data xiao et al 2017 from table 6 the six monitoring stations can be grouped as follows l3 and l6 have the highest skill scores 0 8 and the lowest standard deviations indicating excellent model data agreement l2 and l5 have moderate model data agreement skill score between 0 6 and 0 8 whereas l1 and l4 have poor agreements skill score 0 6 in particular l4 has the largest standard deviation and the smallest index of agreement among the stations indicating that neither the magnitudes nor the trend of salinity is reproduced at l4 it should be noted that the lower standard deviation at l1 relatively to l5 does not indicate a better agreement because both the modeled and the measured salinity are zero at l1 during the pumping events fig 8b which tends to produce a lower standard deviation for both metrics the differences between the eight testing scenarios are subtle however the effects of evaporation are visible as a slightly lower index of agreement when evaporation is neglected at l4 l5 and l6 in contrast results with and without evaporation are indistinguishable at l1 and l3 l2 shows negligible influence of evaporation when considering surface flow alone the s scenario but adding surface subsurface exchange leads to lower skill scores for the no evap scenarios it indicates that the effects of evaporation and surface subsurface on salinity are complex which will be analyzed in more detail together with figs 9 11 below these results are consistent with l4 l6 being connected to large surface areas where evaporation is important whereas fluxes in l1 l3 are dominated by advection in the river particularly during pumping periods the key observations from these results are i the model data agreement is dominated by spatial location rather than by model parameters and ii the inclusion of groundwater appears to be relatively unimportant in the marsh scale prediction of salinity in the upper nueces delta the former issue indicates that improving model data agreement likely requires addressing underlying errors and uncertainty of bathymetry salinity advection and perhaps some of the neglected salinity processes as discussed in section 4 4 the relative importance of groundwater is discussed immediately below we should not take the above analysis as proof that groundwater coupling is unimportant but rather that errors and uncertainties in modeled surface advection are likely to dominate effects of groundwater for the present state of the science to provide further insight fig 9 compares the spatial distribution of salinity for the s no evap s sg60 and the sg20 scenarios before the first pumping event day 151 which corresponds to 2013 5 31 it can be seen that before pumping the salinity in the upper nueces delta is relatively uniform and hypersaline when evaporation is included for surface water fig 9b the overall inundated area in upper reaches of the lagoon shrinks and the salinity increases notably we see the emergence of hot spots of extreme hypersalinity dark red pixels that indicate isolated pockets with ineffective salinity exchange with the surroundings this basin of the nueces delta is only weakly affected by tidal fluxes hence evaporation plays a greater role at its margins the further addition of surface groundwater exchange fig 9 c introduces changes in the distribution of the hypersalinity hot spots and dry pixels but has little impact on the overall salinity distribution across the system comparing fig 9 b and c the sg60 scenario shows fewer dry cells inside the marsh i e white pixels surrounded by water and fewer isolated wet cells outside the marsh i e water pixels surrounded by white thus an effect of groundwater coupling is that cells inside the marsh are less likely to completely dry out through evaporation as the subsurface connection provides a water source similarly outside the marsh isolated pockets of surface water will infiltrate the subsurface to replenish the lost soil moisture due to soil moisture evaporation making it less likely to maintain isolated pockets of surface water when groundwater is included in a model these processes are illustrated in more detail with fig 11 discussed further below for the sg20 scenario fig 9d with lower initial groundwater salinity than sg60 fig 9c the hypersalinity in the lagoon is slightly reduced by the fresher subsurface water a few isolated wet cells inside the marsh show much lower salinity than their surroundings indicating locations where surface subsurface exchange is strong however the overall salinity of sg20 remains higher than s no evap indicating surface subsurface exchange is relatively insignificant compared with evaporation for the large scale salinity balance across the marsh fig 10 compares the spatial distribution of salinity for the s no evap s and sg60 scenarios during and after the first pumping event when pumping starts fig 10a c e the river fills with freshwater which enters the lagoon through two narrow channels the upstream channel fills the lagoon while the downstream channel pushes water towards the bay a region of hypersaline water is initially trapped between the freshwater from the channels in the lower lagoon and a second region of trapped hypersaline water is evident near the entrance to the bay the movement of mixing fronts in these regions is likely the cause of the salinity oscillations seen at the l5 and l6 locations in fig 8 j and l the overall behaviors are similar in all the scenarios although the water trapped in the lower lagoon is of higher salinity for evaporation cases similar to the conditions before pumping evaporation during pumping fig 10c results in more interior dry locations but these are somewhat ameliorated by the coupling of groundwater fig 10e importantly the groundwater coupling creates local hot spots that are sources of hypersalinity although these hypersaline hot spots do not appear to affect the overall salt balance they have the potential to significantly distort the perceived meaning of field data e g a field sensor located at a place that is strongly influenced by hypersaline groundwater will not provide a signal that is indicative of the broader salinity behavior in the nearby region arguably the field sensor l4 might be located near a hypersaline hot spot that is displaced from the model sensor which would explain the field model discrepancy in fig 8 h after the pumping is finished fig 10b d f the s no evap scenario has significantly fresher water than the s and sg60 cases with evaporation however none of the models can directly explain the field data at sites l1 and l2 in fig 8 b d beginning around day 170 when higher salinity water is observed in the upstream river as l2 has a stronger salinity signal than l1 this is clearly a tidal transport from downstream to upstream from the field observations the likely transport path for this water is through the lower connecting channel between the river and the lagoon at l5 fig 8j the upper channel is unlikely to be the salt transport path as l3 would be expected to have higher salinity than l2 which is not the case the l1 and l2 field model discrepancies are probably related to the effectiveness of the modeled tidal fluxes on salinity advection at l5 tidal salinity oscillations are strong after the pumping event in both field and model data but at l1 and l2 the model oscillations are much smaller than those observed these results indicate the modeled channel is effective at handling the strong unidirectional flux of a river inflow from l2 through l5 but is biased against an oscillating tidal flux that leads to upstream salinity transport from l5 to l2 an important conclusion is that the good representation of the daily water surface levels as shown in fig 8 is not sufficient to presume similar accuracy in modeling salinity the key point is that the net salinity transport is affected by the bias between upstream flux on the ebb tide and downstream flux on the flood tide to complete our analysis for marsh scale simulations of the effects of combined evaporation and groundwater coupling on hot spots as noted above a key impact of evaporation and groundwater fig 11 shows the subsurface salinity and the flow fields in the cross sections xs1 and xs2 at day 151 which is before pe1 cross section xs1 is located on the upper edge of the lagoon as shown in fig 6 a which is a typical location at the edge of inundation and hypersalinity for the lagoon from fig 11 a it can be seen there is a thin layer of surface water in an isolated wet cell y 220 m which is in the process of infiltrating into the subsurface and moving laterally to replenish the lost soil moisture due to evaporation in adjacent unsaturated soil also in fig 11 a a similar flow pattern is seen on the rim of the inundated lagoon at y 350 m the second example cross section xs2 is located in the continuum between the river and the bay that is the primary channel see fig 6a for downstream and tidal exchange fig 11 b shows that xs2 lies across two cells isolated by subgrid topography as indicated by the thin layer of surface water compared to their surroundings with surface subsurface exchange the surrounding wet cells provide water that keeps these isolated cells wet thus fig 11 illustrates the mechanisms that leads to the effects discussed in reference to figs 9 and 10 where introduction of the surface subsurface exchange tends to dry out wet cells that are isolated in a dry area while maintaining some surface water in cells surrounded by water that would become dry land without a groundwater source along the intertidal zone the subsurface flow is mostly uni directional from wet to dry regions thus the hypersalinity in dry pores from soil moisture evaporation does not have a subsurface lateral transport path to surface water it follows that hypersalinity is only diluted when tides winds or upstream inflows cause episodic or periodic flooding over the dry pores capturing wetting drying processes in numerical models is a notorious challenge e g caviedes voullieme et al 2020 garcia navarro et al 2019 medeiros and hagen 2013 the task is particularly difficult for the nueces system due to its small overall daily tidal range typically 0 5 m complex tide patterns ward 1997 and shallow depth to provide further insight on the effects of wetting drying fine resolution simulations are used to further understand the transport of salinity in the intertidal zone in section 4 3 below 4 3 small scale high resolution simulations from the marsh scale simulation results section 4 2 salinity of the surface water is affected by evaporation but does not appear sensitive to surface subsurface exchange however the coarse grid resolution for the marsh scale simulation cannot resolve detailed exchange processes near the river channels which is the focus of our small scale simulation approach using 1 m resolution as outlined in section 3 5 the key results for these simulations are provided in fig 12 which is a combined view of the subsurface salinity fields and fluxes for the base no evap and basex3 no evap scenarios that neglect surface evaporation but include soil moisture evaporation note that the additional scenarios including surface evaporation not shown are not significantly different in the mechanisms driving surface subsurface exchange in both cases illustrated in fig 12 lateral and vertical fluxes are strong underneath the intertidal zone 32 x 37 m and the lateral flow is generally from this moist intertidal zone to the dry upland regions x 32 m this is consistent with the 30 m model shown in fig 11 at low tide in the higher amplitude test case fig 12d a lateral subsurface flux flows down the topographic gradient but the magnitude is weak compared to the lateral upland fluxes on higher tides areas that are routinely uncovered by the tides see higher porewater salinity due to evaporation which is apparent by comparing the salinity from 34 x 37 m in fig 12 g and h the former belongs to the immersed zone and the latter is part of the intertidal zone these results imply that the key to model surface subsurface salt flux is the ability to correctly capture soil evaporation and wetting drying in the intertidal zone this is particularly challenging for the 30 m coarse grid model of the nueces delta because of its mild tidal range table 7 lists the mean salinity in the surface domain at the selected times shown in fig 12 together with the corresponding tidal elevation at the open boundary including surface evaporation base and increasing tidal amplitude basex3 creates a greater increase of the surface salinity relative to the trivial salinity increase of the base no evap scenario the increased tidal amplitude in the x3 scenarios causes more salt to be released from the subsurface in the intertidal zone but also increases the exchange flux at the boundary which is held at 40 psu for inflowing tides hence the net effect is somewhat variable when taken together fig 12 and table 7 illustrate that the local increase of surface salinity in the intertidal zone near the river bank is caused by an iteration of two mechanisms i soil moisture evaporation from dry uplands that leads to porewater hypersalinity and ii release of porewater salt into the surface water during tidal inundation however for the present case the flux of high salinity water from the intertidal zone into the ponded water is dwarfed by the effect of evaporative fluxes in the ponded water itself these results are similar to those from the marsh scale simulation section 4 2 confirming that surface subsurface exchange is relatively unimportant in perpetually submerged regions of the nueces delta 4 4 synthesis and future directions taken together the marsh scale and small scale simulations show that surface evaporation is more important than surface groundwater exchange in the evolution of hypersalinity for the upper nueces delta however the groundwater exchange does affect development of the hypersaline hot spots hence neglect of groundwater exchange will alter the modeled distribution and intensity of hot spots note that these hot spots are created through pore water evaporation and affect surface water salinity through episodic wetting drying however the small tidal range in this system provides limited opportunity for this mechanism overall both evaporation and surface groundwater exchange have marginal impact on marsh scale salinity patterns during the period modeled in the nueces delta longer simulations might show whether such wetting drying porewater exchange introduces a significant long term source of hypersalinity or if it is merely washed out in large rainstorms unfortunately such speculation cannot be confirmed or rebutted without inclusion of other neglected salinity processes that might be of equal importance our model neglects a range of processes including rainfall small scale topographic variability vegetation root zone dynamics transpiration soil heterogeneity and precipitation mobilization of dissolved porewater salt arguably two of the most important neglected processes are rainfall and transpiration which have been neglected for similar reasons we lack sufficient data to create robust models admittedly we could have easily included observed rainfall over the delta which would cause dilution of salinity throughout however in hypersaline systems the real world rainfall on dry land can mobilize hypersaline porewaters and previously precipitated salt in extreme cases the rainfall can cause a net increase in salinity if the mobilization of stored salts exceeds the rain s diluting effect thus including rainfall without also including antecedent porewater conditions and precipitation mobilization is to introduce a dilution bias in the model furthermore if rainfall during the 2 month simulation period had a significant impact we would expect to see a correlation between observed surface salinities at the six measurement stations and rainfall events the total rainfall during the 2 month simulation period was only 8 cm distributed over small storms and their timing showed no correlations with either salinity decreases or increases in the absence of a strong observable signal and lacking data for a reasonable model of antecedent conditions and precipitation mobilization of salt we believe neglecting rainfall is the best approach for the present work focusing on effects of including neglecting evaporation and groundwater unlike rainfall transpiration from delta vegetation is a one way process that should increase salinities modeling transpiration is relatively straightforward for continually immersed vegetation where the transpired moisture is directly linked to the surface water however in a wetting drying marsh system with groundwater the source of transpired moisture groundwater surface water or a combination depends on the depth of the root structure and the wetting drying processes we do not have sufficient data in plant distribution plant size root depths and mobilization of root zone hypersalinity to build a mechanistic model of transpiration for the upper nueces delta although transpiration is undoubtedly important over longer time scales in the delta as a contributor to hypersalinity it seems unlikely that it could be the primary driver of model data disagreement for the two months of this study e g fig 8 the unexpected development of hypersaline hot spots through the combination of evaporation and groundwater coupling presents challenges for future field data collection previously it has been considered sufficient to install individual sensors spread widely throughout a marsh arguably the model prediction of localized hypersaline hot spots requires deployment of a group of sensors at each location for example four sensors placed at corners of 60 60 m box twice the present model s grid resolution would be helpful in distinguishing a hypersaline signal representing the large scale salinity evolution from a hot spot in the long term a complete mechanistic model of salinity in a coastal marsh requires inclusion of all the salinity processes neglected herein in particular enabling salt precipitation in the pores and integrating hydrodynamics with the evolution of plant communities transpiration and root zone porewater salinization dunton et al 2001 alexander and dunton 2002 hughes et al 2012 rasser et al 2013 however we believe the present work shows that a major difficulties in accurately modeling hypersalinity in the upper nueces delta are i getting the correct accumulated tidally driven salt fluxes through narrow channels and ii obtaining field data that is sufficiently robust to spatial hot spots of hypersalinity we contend that the major disagreements between measured and observed salinity in fig 8 are unlikely to be addressed by the introduction of more salinity processes which are unlikely to be larger than the introduction of evaporation that was modeled herein despite the neglected salinity processes in our modeling the present work successfully i built and tested a marsh salinity model with asynchronous surface groundwater coupling and ii explained the mechanisms how surface groundwater exchange affects marsh hypersalinity i e through soil evaporation during drying followed by release during flooding rather than through lateral subsurface transport with the mature surface groundwater salinity simulation framework developed herein future studies should focus on improving the subgrid topography model to obtain better prediction of net salinity fluxes driven by wind and oscillating tides 5 conclusions a coupled hydrodynamic and variably saturated subsurface flow model frehg is developed and applied to simulate the evolution of salinity in a shallow coastal marsh frehg solves the full shallow water equations in the surface domain and the density dependent 3d richards equation in the variably saturated subsurface domain the frehg model is validated using benchmark problems in the literature and applied to the upper nueces delta in texas usa to investigate relationships between surface and soil moisture evaporation surface subsurface exchange and observed hypersalinity a subgrid approach and asynchronous surface subsurface coupling are used to create a model that can simulate a large scale region without requiring supercomputer resources the salinity of the upper nueces delta is modeled at two different scales i a marsh scale 2d surface and 3d subsurface simulation that addresses spatial variability over complex topography and ii a fine resolution 1d surface and 2d subsurface simulation that focuses on the wetting drying of the intertidal zone from a computational viewpoint the present work demonstrates that asynchronous coupling between the surface and the subsurface domains significantly reduces computational cost by over 80 the coupling error can be quantified with three dimensionless parameters the error ratio of exchange flux eq 18 the error ratio of dispersive flux eq 19 and the péclet number eq 20 these parameters can serve as the criteria to optimize the selection of subsurface time step δ t g the study illustrates two key mechanisms through which surface subsurface coupling affects the model results in the large scale simulation specifically 1 as soil moisture evaporation removes porewater surface water in the nearby inundated regions will infiltrate through the subsurface and move laterally to replenish the lost soil moisture as a result including surface subsurface exchange leads to fewer isolated dry cells in the marsh interior and fewer isolated wet cells outside the ponded area 2 the subsurface flux is primarily from moist to dry regions which pushes near surface groundwater up the topographic gradient in the model resolved topography of the intertidal zone thus hypersaline porewater does not have a subsurface flux path back into ponded surface water instead the surface subsurface exchange is dominated by tidal inundation of the pores a key observation is that heterogeneity in the wetting drying tidal fluxes leads to the development of isolated hot spots of hypersalinity however the fine resolution simulation reveals that surface subsurface exchange in the intertidal zone is driven by micro topography that may not be well represented in a marsh scale coarse grid model soil moisture evaporation enhances pore salinity as the tide retreats and the accumulated salt enters the surface water during subsequent flooding this process only occurs close to the wetting drying front a large tidal amplitude can extend the range of the intertidal zone and enhance this salinity exchange for the shallow micro tidal upper nueces delta evaporation and surface subsurface exchange do not explain the majority of the discrepancies between modeled and measured salinity instead topographic features below the grid resolution are likely responsible for biases in the modeled water and salt fluxes through narrow channels to address these issues future studies should include i collecting high resolution field data and ii developing more robust numerical techniques to handle subgrid scale topography credit authorship contribution statement zhi li conceptualization methodology software validation formal analysis resources writing original draft visualization project administration funding acquisition ben r hodges formal analysis resources writing review editing xia shen writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study is supported by the fundamental research funds for the central universities china the national natural science foundation of china grant no 52109101 and the key research and development projects of shannxi province china grant no 2022sf 443 the authors would like to thank the texas water development board for providing the field data for surface elevation and salinity at the nueces delta open research software for this research i e the frehg model is under development at https github com zli90 frehg the version used in this manuscript together with the input data of the test problems are available at https github com zli90 frehg tests last accessed on june 18th of 2022 
2259,climate change has resulted in the increased frequency of extreme storms and associated flood risk uncertainties in urban areas which brings more challenges to future urban flood prevention assessing future trends in probabilistic urban flood risk can improve uncertainty estimation of urban floods under climate change and thus it is becoming increasingly urgent and important in this study a probabilistic risk assessment approach of urban flooding was developed to quantify the probabilistic flood risk in urban areas and assess the impacts of future climate change on flood risk results showed probabilistic urban flood risk under the historical condition ranged from 0 to 0 508 with a mean value of 0 104 indicating probabilistic urban flood risk was at the medium risk level the areas where probabilistic flood risk reached the medium risk level under historical condition accounted for 34 3 of the study area the ranges of probabilistic flood risk in the study area were 0 0 588 and 0 0 601 with mean values of 0 126 and 0 131 under ssp2 4 5 and ssp5 8 5 climate change scenarios respectively the areas where probabilistic flood risk reached the high risk level respectively accounted for 17 1 and 32 7 of the study area for ssp2 4 5 and ssp5 8 5 scenarios compared with the historical period probabilistic risk of urban flooding in the study area was projected to increase by 51 3 and 67 4 on average for ssp2 4 5 and ssp5 8 5 scenarios respectively the largest increase of probabilistic flood risk was approximately 200 and 250 for the ssp2 4 5 and ssp5 8 5 scenarios respectively which mainly occurred for forestlands and grasslands these results can effectively improve the uncertainty estimation of risk trends for urban floods under future climate change and thus better informed decision making for urban flood prevention keywords climate change daily precipitation gamma distribution monte carlo simulation probabilistic risk urban flood data availability data will be made available on request 1 introduction urban flood is one of the most frequent and destructive natural hazards which causes massive socio economical losses in cities such as buildings and utility infrastructures damage residents health and property losses chen et al 2019 jha et al 2012 sperotto et al 2016 yin et al 2016 moreover urban flood magnitude is expected to amplify with both urbanization process and future climate change posing threats to urban economic growth and social well being kundzewicz et al 2019 visser 2014 winsemius et al 2016 woodruff et al 2013 zheng et al 2014 therefore there is a growing concern that urban flood risk will dramatically increase in those metropolitan areas where there are a large number of populations and assets alfieri et al 2015 mahmood et al 2017 piadeh et al 2022 sun et al 2020 tate et al 2021 tellman et al 2021 the increasing risk of urban flooding confronts urban managers with new challenges for flood prevention and hinders sustainable development of urban ecosystems chan et al 2018 jiang et al 2018 as an important tool for flood hazard prevention flood risk assessment enables great practical values in flood risk management and can reduce destruction and loss from urban floods lin et al 2020 xu et al 2018 flood risk assessment consists of three main components including hazard i e the depth velocity and frequency of floods exposure i e the population and assets located in flood hazardous areas and vulnerability i e the susceptibility of the exposed elements to hazard field et al 2012 united nations international strategy of disaster reduction unisdr 2011 flood risk assessment can perform a comprehensive evaluation of natural and social properties of floods with the aim of improving the accuracy of characterizing spatial characteristics of flood risk xu et al 2018 yin et al 2015 traditionally three primary types of methods are widely used for flood risk assessment including the historical disaster mathematical statistics method adikari et al 2010 eini et al 2020 jalayer et al 2014 tang et al 2018 multi criteria analysis chen et al 2021 foudi et al 2015 guo et al 2014 kazakis et al 2015 lai et al 2020 lin et al 2020 wang et al 2021 xiao et al 2017 and scenario simulation analysis willems 2013 wu et al 2021 zhu et al 2016 although these approaches are widely employed for assessing flood risk they also include some disadvantages and limitations for example historical disaster statistics method requires large amounts of flood disaster data and does not accurately depict the spatial variability of flood risk multi criteria analysis generally does not consider the inundation depth and velocity of flood characteristics and scenario simulation analysis does not consider the effects of hazard inducing environments and hazard bearing bodies on flood risk park and lee 2020 wang et al 2015 xu et al 2018 yin et al 2015 in summary although significant improvements have been made to improve these weaknesses more efficient methods are still urgently needed to comprehensively assess urban flood risk in recent decades due to the increasing frequency and magnitude of urban flood events occurring in high density urban regions the potential impacts of climate change on urban flooding have received increasing attention sun et al 2021 ward et al 2013 wang et al 2020 it is widely confirmed that global warming trend will lead to a continuous increase in the likelihood of extreme storm events and its intensification causes a higher risk of damaging floods in many regions of the world black and burns 2002 guerreiro et al 2018 mahmoud and gan 2018 noor et al 2022 willems 2013 numerous studies have focused on assessing the impacts of climate change on flood volume and flood risk in urban areas alfieri et al 2015 chen et al 2021 da silva et al 2022 hou et al 2020 rosbjerg 2017 salimi and al ghamdi 2020 zhou et al 2018a zhou et al 2019 for example alfieri et al 2015 assessed that climate change increases the flood risk by 220 in europe at 4 c global warming scenario zhou et al 2018a simulated that urban flood volume increases by 52 over 2020 2040 under the representative concentration pathway rcp 8 5 scenario in hohhot city of china hou et al 2020 predicted the average increase of flood volume ranged from 81 2 to 98 9 under rcp 2 6 rcp 4 5 and rcp 8 5 scenarios in qian an city of china hettiarachchi et al 2018 simulated the magnitude of flood risk increases up to 35 in an urban watershed of minnesota usa chen et al 2021 projected the area of the highest flood risk respectively increases by 8 7 and 19 8 under rcp 4 5 and rcp 8 5 scenarios in the pearl river delta of china thus in response to the potential increased flood risk it is crucial to incorporate future climate change impacts in urban flood risk assessment and management amin et al 2017 zhou et al 2012 flood risk assessment is an essential part of sustainable urban flood management and is becoming even more important with the intensification of climate change effects ahmad and simonovic 2013 moreover to formulate climate change adaptation and mitigation strategies simulating the impacts of future climate change plays a key role in characterizing the evolution trend of flood risk and better understanding the designed options for responding to climate change ghodsi et al 2020 hettiarachchi et al 2018 huong and pathirana 2013 vijayavenkataraman et al 2012 however most of flood risk assessment methods focused on static vulnerability analysis and mostly did not consider the impacts of climate change gallina et al 2016 one of the challenges in investigation of urban flooding is the lack of a quantitative record of its occurrence and magnitude in response to extreme rainfall events rosenzweig et al 2018 since future flood risk projections are characterized by high uncertainty quantitative assessment of the flood risk through identifying a wide range of precipitation frequencies is vital for urban flood disaster forewarning and prevention yin et al 2015 although scenario based approaches are helpful to explore the potential impacts of climate change most studies have provided limited quantitative information on the uncertainty of future urban flood risk under climate change muis et al 2015 probabilistic risk characterization is a quantitative method for describing the likelihood of risk occurrence it can approach a full range of possible consequences and the possibility of each risk level thus increasing the accuracy of risk assessment results under changing conditions and allowing the uncertainty of risk to be quantitatively expressed kang et al 2018 liu et al 2020 muis et al 2015 united states environmental protection agency usepa 2014 to date limited researchers have used probabilistic approaches to delineate flood risk maps and related consequences in urban areas aronica et al 2012 jalayer et al 2014 jenkins et al 2018 liu et al 2020 muis et al 2015 wahl et al 2016 therefore assessing future trends in probabilistic risk of urban flooding can adequately improve the uncertainty estimation of urban flood risk under climate change and it is urgently needed in flood risk assessment in this study a new probabilistic risk assessment method was developed to quantify the probabilistic flood risk in urban areas and assess the impacts of future climate change on flood risk fitted gamma probability distributions and monte carlo stochastic simulations were connected to generate daily precipitation events and the soil conservation service curve number scs cn method was employed to simulate surface runoff the probabilistic risk of urban flooding was quantified according to runoff risk thresholds of different land covers and the spatial characteristics of probabilistic flood risk under historical condition and climate change scenarios were mapped and analyzed the main objectives of this paper were 1 to develop an assessment method for quantifying the probabilistic risk of urban flooding 2 to analyze the spatial characteristics of probabilistic urban flood risk under the historical period and climate change scenarios at the city scale 3 to predict the change trends of probabilistic urban flood risk under future climate changes the results could provide quantitative information on the uncertainty of future urban flood risk under climate change and inform a scientific reference for decision making of urban flood governance 2 materials and methods the assessment of probabilistic urban flood risk and impacts of climate change included three steps the first step is to employ the fitted gamma probability distributions and monte carlo stochastic simulations to generate all possible values of daily precipitation events and then simulate surface runoff of each land cover by the scs cn method the second step is to quantify the probabilistic risk of urban flooding according to runoff risk thresholds of different land covers and analyze the spatial characteristics of probabilistic flood risk under the historical period and climate change scenarios in urban areas the final step is to predict the change trends for probabilistic risk of urban flooding under future climate changes and assess the impacts of climate change on urban flood risk the process of research procedures is shown in fig 1 2 1 study area beijing city as the capital of china is located on the northern edge of the north china plain in 2019 the permanent population of beijing was more than 21 5 million with an average density of 1 312 persons km2 beijing statistical bureau 2020 it has a temperate monsoon climate with an average precipitation of 542 6 mm year precipitation is mostly concentrated from june to september as extreme storm events several researches have investigated that short duration heavy precipitation events have been occurring more frequently in beijing during the past decades cao et al 2016 song et al 2022 zhu et al 2016 in recent years beijing has experienced frequent flood and waterlogging disasters for example the beijing 7 21 extreme storm event occurred in 2012 which claimed 77 deaths and caused of more than 10 billion yuan in direct economic losses therefore this study selected the area within the beijing fifth ring road the total area is 667 31 km2 as the study area to assess urban flood risk and its impacts due to climate change 2 2 land cover data the high resolution geoeye imagery acquired in 2015 was interpreted to classify land cover data the geoeye imagery consists of four multispectral bands 1 65 m and a panchromatic band 0 41 m which has a spatial resolution of 0 5 m tian et al 2019 the land cover classification was achieved using an object based classification method zhou and troy 2008 the ancillary data such as light detecting and lidar data building footprint layers and road polyline layers were used to aid in object based classification qian et al 2015 zhou et al 2018b the study area was classified as seven types of land covers buildings pavements roads forestland grassland bare land and water bodies their spatial distribution is shown in fig 2 the classification accuracy of the land cover data was conducted by visually referencing google earth s sub meter high resolution imagery with the same acquisition date zhou et al 2018b a stratified random sampling method was used to generate the random points in the software of erdas imagine version 9 1 a total number of 300 random sample points were sampled with more than 30 samples for each class zhou et al 2018b error matrices that describe the patterns of mapped class relative to the reference data were generated from which the overall accuracy was derived to assess the accuracy of the classification map the total accuracy of the final land cover classification results was 92 8 table 1 summarizes the total area and the proportions of different land covers the buildings pavements and roads accounts for 21 52 31 49 and 12 08 of the total area respectively the forestland grassland bare land and water body respectively occupies by 27 33 3 47 2 37 and 1 73 2 3 calculation scheme of probabilistic flood risk it is assuming that i denotes a random variable of urban flooding and i c represents the risk threshold of variable i the expression for calculating probabilistic risk of variable i pri can be given as follows 1 pri p i i c 1 f i c where p x is the probability that the flood event within the parentheses will not occur f x is the cumulative distribution function of variable i the probability distribution function of the independent variable i can be given as 2 i f s 1 s l θ 1 θ k where f x is the distribution function of variable i s i denotes the independent variables θ i represents the model parameters in this study surface runoff was selected as the risk receptor indicator to describe urban flood quantity daily precipitation was selected as a random independent variable to determine the probability distribution function because extreme precipitation is the key driver of the increasingly frequent urban flooding in the context of a changing climate blanc et al 2012 huang et al 2020 rosenzweig et al 2018 rözer et al 2019 schanze 2018 meanwhile the other independent variables and parameters of surface runoff are less uncertain the monte carlo stochastic simulation was employed to repeatedly and randomly sample all possible values of daily precipitation from its probability distribution and execution of the hydrological model with these stochastic inputs then aggregation of the large number of executions to obtain an estimate of the flood occurrence possibility the more times the monte carlo stochastic simulation is performed to generate the possible values of daily precipitation the closer the risk frequency approaches to the flood risk probability maccheroni and marinacci 2005 for instance if n samples of daily precipitation were generated from n monte carlo simulations which generating surface runoff including m samples of surface runoff larger than the flood risk threshold i c thus the probabilistic flood risk can be calculated as follows 3 pri m n 2 4 surface runoff calculation in this study surface runoff volume from different land covers was simulated by using the scs cn method the scs cn method is an effective empirical runoff prediction approach it has been widely adopted in runoff calculation of urban surfaces as well as hydrological models fan et al 2013 liu et al 2022a palla and gnecco 2015 xu et al 2020 yao et al 2015 the scs cn approach is based on a water balance hypothesis that a precipitation event generates runoff when the precipitation depth exceeds the amount of initial abstraction chin 2017 surface runoff for a given precipitation event is computed as following 4 q p i a 2 p i a s p i a 0 p i a 5 s 25400 cn 254 6 i a λ s where q denotes the surface runoff depth mm p is the precipitation depth mm ia represents the initial abstraction of precipitation mm s is the potential maximum soil water capacity after runoff generation mm cn is the curve number its value ranging from 0 to 100 λ is the initial abstraction ratio it usually assigned as a constant value of 0 2 cn values of different land cover types were determined using the look up table of technical release 55 from natural resources conservation service nrcs depends upon the soil type and the antecedent moisture condition amc nrcs 1986 according to the analysis of soil infiltration characteristics in beijing by fu et al 2013 the hydrological soil group in the study area assumed with moderate infiltration capacity used as b class the antecedent moisture condition was used at a moderate soil condition amc ii which is considered as the standard for most researches xu et al 2020 the determined cn values of different land covers are summarized in table 2 specially surface runoff generated from water bodies may not bring extra influence on surrounding surfaces thus their cn values can be assigned as 0 yao et al 2015 2 5 flood risk threshold setting and risk level determination the risk thresholds of urban flooding were determined according to the upper limits of runoff coefficients for urban land covers in the code for design of outdoor wastewater engineering gb50014 2021 ministry of housing and urban rural development of the people s republic of china 2021 the determined runoff coefficient thresholds of different land covers are summarized in table 3 in this study due to the exact standards for probabilistic risk levels in china were lacked the probabilistic risk level standards of concern thresholds proposed by the us environmental protection agency usepa united states environmental protection agency usepa 2014 were adopted to determine risk levels of urban flooding that is appropriate to the risk assessment objective and decision making information for flood prewarning according to the determined risk levels the risk probability values classified as four risk levels no risk level probability values 0 05 a low risk level 0 05 probability values 0 1 a moderate risk level 0 1 probability values 0 5 and a high risk level probability values 0 5 table 4 2 6 determination of probability distribution functions of daily precipitation the gamma distribution is widely applied as the standard distribution for precipitation frequency analyses basheer et al 2016 fatichi et al 2011 yu et al 2022 zhi et al 2022 thus gamma distribution was utilized to generate probability density distributions of daily precipitation in this study the general gamma distribution with two parameters is given as 7 f x x α 1 1 β α γ α e x β x 0 α β 0 8 α μ 2 σ 2 9 β σ 2 μ where f denotes the distribution function x is an independent variable α is the shape parameter β is the scale parameter μ and σ 2 are the mean and variance of gamma distribution in this study historical daily precipitation data with 30 years 1991 2020 were collected from national rain gauge stations shared by the china meteorological data service center https data cma cn in the fitting process the historical daily precipitation events were used to determine the shape and scale parameters of gamma distribution the fitted gamma distribution function of historical daily precipitation goodness of fit was 0 92 was expressed as follows 10 f h s d p x x 0 501 1 15 629 0 499 γ 0 499 e x 15 629 the future daily precipitation data of the study area for years 2021 2050 were obtained by downscaling the climate data of the bcc csm2 mr model of global circulation models gcms from the cmip6 archive https portal nccs nasa gov datashare nexgddp cmip6 bcc csm2 mr and calibrated by the historical observed precipitation data the bcc csm2 mr model is one of the models developed by beijing climate center bcc it can realistically reproduce the main patterns of precipitation and had better capability for simulating the evolution of multi year precipitation thus it has been widely used in china hamed et al 2022 liu et al 2022b song et al 2022 wu et al 2019 xin et al 2020 zhang et al 2022 firstly the large scale daily precipitation data of the bcc csm2 mr were downscaled to the local scale of nearby national weather station haidian station 116 28e 39 98 n by the inverse distance weighted interpolation method which according to the distance calculated by the coordinate values of latitude and longitude from the weather station to the geographical center of the four neighbouring gcm grid units liu and zuo 2012 then the historical observed daily precipitation data from the year 1991 2020 of the study area was used to calibrate the downscaling precipitation data from bcc csm2 mr model of the same historical period the time series of downscaling projected precipitation data for future climate change 2021 2050 were standardized with their means and standard deviations corresponding to the historical climate condition and subsequently transformed back with those of historical observed precipitation under the assumption that the bias does not change over time johnson and sharma 2012 after that the gamma distribution functions of daily precipitation for ssp2 4 5 and ssp5 8 5 climate change scenarios goodness of fit was both 0 95 were fitted and respectively expressed as follows 11 f s s p 2 4 5 d p x x 0 401 1 15 954 0 599 γ 0 599 e x 15 954 12 f s s p 5 8 5 d p x x 0 391 1 16 291 0 609 γ 0 609 e x 16 291 2 7 model runs and display of spatial data based on the classification of land covers the study area was consisted of approximately 1 215 million land cover units first attribute table data of land covers in the layer file was derived as a raster data file for further computing then using 10 000 monte carlo stochastic simulations of daily precipitation the surface runoff calculation by employing the scs cn method and the probabilistic flood risk calculation in every land cover unit were all performed using the r software 3 4 2 after that the probability values of flood risk were joined into the attribute table of the land cover layer file finally the statistical analysis and the mapping of spatial probabilistic flood risk at the city scale were realized in arcmap 10 3 3 results 3 1 characteristics of the generated daily precipitation events in the historical period a total of 1 994 observed daily precipitation events were reserved for the future climate change period ssp2 4 5 scenarios retained 3 169 projected daily precipitation events and ssp5 8 5 scenario retained 3 076 projected daily precipitation events compared with the observed and projected daily precipitation data the amount of monte carlo generated daily precipitation events increased by 3 2 5 0 times in this study the mean amounts of daily precipitation for 10 000 monte carlo simulations generated were 7 8 mm 9 5 mm and 9 8 mm and the maximum precipitation amounts were 114 5 mm 109 8 mm and 115 3 mm for the historical period ssp2 4 5 and ssp5 8 5 scenarios respectively the probability density of monte carlo generated daily precipitation for the historical condition ssp2 4 5 and ssp5 8 5 climate change scenarios are shown in fig 3 fig 4 shows the cumulative probability curves of daily precipitation in the historical and climate change scenarios results showed that there are significant changes in the monte carlo generated daily precipitation events between the historical condition and climate change scenarios the probability of daily precipitation under future climate change scenarios gradually increased for all the monte carlo stochastically generated precipitation events the probability density of daily precipitation under the historical period was relatively smaller the cumulative probability curves between ssp2 4 5 and ssp5 8 5 scenarios were slight varied moreover the maximum probability density of precipitation for ssp2 4 5 scenario was greater than for the ssp5 8 5 scenario and historical condition 3 2 characteristics of probabilistic risk for urban flooding under the historical period the calculated probabilistic urban flood risk under the historical period in the study area ranged from 0 to 0 508 with a mean value of 0 104 and a total coefficient of variation of 1 636 indicating probabilistic urban flood risk was at the medium risk level the areas where probabilistic urban flood risk under the historical condition reached the low risk level 0 05 risk probability 0 1 accounting for 0 64 4 3 km2 and the areas where probabilistic flood risk reached the medium risk level 0 1 risk probability 0 5 accounting for 34 3 224 2 km2 of the study area meanwhile only a 0 06 km2 area reached the high probabilistic flood risk level risk probability 0 5 under the historical period moreover probabilistic urban flood risk under the historical condition presented high spatial heterogeneity within the beijing fifth ring roads fig 5 areas exhibiting high probabilistic flood risk were mainly distributed in the impervious surfaces the mean probabilistic flood risk was 0 418 and 0 487 for buildings and roads respectively furthermore forestlands and grasslands showed the lower probabilistic flood risk differently the water body areas exhibited no probabilistic flood risk 3 3 spatial distribution of probabilistic flood risk under future climate change scenarios fig 6 illustrates the spatial characteristics of probabilistic risk for urban flooding under future climate change scenarios the ranges of calculated probabilistic flood risk in the study area were 0 0 588 and 0 0 601 with the mean values of 0 126 and 0 131 and the total coefficients of variation were 1 581 and 1 561 under ssp2 4 5 and ssp5 8 5 climate change scenarios respectively the areas where probabilistic flood risk reached the medium risk level respectively accounted for 16 5 110 0 km2 and 0 92 6 2 km2 of the study area under ssp2 4 5 and ssp5 8 5 scenarios meanwhile the areas where probabilistic flood risk reached the high risk level accounted for 17 1 114 2 km2 and 32 7 218 1 km2 in the study area for ssp2 4 5 and ssp5 8 5 scenarios respectively the mean probabilistic flood risk of buildings and roads was 0 496 and 0 567 under the ssp2 4 5 scenario 0 508 and 0 579 under the ssp5 8 5 scenario respectively the area of surfaces with the high probabilistic flood risk was significantly increased from the ssp2 4 5 scenario to the ssp5 8 5 scenario 3 4 change trends of probabilistic flood risk under future climate change scenarios fig 7 shows the spatial characteristics of percentage changes of probabilistic flood risk under future climate change scenarios compared with the historical period results showed that the ssp5 8 5 scenario decreased the medium flood risk areas by 97 3 compared with the historical period and as well the ssp2 4 5 scenario reduced the medium flood risk areas by 50 9 simultaneously under climate change conditions the area of surfaces with the high probabilistic flood risk increased 114 2 km2 and 218 0 km2 for ssp2 4 5 and ssp5 8 5 scenarios respectively table 5 summaries the median changes for probabilistic flood risk of different land covers under climate change scenarios the order of median percentage changes for probabilistic flood risk under climate change was forestland grassland bare land pavements buildings roads the largest changes of probabilistic flood risk mainly occurred for forestlands and grasslands in the study area however the buildings and roads had the relatively lower changes of probabilistic flood risk under climate change condition overall compared with the historical condition probabilistic risk of urban flooding in the study area was projected to increase by 50 3 67 4 on average from ssp2 4 5 to ssp5 8 5 climate change scenarios particularly the smallest increase in probabilistic flood risk was 16 4 for the ssp2 4 5 scenario as well as 20 0 for the ssp5 8 5 scenario the largest increase of probabilistic flood risk was nearly 200 for the ssp2 4 5 scenario and it was approximately 250 for the ssp5 8 5 scenario 4 discussion 4 1 advantages of probabilistic urban flood risk assessment the projection of future flood risk under climate change condition is challenging due to uncertainties associated with future precipitation projections uncertainty in distribution function applied to generate precipitation and uncertainties from hydrologic model and their input parameters kundzewicz et al 2017 ranger et al 2011 salman and li 2018 moreover while different model structures and procedures are used in the simulation of flood characteristics and frequency they have in common that considerable uncertainties are identified in various parts of flood risk assessment winter et al 2018 therefore it is unfeasible to quantify the likelihood of various risk levels of urban flooding without utilizing probabilistic methods probabilistic risk assessments can approach a full range of possible consequences and the possibility of each risk level thus allowing the uncertainty of risk to be quantitatively expressed united states environmental protection agency usepa 2014 some literature concluded that hydrologic uncertainties are much less significant than those originating from future precipitation projections under climate change in flood risk assessment collet et al 2018 steinschneider et al 2015 in this study in order to address the great uncertainty associated with future precipitation projections the monte carlo simulations stochastically generated 10 000 daily precipitation events according to the fitted gamma probability distributions based on the historical and future daily precipitation data the amount of monte carlo generated daily precipitation events increased by 3 2 5 0 times compared with the observed and projected daily precipitation data which include full range of possible extreme storm events especially it captured the occurrence of infrequent precipitation events with long return period using the developed probabilistic flood risk assessment the calculated probabilistic urban flood risk in the study area ranged from 0 to 0 601 and the mean values varied from 0 104 to 0 131 under the historical period and climate change scenarios consequently the monte carlo stochastically generated daily precipitation and acquired a wider range of possible weather scenarios than historical record of precipitation events which can approximately represent the characteristics of daily precipitation with high variability and provide the likelihood of various risk levels thus allowing for performing more accurate flood risk assessment dawkins et al 2022 zhi et al 2022 further some researchers concluded that the monte carlo stochastic simulation could take into account the uncertainty of precipitation events and possible consequences more exactly quantify the uncertainty of flood risk itself ghersi et al 2017 kalyanapu et al 2012 therefore the developed probabilistic flood risk assessment can effectively reduce the uncertainties of urban flood hazard risk associated with the impacts of future climate change and they can provide more reliable urban flood risk information and future evolution trends 4 2 impacts of future climate change on urban flood risk understanding the driving mechanism behind urban flood risk is essential to inform future climate change mitigation and adaptation strategies under ever changing conditions yu et al 2022 zhou et al 2019 climate change is regarded as one of the key driving factors of flood risk in urban areas which results in large impacts on extreme precipitation patterns and thus can directly intensify the frequency and magnitude of urban floods berndtsson et al 2019 zhou et al 2019 in this study compared with the historical period probabilistic risk of urban flooding in the study area was projected to increase by 51 3 and 67 4 on average for ssp2 4 5 and ssp5 8 5 climate change scenarios respectively these projected results revealed a significant increase in probabilistic risk of future urban flooding under climate change condition which is consistent with previous findings alfieri et al 2015 chen et al 2021 hettiarachchi et al 2018 hou et al 2020 zhou et al 2018a consequently the projected future climate change represented a key driving factor affecting probabilistic urban flood risk although the mean values of probabilistic flood risk in the study area for ssp2 4 5 and ssp5 8 5 scenarios were approached 0 126 and 0 131 respectively further analysis indicated that the area of surfaces with the high probabilistic flood risk was significantly increased from the ssp2 4 5 scenario to the ssp5 8 5 scenario moreover the largest increase of probabilistic flood risk was approximately 200 and 250 for ssp2 4 5 and ssp5 8 5 scenarios respectively therefore the ssp2 4 5 scenario showed a lesser magnitude increase in probabilistic flood risk than the ssp5 8 5 scenario it indicated that decreasing greenhouse gas emissions can lower the urban flood risk these results are similar to zhou et al 2018a they predicted a higher increase 52 in urban flood volume for the rcp 8 5 than the rcp 2 6 scenario 13 as well chen et al 2021 projected the highest flood risk areas are increased by 8 7 and 19 8 under ssp2 4 5 and ssp5 8 5 scenarios respectively it seems likely that extreme storm events were projected to be more predominated at the study area under the high emission scenario than the medium emission scenario chen et al 2021 also highlighted the reduction in greenhouse gas emission could mitigate the effects of future climate change on flood risk further more appropriate options of climate adaptation and mitigation strategies are increasingly needed to deal with the adverse impacts of future climate change on flood risk in urban areas alexander et al 2019 hou et al 2020 leandro et al 2020 4 3 limitations of the study first in the present study surface runoff generated by daily precipitation events over urban areas was spatially assessed which was assumed to represent the potential urban flood risk rather than the real conditions of flood hazard this study mainly focused on risk assessment method which statistically quantified the probabilistic aspects in urban flood risk analysis it aims to better characterize the probability of urban flood hazard in light of climate change and provide useful insight on how climate change may amplify the hazard presented by intense rainfall second the future daily precipitation data only used the projections from bcc csm2 mr model of gcms which would cause a certain uncertainty exists in projection data of future precipitation from the single model further the spatial heterogeneity of daily precipitation in the study area was not considered future studies need to be focused on spatially downscaling the projected climate data from various gcms toward a more reliable projection of future precipitation data and further explore the sources of uncertainty in future flood risk assessment and quantify their contribution to the overall predictive uncertainty third future flood risk changes were projected under climate change condition with the assumption that climate change is the only driving factor of urban flood risk however in urban areas land cover change is also an important driving factor that influences urban flooding the assumption is feasible because that future land cover change in the study area with high density urbanization will be very little due to urban land is the predominant type and approaches saturated in future studies the impacts of land cover change and climate change need to be joined together to comprehensively assess urban flood risk 5 conclusions the present study presented a new probabilistic risk assessment method to quantify the probabilistic risk of urban flooding and assess the impacts of future climate change on urban flood risk the number of monte carlo stochastically generated daily precipitation events increased by 3 2 5 0 times compared with the observed and projected daily precipitation data which acquired a wider range of possible climate scenarios than the historical record precipitation events thus allowing for a more accurate assessment of flood risk overall the calculated probabilistic urban flood risk under the historical period in the study area was at the medium risk level 34 3 of the study area reached the medium flood risk level compared with the historical period probabilistic risk of urban flooding in the study area was projected to on average increase by 51 3 and 67 4 for ssp2 4 5 and ssp5 8 5 climate change scenarios respectively revealing a significant increase in probabilistic risk of future urban flooding it is worth noting that the largest changes of probabilistic flood risk mainly occurred for forestlands and grasslands in the study area although the mean values of probabilistic flood risk in the study area for two climate change scenarios were approached the area of surfaces with the high probabilistic flood risk significantly increased from the ssp2 4 5 scenario to the ssp5 8 5 scenario the ssp2 4 5 scenario showed a lesser magnitude increase in probabilistic flood risk than the ssp5 8 5 scenario indicating that controlling greenhouse gas emissions can effectively lower the flood risk therefore the developed probabilistic risk assessment is an effective quantitative method for characterizing the likelihood of urban flood risk occurrence and it can improve the uncertainty estimation of urban flood trends under future climate change the projected trends of probabilistic flood risk can result in a better understanding of the evolution trends of future urban flood risk thus provide a scientific basis for the characterization and early warning of urban flood hazard the urban flood risk assessment also can assist urban managers in developing flood mitigation strategies to cope with the adverse impacts of future climate change on urban flooding declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the west light foundation of the chinese academy of sciences no 2023 16 no 2020 82 and the national natural science foundation of china 42071051 we thank both reviewers and the journal editor for their constructive and sincere comments that have improved the clarity of the final manuscript 
2259,climate change has resulted in the increased frequency of extreme storms and associated flood risk uncertainties in urban areas which brings more challenges to future urban flood prevention assessing future trends in probabilistic urban flood risk can improve uncertainty estimation of urban floods under climate change and thus it is becoming increasingly urgent and important in this study a probabilistic risk assessment approach of urban flooding was developed to quantify the probabilistic flood risk in urban areas and assess the impacts of future climate change on flood risk results showed probabilistic urban flood risk under the historical condition ranged from 0 to 0 508 with a mean value of 0 104 indicating probabilistic urban flood risk was at the medium risk level the areas where probabilistic flood risk reached the medium risk level under historical condition accounted for 34 3 of the study area the ranges of probabilistic flood risk in the study area were 0 0 588 and 0 0 601 with mean values of 0 126 and 0 131 under ssp2 4 5 and ssp5 8 5 climate change scenarios respectively the areas where probabilistic flood risk reached the high risk level respectively accounted for 17 1 and 32 7 of the study area for ssp2 4 5 and ssp5 8 5 scenarios compared with the historical period probabilistic risk of urban flooding in the study area was projected to increase by 51 3 and 67 4 on average for ssp2 4 5 and ssp5 8 5 scenarios respectively the largest increase of probabilistic flood risk was approximately 200 and 250 for the ssp2 4 5 and ssp5 8 5 scenarios respectively which mainly occurred for forestlands and grasslands these results can effectively improve the uncertainty estimation of risk trends for urban floods under future climate change and thus better informed decision making for urban flood prevention keywords climate change daily precipitation gamma distribution monte carlo simulation probabilistic risk urban flood data availability data will be made available on request 1 introduction urban flood is one of the most frequent and destructive natural hazards which causes massive socio economical losses in cities such as buildings and utility infrastructures damage residents health and property losses chen et al 2019 jha et al 2012 sperotto et al 2016 yin et al 2016 moreover urban flood magnitude is expected to amplify with both urbanization process and future climate change posing threats to urban economic growth and social well being kundzewicz et al 2019 visser 2014 winsemius et al 2016 woodruff et al 2013 zheng et al 2014 therefore there is a growing concern that urban flood risk will dramatically increase in those metropolitan areas where there are a large number of populations and assets alfieri et al 2015 mahmood et al 2017 piadeh et al 2022 sun et al 2020 tate et al 2021 tellman et al 2021 the increasing risk of urban flooding confronts urban managers with new challenges for flood prevention and hinders sustainable development of urban ecosystems chan et al 2018 jiang et al 2018 as an important tool for flood hazard prevention flood risk assessment enables great practical values in flood risk management and can reduce destruction and loss from urban floods lin et al 2020 xu et al 2018 flood risk assessment consists of three main components including hazard i e the depth velocity and frequency of floods exposure i e the population and assets located in flood hazardous areas and vulnerability i e the susceptibility of the exposed elements to hazard field et al 2012 united nations international strategy of disaster reduction unisdr 2011 flood risk assessment can perform a comprehensive evaluation of natural and social properties of floods with the aim of improving the accuracy of characterizing spatial characteristics of flood risk xu et al 2018 yin et al 2015 traditionally three primary types of methods are widely used for flood risk assessment including the historical disaster mathematical statistics method adikari et al 2010 eini et al 2020 jalayer et al 2014 tang et al 2018 multi criteria analysis chen et al 2021 foudi et al 2015 guo et al 2014 kazakis et al 2015 lai et al 2020 lin et al 2020 wang et al 2021 xiao et al 2017 and scenario simulation analysis willems 2013 wu et al 2021 zhu et al 2016 although these approaches are widely employed for assessing flood risk they also include some disadvantages and limitations for example historical disaster statistics method requires large amounts of flood disaster data and does not accurately depict the spatial variability of flood risk multi criteria analysis generally does not consider the inundation depth and velocity of flood characteristics and scenario simulation analysis does not consider the effects of hazard inducing environments and hazard bearing bodies on flood risk park and lee 2020 wang et al 2015 xu et al 2018 yin et al 2015 in summary although significant improvements have been made to improve these weaknesses more efficient methods are still urgently needed to comprehensively assess urban flood risk in recent decades due to the increasing frequency and magnitude of urban flood events occurring in high density urban regions the potential impacts of climate change on urban flooding have received increasing attention sun et al 2021 ward et al 2013 wang et al 2020 it is widely confirmed that global warming trend will lead to a continuous increase in the likelihood of extreme storm events and its intensification causes a higher risk of damaging floods in many regions of the world black and burns 2002 guerreiro et al 2018 mahmoud and gan 2018 noor et al 2022 willems 2013 numerous studies have focused on assessing the impacts of climate change on flood volume and flood risk in urban areas alfieri et al 2015 chen et al 2021 da silva et al 2022 hou et al 2020 rosbjerg 2017 salimi and al ghamdi 2020 zhou et al 2018a zhou et al 2019 for example alfieri et al 2015 assessed that climate change increases the flood risk by 220 in europe at 4 c global warming scenario zhou et al 2018a simulated that urban flood volume increases by 52 over 2020 2040 under the representative concentration pathway rcp 8 5 scenario in hohhot city of china hou et al 2020 predicted the average increase of flood volume ranged from 81 2 to 98 9 under rcp 2 6 rcp 4 5 and rcp 8 5 scenarios in qian an city of china hettiarachchi et al 2018 simulated the magnitude of flood risk increases up to 35 in an urban watershed of minnesota usa chen et al 2021 projected the area of the highest flood risk respectively increases by 8 7 and 19 8 under rcp 4 5 and rcp 8 5 scenarios in the pearl river delta of china thus in response to the potential increased flood risk it is crucial to incorporate future climate change impacts in urban flood risk assessment and management amin et al 2017 zhou et al 2012 flood risk assessment is an essential part of sustainable urban flood management and is becoming even more important with the intensification of climate change effects ahmad and simonovic 2013 moreover to formulate climate change adaptation and mitigation strategies simulating the impacts of future climate change plays a key role in characterizing the evolution trend of flood risk and better understanding the designed options for responding to climate change ghodsi et al 2020 hettiarachchi et al 2018 huong and pathirana 2013 vijayavenkataraman et al 2012 however most of flood risk assessment methods focused on static vulnerability analysis and mostly did not consider the impacts of climate change gallina et al 2016 one of the challenges in investigation of urban flooding is the lack of a quantitative record of its occurrence and magnitude in response to extreme rainfall events rosenzweig et al 2018 since future flood risk projections are characterized by high uncertainty quantitative assessment of the flood risk through identifying a wide range of precipitation frequencies is vital for urban flood disaster forewarning and prevention yin et al 2015 although scenario based approaches are helpful to explore the potential impacts of climate change most studies have provided limited quantitative information on the uncertainty of future urban flood risk under climate change muis et al 2015 probabilistic risk characterization is a quantitative method for describing the likelihood of risk occurrence it can approach a full range of possible consequences and the possibility of each risk level thus increasing the accuracy of risk assessment results under changing conditions and allowing the uncertainty of risk to be quantitatively expressed kang et al 2018 liu et al 2020 muis et al 2015 united states environmental protection agency usepa 2014 to date limited researchers have used probabilistic approaches to delineate flood risk maps and related consequences in urban areas aronica et al 2012 jalayer et al 2014 jenkins et al 2018 liu et al 2020 muis et al 2015 wahl et al 2016 therefore assessing future trends in probabilistic risk of urban flooding can adequately improve the uncertainty estimation of urban flood risk under climate change and it is urgently needed in flood risk assessment in this study a new probabilistic risk assessment method was developed to quantify the probabilistic flood risk in urban areas and assess the impacts of future climate change on flood risk fitted gamma probability distributions and monte carlo stochastic simulations were connected to generate daily precipitation events and the soil conservation service curve number scs cn method was employed to simulate surface runoff the probabilistic risk of urban flooding was quantified according to runoff risk thresholds of different land covers and the spatial characteristics of probabilistic flood risk under historical condition and climate change scenarios were mapped and analyzed the main objectives of this paper were 1 to develop an assessment method for quantifying the probabilistic risk of urban flooding 2 to analyze the spatial characteristics of probabilistic urban flood risk under the historical period and climate change scenarios at the city scale 3 to predict the change trends of probabilistic urban flood risk under future climate changes the results could provide quantitative information on the uncertainty of future urban flood risk under climate change and inform a scientific reference for decision making of urban flood governance 2 materials and methods the assessment of probabilistic urban flood risk and impacts of climate change included three steps the first step is to employ the fitted gamma probability distributions and monte carlo stochastic simulations to generate all possible values of daily precipitation events and then simulate surface runoff of each land cover by the scs cn method the second step is to quantify the probabilistic risk of urban flooding according to runoff risk thresholds of different land covers and analyze the spatial characteristics of probabilistic flood risk under the historical period and climate change scenarios in urban areas the final step is to predict the change trends for probabilistic risk of urban flooding under future climate changes and assess the impacts of climate change on urban flood risk the process of research procedures is shown in fig 1 2 1 study area beijing city as the capital of china is located on the northern edge of the north china plain in 2019 the permanent population of beijing was more than 21 5 million with an average density of 1 312 persons km2 beijing statistical bureau 2020 it has a temperate monsoon climate with an average precipitation of 542 6 mm year precipitation is mostly concentrated from june to september as extreme storm events several researches have investigated that short duration heavy precipitation events have been occurring more frequently in beijing during the past decades cao et al 2016 song et al 2022 zhu et al 2016 in recent years beijing has experienced frequent flood and waterlogging disasters for example the beijing 7 21 extreme storm event occurred in 2012 which claimed 77 deaths and caused of more than 10 billion yuan in direct economic losses therefore this study selected the area within the beijing fifth ring road the total area is 667 31 km2 as the study area to assess urban flood risk and its impacts due to climate change 2 2 land cover data the high resolution geoeye imagery acquired in 2015 was interpreted to classify land cover data the geoeye imagery consists of four multispectral bands 1 65 m and a panchromatic band 0 41 m which has a spatial resolution of 0 5 m tian et al 2019 the land cover classification was achieved using an object based classification method zhou and troy 2008 the ancillary data such as light detecting and lidar data building footprint layers and road polyline layers were used to aid in object based classification qian et al 2015 zhou et al 2018b the study area was classified as seven types of land covers buildings pavements roads forestland grassland bare land and water bodies their spatial distribution is shown in fig 2 the classification accuracy of the land cover data was conducted by visually referencing google earth s sub meter high resolution imagery with the same acquisition date zhou et al 2018b a stratified random sampling method was used to generate the random points in the software of erdas imagine version 9 1 a total number of 300 random sample points were sampled with more than 30 samples for each class zhou et al 2018b error matrices that describe the patterns of mapped class relative to the reference data were generated from which the overall accuracy was derived to assess the accuracy of the classification map the total accuracy of the final land cover classification results was 92 8 table 1 summarizes the total area and the proportions of different land covers the buildings pavements and roads accounts for 21 52 31 49 and 12 08 of the total area respectively the forestland grassland bare land and water body respectively occupies by 27 33 3 47 2 37 and 1 73 2 3 calculation scheme of probabilistic flood risk it is assuming that i denotes a random variable of urban flooding and i c represents the risk threshold of variable i the expression for calculating probabilistic risk of variable i pri can be given as follows 1 pri p i i c 1 f i c where p x is the probability that the flood event within the parentheses will not occur f x is the cumulative distribution function of variable i the probability distribution function of the independent variable i can be given as 2 i f s 1 s l θ 1 θ k where f x is the distribution function of variable i s i denotes the independent variables θ i represents the model parameters in this study surface runoff was selected as the risk receptor indicator to describe urban flood quantity daily precipitation was selected as a random independent variable to determine the probability distribution function because extreme precipitation is the key driver of the increasingly frequent urban flooding in the context of a changing climate blanc et al 2012 huang et al 2020 rosenzweig et al 2018 rözer et al 2019 schanze 2018 meanwhile the other independent variables and parameters of surface runoff are less uncertain the monte carlo stochastic simulation was employed to repeatedly and randomly sample all possible values of daily precipitation from its probability distribution and execution of the hydrological model with these stochastic inputs then aggregation of the large number of executions to obtain an estimate of the flood occurrence possibility the more times the monte carlo stochastic simulation is performed to generate the possible values of daily precipitation the closer the risk frequency approaches to the flood risk probability maccheroni and marinacci 2005 for instance if n samples of daily precipitation were generated from n monte carlo simulations which generating surface runoff including m samples of surface runoff larger than the flood risk threshold i c thus the probabilistic flood risk can be calculated as follows 3 pri m n 2 4 surface runoff calculation in this study surface runoff volume from different land covers was simulated by using the scs cn method the scs cn method is an effective empirical runoff prediction approach it has been widely adopted in runoff calculation of urban surfaces as well as hydrological models fan et al 2013 liu et al 2022a palla and gnecco 2015 xu et al 2020 yao et al 2015 the scs cn approach is based on a water balance hypothesis that a precipitation event generates runoff when the precipitation depth exceeds the amount of initial abstraction chin 2017 surface runoff for a given precipitation event is computed as following 4 q p i a 2 p i a s p i a 0 p i a 5 s 25400 cn 254 6 i a λ s where q denotes the surface runoff depth mm p is the precipitation depth mm ia represents the initial abstraction of precipitation mm s is the potential maximum soil water capacity after runoff generation mm cn is the curve number its value ranging from 0 to 100 λ is the initial abstraction ratio it usually assigned as a constant value of 0 2 cn values of different land cover types were determined using the look up table of technical release 55 from natural resources conservation service nrcs depends upon the soil type and the antecedent moisture condition amc nrcs 1986 according to the analysis of soil infiltration characteristics in beijing by fu et al 2013 the hydrological soil group in the study area assumed with moderate infiltration capacity used as b class the antecedent moisture condition was used at a moderate soil condition amc ii which is considered as the standard for most researches xu et al 2020 the determined cn values of different land covers are summarized in table 2 specially surface runoff generated from water bodies may not bring extra influence on surrounding surfaces thus their cn values can be assigned as 0 yao et al 2015 2 5 flood risk threshold setting and risk level determination the risk thresholds of urban flooding were determined according to the upper limits of runoff coefficients for urban land covers in the code for design of outdoor wastewater engineering gb50014 2021 ministry of housing and urban rural development of the people s republic of china 2021 the determined runoff coefficient thresholds of different land covers are summarized in table 3 in this study due to the exact standards for probabilistic risk levels in china were lacked the probabilistic risk level standards of concern thresholds proposed by the us environmental protection agency usepa united states environmental protection agency usepa 2014 were adopted to determine risk levels of urban flooding that is appropriate to the risk assessment objective and decision making information for flood prewarning according to the determined risk levels the risk probability values classified as four risk levels no risk level probability values 0 05 a low risk level 0 05 probability values 0 1 a moderate risk level 0 1 probability values 0 5 and a high risk level probability values 0 5 table 4 2 6 determination of probability distribution functions of daily precipitation the gamma distribution is widely applied as the standard distribution for precipitation frequency analyses basheer et al 2016 fatichi et al 2011 yu et al 2022 zhi et al 2022 thus gamma distribution was utilized to generate probability density distributions of daily precipitation in this study the general gamma distribution with two parameters is given as 7 f x x α 1 1 β α γ α e x β x 0 α β 0 8 α μ 2 σ 2 9 β σ 2 μ where f denotes the distribution function x is an independent variable α is the shape parameter β is the scale parameter μ and σ 2 are the mean and variance of gamma distribution in this study historical daily precipitation data with 30 years 1991 2020 were collected from national rain gauge stations shared by the china meteorological data service center https data cma cn in the fitting process the historical daily precipitation events were used to determine the shape and scale parameters of gamma distribution the fitted gamma distribution function of historical daily precipitation goodness of fit was 0 92 was expressed as follows 10 f h s d p x x 0 501 1 15 629 0 499 γ 0 499 e x 15 629 the future daily precipitation data of the study area for years 2021 2050 were obtained by downscaling the climate data of the bcc csm2 mr model of global circulation models gcms from the cmip6 archive https portal nccs nasa gov datashare nexgddp cmip6 bcc csm2 mr and calibrated by the historical observed precipitation data the bcc csm2 mr model is one of the models developed by beijing climate center bcc it can realistically reproduce the main patterns of precipitation and had better capability for simulating the evolution of multi year precipitation thus it has been widely used in china hamed et al 2022 liu et al 2022b song et al 2022 wu et al 2019 xin et al 2020 zhang et al 2022 firstly the large scale daily precipitation data of the bcc csm2 mr were downscaled to the local scale of nearby national weather station haidian station 116 28e 39 98 n by the inverse distance weighted interpolation method which according to the distance calculated by the coordinate values of latitude and longitude from the weather station to the geographical center of the four neighbouring gcm grid units liu and zuo 2012 then the historical observed daily precipitation data from the year 1991 2020 of the study area was used to calibrate the downscaling precipitation data from bcc csm2 mr model of the same historical period the time series of downscaling projected precipitation data for future climate change 2021 2050 were standardized with their means and standard deviations corresponding to the historical climate condition and subsequently transformed back with those of historical observed precipitation under the assumption that the bias does not change over time johnson and sharma 2012 after that the gamma distribution functions of daily precipitation for ssp2 4 5 and ssp5 8 5 climate change scenarios goodness of fit was both 0 95 were fitted and respectively expressed as follows 11 f s s p 2 4 5 d p x x 0 401 1 15 954 0 599 γ 0 599 e x 15 954 12 f s s p 5 8 5 d p x x 0 391 1 16 291 0 609 γ 0 609 e x 16 291 2 7 model runs and display of spatial data based on the classification of land covers the study area was consisted of approximately 1 215 million land cover units first attribute table data of land covers in the layer file was derived as a raster data file for further computing then using 10 000 monte carlo stochastic simulations of daily precipitation the surface runoff calculation by employing the scs cn method and the probabilistic flood risk calculation in every land cover unit were all performed using the r software 3 4 2 after that the probability values of flood risk were joined into the attribute table of the land cover layer file finally the statistical analysis and the mapping of spatial probabilistic flood risk at the city scale were realized in arcmap 10 3 3 results 3 1 characteristics of the generated daily precipitation events in the historical period a total of 1 994 observed daily precipitation events were reserved for the future climate change period ssp2 4 5 scenarios retained 3 169 projected daily precipitation events and ssp5 8 5 scenario retained 3 076 projected daily precipitation events compared with the observed and projected daily precipitation data the amount of monte carlo generated daily precipitation events increased by 3 2 5 0 times in this study the mean amounts of daily precipitation for 10 000 monte carlo simulations generated were 7 8 mm 9 5 mm and 9 8 mm and the maximum precipitation amounts were 114 5 mm 109 8 mm and 115 3 mm for the historical period ssp2 4 5 and ssp5 8 5 scenarios respectively the probability density of monte carlo generated daily precipitation for the historical condition ssp2 4 5 and ssp5 8 5 climate change scenarios are shown in fig 3 fig 4 shows the cumulative probability curves of daily precipitation in the historical and climate change scenarios results showed that there are significant changes in the monte carlo generated daily precipitation events between the historical condition and climate change scenarios the probability of daily precipitation under future climate change scenarios gradually increased for all the monte carlo stochastically generated precipitation events the probability density of daily precipitation under the historical period was relatively smaller the cumulative probability curves between ssp2 4 5 and ssp5 8 5 scenarios were slight varied moreover the maximum probability density of precipitation for ssp2 4 5 scenario was greater than for the ssp5 8 5 scenario and historical condition 3 2 characteristics of probabilistic risk for urban flooding under the historical period the calculated probabilistic urban flood risk under the historical period in the study area ranged from 0 to 0 508 with a mean value of 0 104 and a total coefficient of variation of 1 636 indicating probabilistic urban flood risk was at the medium risk level the areas where probabilistic urban flood risk under the historical condition reached the low risk level 0 05 risk probability 0 1 accounting for 0 64 4 3 km2 and the areas where probabilistic flood risk reached the medium risk level 0 1 risk probability 0 5 accounting for 34 3 224 2 km2 of the study area meanwhile only a 0 06 km2 area reached the high probabilistic flood risk level risk probability 0 5 under the historical period moreover probabilistic urban flood risk under the historical condition presented high spatial heterogeneity within the beijing fifth ring roads fig 5 areas exhibiting high probabilistic flood risk were mainly distributed in the impervious surfaces the mean probabilistic flood risk was 0 418 and 0 487 for buildings and roads respectively furthermore forestlands and grasslands showed the lower probabilistic flood risk differently the water body areas exhibited no probabilistic flood risk 3 3 spatial distribution of probabilistic flood risk under future climate change scenarios fig 6 illustrates the spatial characteristics of probabilistic risk for urban flooding under future climate change scenarios the ranges of calculated probabilistic flood risk in the study area were 0 0 588 and 0 0 601 with the mean values of 0 126 and 0 131 and the total coefficients of variation were 1 581 and 1 561 under ssp2 4 5 and ssp5 8 5 climate change scenarios respectively the areas where probabilistic flood risk reached the medium risk level respectively accounted for 16 5 110 0 km2 and 0 92 6 2 km2 of the study area under ssp2 4 5 and ssp5 8 5 scenarios meanwhile the areas where probabilistic flood risk reached the high risk level accounted for 17 1 114 2 km2 and 32 7 218 1 km2 in the study area for ssp2 4 5 and ssp5 8 5 scenarios respectively the mean probabilistic flood risk of buildings and roads was 0 496 and 0 567 under the ssp2 4 5 scenario 0 508 and 0 579 under the ssp5 8 5 scenario respectively the area of surfaces with the high probabilistic flood risk was significantly increased from the ssp2 4 5 scenario to the ssp5 8 5 scenario 3 4 change trends of probabilistic flood risk under future climate change scenarios fig 7 shows the spatial characteristics of percentage changes of probabilistic flood risk under future climate change scenarios compared with the historical period results showed that the ssp5 8 5 scenario decreased the medium flood risk areas by 97 3 compared with the historical period and as well the ssp2 4 5 scenario reduced the medium flood risk areas by 50 9 simultaneously under climate change conditions the area of surfaces with the high probabilistic flood risk increased 114 2 km2 and 218 0 km2 for ssp2 4 5 and ssp5 8 5 scenarios respectively table 5 summaries the median changes for probabilistic flood risk of different land covers under climate change scenarios the order of median percentage changes for probabilistic flood risk under climate change was forestland grassland bare land pavements buildings roads the largest changes of probabilistic flood risk mainly occurred for forestlands and grasslands in the study area however the buildings and roads had the relatively lower changes of probabilistic flood risk under climate change condition overall compared with the historical condition probabilistic risk of urban flooding in the study area was projected to increase by 50 3 67 4 on average from ssp2 4 5 to ssp5 8 5 climate change scenarios particularly the smallest increase in probabilistic flood risk was 16 4 for the ssp2 4 5 scenario as well as 20 0 for the ssp5 8 5 scenario the largest increase of probabilistic flood risk was nearly 200 for the ssp2 4 5 scenario and it was approximately 250 for the ssp5 8 5 scenario 4 discussion 4 1 advantages of probabilistic urban flood risk assessment the projection of future flood risk under climate change condition is challenging due to uncertainties associated with future precipitation projections uncertainty in distribution function applied to generate precipitation and uncertainties from hydrologic model and their input parameters kundzewicz et al 2017 ranger et al 2011 salman and li 2018 moreover while different model structures and procedures are used in the simulation of flood characteristics and frequency they have in common that considerable uncertainties are identified in various parts of flood risk assessment winter et al 2018 therefore it is unfeasible to quantify the likelihood of various risk levels of urban flooding without utilizing probabilistic methods probabilistic risk assessments can approach a full range of possible consequences and the possibility of each risk level thus allowing the uncertainty of risk to be quantitatively expressed united states environmental protection agency usepa 2014 some literature concluded that hydrologic uncertainties are much less significant than those originating from future precipitation projections under climate change in flood risk assessment collet et al 2018 steinschneider et al 2015 in this study in order to address the great uncertainty associated with future precipitation projections the monte carlo simulations stochastically generated 10 000 daily precipitation events according to the fitted gamma probability distributions based on the historical and future daily precipitation data the amount of monte carlo generated daily precipitation events increased by 3 2 5 0 times compared with the observed and projected daily precipitation data which include full range of possible extreme storm events especially it captured the occurrence of infrequent precipitation events with long return period using the developed probabilistic flood risk assessment the calculated probabilistic urban flood risk in the study area ranged from 0 to 0 601 and the mean values varied from 0 104 to 0 131 under the historical period and climate change scenarios consequently the monte carlo stochastically generated daily precipitation and acquired a wider range of possible weather scenarios than historical record of precipitation events which can approximately represent the characteristics of daily precipitation with high variability and provide the likelihood of various risk levels thus allowing for performing more accurate flood risk assessment dawkins et al 2022 zhi et al 2022 further some researchers concluded that the monte carlo stochastic simulation could take into account the uncertainty of precipitation events and possible consequences more exactly quantify the uncertainty of flood risk itself ghersi et al 2017 kalyanapu et al 2012 therefore the developed probabilistic flood risk assessment can effectively reduce the uncertainties of urban flood hazard risk associated with the impacts of future climate change and they can provide more reliable urban flood risk information and future evolution trends 4 2 impacts of future climate change on urban flood risk understanding the driving mechanism behind urban flood risk is essential to inform future climate change mitigation and adaptation strategies under ever changing conditions yu et al 2022 zhou et al 2019 climate change is regarded as one of the key driving factors of flood risk in urban areas which results in large impacts on extreme precipitation patterns and thus can directly intensify the frequency and magnitude of urban floods berndtsson et al 2019 zhou et al 2019 in this study compared with the historical period probabilistic risk of urban flooding in the study area was projected to increase by 51 3 and 67 4 on average for ssp2 4 5 and ssp5 8 5 climate change scenarios respectively these projected results revealed a significant increase in probabilistic risk of future urban flooding under climate change condition which is consistent with previous findings alfieri et al 2015 chen et al 2021 hettiarachchi et al 2018 hou et al 2020 zhou et al 2018a consequently the projected future climate change represented a key driving factor affecting probabilistic urban flood risk although the mean values of probabilistic flood risk in the study area for ssp2 4 5 and ssp5 8 5 scenarios were approached 0 126 and 0 131 respectively further analysis indicated that the area of surfaces with the high probabilistic flood risk was significantly increased from the ssp2 4 5 scenario to the ssp5 8 5 scenario moreover the largest increase of probabilistic flood risk was approximately 200 and 250 for ssp2 4 5 and ssp5 8 5 scenarios respectively therefore the ssp2 4 5 scenario showed a lesser magnitude increase in probabilistic flood risk than the ssp5 8 5 scenario it indicated that decreasing greenhouse gas emissions can lower the urban flood risk these results are similar to zhou et al 2018a they predicted a higher increase 52 in urban flood volume for the rcp 8 5 than the rcp 2 6 scenario 13 as well chen et al 2021 projected the highest flood risk areas are increased by 8 7 and 19 8 under ssp2 4 5 and ssp5 8 5 scenarios respectively it seems likely that extreme storm events were projected to be more predominated at the study area under the high emission scenario than the medium emission scenario chen et al 2021 also highlighted the reduction in greenhouse gas emission could mitigate the effects of future climate change on flood risk further more appropriate options of climate adaptation and mitigation strategies are increasingly needed to deal with the adverse impacts of future climate change on flood risk in urban areas alexander et al 2019 hou et al 2020 leandro et al 2020 4 3 limitations of the study first in the present study surface runoff generated by daily precipitation events over urban areas was spatially assessed which was assumed to represent the potential urban flood risk rather than the real conditions of flood hazard this study mainly focused on risk assessment method which statistically quantified the probabilistic aspects in urban flood risk analysis it aims to better characterize the probability of urban flood hazard in light of climate change and provide useful insight on how climate change may amplify the hazard presented by intense rainfall second the future daily precipitation data only used the projections from bcc csm2 mr model of gcms which would cause a certain uncertainty exists in projection data of future precipitation from the single model further the spatial heterogeneity of daily precipitation in the study area was not considered future studies need to be focused on spatially downscaling the projected climate data from various gcms toward a more reliable projection of future precipitation data and further explore the sources of uncertainty in future flood risk assessment and quantify their contribution to the overall predictive uncertainty third future flood risk changes were projected under climate change condition with the assumption that climate change is the only driving factor of urban flood risk however in urban areas land cover change is also an important driving factor that influences urban flooding the assumption is feasible because that future land cover change in the study area with high density urbanization will be very little due to urban land is the predominant type and approaches saturated in future studies the impacts of land cover change and climate change need to be joined together to comprehensively assess urban flood risk 5 conclusions the present study presented a new probabilistic risk assessment method to quantify the probabilistic risk of urban flooding and assess the impacts of future climate change on urban flood risk the number of monte carlo stochastically generated daily precipitation events increased by 3 2 5 0 times compared with the observed and projected daily precipitation data which acquired a wider range of possible climate scenarios than the historical record precipitation events thus allowing for a more accurate assessment of flood risk overall the calculated probabilistic urban flood risk under the historical period in the study area was at the medium risk level 34 3 of the study area reached the medium flood risk level compared with the historical period probabilistic risk of urban flooding in the study area was projected to on average increase by 51 3 and 67 4 for ssp2 4 5 and ssp5 8 5 climate change scenarios respectively revealing a significant increase in probabilistic risk of future urban flooding it is worth noting that the largest changes of probabilistic flood risk mainly occurred for forestlands and grasslands in the study area although the mean values of probabilistic flood risk in the study area for two climate change scenarios were approached the area of surfaces with the high probabilistic flood risk significantly increased from the ssp2 4 5 scenario to the ssp5 8 5 scenario the ssp2 4 5 scenario showed a lesser magnitude increase in probabilistic flood risk than the ssp5 8 5 scenario indicating that controlling greenhouse gas emissions can effectively lower the flood risk therefore the developed probabilistic risk assessment is an effective quantitative method for characterizing the likelihood of urban flood risk occurrence and it can improve the uncertainty estimation of urban flood trends under future climate change the projected trends of probabilistic flood risk can result in a better understanding of the evolution trends of future urban flood risk thus provide a scientific basis for the characterization and early warning of urban flood hazard the urban flood risk assessment also can assist urban managers in developing flood mitigation strategies to cope with the adverse impacts of future climate change on urban flooding declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the west light foundation of the chinese academy of sciences no 2023 16 no 2020 82 and the national natural science foundation of china 42071051 we thank both reviewers and the journal editor for their constructive and sincere comments that have improved the clarity of the final manuscript 
