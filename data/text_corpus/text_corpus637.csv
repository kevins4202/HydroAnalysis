index,text
3185,evapotranspiration is a key component of the hydrologic cycle accurate short medium and long term forecasts of actual evapotranspiration eta are crucial not only for quantifying the impacts of climate change on the water and energy balance but also for real time estimation of crop water demand and irrigation water allocation in agriculture despite considerable advances in satellite remote sensing technology and the availability of long ground measured and remotely sensed eta timeseries real time eta forecasts are deficient applying a state of the art deep learning dl approach long short term memory lstm models were employed to nowcast real time and forecast ahead of time eta based on 1 major meteorological and ground measured i e soil moisture input variables and 2 long eta timeseries from the moderate resolution imaging spectroradiometer modis onboard of the nasa aqua satellite the conventional lstm and convolutional lstm convlstm dl models were evaluated for seven distinct climatic zones across the contiguous united states the employed lstm and convlstm models were trained and evaluated with data from the national climate assessment land data assimilation system nca ldas and with modis aqua net evapotranspiration myd16a2 product data the obtained results indicate that when major atmospheric and soil moisture input variables are used for the conventional lstm models they yield accurate daily eta forecasts for short 1 3 and 7 days and medium 30 days time scales with normalized root mean squared errors nrmse and nash sutcliffe efficiencies nse of less than 10 and greater than 0 77 respectively at the watershed scale the univariate convlstm models yielded accurate weekly spatiotemporal eta forecasts mean nrmse less than 6 4 and nse greater than 0 66 with higher computational efficiency for various climatic conditions the employed models enable precise forecasts of both the current and future states of eta which is crucial for understanding the impact of climate change on rapidly depleting water resources keywords evapotranspiration forecasting lstm convlstm climate change deep learning 1 introduction quantifying the response of the terrestrial biosphere to global climate change is a grand challenge in hydrologic sciences pan et al 2015 warming of the land and atmosphere alters weather patterns and all components of the water and energy cycles causing extreme weather events and associated natural disasters including floods droughts wildfires and landslides actual evapotranspiration eta is a critical component of the hydrologic cycle because it connects the water evaporation energy latent heat flux and carbon transpiration photosynthesis trade off cycles fisher et al 2017 the eta regulates the water and energy balance of the earth s biosphere hydrosphere and atmosphere especially in water limited ecosystems where it may account for nearly the entire surface water budget fisher et al 2017 oki and kanae 2006 morillas et al 2013 in general eta is determined based on either the water balance or the energy balance provided that all remaining components are known techniques such as the penman monteith method allen 1996 are frequently applied to estimate potential evapotranspiration because of the large number of required meteorological input variables it is challenging to apply such methods in data scarce regions remote sensing rs observations in conjunction with meteorological variables are used as inputs for surface energy balance seb methods for eta estimation methods such as the surface energy balance algorithm for land sebal bastiaanssen et al 1998 the mapping evapotranspiration at high resolution with internalized calibration metric allen et al 2015 and atmosphere land exchange inverse alexi disalexi models norman et al 2003 anderson et al 2004 have been widely applied for large scale mapping of eta based on the combined application of optical and thermal rs observations the earth engine evapotranspiration flux eeflux that integrates the metric algorithm into the google earth engine for processing of landsat satellite images 30 m 16 days offers means for automated long term and large scale eta mapping allen et al 2015 the priestley taylor jet propulsion laboratory pt jpl fisher et al 2008 method a simplified form of the penman monteith equation monteith 1965 provides another option for eta estimation from rs data nasa recently launched the ecostress satellite to estimate eta based on the pt jpl algorithm with spatial and temporal resolutions of 70 m and 3 5 days respectively fisher 2018 2020 two source energy balance tseb models a subcategory of the seb models consider the soil and plant canopy as distinct eta sources norman et al 1995 french et al 2015 andreu et al 2018 the eddy covariance ec method a widely applied ground based energy balance approach is frequently employed for the validation of satellite eta estimates the ec method is also applied at the u s critical zone observatory czo sites as well as at the fluxnet and ameriflux sites baldocchi et al 2001 fisher et al 2007 incorporation of remotely sensed soil moisture data in the pt jpl model has improved eta estimation as shown in purdy et al 2018 which indicates an obvious link between soil moisture and vegetation cover adegoke et al 2002 the fundamental constraint of the aforementioned eta measurement methods is that they provide historical and near real time observations yet many eta applications would benefit from real time data at diurnal resolution which is lacking to date another issue is that cloud induced signal disturbance results in temporal gaps and unequal revisit durations for satellite sensors restricting real time monitoring of eta at large scales quantifying the future states of eta is not only crucial for determining crop water requirements for accurate water allotment planning and for real time irrigation scheduling but also for understanding the water cycle s vulnerability to climate change historically most of the hydrologic forecasting has been focused on the supply side of the water cycle i e precipitation and streamflow nguyen et al 2015 kidd et al 2013 crow et al 2017 largely ignoring demand i e evapotranspiration significant progress in satellite rs and the availability of long term eta observations combined with advances in state of the art data driven approaches for modeling spatiotemporal eta patterns present an unprecedented opportunity for understanding the effect of climate change on the future state of the demand side of the hydrologic cycle this can be accomplished by developing advanced models for short mid and long term forecasting of eta for a range of land surface and climatic conditions recent innovations in the field of machine learning ml offer an exciting opportunity for developing data driven models of physical processes ball et al 2017 lary et al 2016 the application of ml to estimate biophysical parameters from rs observations has shown remarkable results reichstein et al 2019 among the various ml methods deep learning dl has already made a significant impact for weather and hydrologic applications shen et al 2018 moghadam et al 2021 li et al 2022 liu et al 2022 and showed superior performance when compared to traditional ml methods reichstein et al 2019 alom et al 2019 fang et al 2019 the primary advantage of dl is its capacity to discover complicated relationships automatically and effectively and to hierarchically extract spatiotemporal features from raw data deep learning approaches are commonly classified as supervised utilizes labeled data semi supervised uses partially labeled data or unsupervised the most widely used deep learning techniques are supervised methods which include variants of deep neural networks hinton et al 2012 convolutional neural networks cnn fukushima 1988 lecun et al 1998 recurrent neural networks rnn cho et al 2014 rodriguez et al 1999 and long short term memory lstm methods hochreiter and schmidhuber 1997 gers et al 2000 the cnns are capable of learning spatial links whereas rnns are capable of learning temporal patterns the rnns can be employed for forecasting the current and future states of a system based on historical events the lstm method has been developed to learn both short and long term dependencies between time steps of sequential data providing a powerful tool for accurately estimating the present real time and future forecasting state of a system based on past occurrences the use of lstm is particularly advantageous for eta nowcasting and forecasting in situations where nonlinear spatiotemporal dynamics exist and conventional ml methods are unable to address such complicated relationships the convolutional lstm convlstm method is a variant of the lstm that incorporates cnn it is well suited for spatial sequence data such as time series of rs observations xingjian et al 2015 kreuzer et al 2020 recent research has demonstrated the success of dl for extracting spatial information from weather forecast model outputs to detect and classify extreme weather events i e storms and hurricanes liu et al 2016 and 2020 racah et al 2016 other studies have successfully applied dl models for weather and climate forecasting scher 2018 mapping flood susceptibility bui et al 2020 forecasting wind speed liu et al 2019 peng et al 2020 forecasting streamflow liu et al 2020 fu et al 2020 forecasting drought mehr et al 2022 and for estimation of evaporation malik et al 2022 koppa et al 2022 several recent investigations have employed lstm to specifically forecast streamflow hu et al 2020 kratzert et al 2018 kratzert et al 2019 le et al 2019 however it is currently not known whether lstm models can accurately nowcast i e present state and forecast i e future state eta motivated by the importance of eta forecasts availability of long term ground and rs observations and the success of state of the art dl methods for weather and hydrologic modeling and forecasting the objectives of this paper are i to assess the feasibility of conventional lstm applied in conjunction with ground and meteorological observations to accurately forecast short and mid term eta ii to investigate the capability of convlstm with univariate input data to forecast eta based on modis eta observations and iii to demonstrate the effectiveness of lstm and convlstm models for forecasting eta for a variety of climatic conditions in the contiguous united states conus 2 methods and datasets a multivariate conventional lstm network was trained for short and medium range forecasting of eta based on the time series of meteorological and soil variables that were extracted from the national climate assessment land data assimilation system nca ldas for seven locations with vastly different climates and land covers distributed across the conus in addition a watershed scale convlstm network to forecast eta on a weekly time scale based on the modis aqua net evapotranspiration myd16a2 version 6 product was trained both datasets were split into training and test sets with the latter applied to evaluate the performance of the lstm and convlstm forecasts in this study short term refers to lead times of 1 3 and 7 days and mid term to 30 days these timescales have been utilized extensively in hydrologic forecasting e g velazquez et al 2009 regonda et al 2013 sommerlot et al 2016 kim et al 2018 2 1 conventional and convolutional long short term memory networks long short term memory lstm is a particular case of a recurrent neural network rnn model which learns from sequential data previous time steps and forecasts the present and future states of a system hochreiter and schmidhuber 1997 the lstm network consists of layers of memory that contain units referred to as cell states and gates each memory unit contains three gates forget input and output the forget gate controls the information from the previous state that will no longer be stored the input gate specifies the input features that will be stored in the next state and the output gate specifies the information from the new state that will be output the memory cell facilitates the lstm to extract long term dependencies necessary for eta forecasting fig 1 a illustrates the internal structure of a lstm cell following fig 1a the three gates of the lstm network are given as 1 z t t a n h w xz x t w hz h t 1 b z i n p u t n o d e 2 f t σ w fx x t w fh h t 1 w fc c t 1 b f f o r g e t g a t e 3 i t σ w ix x t w ih h t 1 w ic c t 1 b i i n p u t g a t e 4 o t σ w xo x t w ho h t 1 w co c t b o o u t p u t g a t e where xt is the current input for time step t h t 1 is the previous output c is the cell state for time step t long term dependency ht is the hidden state that is the input of the next time step considered as a short term state for four fully connected neurons ft zt it and ot the σ represents the classical sigmoid activation function for the gate units w represents the network weights b is the bias and tanh represents the nonlinear activation function of the cell gate units the c and h are obtained from 5 c t i t z t f t c t 1 c e l l s t a t e 6 h t o t t a n h c t h i d d e n g a t e 7 y t w hy h t b y o u t p u t l a y e r where is the multiplication operation for two vectors at each time step the network outputs a value yt which is compared to the reference eta data y t for the entire time period t the loss function γ t to be minimized is the mean squared error calculated for the time series 8 γ t 1 t t 1 t y t y t 2 in addition a hybrid dl model termed convolutional lstm convlstm which combines cnn and lstm was evaluated convlstm is a special type of lstm layer developed for spatiotemporal forecasts from 2d data e g time series of modis aqua net evapotranspiration shi et al 2015 in this model the future state of a specific cell in the grid is determined by the inputs and past states of its local neighbors this is achieved with a convolution operator in the state to state and input to state transitions the internal structure of a convlstm memory cell and the operating mechanism is depicted in fig 1b equations 9 to 14 represent the architecture of the convlstm and detailed algorithms of the components of the memory cell 9 z t t a n h w xz x t w hz h t 1 b z i n p u t n o d e 10 f t σ w fx x t w fh h t 1 w fc c t 1 b f f o r g e t g a t e 11 i t σ w ix x t w ih h t 1 w ic c t 1 b i i n p u t g a t e 12 o t σ w xo x t w ho h t 1 w co c t b o o u t p u t g a t e 13 c t i t z t f t c t 1 c e l l s t a t e 14 h t o t t a n h c t h i d d e n g a t e 2 2 architecture of the employed deep neural networks two distinct sets of data were used for training and evaluation the initial set used to train and evaluate the standard lstm models consisted of meteorological and ground data extracted from the national climate assessment land data assimilation system nca ldas for the seven selected sites for sixteen years 2001 to 2016 fig 2 depicts the concept of splitting dataset into training testing and forecasting sets for the standard lstm model as shown the lstm models were trained with a long sequence of data to forecast eta for the most recent year where the focus was on 1 3 7 and 30 day lead times for example to forecast eta for the day n 1 1 day lead time the model is fed with the values from the previous n days the forecasted eta value for day n 1 is combined with the previous n days to generate the forecast for day n 2 and so forth the frame window s latency was set to 100 frames the batch size was 16 and training was conducted with an adaptive learning rate of up to 300 epochs the network was composed of two 500 unit thick lstm layers and a final dense layer each lstm layer was assigned a 10 dropout to avoid overfitting the learning rate indicates the network s learning efficiency the batch size indicates the number of samples in each batch the dropout designates the proportion of layer nodes that are randomly turned off and epochs specifies the number of iterations required to obtain the optimal model the architecture of the lstm network employed in this study is depicted in fig 3 a the second dataset consisted of the modis aqua net evapotranspiration myd16a2 version 6 product a univariate convlstm was employed to integrate convolutional and recurrent operations for spatiotemporal forecasting of eta using long term data from the myd16a2 product univariate convlstm was employed because of its availability to learn long term patterns of a single variable i e eta to predict the current and future state from past conditions this approach has been widely applied for sentence completion when a partial sentence is provided as input to predict the next word and when the new word is known it is appended to the input sentence to predict the next word univariate convlstm is of great interest in data scarce regions where data from weather stations is lacking the convlstm was evaluated for four watersheds with differing climates land covers and soil types more than 800 sequential modis aqua eta observations were collected at 8 day interval for each watershed from 2001 to 2019 each sample had a 23 frame lag or frame window the batch size was sixteen and the training period was 200 epochs the convlstm architecture employed in this study is depicted in fig 3b the output of one convlstm layer serves as the input for the subsequent layer in the deep architecture numerous tests were conducted with up to five convlstm layers and the optimal design was chosen the final network is composed of four layers each of which has fifty filters with a size of 3 3 and a stride size of 1 fig 3b because neural networks have a large number of parameters they are prone to overfitting to avoid overfitting a 10 dropout throughout the network was implemented the consideration of dropouts is an effective strategy for reducing overfitting in neural networks srivastava et al 2014 each convlstm layer s forward output was transferred to a batch normalization unit to accelerate the learning process and to alleviate internal covariate shift ioffe and szegedy 2015 to remove the effect of scale disparity and avoid obstacles with convergence during training all input and output variables were rescaled using min max normalization the lstm and convlstm models were implemented in python using the tensorflow abadi et al 2016 implementation of keras an open source machine learning platform keras io the models were executed on a tesla k80 gpu accessed via google colab a sequence to sequence forecasting approach was employed to forecast subsequent steps based on the previous forecasts this strategy is particularly advantageous for short and mid term forecasts as the input variables only need to be accessible until the forecast commences 2 3 study sites the seven selected sites are part of the ameriflux network ameriflux lbl gov and represent different climate zones across the conus which are classified based on the international energy conservation code iecc and the american society of heating refrigerating and air conditioning engineers ashrae scheme and exhibit a wide range of eta dynamics fig 4 depicts an overview of the selected sites together with the frequency distributions of daily eta see also table 1 the walnut gulch lucky hills site us whs in southeastern arizona was established by the united states department of agriculture usda in 1953 the elevation varies between 1252 and 1718 m with a topography ranging from extremely steep slopes 50 to nearly flat concave basin floors the site is located within the hot dry climate zone and exhibits a mean annual temperature of 17 7 c and mean precipitation of 350 mm about two thirds of the precipitation typically falls during the monsoon season from july to september the evapotranspiration might be nearly ten times higher than the annual precipitation the site is predominantly covered by desert shrublands two thirds and desert grasses one third with soils consisting primarily of sandy loam and gravelly loam with little organic matter content the site has frequently been used as a core validation site for soil moisture estimates obtained from satellite rs missions for detailed information about the us whs site readers are referred to skirvin et al 2008 the tonzi ranch us ton site is located in the sierra nevada foothills in north central california the climate is characterized by wet and mild winters and dry and hot summers with a mean annual temperature of 15 8 c a mean precipitation of 560 mm and a mean evapotranspiration of 539 mm the major soil texture is sandy clay loam with low organic matter content the vegetation is dominated by oak grass savanna mixed forests grasslands and shrublands the mean elevation is between 129 and 177 m detailed information about the site is provided in ma et al 2007 the johnson creek us ne3 site is located in eastern nebraska at an elevation of 363 m the climate is cold with an average annual temperature of 10 1 c and an average annual precipitation of 784 mm the site is situated on cropland and mainly covered with temporary crops i e rainfed soybeans and maize after harvest soils remain bare with no till management the lost creek us los site is located in north central wisconsin at an elevation of about 480 m the land cover consists of shrub wetland coniferous forest and grassland sulman et al 2009 the climate is extremely cold with an average annual temperature of 4 0 c and an average annual precipitation of 828 mm that is evenly distributed throughout the year the disney wilderness preserve us dwp site which is located within the hot humid climate zone in south central florida between polk and osceola counties near the headwaters of the everglades ecosystem is a patchwork of forests grasslands and wetland habitats the mean annual temperature is 22 5 c and the mean annual precipitation is 1216 mm the majority of precipitation falls in summer and is associated with tropical storms the low site elevation that ranges from 13 and 21 m causes susceptibility to flooding fine sand is the prevalent soil texture in the region the southern great plains us arm site is located in northern oklahoma within the mixed humid climate zone that is characterized by moderate winters and hot summers annual mean temperature and precipitation are 14 8 c and 890 mm respectively while winter wheat and canola are commonly grown in fall and winter corn sorghum cowpeas barley and soybeans are the typical crops in spring and summer the soils are well drained silt loams silty clay loams or clay loams the niwot ridge us nr1 site located in the colorado rocky mountains is a subalpine forest ecosystem dominated by subalpine fir abies lasiocarpa engelmann spruce picea engelmannii and lodgepole pine pinus contorta with an average canopy height of 11 4 m the mean elevation is 3050 m with gentle slopes 6 7 running from west to east the climate is very cold with an annual mean temperature of 4 0 c and an annual precipitation of about 800 mm with approximately 65 falling as snow monson et al 2002 2005 turnipseed et al 2002 2003 2 4 datasets the point scale ground measured and meteorological variables for the seven selected sites fig 4 were obtained from the national climate assessment land data assimilation system nca ldas ldas gsfc nasa gov nca ldas the nca ldas is an integrated terrestrial water analysis database established by the nasa goddard space flight center hydrological sciences laboratory that integrates in situ and remote sensing observations as well as model estimations to provide high quality analyses and a publicly accessible data for sustained climate assessment in the conus jasinski et al 2019 when compared to land surface models the current nca ldas products proved to be superior for soil moisture snow depth precipitation and evapotranspiration kumar et al 2019 for detailed information about the nca ldas database readers are referred to jasinski et al 2019 and kumar et al 2019 table 2 lists the minimum maximum and mean values of the utilized ground measured and meteorological variables including precipitation net radiation air temperature wind speed soil moisture latent heat flux i e eta sensible heat flux and soil heat flux that were calculated from daily values collected from 2001 to 2016 the five major lstm model inputs for forecasting eta were precipitation net radiation air temperature wind speed and soil moisture soil moisture was used as a proxy for the effect of vegetation cover on eta because it controls root water uptake and transpiration rates the link between soil moisture and vegetation cover has been extensively studied and documented in literature e g adegoke et al 2002 yang et al 2018 the benefit of including soil moisture to improve eta estimations was previously demonstrated by purdy et al 2018 to evaluate their impact on the accuracy of the eta forecasts the soil heat flux and the sensible heat flux were considered as additional input variables fifteen years of data 2001 to 2015 were used for lstm model training and one year 2016 for testing to investigate the eta forecasting capability of the convlstm networks the modis aqua net evapotranspiration product myd16a2 version 6 with 8 day temporal resolution and 500 m spatial resolution was utilized and tested for the walnut gulch us whs tonzi ranch us ton johnson creek us ne3 and lost creek us los watersheds the selected watersheds encompass a broad spectrum of land covers and climate conditions the publicly available myd16a2 product lpdaac usgs gov products myd16a2v006 is based on the penman monteith equation allen 1996 and incorporates daily meteorological data as well as modis vegetation dynamics albedo and land cover observations more than 800 sequential myd16a2 product data were extracted for each watershed from 2001 to 2019 the dataset was divided into a 18 year training set and a one year 2019 test set the ratio was chosen to ensure that the test set contained one full year of data 2 5 model performance metrics to evaluate the performance of the lstm and convlstm models four metrics including the normalized root mean squared error nrmse the bias the coefficient of determination r2 and the nash sutcliffe efficiency nse were selected and calculated as 15 nrmse rmse o max o min 1 n i 1 n f i o i 2 o max o min 16 bias 1 n i 1 n o i f i 17 r 2 i 1 n f i f mean 2 i 1 n o i o mean 2 18 nse 1 i 1 n o i f i 2 i 1 n o i o mean 2 where n is the number of forecasted and reference eta pairs o i and f i are the i th observed and nowcasted forecasted values o min and o max denote the observed minimum and maximum values o mean and f mean denote the mean observed and nowcasted forecasted eta data respectively a nse value of 1 signifies a perfect match between forecasted and observed values the bias was calculated to determine over and under forecasting of the models the nrmse is defined as the rmse divided by the range of ground truth values with a perfect value of zero it should be mentioned that while the rmse is beneficial for comparing the performances of different models for a specific time series nrmse is better suited for comparing model performance across different time series additionally it has been pointed out that the nrmse metric can be used to better determine the performance of hydrologic variables legates and mccabe 1999 3 results and discussion a total of 11 dl models seven of which are multivariate conventional lstm models and four are univariate convlstm models were employed and validated as discussed in sections 2 1 and 2 2 the lstm models were constructed with point scale timeseries of ground measured and meteorological variables from nca ldas whereas the convlstm models were constructed with spatiotemporal eta observations from the modis aqua satellite for the conventional lstm models two levels of input data were utilized and evaluated the first level comprised of soil moisture precipitation net radiation air temperature and wind speed while the second dataset additionally included the sensible heat and soil heat fluxes 3 1 lstm eta forecasts 3 1 1 forecasts based on ground measured and meteorological variables the time series of short 1 3 and 7 days ahead and mid term 30 days ahead daily eta forecasts along with the reference daily eta values for the training set for each of the seven sites are depicted in fig s1 supplemental information a good match is observed between forecasted and reference eta values suggesting that the conventional lstm models successfully capture temporal dynamics of eta hence are capable to nowcast and forecast eta for a wide range of climate conditions the calculated nrmse bias nse and r2 values between forecasted and reference values for the conventional lstm models are listed in table s1 and fig s2 supplemental information indicating good performance of the trained lstm models mean nrmse 6 9 bias 0 008 r2 and nse 0 88 for the seven investigated sites to evaluate the performance of the used conventional lstm models for short and mid term eta forecasts based on meteorological variables and soil moisture the forecasts were compared to the reference eta measurements for the test sets for the seven investigated sites fig 4 forecast results for 1 3 7 and 30 days after a given date are presented because such timeframes are commonly used for hydrologic applications e g regonda et al 2013 sommerlot et al 2016 fig 5 indicates that the overall trends of the daily eta forecasts are consistent with the reference daily eta values this suggests that the conventional lstm models are capable of capturing the temporal patterns of the daily eta throughout the year for a wide range of climatic conditions land covers and soil types however the forecast performance decreases with increasing forecast time which is consistent with other studies e g li et al 2018 zhang et al 2018 the models performed slightly better for the 1 and 3 day forecasts than for the 7 and 30 day forecasts the average nrmse values for 1 3 7 and 30 days for the seven sites are 8 9 9 3 9 6 and 10 respectively this implies that the information gleaned from past events is significant for near future forecasts however the lstm models show limitations with regard to capturing successive daily fluctuations particularly during the warm seasons the deviations are larger which is most likely attributable to changing atmospheric conditions e g cloud cover the forecast performance significantly improves for all sites during colder months this may be explained by a decrease of the eta rate and only minor oscillations of ambient atmospheric conditions during the cold seasons the deviations during the warmer months of the year are more readily apparent when examining the monthly eta forecasts illustrated in fig s3 supplemental information a more accurate match might be attained when the training process is optimized via the use of multidecade datasets to further illustrate the agreement between the forecasted and observed eta values at each site throughout the test year i e 2016 scatter plots are depicted in fig 6 each scatterplot integrates short term 1 3 and 7 day and mid term 30 day forecasts the forecasts are close to the 1 1 line with an average r2 value of 0 88 this indicates that the conventional lstm models are capable of short and mid term forecasting of eta with good accuracy for a wide range of climatic conditions the strongest correlations r2 0 89 were obtained for the us nr1 us ne3 us arm and us los sites which are predominately located in cold regions fig 7 depicts the performance metrics for short and mid term eta forecasts indicating that the conventional lstm models yield a respectable level of accuracy for short and mid term forecasts for all investigated sites the 1 and 3 day forecasts followed by the 7 day forecasts closely match the reference eta measurements there are no significant differences between the 1 and 3 day forecasts i e mean nrmse1 day 0 087 and mean nrsme3 day 0 091 the mean nrsme7 day 0 095 which indicates that the conventional lstm models are slightly more robust on average for daily forecasts than for weekly forecasts the models perform inadequately for the 30 day eta forecasts with a mean nrsme30 day 0 101 and mean nse30 day 0 85 this confirms the findings in hu et al 2020 who report challenges with long term forecasts furthermore the lstm models slightly overestimate short term forecasts for cold climates with a mean bias of 0 020 mm d 1 i e us nr1 us los us ne3 while forecasts for hot climates i e us whs us ton us dpw have a slight positive bias of 0 062 mm d 1 which is consistent with the fitted regression lines shown in fig 6 that fall below the 1 1 line it is evident that the conventional lstm models in general work well with nse values between 0 77 and 0 95 and r2 values between 0 80 and 0 95 for most of the investigated sites fig 7 the lstm models performed slightly better for humid climatic conditions us los us ne3 and us arm for both short and mid term forecasts with mean nrmse and nse values of 0 094 and 0 88 respectively for dry climatic conditions nrmse values 0 096 are slightly higher and nse values 0 85 slightly lower reinforcing better model performance for colder climatic conditions the obtained results show the dependency of the lstm forecast performance on climate conditions with forecasting errors varying between climate zones in addition an increase in the forecast timeframe leads to a decrease in forecast accuracy for some of the investigated sites e g us whs the trend of declining forecast performance is substantially greater for 30 day forecasts this result is consistent with findings of yin et al 2020 who used a deep learning model for forecasting reference evapotranspiration and reported that the overall trend of the forecast performance decreases with increasing forecast lead time from 1 to 7 days when the forecast timeframe increases from 3 to 7 days the mean nrmse and bias values increase by approximately 3 and 103 respectively when the forecast timeframe increases from 7 to 30 days the mean nrmse and bias values increase by 6 and 109 respectively the results obtained in this study largely corroborate the findings of ferreira and cunha 2020 who reported reasonable accuracy mean rmse equal to 0 88 mm d 1 of various machine learning models for reference evapotranspiration forecasting for up to 7 days in brazil yin et al 2020 indicated the potential of lstm models for reference evapotranspiration forecasting with maximum and minimum air temperature and sunshine duration variables in a semiarid region in china they reported rmse and nse values of 0 16 mm d 1 and 0 98 for 1 day and 0 32 mm d 1 and 0 98 for 7 day lead times in the present study the lstm model performed comparably in a similar climate i e us whs with rmse values of 0 22 1 day timeframe and 0 24 mm d 1 7 day timeframes in general the uncertainty of model outputs can be attributed to two main factors including the uncertainty of the input variables and errors in model training in this study we focused on daily short and mid term forecasts it should be noted that for irrigation scheduling and water management in agriculture eta accumulated up to a particular day of the forecast timeframe is more useful than individual eta values while daily eta values are essential for modeling applications 3 1 2 forecast results with inclusion of soil and sensible heat flux data because sensible heat h and soil heat g fluxes are related to eta and net radiation via the surface energy balance their impact on the accuracy of the eta forecasts was evaluated fig 8 depicts the time series of short and mid term eta forecasts when soil heat flux and sensible heat flux data are added to the meteorological i e precipitation net radiation air temperature and wind speed and soil moisture input variables for the lstm models a close match between forecasted and reference eta values was observed for the test set data with average nrmse values of 0 095 0 101 0 103 and 0 106 for the 1 3 7 and 30 day forecasts respectively this suggests that the conventional lstm models are capable of accurately nowcasting and forecasting eta for various considered climatic conditions an evaluation of the impacts of adding soil heat and sensible heat flux variables to the model inputs is summarized in the box plot shown in fig 9 it is evident that inclusion of soil heat and sensible heat flux data does not improve short and mid term eta forecasts on the contrary the forecast accuracy seems to decline average nrmse reduction of 6 4 for all sites particularly for sites us nr1 us arm us los us ne3 that are located within cold climatic zones this is consistent with previous studies which have successfully estimated eta based on less than four meteorological variables patil and deka 2016 ferreira and da cunha 2020 other studies shiri 2018 tikhamarine et al 2019 utilized more than four meteorological input variables including minimum and maximum air temperature dew point temperature wind speed relative humidity and solar radiation to accurately estimate eta with machine learning this suggests that the site location and climate should be considered when selecting the best input variables for eta forecasting for example at low altitudes a combination of air temperature solar radiation and wind speed was sufficient to accurately estimate monthly eta whereas at high altitudes a combination of minimum and maximum air temperatures wind speed relative humidity and solar radiation yielded the best results malik et al 2019 we calculated the correlations between eta and the values of g h and net radiation rn the results summarized in fig s4 supplemental information indicate a strong correlation between eta and rn but only weak correlations between eta and h and g under various climates and land cover types this means that consideration of g and h as additional lstm model input variables does not necessarily improve the accuracy of eta forecasting in this study it was demonstrated that eta can be forecasted with good accuracy for a wide range of climatic conditions when precipitation solar radiation air temperature and wind speed are used together with soil moisture as input variables for lstm models that are trained with long eta time series it is also evident that soil moisture is an important input variable because plant water uptake from the root zone significantly impacts the eta rate while the soil and sensible heat fluxes are connected to eta through the energy balance they didn t improve the accuracy of eta forecasts 3 2 et a forecasts with convlstm based on modis observations fig 10 depicts examples for forecasted eta maps generated for the test set data with convlstm models for the walnut gulch tonzi ranch johnson creek and lost creek watersheds a comparison of the forecasted maps with the modis aqua net evapotranspiration product myd16a2 version 6 reveals similar spatial patterns for the investigated watersheds which indicates that the convlstm models well captured the spatial eta variability at the watershed scale the spatial eta variabilities mean standard deviation for the tonzi ranch johnson creek and lost creek watersheds which exhibit a wide range of climatic conditions and a mixture of land cover and vegetation types ma et al 2007 sulman et al 2009 are 5 7 2 1 mm d 1 14 1 2 8 mm d 1 and 21 9 5 8 mm d 1 respectively the walnut gulch watershed with arid climate and a uniform land cover that is mostly composed of shrubs and grasses skirvin et al 2008 shows a much narrower spatial eta distribution of 3 3 0 46 mmd 1 the spatiotemporal convlstm model performance is shown in fig 11 with the nrmse nse and bias for 7 day forecasts averaged across each watershed the nrmse and nse maps indicate that the univariate convlstm models perform well the watershed averaged nrmse and nse values range between 3 7 and 6 4 and 0 66 and 0 89 respectively which suggests consistency between the convlstm forecasts and reference eta values the convlstm model for walnut gulch performs slightly better with an average nrmse of 3 7 however the lower nrmse value can be also due to the narrower eta range fig 11 shows that for the tonzi ranch johnson creek and lost creek watersheds the nrmse values are higher i e 5 9 6 4 and 6 2 respectively the higher forecast uncertainty for the latter watersheds is attributable to the more heterogeneous land covers when compared to walnut gulch nevertheless the obtained results imply that convlstm is capable of effectively capturing spatiotemporal eta patterns for various climatic conditions and land covers and yields good forecasting accuracy when exclusively trained with long term modis eta data overall for 7 day forecasts the convlstm models generate slightly lower nrmse values when compared to the lstm models see figs 9 and 11 it is notable that the convlstm model for the lost creek watershed significantly under forecasted eta bias 0 24 mm d 1 which is consistent with the results obtained with the conventional lstm model for the same site fig 7 this is most likely due to the effect of environmental variation in the test set data that was not considered in the training set data fang et al 2017 a significant advantage of convlstm when compared to lstm is its ability to learn concurrently from vast and heterogeneous multi dimensional datasets such as provided by satellite remote sensing e g modis aqua net evapotranspiration products the results suggest that when historical modis eta products are integrated there is sufficient information to train a univariate convlstm to forecast weekly eta over a one year period when two decades of modis eta data are merged useful information on eta rate cycles can be derived which can be used to determine the required eta memory length however it is likely that anthropogenic induced changes have an effect on eta memory resulting in uncertainties in eta forecasts unlike the multivariate lstm the univariate convlstm is of great importance for regions where weather station observations are lacking real time lstm and convlstm based eta forecasts can improve hydrologic modeling and extreme climate event forecasting in view of a changing global climate past research has demonstrated that recent anomalies in precipitation evapotranspiration and soil moisture can be used to provide probabilistic forecasts of drought across the u s lorenz et al 2017 4 summary and conclusions in this study conventional lstm models for 1 3 7 and 30 day eta forecasts were evaluated for seven watersheds distributed across the continental united states with vastly different climatic conditions topologies land covers and soil types initially meteorological variables consisting of precipitation net radiation air temperature and wind speed were used together with soil moisture as input for the lstm models to examine if the inclusion of additional variables improves the forecast accuracy of the lstm models the soil heat flux and sensible heat flux two variables crucial for partitioning the incoming solar radiation were added to the initial input variable datasets in addition to the multivariate lstm models univariate convlstm models were developed for the walnut gulch tonzi ranch johnson creek and lost creek watersheds and trained and tested with the modis aqua net evapotranspiration product myd16a2 to forecast weekly eta the main conclusions are as follows 1 when major meteorological variables i e precipitation net radiation air temperature and wind speed were used as input information together with soil moisture the lstm models returned forecasts with good accuracy for all seven investigated sites even though there were no significant performance differences between the short and mid term forecasts the accuracy slightly decreased with increasing forecast timeframe 2 the addition of soil heat flux and sensible heat flux to the initially used input variables did not improve the accuracy of short and mid term lstm eta forecasts on the contrary a slight decrease of forecast accuracy was observed for the majority of the investigated sites 3 the convlstm models with univariate input data generated weekly spatiotemporal eta forecasts with good accuracy for the walnut gulch tonzi ranch johnson creek and lost creek watersheds the eta forecasting accuracy obtained with the convlstm models was slightly better than the accuracy of conventional lstm models for a wide range of climatic conditions 4 the developed deep learning models are capable of forecasting eta without specific ground observations and between eta satellite mission overpasses thereby can improve the temporal resolution of rs observations a unique component of this work was the application of the open source cloud computing environment provided by google colab where models can be quickly loaded retrained and modified when additional data becomes available the codes developed for this study are available upon request because the lstm and convlstm models were developed for a wide range of climatic conditions they can be efficiently applied for other regions of the world with the rapid advancement of physics informed and data driven machine learning approaches future work should focus on the assimilation of latent heat soil heat and sensible heat fluxes into a physically based surface energy balance model to simultaneously provide spatiotemporal forecasts of these variables for a variety of climates soil types and land covers as more accurate remotely sensed eta observations e g ecostress landsat 9 become available in future the developed lstm and convlstm models can be efficiently modified to nowcast and forecast eta in this study we used weekly long term modis satellite eta products to train a univariate convlstm model for eta forecasting previous studies e g liu et al 2022 have indicated that fusion of multiscale soil moisture observations i e in situ and remote sensing into deep learning models has the potential to increase the accuracy of smap soil moisture products the assessment of combining multiscale eta observations modis landsat and eddy covariance with deep learning models for long term spatiotemporal eta forecasts is part of ongoing research in this study we generated eta projections for up to 30 day lead times future research is necessary to understand how far into the future the lstm and convlstm models can forecast eta under different climatic conditions soil types and land covers in addition integration of lstm models with bayesian techniques may increase the accuracy of eta forecasts because the uncertainty associated with both input and model parameters can be assessed credit authorship contribution statement ebrahim babaeian conceptualization investigation methodology formal analysis writing original draft writing review editing funding acquisition sidike paheding conceptualization investigation methodology formal analysis writing review editing nahian siddique investigation methodology formal analysis writing review editing vijay k devabhaktuni conceptualization methodology writing review editing markus tuller conceptualization methodology formal analysis writing original draft writing review editing project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors gratefully acknowledge support from the united states department of agriculture usda national institute of food and agriculture nifa under grant 2020 67019 31028 and from the usda nifa hatch multi state project arzt 1370600 r21 189 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128078 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3185,evapotranspiration is a key component of the hydrologic cycle accurate short medium and long term forecasts of actual evapotranspiration eta are crucial not only for quantifying the impacts of climate change on the water and energy balance but also for real time estimation of crop water demand and irrigation water allocation in agriculture despite considerable advances in satellite remote sensing technology and the availability of long ground measured and remotely sensed eta timeseries real time eta forecasts are deficient applying a state of the art deep learning dl approach long short term memory lstm models were employed to nowcast real time and forecast ahead of time eta based on 1 major meteorological and ground measured i e soil moisture input variables and 2 long eta timeseries from the moderate resolution imaging spectroradiometer modis onboard of the nasa aqua satellite the conventional lstm and convolutional lstm convlstm dl models were evaluated for seven distinct climatic zones across the contiguous united states the employed lstm and convlstm models were trained and evaluated with data from the national climate assessment land data assimilation system nca ldas and with modis aqua net evapotranspiration myd16a2 product data the obtained results indicate that when major atmospheric and soil moisture input variables are used for the conventional lstm models they yield accurate daily eta forecasts for short 1 3 and 7 days and medium 30 days time scales with normalized root mean squared errors nrmse and nash sutcliffe efficiencies nse of less than 10 and greater than 0 77 respectively at the watershed scale the univariate convlstm models yielded accurate weekly spatiotemporal eta forecasts mean nrmse less than 6 4 and nse greater than 0 66 with higher computational efficiency for various climatic conditions the employed models enable precise forecasts of both the current and future states of eta which is crucial for understanding the impact of climate change on rapidly depleting water resources keywords evapotranspiration forecasting lstm convlstm climate change deep learning 1 introduction quantifying the response of the terrestrial biosphere to global climate change is a grand challenge in hydrologic sciences pan et al 2015 warming of the land and atmosphere alters weather patterns and all components of the water and energy cycles causing extreme weather events and associated natural disasters including floods droughts wildfires and landslides actual evapotranspiration eta is a critical component of the hydrologic cycle because it connects the water evaporation energy latent heat flux and carbon transpiration photosynthesis trade off cycles fisher et al 2017 the eta regulates the water and energy balance of the earth s biosphere hydrosphere and atmosphere especially in water limited ecosystems where it may account for nearly the entire surface water budget fisher et al 2017 oki and kanae 2006 morillas et al 2013 in general eta is determined based on either the water balance or the energy balance provided that all remaining components are known techniques such as the penman monteith method allen 1996 are frequently applied to estimate potential evapotranspiration because of the large number of required meteorological input variables it is challenging to apply such methods in data scarce regions remote sensing rs observations in conjunction with meteorological variables are used as inputs for surface energy balance seb methods for eta estimation methods such as the surface energy balance algorithm for land sebal bastiaanssen et al 1998 the mapping evapotranspiration at high resolution with internalized calibration metric allen et al 2015 and atmosphere land exchange inverse alexi disalexi models norman et al 2003 anderson et al 2004 have been widely applied for large scale mapping of eta based on the combined application of optical and thermal rs observations the earth engine evapotranspiration flux eeflux that integrates the metric algorithm into the google earth engine for processing of landsat satellite images 30 m 16 days offers means for automated long term and large scale eta mapping allen et al 2015 the priestley taylor jet propulsion laboratory pt jpl fisher et al 2008 method a simplified form of the penman monteith equation monteith 1965 provides another option for eta estimation from rs data nasa recently launched the ecostress satellite to estimate eta based on the pt jpl algorithm with spatial and temporal resolutions of 70 m and 3 5 days respectively fisher 2018 2020 two source energy balance tseb models a subcategory of the seb models consider the soil and plant canopy as distinct eta sources norman et al 1995 french et al 2015 andreu et al 2018 the eddy covariance ec method a widely applied ground based energy balance approach is frequently employed for the validation of satellite eta estimates the ec method is also applied at the u s critical zone observatory czo sites as well as at the fluxnet and ameriflux sites baldocchi et al 2001 fisher et al 2007 incorporation of remotely sensed soil moisture data in the pt jpl model has improved eta estimation as shown in purdy et al 2018 which indicates an obvious link between soil moisture and vegetation cover adegoke et al 2002 the fundamental constraint of the aforementioned eta measurement methods is that they provide historical and near real time observations yet many eta applications would benefit from real time data at diurnal resolution which is lacking to date another issue is that cloud induced signal disturbance results in temporal gaps and unequal revisit durations for satellite sensors restricting real time monitoring of eta at large scales quantifying the future states of eta is not only crucial for determining crop water requirements for accurate water allotment planning and for real time irrigation scheduling but also for understanding the water cycle s vulnerability to climate change historically most of the hydrologic forecasting has been focused on the supply side of the water cycle i e precipitation and streamflow nguyen et al 2015 kidd et al 2013 crow et al 2017 largely ignoring demand i e evapotranspiration significant progress in satellite rs and the availability of long term eta observations combined with advances in state of the art data driven approaches for modeling spatiotemporal eta patterns present an unprecedented opportunity for understanding the effect of climate change on the future state of the demand side of the hydrologic cycle this can be accomplished by developing advanced models for short mid and long term forecasting of eta for a range of land surface and climatic conditions recent innovations in the field of machine learning ml offer an exciting opportunity for developing data driven models of physical processes ball et al 2017 lary et al 2016 the application of ml to estimate biophysical parameters from rs observations has shown remarkable results reichstein et al 2019 among the various ml methods deep learning dl has already made a significant impact for weather and hydrologic applications shen et al 2018 moghadam et al 2021 li et al 2022 liu et al 2022 and showed superior performance when compared to traditional ml methods reichstein et al 2019 alom et al 2019 fang et al 2019 the primary advantage of dl is its capacity to discover complicated relationships automatically and effectively and to hierarchically extract spatiotemporal features from raw data deep learning approaches are commonly classified as supervised utilizes labeled data semi supervised uses partially labeled data or unsupervised the most widely used deep learning techniques are supervised methods which include variants of deep neural networks hinton et al 2012 convolutional neural networks cnn fukushima 1988 lecun et al 1998 recurrent neural networks rnn cho et al 2014 rodriguez et al 1999 and long short term memory lstm methods hochreiter and schmidhuber 1997 gers et al 2000 the cnns are capable of learning spatial links whereas rnns are capable of learning temporal patterns the rnns can be employed for forecasting the current and future states of a system based on historical events the lstm method has been developed to learn both short and long term dependencies between time steps of sequential data providing a powerful tool for accurately estimating the present real time and future forecasting state of a system based on past occurrences the use of lstm is particularly advantageous for eta nowcasting and forecasting in situations where nonlinear spatiotemporal dynamics exist and conventional ml methods are unable to address such complicated relationships the convolutional lstm convlstm method is a variant of the lstm that incorporates cnn it is well suited for spatial sequence data such as time series of rs observations xingjian et al 2015 kreuzer et al 2020 recent research has demonstrated the success of dl for extracting spatial information from weather forecast model outputs to detect and classify extreme weather events i e storms and hurricanes liu et al 2016 and 2020 racah et al 2016 other studies have successfully applied dl models for weather and climate forecasting scher 2018 mapping flood susceptibility bui et al 2020 forecasting wind speed liu et al 2019 peng et al 2020 forecasting streamflow liu et al 2020 fu et al 2020 forecasting drought mehr et al 2022 and for estimation of evaporation malik et al 2022 koppa et al 2022 several recent investigations have employed lstm to specifically forecast streamflow hu et al 2020 kratzert et al 2018 kratzert et al 2019 le et al 2019 however it is currently not known whether lstm models can accurately nowcast i e present state and forecast i e future state eta motivated by the importance of eta forecasts availability of long term ground and rs observations and the success of state of the art dl methods for weather and hydrologic modeling and forecasting the objectives of this paper are i to assess the feasibility of conventional lstm applied in conjunction with ground and meteorological observations to accurately forecast short and mid term eta ii to investigate the capability of convlstm with univariate input data to forecast eta based on modis eta observations and iii to demonstrate the effectiveness of lstm and convlstm models for forecasting eta for a variety of climatic conditions in the contiguous united states conus 2 methods and datasets a multivariate conventional lstm network was trained for short and medium range forecasting of eta based on the time series of meteorological and soil variables that were extracted from the national climate assessment land data assimilation system nca ldas for seven locations with vastly different climates and land covers distributed across the conus in addition a watershed scale convlstm network to forecast eta on a weekly time scale based on the modis aqua net evapotranspiration myd16a2 version 6 product was trained both datasets were split into training and test sets with the latter applied to evaluate the performance of the lstm and convlstm forecasts in this study short term refers to lead times of 1 3 and 7 days and mid term to 30 days these timescales have been utilized extensively in hydrologic forecasting e g velazquez et al 2009 regonda et al 2013 sommerlot et al 2016 kim et al 2018 2 1 conventional and convolutional long short term memory networks long short term memory lstm is a particular case of a recurrent neural network rnn model which learns from sequential data previous time steps and forecasts the present and future states of a system hochreiter and schmidhuber 1997 the lstm network consists of layers of memory that contain units referred to as cell states and gates each memory unit contains three gates forget input and output the forget gate controls the information from the previous state that will no longer be stored the input gate specifies the input features that will be stored in the next state and the output gate specifies the information from the new state that will be output the memory cell facilitates the lstm to extract long term dependencies necessary for eta forecasting fig 1 a illustrates the internal structure of a lstm cell following fig 1a the three gates of the lstm network are given as 1 z t t a n h w xz x t w hz h t 1 b z i n p u t n o d e 2 f t σ w fx x t w fh h t 1 w fc c t 1 b f f o r g e t g a t e 3 i t σ w ix x t w ih h t 1 w ic c t 1 b i i n p u t g a t e 4 o t σ w xo x t w ho h t 1 w co c t b o o u t p u t g a t e where xt is the current input for time step t h t 1 is the previous output c is the cell state for time step t long term dependency ht is the hidden state that is the input of the next time step considered as a short term state for four fully connected neurons ft zt it and ot the σ represents the classical sigmoid activation function for the gate units w represents the network weights b is the bias and tanh represents the nonlinear activation function of the cell gate units the c and h are obtained from 5 c t i t z t f t c t 1 c e l l s t a t e 6 h t o t t a n h c t h i d d e n g a t e 7 y t w hy h t b y o u t p u t l a y e r where is the multiplication operation for two vectors at each time step the network outputs a value yt which is compared to the reference eta data y t for the entire time period t the loss function γ t to be minimized is the mean squared error calculated for the time series 8 γ t 1 t t 1 t y t y t 2 in addition a hybrid dl model termed convolutional lstm convlstm which combines cnn and lstm was evaluated convlstm is a special type of lstm layer developed for spatiotemporal forecasts from 2d data e g time series of modis aqua net evapotranspiration shi et al 2015 in this model the future state of a specific cell in the grid is determined by the inputs and past states of its local neighbors this is achieved with a convolution operator in the state to state and input to state transitions the internal structure of a convlstm memory cell and the operating mechanism is depicted in fig 1b equations 9 to 14 represent the architecture of the convlstm and detailed algorithms of the components of the memory cell 9 z t t a n h w xz x t w hz h t 1 b z i n p u t n o d e 10 f t σ w fx x t w fh h t 1 w fc c t 1 b f f o r g e t g a t e 11 i t σ w ix x t w ih h t 1 w ic c t 1 b i i n p u t g a t e 12 o t σ w xo x t w ho h t 1 w co c t b o o u t p u t g a t e 13 c t i t z t f t c t 1 c e l l s t a t e 14 h t o t t a n h c t h i d d e n g a t e 2 2 architecture of the employed deep neural networks two distinct sets of data were used for training and evaluation the initial set used to train and evaluate the standard lstm models consisted of meteorological and ground data extracted from the national climate assessment land data assimilation system nca ldas for the seven selected sites for sixteen years 2001 to 2016 fig 2 depicts the concept of splitting dataset into training testing and forecasting sets for the standard lstm model as shown the lstm models were trained with a long sequence of data to forecast eta for the most recent year where the focus was on 1 3 7 and 30 day lead times for example to forecast eta for the day n 1 1 day lead time the model is fed with the values from the previous n days the forecasted eta value for day n 1 is combined with the previous n days to generate the forecast for day n 2 and so forth the frame window s latency was set to 100 frames the batch size was 16 and training was conducted with an adaptive learning rate of up to 300 epochs the network was composed of two 500 unit thick lstm layers and a final dense layer each lstm layer was assigned a 10 dropout to avoid overfitting the learning rate indicates the network s learning efficiency the batch size indicates the number of samples in each batch the dropout designates the proportion of layer nodes that are randomly turned off and epochs specifies the number of iterations required to obtain the optimal model the architecture of the lstm network employed in this study is depicted in fig 3 a the second dataset consisted of the modis aqua net evapotranspiration myd16a2 version 6 product a univariate convlstm was employed to integrate convolutional and recurrent operations for spatiotemporal forecasting of eta using long term data from the myd16a2 product univariate convlstm was employed because of its availability to learn long term patterns of a single variable i e eta to predict the current and future state from past conditions this approach has been widely applied for sentence completion when a partial sentence is provided as input to predict the next word and when the new word is known it is appended to the input sentence to predict the next word univariate convlstm is of great interest in data scarce regions where data from weather stations is lacking the convlstm was evaluated for four watersheds with differing climates land covers and soil types more than 800 sequential modis aqua eta observations were collected at 8 day interval for each watershed from 2001 to 2019 each sample had a 23 frame lag or frame window the batch size was sixteen and the training period was 200 epochs the convlstm architecture employed in this study is depicted in fig 3b the output of one convlstm layer serves as the input for the subsequent layer in the deep architecture numerous tests were conducted with up to five convlstm layers and the optimal design was chosen the final network is composed of four layers each of which has fifty filters with a size of 3 3 and a stride size of 1 fig 3b because neural networks have a large number of parameters they are prone to overfitting to avoid overfitting a 10 dropout throughout the network was implemented the consideration of dropouts is an effective strategy for reducing overfitting in neural networks srivastava et al 2014 each convlstm layer s forward output was transferred to a batch normalization unit to accelerate the learning process and to alleviate internal covariate shift ioffe and szegedy 2015 to remove the effect of scale disparity and avoid obstacles with convergence during training all input and output variables were rescaled using min max normalization the lstm and convlstm models were implemented in python using the tensorflow abadi et al 2016 implementation of keras an open source machine learning platform keras io the models were executed on a tesla k80 gpu accessed via google colab a sequence to sequence forecasting approach was employed to forecast subsequent steps based on the previous forecasts this strategy is particularly advantageous for short and mid term forecasts as the input variables only need to be accessible until the forecast commences 2 3 study sites the seven selected sites are part of the ameriflux network ameriflux lbl gov and represent different climate zones across the conus which are classified based on the international energy conservation code iecc and the american society of heating refrigerating and air conditioning engineers ashrae scheme and exhibit a wide range of eta dynamics fig 4 depicts an overview of the selected sites together with the frequency distributions of daily eta see also table 1 the walnut gulch lucky hills site us whs in southeastern arizona was established by the united states department of agriculture usda in 1953 the elevation varies between 1252 and 1718 m with a topography ranging from extremely steep slopes 50 to nearly flat concave basin floors the site is located within the hot dry climate zone and exhibits a mean annual temperature of 17 7 c and mean precipitation of 350 mm about two thirds of the precipitation typically falls during the monsoon season from july to september the evapotranspiration might be nearly ten times higher than the annual precipitation the site is predominantly covered by desert shrublands two thirds and desert grasses one third with soils consisting primarily of sandy loam and gravelly loam with little organic matter content the site has frequently been used as a core validation site for soil moisture estimates obtained from satellite rs missions for detailed information about the us whs site readers are referred to skirvin et al 2008 the tonzi ranch us ton site is located in the sierra nevada foothills in north central california the climate is characterized by wet and mild winters and dry and hot summers with a mean annual temperature of 15 8 c a mean precipitation of 560 mm and a mean evapotranspiration of 539 mm the major soil texture is sandy clay loam with low organic matter content the vegetation is dominated by oak grass savanna mixed forests grasslands and shrublands the mean elevation is between 129 and 177 m detailed information about the site is provided in ma et al 2007 the johnson creek us ne3 site is located in eastern nebraska at an elevation of 363 m the climate is cold with an average annual temperature of 10 1 c and an average annual precipitation of 784 mm the site is situated on cropland and mainly covered with temporary crops i e rainfed soybeans and maize after harvest soils remain bare with no till management the lost creek us los site is located in north central wisconsin at an elevation of about 480 m the land cover consists of shrub wetland coniferous forest and grassland sulman et al 2009 the climate is extremely cold with an average annual temperature of 4 0 c and an average annual precipitation of 828 mm that is evenly distributed throughout the year the disney wilderness preserve us dwp site which is located within the hot humid climate zone in south central florida between polk and osceola counties near the headwaters of the everglades ecosystem is a patchwork of forests grasslands and wetland habitats the mean annual temperature is 22 5 c and the mean annual precipitation is 1216 mm the majority of precipitation falls in summer and is associated with tropical storms the low site elevation that ranges from 13 and 21 m causes susceptibility to flooding fine sand is the prevalent soil texture in the region the southern great plains us arm site is located in northern oklahoma within the mixed humid climate zone that is characterized by moderate winters and hot summers annual mean temperature and precipitation are 14 8 c and 890 mm respectively while winter wheat and canola are commonly grown in fall and winter corn sorghum cowpeas barley and soybeans are the typical crops in spring and summer the soils are well drained silt loams silty clay loams or clay loams the niwot ridge us nr1 site located in the colorado rocky mountains is a subalpine forest ecosystem dominated by subalpine fir abies lasiocarpa engelmann spruce picea engelmannii and lodgepole pine pinus contorta with an average canopy height of 11 4 m the mean elevation is 3050 m with gentle slopes 6 7 running from west to east the climate is very cold with an annual mean temperature of 4 0 c and an annual precipitation of about 800 mm with approximately 65 falling as snow monson et al 2002 2005 turnipseed et al 2002 2003 2 4 datasets the point scale ground measured and meteorological variables for the seven selected sites fig 4 were obtained from the national climate assessment land data assimilation system nca ldas ldas gsfc nasa gov nca ldas the nca ldas is an integrated terrestrial water analysis database established by the nasa goddard space flight center hydrological sciences laboratory that integrates in situ and remote sensing observations as well as model estimations to provide high quality analyses and a publicly accessible data for sustained climate assessment in the conus jasinski et al 2019 when compared to land surface models the current nca ldas products proved to be superior for soil moisture snow depth precipitation and evapotranspiration kumar et al 2019 for detailed information about the nca ldas database readers are referred to jasinski et al 2019 and kumar et al 2019 table 2 lists the minimum maximum and mean values of the utilized ground measured and meteorological variables including precipitation net radiation air temperature wind speed soil moisture latent heat flux i e eta sensible heat flux and soil heat flux that were calculated from daily values collected from 2001 to 2016 the five major lstm model inputs for forecasting eta were precipitation net radiation air temperature wind speed and soil moisture soil moisture was used as a proxy for the effect of vegetation cover on eta because it controls root water uptake and transpiration rates the link between soil moisture and vegetation cover has been extensively studied and documented in literature e g adegoke et al 2002 yang et al 2018 the benefit of including soil moisture to improve eta estimations was previously demonstrated by purdy et al 2018 to evaluate their impact on the accuracy of the eta forecasts the soil heat flux and the sensible heat flux were considered as additional input variables fifteen years of data 2001 to 2015 were used for lstm model training and one year 2016 for testing to investigate the eta forecasting capability of the convlstm networks the modis aqua net evapotranspiration product myd16a2 version 6 with 8 day temporal resolution and 500 m spatial resolution was utilized and tested for the walnut gulch us whs tonzi ranch us ton johnson creek us ne3 and lost creek us los watersheds the selected watersheds encompass a broad spectrum of land covers and climate conditions the publicly available myd16a2 product lpdaac usgs gov products myd16a2v006 is based on the penman monteith equation allen 1996 and incorporates daily meteorological data as well as modis vegetation dynamics albedo and land cover observations more than 800 sequential myd16a2 product data were extracted for each watershed from 2001 to 2019 the dataset was divided into a 18 year training set and a one year 2019 test set the ratio was chosen to ensure that the test set contained one full year of data 2 5 model performance metrics to evaluate the performance of the lstm and convlstm models four metrics including the normalized root mean squared error nrmse the bias the coefficient of determination r2 and the nash sutcliffe efficiency nse were selected and calculated as 15 nrmse rmse o max o min 1 n i 1 n f i o i 2 o max o min 16 bias 1 n i 1 n o i f i 17 r 2 i 1 n f i f mean 2 i 1 n o i o mean 2 18 nse 1 i 1 n o i f i 2 i 1 n o i o mean 2 where n is the number of forecasted and reference eta pairs o i and f i are the i th observed and nowcasted forecasted values o min and o max denote the observed minimum and maximum values o mean and f mean denote the mean observed and nowcasted forecasted eta data respectively a nse value of 1 signifies a perfect match between forecasted and observed values the bias was calculated to determine over and under forecasting of the models the nrmse is defined as the rmse divided by the range of ground truth values with a perfect value of zero it should be mentioned that while the rmse is beneficial for comparing the performances of different models for a specific time series nrmse is better suited for comparing model performance across different time series additionally it has been pointed out that the nrmse metric can be used to better determine the performance of hydrologic variables legates and mccabe 1999 3 results and discussion a total of 11 dl models seven of which are multivariate conventional lstm models and four are univariate convlstm models were employed and validated as discussed in sections 2 1 and 2 2 the lstm models were constructed with point scale timeseries of ground measured and meteorological variables from nca ldas whereas the convlstm models were constructed with spatiotemporal eta observations from the modis aqua satellite for the conventional lstm models two levels of input data were utilized and evaluated the first level comprised of soil moisture precipitation net radiation air temperature and wind speed while the second dataset additionally included the sensible heat and soil heat fluxes 3 1 lstm eta forecasts 3 1 1 forecasts based on ground measured and meteorological variables the time series of short 1 3 and 7 days ahead and mid term 30 days ahead daily eta forecasts along with the reference daily eta values for the training set for each of the seven sites are depicted in fig s1 supplemental information a good match is observed between forecasted and reference eta values suggesting that the conventional lstm models successfully capture temporal dynamics of eta hence are capable to nowcast and forecast eta for a wide range of climate conditions the calculated nrmse bias nse and r2 values between forecasted and reference values for the conventional lstm models are listed in table s1 and fig s2 supplemental information indicating good performance of the trained lstm models mean nrmse 6 9 bias 0 008 r2 and nse 0 88 for the seven investigated sites to evaluate the performance of the used conventional lstm models for short and mid term eta forecasts based on meteorological variables and soil moisture the forecasts were compared to the reference eta measurements for the test sets for the seven investigated sites fig 4 forecast results for 1 3 7 and 30 days after a given date are presented because such timeframes are commonly used for hydrologic applications e g regonda et al 2013 sommerlot et al 2016 fig 5 indicates that the overall trends of the daily eta forecasts are consistent with the reference daily eta values this suggests that the conventional lstm models are capable of capturing the temporal patterns of the daily eta throughout the year for a wide range of climatic conditions land covers and soil types however the forecast performance decreases with increasing forecast time which is consistent with other studies e g li et al 2018 zhang et al 2018 the models performed slightly better for the 1 and 3 day forecasts than for the 7 and 30 day forecasts the average nrmse values for 1 3 7 and 30 days for the seven sites are 8 9 9 3 9 6 and 10 respectively this implies that the information gleaned from past events is significant for near future forecasts however the lstm models show limitations with regard to capturing successive daily fluctuations particularly during the warm seasons the deviations are larger which is most likely attributable to changing atmospheric conditions e g cloud cover the forecast performance significantly improves for all sites during colder months this may be explained by a decrease of the eta rate and only minor oscillations of ambient atmospheric conditions during the cold seasons the deviations during the warmer months of the year are more readily apparent when examining the monthly eta forecasts illustrated in fig s3 supplemental information a more accurate match might be attained when the training process is optimized via the use of multidecade datasets to further illustrate the agreement between the forecasted and observed eta values at each site throughout the test year i e 2016 scatter plots are depicted in fig 6 each scatterplot integrates short term 1 3 and 7 day and mid term 30 day forecasts the forecasts are close to the 1 1 line with an average r2 value of 0 88 this indicates that the conventional lstm models are capable of short and mid term forecasting of eta with good accuracy for a wide range of climatic conditions the strongest correlations r2 0 89 were obtained for the us nr1 us ne3 us arm and us los sites which are predominately located in cold regions fig 7 depicts the performance metrics for short and mid term eta forecasts indicating that the conventional lstm models yield a respectable level of accuracy for short and mid term forecasts for all investigated sites the 1 and 3 day forecasts followed by the 7 day forecasts closely match the reference eta measurements there are no significant differences between the 1 and 3 day forecasts i e mean nrmse1 day 0 087 and mean nrsme3 day 0 091 the mean nrsme7 day 0 095 which indicates that the conventional lstm models are slightly more robust on average for daily forecasts than for weekly forecasts the models perform inadequately for the 30 day eta forecasts with a mean nrsme30 day 0 101 and mean nse30 day 0 85 this confirms the findings in hu et al 2020 who report challenges with long term forecasts furthermore the lstm models slightly overestimate short term forecasts for cold climates with a mean bias of 0 020 mm d 1 i e us nr1 us los us ne3 while forecasts for hot climates i e us whs us ton us dpw have a slight positive bias of 0 062 mm d 1 which is consistent with the fitted regression lines shown in fig 6 that fall below the 1 1 line it is evident that the conventional lstm models in general work well with nse values between 0 77 and 0 95 and r2 values between 0 80 and 0 95 for most of the investigated sites fig 7 the lstm models performed slightly better for humid climatic conditions us los us ne3 and us arm for both short and mid term forecasts with mean nrmse and nse values of 0 094 and 0 88 respectively for dry climatic conditions nrmse values 0 096 are slightly higher and nse values 0 85 slightly lower reinforcing better model performance for colder climatic conditions the obtained results show the dependency of the lstm forecast performance on climate conditions with forecasting errors varying between climate zones in addition an increase in the forecast timeframe leads to a decrease in forecast accuracy for some of the investigated sites e g us whs the trend of declining forecast performance is substantially greater for 30 day forecasts this result is consistent with findings of yin et al 2020 who used a deep learning model for forecasting reference evapotranspiration and reported that the overall trend of the forecast performance decreases with increasing forecast lead time from 1 to 7 days when the forecast timeframe increases from 3 to 7 days the mean nrmse and bias values increase by approximately 3 and 103 respectively when the forecast timeframe increases from 7 to 30 days the mean nrmse and bias values increase by 6 and 109 respectively the results obtained in this study largely corroborate the findings of ferreira and cunha 2020 who reported reasonable accuracy mean rmse equal to 0 88 mm d 1 of various machine learning models for reference evapotranspiration forecasting for up to 7 days in brazil yin et al 2020 indicated the potential of lstm models for reference evapotranspiration forecasting with maximum and minimum air temperature and sunshine duration variables in a semiarid region in china they reported rmse and nse values of 0 16 mm d 1 and 0 98 for 1 day and 0 32 mm d 1 and 0 98 for 7 day lead times in the present study the lstm model performed comparably in a similar climate i e us whs with rmse values of 0 22 1 day timeframe and 0 24 mm d 1 7 day timeframes in general the uncertainty of model outputs can be attributed to two main factors including the uncertainty of the input variables and errors in model training in this study we focused on daily short and mid term forecasts it should be noted that for irrigation scheduling and water management in agriculture eta accumulated up to a particular day of the forecast timeframe is more useful than individual eta values while daily eta values are essential for modeling applications 3 1 2 forecast results with inclusion of soil and sensible heat flux data because sensible heat h and soil heat g fluxes are related to eta and net radiation via the surface energy balance their impact on the accuracy of the eta forecasts was evaluated fig 8 depicts the time series of short and mid term eta forecasts when soil heat flux and sensible heat flux data are added to the meteorological i e precipitation net radiation air temperature and wind speed and soil moisture input variables for the lstm models a close match between forecasted and reference eta values was observed for the test set data with average nrmse values of 0 095 0 101 0 103 and 0 106 for the 1 3 7 and 30 day forecasts respectively this suggests that the conventional lstm models are capable of accurately nowcasting and forecasting eta for various considered climatic conditions an evaluation of the impacts of adding soil heat and sensible heat flux variables to the model inputs is summarized in the box plot shown in fig 9 it is evident that inclusion of soil heat and sensible heat flux data does not improve short and mid term eta forecasts on the contrary the forecast accuracy seems to decline average nrmse reduction of 6 4 for all sites particularly for sites us nr1 us arm us los us ne3 that are located within cold climatic zones this is consistent with previous studies which have successfully estimated eta based on less than four meteorological variables patil and deka 2016 ferreira and da cunha 2020 other studies shiri 2018 tikhamarine et al 2019 utilized more than four meteorological input variables including minimum and maximum air temperature dew point temperature wind speed relative humidity and solar radiation to accurately estimate eta with machine learning this suggests that the site location and climate should be considered when selecting the best input variables for eta forecasting for example at low altitudes a combination of air temperature solar radiation and wind speed was sufficient to accurately estimate monthly eta whereas at high altitudes a combination of minimum and maximum air temperatures wind speed relative humidity and solar radiation yielded the best results malik et al 2019 we calculated the correlations between eta and the values of g h and net radiation rn the results summarized in fig s4 supplemental information indicate a strong correlation between eta and rn but only weak correlations between eta and h and g under various climates and land cover types this means that consideration of g and h as additional lstm model input variables does not necessarily improve the accuracy of eta forecasting in this study it was demonstrated that eta can be forecasted with good accuracy for a wide range of climatic conditions when precipitation solar radiation air temperature and wind speed are used together with soil moisture as input variables for lstm models that are trained with long eta time series it is also evident that soil moisture is an important input variable because plant water uptake from the root zone significantly impacts the eta rate while the soil and sensible heat fluxes are connected to eta through the energy balance they didn t improve the accuracy of eta forecasts 3 2 et a forecasts with convlstm based on modis observations fig 10 depicts examples for forecasted eta maps generated for the test set data with convlstm models for the walnut gulch tonzi ranch johnson creek and lost creek watersheds a comparison of the forecasted maps with the modis aqua net evapotranspiration product myd16a2 version 6 reveals similar spatial patterns for the investigated watersheds which indicates that the convlstm models well captured the spatial eta variability at the watershed scale the spatial eta variabilities mean standard deviation for the tonzi ranch johnson creek and lost creek watersheds which exhibit a wide range of climatic conditions and a mixture of land cover and vegetation types ma et al 2007 sulman et al 2009 are 5 7 2 1 mm d 1 14 1 2 8 mm d 1 and 21 9 5 8 mm d 1 respectively the walnut gulch watershed with arid climate and a uniform land cover that is mostly composed of shrubs and grasses skirvin et al 2008 shows a much narrower spatial eta distribution of 3 3 0 46 mmd 1 the spatiotemporal convlstm model performance is shown in fig 11 with the nrmse nse and bias for 7 day forecasts averaged across each watershed the nrmse and nse maps indicate that the univariate convlstm models perform well the watershed averaged nrmse and nse values range between 3 7 and 6 4 and 0 66 and 0 89 respectively which suggests consistency between the convlstm forecasts and reference eta values the convlstm model for walnut gulch performs slightly better with an average nrmse of 3 7 however the lower nrmse value can be also due to the narrower eta range fig 11 shows that for the tonzi ranch johnson creek and lost creek watersheds the nrmse values are higher i e 5 9 6 4 and 6 2 respectively the higher forecast uncertainty for the latter watersheds is attributable to the more heterogeneous land covers when compared to walnut gulch nevertheless the obtained results imply that convlstm is capable of effectively capturing spatiotemporal eta patterns for various climatic conditions and land covers and yields good forecasting accuracy when exclusively trained with long term modis eta data overall for 7 day forecasts the convlstm models generate slightly lower nrmse values when compared to the lstm models see figs 9 and 11 it is notable that the convlstm model for the lost creek watershed significantly under forecasted eta bias 0 24 mm d 1 which is consistent with the results obtained with the conventional lstm model for the same site fig 7 this is most likely due to the effect of environmental variation in the test set data that was not considered in the training set data fang et al 2017 a significant advantage of convlstm when compared to lstm is its ability to learn concurrently from vast and heterogeneous multi dimensional datasets such as provided by satellite remote sensing e g modis aqua net evapotranspiration products the results suggest that when historical modis eta products are integrated there is sufficient information to train a univariate convlstm to forecast weekly eta over a one year period when two decades of modis eta data are merged useful information on eta rate cycles can be derived which can be used to determine the required eta memory length however it is likely that anthropogenic induced changes have an effect on eta memory resulting in uncertainties in eta forecasts unlike the multivariate lstm the univariate convlstm is of great importance for regions where weather station observations are lacking real time lstm and convlstm based eta forecasts can improve hydrologic modeling and extreme climate event forecasting in view of a changing global climate past research has demonstrated that recent anomalies in precipitation evapotranspiration and soil moisture can be used to provide probabilistic forecasts of drought across the u s lorenz et al 2017 4 summary and conclusions in this study conventional lstm models for 1 3 7 and 30 day eta forecasts were evaluated for seven watersheds distributed across the continental united states with vastly different climatic conditions topologies land covers and soil types initially meteorological variables consisting of precipitation net radiation air temperature and wind speed were used together with soil moisture as input for the lstm models to examine if the inclusion of additional variables improves the forecast accuracy of the lstm models the soil heat flux and sensible heat flux two variables crucial for partitioning the incoming solar radiation were added to the initial input variable datasets in addition to the multivariate lstm models univariate convlstm models were developed for the walnut gulch tonzi ranch johnson creek and lost creek watersheds and trained and tested with the modis aqua net evapotranspiration product myd16a2 to forecast weekly eta the main conclusions are as follows 1 when major meteorological variables i e precipitation net radiation air temperature and wind speed were used as input information together with soil moisture the lstm models returned forecasts with good accuracy for all seven investigated sites even though there were no significant performance differences between the short and mid term forecasts the accuracy slightly decreased with increasing forecast timeframe 2 the addition of soil heat flux and sensible heat flux to the initially used input variables did not improve the accuracy of short and mid term lstm eta forecasts on the contrary a slight decrease of forecast accuracy was observed for the majority of the investigated sites 3 the convlstm models with univariate input data generated weekly spatiotemporal eta forecasts with good accuracy for the walnut gulch tonzi ranch johnson creek and lost creek watersheds the eta forecasting accuracy obtained with the convlstm models was slightly better than the accuracy of conventional lstm models for a wide range of climatic conditions 4 the developed deep learning models are capable of forecasting eta without specific ground observations and between eta satellite mission overpasses thereby can improve the temporal resolution of rs observations a unique component of this work was the application of the open source cloud computing environment provided by google colab where models can be quickly loaded retrained and modified when additional data becomes available the codes developed for this study are available upon request because the lstm and convlstm models were developed for a wide range of climatic conditions they can be efficiently applied for other regions of the world with the rapid advancement of physics informed and data driven machine learning approaches future work should focus on the assimilation of latent heat soil heat and sensible heat fluxes into a physically based surface energy balance model to simultaneously provide spatiotemporal forecasts of these variables for a variety of climates soil types and land covers as more accurate remotely sensed eta observations e g ecostress landsat 9 become available in future the developed lstm and convlstm models can be efficiently modified to nowcast and forecast eta in this study we used weekly long term modis satellite eta products to train a univariate convlstm model for eta forecasting previous studies e g liu et al 2022 have indicated that fusion of multiscale soil moisture observations i e in situ and remote sensing into deep learning models has the potential to increase the accuracy of smap soil moisture products the assessment of combining multiscale eta observations modis landsat and eddy covariance with deep learning models for long term spatiotemporal eta forecasts is part of ongoing research in this study we generated eta projections for up to 30 day lead times future research is necessary to understand how far into the future the lstm and convlstm models can forecast eta under different climatic conditions soil types and land covers in addition integration of lstm models with bayesian techniques may increase the accuracy of eta forecasts because the uncertainty associated with both input and model parameters can be assessed credit authorship contribution statement ebrahim babaeian conceptualization investigation methodology formal analysis writing original draft writing review editing funding acquisition sidike paheding conceptualization investigation methodology formal analysis writing review editing nahian siddique investigation methodology formal analysis writing review editing vijay k devabhaktuni conceptualization methodology writing review editing markus tuller conceptualization methodology formal analysis writing original draft writing review editing project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors gratefully acknowledge support from the united states department of agriculture usda national institute of food and agriculture nifa under grant 2020 67019 31028 and from the usda nifa hatch multi state project arzt 1370600 r21 189 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128078 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3186,although carbon flux monitoring has been studied extensively in terrestrial ecosystems around the world water vapor flux based on eddy covariance has received little attention as a special type of terrestrial ecosystem wetlands are transitions between land and water material and energy and therefore of great significance in times of global change in wetlands water vapor flux has a significant impact on micrometeorological environments making it the main conduit for water vapor exchange between the wetland and the atmosphere using an eddy covariance tower we measured water vapor flux h2o over four years at the riganqiao fen in the zoige peatlands on the eastern qinghai tibetan plateau china diurnal h2o peaks occurred around 14 00 and annual mean diurnal rate mmol m 2 s 1 was 0 77 0 02 1 2 0 02 0 85 0 02 and 0 93 0 02 respectively over the 4 years daily h2o flux rate was substantially higher between june and august with peak values of 8836 g m 2 d 1 on doy day of year 161 in 2013 the riganqiao peatland was a net water source with an emission average of 429 3 51 5 kg m 2 yr 1 hydrological and temperature were crucial to seasonal variation in water vapor fluxes in both growing and non growing seasons especially the latent heat flux le however interannual water vapor flux and relative humidity rh were significantly positively correlated to water vapor fluxes in 2016 and 2017 but not in 2013 and 2014 net co2 ecosystem exchange nee was significantly negatively related to water vapor flux at seasonal and interannual scales suggesting that enhanced transpiration of alpine wetland plants will also promote co2 absorption over long time scales few previous studies have investigated these patterns based on such an interannual monitoring data with eddy covariance tower on the qinghai tibetan plateau our results suggest that peatland water vapor flux affects not only the micrometeorological environment but also nee in wetland ecosystems over long time scales keywords wetland water vapor flux eddy covariance carbon water coupling qinghai tibetan plateau 1 introduction as complex ecosystems wetlands are an important living environment and play an important role in regulating climate improving water quality and maintaining biodiversity cui et al 2016 as huge soil carbon pools and important natural methane emission sources wetlands have always attracted research attention especially in soil carbon accumulative dynamics and estimated storage chen et al 2014 loisel and yu 2013 page et al 2011 wang et al 2014 yu et al 2010 zhao and yu 2012 paleoclimatic reconstruction finch and hill 2008 novenko et al 2015 zhao and yu 2012 carbon emission monitoring chen et al 2009 hao et al 2011 lund et al 2010 sakabe et al 2018 and environmental effects on soil carbon turnover chimner and cooper 2003 freeman et al 2001 moore and knowles 1989 sistla et al 2013 undoubtedly scholars in recent decades have been concerned about wetland carbon dynamics due to intensifying global warming especially carbon cycling which can more accurately reflect global change impacts on wetland ecosystem service functions conversely in direct monitoring wetland studies water vapor flux has received less attention than carbon flux hydrological factors drive the wetland ecological environment and as the main heat and water exchange between the wetland and the atmosphere water vapor flux has a prominent influence on carbon absorption and emission jia and song 2006 therefore studying water vapor flux can help understand the wetland carbon and energy cycle process and hydrological dynamics wetland water vapor flux is expressed as water vapor per unit area per unit time it s a characteristic ecosystem water cycle parameter and includes wetland water soil vegetation surface evaporation and transpiration processes i e evapotranspiration liu et al 2014 furthermore as an important wetland atmospheric water heat exchange process it affects regional climate and so a study of the coupled relationship between water vapor and carbon fluxes would be helpful to understand the factors and processes affecting the carbon and water cycle regionally although there is still little research cao et al 2016 zhao et al 2005 because of the complexity and diversity of surface characteristics estimation of evapotranspiration in wetlands remains uncertain although many models and micrometeorological methods have been applied anda et al 2015 chen et al 2002 drexler et al 2004 pauliukonis and schneider 2001 however due to technical limitations there has been little continuous water vapor flux monitoring research after the 1990 s a new generation of ultrasonic anemometers and co2 h2o gas analyzers were developed thomas and steven 1995 zhang et al 1986 and the first complete eddy covariance ec software package was developed mcmillen 1988 ecologists have increasingly used these tools to monitor carbon or water exchange between the ecosystem and atmosphere which has formed the rudiments of fluxnet baldocchi et al 2001 ec has been applied to many wetland ecosystems lund et al 2012 sakabe et al 2018 zhao et al 2016 as it can generate more accurate results with higher temporal resolution and it allows continuous measurement of co2 h2o under difficult weather conditions aubinet et al 2012 although fewer than wetland carbon flux studies water vapor flux studies and their influencing factors have received more attention recently eichelmann et al 2018 moffett et al 2010 siedlecki et al 2016 wang et al 2019 yan et al 2018 however in some alpine peatlands such as the qinghai tibetan plateau qtp water vapor flux is still mostly an auxiliary observation item and not studied and discussed in depth the qtp has about 115 584 km2 of wetlands including 34 698 km2 of peatlands lang et al 2019 which play an important role in regional water conservation carbon sequestration and climate regulation most previous qtp peatland studies were located in the northeast on the zoige plateau an area with the highest organic carbon storage and accumulation intensity wang et al 2012 the zoige peatlands are located on the upper reaches of the yellow river covering an area of 4605 km2 sun 1992 wang et al 2014 most peat here was initiated in the early holocene wang et al 2014 with an average thickness of 2 3 m and a maximum up to about 10 m chen et al 2014 sun 1992 many ec carbon flux studies have been increasingly conducted in this region hao et al 2011 liu et al 2019 peng et al 2015 meanwhile continuous water vapor flux monitoring studies have been absent even though regional hydrological dynamics are essential for wetland conservation and management therefore we undertook long term observation of water vapor fluxes between the ecosystem and the atmosphere to increase our understanding of alpine peatland water flux dynamics we installed an ec tower on a typical fen peatland located on the zoige plateau to measure water vapor fluxes from 2013 to 2017 our objectives were to 1 examine diurnal seasonal and interannual variability in ecosystem water vapor fluxes h2o and the factors that contribute to that variability and 2 explore the coupled carbon water cycle relationship in the region 2 methods and materials 2 1 study area our flux tower was installed at the end of 2012 in the riganqiao peatland 33 06 15 419 n 102 39 05 278 e which is located in hongyuan county sichuan province at an altitude of 3 460 m a s l this is one of the largest peatland areas on the zoige plateau with maximum peat thickness of 10 m chen et al 2014 sun 1992 and an average ph of 6 6 7 0 tian et al 2012 dominant vegetation includes carex muliensis carex meyeriarta trollius farreri stapf gentiana formosa caltha palustris poa annua l and potentilla anserina l mean annual air temperature is 1 7 7 7 c and mean annual precipitation is 750 mm 1960 2021 china meteorological data service center the snow period lasts from november to may with 20 cm snow depth liu et al 2019 2 2 measurements h2o fluxes were measured at 2 7 m above the ground on the tower using a 3 d sonic anemometer csat3a campbell scientific logan combined with an open path infrared co2 h2o gas analyzer ec150 campbell scientific flux tower fetch area was calculated from the predominant wind directions using the footprint model kljun et al 2004 and peak contributing distances lay an average of 31 m from the tower environmental variables were also monitored continuously with auxiliary instruments at the site including air temperature ta and relative humidity rh hc2s3 campbell scientific usa soil temperature at 0 05 m depth ts si 111 campbell scientific usa photosynthetically active radiation par li190sb li cor usa volumetric water content vwc cs616 campbell scientific usa water table depth wtd cs451 campbell scientific usa precipitation and snow t200b geonor norway and net radiation cnr 4 kipp zonen netherlands liu et al 2019 liu et al 2021 2 3 quality control and gap filling raw data from the ec system were collected at a frequency of 10 hz and processed using loggernet 4 5 software half hourly fluxes were produced using eddypro 6 2 1 and quality control also ran through this software including sonic temperature correction frequency response correction high and low double coordinate rotation uncorrected flux computation turbulent fluctuations block average webb pearman leuning wpl correction and statistical analysis spike removal amplitude resolution drop outs absolute limits mcdermitt et al 2011 moncrieff et al 1997 wang et al 2007 webb et al 1980 data were excluded if they clearly resulted from instrument malfunction such as values of 9999 missing data accounted for 49 from 2013 to 2014 and 2016 to 2017 data for 2015 were missing for up to three quarters of the year due to instrument failure current methods of water vapor flux data gap filling include mean diurnal variation mdv and linear regression equation cao et al 2016 li et al 2006 liu et al 2014 we compared mdv linear regression and artificial neural network ann which have been widely used in co2 ec flux studies and chose multiple linear regression mlr for our gap filling as it had the highest goodness of fit r2 0 93 the fitting equation was 1 h 2 o 0 237 15 45 e t 0 0037 r h 0 00033 v p d 0 016 w s 0 009 t a where h2o is water vapor flux mmol m 2 s 1 et is evapotranspiration mm h 1 rh is relative humidity vpd is vapor pressure deficit pa ws is wind speed m 1 s 1 and ta is air temperature all data were on a half hour scale the variance inflation factor vif was calculated to measure the collinearity in this equation through car package in r 4 0 4 we found that all vif values of these five variables were 10 indicated there was no collinearity to compare diurnal and seasonal patterns of h2o flux we divided every year into a growing season from may to september suitable period for plant growth and non growing season from october through april of the following year kang et al 2016 2 4 statistical analysis we conducted spearman s rank correlation analysis to explore a potential relationship between h2o and other factors linear and nonlinear regression were performed where half hour or daily h2o served as the dependent variable and environmental factors served as independent variables correlations were considered significant when p 0 05 and highly significant when p 0 01 all statistical analyses were performed using spss 18 0 ibm spss statistics principal component analysis was performed and variable factor maps constructed with the packages factominer and factoextra le et al 2008 respectively in the r program 4 0 4 ross ihaka and robert gentleman this is a statistical method that uses dimensionality reduction to determine correlation between multiple variables figures were drawn using r and origin 8 5 originlab 3 results 3 1 diurnal h2o diurnal h2o flux patterns were very similar across the four years differing only in amplitude peak values occurred around 14 00 and maximum diurnal h2o flux mmol m 2 s 1 was 2 2 0 19 3 9 0 20 2 9 0 19 and 3 0 16 respectively for each year mean diurnal h2o flux rate mmol m 2 s 1 was 0 77 0 02 1 2 0 02 0 85 0 02 and 0 93 0 02 respectively fig 1 a mean diurnal h2o flux rate mmol m 2 s 1 was 2 4 0 05 1 9 0 05 1 7 0 04 and 1 7 0 04 respectively during growing seasons 0 30 0 01 0 81 0 02 0 16 0 02 and 0 33 0 02 respectively during non growing seasons fig 1b 1c peak values occurred between 13 00 and 15 00 during growing seasons and maximum rate mmol m 2 s 1 was 5 4 0 40 5 8 0 34 5 4 0 28 and 5 2 0 26 respectively fig 1b in the non growing seasons peak values occurred between 14 00 and 14 30 maximum rate mmol m 2 s 1 was 1 1 0 13 2 7 0 19 1 0 0 16 and 1 4 0 12 respectively fig 1c amplitude variation was quite limited in the non growing season ranging from 0 3 to 2 7 mmol m 2 s 1 compared to the growing season 0 4 to 5 8 mmol m 2 s 1 fig 1 3 2 seasonal and interannual h2o daily h2o flux values were concentrated around 0 g m 2 d 1 in 2013 2016 and 2017 but considerably higher in 2014 data were mainly concentrated around 700 g m 2 d 1 in each year daily h2o flux rate was generally distributed around 2500 g m 2 d 1 and median values g m 2 d 1 were 1123 1771 1053 and 1222 respectively mean values g m 2 d 1 were 1884 154 1947 92 1362 92 and 1437 80 respectively fig 2 a during growing seasons daily h2o flux values were concentrated similarly in 2014 2016 and 2017 median values g m 2 d 1 were 2915 2728 and 2688 respectively mean values g m 2 d 1 were 2895 111 2678 112 and 2701 99 respectively in 2013 the median value was 3981 g m 2 d 1 and mean value was 4130 256 g m 2 d 1 fig 2b daily h2o flux rate was substantially higher between june and august peak values g m 2 d 1 were 8836 doy 161 5860 doy 198 5945 doy 249 and 4839 doy 202 respectively from 2013 to 2017 fig 3 in non growing seasons median daily h2o flux values g m 2 d 1 were 349 1005 270 and 296 respectively mean values g m 2 d 1 were 486 69 1284 82 255 69 and 503 64 respectively fig 2c peak values g m 2 d 1 were 4109 doy 115 4418 doy 102 3274 doy 101 and 2890 doy 274 respectively fig 3 cumulative h2o flux values kg m 2 in growing seasons were 202 284 410 and 413 respectively in each year in non growing seasons cumulative h2o flux values kg m 2 were 78 180 46 and 104 respectively cumulative h2o flux values kg m 2 were 280 464 456 and 517 respectively from 2013 to 2017 3 3 hydrological and environmental variation during growing seasons the vpd pa median was 573 mean was 653 3 and peak was 1052 25 1 at17 00 the et mm hour 1 median was 0 07 mean was 0 12 0 002 and peak was 0 32 0 01 at14 30 the ta median was 9 3 mean was 9 6 0 04 and peak was 14 5 0 22 at 16 30 the rn w m 2 median was 5 3 mean was 218 10 4 and peak was 1214 71 5 at 13 00 the rh median was 53 5 mean was 54 0 0 17 and peak was 65 3 1 5 at 04 00 fig 4 in non growing seasons the vpd pa median was 361 mean was 441 2 4 and peak was 739 19 1 at 15 30 the et mm hour 1 median was 0 02 mean was 0 04 0 004 and peak was 0 14 0 006 at14 30 the ta median was 0 85 mean was 1 1 0 04 and peak was 5 2 0 22 at 16 00 the rn w m 2 median was 4 0 mean was 248 3 3 and peak was 1096 23 1 at13 30 the rh median was 38 0 mean was 39 0 0 17 and peak was 49 1 1 4 at 07 00 fig 4 3 4 factors influencing seasonal h2o flux linear regression analysis identified half hourly h2o fluxes as significantly related to other hydrological and environmental factors whether in growing or non growing seasons p 0 01 in growing seasons linear regression showed that et r2 0 90 vpd r2 0 33 and ta r2 0 27 were significantly positively related to h2o flux while rh r2 0 11 was significantly negatively related to h2o flux in non growing seasons overall goodness of fit was lower than in growing seasons between et r2 0 90 rh r2 0 03 vpd r2 0 23 and ta r2 0 16 and h2o fluxes but the directions of the variable relationships were similar fig 5 fig 6 furthermore linear and non linear regression analysis also identified half hourly h2o fluxes as significantly different to other heat flux values p 0 01 h sensible heat flux was significantly linearly related to h2o flux r2 0 30 in growing seasons and r2 0 12 in non growing seasons there was a significant exponential correlation between rn net radiation and h2o fluxes r2 0 30 in growing seasons and a significant linear correlation r2 0 24 in non growing seasons le latent heat flux was significantly linearly related to h2o flux r2 0 99 whether in growing or non growing seasons fig 5 fig 6 there was a significant negative correlation between half hourly h2o fluxes and nee net ecosystem co2 exchange in growing r 0 587 p 0 01 and non growing seasons r 0 252 p 0 01 additionally linear regression analysis identified half hourly h2o fluxes as significantly related to nee in growing r2 0 32 and non growing seasons r2 0 09 fig 5 fig 6 3 5 factors influencing interannual h2o flux principal component analysis pca was used to identify dominant influences on interannual h2o flux including ta et vpd rh nee h le vwc 5 15 30 5 15 30 cm depth ws and rn except in 2017 because of many unbelievable negative values due to the sensor failure eigenvalues show the extent of data variability in the principal component eigenvalue 1 means variable interpretation ability is strong we found that about 41 62 51 07 35 06 and 34 28 of the variation was explained by the first principal components axis from 2013 to 2017 respectively cumulatively the first three principal components explained 66 37 73 90 65 95 and 66 55 of data the variation table 1 angles between the arrows represent the correlation of different variations an acute angle is a positive correlation and an obtuse angle is a negative correlation and orthogonal relationships between two variables indicate that they are not correlated in 2013 vpd rn et le and ta were very close to h2o flux indicating they were significantly and positively correlated while nee was on the opposite side of h2o flux indicating it was significantly and negatively correlated in 2014 et le and ta were positively correlated with h2o flux while nee was negatively correlated with it in 2016 most variables were positively correlated with h2o flux only nee and ws were negatively correlated with it in 2017 ta rh et and le were positively correlated with h2o flux while nee and ws were negatively correlated with it fig 7 4 discussion 4 1 a water vapor source from 2013 to 2017 based on our study the mean half hour annual h2o flux mmol m 2 s 1 was 0 92 ranged from 4 7 to 13 5 and acted as an obvious water vapor source especially during the growing season mean h2o flux was 1 66 mmol m 2 s 1 and the maximum was 5 8 mmol m 2 s 1 these results are similar to weng et al 2020 where monthly water vapor flux in the dajiuhu peatland ranged from 2 6 to 5 69 mmol m 2 s 1 from 2017 to 2018 peak water vapor flux in riganqiao occurred between 13 00 and 15 00 which was also similar to dajiuhu 13 30 to 15 00 peaks in other forest ecosystems also occurred around this time chatterjee et al 2019 li et al 2006 liu et al 2014 niu et al 2016 weng et al 2020 table 2 during this time solar radiation is stronger and temperature is higher and plant transpiration and surface evaporation is more vigorous which leads to peak water vapor flux we found that peak et was around 14 30 and peak rn was around 13 00 which also suggests that stronger evapotranspiration can promote water vapor flux emission fig 4 h2o fluxes were lower before 7 00 and after 19 00 both in growing or non growing seasons fig 1 a trend also seen for et and rn fig 4 negative rn and lower et made water vapor flux very weak during this period moreover vpd tended to be stable in this period and since it controls stomatal closure and plant transpiration franks and farquhar 2010 mcadam and brodribb 2015 it is an important factor affecting wetland water vapor flux 4 2 influences of different hydrological and heat factors seasonally h2o flux varied little from january to march and then fluctuated wildly until october due to plant transpiration h2o flux was significantly related to hydrological factors et r2 0 90 rh r2 0 11 vpd r2 0 33 during the growing season et is the sum of plant transpiration and soil evaporation which is the sum of water vapor fluxes in forest soubie et al 2016 which our results in the alpine wetland also reflect the r2 of rh was relatively lower probably because of the wetland s strong water conservation function meaning that rh changes little during the growing season fig 5 vpd describes air dryness and it depends on temperature change dong and cui 1992 so it indirectly reflects the effect of temperature in the non growing season a weaker correlation between hydrological factors and water vapor flux suggests that decreased plant transpiration weakened its influence and that wetland plant growth dynamics is very important to regulate the wetland ecological environment cui and yang 2006 the influence of hydrological factors varies from one year to the next in 2013 and 2014 rh had no obvious correlation with water vapor flux almost right angle but it was correlated to water vapor flux in 2016 and especially in 2017 fig 7 anova results suggested that daily rh did not significantly differ in 2013 and 2014 p 0 05 in contrast to in 2016 and 2017 p 0 05 this suggests that the effects of humidity on water vapor flux vary when air is relatively dry in 2016 mean daily rh was 31 7 median was 33 2 or wet in 2017 mean daily rh was 53 1 median was 58 3 the effect is highly significant conversely when humidity is moderate mean were 46 3 and 49 3 medians were 48 8 and 51 5 in 2013 and 2014 respectively its effect on water vapor flux is unclear at our study site annual precipitation decreased 23 in 2016 575 mm compared with the first two years mean 750 mm and then increased a little in 2017 607 mm liu et al 2019 annual precipitation variation influenced air humidity subsequently highlighting the effects of water vapor flux variation however the effect of water vapor on wetland moisture also depends on ground distance li et al 2007 mean et of our site was 0 12 mm hour 1 during the growing season higher than tundra abnizova et al 2012 helbig et al 2013 simpson et al 2019 and equal to or lower than marsh goulden et al 2007 mengistu et al 2014 sun and song 2008 zhou and zhou 2009 suggesting that differences in vegetation and hydrology can significantly affect ecosystem et dynamics therefore the regulating effect of water vapor in wetland is worthy of further study we mainly studied the relationships between water vapor flux and le h rn and ta at a seasonal scale and found a high correlation between latent heat flux and water vapor flux during growing and non growing seasons r2 0 99 le is the heat exchange of water between the underlying surface and the atmosphere so it s similar to et because the calculation of et also depends on le in ec we also determined that h was significantly related to water vapor flux with a higher r2 during the growing season 0 30 than non growing season 0 12 this could be because h is mainly affected by temperature and a higher temperature during the growing season promoted this correlation this is also supported by the relationship between water vapor flux and ta rn was significantly positively related to water vapor flux but the r2 was low compared with other studies whether in forest lin et al 2013 liu et al 2014 niu et al 2016 zhang et al 2015 or peatland peng et al 2017 weng et al 2020 our r2 were lower this difference may be due to unique geographical site locations our site was located on a plateau and mean month net radiation was lower than in other previous studies chen et al 2016 4 3 water vapor flux and nee relationships between 13 00 and 15 00 open plant stomata promote transpiration which is an important component of water vapor flux fig 1 however plant photosynthetic capacity was also highest at this time as is a co2 absorption peak liu et al 2019 this reflects the importance of plants on ecosystem carbon water exchange during the growing season nee was significantly negatively related to water vapor flux fig 5 p 0 01 r2 0 32 a similar result to other flux studies cao et al 2016 law et al 2002 this suggests that increased plant transpiration during the growing season promotes photosynthesis leading to co2 absorption in the non growing season r2 was lower fig 6 p 0 01 r2 0 09 suggesting the soil evaporation dominated in this period while nee was also almost in remission weakening the negative correlation principal component results also suggested a significant coupling between co2 and h2o flux in diurnal seasonal or even interannual scale wetland carbon flux studies based on ec have increased in recent years along with an emphasis on influencing factors at different scales e g chen et al 2021 lafleur et al 2001 liu et al 2019 zhao et al 2016 however the effect of water vapor flux on the co2 budget has rarely been considered at different scales as the main conduit of water and heat exchange between a wetland and the atmosphere water vapor flux has a significant influence on wetland micrometeorology influencing water temperature sánchez carrillo et al 2004 which may further affect co2 absorption or emissions whatever the effects of stomata on plant photosynthesis and transpiration on a microscale or the effects of water condition on material circulation and energy balance of wetland at a macroscale water vapor flux is closely related to carbon flux studying carbon water coupling is bound to become the focus of subsequent research baldocchi 2020 due to the special hydrological conditions of wetland compared to other terrestrial ecosystems a more systematic approach may be required to investigate the relationships between nee and water vapor flux 5 conclusions our long term ec based water vapor flux study appears to be the first in the zoige peatlands or even the eastern qinghai tibetan plateau our results indicate that from 2013 to 2017 the riganqiao peatland acted as a net water source with different seasonal and interannual variability due to varying weather conditions hydrological and heat factors were crucial to seasonal variation in water vapor flux and there were differences between growing and non growing seasons principal component analysis showed that the correlations between interannual water vapor fluxes and environmental hydrological factors rh differed from 2013 to 2017 suggesting year to year variation therefore continuous long term monitoring is essential to further reveal this alpine wetland interannual pattern moreover nee was significantly negatively related to water vapor flux whether seasonally or from one year to the next many previous carbon flux studies ignored this correlation but we suggest that it is important for annual carbon budgets especially in wetland ecosystems which have unique hydrology plants and soils specifically water vapor flux affects not just the hydrological balance but also carbon absorption and emission of the wetland ecosystem the coupled carbon water relationship is worthy of more research including in depth analysis of its mechanisms through long term monitoring in the region credit authorship contribution statement xinwei liu conceptualization validation investigation formal analysis writing original draft writing review editing data curation wei zhan software investigation data curation dan zhu resources methodology writing review editing funding acquisition ning wu supervision yixin he supervision huai chen conceptualization methodology writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the second tibetan plateau scientific expedition 2019qzkk0304 the strategic priority research program of chinese academy of sciences xda2005010404 national natural science foundation of china 91851108 the authors would like to express their gratitude to editsprings https www editsprings cn for the expert linguistic services provided 
3186,although carbon flux monitoring has been studied extensively in terrestrial ecosystems around the world water vapor flux based on eddy covariance has received little attention as a special type of terrestrial ecosystem wetlands are transitions between land and water material and energy and therefore of great significance in times of global change in wetlands water vapor flux has a significant impact on micrometeorological environments making it the main conduit for water vapor exchange between the wetland and the atmosphere using an eddy covariance tower we measured water vapor flux h2o over four years at the riganqiao fen in the zoige peatlands on the eastern qinghai tibetan plateau china diurnal h2o peaks occurred around 14 00 and annual mean diurnal rate mmol m 2 s 1 was 0 77 0 02 1 2 0 02 0 85 0 02 and 0 93 0 02 respectively over the 4 years daily h2o flux rate was substantially higher between june and august with peak values of 8836 g m 2 d 1 on doy day of year 161 in 2013 the riganqiao peatland was a net water source with an emission average of 429 3 51 5 kg m 2 yr 1 hydrological and temperature were crucial to seasonal variation in water vapor fluxes in both growing and non growing seasons especially the latent heat flux le however interannual water vapor flux and relative humidity rh were significantly positively correlated to water vapor fluxes in 2016 and 2017 but not in 2013 and 2014 net co2 ecosystem exchange nee was significantly negatively related to water vapor flux at seasonal and interannual scales suggesting that enhanced transpiration of alpine wetland plants will also promote co2 absorption over long time scales few previous studies have investigated these patterns based on such an interannual monitoring data with eddy covariance tower on the qinghai tibetan plateau our results suggest that peatland water vapor flux affects not only the micrometeorological environment but also nee in wetland ecosystems over long time scales keywords wetland water vapor flux eddy covariance carbon water coupling qinghai tibetan plateau 1 introduction as complex ecosystems wetlands are an important living environment and play an important role in regulating climate improving water quality and maintaining biodiversity cui et al 2016 as huge soil carbon pools and important natural methane emission sources wetlands have always attracted research attention especially in soil carbon accumulative dynamics and estimated storage chen et al 2014 loisel and yu 2013 page et al 2011 wang et al 2014 yu et al 2010 zhao and yu 2012 paleoclimatic reconstruction finch and hill 2008 novenko et al 2015 zhao and yu 2012 carbon emission monitoring chen et al 2009 hao et al 2011 lund et al 2010 sakabe et al 2018 and environmental effects on soil carbon turnover chimner and cooper 2003 freeman et al 2001 moore and knowles 1989 sistla et al 2013 undoubtedly scholars in recent decades have been concerned about wetland carbon dynamics due to intensifying global warming especially carbon cycling which can more accurately reflect global change impacts on wetland ecosystem service functions conversely in direct monitoring wetland studies water vapor flux has received less attention than carbon flux hydrological factors drive the wetland ecological environment and as the main heat and water exchange between the wetland and the atmosphere water vapor flux has a prominent influence on carbon absorption and emission jia and song 2006 therefore studying water vapor flux can help understand the wetland carbon and energy cycle process and hydrological dynamics wetland water vapor flux is expressed as water vapor per unit area per unit time it s a characteristic ecosystem water cycle parameter and includes wetland water soil vegetation surface evaporation and transpiration processes i e evapotranspiration liu et al 2014 furthermore as an important wetland atmospheric water heat exchange process it affects regional climate and so a study of the coupled relationship between water vapor and carbon fluxes would be helpful to understand the factors and processes affecting the carbon and water cycle regionally although there is still little research cao et al 2016 zhao et al 2005 because of the complexity and diversity of surface characteristics estimation of evapotranspiration in wetlands remains uncertain although many models and micrometeorological methods have been applied anda et al 2015 chen et al 2002 drexler et al 2004 pauliukonis and schneider 2001 however due to technical limitations there has been little continuous water vapor flux monitoring research after the 1990 s a new generation of ultrasonic anemometers and co2 h2o gas analyzers were developed thomas and steven 1995 zhang et al 1986 and the first complete eddy covariance ec software package was developed mcmillen 1988 ecologists have increasingly used these tools to monitor carbon or water exchange between the ecosystem and atmosphere which has formed the rudiments of fluxnet baldocchi et al 2001 ec has been applied to many wetland ecosystems lund et al 2012 sakabe et al 2018 zhao et al 2016 as it can generate more accurate results with higher temporal resolution and it allows continuous measurement of co2 h2o under difficult weather conditions aubinet et al 2012 although fewer than wetland carbon flux studies water vapor flux studies and their influencing factors have received more attention recently eichelmann et al 2018 moffett et al 2010 siedlecki et al 2016 wang et al 2019 yan et al 2018 however in some alpine peatlands such as the qinghai tibetan plateau qtp water vapor flux is still mostly an auxiliary observation item and not studied and discussed in depth the qtp has about 115 584 km2 of wetlands including 34 698 km2 of peatlands lang et al 2019 which play an important role in regional water conservation carbon sequestration and climate regulation most previous qtp peatland studies were located in the northeast on the zoige plateau an area with the highest organic carbon storage and accumulation intensity wang et al 2012 the zoige peatlands are located on the upper reaches of the yellow river covering an area of 4605 km2 sun 1992 wang et al 2014 most peat here was initiated in the early holocene wang et al 2014 with an average thickness of 2 3 m and a maximum up to about 10 m chen et al 2014 sun 1992 many ec carbon flux studies have been increasingly conducted in this region hao et al 2011 liu et al 2019 peng et al 2015 meanwhile continuous water vapor flux monitoring studies have been absent even though regional hydrological dynamics are essential for wetland conservation and management therefore we undertook long term observation of water vapor fluxes between the ecosystem and the atmosphere to increase our understanding of alpine peatland water flux dynamics we installed an ec tower on a typical fen peatland located on the zoige plateau to measure water vapor fluxes from 2013 to 2017 our objectives were to 1 examine diurnal seasonal and interannual variability in ecosystem water vapor fluxes h2o and the factors that contribute to that variability and 2 explore the coupled carbon water cycle relationship in the region 2 methods and materials 2 1 study area our flux tower was installed at the end of 2012 in the riganqiao peatland 33 06 15 419 n 102 39 05 278 e which is located in hongyuan county sichuan province at an altitude of 3 460 m a s l this is one of the largest peatland areas on the zoige plateau with maximum peat thickness of 10 m chen et al 2014 sun 1992 and an average ph of 6 6 7 0 tian et al 2012 dominant vegetation includes carex muliensis carex meyeriarta trollius farreri stapf gentiana formosa caltha palustris poa annua l and potentilla anserina l mean annual air temperature is 1 7 7 7 c and mean annual precipitation is 750 mm 1960 2021 china meteorological data service center the snow period lasts from november to may with 20 cm snow depth liu et al 2019 2 2 measurements h2o fluxes were measured at 2 7 m above the ground on the tower using a 3 d sonic anemometer csat3a campbell scientific logan combined with an open path infrared co2 h2o gas analyzer ec150 campbell scientific flux tower fetch area was calculated from the predominant wind directions using the footprint model kljun et al 2004 and peak contributing distances lay an average of 31 m from the tower environmental variables were also monitored continuously with auxiliary instruments at the site including air temperature ta and relative humidity rh hc2s3 campbell scientific usa soil temperature at 0 05 m depth ts si 111 campbell scientific usa photosynthetically active radiation par li190sb li cor usa volumetric water content vwc cs616 campbell scientific usa water table depth wtd cs451 campbell scientific usa precipitation and snow t200b geonor norway and net radiation cnr 4 kipp zonen netherlands liu et al 2019 liu et al 2021 2 3 quality control and gap filling raw data from the ec system were collected at a frequency of 10 hz and processed using loggernet 4 5 software half hourly fluxes were produced using eddypro 6 2 1 and quality control also ran through this software including sonic temperature correction frequency response correction high and low double coordinate rotation uncorrected flux computation turbulent fluctuations block average webb pearman leuning wpl correction and statistical analysis spike removal amplitude resolution drop outs absolute limits mcdermitt et al 2011 moncrieff et al 1997 wang et al 2007 webb et al 1980 data were excluded if they clearly resulted from instrument malfunction such as values of 9999 missing data accounted for 49 from 2013 to 2014 and 2016 to 2017 data for 2015 were missing for up to three quarters of the year due to instrument failure current methods of water vapor flux data gap filling include mean diurnal variation mdv and linear regression equation cao et al 2016 li et al 2006 liu et al 2014 we compared mdv linear regression and artificial neural network ann which have been widely used in co2 ec flux studies and chose multiple linear regression mlr for our gap filling as it had the highest goodness of fit r2 0 93 the fitting equation was 1 h 2 o 0 237 15 45 e t 0 0037 r h 0 00033 v p d 0 016 w s 0 009 t a where h2o is water vapor flux mmol m 2 s 1 et is evapotranspiration mm h 1 rh is relative humidity vpd is vapor pressure deficit pa ws is wind speed m 1 s 1 and ta is air temperature all data were on a half hour scale the variance inflation factor vif was calculated to measure the collinearity in this equation through car package in r 4 0 4 we found that all vif values of these five variables were 10 indicated there was no collinearity to compare diurnal and seasonal patterns of h2o flux we divided every year into a growing season from may to september suitable period for plant growth and non growing season from october through april of the following year kang et al 2016 2 4 statistical analysis we conducted spearman s rank correlation analysis to explore a potential relationship between h2o and other factors linear and nonlinear regression were performed where half hour or daily h2o served as the dependent variable and environmental factors served as independent variables correlations were considered significant when p 0 05 and highly significant when p 0 01 all statistical analyses were performed using spss 18 0 ibm spss statistics principal component analysis was performed and variable factor maps constructed with the packages factominer and factoextra le et al 2008 respectively in the r program 4 0 4 ross ihaka and robert gentleman this is a statistical method that uses dimensionality reduction to determine correlation between multiple variables figures were drawn using r and origin 8 5 originlab 3 results 3 1 diurnal h2o diurnal h2o flux patterns were very similar across the four years differing only in amplitude peak values occurred around 14 00 and maximum diurnal h2o flux mmol m 2 s 1 was 2 2 0 19 3 9 0 20 2 9 0 19 and 3 0 16 respectively for each year mean diurnal h2o flux rate mmol m 2 s 1 was 0 77 0 02 1 2 0 02 0 85 0 02 and 0 93 0 02 respectively fig 1 a mean diurnal h2o flux rate mmol m 2 s 1 was 2 4 0 05 1 9 0 05 1 7 0 04 and 1 7 0 04 respectively during growing seasons 0 30 0 01 0 81 0 02 0 16 0 02 and 0 33 0 02 respectively during non growing seasons fig 1b 1c peak values occurred between 13 00 and 15 00 during growing seasons and maximum rate mmol m 2 s 1 was 5 4 0 40 5 8 0 34 5 4 0 28 and 5 2 0 26 respectively fig 1b in the non growing seasons peak values occurred between 14 00 and 14 30 maximum rate mmol m 2 s 1 was 1 1 0 13 2 7 0 19 1 0 0 16 and 1 4 0 12 respectively fig 1c amplitude variation was quite limited in the non growing season ranging from 0 3 to 2 7 mmol m 2 s 1 compared to the growing season 0 4 to 5 8 mmol m 2 s 1 fig 1 3 2 seasonal and interannual h2o daily h2o flux values were concentrated around 0 g m 2 d 1 in 2013 2016 and 2017 but considerably higher in 2014 data were mainly concentrated around 700 g m 2 d 1 in each year daily h2o flux rate was generally distributed around 2500 g m 2 d 1 and median values g m 2 d 1 were 1123 1771 1053 and 1222 respectively mean values g m 2 d 1 were 1884 154 1947 92 1362 92 and 1437 80 respectively fig 2 a during growing seasons daily h2o flux values were concentrated similarly in 2014 2016 and 2017 median values g m 2 d 1 were 2915 2728 and 2688 respectively mean values g m 2 d 1 were 2895 111 2678 112 and 2701 99 respectively in 2013 the median value was 3981 g m 2 d 1 and mean value was 4130 256 g m 2 d 1 fig 2b daily h2o flux rate was substantially higher between june and august peak values g m 2 d 1 were 8836 doy 161 5860 doy 198 5945 doy 249 and 4839 doy 202 respectively from 2013 to 2017 fig 3 in non growing seasons median daily h2o flux values g m 2 d 1 were 349 1005 270 and 296 respectively mean values g m 2 d 1 were 486 69 1284 82 255 69 and 503 64 respectively fig 2c peak values g m 2 d 1 were 4109 doy 115 4418 doy 102 3274 doy 101 and 2890 doy 274 respectively fig 3 cumulative h2o flux values kg m 2 in growing seasons were 202 284 410 and 413 respectively in each year in non growing seasons cumulative h2o flux values kg m 2 were 78 180 46 and 104 respectively cumulative h2o flux values kg m 2 were 280 464 456 and 517 respectively from 2013 to 2017 3 3 hydrological and environmental variation during growing seasons the vpd pa median was 573 mean was 653 3 and peak was 1052 25 1 at17 00 the et mm hour 1 median was 0 07 mean was 0 12 0 002 and peak was 0 32 0 01 at14 30 the ta median was 9 3 mean was 9 6 0 04 and peak was 14 5 0 22 at 16 30 the rn w m 2 median was 5 3 mean was 218 10 4 and peak was 1214 71 5 at 13 00 the rh median was 53 5 mean was 54 0 0 17 and peak was 65 3 1 5 at 04 00 fig 4 in non growing seasons the vpd pa median was 361 mean was 441 2 4 and peak was 739 19 1 at 15 30 the et mm hour 1 median was 0 02 mean was 0 04 0 004 and peak was 0 14 0 006 at14 30 the ta median was 0 85 mean was 1 1 0 04 and peak was 5 2 0 22 at 16 00 the rn w m 2 median was 4 0 mean was 248 3 3 and peak was 1096 23 1 at13 30 the rh median was 38 0 mean was 39 0 0 17 and peak was 49 1 1 4 at 07 00 fig 4 3 4 factors influencing seasonal h2o flux linear regression analysis identified half hourly h2o fluxes as significantly related to other hydrological and environmental factors whether in growing or non growing seasons p 0 01 in growing seasons linear regression showed that et r2 0 90 vpd r2 0 33 and ta r2 0 27 were significantly positively related to h2o flux while rh r2 0 11 was significantly negatively related to h2o flux in non growing seasons overall goodness of fit was lower than in growing seasons between et r2 0 90 rh r2 0 03 vpd r2 0 23 and ta r2 0 16 and h2o fluxes but the directions of the variable relationships were similar fig 5 fig 6 furthermore linear and non linear regression analysis also identified half hourly h2o fluxes as significantly different to other heat flux values p 0 01 h sensible heat flux was significantly linearly related to h2o flux r2 0 30 in growing seasons and r2 0 12 in non growing seasons there was a significant exponential correlation between rn net radiation and h2o fluxes r2 0 30 in growing seasons and a significant linear correlation r2 0 24 in non growing seasons le latent heat flux was significantly linearly related to h2o flux r2 0 99 whether in growing or non growing seasons fig 5 fig 6 there was a significant negative correlation between half hourly h2o fluxes and nee net ecosystem co2 exchange in growing r 0 587 p 0 01 and non growing seasons r 0 252 p 0 01 additionally linear regression analysis identified half hourly h2o fluxes as significantly related to nee in growing r2 0 32 and non growing seasons r2 0 09 fig 5 fig 6 3 5 factors influencing interannual h2o flux principal component analysis pca was used to identify dominant influences on interannual h2o flux including ta et vpd rh nee h le vwc 5 15 30 5 15 30 cm depth ws and rn except in 2017 because of many unbelievable negative values due to the sensor failure eigenvalues show the extent of data variability in the principal component eigenvalue 1 means variable interpretation ability is strong we found that about 41 62 51 07 35 06 and 34 28 of the variation was explained by the first principal components axis from 2013 to 2017 respectively cumulatively the first three principal components explained 66 37 73 90 65 95 and 66 55 of data the variation table 1 angles between the arrows represent the correlation of different variations an acute angle is a positive correlation and an obtuse angle is a negative correlation and orthogonal relationships between two variables indicate that they are not correlated in 2013 vpd rn et le and ta were very close to h2o flux indicating they were significantly and positively correlated while nee was on the opposite side of h2o flux indicating it was significantly and negatively correlated in 2014 et le and ta were positively correlated with h2o flux while nee was negatively correlated with it in 2016 most variables were positively correlated with h2o flux only nee and ws were negatively correlated with it in 2017 ta rh et and le were positively correlated with h2o flux while nee and ws were negatively correlated with it fig 7 4 discussion 4 1 a water vapor source from 2013 to 2017 based on our study the mean half hour annual h2o flux mmol m 2 s 1 was 0 92 ranged from 4 7 to 13 5 and acted as an obvious water vapor source especially during the growing season mean h2o flux was 1 66 mmol m 2 s 1 and the maximum was 5 8 mmol m 2 s 1 these results are similar to weng et al 2020 where monthly water vapor flux in the dajiuhu peatland ranged from 2 6 to 5 69 mmol m 2 s 1 from 2017 to 2018 peak water vapor flux in riganqiao occurred between 13 00 and 15 00 which was also similar to dajiuhu 13 30 to 15 00 peaks in other forest ecosystems also occurred around this time chatterjee et al 2019 li et al 2006 liu et al 2014 niu et al 2016 weng et al 2020 table 2 during this time solar radiation is stronger and temperature is higher and plant transpiration and surface evaporation is more vigorous which leads to peak water vapor flux we found that peak et was around 14 30 and peak rn was around 13 00 which also suggests that stronger evapotranspiration can promote water vapor flux emission fig 4 h2o fluxes were lower before 7 00 and after 19 00 both in growing or non growing seasons fig 1 a trend also seen for et and rn fig 4 negative rn and lower et made water vapor flux very weak during this period moreover vpd tended to be stable in this period and since it controls stomatal closure and plant transpiration franks and farquhar 2010 mcadam and brodribb 2015 it is an important factor affecting wetland water vapor flux 4 2 influences of different hydrological and heat factors seasonally h2o flux varied little from january to march and then fluctuated wildly until october due to plant transpiration h2o flux was significantly related to hydrological factors et r2 0 90 rh r2 0 11 vpd r2 0 33 during the growing season et is the sum of plant transpiration and soil evaporation which is the sum of water vapor fluxes in forest soubie et al 2016 which our results in the alpine wetland also reflect the r2 of rh was relatively lower probably because of the wetland s strong water conservation function meaning that rh changes little during the growing season fig 5 vpd describes air dryness and it depends on temperature change dong and cui 1992 so it indirectly reflects the effect of temperature in the non growing season a weaker correlation between hydrological factors and water vapor flux suggests that decreased plant transpiration weakened its influence and that wetland plant growth dynamics is very important to regulate the wetland ecological environment cui and yang 2006 the influence of hydrological factors varies from one year to the next in 2013 and 2014 rh had no obvious correlation with water vapor flux almost right angle but it was correlated to water vapor flux in 2016 and especially in 2017 fig 7 anova results suggested that daily rh did not significantly differ in 2013 and 2014 p 0 05 in contrast to in 2016 and 2017 p 0 05 this suggests that the effects of humidity on water vapor flux vary when air is relatively dry in 2016 mean daily rh was 31 7 median was 33 2 or wet in 2017 mean daily rh was 53 1 median was 58 3 the effect is highly significant conversely when humidity is moderate mean were 46 3 and 49 3 medians were 48 8 and 51 5 in 2013 and 2014 respectively its effect on water vapor flux is unclear at our study site annual precipitation decreased 23 in 2016 575 mm compared with the first two years mean 750 mm and then increased a little in 2017 607 mm liu et al 2019 annual precipitation variation influenced air humidity subsequently highlighting the effects of water vapor flux variation however the effect of water vapor on wetland moisture also depends on ground distance li et al 2007 mean et of our site was 0 12 mm hour 1 during the growing season higher than tundra abnizova et al 2012 helbig et al 2013 simpson et al 2019 and equal to or lower than marsh goulden et al 2007 mengistu et al 2014 sun and song 2008 zhou and zhou 2009 suggesting that differences in vegetation and hydrology can significantly affect ecosystem et dynamics therefore the regulating effect of water vapor in wetland is worthy of further study we mainly studied the relationships between water vapor flux and le h rn and ta at a seasonal scale and found a high correlation between latent heat flux and water vapor flux during growing and non growing seasons r2 0 99 le is the heat exchange of water between the underlying surface and the atmosphere so it s similar to et because the calculation of et also depends on le in ec we also determined that h was significantly related to water vapor flux with a higher r2 during the growing season 0 30 than non growing season 0 12 this could be because h is mainly affected by temperature and a higher temperature during the growing season promoted this correlation this is also supported by the relationship between water vapor flux and ta rn was significantly positively related to water vapor flux but the r2 was low compared with other studies whether in forest lin et al 2013 liu et al 2014 niu et al 2016 zhang et al 2015 or peatland peng et al 2017 weng et al 2020 our r2 were lower this difference may be due to unique geographical site locations our site was located on a plateau and mean month net radiation was lower than in other previous studies chen et al 2016 4 3 water vapor flux and nee relationships between 13 00 and 15 00 open plant stomata promote transpiration which is an important component of water vapor flux fig 1 however plant photosynthetic capacity was also highest at this time as is a co2 absorption peak liu et al 2019 this reflects the importance of plants on ecosystem carbon water exchange during the growing season nee was significantly negatively related to water vapor flux fig 5 p 0 01 r2 0 32 a similar result to other flux studies cao et al 2016 law et al 2002 this suggests that increased plant transpiration during the growing season promotes photosynthesis leading to co2 absorption in the non growing season r2 was lower fig 6 p 0 01 r2 0 09 suggesting the soil evaporation dominated in this period while nee was also almost in remission weakening the negative correlation principal component results also suggested a significant coupling between co2 and h2o flux in diurnal seasonal or even interannual scale wetland carbon flux studies based on ec have increased in recent years along with an emphasis on influencing factors at different scales e g chen et al 2021 lafleur et al 2001 liu et al 2019 zhao et al 2016 however the effect of water vapor flux on the co2 budget has rarely been considered at different scales as the main conduit of water and heat exchange between a wetland and the atmosphere water vapor flux has a significant influence on wetland micrometeorology influencing water temperature sánchez carrillo et al 2004 which may further affect co2 absorption or emissions whatever the effects of stomata on plant photosynthesis and transpiration on a microscale or the effects of water condition on material circulation and energy balance of wetland at a macroscale water vapor flux is closely related to carbon flux studying carbon water coupling is bound to become the focus of subsequent research baldocchi 2020 due to the special hydrological conditions of wetland compared to other terrestrial ecosystems a more systematic approach may be required to investigate the relationships between nee and water vapor flux 5 conclusions our long term ec based water vapor flux study appears to be the first in the zoige peatlands or even the eastern qinghai tibetan plateau our results indicate that from 2013 to 2017 the riganqiao peatland acted as a net water source with different seasonal and interannual variability due to varying weather conditions hydrological and heat factors were crucial to seasonal variation in water vapor flux and there were differences between growing and non growing seasons principal component analysis showed that the correlations between interannual water vapor fluxes and environmental hydrological factors rh differed from 2013 to 2017 suggesting year to year variation therefore continuous long term monitoring is essential to further reveal this alpine wetland interannual pattern moreover nee was significantly negatively related to water vapor flux whether seasonally or from one year to the next many previous carbon flux studies ignored this correlation but we suggest that it is important for annual carbon budgets especially in wetland ecosystems which have unique hydrology plants and soils specifically water vapor flux affects not just the hydrological balance but also carbon absorption and emission of the wetland ecosystem the coupled carbon water relationship is worthy of more research including in depth analysis of its mechanisms through long term monitoring in the region credit authorship contribution statement xinwei liu conceptualization validation investigation formal analysis writing original draft writing review editing data curation wei zhan software investigation data curation dan zhu resources methodology writing review editing funding acquisition ning wu supervision yixin he supervision huai chen conceptualization methodology writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study was supported by the second tibetan plateau scientific expedition 2019qzkk0304 the strategic priority research program of chinese academy of sciences xda2005010404 national natural science foundation of china 91851108 the authors would like to express their gratitude to editsprings https www editsprings cn for the expert linguistic services provided 
3187,dam breaches often have catastrophic consequences in downstream areas hydrodynamic factors and the evacuation potential of the population at risk par have significant impacts on the loss of life lol caused by dam breaches however the existing comprehensive evaluation models have not conducted in depth research on the evacuation potential of populations thus limited guidance is available for relevant departments to formulate emergency plans to reduce the potential lol therefore a new comprehensive evaluation model was proposed in this study according to the relevant references and disaster theory the main influencing factors and the process through which the lol is caused by dam breaches were determined the specific occurrence process was divided into six stages a dam breach causes flood the flood puts the par the par complete the preparation work the par evacuate the un evacuated population shelter themselves inside buildings and flood causes the death of the exposed population to calculate the lol the parameters relevant at each stage were defined furthermore the hydrologic engineering center s river analysis system geographic information system and related materials were used to simulate the flood routing and evacuation potential of the par quantifying the parameters in the model the model was applied to 14 towns in the downstream areas of the luhun reservoir in henan province china and its accuracy was verified by comparing the results obtained from the two existing models in addition the specific suggestions for reducing the potential lol were proposed based on the results of the simulation keywords dam breach loss of life disaster causing mechanism evacuation potential emergency plan 1 introduction dam service flood control navigation power generation and irrigation have significant economic benefits latrubesse et al 2017 however once a dam breach occurs it has disastrous consequences in downstream areas ge et al 2020a pathak et al 2020 zeng et al 2019 according to li et al 2019 china had an average of 57 9 dam breaches per year from 1954 to 2014 although there has been significant improvement in the project quality and management level in recent years dam breaches still occur from time to time owing to natural disasters human factors and strength loss caused by long term disrepair ge et al 2020b thrysøe et al 2021 in july 2018 at least 20 people were killed and more than 100 went missing owing to the flood caused by the collapse of a dam under construction which was a part of the xe pian xe namnoy hydroelectric power project in southeast laos kim and lee 2020 in august 2018 heavy rains caused the dam breach of the sheyuegou reservoir in xinjiang china leading to 20 deaths and 8 missing beijing news 2018 in may 2020 the sardoba reservoir in sirdaryo viloyati uzbekistan broke because of a typhoon and led to the evacuation of approximately 70 000 residents 4 deaths and 56 injuries xinhuanet 2020 in may 2020 the edenville dam in the united states broke due to its poor condition and heavy rainfall causing more than 10 000 people forced to evacuate urgently consequently the potential loss of life lol caused by dam breaches has always attracted the attention of researchers aboelata et al 2003 lumbroso et al 2011 2021 johnstone and garrett 2014 ge et al 2017 georges et al 2019 generally empirical models which established by regression analysis of historical dam breach events were used to establish the functional relationship between the lol and certain key parameters brown and graham 1988 proposed a method for predicting the lol based on the analysis of the population at risk par and the warning time tw considering the various levels of severity of dam breach flood dekay and mcclelland 1993 proposed a formula for estimating the nonlinear relationship between the lol and par graham 1999 added the degree of understanding of the dam breach to the influencing factors and proposed the mortality of the par based on graham 1999 zhou et al 2007 analyzed the data of eight dams in china and established a corresponding assessment model of the lol caused by dam breaches the u s department of the interior bureau of reclamation 2015 has proposed a new method to replace the graham method to estimate the lol despite their easy application most empirical models often have limited use owing to the low availability of the historical dataset jonkman et al 2008 recently the physical models which focus on the formation mechanism analysis of the lol have gradually become research hotspots assaf and hartford 2002 developed a virtual reality approach bc hydro s life safety model lsm to deal with the problems of failure consequence analysis and emergency planning aboelata and bowles 2008 established the lifesim model to evaluate the lol of greater new orleans lumbroso et al 2011 2021 applied the lsm model to malapasset dam canvey island and brumadinho tailings dam combined with monte carlo accurately estimated the possible lol and put forward effective emergency management measures this kind of agent based physical models can simulate countless possible scenarios that may be caused by flood and make effective security decisions however this kind of models have high requirements for data and operation users therefore the comprehensive evaluation models have begun in prosperity jonkman et al 2008 developed a new function related to mortality to estimate the lol caused by flood disasters in low lying areas ehsan 2009 developed an improved method for lol estimation in addition he also discussed the definitions of two flood severity and proposed a new definition of flood severity by using the method of geometric aggregate ga considering more factors affecting the lol and the relationships among them peng and zhang 2012 constructed the huram model based on the bayes model based on data obtained from 14 dam failure cases in china huang et al 2017 proposed a new method for estimating the lol using a three dimensional stratified sampling method li et al 2018 analyzed the weights of the primary factors that affect the consequences of dam breaches using set pair analysis and the variable fuzzy set theory considering the extensive changes and effects of the various factors ge et al 2019 2021 constructed a rapid evaluation model based on the catastrophe theory and used the interval theory to effectively determine the possible upper and lower limits of lol caused by dam breaches rather than a certain value these comprehensive evaluation models focus on the innovation and application of mathematical methods improving the accuracy compared with the empirical models significantly however owing to the lack of in depth analysis of the evacuation potential of the par they are unable to quantify certain critical types of information as effectively as the physical models such as the time required for evacuation shortest roads that can be used for evacuation and the effective evacuation positions resulting in deficiencies in guiding the relevant departments to formulate emergency plans therefore in order to facilitate application and provide reference and basis for formulating emergency evacuation plan to reduce potential lol combined with flood routing simulation a new comprehensive evaluation model was established to quantify evacuation potential such as the time required for evacuation and the effective evacuation positions while estimating lol caused by a dam breach 2 materials and methods 2 1 study areas the luhun reservoir is located in songxian county henan province china on the upper reaches of the yihe river a tributary of the yellow river the luhun reservoir focuses on flood control irrigation power generation water supply and tourism it has a capacity of 1 316 billion m3 whose designed flood standard is a 1 000 year event and the checking flood standard is a 10 000 year event the primary dam is an earth rock dam with a maximum height of 55 m and the terrain from the dam site to longmen grottoes is primarily hilly and shallow with open mountains on either side and flat terrain in the middle most residents live near rivers and the others are sparsely distributed in mountainous areas far away from the rivers secondary and arterial roads constitute the main roads whereas higher traffic capacity roads such as motorways trunk roads and primary roads are fewer the downstream areas of longmen grottoes are the primary locations of schools enterprises and government agencies with open terrain dense population and well developed transportation as shown in fig 1 2 2 analysis of lol caused by dam breaches ehsan 2009 developed an improved method for lol estimation in which all main influencing factors were incorporated in a detailed manner for lol estimation based on the ehsan s model an improved lol evaluation model was proposed by using a different approach which can not only accurately evaluate the lol but also put forward effective evacuation suggestions 2 2 1 analysis of influencing factors of lol the main factors were summarized from the papers of ehsan et al 2009 2013 2014 and then some factors were screened and replaced according to our aim and actual situation for example when evacuating by walking the fage age risk factor and fh health risk factor of the par affects the evacuation speed however due to the difficulty in quantifying the impact and the lack of detailed statistical data in the study area the fage and fh were not taken into account in this study considering whether the factors are easy to quantify or not the fev ease of evacuation factor was expressed by transportation modes mt and transportation network nt fmt material risk factor and fst storey risk factor were expressed by the vulnerability of buildings vb according to the disaster theory the influencing factors were determined from three aspects i e disaster causing factors disaster affected bodies and disaster prone environments wu et al 2021 ensuring that the selected influencing factors systematically and comprehensively reflect the lol 2 2 1 1 disaster causing factors disaster causing factors refer to flood caused by dam breaches the product of flood depth d and velocity v reflects flood severity sf qi and altinakar 2012 and determines the mortality of the exposed population popexp to flood which can be quantified by the mortality function fm jonkman et al 2008 2 2 1 2 disaster affected bodies disaster affected bodies refer to the par without the par there would be no lol regardless of the severity of the flood in the case of flood evacuation is the most effective choice for saving the population according to urbanik 2000 the par require a certain response time tr to evacuate which has a significant impact on the evacuation 2 2 1 3 disaster prone environments disaster prone environments refer to the environmental characteristic factors downstream where the disaster affected bodies are located the warning time tw transportation modes mt and transportation network nt are the key factors that affect the evacuation of the par cheng et al 2011 in addition the downstream buildings provide the primary shelters for the par thus building vulnerability vb is significant rescdam 2000 yang et al 2021 2 2 2 analysis of the formation process of lol the process of lol caused by a dam breach was determined based on the disaster causing mechanism and the interrelationship among the influencing factors ge et al 2021 as shown in fig 2 based on fig 2 the specific lol process can be divided into six stages 1 a dam breach causes flood flood caused by damage to the dam body or auxiliary structures owing to overtopping quality problems improper management and so on pose significant threats to the safety of the downstream population 2 flood puts par the number of par is mainly related to the flood inundation areas and distribution state of the downstream population according to sun et al 2014 and penning rowsell et al 2005 the residents located in the downstream potential submerged areas can be defined as the par 3 par complete the preparation work before evacuation the preparation work of the par consists of two parts receiving the warning and responding the proportion of the population who have completed the preparation work to par can be defined as the preparedness rate rp therefore the number of the population who have completed the preparation work poppre can be calculated by eq 1 the population who have not completed the preparation work becomes a part of the un evacuated population popun eva 1 po p pre p a r r p 4 par evacuate from flood affected areas the proportion of the evacuated population popeva who have reached safe areas before the flood arrives to the poppre can be defined as the evacuation rate re as expressed in eq 2 those who fail to evacuate to safe areas become another part of the popun eva 2 r e popeva poppre 5 popun eva shelter themselves inside buildings the popun eva shelter themselves inside the surrounding buildings certain buildings resist the impact of flood successfully so that the people taking shelter can survive the proportion of the population successfully sheltered popshel to popun eva can be defined as the shelter rate rs which can be approximately expressed by the proportion of damage to the buildings as expressed in eq 3 3 r s po p shel po p un e v a nu m un d e s t numtot where numun dest is the number of buildings that successfully resist the impact of flood and numtot is the total number of buildings that face the flood respectively 6 flood causes the death of the popexp the other buildings are destroyed causing the population that has taken shelter in them to become the popexp a portion of the popexp loses their lives owing to the flood setting fm as the mortality of the popexp the lol can be calculated by eq 4 4 lol p o p exp f m according to eq 1 eq 4 the lol caused by a dam breach can be calculated by eq 5 5 lol p a r 1 r p r e 1 r s f m where par and fm are determined by the flood caused by a dam breach and rp re rs are used to describe the evacuation potential of the par under the threat of flood therefore an accurate simulation of the dam breach flood and the population evacuation potential are the foundation and key to estimating the lol 2 3 simulation of dam breach flood and their effects on lol 2 3 1 simulation of dam breach flood the hydrologic engineering center s river analysis system hec ras hydrodynamic model has been widely used because of its easy operation and complete function it was developed by the hydrologic engineering center of the us army corps of engineers and its primary functions include water surface line calculation of constant flow unsteady flow simulation sediment transport calculation of movable boundaries and water quality analysis united states army corps of engineers 2016 in this study a two dimensional model of unsteady flow was selected to simulate the dam breach flood the main dam of the luhun reservoir is an earth rock dam in general three types of damage that lead to breaches in earth rock dams are carrivick et al 2011 abdedou et al 2020 a overtopping caused by excessive flood during the monsoons b seepage piping and other factors under regular water level conditions during the non flood season and c certain other factors for example earthquakes and wars relevant statistics indicate that overtopping is the primary cause for the breach of an earth rock dam zhao et al 2020 furthermore as these dams are broken gradually most breaches are transverse partial ones peter et al 2018 walder et al 2015 lee 2019 currently there is no authoritative estimation method for the vertical breach height wang et al 2018 for safety the worst situation of breaching at the bottom of the dam was considered therefore the simulation condition of the luhun reservoir dam breach was set as follows overtopping caused a dam breach with horizontal local and vertical dam breaks to the bottom while simulating the flood caused by a dam breach the effects of various types of land on flood routing were also considered the downstream terrain was divided into 50 m 50 m computational grids and the manning coefficient n was assigned dazzi et al 2019 chen et al 2020 2 3 2 determination of the number of the par the number of par primarily depends on the area submerged by the dam breach flood and the distribution of the population in the submerged areas where the reservoir capacity is small or the population density is low the par in the downstream inundation area is relatively small hence in many countries or regions the par distribution at various times and seasons can be obtained through typical surveys and census data however for the luhun reservoir with a capacity of 1 316 billion m3 it is difficult to analyze the population distribution of each place in detail because of the large potential submerged areas therefore the par in a certain area can be regarded as a point and the total par can be obtained by determining the population at each point zhou et al 2007 as expressed in eq 6 6 par i 1 n pari where n is the number of submerged settlements and pari is the size of the population in the ith settlement 2 3 3 determination of the mortality of the popexp the mortality of popexp approximately follows a normal distribution based on the characteristics of the flood the inundated areas were divided into the breach zone zone i zone with rapidly rising water zone ii and remaining zone zone iii each zone had a corresponding mortality function fm jonkman et al 2008 a breach zone owing to the high flow velocities and forces the flood in such areas is extremely destructive when sf 7 m2 s and v 2 m s the buildings will collapse and people will lose their stability simultaneously fm can be considered a constant value as expressed shown in eq 7 7 fm 1 b zone with rapidly rising water the flood intensity in such areas is lower than that in zone i the popexp has the potential to survive but it is significantly affected by the flood rising speed sr when sr 0 5 m h people have little time to escape because the rapid increase in the level of water is particularly hazardous according to peng et al 2012 d 2 1 m and sr 0 5 m h are the lower limits of zone ii and the corresponding fm can be calculated by eq 8 8 fm φ n ln d 1 46 0 28 where φ n is the cumulative normal distribution function c remaining zone in such areas the flood intensity is significantly weakened and the probability of people s survival is likely to be higher the corresponding fm can be calculated by eq 9 9 fm φ n ln d 7 6 2 75 where φ n is the cumulative normal distribution function 2 4 simulation of evacuation potential of par 2 4 1 determination of the rp people receive warning messages from various channels such as the government relatives and friends electronic media radio and social software therefore a certain warning time tw is required in addition after receiving the warning a certain response time tr is also required for people to notify their relatives and friends return home from work wait for the family members and pack luggage kuller et al 2021 it was assumed that the probability distributions of these two events were mutually independent and the probability of each successive event relied on the probability distribution of the activities that preceded it thus the probability of completing the two events is equal to the product of the probabilities of completing each event as shown in table 1 urbanik 2000 xue et al 2019 based on table 1 t 15 min may be composed of 5 min of receiving warning time and 10 min of response time or 10 min of receiving warning time and 5 min of response time therefore the probability of t 15 min is the sum of these two possibilities the probability of other values of t can be determined similarly and the probability distribution of rp can be obtained by accumulation as shown in table 2 2 4 2 determination of the re of par evacuation is a complicated process that is impacted by various factors such as traffic conditions evacuation methods and evacuation routes cheng et al 2011 the population distribution and shelter location in residential areas were simplified as points and the local roads were simplified as lines considering the submerged residential areas as the starting points and the evacuation positions that are not submerged as the end points an od origin destination matrix was established in the gis time is the primary consideration in the process of emergency evacuation thus the matrix was solved at the cost of time in developed countries most residents are evacuated by their own private cars fm et al 2018 however in china owing to low private car ownership a large number of residents have to choose other means of evacuation in addition dam failure usually occurs suddenly in extreme circumstances the government may not have enough time to organize an evacuation therefore it was assumed that the par can evacuate by cars motorcycles and bicycles as well as by walking the evacuation time is related to the road capacity and traffic conditions based on an investigation on a large number of road sections the bureau of public roads 2009 of the united states of america obtained the functional relationship between driving time and the traffic load i e the bpr function as expressed in eq 10 10 t t 0 1 α q c β where t is the driving time of the vehicle on the road section t 0 is the driving time of the free flow of the road section q is the traffic flow of the road section c is the design capacity of the road section α 0 15 and β 4 0 during the process of evacuation the traffic lights at the intersections are mainly controlled by the government which can be ignored however pedestrians crossing the road may cause a greater disturbance to the traffic therefore the coefficient μ was used to correct v 0 as expressed in eq 11 and eq 12 11 t 0 l v 12 v μ v 0 where l is the length of the road section v is the driving speed on the road section l μ is the pedestrian interference coefficient and v 0 is the design speed of the road section the value standard of μ is shown in table 3 cheng et al 2011 without any interference the average speeds of walking cycling and motorcycle evacuation are 6 16 and 50 km h respectively wang and song 2014 however owing to the poor traffic capacity of certain roads it is often difficult to reach the ideal speed therefore the road speed limit which has a significant relationship with the traffic capacity was set as the upper limit of the evacuation speed for example when driving on a road with a speed limit of 20 km h evacuees can reach the ideal average speed of walking or cycling whereas while riding a motorcycle they can only reach a maximum speed of 20 km h the evacuation time required on each road can be determined by dividing the length of the road by the average driving speed on it if the available time is longer than the required time that is the flood arrival time warning time response time time required for evacuation the population can be considered to evacuate successfully hence re can be calculated by eq 2 2 4 3 determination of the rs of popun eva in areas where buildings collapse or safe shelters cannot be provided significant lol may occur the par require a short time to shelter themselves inside their own or nearby buildings therefore it can be assumed that they have been evenly distributed among the buildings before the flood arrives whether a building is damaged or not is mainly determined by flood intensity and building vulnerability the rescdam project 2000 tested the damage caused to buildings in flood and proposed standards accordingly wang and song 2014 established china s building damage standard based on the relevant results as shown in table 4 according to table 4 the vulnerability of buildings is mainly related to their constituent materials and floors material information can be obtained through satellites remote sensing data or surveys in the study area the floor information can be converted from the building vector data the building vector data include the underside contour and height spatial distribution information which can be converted into floor information based on the corresponding criteria yu and wen 2016 as shown in table 5 whether the buildings were damaged or not can be determined based on the superimposition of the building vector data which have been converted into layers with the flood division based on the building damage criteria specified in the gis it is worth noting that one building may be in multiple damaged areas simultaneously and it should be judged based on the most unfavorable situation for example in three story building destruction areas buildings with three floors or less will be destroyed and buildings with more than three floors will not be destroyed a two story building is considered to be damaged if it is in the damaged area of both two story and three story buildings the number of buildings destroyed in each residential area can be counted using the frequency statistics function of the gis therefore the rs of the popun eva can be calculated by eq 3 3 results 3 1 simulation results of dam breach flood based on the simulation results of dam breach flood the maximum width of the breach is reached after 1 35 h final bottom width is 165 m and maximum flow of the breach is 57 769 m3 s the flood reached yichuan county after 0 8 h and longmen grottoes in luolong county after 3 6 h in the longmen grottoes region affected by its narrow valley and low lying terrain the water depth reached a maximum of approximately 29 m and the flow velocity in the center of the river increased sharply to approximately 23 m s beyond longmen grottoes owing to the flat and open terrain downstream the flood begins to spread and the flow velocity gradually slows down and it reaches yanshi county after 8 7 h the total submerged area in luoyang is approximately 291 km2 primarily involving 14 residential areas in songxian county yichuan county luolong county and yanshi county the locations listed in the order of their distances from the dam site from near to far are as follows minggao town a baiyuan town b chengguan town c pengpo town d longmen grottoes left bank e longmen grottoes right bank f longmen town g zhuge town h taikang east road i lilou town j dianzhuang town k pangcun town l zhai town m and yuetan town n the inundation situation is shown in fig 3 3 2 simulation results of par evacuation potential the ownership rate of private cars in luoyang city where the luhun reservoir is located is 19 6 according to cova and johnson 2015 each car can take two to three people 2 5 is selected owing to the lack of detailed statistics it was assumed that the residents give priority to cars whereas the remaining people were evacuated on average using motorcycles and bicycles and by walking thus the proportion of residents evacuated using cars was 49 and that for the other three methods was 17 the time required for evacuation of the par in each town was calculated by the od matrix as shown in fig 4 three conditions were assumed each town issued a warning message 0 0 5 and 1 h before the flood arrived by combining the time required for evacuation the maximum time allowed for the population to complete the preparation work can be calculated at this time the corresponding preparation rate rp is the proportion of the par that can be successfully evacuated that is the re through information from the building vector data converted into floors it was found that there were almost no bungalows in the submerged area nowadays buildings in the downstream area are all constructed from either bricks or concrete taking chengguan town of yichuan county as an example the damage to the buildings in this area is shown in fig 5 and the rs can be calculated by eq 3 3 3 results of estimation of lol based on the results of simulation of flood routing and population evacuation potential the results of estimation of the lol in each town are shown in table 6 4 discussion 4 1 comparison with ehsan s model ehsan 2009 proposed a method for calculation lol as expressed in eq 13 13 lo l i p a r i f a t base f sv f age f mt f st f h f war f ev where loli loss of life at a particular location i downstream of the dam pari population at risk at a particular location i downstream of the dam fatbase base fatality rate of 0 15 fsv flood severity factor fage age risk factor fmt material risk factor fst storey risk factor fh health risk factor fwar warning factor fev ease of evacuation factor ehsan s model was applied to the case of this study to calculate the lol under different warning time the value of the coefficients and the results of lol are shown in table 7 comparison between the estimation results of ehsan s model and the proposed model was made as shown in table 8 according to table 8 the mortality of the proposed model is larger than the ehsan s model which is caused by the following reasons a due to the different national conditions the models of other countries are not necessarily suitable for direct application to china for example in the ehsan s method the value of fst is 14 fst 1 for h i g h s e v e r i t y a n d a l l t y p e s o f h o u s e s 15 fst 1 s for m e d i u m a n d l o w s e v e r i t y where s of more story houses however there may be great differences in the standards of the construction industry the structure and materials of houses in different countries therefore when judging the damage of houses in the flood the standards for houses damage in china as shown in table 4 were used in the proposed model which led to the difference in the evaluation results between the proposed model and ehsan s model b when ehsan s model was used to calculate the lol in study case fsv 0 3 was taken in all medium flood severity areas however the special topography of luhun reservoir leads to more serious flood the flood severity in many areas is of medium severity but very close to high severity at this time fsv 0 8 or 0 9 is more suitable the proposed model took this situation into account in more detail so the results are larger than ehsan s model furthermore the proposed model is more sensitive to water depth d in the same flood severity areas the value of fatbase in ehsan s model is the constant but the value of fm in the proposed model increases with the increasement of d therefore based on the proposed method the calculation results of luhun reservoir with deep flood in the downstream are larger c ehsan s model lays the foundation for the accurate assessment of lol combined with the above comparison it is suggested that when using the ehsan s model the selection of parameters can be analyzed more carefully so as to further improve the accuracy of the results 4 2 comparison with li zhou model based on the actual situation prevailing in china considering the graham method and certain other influencing factors zhou et al 2007 presented the mortality table of the par for estimating the lol caused by dam breaches in china the results of estimation obtained from the model proposed in this study were compared with those of li zhou model as shown in table9 according to table 9 when the warning time for town b is 0 5 h and those of towns j and n are 0 h the estimation results are not within the scope of the li zhou model however this situation can be attributed to specific reasons town b baiyuan town is a rural area where the proportion of houses with more floors is much lower than that in urban areas only approximately 55 of the houses could effectively resist flood in the area hence most of the popun eva are exposed to the flood leading to a significant lol the values of sf for towns j lilou town and n yuetan town are medium primarily because of its large water depth however the flow velocity is small and the impact of the flood on the houses and the popexp is limited thus it will not cause serious casualties the results of the estimation for other towns under various warning times are all within the scope of the li zhou model which verifies the accuracy of the proposed model 4 3 analysis of the simulation results a according to fig 4 town a minggao town and town l pangcun town require the maximum amount of time for complete evacuation at 210 and 187 min respectively town a is closest to the dam site among the 14 residential towns the dam breach flood arrives within 50 min which is far less than the time required for evacuation therefore the relevant departments should prioritize the evacuation town l is far from the dam site and the flood arrives late if the early warning is timely the population will have sufficient time to evacuate the time required for complete evacuation of other towns is within 130 min and the longest is 128 min among these the towns with longer evacuation times are town d pengpo town town f longmen grottoes right bank town k dianzhuang town and town m zhai town which take 124 117 126 and 128 min respectively to reduce the potential lol as much as possible the relevant departments should issue early warnings and properly arrange the evacuation sequence for residents based on the flood arrival time and the amount of time required for evacuation b it is worth noting that if a flood disaster occurs most residents in luolong county will be evacuated to hetaoyuan park luopu park luolong and luoyang sports center the red positions displayed in fig 6 which may cause overcrowding it is recommended that after properly attending to the injured some people should be transferred to nearby locations such as mangshan sports park peony park xiyuan park peony square and the shangyang branch of wangcheng primary school the blue positions displayed in fig 6 in addition fig 3 indicates that yichuan county has less capacity for receiving evacuees than luolong county which makes it inconvenient for the evacuation therefore the relevant departments should set up temporary camps in the surrounding unsubmerged highlands to provide living supplies and medical assistance to asylum seekers c as compared with the existing methods this model can not only estimate the lol caused by dam breaches but also quantify significant information such as evacuation time and effective shelter location to facilitate the relevant departments in formulating effective evacuation strategies in addition unexpected situations may occur in the actual evacuation process such as road obstruction or impassability owing to traffic accidents broken trees and falling stones and prohibited areas owing to the location of chemical enterprises prisons or military bases to handle the impact of these emergencies measures such as road blocking or traffic bans can be set up at the corresponding positions of the vector data in the gis d the results of the estimation obtained from the proposed model are significantly affected by the accuracy of the flood characteristics because of the significant effects of the breach parameters and downstream roughness on the accuracy of the flood simulation parameter selection and processing should be adjusted based on the specific conditions further extreme weather such as rainstorms fog and hail has an adverse impact on the evacuation of the par and the model can be further refined in combination with other relevant studies 5 conclusion according to the analysis of influencing factors and formation process of lol a new comprehensive evaluation model was proposed in which the parameters were quantified based on flood routing and population evacuation potential simulation the hec ras was used to simulate the flood caused by dam breaches and determine the number of par and the mortality of the popexp the gis and related vector data were used to simulate the evacuation potential of par in which the rp re and rs were quantified taking 14 towns downstream of the luhun reservoir in luoyang china as an example the estimation results of the proposed model were compared with those obtained from the two existing methods indicating that the proposed model can effectively determine the potential lol caused by dam breaches in china which provides a reference for the relevant departments to formulate emergency plans credit authorship contribution statement wei ge conceptualization formal analysis writing review editing yutie jiao conceptualization formal analysis writing original draft meimei wu conceptualization methodology validation formal analysis writing original draft zongkun li methodology investigation funding acquisition te wang methodology writing review editing wei li validation supervision yadong zhang validation weixing gao investigation funding acquisition pieter van gelder supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the national natural sciencefoundation of china grant no 52079127 52179144 u2040224 51679222 51709239 the fund of national dam safety research center grant no cx2021b01 program for science technology innovation talents in universities of henan province hastit grant no 22hastit011 the young talent support project of henan province grant no 2021hytp024 and the programs for science and technology development of henan educational committee grant no 202102310394 
3187,dam breaches often have catastrophic consequences in downstream areas hydrodynamic factors and the evacuation potential of the population at risk par have significant impacts on the loss of life lol caused by dam breaches however the existing comprehensive evaluation models have not conducted in depth research on the evacuation potential of populations thus limited guidance is available for relevant departments to formulate emergency plans to reduce the potential lol therefore a new comprehensive evaluation model was proposed in this study according to the relevant references and disaster theory the main influencing factors and the process through which the lol is caused by dam breaches were determined the specific occurrence process was divided into six stages a dam breach causes flood the flood puts the par the par complete the preparation work the par evacuate the un evacuated population shelter themselves inside buildings and flood causes the death of the exposed population to calculate the lol the parameters relevant at each stage were defined furthermore the hydrologic engineering center s river analysis system geographic information system and related materials were used to simulate the flood routing and evacuation potential of the par quantifying the parameters in the model the model was applied to 14 towns in the downstream areas of the luhun reservoir in henan province china and its accuracy was verified by comparing the results obtained from the two existing models in addition the specific suggestions for reducing the potential lol were proposed based on the results of the simulation keywords dam breach loss of life disaster causing mechanism evacuation potential emergency plan 1 introduction dam service flood control navigation power generation and irrigation have significant economic benefits latrubesse et al 2017 however once a dam breach occurs it has disastrous consequences in downstream areas ge et al 2020a pathak et al 2020 zeng et al 2019 according to li et al 2019 china had an average of 57 9 dam breaches per year from 1954 to 2014 although there has been significant improvement in the project quality and management level in recent years dam breaches still occur from time to time owing to natural disasters human factors and strength loss caused by long term disrepair ge et al 2020b thrysøe et al 2021 in july 2018 at least 20 people were killed and more than 100 went missing owing to the flood caused by the collapse of a dam under construction which was a part of the xe pian xe namnoy hydroelectric power project in southeast laos kim and lee 2020 in august 2018 heavy rains caused the dam breach of the sheyuegou reservoir in xinjiang china leading to 20 deaths and 8 missing beijing news 2018 in may 2020 the sardoba reservoir in sirdaryo viloyati uzbekistan broke because of a typhoon and led to the evacuation of approximately 70 000 residents 4 deaths and 56 injuries xinhuanet 2020 in may 2020 the edenville dam in the united states broke due to its poor condition and heavy rainfall causing more than 10 000 people forced to evacuate urgently consequently the potential loss of life lol caused by dam breaches has always attracted the attention of researchers aboelata et al 2003 lumbroso et al 2011 2021 johnstone and garrett 2014 ge et al 2017 georges et al 2019 generally empirical models which established by regression analysis of historical dam breach events were used to establish the functional relationship between the lol and certain key parameters brown and graham 1988 proposed a method for predicting the lol based on the analysis of the population at risk par and the warning time tw considering the various levels of severity of dam breach flood dekay and mcclelland 1993 proposed a formula for estimating the nonlinear relationship between the lol and par graham 1999 added the degree of understanding of the dam breach to the influencing factors and proposed the mortality of the par based on graham 1999 zhou et al 2007 analyzed the data of eight dams in china and established a corresponding assessment model of the lol caused by dam breaches the u s department of the interior bureau of reclamation 2015 has proposed a new method to replace the graham method to estimate the lol despite their easy application most empirical models often have limited use owing to the low availability of the historical dataset jonkman et al 2008 recently the physical models which focus on the formation mechanism analysis of the lol have gradually become research hotspots assaf and hartford 2002 developed a virtual reality approach bc hydro s life safety model lsm to deal with the problems of failure consequence analysis and emergency planning aboelata and bowles 2008 established the lifesim model to evaluate the lol of greater new orleans lumbroso et al 2011 2021 applied the lsm model to malapasset dam canvey island and brumadinho tailings dam combined with monte carlo accurately estimated the possible lol and put forward effective emergency management measures this kind of agent based physical models can simulate countless possible scenarios that may be caused by flood and make effective security decisions however this kind of models have high requirements for data and operation users therefore the comprehensive evaluation models have begun in prosperity jonkman et al 2008 developed a new function related to mortality to estimate the lol caused by flood disasters in low lying areas ehsan 2009 developed an improved method for lol estimation in addition he also discussed the definitions of two flood severity and proposed a new definition of flood severity by using the method of geometric aggregate ga considering more factors affecting the lol and the relationships among them peng and zhang 2012 constructed the huram model based on the bayes model based on data obtained from 14 dam failure cases in china huang et al 2017 proposed a new method for estimating the lol using a three dimensional stratified sampling method li et al 2018 analyzed the weights of the primary factors that affect the consequences of dam breaches using set pair analysis and the variable fuzzy set theory considering the extensive changes and effects of the various factors ge et al 2019 2021 constructed a rapid evaluation model based on the catastrophe theory and used the interval theory to effectively determine the possible upper and lower limits of lol caused by dam breaches rather than a certain value these comprehensive evaluation models focus on the innovation and application of mathematical methods improving the accuracy compared with the empirical models significantly however owing to the lack of in depth analysis of the evacuation potential of the par they are unable to quantify certain critical types of information as effectively as the physical models such as the time required for evacuation shortest roads that can be used for evacuation and the effective evacuation positions resulting in deficiencies in guiding the relevant departments to formulate emergency plans therefore in order to facilitate application and provide reference and basis for formulating emergency evacuation plan to reduce potential lol combined with flood routing simulation a new comprehensive evaluation model was established to quantify evacuation potential such as the time required for evacuation and the effective evacuation positions while estimating lol caused by a dam breach 2 materials and methods 2 1 study areas the luhun reservoir is located in songxian county henan province china on the upper reaches of the yihe river a tributary of the yellow river the luhun reservoir focuses on flood control irrigation power generation water supply and tourism it has a capacity of 1 316 billion m3 whose designed flood standard is a 1 000 year event and the checking flood standard is a 10 000 year event the primary dam is an earth rock dam with a maximum height of 55 m and the terrain from the dam site to longmen grottoes is primarily hilly and shallow with open mountains on either side and flat terrain in the middle most residents live near rivers and the others are sparsely distributed in mountainous areas far away from the rivers secondary and arterial roads constitute the main roads whereas higher traffic capacity roads such as motorways trunk roads and primary roads are fewer the downstream areas of longmen grottoes are the primary locations of schools enterprises and government agencies with open terrain dense population and well developed transportation as shown in fig 1 2 2 analysis of lol caused by dam breaches ehsan 2009 developed an improved method for lol estimation in which all main influencing factors were incorporated in a detailed manner for lol estimation based on the ehsan s model an improved lol evaluation model was proposed by using a different approach which can not only accurately evaluate the lol but also put forward effective evacuation suggestions 2 2 1 analysis of influencing factors of lol the main factors were summarized from the papers of ehsan et al 2009 2013 2014 and then some factors were screened and replaced according to our aim and actual situation for example when evacuating by walking the fage age risk factor and fh health risk factor of the par affects the evacuation speed however due to the difficulty in quantifying the impact and the lack of detailed statistical data in the study area the fage and fh were not taken into account in this study considering whether the factors are easy to quantify or not the fev ease of evacuation factor was expressed by transportation modes mt and transportation network nt fmt material risk factor and fst storey risk factor were expressed by the vulnerability of buildings vb according to the disaster theory the influencing factors were determined from three aspects i e disaster causing factors disaster affected bodies and disaster prone environments wu et al 2021 ensuring that the selected influencing factors systematically and comprehensively reflect the lol 2 2 1 1 disaster causing factors disaster causing factors refer to flood caused by dam breaches the product of flood depth d and velocity v reflects flood severity sf qi and altinakar 2012 and determines the mortality of the exposed population popexp to flood which can be quantified by the mortality function fm jonkman et al 2008 2 2 1 2 disaster affected bodies disaster affected bodies refer to the par without the par there would be no lol regardless of the severity of the flood in the case of flood evacuation is the most effective choice for saving the population according to urbanik 2000 the par require a certain response time tr to evacuate which has a significant impact on the evacuation 2 2 1 3 disaster prone environments disaster prone environments refer to the environmental characteristic factors downstream where the disaster affected bodies are located the warning time tw transportation modes mt and transportation network nt are the key factors that affect the evacuation of the par cheng et al 2011 in addition the downstream buildings provide the primary shelters for the par thus building vulnerability vb is significant rescdam 2000 yang et al 2021 2 2 2 analysis of the formation process of lol the process of lol caused by a dam breach was determined based on the disaster causing mechanism and the interrelationship among the influencing factors ge et al 2021 as shown in fig 2 based on fig 2 the specific lol process can be divided into six stages 1 a dam breach causes flood flood caused by damage to the dam body or auxiliary structures owing to overtopping quality problems improper management and so on pose significant threats to the safety of the downstream population 2 flood puts par the number of par is mainly related to the flood inundation areas and distribution state of the downstream population according to sun et al 2014 and penning rowsell et al 2005 the residents located in the downstream potential submerged areas can be defined as the par 3 par complete the preparation work before evacuation the preparation work of the par consists of two parts receiving the warning and responding the proportion of the population who have completed the preparation work to par can be defined as the preparedness rate rp therefore the number of the population who have completed the preparation work poppre can be calculated by eq 1 the population who have not completed the preparation work becomes a part of the un evacuated population popun eva 1 po p pre p a r r p 4 par evacuate from flood affected areas the proportion of the evacuated population popeva who have reached safe areas before the flood arrives to the poppre can be defined as the evacuation rate re as expressed in eq 2 those who fail to evacuate to safe areas become another part of the popun eva 2 r e popeva poppre 5 popun eva shelter themselves inside buildings the popun eva shelter themselves inside the surrounding buildings certain buildings resist the impact of flood successfully so that the people taking shelter can survive the proportion of the population successfully sheltered popshel to popun eva can be defined as the shelter rate rs which can be approximately expressed by the proportion of damage to the buildings as expressed in eq 3 3 r s po p shel po p un e v a nu m un d e s t numtot where numun dest is the number of buildings that successfully resist the impact of flood and numtot is the total number of buildings that face the flood respectively 6 flood causes the death of the popexp the other buildings are destroyed causing the population that has taken shelter in them to become the popexp a portion of the popexp loses their lives owing to the flood setting fm as the mortality of the popexp the lol can be calculated by eq 4 4 lol p o p exp f m according to eq 1 eq 4 the lol caused by a dam breach can be calculated by eq 5 5 lol p a r 1 r p r e 1 r s f m where par and fm are determined by the flood caused by a dam breach and rp re rs are used to describe the evacuation potential of the par under the threat of flood therefore an accurate simulation of the dam breach flood and the population evacuation potential are the foundation and key to estimating the lol 2 3 simulation of dam breach flood and their effects on lol 2 3 1 simulation of dam breach flood the hydrologic engineering center s river analysis system hec ras hydrodynamic model has been widely used because of its easy operation and complete function it was developed by the hydrologic engineering center of the us army corps of engineers and its primary functions include water surface line calculation of constant flow unsteady flow simulation sediment transport calculation of movable boundaries and water quality analysis united states army corps of engineers 2016 in this study a two dimensional model of unsteady flow was selected to simulate the dam breach flood the main dam of the luhun reservoir is an earth rock dam in general three types of damage that lead to breaches in earth rock dams are carrivick et al 2011 abdedou et al 2020 a overtopping caused by excessive flood during the monsoons b seepage piping and other factors under regular water level conditions during the non flood season and c certain other factors for example earthquakes and wars relevant statistics indicate that overtopping is the primary cause for the breach of an earth rock dam zhao et al 2020 furthermore as these dams are broken gradually most breaches are transverse partial ones peter et al 2018 walder et al 2015 lee 2019 currently there is no authoritative estimation method for the vertical breach height wang et al 2018 for safety the worst situation of breaching at the bottom of the dam was considered therefore the simulation condition of the luhun reservoir dam breach was set as follows overtopping caused a dam breach with horizontal local and vertical dam breaks to the bottom while simulating the flood caused by a dam breach the effects of various types of land on flood routing were also considered the downstream terrain was divided into 50 m 50 m computational grids and the manning coefficient n was assigned dazzi et al 2019 chen et al 2020 2 3 2 determination of the number of the par the number of par primarily depends on the area submerged by the dam breach flood and the distribution of the population in the submerged areas where the reservoir capacity is small or the population density is low the par in the downstream inundation area is relatively small hence in many countries or regions the par distribution at various times and seasons can be obtained through typical surveys and census data however for the luhun reservoir with a capacity of 1 316 billion m3 it is difficult to analyze the population distribution of each place in detail because of the large potential submerged areas therefore the par in a certain area can be regarded as a point and the total par can be obtained by determining the population at each point zhou et al 2007 as expressed in eq 6 6 par i 1 n pari where n is the number of submerged settlements and pari is the size of the population in the ith settlement 2 3 3 determination of the mortality of the popexp the mortality of popexp approximately follows a normal distribution based on the characteristics of the flood the inundated areas were divided into the breach zone zone i zone with rapidly rising water zone ii and remaining zone zone iii each zone had a corresponding mortality function fm jonkman et al 2008 a breach zone owing to the high flow velocities and forces the flood in such areas is extremely destructive when sf 7 m2 s and v 2 m s the buildings will collapse and people will lose their stability simultaneously fm can be considered a constant value as expressed shown in eq 7 7 fm 1 b zone with rapidly rising water the flood intensity in such areas is lower than that in zone i the popexp has the potential to survive but it is significantly affected by the flood rising speed sr when sr 0 5 m h people have little time to escape because the rapid increase in the level of water is particularly hazardous according to peng et al 2012 d 2 1 m and sr 0 5 m h are the lower limits of zone ii and the corresponding fm can be calculated by eq 8 8 fm φ n ln d 1 46 0 28 where φ n is the cumulative normal distribution function c remaining zone in such areas the flood intensity is significantly weakened and the probability of people s survival is likely to be higher the corresponding fm can be calculated by eq 9 9 fm φ n ln d 7 6 2 75 where φ n is the cumulative normal distribution function 2 4 simulation of evacuation potential of par 2 4 1 determination of the rp people receive warning messages from various channels such as the government relatives and friends electronic media radio and social software therefore a certain warning time tw is required in addition after receiving the warning a certain response time tr is also required for people to notify their relatives and friends return home from work wait for the family members and pack luggage kuller et al 2021 it was assumed that the probability distributions of these two events were mutually independent and the probability of each successive event relied on the probability distribution of the activities that preceded it thus the probability of completing the two events is equal to the product of the probabilities of completing each event as shown in table 1 urbanik 2000 xue et al 2019 based on table 1 t 15 min may be composed of 5 min of receiving warning time and 10 min of response time or 10 min of receiving warning time and 5 min of response time therefore the probability of t 15 min is the sum of these two possibilities the probability of other values of t can be determined similarly and the probability distribution of rp can be obtained by accumulation as shown in table 2 2 4 2 determination of the re of par evacuation is a complicated process that is impacted by various factors such as traffic conditions evacuation methods and evacuation routes cheng et al 2011 the population distribution and shelter location in residential areas were simplified as points and the local roads were simplified as lines considering the submerged residential areas as the starting points and the evacuation positions that are not submerged as the end points an od origin destination matrix was established in the gis time is the primary consideration in the process of emergency evacuation thus the matrix was solved at the cost of time in developed countries most residents are evacuated by their own private cars fm et al 2018 however in china owing to low private car ownership a large number of residents have to choose other means of evacuation in addition dam failure usually occurs suddenly in extreme circumstances the government may not have enough time to organize an evacuation therefore it was assumed that the par can evacuate by cars motorcycles and bicycles as well as by walking the evacuation time is related to the road capacity and traffic conditions based on an investigation on a large number of road sections the bureau of public roads 2009 of the united states of america obtained the functional relationship between driving time and the traffic load i e the bpr function as expressed in eq 10 10 t t 0 1 α q c β where t is the driving time of the vehicle on the road section t 0 is the driving time of the free flow of the road section q is the traffic flow of the road section c is the design capacity of the road section α 0 15 and β 4 0 during the process of evacuation the traffic lights at the intersections are mainly controlled by the government which can be ignored however pedestrians crossing the road may cause a greater disturbance to the traffic therefore the coefficient μ was used to correct v 0 as expressed in eq 11 and eq 12 11 t 0 l v 12 v μ v 0 where l is the length of the road section v is the driving speed on the road section l μ is the pedestrian interference coefficient and v 0 is the design speed of the road section the value standard of μ is shown in table 3 cheng et al 2011 without any interference the average speeds of walking cycling and motorcycle evacuation are 6 16 and 50 km h respectively wang and song 2014 however owing to the poor traffic capacity of certain roads it is often difficult to reach the ideal speed therefore the road speed limit which has a significant relationship with the traffic capacity was set as the upper limit of the evacuation speed for example when driving on a road with a speed limit of 20 km h evacuees can reach the ideal average speed of walking or cycling whereas while riding a motorcycle they can only reach a maximum speed of 20 km h the evacuation time required on each road can be determined by dividing the length of the road by the average driving speed on it if the available time is longer than the required time that is the flood arrival time warning time response time time required for evacuation the population can be considered to evacuate successfully hence re can be calculated by eq 2 2 4 3 determination of the rs of popun eva in areas where buildings collapse or safe shelters cannot be provided significant lol may occur the par require a short time to shelter themselves inside their own or nearby buildings therefore it can be assumed that they have been evenly distributed among the buildings before the flood arrives whether a building is damaged or not is mainly determined by flood intensity and building vulnerability the rescdam project 2000 tested the damage caused to buildings in flood and proposed standards accordingly wang and song 2014 established china s building damage standard based on the relevant results as shown in table 4 according to table 4 the vulnerability of buildings is mainly related to their constituent materials and floors material information can be obtained through satellites remote sensing data or surveys in the study area the floor information can be converted from the building vector data the building vector data include the underside contour and height spatial distribution information which can be converted into floor information based on the corresponding criteria yu and wen 2016 as shown in table 5 whether the buildings were damaged or not can be determined based on the superimposition of the building vector data which have been converted into layers with the flood division based on the building damage criteria specified in the gis it is worth noting that one building may be in multiple damaged areas simultaneously and it should be judged based on the most unfavorable situation for example in three story building destruction areas buildings with three floors or less will be destroyed and buildings with more than three floors will not be destroyed a two story building is considered to be damaged if it is in the damaged area of both two story and three story buildings the number of buildings destroyed in each residential area can be counted using the frequency statistics function of the gis therefore the rs of the popun eva can be calculated by eq 3 3 results 3 1 simulation results of dam breach flood based on the simulation results of dam breach flood the maximum width of the breach is reached after 1 35 h final bottom width is 165 m and maximum flow of the breach is 57 769 m3 s the flood reached yichuan county after 0 8 h and longmen grottoes in luolong county after 3 6 h in the longmen grottoes region affected by its narrow valley and low lying terrain the water depth reached a maximum of approximately 29 m and the flow velocity in the center of the river increased sharply to approximately 23 m s beyond longmen grottoes owing to the flat and open terrain downstream the flood begins to spread and the flow velocity gradually slows down and it reaches yanshi county after 8 7 h the total submerged area in luoyang is approximately 291 km2 primarily involving 14 residential areas in songxian county yichuan county luolong county and yanshi county the locations listed in the order of their distances from the dam site from near to far are as follows minggao town a baiyuan town b chengguan town c pengpo town d longmen grottoes left bank e longmen grottoes right bank f longmen town g zhuge town h taikang east road i lilou town j dianzhuang town k pangcun town l zhai town m and yuetan town n the inundation situation is shown in fig 3 3 2 simulation results of par evacuation potential the ownership rate of private cars in luoyang city where the luhun reservoir is located is 19 6 according to cova and johnson 2015 each car can take two to three people 2 5 is selected owing to the lack of detailed statistics it was assumed that the residents give priority to cars whereas the remaining people were evacuated on average using motorcycles and bicycles and by walking thus the proportion of residents evacuated using cars was 49 and that for the other three methods was 17 the time required for evacuation of the par in each town was calculated by the od matrix as shown in fig 4 three conditions were assumed each town issued a warning message 0 0 5 and 1 h before the flood arrived by combining the time required for evacuation the maximum time allowed for the population to complete the preparation work can be calculated at this time the corresponding preparation rate rp is the proportion of the par that can be successfully evacuated that is the re through information from the building vector data converted into floors it was found that there were almost no bungalows in the submerged area nowadays buildings in the downstream area are all constructed from either bricks or concrete taking chengguan town of yichuan county as an example the damage to the buildings in this area is shown in fig 5 and the rs can be calculated by eq 3 3 3 results of estimation of lol based on the results of simulation of flood routing and population evacuation potential the results of estimation of the lol in each town are shown in table 6 4 discussion 4 1 comparison with ehsan s model ehsan 2009 proposed a method for calculation lol as expressed in eq 13 13 lo l i p a r i f a t base f sv f age f mt f st f h f war f ev where loli loss of life at a particular location i downstream of the dam pari population at risk at a particular location i downstream of the dam fatbase base fatality rate of 0 15 fsv flood severity factor fage age risk factor fmt material risk factor fst storey risk factor fh health risk factor fwar warning factor fev ease of evacuation factor ehsan s model was applied to the case of this study to calculate the lol under different warning time the value of the coefficients and the results of lol are shown in table 7 comparison between the estimation results of ehsan s model and the proposed model was made as shown in table 8 according to table 8 the mortality of the proposed model is larger than the ehsan s model which is caused by the following reasons a due to the different national conditions the models of other countries are not necessarily suitable for direct application to china for example in the ehsan s method the value of fst is 14 fst 1 for h i g h s e v e r i t y a n d a l l t y p e s o f h o u s e s 15 fst 1 s for m e d i u m a n d l o w s e v e r i t y where s of more story houses however there may be great differences in the standards of the construction industry the structure and materials of houses in different countries therefore when judging the damage of houses in the flood the standards for houses damage in china as shown in table 4 were used in the proposed model which led to the difference in the evaluation results between the proposed model and ehsan s model b when ehsan s model was used to calculate the lol in study case fsv 0 3 was taken in all medium flood severity areas however the special topography of luhun reservoir leads to more serious flood the flood severity in many areas is of medium severity but very close to high severity at this time fsv 0 8 or 0 9 is more suitable the proposed model took this situation into account in more detail so the results are larger than ehsan s model furthermore the proposed model is more sensitive to water depth d in the same flood severity areas the value of fatbase in ehsan s model is the constant but the value of fm in the proposed model increases with the increasement of d therefore based on the proposed method the calculation results of luhun reservoir with deep flood in the downstream are larger c ehsan s model lays the foundation for the accurate assessment of lol combined with the above comparison it is suggested that when using the ehsan s model the selection of parameters can be analyzed more carefully so as to further improve the accuracy of the results 4 2 comparison with li zhou model based on the actual situation prevailing in china considering the graham method and certain other influencing factors zhou et al 2007 presented the mortality table of the par for estimating the lol caused by dam breaches in china the results of estimation obtained from the model proposed in this study were compared with those of li zhou model as shown in table9 according to table 9 when the warning time for town b is 0 5 h and those of towns j and n are 0 h the estimation results are not within the scope of the li zhou model however this situation can be attributed to specific reasons town b baiyuan town is a rural area where the proportion of houses with more floors is much lower than that in urban areas only approximately 55 of the houses could effectively resist flood in the area hence most of the popun eva are exposed to the flood leading to a significant lol the values of sf for towns j lilou town and n yuetan town are medium primarily because of its large water depth however the flow velocity is small and the impact of the flood on the houses and the popexp is limited thus it will not cause serious casualties the results of the estimation for other towns under various warning times are all within the scope of the li zhou model which verifies the accuracy of the proposed model 4 3 analysis of the simulation results a according to fig 4 town a minggao town and town l pangcun town require the maximum amount of time for complete evacuation at 210 and 187 min respectively town a is closest to the dam site among the 14 residential towns the dam breach flood arrives within 50 min which is far less than the time required for evacuation therefore the relevant departments should prioritize the evacuation town l is far from the dam site and the flood arrives late if the early warning is timely the population will have sufficient time to evacuate the time required for complete evacuation of other towns is within 130 min and the longest is 128 min among these the towns with longer evacuation times are town d pengpo town town f longmen grottoes right bank town k dianzhuang town and town m zhai town which take 124 117 126 and 128 min respectively to reduce the potential lol as much as possible the relevant departments should issue early warnings and properly arrange the evacuation sequence for residents based on the flood arrival time and the amount of time required for evacuation b it is worth noting that if a flood disaster occurs most residents in luolong county will be evacuated to hetaoyuan park luopu park luolong and luoyang sports center the red positions displayed in fig 6 which may cause overcrowding it is recommended that after properly attending to the injured some people should be transferred to nearby locations such as mangshan sports park peony park xiyuan park peony square and the shangyang branch of wangcheng primary school the blue positions displayed in fig 6 in addition fig 3 indicates that yichuan county has less capacity for receiving evacuees than luolong county which makes it inconvenient for the evacuation therefore the relevant departments should set up temporary camps in the surrounding unsubmerged highlands to provide living supplies and medical assistance to asylum seekers c as compared with the existing methods this model can not only estimate the lol caused by dam breaches but also quantify significant information such as evacuation time and effective shelter location to facilitate the relevant departments in formulating effective evacuation strategies in addition unexpected situations may occur in the actual evacuation process such as road obstruction or impassability owing to traffic accidents broken trees and falling stones and prohibited areas owing to the location of chemical enterprises prisons or military bases to handle the impact of these emergencies measures such as road blocking or traffic bans can be set up at the corresponding positions of the vector data in the gis d the results of the estimation obtained from the proposed model are significantly affected by the accuracy of the flood characteristics because of the significant effects of the breach parameters and downstream roughness on the accuracy of the flood simulation parameter selection and processing should be adjusted based on the specific conditions further extreme weather such as rainstorms fog and hail has an adverse impact on the evacuation of the par and the model can be further refined in combination with other relevant studies 5 conclusion according to the analysis of influencing factors and formation process of lol a new comprehensive evaluation model was proposed in which the parameters were quantified based on flood routing and population evacuation potential simulation the hec ras was used to simulate the flood caused by dam breaches and determine the number of par and the mortality of the popexp the gis and related vector data were used to simulate the evacuation potential of par in which the rp re and rs were quantified taking 14 towns downstream of the luhun reservoir in luoyang china as an example the estimation results of the proposed model were compared with those obtained from the two existing methods indicating that the proposed model can effectively determine the potential lol caused by dam breaches in china which provides a reference for the relevant departments to formulate emergency plans credit authorship contribution statement wei ge conceptualization formal analysis writing review editing yutie jiao conceptualization formal analysis writing original draft meimei wu conceptualization methodology validation formal analysis writing original draft zongkun li methodology investigation funding acquisition te wang methodology writing review editing wei li validation supervision yadong zhang validation weixing gao investigation funding acquisition pieter van gelder supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the national natural sciencefoundation of china grant no 52079127 52179144 u2040224 51679222 51709239 the fund of national dam safety research center grant no cx2021b01 program for science technology innovation talents in universities of henan province hastit grant no 22hastit011 the young talent support project of henan province grant no 2021hytp024 and the programs for science and technology development of henan educational committee grant no 202102310394 
3188,extreme floods are underrepresented in stream gauge records sedimentological evidence of past floods paleofloods yields longer records allowing extreme floods to be examined over several holocene climate periods this study examines the influence of hydrogeomorphic complexity floodplain aggradation and spatially variable flood deposition on paleoflood record completeness and their implications for flood magnitude estimates made with paleoflood hydrologic data we collected two sediment cores 500 m apart from the same elevation on a natural levee along a bank of the tennessee river near guntersville alabama we measured grain size from each core at a 1 cm resolution using a malvern 3000 laser granulometer optically stimulated luminescence dating of flood deposits revealed approximate age ranges of 50 6500 years calibrated before present yrs b p for the downstream 3 5 m core i e bo1 and 190 8500 yrs b p for the upstream 4 18 m core i e el2 first a sensitivity analysis revealed adjusted floodplain elevations afe for each paleoflood cross sectional geometry to reflect floodplain aggradation over time enabled the detection of paleoflood magnitude differences suggesting floodplain aggradation should be considered in paleoflood reconstruction within alluvial settings minimum paleodischarge intervals were estimated in a 1d hec ras step backwater model by calculating the minimum paleoflood stage needed to transport the d90 of each paleoflood deposit big oak and east levee 2 sediment cores each contained 15 high magnitude identifiable paleofloods the majority of the bo1 paleofloods occurred in the last 2 000 years while most el2 paleofloods occurred between 2 000 and 5 000 yrs b p suggesting localized geomorphic complexity produced distinct paleoflood records for the same hydrogeomorphic surface four paleoflood events correlate across the two cores based on their ages and grain size distributions and we combined these four floods to create a harmonized flood chronology for the site the timing of these four floods corresponds with paleofloods that occurred in the last 2000 years in the middle section of the tennessee river identified by prior paleoflood hydrologic studies flood frequency analysis bayesian markov chain monte carlo method scenarios with ten configurations of paleoflood hydrologic data revealed differences in the number and timing of paleofloods in three paleoflood chronologies bo1 el2 and the harmonized resulting from hydrogeomorphic complexities affected model distribution parameters goodness of fit and the estimated discharges of annual exceedance probabilities used to inform the design of critical flood infrastructure as a consequence of longer records containing smaller floods the estimated discharge of the 0 01 100 yr 0 001 1000 yr and 0 0001 10 000 years aeps for el2 were 16 11 and 5 smaller respectively than bo1 estimates alluvial rivers present more challenges for reconstructing paleoflood records than bedrock confined channel settings the strategies presented in this paper can help integrate paleoflood hydrologic data into flood frequency analyses for alluvial rivers identifying and minimizing error stemming from hydrogeomorphic complexity these strategies offer opportunities to expand the use of paleoflood hydrologic data in flood frequency analyses to include more rivers located in temperate environments where climate change is intensifying precipitation and a compelling need exists to anticipate and plan for changes in extreme flood occurrence keywords paleoflood hydrology floodplain aggradation bayesian flood frequency alluvial rivers 1 introduction floods are the most frequent natural hazard and the second deadliest severe weather hazard in the united states u s lim and skidmore 2019 the primary use of 20 of dams in the u s is flood control ho et al 2017 seventy percent of dams in the u s were built before 1970 ho et al 2017 meaning that their flood design is based on 70 years of flood data the use of shorter flood records in flood frequency models applied to flood risk assessments results in large uncertainties for low probability floods such as a 10 000 year event as such federal flood frequency guidelines england et al 2019 now recommend extending flood records with historical botanical and sedimentological flood reconstructions when estimating low probability floods where these data are available paleoflood hydrology uses data obtained from flood sediments deposit elevation and age grain size mineralogy etc and hydrological and statistical models used to reconstruct the frequency and magnitude paleodischarge estimates of past floods paleofloods extending flood records by several millennia benito and o connor 2013 by extending the flood record observations of rarer extreme floods are increased reducing the amount of extrapolation required to estimate rare flood probabilities resulting in decreased uncertainty associated with estimations of remote probability floods harden et al 2011 paleoflood reconstructions combined with statistical procedures for treating data with a range of possible values in flood frequency analyses stedinger and cohn 1986 have changed how flood frequency and hazard assessments can be performed plans and designs for significant infrastructures such as dams and nuclear plants must consider extreme and rare probabilities with 10 3 and 10 7 chances of happening each year jarrett and tomlinson 2000 prior to the integration of paleoflood hydrology into flood risk assessments deterministic approaches such as the probable maximum flood salas et al 2014 commonly were relied upon because of the large uncertainties associated with rare annual exceedance probabilities aeps estimations made with probabilistic methods jarrett and tomlinson 2000 stemming from fewer observations of extreme floods in recent decades regulatory agencies such as the u s bureau of reclamation moved towards probabilistic risk assessments because flood frequency curves incorporating paleoflood data yield aep estimates for extreme floods with less uncertainty england 2011 traditionally most paleoflood hydrology studies are in bedrock confined channels located in arid and semi arid climates where flood deposits are less disturbed by biological processes bioturbation and channel geometry is assumed to be consistent through time benito and o connor 2013 paleoflood discharges for bedrock channels are deduced from the elevation of flood deposits and the minimum flood stage required to access deposit elevation few quantitative paleoflood hydrologic studies i e studies resulting in paleodischarge estimates focus on alluvial rivers despite their geographical ubiquity and co occurrence with major population centers and river infrastructure o connor et al 2014 alluvial rivers present specific challenges to applying quantitative paleoflood hydrologic methods for which specific adaptations are lacking the most significant challenge in applying quantitative paleoflood hydrologic methods in an alluvial setting is that flood magnitude cannot reasonably be assumed based on deposit elevation because flood stage is reduced when floodwaters spread laterally across floodplains and terraces during floods recent paleoflood studies circumvent this challenge by differentiating paleoflood magnitude based on sediment coarseness differences measured for each paleoflood deposit increased flood discharges and flow velocities suspend larger grain sizes in higher volumes walling 1974 asselman 2000 lenzi and marchi 2000 if there is suitable overlap with the annual peak flow record measured by stream gauges paleoflood magnitude can be estimated by establishing a linear regression relationship between sediment particle size d90 for example allowing sediment particle size to serve as a proxy for paleodischarge toonen et al 2015 leigh 2018 munoz et al 2018 fuller et al 2018 shen et al 2021 paleoflood discharges that occurred prior to the instrumented record are modeled using the linear regression equation and the influence of aggradation may be limited by detrending the grain size variability leigh 2018 while this approach significantly increases the number of alluvial rivers and reaches where quantitative paleoflood studies can be conducted it is less feasible in river systems where long stream gauge records are not available and where changes in hydrologic connectivity between the channel and floodplain have occurred that can alter statistical relationships between grain size and discharge changes in hydrologic connectivity help determine the flood stage needed to initiate floodplain sedimentation lateral migration and vertical accretion of the floodplain over time change the vertical and lateral distance of the channel from the floodplain and thereby affect the size of sediments that can be deposited on the floodplain standardizing and detrending sediment particle size data improves the identification and estimation of paleodischarges toonen et al 2015 however paleodischarge estimates become less reliable where planform and or channel geometry changes shen et al 2021 because vertical accretion increases floodplain elevation it also increases bankfull thresholds leigh 2018 peng et al 2019 meaning that paleotopography differs through time and impacts paleodischarge estimates van der meulen et al 2021 furthermore aggradation can occur in rapidly in response to an overbank flood meaning bank height may change in abrupt nonlinear patterns knox 2006 shen et al 2015 therefore aggradation may impact hydrologic connectivity rapidly enough to warrant account for changes in floodplain elevation for each paleoflood yet rarely do paleoflood studies address the effect of aggradation on paleodischarge estimates beyond detrending techniques a second challenge to accurate paleodischarge reconstruction in alluvial channels is paleoflood deposit perseveration which is influenced by spatially heterogeneous processes of erosion and deposition harden et al 2010 compared the ages of paleoflood deposits found in 18 bedrock and 20 alluvial river reaches in the southwestern u s deposit ages suggested that bedrock systems tended to preserve younger floods while alluvial settings preserved longer and older paleoflood records but paleoflood chronologies derived from southwestern alluvial rivers contained fewer preserved paleofloods corresponding to a highly active flood period 1000 500 years before present well preserved in bedrock reaches the differences between alluvial and bedrock paleoflood chronologies identified by harden et al 2010 suggest erosion related to channel incision and migration in the alluvial reaches impacted the preservation of extreme floods effectively biasing the total paleoflood chronology for some sites towards smaller flood preservation as a consequence of channel adjustments to changing flood regimes geomorphic studies of modern floods also show that erosion and sedimentation patterns across an alluvial surface can vary depending on storm duration timing and the sediment source area asselman and middelkoop 1998 magilligan et al 2014 heitmuller et al 2017 therefore locations across the same geomorphic surface and elevation may contain differences in records of flood events owing to spatio temporal complexities in erosional and depositional processes finally bioturbation e g soil development and loss of bedding structure from organismal activities also can affect the preservation of flood deposits left unscathed by erosion with humid climates having greater potential for bioturbation benito et al 2020 ultimately all paleoflood hydrologic data require expert interpretation of multiple lines of evidence of past flood activity and a level of simplification to be applied in modeling and predicting complex natural processes ideally paleoflood hydrologic data would be reconstructed under perfect conditions such as a stable river valley with preservation of discrete laminated flood deposits that lack sedimentary gaps and that are located in close proximity to a stream gauge with a long record 100 years in reality ideal conditions rarely occur and limiting paleoflood hydrologic analyses to only include ideal sites would deprive many communities dealing with flood risk particularly in need of extreme flood hazard assessment of the benefits of paleoflood hydrologic analyses such is the case for the tennessee river which is one of the most socio economically significant rivers in the u s more than 10 million people across seven states rely on hydroelectricity generated by the tennessee river tva 2021a a series of 49 cascading dams regulate the flow of the tennessee river tva 2021a by 1945 nine dams completely impounded the tennessee river main channel tva 2021b leaving long unregulated flow records lacking and limiting the possibility of applying a linear regression approach e g toonen et al 2015 to quantify paleodischarges for the river mainstem the river s flow regulation results in good paleoflood deposit preservation however terraces and floodplains are decoupled from the channel except for during extreme flooding over half of the tennessee river basin s 4 6 million residents live along its banks tennessee riverlane 2021 depending on the dams for effective flood control drinking water and power resulting in a compelling need to assess extreme flood risk despite the challenges presented by the river s alluvial nature and flow regulation therefore this paper outlines strategies for minimizing uncertainty in quantitative paleoflood hydrologic analyses in an alluvial setting or where unregulated flow records are limited scenarios that are not uncommon given the global occurrence of river regulation we test the impact of floodplain aggradation through time and paleoflood chronology completeness on flood frequency and magnitude estimates determined with bayesian statistical models and present an underused alternative method for estimating minimum paleoflood discharges based on determining the minimum height needed for particle entrainment first we examine differences and similarities between two paleoflood chronologies developed from two different sediment cores sampled 500 m apart on the same hydrogeomorphic surface a relict natural levee second we assess the impact of adjusting floodplain elevation when calculating paleodischarges to counteract the effect of bankfull thresholds increasing as floodplains aggrade to paleoflood magnitude estimates and perception thresholds third we evaluate the influence of paleoflood preservation differences on flood frequency models specifically shape parameters and estimated discharges for aeps the findings provide new insights for quantitative paleoflood hydrologic studies conducted in alluvial rivers or rivers lacking reliable annual peak flow records which if implemented should result in more robust flood frequency analyses particularly for extreme flood risk assessments i e floods with low aeps 2 methods 2 1 study area paleoflood hydrologic analyses were conducted for a location a relict natural levee of the tennessee river near guntersville alabama fig 1 the tennessee river is a mixed bedrock alluvial system making it well suited to exploring flood deposition issues since it contains both confined bedrock and alluvial channel settings the tennessee river basin can be divided into two sub basins delineated by a deep narrow gorge located near chattanooga tennessee below which the river flows south into the northeastern corner of alabama jones et al 2015 upstream of chattanooga lie the river s headwaters in the great smoky mountains range of the appalachian mountains the upper tennessee basin begins at the confluence of the holston and the french broad rivers near knoxville tennessee the lower tennessee basin below chattanooga takes a western turn in guntersville alabama it crosses the northern portion of alabama before flowing north until its confluence with the lower ohio river near livingston kentucky the overall east to west flow of the river exposes it to several different hydroclimatological flood mechanisms including mid latitude cyclones hurricanes and intense convective storms u s weather bureau 1965 the gulf of mexico provides a nearby source of moisture that feeds the storms affecting the basin the flood of record for the river segment where the study site is located occurred in march 1867 ce resulting from a 12 day quasi stationary front with two secondary bands of moisture from the gulf of mexico tva 1961 strong el niño years increase annual precipitation jones et al 2015 likely because mid latitude cyclones also increase in magnitude and frequency during el niño senkbeil et al 2012 mid latitude cyclones are the most common cause of flooding in the tennessee river lecce 2000 while many tennessee river floods occur in the late winter and spring the most significant increase in seasonal rainfall over the last 50 years has occurred during the summer and fall jones et al 2015 a phenomenon that has been associated with the occurrence of extreme floods smith et al 2018 part of our analyses involved a sedimentological examination of two sediment cores to reconstruct paleoflood frequency and size at the study site the sediments taken from the natural levee have two primary sources with distinct mineralogy including locally derived sheetwash material and overbank sediments deposited during floods sheetwash from hillsides and valleys proximal to the site originate from weathered sedimentary rocks including pennsylvanian aged sandstones and mississippian aged mudstones and limestones osborne and ward 2010 parent materials for overbank sediments come from the tennessee river s headwaters in the great smoky mountains which are comprised of micaceous metamorphic rocks moore 1988 the different geology of the primary source areas delivering sediments to the natural levee makes overbank flood sediments associated with tennessee river flooding visually distinguishable based on mica content harden and o connor 2017 2 2 site selection the paleoflood records used in this research were reconstructed from two sediment cores sampled from a relict natural levee located on the left bank of the tennessee river approximately 10 km from guntersville al usa many paleoflood studies conducted in alluvial settings target low lying floodplain environments distanced from the channel oxbows meander scars paleochannels etc see for example toonen et al 2015 munoz et al 2018 shen et al 2021 such locations have some distinct advantages since their positions away from the active channel can mean less erosion through time and in some cases a sense of flood magnitude can be ascertained based on the inundated area required for flooding to have occurred at the location levees result from a combination of lateral migration and overbank processes that are not well understood ferguson and brierley 1999 johnston et al 2019 while no consistent controlling factors of levee shape and size have been identified levee height is controlled by overbank deposition associated with floods johnston et al 2019 levees are vulnerable to more frequent erosion than backwater environments which can impact deposit preservation brierley et al 1997 despite having a more dynamic sedimentation environment than backwater zones paleoflood studies can be conducted from levees providing adequate dating of materials is achieved e g leigh 2018 peng et al 2020 we selected the natural levee at parches cove for detailed analyses for two primary reasons first it is a relict feature formed prior to the construction of the dams and river regulation 1933 ce which subsequent to damming became decoupled from the channel protecting it from more contemporary floods and erosion this assertion was confirmed at the conclusion of our stratigraphic analyses when ages determined for stratigraphic units showed that none of the deposits were younger than 1917 ce second extensive geomorphological and pedological investigations of the parches cove location revealed that the natural levee contained the best preservation of flood deposits from the tennessee river we exposed trenches pits and cores and described sediment from a total of seven floodplain locations fig 2 before choosing the levee sites for detailed analyses from the preliminary geomorphic and pedologic investigations we determined that the hydrogeomorphic floodplain of the tennessee river occupied only a portion of the parches cove landscape i e the main valley flat the floodplain boundary on the left bank of the river roughly coincided with bedrock and regolith outcroppings located south of clark bluff in fig 2 following an east to west trajectory pits and trenches exposed south of the unnamed hill lacked alluvium initially we suspected the low topographic area highlighted in fig 2 south of the unnamed hill could be a paleochannel because of its upstream to downstream orientation four trenches excavated within the topographic low lacked evidence of paleochannel stratigraphy such as lag deposits or fining upward sequences three sites blue boxes in fig 2 were well developed soils forming within regolith without any tennessee river sediment the western most trench located within the topographic low contained overbank clay rich tennessee river sediments overlying limestone residuum at 2 m below the surface we examined a sediment core from a low lying floodplain area that should have been inundated by the historic 1867 ce flood based on an estimated stage tva 1940 open blue circle on fig 2 but the core contained sediments derived from sheetwash from surrounding hillslopes based on angularity and differences in mineralogy with tennessee river sediment communication with the land manager revealed that this location floods from groundwater intrusion and not overbank water land manager personal communication 2017 the pits trenches and cores we sampled revealed a clay rich paleosol that can be stratigraphically correlated across the active floodplain of parches cove fig 3 this paleosol is consistent with buried bt complexes found in bank exposures of a paleosol located downstream of parches cove stewart 2020 the findings of our preliminary geomorphic and pedologic assessments suggest that the active floodplain of this portion of the tennessee river has been dominated by overbank deposition as opposed to lateral migration and that the river has been confined to a limited portion of the landscape resulting in good perseveration of flood deposits in the natural levee bedrock and regolith outcrops may have aided in deposit preservation by stabilizing the channel s position fig 1 similar to floodplains observed by ferguson and brierley 1999 in another mixed bedrock alluvial river the lower tuross river in the tuross river the levee was preserved over millennia having experienced more overbank deposition than erosion as a consequence of little channel migration the occurrence of the clay rich paleosol also likely contributed to channel stabilization as clay rich bank material has a higher resistance to erosion and lowers lateral migration rates hickin and nanson 1984 2 3 flood peak identification we collected two cores from a natural levee surface at approximately equal elevations 176 19 m asl we described the stratigraphy of sediment cores based on unit thickness texture munsell color sediment structure mineralogy including mica content pedogenic features and other notable features e g bioturbation and cultural artifacts first the geoluminescence dating research lab at baylor university measured optically stimulated luminescence osl dates for flood sediments from the natural levee sites table 1 we estimated deposit dates using an age depth model osl dates in a bayesian accumulation bacon model blaauw et al 2018 we assigned hiatus periods 685 years maximum at the top depth for each buried a horizon to represent multi century surface stability resulting in soil development based on osl dating constraints above and below a representative a horizon additionally the hiatuses indicated where prior information in the bacon model should reset because flood deposition rates subsequent to the hiatuses may differ from the previous period next we reconstructed flood peaks from levees based on the grain size distribution of flood deposits measured at 1 cm resolution using laser granulometry with a malvern mastersizer 3000 several factors may influence grain size variation apart from flood magnitudes such as channel migration surface aggradation sediment availability changes and vegetative cover we used three strategies to statistically control for sediment variation with each sediment core that is unrelated to floods change point analysis cpa was applied to statistically identify down core changes to sedimentation to support stratigraphic facies described in the cores toonen et al 2015 killick et al 2016 we set a low detection threshold for the cpa to avoid the detection of small variability such that change points represent distinct periods of sedimentation created by long term persistence for example people set fires for various management purposes at an intermediate spatial scale in the southern appalachians since the woodland periods 3000 1000 years before present and maize production peaked during the mississippian period approximately 1000 years before present delcourt and delcourt 1998 this land use change would affect sediment yield within a river system over time therefore we used the cpa to identify these critical shifts in sedimentation we processed grain size distributions using end member modeling analysis emma to unmix processes affecting grain sizes within the core dietze et al 2012 toonen et al 2015 munoz et al 2018 processes influencing grain sizes at each site likely including deposition occurring during different phases of storm hydrographs sheetwash and pedogenesis we interpreted the emma results from geologically feasible processes likely impacting sedimentation based on our knowledge of the site such as flood deposition pedogensis and changes in sediment source weltje and prins 2007 van hateren et al 2018 for example during peak discharges most fine particles will remain entrained therefore the grain size distribution of a peak discharge deposit end member should contain mostly coarser sand without a large volume of clay based on emma results the coarsest end member or larger was used to identify sediment core deposit layers corresponding to flood peaks we smoothed grain size data using local polynomial regression loess to reduce localized variability from non flood related variables that can change between flood events such as coarse woody debris or small changes in riparian cover leigh 2018 positive residuals plotting above the loess smooth line were interpreted as flood peaks fig 4 flood peaks derived from high resolution grain size data analysis may represent individual floods flood pulses from the same flood or composite peaks from multiple floods occurring in short succession leigh 2018 without an overlapping instrumented record and only a single historic flood the flood of 1867 ce for reference we limited our paleoflood reconstruction to peaks with positive residual values greater than or equal to 4 which is the positive residual value associated with the 1867 ce flood fig 4 from this subset of flood peaks we removed two smaller flood peaks dated within 50 years and deposited within 5 cm of one another the remaining floods peaks we interpret as a subset of discrete large flood events 2 4 paleoflood magnitude estimation the whitesburg stream gauge operated by the united states geological survey nearest to our site only contains unregulated annual peak flow records from 1925 to 1936 ce paleodischarges are more commonly estimated using linear regression equations for relationships between sediment grain size and instrumented discharge records see leigh 2018 for example but the youngest flood deposit identified in the sediment cores was the historic flood of 1867 ce and both cores distinctly lacked 20th century flood deposits likely because of river regulation that came with the construction of the tva dams consequently we applied a different approach that has been underutilized in paleoflood hydrologic studies conducted in alluvial rivers we estimated paleoflood discharges in this study based on the paleoflood height needed to entrain the coarsest sediment fraction d90 measured for each paleoflood deposit the d90 is the grain size in millimeters below which 90 of the sediment sample is smaller than the d90 diameter the benefit of using d90 as a coarseness metric of sediment rather than the volume of coarsest sediment used in linear regression based estimates of paleodischarges e g toonen et al 2015 leigh 2018 is that it allows the use of sediment transport equations brandon et al 2014 when peak flow records are lacking the d90 for the two sediment cores analyzed in this study consist of 0 25 mm sand we chose to base our discharge reconstructions on the d90 grain size of each extreme paleoflood deposit based on previous research indicating an association between the d90 and high magnitude flood deposition research previously completed upstream of the study site simmons 1993 oblinger 2003 leigh 2018 demonstrated that flood deposits consist of 0 25 mm sand and larger particle diameters confident that medium to coarse sand comprised flood deposition based on the previous studies conducted upstream we chose to use the d90 particle diameter of the paleoflood deposits detected at our study site since our goal was to characterize past extreme floods numerous studies of floodplain deposits worldwide find that particle size distribution end members such as the d90 are associated with the highest magnitude flood events this association has been documented for rivers in the upper mississippi river basin knox and daniels 2002 the upper tennessee river basin wang and leigh 2012 leigh 2018 the lower rhine river in germany and the netherlands toonen et al 2015 and the severn river basin of england pears et al 2020 these studies validate the ideas posited by colby 1963 that the transportation of coarse sediment is more consistently related to increased discharge than the transportation of fine sediment because 1 sources of coarse sediment are more localized coming from what was left in the cross section since the previous high flow event while fine sediment can come from sheetwash runoff and is affected by the availability of fine sediment in extra channel environments and 2 fine sediment supply is more likely to be exhausted prior to high discharge events because their transportation is facilitated by a range of flows well below bankfull we estimated the minimum paleoflood height hpf in meters above the sampling surface required to entrain each d90 particle diameter in meters using eq 1 fig 5 from cyr et al 2015 cyr et al 2015 reworked a critical shear stress equation to solve for height of weight and used the equation to determine paleoflood discharges using pebble diameters in our calculations using eq 1 we used the particle density of quartz for ρs because it was the most common mineral 80 identified in osl samples extracted from the natural levee site stewart 2020 this method of estimating paleoflood discharges uses the same basic assumption underpinning the gauged discharge sediment volume linear regression approach more commonly applied in alluvial paleoflood discharge estimation which is that as discharge increases so too does the flow s ability to entrain coarser particles a key difference is that the equation eq 1 in fig 5 used in our calculations taken from cyr et al 2015 reflect energy changes as a function of water surface height and slope and assume that transport initiates when the product of water height and slope exceed the combined effect of particle cohesion and particle weight to resist transport sand transport could be initiated at lower flood heights because of velocity increases associated with localized hydraulic changes channel constrictions from debris jams or the development of standing waves related to bedforms for example but as previously explained we excluded paleofloods from the flood frequency analyses that did not have positive residuals equal to or greater than the historic flood of record flood of 1867 ce censoring the flood frequency dataset to consist only of large floods we used a step backwater 1 d hydraulic model in hec ras 5 0 3 to estimate paleoflood discharges by iteratively running steady flow discharges until reaching a discharge that matched the stage of each paleoflood hpf the hydraulic model contained sixteen total cross sections six downstream from big oak and eight upstream from east levee 2 big oak had river valley width of approximately 1100 m and a maximum channel width and depth of 280 m and 24 m respectively east levee 2 had a river valley width of approximately 1010 m and a maximum channel width and depth of 363 m and 17 m respectively the 1 m resolution lidar and bathometry were provided by tennessee valley authority lam et al 2017 found that despite there being a greater potential for hydraulic geometry to change as a result of sediment flux in alluvial river valleys these hydraulic geometry changes did not significantly impact paleodischarge estimates derived from paleoflood hydrologic methods for a 2000 year long record lam et al 2017 because few studies have attempted paleodischarge estimates in alluvial rivers however we decided on a conservative approach and adjusted the hydraulic geometry used in the hec ras flow modeling to account for the floodplain aggrading over time aggradation would increase the elevation of the floodplain over time meaning that the stage needed to access the floodplain would also increase not accounting for this geomorphic change potentially could risk underestimating the discharge of more recent paleofloods post aggradation relative to older paleofloods prior to aggradation we identified the soil series correspond to sites with preserved tennessee river alluvium at parches cove then we identified the spatial extent of the active floodplain in the whole river reach using maps of these soils the hydraulic radius spanning active floodplain surfaces was adjusted through time by subtracting elevation equivalent to the depth of a paleoflood deposit as this can be assumed to be the surface of the floodplain during deposition see section 2 5 for more details the channel portion of the hydraulic radius was assumed to be consistent through time and not adjusted because it is comprised of an exposed bedrock shoal based on measurements of depth to bedrock made by tva for dam construction purposes tva 1941 the resulting adjustments required unique hec ras geometries for each paleoflood with consistent manning s n values for all pre historic floods thus the only differences that affect discharges between each modeled paleoflood are the d90 derived flood heights and floodplain elevations in the hydraulic geometries finally we used a range of 25 manning s n values in the channel and on the floodplain to estimate the minimum and maximum discharge ranges for paleofloods we calculated the normal depth using the frictional slope of the 1867 ce flood from the change in flood surface elevation over the length of the river reach we used the reconstructed longitudinal profile created from historical 1867 ce flood high water marks along the tennessee river to measure changes in elevation of the flood profile tva 1940 2 5 sensitivity analysis of impact of adjusted floodplain elevations afes we attempted to develop paleoflood reconstruction methods that best reflect natural processes occurring within the system and that limit assumptions about past environments in the absence of unregulated and long discharge records we back calculated paleodischarges by estimating the paleoflood stage physically needed to deposit sediment d90 on the floodplain but essentially our assumptions and rationale are the same as those made in linear regression based paleodischarge estimates in both cases it is assumed that larger particle sizes require faster velocities associated with larger discharges to be transported and deposited outside of the channel in alluvial rivers however floodplains aggrade and in turn the threshold to exceed bankfull discharge increases with aggradation a given particle size diameter and the corresponding minimum flood stage at the surface would require a larger magnitude flood to occur than the same particle one meter below the surface because the floodplain elevation changed fig 6 therefore it would not be appropriate to treat these floods as equally sized events in this study we uniformly adjusted the floodplain geometry in the 1d hec ras model to account for aggradation of the surface through time based on the depth of the deposit for which a minimum paleodischarge was being modeled uniformly adjusting the floodplain is a simplification of coupled channel floodplain hydrogeomorphic changes but it does limit the number of assumptions needed to be applied across a large spatial domain to recognize the impacts of oversimplifying floodplain elevation we performed a sensitivity analysis of adjusted floodplain elevations afe in minimum paleodischarge estimates on the resulting paleoflood magnitudes and flood frequency curves we compared the percent difference in minimum paleoflood discharges without afe i e the modern surface and with afe modern surface minus the depth to paleoflood deposit additionally we identified minimally adjusted floodplain elevation subset of the paleofloods with afe based on paleodischarge intervals that overlap more than 90 with paleodischarge intervals modelled without afe the full paleoflood chronologies with and without afes and subset chronologies paleoflood with minimally adjusted floodplain elevation were used to generate flood frequency analyses and test their impact on three estimated model parameters location shape and skew and the confidence intervals the sensitivity analysis will provide insight into the point at which the additional uncertainty from adjusting the floodplain may outweigh the benefits afe provides in differentiating paleodischarges 2 6 bayesian flood frequency estimation our flood frequency models incorporate three types of data sources systematic interval and censored data years below perception thresholds systematic data are flow measurements taken regularly under a protocol and represent an exact discharge value in the model interval data are flood events where exact discharge is unknown but the value falls within a known range finally perception thresholds indicate a range of possible discharges below a threshold for a given year independent of observations england et al 2019 years without a perception threshold exceedance contain censored data we used peak flow stream gauge data usgs gauge 03575500 from 1925 to 1936 in each flood frequency analysis ffa we extracted annual peak flow from simulated unregulated total flow records from 1950 to 2013 based on rainfall runoff models provided by the tennessee valley authority tva 2020 derived from dam inflow measurements above our site our systematic data comprised the combined simulated peak flow and observed peak flow data from 1925 to 2013 paleoflood data were included along with the systematic data to create a flood frequency model for each site we performed flood frequency analyses in rmc bestfit v1 0 software using the bayesian markov chain monte carlo mcmc framework kuczera 1999 gaál et al 2010 smith and doughty 2020 rmc bestfit uses the maximum likelihood estimation mle method to fit a log pearson type 3 lp3 distribution curve to the systematic interval and censored data perception thresholds before 1925 were selected based on paleoflood and sedimentation information for each of the ten scenarios table 1 each scenario is given different perception thresholds that reflect the length of the paleoflood record and changes in discharge over time we chose the highest possible perception thresholds for each period based on the lower estimate with the most likely range of discharge based on our paleoflood information 3 paleoflood chronologies 3 1 paleoflood identification and stratigraphic interpretations extensive stratigraphic and statistical analyses of the two sediment cores revealed cumulic alluvial sedimentation overlying a buried paleosol suggesting that both sampling locations experienced progradation of the natural levee throughout much of the mid to late holocene fig 7 our analyses statistical analyses of particle size data and hydrologic modeling identified 15 paleofloods preserved at each site the timing of these paleoflood events however differed between sites fig 8 as a function of preservation most of the sampled and dated big oak paleofloods occurred in the last 2000 years whereas most of the sampled and dated east levee 2 paleofloods occurred before 2000 years before present yrs b p despite the difference in the timing of floods both sites demonstrated a steady increase in minimum flood magnitude over the last 6000 years with the largest magnitude floods occurring within the last 1000 years the four paleofloods estimated to have been the largest preserved floods at parches cove occurred in both sediment cores and their common ages as well as sedimentological and stratigraphic similarities are interpreted as evidence of the same flood events affecting both sediment core sampling locations on the natural levee notably flood magnitude estimates made for the largest floods using a modified shear stress equation cyr et al 2015 differed by 10 between the two coring sites fig 8 suggesting that flood magnitude estimations based on grain size are reliable and comparable between locations despite the core sampling locations being relatively close and flood magnitude estimates being consistent between the two cores the timing of paleofloods excluding the four largest preserved floods varied between the big oak and east levee 2 cores the close proximity of the sampling sites combined with similar paleoflood ages strongly suggest that the four largest floods inundated both of the core sampling locations on the levee fig 7 the sediment cores differed in their physical length and temporal length of record with the big oak core being shorter 3 5 m vs 4 18 m and containing younger materials than the east levee 2 core but the east levee 2 core overlaps the big oak paleoflood record with the oldest flood preserved in the east levee 2 core dating to 6000 yrs b p because the two paleoflood records reconstructed from the two cores temporally overlap it is less likely that the differences in the timing of paleofloods relate to each core containing floods from different intervals of time instead it is more likely that differences in the timing of preserved paleofloods resulted from localized factors influencing spatial deposition and preservation of flood deposits over time stratigraphic observations combined with the results of the change point analyses of the sediment particle size data for each core provide supporting evidence of localized factors contributing to the perseveration of distinct paleoflood chronologies differences in the thickness and depth of stratigraphic units exist between the cores fig 7 both cores contained the same well developed buried paleosols at their bases we identified a several flood packages in the upper half of both cores incipient soils characterized by weakly developed b horizons overlying c horizon overbank parent material despite identical timing of the recent change point between sites age depth models developed using osl ages and change point analyses demonstrate key differences between big oak and east levee 2 big oak contains two distinct sedimentation phases fig 9 the time between 2200 and 6700 yrs b p was a quiet period when sedimentation occurred less frequently and a deep soil formed east levee 2 has soil developed in the same 2200 6700 yrs b p period but paleoflood peaks were preserved and perceived through flood peak analyses until approximately 5000 yrs b p fig 9 east levee 2 s sedimentation phase 2200 5000 yrs b p contained episodes of larger flood peaks in the first half and smaller flood peaks in the latter half of the period it is possible that east levee 2 was strongly coupled with overbank sedimentation during this period 2200 5000 yrs b p because of its lower elevation east levee 2 s more frequent sedimentation during the second changepoint phase resulted in a high topographic position of east levee 2 relative to big oak at the onset of the most recent changepoint 2200 yrs b p both sites captured coarser sediments in the recent phase but big oak site situated at a lower topographic elevation in the downstream direction was likely inundated more frequently by smaller floods than east levee 2 consequently aggradation occurred more rapidly at big oak and decreased the difference in elevation to east levee 2 during the last 2000 years levee development observed at parches cove is consistent with johnston et al 2019 which found progradation in the downstream direction due to elevational differences altering inundation patterns in both the big oak and east levee 2 cores a significant change point occurred 2200 yrs b p marking the onset of the most recent sedimentation phase during which the largest and most frequent floods occurred based on coarse and medium sand volumes although occurring at different core depths at 0 75 m in east levee 2 and at 1 5 m in big oak the timing of the sedimentation phase 2000 yrs b p was consistent in both cores this suggests that although they are the same elevation today east levee 2 was topographically higher than big oak before 2200 yrs b p from approximately 500 1000 yrs b p during an otherwise active sedimentation phase the east levee 2 site lacked deposits dating to this interval based on the preserved record obtained from the big oak site during this timeframe 500 1000 yrs b p the levee experienced large floods and consistent progradation thus it is possible that one or more floodsoccurring between 300 and500 yrs b p eroded previous flood deposition cherokee people lived within parches cove until the 17th century according to historical maps and local history the name parches cove was originally named parched corn cove after the cherokee chief that settled on the land sterling 2016 excavation and cultivation of the land by the cherokee people could have resulted in the loss of flood deposits one pottery shard and some broken shells were identified at east levee 2 stratigraphic evidence of the soils above and below archeological material present clear or gradual boundary contacts by color we did not find any contacts characteristic of human induced mixing therefore we concluded that differences in osl ages of paleofloods are best explained as an unconformity resulting from flood scouring that occurred after 500 years before the present at the east levee 2 sampling location ultimately the preservation of flood deposits older than 2000 years before the present and the depositional gap between 500 and 1000 years before the present at the east levee 2 site resulted in a paleoflood chronology with similar flood magnitude trends through time but a different paleoflood chronology preserved from the paleoflood chronology developed from the big oak sediment core both in terms of number and timing of flood events 3 2 adjusting floodplain elevation to account for levee progradation aggradation of alluvial floodplains naturally increases the magnitude of floods necessary for deposition to occur effectively desensitizing analyses from being able to detect shifts in flood magnitude over time the sampling we conducted prior to site selection revealed that lateral migration of the channel had been limited throughout much of the latter holocene by bedrock and regolith exposures and a widespread clay rich paleosol that acted to confine the channel within a narrow segment of the valley multiple trenches and sediment cores examined from the natural level surface showed the levee to be prograding through vertical accretion during the mid to late holocene based on numerous c horizons and an absence of well developed soils within the upper 1 5 2 m furthermore the increase in deposit thickness observed at the downstream east levee 2 site relative to the upstream big oak site strongly suggested that the levee experienced intervals of longitudinal progradation because of considerable stratigraphic evidence of levee progradation we deemed it necessary to account for changes in floodplain elevation through time in the hydraulic geometries used to determine paleodischarges therefore we adjusted lowered the floodplain elevation in the 1d hec ras model to match the depth of the paleoflood deposit for which a paleodischarge was being estimated although similar floodplain elevational adjustments have been done for paleoflood studies investigating flood magnitude changes in the rhine river basin van der meulen et al 2020 van der meulen et al 2021 the approach remains relatively new and consequently its potential for yielding new insights into flood magnitude changes in alluvial rivers poorly investigated because one of the motivations of the research was to examine changes in flood magnitude over time we conducted a sensitivity analysis to determine the effect of lowering floodplain elevation during discharge estimation using the 1d hec ras modelling by comparing the paleodischarges calculated with an adjusted floodplain elevation afe corresponding the depth of paleoflood deposit depth from the modern surface to paleodischarges without an afe paleodischarges estimated without an afe were determined using the elevation of the modern floodplain adjusting floodplain elevations to reflect flood deposit depths resulted in smaller minimum paleodischarge estimates fig 10 and helped elucidate a trend of increasing paleoflood magnitude over time that would have been imperceivable without using the afe approach in this study relying on interpretations of positive residuals of the loess analysis of the medium to coarse sand volumes to identify flood magnitude changes was insufficient because the most extreme floods 4 positive residuals exhibited similar d90 values magnitude trends in paleoflood discharges become apparent however when the effects of levee aggradation were accounted for using the afe method the greatest reduction of a minimum paleodischarge estimate for the big oak paleoflood record occurred with the deepest paleoflood deposit 1 62 m below the surface which resulted in an 18 smaller minimum paleodischarge estimate without applying an afe fig 10 estimated minimum paleodischarge with an afe for the deepest paleoflood deposit at east levee 2 9 m below the surface was 33 smaller than the estimated paleodischarge without an afe minimum paleodischarges determined with an afe for paleoflood deposits located within approximately one meter of the modern surface 1200 yrs b p for big oak and 2150 yrs b p for east levee 2 containing 10 or less difference in flood magnitude than without an afe the fact that the largest with vs without afe differences in minimum paleodischarge estimates correspond to the paleoflood deposits situated at the base of both cores and the impact of afe appears to diminish as paleoflood deposit depth decreases suggests that simply subtracting elevation based on deposit depth may overcorrect for aggradation likely because compression of stratigraphic units caused by the weight of overlying material increases with depth yet ignoring aggradation and assuming modern channel geometry would also be problematic for reasons previously explained in an effort to reconcile this dichotomy we developed subsets of paleoflood observations with afe at each site that overlap more than 90 with the estimate intervals without afe these paleoflood deposits are closer to the modern floodplain and their estimates are made with minimally adjusted floodplain elevations within hec ras models 4 bayesian flood frequency analyses 4 1 flood frequency scenarios we examined ten flood frequency scenarios to illuminate the influence of paleoflood data interpretation and selection on flood frequency estimation table 2 results for each scenario are available in the supplement materials we compared results between scenarios in sections to specifically demonstrate the impact of adjusting floodplain elevations to estimate minimum paleodischarges and spatially variable flood deposits on flood frequency curves the primary insights from the sensitivity analysis includes paleodischarge estimates with afe generated flood frequency models with a better fit of data along the curves table 2 scenarios including complete paleoflood records and consequently lower perception thresholds scenarios 2 5 produce more positively skewed models which impacted estimated discharge among the aep estimates and poorer goodness of fit the inclusion of only paleoflood discharges with minimally adjusted floodplain elevation improved the fit of data along the curves scenarios 8 9 the harmonized record which included only the highest magnitude paleoflood found at both sites resulted in a more negatively skewed model and had the best fit of data along the curves 4 2 influence of spatial variability on flood frequency estimation the sedimentological analyses determined that the two paleoflood records contained both common and distinct paleoflood observations we used bayesian flood frequency analyses to determine how the two different paleoflood records might affect flood frequency analyses and to investigate the potential benefits of using combined paleoflood records in this section we compare flood frequency models between big oak only scenarios 2 east levee 2 only scenarios 3 and one harmonized record containing the four paleoflood identified at both sites scenario 10 the estimated mean discharges and the location µ and scale σ parameters between flood frequency models were not dramatically different table 2 the estimated shape parameter γ for east levee 2 was the largest difference in model parameters from the other models east levee 2 produced a highly positive skewed model 0 55 compared to the mostly negatively skewed models for all other scenarios or slight positive skew in the full big oak only record 0 14 the positive estimated skew value associated with the east levee 2 model resulted in a flatter curve than big oak and the harmonized record fig 11 although the models did not exhibit significant differences in location parameters the shape parameter s skew in east levee 2 resulted in different estimated discharges fig 11 the most significant difference in estimated discharge for annual exceedance probabilities aeps at all model scenarios and east levee 2 was between 0 01 aep 100 yr flood and 0 0001 10 000 yr flood between this aep range east levee 2 estimated smaller discharges compared to big oak meaning differences in preservation have quantifiable impacts on risk assessments we observedsmaller differences in estimated discharge between big oak and east levee 2 models in the tail ends of the curve but both models estimated higher discharge on the extreme tail than the subset with minimally adjusted floodplain elevation scenarios and harmonized model scenarios fig 12 we also evaluated model performance based upon the span of the confidence intervals that bound the model one of the most beneficial aspects of adding paleoflood data to flood frequency analyses is that it decreases the uncertainty for rare aeps by narrowing confidence interval bounds england et al 2019 but it is essential to consider confidence interval reduction in conjunction with goodness of fit assessments because narrowing confidence interval bounds can occur as a consequence of the length of record and perception threshold selection gaál et al 2010 for aeps below 0 0001 10 000 yr recurrence the east levee 2 flood frequency model scenarios produced the smallest ranges of confidence interval bounds fig 13 because they were the longest records the big oak and harmonized model scenarios also decreased the uncertainty with little difference to east levee 2 relative to the range of confidence bound for systematic only data east levee 2 produced the worst fitting curve which resulted in a lower estimate of paleodischarge for important aeps in comparison to the big oak and harmonized models these differences are related to the completeness of paleoflood observations between the two paleoflood chronologies likely created by flood deposit preservation issues over time 5 discussion 5 1 strategies to address complexity related to aggradation of alluvial surfaces over time 5 1 1 reconstructing paleodischarges complicated by aggradation paleoflood hydrologic data in alluvial rivers are used to improve flood frequency analyses for flood hazard assessment kelson et al 2018 evin et al 2019 and to understand flood regime changes over time munoz et al 2018 the coarseness of overbank deposits can provide insight into paleodischarges in alluvial rivers where the paleoflood stage derived from topographic position alone cannot distinguish flood magnitude the sediment coarseness will reliably estimate paleodischarge if the river s local morphology is stable shen et al 2021 ideal floodplains for paleoflood reconstruction are dominated by overbank processes and experience aggradation over time changing the floodplain elevation and the hydrologic connectivity between the channel and floodplain therefore we must account for aggradation to detect a relationship between sediment coarseness and discharge this study tests an innovative strategy for estimating minimum paleodischarges in an aggradational fluvial environment by adjusting floodplain elevations to reflect morphology contemporary to flood deposition the adjusted floodplain elevations applied in the 1d hydraulic modeling of the minimum estimated paleodischarges improved the detection of magnitude changes and produced flood frequency analyses that fit better along curves with the available systematic discharge data although our method of accounting for levee and floodplain aggradation over time by lowering floodplain elevations based on paleoflood deposit depths simplifies complex floodplain processes the resulting paleoflood chronologies are consistent with paleoflood estimates in other parts of the tennessee river basin harden et al 2020 reconstructed paleofloods using conventional paleostage indicators in an entirely confined bedrock gorge of the tennessee river approximately 140 km upstream of our study area near chattanooga tennessee the parches cove paleoflood chronologies appear to have captured some of the same paleofloods five at big oak and three at east levee 2 identified in the tennessee river gorge table 3 only one flood in 350 ce from the tennessee river gorge record was not identified at the parches cove study sites on average our lower bound estimates for minimum paleoflood discharges were 810 m3 s larger and upper bound estimates were 570 m3 s smaller than the bounds reported for the tennessee river gorge record the lower discharges estimate for the paleofloods are small enough to be explained by increased attenuation space between the gorge and our site downstream average differences between parches cove and tennessee river gorge paleodischarges exclude the discharges of the exceptional 1650 ce paleoflood reconstructed in the tennessee river gorge harden et al 2020 which was at least 14 500 m3 s larger in the gorge than estimates at parches cove the discharge estimated for the 1867 ce flood of record was estimated at approximately 12 990 m3 s in the tennessee river gorge at usgs stream gauge 03568000 the 1867 discharge falls within the uncertainty bounds of paleoflood estimates downstream at parches cove therefore the estimated minimum magnitude of paleofloods using the d90 based reconstruction approach with adjusted floodplain elevations is consistent with other paleoflood reconstruction methods conducted independent of this study 5 1 2 incorporating paleoflood hydrologic data with adjusted floodplain elevation into flood frequency analyses the sensitivity analysis of flood frequency scenarios indicates that estimated minimum paleodischarges with afe produce significantly different curves than paleodischarges with afe while the paleodischarges presented in this study are consistent with other paleoflood estimates on the tennessee river we acknowledge that simplified methods for adjusting floodplain elevation in the 1d hydraulic model can add some level of uncertainty we must make assumptions regarding aggradation throughout the whole reach that may diverge from present day floodplain elevation to a greater degree with increasing depth and age assumptions may be limited in regions with longer historical records van der meulen et al 2020 in our case geomorphic analyses are the only option for inferring floodplain elevation before the 1700 s the spatial extent of this information is limited relative to the study s reach instead we may use the subset of paleoflood with minimally adjusted floodplain elevation to be the least impacted by simplified assumptions applied to the 1d hec ras model the subset of paleoflood data with minimally adjusted floodplain elevation represents the estimated minimum paleodischarge intervals with afe that overlapped 90 or more with the estimated minimum paleodischarges intervals without afe depth and age of deposits beyond this threshold will vary depending upon the sedimentation rate at a given site we recommend sensitivity analyses to identify a subset of paleofloods with minimally adjusted floodplain elevation for each study area section 3 2 uncertainty related to afe assumptions is strategically limited by incorporating only the minimally adjusted floodplain elevation subset into the flood frequency analysis scenarios 8 and 9 represent flood frequency analyses containing only the subset pf paleofloods with minimally adjusted floodplain elevation for big oak and east levee 2 respectively see supplemental material these scenarios resulted in a better fit of the data because subset datasets in only the most recent change point phase did not include the smaller paleoflood in the period prior to 2200 years before present 5 2 strategies to address complexity related to spatial variability of flood deposits this study identified a trend of increasing flood frequency and magnitude that is consistent with other holocene flood records in the upper mississippi river basin the largest floods between 5000 and 3000 years b p were small relative to modern floods knox 1993 2000 soil development and paleoflood estimates for this same timeframe indicate small and infrequent flooding on the tennessee river in each of these regions flood frequency increased in the last 3000 to 2000 years consistent with the sedimentation change points and paleoflood chronologies in this study flood frequency increased again at 1000 years before present in our study area and others in north america and europe ely et al 1993 knox 2000 benito et al 2015 lombardi et al 2021 most of the preserved paleofloods from the east levee 2 site were from an older and quieter flood period for the tennessee river this means the east levee 2 paleoflood dataset is a long record but one with a greater number of small magnitude floods than those preserved in the big oak paleoflood record in total east levee 2 added 15 flood interval observations and an additional 4097 years of information big oak also added 15 flood interval observations but the length of the record only added 2303 years of additional information during a flood period with higher possible discharge ranges the east levee 2 perception thresholds were assigned lower values within the flood frequency model of scenario 3 for several millennia because most of the paleoflood records contained small floods consequently 4082 censored data estimates based on the lower perception thresholds were influential their timing coincided with a documented colder climate interval that existed in northern alabama between approximately 5000 and 2000 yrs b p aharon and dhungana 2017 which likely precluded the occurrence of large or extreme floods from tropical storms or other convective origins glaser et al 2013 consequently the more muted flood regime persevered in the east levee 2 paleoflood chronology generated smaller perception thresholds being applied over a long time span in the flood frequency model resulting in lower uncertainty bounds gaál et al 2010 but with a poorly fit model the stratigraphic interpretations of east levee 2 suggest it is missing some extreme floods from the last 1000 years despite having many smaller older floods preserved the effect of a paleoflood record with better preservation of older smaller floods that resulted in lower perception thresholds being applied in the flood frequency model skewed the model s flood frequency predictions towards more moderate discharges the use of paleoflood data from multiple sites is always recommended for flood frequency analyses benito et al 2020 this study indicates that complex localized factors impact flood deposition and preservation on alluvial surfaces even at small spatial scales we recommend developing harmonized paleoflood records from alluvial sites to ensure the paleoflood chronology chosen for flood frequency analyses does not over or underrepresent flood periods within particular flood regimes the harmonized paleoflood record developed from combined data from big oak and east levee 2 effectively identified the two largest floods at parches cove and provided a robust representation of extreme floods in the last 2000 years based on comparisons with historical flood information and results of paleoflood studies conducted elsewhere in the tennessee river valley as a result the harmonized flood frequency model scenario 10 produced the best fitting curve and significantly reduced uncertainty in the 90 confidence intervals 5 3 strategies for handling long term trends in paleoflood chronologies flood magnitude and frequency change in response to shift in hydroclimate conditions cohn and lins 2005 the extreme flood clustering and a lack of stationarity are more evident when long paleoflood records are considered knox 2000 sheffer et al 2003 while it may no longer be safe to assume stationarity in flood frequency models milly et al 2008 there is no census on how to approach nonstationary flood frequency analyses salas et al 2018 serago and vogel 2018 françois et al 2019 it is necessary to detect changes in floods statistically and identify the physical drivers of these changes to develop a nonstationary flood frequency model merz et al 2012 hall et al 2014 ryberg et al 2020 slater et al 2021 trends in long paleorecords are challenging to prove statistically due to incomplete datasets caused by censored smaller flood discharges and gaps in the natural record ryberg et al 2020 making nonstationarity flood frequency analyses challenging for most paleoflood chronologies in the current state of knowledge it is beyond the scope of this study to address this knowledge gap instead we seek to address the question of which part of the flood series is most relevant to current and future climate redmond et al 2002 sheffer et al 2003 changepoint analyses of annual discharge time series employed in traditional nonstationarity detection methods are used to find significant changes in the mean or variance of flood magnitude or frequency ryberg et al 2020 paleoflood records do not contain annual peak flow information but potentially a change point in sediment coarseness could serve as a proxy for a significant change point in flood regime in this study change point analyses are used to identify significant changes in the mean coarseness of floodplain sediments owing to a combination of changes in flood regime planform geometry and sediment supply therefore grain size changes can be attributed to a combination of atmospheric watershed and hydraulic variables that drive changes in floods merz et al 2012 based on the finding of this study we interpret the most recent sedimentation phase and others with similar mean sedimentation if applicable as representative of the current flood regime this study finds that the last 2200 years of paleoflood records from parches cove are appropriate for large floods and captures a few climate fluctuations more relevant to present and future climate flood frequency scenarios 8 9 and 10 including only more recent paleofloods and minimally adjusted floodplain elevations performed the best because of the larger discharge paleoflood and perceptions thresholds relative to the systematic record 6 conclusions paleoflood chronologies provide invaluable insight into extreme floods because these records extend for millennia or more providing more opportunity for extreme flood data to be captured and spanning hydroclimatological regime changes that operate on centennial and millennial timescales that may affect extreme flood occurrence previous paleoflood studies estimate paleodischarges through high elevation paleostage indicators in bedrock confined rivers or linear regression models with the grain size of alluvial flood deposits calibrated by stream gauge data wilhelm et al 2019 like many other river systems our study area on the tennessee river contained alluvial settings and a short unregulated stream gauge record this study tested new strategies for developing alluvial paleoflood records we found that estimates of paleoflood magnitude made using a sediment transport equation with d90 sediment data and adjusted floodplain elevations were consistent across sample sites and an independently derived tennessee river paleoflood record harden et al 2020 suggesting good potential for this method to be used for paleoflood hydrologic reconstruction of magnitude in other locations with limited discharge records more studies using the same approach in alluvial rivers can help confirm this method s reliability and general applicability for reconstructing paleoflood discharges in aggrading alluvial settings essential information for conducting flood frequency analyses this study found that aggradation and localized spatial variability of flood deposition and preservation can impact flood frequency and magnitude estimates made for extreme floods based on paleoflood hydrologic data in alluvial settings in cases when flood frequency analyses are used to estimate extreme flood risk it is crucial that paleoflood hydrologic datasets 1 account for aggradation while minimizing assumption regarding paleotopography and 2 evaluate the completeness of the preserved paleoflood records we recommend the following strategies to help ensure the most robust paleoflood record in alluvial river systems for flood frequency analyses of extreme floods and to reduce epistemic uncertainty associated with these analyses a detailed geomorphic investigation of an alluvial surface can provide valuable insight into aggradation and other geomorphological changes influencing channel geometry that should be accounted for in paleodischarge estimates whenever possible multiple paleoflood chronologies should be developed for a single site compared and potentially combined the two aforementioned steps when combined permit paleoflood hydrologic data to be evaluated in terms of extreme flood preservation and hydroclimatological transitions and the most robust paleoflood hydrologic data to be applied in flood frequency models as the application of paleoflood data in flood frequency analyses increases it is important that the geomorphic context of these data are considered at every stage of the process from paleoflood chronology development to selection of perception thresholds for example to ensure the most robust flood frequency analyses possible credit authorship contribution statement ray lombardi conceptualization methodology investigation formal analysis writing original draft visualization lisa davis methodology resources writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank the tennessee valley authority joe hoagland tva vice president of innovation and research for funding this research additionally we thank tva hydrologists curt jawdy and miles yaw for providing feedback throughout the project and sharing unregulated systematic data and tva resources we thank archeologists erin pritchard tva and matthew gage university of alabama office of archeological research for helping us obtain arpa permitting prior to sampling of sediments we thank the private landowners who granted us permission and helped facilitate sample collection at the study sites we thank professor david leigh university of georgia for operating and providing access to a giddings soil probe used to collect sediment core samples finally we are grateful to john england jr from the u s army corps of engineers risk management center for reviewing our flood frequency analyses funding sources all analyses presented in this work were supported by tennessee valley authority through project no a19 0163 2019 2020 electric power research institute epri contributed to some of the costs of sediment core sample collection through research contract no 16155 2016 2018 appendix a appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128085 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
3188,extreme floods are underrepresented in stream gauge records sedimentological evidence of past floods paleofloods yields longer records allowing extreme floods to be examined over several holocene climate periods this study examines the influence of hydrogeomorphic complexity floodplain aggradation and spatially variable flood deposition on paleoflood record completeness and their implications for flood magnitude estimates made with paleoflood hydrologic data we collected two sediment cores 500 m apart from the same elevation on a natural levee along a bank of the tennessee river near guntersville alabama we measured grain size from each core at a 1 cm resolution using a malvern 3000 laser granulometer optically stimulated luminescence dating of flood deposits revealed approximate age ranges of 50 6500 years calibrated before present yrs b p for the downstream 3 5 m core i e bo1 and 190 8500 yrs b p for the upstream 4 18 m core i e el2 first a sensitivity analysis revealed adjusted floodplain elevations afe for each paleoflood cross sectional geometry to reflect floodplain aggradation over time enabled the detection of paleoflood magnitude differences suggesting floodplain aggradation should be considered in paleoflood reconstruction within alluvial settings minimum paleodischarge intervals were estimated in a 1d hec ras step backwater model by calculating the minimum paleoflood stage needed to transport the d90 of each paleoflood deposit big oak and east levee 2 sediment cores each contained 15 high magnitude identifiable paleofloods the majority of the bo1 paleofloods occurred in the last 2 000 years while most el2 paleofloods occurred between 2 000 and 5 000 yrs b p suggesting localized geomorphic complexity produced distinct paleoflood records for the same hydrogeomorphic surface four paleoflood events correlate across the two cores based on their ages and grain size distributions and we combined these four floods to create a harmonized flood chronology for the site the timing of these four floods corresponds with paleofloods that occurred in the last 2000 years in the middle section of the tennessee river identified by prior paleoflood hydrologic studies flood frequency analysis bayesian markov chain monte carlo method scenarios with ten configurations of paleoflood hydrologic data revealed differences in the number and timing of paleofloods in three paleoflood chronologies bo1 el2 and the harmonized resulting from hydrogeomorphic complexities affected model distribution parameters goodness of fit and the estimated discharges of annual exceedance probabilities used to inform the design of critical flood infrastructure as a consequence of longer records containing smaller floods the estimated discharge of the 0 01 100 yr 0 001 1000 yr and 0 0001 10 000 years aeps for el2 were 16 11 and 5 smaller respectively than bo1 estimates alluvial rivers present more challenges for reconstructing paleoflood records than bedrock confined channel settings the strategies presented in this paper can help integrate paleoflood hydrologic data into flood frequency analyses for alluvial rivers identifying and minimizing error stemming from hydrogeomorphic complexity these strategies offer opportunities to expand the use of paleoflood hydrologic data in flood frequency analyses to include more rivers located in temperate environments where climate change is intensifying precipitation and a compelling need exists to anticipate and plan for changes in extreme flood occurrence keywords paleoflood hydrology floodplain aggradation bayesian flood frequency alluvial rivers 1 introduction floods are the most frequent natural hazard and the second deadliest severe weather hazard in the united states u s lim and skidmore 2019 the primary use of 20 of dams in the u s is flood control ho et al 2017 seventy percent of dams in the u s were built before 1970 ho et al 2017 meaning that their flood design is based on 70 years of flood data the use of shorter flood records in flood frequency models applied to flood risk assessments results in large uncertainties for low probability floods such as a 10 000 year event as such federal flood frequency guidelines england et al 2019 now recommend extending flood records with historical botanical and sedimentological flood reconstructions when estimating low probability floods where these data are available paleoflood hydrology uses data obtained from flood sediments deposit elevation and age grain size mineralogy etc and hydrological and statistical models used to reconstruct the frequency and magnitude paleodischarge estimates of past floods paleofloods extending flood records by several millennia benito and o connor 2013 by extending the flood record observations of rarer extreme floods are increased reducing the amount of extrapolation required to estimate rare flood probabilities resulting in decreased uncertainty associated with estimations of remote probability floods harden et al 2011 paleoflood reconstructions combined with statistical procedures for treating data with a range of possible values in flood frequency analyses stedinger and cohn 1986 have changed how flood frequency and hazard assessments can be performed plans and designs for significant infrastructures such as dams and nuclear plants must consider extreme and rare probabilities with 10 3 and 10 7 chances of happening each year jarrett and tomlinson 2000 prior to the integration of paleoflood hydrology into flood risk assessments deterministic approaches such as the probable maximum flood salas et al 2014 commonly were relied upon because of the large uncertainties associated with rare annual exceedance probabilities aeps estimations made with probabilistic methods jarrett and tomlinson 2000 stemming from fewer observations of extreme floods in recent decades regulatory agencies such as the u s bureau of reclamation moved towards probabilistic risk assessments because flood frequency curves incorporating paleoflood data yield aep estimates for extreme floods with less uncertainty england 2011 traditionally most paleoflood hydrology studies are in bedrock confined channels located in arid and semi arid climates where flood deposits are less disturbed by biological processes bioturbation and channel geometry is assumed to be consistent through time benito and o connor 2013 paleoflood discharges for bedrock channels are deduced from the elevation of flood deposits and the minimum flood stage required to access deposit elevation few quantitative paleoflood hydrologic studies i e studies resulting in paleodischarge estimates focus on alluvial rivers despite their geographical ubiquity and co occurrence with major population centers and river infrastructure o connor et al 2014 alluvial rivers present specific challenges to applying quantitative paleoflood hydrologic methods for which specific adaptations are lacking the most significant challenge in applying quantitative paleoflood hydrologic methods in an alluvial setting is that flood magnitude cannot reasonably be assumed based on deposit elevation because flood stage is reduced when floodwaters spread laterally across floodplains and terraces during floods recent paleoflood studies circumvent this challenge by differentiating paleoflood magnitude based on sediment coarseness differences measured for each paleoflood deposit increased flood discharges and flow velocities suspend larger grain sizes in higher volumes walling 1974 asselman 2000 lenzi and marchi 2000 if there is suitable overlap with the annual peak flow record measured by stream gauges paleoflood magnitude can be estimated by establishing a linear regression relationship between sediment particle size d90 for example allowing sediment particle size to serve as a proxy for paleodischarge toonen et al 2015 leigh 2018 munoz et al 2018 fuller et al 2018 shen et al 2021 paleoflood discharges that occurred prior to the instrumented record are modeled using the linear regression equation and the influence of aggradation may be limited by detrending the grain size variability leigh 2018 while this approach significantly increases the number of alluvial rivers and reaches where quantitative paleoflood studies can be conducted it is less feasible in river systems where long stream gauge records are not available and where changes in hydrologic connectivity between the channel and floodplain have occurred that can alter statistical relationships between grain size and discharge changes in hydrologic connectivity help determine the flood stage needed to initiate floodplain sedimentation lateral migration and vertical accretion of the floodplain over time change the vertical and lateral distance of the channel from the floodplain and thereby affect the size of sediments that can be deposited on the floodplain standardizing and detrending sediment particle size data improves the identification and estimation of paleodischarges toonen et al 2015 however paleodischarge estimates become less reliable where planform and or channel geometry changes shen et al 2021 because vertical accretion increases floodplain elevation it also increases bankfull thresholds leigh 2018 peng et al 2019 meaning that paleotopography differs through time and impacts paleodischarge estimates van der meulen et al 2021 furthermore aggradation can occur in rapidly in response to an overbank flood meaning bank height may change in abrupt nonlinear patterns knox 2006 shen et al 2015 therefore aggradation may impact hydrologic connectivity rapidly enough to warrant account for changes in floodplain elevation for each paleoflood yet rarely do paleoflood studies address the effect of aggradation on paleodischarge estimates beyond detrending techniques a second challenge to accurate paleodischarge reconstruction in alluvial channels is paleoflood deposit perseveration which is influenced by spatially heterogeneous processes of erosion and deposition harden et al 2010 compared the ages of paleoflood deposits found in 18 bedrock and 20 alluvial river reaches in the southwestern u s deposit ages suggested that bedrock systems tended to preserve younger floods while alluvial settings preserved longer and older paleoflood records but paleoflood chronologies derived from southwestern alluvial rivers contained fewer preserved paleofloods corresponding to a highly active flood period 1000 500 years before present well preserved in bedrock reaches the differences between alluvial and bedrock paleoflood chronologies identified by harden et al 2010 suggest erosion related to channel incision and migration in the alluvial reaches impacted the preservation of extreme floods effectively biasing the total paleoflood chronology for some sites towards smaller flood preservation as a consequence of channel adjustments to changing flood regimes geomorphic studies of modern floods also show that erosion and sedimentation patterns across an alluvial surface can vary depending on storm duration timing and the sediment source area asselman and middelkoop 1998 magilligan et al 2014 heitmuller et al 2017 therefore locations across the same geomorphic surface and elevation may contain differences in records of flood events owing to spatio temporal complexities in erosional and depositional processes finally bioturbation e g soil development and loss of bedding structure from organismal activities also can affect the preservation of flood deposits left unscathed by erosion with humid climates having greater potential for bioturbation benito et al 2020 ultimately all paleoflood hydrologic data require expert interpretation of multiple lines of evidence of past flood activity and a level of simplification to be applied in modeling and predicting complex natural processes ideally paleoflood hydrologic data would be reconstructed under perfect conditions such as a stable river valley with preservation of discrete laminated flood deposits that lack sedimentary gaps and that are located in close proximity to a stream gauge with a long record 100 years in reality ideal conditions rarely occur and limiting paleoflood hydrologic analyses to only include ideal sites would deprive many communities dealing with flood risk particularly in need of extreme flood hazard assessment of the benefits of paleoflood hydrologic analyses such is the case for the tennessee river which is one of the most socio economically significant rivers in the u s more than 10 million people across seven states rely on hydroelectricity generated by the tennessee river tva 2021a a series of 49 cascading dams regulate the flow of the tennessee river tva 2021a by 1945 nine dams completely impounded the tennessee river main channel tva 2021b leaving long unregulated flow records lacking and limiting the possibility of applying a linear regression approach e g toonen et al 2015 to quantify paleodischarges for the river mainstem the river s flow regulation results in good paleoflood deposit preservation however terraces and floodplains are decoupled from the channel except for during extreme flooding over half of the tennessee river basin s 4 6 million residents live along its banks tennessee riverlane 2021 depending on the dams for effective flood control drinking water and power resulting in a compelling need to assess extreme flood risk despite the challenges presented by the river s alluvial nature and flow regulation therefore this paper outlines strategies for minimizing uncertainty in quantitative paleoflood hydrologic analyses in an alluvial setting or where unregulated flow records are limited scenarios that are not uncommon given the global occurrence of river regulation we test the impact of floodplain aggradation through time and paleoflood chronology completeness on flood frequency and magnitude estimates determined with bayesian statistical models and present an underused alternative method for estimating minimum paleoflood discharges based on determining the minimum height needed for particle entrainment first we examine differences and similarities between two paleoflood chronologies developed from two different sediment cores sampled 500 m apart on the same hydrogeomorphic surface a relict natural levee second we assess the impact of adjusting floodplain elevation when calculating paleodischarges to counteract the effect of bankfull thresholds increasing as floodplains aggrade to paleoflood magnitude estimates and perception thresholds third we evaluate the influence of paleoflood preservation differences on flood frequency models specifically shape parameters and estimated discharges for aeps the findings provide new insights for quantitative paleoflood hydrologic studies conducted in alluvial rivers or rivers lacking reliable annual peak flow records which if implemented should result in more robust flood frequency analyses particularly for extreme flood risk assessments i e floods with low aeps 2 methods 2 1 study area paleoflood hydrologic analyses were conducted for a location a relict natural levee of the tennessee river near guntersville alabama fig 1 the tennessee river is a mixed bedrock alluvial system making it well suited to exploring flood deposition issues since it contains both confined bedrock and alluvial channel settings the tennessee river basin can be divided into two sub basins delineated by a deep narrow gorge located near chattanooga tennessee below which the river flows south into the northeastern corner of alabama jones et al 2015 upstream of chattanooga lie the river s headwaters in the great smoky mountains range of the appalachian mountains the upper tennessee basin begins at the confluence of the holston and the french broad rivers near knoxville tennessee the lower tennessee basin below chattanooga takes a western turn in guntersville alabama it crosses the northern portion of alabama before flowing north until its confluence with the lower ohio river near livingston kentucky the overall east to west flow of the river exposes it to several different hydroclimatological flood mechanisms including mid latitude cyclones hurricanes and intense convective storms u s weather bureau 1965 the gulf of mexico provides a nearby source of moisture that feeds the storms affecting the basin the flood of record for the river segment where the study site is located occurred in march 1867 ce resulting from a 12 day quasi stationary front with two secondary bands of moisture from the gulf of mexico tva 1961 strong el niño years increase annual precipitation jones et al 2015 likely because mid latitude cyclones also increase in magnitude and frequency during el niño senkbeil et al 2012 mid latitude cyclones are the most common cause of flooding in the tennessee river lecce 2000 while many tennessee river floods occur in the late winter and spring the most significant increase in seasonal rainfall over the last 50 years has occurred during the summer and fall jones et al 2015 a phenomenon that has been associated with the occurrence of extreme floods smith et al 2018 part of our analyses involved a sedimentological examination of two sediment cores to reconstruct paleoflood frequency and size at the study site the sediments taken from the natural levee have two primary sources with distinct mineralogy including locally derived sheetwash material and overbank sediments deposited during floods sheetwash from hillsides and valleys proximal to the site originate from weathered sedimentary rocks including pennsylvanian aged sandstones and mississippian aged mudstones and limestones osborne and ward 2010 parent materials for overbank sediments come from the tennessee river s headwaters in the great smoky mountains which are comprised of micaceous metamorphic rocks moore 1988 the different geology of the primary source areas delivering sediments to the natural levee makes overbank flood sediments associated with tennessee river flooding visually distinguishable based on mica content harden and o connor 2017 2 2 site selection the paleoflood records used in this research were reconstructed from two sediment cores sampled from a relict natural levee located on the left bank of the tennessee river approximately 10 km from guntersville al usa many paleoflood studies conducted in alluvial settings target low lying floodplain environments distanced from the channel oxbows meander scars paleochannels etc see for example toonen et al 2015 munoz et al 2018 shen et al 2021 such locations have some distinct advantages since their positions away from the active channel can mean less erosion through time and in some cases a sense of flood magnitude can be ascertained based on the inundated area required for flooding to have occurred at the location levees result from a combination of lateral migration and overbank processes that are not well understood ferguson and brierley 1999 johnston et al 2019 while no consistent controlling factors of levee shape and size have been identified levee height is controlled by overbank deposition associated with floods johnston et al 2019 levees are vulnerable to more frequent erosion than backwater environments which can impact deposit preservation brierley et al 1997 despite having a more dynamic sedimentation environment than backwater zones paleoflood studies can be conducted from levees providing adequate dating of materials is achieved e g leigh 2018 peng et al 2020 we selected the natural levee at parches cove for detailed analyses for two primary reasons first it is a relict feature formed prior to the construction of the dams and river regulation 1933 ce which subsequent to damming became decoupled from the channel protecting it from more contemporary floods and erosion this assertion was confirmed at the conclusion of our stratigraphic analyses when ages determined for stratigraphic units showed that none of the deposits were younger than 1917 ce second extensive geomorphological and pedological investigations of the parches cove location revealed that the natural levee contained the best preservation of flood deposits from the tennessee river we exposed trenches pits and cores and described sediment from a total of seven floodplain locations fig 2 before choosing the levee sites for detailed analyses from the preliminary geomorphic and pedologic investigations we determined that the hydrogeomorphic floodplain of the tennessee river occupied only a portion of the parches cove landscape i e the main valley flat the floodplain boundary on the left bank of the river roughly coincided with bedrock and regolith outcroppings located south of clark bluff in fig 2 following an east to west trajectory pits and trenches exposed south of the unnamed hill lacked alluvium initially we suspected the low topographic area highlighted in fig 2 south of the unnamed hill could be a paleochannel because of its upstream to downstream orientation four trenches excavated within the topographic low lacked evidence of paleochannel stratigraphy such as lag deposits or fining upward sequences three sites blue boxes in fig 2 were well developed soils forming within regolith without any tennessee river sediment the western most trench located within the topographic low contained overbank clay rich tennessee river sediments overlying limestone residuum at 2 m below the surface we examined a sediment core from a low lying floodplain area that should have been inundated by the historic 1867 ce flood based on an estimated stage tva 1940 open blue circle on fig 2 but the core contained sediments derived from sheetwash from surrounding hillslopes based on angularity and differences in mineralogy with tennessee river sediment communication with the land manager revealed that this location floods from groundwater intrusion and not overbank water land manager personal communication 2017 the pits trenches and cores we sampled revealed a clay rich paleosol that can be stratigraphically correlated across the active floodplain of parches cove fig 3 this paleosol is consistent with buried bt complexes found in bank exposures of a paleosol located downstream of parches cove stewart 2020 the findings of our preliminary geomorphic and pedologic assessments suggest that the active floodplain of this portion of the tennessee river has been dominated by overbank deposition as opposed to lateral migration and that the river has been confined to a limited portion of the landscape resulting in good perseveration of flood deposits in the natural levee bedrock and regolith outcrops may have aided in deposit preservation by stabilizing the channel s position fig 1 similar to floodplains observed by ferguson and brierley 1999 in another mixed bedrock alluvial river the lower tuross river in the tuross river the levee was preserved over millennia having experienced more overbank deposition than erosion as a consequence of little channel migration the occurrence of the clay rich paleosol also likely contributed to channel stabilization as clay rich bank material has a higher resistance to erosion and lowers lateral migration rates hickin and nanson 1984 2 3 flood peak identification we collected two cores from a natural levee surface at approximately equal elevations 176 19 m asl we described the stratigraphy of sediment cores based on unit thickness texture munsell color sediment structure mineralogy including mica content pedogenic features and other notable features e g bioturbation and cultural artifacts first the geoluminescence dating research lab at baylor university measured optically stimulated luminescence osl dates for flood sediments from the natural levee sites table 1 we estimated deposit dates using an age depth model osl dates in a bayesian accumulation bacon model blaauw et al 2018 we assigned hiatus periods 685 years maximum at the top depth for each buried a horizon to represent multi century surface stability resulting in soil development based on osl dating constraints above and below a representative a horizon additionally the hiatuses indicated where prior information in the bacon model should reset because flood deposition rates subsequent to the hiatuses may differ from the previous period next we reconstructed flood peaks from levees based on the grain size distribution of flood deposits measured at 1 cm resolution using laser granulometry with a malvern mastersizer 3000 several factors may influence grain size variation apart from flood magnitudes such as channel migration surface aggradation sediment availability changes and vegetative cover we used three strategies to statistically control for sediment variation with each sediment core that is unrelated to floods change point analysis cpa was applied to statistically identify down core changes to sedimentation to support stratigraphic facies described in the cores toonen et al 2015 killick et al 2016 we set a low detection threshold for the cpa to avoid the detection of small variability such that change points represent distinct periods of sedimentation created by long term persistence for example people set fires for various management purposes at an intermediate spatial scale in the southern appalachians since the woodland periods 3000 1000 years before present and maize production peaked during the mississippian period approximately 1000 years before present delcourt and delcourt 1998 this land use change would affect sediment yield within a river system over time therefore we used the cpa to identify these critical shifts in sedimentation we processed grain size distributions using end member modeling analysis emma to unmix processes affecting grain sizes within the core dietze et al 2012 toonen et al 2015 munoz et al 2018 processes influencing grain sizes at each site likely including deposition occurring during different phases of storm hydrographs sheetwash and pedogenesis we interpreted the emma results from geologically feasible processes likely impacting sedimentation based on our knowledge of the site such as flood deposition pedogensis and changes in sediment source weltje and prins 2007 van hateren et al 2018 for example during peak discharges most fine particles will remain entrained therefore the grain size distribution of a peak discharge deposit end member should contain mostly coarser sand without a large volume of clay based on emma results the coarsest end member or larger was used to identify sediment core deposit layers corresponding to flood peaks we smoothed grain size data using local polynomial regression loess to reduce localized variability from non flood related variables that can change between flood events such as coarse woody debris or small changes in riparian cover leigh 2018 positive residuals plotting above the loess smooth line were interpreted as flood peaks fig 4 flood peaks derived from high resolution grain size data analysis may represent individual floods flood pulses from the same flood or composite peaks from multiple floods occurring in short succession leigh 2018 without an overlapping instrumented record and only a single historic flood the flood of 1867 ce for reference we limited our paleoflood reconstruction to peaks with positive residual values greater than or equal to 4 which is the positive residual value associated with the 1867 ce flood fig 4 from this subset of flood peaks we removed two smaller flood peaks dated within 50 years and deposited within 5 cm of one another the remaining floods peaks we interpret as a subset of discrete large flood events 2 4 paleoflood magnitude estimation the whitesburg stream gauge operated by the united states geological survey nearest to our site only contains unregulated annual peak flow records from 1925 to 1936 ce paleodischarges are more commonly estimated using linear regression equations for relationships between sediment grain size and instrumented discharge records see leigh 2018 for example but the youngest flood deposit identified in the sediment cores was the historic flood of 1867 ce and both cores distinctly lacked 20th century flood deposits likely because of river regulation that came with the construction of the tva dams consequently we applied a different approach that has been underutilized in paleoflood hydrologic studies conducted in alluvial rivers we estimated paleoflood discharges in this study based on the paleoflood height needed to entrain the coarsest sediment fraction d90 measured for each paleoflood deposit the d90 is the grain size in millimeters below which 90 of the sediment sample is smaller than the d90 diameter the benefit of using d90 as a coarseness metric of sediment rather than the volume of coarsest sediment used in linear regression based estimates of paleodischarges e g toonen et al 2015 leigh 2018 is that it allows the use of sediment transport equations brandon et al 2014 when peak flow records are lacking the d90 for the two sediment cores analyzed in this study consist of 0 25 mm sand we chose to base our discharge reconstructions on the d90 grain size of each extreme paleoflood deposit based on previous research indicating an association between the d90 and high magnitude flood deposition research previously completed upstream of the study site simmons 1993 oblinger 2003 leigh 2018 demonstrated that flood deposits consist of 0 25 mm sand and larger particle diameters confident that medium to coarse sand comprised flood deposition based on the previous studies conducted upstream we chose to use the d90 particle diameter of the paleoflood deposits detected at our study site since our goal was to characterize past extreme floods numerous studies of floodplain deposits worldwide find that particle size distribution end members such as the d90 are associated with the highest magnitude flood events this association has been documented for rivers in the upper mississippi river basin knox and daniels 2002 the upper tennessee river basin wang and leigh 2012 leigh 2018 the lower rhine river in germany and the netherlands toonen et al 2015 and the severn river basin of england pears et al 2020 these studies validate the ideas posited by colby 1963 that the transportation of coarse sediment is more consistently related to increased discharge than the transportation of fine sediment because 1 sources of coarse sediment are more localized coming from what was left in the cross section since the previous high flow event while fine sediment can come from sheetwash runoff and is affected by the availability of fine sediment in extra channel environments and 2 fine sediment supply is more likely to be exhausted prior to high discharge events because their transportation is facilitated by a range of flows well below bankfull we estimated the minimum paleoflood height hpf in meters above the sampling surface required to entrain each d90 particle diameter in meters using eq 1 fig 5 from cyr et al 2015 cyr et al 2015 reworked a critical shear stress equation to solve for height of weight and used the equation to determine paleoflood discharges using pebble diameters in our calculations using eq 1 we used the particle density of quartz for ρs because it was the most common mineral 80 identified in osl samples extracted from the natural levee site stewart 2020 this method of estimating paleoflood discharges uses the same basic assumption underpinning the gauged discharge sediment volume linear regression approach more commonly applied in alluvial paleoflood discharge estimation which is that as discharge increases so too does the flow s ability to entrain coarser particles a key difference is that the equation eq 1 in fig 5 used in our calculations taken from cyr et al 2015 reflect energy changes as a function of water surface height and slope and assume that transport initiates when the product of water height and slope exceed the combined effect of particle cohesion and particle weight to resist transport sand transport could be initiated at lower flood heights because of velocity increases associated with localized hydraulic changes channel constrictions from debris jams or the development of standing waves related to bedforms for example but as previously explained we excluded paleofloods from the flood frequency analyses that did not have positive residuals equal to or greater than the historic flood of record flood of 1867 ce censoring the flood frequency dataset to consist only of large floods we used a step backwater 1 d hydraulic model in hec ras 5 0 3 to estimate paleoflood discharges by iteratively running steady flow discharges until reaching a discharge that matched the stage of each paleoflood hpf the hydraulic model contained sixteen total cross sections six downstream from big oak and eight upstream from east levee 2 big oak had river valley width of approximately 1100 m and a maximum channel width and depth of 280 m and 24 m respectively east levee 2 had a river valley width of approximately 1010 m and a maximum channel width and depth of 363 m and 17 m respectively the 1 m resolution lidar and bathometry were provided by tennessee valley authority lam et al 2017 found that despite there being a greater potential for hydraulic geometry to change as a result of sediment flux in alluvial river valleys these hydraulic geometry changes did not significantly impact paleodischarge estimates derived from paleoflood hydrologic methods for a 2000 year long record lam et al 2017 because few studies have attempted paleodischarge estimates in alluvial rivers however we decided on a conservative approach and adjusted the hydraulic geometry used in the hec ras flow modeling to account for the floodplain aggrading over time aggradation would increase the elevation of the floodplain over time meaning that the stage needed to access the floodplain would also increase not accounting for this geomorphic change potentially could risk underestimating the discharge of more recent paleofloods post aggradation relative to older paleofloods prior to aggradation we identified the soil series correspond to sites with preserved tennessee river alluvium at parches cove then we identified the spatial extent of the active floodplain in the whole river reach using maps of these soils the hydraulic radius spanning active floodplain surfaces was adjusted through time by subtracting elevation equivalent to the depth of a paleoflood deposit as this can be assumed to be the surface of the floodplain during deposition see section 2 5 for more details the channel portion of the hydraulic radius was assumed to be consistent through time and not adjusted because it is comprised of an exposed bedrock shoal based on measurements of depth to bedrock made by tva for dam construction purposes tva 1941 the resulting adjustments required unique hec ras geometries for each paleoflood with consistent manning s n values for all pre historic floods thus the only differences that affect discharges between each modeled paleoflood are the d90 derived flood heights and floodplain elevations in the hydraulic geometries finally we used a range of 25 manning s n values in the channel and on the floodplain to estimate the minimum and maximum discharge ranges for paleofloods we calculated the normal depth using the frictional slope of the 1867 ce flood from the change in flood surface elevation over the length of the river reach we used the reconstructed longitudinal profile created from historical 1867 ce flood high water marks along the tennessee river to measure changes in elevation of the flood profile tva 1940 2 5 sensitivity analysis of impact of adjusted floodplain elevations afes we attempted to develop paleoflood reconstruction methods that best reflect natural processes occurring within the system and that limit assumptions about past environments in the absence of unregulated and long discharge records we back calculated paleodischarges by estimating the paleoflood stage physically needed to deposit sediment d90 on the floodplain but essentially our assumptions and rationale are the same as those made in linear regression based paleodischarge estimates in both cases it is assumed that larger particle sizes require faster velocities associated with larger discharges to be transported and deposited outside of the channel in alluvial rivers however floodplains aggrade and in turn the threshold to exceed bankfull discharge increases with aggradation a given particle size diameter and the corresponding minimum flood stage at the surface would require a larger magnitude flood to occur than the same particle one meter below the surface because the floodplain elevation changed fig 6 therefore it would not be appropriate to treat these floods as equally sized events in this study we uniformly adjusted the floodplain geometry in the 1d hec ras model to account for aggradation of the surface through time based on the depth of the deposit for which a minimum paleodischarge was being modeled uniformly adjusting the floodplain is a simplification of coupled channel floodplain hydrogeomorphic changes but it does limit the number of assumptions needed to be applied across a large spatial domain to recognize the impacts of oversimplifying floodplain elevation we performed a sensitivity analysis of adjusted floodplain elevations afe in minimum paleodischarge estimates on the resulting paleoflood magnitudes and flood frequency curves we compared the percent difference in minimum paleoflood discharges without afe i e the modern surface and with afe modern surface minus the depth to paleoflood deposit additionally we identified minimally adjusted floodplain elevation subset of the paleofloods with afe based on paleodischarge intervals that overlap more than 90 with paleodischarge intervals modelled without afe the full paleoflood chronologies with and without afes and subset chronologies paleoflood with minimally adjusted floodplain elevation were used to generate flood frequency analyses and test their impact on three estimated model parameters location shape and skew and the confidence intervals the sensitivity analysis will provide insight into the point at which the additional uncertainty from adjusting the floodplain may outweigh the benefits afe provides in differentiating paleodischarges 2 6 bayesian flood frequency estimation our flood frequency models incorporate three types of data sources systematic interval and censored data years below perception thresholds systematic data are flow measurements taken regularly under a protocol and represent an exact discharge value in the model interval data are flood events where exact discharge is unknown but the value falls within a known range finally perception thresholds indicate a range of possible discharges below a threshold for a given year independent of observations england et al 2019 years without a perception threshold exceedance contain censored data we used peak flow stream gauge data usgs gauge 03575500 from 1925 to 1936 in each flood frequency analysis ffa we extracted annual peak flow from simulated unregulated total flow records from 1950 to 2013 based on rainfall runoff models provided by the tennessee valley authority tva 2020 derived from dam inflow measurements above our site our systematic data comprised the combined simulated peak flow and observed peak flow data from 1925 to 2013 paleoflood data were included along with the systematic data to create a flood frequency model for each site we performed flood frequency analyses in rmc bestfit v1 0 software using the bayesian markov chain monte carlo mcmc framework kuczera 1999 gaál et al 2010 smith and doughty 2020 rmc bestfit uses the maximum likelihood estimation mle method to fit a log pearson type 3 lp3 distribution curve to the systematic interval and censored data perception thresholds before 1925 were selected based on paleoflood and sedimentation information for each of the ten scenarios table 1 each scenario is given different perception thresholds that reflect the length of the paleoflood record and changes in discharge over time we chose the highest possible perception thresholds for each period based on the lower estimate with the most likely range of discharge based on our paleoflood information 3 paleoflood chronologies 3 1 paleoflood identification and stratigraphic interpretations extensive stratigraphic and statistical analyses of the two sediment cores revealed cumulic alluvial sedimentation overlying a buried paleosol suggesting that both sampling locations experienced progradation of the natural levee throughout much of the mid to late holocene fig 7 our analyses statistical analyses of particle size data and hydrologic modeling identified 15 paleofloods preserved at each site the timing of these paleoflood events however differed between sites fig 8 as a function of preservation most of the sampled and dated big oak paleofloods occurred in the last 2000 years whereas most of the sampled and dated east levee 2 paleofloods occurred before 2000 years before present yrs b p despite the difference in the timing of floods both sites demonstrated a steady increase in minimum flood magnitude over the last 6000 years with the largest magnitude floods occurring within the last 1000 years the four paleofloods estimated to have been the largest preserved floods at parches cove occurred in both sediment cores and their common ages as well as sedimentological and stratigraphic similarities are interpreted as evidence of the same flood events affecting both sediment core sampling locations on the natural levee notably flood magnitude estimates made for the largest floods using a modified shear stress equation cyr et al 2015 differed by 10 between the two coring sites fig 8 suggesting that flood magnitude estimations based on grain size are reliable and comparable between locations despite the core sampling locations being relatively close and flood magnitude estimates being consistent between the two cores the timing of paleofloods excluding the four largest preserved floods varied between the big oak and east levee 2 cores the close proximity of the sampling sites combined with similar paleoflood ages strongly suggest that the four largest floods inundated both of the core sampling locations on the levee fig 7 the sediment cores differed in their physical length and temporal length of record with the big oak core being shorter 3 5 m vs 4 18 m and containing younger materials than the east levee 2 core but the east levee 2 core overlaps the big oak paleoflood record with the oldest flood preserved in the east levee 2 core dating to 6000 yrs b p because the two paleoflood records reconstructed from the two cores temporally overlap it is less likely that the differences in the timing of paleofloods relate to each core containing floods from different intervals of time instead it is more likely that differences in the timing of preserved paleofloods resulted from localized factors influencing spatial deposition and preservation of flood deposits over time stratigraphic observations combined with the results of the change point analyses of the sediment particle size data for each core provide supporting evidence of localized factors contributing to the perseveration of distinct paleoflood chronologies differences in the thickness and depth of stratigraphic units exist between the cores fig 7 both cores contained the same well developed buried paleosols at their bases we identified a several flood packages in the upper half of both cores incipient soils characterized by weakly developed b horizons overlying c horizon overbank parent material despite identical timing of the recent change point between sites age depth models developed using osl ages and change point analyses demonstrate key differences between big oak and east levee 2 big oak contains two distinct sedimentation phases fig 9 the time between 2200 and 6700 yrs b p was a quiet period when sedimentation occurred less frequently and a deep soil formed east levee 2 has soil developed in the same 2200 6700 yrs b p period but paleoflood peaks were preserved and perceived through flood peak analyses until approximately 5000 yrs b p fig 9 east levee 2 s sedimentation phase 2200 5000 yrs b p contained episodes of larger flood peaks in the first half and smaller flood peaks in the latter half of the period it is possible that east levee 2 was strongly coupled with overbank sedimentation during this period 2200 5000 yrs b p because of its lower elevation east levee 2 s more frequent sedimentation during the second changepoint phase resulted in a high topographic position of east levee 2 relative to big oak at the onset of the most recent changepoint 2200 yrs b p both sites captured coarser sediments in the recent phase but big oak site situated at a lower topographic elevation in the downstream direction was likely inundated more frequently by smaller floods than east levee 2 consequently aggradation occurred more rapidly at big oak and decreased the difference in elevation to east levee 2 during the last 2000 years levee development observed at parches cove is consistent with johnston et al 2019 which found progradation in the downstream direction due to elevational differences altering inundation patterns in both the big oak and east levee 2 cores a significant change point occurred 2200 yrs b p marking the onset of the most recent sedimentation phase during which the largest and most frequent floods occurred based on coarse and medium sand volumes although occurring at different core depths at 0 75 m in east levee 2 and at 1 5 m in big oak the timing of the sedimentation phase 2000 yrs b p was consistent in both cores this suggests that although they are the same elevation today east levee 2 was topographically higher than big oak before 2200 yrs b p from approximately 500 1000 yrs b p during an otherwise active sedimentation phase the east levee 2 site lacked deposits dating to this interval based on the preserved record obtained from the big oak site during this timeframe 500 1000 yrs b p the levee experienced large floods and consistent progradation thus it is possible that one or more floodsoccurring between 300 and500 yrs b p eroded previous flood deposition cherokee people lived within parches cove until the 17th century according to historical maps and local history the name parches cove was originally named parched corn cove after the cherokee chief that settled on the land sterling 2016 excavation and cultivation of the land by the cherokee people could have resulted in the loss of flood deposits one pottery shard and some broken shells were identified at east levee 2 stratigraphic evidence of the soils above and below archeological material present clear or gradual boundary contacts by color we did not find any contacts characteristic of human induced mixing therefore we concluded that differences in osl ages of paleofloods are best explained as an unconformity resulting from flood scouring that occurred after 500 years before the present at the east levee 2 sampling location ultimately the preservation of flood deposits older than 2000 years before the present and the depositional gap between 500 and 1000 years before the present at the east levee 2 site resulted in a paleoflood chronology with similar flood magnitude trends through time but a different paleoflood chronology preserved from the paleoflood chronology developed from the big oak sediment core both in terms of number and timing of flood events 3 2 adjusting floodplain elevation to account for levee progradation aggradation of alluvial floodplains naturally increases the magnitude of floods necessary for deposition to occur effectively desensitizing analyses from being able to detect shifts in flood magnitude over time the sampling we conducted prior to site selection revealed that lateral migration of the channel had been limited throughout much of the latter holocene by bedrock and regolith exposures and a widespread clay rich paleosol that acted to confine the channel within a narrow segment of the valley multiple trenches and sediment cores examined from the natural level surface showed the levee to be prograding through vertical accretion during the mid to late holocene based on numerous c horizons and an absence of well developed soils within the upper 1 5 2 m furthermore the increase in deposit thickness observed at the downstream east levee 2 site relative to the upstream big oak site strongly suggested that the levee experienced intervals of longitudinal progradation because of considerable stratigraphic evidence of levee progradation we deemed it necessary to account for changes in floodplain elevation through time in the hydraulic geometries used to determine paleodischarges therefore we adjusted lowered the floodplain elevation in the 1d hec ras model to match the depth of the paleoflood deposit for which a paleodischarge was being estimated although similar floodplain elevational adjustments have been done for paleoflood studies investigating flood magnitude changes in the rhine river basin van der meulen et al 2020 van der meulen et al 2021 the approach remains relatively new and consequently its potential for yielding new insights into flood magnitude changes in alluvial rivers poorly investigated because one of the motivations of the research was to examine changes in flood magnitude over time we conducted a sensitivity analysis to determine the effect of lowering floodplain elevation during discharge estimation using the 1d hec ras modelling by comparing the paleodischarges calculated with an adjusted floodplain elevation afe corresponding the depth of paleoflood deposit depth from the modern surface to paleodischarges without an afe paleodischarges estimated without an afe were determined using the elevation of the modern floodplain adjusting floodplain elevations to reflect flood deposit depths resulted in smaller minimum paleodischarge estimates fig 10 and helped elucidate a trend of increasing paleoflood magnitude over time that would have been imperceivable without using the afe approach in this study relying on interpretations of positive residuals of the loess analysis of the medium to coarse sand volumes to identify flood magnitude changes was insufficient because the most extreme floods 4 positive residuals exhibited similar d90 values magnitude trends in paleoflood discharges become apparent however when the effects of levee aggradation were accounted for using the afe method the greatest reduction of a minimum paleodischarge estimate for the big oak paleoflood record occurred with the deepest paleoflood deposit 1 62 m below the surface which resulted in an 18 smaller minimum paleodischarge estimate without applying an afe fig 10 estimated minimum paleodischarge with an afe for the deepest paleoflood deposit at east levee 2 9 m below the surface was 33 smaller than the estimated paleodischarge without an afe minimum paleodischarges determined with an afe for paleoflood deposits located within approximately one meter of the modern surface 1200 yrs b p for big oak and 2150 yrs b p for east levee 2 containing 10 or less difference in flood magnitude than without an afe the fact that the largest with vs without afe differences in minimum paleodischarge estimates correspond to the paleoflood deposits situated at the base of both cores and the impact of afe appears to diminish as paleoflood deposit depth decreases suggests that simply subtracting elevation based on deposit depth may overcorrect for aggradation likely because compression of stratigraphic units caused by the weight of overlying material increases with depth yet ignoring aggradation and assuming modern channel geometry would also be problematic for reasons previously explained in an effort to reconcile this dichotomy we developed subsets of paleoflood observations with afe at each site that overlap more than 90 with the estimate intervals without afe these paleoflood deposits are closer to the modern floodplain and their estimates are made with minimally adjusted floodplain elevations within hec ras models 4 bayesian flood frequency analyses 4 1 flood frequency scenarios we examined ten flood frequency scenarios to illuminate the influence of paleoflood data interpretation and selection on flood frequency estimation table 2 results for each scenario are available in the supplement materials we compared results between scenarios in sections to specifically demonstrate the impact of adjusting floodplain elevations to estimate minimum paleodischarges and spatially variable flood deposits on flood frequency curves the primary insights from the sensitivity analysis includes paleodischarge estimates with afe generated flood frequency models with a better fit of data along the curves table 2 scenarios including complete paleoflood records and consequently lower perception thresholds scenarios 2 5 produce more positively skewed models which impacted estimated discharge among the aep estimates and poorer goodness of fit the inclusion of only paleoflood discharges with minimally adjusted floodplain elevation improved the fit of data along the curves scenarios 8 9 the harmonized record which included only the highest magnitude paleoflood found at both sites resulted in a more negatively skewed model and had the best fit of data along the curves 4 2 influence of spatial variability on flood frequency estimation the sedimentological analyses determined that the two paleoflood records contained both common and distinct paleoflood observations we used bayesian flood frequency analyses to determine how the two different paleoflood records might affect flood frequency analyses and to investigate the potential benefits of using combined paleoflood records in this section we compare flood frequency models between big oak only scenarios 2 east levee 2 only scenarios 3 and one harmonized record containing the four paleoflood identified at both sites scenario 10 the estimated mean discharges and the location µ and scale σ parameters between flood frequency models were not dramatically different table 2 the estimated shape parameter γ for east levee 2 was the largest difference in model parameters from the other models east levee 2 produced a highly positive skewed model 0 55 compared to the mostly negatively skewed models for all other scenarios or slight positive skew in the full big oak only record 0 14 the positive estimated skew value associated with the east levee 2 model resulted in a flatter curve than big oak and the harmonized record fig 11 although the models did not exhibit significant differences in location parameters the shape parameter s skew in east levee 2 resulted in different estimated discharges fig 11 the most significant difference in estimated discharge for annual exceedance probabilities aeps at all model scenarios and east levee 2 was between 0 01 aep 100 yr flood and 0 0001 10 000 yr flood between this aep range east levee 2 estimated smaller discharges compared to big oak meaning differences in preservation have quantifiable impacts on risk assessments we observedsmaller differences in estimated discharge between big oak and east levee 2 models in the tail ends of the curve but both models estimated higher discharge on the extreme tail than the subset with minimally adjusted floodplain elevation scenarios and harmonized model scenarios fig 12 we also evaluated model performance based upon the span of the confidence intervals that bound the model one of the most beneficial aspects of adding paleoflood data to flood frequency analyses is that it decreases the uncertainty for rare aeps by narrowing confidence interval bounds england et al 2019 but it is essential to consider confidence interval reduction in conjunction with goodness of fit assessments because narrowing confidence interval bounds can occur as a consequence of the length of record and perception threshold selection gaál et al 2010 for aeps below 0 0001 10 000 yr recurrence the east levee 2 flood frequency model scenarios produced the smallest ranges of confidence interval bounds fig 13 because they were the longest records the big oak and harmonized model scenarios also decreased the uncertainty with little difference to east levee 2 relative to the range of confidence bound for systematic only data east levee 2 produced the worst fitting curve which resulted in a lower estimate of paleodischarge for important aeps in comparison to the big oak and harmonized models these differences are related to the completeness of paleoflood observations between the two paleoflood chronologies likely created by flood deposit preservation issues over time 5 discussion 5 1 strategies to address complexity related to aggradation of alluvial surfaces over time 5 1 1 reconstructing paleodischarges complicated by aggradation paleoflood hydrologic data in alluvial rivers are used to improve flood frequency analyses for flood hazard assessment kelson et al 2018 evin et al 2019 and to understand flood regime changes over time munoz et al 2018 the coarseness of overbank deposits can provide insight into paleodischarges in alluvial rivers where the paleoflood stage derived from topographic position alone cannot distinguish flood magnitude the sediment coarseness will reliably estimate paleodischarge if the river s local morphology is stable shen et al 2021 ideal floodplains for paleoflood reconstruction are dominated by overbank processes and experience aggradation over time changing the floodplain elevation and the hydrologic connectivity between the channel and floodplain therefore we must account for aggradation to detect a relationship between sediment coarseness and discharge this study tests an innovative strategy for estimating minimum paleodischarges in an aggradational fluvial environment by adjusting floodplain elevations to reflect morphology contemporary to flood deposition the adjusted floodplain elevations applied in the 1d hydraulic modeling of the minimum estimated paleodischarges improved the detection of magnitude changes and produced flood frequency analyses that fit better along curves with the available systematic discharge data although our method of accounting for levee and floodplain aggradation over time by lowering floodplain elevations based on paleoflood deposit depths simplifies complex floodplain processes the resulting paleoflood chronologies are consistent with paleoflood estimates in other parts of the tennessee river basin harden et al 2020 reconstructed paleofloods using conventional paleostage indicators in an entirely confined bedrock gorge of the tennessee river approximately 140 km upstream of our study area near chattanooga tennessee the parches cove paleoflood chronologies appear to have captured some of the same paleofloods five at big oak and three at east levee 2 identified in the tennessee river gorge table 3 only one flood in 350 ce from the tennessee river gorge record was not identified at the parches cove study sites on average our lower bound estimates for minimum paleoflood discharges were 810 m3 s larger and upper bound estimates were 570 m3 s smaller than the bounds reported for the tennessee river gorge record the lower discharges estimate for the paleofloods are small enough to be explained by increased attenuation space between the gorge and our site downstream average differences between parches cove and tennessee river gorge paleodischarges exclude the discharges of the exceptional 1650 ce paleoflood reconstructed in the tennessee river gorge harden et al 2020 which was at least 14 500 m3 s larger in the gorge than estimates at parches cove the discharge estimated for the 1867 ce flood of record was estimated at approximately 12 990 m3 s in the tennessee river gorge at usgs stream gauge 03568000 the 1867 discharge falls within the uncertainty bounds of paleoflood estimates downstream at parches cove therefore the estimated minimum magnitude of paleofloods using the d90 based reconstruction approach with adjusted floodplain elevations is consistent with other paleoflood reconstruction methods conducted independent of this study 5 1 2 incorporating paleoflood hydrologic data with adjusted floodplain elevation into flood frequency analyses the sensitivity analysis of flood frequency scenarios indicates that estimated minimum paleodischarges with afe produce significantly different curves than paleodischarges with afe while the paleodischarges presented in this study are consistent with other paleoflood estimates on the tennessee river we acknowledge that simplified methods for adjusting floodplain elevation in the 1d hydraulic model can add some level of uncertainty we must make assumptions regarding aggradation throughout the whole reach that may diverge from present day floodplain elevation to a greater degree with increasing depth and age assumptions may be limited in regions with longer historical records van der meulen et al 2020 in our case geomorphic analyses are the only option for inferring floodplain elevation before the 1700 s the spatial extent of this information is limited relative to the study s reach instead we may use the subset of paleoflood with minimally adjusted floodplain elevation to be the least impacted by simplified assumptions applied to the 1d hec ras model the subset of paleoflood data with minimally adjusted floodplain elevation represents the estimated minimum paleodischarge intervals with afe that overlapped 90 or more with the estimated minimum paleodischarges intervals without afe depth and age of deposits beyond this threshold will vary depending upon the sedimentation rate at a given site we recommend sensitivity analyses to identify a subset of paleofloods with minimally adjusted floodplain elevation for each study area section 3 2 uncertainty related to afe assumptions is strategically limited by incorporating only the minimally adjusted floodplain elevation subset into the flood frequency analysis scenarios 8 and 9 represent flood frequency analyses containing only the subset pf paleofloods with minimally adjusted floodplain elevation for big oak and east levee 2 respectively see supplemental material these scenarios resulted in a better fit of the data because subset datasets in only the most recent change point phase did not include the smaller paleoflood in the period prior to 2200 years before present 5 2 strategies to address complexity related to spatial variability of flood deposits this study identified a trend of increasing flood frequency and magnitude that is consistent with other holocene flood records in the upper mississippi river basin the largest floods between 5000 and 3000 years b p were small relative to modern floods knox 1993 2000 soil development and paleoflood estimates for this same timeframe indicate small and infrequent flooding on the tennessee river in each of these regions flood frequency increased in the last 3000 to 2000 years consistent with the sedimentation change points and paleoflood chronologies in this study flood frequency increased again at 1000 years before present in our study area and others in north america and europe ely et al 1993 knox 2000 benito et al 2015 lombardi et al 2021 most of the preserved paleofloods from the east levee 2 site were from an older and quieter flood period for the tennessee river this means the east levee 2 paleoflood dataset is a long record but one with a greater number of small magnitude floods than those preserved in the big oak paleoflood record in total east levee 2 added 15 flood interval observations and an additional 4097 years of information big oak also added 15 flood interval observations but the length of the record only added 2303 years of additional information during a flood period with higher possible discharge ranges the east levee 2 perception thresholds were assigned lower values within the flood frequency model of scenario 3 for several millennia because most of the paleoflood records contained small floods consequently 4082 censored data estimates based on the lower perception thresholds were influential their timing coincided with a documented colder climate interval that existed in northern alabama between approximately 5000 and 2000 yrs b p aharon and dhungana 2017 which likely precluded the occurrence of large or extreme floods from tropical storms or other convective origins glaser et al 2013 consequently the more muted flood regime persevered in the east levee 2 paleoflood chronology generated smaller perception thresholds being applied over a long time span in the flood frequency model resulting in lower uncertainty bounds gaál et al 2010 but with a poorly fit model the stratigraphic interpretations of east levee 2 suggest it is missing some extreme floods from the last 1000 years despite having many smaller older floods preserved the effect of a paleoflood record with better preservation of older smaller floods that resulted in lower perception thresholds being applied in the flood frequency model skewed the model s flood frequency predictions towards more moderate discharges the use of paleoflood data from multiple sites is always recommended for flood frequency analyses benito et al 2020 this study indicates that complex localized factors impact flood deposition and preservation on alluvial surfaces even at small spatial scales we recommend developing harmonized paleoflood records from alluvial sites to ensure the paleoflood chronology chosen for flood frequency analyses does not over or underrepresent flood periods within particular flood regimes the harmonized paleoflood record developed from combined data from big oak and east levee 2 effectively identified the two largest floods at parches cove and provided a robust representation of extreme floods in the last 2000 years based on comparisons with historical flood information and results of paleoflood studies conducted elsewhere in the tennessee river valley as a result the harmonized flood frequency model scenario 10 produced the best fitting curve and significantly reduced uncertainty in the 90 confidence intervals 5 3 strategies for handling long term trends in paleoflood chronologies flood magnitude and frequency change in response to shift in hydroclimate conditions cohn and lins 2005 the extreme flood clustering and a lack of stationarity are more evident when long paleoflood records are considered knox 2000 sheffer et al 2003 while it may no longer be safe to assume stationarity in flood frequency models milly et al 2008 there is no census on how to approach nonstationary flood frequency analyses salas et al 2018 serago and vogel 2018 françois et al 2019 it is necessary to detect changes in floods statistically and identify the physical drivers of these changes to develop a nonstationary flood frequency model merz et al 2012 hall et al 2014 ryberg et al 2020 slater et al 2021 trends in long paleorecords are challenging to prove statistically due to incomplete datasets caused by censored smaller flood discharges and gaps in the natural record ryberg et al 2020 making nonstationarity flood frequency analyses challenging for most paleoflood chronologies in the current state of knowledge it is beyond the scope of this study to address this knowledge gap instead we seek to address the question of which part of the flood series is most relevant to current and future climate redmond et al 2002 sheffer et al 2003 changepoint analyses of annual discharge time series employed in traditional nonstationarity detection methods are used to find significant changes in the mean or variance of flood magnitude or frequency ryberg et al 2020 paleoflood records do not contain annual peak flow information but potentially a change point in sediment coarseness could serve as a proxy for a significant change point in flood regime in this study change point analyses are used to identify significant changes in the mean coarseness of floodplain sediments owing to a combination of changes in flood regime planform geometry and sediment supply therefore grain size changes can be attributed to a combination of atmospheric watershed and hydraulic variables that drive changes in floods merz et al 2012 based on the finding of this study we interpret the most recent sedimentation phase and others with similar mean sedimentation if applicable as representative of the current flood regime this study finds that the last 2200 years of paleoflood records from parches cove are appropriate for large floods and captures a few climate fluctuations more relevant to present and future climate flood frequency scenarios 8 9 and 10 including only more recent paleofloods and minimally adjusted floodplain elevations performed the best because of the larger discharge paleoflood and perceptions thresholds relative to the systematic record 6 conclusions paleoflood chronologies provide invaluable insight into extreme floods because these records extend for millennia or more providing more opportunity for extreme flood data to be captured and spanning hydroclimatological regime changes that operate on centennial and millennial timescales that may affect extreme flood occurrence previous paleoflood studies estimate paleodischarges through high elevation paleostage indicators in bedrock confined rivers or linear regression models with the grain size of alluvial flood deposits calibrated by stream gauge data wilhelm et al 2019 like many other river systems our study area on the tennessee river contained alluvial settings and a short unregulated stream gauge record this study tested new strategies for developing alluvial paleoflood records we found that estimates of paleoflood magnitude made using a sediment transport equation with d90 sediment data and adjusted floodplain elevations were consistent across sample sites and an independently derived tennessee river paleoflood record harden et al 2020 suggesting good potential for this method to be used for paleoflood hydrologic reconstruction of magnitude in other locations with limited discharge records more studies using the same approach in alluvial rivers can help confirm this method s reliability and general applicability for reconstructing paleoflood discharges in aggrading alluvial settings essential information for conducting flood frequency analyses this study found that aggradation and localized spatial variability of flood deposition and preservation can impact flood frequency and magnitude estimates made for extreme floods based on paleoflood hydrologic data in alluvial settings in cases when flood frequency analyses are used to estimate extreme flood risk it is crucial that paleoflood hydrologic datasets 1 account for aggradation while minimizing assumption regarding paleotopography and 2 evaluate the completeness of the preserved paleoflood records we recommend the following strategies to help ensure the most robust paleoflood record in alluvial river systems for flood frequency analyses of extreme floods and to reduce epistemic uncertainty associated with these analyses a detailed geomorphic investigation of an alluvial surface can provide valuable insight into aggradation and other geomorphological changes influencing channel geometry that should be accounted for in paleodischarge estimates whenever possible multiple paleoflood chronologies should be developed for a single site compared and potentially combined the two aforementioned steps when combined permit paleoflood hydrologic data to be evaluated in terms of extreme flood preservation and hydroclimatological transitions and the most robust paleoflood hydrologic data to be applied in flood frequency models as the application of paleoflood data in flood frequency analyses increases it is important that the geomorphic context of these data are considered at every stage of the process from paleoflood chronology development to selection of perception thresholds for example to ensure the most robust flood frequency analyses possible credit authorship contribution statement ray lombardi conceptualization methodology investigation formal analysis writing original draft visualization lisa davis methodology resources writing review editing supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments we thank the tennessee valley authority joe hoagland tva vice president of innovation and research for funding this research additionally we thank tva hydrologists curt jawdy and miles yaw for providing feedback throughout the project and sharing unregulated systematic data and tva resources we thank archeologists erin pritchard tva and matthew gage university of alabama office of archeological research for helping us obtain arpa permitting prior to sampling of sediments we thank the private landowners who granted us permission and helped facilitate sample collection at the study sites we thank professor david leigh university of georgia for operating and providing access to a giddings soil probe used to collect sediment core samples finally we are grateful to john england jr from the u s army corps of engineers risk management center for reviewing our flood frequency analyses funding sources all analyses presented in this work were supported by tennessee valley authority through project no a19 0163 2019 2020 electric power research institute epri contributed to some of the costs of sediment core sample collection through research contract no 16155 2016 2018 appendix a appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128085 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
3189,flooding is a serious and recurring natural hazard flood hazard mapping requires synthesizing relevant factors that affect flood occurrence to allow for an accurate geographical assessment of flood characteristics for flood management activities two multi criteria decision making methods consisting of the analytical hierarchy process ahp and fuzzy ahp f ahp methods were applied in identifying flood hazard areas by using two groups of flood influencing factors fifs to decrease the number of pairwise comparisons required for ahp to enable the use of an optimum set of factors for the ahp and f ahp methods fewer pairwise comparisons can reduce uncertainty caused by inconsistency in the decision making process of a larger number of factors thirteen non correlating fifs were selected and divided into two groups namely the flood susceptibility factors group fsfg and flood vulnerability factors group fvfg fsfg consisted of drainage density elevation land use slope rainfall infiltration topographic wetness index time of concentration and flood depth and fvfg consisted of distance from inundated locations distance from rivers population and distance from roads buildings the methodology was evaluated using three test scenarios a fsfg group only b fvfg group only c flood susceptibility and vulnerability factors group fsvfg the ahp and the f ahp methods were applied in evaluating the influence of each group of factors on the flood hazard maps the result of the evaluation indicated that the fvfg had the highest influence based on the spatial extent of the region by each varying flood hazard class low to very high on the generated flood hazard maps the fvfg had 40 15 and 42 09 influence in comparison with fsfg 25 85 and 25 26 and fsvfg 34 and 32 65 for the ahp and f ahp methods respectively the findings from the sensitivity analysis showed similar findings with the ahp and f ahp methods confirming the accuracy of the methods the validation of the ahp and f ahp methods showed excellent compatibility with the historical flood record and affirmed the relevance of applying fsvfg the methodology applied in this study can be a dependable support tool in flood risk analysis and management for efficient decision making to achieve a resilient city keywords flood vulnerability factors flood susceptibility factors flood hazard mapping resilient city multi criteria decision making 1 introduction floods are among the highest recurring natural disasters that lead to the loss of lives damage the economy and infrastructures and are capable of harming humans and the natural environment cred 2018 toosi et al 2019 according to the usa noaa 2001 research on global economic losses from 1950 to 2002 there is growing fear about the rising population of individuals harmed per year through natural disasters and flooding contributed to 65 of natural disaster victims 2001 higher temperatures altering spatial and temporal distribution patterns of rainfall and the reoccurrence of catastrophic events such as floods and droughts are all evidence of global climate change mccarthy 2009 sachindra et al 2016 to effectively assess this natural disaster a thorough evaluation of the influence of flood factors based on the basins characteristics is required these factors include geo environmental characteristics hydrology population land use and climatic factors over the years remote sensing data has served as a reinforcement alongside field data in assessing quantifying and predicting floods ajin et al 2013 bui et al 2019a dewan et al 2007 franci et al 2016 pradhan 2009 data from remote sensing has also been used to address issues on data availability depending on data availability various methodologies such as empirical physical and physically based models can be employed in flood hazard mapping which is utilized for flood prediction and control janizadeh et al 2019 mosavi et al 2018 siahkamari et al 2018 youssef et al 2016 despite the popularity of the physically based models in analyzing flood inundation levels their accuracy is sometimes dependent on boundary conditions in addition these models may be limited in their ability to model complex flow scenarios requires enormous data input and may involve complex computations in some circumstances additionally physical models are costly to build and require real experiments to validate models the application of global flood hazard maps may make validation of the flood hazard mapping model challenging because the data applied might attempt to explain flood characteristics such as magnitude and spatial extent at low resolutions yet fail in accurately predicting the real event christopher et al 2015 early warning systems ews emergency responders and agencies and local institutions have a large demand for flood risk predictions in flood prone areas which necessitates the need for global flood models to synthesize big and small scale analyses undp 2018 other challenges may include unavailable or insufficient data which makes it difficult to model flood areas accurately using physically based or empirical based models at the basin scale in both gauged and ungauged basins multi criteria decision making mcdm methodologies efficiently demonstrate stakeholders judgment on flood issues and aid in integrating efficient operation between people and policymakers based on this mcdm techniques based on geographic information systems gis have been widely used in finding ranking and synthesizing flood influencing factors fifs for flood hazard mapping studies pourghasemi et al 2019 shafapour et al 2019 the gis based analytic hierarchy process ahp and fuzzy ahp f ahp methods with varying numbers and types of fifs have been successfully utilized in mapping flood hazard areas by several studies gigović et al 2017 luu and von meding 2018 papaioannou et al 2015 yang et al 2013 flood hazard mapping may be challenging because of the subjectivity of the fifs indicators and the selection of the most sensitive factors related to the basin synthesizing relevant factors that affect flood occurrence is very important in flood hazard mapping however few studies apply the optimum factors in delineating the level and extent of flood hazards the accurate assessment and delineation of flood prone areas is complex and challenging primarily owing to the complicated nature of the flood phenomenon bui et al 2019b chapi et al 2017 review findings by mudashiru et al 2021 showed that the mcdm was the most applied flood hazard modelling method amongst the empirical modelling methods which consisted of the machine learning artificial intelligence the statistical and mcdm methods with 18 3 27 and 54 7 application rate respectively additionally the ahp which is the most popular mcdm method madruga and evers 2016 is best applied with factors not exceeding nine to limit uncertainty arising from inconsistency in the decision making process alonso and lamata 2006 goepel 2018 however there is a need to apply an optimum set of non correlating fifs that are capable of delineating flood prone areas in an mcdm model therefore this study applies the ahp and f ahp mcdm methods to identify flood prone areas in the northeast penang basin located in penang malaysia by considering two groups of fifs this study aims to i develop flood hazard index fhi scores for three scenarios using the ahp and f ahp methods to enable the evaluation of the influence of each group of factors on the flood hazard maps ii conduct a sensitivity analysis for each factor based on the single parameter sensitivity analysis technique to develop a sensitized flood hazard index sfhi map iii compare the fhi and sfhi map results with historical flood records between 1984 and 2020 affecting 221 locations and amounting to 1403 flood events to ascertain the accuracy of the ahp and f ahp methods 2 materials and methods the flood hazard mapping framework adopted in this study is a novel combination of two mcdm methods and the application of the fifs for the identification of flood prone areas in the study area the procedures executed in this study to fulfill the objectives are summarized and presented in fig 1 the framework was built to effectively achieve the objectives and is summarized as follows i selecting and evaluating the optimum fifs factors that influence flood generation through geospatial analysis ii comparing the suitability of ahp and f ahp in identifying flood hazard areas in the study iii and evaluating the influence of the flood susceptibility factors group fsfg flood vulnerability factors group fvfg and flood susceptibility and vulnerability factors group fsvfg on the flood hazard output model preliminary processes before attaining the objectives include obtaining the non correlating flood influencing factors optimum factors weighting factors and weight aggregation the determination of the best factors was conducted through a comprehensive literature search the literature search enabled the identification of the relevant and most applied factors and enabled a gap for consideration of the significant factors the pairwise comparison method was applied as the weighting method while the saaty and fuzzy scale were applied respectively in obtaining the weights for each of the ahp and f ahp methods the first objective was achieved by evaluating the flood hazard maps resulting from the ahp and f ahp methods the second objective was achieved by evaluating the influence of each group of factors from the three scenarios on all the flood hazard maps generated from the two mcdm methods applied for this study the third objective was attained after a sensitivity analysis was conducted and the resulting maps from the analysis alongside the flood hazard maps generated from the mcdm methods were validated with the historical flood record of the study area 2 1 study area the methodology is implemented for the northeast penang basin which is one of the five districts in the state of penang in the northeast part of penang island in malaysia as shown in fig 2 the northeast penang area is between longitude 5 24 53 03 and latitude 100 19 48 89 the area covers 123 85 square kilometres approximately and is situated in the heart of the capital city in georgetown the northeast penang area serves as the central city of the state of penang and is one of the most highly populated cities with dense urbanization the climate in the northeast penang area is humid tropical weather with average yearly rainfall recorded at about 1800 3000 mm ismail 2000 the altitude of the northeast penang area ranges from 2 to 785 m above sea level with temperatures ranging from 23 5 c to 31 4 c and humidity percentage ranging from 60 9 to 96 8 the northeast penang area is closely linked with a higher rate of evaporation ali et al 2011 the climactic season of the northeast penang area can be categorized mainly into the pre monsoon season which extends from march to may northeast monsoon which extends from december to april southwest monsoon which extends from june to september and post monsoon which extends only for just the months of october and november the northeast penang area has experienced several flood events resulting from intense rainfall most of these flood events occurred during the northeast monsoon and sometimes during the intermonsoon seasons according to the daily maximum annual rainfall data collected from the department of irrigation and drainage did malaysia from the four stations in the study area the highest maximum daily rainfall occurred during the years 1996 2017 and 2018 the flood events which occurred in september and november 2017 have been reported as the worst flood events in the area with reported destruction of properties and infrastructures as shown in fig 3 therefore an accurate flood hazard map of this area is essential for flood management planning 2 2 data availability most of the data used in this study were obtained from government agencies as shown in table 1 a brief explanation of the fifs is given in section 2 2 1 whilst the gis data processing and analysis procedure are explained in sections 2 3 2 6 2 2 1 flood influencing factors fifs the influencing factors of various floods can be represented by drainage density elevation land use slope rainfall infiltration topographic wetness index time of concentration flood depth distance from rivers distance from roads and buildings population and distance from inundated locations 2 2 1 1 drainage density the drainage density refers to the total length of rivers per unit area liu et al 2019 it is one of the major factors that dictate flood occurrence high drainage density signifies a crucial runoff rate souissi et al 2020 similarly msabi and makonyo 2021 indicated that areas with a high volume of floods are often associated with high drainage density and high runoff volume dinesh et al 2007 2 2 1 2 elevation elevation forms a crucial factor in determining areas that are prone to flooding water flows from terrain with higher altitudes to lower grounds hence making flat areas more prone to flooding as flat areas tend to accumulate flow running off higher and steep terrains patrikaki et al 2018 2 2 1 3 land use land use is a factor related to urbanization progress and it is very important in flood hazard analysis land use influences hydrological processes such as infiltration rate flow velocity evapotranspiration and evaporation souissi et al 2020 urbanization actively modifies a naturally vegetated catchment area by increasing the percentage of imperviousness characterized by man made drainage systems rapid hydrological response to storms and varying spatio temporal distribution of flows guan et al 2015 concisely most changes in flow rates in urban areas result from increased peak storm events and volume of runoff as well as reduced infiltration rate and time of concentration owing to the increased urbanized area cheng and wang 2002 2 2 1 4 slope flat terrains get flooded quicker in comparison to areas with steep slopes characterized by higher grounds where runoff falls from patrikaki et al 2018 in addition to this slope evaluated in terms of change in elevation over the terrain indicates areas susceptible to erosion due to flood 2 2 1 5 rainfall surface runoff generation resulting to flood requires the occurrence of rainfall over the earth s surface therefore runoff is highly dependent on rainfall many factors affect runoff generation and these include rainfall characteristics depth duration intensity and morphological parameters vegetation soil type elevation drainage area basin shape elevation topography and drainage network patterns critchley et al 1991 according to mandeep et al 2008 the major rainy season in the state of penang is during the northeast monsoon period with a record of 1396 mm the accumulated average rainfall accounting for 57 of the annual average rainfall 2485 7 mm measurement in the state the southwest monsoon period accounts for about 856 6 mm of total rainfall and contributes 35 of the average annual rainfall measurement in the state 2 2 1 6 infiltration soil type and clay compositions are effective methods to represent infiltration kheir et al 2008 saragih 2020 the type and texture of soil that is present in an area highly correlates to the infiltration capacity of the terrain which explains how susceptible the area is to flood hazards flood volume and speed are likely to increase in areas characterized by clay soil in comparison to areas characterized by sandy soil clay soil is highly impermeable which makes it more susceptible to flood hazards than sandy soil which is permeable and has a higher infiltration capacity lappas and kallioras 2019 this study applied the lithological units in identifying related infiltration capacity lithology stands out as one of the crucial geomorphology factors that help in flood hazard mapping it is related to the permeability properties of the soil structure in the watershed which varies by rock type souissi et al 2020 2 2 1 7 topographic wetness index the twi is a hydrologic parameter that describes the extent of accumulation of flow in a watershed the index shows the ability of the gravitational forces in the watershed to convey flow downstream the accumulated flow infiltration rate is dependent upon the watersheds soil properties such as permeability structure texture consistency and void ratio pourghasemi et al 2013 2 2 1 8 time of concentration time of concentration tc describes the degree of how quickly a river catchment responds to rainfall turned runoff over its watershed mcenroe et al 2016 the size of a catchment affects the runoff volume as an increased catchment area will result in reduced peak flow an increased tc enables storage filling and infiltration to occur thereby reducing runoff volume steep slopes also reduce tc and retention volume thereby resulting in increased runoff volume according to abdulkareem et al 2019 reduced values of tc indicate rain characterized by high runoff volume and velocity from upstream towards the downstream areas devendra et al 2015 also reported that an increase in non vegetated cover results in a reduction in tc and increased runoff generation 2 2 1 9 flood depth heavy rainfall events form an integral part of the contribution to flooding occurrence and its magnitude wei et al 2019 rainfall with a high intensity usually results in high runoff depth in areas close to the stream networks thereby endangering the downstream environment bui et al 2019a flash floods are often characterized by high intensity rainfall occurrences and short duration storms according to the drainage masterplan report for northeast penang by did 2018 high intensity rainfall is likely to cause flash floods in low terrain areas with poor drainage systems therefore the flood records for the year 2017 affecting 55 locations in the study area were interpolated to analyze the spatial extent of flooding and the affected areas 2 2 1 10 distance from rivers dfr the dfr has a relevant influence on the possibility of occurrence and depth of flooding due to the river overflow resulting from insufficient conveyance capacity janizadeh et al 2019 dfr is also known for its contribution to flooding in areas in closer proximity to rivers shafapour et al 2019 the infrastructures buildings and businesses closer to rivers are more susceptible to the risk of flooding 2 2 1 11 distance from roads and buildings dfrb according to shuster et al 2005 demonstration of urbanization processes includes the expansion of the surface area of road systems reduced drainage capacity through the development of floodplains and modification of landscape for agricultural purposes these alterations cause a decrement in possible pathways for runoff thereby increasing the risk of flooding the urban roads and development reduce the infiltration capacity of an area thereby increasing its susceptibility to flooding shafapour et al 2019 2 2 1 12 population the population is an important flood causing factor when assessing the risk of flood hazards to humans a highly populated area is more at risk of flooding hazards additionally areas with high density populations indicate more people and activities will be disrupted during a flood 2 2 1 13 distance from inundated locations dfil geographical related features such as distance to a hazard area have been indicated to be a key factor in determining the perception of susceptibility to flooding hazards the distance to inundation areas has also been considered as a factor contributing to flash and river flooding analysis o neill et al 2016 pradhan 2009 applied historically flooded areas as the factor in assessing flood susceptibility areas in this study the distance of the study area from flood locations in 2017 is considered a hazard factor 2 3 gis processing and analysis of data the thematic layers for all thirteen fifs are presented in fig 4 a m the drainage density slope elevation and topographic wetness index thematic layers were created in arcgis by applying the tandem x dem and spatial analyst toolbox the thematic layers for rainfall and flood depth were created using the interpolation tool while the distance from rivers distance from roads and buildings and distance from inundated locations were created using the euclidean distance tool the land use map was reclassified from the original shapefile obtained from pegis to obtain five land use classes as described in fig 4c the time of concentration was estimated using an empirical formula with the support of arc hydro and zonal statistics as table tools in arcgis after creating the thematic layers all features of the factors were classified into the five classes with a rating between 1 and 5 using the value function scaling method malczewski 2000 malczewski and rinner 2015 this is a method of standardization of the factors features all factors were normalized using the ahp and f ahp methods to obtain the respective weights the geometric mean approach was utilized for the ahp method to synthesize the group of experts judgments and the weights of the factors were generated using the eigenvector approach the method proposed by chen tung et al 2006 for integrating a range of decision makers opinions is applied for the fuzzy methods while the geometric mean approach proposed by buckley 1985 was utilized in obtaining the factors weights the natural break jenks papaioannou et al 2015 pourghasemi et al 2019 classification method is applied for all factors except for infiltration and land use theclassification method applies an algorithm to group specific attributes values into classes that set it apart by well defined breakpoints these classes are best described in their groups based on an ordinal scale to allow for easy comprehension of the map details the classes are founded on natural grouping that is specific to the dataset campbell and shin 2019 jenks 1967 the method has a limitation of allowing a comparison of two or more maps because of the specificity of the classification group to each dataset type this limitation was the reason why the defined interval classification method was applied for the fhi scores to allow a similar range of scores for an accurate comparison of the maps the weight aggregation to generate the fhi maps was conducted using the wlc technique in the gis environment with the map algebra tool 2 4 flood hazard index fhi evaluation the thirteen non correlating fifs applied in this study and the factors respective weights for the determination of fhi are presented in table 2 flood hazard occurrence usually relies on some of the basins characteristics that is flood hazard zones will be characterized by features like flat areas proximity to rivers impervious land cover type gentle to moderate slope high drainage density and others it is important to consider factors that are explainable by the characteristics of the catchment area related hazards and the flood event the selection of the factors applied in this study was performed based on the proven relevance of the factors in the identification and prediction of flood prone areas from the literature kazakis et al 2015 shafapour et al 2019 yang et al 2013 this was done to prevent collinearity of the factors which reduces the prediction accuracy of the generated flood hazard map al juaidi et al 2018 the factors presented in table 2 are processed with the weighted linear combination wlc which is the sum of the product of estimated factors weight from the experts judgments and the attributes of the factors applied wlc is one of the most common methods that implement a decision criterion in creating integrated maps in gis malczewski 2000 the wlc will produce an fhi map where the cell value represents an integration of all factors weights considered in evaluating flood hazards the influence of each factor depends on the factor s weight and the factor s map cell value eq 1 is applied to obtain the map aggregation 1 fhi w f r f where w f is the factor weight and r f represents the factor attribute represented by a map to obtain the fhi of the fsvfg eq 1 is rewritten as the expression given in eq 2 2 fhi w f w sf r f where w sf is the weight of the corresponding group of the group of factors and r f represents the factor attribute represented by a map the fsfg fvfg and the fsvfg labels for the ahp and f ahp were extracted from table 2 three scenarios were tested to enable the evaluation of each group of factors on the model output the first scenario involved generating fhi maps for only the fsfg group fhi1 and fhi2 the second scenario was to generate fhi maps for only fvfg fhi3 and fhi4 and the third scenario was to generate fhi maps for fsvfg fhi5 and fhi6 for the ahp and f ahp mcdm methods respectively the fhi for the first scenario was evaluated using the expression described in eq 3 3 fhi fsfg w f 1 r f 1 w f 2 r f 2 w f 3 r f 3 w f 4 r f 4 w f 5 r f 5 w f 6 r f 6 w f 7 r f 7 w f 8 r f 8 w f 9 r f 9 the fhi for the second scenario was evaluated using the expression described in eq 4 4 fhi fvfg w f 10 r f 10 w f 11 r f 11 w f 12 r f 12 w f 13 r f 13 the fhi for the third scenario was evaluated using the expression described in eq 5 5 fhi fsvfg w fsfg w f 1 r f 1 w f 2 r f 2 w f 3 r f 3 w f 4 r f 4 w f 5 r f 5 w f 6 r f 6 w f 7 r f 7 w f 8 r f 8 w f 9 r f 9 w fvfg w f 10 r f 10 w f 11 r f 11 w f 12 r f 12 w f 13 r f 13 where w fsfs w fvfs a n d w fsvfs represents the weight of the fsfg fvfg and fsvfg groups respectively the fhi maps generated for the three scenarios are labeled and presented in table 3 the resulting fhi scores are sub categorized into very low low moderate high very high and extremely high flood hazard index classes this classification was based on the equal interval to provide an equal range for the comparison of all six maps derived based on grouping and type of method applied additionally the flood hazard classes were also adopted from the flood hazard classes of the japanese flood fighting act 2001 established by the did in 2003 anuar 2018 2 4 1 mcdm methods the ahp method saaty 1990 framework is operable with the pairwise comparison method it is subjected to a pairwise comparison by developing a ratio matrix which is the input and the resulting relative weights as the output the weights are evaluated by normalizing the eigenvector related to the maximum eigenvalue of the reciprocal matrix the facilitator and the involved decision makers are required at the initial stage to define priorities for the selected factors by evaluating them in pairs based on their respective significance thereby generating a pairwise comparison matrix pcm the saaty scale is described in table 4 as it is applicable in representing the decisions based on their relative importance on the other hand the fuzzy ahp uses a scale of the linguistic variable instead of the numeric variable scale to highlight the preference of one factor over another a scale of linguistic variables has its values expressed in words rather than numbers in a natural or artificial language the notion of a linguistic variable demonstrates a useful method for accurately depicting occurrences that are too complicated to be stated in conventional quantitative terms table 4 lists the linguistic terminology used to express saaty s ahp and f ahp scales a detailed explanation of the f ahp process applied in this study can be found in the studies by chen tung 2000 chen tung et al 2006 the consistency ratio of the decision making process was evaluated using the expression in eq 6 6 ci λ max n n 1 where n number of factors applied and λ max principal eigenvalue in this study the ahp saaty 1990 and the f ahp buckley 1985 were applied to the weight estimation of the selected fifs both methods relied on the pairwise comparison results obtained from consulting fifteen experts in the field of hydrology and water resources engineering the saaty saaty 2000 and the fuzzy scale demirel et al 2008 feloni et al 2019 were applied in the weight assignment process the saaty s scale crisp numbers were transformed into fuzzy numbers to fit the linguistic scale of the f ahp the decision of all fifteen experts was combined by applying the geometric mean method for the ahp before finally applying the principal eigenvalue method to estimate the final weights of the factors the fsfg nine factors generated 36 pairwise comparisons the fvfg four factors generated six pairwise comparisons while the fsvfg two groups generated 1 pairwise comparison summing to just 43 total pairwise comparisons there would have been 78 pairwise comparisons if the thirteen factors were applied directly without grouping the factors the geometric mean method by buckley 1985 was applied in obtaining the fuzzy weights the mean of the fuzzy weights was subsequently used as f ahp weights to enable a smooth aggregation process in gis this was done because the fuzzy weights are represented by lower middle and upper functions the weighting analysis is presented as supplementary material 2 5 evaluating the influence of each group of factors on fhi results three main processes in flood mapping must be successfully tackled the first process involves providing a general framework that explains the mechanism of flooding the second involves identifying the optimal set of factors relating to the flooding process and the third is evaluating the influence of these factors based on flood occurrence this kind of complexity is best handled by applying suitable models and appropriate methods rather than applying a set of factors at once the factors were grouped into two and tested in three scenarios with the two mcdm methods this was done to reduce the number of pairwise comparisons which can limit uncertainty arising from inconsistency in the decision making process of a larger number of factors additionally the influence of each group of factors is evaluated to ascertain the relevance of applying the group of factors in the flood hazard mapping model the influence of each group of fifs was evaluated in two different ways the first approach entails evaluating the influence of each group of factors on the fhi value when fsfg fvfg and fsvfg were applied the second comparison entails the evaluation of the area covered by each fhi class i e very low extremely high fhi of the flood hazard mapping results from fsfg fvfg and fsvfg for the ahp and f ahp methods applied in the study the influence of each group of factors was then evaluated by multiplying the corresponding flood hazard index class by the area product the sum of the product that corresponds to the influence of each group of factors in numerical value was then obtained the percentage influence of each group of the factor was obtained by dividing each corresponding total by the sum of the total of all groups multiplied by 100 2 6 sensitivity analysis and result validation the input of the flood hazard mapping model is represented by the factor weights and the map cell values while the output of the model is represented by the fhi values the reliability of the output relies on the certainty of the input data the decision making process and the wlc model the influence of changing the criterions weights is a widely applied approach in conducting a sensitivity analysis in mcdm modelling through the application of the one at a time technique malczewski and rinner 2015 uncertainties in mcdm methods may arise from both internal and external sources the internal source of uncertainty in this study relates to the decision making process while the external source of uncertainty relates to input data and techniques applied the reliability of a model can be assessed by conducting a sensitivity analysis where the variation in the output is analyzed based on the applied input the single parameter sensitivity analysis enables the evaluation of the effective weights eq 7 souissi et al 2020 by replacing the empirical weights generated through the ahp or some other weighting techniques 7 w e c r c w c wi 100 where c r represents the criterion ranking rating c w represents the relative weight of the criterion and c wi represents the cumulative weight used in estimating the fhi the spsa was proposed by napolitano and fabbri 1996 for evaluating the effect of single parameters on aquifer vulnerability assessment in this study the spsa approach used in mapping flood hazard areas by kazakis et al 2015 souissi et al 2019 toosi et al 2019 was adopted whereby the effective weights of the flood influencing factors both fsfg and fvfg were evaluated to create sensitized fhi maps for all six generated flood hazard maps thelayer weight derived from ahp and f ahp is multiplied by the individual layer itself which is the layer factor that has been used for generating the fhi map and then divided by the generated fhi map the summarized statistics effective weights obtained from the sensitivity analysis are presented in table 5 the mean effective weights are then applied in generating the sensitized fhi sfhi maps the fhi1 fhi6 and sfhi1 sfhi6 maps from the sensitivity test cases were then overlaid with historical flood records of the study area 1984 2020 to validate the accuracy of the methods applied in this study for the ahp and f ahp methods the total number of events between 1984 and 2020 was 1403 affecting a total of 221 places in the study area 3 results and discussion 3 1 results 3 1 1 ahp and f ahp weight evaluation the determination of flood prone areas in this study was modelled using the ahp and f ahp with varying group of factors to identify the group of factors with the highest influence on the output model the ahp and f ahp methods are based on a decision making process whose consistency indexes were 0 015 and 0 036 for the fsfg and fvfg respectively and are below the threshold of 0 10 indicating a satisfactory consistency of the experts judgments saaty and vargas 1980 according to the range of the feature values obtained for each thematic layer of factors shown in fig 4 a m relative weights were assigned to each feature classification based on its relation to flood generation the selected factors factors respective groups and corresponding weight are shown in table 6 and table 7 the result of the f ahp weight estimation indicated that the drainage density was the highest contributing factor amongst others toward flood hazard level based on the weight shown in table 6 for scenario 1 20 44 however with fsvfg it was the third highest contributing factor to the f ahp model table 8 higher values of drainage density are highly correlated with flood hazard occurrence areas characterized by low altitude are distributed along the north northeast and some central parts of the basin it can be observed that the areas with lower altitudes were assigned the highest rating as shown in table 6 the land use composition was grouped into five classes consisting of forest area 51 23 urbanized area 42 80 bareland 3 99 cultivated area 1 03 and waterbody 0 94 as shown in fig 4 c the highest rate was assigned to the water body closely followed by the urban areas land use class as presented in table 6 the thematic map of the slope in fig 4 d showed that the areas with the lowest percentage rise in slope areas 12 4 cover an area of 39 09 of the basin 12 41 32 56 covers an area of 27 03 32 57 52 72 covers an area of 19 74 57 73 80 62 covers an area of 11 73 and 80 63 covers an area of 2 42 similar to the elevation the area with lower values of the slope is assigned higher rates as shown in table 6 the slope is highly related to the amount of runoff its speed the infiltration rate of a catchment and its flow accumulation spatial distribution of the average annual rainfall from 1976 2020 for four rainfall stations in the study area is conducted using the idw method in arcgis the resulting thematic layer from the idw spatial interpolation was classified into five groups r 2240 mm 2250 mm r 2330 mm 2340 mm r 2410 mm 2420 mm r 2490 mm and r 2500 mm as shown in fig 4 e the highest rating was assigned to the area receiving the highest depth of rainfall as shown in table 6 the result of the ahp weight estimation showed that the rainfall was the highest factor amongst others toward flood hazard level based on the weight shown in table 6 for scenario 1 20 65 however with fsvfg it was the fourth highest contributing factor to the f ahp model table 8 the resulting thematic layer had three classes of lithological units as shown in fig 4 f acid intrusive undifferentiated clay and silt marine and clay silt sandy and gravel undifferentiated continental the lithological formations obtained were classified into three infiltration categories based on factors that include secondary porosity clay composition facies similarities and exposed thickness kheir et al 2008 therefore the acid intrusive undifferentiated was classified as moderate permeability clay and silt marine as low permeability and clay silt sandy and gravel undifferentiated as moderate high permeability as presented in table 6 the generated thematic twi map was classified into five groups twi 13 9 5 twi 12 7 1 twi 9 4 4 9 twi 7 and twi 4 8 high values of twi indicate areas with high flow accumulation potential are usually areas characterized by low altitude and gentle moderate slope the higher values of twi were assigned the highest rating as shown in table 6 the resulting tc values from the thematic layer shown in fig 4 h were classified into five with the lowest value assigned the highest rating as shown in table 6 this is because a significant reduction in vegetation cover and replacement with impervious cover will result in lower tc values and contribute to flooding the result of the ahp and f ahp weight estimation showed that the flood depth was the second most contributing factor amongst others toward flood hazard level based on the weight shown in table 6 for fsfg 17 00 and 16 65 however for fsvfg it was the sixth and fourth highest contributing factor for the ahp and fahp models respectively table 8 the resulting thematic layer from the idw spatial interpolation of the flood depth was classified into five groups with the highest flood depth value assigned the highest rating as shown in table 6 fd 0 3665 0 3666 fd 0 7137 0 7138 fd 1 061 1 062 fd 1 408 and fd 1 409 m lower values of dfr indicate areas that are closer to streams and are at higher risk of flooding as rated in table 7 the weighting evaluation for both the ahp and f ahp methods showed that the most contributing factor towards flood hazard was the dfr 18 and 20 respectively as shown in table 8 for fsvfg a low dfrb value may pose a high risk to socio economic activities during a flood event it also indicates that the areas are closer to urbanized areas and are at higher risk of flooding as rated in table 7 the denser populated areas were assigned with a higher rating as indicated in table 7 like the dfr the weighting evaluation for both the ahp and f ahp methods showed that the second most contributing factor towards flood hazard was the dfil 16 and 13 respectively as shown in table 8 for fsvfg the resulting thematic layer as shown in fig 4 m was classified into five groups dfil 997 5 997 6 dfil 1949 1950 dfil 2993 2994 dfil 4037 and dfil 403 with lower values assigned highest rating as shown in table 7 3 1 2 flood hazard mapping the first step was to reclassify all the factor maps which were presented for all factors in fig 4 a m all factors maps were standardized by using the value scale function as explained in section 2 3 the thematic layers and reclassified maps for flood depth drainage density land use elevation slope twi infiltration time of concentration dfr dfrb and dfil had a raster cell size of 10 10 the rainfall idw interpolated raster and the population had varying raster cell sizes that did not correlate with the other factors to correct this both the rainfall and population raster output maps were resampled to 10 10 cell sizes using the bilinear interpolation method with the data management tool in gis the map algebra tool in gis was then used to create flood hazard maps for the ahp and f ahp mcdm methods using equations 3 4 and 5 for the three scenarios as illustrated in fig 5 a f the defined interval classification method was applied for the fhi1 6 to maintain a consistent classification range with an interval size of 0 75 as shown in fig 5a f the actual range of the fhi1 6 scores is presented in table 9 all six flood hazard maps generated were classified into five hazard classes ranging from very low low moderate high very high and extremely high flood hazard level classes as shown in fig 5 a f the breakdown for each fhi class across the six flood hazard maps is presented in table 10 additionally the summary for classification of each flood hazard level and the corresponding coverage area and percentage coverage area is given in table 11 and fig 6 for flood hazard maps generated using the fsfg fvfg and fsvfg respectively for ahp and f ahp methods table 9 showed that fhi1 had an index score ranging from 1 44 4 04 fhi2 had an index score ranging from 1 39 4 14 fhi3 had an index score ranging from 1 31 to 5 fhi4 had an index score ranging from 1 33 to 5 fhi5 had an index score ranging from 1 53 4 36 and fhi6 had an index score ranging from 1 61 to 4 27 respectively table 9 also shows that when only fsfg was applied the maximum index score of the fhi1 for the ahp model was 4 04 but when fsvfg was used the maximum index score of fhi5 increased to 4 36 similarly for the f ahp method the maximum index score increased from 4 14 to 4 27 respectively as shown in table 9 this indicates that the fhi generated from the fsfg i e fhi1 and fhi2 was at the lower bound whilst the fvfg i e fhi3 and fhi4 was at the upper bound this indicated that when fsfg was combined with fvfg the conformity of the fhi scores increased for the two mcdm methods applied for flood hazard mapping in this study the result of the evaluation for the ahp and f ahp shows that the percentage of the coverage area by each flood hazard class for the two methods is almost similar as shown in fig 6 however the f ahp model fhi2 shows the highest coverage area for the very high 0 1 and the ahp fhi1 presented the lowest percentage in the coverage area for the very low 0 005 flood hazard class as shown in fig 6 in addition fhi1 57 4 presented the highest percentage coverage for the moderate flood hazard area in comparison with fhi2 52 5 fig 6 shows that fhi3 and fhi4 had 22 7 and 27 2 occurring in the extremely high flood hazard class and the highest coverage in the very high 34 1 and 35 5 flood hazard class areas respectively fig 6 also shows that the ahp model fhi5 had the most coverage area for the very high 24 13 and the f ahp fhi8 had the largest percentage in the coverage area for the low 1 86 flood hazard class areas respectively from the map generated from the fsvfg shown in fig 5 e and 5 f i e fhi5 and fhi6 the very high and high areas are dispersed majorly towards the north eastern eastern and some northern and southern locations of the study area the land use map was overlaid on each of the six generated flood hazard maps fhi1 fhi6 to evaluate the flood hazard level corresponding to each land use class of the study area this was done by combining each flood hazard map with the land use raster using the combine tool in the spatial analyst toolbox in the gis environment the area for the corresponding flood hazard and land use combination was calculated and extracted the distribution of land use in the five flood hazard classes for fhi1 is presented in fig 7 fig 7 shows that water body 37 54 and 52 44 and urban area 53 46 and 46 07 land use class types had areas dominated in the moderate to high flood hazard classes the bare land was predominantly in the moderate 75 02 flood hazard class the cultivated land use class type was predominantly in the moderate 68 39 flood hazard class while the forest area land use class type was predominantly in the low to moderate 38 11 and 59 32 flood hazard class 3 1 3 evaluating the influence of each group of factors on the fhi maps to obtain the influence of each group of factors on the flood hazard maps the explanation given in section 2 5 was applied the classification shown in table 10 was applied in estimating the area in square kilometres covered by each fhi class for the fsfg fvfg and fsvfg respectively as presented in table 12 and table 13 for the ahp and f ahp methods subsequently the percentage influence was obtained as presented in table 14 and table 15 for the ahp and f ahp methods respectively tables 14 and 15 show that the fvfg had the highest influence on the generated flood hazard maps generated by applying the ahp 40 15 and f ahp 42 09 methods in comparison with fsfg 25 85 and 25 26 and fsvfg 34 and 32 65 respectively it was also observed that the fvfg was on the upper bound in comparison with other groups based on the fhi conformity score which might indicate the fvfg s higher influence additionally this can be attributed to the weights assigned to the fvfg 0 552 and 0 47 for ahp and f ahp respectively 3 1 4 single parameter sensitivity analysis a sensitive parameter is one that elicits the highest change in the model output for a small change in the given input parameter the summarized statistics effective weights mean obtained for the sensitivity analysis are presented in table 16 the mean effective weights were applied in generating sfh1 sfhi6 shown in fig 8 a f the findings from the sensitivity analysis showed weights applied for fsfg for both the ahp and t fahp weights varied in value and sometimes the ranking order of the most contributing factors in comparison to the effective weights for example in scenario 1 the ahp weight for rainfall with the highest contribution was 20 65 see table 6 while the mean effective weight for rainfall was 18 9 see table 16 moreover the sensitivity analysis showed that for sfhi1 and sfhi2 the least sensitive factor was twi however for the fvfg results showed that the weights of factors applied in generating fhi3 and fhi4 showed a similar rank in the order of the weights with the mean effective weights applied for generating sfhi3 and sfhi4 additionally for both sfhi3 and sfhi4 the population was the least sensitive factor furthermore sensitivity analysis for all factors showed similar findings with the fsfg as the effective weights varied from the initial ahp and f ahp weights and in the order of the factors moreover the overall least sensitive factor for sfhi5 and sfhi6 was the twi as well like the fhi5 and fhi6 the effective weights for sfhi5 and sfhi6 showed that the distance from rivers was the most important factor of all factors applied with 20 3 and 29 2 and 17 6 and 26 5 weight and effective weight respectively this confirms the accuracy of the methodology in the assessment of flood hazard areas in this study the fhi maps showed varying fhi conformity scores with the sfhi maps as shown in fig 5 a f and fig 8 a f 3 1 5 validation the flood hazard maps generated based on the three scenarios with fsfg fvfg and fsvfg applying ahp and f ahp i e fhi1 fhi6 and sfhi1 sfhi6 were overlaid with the historical flood event records 221 flood points between 1984 and 2020 of this study area fig 5a f this was done to obtain which of the methods and test cases has the best predicting capability the number of flood events in each fhi class location was extracted using the zonal statistics as table tool in the gis environment table 17 shows the distribution of the extracted number of flood events across the five flood hazard classes for fhi1 6 and sfhi1 6 respectively while fig 9 and fig 10 show the distribution of the number of historical flood events in the flood hazard classes fig 9 shows that 77 8 71 8 and 71 8 of the analyzed historical flood events occurred in the high flood hazard class for fhi1 i e fsfg with ahp method and fhi2 i e fvfg with f ahp method respectively additionally 6 of the historical flood events occurred in the very high flood hazard areas for the fhi2 while 22 2 occurred in the moderate flood hazard areas for the fhi1 respectively the fvfg modelled maps showed that 91 8 of the historical flood events occurred in the extremely high flood hazard class for fhi3 i e fsfg with ahp model and fhi4 i e fvfg with f ahp method respectively however the integration of both fsfg and fvfg as in fhi5 i e fsvfg with the ahp and fhi6 i e fsvfg with the f ahp showed that 96 1 and 88 9 of the historical flood events occurred in the very high flood hazard class respectively it was observed that the fsvfg had a higher percentage of flood events in the very high flood hazard class when compared to only fsfg or only fvfg were applied for the ahp and f ahp methods furthermore it was observed that the fsvfg balanced the overestimation and underestimation in the fsfg and fvfg modelled maps for the two mcdm methods respectively additionally 100 of the historical flood events occurred in the moderate to extremely high flood hazard class areas for fhi1 fhi6 respectively furthermore fig 9 showed that fhi1 had 22 2 of the historical flood occurring in the moderate flood hazard class for fhi1 however the fhi5 fsvfg with the ahp showed that 0 of the historical flood events occurred in the moderate flood hazard class this indicated that when both fsfg and fvfg were combined fsvfg the number of historical flood events occurring in the moderate flood hazard class reduced from 22 2 to 0 this further confirmed the relevance of adopting both the fsfg and fvfg in mapping flood hazard areas in this study fig 10 shows that the flood hazard maps generated from the sensitivity analysis sfhi1 sfhi6 showed different attributes from the fhi1 fhi6 for example the historical flood events in the high flood hazard class for sfhi1 and sfhi2 88 6 and 72 2 were more than fhi1 and fhi2 77 8 and 71 8 respectively however 100 of the historical flood events occurred in the high to extremely high flood hazard class areas for sfhi1 sfhi6 respectively similarly to fhi1 fhi6 the results from the sensitivity analysis have shown similar results to the flood hazard maps created with the ahp and f ahp methods for the three scenarios 3 2 discussion a thorough review by madruga and evers 2016 has signified that although the mcdm is easy to implement it is characterized by uncertainty based on its subjectivity this limitation is highly related to the decision making process which requires a certain number of pairwise comparisons by the decision maker based on the number of factors under consideration the method applied in this present study on the other hand addressed the uncertainty due to the application of a large number of factors in determining the fhi by grouping the factors into two to reduce the number of pairwise comparisons furthermore in this present study less data was applied in the determination of flood prone areas by incorporating the gis mcdm methodology the mcdm derived weights obtained in this study were based on the decision made by experts which met the satisfactory threshold for the consistency index therefore if the same method is to be replicated in another basin the weights of the selected fifs will be dependent on the decision maker s which might produce varying results this might be a drawback depending on the degree of epistemic uncertainty however in the case where the values of the weights are subjected to uncertainty the single parameter sensitivity analysis applied in this study can provide effective and reliable fifs weights for evaluating flood prone areas in the basin the evaluation of the fhi showed the spatial distribution of the flood hazard areas identified from fhi 5 and fhi6 maps fsvfg shown in fig 5 e and f the areas that are surrounded by rivers characterized by lower slope percent denser drainage density high rainfall depth low infiltration rate higher flood depth and flat areas were found to exhibit flood hazard levels of moderate to very high flood hazard class areas however areas characterized by higher elevation lower drainage density lower rainfall amount and farther from rivers and drainage networks were found to exhibit flood hazard levels of low to very low fhi similar findings were reported in studies by kazakis et al 2015 toosi et al 2019 the evaluation of the fhi based on the distribution of fhi in different land use type compositions has shown that the flood prone areas were majorly distributed in the urbanized part of the study area this explains the role of urbanization in contributing to flooding generation as it influences hydrological processes such as infiltration rate flow velocity evapotranspiration and evaporation souissi et al 2020 additionally in urban area or city center the percentage of impervious area is high hence the losses due to interception and evapotranspiration is diminishing concisely land use also influences most changes in flow rates in urban areas resulting from an increased peak flow event increased volume of runoff reduced infiltration rate and reduced time of concentration owing to the increased urbanized area cheng and wang 2002 in the northeast penang area the highly urbanized areas are medium and high density residential areas located mainly in intermediate and flats areas these areas were rightly classified by findings from this study as areas of moderate to very high flood hazard index classes these areas represent a potential platform for implementing suitable land use practices and regulations at the national level to evaluate flooding this can be conducted by providing and improving solutions such as increasing infiltration capacity through the building of effective onsite detention or retention facilities and improving drainage capacities through the flood management system in addition to this there is a need to support this sort of flood mitigation solution with a proper early warning system these findings are capable of providing solutions to flood mitigation and prevention strategies through appropriate land use management practices such as appropriate control at source in urban areas to reduce the risk of flooding due to human actions and possible climate change huong and pathirana 2013 kalnay and cai 2003 shrestha and lohpaisankrit 2017 zhou et al 2004 due to the spatial and temporal variability of flood main causal factors such as hydrology geomorphology climatic and topography flood hazard mapping is quite regional although fhi indexes derived for this study are specific to data for the northeast penang these data can be modified based on other regions characteristics to allow the methodology to be tested in other regions the evaluation of the fifs groups showed that the weight assigned to each group had an impact on the group s influence on the output model these findings correlate with the study by kazakis et al 2015 toosi et al 2019 that reported that the higher the weights assigned to a specific factor the higher is its influence on the flood hazard mapping output model the sensitivity analysis indicated varying weight values but similar results overall these differences have shown that the ahp and the f ahp methods applied are sensitive to model input change despite these variations the flood hazard maps generated with the same factors and model presented almost similar maps to the sensitized maps the validation of the flood maps with flood records between 1984 and 2020 showed that when the fsfg were combined with fvfg fsvfg the flood hazard maps i e fhi5 and fhi6 presented better outcomes because the areas classified as highly susceptible to flooding were the areas that experienced the highest percentage of the historical flood events this indicates the accuracy of the methodology applied in conclusion the ahp and f ahp have performed satisfactorily in identifying flood hazard areas in the current study the flood hazard assessment maps can also provide useful information for regional land use and flood management planning allowing for the identification of safe and non safe urban development regions bathrellos et al 2016 the flood hazard map can be used by planners engineers and policymakers to find ideal regions for sustainable urban growth 4 conclusion the ahp and f ahp methods were applied in identifying flood hazard areas of northeast penang the results of the weighting of the fifs showed that distance from rivers was the most dominating fif while the twi was the least dominating factor of all thirteen fifs for the two mcdm methods as the proximity to rivers is a crucial factor that determines the degree of a basins susceptibility to flooding the resulting fhi maps from the three groups of factors showed that the fvfg had the highest fhi score in comparison with the fsfg and fsvfg the results also indicated that the flood hazard index conformity score increased when fsfg was combined with fvfg for the two mcdm methods ahp and f ahp furthermore the result of the influence of each group of factors on the area covered by varying flood hazard classes very low extremely high showed that the fvfg had the highest influence on the generated flood hazard maps for the ahp and f ahp methods the relevance of the application of optimum factors is provided in the standalone result of the fsfg group which performed lesser in the prediction of flood hazard areas in comparison with the fsvfg furthermore the fvfg standalone result overestimated the fhi class areas in which the historical floods occurred therefore proving the benefit of the methodology the evaluation of the two mcdm methods showed that the resulting map presented close results these findings agree with the article by chan et al 2019 that highlighted that although the ahp and fuzzy methods do not present similar results the solution that the ahp and fuzzy ahp methods produce is similar this is obvious in the validation results obtained from this study which presented an accurate prediction of historical flood areas for the two mcdm methods applied in this study therefore the ahp and f ahp approaches can be concluded to be valid tools for identifying flood hazard locations in this study area and other basins because floods are a common occurrence in the studied area the methods used in this study could aid in identifying potential flood prone areas as well as improving and innovating flood risk management practices the findings of this study can be applied as a preliminary investigation for further research which could include adapting this methodology to other basins with varied climatic characteristics and regimes as well as studying scenarios of an increased number of flood influencing factors that can be classified into more than two groups comparing of different types of mcdm model with similar case scenario applied in this study and evaluating the influence of flood influencing factors on the flood hazard map using machine learning and statistical methods credit authorship contribution statement rofiat bunmi mudashiru investigation conceptualization methodology writing original draft software formal analysis visualization validation writing review editing nuridah sabtu resources formal analysis visualization supervision project administration writing review editing rozi abdullah conceptualization methodology azlan saleh software resources ismail abustan conceptualization methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment the authors would like to acknowledge the effort of ir haniza mukhtar of the department of irrigation and drainage penang malaysia for the support provided in getting the data used in the study the authors also appreciate the financial support of the tertiary institutions education fund tetfund nigeria appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128055 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3189,flooding is a serious and recurring natural hazard flood hazard mapping requires synthesizing relevant factors that affect flood occurrence to allow for an accurate geographical assessment of flood characteristics for flood management activities two multi criteria decision making methods consisting of the analytical hierarchy process ahp and fuzzy ahp f ahp methods were applied in identifying flood hazard areas by using two groups of flood influencing factors fifs to decrease the number of pairwise comparisons required for ahp to enable the use of an optimum set of factors for the ahp and f ahp methods fewer pairwise comparisons can reduce uncertainty caused by inconsistency in the decision making process of a larger number of factors thirteen non correlating fifs were selected and divided into two groups namely the flood susceptibility factors group fsfg and flood vulnerability factors group fvfg fsfg consisted of drainage density elevation land use slope rainfall infiltration topographic wetness index time of concentration and flood depth and fvfg consisted of distance from inundated locations distance from rivers population and distance from roads buildings the methodology was evaluated using three test scenarios a fsfg group only b fvfg group only c flood susceptibility and vulnerability factors group fsvfg the ahp and the f ahp methods were applied in evaluating the influence of each group of factors on the flood hazard maps the result of the evaluation indicated that the fvfg had the highest influence based on the spatial extent of the region by each varying flood hazard class low to very high on the generated flood hazard maps the fvfg had 40 15 and 42 09 influence in comparison with fsfg 25 85 and 25 26 and fsvfg 34 and 32 65 for the ahp and f ahp methods respectively the findings from the sensitivity analysis showed similar findings with the ahp and f ahp methods confirming the accuracy of the methods the validation of the ahp and f ahp methods showed excellent compatibility with the historical flood record and affirmed the relevance of applying fsvfg the methodology applied in this study can be a dependable support tool in flood risk analysis and management for efficient decision making to achieve a resilient city keywords flood vulnerability factors flood susceptibility factors flood hazard mapping resilient city multi criteria decision making 1 introduction floods are among the highest recurring natural disasters that lead to the loss of lives damage the economy and infrastructures and are capable of harming humans and the natural environment cred 2018 toosi et al 2019 according to the usa noaa 2001 research on global economic losses from 1950 to 2002 there is growing fear about the rising population of individuals harmed per year through natural disasters and flooding contributed to 65 of natural disaster victims 2001 higher temperatures altering spatial and temporal distribution patterns of rainfall and the reoccurrence of catastrophic events such as floods and droughts are all evidence of global climate change mccarthy 2009 sachindra et al 2016 to effectively assess this natural disaster a thorough evaluation of the influence of flood factors based on the basins characteristics is required these factors include geo environmental characteristics hydrology population land use and climatic factors over the years remote sensing data has served as a reinforcement alongside field data in assessing quantifying and predicting floods ajin et al 2013 bui et al 2019a dewan et al 2007 franci et al 2016 pradhan 2009 data from remote sensing has also been used to address issues on data availability depending on data availability various methodologies such as empirical physical and physically based models can be employed in flood hazard mapping which is utilized for flood prediction and control janizadeh et al 2019 mosavi et al 2018 siahkamari et al 2018 youssef et al 2016 despite the popularity of the physically based models in analyzing flood inundation levels their accuracy is sometimes dependent on boundary conditions in addition these models may be limited in their ability to model complex flow scenarios requires enormous data input and may involve complex computations in some circumstances additionally physical models are costly to build and require real experiments to validate models the application of global flood hazard maps may make validation of the flood hazard mapping model challenging because the data applied might attempt to explain flood characteristics such as magnitude and spatial extent at low resolutions yet fail in accurately predicting the real event christopher et al 2015 early warning systems ews emergency responders and agencies and local institutions have a large demand for flood risk predictions in flood prone areas which necessitates the need for global flood models to synthesize big and small scale analyses undp 2018 other challenges may include unavailable or insufficient data which makes it difficult to model flood areas accurately using physically based or empirical based models at the basin scale in both gauged and ungauged basins multi criteria decision making mcdm methodologies efficiently demonstrate stakeholders judgment on flood issues and aid in integrating efficient operation between people and policymakers based on this mcdm techniques based on geographic information systems gis have been widely used in finding ranking and synthesizing flood influencing factors fifs for flood hazard mapping studies pourghasemi et al 2019 shafapour et al 2019 the gis based analytic hierarchy process ahp and fuzzy ahp f ahp methods with varying numbers and types of fifs have been successfully utilized in mapping flood hazard areas by several studies gigović et al 2017 luu and von meding 2018 papaioannou et al 2015 yang et al 2013 flood hazard mapping may be challenging because of the subjectivity of the fifs indicators and the selection of the most sensitive factors related to the basin synthesizing relevant factors that affect flood occurrence is very important in flood hazard mapping however few studies apply the optimum factors in delineating the level and extent of flood hazards the accurate assessment and delineation of flood prone areas is complex and challenging primarily owing to the complicated nature of the flood phenomenon bui et al 2019b chapi et al 2017 review findings by mudashiru et al 2021 showed that the mcdm was the most applied flood hazard modelling method amongst the empirical modelling methods which consisted of the machine learning artificial intelligence the statistical and mcdm methods with 18 3 27 and 54 7 application rate respectively additionally the ahp which is the most popular mcdm method madruga and evers 2016 is best applied with factors not exceeding nine to limit uncertainty arising from inconsistency in the decision making process alonso and lamata 2006 goepel 2018 however there is a need to apply an optimum set of non correlating fifs that are capable of delineating flood prone areas in an mcdm model therefore this study applies the ahp and f ahp mcdm methods to identify flood prone areas in the northeast penang basin located in penang malaysia by considering two groups of fifs this study aims to i develop flood hazard index fhi scores for three scenarios using the ahp and f ahp methods to enable the evaluation of the influence of each group of factors on the flood hazard maps ii conduct a sensitivity analysis for each factor based on the single parameter sensitivity analysis technique to develop a sensitized flood hazard index sfhi map iii compare the fhi and sfhi map results with historical flood records between 1984 and 2020 affecting 221 locations and amounting to 1403 flood events to ascertain the accuracy of the ahp and f ahp methods 2 materials and methods the flood hazard mapping framework adopted in this study is a novel combination of two mcdm methods and the application of the fifs for the identification of flood prone areas in the study area the procedures executed in this study to fulfill the objectives are summarized and presented in fig 1 the framework was built to effectively achieve the objectives and is summarized as follows i selecting and evaluating the optimum fifs factors that influence flood generation through geospatial analysis ii comparing the suitability of ahp and f ahp in identifying flood hazard areas in the study iii and evaluating the influence of the flood susceptibility factors group fsfg flood vulnerability factors group fvfg and flood susceptibility and vulnerability factors group fsvfg on the flood hazard output model preliminary processes before attaining the objectives include obtaining the non correlating flood influencing factors optimum factors weighting factors and weight aggregation the determination of the best factors was conducted through a comprehensive literature search the literature search enabled the identification of the relevant and most applied factors and enabled a gap for consideration of the significant factors the pairwise comparison method was applied as the weighting method while the saaty and fuzzy scale were applied respectively in obtaining the weights for each of the ahp and f ahp methods the first objective was achieved by evaluating the flood hazard maps resulting from the ahp and f ahp methods the second objective was achieved by evaluating the influence of each group of factors from the three scenarios on all the flood hazard maps generated from the two mcdm methods applied for this study the third objective was attained after a sensitivity analysis was conducted and the resulting maps from the analysis alongside the flood hazard maps generated from the mcdm methods were validated with the historical flood record of the study area 2 1 study area the methodology is implemented for the northeast penang basin which is one of the five districts in the state of penang in the northeast part of penang island in malaysia as shown in fig 2 the northeast penang area is between longitude 5 24 53 03 and latitude 100 19 48 89 the area covers 123 85 square kilometres approximately and is situated in the heart of the capital city in georgetown the northeast penang area serves as the central city of the state of penang and is one of the most highly populated cities with dense urbanization the climate in the northeast penang area is humid tropical weather with average yearly rainfall recorded at about 1800 3000 mm ismail 2000 the altitude of the northeast penang area ranges from 2 to 785 m above sea level with temperatures ranging from 23 5 c to 31 4 c and humidity percentage ranging from 60 9 to 96 8 the northeast penang area is closely linked with a higher rate of evaporation ali et al 2011 the climactic season of the northeast penang area can be categorized mainly into the pre monsoon season which extends from march to may northeast monsoon which extends from december to april southwest monsoon which extends from june to september and post monsoon which extends only for just the months of october and november the northeast penang area has experienced several flood events resulting from intense rainfall most of these flood events occurred during the northeast monsoon and sometimes during the intermonsoon seasons according to the daily maximum annual rainfall data collected from the department of irrigation and drainage did malaysia from the four stations in the study area the highest maximum daily rainfall occurred during the years 1996 2017 and 2018 the flood events which occurred in september and november 2017 have been reported as the worst flood events in the area with reported destruction of properties and infrastructures as shown in fig 3 therefore an accurate flood hazard map of this area is essential for flood management planning 2 2 data availability most of the data used in this study were obtained from government agencies as shown in table 1 a brief explanation of the fifs is given in section 2 2 1 whilst the gis data processing and analysis procedure are explained in sections 2 3 2 6 2 2 1 flood influencing factors fifs the influencing factors of various floods can be represented by drainage density elevation land use slope rainfall infiltration topographic wetness index time of concentration flood depth distance from rivers distance from roads and buildings population and distance from inundated locations 2 2 1 1 drainage density the drainage density refers to the total length of rivers per unit area liu et al 2019 it is one of the major factors that dictate flood occurrence high drainage density signifies a crucial runoff rate souissi et al 2020 similarly msabi and makonyo 2021 indicated that areas with a high volume of floods are often associated with high drainage density and high runoff volume dinesh et al 2007 2 2 1 2 elevation elevation forms a crucial factor in determining areas that are prone to flooding water flows from terrain with higher altitudes to lower grounds hence making flat areas more prone to flooding as flat areas tend to accumulate flow running off higher and steep terrains patrikaki et al 2018 2 2 1 3 land use land use is a factor related to urbanization progress and it is very important in flood hazard analysis land use influences hydrological processes such as infiltration rate flow velocity evapotranspiration and evaporation souissi et al 2020 urbanization actively modifies a naturally vegetated catchment area by increasing the percentage of imperviousness characterized by man made drainage systems rapid hydrological response to storms and varying spatio temporal distribution of flows guan et al 2015 concisely most changes in flow rates in urban areas result from increased peak storm events and volume of runoff as well as reduced infiltration rate and time of concentration owing to the increased urbanized area cheng and wang 2002 2 2 1 4 slope flat terrains get flooded quicker in comparison to areas with steep slopes characterized by higher grounds where runoff falls from patrikaki et al 2018 in addition to this slope evaluated in terms of change in elevation over the terrain indicates areas susceptible to erosion due to flood 2 2 1 5 rainfall surface runoff generation resulting to flood requires the occurrence of rainfall over the earth s surface therefore runoff is highly dependent on rainfall many factors affect runoff generation and these include rainfall characteristics depth duration intensity and morphological parameters vegetation soil type elevation drainage area basin shape elevation topography and drainage network patterns critchley et al 1991 according to mandeep et al 2008 the major rainy season in the state of penang is during the northeast monsoon period with a record of 1396 mm the accumulated average rainfall accounting for 57 of the annual average rainfall 2485 7 mm measurement in the state the southwest monsoon period accounts for about 856 6 mm of total rainfall and contributes 35 of the average annual rainfall measurement in the state 2 2 1 6 infiltration soil type and clay compositions are effective methods to represent infiltration kheir et al 2008 saragih 2020 the type and texture of soil that is present in an area highly correlates to the infiltration capacity of the terrain which explains how susceptible the area is to flood hazards flood volume and speed are likely to increase in areas characterized by clay soil in comparison to areas characterized by sandy soil clay soil is highly impermeable which makes it more susceptible to flood hazards than sandy soil which is permeable and has a higher infiltration capacity lappas and kallioras 2019 this study applied the lithological units in identifying related infiltration capacity lithology stands out as one of the crucial geomorphology factors that help in flood hazard mapping it is related to the permeability properties of the soil structure in the watershed which varies by rock type souissi et al 2020 2 2 1 7 topographic wetness index the twi is a hydrologic parameter that describes the extent of accumulation of flow in a watershed the index shows the ability of the gravitational forces in the watershed to convey flow downstream the accumulated flow infiltration rate is dependent upon the watersheds soil properties such as permeability structure texture consistency and void ratio pourghasemi et al 2013 2 2 1 8 time of concentration time of concentration tc describes the degree of how quickly a river catchment responds to rainfall turned runoff over its watershed mcenroe et al 2016 the size of a catchment affects the runoff volume as an increased catchment area will result in reduced peak flow an increased tc enables storage filling and infiltration to occur thereby reducing runoff volume steep slopes also reduce tc and retention volume thereby resulting in increased runoff volume according to abdulkareem et al 2019 reduced values of tc indicate rain characterized by high runoff volume and velocity from upstream towards the downstream areas devendra et al 2015 also reported that an increase in non vegetated cover results in a reduction in tc and increased runoff generation 2 2 1 9 flood depth heavy rainfall events form an integral part of the contribution to flooding occurrence and its magnitude wei et al 2019 rainfall with a high intensity usually results in high runoff depth in areas close to the stream networks thereby endangering the downstream environment bui et al 2019a flash floods are often characterized by high intensity rainfall occurrences and short duration storms according to the drainage masterplan report for northeast penang by did 2018 high intensity rainfall is likely to cause flash floods in low terrain areas with poor drainage systems therefore the flood records for the year 2017 affecting 55 locations in the study area were interpolated to analyze the spatial extent of flooding and the affected areas 2 2 1 10 distance from rivers dfr the dfr has a relevant influence on the possibility of occurrence and depth of flooding due to the river overflow resulting from insufficient conveyance capacity janizadeh et al 2019 dfr is also known for its contribution to flooding in areas in closer proximity to rivers shafapour et al 2019 the infrastructures buildings and businesses closer to rivers are more susceptible to the risk of flooding 2 2 1 11 distance from roads and buildings dfrb according to shuster et al 2005 demonstration of urbanization processes includes the expansion of the surface area of road systems reduced drainage capacity through the development of floodplains and modification of landscape for agricultural purposes these alterations cause a decrement in possible pathways for runoff thereby increasing the risk of flooding the urban roads and development reduce the infiltration capacity of an area thereby increasing its susceptibility to flooding shafapour et al 2019 2 2 1 12 population the population is an important flood causing factor when assessing the risk of flood hazards to humans a highly populated area is more at risk of flooding hazards additionally areas with high density populations indicate more people and activities will be disrupted during a flood 2 2 1 13 distance from inundated locations dfil geographical related features such as distance to a hazard area have been indicated to be a key factor in determining the perception of susceptibility to flooding hazards the distance to inundation areas has also been considered as a factor contributing to flash and river flooding analysis o neill et al 2016 pradhan 2009 applied historically flooded areas as the factor in assessing flood susceptibility areas in this study the distance of the study area from flood locations in 2017 is considered a hazard factor 2 3 gis processing and analysis of data the thematic layers for all thirteen fifs are presented in fig 4 a m the drainage density slope elevation and topographic wetness index thematic layers were created in arcgis by applying the tandem x dem and spatial analyst toolbox the thematic layers for rainfall and flood depth were created using the interpolation tool while the distance from rivers distance from roads and buildings and distance from inundated locations were created using the euclidean distance tool the land use map was reclassified from the original shapefile obtained from pegis to obtain five land use classes as described in fig 4c the time of concentration was estimated using an empirical formula with the support of arc hydro and zonal statistics as table tools in arcgis after creating the thematic layers all features of the factors were classified into the five classes with a rating between 1 and 5 using the value function scaling method malczewski 2000 malczewski and rinner 2015 this is a method of standardization of the factors features all factors were normalized using the ahp and f ahp methods to obtain the respective weights the geometric mean approach was utilized for the ahp method to synthesize the group of experts judgments and the weights of the factors were generated using the eigenvector approach the method proposed by chen tung et al 2006 for integrating a range of decision makers opinions is applied for the fuzzy methods while the geometric mean approach proposed by buckley 1985 was utilized in obtaining the factors weights the natural break jenks papaioannou et al 2015 pourghasemi et al 2019 classification method is applied for all factors except for infiltration and land use theclassification method applies an algorithm to group specific attributes values into classes that set it apart by well defined breakpoints these classes are best described in their groups based on an ordinal scale to allow for easy comprehension of the map details the classes are founded on natural grouping that is specific to the dataset campbell and shin 2019 jenks 1967 the method has a limitation of allowing a comparison of two or more maps because of the specificity of the classification group to each dataset type this limitation was the reason why the defined interval classification method was applied for the fhi scores to allow a similar range of scores for an accurate comparison of the maps the weight aggregation to generate the fhi maps was conducted using the wlc technique in the gis environment with the map algebra tool 2 4 flood hazard index fhi evaluation the thirteen non correlating fifs applied in this study and the factors respective weights for the determination of fhi are presented in table 2 flood hazard occurrence usually relies on some of the basins characteristics that is flood hazard zones will be characterized by features like flat areas proximity to rivers impervious land cover type gentle to moderate slope high drainage density and others it is important to consider factors that are explainable by the characteristics of the catchment area related hazards and the flood event the selection of the factors applied in this study was performed based on the proven relevance of the factors in the identification and prediction of flood prone areas from the literature kazakis et al 2015 shafapour et al 2019 yang et al 2013 this was done to prevent collinearity of the factors which reduces the prediction accuracy of the generated flood hazard map al juaidi et al 2018 the factors presented in table 2 are processed with the weighted linear combination wlc which is the sum of the product of estimated factors weight from the experts judgments and the attributes of the factors applied wlc is one of the most common methods that implement a decision criterion in creating integrated maps in gis malczewski 2000 the wlc will produce an fhi map where the cell value represents an integration of all factors weights considered in evaluating flood hazards the influence of each factor depends on the factor s weight and the factor s map cell value eq 1 is applied to obtain the map aggregation 1 fhi w f r f where w f is the factor weight and r f represents the factor attribute represented by a map to obtain the fhi of the fsvfg eq 1 is rewritten as the expression given in eq 2 2 fhi w f w sf r f where w sf is the weight of the corresponding group of the group of factors and r f represents the factor attribute represented by a map the fsfg fvfg and the fsvfg labels for the ahp and f ahp were extracted from table 2 three scenarios were tested to enable the evaluation of each group of factors on the model output the first scenario involved generating fhi maps for only the fsfg group fhi1 and fhi2 the second scenario was to generate fhi maps for only fvfg fhi3 and fhi4 and the third scenario was to generate fhi maps for fsvfg fhi5 and fhi6 for the ahp and f ahp mcdm methods respectively the fhi for the first scenario was evaluated using the expression described in eq 3 3 fhi fsfg w f 1 r f 1 w f 2 r f 2 w f 3 r f 3 w f 4 r f 4 w f 5 r f 5 w f 6 r f 6 w f 7 r f 7 w f 8 r f 8 w f 9 r f 9 the fhi for the second scenario was evaluated using the expression described in eq 4 4 fhi fvfg w f 10 r f 10 w f 11 r f 11 w f 12 r f 12 w f 13 r f 13 the fhi for the third scenario was evaluated using the expression described in eq 5 5 fhi fsvfg w fsfg w f 1 r f 1 w f 2 r f 2 w f 3 r f 3 w f 4 r f 4 w f 5 r f 5 w f 6 r f 6 w f 7 r f 7 w f 8 r f 8 w f 9 r f 9 w fvfg w f 10 r f 10 w f 11 r f 11 w f 12 r f 12 w f 13 r f 13 where w fsfs w fvfs a n d w fsvfs represents the weight of the fsfg fvfg and fsvfg groups respectively the fhi maps generated for the three scenarios are labeled and presented in table 3 the resulting fhi scores are sub categorized into very low low moderate high very high and extremely high flood hazard index classes this classification was based on the equal interval to provide an equal range for the comparison of all six maps derived based on grouping and type of method applied additionally the flood hazard classes were also adopted from the flood hazard classes of the japanese flood fighting act 2001 established by the did in 2003 anuar 2018 2 4 1 mcdm methods the ahp method saaty 1990 framework is operable with the pairwise comparison method it is subjected to a pairwise comparison by developing a ratio matrix which is the input and the resulting relative weights as the output the weights are evaluated by normalizing the eigenvector related to the maximum eigenvalue of the reciprocal matrix the facilitator and the involved decision makers are required at the initial stage to define priorities for the selected factors by evaluating them in pairs based on their respective significance thereby generating a pairwise comparison matrix pcm the saaty scale is described in table 4 as it is applicable in representing the decisions based on their relative importance on the other hand the fuzzy ahp uses a scale of the linguistic variable instead of the numeric variable scale to highlight the preference of one factor over another a scale of linguistic variables has its values expressed in words rather than numbers in a natural or artificial language the notion of a linguistic variable demonstrates a useful method for accurately depicting occurrences that are too complicated to be stated in conventional quantitative terms table 4 lists the linguistic terminology used to express saaty s ahp and f ahp scales a detailed explanation of the f ahp process applied in this study can be found in the studies by chen tung 2000 chen tung et al 2006 the consistency ratio of the decision making process was evaluated using the expression in eq 6 6 ci λ max n n 1 where n number of factors applied and λ max principal eigenvalue in this study the ahp saaty 1990 and the f ahp buckley 1985 were applied to the weight estimation of the selected fifs both methods relied on the pairwise comparison results obtained from consulting fifteen experts in the field of hydrology and water resources engineering the saaty saaty 2000 and the fuzzy scale demirel et al 2008 feloni et al 2019 were applied in the weight assignment process the saaty s scale crisp numbers were transformed into fuzzy numbers to fit the linguistic scale of the f ahp the decision of all fifteen experts was combined by applying the geometric mean method for the ahp before finally applying the principal eigenvalue method to estimate the final weights of the factors the fsfg nine factors generated 36 pairwise comparisons the fvfg four factors generated six pairwise comparisons while the fsvfg two groups generated 1 pairwise comparison summing to just 43 total pairwise comparisons there would have been 78 pairwise comparisons if the thirteen factors were applied directly without grouping the factors the geometric mean method by buckley 1985 was applied in obtaining the fuzzy weights the mean of the fuzzy weights was subsequently used as f ahp weights to enable a smooth aggregation process in gis this was done because the fuzzy weights are represented by lower middle and upper functions the weighting analysis is presented as supplementary material 2 5 evaluating the influence of each group of factors on fhi results three main processes in flood mapping must be successfully tackled the first process involves providing a general framework that explains the mechanism of flooding the second involves identifying the optimal set of factors relating to the flooding process and the third is evaluating the influence of these factors based on flood occurrence this kind of complexity is best handled by applying suitable models and appropriate methods rather than applying a set of factors at once the factors were grouped into two and tested in three scenarios with the two mcdm methods this was done to reduce the number of pairwise comparisons which can limit uncertainty arising from inconsistency in the decision making process of a larger number of factors additionally the influence of each group of factors is evaluated to ascertain the relevance of applying the group of factors in the flood hazard mapping model the influence of each group of fifs was evaluated in two different ways the first approach entails evaluating the influence of each group of factors on the fhi value when fsfg fvfg and fsvfg were applied the second comparison entails the evaluation of the area covered by each fhi class i e very low extremely high fhi of the flood hazard mapping results from fsfg fvfg and fsvfg for the ahp and f ahp methods applied in the study the influence of each group of factors was then evaluated by multiplying the corresponding flood hazard index class by the area product the sum of the product that corresponds to the influence of each group of factors in numerical value was then obtained the percentage influence of each group of the factor was obtained by dividing each corresponding total by the sum of the total of all groups multiplied by 100 2 6 sensitivity analysis and result validation the input of the flood hazard mapping model is represented by the factor weights and the map cell values while the output of the model is represented by the fhi values the reliability of the output relies on the certainty of the input data the decision making process and the wlc model the influence of changing the criterions weights is a widely applied approach in conducting a sensitivity analysis in mcdm modelling through the application of the one at a time technique malczewski and rinner 2015 uncertainties in mcdm methods may arise from both internal and external sources the internal source of uncertainty in this study relates to the decision making process while the external source of uncertainty relates to input data and techniques applied the reliability of a model can be assessed by conducting a sensitivity analysis where the variation in the output is analyzed based on the applied input the single parameter sensitivity analysis enables the evaluation of the effective weights eq 7 souissi et al 2020 by replacing the empirical weights generated through the ahp or some other weighting techniques 7 w e c r c w c wi 100 where c r represents the criterion ranking rating c w represents the relative weight of the criterion and c wi represents the cumulative weight used in estimating the fhi the spsa was proposed by napolitano and fabbri 1996 for evaluating the effect of single parameters on aquifer vulnerability assessment in this study the spsa approach used in mapping flood hazard areas by kazakis et al 2015 souissi et al 2019 toosi et al 2019 was adopted whereby the effective weights of the flood influencing factors both fsfg and fvfg were evaluated to create sensitized fhi maps for all six generated flood hazard maps thelayer weight derived from ahp and f ahp is multiplied by the individual layer itself which is the layer factor that has been used for generating the fhi map and then divided by the generated fhi map the summarized statistics effective weights obtained from the sensitivity analysis are presented in table 5 the mean effective weights are then applied in generating the sensitized fhi sfhi maps the fhi1 fhi6 and sfhi1 sfhi6 maps from the sensitivity test cases were then overlaid with historical flood records of the study area 1984 2020 to validate the accuracy of the methods applied in this study for the ahp and f ahp methods the total number of events between 1984 and 2020 was 1403 affecting a total of 221 places in the study area 3 results and discussion 3 1 results 3 1 1 ahp and f ahp weight evaluation the determination of flood prone areas in this study was modelled using the ahp and f ahp with varying group of factors to identify the group of factors with the highest influence on the output model the ahp and f ahp methods are based on a decision making process whose consistency indexes were 0 015 and 0 036 for the fsfg and fvfg respectively and are below the threshold of 0 10 indicating a satisfactory consistency of the experts judgments saaty and vargas 1980 according to the range of the feature values obtained for each thematic layer of factors shown in fig 4 a m relative weights were assigned to each feature classification based on its relation to flood generation the selected factors factors respective groups and corresponding weight are shown in table 6 and table 7 the result of the f ahp weight estimation indicated that the drainage density was the highest contributing factor amongst others toward flood hazard level based on the weight shown in table 6 for scenario 1 20 44 however with fsvfg it was the third highest contributing factor to the f ahp model table 8 higher values of drainage density are highly correlated with flood hazard occurrence areas characterized by low altitude are distributed along the north northeast and some central parts of the basin it can be observed that the areas with lower altitudes were assigned the highest rating as shown in table 6 the land use composition was grouped into five classes consisting of forest area 51 23 urbanized area 42 80 bareland 3 99 cultivated area 1 03 and waterbody 0 94 as shown in fig 4 c the highest rate was assigned to the water body closely followed by the urban areas land use class as presented in table 6 the thematic map of the slope in fig 4 d showed that the areas with the lowest percentage rise in slope areas 12 4 cover an area of 39 09 of the basin 12 41 32 56 covers an area of 27 03 32 57 52 72 covers an area of 19 74 57 73 80 62 covers an area of 11 73 and 80 63 covers an area of 2 42 similar to the elevation the area with lower values of the slope is assigned higher rates as shown in table 6 the slope is highly related to the amount of runoff its speed the infiltration rate of a catchment and its flow accumulation spatial distribution of the average annual rainfall from 1976 2020 for four rainfall stations in the study area is conducted using the idw method in arcgis the resulting thematic layer from the idw spatial interpolation was classified into five groups r 2240 mm 2250 mm r 2330 mm 2340 mm r 2410 mm 2420 mm r 2490 mm and r 2500 mm as shown in fig 4 e the highest rating was assigned to the area receiving the highest depth of rainfall as shown in table 6 the result of the ahp weight estimation showed that the rainfall was the highest factor amongst others toward flood hazard level based on the weight shown in table 6 for scenario 1 20 65 however with fsvfg it was the fourth highest contributing factor to the f ahp model table 8 the resulting thematic layer had three classes of lithological units as shown in fig 4 f acid intrusive undifferentiated clay and silt marine and clay silt sandy and gravel undifferentiated continental the lithological formations obtained were classified into three infiltration categories based on factors that include secondary porosity clay composition facies similarities and exposed thickness kheir et al 2008 therefore the acid intrusive undifferentiated was classified as moderate permeability clay and silt marine as low permeability and clay silt sandy and gravel undifferentiated as moderate high permeability as presented in table 6 the generated thematic twi map was classified into five groups twi 13 9 5 twi 12 7 1 twi 9 4 4 9 twi 7 and twi 4 8 high values of twi indicate areas with high flow accumulation potential are usually areas characterized by low altitude and gentle moderate slope the higher values of twi were assigned the highest rating as shown in table 6 the resulting tc values from the thematic layer shown in fig 4 h were classified into five with the lowest value assigned the highest rating as shown in table 6 this is because a significant reduction in vegetation cover and replacement with impervious cover will result in lower tc values and contribute to flooding the result of the ahp and f ahp weight estimation showed that the flood depth was the second most contributing factor amongst others toward flood hazard level based on the weight shown in table 6 for fsfg 17 00 and 16 65 however for fsvfg it was the sixth and fourth highest contributing factor for the ahp and fahp models respectively table 8 the resulting thematic layer from the idw spatial interpolation of the flood depth was classified into five groups with the highest flood depth value assigned the highest rating as shown in table 6 fd 0 3665 0 3666 fd 0 7137 0 7138 fd 1 061 1 062 fd 1 408 and fd 1 409 m lower values of dfr indicate areas that are closer to streams and are at higher risk of flooding as rated in table 7 the weighting evaluation for both the ahp and f ahp methods showed that the most contributing factor towards flood hazard was the dfr 18 and 20 respectively as shown in table 8 for fsvfg a low dfrb value may pose a high risk to socio economic activities during a flood event it also indicates that the areas are closer to urbanized areas and are at higher risk of flooding as rated in table 7 the denser populated areas were assigned with a higher rating as indicated in table 7 like the dfr the weighting evaluation for both the ahp and f ahp methods showed that the second most contributing factor towards flood hazard was the dfil 16 and 13 respectively as shown in table 8 for fsvfg the resulting thematic layer as shown in fig 4 m was classified into five groups dfil 997 5 997 6 dfil 1949 1950 dfil 2993 2994 dfil 4037 and dfil 403 with lower values assigned highest rating as shown in table 7 3 1 2 flood hazard mapping the first step was to reclassify all the factor maps which were presented for all factors in fig 4 a m all factors maps were standardized by using the value scale function as explained in section 2 3 the thematic layers and reclassified maps for flood depth drainage density land use elevation slope twi infiltration time of concentration dfr dfrb and dfil had a raster cell size of 10 10 the rainfall idw interpolated raster and the population had varying raster cell sizes that did not correlate with the other factors to correct this both the rainfall and population raster output maps were resampled to 10 10 cell sizes using the bilinear interpolation method with the data management tool in gis the map algebra tool in gis was then used to create flood hazard maps for the ahp and f ahp mcdm methods using equations 3 4 and 5 for the three scenarios as illustrated in fig 5 a f the defined interval classification method was applied for the fhi1 6 to maintain a consistent classification range with an interval size of 0 75 as shown in fig 5a f the actual range of the fhi1 6 scores is presented in table 9 all six flood hazard maps generated were classified into five hazard classes ranging from very low low moderate high very high and extremely high flood hazard level classes as shown in fig 5 a f the breakdown for each fhi class across the six flood hazard maps is presented in table 10 additionally the summary for classification of each flood hazard level and the corresponding coverage area and percentage coverage area is given in table 11 and fig 6 for flood hazard maps generated using the fsfg fvfg and fsvfg respectively for ahp and f ahp methods table 9 showed that fhi1 had an index score ranging from 1 44 4 04 fhi2 had an index score ranging from 1 39 4 14 fhi3 had an index score ranging from 1 31 to 5 fhi4 had an index score ranging from 1 33 to 5 fhi5 had an index score ranging from 1 53 4 36 and fhi6 had an index score ranging from 1 61 to 4 27 respectively table 9 also shows that when only fsfg was applied the maximum index score of the fhi1 for the ahp model was 4 04 but when fsvfg was used the maximum index score of fhi5 increased to 4 36 similarly for the f ahp method the maximum index score increased from 4 14 to 4 27 respectively as shown in table 9 this indicates that the fhi generated from the fsfg i e fhi1 and fhi2 was at the lower bound whilst the fvfg i e fhi3 and fhi4 was at the upper bound this indicated that when fsfg was combined with fvfg the conformity of the fhi scores increased for the two mcdm methods applied for flood hazard mapping in this study the result of the evaluation for the ahp and f ahp shows that the percentage of the coverage area by each flood hazard class for the two methods is almost similar as shown in fig 6 however the f ahp model fhi2 shows the highest coverage area for the very high 0 1 and the ahp fhi1 presented the lowest percentage in the coverage area for the very low 0 005 flood hazard class as shown in fig 6 in addition fhi1 57 4 presented the highest percentage coverage for the moderate flood hazard area in comparison with fhi2 52 5 fig 6 shows that fhi3 and fhi4 had 22 7 and 27 2 occurring in the extremely high flood hazard class and the highest coverage in the very high 34 1 and 35 5 flood hazard class areas respectively fig 6 also shows that the ahp model fhi5 had the most coverage area for the very high 24 13 and the f ahp fhi8 had the largest percentage in the coverage area for the low 1 86 flood hazard class areas respectively from the map generated from the fsvfg shown in fig 5 e and 5 f i e fhi5 and fhi6 the very high and high areas are dispersed majorly towards the north eastern eastern and some northern and southern locations of the study area the land use map was overlaid on each of the six generated flood hazard maps fhi1 fhi6 to evaluate the flood hazard level corresponding to each land use class of the study area this was done by combining each flood hazard map with the land use raster using the combine tool in the spatial analyst toolbox in the gis environment the area for the corresponding flood hazard and land use combination was calculated and extracted the distribution of land use in the five flood hazard classes for fhi1 is presented in fig 7 fig 7 shows that water body 37 54 and 52 44 and urban area 53 46 and 46 07 land use class types had areas dominated in the moderate to high flood hazard classes the bare land was predominantly in the moderate 75 02 flood hazard class the cultivated land use class type was predominantly in the moderate 68 39 flood hazard class while the forest area land use class type was predominantly in the low to moderate 38 11 and 59 32 flood hazard class 3 1 3 evaluating the influence of each group of factors on the fhi maps to obtain the influence of each group of factors on the flood hazard maps the explanation given in section 2 5 was applied the classification shown in table 10 was applied in estimating the area in square kilometres covered by each fhi class for the fsfg fvfg and fsvfg respectively as presented in table 12 and table 13 for the ahp and f ahp methods subsequently the percentage influence was obtained as presented in table 14 and table 15 for the ahp and f ahp methods respectively tables 14 and 15 show that the fvfg had the highest influence on the generated flood hazard maps generated by applying the ahp 40 15 and f ahp 42 09 methods in comparison with fsfg 25 85 and 25 26 and fsvfg 34 and 32 65 respectively it was also observed that the fvfg was on the upper bound in comparison with other groups based on the fhi conformity score which might indicate the fvfg s higher influence additionally this can be attributed to the weights assigned to the fvfg 0 552 and 0 47 for ahp and f ahp respectively 3 1 4 single parameter sensitivity analysis a sensitive parameter is one that elicits the highest change in the model output for a small change in the given input parameter the summarized statistics effective weights mean obtained for the sensitivity analysis are presented in table 16 the mean effective weights were applied in generating sfh1 sfhi6 shown in fig 8 a f the findings from the sensitivity analysis showed weights applied for fsfg for both the ahp and t fahp weights varied in value and sometimes the ranking order of the most contributing factors in comparison to the effective weights for example in scenario 1 the ahp weight for rainfall with the highest contribution was 20 65 see table 6 while the mean effective weight for rainfall was 18 9 see table 16 moreover the sensitivity analysis showed that for sfhi1 and sfhi2 the least sensitive factor was twi however for the fvfg results showed that the weights of factors applied in generating fhi3 and fhi4 showed a similar rank in the order of the weights with the mean effective weights applied for generating sfhi3 and sfhi4 additionally for both sfhi3 and sfhi4 the population was the least sensitive factor furthermore sensitivity analysis for all factors showed similar findings with the fsfg as the effective weights varied from the initial ahp and f ahp weights and in the order of the factors moreover the overall least sensitive factor for sfhi5 and sfhi6 was the twi as well like the fhi5 and fhi6 the effective weights for sfhi5 and sfhi6 showed that the distance from rivers was the most important factor of all factors applied with 20 3 and 29 2 and 17 6 and 26 5 weight and effective weight respectively this confirms the accuracy of the methodology in the assessment of flood hazard areas in this study the fhi maps showed varying fhi conformity scores with the sfhi maps as shown in fig 5 a f and fig 8 a f 3 1 5 validation the flood hazard maps generated based on the three scenarios with fsfg fvfg and fsvfg applying ahp and f ahp i e fhi1 fhi6 and sfhi1 sfhi6 were overlaid with the historical flood event records 221 flood points between 1984 and 2020 of this study area fig 5a f this was done to obtain which of the methods and test cases has the best predicting capability the number of flood events in each fhi class location was extracted using the zonal statistics as table tool in the gis environment table 17 shows the distribution of the extracted number of flood events across the five flood hazard classes for fhi1 6 and sfhi1 6 respectively while fig 9 and fig 10 show the distribution of the number of historical flood events in the flood hazard classes fig 9 shows that 77 8 71 8 and 71 8 of the analyzed historical flood events occurred in the high flood hazard class for fhi1 i e fsfg with ahp method and fhi2 i e fvfg with f ahp method respectively additionally 6 of the historical flood events occurred in the very high flood hazard areas for the fhi2 while 22 2 occurred in the moderate flood hazard areas for the fhi1 respectively the fvfg modelled maps showed that 91 8 of the historical flood events occurred in the extremely high flood hazard class for fhi3 i e fsfg with ahp model and fhi4 i e fvfg with f ahp method respectively however the integration of both fsfg and fvfg as in fhi5 i e fsvfg with the ahp and fhi6 i e fsvfg with the f ahp showed that 96 1 and 88 9 of the historical flood events occurred in the very high flood hazard class respectively it was observed that the fsvfg had a higher percentage of flood events in the very high flood hazard class when compared to only fsfg or only fvfg were applied for the ahp and f ahp methods furthermore it was observed that the fsvfg balanced the overestimation and underestimation in the fsfg and fvfg modelled maps for the two mcdm methods respectively additionally 100 of the historical flood events occurred in the moderate to extremely high flood hazard class areas for fhi1 fhi6 respectively furthermore fig 9 showed that fhi1 had 22 2 of the historical flood occurring in the moderate flood hazard class for fhi1 however the fhi5 fsvfg with the ahp showed that 0 of the historical flood events occurred in the moderate flood hazard class this indicated that when both fsfg and fvfg were combined fsvfg the number of historical flood events occurring in the moderate flood hazard class reduced from 22 2 to 0 this further confirmed the relevance of adopting both the fsfg and fvfg in mapping flood hazard areas in this study fig 10 shows that the flood hazard maps generated from the sensitivity analysis sfhi1 sfhi6 showed different attributes from the fhi1 fhi6 for example the historical flood events in the high flood hazard class for sfhi1 and sfhi2 88 6 and 72 2 were more than fhi1 and fhi2 77 8 and 71 8 respectively however 100 of the historical flood events occurred in the high to extremely high flood hazard class areas for sfhi1 sfhi6 respectively similarly to fhi1 fhi6 the results from the sensitivity analysis have shown similar results to the flood hazard maps created with the ahp and f ahp methods for the three scenarios 3 2 discussion a thorough review by madruga and evers 2016 has signified that although the mcdm is easy to implement it is characterized by uncertainty based on its subjectivity this limitation is highly related to the decision making process which requires a certain number of pairwise comparisons by the decision maker based on the number of factors under consideration the method applied in this present study on the other hand addressed the uncertainty due to the application of a large number of factors in determining the fhi by grouping the factors into two to reduce the number of pairwise comparisons furthermore in this present study less data was applied in the determination of flood prone areas by incorporating the gis mcdm methodology the mcdm derived weights obtained in this study were based on the decision made by experts which met the satisfactory threshold for the consistency index therefore if the same method is to be replicated in another basin the weights of the selected fifs will be dependent on the decision maker s which might produce varying results this might be a drawback depending on the degree of epistemic uncertainty however in the case where the values of the weights are subjected to uncertainty the single parameter sensitivity analysis applied in this study can provide effective and reliable fifs weights for evaluating flood prone areas in the basin the evaluation of the fhi showed the spatial distribution of the flood hazard areas identified from fhi 5 and fhi6 maps fsvfg shown in fig 5 e and f the areas that are surrounded by rivers characterized by lower slope percent denser drainage density high rainfall depth low infiltration rate higher flood depth and flat areas were found to exhibit flood hazard levels of moderate to very high flood hazard class areas however areas characterized by higher elevation lower drainage density lower rainfall amount and farther from rivers and drainage networks were found to exhibit flood hazard levels of low to very low fhi similar findings were reported in studies by kazakis et al 2015 toosi et al 2019 the evaluation of the fhi based on the distribution of fhi in different land use type compositions has shown that the flood prone areas were majorly distributed in the urbanized part of the study area this explains the role of urbanization in contributing to flooding generation as it influences hydrological processes such as infiltration rate flow velocity evapotranspiration and evaporation souissi et al 2020 additionally in urban area or city center the percentage of impervious area is high hence the losses due to interception and evapotranspiration is diminishing concisely land use also influences most changes in flow rates in urban areas resulting from an increased peak flow event increased volume of runoff reduced infiltration rate and reduced time of concentration owing to the increased urbanized area cheng and wang 2002 in the northeast penang area the highly urbanized areas are medium and high density residential areas located mainly in intermediate and flats areas these areas were rightly classified by findings from this study as areas of moderate to very high flood hazard index classes these areas represent a potential platform for implementing suitable land use practices and regulations at the national level to evaluate flooding this can be conducted by providing and improving solutions such as increasing infiltration capacity through the building of effective onsite detention or retention facilities and improving drainage capacities through the flood management system in addition to this there is a need to support this sort of flood mitigation solution with a proper early warning system these findings are capable of providing solutions to flood mitigation and prevention strategies through appropriate land use management practices such as appropriate control at source in urban areas to reduce the risk of flooding due to human actions and possible climate change huong and pathirana 2013 kalnay and cai 2003 shrestha and lohpaisankrit 2017 zhou et al 2004 due to the spatial and temporal variability of flood main causal factors such as hydrology geomorphology climatic and topography flood hazard mapping is quite regional although fhi indexes derived for this study are specific to data for the northeast penang these data can be modified based on other regions characteristics to allow the methodology to be tested in other regions the evaluation of the fifs groups showed that the weight assigned to each group had an impact on the group s influence on the output model these findings correlate with the study by kazakis et al 2015 toosi et al 2019 that reported that the higher the weights assigned to a specific factor the higher is its influence on the flood hazard mapping output model the sensitivity analysis indicated varying weight values but similar results overall these differences have shown that the ahp and the f ahp methods applied are sensitive to model input change despite these variations the flood hazard maps generated with the same factors and model presented almost similar maps to the sensitized maps the validation of the flood maps with flood records between 1984 and 2020 showed that when the fsfg were combined with fvfg fsvfg the flood hazard maps i e fhi5 and fhi6 presented better outcomes because the areas classified as highly susceptible to flooding were the areas that experienced the highest percentage of the historical flood events this indicates the accuracy of the methodology applied in conclusion the ahp and f ahp have performed satisfactorily in identifying flood hazard areas in the current study the flood hazard assessment maps can also provide useful information for regional land use and flood management planning allowing for the identification of safe and non safe urban development regions bathrellos et al 2016 the flood hazard map can be used by planners engineers and policymakers to find ideal regions for sustainable urban growth 4 conclusion the ahp and f ahp methods were applied in identifying flood hazard areas of northeast penang the results of the weighting of the fifs showed that distance from rivers was the most dominating fif while the twi was the least dominating factor of all thirteen fifs for the two mcdm methods as the proximity to rivers is a crucial factor that determines the degree of a basins susceptibility to flooding the resulting fhi maps from the three groups of factors showed that the fvfg had the highest fhi score in comparison with the fsfg and fsvfg the results also indicated that the flood hazard index conformity score increased when fsfg was combined with fvfg for the two mcdm methods ahp and f ahp furthermore the result of the influence of each group of factors on the area covered by varying flood hazard classes very low extremely high showed that the fvfg had the highest influence on the generated flood hazard maps for the ahp and f ahp methods the relevance of the application of optimum factors is provided in the standalone result of the fsfg group which performed lesser in the prediction of flood hazard areas in comparison with the fsvfg furthermore the fvfg standalone result overestimated the fhi class areas in which the historical floods occurred therefore proving the benefit of the methodology the evaluation of the two mcdm methods showed that the resulting map presented close results these findings agree with the article by chan et al 2019 that highlighted that although the ahp and fuzzy methods do not present similar results the solution that the ahp and fuzzy ahp methods produce is similar this is obvious in the validation results obtained from this study which presented an accurate prediction of historical flood areas for the two mcdm methods applied in this study therefore the ahp and f ahp approaches can be concluded to be valid tools for identifying flood hazard locations in this study area and other basins because floods are a common occurrence in the studied area the methods used in this study could aid in identifying potential flood prone areas as well as improving and innovating flood risk management practices the findings of this study can be applied as a preliminary investigation for further research which could include adapting this methodology to other basins with varied climatic characteristics and regimes as well as studying scenarios of an increased number of flood influencing factors that can be classified into more than two groups comparing of different types of mcdm model with similar case scenario applied in this study and evaluating the influence of flood influencing factors on the flood hazard map using machine learning and statistical methods credit authorship contribution statement rofiat bunmi mudashiru investigation conceptualization methodology writing original draft software formal analysis visualization validation writing review editing nuridah sabtu resources formal analysis visualization supervision project administration writing review editing rozi abdullah conceptualization methodology azlan saleh software resources ismail abustan conceptualization methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgment the authors would like to acknowledge the effort of ir haniza mukhtar of the department of irrigation and drainage penang malaysia for the support provided in getting the data used in the study the authors also appreciate the financial support of the tertiary institutions education fund tetfund nigeria appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2022 128055 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
