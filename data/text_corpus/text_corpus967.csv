index,text
4835,this study investigates the performance of multiple high resolution remotely sensed precipitation estimates at hourly and daily time scales over canada for 2014 2018 four products of the recently released integrated multi satellite retrievals for global precipitation measurement imerg v06 and the multi radar multi sensor mrms precipitation rate data are analyzed for different seasons evaluations are based on a suite of metrics to assess different characteristics of precipitation estimates using quality controlled hourly gauge data considered as the truth the results suggest that calibrated precipitation precipitationcal outperforms the other imerg products particularly over the prairies and during fall and summer over the western and eastern coastal regions imerg tends to overestimate precipitation intensities by 25 the discrepancy between satellite and ground based data is higher for more intense precipitation events further analyses indicate that while mrms tends to overestimate the amount of precipitation it outperforms the imerg products based on several metrics especially in detecting the occurrence of precipitation over the eastern coastal regions overall the study of imerg v06 and mrms precipitation estimates at a relatively high temporal resolution indicates that both products have the potential to complement ground based observations over canada keywords imerg v06 mrms qpe evaluation canada precipitation remotely sensed data 1 introduction precipitation is the key input variable to hydrological models and plays an important role in water resources planning including flood and drought analysis monitoring and forecasting abbasian et al 2021 zhang and najafi 2020 however its accurate estimation is challenging particularly in areas with sparse observations and regions with complex terrains although direct precipitation measurements using rain gauges are considered as the most accurate observations petersen et al 2005 there are limitations associated with the at point representation of an entire domain and inability to capture precipitation variability at high resolution villarini et al 2008 therefore there is considerable interest to use indirect remotely sensed estimate rse data such as radar and satellite products as they provide fine scale representations of the amount frequency and distribution of precipitation wen et al 2017 sungmin et al 2017 sun et al 2018 in this study the rse products are evaluated over canada which has a diverse hydroclimate due to its extensive geographical features latitudinal extent and topographic variations polar and arctic climate is dominant in the northern parts and regions on the west experience temperate climate with heavy precipitation associated with air currents from the pacific the presence of the great lakes can moderate the weather in southern parts of ontario and quebec with hot humid summers and cold snowy winters asong et al 2017 singh et al 2019 flooding is the most common natural disaster in canada and among the costliest according to public safety canada many historical flood events in major river systems and populated areas across canada are associated with heavy rain and subsequent excessive runoff lemmen et al 2016 jalili pirani and najafi 2020 therefore reliable precipitation data with high spatial and temporal resolution are essential for flood risk mitigation and water resources management particularly in mountainous regions with limited accessibility nonetheless canada like many other countries suffers from a lack of dense network of gauges especially in remote areas such as the arctic and high elevation zones mekis et al 2018 the existing point coverage of gauge measurements may not represent the highly variable spatial distribution of precipitation properly martinaitis et al 2015 the rse products can address these limitations by providing high resolution spatial and temporal coverage of precipitation that can be used to detect storm events assess flooding and develop mitigation measures najafi et al 2021 some of the widely used satellite precipitation products spps include precipitation estimation from remotely sensed information using artificial neural networks persiann sorooshian et al 2000 aghakouchak et al 2012 hossain and huffman 2008 the national oceanic and atmospheric administration noaa s climate prediction center cpc morphing technique cmorph joyce et al 2004 stampoulis and anagnostou 2012 gumindoga et al 2019 the tropical rainfall measuring mission trmm multi satellite precipitation analysis tmpa huffman et al 2007 villarini and krajewski 2007 tian et al 2007 habib et al 2009 yong et al 2015 mei et al 2016 moazami et al 2014 2016 and the global satellite mapping of precipitation gsmap kubota et al 2007 2009 these satellite products have some limitations associated with the spatial and temporal resolution of precipitation due to the number of infrared ir and microwave mw based sensors utilized to provide more accurate precipitation estimates at fine spatiotemporal scales the national aeronautics and space administration nasa and the japan aerospace and exploration agency jaxa launched the global precipitation measurement gpm mission in february 2014 called the integrated multi satellite retrievals for gpm imerg with a temporal resolution of 30 min and spatial resolution of 0 1 as a successor to trmm hou et al 2014 liu 2016 tang et al 2016 the dual frequency precipitation radar dpr the first of its kind was incorporated in the gpm core observatory to improve the reliability of imerg compared to other spps anjum et al 2019 yuan et al 2018 evaluated tmpa 3b42v7 the latest version 7 post real time research grade product of tmpa and imerg version 5 precipitation products over yellow river source region yrsr a mountainous alpine region in northwestern china this study showed that generally imerg improves the daily precipitation estimates relative to tmpa 3b42v7 by 15 the same assessment over guangdong province in china conducted by wang et al 2018 indicated 20 improvement of imerg to tmpa 3b42v7 in terms of daily rainfall detection further tang et al 2020 compared imerg version 6 with other satellite products including cmorph tmpa 3b42v7 persiann climate data record cdr and climate hazards group infrared precipitation with stations chirps over china in their study the imerg product outperformed other datasets in both statistical and hydrological evaluation nevertheless evaluation of imerg estimates over several regions around the globe has reported different levels of uncertainty associated with this product that may limit its direct use in practical applications sungmin et al 2017 tang et al 2017 wang et al 2018 asong et al 2017 tan et al 2019 thus the accuracy of imerg precipitation products need to be assessed against in situ observations similar to spps radar precipitation data provide real time estimates of rain and snow rates at relatively fine spatial and temporal scales however indirect measurements based on radar reflectivity can cause errors ochoa rodriguez et al 2019 radar precipitation estimates can be influenced by ground clutter e g dust bugs birds and particulates and other non meteorological echoes cone of silence beam blockage and bright banding in the melting layer occurring due to the higher reflectivity associated with melting snow as it is falling aloft martinaitis et al 2017 multi radar integration can mitigate such deficiencies and provide more accurate diagnoses of atmospheric processes compared to the single radar framework zhang et al 2016 for this purpose the national centers for environmental prediction ncep implemented the multi radar multi sensor mrms system which integrates multiple overlapping radars with in situ and remote sensing satellite observations and numerical weather prediction nwp model outputs mrms currently uses 176 operational radars across the conterminous united states conus 146 s band dual polarization weather surveillance radar 1988 doppler wsr 88d radars and southern canada 30c band single polarization weather radars at very high spatial 1 km and temporal 2 min resolution zhang et al 2016 mrms provides four types of quantitative precipitation estimation qpe products 1 radar based qpe radar only with vertical profile of reflectivity vpr correction 2 gauge based qpe gauge only 3 local gauge and vpr bias corrected qpe and 4 gauge and precipitation climatology merged qpe mountain mapper qpe designed for the mountainous areas in the western us and canada but is generated for the entire mrms domain zhang et al 2016 mrms mitigates the radar beam overshoot primarily via the use of multiple radar inputs for a given grid point cocks et al 2017 previous studies have shown that mrms provides reliable precipitation estimates over conus which has led researchers to use them as reference data for evaluating other qpes including imerg and trmm gebregiorgis et al 2018 although mrms covers southern parts of canada south of 55 n to date the detailed performance of this product has not been reported over this domain this study aims to perform the first comprehensive analysis of mrms and the latest version of imerg v06 precipitation products at relatively high temporal resolution hourly and daily across canada the performance of both rses in representing different characteristics of precipitation is evaluated using a set of 15 metrics the remainder of the paper is as follows section 2 describes the rse and ground based datasets section 3 describes the methodology and metrics used for evaluating rse products results and discussions are presented in sections 4 and 5 respectively followed by the concluding remarks in section 6 2 data to evaluate the retrieval products for different climate regimes the study area fig 1 is divided into seven zones from the east to the west coast based on provincial and territorial boundaries zone 7 includes three northern provinces 2 1 ground based observations the amount of total precipitation is assessed at daily and hourly time scales the hourly ground based precipitation records are available from automatic station network operated by environment and climate change canada eccc the network consists of 585 fully automated stations including both surface weather and reference climate stations rcs parameters that are typically observed at these locations are air temperature humidity precipitation accumulation precipitation intensity snow depth air pressure and wind speed and direction three types of instruments are used for automatic measurement of total precipitation amount in canada namely weighing gauges tipping bucket rain gauges tbrgs and optical sensors mekis et al 2018 precipitation amounts are stored in mm with a resolution of 0 1 mm the quarter hour total precipitation amounts are derived over 15 minute intervals 00 15 15 30 30 45 45 60 by taking the difference of the gauge weight between the end and start of each period technical documentation digital archive of canadian climatological data eccc the total hourly precipitation is estimated as the sum of the 15 minute precipitation amounts for minutes 00 through 60 inclusive eccc operates several quality control checks to correct the existing errors in the rcs hourly weather stations after 2014 however prior to this year quality checks were not implemented at the ingest stage technical documentation digital archive of canadian climatological data eccc 2018 in this study 530 hourly station records with less than 10 missing data in each month over the five year period starting from 2014 to the end of 2018 are selected for daily evaluations of imerg 325 quality controlled daily station records provided by eccc with less than 10 missing data in each month are collected as shown in fig 1 rain gauges are not evenly distributed across canada and the density is higher in southern parts of the country the reliability of automatic precipitation instruments for solid precipitation measurement can be undermined due to the blockage of the orifice by snow capping the gauge or accumulating on the side of the orifice walls wind undercatch of snow due to the formation of updrafts over the gauge orifice the unknown role of turbulence on gauge catch and the large variability in gauge catch efficiency for a given gauge and wind speed rasmussen et al 2012 however it is possible to measure the snowfall amount using either single or triple configuration campbell scientific sr50a ultrasonic snow depth sensors at the automatic stations that send ultrasonic pulses and listens for an echo durocher 2011 fischer 2011 because of the highly variable nature of snow depth and the unreliability of measurements at a single point direct snowfall observations over canada are no longer derived from a single sr50a sensor since december 2013 although triple configuration sr50a stations can derive reliable snowfall measurements they need a verified triple configuration algorithm which has not been provided to the eccc by 2018 merkis et al 2018 it should be noted that eccc still uses weighing and tipping bucket gauges for total precipitation measurements including snowfall despite the aforementioned limitations weighing gauges provide a good estimate of precipitation accumulation for all seasons however these traditional automated gauges cannot distinguish between solid or liquid states of precipitation merkis et al 2018 2 2 imerg satellite data in this study the recently released june 2019 version v06b of imerg mission final run with high spatial 0 1 and temporal 30 min resolution is analyzed for 2014 to 2018 the imerg algorithm is intended to inter calibrate merge and interpolate all satellite microwave precipitation estimates together with microwave calibrated infrared satellite estimates and monthly precipitation gauge records huffman et al 2019a the imerg v06 data are available globally from 90 s to 90 n latitude with three early 4 h after observation time late 14 h after observation time and final 3 5 months after the observation time runs to accommodate different user requirements for latency and accuracy tan et al 2019 the post real time final run uses the global precipitation climatology center gpcc monthly precipitation gauge analysis and the european centre for medium range weather forecasts ecmwf ancillary data for calibration therefore this product is expected to provide the most reliable estimates that are suited for research works huffman et al 2019a in order to create the final half hourly calibrated imerg precipitation estimates the ratio between the monthly accumulation of half hourly multi satellite only fields and the monthly satellite gauge field satellite calibrated with monthly gauges is computed next each half hourly field of multi satellite only precipitation estimates in the month is multiplied by the ratio field huffman et al 2019a among 585 eccc automatic stations 71 gauges participate in gpcc mekis et al 2018 therefore 90 of gauges considered in this study have not been used for imerg calibration and are independent of the evaluated datasets in addition the applied ratio does not remove biases at sub monthly scales i e hourly and daily the four different precipitation fields of imerg data are categorized as calibrated precipitation precipitationcal which represents records after the final post processing step described above uncalibrated precipitation precipitationuncal which is recorded data before the final post processing step precipitationcal and precipitationuncal fields are identical for the early and late runs as there are no additional corrections applied infrared ir geostationary satellite precipitation data irprecipitation and precipitation extracted from merging high quality passive microwave pmw sensors hqprecipitation which only includes microwave data and has significant gaps precipitationcal is considered as the most reliable imerg precipitation estimate huffman et al 2019b imerg v06 has some major improvements over previous versions first to drive the morphing scheme it uses total precipitable water vapor from reanalysis data however previous versions of imerg adopt geostationary infrared geo ir data to calculate the motion vectors of precipitation systems which leads to the mismatch between ir based cloud top motions and surface precipitation motions second passive microwave estimates are morphed at high latitudes to reduce spatial gaps huffman et al 2019b tang et al 2020 third the latest version of the goddard profiling algorithm gprof2017 ingested in imerg v06 retrieves total hydrometeor mass in the atmospheric column except for the conical scan imager pmw retrievals which only considers total solid hydrometeor mass over land and coast and then implicitly correlates it to surface precipitation in any phase including rain drizzle snow and hail huffman et al 2019b further imerg v06 includes a new data field called probability of liquid precipitation which provides different phases of the precipitation i e liquid solid or mixed in this study the total precipitation amounts derived from imerg v06 retrieval products are evaluated analysis of different phases of precipitation will be considered in future studies 2 3 radar precipitation products the radar based precipitation data utilized in this study are derived from a product of mrms named surface precipitation rate spr spr uses a quality controlled reflectivity product called the seamless hybrid scan reflectivity shsr mosaic and surface precipitation type spt field to compute instantaneous rain rates in mm h 1 zhang et al 2016 shsr is first derived from single radar polar grids and then mosaicked onto the mrms national cartesian grid grams et al 2014 the mrms domain extends from 20 n to 55 n latitude and from 130 w to 60 w longitude with a horizontal resolution of 0 01 0 01 fig 1 in zhang et al 2016 mrms ingests 3d volume scan data from 146 s band dual polarization wsr 88d in the us and 30c band single polarization weather radars operated by eccc in canada the gauge quality controlled data of mrms is integrated with atmospheric environmental data such as surface and wet bulb temperatures wind and relative humidity extracted from nwp model lightning and rain gauge observations to generate a suite of severe weather and qpe products zhang et al 2016 in this study the total precipitation amount extracted from mrms spr product as radar only qpe not bias corrected by local gauges is used to avoid errors associated with the limitations of rain gauge measurements and interpolation method applied in the local gauge bias corrected product the misrepresentation of ground based winter precipitation can influence local bias corrected values martinaitis et al 2015 the spr data is available from november 1st 2014 till present at 2 min temporal resolution the evaluations are performed for the time period of 2015 until the end of 2018 there are several factors that can increase the uncertainties in radar precipitation estimations particularly during cold season radar variables are indirect measurements of precipitation rates r therefore empirical relationships between radar reflectivity z and r are developed to derive radar qpe different empirical relationships are required for different precipitation phases and regimes an automated surface precipitation classification is employed in mrms such that appropriate relationships may be applied some major uncertainties of radar qpe products are associated with improper calibration and limited operational z r and z s liquid equivalent snowfall rate relationships due to differing snowfall properties also highly variable falling speeds of snow can introduce spatial and temporal uncertainties in winter precipitation estimation this can cause significant elapsed time between radar detection aloft and ground measurement martinaitis et al 2015 in addition the vpr correction applied in the shsr field for mitigating radar errors does not work when the surface temperature is below 0 c and hence is not useful in snow detection further the correction usually works better on flat land than on complex terrain where orographic forcing modulates precipitation distributions zhang et al 2016 similar to imerg the ability of mrms in detecting the total amount of precipitation across the canadian domain are analyzed in this study 3 methodology this section describes the evaluation procedure of multiple imerg v06b satellite precipitation products and mrms at different temporal scales across canada the imerg data are compared against rain gauge records at two temporal scales 1 hourly that analyses precipitation estimates from four products including precipitationcal hereafter prcal precipitationuncal pruncal hqprecipitation prhq and irprecipitation prir obtained from different ir and pmw sensors and 2 daily that is performed for the widely used prcal dataset for both hourly and daily analyses the half hourly imerg data are aggregated and matched with the local hourly daily gauge records the utc based coordinated universal time satellite data is processed to be consistent with local records considering the seven different time zones corresponding to different rain gauges across canada as well as daylight saving times for almost half of the year in many parts of the country evaluation of the mrms product with a 2 min 1 km temporal and spatial resolution is performed at hourly timescale using gauges that cover up to 55 n latitude all analyses are performed by evaluating the gridded rses at locations where there are rain gauges available a direct comparison between gauge points and their corresponding satellite radar pixels is conducted at each given time separately therefore no transformation and interpolation from the points to areal precipitation data are made in order to prevent the uncertainty associated with the spatial estimates of precipitation especially for the areas with fewer gauges to have a more reliable assessment of the imerg and mrms precipitation estimates the corresponding biases are characterized for different seasons winter djf spring mam summer jja and fall son several continuous and categorical evaluation metrics are used to assess the ability of rse to detect rainfall occurrence and amount 3 1 continuous verification metrics continuous indices are used to measure the accuracy of the estimated precipitation magnitudes from imerg and mrms data the widely used metrics including root mean square error rmse mean absolute error mae relative bias rbias and pearson correlation coefficient cc are applied in addition four statistical indices namely hit bias hbias miss bias mbias false bias fbias and correct negative bias cnbias are considered to quantify the error characteristics of rse associated with detectability performance the equations and a brief description of these metrics are listed in table 1 rbias describes the systematic biases of rses mae is used to represent the overall errors of the qpes without considering their directions rmse is used to measure the average error magnitude which gives greater weights to the larger errors relative to mae and cc characterizes the degrees of consistencies in temporal variabilities hbias mbias fbias and cnbias display the systematic biases of rses associated with hit miss false and non events respectively hit events refer to hourly daily records where both rse and ground based precipitation values are 0 1 mm h 1 miss events correspond to gauge records 0 1 mm h 1 while rses are less than 0 1 mm h 1 contrary to the miss events false events are associated with higher than 0 1 mm h 1 of rain detected by satellite radar while no precipitation has been recorded by rain gauges finally non events represent the conditions when both satellite radar and gauge records show precipitation values less than 0 1 mm h 1 the range of r h m f and cn bias is between and with the optimal value of 0 mae and rmse vary between 0 and and cc ranges from 1 to 1 larger errors are associated with larger rbias mae rmse hbias mbias fbias and cnbias values 3 2 categorical verification metrics to measure the ability of rse data to detect rain no rain events based on a threshold of 0 1 mm h 1 seven categorical metrics listed in table 2 are utilized which include hit h miss m false f and correct negative cn fractions as well as probability of detection pod false alarm ratio far and critical success index csi the optimal performance corresponds to m and f fraction values of 0 values of the h and cn fractions depend on the number of rain no rain events however their optimal sum is 100 pod far and csi range between 0 and 1 with the optimal values of 1 0 and 1 respectively pod is sensitive to hits but ignores false alarms while far is sensitive to false alarms and ignores misses pod and far are both very sensitive to the climatological frequency of the event and should be used in conjunction csi is sensitive to hits and penalizes both misses and false alarms it also depends on climatological frequency of events poor scores for rare events since some hits can occur purely due to random chance 4 results the evaluation results of gpm imerg v06 and mrms spr products based on eccc s rain gauge records are presented first the performance of imerg prcal is assessed at a daily timescale followed by the assessment of all four imerg products and mrms estimates at an hourly timescale the hourly evaluations suggested that imerg prcal outperforms the other imerg products therefore to avoid redundant analyses the daily evaluation of imerg estimates was only conducted for prcal product 4 1 evaluation of gpm imerg v06 at daily timescale fig 2 shows the rmse a measure of bias and cc representing consistencies in temporal variations values corresponding to the imerg prcal product at daily timescale for each season across canada results are shown for the 10 km pixels that include ground based observations for the five year period of 2014 to 2018 overall the biases based on rmse are lower in the prairie provinces including manitoba saskatchewan alberta zones 3 5 and eastern parts of british columbia zone 6 although the temporal variations of the imerg estimated precipitation are more consistent with gauge data records over the east coast the corresponding magnitudes are less accurate compared to other regions rmse and cc values vary across seasons during fall and summer the accuracy of imerg is relatively high in several sites while winter shows weaker performance with lower correlations between imerg and ground observations which was expected as discussed in the data section the overall five year and seasonal performance of daily imerg precipitation estimates are evaluated based on rbias mae rmse and cc in fig 3 box and whisker plots show the first q1 and third q3 quartiles i e interquartile range maximum q3 1 5 iqr minimum q1 1 5 iqr values whiskers and the medians of the metrics between all sites across canada positive values of rbias indicate the tendency of imerg to overestimate precipitation which is more considerable in winter rbias varies between 10 and 50 compared to the other seasons 5 25 as expected mae and rmse which emphasizes on biases in extremes values are consistent across seasons with larger variations in winter the mae ranges between 1 4 and 3 1 mm d 1 interquartile range and rmse ranges from 3 5 to 6 5 mm d 1 across all sites the best agreement between imerg estimates and the observed data according to the cc index is in the fall and summer with average values ranging between 0 5 and 0 7 the performance of imerg in detecting the occurrence of precipitation is evaluated using pod far and csi fig 4 overall the results are promising given that the median values of pod and csi are mostly above 0 75 and 0 5 respectively indicating that the precipitation occurrence is often captured by satellite records far values 0 3 0 5 varying between locations and seasons imply that the rse product incorrectly shows the occurrence of precipitation in about 35 median of non events imerg performance is best in the summer with pod 0 78 0 88 and far 0 35 0 45 and worst in the winter with pod 0 5 0 75 and far 0 22 0 6 further analysis of imerg biases using metrics that quantify the misrepresentation of the amounts of precipitation fig 5 is performed the imerg product has the highest hit miss and false biases in winter compared to the other seasons indicating its worst performance during the cold season while it shows better performance in warmer periods i e summer positive values of the hit bias indicate that imerg overestimates the observed precipitation amount by 10 on average which is in agreement with the results from other metrics such as rbias mae and rmse 30 of all days averaged across all sites within the five year period experienced 0 1 mm d 1 of precipitation which is correctly detected by the imerg v06 prcal product fig 6 in addition imerg represents 40 of no precipitation days and hence it detects 70 of all events accurately the product however does not capture 11 of the total events 0 1 mm h 1 while it provides false detection in 20 of the total number of events fig 7 evaluates the performance of imerg in representing the true precipitation at different quantiles for this purpose the satellite and ground based precipitation quantiles 1 to 99 are found using the five year daily data record at each site for different seasons and the average values of each quantile across all sites represented by red dots in fig 7 are taken results show that overall imerg tends to overestimate light to moderate precipitations lower quantiles particularly during summer 4 2 evaluation of imerg v06 and mrms at hourly timescale investigating intense rainfall events over short durations is critical for flood risk analysis particularly over urban areas precipitation estimates from four imerg satellite products as well as the mrms radar data at hourly timescale using eccc s ground based observations are evaluated this is the first analysis of the imerg latest product and mrms data over canada at a relatively high temporal resolution as mentioned before mrms collects the base level data from all radars in a network and processes them at a centralized location to produce high 1 km spatial and 2 min temporal resolution quantitative precipitation estimates qpes this allows for easy integration of multi sensor data and provides enhanced qpe products zhang et al 2016 both imerg and mrms products are aggregated to hourly timescale to perform the evaluations the spatial distributions of rmse and cc corresponding to four different imerg products over the five year period of 2014 2018 are shown in fig 8 overall prcal and pruncal have more accurate estimates with lower rmse and higher cc values compared to those of prir and prhq all products show better performance in the prairie provinces saskatchewan and alberta and regions on the west british columbia with rmse values ranging between 0 25 and 0 75 mm h 1 for prcal pruncal and prir imerg data can represent the temporal variability of the ground based observations relatively well as suggested by cc values 0 4 and above particularly in eastern and western coasts and parts of central canada similar assessments are conducted for the mrms precipitation rates across the coverage area for radar network which includes regions that lie within 42 55 latitude fig 9 represents the spatially distributed rmse and cc values corresponding to the mrms precipitation product for the entire period and different seasons during 2015 2018 according to both metrics mrms shows a satisfactory performance particularly over the regions in the east including southwest ontario and prairies with rmse values ranging from 0 2 to 0 5 and cc values from 0 6 to 0 9 in all seasons in fall and spring mrms data are more consistent with gauge records in most parts of the country however during winter the performance is relatively weak with rmse values consistent with those of the other seasons but low correlations contrary to the mrms performance in winter the assessments show relatively high cc values and high rmses during summer this is partly because of false estimates of the radar in no rain conditions resulting in high rmse while it can detect rain events well resulting in relatively high cc values further a regional evaluation of the four imerg products as well as the mrms precipitation estimates at hourly timescale for the seven zones defined in fig 1 is performed the results based on rbias mae and cc for zone 1 are shown in fig 10 the similar results for zone 2 to 7 are provided in the supplementary material fig s1 mrms shows the best performance in almost all zones and over the four seasons although with relatively large uncertainties except for zone 1 where mrms underestimates the precipitation amount with rbias ranging between 35 and 0 it shows overestimated values in all other zones mrms qpes are most reliable in fall spring and summer in all zones for example in zone 1 best estimates are found in spring with median rbias 10 mae 0 12 mm h 1 and cc 0 7 and in zone 2 fall shows the best estimates with rbias mae and cc of 5 0 1 mm h 1 and 0 73 respectively winter shows the weakest correlations further mrms data have relatively strong linear association with the gauge data cc 0 6 0 8 in zone 1 whereas the values of cc vary between 0 5 and 0 75 in other zones except for winter in zones 4 and 5 in which they range between 0 3 and 0 5 prcal outperforms the other imerg products in most cases with pruncal following closely in terms of mae and cc however pruncal shows larger overestimations compared to prcal rbias values corresponding to prcal range between 10 and 25 in zones 2 5 however in zone 1 and zone 6 prhq shows better performance in terms of rbias 0 15 and 5 to 35 respectively in addition prcal has more accurate estimates for different seasons across all zones except for fall and spring in zone 1 and winter and summer in zone 2 in which prhq shows better results based on mae prcal has lower bias and outperforms the other products across all zones and during different seasons in zones 1 to 5 the variations of maes are minor as represented by relatively short boxplots indicating less variability in the estimates across sites in western areas close to the pacific zone 6 however boxplots are wider indicating more variability in biases between sites mrms outperforms all imerg products to a large degree based on the cc metric the capability of the imerg and mrms products to detect the occurrence of precipitation is further assessed for each zone across the study area for the four seasons fig 11 shows boxplots of the three categorical statistics i e pod far and csi corresponding to all products at hourly timescale over zone 1 the similar results for zone 2 to 7 are provided in the supplementary material fig s2 overall mrms outperforms other products particularly over eastern and western coasts and during warm periods with csi values around 0 5 prhq follows mrms closely as both products are microwave based and can observe hydrometeor profiles relatively accurately huffman et al 2019b prhq shows the best performance in detecting precipitation events among other imerg products with the highest values of pod 0 65 0 75 and csi 0 45 0 55 corresponding to zones 1 and 6 and zones 2 to 5 respectively it also has the lowest values of far among the other products across all zones and all seasons the hbias mbias fbias and cnbias performance metrics corresponding to the imerg and mrms precipitation products are presented in fig 12 the hit bias where both satellite and observed data show precipitation values above 0 1 mm h 1 ranges between 10 and 10 for the prcal product it shows underestimations during summer and overestimations during other months analyses show relatively large false and miss biases for all products and during all seasons the false and miss biases for prcal are 50 40 during all seasons of the study period which reaches up to 170 80 during winter overall among the imerg products prhq shows the lowest false and miss biases except for winter and prcal has the best performance based on the hit bias additionally these bias metrics are relatively lower in the fall compared to the other seasons mrms shows lower miss and hit biases compared to the imerg products fig 13 represents the percentage of hit miss false and correct negative events for both imerg and mrms all products show almost similar performance particularly prcal and pruncal except for prhq which has a relatively large false fraction value indicating that it tends to overestimate precipitation around 90 86 7 correct negative and 3 2 hit fractions of all events are accurately detected by prcal with only 10 error 5 5 false and 4 6 miss fractions mrms shows lower miss fractions compared to the ones corresponding to the imerg products and has a larger hit fraction than prcal pruncal and prir the relatively larger false fraction value 7 1 suggests that mrms tends to overestimate precipitation further the spatially averaged hourly precipitation estimates from imerg and mrms are compared with those of the ground based records across canada the corresponding density color scatterplots over the five year period 2014 2018 for the imerg products and four year period 2015 2018 for mrms are shown in fig 14 prcal and pruncal outperform the other imerg products but show slight overestimations while prhq has the worst performance and significantly overestimates precipitation the q q plots of the hourly quantiles averaged over the study sites across the country fig 15 indicate that imerg products except for prhq which shows significant overestimations at almost all quantiles tend to slightly overestimate intense precipitation events i e values corresponding to higher quantiles and underestimate light precipitation lower quantiles which is in agreement with the findings of sunilkumar et al 2019 mrms follows the straight line in high quantiles while it overestimates low and middle quantiles 5 discussion in this study a comprehensive analysis of imerg and mrms products is performed at hourly and daily time scales over canada overall the evaluation results show promising performance of these remotely sensed data in representing local precipitation at high spatial and temporal resolution the prcal product which provides a combination of both pmw and ir estimates represent the best regional performance among available imerg products across canada with an average rbias value of 20 mae value of 0 15 mm h 1 and correlation of 0 45 over 2014 2018 in contrast the two products of prir and prhq are relatively less reliable as the former shows low correlation coefficients over the country and the latter indicates high values of rmse the findings of this research regarding imerg performance agree with the other studies in terms of overall overestimations better detection capability over plains and less uncertainty during warm months tan et al 2019 provided the first analysis of imerg v06 and showed its improved performance in depicting the diurnal cycle of precipitation around the world compared to the previous version imerg v05 their evaluations against the u s ground based observations showed extensive agreements in capturing summertime diurnal peak of precipitation in the central united states by imerg evaluating the imerg hourly precipitation product against hourly ground based observations showed slight overestimations over mainland china in a study conducted by tang et al 2017 also comparisons between imerg v03 v04 and v05 final run products over the globe at 0 1 0 1 spatial and daily temporal resolution conducted by wang et al 2018 indicated that all imerg versions tend to overestimate precipitation by about 12 as depicted in fig 8 rmse values are lower over central canada versus the coastal regions which are characterized by heavy precipitation this can be attributed to the precipitation estimations from imerg being influenced by topographic conditions sea and land locations xu et al 2019 further our analyses showed that while in several instances prhq slightly outperforms prcal in maintaining the correlation between qpes and gauge data fig 10 and fig s1 the prir product which estimates precipitation from empirical cloud top temperature and rainfall relationships performs worst this is because the infrared wave based sensor does not capture microwave brightness temperatures of hydrometeor profiles and hence cannot detect the precipitation droplets accurately in addition the correlation values significantly drop in winter because of changes in the precipitation regime i e snowfall over zones 1 to 5 the pacific region zone 6 shows fewer changes in the correlation values between seasons with larger variations in winter the performance of the imerg products in representing the occurrence of precipitation is higher over the east and west coasts based on csi values nonetheless the uncertainties are relatively high in zone 6 indicating larger variations across this area because of its diverse topographic and climatic conditions satellite sensors have difficulties in detecting low level orographic rainfall events that often occur at elevations higher than 3000 m elevations chen et al 2019 such as parts of the rocky mountains in western canada zone 6 the pmw based data prhq that are derived based on sensors with higher frequency range display more stable performance at high elevations as expected chen et al 2019 further sungmin and kirstetter 2018 showed that imerg tends to underestimate diurnal variations of precipitation over the mountainous regions in western and eastern us the performance of all products is mostly consistent during fall spring and summer with weaker performance in winter one source of uncertainty in winter precipitation estimation is the lack of reliable ground based precipitation observations during cold seasons as mentioned in the data section precipitation gauges across most parts of canada show poor performance in solid precipitation measurement in addition previous studies have shown problems associated with satellite snowfall estimates because of pmw sensors used in satellite products chen et al 2019 argued that the pwm retrieval which is in contact with the precipitation particles has problems in distinguishing between precipitation and frozen surface further the ir input that utilizes the morphing technique is directly inferred from cloud top temperature and is less affected by the impact of seasonal variation on retrieval results huffman et al 2019a huffman et al 2019b stated that all merged pmw estimates have low accuracies in regions with frozen or icy surfaces thus prhq has relatively low high uncertainties in summer winter while ir input looks more stable and smoother across time by tracing the errors of imerg sources tan et al 2016 concluded that the most reliable imerg estimates come from passive microwave satellites while infrared estimations perform poorly currently imerg classifies rainfall and snowfall using wet bulb temperature with a uniform temperature threshold over the globe it is necessary to acquire a spatially distributed map of temperature thresholds for more precise rainfall and snowfall separation tang et al 2020 the mrms data performs relatively well across southern canada but with uncertainties associated with false and miss estimates this is partly because precipitation features are detected aloft and evaporating before reaching the surface furthermore while the mrms domain covers southern canada to 55 n latitude the 30 canadian radars ingested by mrms do not cover the entire domain this could potentially influence some of the statistics used in these analyses in addition the results of mrms in this study indicate its low performance during winter which is in agreement with the findings of cocks et al 2016 the performance of mrms radar only qpe were assessed over the united states and a distinct negatively biased qpe during the cold season were found also during the cold season radar beam overshoot was more common because of shallower precipitation systems and lower cloud bases weaker performance in winter snowfall mrms and imerg estimates has been also indicated by sadeghi et al 2019 over truckee river basin in the western united states it is also noted that the differences in spatial resolution between point based gauges and areal imerg mrms estimates can contribute to the uncertainties in performance assessments jiang et al 2018 zhang et al 2019 which can be investigated in future studies 6 summary and conclusion this study evaluates the most recent satellite and radar i e imerg v06 and mrms precipitation estimates using ground based observations across canada a suite of performance metrics is used to assess various characteristics of the rse products seasonally at daily and hourly timescales over 2014 2018 for imerg and 2015 2018 for mrms the hourly evaluations suggest that prcal outperforms other imerg products in estimating the precipitation amount although prhq the microwave based product shows large biases in the intensity it detects the occurrence of precipitation more accurately the robustness of such sensors to detect precipitation suggests that they can be used to improve prcal estimates as expected imerg performs better at daily timescale compared to the hourly based on all metrics for example the median rbias and csi of daily prcal are 13 and 52 respectively which reduce to 18 and 25 at hourly scale overall imerg better represents the ground based precipitation amounts over most parts of the interior plains compared to the rest of the country with lower rbias and rmse values nonetheless higher pod and lower far values indicate that precipitation occurrence is best captured over the west and east coasts based on the seasonal assessments imerg provides more reliable precipitation estimates during warm months especially in summer according to correlation coefficients and categorical indices this is in agreement with the findings of asong et al 2017 in addition although imerg is capable of representing the temporal and spatial variations of precipitation over most parts of canada it tends to overestimate the moderate to heavy precipitation events and shows relatively weak performance during the cold season assessments of mrms as the first study of such high resolution radar based precipitation estimates across canada show the overall satisfactory performance of this product throughout its coverage area in the southern parts of the country in addition to maintaining the spatial variations of precipitation in accordance with ground observations mrms exhibits a higher average cc value 0 6 than prcal from imerg 0 4 and better csi values over all regions mrms however tends to underestimate precipitation in the eastern and western parts of canada and overestimates it in the interior plains similar to prhq mrms can detect precipitation occurrence relatively well as they are both microwave based products further mrms has better coverage over the southern parts of canada with higher spatial and temporal resolution than prhq which has several gaps the first comprehensive analysis of the most recent qpe products across the entire ground network stations of canada suggests that both imerg and mrms have considerable capabilities in representing precipitation estimates particularly in the interior and over the east and west coasts respectively however there are systematic and random biases and uncertainties associated with both products that should be adjusted before driving hydrological models or performing risk analyses among others a combination of both products can result in more accurate estimations especially for short duration events and in areas that have sparse rain gauges declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this project was funded by an nserc engage grant through a collaboration with the institute for catastrophic loss reduction iclr the imerg dataset was downloaded from the precipitation measurement mission pmm websites https pmm nasa gov data access downloads gpm and ftp arthurhou pps eosdis nasa gov gpmdata mrms data was downloaded from the national sever storms laboratory nssl website https www nssl noaa gov projects mrms redirect and iowa state university iowa environmental mesonet archived data https mtarchive geol iastate edu the station dataset was downloaded from eccc websites the authors would like to thank kh yau bridget thomas and chantale cerny from eccc for their supports in accessing the hourly ground precipitation dataset and providing information about their quality we also thank antonina struminski bodden undergraduate student at western university for her initial contributions in data processing appendix a list of acronyms cc pearson correlation coefficient chirps climate hazards group infrared precipitation with stations cmorph climate prediction center cpc morphing technique cnbias correct negative bias conus conterminous united states csi critical success index dpr dual frequency precipitation radar djf december january february eccc environment and climate change canada ecmwf european centre for medium range weather forecasts far false alarm ratio fbias false bias geo ir geostationary infrared gpcc global precipitation climatology center gpm global precipitation measurement gprof goddard profiling algorithm gsmap global satellite mapping of precipitation hbias hit bias hqprecipitation precipitation extracted from merging high quality passive microwave sensors imerg v06 integrated multi satellite retrievals for global precipitation measurement version 6 ir infrared irprecipitation infrared geostationary satellite precipitation data jja june july august jaxa japan aerospace and exploration agency nasa national aeronautics and space administration ncep national centers for environmental prediction noaa national oceanic and atmospheric administration nwp numerical weather prediction mae mean absolute error mam march april may mbias miss bias mrms multi radar multi sensor mw microwave persiann precipitation estimation from remotely sensed information using artificial neural networks pmw passive microwave pod probability of detection precipitationcal calibrated precipitation of imerg precipitationuncal uncalibrated precipitation of imerg prcal precipitationcal prhq hqprecipitation prir irprecipitation pruncal precipitationuncal qpe quantitative precipitation estimation rbias relative bias rcs reference climate stations rmse root mean square error rse remotely sensed estimate shsr seamless hybrid scan reflectivity son september october november spp satellite precipitation product spr surface precipitation rate spt surface precipitation type tbrg tipping bucket rain gauge tmpa trmm multi satellite precipitation analysis trmm tropical rainfall measuring mission utc coordinated universal time vpr vertical profile of reflectivity wsr 88d weather surveillance radar 1988 doppler appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125929 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
4835,this study investigates the performance of multiple high resolution remotely sensed precipitation estimates at hourly and daily time scales over canada for 2014 2018 four products of the recently released integrated multi satellite retrievals for global precipitation measurement imerg v06 and the multi radar multi sensor mrms precipitation rate data are analyzed for different seasons evaluations are based on a suite of metrics to assess different characteristics of precipitation estimates using quality controlled hourly gauge data considered as the truth the results suggest that calibrated precipitation precipitationcal outperforms the other imerg products particularly over the prairies and during fall and summer over the western and eastern coastal regions imerg tends to overestimate precipitation intensities by 25 the discrepancy between satellite and ground based data is higher for more intense precipitation events further analyses indicate that while mrms tends to overestimate the amount of precipitation it outperforms the imerg products based on several metrics especially in detecting the occurrence of precipitation over the eastern coastal regions overall the study of imerg v06 and mrms precipitation estimates at a relatively high temporal resolution indicates that both products have the potential to complement ground based observations over canada keywords imerg v06 mrms qpe evaluation canada precipitation remotely sensed data 1 introduction precipitation is the key input variable to hydrological models and plays an important role in water resources planning including flood and drought analysis monitoring and forecasting abbasian et al 2021 zhang and najafi 2020 however its accurate estimation is challenging particularly in areas with sparse observations and regions with complex terrains although direct precipitation measurements using rain gauges are considered as the most accurate observations petersen et al 2005 there are limitations associated with the at point representation of an entire domain and inability to capture precipitation variability at high resolution villarini et al 2008 therefore there is considerable interest to use indirect remotely sensed estimate rse data such as radar and satellite products as they provide fine scale representations of the amount frequency and distribution of precipitation wen et al 2017 sungmin et al 2017 sun et al 2018 in this study the rse products are evaluated over canada which has a diverse hydroclimate due to its extensive geographical features latitudinal extent and topographic variations polar and arctic climate is dominant in the northern parts and regions on the west experience temperate climate with heavy precipitation associated with air currents from the pacific the presence of the great lakes can moderate the weather in southern parts of ontario and quebec with hot humid summers and cold snowy winters asong et al 2017 singh et al 2019 flooding is the most common natural disaster in canada and among the costliest according to public safety canada many historical flood events in major river systems and populated areas across canada are associated with heavy rain and subsequent excessive runoff lemmen et al 2016 jalili pirani and najafi 2020 therefore reliable precipitation data with high spatial and temporal resolution are essential for flood risk mitigation and water resources management particularly in mountainous regions with limited accessibility nonetheless canada like many other countries suffers from a lack of dense network of gauges especially in remote areas such as the arctic and high elevation zones mekis et al 2018 the existing point coverage of gauge measurements may not represent the highly variable spatial distribution of precipitation properly martinaitis et al 2015 the rse products can address these limitations by providing high resolution spatial and temporal coverage of precipitation that can be used to detect storm events assess flooding and develop mitigation measures najafi et al 2021 some of the widely used satellite precipitation products spps include precipitation estimation from remotely sensed information using artificial neural networks persiann sorooshian et al 2000 aghakouchak et al 2012 hossain and huffman 2008 the national oceanic and atmospheric administration noaa s climate prediction center cpc morphing technique cmorph joyce et al 2004 stampoulis and anagnostou 2012 gumindoga et al 2019 the tropical rainfall measuring mission trmm multi satellite precipitation analysis tmpa huffman et al 2007 villarini and krajewski 2007 tian et al 2007 habib et al 2009 yong et al 2015 mei et al 2016 moazami et al 2014 2016 and the global satellite mapping of precipitation gsmap kubota et al 2007 2009 these satellite products have some limitations associated with the spatial and temporal resolution of precipitation due to the number of infrared ir and microwave mw based sensors utilized to provide more accurate precipitation estimates at fine spatiotemporal scales the national aeronautics and space administration nasa and the japan aerospace and exploration agency jaxa launched the global precipitation measurement gpm mission in february 2014 called the integrated multi satellite retrievals for gpm imerg with a temporal resolution of 30 min and spatial resolution of 0 1 as a successor to trmm hou et al 2014 liu 2016 tang et al 2016 the dual frequency precipitation radar dpr the first of its kind was incorporated in the gpm core observatory to improve the reliability of imerg compared to other spps anjum et al 2019 yuan et al 2018 evaluated tmpa 3b42v7 the latest version 7 post real time research grade product of tmpa and imerg version 5 precipitation products over yellow river source region yrsr a mountainous alpine region in northwestern china this study showed that generally imerg improves the daily precipitation estimates relative to tmpa 3b42v7 by 15 the same assessment over guangdong province in china conducted by wang et al 2018 indicated 20 improvement of imerg to tmpa 3b42v7 in terms of daily rainfall detection further tang et al 2020 compared imerg version 6 with other satellite products including cmorph tmpa 3b42v7 persiann climate data record cdr and climate hazards group infrared precipitation with stations chirps over china in their study the imerg product outperformed other datasets in both statistical and hydrological evaluation nevertheless evaluation of imerg estimates over several regions around the globe has reported different levels of uncertainty associated with this product that may limit its direct use in practical applications sungmin et al 2017 tang et al 2017 wang et al 2018 asong et al 2017 tan et al 2019 thus the accuracy of imerg precipitation products need to be assessed against in situ observations similar to spps radar precipitation data provide real time estimates of rain and snow rates at relatively fine spatial and temporal scales however indirect measurements based on radar reflectivity can cause errors ochoa rodriguez et al 2019 radar precipitation estimates can be influenced by ground clutter e g dust bugs birds and particulates and other non meteorological echoes cone of silence beam blockage and bright banding in the melting layer occurring due to the higher reflectivity associated with melting snow as it is falling aloft martinaitis et al 2017 multi radar integration can mitigate such deficiencies and provide more accurate diagnoses of atmospheric processes compared to the single radar framework zhang et al 2016 for this purpose the national centers for environmental prediction ncep implemented the multi radar multi sensor mrms system which integrates multiple overlapping radars with in situ and remote sensing satellite observations and numerical weather prediction nwp model outputs mrms currently uses 176 operational radars across the conterminous united states conus 146 s band dual polarization weather surveillance radar 1988 doppler wsr 88d radars and southern canada 30c band single polarization weather radars at very high spatial 1 km and temporal 2 min resolution zhang et al 2016 mrms provides four types of quantitative precipitation estimation qpe products 1 radar based qpe radar only with vertical profile of reflectivity vpr correction 2 gauge based qpe gauge only 3 local gauge and vpr bias corrected qpe and 4 gauge and precipitation climatology merged qpe mountain mapper qpe designed for the mountainous areas in the western us and canada but is generated for the entire mrms domain zhang et al 2016 mrms mitigates the radar beam overshoot primarily via the use of multiple radar inputs for a given grid point cocks et al 2017 previous studies have shown that mrms provides reliable precipitation estimates over conus which has led researchers to use them as reference data for evaluating other qpes including imerg and trmm gebregiorgis et al 2018 although mrms covers southern parts of canada south of 55 n to date the detailed performance of this product has not been reported over this domain this study aims to perform the first comprehensive analysis of mrms and the latest version of imerg v06 precipitation products at relatively high temporal resolution hourly and daily across canada the performance of both rses in representing different characteristics of precipitation is evaluated using a set of 15 metrics the remainder of the paper is as follows section 2 describes the rse and ground based datasets section 3 describes the methodology and metrics used for evaluating rse products results and discussions are presented in sections 4 and 5 respectively followed by the concluding remarks in section 6 2 data to evaluate the retrieval products for different climate regimes the study area fig 1 is divided into seven zones from the east to the west coast based on provincial and territorial boundaries zone 7 includes three northern provinces 2 1 ground based observations the amount of total precipitation is assessed at daily and hourly time scales the hourly ground based precipitation records are available from automatic station network operated by environment and climate change canada eccc the network consists of 585 fully automated stations including both surface weather and reference climate stations rcs parameters that are typically observed at these locations are air temperature humidity precipitation accumulation precipitation intensity snow depth air pressure and wind speed and direction three types of instruments are used for automatic measurement of total precipitation amount in canada namely weighing gauges tipping bucket rain gauges tbrgs and optical sensors mekis et al 2018 precipitation amounts are stored in mm with a resolution of 0 1 mm the quarter hour total precipitation amounts are derived over 15 minute intervals 00 15 15 30 30 45 45 60 by taking the difference of the gauge weight between the end and start of each period technical documentation digital archive of canadian climatological data eccc the total hourly precipitation is estimated as the sum of the 15 minute precipitation amounts for minutes 00 through 60 inclusive eccc operates several quality control checks to correct the existing errors in the rcs hourly weather stations after 2014 however prior to this year quality checks were not implemented at the ingest stage technical documentation digital archive of canadian climatological data eccc 2018 in this study 530 hourly station records with less than 10 missing data in each month over the five year period starting from 2014 to the end of 2018 are selected for daily evaluations of imerg 325 quality controlled daily station records provided by eccc with less than 10 missing data in each month are collected as shown in fig 1 rain gauges are not evenly distributed across canada and the density is higher in southern parts of the country the reliability of automatic precipitation instruments for solid precipitation measurement can be undermined due to the blockage of the orifice by snow capping the gauge or accumulating on the side of the orifice walls wind undercatch of snow due to the formation of updrafts over the gauge orifice the unknown role of turbulence on gauge catch and the large variability in gauge catch efficiency for a given gauge and wind speed rasmussen et al 2012 however it is possible to measure the snowfall amount using either single or triple configuration campbell scientific sr50a ultrasonic snow depth sensors at the automatic stations that send ultrasonic pulses and listens for an echo durocher 2011 fischer 2011 because of the highly variable nature of snow depth and the unreliability of measurements at a single point direct snowfall observations over canada are no longer derived from a single sr50a sensor since december 2013 although triple configuration sr50a stations can derive reliable snowfall measurements they need a verified triple configuration algorithm which has not been provided to the eccc by 2018 merkis et al 2018 it should be noted that eccc still uses weighing and tipping bucket gauges for total precipitation measurements including snowfall despite the aforementioned limitations weighing gauges provide a good estimate of precipitation accumulation for all seasons however these traditional automated gauges cannot distinguish between solid or liquid states of precipitation merkis et al 2018 2 2 imerg satellite data in this study the recently released june 2019 version v06b of imerg mission final run with high spatial 0 1 and temporal 30 min resolution is analyzed for 2014 to 2018 the imerg algorithm is intended to inter calibrate merge and interpolate all satellite microwave precipitation estimates together with microwave calibrated infrared satellite estimates and monthly precipitation gauge records huffman et al 2019a the imerg v06 data are available globally from 90 s to 90 n latitude with three early 4 h after observation time late 14 h after observation time and final 3 5 months after the observation time runs to accommodate different user requirements for latency and accuracy tan et al 2019 the post real time final run uses the global precipitation climatology center gpcc monthly precipitation gauge analysis and the european centre for medium range weather forecasts ecmwf ancillary data for calibration therefore this product is expected to provide the most reliable estimates that are suited for research works huffman et al 2019a in order to create the final half hourly calibrated imerg precipitation estimates the ratio between the monthly accumulation of half hourly multi satellite only fields and the monthly satellite gauge field satellite calibrated with monthly gauges is computed next each half hourly field of multi satellite only precipitation estimates in the month is multiplied by the ratio field huffman et al 2019a among 585 eccc automatic stations 71 gauges participate in gpcc mekis et al 2018 therefore 90 of gauges considered in this study have not been used for imerg calibration and are independent of the evaluated datasets in addition the applied ratio does not remove biases at sub monthly scales i e hourly and daily the four different precipitation fields of imerg data are categorized as calibrated precipitation precipitationcal which represents records after the final post processing step described above uncalibrated precipitation precipitationuncal which is recorded data before the final post processing step precipitationcal and precipitationuncal fields are identical for the early and late runs as there are no additional corrections applied infrared ir geostationary satellite precipitation data irprecipitation and precipitation extracted from merging high quality passive microwave pmw sensors hqprecipitation which only includes microwave data and has significant gaps precipitationcal is considered as the most reliable imerg precipitation estimate huffman et al 2019b imerg v06 has some major improvements over previous versions first to drive the morphing scheme it uses total precipitable water vapor from reanalysis data however previous versions of imerg adopt geostationary infrared geo ir data to calculate the motion vectors of precipitation systems which leads to the mismatch between ir based cloud top motions and surface precipitation motions second passive microwave estimates are morphed at high latitudes to reduce spatial gaps huffman et al 2019b tang et al 2020 third the latest version of the goddard profiling algorithm gprof2017 ingested in imerg v06 retrieves total hydrometeor mass in the atmospheric column except for the conical scan imager pmw retrievals which only considers total solid hydrometeor mass over land and coast and then implicitly correlates it to surface precipitation in any phase including rain drizzle snow and hail huffman et al 2019b further imerg v06 includes a new data field called probability of liquid precipitation which provides different phases of the precipitation i e liquid solid or mixed in this study the total precipitation amounts derived from imerg v06 retrieval products are evaluated analysis of different phases of precipitation will be considered in future studies 2 3 radar precipitation products the radar based precipitation data utilized in this study are derived from a product of mrms named surface precipitation rate spr spr uses a quality controlled reflectivity product called the seamless hybrid scan reflectivity shsr mosaic and surface precipitation type spt field to compute instantaneous rain rates in mm h 1 zhang et al 2016 shsr is first derived from single radar polar grids and then mosaicked onto the mrms national cartesian grid grams et al 2014 the mrms domain extends from 20 n to 55 n latitude and from 130 w to 60 w longitude with a horizontal resolution of 0 01 0 01 fig 1 in zhang et al 2016 mrms ingests 3d volume scan data from 146 s band dual polarization wsr 88d in the us and 30c band single polarization weather radars operated by eccc in canada the gauge quality controlled data of mrms is integrated with atmospheric environmental data such as surface and wet bulb temperatures wind and relative humidity extracted from nwp model lightning and rain gauge observations to generate a suite of severe weather and qpe products zhang et al 2016 in this study the total precipitation amount extracted from mrms spr product as radar only qpe not bias corrected by local gauges is used to avoid errors associated with the limitations of rain gauge measurements and interpolation method applied in the local gauge bias corrected product the misrepresentation of ground based winter precipitation can influence local bias corrected values martinaitis et al 2015 the spr data is available from november 1st 2014 till present at 2 min temporal resolution the evaluations are performed for the time period of 2015 until the end of 2018 there are several factors that can increase the uncertainties in radar precipitation estimations particularly during cold season radar variables are indirect measurements of precipitation rates r therefore empirical relationships between radar reflectivity z and r are developed to derive radar qpe different empirical relationships are required for different precipitation phases and regimes an automated surface precipitation classification is employed in mrms such that appropriate relationships may be applied some major uncertainties of radar qpe products are associated with improper calibration and limited operational z r and z s liquid equivalent snowfall rate relationships due to differing snowfall properties also highly variable falling speeds of snow can introduce spatial and temporal uncertainties in winter precipitation estimation this can cause significant elapsed time between radar detection aloft and ground measurement martinaitis et al 2015 in addition the vpr correction applied in the shsr field for mitigating radar errors does not work when the surface temperature is below 0 c and hence is not useful in snow detection further the correction usually works better on flat land than on complex terrain where orographic forcing modulates precipitation distributions zhang et al 2016 similar to imerg the ability of mrms in detecting the total amount of precipitation across the canadian domain are analyzed in this study 3 methodology this section describes the evaluation procedure of multiple imerg v06b satellite precipitation products and mrms at different temporal scales across canada the imerg data are compared against rain gauge records at two temporal scales 1 hourly that analyses precipitation estimates from four products including precipitationcal hereafter prcal precipitationuncal pruncal hqprecipitation prhq and irprecipitation prir obtained from different ir and pmw sensors and 2 daily that is performed for the widely used prcal dataset for both hourly and daily analyses the half hourly imerg data are aggregated and matched with the local hourly daily gauge records the utc based coordinated universal time satellite data is processed to be consistent with local records considering the seven different time zones corresponding to different rain gauges across canada as well as daylight saving times for almost half of the year in many parts of the country evaluation of the mrms product with a 2 min 1 km temporal and spatial resolution is performed at hourly timescale using gauges that cover up to 55 n latitude all analyses are performed by evaluating the gridded rses at locations where there are rain gauges available a direct comparison between gauge points and their corresponding satellite radar pixels is conducted at each given time separately therefore no transformation and interpolation from the points to areal precipitation data are made in order to prevent the uncertainty associated with the spatial estimates of precipitation especially for the areas with fewer gauges to have a more reliable assessment of the imerg and mrms precipitation estimates the corresponding biases are characterized for different seasons winter djf spring mam summer jja and fall son several continuous and categorical evaluation metrics are used to assess the ability of rse to detect rainfall occurrence and amount 3 1 continuous verification metrics continuous indices are used to measure the accuracy of the estimated precipitation magnitudes from imerg and mrms data the widely used metrics including root mean square error rmse mean absolute error mae relative bias rbias and pearson correlation coefficient cc are applied in addition four statistical indices namely hit bias hbias miss bias mbias false bias fbias and correct negative bias cnbias are considered to quantify the error characteristics of rse associated with detectability performance the equations and a brief description of these metrics are listed in table 1 rbias describes the systematic biases of rses mae is used to represent the overall errors of the qpes without considering their directions rmse is used to measure the average error magnitude which gives greater weights to the larger errors relative to mae and cc characterizes the degrees of consistencies in temporal variabilities hbias mbias fbias and cnbias display the systematic biases of rses associated with hit miss false and non events respectively hit events refer to hourly daily records where both rse and ground based precipitation values are 0 1 mm h 1 miss events correspond to gauge records 0 1 mm h 1 while rses are less than 0 1 mm h 1 contrary to the miss events false events are associated with higher than 0 1 mm h 1 of rain detected by satellite radar while no precipitation has been recorded by rain gauges finally non events represent the conditions when both satellite radar and gauge records show precipitation values less than 0 1 mm h 1 the range of r h m f and cn bias is between and with the optimal value of 0 mae and rmse vary between 0 and and cc ranges from 1 to 1 larger errors are associated with larger rbias mae rmse hbias mbias fbias and cnbias values 3 2 categorical verification metrics to measure the ability of rse data to detect rain no rain events based on a threshold of 0 1 mm h 1 seven categorical metrics listed in table 2 are utilized which include hit h miss m false f and correct negative cn fractions as well as probability of detection pod false alarm ratio far and critical success index csi the optimal performance corresponds to m and f fraction values of 0 values of the h and cn fractions depend on the number of rain no rain events however their optimal sum is 100 pod far and csi range between 0 and 1 with the optimal values of 1 0 and 1 respectively pod is sensitive to hits but ignores false alarms while far is sensitive to false alarms and ignores misses pod and far are both very sensitive to the climatological frequency of the event and should be used in conjunction csi is sensitive to hits and penalizes both misses and false alarms it also depends on climatological frequency of events poor scores for rare events since some hits can occur purely due to random chance 4 results the evaluation results of gpm imerg v06 and mrms spr products based on eccc s rain gauge records are presented first the performance of imerg prcal is assessed at a daily timescale followed by the assessment of all four imerg products and mrms estimates at an hourly timescale the hourly evaluations suggested that imerg prcal outperforms the other imerg products therefore to avoid redundant analyses the daily evaluation of imerg estimates was only conducted for prcal product 4 1 evaluation of gpm imerg v06 at daily timescale fig 2 shows the rmse a measure of bias and cc representing consistencies in temporal variations values corresponding to the imerg prcal product at daily timescale for each season across canada results are shown for the 10 km pixels that include ground based observations for the five year period of 2014 to 2018 overall the biases based on rmse are lower in the prairie provinces including manitoba saskatchewan alberta zones 3 5 and eastern parts of british columbia zone 6 although the temporal variations of the imerg estimated precipitation are more consistent with gauge data records over the east coast the corresponding magnitudes are less accurate compared to other regions rmse and cc values vary across seasons during fall and summer the accuracy of imerg is relatively high in several sites while winter shows weaker performance with lower correlations between imerg and ground observations which was expected as discussed in the data section the overall five year and seasonal performance of daily imerg precipitation estimates are evaluated based on rbias mae rmse and cc in fig 3 box and whisker plots show the first q1 and third q3 quartiles i e interquartile range maximum q3 1 5 iqr minimum q1 1 5 iqr values whiskers and the medians of the metrics between all sites across canada positive values of rbias indicate the tendency of imerg to overestimate precipitation which is more considerable in winter rbias varies between 10 and 50 compared to the other seasons 5 25 as expected mae and rmse which emphasizes on biases in extremes values are consistent across seasons with larger variations in winter the mae ranges between 1 4 and 3 1 mm d 1 interquartile range and rmse ranges from 3 5 to 6 5 mm d 1 across all sites the best agreement between imerg estimates and the observed data according to the cc index is in the fall and summer with average values ranging between 0 5 and 0 7 the performance of imerg in detecting the occurrence of precipitation is evaluated using pod far and csi fig 4 overall the results are promising given that the median values of pod and csi are mostly above 0 75 and 0 5 respectively indicating that the precipitation occurrence is often captured by satellite records far values 0 3 0 5 varying between locations and seasons imply that the rse product incorrectly shows the occurrence of precipitation in about 35 median of non events imerg performance is best in the summer with pod 0 78 0 88 and far 0 35 0 45 and worst in the winter with pod 0 5 0 75 and far 0 22 0 6 further analysis of imerg biases using metrics that quantify the misrepresentation of the amounts of precipitation fig 5 is performed the imerg product has the highest hit miss and false biases in winter compared to the other seasons indicating its worst performance during the cold season while it shows better performance in warmer periods i e summer positive values of the hit bias indicate that imerg overestimates the observed precipitation amount by 10 on average which is in agreement with the results from other metrics such as rbias mae and rmse 30 of all days averaged across all sites within the five year period experienced 0 1 mm d 1 of precipitation which is correctly detected by the imerg v06 prcal product fig 6 in addition imerg represents 40 of no precipitation days and hence it detects 70 of all events accurately the product however does not capture 11 of the total events 0 1 mm h 1 while it provides false detection in 20 of the total number of events fig 7 evaluates the performance of imerg in representing the true precipitation at different quantiles for this purpose the satellite and ground based precipitation quantiles 1 to 99 are found using the five year daily data record at each site for different seasons and the average values of each quantile across all sites represented by red dots in fig 7 are taken results show that overall imerg tends to overestimate light to moderate precipitations lower quantiles particularly during summer 4 2 evaluation of imerg v06 and mrms at hourly timescale investigating intense rainfall events over short durations is critical for flood risk analysis particularly over urban areas precipitation estimates from four imerg satellite products as well as the mrms radar data at hourly timescale using eccc s ground based observations are evaluated this is the first analysis of the imerg latest product and mrms data over canada at a relatively high temporal resolution as mentioned before mrms collects the base level data from all radars in a network and processes them at a centralized location to produce high 1 km spatial and 2 min temporal resolution quantitative precipitation estimates qpes this allows for easy integration of multi sensor data and provides enhanced qpe products zhang et al 2016 both imerg and mrms products are aggregated to hourly timescale to perform the evaluations the spatial distributions of rmse and cc corresponding to four different imerg products over the five year period of 2014 2018 are shown in fig 8 overall prcal and pruncal have more accurate estimates with lower rmse and higher cc values compared to those of prir and prhq all products show better performance in the prairie provinces saskatchewan and alberta and regions on the west british columbia with rmse values ranging between 0 25 and 0 75 mm h 1 for prcal pruncal and prir imerg data can represent the temporal variability of the ground based observations relatively well as suggested by cc values 0 4 and above particularly in eastern and western coasts and parts of central canada similar assessments are conducted for the mrms precipitation rates across the coverage area for radar network which includes regions that lie within 42 55 latitude fig 9 represents the spatially distributed rmse and cc values corresponding to the mrms precipitation product for the entire period and different seasons during 2015 2018 according to both metrics mrms shows a satisfactory performance particularly over the regions in the east including southwest ontario and prairies with rmse values ranging from 0 2 to 0 5 and cc values from 0 6 to 0 9 in all seasons in fall and spring mrms data are more consistent with gauge records in most parts of the country however during winter the performance is relatively weak with rmse values consistent with those of the other seasons but low correlations contrary to the mrms performance in winter the assessments show relatively high cc values and high rmses during summer this is partly because of false estimates of the radar in no rain conditions resulting in high rmse while it can detect rain events well resulting in relatively high cc values further a regional evaluation of the four imerg products as well as the mrms precipitation estimates at hourly timescale for the seven zones defined in fig 1 is performed the results based on rbias mae and cc for zone 1 are shown in fig 10 the similar results for zone 2 to 7 are provided in the supplementary material fig s1 mrms shows the best performance in almost all zones and over the four seasons although with relatively large uncertainties except for zone 1 where mrms underestimates the precipitation amount with rbias ranging between 35 and 0 it shows overestimated values in all other zones mrms qpes are most reliable in fall spring and summer in all zones for example in zone 1 best estimates are found in spring with median rbias 10 mae 0 12 mm h 1 and cc 0 7 and in zone 2 fall shows the best estimates with rbias mae and cc of 5 0 1 mm h 1 and 0 73 respectively winter shows the weakest correlations further mrms data have relatively strong linear association with the gauge data cc 0 6 0 8 in zone 1 whereas the values of cc vary between 0 5 and 0 75 in other zones except for winter in zones 4 and 5 in which they range between 0 3 and 0 5 prcal outperforms the other imerg products in most cases with pruncal following closely in terms of mae and cc however pruncal shows larger overestimations compared to prcal rbias values corresponding to prcal range between 10 and 25 in zones 2 5 however in zone 1 and zone 6 prhq shows better performance in terms of rbias 0 15 and 5 to 35 respectively in addition prcal has more accurate estimates for different seasons across all zones except for fall and spring in zone 1 and winter and summer in zone 2 in which prhq shows better results based on mae prcal has lower bias and outperforms the other products across all zones and during different seasons in zones 1 to 5 the variations of maes are minor as represented by relatively short boxplots indicating less variability in the estimates across sites in western areas close to the pacific zone 6 however boxplots are wider indicating more variability in biases between sites mrms outperforms all imerg products to a large degree based on the cc metric the capability of the imerg and mrms products to detect the occurrence of precipitation is further assessed for each zone across the study area for the four seasons fig 11 shows boxplots of the three categorical statistics i e pod far and csi corresponding to all products at hourly timescale over zone 1 the similar results for zone 2 to 7 are provided in the supplementary material fig s2 overall mrms outperforms other products particularly over eastern and western coasts and during warm periods with csi values around 0 5 prhq follows mrms closely as both products are microwave based and can observe hydrometeor profiles relatively accurately huffman et al 2019b prhq shows the best performance in detecting precipitation events among other imerg products with the highest values of pod 0 65 0 75 and csi 0 45 0 55 corresponding to zones 1 and 6 and zones 2 to 5 respectively it also has the lowest values of far among the other products across all zones and all seasons the hbias mbias fbias and cnbias performance metrics corresponding to the imerg and mrms precipitation products are presented in fig 12 the hit bias where both satellite and observed data show precipitation values above 0 1 mm h 1 ranges between 10 and 10 for the prcal product it shows underestimations during summer and overestimations during other months analyses show relatively large false and miss biases for all products and during all seasons the false and miss biases for prcal are 50 40 during all seasons of the study period which reaches up to 170 80 during winter overall among the imerg products prhq shows the lowest false and miss biases except for winter and prcal has the best performance based on the hit bias additionally these bias metrics are relatively lower in the fall compared to the other seasons mrms shows lower miss and hit biases compared to the imerg products fig 13 represents the percentage of hit miss false and correct negative events for both imerg and mrms all products show almost similar performance particularly prcal and pruncal except for prhq which has a relatively large false fraction value indicating that it tends to overestimate precipitation around 90 86 7 correct negative and 3 2 hit fractions of all events are accurately detected by prcal with only 10 error 5 5 false and 4 6 miss fractions mrms shows lower miss fractions compared to the ones corresponding to the imerg products and has a larger hit fraction than prcal pruncal and prir the relatively larger false fraction value 7 1 suggests that mrms tends to overestimate precipitation further the spatially averaged hourly precipitation estimates from imerg and mrms are compared with those of the ground based records across canada the corresponding density color scatterplots over the five year period 2014 2018 for the imerg products and four year period 2015 2018 for mrms are shown in fig 14 prcal and pruncal outperform the other imerg products but show slight overestimations while prhq has the worst performance and significantly overestimates precipitation the q q plots of the hourly quantiles averaged over the study sites across the country fig 15 indicate that imerg products except for prhq which shows significant overestimations at almost all quantiles tend to slightly overestimate intense precipitation events i e values corresponding to higher quantiles and underestimate light precipitation lower quantiles which is in agreement with the findings of sunilkumar et al 2019 mrms follows the straight line in high quantiles while it overestimates low and middle quantiles 5 discussion in this study a comprehensive analysis of imerg and mrms products is performed at hourly and daily time scales over canada overall the evaluation results show promising performance of these remotely sensed data in representing local precipitation at high spatial and temporal resolution the prcal product which provides a combination of both pmw and ir estimates represent the best regional performance among available imerg products across canada with an average rbias value of 20 mae value of 0 15 mm h 1 and correlation of 0 45 over 2014 2018 in contrast the two products of prir and prhq are relatively less reliable as the former shows low correlation coefficients over the country and the latter indicates high values of rmse the findings of this research regarding imerg performance agree with the other studies in terms of overall overestimations better detection capability over plains and less uncertainty during warm months tan et al 2019 provided the first analysis of imerg v06 and showed its improved performance in depicting the diurnal cycle of precipitation around the world compared to the previous version imerg v05 their evaluations against the u s ground based observations showed extensive agreements in capturing summertime diurnal peak of precipitation in the central united states by imerg evaluating the imerg hourly precipitation product against hourly ground based observations showed slight overestimations over mainland china in a study conducted by tang et al 2017 also comparisons between imerg v03 v04 and v05 final run products over the globe at 0 1 0 1 spatial and daily temporal resolution conducted by wang et al 2018 indicated that all imerg versions tend to overestimate precipitation by about 12 as depicted in fig 8 rmse values are lower over central canada versus the coastal regions which are characterized by heavy precipitation this can be attributed to the precipitation estimations from imerg being influenced by topographic conditions sea and land locations xu et al 2019 further our analyses showed that while in several instances prhq slightly outperforms prcal in maintaining the correlation between qpes and gauge data fig 10 and fig s1 the prir product which estimates precipitation from empirical cloud top temperature and rainfall relationships performs worst this is because the infrared wave based sensor does not capture microwave brightness temperatures of hydrometeor profiles and hence cannot detect the precipitation droplets accurately in addition the correlation values significantly drop in winter because of changes in the precipitation regime i e snowfall over zones 1 to 5 the pacific region zone 6 shows fewer changes in the correlation values between seasons with larger variations in winter the performance of the imerg products in representing the occurrence of precipitation is higher over the east and west coasts based on csi values nonetheless the uncertainties are relatively high in zone 6 indicating larger variations across this area because of its diverse topographic and climatic conditions satellite sensors have difficulties in detecting low level orographic rainfall events that often occur at elevations higher than 3000 m elevations chen et al 2019 such as parts of the rocky mountains in western canada zone 6 the pmw based data prhq that are derived based on sensors with higher frequency range display more stable performance at high elevations as expected chen et al 2019 further sungmin and kirstetter 2018 showed that imerg tends to underestimate diurnal variations of precipitation over the mountainous regions in western and eastern us the performance of all products is mostly consistent during fall spring and summer with weaker performance in winter one source of uncertainty in winter precipitation estimation is the lack of reliable ground based precipitation observations during cold seasons as mentioned in the data section precipitation gauges across most parts of canada show poor performance in solid precipitation measurement in addition previous studies have shown problems associated with satellite snowfall estimates because of pmw sensors used in satellite products chen et al 2019 argued that the pwm retrieval which is in contact with the precipitation particles has problems in distinguishing between precipitation and frozen surface further the ir input that utilizes the morphing technique is directly inferred from cloud top temperature and is less affected by the impact of seasonal variation on retrieval results huffman et al 2019a huffman et al 2019b stated that all merged pmw estimates have low accuracies in regions with frozen or icy surfaces thus prhq has relatively low high uncertainties in summer winter while ir input looks more stable and smoother across time by tracing the errors of imerg sources tan et al 2016 concluded that the most reliable imerg estimates come from passive microwave satellites while infrared estimations perform poorly currently imerg classifies rainfall and snowfall using wet bulb temperature with a uniform temperature threshold over the globe it is necessary to acquire a spatially distributed map of temperature thresholds for more precise rainfall and snowfall separation tang et al 2020 the mrms data performs relatively well across southern canada but with uncertainties associated with false and miss estimates this is partly because precipitation features are detected aloft and evaporating before reaching the surface furthermore while the mrms domain covers southern canada to 55 n latitude the 30 canadian radars ingested by mrms do not cover the entire domain this could potentially influence some of the statistics used in these analyses in addition the results of mrms in this study indicate its low performance during winter which is in agreement with the findings of cocks et al 2016 the performance of mrms radar only qpe were assessed over the united states and a distinct negatively biased qpe during the cold season were found also during the cold season radar beam overshoot was more common because of shallower precipitation systems and lower cloud bases weaker performance in winter snowfall mrms and imerg estimates has been also indicated by sadeghi et al 2019 over truckee river basin in the western united states it is also noted that the differences in spatial resolution between point based gauges and areal imerg mrms estimates can contribute to the uncertainties in performance assessments jiang et al 2018 zhang et al 2019 which can be investigated in future studies 6 summary and conclusion this study evaluates the most recent satellite and radar i e imerg v06 and mrms precipitation estimates using ground based observations across canada a suite of performance metrics is used to assess various characteristics of the rse products seasonally at daily and hourly timescales over 2014 2018 for imerg and 2015 2018 for mrms the hourly evaluations suggest that prcal outperforms other imerg products in estimating the precipitation amount although prhq the microwave based product shows large biases in the intensity it detects the occurrence of precipitation more accurately the robustness of such sensors to detect precipitation suggests that they can be used to improve prcal estimates as expected imerg performs better at daily timescale compared to the hourly based on all metrics for example the median rbias and csi of daily prcal are 13 and 52 respectively which reduce to 18 and 25 at hourly scale overall imerg better represents the ground based precipitation amounts over most parts of the interior plains compared to the rest of the country with lower rbias and rmse values nonetheless higher pod and lower far values indicate that precipitation occurrence is best captured over the west and east coasts based on the seasonal assessments imerg provides more reliable precipitation estimates during warm months especially in summer according to correlation coefficients and categorical indices this is in agreement with the findings of asong et al 2017 in addition although imerg is capable of representing the temporal and spatial variations of precipitation over most parts of canada it tends to overestimate the moderate to heavy precipitation events and shows relatively weak performance during the cold season assessments of mrms as the first study of such high resolution radar based precipitation estimates across canada show the overall satisfactory performance of this product throughout its coverage area in the southern parts of the country in addition to maintaining the spatial variations of precipitation in accordance with ground observations mrms exhibits a higher average cc value 0 6 than prcal from imerg 0 4 and better csi values over all regions mrms however tends to underestimate precipitation in the eastern and western parts of canada and overestimates it in the interior plains similar to prhq mrms can detect precipitation occurrence relatively well as they are both microwave based products further mrms has better coverage over the southern parts of canada with higher spatial and temporal resolution than prhq which has several gaps the first comprehensive analysis of the most recent qpe products across the entire ground network stations of canada suggests that both imerg and mrms have considerable capabilities in representing precipitation estimates particularly in the interior and over the east and west coasts respectively however there are systematic and random biases and uncertainties associated with both products that should be adjusted before driving hydrological models or performing risk analyses among others a combination of both products can result in more accurate estimations especially for short duration events and in areas that have sparse rain gauges declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this project was funded by an nserc engage grant through a collaboration with the institute for catastrophic loss reduction iclr the imerg dataset was downloaded from the precipitation measurement mission pmm websites https pmm nasa gov data access downloads gpm and ftp arthurhou pps eosdis nasa gov gpmdata mrms data was downloaded from the national sever storms laboratory nssl website https www nssl noaa gov projects mrms redirect and iowa state university iowa environmental mesonet archived data https mtarchive geol iastate edu the station dataset was downloaded from eccc websites the authors would like to thank kh yau bridget thomas and chantale cerny from eccc for their supports in accessing the hourly ground precipitation dataset and providing information about their quality we also thank antonina struminski bodden undergraduate student at western university for her initial contributions in data processing appendix a list of acronyms cc pearson correlation coefficient chirps climate hazards group infrared precipitation with stations cmorph climate prediction center cpc morphing technique cnbias correct negative bias conus conterminous united states csi critical success index dpr dual frequency precipitation radar djf december january february eccc environment and climate change canada ecmwf european centre for medium range weather forecasts far false alarm ratio fbias false bias geo ir geostationary infrared gpcc global precipitation climatology center gpm global precipitation measurement gprof goddard profiling algorithm gsmap global satellite mapping of precipitation hbias hit bias hqprecipitation precipitation extracted from merging high quality passive microwave sensors imerg v06 integrated multi satellite retrievals for global precipitation measurement version 6 ir infrared irprecipitation infrared geostationary satellite precipitation data jja june july august jaxa japan aerospace and exploration agency nasa national aeronautics and space administration ncep national centers for environmental prediction noaa national oceanic and atmospheric administration nwp numerical weather prediction mae mean absolute error mam march april may mbias miss bias mrms multi radar multi sensor mw microwave persiann precipitation estimation from remotely sensed information using artificial neural networks pmw passive microwave pod probability of detection precipitationcal calibrated precipitation of imerg precipitationuncal uncalibrated precipitation of imerg prcal precipitationcal prhq hqprecipitation prir irprecipitation pruncal precipitationuncal qpe quantitative precipitation estimation rbias relative bias rcs reference climate stations rmse root mean square error rse remotely sensed estimate shsr seamless hybrid scan reflectivity son september october november spp satellite precipitation product spr surface precipitation rate spt surface precipitation type tbrg tipping bucket rain gauge tmpa trmm multi satellite precipitation analysis trmm tropical rainfall measuring mission utc coordinated universal time vpr vertical profile of reflectivity wsr 88d weather surveillance radar 1988 doppler appendix b supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2020 125929 appendix b supplementary data the following are the supplementary data to this article supplementary data 1 
4836,nutrient criteria provide the numeric basis for lake eutrophication management however there are two obstacles that can hinder the effective application of nutrient criteria including 1 although total phosphorus tp and total nitrogen tn might co limit phytoplankton biomass in eutrophic lakes their criteria are often developed independently and 2 the linkage between nutrient criteria and the percentile based compliance assessment method of chlorophyll a chl as a measure of phytoplankton biomass has not been well established to resolve these obstacles we propose a novel analytical framework of nutrient criteria development by which joint nutrient criteria are developed using quantile regression qr we demonstrated the steps necessary to utilize this novel approach using tp tn and chl data from lake dianchi a hypereutrophic lake located in southwestern china first we built candidate qr models to quantify the nutrient chl relationship at six regression quantiles next we conducted the sequential wald test to select the best model for each regression quantile finally we visualized the joint nutrient criteria surface using a contour map the contour map effectively illustrated the joint nutrient criteria by showing the linkage of tp and tn criterion in addition based on the qr it was easy to deduce nutrient criteria which met the requirement of percentile based compliance assessment we further found that joint nutrient criteria could help the selection of an efficient load reduction strategy in the watershed the proposed method can be generalized to other systems and may facilitate site specific lake eutrophication management keywords eutrophication joint nutrient criteria quantile regression sequential wald test compliance assessment 1 introduction nutrient criteria provide the numeric foundation for lake eutrophication management heiskary and bouchard 2015 particularly for curbing excessive phytoplankton biomass soranno et al 2008 and informing watershed load reduction strategies poikane et al 2019 while other factors such as water temperature could impact the growth of phytoplankton nutrients are relatively more manageable through actions like watershed load reduction paerl et al 2011 nutrient criteria are mainly deduced from the nutrient chlorophyll a chl as a measure of phytoplankton biomass relationship by identifying critical nutrient concentrations that result in a target chl concentration freeman et al 2009 usepa 2010 bachmann et al 2012 huo et al 2013 in fact a substantial amount of work has been conducted to develop total phosphorus tp and total nitrogen tn criteria for inland lakes heiskary and wilson 2008 herlihy et al 2013 huo et al 2018 although many informative studies have been performed on the development of nutrient criteria there are two obstacles hindering effective application of nutrient criteria to lake eutrophication management the first one is that although chl might be co limited by tp and tn in eutrophic lakes filstrup and downing 2017 wurtsbaugh et al 2019 there is a lack of linkage between tp and tn criterion current criterion development of one nutrient based on the stressor response model is often independent and without consideration of the other liu et al 2018 poikane et al 2019 tong et al 2019 huo et al 2019 that is the tp criterion is deduced based on the tp chl relationship while the tn criterion is deduced using the tn chl relationship however it has been recognized that tp and tn should often be simultaneously considered as predictors in the nutrient chl relationship malve and qian 2006 liang et al 2019 therefore the effectiveness of a nutrient criterion deduced from a single nutrient chl relationship may be highly uncertain moreover there might be a significant interaction between tp and tn on chl which would be missed when developing an independent criterion kotamäki et al 2015 qian et al 2019 failure to account for such a significant interaction may result in biased parameter estimates and might lead to an improper nutrient criterion the second obstacle is that the linkage between nutrient criteria and the compliance assessment of chl has not been well established scott and haggard 2015 to curb lake eutrophication an important goal is to reduce chl to a specific target level the compliance assessment of chl is essential to evaluate the achievement of lake eutrophication management in practice the compliance assessment metric has long been an upper percentile of water quality variables mcbride and ellis 2001 borsuk et al 2002 qian et al 2015 smith and canale 2015 for example walker 1984 proposed a compliance assessment method based on the frequency of chl exceeding a specific level the u s environmental protection agency guidelines require a waterbody to be listed as impaired when more than 10 of the samples violate the standard smith et al 2001 indicating that the 90 quantile of samples is used to compare with the standard generally the assessment of an upper percentile is a more conservative way than that of the average and in the meanwhile allows for the violation of a small proportion of samples gibbons 2003 such an assessment method could provide information on the noncompliance probability of water quality variables liang et al 2017 moreover the upper percentile of chl is more related to some extreme conditions e g algal bloom than the average chl and thus can better inform lake eutrophication management ostrofsky and rigler 1987 jones et al 2011 while the compliance assessment method of chl is percentile based current nutrient chl relationships are often developed using mean regression methods e g linear regression or random forest xu et al 2015 tong et al 2019 common practices of mean regression methods often focus on the average chl concentration heiskary and wilson 2008 trebitz 2012 tong et al 2019 liang et al 2020 which would guarantee the compliance of average chl but might not meet the requirement of the percentile based compliance assessment note that the percentile of chl concentration could also be obtained using a mean regression method borsuk et al 2002 malve and qian 2006 gronewold et al 2008 however its accuracy heavily relies on meeting the homoscedasticity assumption cade and noon 2003 das et al 2019 the log transformation has been successfully used to accommodate this assumption oliver et al 2017 wagner and schliep 2018 liang et al 2019 but this may not guarantee homoscedasticity for all cases in this study we propose a novel analytical framework for nutrient criteria development in the framework we 1 propose joint nutrient criteria to reflect the linkage of tp and tn criterion for determining target chl levels and 2 employ quantile regression qr koenker and bassett 1978 to illustrate the nutrient chl relationship to bridge the gap between nutrient criteria and the percentile based chl compliance assessment method qr explores the effect of predictor s on any interested quantiles of the response das et al 2019 compared with mean regression qr is robust to outliers in the response requires no assumptions on the distribution of the response and provides a more complete view of the relationship between predictor s and response variables cade and noon 2003 das et al 2019 although qr has been used in ecological studies for about two decades cade et al 1999 it has only recently been applied to illustrate nutrient chl relationships xu et al 2015 and has rarely been used in nutrient criteria development to demonstrate steps of the proposed framework we used tp tn and chl data from a hypereutrophic lake lake dianchi china as a case study we further discuss applications of the proposed joint nutrient criteria to lake eutrophication management 2 materials and methods 2 1 study area lake dianchi 24 29 n 25 28 n 102 29 e 103 01 e is located on yunnan guizhou plateau southwest china it is a shallow lake with the mean depth of 4 4 m the lake area is approximately 309 km2 the east to west distance of the lake is 7 km and the north to south distance is 40 km the watershed is in a subtropical moist monsoon zone with an average annual precipitation of approximately 1 000 mm and an average air temperature of approximately 14 5 c lake dianchi is located in the lower part of the watershed and receives both point wastewater and non point sources of nutrients the lake is facing a severe eutrophication problem that has spanned the past two decades liang et al 2018 and therefore it is critical to develop reasonable nutrient criteria to inform eutrophication management long term january 1999 june 2019 monthly observations of tp tn and chl from eight sites were used for this analysis data are from the environmental monitoring site of yunnan province http www ynsem com cn there are few 32 missing values which were interpolated using the median polish method following qian et al 2000 the average tp tn and chl concentrations during our research period are 0 160 mg l 2 04 mg l and 0 069 mg l respectively showing the hypereutrophic state of lake dianchi 2 2 joint nutrient criteria development and modeling in this study we focus on the criteria development of tp and tn it is worth noting that some active forms of nutrients e g dissolved inorganic nitrogen and phosphate are more directly related to algal growth and the criteria development of other nutrient forms could also be important yang et al 2019 however the development of reliable site specific nutrient criteria requires a relatively long term data set the development of criteria of other nutrient forms is thereby often constrained by the lack of necessary data examination of the scatter plots between tp and tn versus chl figure s1 indicates that linear qr is appropriate for illustrating the nutrient chl relationship in lake dianchi the main function of the linear qr eq 1 is shown below 1 y i θ 0 θ x i i where i is the rank of observations i 1 2 n n is the sample size y represents the response chl and x represents the predictor s tp and or tn θ 0 and θ represent the regression intercept and slope s is the error unlike ordinary least squares which estimates parameters by minimizing the residual sum of squares altman and krzywinski 2015 the parameters estimation in linear qr is based on the minimum of weighted absolute biases eq 2 koenker and bassett 1978 2 min i i y i θ x i τ y i θ 0 θ x i i i y i θ x i 1 τ y i θ 0 θ x i where τ represents the quantile of the response effects of nutrients at several upper quantiles of chl were explored τ 0 5 0 6 0 7 0 8 0 9 0 95 while the qr is robust to outliers of the response chl observations with very high or very low values of predictors tn and tp can influence the relationship for example a small number of observations with high nutrient concentrations but low chl concentrations can easily change the shape of the regression curve because these observations only account for a small proportion of the total observations and do not span the entire distribution of chl their impact on the relationship can be substantial for the purpose of nutrient criteria development we do not have to pay much attention to these more extreme observations because model extrapolation is not required as such we selected observations with nutrient concentrations in the range of their 10 90 quantile the final sample size is 1306 observations of tp tn and chl the proposed framework for joint nutrient criteria development has three steps fig 1 the first step is to develop candidate models that represent potential nutrient chl relationships in our case we developed five candidate models that represent hypotheses of how chl responds to tp and tn the first model model 1 was developed according to the common practice of illustrating the nutrient chl relationship using mean regression malve and qian 2006 in this model main effects of tp tn and their interaction term were included this was an effects parameterized regression that included an intercept term for a mean nutrient chl regression a log log linear model is typically fitted to accommodate the normality and homoscedasticity assumptions oliver et al 2017 however qr is not constrained by the above assumptions and the log transformation is not necessary theoretically when nutrients concentrations approach zero the chl concentration should also be near zero heiskary and bouchard 2015 thus we also developed a candidate model without the intercept term model 2 some studies have also revealed that the interaction term might not be important liang et al 2018 so the third candidate model lacked an interaction term lastly we considered single nutrient limiting conditions and developed candidate models four and five for tp and tn respectively a summary of the candidate models is shown in table 1 the second step is to fit the models and perform model selection to obtain the best model for describing the nutrient chl relationship for each candidate model there were six quantiles to fit resulting in a total of 30 qr models a modified version of the barrodale and roberts algorithm for l 1 regression was used for parameters estimation koenker and d orey 1987 after parameter estimation we selected the best model for each regression quantile using a sequential wald test the wald test is a commonly used method for nested model comparison koenker and bassett 1982 and tests the null hypothesis that less complex models with fewer estimated parameters are adequate relative to the largest specified model full model using the sequential wald test we first test all five models by which model 1 is the full model if the performances of all the four simpler models candidate model 2 5 are significantly worse than the full model as indicated by sequential wald test results then the full model should be selected as the best model and the sequential test terminates otherwise model 1 is removed and model 2 becomes the full model for comparing the remaining models this process is repeated until the best model is identified moreover we applied joint wald test to examine the equality of slopes which could indicate the whether the homoscedasticity assumption is violated or not for a mean regression method after model selection the third step is to deduce the joint nutrient criteria we first select several target chl levels then we determine the joint nutrient criteria using the estimated parameters from the best nutrient chl relationship the deduced nutrient criteria were reflected by an expression between tn and tp because the joint nutrient criteria are 2 dimensional and difficult to show in a table the final step is to illustrate the joint nutrient criteria using a contour map fig 1 the contour map is an effective way to show the nutrient chl relationship when both tn and tp are used as predictors malve and qian 2006 yuan and pollard 2015 liang et al 2019 note that if the selected model has only one nutrient as the predictor the contour map is not required 2 3 single nutrient criterion development to compare the joint nutrient criteria and the single nutrient criteria we also developed single nutrient criterion following common practices of single nutrient criterion development huo et al 2013 we fitted log log linear nutrient chl relationship to deduce the single nutrient criterion 3 log y i β 0 β log x i ε i where i is the rank of observations i 1 2 n n is the sample size log y represents the log transformed chl observation and log x represents the log transformed tp or tn observation β 0 and β represent the regression intercept and slope s ε is the error note that eq 3 is similar to eq 1 but eq 3 only includes one nutrient as the predictor while eq 1 could have more predictors all the computations were conducted using the r software r version 3 6 1 r core team 2019 the algorithm for parameter estimation of qr models was implemented using the rq function in the quantreg package koenker et al 2019 the sequential and joint wald tests are based on the anova function in the quantreg package the code for the development of qr and model selection can be found at https doi org 10 5281 zenodo 3956328 3 results 3 1 model selection and parameter estimation model selection results are shown in table 2 the best models were either models 2 or 3 depending on the quantile the addition of the intercept did not significantly improve model performance supporting the common view that when nutrient concentrations are zero the chl concentration should also be zero heiskary and bouchard 2015 in addition model selection indicated that both nutrients were important predictors of chl and therefore should be included as predictors for all the regression quantiles evaluated the estimated parameters for the effects of tp and tn across the different quantiles indicate that the response of chl per unit increase in tp or tn is greater at higher regression quantiles table 2 the interaction term for tp and tn was not significant for lower quantiles τ 0 5 0 6 0 7 and was more likely to be significant at upper quantiles τ 0 8 0 9 0 95 the significant interaction terms were negative indicating that the increase of one nutrient would lower the effect of the other nutrient on chl which agrees with previous work using mean regression qian et al 2019 the magnitude of the interaction term was larger at a higher quantile indicating an increasing interactive effect with increasing regression quantile 3 2 joint nutrient criteria contour maps fig 2 illustrate the deduced nutrient criteria in the contour map x and y axes represent tp and tn respectively and isolines represent a range of target chl concentrations as regression quantiles increase isolines move toward the lower left of the plots indicating stricter nutrient criteria at higher regression quantiles isolines in fig 2 d f are curvlinear illustrating the interactive effect of tp and tn on chl we explored joint nutrient criteria for six target chl concentrations at six regression quantiles in practice however if the target chl and the regression quantile are determined joint nutrient criteria can be simply shown by a single isoline for example if the target chl is 0 08 mg l and the regression quantile is 0 9 the corresponding joint nutrient criteria is the green curve in fig 2 e 4 discussion 4 1 incorporating the linkage between tp and tn criterion the joint nutrient criteria incorporate the linkage of tp and tn criterion via the inclusion of both nutrients as predictors in the nutrient chl relationship joint nutrient criteria simultaneously reflect effects of both nutrients on chl as shown by the contour map for a certain target chl level the criterion for one nutrient may be dependent on the concentration of the other nutrient fig 2 this is the most notable feature of joint nutrient criteria compared with the development of single nutrient criterion where the nutrient criterion is invariant across concentrations of other potentially limiting nutrients moreover there might be biases between joint nutrient criteria and nutrient criteria deduced from the single nutrient chl relationship we fitted qr models with only one nutrient as the predictor model 4 and 5 in table 1 and then calculated the nutrient criteria by setting the target chl concentration to be 0 08 mg l and by setting the quantile to be 0 9 respectively in fig 3 the deviation of the point from the isoline in the same color shows the bias between the two types of nutrient criteria as we can see in a few cases the point matches with the isoline indicating that the single nutrient criterion might be consistent with the joint nutrient criteria however the bias exists for most cases fig 3 emphasizing the necessity of including both nutrients in the nutrient chl relationship besides the joint nutrient criteria provide many combinations of tp and tn criterion while the single nutrient criterion only has one combination 4 2 advantages of using quantile regression the main advantage of applying qr is to bridge the management gap between nutrient criteria and compliance assessment based on the qr we easily obtain the joint nutrient criteria given the target chl concentration and the regression quantile the regression quantile is consistent with the percentile of the compliance assessment suppose that the percentile is τ for the compliance assessment the deduced nutrient criteria aim to make the τ th quantile of chl meet the standard the qr can easily accommodate water quality compliance assessments with different percentiles therefore qr makes the nutrient criteria development in harmony with the compliance assessment which could facilitate effective lake eutrophication control practices in contrast nutrient criteria deduced by mean regression might give ambiguous information for the percentile based compliance assessment for example we fitted the log log linear nutrient chl relationship for tp and tn respectively then we calculated the corresponding criteria setting the target chl to be 0 04 mg l 0 06 mg l and 0 08 mg l we found that the combination of these nutrient criteria would locate between isolines of 0 7 0 8 quantile fig 4 a isolines of 0 6 0 7 quantile fig 4 b and around the isoline of 0 5 quantile fig 4 c respectively that is probabilities of chl exceeding corresponding targets are between 0 2 and 0 3 between 0 3 and 0 4 and about 0 5 respectively this discrepancy in noncompliance probability makes it difficult to meet the requirement of percentile based compliance assessments using the nutrient criteria deduced from mean regression although qr has advantages and intuitive appeal for developing criteria some mean regression methods such as linear regression could also be used to deduce the quantile of chl concentrations borsuk et al 2002 malve and qian 2006 gronewold et al 2008 and thereby are potentially capable of quantile based nutrient criteria in such studies the log log linear nutrient chl relationship was first built using a mean regression method and then the distribution of chl was obtained note that the accuracy of the quantile estimation relies heavily on the homoscedasticity assumption in mean regression methods which might be violated an effective tool to test the violation is to examine the regression slopes of qr models for a range of regression quantiles das et al 2019 if slopes are significantly different then the mean regression method might be inadequate and the deduced nutrient criteria might be misleading in our case we examined the qr slopes of tp tn and interactive term for nine symmetrical regression quantiles 0 1 0 2 0 9 the observations were log transformed following common practices of building nutrient chl relationship borsuk et al 2002 malve and qian 2006 gronewold et al 2008 a joint wald test koenker et al 2019 was employed to test the equality of slopes at different regression quantiles and showed the inequality of slopes p 0 05 therefore the mean regression method is not adequate to estimate percentiles of chl concentration in our case there may be occasions where using mean regression methods to predict the percentile of chl concentration is adequate however above results suggest that this should be done with caution it would be useful to examine the equality of slopes for a range of regression quantiles using qr prior to applying mean regression if the equality of slopes is confirmed then nutrient criteria could be deduced otherwise using mean regression is not suitable due to the possibility of violation of the homoscedasticity assumption in contrast the usage of qr is much more convenient intuitive and reliable 4 3 informing watershed load reduction joint nutrient criteria can also inform the selection of an efficient watershed load reduction strategy tp and tn loads are often simultaneously reduced by watershed load reduction actions e g via wetlands fisher and acreman 2004 sewage treatment plants boynton et al 2008 and best management practices qiu et al 2018 in addition tp and tn are also highly coupled in lake ecosystems oliver et al 2017 aubriot 2018 in practice through the modelling of nutrient dynamics in the watershed and waterbody using a water quality model the effect of a load reduction strategy on nutrient concentrations can be quantified dai et al 2018 and the concentration reduction curve red or blue curve in fig 5 could be obtained for example suppose the effect of a load reduction strategy on nutrient concentrations is the blue line in fig 5a and the aim of load reduction is to make the probability of chl exceeding 0 08 mg l less than 10 the green lines in fig 5 shows joint nutrient criteria when the target chl concentration is 0 08 mg l and the regression quantile is 0 9 the same as the green isoline in fig 2 e point a shows the current combination of tp and tn concentrations the intersection of the effect curve of load reduction strategy and joint nutrient criteria point b in fig 5 a shows expected nutrient concentrations when chl meets the standard based on which we can calculate the cost e g required time or money to get from point a to point b suppose now we have another load reduction strategy and its effect curve is the red line in fig 5 a we can also calculate the corresponding cost to get from point a to point c and compare the two strategies by contrast the form of current nutrient criteria might lead to extra cost of load reduction current nutrient criteria consist of one tp criterion and one tn criterion and thus could be presented as a point in fig 5 such as point d or e in fig 5 b suppose point d is the deduced nutrient criteria and the blue line is the effect curve we found that to meet the requirement of the nutrient criteria we would need to keep taking management actions until the nutrient concentrations reduce to point g so that both nutrient concentrations are not larger than that of point d but in fact chl should meet the requirement at point b extra cost is paid from point b to point g if point e is the deduced nutrient criteria extra cost is paid from point b to point f 4 4 generalization of joint nutrient criteria considering the mismatch between ecoregional and site specific nutrient chl relationships known as ecological fallacy caused by the heterogeneity of ecological contexts qian et al 2019 liang et al 2020 there is a need for the development of site specific nutrient criteria olson and hawkins 2013 liang et al 2020 we have demonstrated that the proposed joint nutrient criteria development framework could reasonably link the tp and tn criterion bridge the management gap between water quality compliance assessment method and nutrient criteria development and further inform watershed nutrient load reduction although our study focuses on a lake case study we suggest that the proposed method and application of joint nutrient criteria could benefit site specific lake ecosystem management more broadly for the following reasons 1 the application of qr and corresponding model selection process are straightforward to implement in freely available statistical software e g the r software as we used in this study 2 because chl tn and tp data are widely available the proposed method could be easily applied to other lakes 3 this approach can be applied using other forms of nutrients which are often quantified in monitoring programs additional nutrient forms could be added as predictors and additional candidate models could be built in the first step of our approach we can then determine which nutrient form s should be included via the model selection process in the second step finally only nutrient forms that would significantly improve model performance would be included in the joint nutrient criteria that said careful consideration of what types of nutrient forms to include is prudent since including too many nutrients into a joint nutrient criterion could make eutrophication management overly complicated 4 other management endpoints such as algal communities smucker et al 2013 or macroinvertebrate metrics wagenhoff et al 2017 could also be chosen as the response aiming to achieve an acceptable ecological status our method could also be extended to such cases where nonlinear qr such as additive non parametric qr koenker et al 1994 qr neural networks cannon 2011 or qr forests meinshausen 2006 might be required 5 conclusions we proposed a novel analytical framework for the development of nutrient criteria and used lake dianchi china as a case to illustrate the steps of the framework the percentile based joint nutrient criteria as shown by the contour map incorporate the dependencies between tp and tn criterion the application of qr bridges the gap between nutrient criteria and the compliance assessment we further found that joint nutrient criteria can help with the selection of a watershed nutrient load reduction strategy and believe that our approach can help inform site specific lake eutrophication management our approach can also be generalized to other lakes nutrient forms and management endpoints credit authorship contribution statement zhongyao liang conceptualization methodology software formal analysis resources writing original draft writing review editing visualization yaoyang xu methodology software writing original draft writing review editing qianlinglin qiu methodology software writing original draft writing review editing yong liu resources writing original draft writing review editing wentao lu writing original draft writing review editing tyler wagner formal analysis writing original draft writing review editing visualization supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by the national science foundation of china 51779002 national science foundation ef 1638679 ef 1638554 ef 1638539 and ef 1638550 and 111 project b20009 any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government we would like to thank the editor prof huaming guo associate editor and reviewers for their insightful and detailed comments and suggestions we appreciate helpful comments and suggestions in prereviews by ms sifeng wu nanyang technological university appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2020 125883 supplementary data the following are the supplementary data to this article supplementary data 1 
4836,nutrient criteria provide the numeric basis for lake eutrophication management however there are two obstacles that can hinder the effective application of nutrient criteria including 1 although total phosphorus tp and total nitrogen tn might co limit phytoplankton biomass in eutrophic lakes their criteria are often developed independently and 2 the linkage between nutrient criteria and the percentile based compliance assessment method of chlorophyll a chl as a measure of phytoplankton biomass has not been well established to resolve these obstacles we propose a novel analytical framework of nutrient criteria development by which joint nutrient criteria are developed using quantile regression qr we demonstrated the steps necessary to utilize this novel approach using tp tn and chl data from lake dianchi a hypereutrophic lake located in southwestern china first we built candidate qr models to quantify the nutrient chl relationship at six regression quantiles next we conducted the sequential wald test to select the best model for each regression quantile finally we visualized the joint nutrient criteria surface using a contour map the contour map effectively illustrated the joint nutrient criteria by showing the linkage of tp and tn criterion in addition based on the qr it was easy to deduce nutrient criteria which met the requirement of percentile based compliance assessment we further found that joint nutrient criteria could help the selection of an efficient load reduction strategy in the watershed the proposed method can be generalized to other systems and may facilitate site specific lake eutrophication management keywords eutrophication joint nutrient criteria quantile regression sequential wald test compliance assessment 1 introduction nutrient criteria provide the numeric foundation for lake eutrophication management heiskary and bouchard 2015 particularly for curbing excessive phytoplankton biomass soranno et al 2008 and informing watershed load reduction strategies poikane et al 2019 while other factors such as water temperature could impact the growth of phytoplankton nutrients are relatively more manageable through actions like watershed load reduction paerl et al 2011 nutrient criteria are mainly deduced from the nutrient chlorophyll a chl as a measure of phytoplankton biomass relationship by identifying critical nutrient concentrations that result in a target chl concentration freeman et al 2009 usepa 2010 bachmann et al 2012 huo et al 2013 in fact a substantial amount of work has been conducted to develop total phosphorus tp and total nitrogen tn criteria for inland lakes heiskary and wilson 2008 herlihy et al 2013 huo et al 2018 although many informative studies have been performed on the development of nutrient criteria there are two obstacles hindering effective application of nutrient criteria to lake eutrophication management the first one is that although chl might be co limited by tp and tn in eutrophic lakes filstrup and downing 2017 wurtsbaugh et al 2019 there is a lack of linkage between tp and tn criterion current criterion development of one nutrient based on the stressor response model is often independent and without consideration of the other liu et al 2018 poikane et al 2019 tong et al 2019 huo et al 2019 that is the tp criterion is deduced based on the tp chl relationship while the tn criterion is deduced using the tn chl relationship however it has been recognized that tp and tn should often be simultaneously considered as predictors in the nutrient chl relationship malve and qian 2006 liang et al 2019 therefore the effectiveness of a nutrient criterion deduced from a single nutrient chl relationship may be highly uncertain moreover there might be a significant interaction between tp and tn on chl which would be missed when developing an independent criterion kotamäki et al 2015 qian et al 2019 failure to account for such a significant interaction may result in biased parameter estimates and might lead to an improper nutrient criterion the second obstacle is that the linkage between nutrient criteria and the compliance assessment of chl has not been well established scott and haggard 2015 to curb lake eutrophication an important goal is to reduce chl to a specific target level the compliance assessment of chl is essential to evaluate the achievement of lake eutrophication management in practice the compliance assessment metric has long been an upper percentile of water quality variables mcbride and ellis 2001 borsuk et al 2002 qian et al 2015 smith and canale 2015 for example walker 1984 proposed a compliance assessment method based on the frequency of chl exceeding a specific level the u s environmental protection agency guidelines require a waterbody to be listed as impaired when more than 10 of the samples violate the standard smith et al 2001 indicating that the 90 quantile of samples is used to compare with the standard generally the assessment of an upper percentile is a more conservative way than that of the average and in the meanwhile allows for the violation of a small proportion of samples gibbons 2003 such an assessment method could provide information on the noncompliance probability of water quality variables liang et al 2017 moreover the upper percentile of chl is more related to some extreme conditions e g algal bloom than the average chl and thus can better inform lake eutrophication management ostrofsky and rigler 1987 jones et al 2011 while the compliance assessment method of chl is percentile based current nutrient chl relationships are often developed using mean regression methods e g linear regression or random forest xu et al 2015 tong et al 2019 common practices of mean regression methods often focus on the average chl concentration heiskary and wilson 2008 trebitz 2012 tong et al 2019 liang et al 2020 which would guarantee the compliance of average chl but might not meet the requirement of the percentile based compliance assessment note that the percentile of chl concentration could also be obtained using a mean regression method borsuk et al 2002 malve and qian 2006 gronewold et al 2008 however its accuracy heavily relies on meeting the homoscedasticity assumption cade and noon 2003 das et al 2019 the log transformation has been successfully used to accommodate this assumption oliver et al 2017 wagner and schliep 2018 liang et al 2019 but this may not guarantee homoscedasticity for all cases in this study we propose a novel analytical framework for nutrient criteria development in the framework we 1 propose joint nutrient criteria to reflect the linkage of tp and tn criterion for determining target chl levels and 2 employ quantile regression qr koenker and bassett 1978 to illustrate the nutrient chl relationship to bridge the gap between nutrient criteria and the percentile based chl compliance assessment method qr explores the effect of predictor s on any interested quantiles of the response das et al 2019 compared with mean regression qr is robust to outliers in the response requires no assumptions on the distribution of the response and provides a more complete view of the relationship between predictor s and response variables cade and noon 2003 das et al 2019 although qr has been used in ecological studies for about two decades cade et al 1999 it has only recently been applied to illustrate nutrient chl relationships xu et al 2015 and has rarely been used in nutrient criteria development to demonstrate steps of the proposed framework we used tp tn and chl data from a hypereutrophic lake lake dianchi china as a case study we further discuss applications of the proposed joint nutrient criteria to lake eutrophication management 2 materials and methods 2 1 study area lake dianchi 24 29 n 25 28 n 102 29 e 103 01 e is located on yunnan guizhou plateau southwest china it is a shallow lake with the mean depth of 4 4 m the lake area is approximately 309 km2 the east to west distance of the lake is 7 km and the north to south distance is 40 km the watershed is in a subtropical moist monsoon zone with an average annual precipitation of approximately 1 000 mm and an average air temperature of approximately 14 5 c lake dianchi is located in the lower part of the watershed and receives both point wastewater and non point sources of nutrients the lake is facing a severe eutrophication problem that has spanned the past two decades liang et al 2018 and therefore it is critical to develop reasonable nutrient criteria to inform eutrophication management long term january 1999 june 2019 monthly observations of tp tn and chl from eight sites were used for this analysis data are from the environmental monitoring site of yunnan province http www ynsem com cn there are few 32 missing values which were interpolated using the median polish method following qian et al 2000 the average tp tn and chl concentrations during our research period are 0 160 mg l 2 04 mg l and 0 069 mg l respectively showing the hypereutrophic state of lake dianchi 2 2 joint nutrient criteria development and modeling in this study we focus on the criteria development of tp and tn it is worth noting that some active forms of nutrients e g dissolved inorganic nitrogen and phosphate are more directly related to algal growth and the criteria development of other nutrient forms could also be important yang et al 2019 however the development of reliable site specific nutrient criteria requires a relatively long term data set the development of criteria of other nutrient forms is thereby often constrained by the lack of necessary data examination of the scatter plots between tp and tn versus chl figure s1 indicates that linear qr is appropriate for illustrating the nutrient chl relationship in lake dianchi the main function of the linear qr eq 1 is shown below 1 y i θ 0 θ x i i where i is the rank of observations i 1 2 n n is the sample size y represents the response chl and x represents the predictor s tp and or tn θ 0 and θ represent the regression intercept and slope s is the error unlike ordinary least squares which estimates parameters by minimizing the residual sum of squares altman and krzywinski 2015 the parameters estimation in linear qr is based on the minimum of weighted absolute biases eq 2 koenker and bassett 1978 2 min i i y i θ x i τ y i θ 0 θ x i i i y i θ x i 1 τ y i θ 0 θ x i where τ represents the quantile of the response effects of nutrients at several upper quantiles of chl were explored τ 0 5 0 6 0 7 0 8 0 9 0 95 while the qr is robust to outliers of the response chl observations with very high or very low values of predictors tn and tp can influence the relationship for example a small number of observations with high nutrient concentrations but low chl concentrations can easily change the shape of the regression curve because these observations only account for a small proportion of the total observations and do not span the entire distribution of chl their impact on the relationship can be substantial for the purpose of nutrient criteria development we do not have to pay much attention to these more extreme observations because model extrapolation is not required as such we selected observations with nutrient concentrations in the range of their 10 90 quantile the final sample size is 1306 observations of tp tn and chl the proposed framework for joint nutrient criteria development has three steps fig 1 the first step is to develop candidate models that represent potential nutrient chl relationships in our case we developed five candidate models that represent hypotheses of how chl responds to tp and tn the first model model 1 was developed according to the common practice of illustrating the nutrient chl relationship using mean regression malve and qian 2006 in this model main effects of tp tn and their interaction term were included this was an effects parameterized regression that included an intercept term for a mean nutrient chl regression a log log linear model is typically fitted to accommodate the normality and homoscedasticity assumptions oliver et al 2017 however qr is not constrained by the above assumptions and the log transformation is not necessary theoretically when nutrients concentrations approach zero the chl concentration should also be near zero heiskary and bouchard 2015 thus we also developed a candidate model without the intercept term model 2 some studies have also revealed that the interaction term might not be important liang et al 2018 so the third candidate model lacked an interaction term lastly we considered single nutrient limiting conditions and developed candidate models four and five for tp and tn respectively a summary of the candidate models is shown in table 1 the second step is to fit the models and perform model selection to obtain the best model for describing the nutrient chl relationship for each candidate model there were six quantiles to fit resulting in a total of 30 qr models a modified version of the barrodale and roberts algorithm for l 1 regression was used for parameters estimation koenker and d orey 1987 after parameter estimation we selected the best model for each regression quantile using a sequential wald test the wald test is a commonly used method for nested model comparison koenker and bassett 1982 and tests the null hypothesis that less complex models with fewer estimated parameters are adequate relative to the largest specified model full model using the sequential wald test we first test all five models by which model 1 is the full model if the performances of all the four simpler models candidate model 2 5 are significantly worse than the full model as indicated by sequential wald test results then the full model should be selected as the best model and the sequential test terminates otherwise model 1 is removed and model 2 becomes the full model for comparing the remaining models this process is repeated until the best model is identified moreover we applied joint wald test to examine the equality of slopes which could indicate the whether the homoscedasticity assumption is violated or not for a mean regression method after model selection the third step is to deduce the joint nutrient criteria we first select several target chl levels then we determine the joint nutrient criteria using the estimated parameters from the best nutrient chl relationship the deduced nutrient criteria were reflected by an expression between tn and tp because the joint nutrient criteria are 2 dimensional and difficult to show in a table the final step is to illustrate the joint nutrient criteria using a contour map fig 1 the contour map is an effective way to show the nutrient chl relationship when both tn and tp are used as predictors malve and qian 2006 yuan and pollard 2015 liang et al 2019 note that if the selected model has only one nutrient as the predictor the contour map is not required 2 3 single nutrient criterion development to compare the joint nutrient criteria and the single nutrient criteria we also developed single nutrient criterion following common practices of single nutrient criterion development huo et al 2013 we fitted log log linear nutrient chl relationship to deduce the single nutrient criterion 3 log y i β 0 β log x i ε i where i is the rank of observations i 1 2 n n is the sample size log y represents the log transformed chl observation and log x represents the log transformed tp or tn observation β 0 and β represent the regression intercept and slope s ε is the error note that eq 3 is similar to eq 1 but eq 3 only includes one nutrient as the predictor while eq 1 could have more predictors all the computations were conducted using the r software r version 3 6 1 r core team 2019 the algorithm for parameter estimation of qr models was implemented using the rq function in the quantreg package koenker et al 2019 the sequential and joint wald tests are based on the anova function in the quantreg package the code for the development of qr and model selection can be found at https doi org 10 5281 zenodo 3956328 3 results 3 1 model selection and parameter estimation model selection results are shown in table 2 the best models were either models 2 or 3 depending on the quantile the addition of the intercept did not significantly improve model performance supporting the common view that when nutrient concentrations are zero the chl concentration should also be zero heiskary and bouchard 2015 in addition model selection indicated that both nutrients were important predictors of chl and therefore should be included as predictors for all the regression quantiles evaluated the estimated parameters for the effects of tp and tn across the different quantiles indicate that the response of chl per unit increase in tp or tn is greater at higher regression quantiles table 2 the interaction term for tp and tn was not significant for lower quantiles τ 0 5 0 6 0 7 and was more likely to be significant at upper quantiles τ 0 8 0 9 0 95 the significant interaction terms were negative indicating that the increase of one nutrient would lower the effect of the other nutrient on chl which agrees with previous work using mean regression qian et al 2019 the magnitude of the interaction term was larger at a higher quantile indicating an increasing interactive effect with increasing regression quantile 3 2 joint nutrient criteria contour maps fig 2 illustrate the deduced nutrient criteria in the contour map x and y axes represent tp and tn respectively and isolines represent a range of target chl concentrations as regression quantiles increase isolines move toward the lower left of the plots indicating stricter nutrient criteria at higher regression quantiles isolines in fig 2 d f are curvlinear illustrating the interactive effect of tp and tn on chl we explored joint nutrient criteria for six target chl concentrations at six regression quantiles in practice however if the target chl and the regression quantile are determined joint nutrient criteria can be simply shown by a single isoline for example if the target chl is 0 08 mg l and the regression quantile is 0 9 the corresponding joint nutrient criteria is the green curve in fig 2 e 4 discussion 4 1 incorporating the linkage between tp and tn criterion the joint nutrient criteria incorporate the linkage of tp and tn criterion via the inclusion of both nutrients as predictors in the nutrient chl relationship joint nutrient criteria simultaneously reflect effects of both nutrients on chl as shown by the contour map for a certain target chl level the criterion for one nutrient may be dependent on the concentration of the other nutrient fig 2 this is the most notable feature of joint nutrient criteria compared with the development of single nutrient criterion where the nutrient criterion is invariant across concentrations of other potentially limiting nutrients moreover there might be biases between joint nutrient criteria and nutrient criteria deduced from the single nutrient chl relationship we fitted qr models with only one nutrient as the predictor model 4 and 5 in table 1 and then calculated the nutrient criteria by setting the target chl concentration to be 0 08 mg l and by setting the quantile to be 0 9 respectively in fig 3 the deviation of the point from the isoline in the same color shows the bias between the two types of nutrient criteria as we can see in a few cases the point matches with the isoline indicating that the single nutrient criterion might be consistent with the joint nutrient criteria however the bias exists for most cases fig 3 emphasizing the necessity of including both nutrients in the nutrient chl relationship besides the joint nutrient criteria provide many combinations of tp and tn criterion while the single nutrient criterion only has one combination 4 2 advantages of using quantile regression the main advantage of applying qr is to bridge the management gap between nutrient criteria and compliance assessment based on the qr we easily obtain the joint nutrient criteria given the target chl concentration and the regression quantile the regression quantile is consistent with the percentile of the compliance assessment suppose that the percentile is τ for the compliance assessment the deduced nutrient criteria aim to make the τ th quantile of chl meet the standard the qr can easily accommodate water quality compliance assessments with different percentiles therefore qr makes the nutrient criteria development in harmony with the compliance assessment which could facilitate effective lake eutrophication control practices in contrast nutrient criteria deduced by mean regression might give ambiguous information for the percentile based compliance assessment for example we fitted the log log linear nutrient chl relationship for tp and tn respectively then we calculated the corresponding criteria setting the target chl to be 0 04 mg l 0 06 mg l and 0 08 mg l we found that the combination of these nutrient criteria would locate between isolines of 0 7 0 8 quantile fig 4 a isolines of 0 6 0 7 quantile fig 4 b and around the isoline of 0 5 quantile fig 4 c respectively that is probabilities of chl exceeding corresponding targets are between 0 2 and 0 3 between 0 3 and 0 4 and about 0 5 respectively this discrepancy in noncompliance probability makes it difficult to meet the requirement of percentile based compliance assessments using the nutrient criteria deduced from mean regression although qr has advantages and intuitive appeal for developing criteria some mean regression methods such as linear regression could also be used to deduce the quantile of chl concentrations borsuk et al 2002 malve and qian 2006 gronewold et al 2008 and thereby are potentially capable of quantile based nutrient criteria in such studies the log log linear nutrient chl relationship was first built using a mean regression method and then the distribution of chl was obtained note that the accuracy of the quantile estimation relies heavily on the homoscedasticity assumption in mean regression methods which might be violated an effective tool to test the violation is to examine the regression slopes of qr models for a range of regression quantiles das et al 2019 if slopes are significantly different then the mean regression method might be inadequate and the deduced nutrient criteria might be misleading in our case we examined the qr slopes of tp tn and interactive term for nine symmetrical regression quantiles 0 1 0 2 0 9 the observations were log transformed following common practices of building nutrient chl relationship borsuk et al 2002 malve and qian 2006 gronewold et al 2008 a joint wald test koenker et al 2019 was employed to test the equality of slopes at different regression quantiles and showed the inequality of slopes p 0 05 therefore the mean regression method is not adequate to estimate percentiles of chl concentration in our case there may be occasions where using mean regression methods to predict the percentile of chl concentration is adequate however above results suggest that this should be done with caution it would be useful to examine the equality of slopes for a range of regression quantiles using qr prior to applying mean regression if the equality of slopes is confirmed then nutrient criteria could be deduced otherwise using mean regression is not suitable due to the possibility of violation of the homoscedasticity assumption in contrast the usage of qr is much more convenient intuitive and reliable 4 3 informing watershed load reduction joint nutrient criteria can also inform the selection of an efficient watershed load reduction strategy tp and tn loads are often simultaneously reduced by watershed load reduction actions e g via wetlands fisher and acreman 2004 sewage treatment plants boynton et al 2008 and best management practices qiu et al 2018 in addition tp and tn are also highly coupled in lake ecosystems oliver et al 2017 aubriot 2018 in practice through the modelling of nutrient dynamics in the watershed and waterbody using a water quality model the effect of a load reduction strategy on nutrient concentrations can be quantified dai et al 2018 and the concentration reduction curve red or blue curve in fig 5 could be obtained for example suppose the effect of a load reduction strategy on nutrient concentrations is the blue line in fig 5a and the aim of load reduction is to make the probability of chl exceeding 0 08 mg l less than 10 the green lines in fig 5 shows joint nutrient criteria when the target chl concentration is 0 08 mg l and the regression quantile is 0 9 the same as the green isoline in fig 2 e point a shows the current combination of tp and tn concentrations the intersection of the effect curve of load reduction strategy and joint nutrient criteria point b in fig 5 a shows expected nutrient concentrations when chl meets the standard based on which we can calculate the cost e g required time or money to get from point a to point b suppose now we have another load reduction strategy and its effect curve is the red line in fig 5 a we can also calculate the corresponding cost to get from point a to point c and compare the two strategies by contrast the form of current nutrient criteria might lead to extra cost of load reduction current nutrient criteria consist of one tp criterion and one tn criterion and thus could be presented as a point in fig 5 such as point d or e in fig 5 b suppose point d is the deduced nutrient criteria and the blue line is the effect curve we found that to meet the requirement of the nutrient criteria we would need to keep taking management actions until the nutrient concentrations reduce to point g so that both nutrient concentrations are not larger than that of point d but in fact chl should meet the requirement at point b extra cost is paid from point b to point g if point e is the deduced nutrient criteria extra cost is paid from point b to point f 4 4 generalization of joint nutrient criteria considering the mismatch between ecoregional and site specific nutrient chl relationships known as ecological fallacy caused by the heterogeneity of ecological contexts qian et al 2019 liang et al 2020 there is a need for the development of site specific nutrient criteria olson and hawkins 2013 liang et al 2020 we have demonstrated that the proposed joint nutrient criteria development framework could reasonably link the tp and tn criterion bridge the management gap between water quality compliance assessment method and nutrient criteria development and further inform watershed nutrient load reduction although our study focuses on a lake case study we suggest that the proposed method and application of joint nutrient criteria could benefit site specific lake ecosystem management more broadly for the following reasons 1 the application of qr and corresponding model selection process are straightforward to implement in freely available statistical software e g the r software as we used in this study 2 because chl tn and tp data are widely available the proposed method could be easily applied to other lakes 3 this approach can be applied using other forms of nutrients which are often quantified in monitoring programs additional nutrient forms could be added as predictors and additional candidate models could be built in the first step of our approach we can then determine which nutrient form s should be included via the model selection process in the second step finally only nutrient forms that would significantly improve model performance would be included in the joint nutrient criteria that said careful consideration of what types of nutrient forms to include is prudent since including too many nutrients into a joint nutrient criterion could make eutrophication management overly complicated 4 other management endpoints such as algal communities smucker et al 2013 or macroinvertebrate metrics wagenhoff et al 2017 could also be chosen as the response aiming to achieve an acceptable ecological status our method could also be extended to such cases where nonlinear qr such as additive non parametric qr koenker et al 1994 qr neural networks cannon 2011 or qr forests meinshausen 2006 might be required 5 conclusions we proposed a novel analytical framework for the development of nutrient criteria and used lake dianchi china as a case to illustrate the steps of the framework the percentile based joint nutrient criteria as shown by the contour map incorporate the dependencies between tp and tn criterion the application of qr bridges the gap between nutrient criteria and the compliance assessment we further found that joint nutrient criteria can help with the selection of a watershed nutrient load reduction strategy and believe that our approach can help inform site specific lake eutrophication management our approach can also be generalized to other lakes nutrient forms and management endpoints credit authorship contribution statement zhongyao liang conceptualization methodology software formal analysis resources writing original draft writing review editing visualization yaoyang xu methodology software writing original draft writing review editing qianlinglin qiu methodology software writing original draft writing review editing yong liu resources writing original draft writing review editing wentao lu writing original draft writing review editing tyler wagner formal analysis writing original draft writing review editing visualization supervision project administration funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research was funded by the national science foundation of china 51779002 national science foundation ef 1638679 ef 1638554 ef 1638539 and ef 1638550 and 111 project b20009 any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government we would like to thank the editor prof huaming guo associate editor and reviewers for their insightful and detailed comments and suggestions we appreciate helpful comments and suggestions in prereviews by ms sifeng wu nanyang technological university appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2020 125883 supplementary data the following are the supplementary data to this article supplementary data 1 
4837,an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method for inferring inflow from the amu darya to the aral sea under ensemble prediction p p gao writing original draft methodology software a b y p li conceptualization methodology supervision b c g h huang supervision b c y y su data curation investigation b a sino canada energy and environmental research center north china electric power university beijing 102206 china sino canada energy and environmental research center north china electric power university beijing 102206 china sino canada energy and environmental research center north china electric power university beijing 102206 china b center for energy environment and ecology research school of environment beijing normal university beijing 100875 china center for energy environment and ecology research school of environment beijing normal university beijing 100875 china center for energy environment and ecology research school of environment beijing normal university beijing 100875 china c institute for energy environment and sustainable communities university of regina regina sask s4s 0a2 canada institute for energy environment and sustainable communities university of regina regina sask s4s 0a2 canada institute for energy environment and sustainable communities university of regina regina sask s4s 0a2 canada corresponding author this manuscript was handled by a bardossy editor in chief with the assistance of sheng yue associate editor graphical abstract an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method is developed through integrating techniques of bayesian inference least squares support vector machine lsvm and factorial analysis fa into a general framework b lsvm fa has advantages in i capturing the complicated nonlinear relationship between input factors and streamflow ii optimizing the key parameters of lsvm through a maximum posterior density estimation and iii quantifying the contributions of individual and interactive effects of multiple factors to streamflow variation b lsvm fa is then applied to inferring the changes in inflow from the amu darya to the aral sea named as iata results obtained cannot only identify the key impact factors reducing iata during the period of 1960 2015 but also predict future trends in iata for 2020 2050 comparing to the conventional ann svm and lsvm the proposed method performs better in describing the iata changes with anthropogenic hydrometeorological and ecological factors in terms of nse rmse and pbs results disclose that the major factors affecting iata at annual seasonal scale are upstream streamflow agricultural water use in uzbekistan reservoir water storage and evapotranspiration the significant differences in the contributions of main factors to iata at seasonal scale are observed because each season has unique characteristics of human activities meteorological conditions and vegetation coverages in order to seek the feasible strategies of recovering the iata level in the future 162 scenarios based on ensemble prediction are analyzed results indicate that the iata would restore to its 1970s condition if the drip irrigation rate reaches 50 at the end of 2050 and the reservoir water storage level reduces to the average value of 1960 1970 the findings can provide valuable suggestions for decision makers to increase iata and thus ameliorating the ecological crisis within the aral sea basin keywords amu darya bayesian inference ensemble prediction factorial analysis least squares support vector machine streamflow variation 1 introduction streamflow is a vital resource for guaranteeing the sustainable development of human society and plays a significant role in securing the function of ecosystems xin et al 2019 kadir et al 2020 anthropogenic activities e g urbanization irrigation agriculture and reservoir operation could lead to changes in streamflow sharma et al 2019 such changes could result in severe water issues and irreversible environmental consequences to basin ecosystems including vegetation degradation dwindling in lake areas and loss of natural habitats xue et al 2017 jiang et al 2020 aside from anthropogenic activity climate change can also affect streamflow formation by altering hydrology process e g precipitation potential evapotranspiration and snowmelt which further strengthens the complexity and uncertainty of the streamflow alteration tang and wang 2020 evidences from many basins world widely demonstrate that anthropogenic activity and climate change have presented a challenge for water resources management liu et al 2017 darvini and memmola 2020 a better understanding of impact factors and future changes is imperative to identify the responses of streamflow to anthropogenic activity and climate change and to develop sustainable water resources management and protection strategies many efforts have been made to infer streamflow alterations under anthropogenic activity and climate change such as statistical analysis li et al 2014 awotwi et al 2017 physical model shadkam et al 2016 wang et al 2019 and data driven model abbasi et al 2020 cheng et al 2020 statistical analysis as a non parametric method can effectively analyze the time series association between input factors and streamflow nevertheless it is incapable of capturing sophisticated nonlinear features hidden between them serinaldi et al 2018 physical model is a powerful tool for representing complex hydrological cycle processes sunde et al 2016 however large amounts of input data related to anthropogenic activity and climate change are required for adjusting the model structure and computational parameter it is challenging to obtain sufficient and accurate data in ungauged basins which would cause poor model performances and some uncertainties yoon et al 2011 data driven models are regarded as substitution techniques for reproducing the underlying hydrological process they have minimum data requirement and rapid calculation ability which have been used for streamflow simulation luo et al 2019 artificial neural network ann a frequently used data driven model has been employed to handle dynamic and nonlinear hydrological systems due to its strong capability of nonlinear mapping tan et al 2018 nevertheless ann has several shortcomings such as lots of adjustable parameters convergence to a local minimum and over fitting baek and kim 2018 based on the structural risk minimization principle fortunately support vector machine svm can overcome the limitations of ann considering its merits in a small sample nonlinearity and globally optimal solution bisgin et al 2018 svm has been widely used for the hydrological field huang et al 2014 chowdhury 2019 meng et al 2019 however svm is associated with a relatively high computational burden owing to inequality constraints and quadratic problems mahmoodi et al 2014 least squares support vector machine lsvm is considered as an upgraded version of svm through converting convex quadratic programming and inequality constraints into linear equations compared with svm lsvm highly simplifies the optimization process and exhibits more computationally efficient bemani et al 2020 extensive studies have been conducted on lsvm applications to streamflow simulation shabri and suhartono 2012 sayagavi et al 2016 adnan et al 2020 tikhamarine et al 2020 yu et al 2020 for example shabri and suhartono 2012 used lsvm for streamflow forecasting of the kinta river peninsular malaysia suggesting that lsvm outperformed ann and svm sayagavi et al 2016 used lsvm and model trees to estimate streamflow in the upper krishna basin india indicating that lsvm simulated better and captured the higher peak discharges adnan et al 2020 introduced optimally pruned extreme learning machine op elm lsvm multivariate adaptive regression splines mars and m5t to model monthly streamflow of the swat river basin pakistan results demonstrated that lsvm performed better than op elm and m5tree these research works shows that lsvm is a valuable simulation tool and is preferred in large scale problems where accuracy and time are of significance the fitting accuracy and efficiency of lsvm are sensitive to the selections of regularization and kernel parameters liu et al 2020a 2020b numerous optimization tools have been used for estimating the model parameters for lsvm such as cross validation sachindra et al 2012 particle swarm optimization dong et al 2017 genetic algorithm zendehboudi 2016 and bayesian inference rajabi and ataie ashtiani 2016 the proposed algorithms were conducive to obtaining the optimal model parameter of lsvm leading to efficient model learning among the parameter optimization approaches bayesian inference cannot only realize satisfactory generalization performance but also quantify the uncertainty or variability in model parameters using both prior belief and observations sun et al 2017 it would be valuable to consider combining bayesian inference and lsvm for the hydrological parameter optimization generally the integrated bayesian least squares support vector machine b lsvm method can effectively map the complicated nonlinear relationship between input factors and streamflow however b lsvm has trouble in quantitatively analyzing the contributions of anthropogenic activity and climate change to streamflow variation besides the interactive effects of input factors should not be neglected because they could significantly influence system performance jiang et al 2017 factorial analysis fa viewed as a multivariate inference method can efficiently reveal the main effect of a single factor and different level interactions of multiple input factors on the system performance zhang et al 2019 fa has been widely used in various experimental researches and practical applications bourgeois et al 2015 saleh et al 2018 lin et al 2019 these applications demonstrate that fa can be combined with b lsvm to address its limitation in the sensitivity analysis unfortunately no previous study was reported on introducing fa into the b lsvm method for hydrological process analysis therefore the objective of this study is to develop an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method for analyzing the effects of anthropogenic activity and climate change on streamflow b lsvm fa will incorporate bayesian inference least squares support vector machine lsvm and factorial analysis fa within a general framework it can capture the nonlinear relationship between input factors and streamflow in which the key regularization and kernel parameters of lsvm are optimized by bayesian inference based on fa b lsvm fa can quantitatively identify the contributions of input factors and their interactions to streamflow variation the b lsvm fa method will then be applied to a real case of the amu darya basin adb to disclose key factors affecting the inflow from the amu darya to the aral sea iata equivalent to outlet streamflow of the amu darya as well as to seek strategies of increasing iata under ensemble prediction results obtained are expected to provide valuable suggestions for ameliorating the ecological crisis within the aral sea basin 2 the study area the amu darya situated between 34 30 n 43 45 n latitudes and 58 15 e 75 07 e longitudes is the largest inland river in central asia it originates from the pamir mountains running approximately 2 540 km across tajikistan uzbekistan and turkmenistan before flowing into the aral sea the streamflow is mainly regulated by snow and glaciers melting with an average annual value of 79 km3 crosa et al 2006 the amu darya basin adb as shown in fig 1 encompasses an area of nearly 465 000 km2 and contains fourteen states it is characterized by a continental climate with an annual average temperature of 13 0 c precipitation in the adb varies mainly according to topography from the highest elevation to the lowest reach the annual average precipitation decreases from 1015 mm to 100 mm in 2015 the population of the adb was approximately 25 9 million and the urbanization rate was 42 5 ma et al 2020 the gross domestic product was us 67 7 billion in which the contributions of industry and agriculture were 83 9 and 16 1 respectively the amu darya contributes to about 68 of the total water of the aral sea unep 2006 in the adb the water resources are used primarily for agriculture industrial domestic and drinking purposes in the 1960s large scale water diversion and irrigation programs were commenced in the soviet union for the extensive expansion of cotton cultivation from then on numerous irrigation canals and reservoirs were constructed to divert water from the amu darya to cultivated land leading to a dramatic decrease of iata from 1960 to 2015 the iata decreased sharply from 43 0 km3 year to 5 9 km3 year the significant decline of iata ultimately resulted in the shrinkage of the aral sea compared to the 1960 s the sea level of the aral sea dropped nearly 26 m and area reduced by 90 burr et al 2019 the aral sea recession has caused severe eco environmental crises including vegetation degradation land salinization salt storm and aquatic extinction izhitskiy et al 2016 jiang et al 2020 the aral sea degradation also affected atmospheric circulation system and resulted in obvious changes in evapotranspiration precipitation and upstream streamflow significant changes in the hydrometeorological and ecological factors further exacerbated the reduction of iata therefore it is urgent to identify the effects of anthropogenic activity and climate change factors on the variation of iata and to recover the iata for mitigating the consequences of the ecological disaster of the aral sea 3 methodology fig 2 presents the framework of the b lsvm fa method whose procedures are summarized as i input data collection ii hydrological model set up and simulation and iii factorial analysis design b lsvm is used for building the relationship between input factors and iata ann svm and lsvm methods are proposed for demonstrating the effectiveness of the b lsvm method in iata simulation fa is further implemented to quantitatively estimate the individual and interactive effects of multiple input factors on iata 3 1 least squares support vector machine lsvm lsvm is an upgraded version of svm there are two main distinctions between lsvm and svm i lsvm uses equality constraints rather than inequality one ii quadratic programming problems are converted into a linear system these two changes simplify the computational complexity and improve the operation speed okkan and serbes 2012 for the training set x i y i i 1 2 n related to input factors and iata the regression equation can be defined as 1 y x ω t φ x b where φ x is mapping function b is bias term the weight vector ω can be calculated by solving the following optimization problem 2 min ω b ξ j ω ξ 1 2 ω t ω γ 2 i 1 n ξ 2 s t y i ω t φ x i b ξ i i 1 2 n where γ is penalty factor ξ is error variable vector representing the error between the calibration data i and its simulated value the solution of the optimization problem is established by regarding the lagrange function as 3 l ω b ξ β 1 2 ω t ω γ 2 i 1 n ξ 2 i 1 n β i ω t φ x i b ξ i y i where β i is the lagrange multiplier vector according to the karush kuhn tucker kkt conditions the solution for optimality can be obtained by differentiating equation 3 with the variables of ω b ξ and β i which are presented as follows 4 l ω b ξ β ω 0 ω i 1 n β i y i φ x i l ω b ξ β b 0 i 1 n β i 0 l ω b ξ β ξ 0 β i γ ξ i l ω b ξ β β i 0 y i ω t φ x i β 1 ξ i 0 by solving eq 4 the relationship between input factors and iata can be expressed as the following nonlinear regression function 5 y i 1 n α i k x i x b where k x i x denotes kernel function which satisfies mercer s condition and represents the inner product in d dimensional feature space through introducing a suitable kernel function the computational difficulty in high dimension space can be avoided there are many types of kernel functions that are implemented in the lsvm model such as radial basis function rbf kernel gaussian function kernel polynomial function kernel and linear function kernel in this study rbf kernel is selected in lsvm model barzegar et al 2019 6 k x i x j exp x i x j 2 σ 2 where σ denotes the squared bandwidth determining the complexity of the sample data distribution the accuracy and convergence of lsvm are controlled by regularization γ and kernel σ parameters cross validation as a simple and efficient technique was often been employed to the model selection for the lsvm with good generalization capabilities zhang and shetty 2016 however cross validation may lead to excessive optimization and model over fitting when validation set are selected improperly cawley and talbot 2007 these issues generally show a relatively high variance resulting in poor effect of local modeling in this paper bayesian inference is investigated to mitigate the effects of the high variance of cross validation to enhance predictive performance 3 2 bayesian inference bayesian inference presented by mackay mackay 1995 has been employed to the optimization of parameters within machine learning model in this study bayesian inference is integrated into the lsvm model to optimize parameter values which can be conducted through 3 level inferences gestel et al 2002 the optimal parameter and model are obtained through a maximum posterior density estimated according to bayes rule liu et al 2020a 2020b 7 p θ x p x θ p θ p x p x θ p θ where x x 1 x 2 x n represents n observed data points θ is the parameter of the data point s distribution denotes the hyperparameter of the parameter distribution p θ is the prior distribution while likelihood function p x θ presents the distribution of the observed data conditional on its parameter p θ x is the posterior distribution the detailed procedures of 3 level inferences are provided in appendix a to investigate the performance of b lsvm ann svm and lsvm with cross validation are adopted to verify the effectiveness of the b lsvm model which are presented in appendix b 3 3 performance evaluation of the models to evaluate the performances of ann svm lsvm and b lsvm models the nash sutcliffe efficiency nse standard deviation of error sde and percent bias pbs were selected which could be calculated using equations 8 10 respectively 8 nse i 1 n y obs i y obs 2 i 1 n y obs i y sim i 2 i 1 n y obs i y obs 2 9 sde 1 n i 1 n y obs i y sim i 1 n i 1 n y obs i y sim i 2 10 pbs 100 i 1 n y obs i y sim i i 1 n y obs i where y obs i and y sim i are the observed and simulated iata respectively y obs i denotes the average value of iata n is the number of simulated data 3 4 factorial analysis the effects of input factors on iata variation are complicated especially some potential interactive effects can be significant but hard to be determined factorial analysis fa can disclose which factors and which interactions have a remarkable effect on the system response box et al 1978 fa models input factors as linear combinations and the coefficients of the linear model are defined as follows 11 y c 0 i c i x i i j j i c ij x i x j where y denotes the output of the simulation model c 0 is the average effect c i indicates the main effect of factor x i c ij reflects a two factor interaction effect between x i and x j the simplest and the most common application of fa is the 2 k factorial design which contains k factors with each having two levels i e low and high the statistical model for a full 2 k design consists of 2 k 1 effects that comprise k main effects up to k factor interaction the main effect of each factor can be calculated as the difference value between two averages box et al 1978 the value of the interactive effect of combination ab can be calculated as equation 13 12 c i main effect y y 13 ab 1 2 a b a b where y and y are the average of the maximum and minimum output value respectively generally if there is an interaction effect ab this means that the effect of factor a on output will depend on the level of factor b to assess an effect or to obtain the sum of squares for an effect the contrast can be calculated by expanding the right hand side 14 contrast ab k a 1 b 1 k 1 where the sign in each of parentheses would be negative if the factor is included in the effect and positive if the factor is not included after determining the contrast for the effects the main and interactive effects and the sum of squares can be obtained according to 15 e ab k 2 contrast ab k n 2 k contrast ab k n 2 k 1 and 16 s s ab k contrast ab k 2 n 2 k where e ab k is the main or interactive effect of all factors s s ab k is the sum of squares for factor i or two factor interaction n indicates the number of replicates 3 5 date acquisition and processing in this study fifteen factors related to anthropogenic hydrometeorological and ecological are selected for iata simulation the selected factors their abbreviations data sources and time scales are listed in table 1 the temporal data of anthropogenic and hydrometeorological obtained are numbers that can be directly used for b lsvm fa method the ecological data i e ndvi fvc acquired from modis images can be converted to readable numbers by arcgis tools because those data are obtained from different time scales data processing is necessary to unify all the data on the same extent using the mean value composition method the datasets for hydrometeorological and ecological factors are assembled to yearly values finally 896 data points with a temporal scale of the year covering the period from 1960 to 2015 have been used for modeling formulation including 56 sets of samples and 16 factors a reliable relationship between input factors and iata depends on the quality of the generalization performance of b lsvm to build a model with good generalization performance a sensible data splitting strategy is needed and crucial for model validation xu and goodacre 2018 in this study a resampling strategy is employed to generate calibration and validation datasets resampling is the method that randomly draws samples from the original data samples dodangeh et al 2020 during iata simulation the data are randomly divided into two subsets namely calibration and validation the calibration set is used to perform and generate a model structure which contains 75 42 data points the validation set including 25 14 data points is then exploited to verify the performance and validity of b lsvm for unseen data 4 result analysis 4 1 simulation evaluation and model comparison in this study 10 000 resamplings were randomly drawn and three performance indices i e nse r2 and rmse were calculated for each resampling the distributions of three indices in calibration and validation periods are presented in fig 3 different combinations of calibration and validation datasets would lead to varied simulation performances the simulation performance of b lsvm is the best when the highest nse and r2 and the lowest rmse are obtained in this study the best performance of 10 000 resamples would be selected to reflect the complex nonlinear relationships among iata anthropogenic hydrometeorological and ecological factors three contrasting methods i e lsvm svm ann would use the best combination of calibration and validation datasets to verify the reliability of b lsvm in the iata simulation the observed and simulated iata from different models during calibration and validation periods are presented in fig 4 a d for calibration period the simulated results of those four models agree well with the observed data best nse is obtained for lsvm with value of 0 97 followed by b lsvm 0 95 svm 0 93 and ann 0 87 in validation period however b lsvm would lead to the most satisfactory performance with nse being 0 86 while lsvm svm and ann are 0 27 0 76 and 0 23 respectively results show a sharp decrease of nse in lsvm and ann which signifies an indication of overfitting with the observed data results also indicate that the b lsvm has a sound agreement between simulation and observation data which can effectively capture iata s inter annual variability in this study the taylor diagram was used to quantify the integrated performance of four models against the observations the diagram provides a concise summary of how closely model simulations match observations in terms of the correlation coefficient cc standard deviation std and root mean squared error rmse fig 4 e g present the taylor diagram for calibration validation and integrated simulation respectively from the results in calibration period fig 4 e lsvm has the best performance and is located the nearest from the observation point followed by b lsvm svm and ann with validation period fig 4 f b lsvm with cc of 0 93 std of 9 38 km3 and rmse of 3 46 is located in the nearest to the observation point at the same time lsvm with std of 14 97 km3 and rmse of 6 71 is in the second quadrant by far away from the observation point lsvm shows much higher inter annual variability compared to the observation whose std is 9 50 km3 for integrated simulation performance fig 4 g the nearest to the observation point is the b lsvm model with cc of 0 97 rmse of 2 98 and std of 11 27 km3 and slight farther are models lsvm and svm ann gets the worst simulation performance with cc of 0 89 and rmse of 5 76 the normal probability plots as shown in fig 5 of the residuals are presented to reflect the error of different models the residual points fall close on the straight line suggesting the model fits the observation quite well the residuals are lines in the range of 7 7 to 9 2 for b lsvm 12 3 to 10 2 for lsvm 6 7 to 21 3 for svm and 15 8 to 18 5 for ann respectively the linear trend of the residuals indicates the robustness and accuracy of b lsvm results besides two other accuracy indicators were also selected to assess the model performance including sde and pbs lower sde and pbs values demonstrate favorable performance as shown in fig 6 b lsvm yields superior sde and pbs values for example the order of sde values is as follows b lsvm 2 98 svm 3 81 lsvm 3 95 ann 5 76 the pbs values indicate that b lsvm lsvm and ann under estimated by 0 6 8 0 and 4 35 and svm over estimated by 4 2 results indicate that b lsvm yields a minimum error in iata simulation as stated above b lsvm can provide a more accurate iata simulation compared with lsvm svm and ann therefore b lsvm would be used to construct a statistical relationship between iata and input factors 4 2 main factors influencing iata the effects of fifteen factors on iata were investigated based on fa where each factor had two levels i e low and high leading to 215 design combinations the low and high levels of factors are provided in table 2 the trained b lsvm model was then utilized to simulate iata for each of the treatment combinations fig 6 depicts the simulated iata of 32 768 factorial experiments the highest lowest and average iata are 40 32 km3 4 44 km3 17 23 km3 respectively the factor values related to the highest and lowest iata are presented in table 2 results indicate that the highest or lowest iata is not achieved when the factor values are all at their high or low levels for example the highest and lowest iata can be obtained when ndvi fvc and prcp are high meanwhile the highest or lowest iata is not obtained when other factors remain unchanged but ndvi fvc and prcp being their low level it can be ascribed to the complexation and nonlinear relationship between input factors and iata results disclose that the uncertainties projected in the factors and different combinations of factors would lead to changed iata utilizing factorial experimental design the main and interaction effects can be determined fig 7 visualizes the main effects of a single factor on iata variation results indicate that different factors have varied impacts on iata characterizing as positive or negative effects the slop of all anthropogenic factors e g duz iuz auz dtj itj atj dtm itm atm and rws are negative indicating its negative effect on iata anthropogenic factors relate to the water consumption process which increases water diversion from the amu darya leading to decreased iata the hydrometeorological factors e g prcp and us exhibit a positive effect on iata because prcp and us are the two main sources for iata the negative effect of et on iata is because evapotranspiration decreases the capacity for streamflow for ecological factors the slopes of ndvi and fvc are positive demonstrating their positive effects on iata it is since the values of ndvi and fvc correspond to the condition of vegetation health within a specific range higher ndvi and fvc can help to cool off the surface the temperature which has a positive effect on long term water conservation deng et al 2018 wu and zhang 2019 among all impact factors us has the steepest slope suggesting that the effect of us is more significant than that of other fourteen factors for example iata would be increased from 14 46 to 19 90 km3 with the us rising from its low level of 20 85 km3 to a high level of 61 12 km3 this may be explained by the fact that the streamflow formation in the amu darya is dominated by the upstream snow and ice melting process table 3 provides the quantitative results of the main effects results show that all the factors have statistical significance on iata the contributions of fifteen factors to the variation of iata follow the order of us 31 76 auz 21 29 rws 16 68 et 11 38 atj 3 74 atm 2 51 itj 2 26 dtj 1 31 duz 1 04 ndvi 0 99 itm 0 97 dtm 0 92 iuz 0 76 prcp 0 43 fvc 0 01 in general anthropogenic factors have the most significant impact on iata variation with a total contribution of 51 48 followed by hydrometeorological and ecological factors with the total contributions being 43 57 and 1 respectively among anthropogenic factors agricultural water use and reservoir water storage play a dominant role in iata reduction with the contribution being 44 22 this is because a large amount of water used for irrigation and hydropower generation directly decrease streamflow and increase actual evapotranspiration for hydrometeorological factors us has the largest positive effect of 2 76 and contributes 31 76 to iata in contrast prcp shows relatively less with the value being 0 43 mainly due to the arid climate i e low precipitation and high evapotranspiration in the adb fig 8 depicts the contributions of interactive factors to iata and the matrix of interaction plot all the interactions for two factors have statistically significant p 0 05 effects on iata fig 8 a shows the total contribution for two factors interaction would be 3 8 in which the interaction between auz and us would get the highest contribution of 0 45 as shown in fig 8 b when auz is at its low level the iata would be increased from 16 39 km3 to 22 58 km3 if us varies from 20 85 km3 to 61 12 km3 when auz is at its high level a variation from 20 85 km3 to 61 12 km3 in the us will lead to an increase from 12 53 km3 to 17 40 km3 in the iata results disclose that when auz is at its lower level us would have a significant positive effect on iata this is because low level auz means less water consumption which increases the sensitivity of iata to upstream snowmelt streamflow results imply that reducing agricultural water consumption is critical to restoring water flow into the aral sea under climate change in addition the effect of us depends on the level of ndvi us would have a significant positive effect on iata when ndvi is at a high level the highest iata would be obtained when us and ndvi are at their high levels the reason is mainly because a high level of ndvi would enhance water conservation capacity to moderate surface streamflow and increase soil streamflow thus increasing iata results indicate that decision makers need to consider these interactions between factors to develop more reasonable and practical water management strategies 5 discussion 5 1 main factors affecting iata at seasonal scale as mentioned above upstream streamflow agricultural water use and reservoir water storage have a more significant effect on iata at annual scale however seasonal variations in the streamflow and water consumption exhibit different effects on iata for example seasonal snowmelt contributes a considerable share of the streamflow in amu darya which is the highest in summer and lowest in winter additionally agricultural water use abstracted from amu darya varies considerably with seasons because different crops have changed growing seasons analyzing the key impact factors of seasonal iata variation could highlight which factors are dominant in different seasons to disclose the main factors for iata variation at seasonal scale the data for four seasons were collected including spring march april may summer june july august autumn september october november and winter december january february the effects of fifteen factors on iata in four seasons were studied based on the developed b lsvm fa model fig 9 displays the simulation results for different seasons the highest iata of 215 treatments for spring summer autumn and winter are 4 25 km3 14 80 km3 8 37 km3 2 81 km3 respectively while lowest iata are 0 50 km3 0 50 km3 0 01 km3 and 0 25 km3 respectively the average iata from spring to winter are 2 51 km3 7 79 km3 3 72 km3 and 0 39 km3 results indicate that the iatas in different seasons vary significantly and warm seasons summer and autumn play a significant role in supplying water for the aral sea this is because a higher temperature would lead to higher streamflow from snowmelt in amu darya the large fluctuation of the iata of different treatments in the same season demonstrates that the iata is sensitive to the selected factors and the b lsvm fa model can well reflect it fig 10 shows the main effects of fifteen factors on iata under different seasons the contributions of individual factors to iata are presented in fig 11 in which the symbol denotes the negative effect on iata for spring the main factors affecting the iata are us auz atm and rws with contributions of 21 40 16 95 10 02 and 8 98 respectively for summer the iata is sensitive to us 36 90 auz 16 34 et 13 58 and atm 9 04 for autumn the order of contributions is us 18 52 rws 10 57 auz 10 49 et 8 39 while the order of contributions in winter is auz 16 31 us 14 03 rws 9 08 atm 8 95 in addition the total contribution related to anthropogenic hydrometeorological and ecological factors also varies significantly in different seasons the total contribution of anthropogenic factors reaches highest in winter with its values being 74 03 followed by spring 64 79 autumn 54 39 and summer 41 96 among anthropogenic factors agricultural water use has the most significant impact on iata with the average contribution being 25 63 in four seasons for hydrometeorological factors the highest total contribution occurs in summer 51 96 followed by spring 29 66 autumn 27 43 and winter 18 86 as for ecological factors the order of the total contributions is summer 2 93 autumn 2 32 spring 1 45 winter 0 36 the above differences can be attributed to the fact that each season has unique characteristics in terms of human activities meteorological conditions and vegetation coverages agricultural water use is influenced by the types of farm products and the duration of the growing season cotton one of the most water intensive crops is the primary crop in the adb which is planted during april early may and harvested in september during spring and summer plenty of water has to be diverted from the amu darya for irrigation besides serious soil salinization in the adb has pushed farmers to put more water to wash away the salts before planting cotton to promote agricultural irrigation capacity large scale reservoirs were constructed before the disintegration of the former soviet union during the soviet regime dams in tajikistan stored water in autumn and winter and released it in spring and summer to irrigate downstream crops after the dissolution of the soviet union tajikistan began to use water in winter to produce hydropower resulting in downstream water shortages in summer the contradiction between upstream and downstream water demand leads to the difference in reservoir water storage in different seasons the total contribution of hydrometeorological factors varies in different seasons is due to the changes in temperature the streamflow is produced from snowmelt which is dominated by heat in the adb high temperature occurs in summer and low temperature occurs in winter increases in air temperature from winter to summer could lead to seasonal snowmelt in the spring and more streamflow in summer 5 2 prospects for increasing streamflow to the aral sea in this study key factors affecting iata have been quantitatively analyzed anthropogenic factors have a significant adverse effect on iata variation particularly agricultural water use and reservoir water storage in the adb furrow irrigation is the mainly used irrigation technique because irrigation water use efficiency is poorly understood in all riparian countries such irrigation mode results in enormous water losses and causes increased salinity that requires more water for soil washing besides massive regulatory reservoirs were built to provide further water control which stopped extensive water running away into the aral sea these two main human activities induced a sharp decrease in iata engendering the aral sea s ecological catastrophe restoring the water level of the aral sea requires the efforts to improve water use efficiency by enhancing irrigation techniques and to decrease reservoir water storage drip irrigation as a highly efficient technique for improving water use efficiency has received increased attention in the central asia however only a few percentages of irrigated lands used drip irrigation system due to expensive cost and complex equipment there exists a huge room for the implementation of drip irrigation technology with economic growth and cost reduction in this study the policy scenarios of gradually expanding the implementation of drip irrigation technology are designed to support the sustainable development of irrigated agriculture and increase the streamflow into the aral sea at present the average irrigation quotas in tajikistan turkmenistan and uzbekistan are 9936 m3 ha 14663 m3 ha and 11587 m3 ha respectively in xinjiang province of china which is also an arid region of central asia the average irrigation quotas for furrow and drip irrigations are less than 8000 m3 ha and 5000 m3 ha respectively based on a long time optimization plan at the end of 2050 the average quotas of furrow irrigation and drip irrigation of three countries will be designed to decrease to the current level of xinjiang province year by year also different irrigation schemes under the combination of furrow irrigation and drip irrigation are designed including 50 furrow irrigation 50 drip irrigation 60 furrow irrigation 40 drip irrigation and 70 furrow irrigation 30 drip irrigation in addition scenarios for reservoir water storage and evapotranspiration are also designed and listed in table 4 in general two reservoir water storage levels three evapotranspiration levels and three countries with each having three irrigation schemes are considered leading to 162 scenarios using the b lsvm model it is convenient to predict the trend in iata for the period 2020 2050 under 162 scenarios each year would have 162 results of the iata fig 12 shows the results of iata under all scenarios which includes three different periods namely the recent term 2020 2030 middle term 2031 2040 and long term 2041 2050 results show a consistent increase in predicted iata from 2020 to 2050 following the increased drip irrigation ratio and decreased reservoir water storage for example the average of iata would increase from 10 20 km3 to 12 15 km3 during recent term 2020 2030 from 12 40 km3 to 14 88 km3 during middle term 2031 2040 and from 15 18 km3 to 17 74 km3 during long term 2041 2050 respectively the results of the b lsvm model estimate the average of iata would be 17 74 km3 at the end of 2050 with an annual average growth rate of 1 86 fig 12 also depicts the values of iata of 162 scenarios at the end of each period ranging from 9 77 km3 to 15 26 km3 in 2030 from 13 16 km3 to 17 08 km3 in 2040 and from 16 79 km3 to 18 94 km3 in 2050 respectively taking 2050 as an example fig 12 f the highest iata occurs when the combination of furrow irrigation and drip irrigation is 50 50 in all three countries and the reservoir water storage and evapotranspiration are at their low levels results imply that approximately 18 94 km3 of the streamflow would flow into the aral sea at the end of 2050 if the future ratio of drip irrigation reaches 50 and reservoir water storage reduces to the average level of 1960 1970 under this circumstance the project would help restore the iata to its 1970 s condition whose average value is 15 02 km3 during 1970 1980 results obtained demonstrated that the advancement of irrigation technique and decrease of reservoir water storage have significant positive effects on the recovery of the aral sea this study is the first attempt to correlate the iata with impact factors in the adb using the developed b lsvm fa method results indicate that b lsvm fa is an effective tool to describe the nonlinear relationship among multiple factors and reveal the effects of main and interactive on iata besides b lsvm fa can be used to assist decision makers in devising anthropogenic targets for increasing streamflow to the aral sea however b lsvm fa still has space for further improvement for example uncertainties may exist in the decision process due to the limitations and the errors in observations and random hydrological processes more robust methods e g bootstrapping can be incorporated into b lsvm fa to alleviate this data challenge in addition the two level factorial analysis is difficult to reflect the nonlinear relationships between modeling inputs and outputs which are involved in the complex hydrological processes future work could aim at exploring multi level factorial analysis for a better understanding of the nonlinear relationship between input factors and system response 6 conclusions in this study an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method has been developed through integrating bayesian inference least squares support vector lsvm and factorial analysis fa into a general framework b lsvm fa has the capability of i capturing the complicated nonlinear relationship to describe the way the system response changes with multiple factors ii optimizing the key parameters of lsvm through a maximum posterior density estimation and iii quantifying the contributions of main and interactive effects of multiple factors to system response b lsvm fa has been applied to disclosing the effects of multiple factors on iata over the amu darya basin adb during 1960 2015 to restore the ecological environment of the aral sea 162 scenarios have been designed to infer the future changes in iata during 2020 2050 several findings can be summarized as follows i b lsvm fa is acceptable in simulating iata compared with ann svm and lsvm in terms of nse rmse and pbs ii at annual scale the key factors affecting iata follows the order of us 31 76 auz 21 29 rws 16 68 et 11 38 anthropogenic factors account for 51 48 on the change of iata followed by hydrometeorological and ecological factors that contributes 43 57 and 1 respectively interactions between two factors contribute about 3 8 in which the interaction between auz and us has prominent effect on iata iii at seasonal scale the significant differences in the contributions of main factor to iata are observed because different seasons have varied human activities meteorological conditions and states of the vegetation coverages and iv based on the prediction for the period 2020 2050 under 162 scenarios if the drip irrigation rate reaches 50 and the reservoir water storage level reduces to the average value of 1960 1970 approximately 18 94 km3 of the streamflow would flow into the aral sea at the end of 2050 which would help restore the iata to its 1970 s condition findings are meaningful for decision makers to develop sustainable water resources management strategies to increase iata thus ameliorating the ecological crisis within the aral sea basin credit authorship contribution statement p p gao writing original draft methodology software y p li conceptualization methodology supervision g h huang supervision y y su data curation investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the strategic priority research program of chinese academy of sciences xda20060302 and the national natural science foundation of china 51779008 the authors are grateful to the editors and the anonymous reviewers for their insightful comments and suggestions appendix a bayesian inference method level 1 inference of the model parameter ω and b considering the data set d x i y i i 1 n and hyperparameters μ and ξ of the model h the model parameters of ω and b can be inferenced through the following posterior probability a 1 p ω b d ln μ ln ξ h p d ω b ln μ ln ξ h p ω b ln μ ln ξ h p d ln μ ln ξ h where p d ln μ ln ξ h is a normalized factor by which the sum of all possible ω and b is equal to 1 p d ω b ln μ ln ξ h is the likelihood function p ω b ln μ ln ξ h denotes the joint prior probability distribution of ω and b assuming p d ω b ln μ ln ξ h is independent of the parameter μ that is a 2 p d ω b ln μ ln ξ h p d ω b ln ξ h if p ω b ln μ ln ξ h is independent of ξ and ω is independent of b assuming p b h and p ω ln μ h are uniform distribution and gaussian probability distribution respectively model a 1 can be presented as a 3 p ω b d ln μ ln ξ h μ 2 π nf 2 exp μ 2 ω t ω 1 2 π σ b 2 exp b 2 2 σ b 2 μ 2 π nf 2 exp μ 2 ω t ω where σ b for equation a 2 assuming all the data points are independent it can be expressed as a 4 p d ω b ln ξ h i 1 n p y i x i ω b ln ξ h p x i ω b ln ξ h where a 5 p x i ω b ln ξ h p x i a 6 p y i x i ω b ln ξ h ξ 2 π 1 2 exp ξ 2 y i ω t φ x i b 2 the substitution of a 5 in a 3 provides a 7 p d ω b ln ξ h i 1 n p x i ξ 2 π 1 2 exp ξ 2 y i ω t φ x i b 2 substituting equations a 2 a 3 and a 7 into a 1 we obtain a 8 p ω b d ln μ ln ξ h exp μ 2 ω t ω exp ξ 2 i 1 n e i 2 the maximum posteriori estimates ω mp and bmp are then obtained by minimizing equation a 8 level 2 inference of the hyperparameters μ and ξ applying bayes rule in level 2 inference to obtain the optimal hyperparameters of μ mp and ξ mp from the given data set d the minimization problem in hyperparameters is reformulated into a scalar optimization problem in γ ξ μ the most likely μ and ξ can be determined as a 9 p d ln μ ln ξ h p d ln μ ln ξ h p ln μ ln ξ h p d h p d ln μ ln ξ h p ln ξ h p ln μ h p d h where p ln μ ln ξ h p ln ξ h p ln μ h substituting equations a 2 a 3 a 7 and a 8 into a 1 p d ln μ ln ξ h can be solved assuming μ and ξ are flat noninformative prior distribution equation a 9 can be written as a 10 p ln μ ln ξ d h μ nf ξ n det h exp j 1 ω b 1 2 g t h g where j 1 ω b j 1 ω mp b mp 1 2 g t h g with g ω ω mp b b mp det h is given using the eigenvalues of g expressing as det h n μ nf n eff ξ i 1 n eff μ ξ λ g i where λ g i are the nonzero eigenvalues of m ω m taking the negative logarithm of p ln μ ln ξ d h the optimal hyperparameters μ and ξ are obtained as follow a 11 min j 2 μ ξ μ e w ω mp b mp ξ e d ω mp b mp 1 2 i 1 n eff ln μ λ g i n eff 2 ln μ n 1 2 ln ξ through solving equation a 11 we obtain a 12 2 μ mp e w ω mp γ eff 1 a 13 2 ζ mp e d ω mp b mp n γ eff from the above definition γ ξ μ that is γ mp ξ mp μ mp by adding equations a 12 and a 13 together the optimal μ mp and ξ mp can be calculated a 14 2 μ mp e w ω mp γ mp e d ω mp b mp n 1 for the lsvm the effective number of parameters defined as a 15 γ eff 1 i 1 n eff ζ mp λ g i μ mp ζ mp λ g i 1 i 1 n eff γ mp λ g i 1 γ mp λ g i by substituting equation a 14 and γ ξ μ into equation a 11 the optimization problem can be reformulated as a 16 min j 3 μ ξ i 1 n 1 ln λ g i 1 γ n 1 l n e w ω mp γ γ e d ω mp b mp with λ g i 0 for i n eff the derivative j 3 γ can be represented as a 17 j 3 γ i 1 n 1 1 γ λ g i γ 2 n 1 e d ω mp b mp e w ω mp γ e d ω mp b mp because of the second logarithmic term this cost function is not convex and it is useful to start from different initial values for γ the condition for the optimality j 3 γ 0 is a 18 γ mp n n eff γ ef 1 e w ω mp e d ω mp b mp it is necessary to determine the expressions for e d ω mp b mp e w ω mp and e d ω mp b mp in equations a 17 and a 18 these terms can be obtained in terms of the output vector y and the eigenvalue decomposition of the centered kernel matrix m ω m a 19 e d ω mp b mp 1 2 γ 2 y t m v g d g γ 1 i neff 2 v g t m y a 20 e w ω mp 1 2 y t m v g d g d g γ 1 i neff 2 v g t m y by combining equations a 15 a 18 a 19 and a 20 the optimal μ mp and ξ mp are derived from μ mp γ eff 1 2 e w ω mp and ξ mp n eff γ eff 2 e d ω mp b mp level 3 inference of the parameters of kernel function after determination of the hyperparameters μ mp and ξ mp on the level 2 inference a suitable model h have to be selected by applying bayes rule on level 3 inference for lsvm different models denote varied kernel functions level 3 inference compares different models by estimating the posterior of model hj a 21 p h j d p d h j p h j the prior p h j for all possible models is assumed to be uniform distribution thus equation a 21 can be written as p h j d p d h j a separable gaussian prior distribution p ln μ mp ln ξ mp h j with error bars σ ln μ and σ ln ξ is predefined for all the models hj according to equation a 22 the posterior p d h j becomes a 22 p d h j p d ln μ mp ln ξ mp h j σ ln μ d σ ln ξ d σ ln μ σ ln ξ where the error bars σ ln μ and σ ln ξ can be approximated as σ ln μ d σ ln μ d 2 2 γ eff 1 and σ l n ξ d σ l n ξ d 2 2 n γ eff the kernel function parameter is obtained by maximizing p d h j a 23 p d h j μ mp 2 ξ mp n 1 γ eff 1 n γ eff i 1 n eff μ mp ξ mp λ g i appendix b the introductions of ann and svm artificial neural network ann ann can be used for modeling the nonlinear relationship between input and output factors it comprises three layers namely input output and hidden layers each layer consists of lots of neurons the number of neurons depend on the complexity of the data type and other requirements each neuron has two network parameters weights w and bias b the equation of ann can be generated as valipour et al 2013 b 1 y f o j 1 h w j f h i 1 n w ij x i b j b o where h denotes the number of neurons in the hidden layer n is the amount of the input neurons y is the iata fo is the transfer function of the output layer wj denotes the weight parameter between hidden neuron j and output neuron wij shows the weight parameter between input and hidden neurons xi is the ith input factor bj and bo are the bias for hidden neuron and output neuron respectively fh denotes the activation function which is expressed as b 2 f y 1 1 e y further introductions for the theoretical background of ann can be obtained from the study described by haykin 2009 support vector machine svm svm is a supervised machine learning method based on statistical learning theory vapnik 1998 the idea of svm is to map the original input data into a high dimensional feature space via nonlinear mapping the regression equation can be expressed as b 3 f x i 1 n w i ϕ i x b where ϕ i x i 1 n is mapping function b is bias term w t i 1 n is coefficient vector which can be obtained by calculating quadratic programming problem b 4 min 1 2 w 2 c i 1 n ξ i ξ i s t y i w ϕ x i b ε ξ i w ϕ x i y i b ε ξ i ξ i 0 ξ i 0 i 1 n where c denotes the penalty factor ξ i is a slack variable to solve the equation b 2 2 the lagrange function is defined as b 5 l w b ξ α γ 1 2 w 2 c i 1 n ξ i i 1 n α i y i w x i b 1 ξ i i 1 n γ i ξ i where α i γ i r are lagrange multipliers by transforming equation b 2 3 to duality problem and adding karush kuhn tucker kkt conditions the regression function can be written as joshi et al 2012 b 6 f x α α i 1 n α α k x i x b b 7 k x i x i 1 d ϕ i x i ϕ i x ϕ i x ϕ x 
4837,an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method for inferring inflow from the amu darya to the aral sea under ensemble prediction p p gao writing original draft methodology software a b y p li conceptualization methodology supervision b c g h huang supervision b c y y su data curation investigation b a sino canada energy and environmental research center north china electric power university beijing 102206 china sino canada energy and environmental research center north china electric power university beijing 102206 china sino canada energy and environmental research center north china electric power university beijing 102206 china b center for energy environment and ecology research school of environment beijing normal university beijing 100875 china center for energy environment and ecology research school of environment beijing normal university beijing 100875 china center for energy environment and ecology research school of environment beijing normal university beijing 100875 china c institute for energy environment and sustainable communities university of regina regina sask s4s 0a2 canada institute for energy environment and sustainable communities university of regina regina sask s4s 0a2 canada institute for energy environment and sustainable communities university of regina regina sask s4s 0a2 canada corresponding author this manuscript was handled by a bardossy editor in chief with the assistance of sheng yue associate editor graphical abstract an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method is developed through integrating techniques of bayesian inference least squares support vector machine lsvm and factorial analysis fa into a general framework b lsvm fa has advantages in i capturing the complicated nonlinear relationship between input factors and streamflow ii optimizing the key parameters of lsvm through a maximum posterior density estimation and iii quantifying the contributions of individual and interactive effects of multiple factors to streamflow variation b lsvm fa is then applied to inferring the changes in inflow from the amu darya to the aral sea named as iata results obtained cannot only identify the key impact factors reducing iata during the period of 1960 2015 but also predict future trends in iata for 2020 2050 comparing to the conventional ann svm and lsvm the proposed method performs better in describing the iata changes with anthropogenic hydrometeorological and ecological factors in terms of nse rmse and pbs results disclose that the major factors affecting iata at annual seasonal scale are upstream streamflow agricultural water use in uzbekistan reservoir water storage and evapotranspiration the significant differences in the contributions of main factors to iata at seasonal scale are observed because each season has unique characteristics of human activities meteorological conditions and vegetation coverages in order to seek the feasible strategies of recovering the iata level in the future 162 scenarios based on ensemble prediction are analyzed results indicate that the iata would restore to its 1970s condition if the drip irrigation rate reaches 50 at the end of 2050 and the reservoir water storage level reduces to the average value of 1960 1970 the findings can provide valuable suggestions for decision makers to increase iata and thus ameliorating the ecological crisis within the aral sea basin keywords amu darya bayesian inference ensemble prediction factorial analysis least squares support vector machine streamflow variation 1 introduction streamflow is a vital resource for guaranteeing the sustainable development of human society and plays a significant role in securing the function of ecosystems xin et al 2019 kadir et al 2020 anthropogenic activities e g urbanization irrigation agriculture and reservoir operation could lead to changes in streamflow sharma et al 2019 such changes could result in severe water issues and irreversible environmental consequences to basin ecosystems including vegetation degradation dwindling in lake areas and loss of natural habitats xue et al 2017 jiang et al 2020 aside from anthropogenic activity climate change can also affect streamflow formation by altering hydrology process e g precipitation potential evapotranspiration and snowmelt which further strengthens the complexity and uncertainty of the streamflow alteration tang and wang 2020 evidences from many basins world widely demonstrate that anthropogenic activity and climate change have presented a challenge for water resources management liu et al 2017 darvini and memmola 2020 a better understanding of impact factors and future changes is imperative to identify the responses of streamflow to anthropogenic activity and climate change and to develop sustainable water resources management and protection strategies many efforts have been made to infer streamflow alterations under anthropogenic activity and climate change such as statistical analysis li et al 2014 awotwi et al 2017 physical model shadkam et al 2016 wang et al 2019 and data driven model abbasi et al 2020 cheng et al 2020 statistical analysis as a non parametric method can effectively analyze the time series association between input factors and streamflow nevertheless it is incapable of capturing sophisticated nonlinear features hidden between them serinaldi et al 2018 physical model is a powerful tool for representing complex hydrological cycle processes sunde et al 2016 however large amounts of input data related to anthropogenic activity and climate change are required for adjusting the model structure and computational parameter it is challenging to obtain sufficient and accurate data in ungauged basins which would cause poor model performances and some uncertainties yoon et al 2011 data driven models are regarded as substitution techniques for reproducing the underlying hydrological process they have minimum data requirement and rapid calculation ability which have been used for streamflow simulation luo et al 2019 artificial neural network ann a frequently used data driven model has been employed to handle dynamic and nonlinear hydrological systems due to its strong capability of nonlinear mapping tan et al 2018 nevertheless ann has several shortcomings such as lots of adjustable parameters convergence to a local minimum and over fitting baek and kim 2018 based on the structural risk minimization principle fortunately support vector machine svm can overcome the limitations of ann considering its merits in a small sample nonlinearity and globally optimal solution bisgin et al 2018 svm has been widely used for the hydrological field huang et al 2014 chowdhury 2019 meng et al 2019 however svm is associated with a relatively high computational burden owing to inequality constraints and quadratic problems mahmoodi et al 2014 least squares support vector machine lsvm is considered as an upgraded version of svm through converting convex quadratic programming and inequality constraints into linear equations compared with svm lsvm highly simplifies the optimization process and exhibits more computationally efficient bemani et al 2020 extensive studies have been conducted on lsvm applications to streamflow simulation shabri and suhartono 2012 sayagavi et al 2016 adnan et al 2020 tikhamarine et al 2020 yu et al 2020 for example shabri and suhartono 2012 used lsvm for streamflow forecasting of the kinta river peninsular malaysia suggesting that lsvm outperformed ann and svm sayagavi et al 2016 used lsvm and model trees to estimate streamflow in the upper krishna basin india indicating that lsvm simulated better and captured the higher peak discharges adnan et al 2020 introduced optimally pruned extreme learning machine op elm lsvm multivariate adaptive regression splines mars and m5t to model monthly streamflow of the swat river basin pakistan results demonstrated that lsvm performed better than op elm and m5tree these research works shows that lsvm is a valuable simulation tool and is preferred in large scale problems where accuracy and time are of significance the fitting accuracy and efficiency of lsvm are sensitive to the selections of regularization and kernel parameters liu et al 2020a 2020b numerous optimization tools have been used for estimating the model parameters for lsvm such as cross validation sachindra et al 2012 particle swarm optimization dong et al 2017 genetic algorithm zendehboudi 2016 and bayesian inference rajabi and ataie ashtiani 2016 the proposed algorithms were conducive to obtaining the optimal model parameter of lsvm leading to efficient model learning among the parameter optimization approaches bayesian inference cannot only realize satisfactory generalization performance but also quantify the uncertainty or variability in model parameters using both prior belief and observations sun et al 2017 it would be valuable to consider combining bayesian inference and lsvm for the hydrological parameter optimization generally the integrated bayesian least squares support vector machine b lsvm method can effectively map the complicated nonlinear relationship between input factors and streamflow however b lsvm has trouble in quantitatively analyzing the contributions of anthropogenic activity and climate change to streamflow variation besides the interactive effects of input factors should not be neglected because they could significantly influence system performance jiang et al 2017 factorial analysis fa viewed as a multivariate inference method can efficiently reveal the main effect of a single factor and different level interactions of multiple input factors on the system performance zhang et al 2019 fa has been widely used in various experimental researches and practical applications bourgeois et al 2015 saleh et al 2018 lin et al 2019 these applications demonstrate that fa can be combined with b lsvm to address its limitation in the sensitivity analysis unfortunately no previous study was reported on introducing fa into the b lsvm method for hydrological process analysis therefore the objective of this study is to develop an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method for analyzing the effects of anthropogenic activity and climate change on streamflow b lsvm fa will incorporate bayesian inference least squares support vector machine lsvm and factorial analysis fa within a general framework it can capture the nonlinear relationship between input factors and streamflow in which the key regularization and kernel parameters of lsvm are optimized by bayesian inference based on fa b lsvm fa can quantitatively identify the contributions of input factors and their interactions to streamflow variation the b lsvm fa method will then be applied to a real case of the amu darya basin adb to disclose key factors affecting the inflow from the amu darya to the aral sea iata equivalent to outlet streamflow of the amu darya as well as to seek strategies of increasing iata under ensemble prediction results obtained are expected to provide valuable suggestions for ameliorating the ecological crisis within the aral sea basin 2 the study area the amu darya situated between 34 30 n 43 45 n latitudes and 58 15 e 75 07 e longitudes is the largest inland river in central asia it originates from the pamir mountains running approximately 2 540 km across tajikistan uzbekistan and turkmenistan before flowing into the aral sea the streamflow is mainly regulated by snow and glaciers melting with an average annual value of 79 km3 crosa et al 2006 the amu darya basin adb as shown in fig 1 encompasses an area of nearly 465 000 km2 and contains fourteen states it is characterized by a continental climate with an annual average temperature of 13 0 c precipitation in the adb varies mainly according to topography from the highest elevation to the lowest reach the annual average precipitation decreases from 1015 mm to 100 mm in 2015 the population of the adb was approximately 25 9 million and the urbanization rate was 42 5 ma et al 2020 the gross domestic product was us 67 7 billion in which the contributions of industry and agriculture were 83 9 and 16 1 respectively the amu darya contributes to about 68 of the total water of the aral sea unep 2006 in the adb the water resources are used primarily for agriculture industrial domestic and drinking purposes in the 1960s large scale water diversion and irrigation programs were commenced in the soviet union for the extensive expansion of cotton cultivation from then on numerous irrigation canals and reservoirs were constructed to divert water from the amu darya to cultivated land leading to a dramatic decrease of iata from 1960 to 2015 the iata decreased sharply from 43 0 km3 year to 5 9 km3 year the significant decline of iata ultimately resulted in the shrinkage of the aral sea compared to the 1960 s the sea level of the aral sea dropped nearly 26 m and area reduced by 90 burr et al 2019 the aral sea recession has caused severe eco environmental crises including vegetation degradation land salinization salt storm and aquatic extinction izhitskiy et al 2016 jiang et al 2020 the aral sea degradation also affected atmospheric circulation system and resulted in obvious changes in evapotranspiration precipitation and upstream streamflow significant changes in the hydrometeorological and ecological factors further exacerbated the reduction of iata therefore it is urgent to identify the effects of anthropogenic activity and climate change factors on the variation of iata and to recover the iata for mitigating the consequences of the ecological disaster of the aral sea 3 methodology fig 2 presents the framework of the b lsvm fa method whose procedures are summarized as i input data collection ii hydrological model set up and simulation and iii factorial analysis design b lsvm is used for building the relationship between input factors and iata ann svm and lsvm methods are proposed for demonstrating the effectiveness of the b lsvm method in iata simulation fa is further implemented to quantitatively estimate the individual and interactive effects of multiple input factors on iata 3 1 least squares support vector machine lsvm lsvm is an upgraded version of svm there are two main distinctions between lsvm and svm i lsvm uses equality constraints rather than inequality one ii quadratic programming problems are converted into a linear system these two changes simplify the computational complexity and improve the operation speed okkan and serbes 2012 for the training set x i y i i 1 2 n related to input factors and iata the regression equation can be defined as 1 y x ω t φ x b where φ x is mapping function b is bias term the weight vector ω can be calculated by solving the following optimization problem 2 min ω b ξ j ω ξ 1 2 ω t ω γ 2 i 1 n ξ 2 s t y i ω t φ x i b ξ i i 1 2 n where γ is penalty factor ξ is error variable vector representing the error between the calibration data i and its simulated value the solution of the optimization problem is established by regarding the lagrange function as 3 l ω b ξ β 1 2 ω t ω γ 2 i 1 n ξ 2 i 1 n β i ω t φ x i b ξ i y i where β i is the lagrange multiplier vector according to the karush kuhn tucker kkt conditions the solution for optimality can be obtained by differentiating equation 3 with the variables of ω b ξ and β i which are presented as follows 4 l ω b ξ β ω 0 ω i 1 n β i y i φ x i l ω b ξ β b 0 i 1 n β i 0 l ω b ξ β ξ 0 β i γ ξ i l ω b ξ β β i 0 y i ω t φ x i β 1 ξ i 0 by solving eq 4 the relationship between input factors and iata can be expressed as the following nonlinear regression function 5 y i 1 n α i k x i x b where k x i x denotes kernel function which satisfies mercer s condition and represents the inner product in d dimensional feature space through introducing a suitable kernel function the computational difficulty in high dimension space can be avoided there are many types of kernel functions that are implemented in the lsvm model such as radial basis function rbf kernel gaussian function kernel polynomial function kernel and linear function kernel in this study rbf kernel is selected in lsvm model barzegar et al 2019 6 k x i x j exp x i x j 2 σ 2 where σ denotes the squared bandwidth determining the complexity of the sample data distribution the accuracy and convergence of lsvm are controlled by regularization γ and kernel σ parameters cross validation as a simple and efficient technique was often been employed to the model selection for the lsvm with good generalization capabilities zhang and shetty 2016 however cross validation may lead to excessive optimization and model over fitting when validation set are selected improperly cawley and talbot 2007 these issues generally show a relatively high variance resulting in poor effect of local modeling in this paper bayesian inference is investigated to mitigate the effects of the high variance of cross validation to enhance predictive performance 3 2 bayesian inference bayesian inference presented by mackay mackay 1995 has been employed to the optimization of parameters within machine learning model in this study bayesian inference is integrated into the lsvm model to optimize parameter values which can be conducted through 3 level inferences gestel et al 2002 the optimal parameter and model are obtained through a maximum posterior density estimated according to bayes rule liu et al 2020a 2020b 7 p θ x p x θ p θ p x p x θ p θ where x x 1 x 2 x n represents n observed data points θ is the parameter of the data point s distribution denotes the hyperparameter of the parameter distribution p θ is the prior distribution while likelihood function p x θ presents the distribution of the observed data conditional on its parameter p θ x is the posterior distribution the detailed procedures of 3 level inferences are provided in appendix a to investigate the performance of b lsvm ann svm and lsvm with cross validation are adopted to verify the effectiveness of the b lsvm model which are presented in appendix b 3 3 performance evaluation of the models to evaluate the performances of ann svm lsvm and b lsvm models the nash sutcliffe efficiency nse standard deviation of error sde and percent bias pbs were selected which could be calculated using equations 8 10 respectively 8 nse i 1 n y obs i y obs 2 i 1 n y obs i y sim i 2 i 1 n y obs i y obs 2 9 sde 1 n i 1 n y obs i y sim i 1 n i 1 n y obs i y sim i 2 10 pbs 100 i 1 n y obs i y sim i i 1 n y obs i where y obs i and y sim i are the observed and simulated iata respectively y obs i denotes the average value of iata n is the number of simulated data 3 4 factorial analysis the effects of input factors on iata variation are complicated especially some potential interactive effects can be significant but hard to be determined factorial analysis fa can disclose which factors and which interactions have a remarkable effect on the system response box et al 1978 fa models input factors as linear combinations and the coefficients of the linear model are defined as follows 11 y c 0 i c i x i i j j i c ij x i x j where y denotes the output of the simulation model c 0 is the average effect c i indicates the main effect of factor x i c ij reflects a two factor interaction effect between x i and x j the simplest and the most common application of fa is the 2 k factorial design which contains k factors with each having two levels i e low and high the statistical model for a full 2 k design consists of 2 k 1 effects that comprise k main effects up to k factor interaction the main effect of each factor can be calculated as the difference value between two averages box et al 1978 the value of the interactive effect of combination ab can be calculated as equation 13 12 c i main effect y y 13 ab 1 2 a b a b where y and y are the average of the maximum and minimum output value respectively generally if there is an interaction effect ab this means that the effect of factor a on output will depend on the level of factor b to assess an effect or to obtain the sum of squares for an effect the contrast can be calculated by expanding the right hand side 14 contrast ab k a 1 b 1 k 1 where the sign in each of parentheses would be negative if the factor is included in the effect and positive if the factor is not included after determining the contrast for the effects the main and interactive effects and the sum of squares can be obtained according to 15 e ab k 2 contrast ab k n 2 k contrast ab k n 2 k 1 and 16 s s ab k contrast ab k 2 n 2 k where e ab k is the main or interactive effect of all factors s s ab k is the sum of squares for factor i or two factor interaction n indicates the number of replicates 3 5 date acquisition and processing in this study fifteen factors related to anthropogenic hydrometeorological and ecological are selected for iata simulation the selected factors their abbreviations data sources and time scales are listed in table 1 the temporal data of anthropogenic and hydrometeorological obtained are numbers that can be directly used for b lsvm fa method the ecological data i e ndvi fvc acquired from modis images can be converted to readable numbers by arcgis tools because those data are obtained from different time scales data processing is necessary to unify all the data on the same extent using the mean value composition method the datasets for hydrometeorological and ecological factors are assembled to yearly values finally 896 data points with a temporal scale of the year covering the period from 1960 to 2015 have been used for modeling formulation including 56 sets of samples and 16 factors a reliable relationship between input factors and iata depends on the quality of the generalization performance of b lsvm to build a model with good generalization performance a sensible data splitting strategy is needed and crucial for model validation xu and goodacre 2018 in this study a resampling strategy is employed to generate calibration and validation datasets resampling is the method that randomly draws samples from the original data samples dodangeh et al 2020 during iata simulation the data are randomly divided into two subsets namely calibration and validation the calibration set is used to perform and generate a model structure which contains 75 42 data points the validation set including 25 14 data points is then exploited to verify the performance and validity of b lsvm for unseen data 4 result analysis 4 1 simulation evaluation and model comparison in this study 10 000 resamplings were randomly drawn and three performance indices i e nse r2 and rmse were calculated for each resampling the distributions of three indices in calibration and validation periods are presented in fig 3 different combinations of calibration and validation datasets would lead to varied simulation performances the simulation performance of b lsvm is the best when the highest nse and r2 and the lowest rmse are obtained in this study the best performance of 10 000 resamples would be selected to reflect the complex nonlinear relationships among iata anthropogenic hydrometeorological and ecological factors three contrasting methods i e lsvm svm ann would use the best combination of calibration and validation datasets to verify the reliability of b lsvm in the iata simulation the observed and simulated iata from different models during calibration and validation periods are presented in fig 4 a d for calibration period the simulated results of those four models agree well with the observed data best nse is obtained for lsvm with value of 0 97 followed by b lsvm 0 95 svm 0 93 and ann 0 87 in validation period however b lsvm would lead to the most satisfactory performance with nse being 0 86 while lsvm svm and ann are 0 27 0 76 and 0 23 respectively results show a sharp decrease of nse in lsvm and ann which signifies an indication of overfitting with the observed data results also indicate that the b lsvm has a sound agreement between simulation and observation data which can effectively capture iata s inter annual variability in this study the taylor diagram was used to quantify the integrated performance of four models against the observations the diagram provides a concise summary of how closely model simulations match observations in terms of the correlation coefficient cc standard deviation std and root mean squared error rmse fig 4 e g present the taylor diagram for calibration validation and integrated simulation respectively from the results in calibration period fig 4 e lsvm has the best performance and is located the nearest from the observation point followed by b lsvm svm and ann with validation period fig 4 f b lsvm with cc of 0 93 std of 9 38 km3 and rmse of 3 46 is located in the nearest to the observation point at the same time lsvm with std of 14 97 km3 and rmse of 6 71 is in the second quadrant by far away from the observation point lsvm shows much higher inter annual variability compared to the observation whose std is 9 50 km3 for integrated simulation performance fig 4 g the nearest to the observation point is the b lsvm model with cc of 0 97 rmse of 2 98 and std of 11 27 km3 and slight farther are models lsvm and svm ann gets the worst simulation performance with cc of 0 89 and rmse of 5 76 the normal probability plots as shown in fig 5 of the residuals are presented to reflect the error of different models the residual points fall close on the straight line suggesting the model fits the observation quite well the residuals are lines in the range of 7 7 to 9 2 for b lsvm 12 3 to 10 2 for lsvm 6 7 to 21 3 for svm and 15 8 to 18 5 for ann respectively the linear trend of the residuals indicates the robustness and accuracy of b lsvm results besides two other accuracy indicators were also selected to assess the model performance including sde and pbs lower sde and pbs values demonstrate favorable performance as shown in fig 6 b lsvm yields superior sde and pbs values for example the order of sde values is as follows b lsvm 2 98 svm 3 81 lsvm 3 95 ann 5 76 the pbs values indicate that b lsvm lsvm and ann under estimated by 0 6 8 0 and 4 35 and svm over estimated by 4 2 results indicate that b lsvm yields a minimum error in iata simulation as stated above b lsvm can provide a more accurate iata simulation compared with lsvm svm and ann therefore b lsvm would be used to construct a statistical relationship between iata and input factors 4 2 main factors influencing iata the effects of fifteen factors on iata were investigated based on fa where each factor had two levels i e low and high leading to 215 design combinations the low and high levels of factors are provided in table 2 the trained b lsvm model was then utilized to simulate iata for each of the treatment combinations fig 6 depicts the simulated iata of 32 768 factorial experiments the highest lowest and average iata are 40 32 km3 4 44 km3 17 23 km3 respectively the factor values related to the highest and lowest iata are presented in table 2 results indicate that the highest or lowest iata is not achieved when the factor values are all at their high or low levels for example the highest and lowest iata can be obtained when ndvi fvc and prcp are high meanwhile the highest or lowest iata is not obtained when other factors remain unchanged but ndvi fvc and prcp being their low level it can be ascribed to the complexation and nonlinear relationship between input factors and iata results disclose that the uncertainties projected in the factors and different combinations of factors would lead to changed iata utilizing factorial experimental design the main and interaction effects can be determined fig 7 visualizes the main effects of a single factor on iata variation results indicate that different factors have varied impacts on iata characterizing as positive or negative effects the slop of all anthropogenic factors e g duz iuz auz dtj itj atj dtm itm atm and rws are negative indicating its negative effect on iata anthropogenic factors relate to the water consumption process which increases water diversion from the amu darya leading to decreased iata the hydrometeorological factors e g prcp and us exhibit a positive effect on iata because prcp and us are the two main sources for iata the negative effect of et on iata is because evapotranspiration decreases the capacity for streamflow for ecological factors the slopes of ndvi and fvc are positive demonstrating their positive effects on iata it is since the values of ndvi and fvc correspond to the condition of vegetation health within a specific range higher ndvi and fvc can help to cool off the surface the temperature which has a positive effect on long term water conservation deng et al 2018 wu and zhang 2019 among all impact factors us has the steepest slope suggesting that the effect of us is more significant than that of other fourteen factors for example iata would be increased from 14 46 to 19 90 km3 with the us rising from its low level of 20 85 km3 to a high level of 61 12 km3 this may be explained by the fact that the streamflow formation in the amu darya is dominated by the upstream snow and ice melting process table 3 provides the quantitative results of the main effects results show that all the factors have statistical significance on iata the contributions of fifteen factors to the variation of iata follow the order of us 31 76 auz 21 29 rws 16 68 et 11 38 atj 3 74 atm 2 51 itj 2 26 dtj 1 31 duz 1 04 ndvi 0 99 itm 0 97 dtm 0 92 iuz 0 76 prcp 0 43 fvc 0 01 in general anthropogenic factors have the most significant impact on iata variation with a total contribution of 51 48 followed by hydrometeorological and ecological factors with the total contributions being 43 57 and 1 respectively among anthropogenic factors agricultural water use and reservoir water storage play a dominant role in iata reduction with the contribution being 44 22 this is because a large amount of water used for irrigation and hydropower generation directly decrease streamflow and increase actual evapotranspiration for hydrometeorological factors us has the largest positive effect of 2 76 and contributes 31 76 to iata in contrast prcp shows relatively less with the value being 0 43 mainly due to the arid climate i e low precipitation and high evapotranspiration in the adb fig 8 depicts the contributions of interactive factors to iata and the matrix of interaction plot all the interactions for two factors have statistically significant p 0 05 effects on iata fig 8 a shows the total contribution for two factors interaction would be 3 8 in which the interaction between auz and us would get the highest contribution of 0 45 as shown in fig 8 b when auz is at its low level the iata would be increased from 16 39 km3 to 22 58 km3 if us varies from 20 85 km3 to 61 12 km3 when auz is at its high level a variation from 20 85 km3 to 61 12 km3 in the us will lead to an increase from 12 53 km3 to 17 40 km3 in the iata results disclose that when auz is at its lower level us would have a significant positive effect on iata this is because low level auz means less water consumption which increases the sensitivity of iata to upstream snowmelt streamflow results imply that reducing agricultural water consumption is critical to restoring water flow into the aral sea under climate change in addition the effect of us depends on the level of ndvi us would have a significant positive effect on iata when ndvi is at a high level the highest iata would be obtained when us and ndvi are at their high levels the reason is mainly because a high level of ndvi would enhance water conservation capacity to moderate surface streamflow and increase soil streamflow thus increasing iata results indicate that decision makers need to consider these interactions between factors to develop more reasonable and practical water management strategies 5 discussion 5 1 main factors affecting iata at seasonal scale as mentioned above upstream streamflow agricultural water use and reservoir water storage have a more significant effect on iata at annual scale however seasonal variations in the streamflow and water consumption exhibit different effects on iata for example seasonal snowmelt contributes a considerable share of the streamflow in amu darya which is the highest in summer and lowest in winter additionally agricultural water use abstracted from amu darya varies considerably with seasons because different crops have changed growing seasons analyzing the key impact factors of seasonal iata variation could highlight which factors are dominant in different seasons to disclose the main factors for iata variation at seasonal scale the data for four seasons were collected including spring march april may summer june july august autumn september october november and winter december january february the effects of fifteen factors on iata in four seasons were studied based on the developed b lsvm fa model fig 9 displays the simulation results for different seasons the highest iata of 215 treatments for spring summer autumn and winter are 4 25 km3 14 80 km3 8 37 km3 2 81 km3 respectively while lowest iata are 0 50 km3 0 50 km3 0 01 km3 and 0 25 km3 respectively the average iata from spring to winter are 2 51 km3 7 79 km3 3 72 km3 and 0 39 km3 results indicate that the iatas in different seasons vary significantly and warm seasons summer and autumn play a significant role in supplying water for the aral sea this is because a higher temperature would lead to higher streamflow from snowmelt in amu darya the large fluctuation of the iata of different treatments in the same season demonstrates that the iata is sensitive to the selected factors and the b lsvm fa model can well reflect it fig 10 shows the main effects of fifteen factors on iata under different seasons the contributions of individual factors to iata are presented in fig 11 in which the symbol denotes the negative effect on iata for spring the main factors affecting the iata are us auz atm and rws with contributions of 21 40 16 95 10 02 and 8 98 respectively for summer the iata is sensitive to us 36 90 auz 16 34 et 13 58 and atm 9 04 for autumn the order of contributions is us 18 52 rws 10 57 auz 10 49 et 8 39 while the order of contributions in winter is auz 16 31 us 14 03 rws 9 08 atm 8 95 in addition the total contribution related to anthropogenic hydrometeorological and ecological factors also varies significantly in different seasons the total contribution of anthropogenic factors reaches highest in winter with its values being 74 03 followed by spring 64 79 autumn 54 39 and summer 41 96 among anthropogenic factors agricultural water use has the most significant impact on iata with the average contribution being 25 63 in four seasons for hydrometeorological factors the highest total contribution occurs in summer 51 96 followed by spring 29 66 autumn 27 43 and winter 18 86 as for ecological factors the order of the total contributions is summer 2 93 autumn 2 32 spring 1 45 winter 0 36 the above differences can be attributed to the fact that each season has unique characteristics in terms of human activities meteorological conditions and vegetation coverages agricultural water use is influenced by the types of farm products and the duration of the growing season cotton one of the most water intensive crops is the primary crop in the adb which is planted during april early may and harvested in september during spring and summer plenty of water has to be diverted from the amu darya for irrigation besides serious soil salinization in the adb has pushed farmers to put more water to wash away the salts before planting cotton to promote agricultural irrigation capacity large scale reservoirs were constructed before the disintegration of the former soviet union during the soviet regime dams in tajikistan stored water in autumn and winter and released it in spring and summer to irrigate downstream crops after the dissolution of the soviet union tajikistan began to use water in winter to produce hydropower resulting in downstream water shortages in summer the contradiction between upstream and downstream water demand leads to the difference in reservoir water storage in different seasons the total contribution of hydrometeorological factors varies in different seasons is due to the changes in temperature the streamflow is produced from snowmelt which is dominated by heat in the adb high temperature occurs in summer and low temperature occurs in winter increases in air temperature from winter to summer could lead to seasonal snowmelt in the spring and more streamflow in summer 5 2 prospects for increasing streamflow to the aral sea in this study key factors affecting iata have been quantitatively analyzed anthropogenic factors have a significant adverse effect on iata variation particularly agricultural water use and reservoir water storage in the adb furrow irrigation is the mainly used irrigation technique because irrigation water use efficiency is poorly understood in all riparian countries such irrigation mode results in enormous water losses and causes increased salinity that requires more water for soil washing besides massive regulatory reservoirs were built to provide further water control which stopped extensive water running away into the aral sea these two main human activities induced a sharp decrease in iata engendering the aral sea s ecological catastrophe restoring the water level of the aral sea requires the efforts to improve water use efficiency by enhancing irrigation techniques and to decrease reservoir water storage drip irrigation as a highly efficient technique for improving water use efficiency has received increased attention in the central asia however only a few percentages of irrigated lands used drip irrigation system due to expensive cost and complex equipment there exists a huge room for the implementation of drip irrigation technology with economic growth and cost reduction in this study the policy scenarios of gradually expanding the implementation of drip irrigation technology are designed to support the sustainable development of irrigated agriculture and increase the streamflow into the aral sea at present the average irrigation quotas in tajikistan turkmenistan and uzbekistan are 9936 m3 ha 14663 m3 ha and 11587 m3 ha respectively in xinjiang province of china which is also an arid region of central asia the average irrigation quotas for furrow and drip irrigations are less than 8000 m3 ha and 5000 m3 ha respectively based on a long time optimization plan at the end of 2050 the average quotas of furrow irrigation and drip irrigation of three countries will be designed to decrease to the current level of xinjiang province year by year also different irrigation schemes under the combination of furrow irrigation and drip irrigation are designed including 50 furrow irrigation 50 drip irrigation 60 furrow irrigation 40 drip irrigation and 70 furrow irrigation 30 drip irrigation in addition scenarios for reservoir water storage and evapotranspiration are also designed and listed in table 4 in general two reservoir water storage levels three evapotranspiration levels and three countries with each having three irrigation schemes are considered leading to 162 scenarios using the b lsvm model it is convenient to predict the trend in iata for the period 2020 2050 under 162 scenarios each year would have 162 results of the iata fig 12 shows the results of iata under all scenarios which includes three different periods namely the recent term 2020 2030 middle term 2031 2040 and long term 2041 2050 results show a consistent increase in predicted iata from 2020 to 2050 following the increased drip irrigation ratio and decreased reservoir water storage for example the average of iata would increase from 10 20 km3 to 12 15 km3 during recent term 2020 2030 from 12 40 km3 to 14 88 km3 during middle term 2031 2040 and from 15 18 km3 to 17 74 km3 during long term 2041 2050 respectively the results of the b lsvm model estimate the average of iata would be 17 74 km3 at the end of 2050 with an annual average growth rate of 1 86 fig 12 also depicts the values of iata of 162 scenarios at the end of each period ranging from 9 77 km3 to 15 26 km3 in 2030 from 13 16 km3 to 17 08 km3 in 2040 and from 16 79 km3 to 18 94 km3 in 2050 respectively taking 2050 as an example fig 12 f the highest iata occurs when the combination of furrow irrigation and drip irrigation is 50 50 in all three countries and the reservoir water storage and evapotranspiration are at their low levels results imply that approximately 18 94 km3 of the streamflow would flow into the aral sea at the end of 2050 if the future ratio of drip irrigation reaches 50 and reservoir water storage reduces to the average level of 1960 1970 under this circumstance the project would help restore the iata to its 1970 s condition whose average value is 15 02 km3 during 1970 1980 results obtained demonstrated that the advancement of irrigation technique and decrease of reservoir water storage have significant positive effects on the recovery of the aral sea this study is the first attempt to correlate the iata with impact factors in the adb using the developed b lsvm fa method results indicate that b lsvm fa is an effective tool to describe the nonlinear relationship among multiple factors and reveal the effects of main and interactive on iata besides b lsvm fa can be used to assist decision makers in devising anthropogenic targets for increasing streamflow to the aral sea however b lsvm fa still has space for further improvement for example uncertainties may exist in the decision process due to the limitations and the errors in observations and random hydrological processes more robust methods e g bootstrapping can be incorporated into b lsvm fa to alleviate this data challenge in addition the two level factorial analysis is difficult to reflect the nonlinear relationships between modeling inputs and outputs which are involved in the complex hydrological processes future work could aim at exploring multi level factorial analysis for a better understanding of the nonlinear relationship between input factors and system response 6 conclusions in this study an integrated bayesian least squares support vector machine factorial analysis b lsvm fa method has been developed through integrating bayesian inference least squares support vector lsvm and factorial analysis fa into a general framework b lsvm fa has the capability of i capturing the complicated nonlinear relationship to describe the way the system response changes with multiple factors ii optimizing the key parameters of lsvm through a maximum posterior density estimation and iii quantifying the contributions of main and interactive effects of multiple factors to system response b lsvm fa has been applied to disclosing the effects of multiple factors on iata over the amu darya basin adb during 1960 2015 to restore the ecological environment of the aral sea 162 scenarios have been designed to infer the future changes in iata during 2020 2050 several findings can be summarized as follows i b lsvm fa is acceptable in simulating iata compared with ann svm and lsvm in terms of nse rmse and pbs ii at annual scale the key factors affecting iata follows the order of us 31 76 auz 21 29 rws 16 68 et 11 38 anthropogenic factors account for 51 48 on the change of iata followed by hydrometeorological and ecological factors that contributes 43 57 and 1 respectively interactions between two factors contribute about 3 8 in which the interaction between auz and us has prominent effect on iata iii at seasonal scale the significant differences in the contributions of main factor to iata are observed because different seasons have varied human activities meteorological conditions and states of the vegetation coverages and iv based on the prediction for the period 2020 2050 under 162 scenarios if the drip irrigation rate reaches 50 and the reservoir water storage level reduces to the average value of 1960 1970 approximately 18 94 km3 of the streamflow would flow into the aral sea at the end of 2050 which would help restore the iata to its 1970 s condition findings are meaningful for decision makers to develop sustainable water resources management strategies to increase iata thus ameliorating the ecological crisis within the aral sea basin credit authorship contribution statement p p gao writing original draft methodology software y p li conceptualization methodology supervision g h huang supervision y y su data curation investigation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the strategic priority research program of chinese academy of sciences xda20060302 and the national natural science foundation of china 51779008 the authors are grateful to the editors and the anonymous reviewers for their insightful comments and suggestions appendix a bayesian inference method level 1 inference of the model parameter ω and b considering the data set d x i y i i 1 n and hyperparameters μ and ξ of the model h the model parameters of ω and b can be inferenced through the following posterior probability a 1 p ω b d ln μ ln ξ h p d ω b ln μ ln ξ h p ω b ln μ ln ξ h p d ln μ ln ξ h where p d ln μ ln ξ h is a normalized factor by which the sum of all possible ω and b is equal to 1 p d ω b ln μ ln ξ h is the likelihood function p ω b ln μ ln ξ h denotes the joint prior probability distribution of ω and b assuming p d ω b ln μ ln ξ h is independent of the parameter μ that is a 2 p d ω b ln μ ln ξ h p d ω b ln ξ h if p ω b ln μ ln ξ h is independent of ξ and ω is independent of b assuming p b h and p ω ln μ h are uniform distribution and gaussian probability distribution respectively model a 1 can be presented as a 3 p ω b d ln μ ln ξ h μ 2 π nf 2 exp μ 2 ω t ω 1 2 π σ b 2 exp b 2 2 σ b 2 μ 2 π nf 2 exp μ 2 ω t ω where σ b for equation a 2 assuming all the data points are independent it can be expressed as a 4 p d ω b ln ξ h i 1 n p y i x i ω b ln ξ h p x i ω b ln ξ h where a 5 p x i ω b ln ξ h p x i a 6 p y i x i ω b ln ξ h ξ 2 π 1 2 exp ξ 2 y i ω t φ x i b 2 the substitution of a 5 in a 3 provides a 7 p d ω b ln ξ h i 1 n p x i ξ 2 π 1 2 exp ξ 2 y i ω t φ x i b 2 substituting equations a 2 a 3 and a 7 into a 1 we obtain a 8 p ω b d ln μ ln ξ h exp μ 2 ω t ω exp ξ 2 i 1 n e i 2 the maximum posteriori estimates ω mp and bmp are then obtained by minimizing equation a 8 level 2 inference of the hyperparameters μ and ξ applying bayes rule in level 2 inference to obtain the optimal hyperparameters of μ mp and ξ mp from the given data set d the minimization problem in hyperparameters is reformulated into a scalar optimization problem in γ ξ μ the most likely μ and ξ can be determined as a 9 p d ln μ ln ξ h p d ln μ ln ξ h p ln μ ln ξ h p d h p d ln μ ln ξ h p ln ξ h p ln μ h p d h where p ln μ ln ξ h p ln ξ h p ln μ h substituting equations a 2 a 3 a 7 and a 8 into a 1 p d ln μ ln ξ h can be solved assuming μ and ξ are flat noninformative prior distribution equation a 9 can be written as a 10 p ln μ ln ξ d h μ nf ξ n det h exp j 1 ω b 1 2 g t h g where j 1 ω b j 1 ω mp b mp 1 2 g t h g with g ω ω mp b b mp det h is given using the eigenvalues of g expressing as det h n μ nf n eff ξ i 1 n eff μ ξ λ g i where λ g i are the nonzero eigenvalues of m ω m taking the negative logarithm of p ln μ ln ξ d h the optimal hyperparameters μ and ξ are obtained as follow a 11 min j 2 μ ξ μ e w ω mp b mp ξ e d ω mp b mp 1 2 i 1 n eff ln μ λ g i n eff 2 ln μ n 1 2 ln ξ through solving equation a 11 we obtain a 12 2 μ mp e w ω mp γ eff 1 a 13 2 ζ mp e d ω mp b mp n γ eff from the above definition γ ξ μ that is γ mp ξ mp μ mp by adding equations a 12 and a 13 together the optimal μ mp and ξ mp can be calculated a 14 2 μ mp e w ω mp γ mp e d ω mp b mp n 1 for the lsvm the effective number of parameters defined as a 15 γ eff 1 i 1 n eff ζ mp λ g i μ mp ζ mp λ g i 1 i 1 n eff γ mp λ g i 1 γ mp λ g i by substituting equation a 14 and γ ξ μ into equation a 11 the optimization problem can be reformulated as a 16 min j 3 μ ξ i 1 n 1 ln λ g i 1 γ n 1 l n e w ω mp γ γ e d ω mp b mp with λ g i 0 for i n eff the derivative j 3 γ can be represented as a 17 j 3 γ i 1 n 1 1 γ λ g i γ 2 n 1 e d ω mp b mp e w ω mp γ e d ω mp b mp because of the second logarithmic term this cost function is not convex and it is useful to start from different initial values for γ the condition for the optimality j 3 γ 0 is a 18 γ mp n n eff γ ef 1 e w ω mp e d ω mp b mp it is necessary to determine the expressions for e d ω mp b mp e w ω mp and e d ω mp b mp in equations a 17 and a 18 these terms can be obtained in terms of the output vector y and the eigenvalue decomposition of the centered kernel matrix m ω m a 19 e d ω mp b mp 1 2 γ 2 y t m v g d g γ 1 i neff 2 v g t m y a 20 e w ω mp 1 2 y t m v g d g d g γ 1 i neff 2 v g t m y by combining equations a 15 a 18 a 19 and a 20 the optimal μ mp and ξ mp are derived from μ mp γ eff 1 2 e w ω mp and ξ mp n eff γ eff 2 e d ω mp b mp level 3 inference of the parameters of kernel function after determination of the hyperparameters μ mp and ξ mp on the level 2 inference a suitable model h have to be selected by applying bayes rule on level 3 inference for lsvm different models denote varied kernel functions level 3 inference compares different models by estimating the posterior of model hj a 21 p h j d p d h j p h j the prior p h j for all possible models is assumed to be uniform distribution thus equation a 21 can be written as p h j d p d h j a separable gaussian prior distribution p ln μ mp ln ξ mp h j with error bars σ ln μ and σ ln ξ is predefined for all the models hj according to equation a 22 the posterior p d h j becomes a 22 p d h j p d ln μ mp ln ξ mp h j σ ln μ d σ ln ξ d σ ln μ σ ln ξ where the error bars σ ln μ and σ ln ξ can be approximated as σ ln μ d σ ln μ d 2 2 γ eff 1 and σ l n ξ d σ l n ξ d 2 2 n γ eff the kernel function parameter is obtained by maximizing p d h j a 23 p d h j μ mp 2 ξ mp n 1 γ eff 1 n γ eff i 1 n eff μ mp ξ mp λ g i appendix b the introductions of ann and svm artificial neural network ann ann can be used for modeling the nonlinear relationship between input and output factors it comprises three layers namely input output and hidden layers each layer consists of lots of neurons the number of neurons depend on the complexity of the data type and other requirements each neuron has two network parameters weights w and bias b the equation of ann can be generated as valipour et al 2013 b 1 y f o j 1 h w j f h i 1 n w ij x i b j b o where h denotes the number of neurons in the hidden layer n is the amount of the input neurons y is the iata fo is the transfer function of the output layer wj denotes the weight parameter between hidden neuron j and output neuron wij shows the weight parameter between input and hidden neurons xi is the ith input factor bj and bo are the bias for hidden neuron and output neuron respectively fh denotes the activation function which is expressed as b 2 f y 1 1 e y further introductions for the theoretical background of ann can be obtained from the study described by haykin 2009 support vector machine svm svm is a supervised machine learning method based on statistical learning theory vapnik 1998 the idea of svm is to map the original input data into a high dimensional feature space via nonlinear mapping the regression equation can be expressed as b 3 f x i 1 n w i ϕ i x b where ϕ i x i 1 n is mapping function b is bias term w t i 1 n is coefficient vector which can be obtained by calculating quadratic programming problem b 4 min 1 2 w 2 c i 1 n ξ i ξ i s t y i w ϕ x i b ε ξ i w ϕ x i y i b ε ξ i ξ i 0 ξ i 0 i 1 n where c denotes the penalty factor ξ i is a slack variable to solve the equation b 2 2 the lagrange function is defined as b 5 l w b ξ α γ 1 2 w 2 c i 1 n ξ i i 1 n α i y i w x i b 1 ξ i i 1 n γ i ξ i where α i γ i r are lagrange multipliers by transforming equation b 2 3 to duality problem and adding karush kuhn tucker kkt conditions the regression function can be written as joshi et al 2012 b 6 f x α α i 1 n α α k x i x b b 7 k x i x i 1 d ϕ i x i ϕ i x ϕ i x ϕ x 
4838,modeling the relationship between rainfall and runoff is an important issue in hydrology but it is a complicated task because both the high levels of complexity in which both processes are embedded and the associated uncertainty affect the forecasting neuro fuzzy models have emerged as a useful approach given the ability of neural networks to optimize parameters in a fuzzy system in this work a self identification neuro fuzzy inference model sinfim for modeling the relationship between rainfall and runoff on a chilean watershed is proposed to reduce the uncertainty of selecting both the rainfall and runoff lags and the number of membership functions required in a fuzzy system the data comes from the diguillín river located in ñuble region and average daily runoff and average daily rainfall recorded from years 2000 to 2018 according to the chilean directorate of water resources dga in addition we worked with the colorado river basin located in the maule region to validate the method developed the experimental results showed a good adjustment using the last 3 years as validation set further improvement was achieved using only the last year was used as validation test obtaining 84 of r 2 and 0 91 kling gupta efficiency higher than other forecasting models such as adaptive neuro fuzzy inference system anfis artificial neural networks ann and long short term memory lstm approach in addition nash sutcliffe efficiency and percent bias indicate the method is a promising model on the other hand even better results were obtained in the validation basin whose adjustment was 94 and an efficiency of 97 therefore the proposed model is a solid alternative to forecast the runoff in a given watershed obtaining good performance measurements managing to predict both the low and peak runoff values from rainfall events avoiding the requirement to determine a priori the lags of time series and the number of fuzzy rules keywords rainfall runoff modeling neuro fuzzy model sinfim framework 1 introduction hydrological models are key tools for water and environment resource management they represent hydrological processes and evaluate conditions for urban and environmental planning such as land use flood and water resources management of watersheds nourani et al 2013 a popular approach is modeling the relationship between rainfall and runoff process using a set of equations that explain runoff as a function of rainfall and may include other parameters used to describe watershed characteristics masseroni et al 2017 although there is a cause and effect relationship between both processes rainfall runoff modeling with high accuracy is affected by its non linear behavior associated with the complex characteristics of the water cycle adnan et al 2019 in addition to rainfall runoff depends on many other factors such as initial soil moisture land use basin geomorphology evaporation infiltration distribution and rainfall duration atc 2000 there are several approaches to model a the rainfall runoff relationship methods like simple and multiple regression models auto regressive moving average arma the lumped process oriented deterministic bucket style models artificial neural networks and distributed physics models are part of them beven 2011 anusree and varghese 2016 each of these approaches has its own advantages and drawbacks but the reduction of the predictive uncertainty of the model is considered as one the paramount elements to be considered masseroni et al 2017 gopalan et al 2019 this uncertainty can be incorporated taking into account measurement of the input variables such as rainfall and temperature as well as the selection of the parameter values used in the model since they depend on the climatic conditions even the choice of the structure of the model establishing governing equations by itself implies uncertainty knoben et al 2019 in fact in a recent work a large number of researchers looking for greater harmonization on research efforts identified that the mechanism to disentangle and reduce the structural uncertainty of the model parameter input in hydrological prediction as one of main unresolved problems in hydrology blöschl et al 2019 fuzzy logic has emerged as useful approach to model phenomena with some degree of uncertainty including hydrological processes the main idea is to consider variables in a linguistically uncertain manner rather than numerical precise quantities sen and altunkaynak 2004 moraga and salas 2005 a neuro fuzzy model is a structure in which the neural network uses training data to determine the membership functions and fuzzy rules of a fuzzy logic system zahedi and zahedi 2018 this allows to have a fuzzy system to represent the process in an interpretable way thus mitigating both individual approaches drawbacks the neural networks black box behavior and the problems of finding suitable membership values for fuzzy systems kumari and sunita 2013 many neuro fuzzy systems are based on takagi sugeno kang structure because they allow the application of gradient descent learning as long as differentiable membership functions are used nauck and nürnberger 2013 one of the first and popular neuro fuzzy systems is the adaptive network based fuzzy inference system anfis model proposed in 1991 by jang 1993 widely applied in rainfall runoff modeling anusree and varghese 2016 jothiprakash et al 2009 ghose et al 2013 panchal et al 2014 although anfis model has shown good results its algorithm employs offline learning which suffers from increased computational time and requires retraining to capture recent changes of the system moreover the number of rules is predefined by the user and overfitting is a common problem when the data are overtrained in fact every data set that is trained using anfis has its maximum number of epochs before overfitting occurs al hmouz et al 2011 with the idea of optimizing the anfis prediction a series of hybrid models have been proposed zhou et al 2019 proposed an evolutionary recurrent anfis for modelling multi step ahead flood forecasts embedded with genetic algorithm ga and least square estimator gl bartoletti et al 2018 proposed a combination between principal component analysis pca and anfis model with the emphasis on how to set up an efficient data structure that produces a good output flow estimation pca approach provides some degree of freedom by choosing the number of components to keep allowing a trade off between accuracy and network complexity meanwhile nourani et al 2011 proposed to apply a wavelet transformation in the input time series and then introduce different scales in the anfis model to obtain the runoff prediction in a structure called wanfis the wavelet transform provides useful decomposition of the main time series rainfall and runoff in this case to improve the forecasting a recent modified adaptive neuro fuzzy inference system for runoff estimation was proposed by nath et al 2019 this work was focused on reducing the computational complexity of anfis by incorporating the particle swarm optimization pso algorithm in a framework called pso anfis which was used for estimating the parameters pertaining to anfis other optimized approaches such as anfis ant colony optimization for continuous domain anfis acor azad et al 2018 anfis grey wolf optimizer gwo anfis gwo dehghani et al 2019 or anfis genetic algorithms anfis ga ghose et al 2013 have been proposed with their own advantages and applicability recently an extension of anfis model called self organization neuro fuzzy inference system sonfis has been proposed by allende cid et al 2016 2008 although the neural network structure has the same layers as the anfis model the learning process incorporates mathematical operators to define the number of fuzzy rules required in the system in other words the network automatically organizes itself to identify the set of takagi sugeno kang type rules necessary to model the data set since the relationship between rainfall and runoff has a degree of uncertainty it may decrease if the number of membership functions and the respective rules are not set in advance this model has been used with financial and experimental data sets but it has not been used for modeling hydrological phenomena which serves as motivation for its use in runoff prediction on the other hand the selection of lags of both time series rainfall and runoff is a key pre processing step in day ahead forecasting runoff events the literature suggests among the most common methods for lag selection methods the partial autocorrelation function pacf nath et al 2019 xie et al 2019 tran et al 2017 rizeei et al 2018 cross correlation analysis cca or micca a combination of these last two chang et al 2017 nevertheless these functions locate the lags based on their linear dependence with the value to be predicted so that for phenomena with non linear behaviors algorithms with a more flexible structure can identify the most optimal lags nourani et al 2011 other approaches used in hydrology are entropy analysis nourani et al 2015 mutual information mi may et al 2008 and algorithms that might involve dimensionality reduction such as the gamma test singh et al 2018 pca or clustering methods remesan et al 2018 furthermore in recent years methods based on machine learning have been presented as alternatives for the selection of suitable inputs such as the input variable selection proposed by taormina and chau 2015 that employs an algorithm which combines binary coded discrete fully informed particle swarm optimization bfips and extreme learning machines elm more recently in 2016 veloz et al 2016 proposed sifar self identification of lags of an autoregressive takagi sugeno kang based model as a method to find the most influential lags of a fuzzy model for time series applications sifar algorithm has not been used in hydrology and provides a local representation which allows the description of a nonlinear system using a set of simple mathematical functions aggregated to describe the overall complexity that underlies its dynamic process in chile few studies have developed neuro fuzzy systems for rainfall runoff modeling implementing instead conceptual models which despite their usefulness in support decision making systems have several limitations such as the lack of consideration of the groundwater exchange or the assumption of environmental standard conditions parra et al 2018 therefore the aim of this work is to propose a new neuro fuzzy model for predicting runoff from rainfall measurements called self identification neuro fuzzy inference model sinfim in a chilean watershed the novelty of this method is that it allows reducing the uncertainty associated with the runoff forecasting regarding inputs and hyperparameters selection because it finds the relevant rainfall and runoff lags for a neuro fuzzy system which in turn automatically identifies the number of rules necessary to model the phenomenon this framework is our main contribution to professionals involved in the management of watershed resources to make appropriate decisions in environmental planning the paper is organized as follows next section section 2 presents the hybrid framework used to model the rainfall runoff relationship describing the models involved in the algorithm then the description of the dataset experiments and the performance measures used are in methods and materials section 3 section 4 presents experimental results and section 5 some discussion finally section 6 concludes with some remarks 2 self identification neuro fuzzy inference model sinfim self identification neuro fuzzy inference model sinfim is presented as method to forecast day ahead runoff events this framework reduces the uncertainty associated with the lags and hyperparameters selection in a fuzzy system fig 1 the proposed algorithms involve the following components 1 self identification of rainfall and runoff lags using a model based on a fuzzy partitioning or clustering of each input uni dimensional time series the more relevant rainfall x and runoff q lags to predict q t 1 are selected 2 adaptive neuro fuzzy inference system relevant lags selected in the previous step are the inputs for an adaptive neuro fuzzy inference system which involves a fuzzy model with a hybrid learning algorithm and a predefined number of membership functions this model serves as the fundamental structure to predict q t 1 3 self identification of fuzzy rules once the base neuro fuzzy model is obtained a series of mathematical operators are iteratively applied in order to identify the number of fuzzy rules required to model the relationship between rainfall and runoff with the best performance then the consequent parameters are updated and finally the output is predicted 2 1 self identification of rainfall and runoff lags the proposed framework begins with the identification of the most influential lags for each time series considered rainfall and runoff for this a model based on the component of sifar method proposed by veloz et al 2016 associated with lags relevance evaluation is developed this model represents a set of local predictors in order to define different sub domains along the lag space the process is summarized in fig 2 above the time series x t is a stochastic process whose samples are observed in regular time intervals ranging from t 1 t for selection of lags sifar model used a nonlinear autoregressive relationship x t f x t 1 x t d where d is the maximum expected order of the time series model and is user defined for notation purposes a time series is arranged in a regressor matrix x x kj n x d with n t d and a target vector y x d 1 x t the j th column of x is given by x d 1 j x t j the k th row of the matrix x and the k th element of the vector y are denoted as x k and y k respectively the first step is to apply fuzzy c means fcm in the target space y using the entire dataset generating a local domain and considering only those values belonging to this region with a high degree of membership x the number of partitions in both spaces is defined in advance and v v 1 v n 0 represents the cluster prototypes where n 0 is the number of clusters in which the target space is partitioned after that the possibility distribution is computed for each cluster h th as follows 1 t hk 1 p 1 n y k v h y k v p 2 η 1 with 1 h n o and 1 k n y k represents the k th element of the target vector y while η is user defined usually set to 2 the third step computes scale parameters σ 1 σ n 0 using the diagonal elements of the fuzzy covariance matrix 2 σ h 2 k 1 n t hk m y k v h 2 k 1 n t hk m afterwards for each obtained cluster an α cut set o α 1 o α h o α n 0 is computed where o α h y k y μ h y k α 0 constitutes the most representative and similar data samples the following step consists of applying the initial procedures to each α cut generated in the regressor space that is applying the fcm technique and obtaining the cluster centers in addition of calculating their possibility distribution and scale parameters the set of cluster prototypes obtained are denoted by v h v 1 h v n in h where v i h v ij h corresponds to the i th cluster prototype vector associated with the h th α cut obtained in the target space and v ij h represents its element associated with the j th lag through 3 t ik h 1 p 1 n x k v i h x k v p h 2 η 1 i k k the possibility distribution is computed where i is the indicator function based on it the scale parameters σ ij are computed using the equation 4 σ ij h k k t ik h m x kj v ij h 2 k k t ik h m where x kj corresponds to the j th lag variable of the k th element of the process and v ij h are the set of cluster centers the next step consists in evaluating the contribution to local smooth mapping between the regressor and target spaces of each lag with the following equation 5 r h j k in h k 0 h where k 0 h k y k o α h k in h k x k i α h i α h i 1 n in x k x y k o α h w i h x k α in constitutes the cardinality of the resulting set and w i h the strength level for the i th cluster in the regressor space the set of lags is ordered according to r j j 1 d results and the first q elements are taken this selection could involve redundant partitions which later will be removed based on the similarity of μ ij membership functions two clusters will be merged if the result of the supremum minimum composition s j i 1 i 2 sup min μ i 1 j μ i 2 j with i 1 i 2 1 n and i 1 i 2 is greater than or equal to a threshold α f defined by the user in this step and after applying the entire the algorithm for each uni dimensional time series rainfall and runoff the relevant and non redundant lags are selected 2 2 adaptive neuro fuzzy inference system once the most relevant rainfall and runoff lags are selected they constitute of a neuro fuzzy model to predict one day ahead runoff events for this a model based on the adaptive neuro fuzzy inference system anfis proposed in 1993 by jang 1993 is developed it is a special feed forward neural network and its fundamental axis is to model the phenomenon based on the fuzzy takagi sugeno kang rules of the form 6 r r if x 1 is μ j 1 1 and and x n is μ j n n then y β o r β 1 r x 1 β n r x n where μ j i is the degree to which an input x i satisfies a linguistic quantifier calculated using a certain membership function that involves a set of parameters η called premises depending on this degree of membership the output y is determined and its parameter vector θ containing the parameters β in the linear equation is called consequent the network implies five components layers layer 1 associates each input to a certain fuzzy set through a gaussian type membership function in layer 2 the and t norm operator is used to obtain the strength of each of the rules specified in layer 1 which will later be normalized in layer 3 the layer 4 computes the contribution of each rule using both consequent parameters and layer 3 output vector finally the layer 5 computes the weighted global output of all the incoming signals fig 3 once the base architecture is constructed with a predefined number of nodes for each layers a hybrid learning is developed this is an ordinary least square ols estimation is used to determine the consequent parameters and the back propagation learning algorithm to estimate the premise parameters 2 3 self identification of fuzzy rules after the anfis hybrid learning is developed a series of mathematical operators proposed by allende cid et al 2016 are iteratively applied in order to automatically identify the number of rules required to model the dataset grownet split membership functions and vanish membership functions fig 4 grow net is the first operator to run and it evaluates if the current fuzzy rules sub networks work well according to the user predetermined threshold δ this comparison is based on the firing strength w k of all sub networks in the layer 2 of the anfis model for each input x with dimension d where the maximum should be greater than threshold δ 7 max k 1 k w k δ d otherwise the sample x y is grouped into a set ϑ k and from this the operator generates a new sub network for each dimension μ a i k 1 x i η i k 1 i 1 d in order to increase the granularity of the partition of the feature space this new sub network is created only for each group that has a number of samples more than the user defined n grow and the premise parameters are initialized with the mean and standard deviation of the samples from the group while the consequent parameters are randomly initialized in the case that grow net did not add new rules split net divides into two new ones those sub networks with poor performance based on a predetermined threshold which represents the mean square error 8 e k 1 n k x y ϑ k y g x η θ 2 where n k represents the sample size of ϑ k and g x η θ corresponds to the output of layer 5 of anfis model to split a sub network grow net requires a minimum number of samples n split predefined by user and a mean square error greater than then the premise parameters are divided and the consequent parameters are randomly initialized finally the vanishnet operator deletes a sub network that has a poor performance or is modeling not a sufficient amount of data points according to a threshold λ user defined this makes possible to eliminate networks created in the previous steps whose contribution to the model are not significant this operators works when variable age k an auxiliary variable that increases by one if the sub network models no data reached the hyper parameter λ the operators are executed iteratively and this iteration stops when new sub network is not created after that the next step adjusts the premise and consequent parameters of the remaining sub networks a summary of these operators is showed in fig 4 3 methods and materials 3 1 study region the data was collected from the diguillín river watershed in san lorenzo atacalco chile sub watershed of the diguillín river located between latitudes 36 48 s 37 03 s and longitudes 71 19 w 72 22 w with a drainage area of 208 49 km 2 its topography shows that it has elevations ranging from 100 to 3175masl meters above sea level in the eastern limit the highest areas constitute a small portion corresponding to snow and glaciers it also has a smaller area associated with agricultural uses but most of the watershed corresponds to forests meadows and thickets fig 5 the main channel of this sub watershed is the diguillín river which is born in the southwest base of the nevados de chillán volcanic complex and covers a length of 35 04 km that gives rise to the nevados de chillán valley zúñiga et al 2012 the diguillín river is inserted in ñuble region has a total route of 102 km to its confluence with the itata river and forms one of the three sub watersheds figueroa et al 2014 the diguillín river watershed has an average annual rainfall of 1875 mm during winter rain with significant rainfall between the months of may and august plus a period of thaw during spring and early summer with respect to temperatures it has a monthly average of 12 4 c with a range between 6 c in winter and 20 c in summer morales calderón et al 2014 as for its geology it is influenced by volcanic processes associated with the volcanic complex volcan chillán which would have formed different geological units along approximate 650 km and which are associated with fractured rocks the existence of volcanic rocks explains the behavior of groundwater and the formation of a recharge zone associated with the watershed on the other hand the presence of fluvio glacial deposits and sedimentary rocks denotes quite permeable areas that would favor the formation of aquifers zúñiga et al 2012 average daily rainfall and average daily runoff of watershed fig 6 recorded by fundo atacalco from years 2000 to 2018 were collected from the chilean directorate of water resources dga as it can be seen the average daily rainfall was higher in the first ten years having as maximum peak in the year 2002 and minimum peak in 2010 fig 6a in fact it should be taken into account that since 2010 an uninterrupted sequence of dry years with annual rainfall deficits ranging from 25 to 45 has prevailed in central chile giving an event series called megadrought md this is the longest continuous dry spell in the historical record 1915 onward and it coincided with a very warm decade in the interior valleys of central chile and the subtropical andes garreaud et al 2017 in contrast the average daily runoff was as diverse as average daily rainfall during the first 5 years the runoff values were higher but with a progressive decrease and with extreme minimum values in 2013 and 2017 in addition isolated peaks are observed in 2002 and 2006 fig 6b fundo atacalco station is located in 36 55 03 latitude 71 34 53 longitude stemberga 2017 rainfall measurements were made using a hellman rain gauge meanwhile runoff measurements were made with a limnimeter in diguillín river station in san lorenzo 3 1 1 validation watershed to evaluate the reproducibility of the model proposed and developed under the conditions of the diguillín river watershed the configuration obtained was applied in another watershed with a different set of observed data on rainfall and runoff this data was collected from colorado river watershed in maule region chile located inside the lontué river sub watershed and is controlled by the colorado river pluviometric station in junta con palos located at 35 16 28 latitude and 71 00 10 longitude with a drainage area of 878 km 2 fig 7 niemeyer fernández 1980 c i c en ingeniería 2004 the topography of this watershed shows that it has elevations ranging from 656 to 4065masl in the eastern limit argentina the highest areas make up a portion corresponding to snows and glaciers with a high presence of bare soils the main channel of this sub basin is the colorado river which is born at the foot of the las mulas hill and is located in the province of curicó maule region it has a total route of 78 km until its confluence with the lontué river forming part of its sub basin niemeyer fernández 1980 average daily rainfall recorded by monte oscuro station latitude 35 07 30 and longitude 70 58 43 and average daily runoff from the colorado river watershed from years 1999 to 2017 fig 8 were collected from the dga 3 2 experiments 3 2 1 parameter levels for self identification of rainfall and runoff relevant lags to develop the first step of the model it is necessary to set some parameters required in the self identification of relevant lags based on previous studies and knowledge expert we choose the parameters showed in table 1 at the same time that ten repetitions were performed to evaluate the consistency of the lags found the automatic selection of lags in addition to provide the input required for runoff prediction is expected to produce a certain degree of multi collinearity due to both the relationship between precipitation and the generated runoff as well as the dependence on the daily average runoff levels of the previous days however this tends to significantly affect predictions when the predictive method is a linear regression model but with low impact on non linear prediction models an alternative for dealing with multi collinearity is to use models such as neural networks since they have a better fit and a lower mean square error garg and tai 2013 obite et al 2020 thus using a model that combines fuzzy logic with neural networks in addition to the non linear method used for selection of lags it is generally safe to ignore the possible effect of multi collinearity 3 3 parameter levels for the self identification of fuzzy rules once the relevant lags of each time series model parameters were selected two experiments were carried out dividing the time series into two non overlapping segments training and validation set in the first experiment the initial fifteen years of data was considered as training set and the last 3 years as validation set in the second the former seventeen years were used for the training set and the last year was used for the validation set such setup was done aiming to evaluate the ability of the sinfim method for predicting runoff in any season of the year having january as the beginning of summer and december as the end of spring hence one year has been selected as the validation period experiment 2 on the other hand three years were selected as the validation set to evaluate the performance of the model in predicting the runoff values considering more than one period experiment 1 for the purpose of choose the best parameters combination to develop the self identification of fuzzy rules for each experiment a factorial design was conducted carried out with the parameter levels as showed in table 2 considering n split n grow and n vanish n grow 270 parameter combinations could be obtained which were compared using mean square error mse 9 mse 1 n i 1 n y i y i 2 where y i is the vector of observed runoff values and y i id the vector of predicted runoff values due to mega drought in the last periods rainfall events represent in many cases extreme values that affect runoff levels therefore the selection of parameters for the neuro fuzzy model was made to make the algorithm sensitive to these extreme values this differentiates it from the original model proposed by allende cid et al 2016 where the adjustment of the parameters had as one of its objectives the stabilization of the model to increase its robustness 3 4 comparison with other approaches in the interest of comparing the proposed framework other approaches were applied using the same relevant lags found 1 anfis this model was developed considering the number of membership functions also gaussian type and number of epochs found in sinfim method but without the self identification of fuzzy rules 2 artificial neural network ann a feed forward neural network was developed considering the number of membership functions found with sinfim method as hidden neurons size 3 long short term memory lstm to develop this deep learning model a factorial design was previously carried out to evaluate the most suitable set of hyperparameters hidden layers size 10 30 50 mini batch size 4 12 16 32 64 epochs 50 100 200 300 optimizer rmsprop sgd adam and a activation function type linear the combination that showed the best result was 50 hidden layers 100 epochs of training 32 mini batch size and an optimizer adam 3 5 performance measures to compare the proposed framework with the other considered models were considered the following performance measures coefficient of determination r 2 10 r 2 i 1 n y i y i y i y i i 1 n y i y i 2 i 1 n y i y i 2 2 where y i corresponds to average of predicted runoff r 2 values are in the interval 0 1 in general a value close to 1 indicates a good fit of the data and a high percentage of variability explained by the model nash sutcliffe efficiency nse 11 nse 1 i 1 n y i y i 2 i 1 n y i y i 2 where y i is the average of observed runoff nse is a normalized statistic that determines the relative magnitude of the residual variance compared to the measured data variance hence nse 1 corresponds to a perfect match of the model to the observed data according to molnar 2011 nse values can be interpreted as follows 0 2 insufficient model 0 2 0 4 satisfactory model 0 4 0 6 good model 0 6 0 8 very good model and 0 8 as an excellent model percent bias pbias 12 pbias 100 i 1 n y i y i i 1 n y i pbias measures the average tendency of the simulated values to be larger or smaller than their observed ones the optimal value of pbias is 0 with low magnitude values indicating accurate model simulation positive values indicate overestimation bias whereas negative values indicate model underestimation bias based on moriasi et al 2007 the model can be analyzed as follows pbias 10 very good 10 pbias 15 good 15 pbias 25 satisfactory and pbias 25 unsatisfactory kling gupta efficiency kge 13 kge 1 r 1 2 σ pred σ obs 1 2 y i y i 1 2 where r is the linear correlation between observed and predicted values while σ obs and σ pred represent the standard deviation of observed and predicted runoff values respectively kge ranges from to 1 where a value closer to 1 indicates a good accuracy for the model knoben et al 2019 once the model parameters were selected each experiment was executed 10 times and results were presented in tables as mean standard deviation to show the relationship between observed and predicted values using the trial with the best result in both training and validation set were constructed scatter plots with 95 confidence intervals around the estimated regression line using bootstrap with 1000 resamples 4 results 4 1 relevant lags and selection of parameter levels for the self identification of fuzzy rules the first step of the framework gave the relevant lags to predict q t 1 through a self identification model obtaining x t and q t q t 1 q t 2 q t 3 as rainfall x and runoff q time series relevant lags respectively once the input set was selected a previous step was executed to include runoff missing values this forecasting was made considering the previous values as a training set to predict the missing values after all of them had been estimated the experiments were carried out as described in methods and materials on the other hand missing rainfall values were imputed with the average value of observed rainfall in other stations with the input set the parameter levels for the self identification of fuzzy rules were evaluated and the combinations with best performance are shown in table 3 for the first experiment and table 4 for the second experiment in the first experiment using the last 3 years as a validation set the combination number one showed the best mse result while the minimum mse value was obtained in combination twenty when only the last year was used as validation set in the second experiment as a result both combinations represent within the options contemplated the best set of parameters to model the rainfall runoff relationship with the dataset used 4 2 runoff forecasting in this section the performance of sinfim to model rainfall runoff relationship of a chilean watershed is shown and compared with the other approaches the results using the last three years as a validation set experiment one are showed in table 5 sinfim showed the best performance in almost all measures highlighting its minimum value of mse and the highest r 2 nse and kge results are highlighted followed by ann and anfis models lstm showed the worst performance with the highest mse and lowest r 2 and nse values see table 6 despite having a good behavior compared to the other algorithms the sinfim framework presents a 71 adjustment leaving still 29 of total variance that is not explained by it in fact fig 9 shows that although in the majority of the validation set there is a good estimation when using the last 3 years as a validation set there are certain points where the model fails to reach the flow peaks while in others it has to overestimate the values this lack of adjustment can be observed in fig 10 in this figure it can be seen that although most of the points are within the confidence bands there are still many scattered values that are not predicted correctly however this overestimation is not large since the average pbias obtained was less than 10 and its nse described it as good model using last year as validation set showed the same pattern observed in experiment one sinfim had the best performance in all measures followed by ann and anfis nevertheless the measure results were better reducing the mse value and increasing r 2 around 84 nse and kge values indicating that sinfim is an excellent model with a good accuracy to determine the relationship between rainfall and runoff in fig 11 a very good performance is observed thorough all data with the exception of two points where an overestimation followed by an underestimation of runoff occurs respectively but it s only two out of 364 runoff values from the validation set therefore the model has proven to be a good alternative for predicting of runoff at any time of the year this good fit can be seen in the fig 12 backing up the nse result that asserts sinfim as a remarkable alternative as a model the figure shows that only less than 10 points fall out of the confidence interval indicating a good adjustment and subsequently a satisfactory prediction of the runoff values 4 2 1 watershed validation results since the configuration obtained in experiment number two with the diguillín river basin where only the last year was used as a validation period showed the best result with the sinfim method this same configuration was applied to validate its performance with another watershed in this case the colorado river watershed the sinfin method in its first stage a configuration of input components similar to the diguillín river watershed was obtained x t and q t q t 1 q t 2 q t 3 as rainfall x and runoff q time series relevant lags respectively the results obtained in the predictive module are shown in table 7 with the exception of the mse values of the training set a considerable improvement is observed in all performance metrics compared to the results obtained by the sinfim method in the diguillín river watershed a high percentage of adjustment was obtained reaching 94 in the validation set in addition to high nse and kge indices this good fit is observed in fig 13 where the method can predict low medium and high flows in addition to predicting the consecutive increase in flow observed from day 260 also there are few points where the sinfim method does not achieve an optimal runoff prediction with little scattered values fig 14 5 discussion in this work a self identification neuro fuzzy inference framework to model the rainfall runoff relationship in a chilean watershed is introduced as a means to decrease the uncertainty associated with the selection of inputs and the number of membership functions required in the fuzzy system although the basin used to evaluate and develop the proposed method was the diguillín river watershed the hyperparameter configuration obtained was used in colorado river watershed to validate its performance and evaluate its scalability in both experiments the proposed method achieved a superior performance to the other evaluated predictive models such as anfis ann and lstm obtaining the best results when using only one year as a validation set this may be mainly since the variability in the observations of rainfall and runoff decreases as the period to be evaluated is reduced considering also that the 3 years used as the validation set in experiment 1 are different from each other the accuracy obtained with one year as validation set was greater than 80 and higher than 90 in the watershed validation better than those reported by shoaib et al 2014 where a comparative study of different wavelet based neural network models for rainfall runoff modeling was presented although the authors highlighted the advantage of pre processing the time series by extracting features with the wavelet transformation as other studies vivas et al 2019 in addition to the choice of the mother wavelet to improve performance the proposed model shows a better nse values and a higher r 2 in all cases similarly our results indicate better performance metrics than those reported by behmanesh and ayashm 2015 who assessed the rainfall runoff relationship in a basin in mississippi applying ann and anfis as predictive models the proposed method outperforms the results by kumar et al 2016 who applied a traditional ann to forecast runoff this results might suggest that the ann and anfis model by themselves do not generate a good prediction of runoff given the complexity of its relationship with rainfall in addition to having other influential factors such as temperature or soil saturation researches such as nath et al 2019 nourani et al 2011 or anusree and varghese 2016 presented an optimized algorithm using different input combinations one of the main advantages of our proposal is that it includes a module for identifying relevant lags so that an a priori selection of the input elements to the predictive model is not required although there are other methods for the selection of the input elements of the rain time series and runoff used in neuro fuzzy models such as partial autocorrelation function pacf nath et al 2019 xie et al 2019 cross correlation analysis cca chang et al 2017 entropy analysis nourani et al 2015 or mutual information mi may et al 2008 we consider that proposed algorithm in this study is more advantageous because its structure is developed with a focus on identify lags in a nonlinear environment such as in fuzzy systems veloz et al 2016 although deep learning dl approaches have shown great performances in modeling the relationship between rainfall and runoff in different watersheds and synthetic data hu et al 2018 kratzert et al 2018 li et al 2018 van et al 2020 according to our results the long short term memory lstm network developed showed the lowest performance as a forecasting models despite the fact that among the advantages of the lstm is its ability to learn long term dependencies between the provided input and output of the network kao et al 2020 the high variability of the observations in our case study might have influenced the performance of the model this could be explained because the data includes daily observations from all seasons of the year as well as a great period with little rain associated with the mega drought phenomenon that has been going through chile since 2010 garreaud et al 2017 in fact data heterogeneity in terms of quantities measured and scales have already been mentioned as an difficult aspect to directly implement existing results obtained on hydrological deterministic experiments marçais and de dreuzy 2017 furthermore the proposed model in this study has shown comparable performance with works as alike as jothiprakash et al 2009 showed several models with good performances through varying the number of membership functions and combinations in the time series although in some of these models the r 2 performance was higher than that obtained in our study they have the drawback that the user has to set the number of membership functions while sinfim does it automatically similarly our performance results are lesser than the second of the architectures proposed by nourani et al 2013 who presented a fusion between the wavelet transformation with anfis model with a r 2 of 90 this could be mainly due to the characteristics of the watersheds under study nourani et al 2013 used data from watersheds located in iran whose daily maximum runoff values do not exceed 90 m 3 s while rainfall is less than 40 mm in our work the hydrological conditions are more variable having precipitation values that reach 233 mm and runoff rates up to 544 m 3 s therefore the ability of sinfim to model extreme runoff values given a rainfall event is highlighted a fact that can be seen in figs 9 and 11 where the model successfully predicts runoff peaks greater than 150 m 3 s in addition sinfim stands out for not requiring the pre processing of the time series to obtain a good performance which facilitates its application and that would allow a more direct understanding of the predicted runoff values from the results obtained in our work we must not only emphasize its good performance compared to the state of the art alternatives but also the main advantage of applying a self organizing fuzzy system to predict the runoff in models like anfis expert knowledge is required to define the number of premises which is why many proposed approaches generate an initial set of rules based on a clustering technique in our case this step is not necessary since the algorithm itself defines the number of rules necessary to model the data set allende cid et al 2016 even when the parameters defined by the operators require some prior knowledge of the phenomenon under study this causes the reduction of uncertainty and error associated with the choice of such parameters in the fuzzy system also the number of rules can be controlled by setting the algorithm parameter properly creating a more parsimonious model these are very important if we consider that the possible results in the prediction of the runoff depend on other variables besides the rainfall such as the environmental conditions of humidity and the type of soil which can generate different rules in the premise depending on the watershed to study another relevant aspect to be pointed out is that there are few studies that examine the runoff rainfall relationship using a similar number of periods as used in this study as a database for example the works of nourani et al 2011 or asadi et al 2013 use a maximum of 12 years including training and validation sets in our case we used a total of 19 years so we increased the amount of rain drought and runoff events that the proposed algorithm could learn besides our proposal managed to efficiently grasp and model the variability of the runoff levels throughout the period unlike those reported by talei et al 2010 ghose et al 2013 or panchal et al 2014 which work only with rainy months or with specific precipitation events although the proposed framework has advantages in terms of the selection of input elements and the good performance obtained in modeling runoff also it should be noted that it fails to explain the entire process having approximately 16 variability not explained in the best of the scenarios according to the determination coefficients obtained this is due in part to the variability of the data used for training and to the presence of other influencing variables in the hydrological process such as temperature and land use among others in addition although the meteorological station used provides precipitation data with high incidence on runoff since it is located within the watershed area it is not completely representative of the total precipitation 29 according to the registered measurements of the thiesen polygons that is why for future studies other covariates such as temperature or height in addition to other meteorological stations should be considered to capture as much information as possible associated with rainfall however it should be noted that the distribution of meteorological stations throughout the basin area influences the capture of rainfall variability hence the colorado river watershed having a better meteorological stations distribution will generate a better runoff prediction therefore the inclusion of new covariates will depend on both the basin under study and the characteristics of the meteorological station an aspect to consider corresponds to the selection of the hyperparameters in ann anfis and lstm models it is well known that the selection of parameters prior to training can affect performance if they are not suitable for modeling with the data set under study probst et al 2019 van rijn and hutter 2018 torres et al 2003 in fact there are optimization tools such as harris hawks optimizer tikhamarine et al 2020 particle swarm optimization feng et al 2020 tikhamarine et al 2020 genetic algorithm dodangeh et al 2020 or grey wolf optimization dehghani et al 2019 among others that allow the optimal selection of these values to achieve the best performance however in this work the selection of hyperparameters was made based on the experience of the researchers and the number of fuzzy rules obtained in sinfim method thus it is possible to further improve the performance of these models nevertheless evaluating optimization algorithms for each of the models used and comparing them with the proposed method could be include in a future work however these models were used as substitutes for the runoff prediction module in sinfim so the uncertainty associated with the selection of the input values was reduced with the implementation of the sifar model finally this work represents one of the first studies in which a neuro fuzzy model is applied to predict the runoff in a chilean watershed so it provides the region with a useful tool to make decisions about land use and availability of water resources among others our main contribution is to provide a method to engineers and other professionals involved in the management of water resources and environmental planning which allows to predict the runoff values of the diguillín river watershed regardless of the season and conditions of drought or rain and which in turn implies capturing the uncertainty associated with the runoff rainfall relationship we proposed to extend the application of the framework to other watersheds in the country and optimize the elements of the input space and the thresholds used in the algorithm operators 6 conclusion in this work a new framework called self identification neuro fuzzy inference model sinfim for predicting one day ahead runoff in a chilean watershed was proposed specific findings of this study include 1 sinfim method has shown better performance than other methods such as anfis ann and lstm for predicting one day ahead runoff achieving an adjustment higher than 80 in the watershed under study and higher that 90 in the watershed validation in addition nash sutcliffe efficiency and percent bias indicate that sinfim is a promising model 2 the proposal by automatically identifying the lags and the fuzzy rules required in a neuro fuzzy system allows the reduction of the error and uncertainty associated with user setting parameters 3 sinfim method can predict any runoff value regardless of the season of the year managing to estimate low medium and peak runoff values also time series datasets do not need a pre processing step to be included in the model as input although the proposed method has good performance indicators in the prediction of flow it cannot fully explain the variability associated with the phenomenon under study being mostly observed in the diguillín river watershed which showed a maximum of 84 adjustment however this adjustment was greater in the basin used in the validation of the method thus the characteristics of the basin affect the prediction of runoff requiring in some cases to include other covariates that would contribute to improving performance the main limitation of this study is that no optimization algorithm was applied to obtain the hyperparameters in the models used to compare the sinfim and this could affect their performances only in the lstm a factorial design with a grid of options was made that is why the evaluation of models that allow obtaining the optimal hyperparameters of the methods used will be considered in future research however even using these models as runoff prediction approach the uncertainty in the selection of lags was addressed considering the automatic selection carried out with the sifar model finally although this study worked with two watersheds the diguillń river for the development of the method and the colorado river for its validation it is necessary to apply the sinfim method in other basins with different characteristics both in chile and in other countries to evaluate their performance furthermore it is interesting to evaluate the method in the multi step ahead runoff prediction scheme however with the preliminary results obtained in this study we can conclude that the proposed method represents a good alternative in runoff one day ahead prediction thus constituting a useful tool for professionals involved in environmental planning credit authorship contribution statement yerel morales conceptualization methodology software validation formal analysis investigation resources writing original draft writing review editing visualization marvin querales conceptualization methodology software validation formal analysis investigation resources writing original draft writing review editing visualization harvey rosas conceptualization methodology validation formal analysis investigation writing review editing visualization héctor allende cid methodology validation formal analysis investigation writing review editing rodrigo salas conceptualization supervision methodology software validation formal analysis investigation resources writing review editing visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
4838,modeling the relationship between rainfall and runoff is an important issue in hydrology but it is a complicated task because both the high levels of complexity in which both processes are embedded and the associated uncertainty affect the forecasting neuro fuzzy models have emerged as a useful approach given the ability of neural networks to optimize parameters in a fuzzy system in this work a self identification neuro fuzzy inference model sinfim for modeling the relationship between rainfall and runoff on a chilean watershed is proposed to reduce the uncertainty of selecting both the rainfall and runoff lags and the number of membership functions required in a fuzzy system the data comes from the diguillín river located in ñuble region and average daily runoff and average daily rainfall recorded from years 2000 to 2018 according to the chilean directorate of water resources dga in addition we worked with the colorado river basin located in the maule region to validate the method developed the experimental results showed a good adjustment using the last 3 years as validation set further improvement was achieved using only the last year was used as validation test obtaining 84 of r 2 and 0 91 kling gupta efficiency higher than other forecasting models such as adaptive neuro fuzzy inference system anfis artificial neural networks ann and long short term memory lstm approach in addition nash sutcliffe efficiency and percent bias indicate the method is a promising model on the other hand even better results were obtained in the validation basin whose adjustment was 94 and an efficiency of 97 therefore the proposed model is a solid alternative to forecast the runoff in a given watershed obtaining good performance measurements managing to predict both the low and peak runoff values from rainfall events avoiding the requirement to determine a priori the lags of time series and the number of fuzzy rules keywords rainfall runoff modeling neuro fuzzy model sinfim framework 1 introduction hydrological models are key tools for water and environment resource management they represent hydrological processes and evaluate conditions for urban and environmental planning such as land use flood and water resources management of watersheds nourani et al 2013 a popular approach is modeling the relationship between rainfall and runoff process using a set of equations that explain runoff as a function of rainfall and may include other parameters used to describe watershed characteristics masseroni et al 2017 although there is a cause and effect relationship between both processes rainfall runoff modeling with high accuracy is affected by its non linear behavior associated with the complex characteristics of the water cycle adnan et al 2019 in addition to rainfall runoff depends on many other factors such as initial soil moisture land use basin geomorphology evaporation infiltration distribution and rainfall duration atc 2000 there are several approaches to model a the rainfall runoff relationship methods like simple and multiple regression models auto regressive moving average arma the lumped process oriented deterministic bucket style models artificial neural networks and distributed physics models are part of them beven 2011 anusree and varghese 2016 each of these approaches has its own advantages and drawbacks but the reduction of the predictive uncertainty of the model is considered as one the paramount elements to be considered masseroni et al 2017 gopalan et al 2019 this uncertainty can be incorporated taking into account measurement of the input variables such as rainfall and temperature as well as the selection of the parameter values used in the model since they depend on the climatic conditions even the choice of the structure of the model establishing governing equations by itself implies uncertainty knoben et al 2019 in fact in a recent work a large number of researchers looking for greater harmonization on research efforts identified that the mechanism to disentangle and reduce the structural uncertainty of the model parameter input in hydrological prediction as one of main unresolved problems in hydrology blöschl et al 2019 fuzzy logic has emerged as useful approach to model phenomena with some degree of uncertainty including hydrological processes the main idea is to consider variables in a linguistically uncertain manner rather than numerical precise quantities sen and altunkaynak 2004 moraga and salas 2005 a neuro fuzzy model is a structure in which the neural network uses training data to determine the membership functions and fuzzy rules of a fuzzy logic system zahedi and zahedi 2018 this allows to have a fuzzy system to represent the process in an interpretable way thus mitigating both individual approaches drawbacks the neural networks black box behavior and the problems of finding suitable membership values for fuzzy systems kumari and sunita 2013 many neuro fuzzy systems are based on takagi sugeno kang structure because they allow the application of gradient descent learning as long as differentiable membership functions are used nauck and nürnberger 2013 one of the first and popular neuro fuzzy systems is the adaptive network based fuzzy inference system anfis model proposed in 1991 by jang 1993 widely applied in rainfall runoff modeling anusree and varghese 2016 jothiprakash et al 2009 ghose et al 2013 panchal et al 2014 although anfis model has shown good results its algorithm employs offline learning which suffers from increased computational time and requires retraining to capture recent changes of the system moreover the number of rules is predefined by the user and overfitting is a common problem when the data are overtrained in fact every data set that is trained using anfis has its maximum number of epochs before overfitting occurs al hmouz et al 2011 with the idea of optimizing the anfis prediction a series of hybrid models have been proposed zhou et al 2019 proposed an evolutionary recurrent anfis for modelling multi step ahead flood forecasts embedded with genetic algorithm ga and least square estimator gl bartoletti et al 2018 proposed a combination between principal component analysis pca and anfis model with the emphasis on how to set up an efficient data structure that produces a good output flow estimation pca approach provides some degree of freedom by choosing the number of components to keep allowing a trade off between accuracy and network complexity meanwhile nourani et al 2011 proposed to apply a wavelet transformation in the input time series and then introduce different scales in the anfis model to obtain the runoff prediction in a structure called wanfis the wavelet transform provides useful decomposition of the main time series rainfall and runoff in this case to improve the forecasting a recent modified adaptive neuro fuzzy inference system for runoff estimation was proposed by nath et al 2019 this work was focused on reducing the computational complexity of anfis by incorporating the particle swarm optimization pso algorithm in a framework called pso anfis which was used for estimating the parameters pertaining to anfis other optimized approaches such as anfis ant colony optimization for continuous domain anfis acor azad et al 2018 anfis grey wolf optimizer gwo anfis gwo dehghani et al 2019 or anfis genetic algorithms anfis ga ghose et al 2013 have been proposed with their own advantages and applicability recently an extension of anfis model called self organization neuro fuzzy inference system sonfis has been proposed by allende cid et al 2016 2008 although the neural network structure has the same layers as the anfis model the learning process incorporates mathematical operators to define the number of fuzzy rules required in the system in other words the network automatically organizes itself to identify the set of takagi sugeno kang type rules necessary to model the data set since the relationship between rainfall and runoff has a degree of uncertainty it may decrease if the number of membership functions and the respective rules are not set in advance this model has been used with financial and experimental data sets but it has not been used for modeling hydrological phenomena which serves as motivation for its use in runoff prediction on the other hand the selection of lags of both time series rainfall and runoff is a key pre processing step in day ahead forecasting runoff events the literature suggests among the most common methods for lag selection methods the partial autocorrelation function pacf nath et al 2019 xie et al 2019 tran et al 2017 rizeei et al 2018 cross correlation analysis cca or micca a combination of these last two chang et al 2017 nevertheless these functions locate the lags based on their linear dependence with the value to be predicted so that for phenomena with non linear behaviors algorithms with a more flexible structure can identify the most optimal lags nourani et al 2011 other approaches used in hydrology are entropy analysis nourani et al 2015 mutual information mi may et al 2008 and algorithms that might involve dimensionality reduction such as the gamma test singh et al 2018 pca or clustering methods remesan et al 2018 furthermore in recent years methods based on machine learning have been presented as alternatives for the selection of suitable inputs such as the input variable selection proposed by taormina and chau 2015 that employs an algorithm which combines binary coded discrete fully informed particle swarm optimization bfips and extreme learning machines elm more recently in 2016 veloz et al 2016 proposed sifar self identification of lags of an autoregressive takagi sugeno kang based model as a method to find the most influential lags of a fuzzy model for time series applications sifar algorithm has not been used in hydrology and provides a local representation which allows the description of a nonlinear system using a set of simple mathematical functions aggregated to describe the overall complexity that underlies its dynamic process in chile few studies have developed neuro fuzzy systems for rainfall runoff modeling implementing instead conceptual models which despite their usefulness in support decision making systems have several limitations such as the lack of consideration of the groundwater exchange or the assumption of environmental standard conditions parra et al 2018 therefore the aim of this work is to propose a new neuro fuzzy model for predicting runoff from rainfall measurements called self identification neuro fuzzy inference model sinfim in a chilean watershed the novelty of this method is that it allows reducing the uncertainty associated with the runoff forecasting regarding inputs and hyperparameters selection because it finds the relevant rainfall and runoff lags for a neuro fuzzy system which in turn automatically identifies the number of rules necessary to model the phenomenon this framework is our main contribution to professionals involved in the management of watershed resources to make appropriate decisions in environmental planning the paper is organized as follows next section section 2 presents the hybrid framework used to model the rainfall runoff relationship describing the models involved in the algorithm then the description of the dataset experiments and the performance measures used are in methods and materials section 3 section 4 presents experimental results and section 5 some discussion finally section 6 concludes with some remarks 2 self identification neuro fuzzy inference model sinfim self identification neuro fuzzy inference model sinfim is presented as method to forecast day ahead runoff events this framework reduces the uncertainty associated with the lags and hyperparameters selection in a fuzzy system fig 1 the proposed algorithms involve the following components 1 self identification of rainfall and runoff lags using a model based on a fuzzy partitioning or clustering of each input uni dimensional time series the more relevant rainfall x and runoff q lags to predict q t 1 are selected 2 adaptive neuro fuzzy inference system relevant lags selected in the previous step are the inputs for an adaptive neuro fuzzy inference system which involves a fuzzy model with a hybrid learning algorithm and a predefined number of membership functions this model serves as the fundamental structure to predict q t 1 3 self identification of fuzzy rules once the base neuro fuzzy model is obtained a series of mathematical operators are iteratively applied in order to identify the number of fuzzy rules required to model the relationship between rainfall and runoff with the best performance then the consequent parameters are updated and finally the output is predicted 2 1 self identification of rainfall and runoff lags the proposed framework begins with the identification of the most influential lags for each time series considered rainfall and runoff for this a model based on the component of sifar method proposed by veloz et al 2016 associated with lags relevance evaluation is developed this model represents a set of local predictors in order to define different sub domains along the lag space the process is summarized in fig 2 above the time series x t is a stochastic process whose samples are observed in regular time intervals ranging from t 1 t for selection of lags sifar model used a nonlinear autoregressive relationship x t f x t 1 x t d where d is the maximum expected order of the time series model and is user defined for notation purposes a time series is arranged in a regressor matrix x x kj n x d with n t d and a target vector y x d 1 x t the j th column of x is given by x d 1 j x t j the k th row of the matrix x and the k th element of the vector y are denoted as x k and y k respectively the first step is to apply fuzzy c means fcm in the target space y using the entire dataset generating a local domain and considering only those values belonging to this region with a high degree of membership x the number of partitions in both spaces is defined in advance and v v 1 v n 0 represents the cluster prototypes where n 0 is the number of clusters in which the target space is partitioned after that the possibility distribution is computed for each cluster h th as follows 1 t hk 1 p 1 n y k v h y k v p 2 η 1 with 1 h n o and 1 k n y k represents the k th element of the target vector y while η is user defined usually set to 2 the third step computes scale parameters σ 1 σ n 0 using the diagonal elements of the fuzzy covariance matrix 2 σ h 2 k 1 n t hk m y k v h 2 k 1 n t hk m afterwards for each obtained cluster an α cut set o α 1 o α h o α n 0 is computed where o α h y k y μ h y k α 0 constitutes the most representative and similar data samples the following step consists of applying the initial procedures to each α cut generated in the regressor space that is applying the fcm technique and obtaining the cluster centers in addition of calculating their possibility distribution and scale parameters the set of cluster prototypes obtained are denoted by v h v 1 h v n in h where v i h v ij h corresponds to the i th cluster prototype vector associated with the h th α cut obtained in the target space and v ij h represents its element associated with the j th lag through 3 t ik h 1 p 1 n x k v i h x k v p h 2 η 1 i k k the possibility distribution is computed where i is the indicator function based on it the scale parameters σ ij are computed using the equation 4 σ ij h k k t ik h m x kj v ij h 2 k k t ik h m where x kj corresponds to the j th lag variable of the k th element of the process and v ij h are the set of cluster centers the next step consists in evaluating the contribution to local smooth mapping between the regressor and target spaces of each lag with the following equation 5 r h j k in h k 0 h where k 0 h k y k o α h k in h k x k i α h i α h i 1 n in x k x y k o α h w i h x k α in constitutes the cardinality of the resulting set and w i h the strength level for the i th cluster in the regressor space the set of lags is ordered according to r j j 1 d results and the first q elements are taken this selection could involve redundant partitions which later will be removed based on the similarity of μ ij membership functions two clusters will be merged if the result of the supremum minimum composition s j i 1 i 2 sup min μ i 1 j μ i 2 j with i 1 i 2 1 n and i 1 i 2 is greater than or equal to a threshold α f defined by the user in this step and after applying the entire the algorithm for each uni dimensional time series rainfall and runoff the relevant and non redundant lags are selected 2 2 adaptive neuro fuzzy inference system once the most relevant rainfall and runoff lags are selected they constitute of a neuro fuzzy model to predict one day ahead runoff events for this a model based on the adaptive neuro fuzzy inference system anfis proposed in 1993 by jang 1993 is developed it is a special feed forward neural network and its fundamental axis is to model the phenomenon based on the fuzzy takagi sugeno kang rules of the form 6 r r if x 1 is μ j 1 1 and and x n is μ j n n then y β o r β 1 r x 1 β n r x n where μ j i is the degree to which an input x i satisfies a linguistic quantifier calculated using a certain membership function that involves a set of parameters η called premises depending on this degree of membership the output y is determined and its parameter vector θ containing the parameters β in the linear equation is called consequent the network implies five components layers layer 1 associates each input to a certain fuzzy set through a gaussian type membership function in layer 2 the and t norm operator is used to obtain the strength of each of the rules specified in layer 1 which will later be normalized in layer 3 the layer 4 computes the contribution of each rule using both consequent parameters and layer 3 output vector finally the layer 5 computes the weighted global output of all the incoming signals fig 3 once the base architecture is constructed with a predefined number of nodes for each layers a hybrid learning is developed this is an ordinary least square ols estimation is used to determine the consequent parameters and the back propagation learning algorithm to estimate the premise parameters 2 3 self identification of fuzzy rules after the anfis hybrid learning is developed a series of mathematical operators proposed by allende cid et al 2016 are iteratively applied in order to automatically identify the number of rules required to model the dataset grownet split membership functions and vanish membership functions fig 4 grow net is the first operator to run and it evaluates if the current fuzzy rules sub networks work well according to the user predetermined threshold δ this comparison is based on the firing strength w k of all sub networks in the layer 2 of the anfis model for each input x with dimension d where the maximum should be greater than threshold δ 7 max k 1 k w k δ d otherwise the sample x y is grouped into a set ϑ k and from this the operator generates a new sub network for each dimension μ a i k 1 x i η i k 1 i 1 d in order to increase the granularity of the partition of the feature space this new sub network is created only for each group that has a number of samples more than the user defined n grow and the premise parameters are initialized with the mean and standard deviation of the samples from the group while the consequent parameters are randomly initialized in the case that grow net did not add new rules split net divides into two new ones those sub networks with poor performance based on a predetermined threshold which represents the mean square error 8 e k 1 n k x y ϑ k y g x η θ 2 where n k represents the sample size of ϑ k and g x η θ corresponds to the output of layer 5 of anfis model to split a sub network grow net requires a minimum number of samples n split predefined by user and a mean square error greater than then the premise parameters are divided and the consequent parameters are randomly initialized finally the vanishnet operator deletes a sub network that has a poor performance or is modeling not a sufficient amount of data points according to a threshold λ user defined this makes possible to eliminate networks created in the previous steps whose contribution to the model are not significant this operators works when variable age k an auxiliary variable that increases by one if the sub network models no data reached the hyper parameter λ the operators are executed iteratively and this iteration stops when new sub network is not created after that the next step adjusts the premise and consequent parameters of the remaining sub networks a summary of these operators is showed in fig 4 3 methods and materials 3 1 study region the data was collected from the diguillín river watershed in san lorenzo atacalco chile sub watershed of the diguillín river located between latitudes 36 48 s 37 03 s and longitudes 71 19 w 72 22 w with a drainage area of 208 49 km 2 its topography shows that it has elevations ranging from 100 to 3175masl meters above sea level in the eastern limit the highest areas constitute a small portion corresponding to snow and glaciers it also has a smaller area associated with agricultural uses but most of the watershed corresponds to forests meadows and thickets fig 5 the main channel of this sub watershed is the diguillín river which is born in the southwest base of the nevados de chillán volcanic complex and covers a length of 35 04 km that gives rise to the nevados de chillán valley zúñiga et al 2012 the diguillín river is inserted in ñuble region has a total route of 102 km to its confluence with the itata river and forms one of the three sub watersheds figueroa et al 2014 the diguillín river watershed has an average annual rainfall of 1875 mm during winter rain with significant rainfall between the months of may and august plus a period of thaw during spring and early summer with respect to temperatures it has a monthly average of 12 4 c with a range between 6 c in winter and 20 c in summer morales calderón et al 2014 as for its geology it is influenced by volcanic processes associated with the volcanic complex volcan chillán which would have formed different geological units along approximate 650 km and which are associated with fractured rocks the existence of volcanic rocks explains the behavior of groundwater and the formation of a recharge zone associated with the watershed on the other hand the presence of fluvio glacial deposits and sedimentary rocks denotes quite permeable areas that would favor the formation of aquifers zúñiga et al 2012 average daily rainfall and average daily runoff of watershed fig 6 recorded by fundo atacalco from years 2000 to 2018 were collected from the chilean directorate of water resources dga as it can be seen the average daily rainfall was higher in the first ten years having as maximum peak in the year 2002 and minimum peak in 2010 fig 6a in fact it should be taken into account that since 2010 an uninterrupted sequence of dry years with annual rainfall deficits ranging from 25 to 45 has prevailed in central chile giving an event series called megadrought md this is the longest continuous dry spell in the historical record 1915 onward and it coincided with a very warm decade in the interior valleys of central chile and the subtropical andes garreaud et al 2017 in contrast the average daily runoff was as diverse as average daily rainfall during the first 5 years the runoff values were higher but with a progressive decrease and with extreme minimum values in 2013 and 2017 in addition isolated peaks are observed in 2002 and 2006 fig 6b fundo atacalco station is located in 36 55 03 latitude 71 34 53 longitude stemberga 2017 rainfall measurements were made using a hellman rain gauge meanwhile runoff measurements were made with a limnimeter in diguillín river station in san lorenzo 3 1 1 validation watershed to evaluate the reproducibility of the model proposed and developed under the conditions of the diguillín river watershed the configuration obtained was applied in another watershed with a different set of observed data on rainfall and runoff this data was collected from colorado river watershed in maule region chile located inside the lontué river sub watershed and is controlled by the colorado river pluviometric station in junta con palos located at 35 16 28 latitude and 71 00 10 longitude with a drainage area of 878 km 2 fig 7 niemeyer fernández 1980 c i c en ingeniería 2004 the topography of this watershed shows that it has elevations ranging from 656 to 4065masl in the eastern limit argentina the highest areas make up a portion corresponding to snows and glaciers with a high presence of bare soils the main channel of this sub basin is the colorado river which is born at the foot of the las mulas hill and is located in the province of curicó maule region it has a total route of 78 km until its confluence with the lontué river forming part of its sub basin niemeyer fernández 1980 average daily rainfall recorded by monte oscuro station latitude 35 07 30 and longitude 70 58 43 and average daily runoff from the colorado river watershed from years 1999 to 2017 fig 8 were collected from the dga 3 2 experiments 3 2 1 parameter levels for self identification of rainfall and runoff relevant lags to develop the first step of the model it is necessary to set some parameters required in the self identification of relevant lags based on previous studies and knowledge expert we choose the parameters showed in table 1 at the same time that ten repetitions were performed to evaluate the consistency of the lags found the automatic selection of lags in addition to provide the input required for runoff prediction is expected to produce a certain degree of multi collinearity due to both the relationship between precipitation and the generated runoff as well as the dependence on the daily average runoff levels of the previous days however this tends to significantly affect predictions when the predictive method is a linear regression model but with low impact on non linear prediction models an alternative for dealing with multi collinearity is to use models such as neural networks since they have a better fit and a lower mean square error garg and tai 2013 obite et al 2020 thus using a model that combines fuzzy logic with neural networks in addition to the non linear method used for selection of lags it is generally safe to ignore the possible effect of multi collinearity 3 3 parameter levels for the self identification of fuzzy rules once the relevant lags of each time series model parameters were selected two experiments were carried out dividing the time series into two non overlapping segments training and validation set in the first experiment the initial fifteen years of data was considered as training set and the last 3 years as validation set in the second the former seventeen years were used for the training set and the last year was used for the validation set such setup was done aiming to evaluate the ability of the sinfim method for predicting runoff in any season of the year having january as the beginning of summer and december as the end of spring hence one year has been selected as the validation period experiment 2 on the other hand three years were selected as the validation set to evaluate the performance of the model in predicting the runoff values considering more than one period experiment 1 for the purpose of choose the best parameters combination to develop the self identification of fuzzy rules for each experiment a factorial design was conducted carried out with the parameter levels as showed in table 2 considering n split n grow and n vanish n grow 270 parameter combinations could be obtained which were compared using mean square error mse 9 mse 1 n i 1 n y i y i 2 where y i is the vector of observed runoff values and y i id the vector of predicted runoff values due to mega drought in the last periods rainfall events represent in many cases extreme values that affect runoff levels therefore the selection of parameters for the neuro fuzzy model was made to make the algorithm sensitive to these extreme values this differentiates it from the original model proposed by allende cid et al 2016 where the adjustment of the parameters had as one of its objectives the stabilization of the model to increase its robustness 3 4 comparison with other approaches in the interest of comparing the proposed framework other approaches were applied using the same relevant lags found 1 anfis this model was developed considering the number of membership functions also gaussian type and number of epochs found in sinfim method but without the self identification of fuzzy rules 2 artificial neural network ann a feed forward neural network was developed considering the number of membership functions found with sinfim method as hidden neurons size 3 long short term memory lstm to develop this deep learning model a factorial design was previously carried out to evaluate the most suitable set of hyperparameters hidden layers size 10 30 50 mini batch size 4 12 16 32 64 epochs 50 100 200 300 optimizer rmsprop sgd adam and a activation function type linear the combination that showed the best result was 50 hidden layers 100 epochs of training 32 mini batch size and an optimizer adam 3 5 performance measures to compare the proposed framework with the other considered models were considered the following performance measures coefficient of determination r 2 10 r 2 i 1 n y i y i y i y i i 1 n y i y i 2 i 1 n y i y i 2 2 where y i corresponds to average of predicted runoff r 2 values are in the interval 0 1 in general a value close to 1 indicates a good fit of the data and a high percentage of variability explained by the model nash sutcliffe efficiency nse 11 nse 1 i 1 n y i y i 2 i 1 n y i y i 2 where y i is the average of observed runoff nse is a normalized statistic that determines the relative magnitude of the residual variance compared to the measured data variance hence nse 1 corresponds to a perfect match of the model to the observed data according to molnar 2011 nse values can be interpreted as follows 0 2 insufficient model 0 2 0 4 satisfactory model 0 4 0 6 good model 0 6 0 8 very good model and 0 8 as an excellent model percent bias pbias 12 pbias 100 i 1 n y i y i i 1 n y i pbias measures the average tendency of the simulated values to be larger or smaller than their observed ones the optimal value of pbias is 0 with low magnitude values indicating accurate model simulation positive values indicate overestimation bias whereas negative values indicate model underestimation bias based on moriasi et al 2007 the model can be analyzed as follows pbias 10 very good 10 pbias 15 good 15 pbias 25 satisfactory and pbias 25 unsatisfactory kling gupta efficiency kge 13 kge 1 r 1 2 σ pred σ obs 1 2 y i y i 1 2 where r is the linear correlation between observed and predicted values while σ obs and σ pred represent the standard deviation of observed and predicted runoff values respectively kge ranges from to 1 where a value closer to 1 indicates a good accuracy for the model knoben et al 2019 once the model parameters were selected each experiment was executed 10 times and results were presented in tables as mean standard deviation to show the relationship between observed and predicted values using the trial with the best result in both training and validation set were constructed scatter plots with 95 confidence intervals around the estimated regression line using bootstrap with 1000 resamples 4 results 4 1 relevant lags and selection of parameter levels for the self identification of fuzzy rules the first step of the framework gave the relevant lags to predict q t 1 through a self identification model obtaining x t and q t q t 1 q t 2 q t 3 as rainfall x and runoff q time series relevant lags respectively once the input set was selected a previous step was executed to include runoff missing values this forecasting was made considering the previous values as a training set to predict the missing values after all of them had been estimated the experiments were carried out as described in methods and materials on the other hand missing rainfall values were imputed with the average value of observed rainfall in other stations with the input set the parameter levels for the self identification of fuzzy rules were evaluated and the combinations with best performance are shown in table 3 for the first experiment and table 4 for the second experiment in the first experiment using the last 3 years as a validation set the combination number one showed the best mse result while the minimum mse value was obtained in combination twenty when only the last year was used as validation set in the second experiment as a result both combinations represent within the options contemplated the best set of parameters to model the rainfall runoff relationship with the dataset used 4 2 runoff forecasting in this section the performance of sinfim to model rainfall runoff relationship of a chilean watershed is shown and compared with the other approaches the results using the last three years as a validation set experiment one are showed in table 5 sinfim showed the best performance in almost all measures highlighting its minimum value of mse and the highest r 2 nse and kge results are highlighted followed by ann and anfis models lstm showed the worst performance with the highest mse and lowest r 2 and nse values see table 6 despite having a good behavior compared to the other algorithms the sinfim framework presents a 71 adjustment leaving still 29 of total variance that is not explained by it in fact fig 9 shows that although in the majority of the validation set there is a good estimation when using the last 3 years as a validation set there are certain points where the model fails to reach the flow peaks while in others it has to overestimate the values this lack of adjustment can be observed in fig 10 in this figure it can be seen that although most of the points are within the confidence bands there are still many scattered values that are not predicted correctly however this overestimation is not large since the average pbias obtained was less than 10 and its nse described it as good model using last year as validation set showed the same pattern observed in experiment one sinfim had the best performance in all measures followed by ann and anfis nevertheless the measure results were better reducing the mse value and increasing r 2 around 84 nse and kge values indicating that sinfim is an excellent model with a good accuracy to determine the relationship between rainfall and runoff in fig 11 a very good performance is observed thorough all data with the exception of two points where an overestimation followed by an underestimation of runoff occurs respectively but it s only two out of 364 runoff values from the validation set therefore the model has proven to be a good alternative for predicting of runoff at any time of the year this good fit can be seen in the fig 12 backing up the nse result that asserts sinfim as a remarkable alternative as a model the figure shows that only less than 10 points fall out of the confidence interval indicating a good adjustment and subsequently a satisfactory prediction of the runoff values 4 2 1 watershed validation results since the configuration obtained in experiment number two with the diguillín river basin where only the last year was used as a validation period showed the best result with the sinfim method this same configuration was applied to validate its performance with another watershed in this case the colorado river watershed the sinfin method in its first stage a configuration of input components similar to the diguillín river watershed was obtained x t and q t q t 1 q t 2 q t 3 as rainfall x and runoff q time series relevant lags respectively the results obtained in the predictive module are shown in table 7 with the exception of the mse values of the training set a considerable improvement is observed in all performance metrics compared to the results obtained by the sinfim method in the diguillín river watershed a high percentage of adjustment was obtained reaching 94 in the validation set in addition to high nse and kge indices this good fit is observed in fig 13 where the method can predict low medium and high flows in addition to predicting the consecutive increase in flow observed from day 260 also there are few points where the sinfim method does not achieve an optimal runoff prediction with little scattered values fig 14 5 discussion in this work a self identification neuro fuzzy inference framework to model the rainfall runoff relationship in a chilean watershed is introduced as a means to decrease the uncertainty associated with the selection of inputs and the number of membership functions required in the fuzzy system although the basin used to evaluate and develop the proposed method was the diguillín river watershed the hyperparameter configuration obtained was used in colorado river watershed to validate its performance and evaluate its scalability in both experiments the proposed method achieved a superior performance to the other evaluated predictive models such as anfis ann and lstm obtaining the best results when using only one year as a validation set this may be mainly since the variability in the observations of rainfall and runoff decreases as the period to be evaluated is reduced considering also that the 3 years used as the validation set in experiment 1 are different from each other the accuracy obtained with one year as validation set was greater than 80 and higher than 90 in the watershed validation better than those reported by shoaib et al 2014 where a comparative study of different wavelet based neural network models for rainfall runoff modeling was presented although the authors highlighted the advantage of pre processing the time series by extracting features with the wavelet transformation as other studies vivas et al 2019 in addition to the choice of the mother wavelet to improve performance the proposed model shows a better nse values and a higher r 2 in all cases similarly our results indicate better performance metrics than those reported by behmanesh and ayashm 2015 who assessed the rainfall runoff relationship in a basin in mississippi applying ann and anfis as predictive models the proposed method outperforms the results by kumar et al 2016 who applied a traditional ann to forecast runoff this results might suggest that the ann and anfis model by themselves do not generate a good prediction of runoff given the complexity of its relationship with rainfall in addition to having other influential factors such as temperature or soil saturation researches such as nath et al 2019 nourani et al 2011 or anusree and varghese 2016 presented an optimized algorithm using different input combinations one of the main advantages of our proposal is that it includes a module for identifying relevant lags so that an a priori selection of the input elements to the predictive model is not required although there are other methods for the selection of the input elements of the rain time series and runoff used in neuro fuzzy models such as partial autocorrelation function pacf nath et al 2019 xie et al 2019 cross correlation analysis cca chang et al 2017 entropy analysis nourani et al 2015 or mutual information mi may et al 2008 we consider that proposed algorithm in this study is more advantageous because its structure is developed with a focus on identify lags in a nonlinear environment such as in fuzzy systems veloz et al 2016 although deep learning dl approaches have shown great performances in modeling the relationship between rainfall and runoff in different watersheds and synthetic data hu et al 2018 kratzert et al 2018 li et al 2018 van et al 2020 according to our results the long short term memory lstm network developed showed the lowest performance as a forecasting models despite the fact that among the advantages of the lstm is its ability to learn long term dependencies between the provided input and output of the network kao et al 2020 the high variability of the observations in our case study might have influenced the performance of the model this could be explained because the data includes daily observations from all seasons of the year as well as a great period with little rain associated with the mega drought phenomenon that has been going through chile since 2010 garreaud et al 2017 in fact data heterogeneity in terms of quantities measured and scales have already been mentioned as an difficult aspect to directly implement existing results obtained on hydrological deterministic experiments marçais and de dreuzy 2017 furthermore the proposed model in this study has shown comparable performance with works as alike as jothiprakash et al 2009 showed several models with good performances through varying the number of membership functions and combinations in the time series although in some of these models the r 2 performance was higher than that obtained in our study they have the drawback that the user has to set the number of membership functions while sinfim does it automatically similarly our performance results are lesser than the second of the architectures proposed by nourani et al 2013 who presented a fusion between the wavelet transformation with anfis model with a r 2 of 90 this could be mainly due to the characteristics of the watersheds under study nourani et al 2013 used data from watersheds located in iran whose daily maximum runoff values do not exceed 90 m 3 s while rainfall is less than 40 mm in our work the hydrological conditions are more variable having precipitation values that reach 233 mm and runoff rates up to 544 m 3 s therefore the ability of sinfim to model extreme runoff values given a rainfall event is highlighted a fact that can be seen in figs 9 and 11 where the model successfully predicts runoff peaks greater than 150 m 3 s in addition sinfim stands out for not requiring the pre processing of the time series to obtain a good performance which facilitates its application and that would allow a more direct understanding of the predicted runoff values from the results obtained in our work we must not only emphasize its good performance compared to the state of the art alternatives but also the main advantage of applying a self organizing fuzzy system to predict the runoff in models like anfis expert knowledge is required to define the number of premises which is why many proposed approaches generate an initial set of rules based on a clustering technique in our case this step is not necessary since the algorithm itself defines the number of rules necessary to model the data set allende cid et al 2016 even when the parameters defined by the operators require some prior knowledge of the phenomenon under study this causes the reduction of uncertainty and error associated with the choice of such parameters in the fuzzy system also the number of rules can be controlled by setting the algorithm parameter properly creating a more parsimonious model these are very important if we consider that the possible results in the prediction of the runoff depend on other variables besides the rainfall such as the environmental conditions of humidity and the type of soil which can generate different rules in the premise depending on the watershed to study another relevant aspect to be pointed out is that there are few studies that examine the runoff rainfall relationship using a similar number of periods as used in this study as a database for example the works of nourani et al 2011 or asadi et al 2013 use a maximum of 12 years including training and validation sets in our case we used a total of 19 years so we increased the amount of rain drought and runoff events that the proposed algorithm could learn besides our proposal managed to efficiently grasp and model the variability of the runoff levels throughout the period unlike those reported by talei et al 2010 ghose et al 2013 or panchal et al 2014 which work only with rainy months or with specific precipitation events although the proposed framework has advantages in terms of the selection of input elements and the good performance obtained in modeling runoff also it should be noted that it fails to explain the entire process having approximately 16 variability not explained in the best of the scenarios according to the determination coefficients obtained this is due in part to the variability of the data used for training and to the presence of other influencing variables in the hydrological process such as temperature and land use among others in addition although the meteorological station used provides precipitation data with high incidence on runoff since it is located within the watershed area it is not completely representative of the total precipitation 29 according to the registered measurements of the thiesen polygons that is why for future studies other covariates such as temperature or height in addition to other meteorological stations should be considered to capture as much information as possible associated with rainfall however it should be noted that the distribution of meteorological stations throughout the basin area influences the capture of rainfall variability hence the colorado river watershed having a better meteorological stations distribution will generate a better runoff prediction therefore the inclusion of new covariates will depend on both the basin under study and the characteristics of the meteorological station an aspect to consider corresponds to the selection of the hyperparameters in ann anfis and lstm models it is well known that the selection of parameters prior to training can affect performance if they are not suitable for modeling with the data set under study probst et al 2019 van rijn and hutter 2018 torres et al 2003 in fact there are optimization tools such as harris hawks optimizer tikhamarine et al 2020 particle swarm optimization feng et al 2020 tikhamarine et al 2020 genetic algorithm dodangeh et al 2020 or grey wolf optimization dehghani et al 2019 among others that allow the optimal selection of these values to achieve the best performance however in this work the selection of hyperparameters was made based on the experience of the researchers and the number of fuzzy rules obtained in sinfim method thus it is possible to further improve the performance of these models nevertheless evaluating optimization algorithms for each of the models used and comparing them with the proposed method could be include in a future work however these models were used as substitutes for the runoff prediction module in sinfim so the uncertainty associated with the selection of the input values was reduced with the implementation of the sifar model finally this work represents one of the first studies in which a neuro fuzzy model is applied to predict the runoff in a chilean watershed so it provides the region with a useful tool to make decisions about land use and availability of water resources among others our main contribution is to provide a method to engineers and other professionals involved in the management of water resources and environmental planning which allows to predict the runoff values of the diguillín river watershed regardless of the season and conditions of drought or rain and which in turn implies capturing the uncertainty associated with the runoff rainfall relationship we proposed to extend the application of the framework to other watersheds in the country and optimize the elements of the input space and the thresholds used in the algorithm operators 6 conclusion in this work a new framework called self identification neuro fuzzy inference model sinfim for predicting one day ahead runoff in a chilean watershed was proposed specific findings of this study include 1 sinfim method has shown better performance than other methods such as anfis ann and lstm for predicting one day ahead runoff achieving an adjustment higher than 80 in the watershed under study and higher that 90 in the watershed validation in addition nash sutcliffe efficiency and percent bias indicate that sinfim is a promising model 2 the proposal by automatically identifying the lags and the fuzzy rules required in a neuro fuzzy system allows the reduction of the error and uncertainty associated with user setting parameters 3 sinfim method can predict any runoff value regardless of the season of the year managing to estimate low medium and peak runoff values also time series datasets do not need a pre processing step to be included in the model as input although the proposed method has good performance indicators in the prediction of flow it cannot fully explain the variability associated with the phenomenon under study being mostly observed in the diguillín river watershed which showed a maximum of 84 adjustment however this adjustment was greater in the basin used in the validation of the method thus the characteristics of the basin affect the prediction of runoff requiring in some cases to include other covariates that would contribute to improving performance the main limitation of this study is that no optimization algorithm was applied to obtain the hyperparameters in the models used to compare the sinfim and this could affect their performances only in the lstm a factorial design with a grid of options was made that is why the evaluation of models that allow obtaining the optimal hyperparameters of the methods used will be considered in future research however even using these models as runoff prediction approach the uncertainty in the selection of lags was addressed considering the automatic selection carried out with the sifar model finally although this study worked with two watersheds the diguillń river for the development of the method and the colorado river for its validation it is necessary to apply the sinfim method in other basins with different characteristics both in chile and in other countries to evaluate their performance furthermore it is interesting to evaluate the method in the multi step ahead runoff prediction scheme however with the preliminary results obtained in this study we can conclude that the proposed method represents a good alternative in runoff one day ahead prediction thus constituting a useful tool for professionals involved in environmental planning credit authorship contribution statement yerel morales conceptualization methodology software validation formal analysis investigation resources writing original draft writing review editing visualization marvin querales conceptualization methodology software validation formal analysis investigation resources writing original draft writing review editing visualization harvey rosas conceptualization methodology validation formal analysis investigation writing review editing visualization héctor allende cid methodology validation formal analysis investigation writing review editing rodrigo salas conceptualization supervision methodology software validation formal analysis investigation resources writing review editing visualization declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
4839,this paper aims at improving long term streamflow forecasts by implementing a novel technique based on conditioning the parameters of a stochastic weather generator on large scale climate indices with varying lengths of training periods during the establishment of correlations the most important climate indices are identified by looking at yearly correlations between a set of 40 indices and meteorological data precipitation and temperature at the watershed scale a linear model is then constructed to identify precipitation and temperature anomalies to induce perturbations in the stochastic weather generator time windows of 5 10 15 20 and 30 years are used in determining the optimal linear model the performance of the proposed approach is assessed against that of a resampling of past climatology and using the same stochastic weather generator unconditioned on climate indices each member of the ensemble weather forecast is then fed to a hydrological model to create the ensemble streamflow forecasts esf with a one year forecasting horizon the three approaches are tested in hindcast mode over a 30 year period at 12 forecast dates results show that temperatures are significantly correlated with large scale climate indices whereas precipitation is only weakly related to the same indices the length of the time window has a considerable impact on the prediction ability of the linear models the precipitation models based on short duration time windows performed better than those based on longer windows while the reverse was found for the temperature models a comparison between all three ensemble streamflow forecast approaches is assessed using the continuous ranked probability score crps metric results show that the proposed method improves long term streamflow forecasting particularly the volumetric bias and the peak flows during the spring flood keywords long term streamflow forecast large scale climate indices stochastic weather generator non stationarity 1 introduction sustainable water resource management is a fundamental requirement across the globe and streamflow forecasting is an integral component of an efficient water management strategy while a proper short term streamflow forecast of between 1 and 15 days can help predict floods and other short term events providing a long term streamflow forecast horizon ranging from a few weeks to the annual scale can be crucial for hydropower generation planning reservoir management and operation effective irrigation management decision making and environmental and ecosystem protection anghileri et al 2016 turner et al 2020 zhao et al 2012 the main issue in making and improving long term streamflow forecasts is dealing with complex uncertainties rooted in the stochasticity non linearity and non stationarity characteristics of streamflow time series narsimlu et al 2015 to better manage the different sources of forecast uncertainty probabilistic forecasts have come to replace more traditional deterministic approaches in a probabilistic approach a collection of deterministic forecasts is generated to simulate the same event and provide representative samples of the future the first use of probabilistic approaches in inflow forecasting dates back to 1980 and was called ensemble streamflow prediction day 1985 the esp forecast offers a way to communicate uncertainties and its advantages over deterministic forecasts has been explored in many studies arnal et al 2018 the two main approaches for making long term esps consist of a resampling of past climatology and a process using weather generators resampling past climatology is by far the most common long term forecasting method it was first used in the 90s in order to tackle the problems parametric models faced in forecasting hydrological time series king et al 2014 the main problem with these methods was their assumption of normality and the requirement that data be transformed into a normal distribution prior to the models being fitted data distribution transformation represents one of the main sources of bias in parametric methods moreover these methods cannot fully capture the non linearity of hydrological data prairie et al 2007 sharma et al 1997 to overcome this problem resampling methods such as the index sequential method k nn bootstrapping methods and kernel based approaches have been developed keller et al 2017 khaki et al 2018 sharifazari and araghinejad 2015 resampling methods are widely used due to their relative ease of implementation however most of these methods suffer from the same potential drawbacks 1 any deficiency in the historical records will be transferred to the forecast 2 the number of forecast members in an ensemble is generally limited to the length of existing records and 3 resampling methods typically assume stationarity of the data over the historical record forecasts can therefore be unreliable in non stationarity conditions such as that induced by anthropogenic climate change li et al 2017 ndzabandzaba 2020 various methods and techniques have been proposed through the years to improve resampling methods but additional research is still needed to address the issues mentioned lee et al 2010 sharifazari and araghinejad 2015 sivakumar 2017 stochastic weather generators were first developed in the 80s semenov 2008 wilks and wilby 1999 the initial purpose of weather generators was to generate long time series of weather variables with statistical properties identical to those of observed series the weather time series thus generated could be used in hydrological modeling and risk assessment studies where access to long time series is an important issue the ability of stochastic weather generators to provide long time series without any missing values has been assessed and demonstrated in many studies caron et al 2008 dabhi et al 2018 goldman 2017 these weather generators performance has improved in many aspects over the years for example several methods have been developed to improve their low frequency variability underestimation chen et al 2010 hansen and mavromatis 2001 multisite stochastic weather generators have been developed to consider the spatial variability of hydroclimatic time series khalili et al 2011 in addition various approaches have been implemented to improve the representation of intervariable correlations chen and brissette 2015 chen et al 2018 more advanced versions of stochastic weather generators have been developed which focus on generating spatially gridded weather peleg et al 2017 developed the aw gen 2d which is an advanced weather generator for two dimensional grids and can simulate weather variables at high spatial and temporal resolutions in a gridded form in a more recent study dubrovsky et al 2020 developed a new parametric multi site multi variable stochastic weather generator spagetta climate change impact studies represent one of the main areas in which stochastic weather generators have been used in the past decade they have been used to downscale the resolution of coarse climate data to finer and local scales with the main objective of providing various realizations and their associated uncertainties for climate and hydrological predictions caron et al 2008 fatichi et al 2013 peleg et al 2019 this approach was first proposed by wilks 1992 and is based on conditioning the parameters of the stochastic weather generator according to climate projections based on greenhouse gas emission scenarios results have shown that stochastic weather generators can be used as a reliable downscaling tool in climate change impact assessment studies maraun and widmann 2018 stochastic weather generators have also been used as a downscaling tool in many other more generic studies chen et al 2012b 2018 despite the widespread use of these generators in climate change impact studies comparatively little attention has been paid to their advantages in hydrological modeling and streamflow forecasting the ability to condition the parameters of a weather generator to account for a dynamic climate can be leveraged in streamflow forecasting and in particular used to take into account the anthropogenic component of climate change there is a scientific consensus on climate change and its impact on regional ecosystems ipcc 2007 however many hydrometeorological models have been developed under the assumption of stationarity for both climate and hydrological time series under this assumption internal variability is assumed as the main cause of interannual variability with the anthropogenic signal now being dominant for temperature variability over many parts of the world martel et al 2018 it is therefore fundamental to take into account trends in hydrometeorological time series failure to consider non stationarity in hydrological modeling can result in the underestimation or overestimation of forecast streamflows and may consequently impact the management of water resources systems in non stationary conditions the probability distribution of hydrological time series changes over time distribution statistics such as the mean and variance thus change through time as well gagniuc 2017 non stationarity in hydrological time series can be caused by a non stationary climate but it can also be caused by exogeneous factors such as changes in land use pathiraja et al 2016 soil properties yan and moradkhani 2016 evapotranspiration xiong et al 2019 or combinations thereof shi et al 2015 in recent decades various approaches have been proposed to consider non stationarity in hydrological modeling with one of the main ones consisting in the use of large scale climate indices as covariates large scale climate indices represent non stationary patterns of variability that are linked to hydrometeorological time series distributions ouarda and charron 2018 2019 in general the first methods developed for incorporating large scale climate indices in hydrological forecasts can be classified in under pre and post processing schemes in pre processing schemes meteorological inputs to the hydrological model are based on large scale climate index information here historical records are selected based on past similarity to current oceanic and atmospheric states as represented by climate indices hamlet and lettenmaier 1999 werner et al 2004 wood et al 2002 in post processing schemes forecasting is performed as usual but each forecast is weighted based on past similarity to current climate indices najafi et al 2012 werner et al 2004 the most common approach used to define a relationship between large scale climate indices and hydro meteorological variables uses the former as a main predictor to predict a hydro meteorological variable methods such as simple and multiple regressions principal component analysis singular value decomposition svd canonical correlation analysis and combined principal correlation have been used to define a relationship between the different spatial and temporal scales of large scale oscillations and local observations bhandari et al 2018 2019 kalra et al 2013 tootle and piechota 2006 notwithstanding all the recent work that has been done in this area efforts are still ongoing to determine how to properly link current atmospheric and oceanic states to improve streamflow forecasts liu et al 2019a o brien et al 2019 a limited number of studies have endeavored to use stochastic weather generators for non stationarity modeling of weather variables and streamflow forecasts for example šípek and daňhelka 2015 used a stochastic weather generator to generate stochastic variability around a small subset of years based on the similarity with present climate indices the main objective of this study is therefore to propose an approach to capture non stationarity in long term streamflow forecasting by incorporating large scale climate indices in the streamflow forecasting process and by varying the length of the training period the approach is based on constructing precipitation and temperature models that depend on a subset of relevant large scale climate indices these models will be used to modify the parameters of a stochastic weather generator in order to produce time series of precipitation and temperature that are more representative of climate variability at the time the streamflow forecast is issued the remainder of this paper is divided into four sections the watershed and data are first described in section 2 followed by the methodology in section 3 results are then presented and discussed in sections 4 and 5 respectively 2 watershed and data description this study was conducted on the lake saint jean watershed located in the province of quebec canada fig 1 the lake saint jean basin has a surface area of 45 261 km2 four main rivers flow into the lake saint jean which for its part measures 1000 km2 rio tinto one of the world s largest aluminum producers operates six power plants on this watershed with an average capacity of 2000 megawatts the development of the aluminum industry and its impact on the regional economy are closely linked to the hydropower potential of the lake saint jean watershed dibike and coulibaly 2005 during summer and fall months rainfall is usually sufficient to ensure the high efficiency use of the reservoir during winter streamflows to the reservoir decrease sharply and water must be drawn from the reservoir to maintain production finally during spring the freshet brings enough water to fill the reservoir several times over leading to regular unproductive spills during that period therefore it is critical that planning be done to ensure that long term winter and spring melt reservoir levels will provide maximum energy production during winter but avoid water shortages before the freshet arsenault and côté 2018 arsenault et al 2016b côté and arsenault 2019 the lake saint jean is sparsely inhabited and consists of a mostly homogeneous boreal forest cover the mean annual precipitation over the watersheds is 970 mm while the mean annual minimum and maximum temperatures are 5 4 c and 5 7 c respectively the mean annual streamflow for its part is 861 m3 s the watershed outlet is on the saguenay river which flows into the st lawrence river fig 1 shows the lake saint jean watershed precipitation and temperature data used in this study come from the natural resources canada nrcan dataset nrcan is a 10 km resolution canada wide gridded daily precipitation and temperature dataset hutchinson et al 2009 the mean annual precipitation maximum and minimum temperatures over the watershed for the 1950 2010 period are plotted in fig 2 the 10 year precipitation maximum and minimum temperatures moving average is plotted as well there is an increasing temperature trend over the past 40 years 1 5 which matches the expected anthropogenic climate change at high latitudes a sharp decrease in precipitation over the past 15 years can also be observed which could be the result of natural variability or associated to some degree to climate change for this study a set of 40 large scale climate indices at the monthly scale was obtained from noaa s climate diagnostics center by using an uncertain pre screening process this large selection of indices ensures that no potentially relevant indices are left out table 1 presents the list of all climate indices considered 3 methodology in this section the resampling and weather generator esp methods are described following which the proposed method for this study is introduced and detailed the experimental setup and evaluation framework are presented at the end of the section 3 1 resampling method in this study past observed climatology resampling is used as the benchmark method this approach is the most commonly used non parametric method for generating long term ensemble weather forecasts this work uses equiprobable resampling with no reshuffling between precipitation and temperature years lall and sharma 1996 this means that the precipitation and temperatures are not mixed between years the number of members in each of the ensembles is therefore equal to the number of years in the historical period up to the forecast year 3 2 stochastic weather generator the stochastic weather generator used in this study is weagets which is a matlab based daily scale weather generator chen et al 2012a and its performance has previously been evaluated and found to be good in the case study watershed chen et al 2019 2011 weagets starts by generating precipitation in two steps the probability of a wet day is evaluated using a markov chain on wet days precipitation amounts are modeled using either an exponential or a gamma distribution minimum and maximum temperatures are then computed based on the wet or dry day status a first order auto regressive process ensures the proper autocorrelation and cross correlation of all three weather time series weagets is based on the work of richardson and wright 1984 we use a first order markov chain is used for precipitation occurrence this implies that the probability of precipitation on any day only depends on the dry wet status of the previous day the exponential distribution is used to generate precipitation quantity as per eq 1 1 f x λ λ e λ x where f x λ is the probability density function with parameters λ and x λ is the inverse of the mean daily precipitation and x is the daily precipitation value 3 3 coupling large scale climate indices with a stochastic weather generator this approach consists of four main steps as shown in fig 3 first for each forecast year a regression model between a subset of large scale climate indices and each weather variable precipitation maximum and minimum temperatures is established based on common available years between the weather variables historical records and large scale climate indices in a second step for each forecast during a year the regression model is used to calculate predicted precipitation and temperature anomalies over the forecast horizon these predicted anomalies are then used as perturbations to the stochastic weather generations previously calibrated using the entire historical record in essence the climate indices are used as predictors of climate anomalies in tuning the weather generator parameters next an ensemble weather forecast is generated ewf using the weather generator finally the hydrological response to the ewf is simulated using the hydrological model to create the ensemble streamflow forecast the forecast lead time is always one year and the number of forecasts in each ensemble is 500 in addition to assess the sensitivity to initiation date forecasts are made 12 times per year on the first day of each month 3 3 1 step 1 regression models between climate indices and local climate anomalies in the first step a climate index best selection is made for each weather variable at the annual scale a simple stepwise linear regression is chosen for selecting the best subset of large scale climate indices as is shown in equation 2 2 y w β 0 β 1 x 1 β 2 x 2 β i x i ε where y w is the predicted weather variable predictand and w is either the mean annual precipitation or the maximum or minimum temperature x i are the climate indices i i 1 2 40 which are used as predictors and β i and ε are respectively the regression coefficients and residual the phase of climate indices varies in the inter annual multi annual decadal and multi decadal timescales due to complex interactions between the atmosphere and sea surface temperature anomalies consequently the correlations between large scale climate indices and weather variables are expected to vary in time due to non linear interactions within the climate system it is therefore also necessary to find the optimal time window to define these correlations accordingly this study defines 5 time periods last 5 10 15 20 and 30 years in its strategy to find the optimal time period for defining the regression between the climate indices and weather variables 3 3 2 step 2 calculating expected precipitation and temperature anomalies at the forecast date the regression models previous step are used to compute the expected mean annual precipitation and temperature anomalies over the forecast period the anomalies represent the deviation from the historical climatology using the change factor method diaz nieto and wilby 2005 as presented in equations 3 and 4 2 p a n o m a l y p c i p r e f 3 t a n o m a l y t c i t r e f the precipitation p a n o m a l y and temperature t a n o m a l y anomalies are expressed as the ratio precipitation and difference temperature between their projected values over the forecast period p c i a n d t c i and historical mean values p r e f and t r e f 3 3 3 step 3 modification of the weather generator parameters the parameters of the stochastic weather generator defining the monthly means are modified according to the calculated precipitation and temperature anomalies using eqs 4 and 5 4 p w g p r e f p a n o m a l y 5 t w g t r e f t a n o m a l y where p w g and t w g become the main driving values as opposed to p r e f and t r e f the ensemble weather forecast ewf is then generated by the stochastic weather generator the perturbation scheme only modifies the mean values and variability remains based on the entire historical record 3 3 4 step 4 hydrological simulation in the final step the hydrological response to the ensemble weather forecast ewf is simulated with a hydrological model the hsami hydrological model was used in this study fortin 2000 hsami is a lumped conceptual rainfall runoff hydrological model with 23 adjustable parameters that was developed by hydro québec it is used for operational forecasting at the daily and hourly time scales over 100 catchments it has also been used for many research applications across north america with good results arsenault et al 2016a 2013 castaneda gonzalez et al 2018 two parameters are used for scaling potential evapotranspiration six used for snowmelt five for simulating horizontal flows and ten for vertical flows water movement in the vertical axis is simulated by four interconnected linear reservoirs consisting of surface water snow on the ground and saturated and unsaturated zones water movement in the horizontal axis is filtered by one linear reservoir and two unit hydrographs hsami requires daily precipitation and maximum and minimum temperatures as inputs while the cloud cover fraction and snow water equivalent can also be used these data are however not measured at the study site the calibration of hsami in this study was performed with the cmaes covariance matrix adaptation evolution strategy igel et al 2007 algorithm with the objective of finding the maximum value of the nash sutcliffe efficiency criteria this algorithm choice was made following the work of arsenault et al 2013 in order to avoid injecting additional unnecessary biases due to the hydrological modeling hsami was calibrated with all observed discharge data for 1950 to 2009 to include as much information as possible in the parameter set arsenault et al 2018 and the simulated discharge was used in this work instead of observed discharge this resulted in a perfect hydrological modeling therefore removing any uncertainty due to initial conditions as well as the need to implement a data assimilation system 3 4 evaluation framework to investigate the merits of using this method in long term streamflow forecasting the 1980 2009 time horizon is used as the hindcasting period with the 1950 1979 period representing the original historical record for each year of the hindcast period the best regression model is chosen and applied to compute precipitation and temperature anomalies using all of the preceding years as the historical record twelve dates are used to initiate the forecasts on the first day of each month to assess the sensitivity of the proposed method to the issue date the method s performance is compared with the resampling method and the unmodified stochastic weather generator fig 4 shows the evaluation framework implemented in this study the bias and pearson correlation coefficient r are employed to evaluate the ensemble weather forecasts ewfs the continuous ranked probability score crps and nash sutcliffe efficiency nse are used to evaluate the performance of the proposed esp method the crps is an extension of the mean absolute error to probabilistic forecasts it essentially measures the difference between the empirical cumulative distribution function cdf of the forecasted values and the observed value matheson and winkler 1976 if f is the predictive cdf and y is the observation the crps can be defined by eq 6 6 c r p s f y f t h t y 2 d t where h t y is the heaviside function h 0 when t y otherwise h 1 hersbach 2000 toth et al 2003 the crps units are the same as the observation i e m3 s in this study 4 results fig 5 presents the correlation coefficient between the observed mean annual precipitation the maximum and minimum temperatures and the mean annual value of each of the 40 selected climate indices the correlations were all calculated using all common available years between the records of each climate index and weather variable fig 5 shows that temperatures correlate more with large scale climate indices than with precipitation the number of large scale climate indices which have a correlation with temperatures is also larger than for precipitation however because of the dynamical interactions between the various indices correlations with surface variables may not be constant in time and using a large time window to establish correlations may in fact hide stronger correlations in the shorter term to illustrate this fig 6 shows the annual correlation between nino 3 and a 10 year moving average for precipitation and maximum and minimum temperatures fig 6 clearly shows the cyclical nature of the correlation between nino3 and climate variables on the lake saint jean watershed as shown in fig 5 there is no correlation with nino3 when looking at the entire duration of the time series to address this issue in identifying the relationship between large scale climate indices and weather variables 5 time windows 5 10 15 20 and 30 years are considered in defining the regression models the regression between each weather variable and large scale climate indices is dynamically constructed based on each new forecast year the regression models are then used to assess precipitation and temperature anomalies to modify the weather generator fig 7 shows the 1 year ahead predicted mean annual temperature and precipitation for every monthly forecast made over the 1980 2009 period each graph therefore contains 360 points comprised of 30 years of monthly forecasts fig 7 shows a clear impact of the length of the time window used to build the regression models the precipitation model favors a shorter time window of 10 to 15 years whereas temperatures can make a better use of longer time series up to their full length and certainly longer than 15 years based on these results 10 20 and 30 year time windows were selected to construct the optimum regression model for precipitation maximum and minimum temperatures respectively all correlations presented in fig 7 are statistically significant with p values inferior to 0 001 in all cases the number of times each climate index is used in a regression model is counted over every monthly forecast over the 30 year calibration period results are sorted and plotted in fig 8 as can be seen in fig 8 a small subset of climate indices is systematically preferred for temperature a subset of 5 indices emerges enso and amm figure among the five most influential elements for both minimum and maximum temperatures the others are amo ns eos and ep np for maximum temperature and nta ea wr and np for minimum temperature for precipitation the selection frequency is more uniform but two indices emerge nonetheless qbo quasi biennial oscillation and amo atlantic multidecadal oscillation to evaluate the performance of the proposed method in forecasting the mean annual precipitation maximum and minimum temperatures fig 9 shows the biases between forecast and observed values the figure also presents the biases of the three chosen esp methods namely resampling weather generator and conditioned weather generator with regression time windows varying between 5 and 30 years as was the case for fig 7 the performance of the proposed method in forecasting mean annual precipitation is strongly linked to the length of the time window used to build the regression model the last 10 years is the best window length to use for the studied catchment the mean biases are always smaller than for the other time windows and the resampling and basic weather generator benchmark methods the proposed method also clearly decreases the mean bias of the forecast maximum and minimum temperature in comparison with the other two methods this applies to all time windows using a longer time window gives slightly better results especially for maximum temperature the impacts of using the 5 to 30 year regression models on streamflow forecasts are presented in fig 10 which shows the mean annual forecast hydrographs over the 30 year hindcast period for the january 1st issue date fig 10 shows the impact of the window length on the performance of the proposed esp using 10 or 15 year windows yields the best results with noteworthy improvements around the spring flood the best performance is obtained using 10 20 and 30 year time windows for precipitation maximum and minimum temperatures respectively bottom right figure historical resampling results in a late flood onset along with an overestimation of flood peak the performance of the basic weather generator is close to that of the resampling method albeit slightly worse for the mean hydrograph peak flow fig 11 presents the mean streamflow crps obtained with resampling and the difference between the weather generator approaches crps and the resampling crps to identify where the proposed method is better than the resampling approach lower values indicate reductions in crps which means that the proposed method is better than the resampling approach and vice versa values in blue indicate a lower crps and therefore an improvement over historical resampling values in red indicate a performance decrease the y axis shows the issue date of forecast and the x axis shows the extracted mean monthly crps values over 30 years of forecasts from 1980 to 2009 the differences in mean monthly crps indicate that the performance of the calibrated weather generator is very close to that of the resampling method with the exception of a slight overestimation around flood time which is consistent with the results of fig 10 the proposed perturbation method reduces crps values during the flooding period but its performance depends on the chosen window length fig 11 shows that making esp forecasts using regressions based on the past 5 years decreases forecast performance whereas all other time windows produce better forecasts the main improvements are observed for the spring flood which is a critical period for water management there are only minor differences between using 10 to 30 year windows but using 15 years for all three variables nonetheless results in slightly better performing forecasts for the flood period outside the flooding period using a longer window yields slightly better results using optimal windows for all three variables lower right figure provides results largely similar to that of using a fixed 15 year window tables 2 and 3 present the mean nse and mean relative bias values for 1 year ahead streamflow forecasts over 30 forecast years due to the importance of floods the results of the mean nse and relative bias for the month of may in particular as the main month of spring floods are presented in tables 4 and 5 overall the performance of the proposed method is on average superior to resampling and the classical weather generator approach the initiation date of the forecasts and the length of the time window used in defining the regressions are the determinant aspects of proposed method s performance 5 discussion in this study large scale atmospheric and oceanic indices were used to describe patterns of natural climate variability according to many studies the relationship between large scale climate indices and climate anomalies is not constant and this non stationarity is expressed at different time scales hertig et al 2015 it is therefore not surprising that the relationship between regional weather variables and large scale climate indices is dynamic and non stationary as discussed in other studies nalley et al 2019 figs 5 and 6 demonstrate the extent to which correlations can be found to be absent or statistically significant depending on the chosen time period finding the best time scale for investigating the relationship between weather variables and large scale climate indices is one of the major challenges in this area o brien et al 2019 this study therefore considered 5 different time windows in building the best performing regression model as was shown in the results of fig 7 the precipitation regression models which are established based on shorter windows provide better precipitation estimates in contrast the temperature regression models benefit from longer windows a possible explanation may be related to the concept of historical memory any climate state can be decomposed into two parts the memory part and the weather scale dynamical excitation part hasselmann 1976 the predictability of weather variables is limited by those two terms since measuring the dynamical forcing is challenging attention is mostly concentrated on modeling the internal variability using the existing memory part doblas reyes et al 2013 meehl et al 2014 it has been shown that climate memory has a non negligible impact on most climate variables with the exception of precipitation xie et al 2019 according to earlier studies the long term memory contribution to the modeling and characterization of precipitation is weak and in some cases long term precipitation correlation behaves as white noise in precipitation modeling jiang et al 2017 therefore the precipitation models rely less on the memory part than does the temperature model this can explain why the best temperature models are built based on longer time windows another way of looking at this is simply to realize that at the spatial and temporal scales considered in this study and for the chosen watershed internal climate variability is much more important for precipitation than temperature when compared to the synoptic control of sea surface temperature anomalies these findings are observed in some reginal scale studies precipitation uncertainties are caused mainly by climate variability rather than other sources such as emission scenarios and climate models fatichi et al 2016 hawkins and sutton 2011 trenberth 2012 the influence of each climate index on weather variables was presented in fig 8 these results indicate that many climate indices have a simultaneous influence on the local climate while most of the work in this domain has tended to focus on the main indices e g enso amo nao pdo the results from this study indicate that other indices also have a significant influence a fact that is often neglected in other studies in this work amo and qbo are identified as the two most significant climate indices in precipitation modeling the impact of amo over eastern canada has been relatively widely studied assani et al 2010 but that of qbo which influences convection and precipitation gray et al 2018 has largely been neglected recent studies also suggest that there is a need to improve our understanding of other climate indices in order to increase north american climate predictability hartmann 2015 kug et al 2015 wang et al 2014 the results for the studied watershed indicate that a comparatively larger number of indices are correlated with temperature as compared to precipitation the same findings are obtained in other studies that have attempted to assess the complex interaction between multiple large scale climate indices and weather variables de beurs et al 2018 leathers et al 1991 tomingas 2002 climate studies have shown that temperature variability is largely related to synoptic scale variability while precipitation is significantly more affected by the local scale and is hence driven by large scale circulation to a much lesser extent than is temperature fatichi et al 2016 climate change impact studies have also clearly demonstrated the importance of the spatial scale when looking at precipitation variability fischer and knutti 2014 martel et al 2018 variability becomes less important as we go from the local to the regional scale accordingly looking for relations between precipitation and large scale circulation poses a much bigger challenge at the catchment scale than it would be at the regional scale with the exception of the largest continental size catchments the performance of the proposed method in forecasting mean annual precipitation and temperatures was evaluated and compared to that of historical resampling and using the basic calibrated weather generator results showed that the proposed method reduced both precipitation and the temperature mean annual biases in comparison with the two other methods it improved temperature forecasting for all the time windows considered improvements in precipitation forecasting were more dependent on the time window considered to build the regression model these results were largely transferred to streamflow forecasts after a hydrological model was used the ensemble streamflow forecasts were assessed by looking at the forecast mean annual hydrographs and monthly crps values the results presented in figs 10 and 11 suggest that spring flood can be better estimated when a 10 year or longer time window is used to build the regression models the proposed method performed well at estimating the flood onset this improvement is related to a better temperature estimation as shown in fig 9 temperature is the main driver of snowmelt initiation and therefore plays a key role in the physical processes leading to the onset of the spring flood it has been shown that the flood onset and recession are mainly determined by temperature barnett et al 2005 an under or overestimation of forecast temperatures will affect all streamflow characteristics during the snowmelt period the benchmark methods of resampling and unconditioned weather generator lead to a forecast flood beginning too late on average this results when forecast temperatures are too cold as has also been reported in other studies hongbo et al 2015 liu et al 2019b meng et al 2019 the increasing temperature trend in fig 2 cannot be captured by both benchmark methods the incorporation of large scale climate indices in the forecasting process leads to a better representation of temperature anomalies during the snowmelt period thus leading to better flood forecasts these results were also confirmed in tables 4 and 5 where the nse and mean relative bias were more accurate with the proposed method than with the resampling or simple weather generator approach the proposed method makes use of the fact that the large scale climate indices which are used as the main predictors of the method can be available up to one year ahead or more hermanson and sutton 2010 luo et al 2008 power et al 2006 seitola and järvinen 2014 tian and fan 2015 the experimental setup of this study is based on a hindcasting approach in order to avoid any unnecessary bias due to large scale climate indices predictions and their uncertainty therefore the methodological framework chosen for this study comes with limitations an important one is that the hindcast approach used in this project assumes perfect a priori knowledge of climate indices over the forecasting period in an operational context these values will not be perfectly known as climate indices would also have to be forecast this is not necessarily a problem for decadal indices but it is definitely a challenge for interannual indices such as enso which have been shown to be difficult to accurately forecast ham et al 2019 using the calibrated weather generator on the historical period a user would provide the historical weather historical climate indices and the forecasted climate indices so that the generator s parameters could be estimated for the future period the proposed methodology could be improved in many ways while this work only considered stepwise regression more complex non linear approaches e g neural networks could be used to link climate indices to local climatology since it is known that local scale induced variability is largest in the summer it would likely be beneficial to perform the analysis on a seasonal basis this should result in better performance over the winter season than the performances presented at the annual scale as well this would lessen the problem of having to forecast the climate indices over the longer yearly horizon finally the results presented cannot be generalized to other watersheds since the links between sea surface temperature anomalies and the local climate are region dependent the approach should therefore be tested on other watersheds in addition the hsami model used in this study is a conceptual and lumped model other types of models might react differently to the weather generator outputs and could generate streamflow with different characteristics it could therefore be envisioned to extend the methodology to various types of hydrological models to evaluate the method s performance in a diversity of contexts 6 conclusion this paper presented a long term ensemble streamflow forecasting method in which a stochastic weather generator is conditioned on large scale climate indices to take into account internal climate variability stepwise linear regression models between a subset of 40 climate indices and local climate anomalies are built to represent climate non stationarity for an eastern canadian catchment the stochastic weather generator uses the predicted climate anomalies to produce an ensemble weather forecast this forecast is then fed to a hydrological model to generate long term ensemble streamflow forecasts results show that the proposed method improves long term streamflow forecasts over the studied catchment and especially around the flood peak results also show a strong dependence on the time window duration used in defining the regression models shorter durations are preferable for precipitation whereas longer time windows result in better performance for minimum and maximum temperatures these results are consistent with the larger internal climate variability of precipitation at the catchment scale funding this work was supported by natural sciences and engineering research council of canada ca credit authorship contribution statement samaneh sohrabi conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization project administration françois p brissette conceptualization methodology software validation formal analysis resources data curation writing review editing visualization supervision project administration funding acquisition richard arsenault validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
4839,this paper aims at improving long term streamflow forecasts by implementing a novel technique based on conditioning the parameters of a stochastic weather generator on large scale climate indices with varying lengths of training periods during the establishment of correlations the most important climate indices are identified by looking at yearly correlations between a set of 40 indices and meteorological data precipitation and temperature at the watershed scale a linear model is then constructed to identify precipitation and temperature anomalies to induce perturbations in the stochastic weather generator time windows of 5 10 15 20 and 30 years are used in determining the optimal linear model the performance of the proposed approach is assessed against that of a resampling of past climatology and using the same stochastic weather generator unconditioned on climate indices each member of the ensemble weather forecast is then fed to a hydrological model to create the ensemble streamflow forecasts esf with a one year forecasting horizon the three approaches are tested in hindcast mode over a 30 year period at 12 forecast dates results show that temperatures are significantly correlated with large scale climate indices whereas precipitation is only weakly related to the same indices the length of the time window has a considerable impact on the prediction ability of the linear models the precipitation models based on short duration time windows performed better than those based on longer windows while the reverse was found for the temperature models a comparison between all three ensemble streamflow forecast approaches is assessed using the continuous ranked probability score crps metric results show that the proposed method improves long term streamflow forecasting particularly the volumetric bias and the peak flows during the spring flood keywords long term streamflow forecast large scale climate indices stochastic weather generator non stationarity 1 introduction sustainable water resource management is a fundamental requirement across the globe and streamflow forecasting is an integral component of an efficient water management strategy while a proper short term streamflow forecast of between 1 and 15 days can help predict floods and other short term events providing a long term streamflow forecast horizon ranging from a few weeks to the annual scale can be crucial for hydropower generation planning reservoir management and operation effective irrigation management decision making and environmental and ecosystem protection anghileri et al 2016 turner et al 2020 zhao et al 2012 the main issue in making and improving long term streamflow forecasts is dealing with complex uncertainties rooted in the stochasticity non linearity and non stationarity characteristics of streamflow time series narsimlu et al 2015 to better manage the different sources of forecast uncertainty probabilistic forecasts have come to replace more traditional deterministic approaches in a probabilistic approach a collection of deterministic forecasts is generated to simulate the same event and provide representative samples of the future the first use of probabilistic approaches in inflow forecasting dates back to 1980 and was called ensemble streamflow prediction day 1985 the esp forecast offers a way to communicate uncertainties and its advantages over deterministic forecasts has been explored in many studies arnal et al 2018 the two main approaches for making long term esps consist of a resampling of past climatology and a process using weather generators resampling past climatology is by far the most common long term forecasting method it was first used in the 90s in order to tackle the problems parametric models faced in forecasting hydrological time series king et al 2014 the main problem with these methods was their assumption of normality and the requirement that data be transformed into a normal distribution prior to the models being fitted data distribution transformation represents one of the main sources of bias in parametric methods moreover these methods cannot fully capture the non linearity of hydrological data prairie et al 2007 sharma et al 1997 to overcome this problem resampling methods such as the index sequential method k nn bootstrapping methods and kernel based approaches have been developed keller et al 2017 khaki et al 2018 sharifazari and araghinejad 2015 resampling methods are widely used due to their relative ease of implementation however most of these methods suffer from the same potential drawbacks 1 any deficiency in the historical records will be transferred to the forecast 2 the number of forecast members in an ensemble is generally limited to the length of existing records and 3 resampling methods typically assume stationarity of the data over the historical record forecasts can therefore be unreliable in non stationarity conditions such as that induced by anthropogenic climate change li et al 2017 ndzabandzaba 2020 various methods and techniques have been proposed through the years to improve resampling methods but additional research is still needed to address the issues mentioned lee et al 2010 sharifazari and araghinejad 2015 sivakumar 2017 stochastic weather generators were first developed in the 80s semenov 2008 wilks and wilby 1999 the initial purpose of weather generators was to generate long time series of weather variables with statistical properties identical to those of observed series the weather time series thus generated could be used in hydrological modeling and risk assessment studies where access to long time series is an important issue the ability of stochastic weather generators to provide long time series without any missing values has been assessed and demonstrated in many studies caron et al 2008 dabhi et al 2018 goldman 2017 these weather generators performance has improved in many aspects over the years for example several methods have been developed to improve their low frequency variability underestimation chen et al 2010 hansen and mavromatis 2001 multisite stochastic weather generators have been developed to consider the spatial variability of hydroclimatic time series khalili et al 2011 in addition various approaches have been implemented to improve the representation of intervariable correlations chen and brissette 2015 chen et al 2018 more advanced versions of stochastic weather generators have been developed which focus on generating spatially gridded weather peleg et al 2017 developed the aw gen 2d which is an advanced weather generator for two dimensional grids and can simulate weather variables at high spatial and temporal resolutions in a gridded form in a more recent study dubrovsky et al 2020 developed a new parametric multi site multi variable stochastic weather generator spagetta climate change impact studies represent one of the main areas in which stochastic weather generators have been used in the past decade they have been used to downscale the resolution of coarse climate data to finer and local scales with the main objective of providing various realizations and their associated uncertainties for climate and hydrological predictions caron et al 2008 fatichi et al 2013 peleg et al 2019 this approach was first proposed by wilks 1992 and is based on conditioning the parameters of the stochastic weather generator according to climate projections based on greenhouse gas emission scenarios results have shown that stochastic weather generators can be used as a reliable downscaling tool in climate change impact assessment studies maraun and widmann 2018 stochastic weather generators have also been used as a downscaling tool in many other more generic studies chen et al 2012b 2018 despite the widespread use of these generators in climate change impact studies comparatively little attention has been paid to their advantages in hydrological modeling and streamflow forecasting the ability to condition the parameters of a weather generator to account for a dynamic climate can be leveraged in streamflow forecasting and in particular used to take into account the anthropogenic component of climate change there is a scientific consensus on climate change and its impact on regional ecosystems ipcc 2007 however many hydrometeorological models have been developed under the assumption of stationarity for both climate and hydrological time series under this assumption internal variability is assumed as the main cause of interannual variability with the anthropogenic signal now being dominant for temperature variability over many parts of the world martel et al 2018 it is therefore fundamental to take into account trends in hydrometeorological time series failure to consider non stationarity in hydrological modeling can result in the underestimation or overestimation of forecast streamflows and may consequently impact the management of water resources systems in non stationary conditions the probability distribution of hydrological time series changes over time distribution statistics such as the mean and variance thus change through time as well gagniuc 2017 non stationarity in hydrological time series can be caused by a non stationary climate but it can also be caused by exogeneous factors such as changes in land use pathiraja et al 2016 soil properties yan and moradkhani 2016 evapotranspiration xiong et al 2019 or combinations thereof shi et al 2015 in recent decades various approaches have been proposed to consider non stationarity in hydrological modeling with one of the main ones consisting in the use of large scale climate indices as covariates large scale climate indices represent non stationary patterns of variability that are linked to hydrometeorological time series distributions ouarda and charron 2018 2019 in general the first methods developed for incorporating large scale climate indices in hydrological forecasts can be classified in under pre and post processing schemes in pre processing schemes meteorological inputs to the hydrological model are based on large scale climate index information here historical records are selected based on past similarity to current oceanic and atmospheric states as represented by climate indices hamlet and lettenmaier 1999 werner et al 2004 wood et al 2002 in post processing schemes forecasting is performed as usual but each forecast is weighted based on past similarity to current climate indices najafi et al 2012 werner et al 2004 the most common approach used to define a relationship between large scale climate indices and hydro meteorological variables uses the former as a main predictor to predict a hydro meteorological variable methods such as simple and multiple regressions principal component analysis singular value decomposition svd canonical correlation analysis and combined principal correlation have been used to define a relationship between the different spatial and temporal scales of large scale oscillations and local observations bhandari et al 2018 2019 kalra et al 2013 tootle and piechota 2006 notwithstanding all the recent work that has been done in this area efforts are still ongoing to determine how to properly link current atmospheric and oceanic states to improve streamflow forecasts liu et al 2019a o brien et al 2019 a limited number of studies have endeavored to use stochastic weather generators for non stationarity modeling of weather variables and streamflow forecasts for example šípek and daňhelka 2015 used a stochastic weather generator to generate stochastic variability around a small subset of years based on the similarity with present climate indices the main objective of this study is therefore to propose an approach to capture non stationarity in long term streamflow forecasting by incorporating large scale climate indices in the streamflow forecasting process and by varying the length of the training period the approach is based on constructing precipitation and temperature models that depend on a subset of relevant large scale climate indices these models will be used to modify the parameters of a stochastic weather generator in order to produce time series of precipitation and temperature that are more representative of climate variability at the time the streamflow forecast is issued the remainder of this paper is divided into four sections the watershed and data are first described in section 2 followed by the methodology in section 3 results are then presented and discussed in sections 4 and 5 respectively 2 watershed and data description this study was conducted on the lake saint jean watershed located in the province of quebec canada fig 1 the lake saint jean basin has a surface area of 45 261 km2 four main rivers flow into the lake saint jean which for its part measures 1000 km2 rio tinto one of the world s largest aluminum producers operates six power plants on this watershed with an average capacity of 2000 megawatts the development of the aluminum industry and its impact on the regional economy are closely linked to the hydropower potential of the lake saint jean watershed dibike and coulibaly 2005 during summer and fall months rainfall is usually sufficient to ensure the high efficiency use of the reservoir during winter streamflows to the reservoir decrease sharply and water must be drawn from the reservoir to maintain production finally during spring the freshet brings enough water to fill the reservoir several times over leading to regular unproductive spills during that period therefore it is critical that planning be done to ensure that long term winter and spring melt reservoir levels will provide maximum energy production during winter but avoid water shortages before the freshet arsenault and côté 2018 arsenault et al 2016b côté and arsenault 2019 the lake saint jean is sparsely inhabited and consists of a mostly homogeneous boreal forest cover the mean annual precipitation over the watersheds is 970 mm while the mean annual minimum and maximum temperatures are 5 4 c and 5 7 c respectively the mean annual streamflow for its part is 861 m3 s the watershed outlet is on the saguenay river which flows into the st lawrence river fig 1 shows the lake saint jean watershed precipitation and temperature data used in this study come from the natural resources canada nrcan dataset nrcan is a 10 km resolution canada wide gridded daily precipitation and temperature dataset hutchinson et al 2009 the mean annual precipitation maximum and minimum temperatures over the watershed for the 1950 2010 period are plotted in fig 2 the 10 year precipitation maximum and minimum temperatures moving average is plotted as well there is an increasing temperature trend over the past 40 years 1 5 which matches the expected anthropogenic climate change at high latitudes a sharp decrease in precipitation over the past 15 years can also be observed which could be the result of natural variability or associated to some degree to climate change for this study a set of 40 large scale climate indices at the monthly scale was obtained from noaa s climate diagnostics center by using an uncertain pre screening process this large selection of indices ensures that no potentially relevant indices are left out table 1 presents the list of all climate indices considered 3 methodology in this section the resampling and weather generator esp methods are described following which the proposed method for this study is introduced and detailed the experimental setup and evaluation framework are presented at the end of the section 3 1 resampling method in this study past observed climatology resampling is used as the benchmark method this approach is the most commonly used non parametric method for generating long term ensemble weather forecasts this work uses equiprobable resampling with no reshuffling between precipitation and temperature years lall and sharma 1996 this means that the precipitation and temperatures are not mixed between years the number of members in each of the ensembles is therefore equal to the number of years in the historical period up to the forecast year 3 2 stochastic weather generator the stochastic weather generator used in this study is weagets which is a matlab based daily scale weather generator chen et al 2012a and its performance has previously been evaluated and found to be good in the case study watershed chen et al 2019 2011 weagets starts by generating precipitation in two steps the probability of a wet day is evaluated using a markov chain on wet days precipitation amounts are modeled using either an exponential or a gamma distribution minimum and maximum temperatures are then computed based on the wet or dry day status a first order auto regressive process ensures the proper autocorrelation and cross correlation of all three weather time series weagets is based on the work of richardson and wright 1984 we use a first order markov chain is used for precipitation occurrence this implies that the probability of precipitation on any day only depends on the dry wet status of the previous day the exponential distribution is used to generate precipitation quantity as per eq 1 1 f x λ λ e λ x where f x λ is the probability density function with parameters λ and x λ is the inverse of the mean daily precipitation and x is the daily precipitation value 3 3 coupling large scale climate indices with a stochastic weather generator this approach consists of four main steps as shown in fig 3 first for each forecast year a regression model between a subset of large scale climate indices and each weather variable precipitation maximum and minimum temperatures is established based on common available years between the weather variables historical records and large scale climate indices in a second step for each forecast during a year the regression model is used to calculate predicted precipitation and temperature anomalies over the forecast horizon these predicted anomalies are then used as perturbations to the stochastic weather generations previously calibrated using the entire historical record in essence the climate indices are used as predictors of climate anomalies in tuning the weather generator parameters next an ensemble weather forecast is generated ewf using the weather generator finally the hydrological response to the ewf is simulated using the hydrological model to create the ensemble streamflow forecast the forecast lead time is always one year and the number of forecasts in each ensemble is 500 in addition to assess the sensitivity to initiation date forecasts are made 12 times per year on the first day of each month 3 3 1 step 1 regression models between climate indices and local climate anomalies in the first step a climate index best selection is made for each weather variable at the annual scale a simple stepwise linear regression is chosen for selecting the best subset of large scale climate indices as is shown in equation 2 2 y w β 0 β 1 x 1 β 2 x 2 β i x i ε where y w is the predicted weather variable predictand and w is either the mean annual precipitation or the maximum or minimum temperature x i are the climate indices i i 1 2 40 which are used as predictors and β i and ε are respectively the regression coefficients and residual the phase of climate indices varies in the inter annual multi annual decadal and multi decadal timescales due to complex interactions between the atmosphere and sea surface temperature anomalies consequently the correlations between large scale climate indices and weather variables are expected to vary in time due to non linear interactions within the climate system it is therefore also necessary to find the optimal time window to define these correlations accordingly this study defines 5 time periods last 5 10 15 20 and 30 years in its strategy to find the optimal time period for defining the regression between the climate indices and weather variables 3 3 2 step 2 calculating expected precipitation and temperature anomalies at the forecast date the regression models previous step are used to compute the expected mean annual precipitation and temperature anomalies over the forecast period the anomalies represent the deviation from the historical climatology using the change factor method diaz nieto and wilby 2005 as presented in equations 3 and 4 2 p a n o m a l y p c i p r e f 3 t a n o m a l y t c i t r e f the precipitation p a n o m a l y and temperature t a n o m a l y anomalies are expressed as the ratio precipitation and difference temperature between their projected values over the forecast period p c i a n d t c i and historical mean values p r e f and t r e f 3 3 3 step 3 modification of the weather generator parameters the parameters of the stochastic weather generator defining the monthly means are modified according to the calculated precipitation and temperature anomalies using eqs 4 and 5 4 p w g p r e f p a n o m a l y 5 t w g t r e f t a n o m a l y where p w g and t w g become the main driving values as opposed to p r e f and t r e f the ensemble weather forecast ewf is then generated by the stochastic weather generator the perturbation scheme only modifies the mean values and variability remains based on the entire historical record 3 3 4 step 4 hydrological simulation in the final step the hydrological response to the ensemble weather forecast ewf is simulated with a hydrological model the hsami hydrological model was used in this study fortin 2000 hsami is a lumped conceptual rainfall runoff hydrological model with 23 adjustable parameters that was developed by hydro québec it is used for operational forecasting at the daily and hourly time scales over 100 catchments it has also been used for many research applications across north america with good results arsenault et al 2016a 2013 castaneda gonzalez et al 2018 two parameters are used for scaling potential evapotranspiration six used for snowmelt five for simulating horizontal flows and ten for vertical flows water movement in the vertical axis is simulated by four interconnected linear reservoirs consisting of surface water snow on the ground and saturated and unsaturated zones water movement in the horizontal axis is filtered by one linear reservoir and two unit hydrographs hsami requires daily precipitation and maximum and minimum temperatures as inputs while the cloud cover fraction and snow water equivalent can also be used these data are however not measured at the study site the calibration of hsami in this study was performed with the cmaes covariance matrix adaptation evolution strategy igel et al 2007 algorithm with the objective of finding the maximum value of the nash sutcliffe efficiency criteria this algorithm choice was made following the work of arsenault et al 2013 in order to avoid injecting additional unnecessary biases due to the hydrological modeling hsami was calibrated with all observed discharge data for 1950 to 2009 to include as much information as possible in the parameter set arsenault et al 2018 and the simulated discharge was used in this work instead of observed discharge this resulted in a perfect hydrological modeling therefore removing any uncertainty due to initial conditions as well as the need to implement a data assimilation system 3 4 evaluation framework to investigate the merits of using this method in long term streamflow forecasting the 1980 2009 time horizon is used as the hindcasting period with the 1950 1979 period representing the original historical record for each year of the hindcast period the best regression model is chosen and applied to compute precipitation and temperature anomalies using all of the preceding years as the historical record twelve dates are used to initiate the forecasts on the first day of each month to assess the sensitivity of the proposed method to the issue date the method s performance is compared with the resampling method and the unmodified stochastic weather generator fig 4 shows the evaluation framework implemented in this study the bias and pearson correlation coefficient r are employed to evaluate the ensemble weather forecasts ewfs the continuous ranked probability score crps and nash sutcliffe efficiency nse are used to evaluate the performance of the proposed esp method the crps is an extension of the mean absolute error to probabilistic forecasts it essentially measures the difference between the empirical cumulative distribution function cdf of the forecasted values and the observed value matheson and winkler 1976 if f is the predictive cdf and y is the observation the crps can be defined by eq 6 6 c r p s f y f t h t y 2 d t where h t y is the heaviside function h 0 when t y otherwise h 1 hersbach 2000 toth et al 2003 the crps units are the same as the observation i e m3 s in this study 4 results fig 5 presents the correlation coefficient between the observed mean annual precipitation the maximum and minimum temperatures and the mean annual value of each of the 40 selected climate indices the correlations were all calculated using all common available years between the records of each climate index and weather variable fig 5 shows that temperatures correlate more with large scale climate indices than with precipitation the number of large scale climate indices which have a correlation with temperatures is also larger than for precipitation however because of the dynamical interactions between the various indices correlations with surface variables may not be constant in time and using a large time window to establish correlations may in fact hide stronger correlations in the shorter term to illustrate this fig 6 shows the annual correlation between nino 3 and a 10 year moving average for precipitation and maximum and minimum temperatures fig 6 clearly shows the cyclical nature of the correlation between nino3 and climate variables on the lake saint jean watershed as shown in fig 5 there is no correlation with nino3 when looking at the entire duration of the time series to address this issue in identifying the relationship between large scale climate indices and weather variables 5 time windows 5 10 15 20 and 30 years are considered in defining the regression models the regression between each weather variable and large scale climate indices is dynamically constructed based on each new forecast year the regression models are then used to assess precipitation and temperature anomalies to modify the weather generator fig 7 shows the 1 year ahead predicted mean annual temperature and precipitation for every monthly forecast made over the 1980 2009 period each graph therefore contains 360 points comprised of 30 years of monthly forecasts fig 7 shows a clear impact of the length of the time window used to build the regression models the precipitation model favors a shorter time window of 10 to 15 years whereas temperatures can make a better use of longer time series up to their full length and certainly longer than 15 years based on these results 10 20 and 30 year time windows were selected to construct the optimum regression model for precipitation maximum and minimum temperatures respectively all correlations presented in fig 7 are statistically significant with p values inferior to 0 001 in all cases the number of times each climate index is used in a regression model is counted over every monthly forecast over the 30 year calibration period results are sorted and plotted in fig 8 as can be seen in fig 8 a small subset of climate indices is systematically preferred for temperature a subset of 5 indices emerges enso and amm figure among the five most influential elements for both minimum and maximum temperatures the others are amo ns eos and ep np for maximum temperature and nta ea wr and np for minimum temperature for precipitation the selection frequency is more uniform but two indices emerge nonetheless qbo quasi biennial oscillation and amo atlantic multidecadal oscillation to evaluate the performance of the proposed method in forecasting the mean annual precipitation maximum and minimum temperatures fig 9 shows the biases between forecast and observed values the figure also presents the biases of the three chosen esp methods namely resampling weather generator and conditioned weather generator with regression time windows varying between 5 and 30 years as was the case for fig 7 the performance of the proposed method in forecasting mean annual precipitation is strongly linked to the length of the time window used to build the regression model the last 10 years is the best window length to use for the studied catchment the mean biases are always smaller than for the other time windows and the resampling and basic weather generator benchmark methods the proposed method also clearly decreases the mean bias of the forecast maximum and minimum temperature in comparison with the other two methods this applies to all time windows using a longer time window gives slightly better results especially for maximum temperature the impacts of using the 5 to 30 year regression models on streamflow forecasts are presented in fig 10 which shows the mean annual forecast hydrographs over the 30 year hindcast period for the january 1st issue date fig 10 shows the impact of the window length on the performance of the proposed esp using 10 or 15 year windows yields the best results with noteworthy improvements around the spring flood the best performance is obtained using 10 20 and 30 year time windows for precipitation maximum and minimum temperatures respectively bottom right figure historical resampling results in a late flood onset along with an overestimation of flood peak the performance of the basic weather generator is close to that of the resampling method albeit slightly worse for the mean hydrograph peak flow fig 11 presents the mean streamflow crps obtained with resampling and the difference between the weather generator approaches crps and the resampling crps to identify where the proposed method is better than the resampling approach lower values indicate reductions in crps which means that the proposed method is better than the resampling approach and vice versa values in blue indicate a lower crps and therefore an improvement over historical resampling values in red indicate a performance decrease the y axis shows the issue date of forecast and the x axis shows the extracted mean monthly crps values over 30 years of forecasts from 1980 to 2009 the differences in mean monthly crps indicate that the performance of the calibrated weather generator is very close to that of the resampling method with the exception of a slight overestimation around flood time which is consistent with the results of fig 10 the proposed perturbation method reduces crps values during the flooding period but its performance depends on the chosen window length fig 11 shows that making esp forecasts using regressions based on the past 5 years decreases forecast performance whereas all other time windows produce better forecasts the main improvements are observed for the spring flood which is a critical period for water management there are only minor differences between using 10 to 30 year windows but using 15 years for all three variables nonetheless results in slightly better performing forecasts for the flood period outside the flooding period using a longer window yields slightly better results using optimal windows for all three variables lower right figure provides results largely similar to that of using a fixed 15 year window tables 2 and 3 present the mean nse and mean relative bias values for 1 year ahead streamflow forecasts over 30 forecast years due to the importance of floods the results of the mean nse and relative bias for the month of may in particular as the main month of spring floods are presented in tables 4 and 5 overall the performance of the proposed method is on average superior to resampling and the classical weather generator approach the initiation date of the forecasts and the length of the time window used in defining the regressions are the determinant aspects of proposed method s performance 5 discussion in this study large scale atmospheric and oceanic indices were used to describe patterns of natural climate variability according to many studies the relationship between large scale climate indices and climate anomalies is not constant and this non stationarity is expressed at different time scales hertig et al 2015 it is therefore not surprising that the relationship between regional weather variables and large scale climate indices is dynamic and non stationary as discussed in other studies nalley et al 2019 figs 5 and 6 demonstrate the extent to which correlations can be found to be absent or statistically significant depending on the chosen time period finding the best time scale for investigating the relationship between weather variables and large scale climate indices is one of the major challenges in this area o brien et al 2019 this study therefore considered 5 different time windows in building the best performing regression model as was shown in the results of fig 7 the precipitation regression models which are established based on shorter windows provide better precipitation estimates in contrast the temperature regression models benefit from longer windows a possible explanation may be related to the concept of historical memory any climate state can be decomposed into two parts the memory part and the weather scale dynamical excitation part hasselmann 1976 the predictability of weather variables is limited by those two terms since measuring the dynamical forcing is challenging attention is mostly concentrated on modeling the internal variability using the existing memory part doblas reyes et al 2013 meehl et al 2014 it has been shown that climate memory has a non negligible impact on most climate variables with the exception of precipitation xie et al 2019 according to earlier studies the long term memory contribution to the modeling and characterization of precipitation is weak and in some cases long term precipitation correlation behaves as white noise in precipitation modeling jiang et al 2017 therefore the precipitation models rely less on the memory part than does the temperature model this can explain why the best temperature models are built based on longer time windows another way of looking at this is simply to realize that at the spatial and temporal scales considered in this study and for the chosen watershed internal climate variability is much more important for precipitation than temperature when compared to the synoptic control of sea surface temperature anomalies these findings are observed in some reginal scale studies precipitation uncertainties are caused mainly by climate variability rather than other sources such as emission scenarios and climate models fatichi et al 2016 hawkins and sutton 2011 trenberth 2012 the influence of each climate index on weather variables was presented in fig 8 these results indicate that many climate indices have a simultaneous influence on the local climate while most of the work in this domain has tended to focus on the main indices e g enso amo nao pdo the results from this study indicate that other indices also have a significant influence a fact that is often neglected in other studies in this work amo and qbo are identified as the two most significant climate indices in precipitation modeling the impact of amo over eastern canada has been relatively widely studied assani et al 2010 but that of qbo which influences convection and precipitation gray et al 2018 has largely been neglected recent studies also suggest that there is a need to improve our understanding of other climate indices in order to increase north american climate predictability hartmann 2015 kug et al 2015 wang et al 2014 the results for the studied watershed indicate that a comparatively larger number of indices are correlated with temperature as compared to precipitation the same findings are obtained in other studies that have attempted to assess the complex interaction between multiple large scale climate indices and weather variables de beurs et al 2018 leathers et al 1991 tomingas 2002 climate studies have shown that temperature variability is largely related to synoptic scale variability while precipitation is significantly more affected by the local scale and is hence driven by large scale circulation to a much lesser extent than is temperature fatichi et al 2016 climate change impact studies have also clearly demonstrated the importance of the spatial scale when looking at precipitation variability fischer and knutti 2014 martel et al 2018 variability becomes less important as we go from the local to the regional scale accordingly looking for relations between precipitation and large scale circulation poses a much bigger challenge at the catchment scale than it would be at the regional scale with the exception of the largest continental size catchments the performance of the proposed method in forecasting mean annual precipitation and temperatures was evaluated and compared to that of historical resampling and using the basic calibrated weather generator results showed that the proposed method reduced both precipitation and the temperature mean annual biases in comparison with the two other methods it improved temperature forecasting for all the time windows considered improvements in precipitation forecasting were more dependent on the time window considered to build the regression model these results were largely transferred to streamflow forecasts after a hydrological model was used the ensemble streamflow forecasts were assessed by looking at the forecast mean annual hydrographs and monthly crps values the results presented in figs 10 and 11 suggest that spring flood can be better estimated when a 10 year or longer time window is used to build the regression models the proposed method performed well at estimating the flood onset this improvement is related to a better temperature estimation as shown in fig 9 temperature is the main driver of snowmelt initiation and therefore plays a key role in the physical processes leading to the onset of the spring flood it has been shown that the flood onset and recession are mainly determined by temperature barnett et al 2005 an under or overestimation of forecast temperatures will affect all streamflow characteristics during the snowmelt period the benchmark methods of resampling and unconditioned weather generator lead to a forecast flood beginning too late on average this results when forecast temperatures are too cold as has also been reported in other studies hongbo et al 2015 liu et al 2019b meng et al 2019 the increasing temperature trend in fig 2 cannot be captured by both benchmark methods the incorporation of large scale climate indices in the forecasting process leads to a better representation of temperature anomalies during the snowmelt period thus leading to better flood forecasts these results were also confirmed in tables 4 and 5 where the nse and mean relative bias were more accurate with the proposed method than with the resampling or simple weather generator approach the proposed method makes use of the fact that the large scale climate indices which are used as the main predictors of the method can be available up to one year ahead or more hermanson and sutton 2010 luo et al 2008 power et al 2006 seitola and järvinen 2014 tian and fan 2015 the experimental setup of this study is based on a hindcasting approach in order to avoid any unnecessary bias due to large scale climate indices predictions and their uncertainty therefore the methodological framework chosen for this study comes with limitations an important one is that the hindcast approach used in this project assumes perfect a priori knowledge of climate indices over the forecasting period in an operational context these values will not be perfectly known as climate indices would also have to be forecast this is not necessarily a problem for decadal indices but it is definitely a challenge for interannual indices such as enso which have been shown to be difficult to accurately forecast ham et al 2019 using the calibrated weather generator on the historical period a user would provide the historical weather historical climate indices and the forecasted climate indices so that the generator s parameters could be estimated for the future period the proposed methodology could be improved in many ways while this work only considered stepwise regression more complex non linear approaches e g neural networks could be used to link climate indices to local climatology since it is known that local scale induced variability is largest in the summer it would likely be beneficial to perform the analysis on a seasonal basis this should result in better performance over the winter season than the performances presented at the annual scale as well this would lessen the problem of having to forecast the climate indices over the longer yearly horizon finally the results presented cannot be generalized to other watersheds since the links between sea surface temperature anomalies and the local climate are region dependent the approach should therefore be tested on other watersheds in addition the hsami model used in this study is a conceptual and lumped model other types of models might react differently to the weather generator outputs and could generate streamflow with different characteristics it could therefore be envisioned to extend the methodology to various types of hydrological models to evaluate the method s performance in a diversity of contexts 6 conclusion this paper presented a long term ensemble streamflow forecasting method in which a stochastic weather generator is conditioned on large scale climate indices to take into account internal climate variability stepwise linear regression models between a subset of 40 climate indices and local climate anomalies are built to represent climate non stationarity for an eastern canadian catchment the stochastic weather generator uses the predicted climate anomalies to produce an ensemble weather forecast this forecast is then fed to a hydrological model to generate long term ensemble streamflow forecasts results show that the proposed method improves long term streamflow forecasts over the studied catchment and especially around the flood peak results also show a strong dependence on the time window duration used in defining the regression models shorter durations are preferable for precipitation whereas longer time windows result in better performance for minimum and maximum temperatures these results are consistent with the larger internal climate variability of precipitation at the catchment scale funding this work was supported by natural sciences and engineering research council of canada ca credit authorship contribution statement samaneh sohrabi conceptualization methodology software validation formal analysis investigation resources data curation writing original draft writing review editing visualization project administration françois p brissette conceptualization methodology software validation formal analysis resources data curation writing review editing visualization supervision project administration funding acquisition richard arsenault validation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
