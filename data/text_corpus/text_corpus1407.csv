index,text
7035,areal reduction factors arfs transform an estimate of extreme rainfall at a point to an estimate of extreme rainfall over a spatial domain and are commonly used in flood risk estimation for applications such as the design of large infrastructure dam safety and land use planning arfs are needed to estimate flood risk for very rare events that are often larger than the biggest historical events the nature of the relationship between arfs and frequency for long return periods is unclear as it depends on the asymptotic dependence structure of rainfall over a region i e the extent to which rainfall from a surrounding region is extreme as rainfall at a point becomes more extreme miscalculating this for very rare events could lead to poor design of infrastructure to investigate this spatial rainfall processes are simulated using asymptotically dependent and independent models and the implications for arfs of the asymptotic assumptions are explored in a synthetic study the models are then applied to a case study in victoria australia using 88 daily rainfall gauges with 50 years of data the analysis shows that the observed data follow the behaviour of an asymptotically independent process leading to arfs that decrease with increasing return period the study demonstrates that the use of inverted max stable process models to simulate arfs can provide a rigorous alternative to empirical approaches particularly for long return periods requiring significant extrapolation from the data keywords areal reduction factor asymptotic dependence asymptotic independence extreme rainfall inverted max stable process max stable process 1 introduction areal reduction factors arfs are commonly employed to convert point based estimates of extreme rainfall usually in the form of intensity frequency duration ifd relationships to a catchment wide rainfall intensity of equivalent exceedance probability ball et al 2016 arfs account for the spatial dependence of rainfall and generally have a value of unity for very small catchment areas where catchment average rainfall is almost equivalent to point rainfall and decrease as the area increases in addition to understanding how arfs scale with area it is important to understand how they scale with the exceedance probability of the extreme rainfall event especially for very rare but high consequence events for which observations are scarce the scaling of arfs with geographic area and frequency is often provided as part of engineering design guidance ball et al 2016 and when combined with ifd maps can be used as an input to flood models approaches to estimating arfs can be classified as empirical or analytic empirical methods describe the observed relationship between distributions of point rainfall extremes and areal extremes for a range of frequencies and areal extents they assume homogeneity of the distribution after rescaling for all points in a region but make no parametric assumptions on the dependence structure of the rainfall process svensson and jones 2010 the implementation depends on whether the method is storm centred or fixed area in the storm centred approach the areal extent is not fixed and the central location the point having maximum rainfall changes with each storm the arf is then calculated based on the concurrent maximal point and areal estimates of rainfall this approach is difficult to implement for multi centre storms and has not seen widespread application asquith and famiglietti 2000 in contrast the fixed area approach myers 1980 omolayo 1993 shaw et al 2011 siriwardena and weinmann 1996 takes an area such as a catchment and constructs the ratio of areal average rainfall and point rainfall at a representative location with both extremes having the same exceedance probability the point and the area extremes may not come from the same event the storm centred approach is sometimes used with probable maximum precipitation storms whereas the fixed area approach is used widely in design methods that by construction preserve a specified event frequency such as the design of drainage systems and hydraulic structures for flood control srikanthan 1995 unlike empirical methods analytic methods are based on statistical models for the spatial dependence of rainfall over a region svensson and jones 2010 an early method used the pairwise correlation between gauges rodriguez iturbe and mejía 1974 assuming various decaying isotropic correlation functions e g exponential bessel and a gaussian process for areal average rainfall another early method involves consideration of partial coverage of catchments where an analytic representation of a storm having specified extent and speed is assumed to cross over the catchment bengtsson and niemczynowicz 1986 more elaborate statistical models have been used as the basis of arfs to better reflect the properties of spatial rainfall including poisson distributed threshold exceedances bacchi and ranzi 1996 multi fractal models that use a scale invariance assumption veneziano and langousis 2005 and max stable models buishand et al 2008 whether empirical or analytical approaches are used to estimate arfs a key question is how arfs scale with rainfall frequency or what is the asymptotic behaviour of arfs where the term asymptotic indicates limiting properties as events become increasingly rare several papers using a variety of methods suggest that arfs decrease with rarer events they include i a fixed area empirical approach applied to a 46 year dataset allen and degaetano 2005 ii an annual maxima centred empirical approach applied to 9 year and 24 year datasets asquith and famiglietti 2000 and iii an analytical approach based on an assumed spatial correlation structure of rainfall estimated from a 4 year dataset sivapalan and blöschl 1998 however a detailed analysis of the tail dependence of spatial rainfall extremes which would assist in understanding the asymptotic behaviour of arfs is still lacking this is particularly critical when extrapolating to rare events given that data availability is typically on the order of several decades but interest often focuses on longer return periods e g 100 or 1000 years tail dependence behaviour for extremes can be classified as asymptotically dependent or asymptotically independent and both can occur in spatial extremes davison et al 2013 thibaud et al 2013 wadsworth and tawn 2012 for asymptotically dependent models the level of dependence stabilizes with increasing return period indicating that the areal coefficient or reduction factor which is equivalent to arfs in hydrology should theoretically be stable above certain high levels coles and tawn 1996 engelke et al 2017 ferreira et al 2012 some papers have used an asymptotically dependent model e g a max stable process to simulate spatial extreme rainfall nicolet et al 2017 padoan et al 2010 westra and sisson 2011 however thibaud et al 2013 suggest that extreme rainfall may be asymptotically independent although their study concerned a mountain catchment with only 575 days of record with 58 missing data making it difficult to assess whether their tentative conclusion can be generalized for asymptotically independent models wadsworth and tawn 2012 the level of dependence declines with increasing return period and intuitively the corresponding arfs should decrease in order to select models suitable for spatial dependence of extreme rainfall and use them to calculate arfs for rare events it is thus critical to confirm whether rainfall is asymptotically dependent or independent to directly explore the relationship between the arfs and return period we perform a simulation study to investigate tail dependence followed by a real case study to simulate the rainfall process models of both asymptotically dependent and independent spatial extremes are introduced and used with the fixed area method to estimate arfs section 2 section 3 describes the data used and the case study which shows how these assumptions change the arfs with return period section 4 1 a diagnostic procedure is used to indicate whether the observed rainfall data are asymptotically dependent or independent before fitting the models and simulating the rainfall process for the case study section 4 2 1 the modelled arfs together with the diagnostic results and the fitted results help to determine the asymptotic dependence structure of the observed rainfall which then suggests the likely behaviour of arfs for long return periods section 4 2 2 our results and their potential implications are discussed in section 5 2 methodology 2 1 modelling for rainfall extremes at a single location for reasons of mathematical simplicity models for spatial extremes have unit fréchet marginal distributions but this is not the case for real rainfall data so marginal modelling is needed so that data simulated on the unit fréchet scale can be transformed to the rainfall scale this study considers the behaviour of extremes that exceed a high threshold u for large u the distribution of y conditional on y u may be approximated by the generalized pareto distribution gpd davison and smith 1990 pickands 1975 thibaud et al 2013 which has distribution function 1 g y 1 1 ξ y u σ u 1 ξ y u defined on y 1 ξ y u σ u 0 where σ u 0 and ξ are scale and shape parameters respectively the probability that a level y is exceeded is then φ u 1 g y where φ u p r y u the selection of the appropriate threshold u involves a trade off between bias and variance too low a threshold will lead to bias due to a poor gpd approximation whereas too high a threshold will lead to high variance due to a small number of excesses two approaches commonly used to determine the appropriate threshold u are the mean residual life and parameter estimate plots coles 2001 davison and smith 1990 which rely on a stability property if a gpd is valid for all excesses above u then those of any threshold greater than u should also follow a gpd 2 2 dependence modelling for spatial rainfall extremes consider a spatial domain x with a stationary stochastic process y x x x r 2 that represents spatial rainfall we say that y x is asymptotically dependent if lim y p y x 1 y y x 2 y 0 for all x 1 x 2 the dependence structure stabilizes at high thresholds on the other hand if lim y p y x 1 y y x 2 y 0 for all x 1 x 2 then we say that y x is asymptotically independent its dependence structure becomes weaker when the threshold increases so that the spatial extent of an extreme event can be expected to diminish as its rarity increases max stable processes are the non degenerate limits for linearly rescaled maxima of random processes and are asymptotically dependent in simplified terms as the maxima become more extreme their distribution retains the same shape after linear rescaling as represented in eq 2 suppose that y k x x x r 2 k 1 m represent m independent realisations of a continuous process indexed by x in a spatial domain x if the limit 2 z x lim m m a x k 1 m y k x b m x a m x exists jointly for all x x r 2 and is non degenerate for some normalising constants a m x 0 and b m x then z x is a max stable process de haan 1984 as mentioned above it is mathematically convenient to consider so called simple max stable processes which have unit fréchet margins the marginal distributions can easily be transformed to the gpd scale all simple max stable processes on x may be represented in the form 3 z x max i 1 w i x u i x x where the u i are points of a unit rate poisson process on 0 and the w i x are independent replicas of a continuous non negative stochastic process w x defined on x with e w x 1 for all x x eq 3 can be interpreted as a rainfall storm process in which w i x represent the storm shapes and 1 u i represents the magnitude at the centre of each storm the inverted max stable process is an example of an asymptotically independent model wadsworth and tawn 2012 let z x be a max stable process as in eq 3 and define 4 ω x 1 z x min i 1 u i w i x x then ω is an asymptotically independent process with standard exponential margins to transform ω to unit fréchet margins the following transformation is used 5 ω x 1 l o g 1 e ω x x x then ω x is an asymptotically independent process with unit fréchet margins from eq 3 and eq 4 different models for w give different max stable and inverted max stable processes this study focuses on two popular and easily simulated classes of max stable processes brown resnick processes where w is a log gaussian process asadi et al 2015 huser and davison 2013 kabluchko et al 2009 oesting et al 2017 and extremal t processes where w is a transformed stationary gaussian process opitz 2013 the next section will provide details of their dependence structures 2 3 fitting of dependence models the dependence structure of the max stable process is encapsulated by the pairwise extremal coefficient θ 1 2 while that of the inverted max stable process is encapsulated by the pairwise residual tail dependence coefficient η 0 1 ledford and tawn 1996 with y x a continuous process the empirical pairwise extremal coefficient θ and the empirical pairwise residual tail dependence coefficient η for each pair of locations x 1 x 2 x are calculated using the formulae 6 θ x 1 x 2 2 lim y p y x 1 y y x 2 y and 7 η x 1 x 2 lim y l o g p y x 2 y l o g p y x 1 y y x 2 y with the probabilities replaced by their empirical counterparts for suitably high values of y typically above the 0 8 quantile of the corresponding distribution the interpretations of θ and η are if θ 2 then y x 1 and y x 2 are asymptotically dependent and necessarily η 1 in this case θ indicates the level of extremal dependence between y x 1 and y x 2 if θ 2 then y x 1 and y x 2 are asymptotically independent and η 1 indicates the level of extremal dependence between y x 1 and y x 2 coles et al 1999 with lower values indicating lower dependence to estimate the dependence structure of the max stable and inverted max stable models the theoretical extremal coefficient and residual tail dependence coefficient functions are usually fitted to their empirical counterparts if the process is stationary and isotropic then they depend only on the euclidean distance h x 1 x 2 between two locations the theoretical extremal coefficient function for the extremal t model is 8 θ h 2 t α 1 α 1 1 ρ h 1 ρ h where t α 1 is a standard univariate student t cdf with α 1 degrees of freedom and ρ h is the correlation function of the stationary gaussian process used to construct the extremal t process for this analysis the powered exponential correlation 9 ρ h e x p h c ν c 0 0 ν 2 is used the theoretical extremal coefficient function for the brown resnick model is 10 θ h 2 φ γ h 2 where φ is the standard normal cumulative distribution function and the variogram γ h h β q for q 0 and β 0 2 these two models are fitted to the empirical extremal coefficients by choosing parameters α c and ν or parameters q and β to minimize the sum of squared errors a similar fitting process is used for the inverted extremal t and inverted brown resnick models the theoretical residual tail dependence coefficient functions for the inverted extremal t and the inverted brown resnick models are and 12 η h 1 2 φ γ h 2 the dependence structures could be fitted more efficiently using likelihood methods both for max stable engelke et al 2015 thibaud and opitz 2015 wadsworth and tawn 2014 and for inverted max stable models wadsworth and tawn 2012 but here we use least squares for simplicity 2 4 estimating arfs using the fixed area approach bell s method siriwardena and weinmann 1996 a fixed area approach to calculating arfs treats them as ratios of spatial rainfall to representative point rainfall at equal recurrence intervals we use this method because it accounts for spatial rainfall patterns and has been used in recent studies bennett et al 2016a jordan et al 2013 li et al 2015 to calculate arfs for the spatial domain x with area a frequency f and duration d we write 13 arf a f d c a d f r d f where c a d f is the spatial rainfall depth for the catchment and r d f is the representative extreme point rainfall calculated as the spatial average of the extreme point rainfall values within the catchment the following steps are needed to calculate arfs using eq 13 step 1 calculate spatial rainfall depth let r denote the set of point rainfall depths for a given duration d for all points x in a spatial domain x and all time intervals t in the data record of length θ with time increment equal to the rainfall duration d such that r r x t x x t 1 θ d for the t th time interval the spatial rainfall depth for a catchment is defined as 14 c t a d 1 a x r x t d x frequency analysis is then applied to c a d c 1 a d c θ d a d to calculate c a d f step 2 estimate representative extreme point rainfall for a catchment the representative point rainfall of a certain frequency denoted by r d f is the spatial average of the extreme point rainfall values within the catchment domain 15 r d f 1 a x r x d f d x where r x d f denotes the rainfall depth corresponding to duration d for a particular location x and frequency f it is also noted that in this paper both integrals in eq 14 and eq 15 were implemented by the thiessen weighted average which is a very simple weighted average based on a geometric relationship between the gauge locations 3 case study and data the case study for this paper uses a relatively densely gauged region in victoria australia fig 1 a bounded by longitudes from 142 0 to 144 1 and latitudes from 38 7 to 36 6 only those gauges with daily data available over a common period from 1960 to 2009 are selected given the length of instrumental records it is difficult to extrapolate arfs for long return periods whereas simulation can achieve this for a model that provides a good match to the marginal distributions the simulation of rainfall is performed for each site within the region fig 1 so that the marginal distribution of each site can be directly compared to observations and so that the results are not confounded by the introduction of a spatial model if the gauges are unrepresentative of the region then bias may be introduced into calculated statistics such as the arf but the region for our case study is relatively homogeneous with evenly spaced gauges if a reliable spatial model of rainfall extremes was available it would be possible to construct the arf based on simulations on a regular grid or specific to a given catchment the source of the daily rainfall data was the australian bureau of meteorology to provide a complete dataset the bureau of meteorology used an algorithm that used the neighbouring rainfall gauges to infill any missing data and to disaggregate accumulated data this study only includes the 88 gauges that had less than 20 of their data filled in most of the region receives between 410 mm and 1200 mm of rainfall per year fig 1b the highest rainfall is in the southernmost part of the domain with two gauges having average annual rainfall above 1900 mm rainfall is higher in winter and spring and lower in summer and autumn although the winter and spring averages are higher than in the other seasons annual maximum daily rainfall events can occur in any season owing to the seasonality only the wetter period from may to october is used to analyse the behaviour of arfs 4 results 4 1 effects of asymptotic dependence structures on the behaviour of arfs with return periods we now present a synthetic study to demonstrate how the asymptotic dependence structure affects the behaviour of arfs for increasing return periods to eliminate the effect of marginal variability we used synthetic constant scale and shape parameters for all locations comparable with those from the real data over a synthetic study domain that is identical with that of the real case study sets of data with unit fréchet margins simulated from the brown resnick and inverted brown resnick models over a spatial domain were transformed to the rainfall scale using these synthetic constant marginal parameters and then areal reduction factors were calculated based on these two sets of simulations as the dependence properties do not depend on the marginal distributions pairwise extremal coefficients and residual tail dependence coefficients can be calculated directly from sets of data with unit fréchet margins on the contrary since the arfs integration on the rainfall scale they are not only affected by the dependence properties but also by the marginal distributions since the focus of the synthetic study is on the behaviour in terms of arfs and the dependence measures θ h and η h rather than on the parametric properties of the models the two sets of simulations need not have identical parameters the pairwise extremal coefficients and residual tail dependence coefficients for different thresholds for each simulation are given in figs 2 and 3 fig 2 indicates that for increasing thresholds the extremal coefficients for asymptotically dependent models stabilize while the residual tail dependence coefficients increase fig 3 shows that for increasing thresholds the asymptotically independent model s extremal coefficients increase while its residual tail dependence coefficients stabilize this behaviour can be used to distinguish asymptotically dependent from asymptotically independent data fig 4 indicates how the behaviour of the corresponding arfs depends on the return period as the return period increases the arfs increase for the asymptotically dependent model and decrease for the asymptotically independent model the arfs from both models seem to converge at very high return periods e g 500 year and 1000 year suggesting that arf behaviour at shorter return periods is pre asymptotic though a limit is reached for long enough return periods as the arfs are sensitive to the asymptotic behaviour it is important to identify the latter correctly 4 2 case study results 4 2 1 modelling the rainfall process to model the rainfall for the case study we first fitted the gpd with appropriate thresholds to the observed daily rainfall data then the extremal t and brown resnick max stable and inverted max stable processes were calibrated as described above each daily record was treated as an independent replicate of the spatial rainfall process by applying standard methods coles 2001 to a subset of the rain stations thresholds at the 0 99 quantile of all daily rainfall values at each site were found to be reasonable the marginal estimates were obtained by fitting the gpd to the excesses above the selected thresholds with the shape parameter taken to be an unknown constant throughout the catchment as in previous studies davison et al 2012 thibaud et al 2013 westra and sisson 2011 the gpd was fitted jointly at all stations via one likelihood function with different scale parameters qq plots which can be found in the supplementary material fig s1 fig s4 show that the marginal estimates are reasonable we implemented a diagnostic procedure to assess tail dependence behaviour for the observed data calculating the empirical pairwise extremal and residual tail dependence coefficients for a range of thresholds for higher thresholds the extremal coefficients increase and the residual tail dependence coefficients stabilize fig 5 so the observed data match the characteristics of the asymptotically independent data discussed in section 4 1 this suggests that we use inverted max stable models to calculate arfs fits of the extremal coefficient function for the max stable processes and the residual tail dependence coefficient function for the inverted max stable processes to their empirical counterparts are shown in fig 6 for two thresholds both asymptotically dependent and independent models fit the observed data well for both thresholds the extremal and tail dependence coefficients fitted at the 0 99 threshold are also presented in the right panel of fig 7 the fitted extremal coefficient functions differ significantly for the two thresholds but the fitted residual tail dependence coefficient functions barely change strongly suggesting that the asymptotically dependent models cannot capture the empirical dependence structure but that the asymptotically independent models can fig 6 shows generally reasonable performance for both asymptotically independent models suggesting that both inverted brown resnick and inverted extremal t models are sufficiently flexible to match the empirical residual tail dependence coefficients although the former appears to perform better for distances over 150 km both models are used to simulate the rainfall process for the case study the max stable processes were simulated using the algorithm of dombry et al 2016 and the inverted max stable processes were obtained via eqs 4 and 5 spatial rainfall processes are obtained by transforming the simulations which have unit fréchet marginal distributions to the scale of the original data using the distribution in eq 1 above the threshold and the empirical distribution of the original data below it this ensures that the simulated rainfall contains zero values dry days thereby mirroring the zeroes in the empirical distribution thibaud et al 2013 this also forces the rainfall simulated below the threshold to have the same fitted extremal dependence structure as rainfall above the threshold which may be inappropriate however the dependence structure for rainfall below the threshold contributes insignificantly to extreme events thibaud et al 2013 and thus is unlikely to influence our results moreover the transformation ensures that the simulated marginal distributions match the observed marginal distributions below the threshold 4 2 2 comparison of analytic arfs to empirical observations for different return periods arfs were calculated using both the observed data and simulated data for different areas and different return periods the asymptotically independent simulated data come from the inverted extremal t and inverted brown resnick models the results in fig 7 show that arfs from both the inverted extremal t and inverted brown resnick models decrease when return periods increase consistent with the observed data for the inverted extremal t model the arfs for 5 and 10 year return periods are significantly under estimated while those for longer return periods are closer to those for the observed data by contrast arfs from the inverted brown resnick model for a 5 year return period almost match that from observed data while arfs for longer return periods give slight overestimates to further evaluate the performance of the inverted extremal t and brown resnick models the arfs from the observed and the simulated data are plotted for different areas at the same return period bootstrapped 95 confidence intervals are estimated for the arfs from observed data by resampling with replacement the observed data from all 88 gauges simultaneously fig 8 shows the results for the inverted extremal t and brown resnick models fig 8 indicates that the performance of the inverted extremal t model is poor as the arfs from simulations at a 5 year return period are significantly too low being outside the 95 confidence band the same is true for the 10 year return period not shown the arfs from simulation of the inverted brown resnick model for both 5 year and 100 year return periods are close to those from observed data and the same is true for 10 year and 50 year return periods not shown here this suggests that the inverted brown resnick model gives better simulated spatial rainfall for the case study fig 8 also shows that the inverted brown resnick model provides smooth arfs at the 100 year return period so it should also be useful when extrapolating to rarer frequencies 5 discussion and conclusions the use of design events with long return periods is common in hydrology e g for large scale infrastructure such as dams or for design along built up water courses in urban environments translating extreme point rainfall to an area leads to significant uncertainty in arfs but there has been limited research into arfs and their underlying assumptions relative to other aspects of the design process moreover arfs are typically based on empirical studies that do not account for analytic tail dependence properties and are limited under extrapolation to rare events we designed a synthetic study to see how different asymptotic assumptions affect the behaviour of arfs with respect to return period using two dependence models to simulate spatial rainfall this indicates that arfs from asymptotically dependent data increase for longer return periods and converge to a limiting state fig 4 appearing stable at 200 500 and 1000 year return periods in contrast arfs from asymptotically independent data decrease for longer return periods the synthetic study also shows that pairwise extremal coefficients for asymptotically dependent data stabilize for increasing thresholds while the pairwise residual tail dependence coefficients increase by contrast as thresholds increase for asymptotically independent data the pairwise extremal coefficients increase but the pairwise residual tail dependence coefficients stabilize these features can be used to assess the asymptotic behaviour of observed data a diagnostic procedure which estimates the pairwise extremal coefficients and pairwise tail dependence coefficients at different thresholds was employed before fitting models to observed data it indicates that the observed data are asymptotically independent fig 5 when fitting the max stable and inverted max stable models to observed rainfall data at different thresholds the results also confirm that only asymptotically independent models can represent the dependence structure of the observed data together with thibaud et al 2013 this suggests that max stable processes may not be suitable for modelling rainfall extremes although this would need to be confirmed by further work future studies about spatial rainfall extremes should take this into consideration this paper has shown that observed arfs follow the behaviour of an asymptotically independent process and that inverted max stable process models are able to reproduce this behaviour to date a significant amount of engineering design has been conducted by decoupling statistics of extremal rainfall at a point as in intensity durationfrequency maps from estimates of rainfall over a region arfs one possibility suggested by our work is to use simulation studies such as in this paper to supplement the derivation of empirical arfs for different regions providing smooth extrapolations of arfs and the ability to calculate localised arfs for individual catchments as with empirical studies we can anticipate significant differences in arfs for different regions another possibility is the direct use of spatiotemporal models of rainfall in the design of infrastructure requiring very rare events as with large dams and water related infrastructure in major urban centres that have high consequence impacts spatiotemporal rainfall models have become increasingly used for hydrologic analysis and design including multi scaling models over and gupta 1996 poisson cluster models leonard et al 2008 and gaussian latent variable models bennett et al 2016b however the development and calibration of these models is typically based on all the data with the extremal properties evaluated as an emergent feature while there has also been increasing attention given to the dependence structure of spatiotemporal extremes including gaussian dependence of multisite extreme rainfall evin et al 2018 renard and lang 2007 and multi scaling frameworks of spatial rainfall panthou et al 2014 veneziano and langousis 2005 there is an ongoing need to provide a rigorous framework for extremes over a region that is also linked to more frequent rainfall our analysis suggests that the rainfall process is asymptotically independent so the arfs decrease for longer return periods the smoothness of the modelled arfs is useful when extrapolating to rare events our findings provide a rigorous foundation for the development of arf curves against both area and frequency as the basis for engineering design acknowledgments the lead author was supported by the australia awards scholarships aas from australia government seth westra was supported by australian research council discovery grant dp150100411 anthony c davison and sebastian engelke were supported by the swiss national science foundation the paper was completed while acd was a visitor at the institute for mathematical sciences national university of singapore and se was a visitor at the department of statistical sciences university of toronto we thank leticia mooney for her help in improving this manuscript the rainfall data used in this study were provided by the australian bureau of meteorology and can be obtained from the corresponding author appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 061 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
7035,areal reduction factors arfs transform an estimate of extreme rainfall at a point to an estimate of extreme rainfall over a spatial domain and are commonly used in flood risk estimation for applications such as the design of large infrastructure dam safety and land use planning arfs are needed to estimate flood risk for very rare events that are often larger than the biggest historical events the nature of the relationship between arfs and frequency for long return periods is unclear as it depends on the asymptotic dependence structure of rainfall over a region i e the extent to which rainfall from a surrounding region is extreme as rainfall at a point becomes more extreme miscalculating this for very rare events could lead to poor design of infrastructure to investigate this spatial rainfall processes are simulated using asymptotically dependent and independent models and the implications for arfs of the asymptotic assumptions are explored in a synthetic study the models are then applied to a case study in victoria australia using 88 daily rainfall gauges with 50 years of data the analysis shows that the observed data follow the behaviour of an asymptotically independent process leading to arfs that decrease with increasing return period the study demonstrates that the use of inverted max stable process models to simulate arfs can provide a rigorous alternative to empirical approaches particularly for long return periods requiring significant extrapolation from the data keywords areal reduction factor asymptotic dependence asymptotic independence extreme rainfall inverted max stable process max stable process 1 introduction areal reduction factors arfs are commonly employed to convert point based estimates of extreme rainfall usually in the form of intensity frequency duration ifd relationships to a catchment wide rainfall intensity of equivalent exceedance probability ball et al 2016 arfs account for the spatial dependence of rainfall and generally have a value of unity for very small catchment areas where catchment average rainfall is almost equivalent to point rainfall and decrease as the area increases in addition to understanding how arfs scale with area it is important to understand how they scale with the exceedance probability of the extreme rainfall event especially for very rare but high consequence events for which observations are scarce the scaling of arfs with geographic area and frequency is often provided as part of engineering design guidance ball et al 2016 and when combined with ifd maps can be used as an input to flood models approaches to estimating arfs can be classified as empirical or analytic empirical methods describe the observed relationship between distributions of point rainfall extremes and areal extremes for a range of frequencies and areal extents they assume homogeneity of the distribution after rescaling for all points in a region but make no parametric assumptions on the dependence structure of the rainfall process svensson and jones 2010 the implementation depends on whether the method is storm centred or fixed area in the storm centred approach the areal extent is not fixed and the central location the point having maximum rainfall changes with each storm the arf is then calculated based on the concurrent maximal point and areal estimates of rainfall this approach is difficult to implement for multi centre storms and has not seen widespread application asquith and famiglietti 2000 in contrast the fixed area approach myers 1980 omolayo 1993 shaw et al 2011 siriwardena and weinmann 1996 takes an area such as a catchment and constructs the ratio of areal average rainfall and point rainfall at a representative location with both extremes having the same exceedance probability the point and the area extremes may not come from the same event the storm centred approach is sometimes used with probable maximum precipitation storms whereas the fixed area approach is used widely in design methods that by construction preserve a specified event frequency such as the design of drainage systems and hydraulic structures for flood control srikanthan 1995 unlike empirical methods analytic methods are based on statistical models for the spatial dependence of rainfall over a region svensson and jones 2010 an early method used the pairwise correlation between gauges rodriguez iturbe and mejía 1974 assuming various decaying isotropic correlation functions e g exponential bessel and a gaussian process for areal average rainfall another early method involves consideration of partial coverage of catchments where an analytic representation of a storm having specified extent and speed is assumed to cross over the catchment bengtsson and niemczynowicz 1986 more elaborate statistical models have been used as the basis of arfs to better reflect the properties of spatial rainfall including poisson distributed threshold exceedances bacchi and ranzi 1996 multi fractal models that use a scale invariance assumption veneziano and langousis 2005 and max stable models buishand et al 2008 whether empirical or analytical approaches are used to estimate arfs a key question is how arfs scale with rainfall frequency or what is the asymptotic behaviour of arfs where the term asymptotic indicates limiting properties as events become increasingly rare several papers using a variety of methods suggest that arfs decrease with rarer events they include i a fixed area empirical approach applied to a 46 year dataset allen and degaetano 2005 ii an annual maxima centred empirical approach applied to 9 year and 24 year datasets asquith and famiglietti 2000 and iii an analytical approach based on an assumed spatial correlation structure of rainfall estimated from a 4 year dataset sivapalan and blöschl 1998 however a detailed analysis of the tail dependence of spatial rainfall extremes which would assist in understanding the asymptotic behaviour of arfs is still lacking this is particularly critical when extrapolating to rare events given that data availability is typically on the order of several decades but interest often focuses on longer return periods e g 100 or 1000 years tail dependence behaviour for extremes can be classified as asymptotically dependent or asymptotically independent and both can occur in spatial extremes davison et al 2013 thibaud et al 2013 wadsworth and tawn 2012 for asymptotically dependent models the level of dependence stabilizes with increasing return period indicating that the areal coefficient or reduction factor which is equivalent to arfs in hydrology should theoretically be stable above certain high levels coles and tawn 1996 engelke et al 2017 ferreira et al 2012 some papers have used an asymptotically dependent model e g a max stable process to simulate spatial extreme rainfall nicolet et al 2017 padoan et al 2010 westra and sisson 2011 however thibaud et al 2013 suggest that extreme rainfall may be asymptotically independent although their study concerned a mountain catchment with only 575 days of record with 58 missing data making it difficult to assess whether their tentative conclusion can be generalized for asymptotically independent models wadsworth and tawn 2012 the level of dependence declines with increasing return period and intuitively the corresponding arfs should decrease in order to select models suitable for spatial dependence of extreme rainfall and use them to calculate arfs for rare events it is thus critical to confirm whether rainfall is asymptotically dependent or independent to directly explore the relationship between the arfs and return period we perform a simulation study to investigate tail dependence followed by a real case study to simulate the rainfall process models of both asymptotically dependent and independent spatial extremes are introduced and used with the fixed area method to estimate arfs section 2 section 3 describes the data used and the case study which shows how these assumptions change the arfs with return period section 4 1 a diagnostic procedure is used to indicate whether the observed rainfall data are asymptotically dependent or independent before fitting the models and simulating the rainfall process for the case study section 4 2 1 the modelled arfs together with the diagnostic results and the fitted results help to determine the asymptotic dependence structure of the observed rainfall which then suggests the likely behaviour of arfs for long return periods section 4 2 2 our results and their potential implications are discussed in section 5 2 methodology 2 1 modelling for rainfall extremes at a single location for reasons of mathematical simplicity models for spatial extremes have unit fréchet marginal distributions but this is not the case for real rainfall data so marginal modelling is needed so that data simulated on the unit fréchet scale can be transformed to the rainfall scale this study considers the behaviour of extremes that exceed a high threshold u for large u the distribution of y conditional on y u may be approximated by the generalized pareto distribution gpd davison and smith 1990 pickands 1975 thibaud et al 2013 which has distribution function 1 g y 1 1 ξ y u σ u 1 ξ y u defined on y 1 ξ y u σ u 0 where σ u 0 and ξ are scale and shape parameters respectively the probability that a level y is exceeded is then φ u 1 g y where φ u p r y u the selection of the appropriate threshold u involves a trade off between bias and variance too low a threshold will lead to bias due to a poor gpd approximation whereas too high a threshold will lead to high variance due to a small number of excesses two approaches commonly used to determine the appropriate threshold u are the mean residual life and parameter estimate plots coles 2001 davison and smith 1990 which rely on a stability property if a gpd is valid for all excesses above u then those of any threshold greater than u should also follow a gpd 2 2 dependence modelling for spatial rainfall extremes consider a spatial domain x with a stationary stochastic process y x x x r 2 that represents spatial rainfall we say that y x is asymptotically dependent if lim y p y x 1 y y x 2 y 0 for all x 1 x 2 the dependence structure stabilizes at high thresholds on the other hand if lim y p y x 1 y y x 2 y 0 for all x 1 x 2 then we say that y x is asymptotically independent its dependence structure becomes weaker when the threshold increases so that the spatial extent of an extreme event can be expected to diminish as its rarity increases max stable processes are the non degenerate limits for linearly rescaled maxima of random processes and are asymptotically dependent in simplified terms as the maxima become more extreme their distribution retains the same shape after linear rescaling as represented in eq 2 suppose that y k x x x r 2 k 1 m represent m independent realisations of a continuous process indexed by x in a spatial domain x if the limit 2 z x lim m m a x k 1 m y k x b m x a m x exists jointly for all x x r 2 and is non degenerate for some normalising constants a m x 0 and b m x then z x is a max stable process de haan 1984 as mentioned above it is mathematically convenient to consider so called simple max stable processes which have unit fréchet margins the marginal distributions can easily be transformed to the gpd scale all simple max stable processes on x may be represented in the form 3 z x max i 1 w i x u i x x where the u i are points of a unit rate poisson process on 0 and the w i x are independent replicas of a continuous non negative stochastic process w x defined on x with e w x 1 for all x x eq 3 can be interpreted as a rainfall storm process in which w i x represent the storm shapes and 1 u i represents the magnitude at the centre of each storm the inverted max stable process is an example of an asymptotically independent model wadsworth and tawn 2012 let z x be a max stable process as in eq 3 and define 4 ω x 1 z x min i 1 u i w i x x then ω is an asymptotically independent process with standard exponential margins to transform ω to unit fréchet margins the following transformation is used 5 ω x 1 l o g 1 e ω x x x then ω x is an asymptotically independent process with unit fréchet margins from eq 3 and eq 4 different models for w give different max stable and inverted max stable processes this study focuses on two popular and easily simulated classes of max stable processes brown resnick processes where w is a log gaussian process asadi et al 2015 huser and davison 2013 kabluchko et al 2009 oesting et al 2017 and extremal t processes where w is a transformed stationary gaussian process opitz 2013 the next section will provide details of their dependence structures 2 3 fitting of dependence models the dependence structure of the max stable process is encapsulated by the pairwise extremal coefficient θ 1 2 while that of the inverted max stable process is encapsulated by the pairwise residual tail dependence coefficient η 0 1 ledford and tawn 1996 with y x a continuous process the empirical pairwise extremal coefficient θ and the empirical pairwise residual tail dependence coefficient η for each pair of locations x 1 x 2 x are calculated using the formulae 6 θ x 1 x 2 2 lim y p y x 1 y y x 2 y and 7 η x 1 x 2 lim y l o g p y x 2 y l o g p y x 1 y y x 2 y with the probabilities replaced by their empirical counterparts for suitably high values of y typically above the 0 8 quantile of the corresponding distribution the interpretations of θ and η are if θ 2 then y x 1 and y x 2 are asymptotically dependent and necessarily η 1 in this case θ indicates the level of extremal dependence between y x 1 and y x 2 if θ 2 then y x 1 and y x 2 are asymptotically independent and η 1 indicates the level of extremal dependence between y x 1 and y x 2 coles et al 1999 with lower values indicating lower dependence to estimate the dependence structure of the max stable and inverted max stable models the theoretical extremal coefficient and residual tail dependence coefficient functions are usually fitted to their empirical counterparts if the process is stationary and isotropic then they depend only on the euclidean distance h x 1 x 2 between two locations the theoretical extremal coefficient function for the extremal t model is 8 θ h 2 t α 1 α 1 1 ρ h 1 ρ h where t α 1 is a standard univariate student t cdf with α 1 degrees of freedom and ρ h is the correlation function of the stationary gaussian process used to construct the extremal t process for this analysis the powered exponential correlation 9 ρ h e x p h c ν c 0 0 ν 2 is used the theoretical extremal coefficient function for the brown resnick model is 10 θ h 2 φ γ h 2 where φ is the standard normal cumulative distribution function and the variogram γ h h β q for q 0 and β 0 2 these two models are fitted to the empirical extremal coefficients by choosing parameters α c and ν or parameters q and β to minimize the sum of squared errors a similar fitting process is used for the inverted extremal t and inverted brown resnick models the theoretical residual tail dependence coefficient functions for the inverted extremal t and the inverted brown resnick models are and 12 η h 1 2 φ γ h 2 the dependence structures could be fitted more efficiently using likelihood methods both for max stable engelke et al 2015 thibaud and opitz 2015 wadsworth and tawn 2014 and for inverted max stable models wadsworth and tawn 2012 but here we use least squares for simplicity 2 4 estimating arfs using the fixed area approach bell s method siriwardena and weinmann 1996 a fixed area approach to calculating arfs treats them as ratios of spatial rainfall to representative point rainfall at equal recurrence intervals we use this method because it accounts for spatial rainfall patterns and has been used in recent studies bennett et al 2016a jordan et al 2013 li et al 2015 to calculate arfs for the spatial domain x with area a frequency f and duration d we write 13 arf a f d c a d f r d f where c a d f is the spatial rainfall depth for the catchment and r d f is the representative extreme point rainfall calculated as the spatial average of the extreme point rainfall values within the catchment the following steps are needed to calculate arfs using eq 13 step 1 calculate spatial rainfall depth let r denote the set of point rainfall depths for a given duration d for all points x in a spatial domain x and all time intervals t in the data record of length θ with time increment equal to the rainfall duration d such that r r x t x x t 1 θ d for the t th time interval the spatial rainfall depth for a catchment is defined as 14 c t a d 1 a x r x t d x frequency analysis is then applied to c a d c 1 a d c θ d a d to calculate c a d f step 2 estimate representative extreme point rainfall for a catchment the representative point rainfall of a certain frequency denoted by r d f is the spatial average of the extreme point rainfall values within the catchment domain 15 r d f 1 a x r x d f d x where r x d f denotes the rainfall depth corresponding to duration d for a particular location x and frequency f it is also noted that in this paper both integrals in eq 14 and eq 15 were implemented by the thiessen weighted average which is a very simple weighted average based on a geometric relationship between the gauge locations 3 case study and data the case study for this paper uses a relatively densely gauged region in victoria australia fig 1 a bounded by longitudes from 142 0 to 144 1 and latitudes from 38 7 to 36 6 only those gauges with daily data available over a common period from 1960 to 2009 are selected given the length of instrumental records it is difficult to extrapolate arfs for long return periods whereas simulation can achieve this for a model that provides a good match to the marginal distributions the simulation of rainfall is performed for each site within the region fig 1 so that the marginal distribution of each site can be directly compared to observations and so that the results are not confounded by the introduction of a spatial model if the gauges are unrepresentative of the region then bias may be introduced into calculated statistics such as the arf but the region for our case study is relatively homogeneous with evenly spaced gauges if a reliable spatial model of rainfall extremes was available it would be possible to construct the arf based on simulations on a regular grid or specific to a given catchment the source of the daily rainfall data was the australian bureau of meteorology to provide a complete dataset the bureau of meteorology used an algorithm that used the neighbouring rainfall gauges to infill any missing data and to disaggregate accumulated data this study only includes the 88 gauges that had less than 20 of their data filled in most of the region receives between 410 mm and 1200 mm of rainfall per year fig 1b the highest rainfall is in the southernmost part of the domain with two gauges having average annual rainfall above 1900 mm rainfall is higher in winter and spring and lower in summer and autumn although the winter and spring averages are higher than in the other seasons annual maximum daily rainfall events can occur in any season owing to the seasonality only the wetter period from may to october is used to analyse the behaviour of arfs 4 results 4 1 effects of asymptotic dependence structures on the behaviour of arfs with return periods we now present a synthetic study to demonstrate how the asymptotic dependence structure affects the behaviour of arfs for increasing return periods to eliminate the effect of marginal variability we used synthetic constant scale and shape parameters for all locations comparable with those from the real data over a synthetic study domain that is identical with that of the real case study sets of data with unit fréchet margins simulated from the brown resnick and inverted brown resnick models over a spatial domain were transformed to the rainfall scale using these synthetic constant marginal parameters and then areal reduction factors were calculated based on these two sets of simulations as the dependence properties do not depend on the marginal distributions pairwise extremal coefficients and residual tail dependence coefficients can be calculated directly from sets of data with unit fréchet margins on the contrary since the arfs integration on the rainfall scale they are not only affected by the dependence properties but also by the marginal distributions since the focus of the synthetic study is on the behaviour in terms of arfs and the dependence measures θ h and η h rather than on the parametric properties of the models the two sets of simulations need not have identical parameters the pairwise extremal coefficients and residual tail dependence coefficients for different thresholds for each simulation are given in figs 2 and 3 fig 2 indicates that for increasing thresholds the extremal coefficients for asymptotically dependent models stabilize while the residual tail dependence coefficients increase fig 3 shows that for increasing thresholds the asymptotically independent model s extremal coefficients increase while its residual tail dependence coefficients stabilize this behaviour can be used to distinguish asymptotically dependent from asymptotically independent data fig 4 indicates how the behaviour of the corresponding arfs depends on the return period as the return period increases the arfs increase for the asymptotically dependent model and decrease for the asymptotically independent model the arfs from both models seem to converge at very high return periods e g 500 year and 1000 year suggesting that arf behaviour at shorter return periods is pre asymptotic though a limit is reached for long enough return periods as the arfs are sensitive to the asymptotic behaviour it is important to identify the latter correctly 4 2 case study results 4 2 1 modelling the rainfall process to model the rainfall for the case study we first fitted the gpd with appropriate thresholds to the observed daily rainfall data then the extremal t and brown resnick max stable and inverted max stable processes were calibrated as described above each daily record was treated as an independent replicate of the spatial rainfall process by applying standard methods coles 2001 to a subset of the rain stations thresholds at the 0 99 quantile of all daily rainfall values at each site were found to be reasonable the marginal estimates were obtained by fitting the gpd to the excesses above the selected thresholds with the shape parameter taken to be an unknown constant throughout the catchment as in previous studies davison et al 2012 thibaud et al 2013 westra and sisson 2011 the gpd was fitted jointly at all stations via one likelihood function with different scale parameters qq plots which can be found in the supplementary material fig s1 fig s4 show that the marginal estimates are reasonable we implemented a diagnostic procedure to assess tail dependence behaviour for the observed data calculating the empirical pairwise extremal and residual tail dependence coefficients for a range of thresholds for higher thresholds the extremal coefficients increase and the residual tail dependence coefficients stabilize fig 5 so the observed data match the characteristics of the asymptotically independent data discussed in section 4 1 this suggests that we use inverted max stable models to calculate arfs fits of the extremal coefficient function for the max stable processes and the residual tail dependence coefficient function for the inverted max stable processes to their empirical counterparts are shown in fig 6 for two thresholds both asymptotically dependent and independent models fit the observed data well for both thresholds the extremal and tail dependence coefficients fitted at the 0 99 threshold are also presented in the right panel of fig 7 the fitted extremal coefficient functions differ significantly for the two thresholds but the fitted residual tail dependence coefficient functions barely change strongly suggesting that the asymptotically dependent models cannot capture the empirical dependence structure but that the asymptotically independent models can fig 6 shows generally reasonable performance for both asymptotically independent models suggesting that both inverted brown resnick and inverted extremal t models are sufficiently flexible to match the empirical residual tail dependence coefficients although the former appears to perform better for distances over 150 km both models are used to simulate the rainfall process for the case study the max stable processes were simulated using the algorithm of dombry et al 2016 and the inverted max stable processes were obtained via eqs 4 and 5 spatial rainfall processes are obtained by transforming the simulations which have unit fréchet marginal distributions to the scale of the original data using the distribution in eq 1 above the threshold and the empirical distribution of the original data below it this ensures that the simulated rainfall contains zero values dry days thereby mirroring the zeroes in the empirical distribution thibaud et al 2013 this also forces the rainfall simulated below the threshold to have the same fitted extremal dependence structure as rainfall above the threshold which may be inappropriate however the dependence structure for rainfall below the threshold contributes insignificantly to extreme events thibaud et al 2013 and thus is unlikely to influence our results moreover the transformation ensures that the simulated marginal distributions match the observed marginal distributions below the threshold 4 2 2 comparison of analytic arfs to empirical observations for different return periods arfs were calculated using both the observed data and simulated data for different areas and different return periods the asymptotically independent simulated data come from the inverted extremal t and inverted brown resnick models the results in fig 7 show that arfs from both the inverted extremal t and inverted brown resnick models decrease when return periods increase consistent with the observed data for the inverted extremal t model the arfs for 5 and 10 year return periods are significantly under estimated while those for longer return periods are closer to those for the observed data by contrast arfs from the inverted brown resnick model for a 5 year return period almost match that from observed data while arfs for longer return periods give slight overestimates to further evaluate the performance of the inverted extremal t and brown resnick models the arfs from the observed and the simulated data are plotted for different areas at the same return period bootstrapped 95 confidence intervals are estimated for the arfs from observed data by resampling with replacement the observed data from all 88 gauges simultaneously fig 8 shows the results for the inverted extremal t and brown resnick models fig 8 indicates that the performance of the inverted extremal t model is poor as the arfs from simulations at a 5 year return period are significantly too low being outside the 95 confidence band the same is true for the 10 year return period not shown the arfs from simulation of the inverted brown resnick model for both 5 year and 100 year return periods are close to those from observed data and the same is true for 10 year and 50 year return periods not shown here this suggests that the inverted brown resnick model gives better simulated spatial rainfall for the case study fig 8 also shows that the inverted brown resnick model provides smooth arfs at the 100 year return period so it should also be useful when extrapolating to rarer frequencies 5 discussion and conclusions the use of design events with long return periods is common in hydrology e g for large scale infrastructure such as dams or for design along built up water courses in urban environments translating extreme point rainfall to an area leads to significant uncertainty in arfs but there has been limited research into arfs and their underlying assumptions relative to other aspects of the design process moreover arfs are typically based on empirical studies that do not account for analytic tail dependence properties and are limited under extrapolation to rare events we designed a synthetic study to see how different asymptotic assumptions affect the behaviour of arfs with respect to return period using two dependence models to simulate spatial rainfall this indicates that arfs from asymptotically dependent data increase for longer return periods and converge to a limiting state fig 4 appearing stable at 200 500 and 1000 year return periods in contrast arfs from asymptotically independent data decrease for longer return periods the synthetic study also shows that pairwise extremal coefficients for asymptotically dependent data stabilize for increasing thresholds while the pairwise residual tail dependence coefficients increase by contrast as thresholds increase for asymptotically independent data the pairwise extremal coefficients increase but the pairwise residual tail dependence coefficients stabilize these features can be used to assess the asymptotic behaviour of observed data a diagnostic procedure which estimates the pairwise extremal coefficients and pairwise tail dependence coefficients at different thresholds was employed before fitting models to observed data it indicates that the observed data are asymptotically independent fig 5 when fitting the max stable and inverted max stable models to observed rainfall data at different thresholds the results also confirm that only asymptotically independent models can represent the dependence structure of the observed data together with thibaud et al 2013 this suggests that max stable processes may not be suitable for modelling rainfall extremes although this would need to be confirmed by further work future studies about spatial rainfall extremes should take this into consideration this paper has shown that observed arfs follow the behaviour of an asymptotically independent process and that inverted max stable process models are able to reproduce this behaviour to date a significant amount of engineering design has been conducted by decoupling statistics of extremal rainfall at a point as in intensity durationfrequency maps from estimates of rainfall over a region arfs one possibility suggested by our work is to use simulation studies such as in this paper to supplement the derivation of empirical arfs for different regions providing smooth extrapolations of arfs and the ability to calculate localised arfs for individual catchments as with empirical studies we can anticipate significant differences in arfs for different regions another possibility is the direct use of spatiotemporal models of rainfall in the design of infrastructure requiring very rare events as with large dams and water related infrastructure in major urban centres that have high consequence impacts spatiotemporal rainfall models have become increasingly used for hydrologic analysis and design including multi scaling models over and gupta 1996 poisson cluster models leonard et al 2008 and gaussian latent variable models bennett et al 2016b however the development and calibration of these models is typically based on all the data with the extremal properties evaluated as an emergent feature while there has also been increasing attention given to the dependence structure of spatiotemporal extremes including gaussian dependence of multisite extreme rainfall evin et al 2018 renard and lang 2007 and multi scaling frameworks of spatial rainfall panthou et al 2014 veneziano and langousis 2005 there is an ongoing need to provide a rigorous framework for extremes over a region that is also linked to more frequent rainfall our analysis suggests that the rainfall process is asymptotically independent so the arfs decrease for longer return periods the smoothness of the modelled arfs is useful when extrapolating to rare events our findings provide a rigorous foundation for the development of arf curves against both area and frequency as the basis for engineering design acknowledgments the lead author was supported by the australia awards scholarships aas from australia government seth westra was supported by australian research council discovery grant dp150100411 anthony c davison and sebastian engelke were supported by the swiss national science foundation the paper was completed while acd was a visitor at the institute for mathematical sciences national university of singapore and se was a visitor at the department of statistical sciences university of toronto we thank leticia mooney for her help in improving this manuscript the rainfall data used in this study were provided by the australian bureau of meteorology and can be obtained from the corresponding author appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 061 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
7036,reservoirs and dams are vital human built infrastructures that play essential roles in flood control hydroelectric power generation water supply navigation and other functions the realization of those functions requires efficient reservoir operation and the effective controls on the outflow from a reservoir or dam over the last decade artificial intelligence ai techniques have become increasingly popular in the field of streamflow forecasts reservoir operation planning and scheduling approaches in this study three ai models namely the backpropagation bp neural network support vector regression svr technique and long short term memory lstm model are employed to simulate reservoir operation at monthly daily and hourly time scales using approximately 30 years of historical reservoir operation records this study aims to summarize the influence of the parameter settings on model performance and to explore the applicability of the lstm model to reservoir operation simulation the results show the following 1 for the bp neural network and lstm model the effects of the number of maximum iterations on model performance should be prioritized for the svr model the simulation performance is directly related to the selection of the kernel function and sigmoid and rbf kernel functions should be prioritized 2 the bp neural network and svr are suitable for the model to learn the operation rules of a reservoir from a small amount of data and 3 the lstm model is able to effectively reduce the time consumption and memory storage required by other ai models and demonstrate good capability in simulating low flow conditions and the outflow curve for the peak operation period keywords reservoir operation artificial intelligence bp neural network svr lstm 1 introduction half of the major global river systems are affected by reservoirs and dams and human beings manage and utilize water resources through reservoirs for power generation water supply navigation disaster prevention flood control and mitigation drought relief dynesius and nilsso 1994 wcd 2000 icold 2011 lehner et al 2011 shang et al 2018 in recent years many countries including china have also actively adopted reservoir operations to mitigate the adverse effects of reservoirs and maintain the health of river ecosystems the scientific calculation simulation and prediction of reservoir storage or release as well as the development of proper reservoir operation plans are important to achieve all types of reservoir functions and to avoid danger to humans and river ecology loucks and sigvaldason 1981 starting in the 1980s with the development of hydrology hydraulics and river dynamics conceptual or physical based models such as hec ressim weap21 etc have been proposed and are widely used in reservoir hydrological process simulation and reservoir operation decisions klipsch and hurst 2003 yates et al 2005 such models transform the empirical mechanical and blind operation patterns of early reservoir operations that were based on historical hydrological statistics operated by so called rule curves physical based models provide a more practical physical and mathematical basis for the calculation of controlled releases or storage see table 1 however the practical application scenarios of reservoir operation are extremely complex and involve multiple time scales and multiflow regimes often accompanied by occasional emergencies a reservoir should undertake the medium and long term seasonal and monthly scale operation task of managing downstream water supply and optimization of economic benefit reservoirs should also undertake short term daily and hourly scale operation tasks of managing power grid load water demand navigation and stimulation of fish breeding disaster prevention emergency operations during floods droughts these various scheduling scenarios illustrate that the actual operation process of a reservoir is rapidly changing and often deviates from the operation plan these deviations often make it difficult for the physical model based on the operation rule to accurately simulate reservoir operation and predict the reservoir controlled releases johnson et al 1991 oliveira and loucks 1997 in addition when the physical model needs to be rebuilt with a new scheduling rule the demand for the professional expertise of the reservoir operator is high and the calculation time of the model cannot meet the requirements of emergency operation reservoir operation is the result of multiple factors with strongly nonlinear interactions which are influenced by natural conditions such as precipitation runoff agricultural irrigation and human needs such as industrial production water consumption power grid peak shaving flood peak shaving these complex factors have uncertainty and increase the difficulty of using physical based models in recent years with the development of artificial intelligence ai and big data mining technology data driven ai models have become important in various fields this kind of model does not heavily rely on physical meaning but is good at solving nonlinear simulation and prediction problems that are influenced by multiple complex factors at present ai models have been successfully extended to the reservoir operation field in contrast to physical based models ai models have the ability to autonomously learn the various reservoir operation rules from a large amount of hydrological data and the real time reservoir operation data moreover ai models need low professional requirements from operators and have fast response speeds hejazi and cai 2009 among the many ai models artificial neural networks ann and support vector machine or regression svm or svr are the two most typical models in the field of reservoir operation ann models benefit from the proposed backpropagation algorithm bp the bp solves the training problem of the neural network which gives the ann models good nonlinear prediction ability many scholars have successfully promoted ann in the reservoir operation field thirumalaiah and deo 1998 jain et al 1999 chaves and chang 2008 then to further improve the accuracy of the ann model some scholars coupled the ann algorithm with other ai algorithms and explored the application of the improved ann algorithm in reservoir management for example chaves and chang 2008 improved ann by combining them with a genetic algorithm and verified the applicability of the improved ann in reservoir operation simulation chen and chang 2009 combined evolutionary algorithm and ann and proposed a new evolutionary ann algorithm for reservoir inflow prediction with increased ann model research the limitations of ann have been highlighted such as local optimal solutions and gradient disappearance which limit the application of the model yang et al 2017a at this time the svm algorithm invented by cortes and vapnik 1995 is better than ann in many aspects with fast training speed and global optimal solutions the svr algorithm is derived from svm which is similar to the svm algorithm and it is one of the most widely used ai models in the reservoir operation field lin et al 2006 hipni et al 2013 yang et al 2017b meanwhile some scholars coupled the svr algorithm with other ai algorithms and explored the application of the improved svr algorithm in reservoir management khalil et al 2005 su et al 2013 ji et al 2014 aboutalebi et al 2015 for example aboutalebi et al 2015 coupled the nondominated sorting genetic algorithm and svr algorithm and applied the coupled model to optimize reservoir operation rules in addition to the above two classic ai algorithms many other ai algorithms have been successfully applied to the reservoir operation field such as genetic algorithm ga adaptive network based fuzzy inference system anfis decision tree dt chang and chang 2001 and chang et al 2005 coupled the ga and anfis and applied the coupled model to estimate reservoir storage or release yang et al 2016 used the improved dt algorithm classification and regression tree to reasonably estimate the storage or release of 9 reservoirs in california although the above ai algorithms have been proved to be applicable to the estimation of reservoir storage or release those algorithms still have some shortcomings such as insufficient feature extraction capability and longer time consumption in recent years a new type of machine learning method i e deep learning has gradually become the frontier of computer science and technology and has achieved great success in the fields of computer vision speech recognition and natural language processing deep learning derived from ann is a new field in machine learning research this algorithm has been proven as an abstract high level representation of attribute categories or characteristics through the combination of low level features and can significantly improve recognition accuracy girshick et al 2014 lecun et al 2015 lstm model is a widely used deep learning model which is applied to hydrological forecasting because of its ability to solve complex scheduling problems zhang et al 2018 zaytar and amrani 2016 and zhang et al 2018 applied the lstm model to forecast weather and urban sewage pipeline overflow respectively they obtained satisfactory results and verified the validity of lstm in the prediction of timing problems shi et al 2015 improved the traditional lstm model proposed a convolutional lstm convlstm and used it to build an end to end trainable model for the precipitation nowcasting problem on the spatial and temporal scale and the application of the lstm model has been extended from a one dimension temporal sequence to a two dimension spatial and temporal sequence because lstm is a new type of deep learning model it has few reports in the field of reservoir operation in recent years research on ai models in the field of reservoir operation has developed rapidly but there are still many shortcomings first at present ai model research focuses on a specific case problem often a single time scale or flow regime and lacks a systematic comparison of the simulation effect of the model with complex operation scenarios multiscale and multiflow regime second the deep learning model as a popular ai model has a strong ability to address the time series problem but whether the model can address the reservoir operation problem effectively and accurately is unknown third the parameter setting is the key technology of ai model building however investigations of different parameters among those models and comprehensive comparison studies are rarely reported therefore in this study we selected three ai models 1 a benchmark three layer backpropagation bp neural network 2 an svr technique and 3 the long short term memory lstm model and constructed a reservoir operation model with three time scales including hourly daily and monthly scale to analyze the sensitivity of applying ai models to reservoir operation for case study we choose gezhouba gzb reservoir in china which had relatively complete detail and long sequence operation records to test the simulation performance of three models at various flow regimes including 1 low flow 2 intermediate flow and 3 high flow in summary the goals of this study are 1 to summarize the influence of the parameter settings on model performance and propose parameter settings for different ai models in assisting reservoir operation 2 to compare the simulation results under different time scales and flow regimes and propose suggestions for the applicability of ai models under different inflow scenarios and 3 to explore the superiority of the lstm model over traditional ai models in assisting reservoir operations and investigate the improvement of prediction accuracy and calculation speed 2 methodology 2 1 bp neural network ann are mathematical models of biologically motivated computation haykin 1994 and they are known as flexible modeling tools with the ability to provide a neural computing approach for processing complex problems that might otherwise not be solved with a mathematical formula yang et al 2017a ann application in hydrology started in the early 1990s in the last decade ann have been applied to hydrology including rainfall runoff modeling wu and chau 2011 chiang et al 2004 streamflow forecasting moradkhani et al 2004 anctil et al 2004 ground water johnson and rogers 2000 reservoir operation chaves et al 2004 jain et al 1999 cheng et al 2015 in this study a feed forward neural network is used in combination with an error backpropagation training algorithm namely the bp neural network the bp neural network consists of one input layer one or more hidden layers and one output layer fig 1 the important issues in the establishment of topological structure include the determination of the number of hidden layers the number of hidden neurons nodes and the transfer function the kolmogorov theorem has certified that a single hidden layer is competent for ann to approximate any complicated nonlinear function and establish a nonlinear mapping between the input and output layers therefore this study establishes a three layer bp neural network the topological configuration and the selection of the activation function are illustrated in fig 1 in contrast to the signal the error is backward propagated and in the process of backward propagation the weights and deviations of the network are gradually adjusted to complete the training the interested readers are referred to thirumalaiah and deo 1998 jain and srinivasulu 2004 fernando and shamseldin 2009 senthil kumar et al 2012 for further details 2 2 svr the basic concept of svr is to nonlinearly map the initial data in a higher dimensional feature space and to solve the linear regression problem in the feature space fig 2 therefore svr usually needs to build a suitable function f x to describe the nonlinear relationship between feature x i and target value y i as shown in the following eq 4 1 f x i w φ x i b where w is the coefficient vector φ xi is the transformation function and w and b represent the weight and bias respectively w and b are estimated by minimizing the so called regularized risk function as shown in the following eq 5 2 r w 1 2 w 2 c i 1 n l ε y i f x i where 1 2 w 2 is the regularization term c is the penalty coefficient l ε y i f x i is the ε insensitive loss function which is calculated according to eq 6 3 l ε y i f x i max 0 y i f x i ε where ε denotes the permitted error threshold so that ε will be ignored if the predicted value is within the threshold otherwise the loss equals a value greater than ε to solve the optimization boundary two slack factors ξ and ξ are introduced 4 min f w ξ ξ 1 2 w 2 c i 1 n ξ ξ subject to 5 y i w φ x i b ε ξ ξ 0 w φ x i b y i ε ξ ξ 0 the key is to develop a lagrangian function according to the objective function and the corresponding constraint conditions 6 max h i i 1 2 i 1 n j 1 n i i j j k x i x j i 1 n y i i i ε i 1 n y i i i subject to 7 i 1 n i i 0 i i 0 c hence the regression function is as follows 8 f x i 1 n i i k x i x j b where k xi xj is the kernel function in this study the simulation effect of kernel function is tested include the linear polynomial radial basis function rbf and sigmoid kernels as shown in the following equation 9 linear k e r n e l k x x i x x i polynomial k e r n e l k x x i γ x x i b d radial b a s i s f u n c t i o n k e r n e l k x x i exp x x i 2 σ 2 sigmoid k e r n e l k x x i tanh γ x x i v where d is the degree of the polynomial term v represents the residuals and γ is the structural parameter in the polynomial rbf and sigmoid kernels different d γ and penalty coefficient c values will be tested in the paper 2 3 lstm long short term memory is a complex recurrent model developed by hochreiter and schmidhuber 1997 to address the deficiencies of rnns in contrast to rnns lstms apply memory blocks to replace the hidden layer of rnns in this paper the lstm network consists of parallel memory blocks recurrently connected to each other lying between an input layer and an output layer and the conceptual illustration is shown in fig 3 the lstm block was obtained from gers et al 2000 and it consists of an input gate a memory cell a forget gate and an output gate as shown in fig 4 the corresponding forward propagation equations are presented below for our lstm the first step is to decide what information to remove from the cell state by the forget gate the forget gate is essentially a sigmoid function the forget gate will generate an ft value between 0 and 1 based on the previous moment output ht 1 and current input xt to decide whether to let the information ct 1 that is produced in the previous moment pass or partially pass which is depicted by eq 13 10 f t σ w xf x t w hf h t 1 b f the next step is to decide what new information will be stored in the cell state the step is divided into two parts first the input gate determines which values will be updated second the memory cell generates a vector of new candidate values ct which can be added to the cell state in the next step we combine eqs 14 and 15 to update the state 11 i t σ w xi x t w hi h t 1 b i 12 c t f t c t 1 i t t a n h w xc x t w hc h t 1 b c finally we decide what information we are going to output first we decide what parts of the cell state to output by running a sigmoid layer then we resize the c t value to 1 to 1 through tanh and multiply it by the output of the sigmoid gate so that we output only the target information 13 o t σ w xo x t w ho h t 1 b o 14 h t o t tanh c t in eqs 13 17 f i c o and h are the forget gate input gate cell output gate and hidden output respectively wx and wh in eqs 15 17 are the input and hidden weights for the gates or cells with the corresponding subscripts b in eqs 15 17 represents learnable biases for the gates and σ and tanh represent the gate activation function the logistic sigmoid in this paper and the hyperbolic tangent activation function respectively in this study we establish a three layer lstm network that consists of one input layer one lstm hidden layer and one output layer and we train the network with an algorithm termed backpropagation through time bptt which has a similar principle to the bp algorithm by using a backpropagation network to continuously adjust the weights and thresholds werbos 1990 3 data and processing 3 1 case reservoir and operation data the gezhouba gzb dam is the first dam across yangtze river which built after the founding of new china fig 5 it located in yichang city of hubei province approximately 38 km downstream of the three gorges dam plays a role in power generation flood control navigation and fisheries and provides other comprehensive benefits gzb is a large scale water project that controls a drainage area of 1 106 m2 accounting for more than half of the yangtze river basin the mean annual discharge of this reservoir is 14 300 m3 s the design flood discharge is 86 000 m3 s the normal water level is 66 0 m the maximum dam height is 53 8 m and the total storage is 15 8 108 m3 gzb reservoir has relatively mature operating rules and complete detail and long sequence operation records these records cover all kinds of operating scenarios such as the flood control drought relief peaking generation navigation and fish spawning stimulation etc and provide a large number of operating data for machine learning in this study the reservoir hydrological data and operation data were obtained from the official website of china three gorges corporation http www ctg com cn the gzb data span a period of more than 30 years from 1982 to 2015 the data include the inflow and outflow of the reservoir and the water level upstream and downstream of the dam measured every six hours or four hours when the flood peak passes through the reservoir all reservoir operating indicators are more intensive monitored these data were aggregated into daily and monthly time scales 3 2 model building and inputs in this study we use selected artificial intelligence and data mining tools namely the bp neural network svr and lstm to simulate the gzb reservoir operation at monthly daily and hourly scales the hourly data refer to the reservoir operation data collected every two or four hours gzb reservoir operation data span the period from 27 june 1981 to 7 september 2015 based on the commonly accepted 80 20 split rule the data from 1 january 2008 to 7 september 2015 are used as the test period and the remainder are used for training as shown in table 2 the reservoir operation data are imported as model input decision variables and output target variable specifically the inputs include current and previous inflow 1 moment lag previous outflow 1 moment lag the current and previous water level in front of the dam 1 moment lag the current and previous water level of the downstream region 1 moment lag and the current time month of year therefore 9 inputs are included in the model the model output is the current outflow of the reservoir to match the consistency of the model all source data were normalized in the range 0 0 1 0 and were then transformed to original values after the simulation using the normalized equation is as follows 15 x x ori x min x max x min where x is the normalized value xori is the original value and xmin and xmax are the respective minimum and maximum original values the input construction was standardized for all methods i e bp svr and the lstm model to ensure an impartial comparison 3 3 parameterization and setting to illustrate the strengths and weaknesses of the different ai methods different parameterizations are used for bp svr and lstm in bp four maximum iteration mi numbers are tested i e 1 105 5 105 1 106 and 2 106 in combination with different numbers of hidden nodes i e 5 10 15 and 20 in svr four types of kernel functions are set i e linear rbf polynomial and sigmoid kernel functions with different penalty coefficients c 20 values are selected from 0 0001 to 10 000 according to the geometric progression gamma γ 20 values are selected from 0 0001 to 10 000 according to the geometric progression and degree d i e 2 3 4 therefore for linear kernel function we test 20 set of parameterizations for rbf and sigmoid kernel function we test 400 set of parameterizations and for polynomial kernel function we test 1200 set of parameterizations then a performance comparison is conducted among various types of kernel functions in combination with the optimal parameters with respect to the lstm model different mi numbers are tested including 50 75 100 and 200 iterations in combination with various numbers of hidden nodes i e 10 20 30 40 and 50 specific parameter configurations are described in the results and discussion sections 3 4 model evaluation statistics to mathematically quantify the skill of the model simulations four statistical measures are calculated the root mean square error rmse rmse observation standard deviation ratio rsr and the nash sutcliffe model efficiency coefficient nse nash and sutcliffe 1970 the indices rmse and rsr are valuable because they indicate error in the units or squared units of the constituent of interest which contributes to result analysis and rmse and rsr values of 0 indicate a perfect fit the nse is a normalized statistic that determines the relative magnitude of the residual variance compared to the measured data variance nash and sutcliffe 1970 nse values range from negative infinity to 1 with 1 indicating an exact match between simulated and observed values as suggested by previous studies an rmse value less than half the standard deviation of the observed data may be considered low and if rsr 0 7 and nse 0 5 model performance can be considered satisfactory singh et al 2010 moriasi et al 2007 yang et al 2017b the equations of the selected statistics are shown below eqs 19 20 16 rmse i 0 n s i o i 2 n 17 rsr rmse stde v obs i 0 n s i o i 2 i 0 n o i o i 2 18 nse 1 i 0 n o i s i 2 i 0 n o i o i 2 where oi and si are the respective observed and simulated values for outflows o s and s i are the respective average observed and simulated inflows and n is the total number of observations in eq 21 r α and β represent the correlation coefficient variability and bias ratio between the simulations and observations respectively to estimate the uncertainty associated with model simulations the residuals of testing sets are computed and analyzed the analysis consists of three components independence analysis heteroscedastic analysis and normality analysis the implementation methods consist of plotting graphs of residual autocorrelation residual variation relative to observed values and residual probability distributions figs 11 13 the residual independent analysis is based on residual autocorrelation if the residual sequence is autocorrelated then the model fails to fully explain the variation rule of the variable and there is some regularity that is not explained which eventually leads to a larger prediction deviation of the model on the other hand low residual heteroscedasticity and a close approximation to the normal distribution indicate the model is closer to unbiased estimation and has low uncertainty the so called residual is the difference between the predicted value and the actual observed value which is calculated according to eq 22 19 e i o i s i where ei represents residuals oi represents observed values and si represents predicted values in this paper the model residuals were standardized before the residual analysis and the process is as follows 20 r s i e i σ where rs represents standardized residuals and σ represents the standard deviation all the experiments presented in this study were performed on an inter r xeon r cpu e5 2660 v3 2 60 ghz with 64 gb ddr3 1600 mhz memory 4 results 4 1 comparison of simulation results for different time scales in this section the observed gzb reservoir outflows are compared with simulated results based on the three different ai models i e the bp neural network svr and lstm model combined with various model parameters first our results show that bp neural network and lstm the number of hidden nodes and maximum iterations are two key parameters that affect the simulation accuracy moreover there is no obvious regularity about the effect of the number of hidden nodes on simulation accuracy but the increase of the number of maximum iterations can significantly improve the simulation accuracy of the two models figs 6 and 7 with respect to svr the choice of kernel function can directly affect the model accuracy our results show that at monthly scale the simulation accuracy is ranked as sigmoid polynomial rbf linear among the different kernel functions at daily scale the best accuracy ranking is sigmoid rbf linear polynomial and at hourly scale the best accuracy ranking is sigmoid rbf polynomial linear table 4 on the other hand the prediction performances of the bp neural network svr and lstm model are shown in tables 3 5 and figs 8 10 the calculation results show that at the monthly scale the best rmse values obtained by the bp neural network svr and lstm model are 1122 827 1932 814 and 161 712 the best rsr values are 0 1411 0 2429 and 0 0203 and the best nse values are 0 9799 0 9404 and 0 9996 respectively tables 3 5 the best simulation results are shown in fig 8 when the best statistical results are achieved the mi and h of the bp neural network are 2 106 and 15 respectively the kernel function of svr is sigmoid the respective values of γ and c are 0 1265 and 3 728 and the mi and h of the lstm model are 200 and 50 respectively tables 3 5 according to the comparison among different models the best accuracy ranking is the lstm model bp neural network svr with respect to the daily time scale the best rmse values generated using the bp neural network svr and lstm model are 1073 402 1332 720 and 663 723 the best rsr values are 0 1253 0 1556 and 0 0230 and the best nse values are 0 9843 0 9758 and 0 9935 respectively tables 3 5 the best simulation results are shown in fig 9 when the best statistical results are obtained the mi and h of the bp neural network are 2 106 and 5 respectively table 3 the kernel function of svr is sigmoid and the values of γ and c are 0 0869 and 2 560 respectively table 4 in addition the mi and h of the lstm model are 200 and 20 respectively table 5 according to our experimental results the best accuracy ranking is the lstm model bp neural network svr tables 3 5 fig 9 the results of the hourly time scale suggest that the best rmse values produced by the bp neural network svr and lstm model are 1596 052 1051 484 and 488 121 the best rsr values are 0 1885 0 1242 and 0 0577 and the best nse values are 0 9645 0 9846 and 0 9967 respectively tables 3 5 the best simulation results are shown in fig 10 when the best statistical results are achieved the mi and h of the bp neural network are 2 106 and 20 respectively table 3 the kernel function of svr is sigmoid the values of γ and c are 0 0464 and 2 783 respectively table 4 and the mi and h of the lstm model are 75 and 50 respectively table 5 notably within a day gezhouba peak load dispatching operation according to the inflow conditions and peak frequency modulation to meet the demand of the power grid and to stabilize the flow regime of the reservoir therefore compared with the monthly and daily scales the hourly model needs to consider the predicted accuracy of outflow for the peak operation period fig 10 shows that the simulation accuracy of the lstm model is higher than that of the bp neural network and svr during the peak load dispatching operation period overall the best accuracy ranking is the lstm model svr bp neural network in addition to the simulation accuracy the calculation speed is also an important index to measure the performance of a model in this paper the time consumption is used as an evaluation index to compare the calculation speed of the three models the experimental results show that there are significant differences in the calculation speed among the three models and the three time scales in general the time consumption is ranked as the bp neural network svr lstm model among the different models and as the hourly scale daily scale monthly scale among the different time scales the bp neural network is the longest running model and the time consumption increases as mi increases table 3 the time consumption associated with optimal results at the monthly daily and hourly scales is 74 05 56 519 31 23 and 786 13 09 respectively table 3 in addition to the time scale the time consumption of svr is also related to the selected kernel function and the time consumption is ranked as polynomial sigmoid rbf linear the time consumption associated with optimal results at the monthly daily and hourly scales is 5 47 49 26 03 and 204 16 42 respectively table 4 similar to the bp neural network the time consumption of the lstm model is related to the time scale and mi which manifests as an increase in the time consumption with an increase in mi and the time consumption associated with optimal statistical results for the lstm algorithm is 6 37 04 and 1 5 21 for the monthly daily and hourly scales respectively table 5 it should be noted that the time consumption of the lstm model is significantly lower than that of the bp neural network and svr tables 3 5 4 2 residuals analysis as shown in figs 11 13 to evaluate the uncertainty of the models residual analysis is performed on the best statistical results of the three models at different time scales at the monthly scale the experimental results show that the r s of the svr model has a significant autocorrelation and the acf presents a trend of alternating positive and negative variations as the lag changes fig 11b compared with svr the autocorrelation of r s for the bp neural network and lstm model is weak and the acf lies mainly in the 95 confidence interval fig 11a c fig 9d f show the scatter points of r s as a function of observed reservoir outflows it is clear that the r s values do not appear to be randomly distributed over the flow interval for each model and the r s of the lstm model shows an obvious increasing trend with an increase in outflow fig 11g i display the probability density distribution of r s for the three models the results show that the probability density distribution curve of r s for the bp neural network is flat with obvious skewness and the values of r s are mainly distributed between 1 and 3 fig 11g with respect to the svr model the probability density of r s shows a bimodal distribution ranging mainly between 2 and 0 fig 11h the r s of the lstm model presents a unimodal distribution with a sharp peak and the r s values are mainly distributed between 2 and 2 fig 11i at the daily scale the autocorrelation of r s for the lstm model is the weakest whereas the r s values of the bp neural network and svr model show remarkable autocorrelation fig 12a c the r s values of the three models exhibit heteroscedasticity as the observed outflow changes compared with the bp neural network and svr the spatial distribution of r s with observed outflow for the lstm model is relatively uniform fig 12d f the probability density of r s for the bp neural network displays a unimodal distribution ranging mainly between 1 and 1 fig 12g the r s of svr has a multimodal distribution with three peaks two high and one low distributed at 1 2 0 and 1 4 respectively fig 12h the r s of the lstm model presents a unimodal distribution with a sharp peak and r s is mainly distributed between 1 and 2 fig 12i the experimental results show that at the hourly scale autocorrelation of r s is found in all three models fig 13a c the acf values of the bp neural network and svr are positive with periodic increases or decreases as the lag changes fig 13a and b the acf values of the lstm model present a trend of alternating positive and negative variations as the lag changes and also exhibit the phenomenon of periodic increases or decreases the r s values of all three models exhibit heteroscedasticity fig 13d f the probability density curve of r s for the bp neural network model has a single peak ranging mainly between 1 and 2 and obvious mainly positive skewness is exhibited fig 13g the distribution of r s for the svr model is also unimodal and a wide distribution is evident between 4 and 2 fig 13h with respect to the lstm model the probability density curve of r s is unimodal and r s is densely distributed mainly between 1 and 1 fig 13i 4 3 comparison of simulation results for different flow regimes the experimental results of section 4 2 show that model uncertainty varies with observed flow to better determine the ability of the models to reproduce different flow regimes the models with the best simulation results are evaluated for three specific regimes i e low intermediate and high flow conditions the division of these flow regimes is based on the calculation of the inflow frequency distribution curve the flow regimes are categorized by using the 25th and 75th percentiles and the flow limit is 5985 m3 s and 18 050 m3 s respectively the model accuracy for the different flow regimes is graphically represented in three scatter plots figs 14 16 and is measured in terms of rmse rsr and nse table 6 the experimental results show that in general the lstm model has a significant advantage with respect to simulation accuracy and this model can produce more accurate simulation results for each time scale and flow regime specifically at the monthly scale the comparison results show that the evaluation index values of the lstm model are the best and the simulation accuracy is the highest the comparison results of the two other models show that under low flow conditions the simulation accuracy of these two models is not ideal i e the rsr value is greater than 1 and the nse value is negative under intermediate and high flow conditions the simulation accuracy of the two latter models meets the evaluation criteria and the accuracy of the bp neural network simulation is higher than that of svr table 6 fig 14 at the daily time scale the simulation accuracy of the lstm model is significantly higher than that of the two other models under low flow conditions poor simulation is observed for the bp neural network and svr and it is difficult to obtain satisfactory results under intermediate and high flow conditions both of these models exhibit satisfactory simulation results the simulation accuracy of the svr model is slightly higher than that of the bp neural network under intermediate flow conditions whereas the simulation accuracy of the bp neural network is higher than that of svr under high flow conditions table 6 fig 15 at the hourly scale the lstm model also shows higher prediction accuracy than the bp neural network and svr table 6 the simulation accuracy of the bp neural network and svr is poor under low flow conditions under intermediate and high flow conditions the simulation accuracy of the two models meets the evaluation criteria the simulation accuracy of svr is higher than that of the bp neural network under intermediate flow conditions whereas the simulation accuracy of the bp neural network is slightly higher than that of svr under high flow conditions table 6 fig 16 5 discussion 5 1 suggestions for model parameterization parameter setting has always been the focus of the performance research of ai models in this study we test the influence of different parameter combinations on the performance of three selected ai models first we explore the effect of the maximum number of iterations and the number of hidden nodes on the accuracy of a bp neural network according to the statistics shown in table 3 for the bp neural network 1 in general an increase in the number of maximum iterations can improve the simulation accuracy and 2 the effects of the number of hidden nodes on the simulation accuracy are uncertain and irregular in addition selection of the appropriate number of hidden nodes can help improve the statistics as shown in table 3 the best bp neural network statistics for the three time scales are consistently achieved by a maximum number of iterations equal to 2 106 in the use of the bp neural network in our study an error backpropagation combined with a gradient descent algorithm is employed as the number of maximum iterations increases the gradient optimization scheme continuously explores the response surface of the objective function eq 3 and the evolution is not completed until the algorithm reaches the preset error value or the allowable number of maximum iterations however as the search evolves with more iterations the gradient of the objective function will decrease consequently any further increase in the maximum iteration number results in less improvement in the objective function value as shown for the 1 106 and 2 106 maximum iteration scenarios in table 3 in addition to ensure that the network training reaches the maximum number of iterations the error value is set as 0 0001 which is significantly lower than that of the model our results show that choosing the appropriate number of hidden nodes can significantly improve model accuracy but the effect of the number of hidden nodes on accuracy is unpredictable the best bp neural network statistics for the monthly daily and hourly time scales are obtained when the number of hidden nodes is 15 5 and 20 respectively table 3 as mentioned in yao 1999 the number of hidden nodes in ann is crucial for model performance and should be jointly designed and optimized with a proper training algorithm as such the number of hidden nodes is one of the research hotspots in the ann field it is generally believed that determination of the number of hidden nodes is related to the number of input and output nodes lippmann 1987 chen 1996 moody and antsaklis 1996 nevertheless studies have not adopted a universally accepted method for choosing the number of hidden nodes at present the number of hidden nodes is usually determined by trial and error with the objective of minimizing the cost function with respect to svr we examine the influence of the kernel function on the simulation performance based on an optimal structural parameter γ penalty coefficients c and degree d for the polynomial the kernel function is introduced to map the linear nonseparable training sample from the input space to the feature space thereby realizing the linear separability of the training samples in the feature space in this way a linear classifier can be used to divide the training samples after mapping in the feature space as shown in table 4 svr models are able to produce satisfactory results but the simulation accuracy and time consumption differ significantly among different kernel functions our results show that regardless of the time scale the best simulation accuracy is consistently generated by the sigmoid kernel function however the time consumption of this function is relatively long table 4 this is not consistent with previous research and most reviewed studies have suggested that rbf is the most appropriate kernel function that tends to exhibit satisfactory performance yaseen et al 2015 however technological research conducted on the kernel function shows that any kernel function has its own advantages and limitations because of different training samples and kernel functions have different classification abilities amari and wu 1999 asefa et al 2006 yang et al 2017b the sigmoid kernel function is derived from ann and has been proved to have good global classification performance lin and lin 2005 our results also show that the classification performance of the sigmoid kernel function is better than that of other kernel functions for our training sample with respect to the lstm model we mainly consider the influence of the number of maximum iterations and hidden nodes on model performance and the main results in this paper are as follows 1 an increase in the number of maximum iterations improves the precision of the lstm model and 2 a change in the number of hidden nodes affects the simulation accuracy but the function is weak and irregular as shown in table 5 when the number of maximum iterations increases from 50 to 75 the model accuracy is effectively increased but increasing the number of maximum iterations to greater than 100 does not improve accuracy further based on an advanced investigation we deduce that model accuracy is not improved further because the training process of the lstm model adopts the bptt algorithm which has a similar principle as the classical bp algorithm the bptt algorithm uses a forward algorithm to calculate the output value backward calculates the error of each individual lstm cell and continuously updates the network weight extending the direction to reduce the error with the narrowing of the gap between the model s output value and the desired output value the decline rate of the model error tends to slow down so an increase in the number of maximum iterations does not significantly improve model precision when the number of maximum iterations reaches a certain limit however unlike the bp neural network the number of iterations required for lstm model convergence is much smaller than the bp neural network our analysis indicates that the reason for this result is that the lstm model has strong feature extraction capabilities which ensures that the model can extract the characteristic information of the data more efficiently and complete the convergence process quickly according to our experimental results we cannot specify how to achieve the best statistics by choosing the number of hidden nodes however it is worth noting that while the number of iterations is the same the changes of number of hidden node have only a limited effect on the simulation accuracy at present studies that examine the influence of the number of hidden nodes on the precision of lstm models are rarely reported wielgosz et al 2017 tested the influence of the number of hidden nodes on simulation accuracy and concluded that for their test data the simulation accuracy was highest when the number of hidden nodes was 32 but the effect of different numbers of hidden nodes on model accuracy was not discussed in detail in conclusion we believe that priority should be given to the number of maximum iterations in the bp neural network and lstm model building and a reasonable increase the number of maximum iterations can significantly improve the model accuracy in contrast the number of hidden nodes has a weak effect on model accuracy for the svr model the selection of kernel function is the key to model construction combined with previous research results we believe that sigmoid and rbf kernel function can be considered the priority object meanwhile in the process of model construction due to differences in data volume and structure model parameters have different influences on model performance therefore we suggest that the model should be repeatedly trained before practical application to determine the optimal parameters and ensure the prediction ability of the model 5 2 suggestions for the applicability of ai models under different scenarios the ai model has the ability to address complex nonlinear prediction problems which is widely applied in the field of reservoir operation simulation at present reports on the performance comparison and analysis of ai models are common but such reports mainly focus on the global precision comparison analysis of a single time scale however analyzing the global and extreme event simulation performance of the model from multiple time scales is the key to the model comprehensive learning operation rule and generating long and short term operation plans for different scenarios therefore in this study we analyzed the simulation results of the bp neural network svr and lstm under different time scales and flow regimes from three aspects of model accuracy uncertainty and calculation speed based on the above analysis we explored the guiding significance of three ai models for reservoir long and short term operation and the coping capacity of three ai models for extreme inflow conditions such as drought and flood and we summarized the application scenarios of each model in order to provide a reference for the practical application of these model first the application effect of the bp neural network in reservoir operation was studied in the 1990s the emergence of bp algorithm greatly facilitated the development of ann and effectively promoted the research of ann algorithms in the field of reservoir operation in our study the bp neural network was applied to the reservoir operation simulation and the results showed that for reservoir long term operation monthly scale the simulation accuracy of the ann model is good the uncertainty is weak and the time consumption is long at the daily scale the accuracy of the bp model still met the evaluation criteria but the residuals were autocorrelated and exhibited heteroscedasticity and the time consumption increased at the hourly scale due to the further increase in data volume the disadvantages of the model regarding the uncertainty and time consumption are more obvious table 3 thus we consider that if the model is able to learn the operation rule of a reservoir from a small amount of data such as the research of reservoir long term operations or the influence factors of reservoir operations the bp neural network can obtain satisfactory simulation accuracy and the time consumption is not too long so it can be used for the simulation of reservoir operations however for large reservoirs and the short term fine operation of reservoirs the data that are required by the model learning reservoir operation rules are large due to the large number of influencing factors in this case the time consumption of the bp neural network is too long and the applicability is weak on the other hand for different flow regimes the results show that under intermediate and high flow conditions the bp neural network can obtain satisfactory results but under low flow conditions the bp neural network has poor simulation results and is not suitable for simulation of low inflow scenarios because the feature extraction ability is poor the training time of the bp neural network is too long and the practical application is limited the emergence of the svr algorithm partly compensates for the deficiency in bp neural networks the svr algorithm introduces the lagrangian method to simplify the quadratic optimization problem in svr calculations and introduces the kernel function to reduce the complexity of high dimensional computations thus allowing the svr model to calculate the high efficiency characteristics this paper first compares the processing power of the model to different time scale problems the results show that the svr algorithm can attain satisfactory statistics but compared with the bp neural network the two models have advantages and disadvantages at monthly and daily time scales the accuracy of the bp neural network model is higher than svr and at the hourly time scale the calculation accuracy of the svr model is higher than that of the bp neural network tables 3 and 4 in this study the simulation ability of the model to different time scale problems reflects the processing power of the model to different data volumes to some extent therefore the bp neural network has a stronger processing capability than svr when the data volume is small whereas the advantages of the svr model are gradually revealed when the data volume is large next we compared the differences in calculation speed and the uncertainty of the two models and the results show that compared with the bp neural network the computing speed of the svr model significantly increased but the time was still very long and the uncertainty of the svr model is high tables 3 and 4 finally under different flow regimes our research results show that svr still does not overcome the problem that the bp neural network cannot simulate low flow conditions table 6 figs 14 16 in view of the above problems namely that the simulated speed of the traditional ai models is slow the accuracy needs to be increased and it is difficult to address extreme events we turned our attention to the lstm model which performed well in solving the time series problems taking the gzb reservoir as an example this paper constructs an lstm model to predict the outflow of the gzb reservoir and explores the application of lstm in reservoir operations the results show that the lstm model effectively makes up for the deficiency of the traditional ai models whether from the accuracy uncertainty calculation speed extreme conditions processing the lstm has significant advantages over the bp neural network and svr tables 3 6 figs 8 16 especially at the hourly scale facing vast amounts of data lstm performance is outstanding and the training and prediction process takes only approximately an hour meanwhile lstm is the only one of the three models that can accurately simulate the outflow curve of gzb for the peaking operation period fig 10 the experimental results for show that the lstm model overcomes the disadvantage of previous models i e poor simulation accuracy for extreme events and the lstm model can accurately predict reservoir outflow under low and high inflow conditions in conclusion compared with the bp neural network and svr the lstm model has significant advantages in terms of simulation accuracy stability and computing speed and we believe that lstm as a deep learning model has a strong sequential predictive ability and can be used for reservoir operation simulations at present the application of the lstm model in reservoir operation has been rarely reported but zhang et al 2018 arrived at similar conclusions in the study of sewage overflow prediction which can provide some reference for us zhang et al 2018 compared the predictive effects of the lstm and svr models on sewage discharge and the results showed that the simulation accuracy of the lstm model was significantly higher than that of the svr model which was similar to our conclusion in summary with respect to the ai model applicability the bp neural network is suitable if the model is able to learn the operation rule of a reservoir from a small amount of data such as the research of reservoir long term operations or if the influence factors of reservoir operation are small for large reservoirs short term fine operation of reservoirs and low inflow conditions the applicability of the bp neural network is weak the main limitation of the bp neural network is that the independent feature extraction ability of the network is poor so the time consumption required for satisfactory results is too long the applicability of the svr model and the bp neural network is similar although the svr model improves computing speed its ability to address massive data and low inflow conditions is still insufficient by contrast the lstm model has obvious advantages and can quickly and accurately simulate the reservoir operation under various time scales and flow conditions therefore lstm can be used for medium and long term reservoir operation and short term refinement operation simulation as well as to address various emergencies meanwhile the lstm effectively solves the time consumption problems of the bp neural network and svr model corrects for the fact that traditional ai cannot simulate low flow conditions or the outflow curve for the peak operation period 6 conclusions reservoir operation is an important part of reservoir management and the theory and method of reservoir operation have been gradually developed with the construction of reservoirs and hydropower stations in the early 20th century at present according to the theoretical basis of the model reservoir operation models are divided into two main categories models based on physical concepts and ai models based on data mining technology however a physical based model is useful only if the operating rules incorporated in the simulation can realistically reflect the actual operation in practice the operation of a reservoir is affected by many uncertain factors such as natural conditions and artificial demand and the operation often deviates from the operating rules which limits the application of such models ai models or data driven models are able to autonomously learn the operating rules from the historical operation data of a reservoir and thus have greater robustness and are good at dealing with complex factors this paper investigated the usefulness of two traditional ai models bp neural network and svr and a new deep learning model lstm model in assisting reservoir operation detailed discussion and recommendation are made with respect to the process of model parameter settings the simulation performances and the applications of employed ai models under different flow regimes and temporal resolution the main conclusions are as follows 1 with respect to parameter setting our results show for the bp neural network and lstm model the effects of the number of maximum iterations on model performance should be prioritized the effects of the number of hidden nodes on model performance are limited for the svr model the simulation performance is directly related to the selection of the kernel function combined with previous research results we consider that sigmoid and rbf kernel functions should be prioritized in uses of svr model meanwhile in the process of model construction due to differences in data volume and structure model parameters have a different influence on model performance therefore we suggest that the model should be repeatedly trained before practical application to determine the optimal parameters and ensure the prediction ability of the model 2 with respect to the ai model applicability the bp neural network is suitable if the model is able to learn the operation rule of a reservoir from a small amount of data such as the research of reservoir long term operation or if the influence factors of reservoir operation are small for large reservoirs short term fine operation of reservoirs and low inflow conditions the applicability of the bp neural network is weak the main reason to limit the application of the bp neural network is that the independent feature extraction ability of the network is poor so the time consumption required for satisfactory results is long the applicable conditions of the svr model and bp neural network are similar although the svr model improves computing speed its ability to address massive data and low inflow conditions is still insufficient by contrast the lstm model has obvious advantages and can quickly and accurately simulate the reservoir operation under various time scales and flow conditions therefore lstm can be used for medium and long term reservoir operation and short term refinement operation simulation as well as to address various emergencies 3 the lstm model can effectively solves the time consumption problem associated with the bp neural network and svr model and it has superior performances over other ai models in simulating reservoir operation during low flow conditions or the outflow curve for the peak operation period whereas traditional bp neural network and svr model tend to fail acknowledgement the data presented in this paper are available at the official website of the china three gorges corporation cdec http www ctg com cn this paper is a part of a joint cooperation between the china institute of water resources and hydropower research and the university of california irvine this work was supported by the national key research and development program of china no 2016yfe0102400 the research program of songhua river hydroelectric power generation co ltd the fengman dam reconstruction program construction bureau jsfw 2015 198 the scientific research program for the china three gorges corporation 0799564 the fundamental research funds for the china institute of water resources and hydropower research sd0145b162017 the u s department of energy doe prime award de ia0000018 and california energy commission cec award 300 15 005 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 050 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 
7036,reservoirs and dams are vital human built infrastructures that play essential roles in flood control hydroelectric power generation water supply navigation and other functions the realization of those functions requires efficient reservoir operation and the effective controls on the outflow from a reservoir or dam over the last decade artificial intelligence ai techniques have become increasingly popular in the field of streamflow forecasts reservoir operation planning and scheduling approaches in this study three ai models namely the backpropagation bp neural network support vector regression svr technique and long short term memory lstm model are employed to simulate reservoir operation at monthly daily and hourly time scales using approximately 30 years of historical reservoir operation records this study aims to summarize the influence of the parameter settings on model performance and to explore the applicability of the lstm model to reservoir operation simulation the results show the following 1 for the bp neural network and lstm model the effects of the number of maximum iterations on model performance should be prioritized for the svr model the simulation performance is directly related to the selection of the kernel function and sigmoid and rbf kernel functions should be prioritized 2 the bp neural network and svr are suitable for the model to learn the operation rules of a reservoir from a small amount of data and 3 the lstm model is able to effectively reduce the time consumption and memory storage required by other ai models and demonstrate good capability in simulating low flow conditions and the outflow curve for the peak operation period keywords reservoir operation artificial intelligence bp neural network svr lstm 1 introduction half of the major global river systems are affected by reservoirs and dams and human beings manage and utilize water resources through reservoirs for power generation water supply navigation disaster prevention flood control and mitigation drought relief dynesius and nilsso 1994 wcd 2000 icold 2011 lehner et al 2011 shang et al 2018 in recent years many countries including china have also actively adopted reservoir operations to mitigate the adverse effects of reservoirs and maintain the health of river ecosystems the scientific calculation simulation and prediction of reservoir storage or release as well as the development of proper reservoir operation plans are important to achieve all types of reservoir functions and to avoid danger to humans and river ecology loucks and sigvaldason 1981 starting in the 1980s with the development of hydrology hydraulics and river dynamics conceptual or physical based models such as hec ressim weap21 etc have been proposed and are widely used in reservoir hydrological process simulation and reservoir operation decisions klipsch and hurst 2003 yates et al 2005 such models transform the empirical mechanical and blind operation patterns of early reservoir operations that were based on historical hydrological statistics operated by so called rule curves physical based models provide a more practical physical and mathematical basis for the calculation of controlled releases or storage see table 1 however the practical application scenarios of reservoir operation are extremely complex and involve multiple time scales and multiflow regimes often accompanied by occasional emergencies a reservoir should undertake the medium and long term seasonal and monthly scale operation task of managing downstream water supply and optimization of economic benefit reservoirs should also undertake short term daily and hourly scale operation tasks of managing power grid load water demand navigation and stimulation of fish breeding disaster prevention emergency operations during floods droughts these various scheduling scenarios illustrate that the actual operation process of a reservoir is rapidly changing and often deviates from the operation plan these deviations often make it difficult for the physical model based on the operation rule to accurately simulate reservoir operation and predict the reservoir controlled releases johnson et al 1991 oliveira and loucks 1997 in addition when the physical model needs to be rebuilt with a new scheduling rule the demand for the professional expertise of the reservoir operator is high and the calculation time of the model cannot meet the requirements of emergency operation reservoir operation is the result of multiple factors with strongly nonlinear interactions which are influenced by natural conditions such as precipitation runoff agricultural irrigation and human needs such as industrial production water consumption power grid peak shaving flood peak shaving these complex factors have uncertainty and increase the difficulty of using physical based models in recent years with the development of artificial intelligence ai and big data mining technology data driven ai models have become important in various fields this kind of model does not heavily rely on physical meaning but is good at solving nonlinear simulation and prediction problems that are influenced by multiple complex factors at present ai models have been successfully extended to the reservoir operation field in contrast to physical based models ai models have the ability to autonomously learn the various reservoir operation rules from a large amount of hydrological data and the real time reservoir operation data moreover ai models need low professional requirements from operators and have fast response speeds hejazi and cai 2009 among the many ai models artificial neural networks ann and support vector machine or regression svm or svr are the two most typical models in the field of reservoir operation ann models benefit from the proposed backpropagation algorithm bp the bp solves the training problem of the neural network which gives the ann models good nonlinear prediction ability many scholars have successfully promoted ann in the reservoir operation field thirumalaiah and deo 1998 jain et al 1999 chaves and chang 2008 then to further improve the accuracy of the ann model some scholars coupled the ann algorithm with other ai algorithms and explored the application of the improved ann algorithm in reservoir management for example chaves and chang 2008 improved ann by combining them with a genetic algorithm and verified the applicability of the improved ann in reservoir operation simulation chen and chang 2009 combined evolutionary algorithm and ann and proposed a new evolutionary ann algorithm for reservoir inflow prediction with increased ann model research the limitations of ann have been highlighted such as local optimal solutions and gradient disappearance which limit the application of the model yang et al 2017a at this time the svm algorithm invented by cortes and vapnik 1995 is better than ann in many aspects with fast training speed and global optimal solutions the svr algorithm is derived from svm which is similar to the svm algorithm and it is one of the most widely used ai models in the reservoir operation field lin et al 2006 hipni et al 2013 yang et al 2017b meanwhile some scholars coupled the svr algorithm with other ai algorithms and explored the application of the improved svr algorithm in reservoir management khalil et al 2005 su et al 2013 ji et al 2014 aboutalebi et al 2015 for example aboutalebi et al 2015 coupled the nondominated sorting genetic algorithm and svr algorithm and applied the coupled model to optimize reservoir operation rules in addition to the above two classic ai algorithms many other ai algorithms have been successfully applied to the reservoir operation field such as genetic algorithm ga adaptive network based fuzzy inference system anfis decision tree dt chang and chang 2001 and chang et al 2005 coupled the ga and anfis and applied the coupled model to estimate reservoir storage or release yang et al 2016 used the improved dt algorithm classification and regression tree to reasonably estimate the storage or release of 9 reservoirs in california although the above ai algorithms have been proved to be applicable to the estimation of reservoir storage or release those algorithms still have some shortcomings such as insufficient feature extraction capability and longer time consumption in recent years a new type of machine learning method i e deep learning has gradually become the frontier of computer science and technology and has achieved great success in the fields of computer vision speech recognition and natural language processing deep learning derived from ann is a new field in machine learning research this algorithm has been proven as an abstract high level representation of attribute categories or characteristics through the combination of low level features and can significantly improve recognition accuracy girshick et al 2014 lecun et al 2015 lstm model is a widely used deep learning model which is applied to hydrological forecasting because of its ability to solve complex scheduling problems zhang et al 2018 zaytar and amrani 2016 and zhang et al 2018 applied the lstm model to forecast weather and urban sewage pipeline overflow respectively they obtained satisfactory results and verified the validity of lstm in the prediction of timing problems shi et al 2015 improved the traditional lstm model proposed a convolutional lstm convlstm and used it to build an end to end trainable model for the precipitation nowcasting problem on the spatial and temporal scale and the application of the lstm model has been extended from a one dimension temporal sequence to a two dimension spatial and temporal sequence because lstm is a new type of deep learning model it has few reports in the field of reservoir operation in recent years research on ai models in the field of reservoir operation has developed rapidly but there are still many shortcomings first at present ai model research focuses on a specific case problem often a single time scale or flow regime and lacks a systematic comparison of the simulation effect of the model with complex operation scenarios multiscale and multiflow regime second the deep learning model as a popular ai model has a strong ability to address the time series problem but whether the model can address the reservoir operation problem effectively and accurately is unknown third the parameter setting is the key technology of ai model building however investigations of different parameters among those models and comprehensive comparison studies are rarely reported therefore in this study we selected three ai models 1 a benchmark three layer backpropagation bp neural network 2 an svr technique and 3 the long short term memory lstm model and constructed a reservoir operation model with three time scales including hourly daily and monthly scale to analyze the sensitivity of applying ai models to reservoir operation for case study we choose gezhouba gzb reservoir in china which had relatively complete detail and long sequence operation records to test the simulation performance of three models at various flow regimes including 1 low flow 2 intermediate flow and 3 high flow in summary the goals of this study are 1 to summarize the influence of the parameter settings on model performance and propose parameter settings for different ai models in assisting reservoir operation 2 to compare the simulation results under different time scales and flow regimes and propose suggestions for the applicability of ai models under different inflow scenarios and 3 to explore the superiority of the lstm model over traditional ai models in assisting reservoir operations and investigate the improvement of prediction accuracy and calculation speed 2 methodology 2 1 bp neural network ann are mathematical models of biologically motivated computation haykin 1994 and they are known as flexible modeling tools with the ability to provide a neural computing approach for processing complex problems that might otherwise not be solved with a mathematical formula yang et al 2017a ann application in hydrology started in the early 1990s in the last decade ann have been applied to hydrology including rainfall runoff modeling wu and chau 2011 chiang et al 2004 streamflow forecasting moradkhani et al 2004 anctil et al 2004 ground water johnson and rogers 2000 reservoir operation chaves et al 2004 jain et al 1999 cheng et al 2015 in this study a feed forward neural network is used in combination with an error backpropagation training algorithm namely the bp neural network the bp neural network consists of one input layer one or more hidden layers and one output layer fig 1 the important issues in the establishment of topological structure include the determination of the number of hidden layers the number of hidden neurons nodes and the transfer function the kolmogorov theorem has certified that a single hidden layer is competent for ann to approximate any complicated nonlinear function and establish a nonlinear mapping between the input and output layers therefore this study establishes a three layer bp neural network the topological configuration and the selection of the activation function are illustrated in fig 1 in contrast to the signal the error is backward propagated and in the process of backward propagation the weights and deviations of the network are gradually adjusted to complete the training the interested readers are referred to thirumalaiah and deo 1998 jain and srinivasulu 2004 fernando and shamseldin 2009 senthil kumar et al 2012 for further details 2 2 svr the basic concept of svr is to nonlinearly map the initial data in a higher dimensional feature space and to solve the linear regression problem in the feature space fig 2 therefore svr usually needs to build a suitable function f x to describe the nonlinear relationship between feature x i and target value y i as shown in the following eq 4 1 f x i w φ x i b where w is the coefficient vector φ xi is the transformation function and w and b represent the weight and bias respectively w and b are estimated by minimizing the so called regularized risk function as shown in the following eq 5 2 r w 1 2 w 2 c i 1 n l ε y i f x i where 1 2 w 2 is the regularization term c is the penalty coefficient l ε y i f x i is the ε insensitive loss function which is calculated according to eq 6 3 l ε y i f x i max 0 y i f x i ε where ε denotes the permitted error threshold so that ε will be ignored if the predicted value is within the threshold otherwise the loss equals a value greater than ε to solve the optimization boundary two slack factors ξ and ξ are introduced 4 min f w ξ ξ 1 2 w 2 c i 1 n ξ ξ subject to 5 y i w φ x i b ε ξ ξ 0 w φ x i b y i ε ξ ξ 0 the key is to develop a lagrangian function according to the objective function and the corresponding constraint conditions 6 max h i i 1 2 i 1 n j 1 n i i j j k x i x j i 1 n y i i i ε i 1 n y i i i subject to 7 i 1 n i i 0 i i 0 c hence the regression function is as follows 8 f x i 1 n i i k x i x j b where k xi xj is the kernel function in this study the simulation effect of kernel function is tested include the linear polynomial radial basis function rbf and sigmoid kernels as shown in the following equation 9 linear k e r n e l k x x i x x i polynomial k e r n e l k x x i γ x x i b d radial b a s i s f u n c t i o n k e r n e l k x x i exp x x i 2 σ 2 sigmoid k e r n e l k x x i tanh γ x x i v where d is the degree of the polynomial term v represents the residuals and γ is the structural parameter in the polynomial rbf and sigmoid kernels different d γ and penalty coefficient c values will be tested in the paper 2 3 lstm long short term memory is a complex recurrent model developed by hochreiter and schmidhuber 1997 to address the deficiencies of rnns in contrast to rnns lstms apply memory blocks to replace the hidden layer of rnns in this paper the lstm network consists of parallel memory blocks recurrently connected to each other lying between an input layer and an output layer and the conceptual illustration is shown in fig 3 the lstm block was obtained from gers et al 2000 and it consists of an input gate a memory cell a forget gate and an output gate as shown in fig 4 the corresponding forward propagation equations are presented below for our lstm the first step is to decide what information to remove from the cell state by the forget gate the forget gate is essentially a sigmoid function the forget gate will generate an ft value between 0 and 1 based on the previous moment output ht 1 and current input xt to decide whether to let the information ct 1 that is produced in the previous moment pass or partially pass which is depicted by eq 13 10 f t σ w xf x t w hf h t 1 b f the next step is to decide what new information will be stored in the cell state the step is divided into two parts first the input gate determines which values will be updated second the memory cell generates a vector of new candidate values ct which can be added to the cell state in the next step we combine eqs 14 and 15 to update the state 11 i t σ w xi x t w hi h t 1 b i 12 c t f t c t 1 i t t a n h w xc x t w hc h t 1 b c finally we decide what information we are going to output first we decide what parts of the cell state to output by running a sigmoid layer then we resize the c t value to 1 to 1 through tanh and multiply it by the output of the sigmoid gate so that we output only the target information 13 o t σ w xo x t w ho h t 1 b o 14 h t o t tanh c t in eqs 13 17 f i c o and h are the forget gate input gate cell output gate and hidden output respectively wx and wh in eqs 15 17 are the input and hidden weights for the gates or cells with the corresponding subscripts b in eqs 15 17 represents learnable biases for the gates and σ and tanh represent the gate activation function the logistic sigmoid in this paper and the hyperbolic tangent activation function respectively in this study we establish a three layer lstm network that consists of one input layer one lstm hidden layer and one output layer and we train the network with an algorithm termed backpropagation through time bptt which has a similar principle to the bp algorithm by using a backpropagation network to continuously adjust the weights and thresholds werbos 1990 3 data and processing 3 1 case reservoir and operation data the gezhouba gzb dam is the first dam across yangtze river which built after the founding of new china fig 5 it located in yichang city of hubei province approximately 38 km downstream of the three gorges dam plays a role in power generation flood control navigation and fisheries and provides other comprehensive benefits gzb is a large scale water project that controls a drainage area of 1 106 m2 accounting for more than half of the yangtze river basin the mean annual discharge of this reservoir is 14 300 m3 s the design flood discharge is 86 000 m3 s the normal water level is 66 0 m the maximum dam height is 53 8 m and the total storage is 15 8 108 m3 gzb reservoir has relatively mature operating rules and complete detail and long sequence operation records these records cover all kinds of operating scenarios such as the flood control drought relief peaking generation navigation and fish spawning stimulation etc and provide a large number of operating data for machine learning in this study the reservoir hydrological data and operation data were obtained from the official website of china three gorges corporation http www ctg com cn the gzb data span a period of more than 30 years from 1982 to 2015 the data include the inflow and outflow of the reservoir and the water level upstream and downstream of the dam measured every six hours or four hours when the flood peak passes through the reservoir all reservoir operating indicators are more intensive monitored these data were aggregated into daily and monthly time scales 3 2 model building and inputs in this study we use selected artificial intelligence and data mining tools namely the bp neural network svr and lstm to simulate the gzb reservoir operation at monthly daily and hourly scales the hourly data refer to the reservoir operation data collected every two or four hours gzb reservoir operation data span the period from 27 june 1981 to 7 september 2015 based on the commonly accepted 80 20 split rule the data from 1 january 2008 to 7 september 2015 are used as the test period and the remainder are used for training as shown in table 2 the reservoir operation data are imported as model input decision variables and output target variable specifically the inputs include current and previous inflow 1 moment lag previous outflow 1 moment lag the current and previous water level in front of the dam 1 moment lag the current and previous water level of the downstream region 1 moment lag and the current time month of year therefore 9 inputs are included in the model the model output is the current outflow of the reservoir to match the consistency of the model all source data were normalized in the range 0 0 1 0 and were then transformed to original values after the simulation using the normalized equation is as follows 15 x x ori x min x max x min where x is the normalized value xori is the original value and xmin and xmax are the respective minimum and maximum original values the input construction was standardized for all methods i e bp svr and the lstm model to ensure an impartial comparison 3 3 parameterization and setting to illustrate the strengths and weaknesses of the different ai methods different parameterizations are used for bp svr and lstm in bp four maximum iteration mi numbers are tested i e 1 105 5 105 1 106 and 2 106 in combination with different numbers of hidden nodes i e 5 10 15 and 20 in svr four types of kernel functions are set i e linear rbf polynomial and sigmoid kernel functions with different penalty coefficients c 20 values are selected from 0 0001 to 10 000 according to the geometric progression gamma γ 20 values are selected from 0 0001 to 10 000 according to the geometric progression and degree d i e 2 3 4 therefore for linear kernel function we test 20 set of parameterizations for rbf and sigmoid kernel function we test 400 set of parameterizations and for polynomial kernel function we test 1200 set of parameterizations then a performance comparison is conducted among various types of kernel functions in combination with the optimal parameters with respect to the lstm model different mi numbers are tested including 50 75 100 and 200 iterations in combination with various numbers of hidden nodes i e 10 20 30 40 and 50 specific parameter configurations are described in the results and discussion sections 3 4 model evaluation statistics to mathematically quantify the skill of the model simulations four statistical measures are calculated the root mean square error rmse rmse observation standard deviation ratio rsr and the nash sutcliffe model efficiency coefficient nse nash and sutcliffe 1970 the indices rmse and rsr are valuable because they indicate error in the units or squared units of the constituent of interest which contributes to result analysis and rmse and rsr values of 0 indicate a perfect fit the nse is a normalized statistic that determines the relative magnitude of the residual variance compared to the measured data variance nash and sutcliffe 1970 nse values range from negative infinity to 1 with 1 indicating an exact match between simulated and observed values as suggested by previous studies an rmse value less than half the standard deviation of the observed data may be considered low and if rsr 0 7 and nse 0 5 model performance can be considered satisfactory singh et al 2010 moriasi et al 2007 yang et al 2017b the equations of the selected statistics are shown below eqs 19 20 16 rmse i 0 n s i o i 2 n 17 rsr rmse stde v obs i 0 n s i o i 2 i 0 n o i o i 2 18 nse 1 i 0 n o i s i 2 i 0 n o i o i 2 where oi and si are the respective observed and simulated values for outflows o s and s i are the respective average observed and simulated inflows and n is the total number of observations in eq 21 r α and β represent the correlation coefficient variability and bias ratio between the simulations and observations respectively to estimate the uncertainty associated with model simulations the residuals of testing sets are computed and analyzed the analysis consists of three components independence analysis heteroscedastic analysis and normality analysis the implementation methods consist of plotting graphs of residual autocorrelation residual variation relative to observed values and residual probability distributions figs 11 13 the residual independent analysis is based on residual autocorrelation if the residual sequence is autocorrelated then the model fails to fully explain the variation rule of the variable and there is some regularity that is not explained which eventually leads to a larger prediction deviation of the model on the other hand low residual heteroscedasticity and a close approximation to the normal distribution indicate the model is closer to unbiased estimation and has low uncertainty the so called residual is the difference between the predicted value and the actual observed value which is calculated according to eq 22 19 e i o i s i where ei represents residuals oi represents observed values and si represents predicted values in this paper the model residuals were standardized before the residual analysis and the process is as follows 20 r s i e i σ where rs represents standardized residuals and σ represents the standard deviation all the experiments presented in this study were performed on an inter r xeon r cpu e5 2660 v3 2 60 ghz with 64 gb ddr3 1600 mhz memory 4 results 4 1 comparison of simulation results for different time scales in this section the observed gzb reservoir outflows are compared with simulated results based on the three different ai models i e the bp neural network svr and lstm model combined with various model parameters first our results show that bp neural network and lstm the number of hidden nodes and maximum iterations are two key parameters that affect the simulation accuracy moreover there is no obvious regularity about the effect of the number of hidden nodes on simulation accuracy but the increase of the number of maximum iterations can significantly improve the simulation accuracy of the two models figs 6 and 7 with respect to svr the choice of kernel function can directly affect the model accuracy our results show that at monthly scale the simulation accuracy is ranked as sigmoid polynomial rbf linear among the different kernel functions at daily scale the best accuracy ranking is sigmoid rbf linear polynomial and at hourly scale the best accuracy ranking is sigmoid rbf polynomial linear table 4 on the other hand the prediction performances of the bp neural network svr and lstm model are shown in tables 3 5 and figs 8 10 the calculation results show that at the monthly scale the best rmse values obtained by the bp neural network svr and lstm model are 1122 827 1932 814 and 161 712 the best rsr values are 0 1411 0 2429 and 0 0203 and the best nse values are 0 9799 0 9404 and 0 9996 respectively tables 3 5 the best simulation results are shown in fig 8 when the best statistical results are achieved the mi and h of the bp neural network are 2 106 and 15 respectively the kernel function of svr is sigmoid the respective values of γ and c are 0 1265 and 3 728 and the mi and h of the lstm model are 200 and 50 respectively tables 3 5 according to the comparison among different models the best accuracy ranking is the lstm model bp neural network svr with respect to the daily time scale the best rmse values generated using the bp neural network svr and lstm model are 1073 402 1332 720 and 663 723 the best rsr values are 0 1253 0 1556 and 0 0230 and the best nse values are 0 9843 0 9758 and 0 9935 respectively tables 3 5 the best simulation results are shown in fig 9 when the best statistical results are obtained the mi and h of the bp neural network are 2 106 and 5 respectively table 3 the kernel function of svr is sigmoid and the values of γ and c are 0 0869 and 2 560 respectively table 4 in addition the mi and h of the lstm model are 200 and 20 respectively table 5 according to our experimental results the best accuracy ranking is the lstm model bp neural network svr tables 3 5 fig 9 the results of the hourly time scale suggest that the best rmse values produced by the bp neural network svr and lstm model are 1596 052 1051 484 and 488 121 the best rsr values are 0 1885 0 1242 and 0 0577 and the best nse values are 0 9645 0 9846 and 0 9967 respectively tables 3 5 the best simulation results are shown in fig 10 when the best statistical results are achieved the mi and h of the bp neural network are 2 106 and 20 respectively table 3 the kernel function of svr is sigmoid the values of γ and c are 0 0464 and 2 783 respectively table 4 and the mi and h of the lstm model are 75 and 50 respectively table 5 notably within a day gezhouba peak load dispatching operation according to the inflow conditions and peak frequency modulation to meet the demand of the power grid and to stabilize the flow regime of the reservoir therefore compared with the monthly and daily scales the hourly model needs to consider the predicted accuracy of outflow for the peak operation period fig 10 shows that the simulation accuracy of the lstm model is higher than that of the bp neural network and svr during the peak load dispatching operation period overall the best accuracy ranking is the lstm model svr bp neural network in addition to the simulation accuracy the calculation speed is also an important index to measure the performance of a model in this paper the time consumption is used as an evaluation index to compare the calculation speed of the three models the experimental results show that there are significant differences in the calculation speed among the three models and the three time scales in general the time consumption is ranked as the bp neural network svr lstm model among the different models and as the hourly scale daily scale monthly scale among the different time scales the bp neural network is the longest running model and the time consumption increases as mi increases table 3 the time consumption associated with optimal results at the monthly daily and hourly scales is 74 05 56 519 31 23 and 786 13 09 respectively table 3 in addition to the time scale the time consumption of svr is also related to the selected kernel function and the time consumption is ranked as polynomial sigmoid rbf linear the time consumption associated with optimal results at the monthly daily and hourly scales is 5 47 49 26 03 and 204 16 42 respectively table 4 similar to the bp neural network the time consumption of the lstm model is related to the time scale and mi which manifests as an increase in the time consumption with an increase in mi and the time consumption associated with optimal statistical results for the lstm algorithm is 6 37 04 and 1 5 21 for the monthly daily and hourly scales respectively table 5 it should be noted that the time consumption of the lstm model is significantly lower than that of the bp neural network and svr tables 3 5 4 2 residuals analysis as shown in figs 11 13 to evaluate the uncertainty of the models residual analysis is performed on the best statistical results of the three models at different time scales at the monthly scale the experimental results show that the r s of the svr model has a significant autocorrelation and the acf presents a trend of alternating positive and negative variations as the lag changes fig 11b compared with svr the autocorrelation of r s for the bp neural network and lstm model is weak and the acf lies mainly in the 95 confidence interval fig 11a c fig 9d f show the scatter points of r s as a function of observed reservoir outflows it is clear that the r s values do not appear to be randomly distributed over the flow interval for each model and the r s of the lstm model shows an obvious increasing trend with an increase in outflow fig 11g i display the probability density distribution of r s for the three models the results show that the probability density distribution curve of r s for the bp neural network is flat with obvious skewness and the values of r s are mainly distributed between 1 and 3 fig 11g with respect to the svr model the probability density of r s shows a bimodal distribution ranging mainly between 2 and 0 fig 11h the r s of the lstm model presents a unimodal distribution with a sharp peak and the r s values are mainly distributed between 2 and 2 fig 11i at the daily scale the autocorrelation of r s for the lstm model is the weakest whereas the r s values of the bp neural network and svr model show remarkable autocorrelation fig 12a c the r s values of the three models exhibit heteroscedasticity as the observed outflow changes compared with the bp neural network and svr the spatial distribution of r s with observed outflow for the lstm model is relatively uniform fig 12d f the probability density of r s for the bp neural network displays a unimodal distribution ranging mainly between 1 and 1 fig 12g the r s of svr has a multimodal distribution with three peaks two high and one low distributed at 1 2 0 and 1 4 respectively fig 12h the r s of the lstm model presents a unimodal distribution with a sharp peak and r s is mainly distributed between 1 and 2 fig 12i the experimental results show that at the hourly scale autocorrelation of r s is found in all three models fig 13a c the acf values of the bp neural network and svr are positive with periodic increases or decreases as the lag changes fig 13a and b the acf values of the lstm model present a trend of alternating positive and negative variations as the lag changes and also exhibit the phenomenon of periodic increases or decreases the r s values of all three models exhibit heteroscedasticity fig 13d f the probability density curve of r s for the bp neural network model has a single peak ranging mainly between 1 and 2 and obvious mainly positive skewness is exhibited fig 13g the distribution of r s for the svr model is also unimodal and a wide distribution is evident between 4 and 2 fig 13h with respect to the lstm model the probability density curve of r s is unimodal and r s is densely distributed mainly between 1 and 1 fig 13i 4 3 comparison of simulation results for different flow regimes the experimental results of section 4 2 show that model uncertainty varies with observed flow to better determine the ability of the models to reproduce different flow regimes the models with the best simulation results are evaluated for three specific regimes i e low intermediate and high flow conditions the division of these flow regimes is based on the calculation of the inflow frequency distribution curve the flow regimes are categorized by using the 25th and 75th percentiles and the flow limit is 5985 m3 s and 18 050 m3 s respectively the model accuracy for the different flow regimes is graphically represented in three scatter plots figs 14 16 and is measured in terms of rmse rsr and nse table 6 the experimental results show that in general the lstm model has a significant advantage with respect to simulation accuracy and this model can produce more accurate simulation results for each time scale and flow regime specifically at the monthly scale the comparison results show that the evaluation index values of the lstm model are the best and the simulation accuracy is the highest the comparison results of the two other models show that under low flow conditions the simulation accuracy of these two models is not ideal i e the rsr value is greater than 1 and the nse value is negative under intermediate and high flow conditions the simulation accuracy of the two latter models meets the evaluation criteria and the accuracy of the bp neural network simulation is higher than that of svr table 6 fig 14 at the daily time scale the simulation accuracy of the lstm model is significantly higher than that of the two other models under low flow conditions poor simulation is observed for the bp neural network and svr and it is difficult to obtain satisfactory results under intermediate and high flow conditions both of these models exhibit satisfactory simulation results the simulation accuracy of the svr model is slightly higher than that of the bp neural network under intermediate flow conditions whereas the simulation accuracy of the bp neural network is higher than that of svr under high flow conditions table 6 fig 15 at the hourly scale the lstm model also shows higher prediction accuracy than the bp neural network and svr table 6 the simulation accuracy of the bp neural network and svr is poor under low flow conditions under intermediate and high flow conditions the simulation accuracy of the two models meets the evaluation criteria the simulation accuracy of svr is higher than that of the bp neural network under intermediate flow conditions whereas the simulation accuracy of the bp neural network is slightly higher than that of svr under high flow conditions table 6 fig 16 5 discussion 5 1 suggestions for model parameterization parameter setting has always been the focus of the performance research of ai models in this study we test the influence of different parameter combinations on the performance of three selected ai models first we explore the effect of the maximum number of iterations and the number of hidden nodes on the accuracy of a bp neural network according to the statistics shown in table 3 for the bp neural network 1 in general an increase in the number of maximum iterations can improve the simulation accuracy and 2 the effects of the number of hidden nodes on the simulation accuracy are uncertain and irregular in addition selection of the appropriate number of hidden nodes can help improve the statistics as shown in table 3 the best bp neural network statistics for the three time scales are consistently achieved by a maximum number of iterations equal to 2 106 in the use of the bp neural network in our study an error backpropagation combined with a gradient descent algorithm is employed as the number of maximum iterations increases the gradient optimization scheme continuously explores the response surface of the objective function eq 3 and the evolution is not completed until the algorithm reaches the preset error value or the allowable number of maximum iterations however as the search evolves with more iterations the gradient of the objective function will decrease consequently any further increase in the maximum iteration number results in less improvement in the objective function value as shown for the 1 106 and 2 106 maximum iteration scenarios in table 3 in addition to ensure that the network training reaches the maximum number of iterations the error value is set as 0 0001 which is significantly lower than that of the model our results show that choosing the appropriate number of hidden nodes can significantly improve model accuracy but the effect of the number of hidden nodes on accuracy is unpredictable the best bp neural network statistics for the monthly daily and hourly time scales are obtained when the number of hidden nodes is 15 5 and 20 respectively table 3 as mentioned in yao 1999 the number of hidden nodes in ann is crucial for model performance and should be jointly designed and optimized with a proper training algorithm as such the number of hidden nodes is one of the research hotspots in the ann field it is generally believed that determination of the number of hidden nodes is related to the number of input and output nodes lippmann 1987 chen 1996 moody and antsaklis 1996 nevertheless studies have not adopted a universally accepted method for choosing the number of hidden nodes at present the number of hidden nodes is usually determined by trial and error with the objective of minimizing the cost function with respect to svr we examine the influence of the kernel function on the simulation performance based on an optimal structural parameter γ penalty coefficients c and degree d for the polynomial the kernel function is introduced to map the linear nonseparable training sample from the input space to the feature space thereby realizing the linear separability of the training samples in the feature space in this way a linear classifier can be used to divide the training samples after mapping in the feature space as shown in table 4 svr models are able to produce satisfactory results but the simulation accuracy and time consumption differ significantly among different kernel functions our results show that regardless of the time scale the best simulation accuracy is consistently generated by the sigmoid kernel function however the time consumption of this function is relatively long table 4 this is not consistent with previous research and most reviewed studies have suggested that rbf is the most appropriate kernel function that tends to exhibit satisfactory performance yaseen et al 2015 however technological research conducted on the kernel function shows that any kernel function has its own advantages and limitations because of different training samples and kernel functions have different classification abilities amari and wu 1999 asefa et al 2006 yang et al 2017b the sigmoid kernel function is derived from ann and has been proved to have good global classification performance lin and lin 2005 our results also show that the classification performance of the sigmoid kernel function is better than that of other kernel functions for our training sample with respect to the lstm model we mainly consider the influence of the number of maximum iterations and hidden nodes on model performance and the main results in this paper are as follows 1 an increase in the number of maximum iterations improves the precision of the lstm model and 2 a change in the number of hidden nodes affects the simulation accuracy but the function is weak and irregular as shown in table 5 when the number of maximum iterations increases from 50 to 75 the model accuracy is effectively increased but increasing the number of maximum iterations to greater than 100 does not improve accuracy further based on an advanced investigation we deduce that model accuracy is not improved further because the training process of the lstm model adopts the bptt algorithm which has a similar principle as the classical bp algorithm the bptt algorithm uses a forward algorithm to calculate the output value backward calculates the error of each individual lstm cell and continuously updates the network weight extending the direction to reduce the error with the narrowing of the gap between the model s output value and the desired output value the decline rate of the model error tends to slow down so an increase in the number of maximum iterations does not significantly improve model precision when the number of maximum iterations reaches a certain limit however unlike the bp neural network the number of iterations required for lstm model convergence is much smaller than the bp neural network our analysis indicates that the reason for this result is that the lstm model has strong feature extraction capabilities which ensures that the model can extract the characteristic information of the data more efficiently and complete the convergence process quickly according to our experimental results we cannot specify how to achieve the best statistics by choosing the number of hidden nodes however it is worth noting that while the number of iterations is the same the changes of number of hidden node have only a limited effect on the simulation accuracy at present studies that examine the influence of the number of hidden nodes on the precision of lstm models are rarely reported wielgosz et al 2017 tested the influence of the number of hidden nodes on simulation accuracy and concluded that for their test data the simulation accuracy was highest when the number of hidden nodes was 32 but the effect of different numbers of hidden nodes on model accuracy was not discussed in detail in conclusion we believe that priority should be given to the number of maximum iterations in the bp neural network and lstm model building and a reasonable increase the number of maximum iterations can significantly improve the model accuracy in contrast the number of hidden nodes has a weak effect on model accuracy for the svr model the selection of kernel function is the key to model construction combined with previous research results we believe that sigmoid and rbf kernel function can be considered the priority object meanwhile in the process of model construction due to differences in data volume and structure model parameters have different influences on model performance therefore we suggest that the model should be repeatedly trained before practical application to determine the optimal parameters and ensure the prediction ability of the model 5 2 suggestions for the applicability of ai models under different scenarios the ai model has the ability to address complex nonlinear prediction problems which is widely applied in the field of reservoir operation simulation at present reports on the performance comparison and analysis of ai models are common but such reports mainly focus on the global precision comparison analysis of a single time scale however analyzing the global and extreme event simulation performance of the model from multiple time scales is the key to the model comprehensive learning operation rule and generating long and short term operation plans for different scenarios therefore in this study we analyzed the simulation results of the bp neural network svr and lstm under different time scales and flow regimes from three aspects of model accuracy uncertainty and calculation speed based on the above analysis we explored the guiding significance of three ai models for reservoir long and short term operation and the coping capacity of three ai models for extreme inflow conditions such as drought and flood and we summarized the application scenarios of each model in order to provide a reference for the practical application of these model first the application effect of the bp neural network in reservoir operation was studied in the 1990s the emergence of bp algorithm greatly facilitated the development of ann and effectively promoted the research of ann algorithms in the field of reservoir operation in our study the bp neural network was applied to the reservoir operation simulation and the results showed that for reservoir long term operation monthly scale the simulation accuracy of the ann model is good the uncertainty is weak and the time consumption is long at the daily scale the accuracy of the bp model still met the evaluation criteria but the residuals were autocorrelated and exhibited heteroscedasticity and the time consumption increased at the hourly scale due to the further increase in data volume the disadvantages of the model regarding the uncertainty and time consumption are more obvious table 3 thus we consider that if the model is able to learn the operation rule of a reservoir from a small amount of data such as the research of reservoir long term operations or the influence factors of reservoir operations the bp neural network can obtain satisfactory simulation accuracy and the time consumption is not too long so it can be used for the simulation of reservoir operations however for large reservoirs and the short term fine operation of reservoirs the data that are required by the model learning reservoir operation rules are large due to the large number of influencing factors in this case the time consumption of the bp neural network is too long and the applicability is weak on the other hand for different flow regimes the results show that under intermediate and high flow conditions the bp neural network can obtain satisfactory results but under low flow conditions the bp neural network has poor simulation results and is not suitable for simulation of low inflow scenarios because the feature extraction ability is poor the training time of the bp neural network is too long and the practical application is limited the emergence of the svr algorithm partly compensates for the deficiency in bp neural networks the svr algorithm introduces the lagrangian method to simplify the quadratic optimization problem in svr calculations and introduces the kernel function to reduce the complexity of high dimensional computations thus allowing the svr model to calculate the high efficiency characteristics this paper first compares the processing power of the model to different time scale problems the results show that the svr algorithm can attain satisfactory statistics but compared with the bp neural network the two models have advantages and disadvantages at monthly and daily time scales the accuracy of the bp neural network model is higher than svr and at the hourly time scale the calculation accuracy of the svr model is higher than that of the bp neural network tables 3 and 4 in this study the simulation ability of the model to different time scale problems reflects the processing power of the model to different data volumes to some extent therefore the bp neural network has a stronger processing capability than svr when the data volume is small whereas the advantages of the svr model are gradually revealed when the data volume is large next we compared the differences in calculation speed and the uncertainty of the two models and the results show that compared with the bp neural network the computing speed of the svr model significantly increased but the time was still very long and the uncertainty of the svr model is high tables 3 and 4 finally under different flow regimes our research results show that svr still does not overcome the problem that the bp neural network cannot simulate low flow conditions table 6 figs 14 16 in view of the above problems namely that the simulated speed of the traditional ai models is slow the accuracy needs to be increased and it is difficult to address extreme events we turned our attention to the lstm model which performed well in solving the time series problems taking the gzb reservoir as an example this paper constructs an lstm model to predict the outflow of the gzb reservoir and explores the application of lstm in reservoir operations the results show that the lstm model effectively makes up for the deficiency of the traditional ai models whether from the accuracy uncertainty calculation speed extreme conditions processing the lstm has significant advantages over the bp neural network and svr tables 3 6 figs 8 16 especially at the hourly scale facing vast amounts of data lstm performance is outstanding and the training and prediction process takes only approximately an hour meanwhile lstm is the only one of the three models that can accurately simulate the outflow curve of gzb for the peaking operation period fig 10 the experimental results for show that the lstm model overcomes the disadvantage of previous models i e poor simulation accuracy for extreme events and the lstm model can accurately predict reservoir outflow under low and high inflow conditions in conclusion compared with the bp neural network and svr the lstm model has significant advantages in terms of simulation accuracy stability and computing speed and we believe that lstm as a deep learning model has a strong sequential predictive ability and can be used for reservoir operation simulations at present the application of the lstm model in reservoir operation has been rarely reported but zhang et al 2018 arrived at similar conclusions in the study of sewage overflow prediction which can provide some reference for us zhang et al 2018 compared the predictive effects of the lstm and svr models on sewage discharge and the results showed that the simulation accuracy of the lstm model was significantly higher than that of the svr model which was similar to our conclusion in summary with respect to the ai model applicability the bp neural network is suitable if the model is able to learn the operation rule of a reservoir from a small amount of data such as the research of reservoir long term operations or if the influence factors of reservoir operation are small for large reservoirs short term fine operation of reservoirs and low inflow conditions the applicability of the bp neural network is weak the main limitation of the bp neural network is that the independent feature extraction ability of the network is poor so the time consumption required for satisfactory results is too long the applicability of the svr model and the bp neural network is similar although the svr model improves computing speed its ability to address massive data and low inflow conditions is still insufficient by contrast the lstm model has obvious advantages and can quickly and accurately simulate the reservoir operation under various time scales and flow conditions therefore lstm can be used for medium and long term reservoir operation and short term refinement operation simulation as well as to address various emergencies meanwhile the lstm effectively solves the time consumption problems of the bp neural network and svr model corrects for the fact that traditional ai cannot simulate low flow conditions or the outflow curve for the peak operation period 6 conclusions reservoir operation is an important part of reservoir management and the theory and method of reservoir operation have been gradually developed with the construction of reservoirs and hydropower stations in the early 20th century at present according to the theoretical basis of the model reservoir operation models are divided into two main categories models based on physical concepts and ai models based on data mining technology however a physical based model is useful only if the operating rules incorporated in the simulation can realistically reflect the actual operation in practice the operation of a reservoir is affected by many uncertain factors such as natural conditions and artificial demand and the operation often deviates from the operating rules which limits the application of such models ai models or data driven models are able to autonomously learn the operating rules from the historical operation data of a reservoir and thus have greater robustness and are good at dealing with complex factors this paper investigated the usefulness of two traditional ai models bp neural network and svr and a new deep learning model lstm model in assisting reservoir operation detailed discussion and recommendation are made with respect to the process of model parameter settings the simulation performances and the applications of employed ai models under different flow regimes and temporal resolution the main conclusions are as follows 1 with respect to parameter setting our results show for the bp neural network and lstm model the effects of the number of maximum iterations on model performance should be prioritized the effects of the number of hidden nodes on model performance are limited for the svr model the simulation performance is directly related to the selection of the kernel function combined with previous research results we consider that sigmoid and rbf kernel functions should be prioritized in uses of svr model meanwhile in the process of model construction due to differences in data volume and structure model parameters have a different influence on model performance therefore we suggest that the model should be repeatedly trained before practical application to determine the optimal parameters and ensure the prediction ability of the model 2 with respect to the ai model applicability the bp neural network is suitable if the model is able to learn the operation rule of a reservoir from a small amount of data such as the research of reservoir long term operation or if the influence factors of reservoir operation are small for large reservoirs short term fine operation of reservoirs and low inflow conditions the applicability of the bp neural network is weak the main reason to limit the application of the bp neural network is that the independent feature extraction ability of the network is poor so the time consumption required for satisfactory results is long the applicable conditions of the svr model and bp neural network are similar although the svr model improves computing speed its ability to address massive data and low inflow conditions is still insufficient by contrast the lstm model has obvious advantages and can quickly and accurately simulate the reservoir operation under various time scales and flow conditions therefore lstm can be used for medium and long term reservoir operation and short term refinement operation simulation as well as to address various emergencies 3 the lstm model can effectively solves the time consumption problem associated with the bp neural network and svr model and it has superior performances over other ai models in simulating reservoir operation during low flow conditions or the outflow curve for the peak operation period whereas traditional bp neural network and svr model tend to fail acknowledgement the data presented in this paper are available at the official website of the china three gorges corporation cdec http www ctg com cn this paper is a part of a joint cooperation between the china institute of water resources and hydropower research and the university of california irvine this work was supported by the national key research and development program of china no 2016yfe0102400 the research program of songhua river hydroelectric power generation co ltd the fengman dam reconstruction program construction bureau jsfw 2015 198 the scientific research program for the china three gorges corporation 0799564 the fundamental research funds for the china institute of water resources and hydropower research sd0145b162017 the u s department of energy doe prime award de ia0000018 and california energy commission cec award 300 15 005 appendix a supplementary data supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 050 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 supplementary data 2 supplementary data 3 
7037,short term prediction of hydrological time series using chaotic dynamical systems approach has gained popularity however noise can severely affect the prediction accuracy of any data driven modelling approach noise reduction processes attempted in chaotic hydrological time series analysis were later questioned by elshorbagy et al 2002 for their appropriateness for noise reduction processes only a few studies on noise reduction have appeared since then and these too were limited to introducing new noise reduction methods most of the past studies on chaotic time series noise reduction shared a general perception that the noise reduced data trained models can give better predictions they used off line noise reduction methods to obtain a noise reduced data set which was then used to make prediction models however the results of this study showed that this was not necessarily true and often flawed when the input data was noisier instead noise reduced data inputs were shown to yield higher prediction accuracy even with noisy data trained models thus the study showed a real need to use real time noise reduction methods instead of off line noise reduction methods that had previously been used the extended kalman filter ekf a popular nonlinear state estimation method from controls literature was introduced as a real time noise reduction method and its effectiveness was demonstrated on both synthetic chaotic time series and real river flow time series ekf produced prediction improvement as high as 15 40 on the benchmark time series with noise levels varying from 1 to 30 two river flow series with low average flows showed prediction improvement whereas three other flow series with relatively large average flows did not artificial neural network ann models were used as the state space models in ekf and adopting them to time delays different from 1 unit was also demonstrated the study demonstrated an indirect validation method to verify the effectiveness of noise reduction when several interrelated time series were available this was supported in observed discharge time series of the ciliwung river in jakarta indonesia keywords noise real time prediction time series river flow extended kalman filter chaos 1 introduction several studies have attempted the issue of noise reduction in chaotic hydrological time series e g porporato and ridolfi 1997 kawamura et al 1998 sivakumar et al 1999a b jayawardena and gurung 2000 however all these studies were later critically commented by elshorbagy et al 2002 due to their inappropriate use of noise reduction porporato and ridolfi 1997 were the first to apply noise reduction in chaotic hydrological time series sivakumar et al 1999a b showed some drawbacks in porporato and ridolfi 1997 and proposed a systematic approach for noise reduction later elshorbagy et al 2002 showed drawbacks in sivakumar et al 1999a b and other works porporato and ridolfi 1997 kawamura et al 1998 jayawardena and gurung 2000 since then only a very few studies sun et al 2008 han and liu 2009 liu and liao 2011 jafari et al 2012 han and chang 2013 on noise reduction in chaotic time series have been published they too are limited to introducing noise reduction methods and to measuring noise levels orzeszko 2008 çoban et al 2012 jayawardena et al 2008 all these noise reduction methods have considered off line noise reduction mainly for the purpose of chaos identification no studies to the authors knowledge have focused on noise reduction for real time prediction improvement purposes the erroneous noise reduction approaches and applications thus their resulting perceived both remarkable improvement in prediction accuracy and good data quality seem to have blurred hydrology community on the effectiveness of nonlinear noise reduction this study looks into the possibilities of incorporating noise reduction to improve real time prediction accuracy in this course the possible ways of improving real time predictions are hypothesized by examining the noise reduction problem and they are tested by simulation of theoretical chaotic time series this reveals a misconception in past studies on off line noise reduction and shows the real need for real time noise reduction then the ekf with ann models is demonstrated for real time prediction improvement of noisy time series a method for validation of noise reduction in real data is then proposed and demonstrated on ciliwung river in jakarta indonesia paper is organized as follows section 2 discusses the noise reduction problem concerns on noise reduction applications in hydrological literature an overview of the methodology followed in this study and a description of the data used theory of the linear kalman filter ekf and its adoption with ann models are given in section 3 section 4 is the results and discussion followed by conclusions in section 5 2 materials and methods 2 1 prediction of chaotic time series takens 1981 showed that it is possible to reconstruct the dynamics of a chaotic system using only a single variable of the system packard et al 1980 and takens 1981 described the time delay coordinate method to construct the phase space from single variable scalar time series accordingly the phase space vector x i can be expressed as in eq 1 1 x i x i x i τ x i m 1 τ where x i is the observed value at time t i i δ t where δ t is the sampling interval m is called the embedding dimension and τ is the time delay which is a suitable multiple of the sampling time δ t in phase space prediction a nonlinear functional relationship between the current state x i and the future value x i t of the form given in eq 2 is used where t is referred to as the lead time measured in terms of the sampling intervals 2 x i t f t x i 2 2 noise reduction of chaotic time series the noise reduction problem for time series data may be defined as follows suppose y i r i 1 2 n is a noisy time series where the corresponding true i e noise free series is x i r i 1 2 n the true or noise free series is generally unknown the aim of noise reduction is to come up with a noise reduced series y i r i 1 2 n that minimizes the differences ε i y i x i such that ε i ε i where ε i y i x i preferably for all i 1 2 n in which ε i 0 in other words the noise reduced series y i will be closer to the true series x i than does the noisy series y i noise reduction in general may be applied in off line or in real time in off line applications both the past y p p r and the future y f f r records of a particular record y r are used to reduce noise in that record in contrast future records are not used in real time applications therefore in real time when a measured value becomes available that value and the past values are used to derive a noise reduced estimate for that measured value almost all the nonlinear noise reduction techniques appeared in chaos literature can be effectively applied only in off line noise reduction e g hammel 1990 kostelich and yorke 1990 schreiber and grassberger 1991 cawly and hsu 1992 sauer 1992 schreiber 1993 etc real time noise reduction techniques are not readily available in chaotic nonlinear noise reduction literature 2 3 relevant concerns on noise reduction in chaotic hydrological time series as mentioned earlier elshorbagy et al 2002 questioned the noise reduction approaches applied in various studies sivakumar et al 1999a b porporato and ridolfi 1997 kawamura et al 1998 jayawardena and gurung 2000 the main concerns comments of elshorbagy et al 2002 relevant to the present study are summarized as follows details can be found in karunasingha 2005 1 the earlier studies measured the prediction performance in validation by comparing the predicted values against noise reduced data instead of against the original raw data and 2 the accuracy measures used for the noise removal were inappropriate note that the earlier studies considered the prediction model perfectly models the underlying dynamics and the removed part is considered noise to a single model not the absolute noise the comments raised by elshorbagy et al 2002 above are justified they applied the approach proposed by sivakumar et al 1999b on english river ontario canada with the simple noise reduction proposed by schreiber 1993 and verified their doubts the study of elshorbagy et al 2002 showed the followings 1 when prediction accuracy is measured by comparing the predicted values with noise reduced verification data unrealistically high prediction accuracy was observed this means that comparing predictions with noise reduced data is inappropriate and 2 the improvement in prediction performance with noise reduced data with two different models were significantly different this supports the claim of different perceptions of noise from different models in noise reduction of real data totally reliable ways of verifying the noise removal are not available grassberger et al 1993 with real time series data such as rainfall and runoff using prediction accuracy as a criterion seems to be the most reasonable alternative the question is what to compare the prediction results with elshorbagy et al 2002 showed that comparing the predicted values with noise reduced values to arrive at a measure of prediction accuracy and using it to measure the effectiveness of noise reduction is an incorrect approach one way to overcome this however is to compare the predicted values with the corresponding original values this to a certain extent may be considered as model independent as well the reason being what any prediction technique tries to accomplish is to reduce the prediction error resulting from the predicted values compared to their counterparts the observed values another serious flaw in using off line noise reduced validation data for predicting is that such noise reduced values are derived with the use of future observed data as well this is therefore not applicable in real time predictions noise reduction approach for real time prediction which is one of the main focus in this study is not readily available 2 4 noise reduction for prediction enhancement of chaotic time series consider the evolution of a chaotic dynamical system that relates the current state to a future value which may be expressed as x i 1 f x i using a one step lead time in eq 2 there are two main components in this expression 1 the function f and 2 the current state x i in the case of chaotic time series analysis an approximation to the function f f is derived from the past time series data which is referred to as a data driven model or simply a model when the current state is known the prediction for the future is then given as f x i real data contains noise and the recorded data are not exactly the series x i but some measured series y i expressed as in eq 3 where υ i is measurement noise 3 y i x i υ i if the data contains noise the function f cannot be accurately approximated and that affects the prediction accuracy when the input data x i contains noise the prediction performance is expected to be poor thus it is expected that the prediction accuracy to improve by using 1 a better model configured with noise reduced data and or 2 using noise reduced input data to configure a better prediction model a noise reduced data set can be used for this purpose any off line noise reduction technique can be applied to reduce noise in input data noise reduction has to be incorporated in real time or on line earlier studies on noise reduction questioned by elshorbagy et al 2002 have used off line noise reduction with an implicit assumption that models configured with noise reduced data i e better models can improve prediction performance however the findings of those studies are uncertain due to the drawbacks mentioned earlier therefore the present study investigates 1 the possibility of improving prediction performance using the readily available off line noise reduction techniques i e whether the models derived from noise reduced data enhances prediction performance and 2 the effectiveness of real time noise reduction i e noise reduction of input data in chaos based prediction improvement 2 5 overview of methodology this section gives an overview of the methodologies with a little elaboration on how models are derived and used in noise reduction of real data totally reliable ways of verifying the noise removal are not available grassberger et al 1993 it is therefore very important to test any noise reduction procedure on a data set where the true signal is known kantz and schreiber 2004 in this study all the investigations were first performed on a chaotic lorenz series and a chaotic mackey glass time series contaminated with known noise levels here the noise level is defined as the ratio of standard deviation of noise to standard deviation of noise free series signal calculated as a percentage random variables in real life result from the sum of a large number of random effects variables and using the famous central limit theorem in probability theory gaussian distribution is often used to model such real random variables the measurement noise in eq 3 is generally assumed to be gaussian therefore gaussian random noise was added to noise free chaotic time series to obtain noisy series five different noise levels from very mild noise to very high noise 0 or noise free 1 10 20 30 were considered then the methods were applied on five real river flow time series of which the levels of measurement noise were unknown ann specifically multilayer perceptron models were used as prediction models as they are by far the most popular type of models in various hydrologic applications e g wu and chau 2011 fotovatikhah et al 2018 more details on ann model training and choice of optimal parameters including m and τ relevant to this study can be found at karunasinghe and liong 2006 in summary each time series was divided into three parts training calibration and validation for modelling and validation purposes for each time series the training set was used to train several ann models and the model with the highest prediction accuracy on the calibration set was chosen as the ann model for that time series thus minimizing the overfitting and local minima issues of ann whenever such choices were made prediction accuracy was calculated by comparing the predictions with corresponding original noisy outputs these models were then tested on validation sets of different levels of noise the prediction accuracies of these validations were calculated by comparing the predictions with the corresponding noisy validation outputs or the noise free outputs as per the requirement other relevant details of the investigations are explained later in the results and discussion section 2 6 data and prediction performance measures used in this study the investigations were conducted using several theoretical and real data sets currently the measurement noise levels available in hydrological time series are unknown therefore as the first investigation five daily river flow time series of three rivers with average flows of different magnitudes were chosen the lorenz and the mackey glass time series are perhaps the two most widely used benchmark series for chaotic time series analysis and were chosen for the study of those two river flows have shown chaotic behavior yu 2004 karunasingha 2005 and the other three have shown good predictions with chaos approach sun et al 2014 lorenz 1963 abstracted three ordinary differential equations from galerkin approximation to the partial differential equations of thermal convection in the lower atmosphere abarbanel 1996 these have served as a set of benchmark equations for testing ideas in nonlinear dynamics lorenz model consists of the three ordinary differential equations as given in eq 4 4 x σ y x y x z γ x y z x y b z when standard parameter values σ 16 b 4 and γ 45 92 are used the orbits of the lorenz system reside on a geometric object of dimension 2 06 approximately and exhibit non periodic chaotic motion abarbanel 1996 the x t component was solved from the above equations by fourth order runge kutta method with a time step of δt 0 01 six thousand values of this x t time series was used in this study mackey glass time series refers to the delayed differential equation as given in eq 5 5 dx t dt ax t τ 1 x t τ 10 b x t when a 0 2 b 0 1 and τ 17 the series shows chaotic behavior the system was numerically solved using the 4th order runge kutta method at discrete equally spaced time steps to derive the chaotic mackey glass time series the daily river flows used were 1 mississippi river at vicksburg 1975 1993 2 wabash river at mt carmel 1960 1978 and ciliwung river in jakarta 1 17 2006 12 31 2006 recorded at three measurement stations katulampa upstream ratujaya and sugutamu downstream mississippi river is characterized by large flow rates mean flow of approximately 18 500 m3 s while wabash river is of moderate flow rates mean flow of about 750 m3 s and ciliwung river is of low flow rates mean discharges of about 9 9 and 29 m3 s at katulampa ratujaya and sugutamu respectively jakarta the capital of republic of indonesia and a populous city with over 9 5 million inhabitants suffers from massive flooding almost every year out of 13 main rivers flowing through the region ciliwung river is the longest sun et al 2014 liu et al 2014 the first two river flow series are available in the us geological survey website http water usgs gov in order to evaluate the prediction performance of the models and noise reduction two error measures were used legates and mccabe 1999 recommend the use of at least one absolute error measure and one relative error measure to test the model performance in hydrologic and hydro climatic model validation the normalized root mean square error nrmse was chosen as the relative error measure in this study as it gives a better resolution of values for cases with very good predictions e g models trained with low levels of noise the nrmse is given in eq 6 where x i is the predicted value of x i and x is average value of the time series 6 nrmse i 1 n x i x i 2 i 1 n x i x 2 a zero value in nrmse indicates a perfect prediction while a value larger than 1 indicates that the predictions are no better than using the average value of the time series x note that the popularly used nash sutcliffe coefficient of efficiency ce and nrmse are related as ce 1 nrmse2 the absolute error measure mean absolute error mae is given in eq 7 where x i is the desired value and x i is the predicted value 7 mae i 1 n x i x i n 3 theory 3 1 introduction the kalman filter kalman 1960 is the most widely used tool to estimate the system states from noisy measurements it uses observed measurements from a dynamical system to make more accurate estimates of the system s states kalman filtering techniques are core and widely used techniques in controls literature the direct extension of the original linear kalman filter for nonlinear systems is called the extended kalman filter and the derivation of these filters can be found in numerous documents e g maybeck 1979 einicke and white 1999 welch and bishop 2004 the extended kalman filter comprises of a set of equations that describe a nonlinear system and a theory that optimally blends the observations and model predictions to make better system estimates kalman filter kf was originally derived for linear systems but most of the real world systems are nonlinear the direct extension of linear kf for nonlinear systems is called the extended kalman filter ekf improved variations and other forms of kf which are claimed to be better than ekf are also available for nonlinear systems to understand the kalman filter technique and the ekf formulation it is essential to understand the linear kalman filter therefore the linear kalman filter is explained first and the ekf in its most basic form is presented next among the many references the derivation of these filters has been documented this section follows the work of welch and bishop 2004 3 2 linear kalman filter the kalman filter addresses the problem of trying to estimate the state x r n of a discrete time controlled process governed by the linear stochastic difference equation 8 x k a k x k 1 b k u k w k 1 with a measurement z r m that is 9 z k h k x k υ k the random variables w k and υ k represent the process and the measurement noise respectively they are assumed to be independent of each other white and of normal probability distributions 10 p w n 0 q p υ n 0 r in practice the process noise covariance q and measurement noise covariance r matrices might change with each time step or measurement however here it is assumed that they are constant the set of relations given in eqs 8 and 9 is called the state space model the n n matrix ak in eq 8 relates the state at the previous time step k 1 to the state at the current step k in the absence of either a driving function or process noise the n l matrix bk relates the optional control input u r l to the state x the m n matrix hk in the measurement equation relates the state to the measurement z k define x k r n to be a priori state estimate at step k given the knowledge of the process prior to step k and x k r n to be our a posteriori state estimate at step k given measurement z k an n m matrix kk gain or blending factor is chosen so that the a posteriori error covariance is minimized it can be shown that see welch and bishop 2004 11 k k p k h k t h k p k h k t r k 1 which is referred to as the kalman gain matrix and 12 p k i k k h k p k which is the optimized value of the updated estimation error covariance matrix the a priori estimates are obtained in the prediction step or the time update step where the quantities are projected through time the a priori estimates are obtained as 13 x k a x k 1 bu k 14 p k ap k 1 a t q once kk and pk are found the a posteriori estimates can be obtained in the correction step or the measurement update step as follows 15 k k p k h k t h k p k h k t r k 1 16 x k x k k k z k h x k 17 p k i k k h k p k the initial conditions for the filter can be given as 18 e x 0 x 0 and e x 0 x 0 x 0 x 0 t p o when no other information is available an arbitrary value may be chosen as the initial state estimate 3 3 extended kalman filter for nonlinear systems the extended kalman filter derivation can be outlined as follows welch and bishop 2004 assume that the system has a state vector x r n and is governed by the nonlinear stochastic difference equation 19 x k f x k 1 u k 1 w k 1 with a measurement z r m where 20 z k h x k υ k in eqs 19 and 20 w k and υ k represent as earlier process and measurement noises in practice the individual values of the noise w k and υ k are unknown f is a nonlinear function and h can be a linear or a nonlinear function using taylor series approximation on eqs 19 and 20 to linearize and after some manipulations the final ekf time update and measurement update equations can be given as follows time update 21 x k f x k 1 u k 1 0 22 p k a k p k 1 a k t w k q k 1 w k t measurement update 23 k k p k h k t h k p k h k t v k r k v k t 1 24 x k x k k k z k h x k 0 25 p k i k k h k p k in the above equations a is the jacobian matrix of partial derivatives of f with respect to x w is the jacobian matrix of partial derivatives of f with respect to w h is the jacobian matrix of partial derivatives of h with respect to x and v is the jacobian matrix of partial derivatives of h with respect to υ the kalman filter cycles between time update and measurement update over the time steps fig 1 3 4 adoption of ekf with data driven models for real time noise reduction in real time prediction applications the challenge is to estimate the noise reduced value as soon as the observation is obtained so that it can be used as an input to make a more accurate prediction of the future value the extended kalman filter s approach is when a new measurement becomes available the corrected state in the measurement update step can be considered as a noise reduced state this noise reduced state will then be used as the input to make the prediction for the next time step in the time update step ideally ekf assumes a perfect state space model a few studies walker and mees 1997 judd 2003 that have applied ekf in chaotic time series prediction have used the exact governing equations or a nearly perfect model derived from noise free data however this kind of perfect models are not in existence for most of the real world systems in real dynamical systems where perhaps only one or few variables are observed all one can obtain is a data driven model trained from most probably noisy data justification of the use of less than perfect models in ekf can be given as follows in order for ekf to make an improved prediction with the more correct estimate of the state see fig 1 the prediction model should be able to produce better predictions with less noisy inputs this is because the ekf uses measurement update value which is theoretically less noisy than the measurement to predict in time update step if the prediction model is able to give a better prediction with the less noisy measurement update correction the next measurement update step which uses the predicted value will in turn yield a better estimate correction thus the whole algorithm will lead to improved estimates and predictions note that section 4 2 investigates whether less noisy measurements can yield more accurate predictions with noisy data trained models ekf does not use the future records of a point to come up with a better estimate for that point therefore it has the potential to be used as a real time noise reduction technique it should be noted that kalman filter estimates can be considered as noise reduced data for systems where the system state is directly observed i e in systems where h i where i is the identity matrix in the measurement model eq 9 the chaos application is a special case where the observations are directly used to determine the states and therefore the kf estimates can be considered as noise reduced data without any conversion errors due to transformations through h the above discussion leads to the hypothesis that it is possible to use a model trained with noisy data in ekf and to use ekf as a real time noise reduction technique in chaotic time series analysis provided that such a model can yield improved predictions with less noisy inputs the next section explains how the noisy data trained ann model is incorporated in the state space model of the extended kalman filter 3 5 ann model trained with noisy data in ekf noise reduction in chaotic time series prediction we try to approximate the dynamical rule 26 x t t f t x t x t τ x t m 1 τ relating a future coordinate to past coordinates the approximation can be expressed as 27 x t t f t x t x t τ x t m 1 τ w t where ft is the approximate model and wt is the residual error taking both the time delay τ and the prediction horizon t to be unity the relationship can be expressed as 28 x k f x k 1 x k 2 x k m w k since the observed data contain measurement noise the observations can be related to actual signal as 29 y k x k υ k eqs 28 and 29 closely resemble the state space model of extended kalman filter given in eqs 19 and 20 with the exception of scalars at the places of vectors in ekf state space model following haykin 2001 the state space representation can be formulated as 30 x k f x k 1 b w k x k x k 1 x k m 1 f x k 1 x k 2 x k m 1 0 0 0 0 1 0 0 0 0 1 0 x k 1 x k 2 x k m 1 0 0 w k 31 y k cx k υ k 1 0 0 x k υ k where the state x k is chosen to be the phase space vector and the state transition function f has its first element given by f with the remaining values corresponding to the shifted values of the previous state here the residual error is considered as process noise haykin 2001 in chaotic time series prediction the optimal time delay may not necessarily be unity the following procedure is followed in this study for delay times different from unity the state space model was implemented as shown in eq 32 32 x k f x k 1 b w k x k x k τ x k m 1 τ f x k 1 x k 1 τ x k 1 m 1 τ 1 0 0 0 0 1 0 0 0 0 1 0 x k τ x k 2 τ x k m τ 1 0 0 w k as before the first element of the state vector is given by f with the remaining values now given by the corresponding lag elements not necessarily from previous state it should be noted that although the updated previous state x k 1 is readily available for use in f the updated values of other lag elements are not therefore in this study a pool of states was maintained in a temporary file where their elements were updated once a state estimate was made the idea was that when a corrected estimate was obtained in the measurement update step the corresponding elements in the pool were updated with the elements of the state x k the corresponding lag elements for the use in eq 32 were chosen from this updated file the temporary states file looked like eq 33 when the state estimate of x k was made the elements of the future states which have similar elements were replaced by those updated elements of x k for example in eq 33 when updated x k was available the last element of state x k m 1 τ can be replaced by the first element of x k it should also be noted that some of the values of this pool of states are empty for example the elements starting from x k 1 upwards are unknown this updating process continued whenever an estimate was made in addition the oldest estimate was removed from the temporary file and a new column was added in this process an element was generally replaced m times by better estimates 33 x k x k τ x k m 1 τ x k 1 x k 1 τ x k 1 m 1 τ x k m 1 τ x k m 2 τ x k m m 1 τ 1 4 results and discussion 4 1 ann models ann models for 1 step ahead prediction were trained for each time series as described in section 2 5 when selecting the best model for a given time series the one step prediction accuracy calculated on the calibration set by comparing the predictions with noisy calibration outputs was used then the best model for each series was used to predict one step ahead predictions of the noisy validation set the resulting predictions were compared against the corresponding noisy and the noise free validation outputs their error measures are shown in table 1 for the lorenz and the mackey glass time series these will be used for comparison purposes in the next sections note that in calculating the nrmse and the mae using eqs 6 and 7 x i is the predicted value x i is the noisy validation output when comparing against noisy validation outputs and x i is the noise free validation output when comparing against noise free outputs table 1 shows that the actual prediction accuracy of a model i e error calculated comparing with noise free outputs is better than what is shown by the error measures calculated through comparison with noisy outputs this shows that noisy data limits the possibility of knowing the actual prediction performance of a model 4 2 do models trained with less noisy data yield better predictions or do noise reduced inputs help models predict better this section investigates two matters simultaneously one is the efficacy of off line noise reduction in prediction improvement and the other is whether noisy data trained ann models can yield better predictions with noise reduced inputs off line noise reduction can be used to reduce noise in a training data set which can facilitate configuring a more accurate prediction model than when noisy data are used as noted in section 2 5 it seems natural to expect that prediction models derived with noise reduced data will yield more accurate predictions than models derived with noisier data this section explores through simulations whether such models indeed give better prediction performance when inputs i e x i in eq 2 are noisier than that of the data used to derive the prediction model noise added chaotic lorenz time series and mackey glass time series were used in the simulations first models were trained for all the time series data sets for lead time t of one unit results already shown in the previous section each model was then used to predict validation data sets of inputs i e x i in eq 2 of different noise levels the predicted values were compared against both the corresponding noisy validation outputs and the noise free validation outputs and their error measures were calculated these results are shown in table 2 since both the nrmse and the mae produced consistent results only mae values are shown table 2 shows that the noise level of noise in the validation inputs affects the prediction accuracy more than the level of noise of the data used to train the model when noise level in the validation inputs was low even a model trained with much noisier data gave better prediction accuracy compared to a model trained with less noisy data for example a model trained with 20 noisy data yields better prediction accuracy for 10 noisy validation inputs than a model trained with 10 noisy data for 20 noisy validation inputs this also justifies the used of noisy data trained models in ekf as discussed in section 3 4 these illustrate that the real time noise reduction can be more effective in providing higher prediction accuracy than off line noise reduction methods which cannot reduce noise in input data another observation from table 2 is the lack of robustness of the models trained with less noisy data when noisy inputs are used in validation for example the models trained with 1 noisy data and validated on 10 noisy inputs have worse prediction accuracies than those models trained with 10 noisy data and validated on 10 noisy inputs similar observations can be made on other noise levels most notably the models trained with noise free data produced worse predictions with noisy validation inputs than those comparable noisy data trained models therefore it is clear from table 2 that models trained with noise reduced data and hence off line noise reduction does not ascertain better prediction performance on the other hand the results show that the noise reduced inputs real time noise reduction can enhance the prediction accuracy thus the key factor in improving the prediction accuracy is the noise reduced input data the results provide answers to the questions raised in the beginning of this section these findings are summarized in table 3 the reason for the discrepancy in model performance between models trained with noisy data and models trained with noise free data on validation inputs of different noise levels can be due to two reasons on one hand the noisy data trained models can be robust and on the other hand the sophisticated noise free data trained models can produce worse predictions on noisy inputs due to the divergence of trajectories owing to the sensitivity of chaotic systems to initial conditions in summary these results show that using the readily available off line nonlinear noise reduction techniques which have thus far been used in chaos hydrological literature are not successful approaches for improving real time prediction accuracy instead the results show that the real time noise reduction where noise is reduced in the current input or current record is capable of prediction improvement therefore investigating suitable real time noise reduction techniques that can be used in chaotic time series noise reduction is called for 4 3 application of ekf lorenz and mackey glass time series this section evaluates the ekf on noisy chaotic lorenz and mackey glass time series prediction with noisy data trained ann model used in ekf state space model findings in the earlier section justified the use of noisy data trained ann models in ekf observation noise levels used were 1 10 20 and 30 the kalman filtering toolbox rebel 0 2 6 developed by rudolph van der merwe which was available at http choosh csee ogi edu rebel was used in this study currently this software is available at http www pdx edu biomedical signal processing lab signal point kalman filters and the rebel toolkit an exhaustive search was conducted on a predetermined range of the two ekf parameters the observation noise covariance and the process noise covariance to find their optimal values this study used the prediction error evaluated comparing the predicted values against the noisy calibration data as the criterion for selection of optimal observation noise covariance and process noise covariance the percentage prediction improvement of ekf predictions over the predictions made with ann were calculated as in eq 34 34 i m p r o v e m e n t prediction e r r o r w i t h a n n p r e d i c t i o n e r r o r w i t h e k f prediction e r r o r w i t h a n n 100 the prediction errors with respect to noisy and noise free outputs and the percentages of improvements for the lorenz and the mackey glass time series are shown in tables 4 and 5 respectively the percentages of improvements for both time series show that ekf yields significantly higher prediction accuracies at all noise levels equally good improvements at different noise levels show the robustness of ekf for the lorenz time series the predicted values are approximately 20 more accurate than their counterparts resulting from ann for mackey glass time series the improvement is over 30 for all the noise levels the effectiveness of ekf also shows that it has been able to produce noise reduced values in the measurement update step and the corrected states can be considered as noise reduced values it should be noted that although not very prominent the prediction improvement is reflected in prediction error against noisy data too this is advantageous since there is hope in using prediction error measured against noisy data as a criterion for identifying noise reduction in real world data where the noise free signal is unknown in summary the results show the effectiveness in real time noise reduction for chaotic time series prediction improvement and in particular the effectiveness and applicability of ekf for such applications 4 4 application of ekf on the river flow time series the extended kalman filter was then applied on the five daily river flow time series the same ranges of observation noise covariance and process noise covariance values considered earlier in the lorenz and mackey glass series were considered initially with time series values normalized into an interval between 0 and 1 the results indicated that the optimal observation noise covariances were very low therefore the tests were repeated with observation covariance varying from 0 001 to 0 1 in steps of 0 005 this in addition to the initial range results on the river flow time series are shown in table 6 since the true signal is unknown only prediction errors with respect to noisy data can be computed results show that ekf does not yield any prediction improvement on three river flow time series namely mississippi wabash and ciliwung measured at sugutamu their prediction performance is of the same order as in using ann only however the two discharge series ciliwung river measured at katulampa and ratujaya show improved predictions with ekf ekf improves prediction accuracy by filtering out the measurement noise in data the nature and the level of measurement noise in the data and the prediction model can affect the effectiveness of ekf on a given data set the apparent inability of ekf to improve predictions on mississippi wabash and sugutamu series can therefore be due to several reasons it is possible that the magnitudes of measurement noise in these series are small compared to the magnitudes of the measurements and the effect of removal of part of this measurement noise on prediction may be insignificant the flow time series with large averages where the magnitudes of the measurement noise can be small compared to the magnitudes of the measurements not showing any improvements while the ones with low averages ciliwung river at katulampa and ratujaya where the magnitudes of the measurement noise can be considerable compared to the measurements showing improvement also supports the aforementioned hypothesis it was observed that the optimal observation noise covariances were much smaller than the process noise covariances for the mississippi and the wabash river flow time series this suggests the dynamical noise due to natural variability of the systems is more prominent than the observation noise on those series and the contribution of measurement noise to the prediction error is less prominent the ekf assumes the noise to be white and gaussian distributed this may not be true in the real river flow time series and it is also possible that the noise is correlated although the ekf is known to work well in practice even when the assumptions are violated abeel 2012 whether these factors too affected the efficacy of ekf in this study is not clear identifying the features of case studies with significant measurement noise can be the future direction of this study however the findings still remain encouraging the effectiveness of ekf on the ciliwung river discharge time series and the theoretical chaotic series with gaussian noise shows that ekf can be effective in certain real case studies most importantly ekf has not deteriorated prediction accuracy by any significant amount in any of the cases considered therefore in the worst case scenario its application would produce predictions almost as good as when ekf was not applied the crucial factor in noise reduction in real flow series is that one has to depend on the noisy data of the same series for validation as well in order to test the effectiveness of noise reduction on a data set which is independent of the data used to noise reduction we performed the following investigation on ciliwung river data 4 5 an indirect validation to verify noise reduction in ciliwung river it is reasonable to assume that the discharge series of the downstream station sugutamu be related to the discharge series of the two upstream stations katulampa and ratujaya therefore we modeled this relationship using ann in the functional form given in eq 35 where s t denotes the discharge at sugutamu at time t whereas r t and k t means the same for ratujaya and katulampa respectively the final objective was to compare the closeness of the modeled series to the observed s t series when observed discharge data r t and k t were used as inputs and when noise reduced discharge data r nrt and k nrt were used as inputs for comparison purposes we developed thirty ann models with number of neurons changing 2 4 each with ten different initial weights for each of these 30 ann models we can calculate the model errors by comparing the observed s t and s t where s t f ann r t k t then we chose 3 noise reduced series from each station ratujaya and katulampa the noise reduced series corresponding to observation process noise covariances pairs 0 5 10 1 10 and 2 10 respectively showed equally good prediction performance as those shown in table 6 with each ann model and 3 noise reduced series from 2 stations as inputs we reproduced 3 3 9 simulated series as s t f ann r nrt k nrt and the simulation errors were calculated comparing s t and s t these errors were then compared with those between s t and s t for 30 ann models this gave 30 9 270 comparisons we used mae nrmse minimum error emin maximum error emax and maximum percentage error maxpe for this comparison for the latter 3 measures error was defined as simulated value minus observed value the number of cases where the model performance was improved when using noise reduced inputs are shown in table 7 table 7 shows that on average the noise reduced data has produced better simulated series for s t with respect to all the error measures considered the magnitudes of the improvement were however not that significant for the averaged error measures mae and nrmse not shown yet the improvement shown in significantly large number of cases with different error measures is clear evidence that the noise reduction has been effective 35 s t f r t k t 5 summary and discussion of results many past studies on chaotic time series noise reduction shared a general perception based on intuition rather than on evidence that noise reduced data trained models can give better predictions however the results of this study showed that this was not necessarily true and often flawed when the input data was noisier the robustness of noisy data trained models and the sensitivity to initial conditions of the less noisy data trained models can be the reasons for the apparent discrepancy this finding shows that off line noise reduction which only helps making a noise reduced data trained model does not ascertain any prediction improvement and its prediction accuracy can even be lower than using a noisy data trained model noise reduced data inputs on the other hand helped the noisy data trained model to yield higher prediction accuracy this finding justifies the use of noisy data trained models in ekf as discussed in section 3 4 it was also found that a model trained with data of same level of noise as its inputs was more robust therefore it can be deduced that a model trained with low noise level can improve the prediction accuracy if it is supported with input data of equally low or lower noise thus the study shows that the key factor in improving the prediction accuracy is the noise reduced input data which requires real time noise reduction the nonlinear noise reduction techniques developed in chaos literature are designed primarily for off line noise reduction applications this implies that it is more advantageous for the chaotic dynamical systems community to consider methods developed in controls literature when dealing with real time applications such as prediction of noisy data similar recommendations were made by walker and mees 1997 too results showed the effectiveness of ekf adopted from controls literature to improve prediction accuracy in synthetic and real time series the robustness of ekf on series with noise levels ranging from mild to very high was also appreciable it should be noted that the robustness of the algorithm is the most important factor for noise reduction applications where true signal is unknown grassberger et al 1993 we believe that real time methods such as unscented kalman filter and second order extended kalman filter that have been shown to be more accurate on highly nonlinear systems gustafsson and hendeby 2012 can also be effective when used in place of the ekf also in our experience the effectiveness of ekf does not depend on the particular prediction model adopted karunasingha 2005 showed that ekf performed equally well with support vector machine svm models as with ann models however it should also be noted that there is a limit in the quality of predictions that can be achieved by these noisy data trained models in ekf for example with the model trained with 30 noisy lorenz data table 2 even if the ekf were able to yield perfect estimates i e noise free data the prediction error measure mae will not be less than 0 7356 due to the imperfectness of the model this casts reasonable doubts whether an iterative approach i e training a model with noise reduced data and using it then in ekf to make better estimations and continuously repeating the procedure might provide better predictions investigations towards this aspect would be worthwhile the applications of ekf on river flow time series showed prediction improvement on ciliwung river s flow time series with low average flows mississippi and wabash rivers flow time series with large average flows did not show any prediction improvement it is possible that when observation noise levels are very low compared to the average flow rates the effect of removal of part of the measurement noise is insignificant to affect the error measures and the dynamical noise of the systems due to natural variability contributes significantly to the prediction error practically measurement noise in hydrological data may be expected to be considerable in situations such as measurements are recorded at large time intervals and lacks smoothness due to averaging e g daily mean recording methods lacks precision missing records are replaced with estimates etc it should also be noted that the prediction improvement reflected over noisy data was significantly low even for the lorenz and the mackey glass time series therefore investigating validation methods other than the prediction error on noisy data of the same series is immensely important for the advancement of noise reduction in real world data the idea behind the indirect validation that this study demonstrated on the observed discharge time series of ciliwung river can be one possible solution it can be effective in dealing with several interrelated time series of a hydrological system the result also suggests that noise reduced time series as inputs may enhance the overall performance of integrated hydrological models advances in computing resources data collection and processing have led to new developments coupling multivariable data with hybrid methods fotovatikhah et al 2018 these hybrid methods are becoming popular due to their improved accuracy compared to single models for example fotovatikhah et al 2018 shows that hybrid methods are superior to single methods in flood and debris flow forecasting considering all those facts and findings we expect that the hybrid method demonstrated in this study coupling ann and ekf can be effective and be validated in hydrological problems dealing with several time series such as rainfall runoff modeling wu and chau 2011 water quality management liu et al 2017 dendrohydrological modeling gholami et al 2015 local weather forecasting missing data estimation etc there are a number of assumptions that are related with ekf and the measured data in real world applications two situations may arise assumptions are satisfied or the assumptions are not fully valid violated in this study in all the cases ekf had either shown prediction improvement or had produced equally good predictions as when ekf was not applied this means the application of ekf is unlikely to deteriorate the predictions depending on whether or not the assumptions are satisfied or violated the nature of measurement noise in observed data is generally unknown and sometimes may be even impossible to determine however investigating the case studies where the measurement noise in data is considerably large can help identify cases where noise reduction can be useful when observed data is used for validation and model evaluation as this study did with real data noise reduction cannot be expected to have adverse effects on data worse than that resulting from any other data driven model the reason is the parameters of data driven models too are determined by evaluating the model s performance on observed data considering these and also the fact that the time delay coordinate method is now used in time series prediction irrespective of whether they being chaotic or stochastic we expect the proposed noise reduction procedures to be effective in a wide variety of problems dealing with time series data 6 conclusion since elshorbagy et al 2002 pointed out the drawbacks in the noise reduction approaches on chaotic hydrological time series published thus far only a few studies have appeared on noise reduction and they too have not cleared the doubts of the hydrology community on the effectiveness of nonlinear noise reduction this study investigated the possibilities of incorporating noise reduction to improve prediction accuracy especially in real time prediction by identifying and utilizing suitable noise reduction methods and approaches this study reveals a major misconception in past studies on noise reduction of noisy chaotic hydrological time series those studies expected that models trained with noise reduced data could provide improved predictions and as a result the investigations were mostly limited to off line noise reduction to the contrary of this general anticipation the findings of this study show that the prediction accuracy may not necessarily be enhanced with models trained with noise reduced data instead it has been shown that noise reduced data inputs can enhance prediction accuracy regardless of whether or not the model is trained with noise reduced data these findings in addition confirm the necessity for going beyond the conventional off line nonlinear noise reduction techniques to real time noise reduction methods this study showed that the real time nonlinear state estimation method the extended kaman filter from controls literature together with ann trained with noisy data as a state space model can be used as a reliable and robust technique for real time prediction improvement of noisy chaotic time series the study justified through simulations the use of imperfect models ann trained with noisy data in the state space model of ekf in addition the study demonstrated how ekf can be implemented for time delays different from one unit when time delay coordinate method for prediction was used the investigation was limited to one step prediction of five river flow series in additional to lorenz and mackey glass series the ekf produced significant prediction improvement as high as 15 40 over ann models in the noise added lorenz and the mackey glass time series prediction the effectiveness of ekf on noise levels ranging from mild 1 to very high 30 showed its robustness which is the most desirable factor in a noise reduction method only gaussian white noise was used in this study testing ekf for non gaussian and coloured noises and studying filters that are designed for non gaussian coloured noises will be useful when applied on river flow time series ekf showed prediction improvement on two discharge series of ciliwung river with low average flows mississippi and wabash river flow time series with large average flows did not show any prediction improvement the findings suggest that noise reduction can be effective where the measurement noise is considerably large compared to average observations identifying the hydrological data records that are more likely to contain large measurement errors will greatly help future investigations the study showed that the real effectiveness of noise reduction is not reflected on error measures with respect to noisy data of the same series thus finding better validation methods for evaluating noise removal is extremely important for the advancement of noise reduction in real data the study proposed a possible solution through an indirect validation method that can be used to verify the effectiveness of noise reduction in cases where several interrelated time series were available this was supported by the observed discharge time series of ciliwung river in jakarta indonesia therefore the real time noise reduction can be effective and be validated in hydrological problems dealing with time series of several interrelated variables of a system acknowledgements the first author wishes to thank the national university of singapore for awarding a research scholarship during which a part of this work was completed we would like to thank the anonymous reviewers for their useful comments which improved the quality of the manuscript us geological survey usgs data available free of charge were downloaded from http water usgs gov 
7037,short term prediction of hydrological time series using chaotic dynamical systems approach has gained popularity however noise can severely affect the prediction accuracy of any data driven modelling approach noise reduction processes attempted in chaotic hydrological time series analysis were later questioned by elshorbagy et al 2002 for their appropriateness for noise reduction processes only a few studies on noise reduction have appeared since then and these too were limited to introducing new noise reduction methods most of the past studies on chaotic time series noise reduction shared a general perception that the noise reduced data trained models can give better predictions they used off line noise reduction methods to obtain a noise reduced data set which was then used to make prediction models however the results of this study showed that this was not necessarily true and often flawed when the input data was noisier instead noise reduced data inputs were shown to yield higher prediction accuracy even with noisy data trained models thus the study showed a real need to use real time noise reduction methods instead of off line noise reduction methods that had previously been used the extended kalman filter ekf a popular nonlinear state estimation method from controls literature was introduced as a real time noise reduction method and its effectiveness was demonstrated on both synthetic chaotic time series and real river flow time series ekf produced prediction improvement as high as 15 40 on the benchmark time series with noise levels varying from 1 to 30 two river flow series with low average flows showed prediction improvement whereas three other flow series with relatively large average flows did not artificial neural network ann models were used as the state space models in ekf and adopting them to time delays different from 1 unit was also demonstrated the study demonstrated an indirect validation method to verify the effectiveness of noise reduction when several interrelated time series were available this was supported in observed discharge time series of the ciliwung river in jakarta indonesia keywords noise real time prediction time series river flow extended kalman filter chaos 1 introduction several studies have attempted the issue of noise reduction in chaotic hydrological time series e g porporato and ridolfi 1997 kawamura et al 1998 sivakumar et al 1999a b jayawardena and gurung 2000 however all these studies were later critically commented by elshorbagy et al 2002 due to their inappropriate use of noise reduction porporato and ridolfi 1997 were the first to apply noise reduction in chaotic hydrological time series sivakumar et al 1999a b showed some drawbacks in porporato and ridolfi 1997 and proposed a systematic approach for noise reduction later elshorbagy et al 2002 showed drawbacks in sivakumar et al 1999a b and other works porporato and ridolfi 1997 kawamura et al 1998 jayawardena and gurung 2000 since then only a very few studies sun et al 2008 han and liu 2009 liu and liao 2011 jafari et al 2012 han and chang 2013 on noise reduction in chaotic time series have been published they too are limited to introducing noise reduction methods and to measuring noise levels orzeszko 2008 çoban et al 2012 jayawardena et al 2008 all these noise reduction methods have considered off line noise reduction mainly for the purpose of chaos identification no studies to the authors knowledge have focused on noise reduction for real time prediction improvement purposes the erroneous noise reduction approaches and applications thus their resulting perceived both remarkable improvement in prediction accuracy and good data quality seem to have blurred hydrology community on the effectiveness of nonlinear noise reduction this study looks into the possibilities of incorporating noise reduction to improve real time prediction accuracy in this course the possible ways of improving real time predictions are hypothesized by examining the noise reduction problem and they are tested by simulation of theoretical chaotic time series this reveals a misconception in past studies on off line noise reduction and shows the real need for real time noise reduction then the ekf with ann models is demonstrated for real time prediction improvement of noisy time series a method for validation of noise reduction in real data is then proposed and demonstrated on ciliwung river in jakarta indonesia paper is organized as follows section 2 discusses the noise reduction problem concerns on noise reduction applications in hydrological literature an overview of the methodology followed in this study and a description of the data used theory of the linear kalman filter ekf and its adoption with ann models are given in section 3 section 4 is the results and discussion followed by conclusions in section 5 2 materials and methods 2 1 prediction of chaotic time series takens 1981 showed that it is possible to reconstruct the dynamics of a chaotic system using only a single variable of the system packard et al 1980 and takens 1981 described the time delay coordinate method to construct the phase space from single variable scalar time series accordingly the phase space vector x i can be expressed as in eq 1 1 x i x i x i τ x i m 1 τ where x i is the observed value at time t i i δ t where δ t is the sampling interval m is called the embedding dimension and τ is the time delay which is a suitable multiple of the sampling time δ t in phase space prediction a nonlinear functional relationship between the current state x i and the future value x i t of the form given in eq 2 is used where t is referred to as the lead time measured in terms of the sampling intervals 2 x i t f t x i 2 2 noise reduction of chaotic time series the noise reduction problem for time series data may be defined as follows suppose y i r i 1 2 n is a noisy time series where the corresponding true i e noise free series is x i r i 1 2 n the true or noise free series is generally unknown the aim of noise reduction is to come up with a noise reduced series y i r i 1 2 n that minimizes the differences ε i y i x i such that ε i ε i where ε i y i x i preferably for all i 1 2 n in which ε i 0 in other words the noise reduced series y i will be closer to the true series x i than does the noisy series y i noise reduction in general may be applied in off line or in real time in off line applications both the past y p p r and the future y f f r records of a particular record y r are used to reduce noise in that record in contrast future records are not used in real time applications therefore in real time when a measured value becomes available that value and the past values are used to derive a noise reduced estimate for that measured value almost all the nonlinear noise reduction techniques appeared in chaos literature can be effectively applied only in off line noise reduction e g hammel 1990 kostelich and yorke 1990 schreiber and grassberger 1991 cawly and hsu 1992 sauer 1992 schreiber 1993 etc real time noise reduction techniques are not readily available in chaotic nonlinear noise reduction literature 2 3 relevant concerns on noise reduction in chaotic hydrological time series as mentioned earlier elshorbagy et al 2002 questioned the noise reduction approaches applied in various studies sivakumar et al 1999a b porporato and ridolfi 1997 kawamura et al 1998 jayawardena and gurung 2000 the main concerns comments of elshorbagy et al 2002 relevant to the present study are summarized as follows details can be found in karunasingha 2005 1 the earlier studies measured the prediction performance in validation by comparing the predicted values against noise reduced data instead of against the original raw data and 2 the accuracy measures used for the noise removal were inappropriate note that the earlier studies considered the prediction model perfectly models the underlying dynamics and the removed part is considered noise to a single model not the absolute noise the comments raised by elshorbagy et al 2002 above are justified they applied the approach proposed by sivakumar et al 1999b on english river ontario canada with the simple noise reduction proposed by schreiber 1993 and verified their doubts the study of elshorbagy et al 2002 showed the followings 1 when prediction accuracy is measured by comparing the predicted values with noise reduced verification data unrealistically high prediction accuracy was observed this means that comparing predictions with noise reduced data is inappropriate and 2 the improvement in prediction performance with noise reduced data with two different models were significantly different this supports the claim of different perceptions of noise from different models in noise reduction of real data totally reliable ways of verifying the noise removal are not available grassberger et al 1993 with real time series data such as rainfall and runoff using prediction accuracy as a criterion seems to be the most reasonable alternative the question is what to compare the prediction results with elshorbagy et al 2002 showed that comparing the predicted values with noise reduced values to arrive at a measure of prediction accuracy and using it to measure the effectiveness of noise reduction is an incorrect approach one way to overcome this however is to compare the predicted values with the corresponding original values this to a certain extent may be considered as model independent as well the reason being what any prediction technique tries to accomplish is to reduce the prediction error resulting from the predicted values compared to their counterparts the observed values another serious flaw in using off line noise reduced validation data for predicting is that such noise reduced values are derived with the use of future observed data as well this is therefore not applicable in real time predictions noise reduction approach for real time prediction which is one of the main focus in this study is not readily available 2 4 noise reduction for prediction enhancement of chaotic time series consider the evolution of a chaotic dynamical system that relates the current state to a future value which may be expressed as x i 1 f x i using a one step lead time in eq 2 there are two main components in this expression 1 the function f and 2 the current state x i in the case of chaotic time series analysis an approximation to the function f f is derived from the past time series data which is referred to as a data driven model or simply a model when the current state is known the prediction for the future is then given as f x i real data contains noise and the recorded data are not exactly the series x i but some measured series y i expressed as in eq 3 where υ i is measurement noise 3 y i x i υ i if the data contains noise the function f cannot be accurately approximated and that affects the prediction accuracy when the input data x i contains noise the prediction performance is expected to be poor thus it is expected that the prediction accuracy to improve by using 1 a better model configured with noise reduced data and or 2 using noise reduced input data to configure a better prediction model a noise reduced data set can be used for this purpose any off line noise reduction technique can be applied to reduce noise in input data noise reduction has to be incorporated in real time or on line earlier studies on noise reduction questioned by elshorbagy et al 2002 have used off line noise reduction with an implicit assumption that models configured with noise reduced data i e better models can improve prediction performance however the findings of those studies are uncertain due to the drawbacks mentioned earlier therefore the present study investigates 1 the possibility of improving prediction performance using the readily available off line noise reduction techniques i e whether the models derived from noise reduced data enhances prediction performance and 2 the effectiveness of real time noise reduction i e noise reduction of input data in chaos based prediction improvement 2 5 overview of methodology this section gives an overview of the methodologies with a little elaboration on how models are derived and used in noise reduction of real data totally reliable ways of verifying the noise removal are not available grassberger et al 1993 it is therefore very important to test any noise reduction procedure on a data set where the true signal is known kantz and schreiber 2004 in this study all the investigations were first performed on a chaotic lorenz series and a chaotic mackey glass time series contaminated with known noise levels here the noise level is defined as the ratio of standard deviation of noise to standard deviation of noise free series signal calculated as a percentage random variables in real life result from the sum of a large number of random effects variables and using the famous central limit theorem in probability theory gaussian distribution is often used to model such real random variables the measurement noise in eq 3 is generally assumed to be gaussian therefore gaussian random noise was added to noise free chaotic time series to obtain noisy series five different noise levels from very mild noise to very high noise 0 or noise free 1 10 20 30 were considered then the methods were applied on five real river flow time series of which the levels of measurement noise were unknown ann specifically multilayer perceptron models were used as prediction models as they are by far the most popular type of models in various hydrologic applications e g wu and chau 2011 fotovatikhah et al 2018 more details on ann model training and choice of optimal parameters including m and τ relevant to this study can be found at karunasinghe and liong 2006 in summary each time series was divided into three parts training calibration and validation for modelling and validation purposes for each time series the training set was used to train several ann models and the model with the highest prediction accuracy on the calibration set was chosen as the ann model for that time series thus minimizing the overfitting and local minima issues of ann whenever such choices were made prediction accuracy was calculated by comparing the predictions with corresponding original noisy outputs these models were then tested on validation sets of different levels of noise the prediction accuracies of these validations were calculated by comparing the predictions with the corresponding noisy validation outputs or the noise free outputs as per the requirement other relevant details of the investigations are explained later in the results and discussion section 2 6 data and prediction performance measures used in this study the investigations were conducted using several theoretical and real data sets currently the measurement noise levels available in hydrological time series are unknown therefore as the first investigation five daily river flow time series of three rivers with average flows of different magnitudes were chosen the lorenz and the mackey glass time series are perhaps the two most widely used benchmark series for chaotic time series analysis and were chosen for the study of those two river flows have shown chaotic behavior yu 2004 karunasingha 2005 and the other three have shown good predictions with chaos approach sun et al 2014 lorenz 1963 abstracted three ordinary differential equations from galerkin approximation to the partial differential equations of thermal convection in the lower atmosphere abarbanel 1996 these have served as a set of benchmark equations for testing ideas in nonlinear dynamics lorenz model consists of the three ordinary differential equations as given in eq 4 4 x σ y x y x z γ x y z x y b z when standard parameter values σ 16 b 4 and γ 45 92 are used the orbits of the lorenz system reside on a geometric object of dimension 2 06 approximately and exhibit non periodic chaotic motion abarbanel 1996 the x t component was solved from the above equations by fourth order runge kutta method with a time step of δt 0 01 six thousand values of this x t time series was used in this study mackey glass time series refers to the delayed differential equation as given in eq 5 5 dx t dt ax t τ 1 x t τ 10 b x t when a 0 2 b 0 1 and τ 17 the series shows chaotic behavior the system was numerically solved using the 4th order runge kutta method at discrete equally spaced time steps to derive the chaotic mackey glass time series the daily river flows used were 1 mississippi river at vicksburg 1975 1993 2 wabash river at mt carmel 1960 1978 and ciliwung river in jakarta 1 17 2006 12 31 2006 recorded at three measurement stations katulampa upstream ratujaya and sugutamu downstream mississippi river is characterized by large flow rates mean flow of approximately 18 500 m3 s while wabash river is of moderate flow rates mean flow of about 750 m3 s and ciliwung river is of low flow rates mean discharges of about 9 9 and 29 m3 s at katulampa ratujaya and sugutamu respectively jakarta the capital of republic of indonesia and a populous city with over 9 5 million inhabitants suffers from massive flooding almost every year out of 13 main rivers flowing through the region ciliwung river is the longest sun et al 2014 liu et al 2014 the first two river flow series are available in the us geological survey website http water usgs gov in order to evaluate the prediction performance of the models and noise reduction two error measures were used legates and mccabe 1999 recommend the use of at least one absolute error measure and one relative error measure to test the model performance in hydrologic and hydro climatic model validation the normalized root mean square error nrmse was chosen as the relative error measure in this study as it gives a better resolution of values for cases with very good predictions e g models trained with low levels of noise the nrmse is given in eq 6 where x i is the predicted value of x i and x is average value of the time series 6 nrmse i 1 n x i x i 2 i 1 n x i x 2 a zero value in nrmse indicates a perfect prediction while a value larger than 1 indicates that the predictions are no better than using the average value of the time series x note that the popularly used nash sutcliffe coefficient of efficiency ce and nrmse are related as ce 1 nrmse2 the absolute error measure mean absolute error mae is given in eq 7 where x i is the desired value and x i is the predicted value 7 mae i 1 n x i x i n 3 theory 3 1 introduction the kalman filter kalman 1960 is the most widely used tool to estimate the system states from noisy measurements it uses observed measurements from a dynamical system to make more accurate estimates of the system s states kalman filtering techniques are core and widely used techniques in controls literature the direct extension of the original linear kalman filter for nonlinear systems is called the extended kalman filter and the derivation of these filters can be found in numerous documents e g maybeck 1979 einicke and white 1999 welch and bishop 2004 the extended kalman filter comprises of a set of equations that describe a nonlinear system and a theory that optimally blends the observations and model predictions to make better system estimates kalman filter kf was originally derived for linear systems but most of the real world systems are nonlinear the direct extension of linear kf for nonlinear systems is called the extended kalman filter ekf improved variations and other forms of kf which are claimed to be better than ekf are also available for nonlinear systems to understand the kalman filter technique and the ekf formulation it is essential to understand the linear kalman filter therefore the linear kalman filter is explained first and the ekf in its most basic form is presented next among the many references the derivation of these filters has been documented this section follows the work of welch and bishop 2004 3 2 linear kalman filter the kalman filter addresses the problem of trying to estimate the state x r n of a discrete time controlled process governed by the linear stochastic difference equation 8 x k a k x k 1 b k u k w k 1 with a measurement z r m that is 9 z k h k x k υ k the random variables w k and υ k represent the process and the measurement noise respectively they are assumed to be independent of each other white and of normal probability distributions 10 p w n 0 q p υ n 0 r in practice the process noise covariance q and measurement noise covariance r matrices might change with each time step or measurement however here it is assumed that they are constant the set of relations given in eqs 8 and 9 is called the state space model the n n matrix ak in eq 8 relates the state at the previous time step k 1 to the state at the current step k in the absence of either a driving function or process noise the n l matrix bk relates the optional control input u r l to the state x the m n matrix hk in the measurement equation relates the state to the measurement z k define x k r n to be a priori state estimate at step k given the knowledge of the process prior to step k and x k r n to be our a posteriori state estimate at step k given measurement z k an n m matrix kk gain or blending factor is chosen so that the a posteriori error covariance is minimized it can be shown that see welch and bishop 2004 11 k k p k h k t h k p k h k t r k 1 which is referred to as the kalman gain matrix and 12 p k i k k h k p k which is the optimized value of the updated estimation error covariance matrix the a priori estimates are obtained in the prediction step or the time update step where the quantities are projected through time the a priori estimates are obtained as 13 x k a x k 1 bu k 14 p k ap k 1 a t q once kk and pk are found the a posteriori estimates can be obtained in the correction step or the measurement update step as follows 15 k k p k h k t h k p k h k t r k 1 16 x k x k k k z k h x k 17 p k i k k h k p k the initial conditions for the filter can be given as 18 e x 0 x 0 and e x 0 x 0 x 0 x 0 t p o when no other information is available an arbitrary value may be chosen as the initial state estimate 3 3 extended kalman filter for nonlinear systems the extended kalman filter derivation can be outlined as follows welch and bishop 2004 assume that the system has a state vector x r n and is governed by the nonlinear stochastic difference equation 19 x k f x k 1 u k 1 w k 1 with a measurement z r m where 20 z k h x k υ k in eqs 19 and 20 w k and υ k represent as earlier process and measurement noises in practice the individual values of the noise w k and υ k are unknown f is a nonlinear function and h can be a linear or a nonlinear function using taylor series approximation on eqs 19 and 20 to linearize and after some manipulations the final ekf time update and measurement update equations can be given as follows time update 21 x k f x k 1 u k 1 0 22 p k a k p k 1 a k t w k q k 1 w k t measurement update 23 k k p k h k t h k p k h k t v k r k v k t 1 24 x k x k k k z k h x k 0 25 p k i k k h k p k in the above equations a is the jacobian matrix of partial derivatives of f with respect to x w is the jacobian matrix of partial derivatives of f with respect to w h is the jacobian matrix of partial derivatives of h with respect to x and v is the jacobian matrix of partial derivatives of h with respect to υ the kalman filter cycles between time update and measurement update over the time steps fig 1 3 4 adoption of ekf with data driven models for real time noise reduction in real time prediction applications the challenge is to estimate the noise reduced value as soon as the observation is obtained so that it can be used as an input to make a more accurate prediction of the future value the extended kalman filter s approach is when a new measurement becomes available the corrected state in the measurement update step can be considered as a noise reduced state this noise reduced state will then be used as the input to make the prediction for the next time step in the time update step ideally ekf assumes a perfect state space model a few studies walker and mees 1997 judd 2003 that have applied ekf in chaotic time series prediction have used the exact governing equations or a nearly perfect model derived from noise free data however this kind of perfect models are not in existence for most of the real world systems in real dynamical systems where perhaps only one or few variables are observed all one can obtain is a data driven model trained from most probably noisy data justification of the use of less than perfect models in ekf can be given as follows in order for ekf to make an improved prediction with the more correct estimate of the state see fig 1 the prediction model should be able to produce better predictions with less noisy inputs this is because the ekf uses measurement update value which is theoretically less noisy than the measurement to predict in time update step if the prediction model is able to give a better prediction with the less noisy measurement update correction the next measurement update step which uses the predicted value will in turn yield a better estimate correction thus the whole algorithm will lead to improved estimates and predictions note that section 4 2 investigates whether less noisy measurements can yield more accurate predictions with noisy data trained models ekf does not use the future records of a point to come up with a better estimate for that point therefore it has the potential to be used as a real time noise reduction technique it should be noted that kalman filter estimates can be considered as noise reduced data for systems where the system state is directly observed i e in systems where h i where i is the identity matrix in the measurement model eq 9 the chaos application is a special case where the observations are directly used to determine the states and therefore the kf estimates can be considered as noise reduced data without any conversion errors due to transformations through h the above discussion leads to the hypothesis that it is possible to use a model trained with noisy data in ekf and to use ekf as a real time noise reduction technique in chaotic time series analysis provided that such a model can yield improved predictions with less noisy inputs the next section explains how the noisy data trained ann model is incorporated in the state space model of the extended kalman filter 3 5 ann model trained with noisy data in ekf noise reduction in chaotic time series prediction we try to approximate the dynamical rule 26 x t t f t x t x t τ x t m 1 τ relating a future coordinate to past coordinates the approximation can be expressed as 27 x t t f t x t x t τ x t m 1 τ w t where ft is the approximate model and wt is the residual error taking both the time delay τ and the prediction horizon t to be unity the relationship can be expressed as 28 x k f x k 1 x k 2 x k m w k since the observed data contain measurement noise the observations can be related to actual signal as 29 y k x k υ k eqs 28 and 29 closely resemble the state space model of extended kalman filter given in eqs 19 and 20 with the exception of scalars at the places of vectors in ekf state space model following haykin 2001 the state space representation can be formulated as 30 x k f x k 1 b w k x k x k 1 x k m 1 f x k 1 x k 2 x k m 1 0 0 0 0 1 0 0 0 0 1 0 x k 1 x k 2 x k m 1 0 0 w k 31 y k cx k υ k 1 0 0 x k υ k where the state x k is chosen to be the phase space vector and the state transition function f has its first element given by f with the remaining values corresponding to the shifted values of the previous state here the residual error is considered as process noise haykin 2001 in chaotic time series prediction the optimal time delay may not necessarily be unity the following procedure is followed in this study for delay times different from unity the state space model was implemented as shown in eq 32 32 x k f x k 1 b w k x k x k τ x k m 1 τ f x k 1 x k 1 τ x k 1 m 1 τ 1 0 0 0 0 1 0 0 0 0 1 0 x k τ x k 2 τ x k m τ 1 0 0 w k as before the first element of the state vector is given by f with the remaining values now given by the corresponding lag elements not necessarily from previous state it should be noted that although the updated previous state x k 1 is readily available for use in f the updated values of other lag elements are not therefore in this study a pool of states was maintained in a temporary file where their elements were updated once a state estimate was made the idea was that when a corrected estimate was obtained in the measurement update step the corresponding elements in the pool were updated with the elements of the state x k the corresponding lag elements for the use in eq 32 were chosen from this updated file the temporary states file looked like eq 33 when the state estimate of x k was made the elements of the future states which have similar elements were replaced by those updated elements of x k for example in eq 33 when updated x k was available the last element of state x k m 1 τ can be replaced by the first element of x k it should also be noted that some of the values of this pool of states are empty for example the elements starting from x k 1 upwards are unknown this updating process continued whenever an estimate was made in addition the oldest estimate was removed from the temporary file and a new column was added in this process an element was generally replaced m times by better estimates 33 x k x k τ x k m 1 τ x k 1 x k 1 τ x k 1 m 1 τ x k m 1 τ x k m 2 τ x k m m 1 τ 1 4 results and discussion 4 1 ann models ann models for 1 step ahead prediction were trained for each time series as described in section 2 5 when selecting the best model for a given time series the one step prediction accuracy calculated on the calibration set by comparing the predictions with noisy calibration outputs was used then the best model for each series was used to predict one step ahead predictions of the noisy validation set the resulting predictions were compared against the corresponding noisy and the noise free validation outputs their error measures are shown in table 1 for the lorenz and the mackey glass time series these will be used for comparison purposes in the next sections note that in calculating the nrmse and the mae using eqs 6 and 7 x i is the predicted value x i is the noisy validation output when comparing against noisy validation outputs and x i is the noise free validation output when comparing against noise free outputs table 1 shows that the actual prediction accuracy of a model i e error calculated comparing with noise free outputs is better than what is shown by the error measures calculated through comparison with noisy outputs this shows that noisy data limits the possibility of knowing the actual prediction performance of a model 4 2 do models trained with less noisy data yield better predictions or do noise reduced inputs help models predict better this section investigates two matters simultaneously one is the efficacy of off line noise reduction in prediction improvement and the other is whether noisy data trained ann models can yield better predictions with noise reduced inputs off line noise reduction can be used to reduce noise in a training data set which can facilitate configuring a more accurate prediction model than when noisy data are used as noted in section 2 5 it seems natural to expect that prediction models derived with noise reduced data will yield more accurate predictions than models derived with noisier data this section explores through simulations whether such models indeed give better prediction performance when inputs i e x i in eq 2 are noisier than that of the data used to derive the prediction model noise added chaotic lorenz time series and mackey glass time series were used in the simulations first models were trained for all the time series data sets for lead time t of one unit results already shown in the previous section each model was then used to predict validation data sets of inputs i e x i in eq 2 of different noise levels the predicted values were compared against both the corresponding noisy validation outputs and the noise free validation outputs and their error measures were calculated these results are shown in table 2 since both the nrmse and the mae produced consistent results only mae values are shown table 2 shows that the noise level of noise in the validation inputs affects the prediction accuracy more than the level of noise of the data used to train the model when noise level in the validation inputs was low even a model trained with much noisier data gave better prediction accuracy compared to a model trained with less noisy data for example a model trained with 20 noisy data yields better prediction accuracy for 10 noisy validation inputs than a model trained with 10 noisy data for 20 noisy validation inputs this also justifies the used of noisy data trained models in ekf as discussed in section 3 4 these illustrate that the real time noise reduction can be more effective in providing higher prediction accuracy than off line noise reduction methods which cannot reduce noise in input data another observation from table 2 is the lack of robustness of the models trained with less noisy data when noisy inputs are used in validation for example the models trained with 1 noisy data and validated on 10 noisy inputs have worse prediction accuracies than those models trained with 10 noisy data and validated on 10 noisy inputs similar observations can be made on other noise levels most notably the models trained with noise free data produced worse predictions with noisy validation inputs than those comparable noisy data trained models therefore it is clear from table 2 that models trained with noise reduced data and hence off line noise reduction does not ascertain better prediction performance on the other hand the results show that the noise reduced inputs real time noise reduction can enhance the prediction accuracy thus the key factor in improving the prediction accuracy is the noise reduced input data the results provide answers to the questions raised in the beginning of this section these findings are summarized in table 3 the reason for the discrepancy in model performance between models trained with noisy data and models trained with noise free data on validation inputs of different noise levels can be due to two reasons on one hand the noisy data trained models can be robust and on the other hand the sophisticated noise free data trained models can produce worse predictions on noisy inputs due to the divergence of trajectories owing to the sensitivity of chaotic systems to initial conditions in summary these results show that using the readily available off line nonlinear noise reduction techniques which have thus far been used in chaos hydrological literature are not successful approaches for improving real time prediction accuracy instead the results show that the real time noise reduction where noise is reduced in the current input or current record is capable of prediction improvement therefore investigating suitable real time noise reduction techniques that can be used in chaotic time series noise reduction is called for 4 3 application of ekf lorenz and mackey glass time series this section evaluates the ekf on noisy chaotic lorenz and mackey glass time series prediction with noisy data trained ann model used in ekf state space model findings in the earlier section justified the use of noisy data trained ann models in ekf observation noise levels used were 1 10 20 and 30 the kalman filtering toolbox rebel 0 2 6 developed by rudolph van der merwe which was available at http choosh csee ogi edu rebel was used in this study currently this software is available at http www pdx edu biomedical signal processing lab signal point kalman filters and the rebel toolkit an exhaustive search was conducted on a predetermined range of the two ekf parameters the observation noise covariance and the process noise covariance to find their optimal values this study used the prediction error evaluated comparing the predicted values against the noisy calibration data as the criterion for selection of optimal observation noise covariance and process noise covariance the percentage prediction improvement of ekf predictions over the predictions made with ann were calculated as in eq 34 34 i m p r o v e m e n t prediction e r r o r w i t h a n n p r e d i c t i o n e r r o r w i t h e k f prediction e r r o r w i t h a n n 100 the prediction errors with respect to noisy and noise free outputs and the percentages of improvements for the lorenz and the mackey glass time series are shown in tables 4 and 5 respectively the percentages of improvements for both time series show that ekf yields significantly higher prediction accuracies at all noise levels equally good improvements at different noise levels show the robustness of ekf for the lorenz time series the predicted values are approximately 20 more accurate than their counterparts resulting from ann for mackey glass time series the improvement is over 30 for all the noise levels the effectiveness of ekf also shows that it has been able to produce noise reduced values in the measurement update step and the corrected states can be considered as noise reduced values it should be noted that although not very prominent the prediction improvement is reflected in prediction error against noisy data too this is advantageous since there is hope in using prediction error measured against noisy data as a criterion for identifying noise reduction in real world data where the noise free signal is unknown in summary the results show the effectiveness in real time noise reduction for chaotic time series prediction improvement and in particular the effectiveness and applicability of ekf for such applications 4 4 application of ekf on the river flow time series the extended kalman filter was then applied on the five daily river flow time series the same ranges of observation noise covariance and process noise covariance values considered earlier in the lorenz and mackey glass series were considered initially with time series values normalized into an interval between 0 and 1 the results indicated that the optimal observation noise covariances were very low therefore the tests were repeated with observation covariance varying from 0 001 to 0 1 in steps of 0 005 this in addition to the initial range results on the river flow time series are shown in table 6 since the true signal is unknown only prediction errors with respect to noisy data can be computed results show that ekf does not yield any prediction improvement on three river flow time series namely mississippi wabash and ciliwung measured at sugutamu their prediction performance is of the same order as in using ann only however the two discharge series ciliwung river measured at katulampa and ratujaya show improved predictions with ekf ekf improves prediction accuracy by filtering out the measurement noise in data the nature and the level of measurement noise in the data and the prediction model can affect the effectiveness of ekf on a given data set the apparent inability of ekf to improve predictions on mississippi wabash and sugutamu series can therefore be due to several reasons it is possible that the magnitudes of measurement noise in these series are small compared to the magnitudes of the measurements and the effect of removal of part of this measurement noise on prediction may be insignificant the flow time series with large averages where the magnitudes of the measurement noise can be small compared to the magnitudes of the measurements not showing any improvements while the ones with low averages ciliwung river at katulampa and ratujaya where the magnitudes of the measurement noise can be considerable compared to the measurements showing improvement also supports the aforementioned hypothesis it was observed that the optimal observation noise covariances were much smaller than the process noise covariances for the mississippi and the wabash river flow time series this suggests the dynamical noise due to natural variability of the systems is more prominent than the observation noise on those series and the contribution of measurement noise to the prediction error is less prominent the ekf assumes the noise to be white and gaussian distributed this may not be true in the real river flow time series and it is also possible that the noise is correlated although the ekf is known to work well in practice even when the assumptions are violated abeel 2012 whether these factors too affected the efficacy of ekf in this study is not clear identifying the features of case studies with significant measurement noise can be the future direction of this study however the findings still remain encouraging the effectiveness of ekf on the ciliwung river discharge time series and the theoretical chaotic series with gaussian noise shows that ekf can be effective in certain real case studies most importantly ekf has not deteriorated prediction accuracy by any significant amount in any of the cases considered therefore in the worst case scenario its application would produce predictions almost as good as when ekf was not applied the crucial factor in noise reduction in real flow series is that one has to depend on the noisy data of the same series for validation as well in order to test the effectiveness of noise reduction on a data set which is independent of the data used to noise reduction we performed the following investigation on ciliwung river data 4 5 an indirect validation to verify noise reduction in ciliwung river it is reasonable to assume that the discharge series of the downstream station sugutamu be related to the discharge series of the two upstream stations katulampa and ratujaya therefore we modeled this relationship using ann in the functional form given in eq 35 where s t denotes the discharge at sugutamu at time t whereas r t and k t means the same for ratujaya and katulampa respectively the final objective was to compare the closeness of the modeled series to the observed s t series when observed discharge data r t and k t were used as inputs and when noise reduced discharge data r nrt and k nrt were used as inputs for comparison purposes we developed thirty ann models with number of neurons changing 2 4 each with ten different initial weights for each of these 30 ann models we can calculate the model errors by comparing the observed s t and s t where s t f ann r t k t then we chose 3 noise reduced series from each station ratujaya and katulampa the noise reduced series corresponding to observation process noise covariances pairs 0 5 10 1 10 and 2 10 respectively showed equally good prediction performance as those shown in table 6 with each ann model and 3 noise reduced series from 2 stations as inputs we reproduced 3 3 9 simulated series as s t f ann r nrt k nrt and the simulation errors were calculated comparing s t and s t these errors were then compared with those between s t and s t for 30 ann models this gave 30 9 270 comparisons we used mae nrmse minimum error emin maximum error emax and maximum percentage error maxpe for this comparison for the latter 3 measures error was defined as simulated value minus observed value the number of cases where the model performance was improved when using noise reduced inputs are shown in table 7 table 7 shows that on average the noise reduced data has produced better simulated series for s t with respect to all the error measures considered the magnitudes of the improvement were however not that significant for the averaged error measures mae and nrmse not shown yet the improvement shown in significantly large number of cases with different error measures is clear evidence that the noise reduction has been effective 35 s t f r t k t 5 summary and discussion of results many past studies on chaotic time series noise reduction shared a general perception based on intuition rather than on evidence that noise reduced data trained models can give better predictions however the results of this study showed that this was not necessarily true and often flawed when the input data was noisier the robustness of noisy data trained models and the sensitivity to initial conditions of the less noisy data trained models can be the reasons for the apparent discrepancy this finding shows that off line noise reduction which only helps making a noise reduced data trained model does not ascertain any prediction improvement and its prediction accuracy can even be lower than using a noisy data trained model noise reduced data inputs on the other hand helped the noisy data trained model to yield higher prediction accuracy this finding justifies the use of noisy data trained models in ekf as discussed in section 3 4 it was also found that a model trained with data of same level of noise as its inputs was more robust therefore it can be deduced that a model trained with low noise level can improve the prediction accuracy if it is supported with input data of equally low or lower noise thus the study shows that the key factor in improving the prediction accuracy is the noise reduced input data which requires real time noise reduction the nonlinear noise reduction techniques developed in chaos literature are designed primarily for off line noise reduction applications this implies that it is more advantageous for the chaotic dynamical systems community to consider methods developed in controls literature when dealing with real time applications such as prediction of noisy data similar recommendations were made by walker and mees 1997 too results showed the effectiveness of ekf adopted from controls literature to improve prediction accuracy in synthetic and real time series the robustness of ekf on series with noise levels ranging from mild to very high was also appreciable it should be noted that the robustness of the algorithm is the most important factor for noise reduction applications where true signal is unknown grassberger et al 1993 we believe that real time methods such as unscented kalman filter and second order extended kalman filter that have been shown to be more accurate on highly nonlinear systems gustafsson and hendeby 2012 can also be effective when used in place of the ekf also in our experience the effectiveness of ekf does not depend on the particular prediction model adopted karunasingha 2005 showed that ekf performed equally well with support vector machine svm models as with ann models however it should also be noted that there is a limit in the quality of predictions that can be achieved by these noisy data trained models in ekf for example with the model trained with 30 noisy lorenz data table 2 even if the ekf were able to yield perfect estimates i e noise free data the prediction error measure mae will not be less than 0 7356 due to the imperfectness of the model this casts reasonable doubts whether an iterative approach i e training a model with noise reduced data and using it then in ekf to make better estimations and continuously repeating the procedure might provide better predictions investigations towards this aspect would be worthwhile the applications of ekf on river flow time series showed prediction improvement on ciliwung river s flow time series with low average flows mississippi and wabash rivers flow time series with large average flows did not show any prediction improvement it is possible that when observation noise levels are very low compared to the average flow rates the effect of removal of part of the measurement noise is insignificant to affect the error measures and the dynamical noise of the systems due to natural variability contributes significantly to the prediction error practically measurement noise in hydrological data may be expected to be considerable in situations such as measurements are recorded at large time intervals and lacks smoothness due to averaging e g daily mean recording methods lacks precision missing records are replaced with estimates etc it should also be noted that the prediction improvement reflected over noisy data was significantly low even for the lorenz and the mackey glass time series therefore investigating validation methods other than the prediction error on noisy data of the same series is immensely important for the advancement of noise reduction in real world data the idea behind the indirect validation that this study demonstrated on the observed discharge time series of ciliwung river can be one possible solution it can be effective in dealing with several interrelated time series of a hydrological system the result also suggests that noise reduced time series as inputs may enhance the overall performance of integrated hydrological models advances in computing resources data collection and processing have led to new developments coupling multivariable data with hybrid methods fotovatikhah et al 2018 these hybrid methods are becoming popular due to their improved accuracy compared to single models for example fotovatikhah et al 2018 shows that hybrid methods are superior to single methods in flood and debris flow forecasting considering all those facts and findings we expect that the hybrid method demonstrated in this study coupling ann and ekf can be effective and be validated in hydrological problems dealing with several time series such as rainfall runoff modeling wu and chau 2011 water quality management liu et al 2017 dendrohydrological modeling gholami et al 2015 local weather forecasting missing data estimation etc there are a number of assumptions that are related with ekf and the measured data in real world applications two situations may arise assumptions are satisfied or the assumptions are not fully valid violated in this study in all the cases ekf had either shown prediction improvement or had produced equally good predictions as when ekf was not applied this means the application of ekf is unlikely to deteriorate the predictions depending on whether or not the assumptions are satisfied or violated the nature of measurement noise in observed data is generally unknown and sometimes may be even impossible to determine however investigating the case studies where the measurement noise in data is considerably large can help identify cases where noise reduction can be useful when observed data is used for validation and model evaluation as this study did with real data noise reduction cannot be expected to have adverse effects on data worse than that resulting from any other data driven model the reason is the parameters of data driven models too are determined by evaluating the model s performance on observed data considering these and also the fact that the time delay coordinate method is now used in time series prediction irrespective of whether they being chaotic or stochastic we expect the proposed noise reduction procedures to be effective in a wide variety of problems dealing with time series data 6 conclusion since elshorbagy et al 2002 pointed out the drawbacks in the noise reduction approaches on chaotic hydrological time series published thus far only a few studies have appeared on noise reduction and they too have not cleared the doubts of the hydrology community on the effectiveness of nonlinear noise reduction this study investigated the possibilities of incorporating noise reduction to improve prediction accuracy especially in real time prediction by identifying and utilizing suitable noise reduction methods and approaches this study reveals a major misconception in past studies on noise reduction of noisy chaotic hydrological time series those studies expected that models trained with noise reduced data could provide improved predictions and as a result the investigations were mostly limited to off line noise reduction to the contrary of this general anticipation the findings of this study show that the prediction accuracy may not necessarily be enhanced with models trained with noise reduced data instead it has been shown that noise reduced data inputs can enhance prediction accuracy regardless of whether or not the model is trained with noise reduced data these findings in addition confirm the necessity for going beyond the conventional off line nonlinear noise reduction techniques to real time noise reduction methods this study showed that the real time nonlinear state estimation method the extended kaman filter from controls literature together with ann trained with noisy data as a state space model can be used as a reliable and robust technique for real time prediction improvement of noisy chaotic time series the study justified through simulations the use of imperfect models ann trained with noisy data in the state space model of ekf in addition the study demonstrated how ekf can be implemented for time delays different from one unit when time delay coordinate method for prediction was used the investigation was limited to one step prediction of five river flow series in additional to lorenz and mackey glass series the ekf produced significant prediction improvement as high as 15 40 over ann models in the noise added lorenz and the mackey glass time series prediction the effectiveness of ekf on noise levels ranging from mild 1 to very high 30 showed its robustness which is the most desirable factor in a noise reduction method only gaussian white noise was used in this study testing ekf for non gaussian and coloured noises and studying filters that are designed for non gaussian coloured noises will be useful when applied on river flow time series ekf showed prediction improvement on two discharge series of ciliwung river with low average flows mississippi and wabash river flow time series with large average flows did not show any prediction improvement the findings suggest that noise reduction can be effective where the measurement noise is considerably large compared to average observations identifying the hydrological data records that are more likely to contain large measurement errors will greatly help future investigations the study showed that the real effectiveness of noise reduction is not reflected on error measures with respect to noisy data of the same series thus finding better validation methods for evaluating noise removal is extremely important for the advancement of noise reduction in real data the study proposed a possible solution through an indirect validation method that can be used to verify the effectiveness of noise reduction in cases where several interrelated time series were available this was supported by the observed discharge time series of ciliwung river in jakarta indonesia therefore the real time noise reduction can be effective and be validated in hydrological problems dealing with time series of several interrelated variables of a system acknowledgements the first author wishes to thank the national university of singapore for awarding a research scholarship during which a part of this work was completed we would like to thank the anonymous reviewers for their useful comments which improved the quality of the manuscript us geological survey usgs data available free of charge were downloaded from http water usgs gov 
7038,the rincon valley in arid south central new mexico is especially impacted by reduced surface water supply because the contribution of groundwater is limited by aquifer constraints consecutive surface water allotment shortages in the elephant butte irrigation district ebid have reduced recharge the effects are compounded by farmers continuing to extract groundwater to meet crop requirements conjunctive use assumes aquifer resilience i e ability to absorb pumping stress but not necessarily in drought this study further develops the water table fluctuation method by analyzing data from the ebid s groundwater monitoring program to reveal conjunctive use controls over the spatial and interannual variability of net storage changes from 2009 to 2016 in the valley and introduces the term groundwater surface water ratio of application gsra that has potential for characterizing system resilience in conjunctive use settings regression modeling shows that variation in the annual ebid surface water allotment correlates strongly with year end water table elevations even more strongly than total annual groundwater extractions for irrigation suggesting that variable surface water allotments are a primary driver of this system dewatering of the aquifer as of 2011 significantly altered the system hydrology such that from 2011 to 2016 net change in storage correlates strongly with the annual surface water allotment corresponding to large river losses for the same period but resulting in net gains in storage from 2014 to 2016 rapid storage loss and rebound in this constrained aquifer system allowed quantification of aquifer resilience enabling the development of a gsra as a potential planning metric keywords groundwater drought conjunctive use irrigation resiliency 1 introduction interactions between groundwater and surface water are a critical consideration for integrated conjunctive river basin management hantush 1965 hunt 1999 turney 1999 woessner 2000 rushton 2002 simonds and sinclair 2002 sophocleous 2002 kollet et al 2003 mair and fares 2010 especially during periods of protracted drought tao et al 2011 water scarcity generally impacts water resources in most of the world but desert areas are more susceptible to drought de vries and simmers 2002 groundwater storage variability over time and space is critical to sustainable water resources richts et al 2011 and has become a focus in many parts of the world in recent years richey et al 2015a note that surface water is the principal freshwater supply appropriated to meet human water demand globally but the importance of groundwater is increasing as surface supplies become less reliable and predictable kundzewicz and döll 2009 groundwater is increasingly relied upon during times of drought as a presumed resilient alternative water source famiglietti 2014 however upon conducting a groundwater stress assessment to quantify the relationship between groundwater use and availability in the world s 37 largest aquifer systems richey et al 2015a report that estimates of groundwater stress based on withdrawal statistics are unable to capture the range of characteristic stress regimes which can be inferred as evidence that quantifying groundwater resilience remains a challenge groundwater resilience within the elephant butte irrigation district ebid in the arid lower rio grande basin of south central new mexico usa has become an issue of interstate concern farmers in the rincon valley fig 1 along the rio grande within the ebid are especially impacted by protracted drought because the unique geology of the area conover 1954 davie and spiegel 1967 king and hawley 1975 wilson et al 1981 hawley et al 2005 limits the use of groundwater for supplementation of limited surface water for irrigation an extensive clay aquitard underlies the shallow yet finite unconfined alluvium aquifer common to the rincon valley the aquifer lateral extents are narrowly bounded and lateral groundwater flow is insignificant compared to pumping and recharge flows while the hydrogeology of the rincon valley shallow aquifer is well documented and further acknowledged in this study no formalized research has been conducted to quantify the vulnerabilities of this system in response to protracted surface water shortage this study refers to conjunctive use as the supplementation augmentation or periodic substitution of variable surface water by pumping groundwater for irrigation in interrelated systems and contends that the rincon valley shallow aquifer like other aquifer systems in conjunctive use settings is subject to hydrologic metrics that may be expressed in terms of resilience resilience is often discussed in the context of climate change as the ability of a system to absorb disturbances while retaining the same basic structure and ways of functioning and the capacity to adapt to stress and change ipcc 2012 this study refers to groundwater resilience similarly as the capacity of the aquifer to absorb variable pumping stress while retaining the same basic functionality in the context of variable surface water availability and recharge in an interrelated system however this is not an expression of sustainability conjunctive use assumes aquifer resilience such that pumping stress is absorbed but not necessarily during drought at least not indefinitely if drought conditions are severe and persist long enough then all other things being equal i e groundwater extractions remain unabated and or in excess of recharge resilience limitations will eventually be reached and the system may no longer be sustainable regardless of the potential for resilience or how it is defined methods are lacking to assess the resilience of aquifer storage at a local level where management potential is perhaps greatest knowledge of the relative limits of stress that local aquifers may sustain is a critical management consideration and needs to be further evaluated richey et al 2015a b sheng 2013 offers a timely however broad account of the impacts of groundwater pumping and climate variability within the rio grande basin downstream of elephant butte dam and notes that the state of the science relative to water sustainability in this region has room for improvement integrated numeric modeling efforts that are specific to the lower rio grande of new mexico have endeavored to predict the interactions between surface water and groundwater in this area although the earlier works were much more concerned with the immediate downstream mesilla valley which is a much larger and deeper system relative to the rincon valley some of these earlier works include frenzel and kaehler 1992 hamilton and maddock 1993 and lang 1995 later works that are inclusive of the rincon valley include weedon and maddock 1999 papadopulus and associates 2007 schmid and hanson 2009 hanson et al 2010 usbr 2015 and knight 2015 still questions concerning groundwater resilience in this area persist particularly as conditions favoring a reduced surface water supply in the rio grande basin are predicted to intensify usbr 2011 it is important to examine groundwater storage changes over time and to consider multiple methods for doing so an ongoing study that is not specific to the lower rio grande or the rincon valley yet but that has bearing on the nature of the work presented here is documented by rinehart et al 2015 in which the goal using geostatistical methods was to provide groundwater storage change estimates in alluvial basins throughout new mexico prior studies of regional aquifer storage include the work of mcguire 2013 in the southern high plains which was similar in some respects to the work that is presented here as far as making use of groundwater elevation data to estimate storage other studies such as kumar 2007 ahmadi and sedghamiz 2008 and chung and rogers 2012 have compared different types of kriging interpolations to estimate storage another approach originally introduced by montgomery 1971 but receiving renewed interest e g gehman et al 2009 is the use of temporal gravity surveys in which measurements of changes in gravity over time can be used to estimate variations in groundwater mass associated with a rise or fall in the water table fundamentally studies of this nature are varied conceptualizations of the water table fluctuation wtf method which depending on the fluid flow complexity is a simple and effective approach widely used to determine groundwater recharge healy and cook 2002 crosbie et al 2005 delin et al 2007 healy and scanlon 2010 for example wang et al 2014 used the wtf method to effectively estimate the spatiotemporal variability of groundwater recharge for the largest rice production region in northeast china the wtf method is simple and easy to apply because it requires information regarding only the water table and specific yield of an aquifer however extension of the wtf method over space and time to examine changes in groundwater storage rather than just recharge may offer a relatively easy effective way to evaluate conjunctive use and the impacts of drought on water resources management due to its relative simplicity and constrained groundwater flow system the rincon valley in southern new mexico is well suited to advance the wtf method for groundwater storage measurements and to serve as an example of quantifying groundwater resilience the purpose of this study is to further develop the wtf method to evaluate groundwater resilience by analyzing data from the ebid s groundwater monitoring program to determine the spatial and interannual variability of net storage changes from 2009 to 2016 in the rincon valley shallow alluvium aquifer this study explores these results as an indicator of aquifer resilience and river performance i e net river loss or gain in the context of hydrologic drought later defined and conjunctive use of water for irrigation and offers a new term the groundwater surface water ratio of application later defined this study also examines controls and indicators of resilience by relating net storage and average water table elevation changes with the annual pro rata ebid surface water allotment and total annual metered extractions of groundwater for irrigation 2 materials and methods 2 1 study area the annual surface water supply provided by storage in elephant butte and caballo reservoirs located in the upstream extent of the lower rio grande basin in southern new mexico a primary feature of the u s bureau of reclamation rio grande project has been reduced substantially due to ongoing regional drought elephant butte reservoir is the primary means of storage servicing the rio grande project which is concerned with the irrigation of lands in southern new mexico ebid inclusive of the mesilla and rincon valleys and lands in west texas el paso county water improvement district no 1 it is also an important means of meeting downstream delivery obligations by the u s to mexico as per a 1906 international treaty caballo reservoir located immediately downstream of elephant butte on the rio grande serves principally as a regulating feature for rio grande project seasonal releases in a full supply year irrigation releases from storage for all rio grande project contract beneficiaries begin in march and end in september for a total volume of about 790 000 acre feet 974 4 m cubic meters inclusive of a full pro rata ebid surface water allotment of 3 024 acre feet 36 288 acre inches per irrigated acre 9217 cubic meters per hectare for lands assessed to receive surface water within the ebid a total of 90 640 acres 36 681 ha are assessed to receive surface water throughout the ebid the rincon valley contains about 28 064 acres 11 357 ha of which 18 651 acres 7547 ha are assessed to receive surface water ebid 2016 but on average only about 17 000 acres 6880 ha in the rincon valley are irrigated annually almost all about 95 of these lands are irrigated with a combination of surface water delivered through the ebid on a pro rata basis and groundwater pumped in varying amounts from individual farmer owned wells the rincon valley fig 1 comprises the northern extent of the ebid floodplain elevation above mean sea level at the northern end by caballo dam is about 4160 feet 1268 m and 4100 feet 1250 m at the lower end of the valley which is about 32 miles 51 5 km long the width of the valley floor is constrained from one to two miles 1 6 3 2 km in a classic basin and range province that is characterized by rugged mountain ranges and gently sloping chihuahuan desert plains divided by the riparian corridor of the rio grande the basin is bounded by near vertical faults associated with mountain ranges that are generally aligned in a north south direction with the caballo and doña ana mountains bounding the rincon valley to the east and the black range and sierra de las uvas mountains to the west records from a weather station located at new mexico state university show the average annual precipitation from 1976 to present to be 9 28 in 236 mm 54 of which falls during the summer monsoon months of july september wrcc 2015 using classic methodology described by blaney and criddle 1962 gabin and lesperance 1977 report that peak potential evapotranspiration using alfalfa as a reference crop in the area occurs during july wherein a monthly total of 9 25 in 234 95 mm of water is estimated to be evapotranspired on average and that total annual potential evapotranspiration in the area is estimated to be 49 82 in 1265 43 mm on average local precipitation has traditionally been considered a very small part essentially negligible of the irrigation water budget in this area but this certainly may not be the case in other study areas ebid pro rata surface water allotments for the last eight years table 1 have averaged only 12 9 acre inches per acre 3270 cubic meters per hectare per year about 36 percent of a full allotment climate forecasts concerned with the regional rio grande basin inclusive of watersheds in southern colorado and northern new mexico headwaters of the rio grande suggest that an average of this nature may be more common than not for years to come usbr 2011 rather than focusing on drought as localized above average aridity reflecting local weather variation this study defines hydrologic drought as a circumstance where protracted regional drought impacting upstream upland watersheds leads to a persistent reduction in the volume of surface water in local reservoir storage and therefore consecutive annual shortages of surface water available for local release for the purposes of this study an ebid pro rata surface water allotment that is less than 66 7 percent of a full allotment less than 2 0 acre feet per acre 6096 cubic meters per hectare is considered to reflect significant hydrologic drought conditions very few domestic wells or other municipal and industrial wells exist in the rincon valley the village of hatch the largest urban area in the rincon valley is the primary provider of water for drinking and sanitary purposes and imports potable water via pipeline from an alternative groundwater source known as the nutt hockett basin this groundwater source is located about 12 miles 19 3 km to the southwest of hatch and is hydraulically independent of the rincon valley irrigated agriculture is by far the dominant use of water including extraction of groundwater with or without hydrologic drought conditions in the rincon valley irrigation is predominantly by surface flood application to farmlands that in most cases are regularly laser leveled but does include shallow subsurface drip tape use combined with traditional flood practices in many instances the rincon valley is world renown for the famous hatch brand chile in 2014 new mexico ranked first in the u s for total acreage planted in chile california was second and ranked second just behind california for total onion production nmda 1998 hatch brand chile and other vegetable production particularly onions is a significant component of the local economy hall and skaggs 2003 irrigated agriculture is by far the foremost form of industry and source of income and tax revenue in the rincon valley 2 2 groundwater surface water ratio of application this study introduces a new term the groundwater surface water conjunctive use ratio of application gsra defined as the total volume of groundwater extracted and applied for irrigation per unit time divided by the total volume of surface water diverted and applied for irrigation per unit time within a common river basin and hydraulically interrelated aquifer system the term is specific to water resource settings that are or should be conjunctively used and managed the significance of the gsra as a metric of aquifer resilience is that over time even in the absence of more detailed information specific to net depletion i e evapotranspiration that is typically much more difficult to accurately assess howes et al 2014 the gsra can serve as an indicator of aquifer stress relative to surface water availability and potential recharge the gsra can therefore also serve as a metric for determining steady state conditions i e a circumstance where net change in aquifer storage equals zero other terms have been suggested to characterize aquifer stress but are more concerned with generalized estimates of aquifer longevity in the context of sustainability and not necessarily resilience richey et al 2015a offer the idea of a total groundwater stress ratio defined as the ratio of total storage to the groundwater depletion rate to estimate timescales to depletion by accounting for the buffer capacity of aquifer storage they found that the current state of knowledge of large scale groundwater storage has uncertainty ranges across orders of magnitude that severely limit the characterization of resilience at least in the numerous large regional aquifers they studied around the world this study suggests that the gsra as a metric for groundwater resilience is a potentially practical useful approach for localized management in conjunctive use settings where groundwater storage tends to remain in flux anyway and that a focus on total storage may have limited utility in most irrigation projects since total storage and economically recoverable storage are typically very different things 2 3 hydrogeology the surface waters of the rio grande and the groundwater of the shallow alluvium aquifer of the rincon valley are a highly connected essentially singular resource conover 1954 wilson et al 1981 frenzel and kaehler 1992 winter et al 1998 turney 1999 hawley and kennedy 2004 and others among the most complete hydrogeologic descriptions of the rincon valley and surrounding region is offered by hawley et al 2005 noting that the rio grande is the only significant surface water resource in the region and therefore the main source of recharge conover 1954 king et al 1971 and wilson et al 1981 report that the shallow alluvial deposits associated with the river in the inner valley in this area serve as the ultimate discharge zone for pre development groundwater flow from adjacent basins and uplands hawley et al 2005 stress that the essential hydrogeologic characteristic of the rincon valley in terms of groundwater resources is the absence of any significant basin fill aquifer unit beneath the shallow alluvial fill of the inner valley test drilling of several exploratory wells in the area the deepest to about 2000 feet 610 m document the presence of a very thick estimated about 2500 feet 762 m sequence of fine grained basin floor sediments clays deriving from a prehistoric playa lake below the inner valley fill king et al 1971 wilson et al 1981 with virtually no potential for freshwater production due to very low hydraulic conductivity the upper elevation of this sequence reflects the lower extent of the productive aquifer and lateral extents providing a width of no more than one to two miles 1 6 3 2 km are evidenced by steep vertical faults essentially no aquifer exists in the rincon valley except the shallow alluvium which on average is only about 80 feet 24 m deep and renders a useable average of only about 55 feet 17 m of saturated thickness wilson et al 1981 within the modern floodplain of the rincon valley a 30 40 foot 9 12 m thick gravel layer occupies the lower part of the alluvium and is overlain by thin lenses and layers of sand gravel and clay but is otherwise considered to be mostly homogenous aquifer material wilson et al 1981 with transmissivity averaging about 17 100 feet squared per day 1588 m2 day static depth to water in the valley floodplain alluvium is normally following initial development early 1950s through 1970s from 8 to 15 feet 2 5 m below land surface the north to south flow of groundwater in the rincon valley is at about the same slope as the ground surface about 5 feet per mile 1 m per kilometer wilson et al 1981 further describe the groundwater resources of the rincon valley as a long narrow continuous aquifer comprised of quaternary gravel sand and clay deposits which is entrenched in the red clay of the santa fe group lacustrine facies 2 4 net change in groundwater table elevation within the rincon valley the ebid maintains a network of thirteen 13 instrumented shallow monitoring wells dedicated to tracking shallow groundwater levels in the area relative to the rincon valley spatial extent of about 28 064 acres 11 357 ha the locations of ebid s monitoring wells are described in table 2 and are situated to approximate uniform coverage of the rincon valley each monitoring well features a 2 0 inch 5 1 cm casing and is completed to a total depth of approximately 25 feet 8 m below the soil water interface about 40 feet 12 m below ground surface the bottom 20 feet 6 m of each well is screened and beyond that a blank sump of about 10 feet 3 m occupies the very bottom of each well to accommodate eventual sediment accumulation the screened interval of each well is within about the middle of the average saturated thickness of the aquifer all sites were surveyed to establish appropriate benchmark elevations since 2009 groundwater table elevations measured as a function of pressure head with submersible pressure transducers instrumentation northwest inc model pt2x purchased and installed by the ebid very near within 6 0 in 15 24 cm the bottom of the screen of each of the new monitoring wells have been recorded continuously every thirty 30 minutes and temporarily stored in data loggers campbell scientific inc model cr10x at each site powered with solar and battery backup for monthly data retrieval these sensors were configured with a gauge option to include venting technology to compensate for variable barometric pressure effects precision of 0 05 ebid recently mid 2015 replaced these instruments with simpler more reliable pneumatic bubbler sensors control design inc model cd103 precision of 0 05 paired with remote telemetry units control design inc model cd110 to achieve essentially real time data acquisition the change in instrumentation did not produce any discernible shift in measurement data particularly since in season while irrigation well pumping is underway fluctuations in the local water table are typically several orders of magnitude greater than the measurement error of the instrumentation before and after the change in instrumentation this type of groundwater monitoring program to measure real time fluctuations in the water table is useful for many reasons however this study is concerned with year end interannual december 31 to december 31 groundwater table elevation changes at each monitoring site in the rincon valley at year end groundwater table elevations at and between monitoring wells are subject to minimal influence by nearby irrigation production wells fluctuating cones of depression since very little or no irrigation is expected to be underway or to have occurred for about a month prior the potential for the static elevation of the groundwater table at each monitoring well location to have reached a point of new relative equilibrium will have reached a maximum at this time i e after harvest there is typically more uncertainty in groundwater pumping conditions at the early part of the growing season before the start of the next surface water release beginning mid late april to as late as june 1 in recent years of reduced surface water supply in this study the average december 31 groundwater table elevation at all sites at each year end was compared to total annual groundwater extraction from all metered irrigation production wells nmose 2017 in the rincon valley that are used in conjunction with the total annual ebid pro rata surface water allotment and comparison was also made to the calculated annual net river loss or gain 2 5 net change in groundwater storage a spatial modeling approach utilizing analytical tools available in a geographic information system arcgis v 10 2 environmental systems research institute framework adapted to the rincon valley was used to show where and to what extent year end groundwater table elevation changes and net groundwater storage changes have occurred in recent years it is assumed that each monitoring well location and the year end groundwater elevation data associated with each monitoring well contributes equally to characterizing the collective response of the shallow alluvium aquifer to pumping stress and or recharge healy and cook 2002 report that a basic assumption inherent in the wtf method and critical to its successful application is that specific yield is known and constant over the time period of the wtfs however variation in aquifer properties is generally area and depth dependent the guidance offered by yeh et al 2015 clarifies that the challenges posed by aquifer heterogeneity are opportunities for stochastic approaches to characterizing aquifer properties such as the use of hydraulic tomography nevertheless spatial differences in specific yield and or storage coefficients within the same stratigraphic layer of interest are generally not differentiated between individual cells within a typical groundwater flow model discretization grid in the case of the rincon valley the stratigraphic layer of interest is physically limited to the shallow alluvium because the unconfined shallow alluvium aquifer in the rincon valley is finite and laterally bounded and reported to be largely homogenous wilson et al 1981 this study likewise assumes that specific yield is spatially uniform for this study an average specific yield sy of 0 2 was distributed throughout the shallow alluvium aquifer conover 1954 richardson et al 1972 lizarraga 1978 and wilson et al 1981 each independently reported a sy of at least 20 percent for the shallow alluvium within the lower rio grande basin several previous modeling efforts in the lower rio grande including frenzel and kaehler 1992 hamilton and maddock 1993 lang 1995 weedon and maddock 1999 and papadopulus and associates 2007 each assigned a value of 0 2 for sy to the uppermost model layer reflecting the shallow alluvium aquifer and each assumed that sy is uniform across the uppermost model layer sy is an important aquifer property particularly for purposes of this study concerned with change in aquifer storage this is evident in the following relationship noted by fetter 2001 1 v w s a δ h where vw is the volume of water acre feet or m3 drained from a portion of the aquifer s is the storativity or sy in an unconfined aquifer dimensionless a is the surface area overlying the drained portion of the aquifer acres or hectares and δ h is the change in groundwater elevation or hydraulic head ft or m in the context of aquifer resilience sy is especially important as the volume of water in the aquifer relative to the aquifer volume and if land subsidence is prevalent and collapse of aquifer material pore structure occurs reductions in sy can be expected which limits the capacity of the aquifer to rebound to the extent that δ h is found to be changing over time relative to some baseline elevation then vw can also express the volume of water gained by a portion of the aquifer and therefore relates to recharge and the fundamental premise of the wtf method the basic assumption of the wtf method is that the rise of groundwater level in unconfined aquifers is caused by the response to the infiltration of water rainfall irrigation etc arriving at the groundwater table recharge recharge rate r l time can therefore be quantified as follows healy and cook 2002 2 r s y δ h δ t where δ t is the time of recharge period the flux therefore is reflected by change in aquifer storage which may also be expressed as a volumetric discharge or water use rate by applying eq 2 over the aquifer area this allows the wtf method to account for changes in groundwater storage associated with water use to the extent that pumping stress on the aquifer over time exceeds recharge over time then dewatering of the aquifer occurs and storage is necessarily reduced the inverse is also plausible in which case the aquifer storage would be in a gaining state aquifer storage as with streams can be gaining under recharge conditions and losing under discharge conditions this dynamic can be convoluted in conjunctive use settings because r may reflect either river infiltration recharge flux or groundwater pumping discharge flux and both may be occurring prior wtf applications for characterization of natural recharge through groundwater elevation measurement are extended here to an irrigated agriculture managed aquifer river system where groundwater storage relates directly to conjunctive water use rates summation of volume change at each year end from each monitoring well and associated area in the rincon valley are reported as the calculated net change in storage from the shallow alluvium aquifer for each year and are also reported at each monitoring site relative to december 31 2009 groundwater table conditions in the rincon valley total annual net change in aquifer storage is then compared to the total annual ebid pro rata surface water allotment and total annual groundwater extraction quantification of these relationships in the context of groundwater resilience and conjunctive use are feasible because groundwater extractions combined with the use of available surface water for irrigation are in this study area the predominant variables influencing change in aquifer storage accordingly this study refers to the groundwater surface water conjunctive use ratio of application gsra dimensionless defined previously gsra extends from eq 2 to address the convolution of recharge and discharge associated with conjunctive use as gsra can be considered the ratio of groundwater pumping discharge flux to river infiltration recharge flux or groundwater use to surface water availability and use this study postulates that if the gsra consistently exceeds 1 0 then it is expected that the aquifer s capacity to buffer pumping stress relative to a variable recharge flux volume will eventually be reduced this is not to suggest that the gsra cannot average somewhat greater than 1 0 over time and the resilience of the aquifer still be preserved it is reasonable to expect that an average threshold or range for gsra exists within which groundwater resilience in conjunctive use settings can be maintained such that net change in aquifer storage over time is ultimately equal or close to zero determination of a threshold gsra such that net change in aquifer storage is equal to zero is expected to represent steady state conditions but may not necessarily reveal a managerial target or definitive metric of aquifer resilience this study furthers the wtf method by extending eq 2 building on the work of healy and cook 2002 to quantify interannual groundwater storage vw change over the aquifer area individual area values a that could be attributed to groundwater monitoring wells throughout the rincon valley were discretized with thiessen polygons thiessen 1911 utilizing arcgis spatial analysis software the thiessen method uses a weighing factor for each sampling point to adjust for non uniform sampling point distribution the weighing factor is based on the size of the area within the area of interest the thiessen method was chosen for this study because of its relative simplicity and potential for adaptation elsewhere an imperfect distribution of monitoring wells the narrow physiological features of the rincon valley itself and the resultant irregular geometry and corresponding areas of the polygons produced by the thiessen method in this case is somewhat coarse table 2 this is shown in fig 2 which is a discretization map of the rincon valley as bounded by the lateral extents of the aquifer and includes the names and locations of the several small communities in the valley other spatial analysis methods such as kriging or inverse distance weighting whereby the field is discretized on the basis of pixels or groups of pixels among other could very well be adapted to the purposes of this work although not presented here this study found that kriging methods provided no significant difference from or apparent benefit over the simpler thiessen approach chosen for this study at least with the available data 2 6 river performance gains or losses in river discharge can result from seepage in the streambed or from bank storage evaporation from the water surface and transpiration by vegetation along the river banks discharge in the ebid reach of the rio grande is controlled almost exclusively by irrigation releases from caballo dam crilley et al 2013 in this study it is affirmed that seepage in the streambed is also controlled by the static average year end groundwater table elevation the mass balance equation used for calculating net annual river seepage gain or loss in the rincon valley subreach of the rio grande is as follows simonds and sinclair 2002 q s q ds q us q in q out where qs is the net seepage gain or loss for the subreach acre feet or m3 qds is the discharge measured at the downstream end of the subreach acre feet or m3 qus is the discharge measured at the upstream end of the subreach acre feet or m3 qin is the sum of inflows acre feet or m3 and qout is the sum of outflows acre feet or m3 data were obtained from ebid river gauges at strategic locations along the rio grande within the ebid qds and qus including metered diversion dams for purposes of delivering surface water to ebid farmers qout further the ebid has developed and is continuing to expand a network of weather stations and rain gauges within the immediate area watershed to anticipate flood events but also to serve a storm water capture program qin the data available from ebid s storm water capture program were used for qin however evapotranspiration et was not separately estimated in this study the result is the calculated net annual flux of water gained or lost from the streambed for this reach of the rio grande which is compared to the average annual year end groundwater table elevation in the rincon valley 3 results and discussion 3 1 groundwater elevation and net storage changes table 3 provides a summary of the average annual year end groundwater elevation change taken from year end groundwater elevation measurements at all ebid monitoring wells in the rincon valley and the corresponding calculated net change in aquifer storage totalized for each year during the study period results indicate that the groundwater table elevation in the rincon valley declined an average of 2 3 feet 0 7 m over the course of the study period this translated to an average 4 2 loss of the average saturated thickness of the aquifer relative to about 55 feet 17 m reported by wilson et al 1981 as the average useable thickness between 2014 and 2016 gains in storage were calculated and are an indication of aquifer resilience on the basis that a period of reduced aquifer stress and increased recharge demonstrates that the aquifer can and does remain functional with potential to rebound if conditions conducive to recovery are present this also suggests that change in storage is a function of supply and demand as assumed feasible for conjunctive use which this study suggests is reflected by the gsra nevertheless major losses occurring in 2011 and 2013 had created a dominant deficit effect such that at the end of the study period a cumulative storage loss of 12 524 acre feet 15 448 k m3 was sustained as long as a storage void persists in the aquifer the potential for continued gains will persist fig 3 contains data for the average year end groundwater table elevation and the total annual ebid pro rata surface water allotment delivered to lands in the rincon valley for each year during this study included also is the 2016 surveyed ibwc 2017 average riverbed elevation in the rincon valley assuming that the 2016 average riverbed elevation is representative of the average riverbed elevation for the study period it is revealed that after 2010 the average year end groundwater table elevation had receded well below the base of the riverbed this condition following 2010 will have certainly increased the rate of recharge of available surface water to the aquifer however limited in recharge volume by substantially reduced surface water allotments after 2010 the trend in fig 3 indicates that increases in surface water allotment increase groundwater storage due to recharge along the river and decreases in groundwater pumping when surface water is available this trend reveals the dependence of resilience of aquifer storage on recharge from surface water and shows that the average year end groundwater table elevation correlates well r2 0 83 within a reasonable confidence interval 0 654 r2 1 00 at 95 with the total annual ebid surface water allotment while the surface water allotments in 2009 and 2010 were much greater than subsequent years during the study period the p value calculated in this instance 0 0017 is much lower than 0 05 demonstrating that the effects of substantially reduced surface water allotments in years after 2009 and 2010 are in statistical keeping with the trend on average over the aquifer fig 3 shows a consistent trend additionally the gsra is intended to represent conjunctive use from year to year regardless of spatial or temporal uniformity within a given irrigation season fig 4 presents total annual metered groundwater extractions for irrigation of lands in the rincon valley that are also irrigated with surface water relative to the total annual ebid pro rata surface water allotments delivered in the rincon valley during this study the data indicate that groundwater pumping has been inversely related to surface water use and availability this trend demonstrates the conjunctive use of this system proving that groundwater pumping for irrigation in the rincon valley is essentially a substitute for and strongly correlated with r2 0 87 hydrologic drought impacts on the ebid surface water allotment the calculated p value 0 000747 and confidence interval 0 732 r2 1 00 at 95 found in this instance tends to substantiate the significance of this relationship 2009 and 2010 reflect years when the ebid surface water allotment was much closer to full however subsequent years were dominated by hydrologic drought and elevated pumping levels particularly in 2011 and 2013 even so a variable rate of substitution of groundwater extraction for surface water is apparent on average over the aquifer fig 4 shows a consistent trend and the gsra is intended to represent conjunctive use on an annual basis regardless of spatial or temporal uniformity of applied water for irrigation in a given year fig 5 presents the relationship between the average year end groundwater table elevation and total annual metered groundwater extractions for irrigation and indicates that in season groundwater pumping is as expected well correlated r2 0 80 with the average year end groundwater table elevation increases in groundwater extraction directly result in decreases in groundwater storage within the aquifer the p value 0 002539 and confidence interval 0 608 r2 1 00 at 95 calculated with this relationship is acceptable in comparison fig 3 reveals that the relationship with the ebid surface water allotment is slightly stronger r2 0 83 with slightly more convincing background statistics however the explanatory variables x axis in either case are themselves highly correlated figs 3 and 5 indicate the two primary controls over changes in aquifer storage are the groundwater and surface water use in this conjunctive use managed aquifer fig 5 also shows that aquifer storage resilience is certainly influenced by and may eventually be threatened by groundwater extraction surface water allotments may be considered the driving variable in this system because variable groundwater extraction is largely in response to variable surface water allotments and because surface water allotments are the primary source of aquifer recharge table 4 provides results for the individual thiessen polygon net changes in aquifer storage calculated at each monitoring site during this study notably in 2011 sites rin 2r rin 9r and rin 10r to the north in general experienced substantially greater loss from storage than any other site at any other time during the study period assuming a spatially uniform specific yield the standard deviation across these three regions is about three times greater in 2011 than in other years suggesting that pumping tended to be spatially concentrated in 2011 and in 2013 which reflect years of significant surface water shortage and greatest groundwater extractions fig 4 fig 6 presents net change in aquifer storage in the rincon valley relative to december 31 2009 groundwater table conditions and relative to the total annual ebid surface water allotment for the period of 2011 2016 linear trend and 2009 2016 non linear trend after 2010 a void in aquifer storage had been created as result of reduced recharge and increased groundwater extraction decrease in groundwater storage during 2011 and 2013 and this void in storage allowed for the potential for gains in groundwater storage that were realized particularly in 2014 2015 and 2016 the period of 2009 to 2016 reflects a circumstance where and when the aquifer s buffering capacity or near term resilience to mitigate pumping stress is accounted for in the context of conditions in 2009 and 2010 when the aquifer was at or very near storage capacity because of large net annual gains in the river were calculated for 2009 and 2010 discussed later a non linear trend was evident for the period 2009 2016 and the correlation coefficient is low r2 0 39 apparently because significantly different aquifer conditions are represented in the same plot eventually when if the aquifer returns to a fully recharged state such as conditions observed in 2009 then a non linear trend is expected to best represent net change in aquifer storage relative to surface water allotments the period from 2011 to 2016 was found to approximate linear behavior r2 0 83 suggesting that the hydrology of this system was at that time as of the end of 2011 substantially altered these results suggest that as of the end of 2011 stress on the aquifer from groundwater extraction combined with reduced recharge from surface water shortage may have led to the aquifer being disconnected from the river to one degree or another brunner et al 2009 report that if the groundwater table below a stream is sufficiently deep relative to streambed elevation changes in the groundwater table position do not alter the infiltration rate which is defined as a disconnected system as noted above the riverbed elevation in fig 5 indicates the river was a gaining stream in 2009 and 2010 the river was a losing stream during all other years and the river may have become disconnected while it was a losing stream following full or closer to full consecutive annual ebid surface water allotments the aquifer is expected to rebound and the system would be expected to return to a connected status the resilience of the aquifer therefore changes over time in response to changing surface water allotments and the frequency and duration of hydrologic drought particularly if groundwater extractions for irrigation remain dependent on available surface water in this way the resilience of the aquifer is dependent on the gsra 3 2 groundwater surface water ratio of application the calculated annual gsra for the study period is reported in table 5 and includes total annual metered groundwater pumping from all irrigation wells in the rincon valley that are conjunctively used with surface water actual farm deliveries of surface water in the rincon valley table 1 were used in these computations as expected in keeping with fig 4 2011 and 2013 are years when groundwater extractions were highest combined with particularly low ebid surface water allotments and therefore the highest calculated gsras were observed substantially more groundwater was pumped than surface water was available to irrigate with the computed standard deviation over time 5 69 was about 92 of the mean 6 21 gsra during the study period indicating substantial variation in the annual proportion of groundwater and surface water used to irrigate however the gsra of 2 54 at the end of the study period 2016 having dropped from a high of 17 76 found for 2013 implies that conjunctive use of water for irrigation in the rincon valley may be fluctuating within a reasonable range of system resilience and range of gsra values even though ebid surface water allotments for the last six years majority of this study remained well below half of a full allotment this may point to adaptation of the rincon valley farming community to hydrologic drought fig 7 is a plot of the gsra relative to net change a and cumulative change b in aquifer storage where groundwater table conditions as of december 31 2009 are taken to be a baseline for purposes of this study fig 7a compares gsra values with single year storage changes and suggests that as the gsra increases beyond about 4 63 then net loss from aquifer storage is predicted r2 0 58 with increasing groundwater storage loss as the gsra increases as of 2011 a void in aquifer storage had been created therefore the potential for gains in storage had been established relative to the minor changes in storage calculated in 2009 and 2010 when the aquifer was at capacity 2009 or near capacity 2010 the correlation coefficient in this instance is low and the confidence interval 0 222 r2 0 936 at 95 and p value 0 0283 indicates that this relationship is marginal regardless the gsra broadly captures the groundwater storage change impacts attributed to use of surface and groundwater for irrigation in the rincon valley within a given year and the effects of this water use non uniformity within a given year and from year to year are insignificant compared to impacts on net change in aquifer storage a threshold value or range of gsra values specific to a given surface groundwater system may have utility as a guide to aquifer resilience over time particularly in this system where groundwater extractions tend to be a substitute for limited surface water availability fig 7b presents data and a regression for cumulative net change in aquifer storage as a function of the gsra and reports a non linear relationship such that a gsra found to be 4 63 value for zero net change in storage from fig 7a over time is predicted r2 0 78 to produce a cumulative loss from aquifer storage of about 16 870 acre feet 20 808 k m3 the mean gsra found during the study period 6 21 table 5 is predicted to result in a cumulative net loss from storage of about 19 360 acre feet 23 880 k m3 the actual cumulative net loss from storage calculated for the study period was 12 524 acre feet 15 448 k m3 which fig 7b predicts would be met with a gsra averaging about 2 77 this discrepancy is most likely a reflection of the relatively small dataset limited number of years of available reliable data used in this study uncertainty in the data and regression and the nonlinearity of the trend interestingly however the gsra found for 2012 4 67 table 5 represents a time of the least amount of net change in storage during the study period table 3 and is very close to the threshold gsra of 4 63 required for a change in storage of zero fig 7a the implication of this as applied to fig 7b is that a cumulative net loss from storage at least as large as that calculated through 2012 can be sustained and if net change in storage is thereafter stabilized further losses are minimal then the aquifer will adjust to a new equilibrium the existence of a dynamic equilibrium is in keeping with dynamic recharge flux fluctuations in the proportions of surface and groundwater used to irrigate conjunctive use and therefore the gsra these results are indications that over time management intervention and or incentive to reduce the average gsra perhaps to approximate 1 0 if even temporarily in response to protracted hydrologic drought could eventually be fundamental to system resilience in this way the gsra analysis presented herein can help to inform groundwater resilience 3 3 river performance fig 8 contains data for net annual river loss or gain for the rincon valley reach of the rio grande relative to the average annual year end groundwater table elevation measured at all ebid monitoring sites in the rincon valley during this study fig 8 also identifies the average riverbed elevation as surveyed at the center of the rio grande along the rincon valley reach of the river during the winter when the riverbed was dry of 2016 ibwc 2017 negative change in river volume i e river loss is in part transmitted as recharge to increase groundwater storage positive change in river volume i e river gain and is generally due to discharge from groundwater storage the observed transition shown in fig 8 of the rio grande from a gaining stream to a losing stream is consistent with the previous discussions from figs 3 and 5 as evidenced by the linearity in groundwater elevation response following the transition from a gaining river condition to losing the groundwater system equilibrates within each year due to the constrained aquifer geometry in this case this aids in the evaluation of groundwater resilience and system response to changes in stress through changes in surface and groundwater use from 2011 to 2016 the average year end water table elevation had receded well below the base of the riverbed reaching a low of 4042 9 feet 1232 3 m above mean sea level suggesting that the aquifer may have been in some places disconnected brunner et al 2009 from the river during this period in terms of annual river losses documented for most of the study period 2011 2016 compared with much larger annual groundwater extractions for irrigation relative to groundwater elevations fig 5 for the same period annual groundwater extractions can and at times do occur in volumes well in excess of potential annual recharge from the river this highlights the importance of the alluvium aquifer of the rincon valley as a resource for buffering hydrologic drought the feasibility of conjunctive use in this system and the potential for limits to aquifer resilience dewatering of the aquifer as of 2011 introduced stress to the system such that from 2011 to 2016 net change in storage fig 6 correlates strongly with the annual surface water allotment suggesting that the recharge rate from the river may have reached a maximum during this time the annual gains in storage from 2014 to 2016 are attributed to recharge in keeping with the annual ebid surface water allotment however relatively small the allotments were during this time the size of the allotments is relevant because to the extent that more surface water is available to irrigate with and for a longer duration during the irrigation season then less groundwater is pumped resulting in less stress on the aquifer the annual gains in storage from 2014 to 2016 can most likely be attributed to the lowering gsra values observed during this time period this further affirms the dependence of the alluvium aquifer storage in the rincon valley on the annual ebid surface water allotment and management of water use to maintain low grsa values the rincon valley alluvium aquifer demonstrates losses in response to pumping stress rapidly due to the constrained geometry and hydraulic properties of the aquifer but it is also quick to demonstrate gains in response to recharge which is a measure of a resilient system with a correlation of almost 70 r2 0 68 fig 8 suggests that the net annual flux of water gained or lost from the streambed for this reach of the rio grande may be stabilized i e zero change in river storage when the average year end groundwater table elevation is maintained at least at 4046 3 feet 1233 3 m above mean sea level navd 88 it is important to note that this is a volatile number and depends on a number of external fluxes themselves volatile influencing the system and therefore does not represent a particular managerial target rather these results suggest that there are a range of average year end groundwater table elevations relative to the average riverbed elevation that may help to inform where and when net annual loss from the streambed approaches a maximum recharge rate this has implications for groundwater resilience and also operational efficiency of the river itself 3 4 management implications relative to net change in aquifer storage as shown in fig 6 with a correlation of just over 80 r2 0 83 while dominated by hydrologic drought 2011 2016 during this study a minimum consecutive total annual ebid pro rata surface water allotment applied in the rincon valley of about 12 467 acre feet 15 378 k m3 was calculated as necessary to stabilize the system at least relative to conditions observed from 2011 to 2016 this is only about 0 75 ac ft per acre 2 29 m3 hectare about 25 of a full allotment and is not suggested to represent a long term minimum surface water allotment necessary to maintain system resilience let alone sufficient for the farming community in the rincon valley to remain viable graphically it is apparent from fig 6 that relatively little net change in storage occurred in 2012 or 2014 table 4 which in terms of negligible net storage change is comparable to 2009 and 2010 a time when the aquifer was at or near storage capacity yet the end of 2014 reflects a time when cumulative loss from storage fig 7b was by far the greatest during the study period and actually the greatest for many years decades prior since the early mid 1950 s the obvious cause of this was remarkably low surface water allotments in 2011 and 2013 combined with expansive groundwater extractions in response had rio grande project operations and or upstream conditions been able to adjust to deliver 25 of a full surface water allotment to the ebid in 2011 and 2013 rather than the 11 1 and 9 7 respectively table 1 then aquifer storage changes in the rincon valley during this study would have most likely been different less management goals that target the optimal use of available surface water to facilitate aquifer recharge and that simultaneously or at strategically planned times reduce the stress of groundwater extractions in this system should be explored an unexhaustive account of options include optimization analysis to quantify the potential for less on farm groundwater extraction through increased on farm surface water delivery efficiency by strategic synthetic lining and or piping of select otherwise unlined earthen canals and laterals this should be approached cautiously and with attention to not compromising recharge potential with efforts to modernize conveyance infrastructure it is realized that the existing unlined earthen canals and laterals do serve in part as a vehicle for aquifer recharge while surface water deliveries are underway however the river itself and subsequent on farm flood application of surface water for irrigation may be the predominant source of recharge in this system to the extent that enhanced more efficient conveyance of available surface water for irrigation may reduce groundwater extractions in otherwise problem areas to meet crop requirements then less stress on the aquifer is expected and should be explored sediment removal and channel maintenance may be used to avoid decreases in recharge associated with lower hydraulic conductivity sedimentation further effort could be undertaken to capture and quantify incidental storm water events that normally reach or can be practicably engineered to safely reach the river for diversion and use or strategically impounded and allowed to infiltrate in the interests of aquifer recharge for example storm waters occurring below caballo dam within the ebid are accounted for independent of rio grande project surface water releases from reservoir storage including those for downstream delivery obligations and so may be utilized this way depending on fluid flow complexity aquifer characteristics and water allocation schemes the purposely simple straight forward methodology used in this study may have potential in other conjunctive use settings however additional consideration and limitation may exist for systems that exhibit moderate heterogeneity in specific yield storage coefficients and or hydraulic conductivity including irregular unconstrained and or partially constrained aquifer geometry differing aquifer properties or hydraulically connected aquifers at various depths and unmanaged not reclaimed river and attendant surface water operations among other considerations the methodology presented in this study may serve as a start to characterizing conjunctive use and groundwater resilience in more complicated systems but should be followed by more exhaustive efforts including hydrologic modeling above all hydrologic monitoring and measurement is fundamental to this methodology and to the modeling efforts that may follow 4 conclusions this study further developed the wtf method by quantifying storage changes as a function of annual groundwater and surface water conjunctive use irrigated agriculture managed aquifer river systems this approach was also used to investigate groundwater conjunctive use and resilience with application of data from the ebid s rincon groundwater monitoring program to reveal the spatial and interannual variability of net storage changes from 2009 to 2016 in the rincon valley in the arid lower rio grande basin of south central new mexico and to examine the vulnerabilities of the aquifer to protracted hydrologic drought in this study regression modeling showed that variation in the annual pro rata ebid surface water allotment correlates strongly with year end water table elevations and with total annual groundwater extractions for irrigation this confirms that groundwater pumping for irrigation in the rincon valley is essentially a substitute for hydrologic drought impacts on the annual ebid surface water allotment added evidence that annual flows in the rio grande tend to govern this system was observed in the dewatering of the aquifer as of 2011 which significantly altered the system hydrology i e transition to losing stream such that persistent large net losses from the river recharge to the aquifer occurred for most of the study period from 2011 to 2016 net change in aquifer storage correlated strongly with the annual ebid surface water allotment providing for net gains in aquifer storage from 2014 to 2016 relative to december 31 2009 baseline conditions major storage losses occurring in 2011 and 2013 created a dominant deficit effect such that by the end of the study period a cumulative storage loss of 12 524 acre feet 15 448 k m3 was sustained given an average 4 2 loss of the average useable saturated thickness of the aquifer during the study period if surface water shortages to the ebid remain as they have then the need for an eventual reduction in groundwater depletions is surely unavoidable these results affirm the above noted relationship of lower annual ebid surface water allotments therefore less recharge with greater groundwater extractions for irrigation tended to lower the average year end groundwater elevations which resulted in greater annual net losses from aquifer storage however these results also prove that the reverse gains can be expected and at essentially the same rate in this system the rincon valley alluvium aquifer is quick to demonstrate losses but it is also quick to demonstrate gains this study introduced a new term the gsra as the ratio of the conjunctive surface and groundwater uses and the ratio of fluxes into and out of the aquifer that contribute to changes in storage which has potential for characterizing resilience of surface and groundwater interactions in conjunctive use settings a range of gsra values that are system specific can help to inform groundwater resilience but more should be done to examine the applicability controls and limitations of the gsra the gsra calculated at the end of this study 2 54 relative to a peak gsra of 17 76 calculated for 2013 implies that conjunctive use of water for irrigation in the rincon valley is fluctuating within a range of gsra values on the backdrop of hydrologic drought yet groundwater resilience in this system appears to thus far be preserved lower values of gsra approximating 1 0 may reflect an idealized circumstance e g similar to safe yield and may not be practical in the context of enduring uncertain hydrologic drought conditions in most conjunctive use settings at least not for very long it may however serve as a temporary management metric if groundwater resilience is found to be in or very near a compromised state should this be the case monitoring of gsra as a metric for aquifer resilience and sustainability is expected to be useful the gsra appears to be a transferable metric with potential to promote or at least characterize groundwater resilience knowledge of the aquifer specific range of gsra values and associated hydrologic effects may be determined through the methodology offered by this study as specific to an aquifer of interest and perhaps associated with water resource management alternatives appropriate to a conjunctive use setting of interest acknowledgements the authors wish to thank four anonymous reviewers of a draft of this paper for providing highly constructive input the lead author is especially appreciative of insightful thorough commentary received from the journal of hydrology editor dr timothy l jones former professor of soil physics at new mexico state university provided the lead author with inspiration in this field of study and interest in science generally many years ago this study was supported primarily by the ebid of new mexico but also in part by a graduate student assistantship from the water science and management program at new mexico state university mr gary esslinger general manager of the ebid is thanked for his encouragement and support gratitude is especially owed to mr patrick lopez ebid technology director and mr dennis mccarville ebid gis analyst 
7038,the rincon valley in arid south central new mexico is especially impacted by reduced surface water supply because the contribution of groundwater is limited by aquifer constraints consecutive surface water allotment shortages in the elephant butte irrigation district ebid have reduced recharge the effects are compounded by farmers continuing to extract groundwater to meet crop requirements conjunctive use assumes aquifer resilience i e ability to absorb pumping stress but not necessarily in drought this study further develops the water table fluctuation method by analyzing data from the ebid s groundwater monitoring program to reveal conjunctive use controls over the spatial and interannual variability of net storage changes from 2009 to 2016 in the valley and introduces the term groundwater surface water ratio of application gsra that has potential for characterizing system resilience in conjunctive use settings regression modeling shows that variation in the annual ebid surface water allotment correlates strongly with year end water table elevations even more strongly than total annual groundwater extractions for irrigation suggesting that variable surface water allotments are a primary driver of this system dewatering of the aquifer as of 2011 significantly altered the system hydrology such that from 2011 to 2016 net change in storage correlates strongly with the annual surface water allotment corresponding to large river losses for the same period but resulting in net gains in storage from 2014 to 2016 rapid storage loss and rebound in this constrained aquifer system allowed quantification of aquifer resilience enabling the development of a gsra as a potential planning metric keywords groundwater drought conjunctive use irrigation resiliency 1 introduction interactions between groundwater and surface water are a critical consideration for integrated conjunctive river basin management hantush 1965 hunt 1999 turney 1999 woessner 2000 rushton 2002 simonds and sinclair 2002 sophocleous 2002 kollet et al 2003 mair and fares 2010 especially during periods of protracted drought tao et al 2011 water scarcity generally impacts water resources in most of the world but desert areas are more susceptible to drought de vries and simmers 2002 groundwater storage variability over time and space is critical to sustainable water resources richts et al 2011 and has become a focus in many parts of the world in recent years richey et al 2015a note that surface water is the principal freshwater supply appropriated to meet human water demand globally but the importance of groundwater is increasing as surface supplies become less reliable and predictable kundzewicz and döll 2009 groundwater is increasingly relied upon during times of drought as a presumed resilient alternative water source famiglietti 2014 however upon conducting a groundwater stress assessment to quantify the relationship between groundwater use and availability in the world s 37 largest aquifer systems richey et al 2015a report that estimates of groundwater stress based on withdrawal statistics are unable to capture the range of characteristic stress regimes which can be inferred as evidence that quantifying groundwater resilience remains a challenge groundwater resilience within the elephant butte irrigation district ebid in the arid lower rio grande basin of south central new mexico usa has become an issue of interstate concern farmers in the rincon valley fig 1 along the rio grande within the ebid are especially impacted by protracted drought because the unique geology of the area conover 1954 davie and spiegel 1967 king and hawley 1975 wilson et al 1981 hawley et al 2005 limits the use of groundwater for supplementation of limited surface water for irrigation an extensive clay aquitard underlies the shallow yet finite unconfined alluvium aquifer common to the rincon valley the aquifer lateral extents are narrowly bounded and lateral groundwater flow is insignificant compared to pumping and recharge flows while the hydrogeology of the rincon valley shallow aquifer is well documented and further acknowledged in this study no formalized research has been conducted to quantify the vulnerabilities of this system in response to protracted surface water shortage this study refers to conjunctive use as the supplementation augmentation or periodic substitution of variable surface water by pumping groundwater for irrigation in interrelated systems and contends that the rincon valley shallow aquifer like other aquifer systems in conjunctive use settings is subject to hydrologic metrics that may be expressed in terms of resilience resilience is often discussed in the context of climate change as the ability of a system to absorb disturbances while retaining the same basic structure and ways of functioning and the capacity to adapt to stress and change ipcc 2012 this study refers to groundwater resilience similarly as the capacity of the aquifer to absorb variable pumping stress while retaining the same basic functionality in the context of variable surface water availability and recharge in an interrelated system however this is not an expression of sustainability conjunctive use assumes aquifer resilience such that pumping stress is absorbed but not necessarily during drought at least not indefinitely if drought conditions are severe and persist long enough then all other things being equal i e groundwater extractions remain unabated and or in excess of recharge resilience limitations will eventually be reached and the system may no longer be sustainable regardless of the potential for resilience or how it is defined methods are lacking to assess the resilience of aquifer storage at a local level where management potential is perhaps greatest knowledge of the relative limits of stress that local aquifers may sustain is a critical management consideration and needs to be further evaluated richey et al 2015a b sheng 2013 offers a timely however broad account of the impacts of groundwater pumping and climate variability within the rio grande basin downstream of elephant butte dam and notes that the state of the science relative to water sustainability in this region has room for improvement integrated numeric modeling efforts that are specific to the lower rio grande of new mexico have endeavored to predict the interactions between surface water and groundwater in this area although the earlier works were much more concerned with the immediate downstream mesilla valley which is a much larger and deeper system relative to the rincon valley some of these earlier works include frenzel and kaehler 1992 hamilton and maddock 1993 and lang 1995 later works that are inclusive of the rincon valley include weedon and maddock 1999 papadopulus and associates 2007 schmid and hanson 2009 hanson et al 2010 usbr 2015 and knight 2015 still questions concerning groundwater resilience in this area persist particularly as conditions favoring a reduced surface water supply in the rio grande basin are predicted to intensify usbr 2011 it is important to examine groundwater storage changes over time and to consider multiple methods for doing so an ongoing study that is not specific to the lower rio grande or the rincon valley yet but that has bearing on the nature of the work presented here is documented by rinehart et al 2015 in which the goal using geostatistical methods was to provide groundwater storage change estimates in alluvial basins throughout new mexico prior studies of regional aquifer storage include the work of mcguire 2013 in the southern high plains which was similar in some respects to the work that is presented here as far as making use of groundwater elevation data to estimate storage other studies such as kumar 2007 ahmadi and sedghamiz 2008 and chung and rogers 2012 have compared different types of kriging interpolations to estimate storage another approach originally introduced by montgomery 1971 but receiving renewed interest e g gehman et al 2009 is the use of temporal gravity surveys in which measurements of changes in gravity over time can be used to estimate variations in groundwater mass associated with a rise or fall in the water table fundamentally studies of this nature are varied conceptualizations of the water table fluctuation wtf method which depending on the fluid flow complexity is a simple and effective approach widely used to determine groundwater recharge healy and cook 2002 crosbie et al 2005 delin et al 2007 healy and scanlon 2010 for example wang et al 2014 used the wtf method to effectively estimate the spatiotemporal variability of groundwater recharge for the largest rice production region in northeast china the wtf method is simple and easy to apply because it requires information regarding only the water table and specific yield of an aquifer however extension of the wtf method over space and time to examine changes in groundwater storage rather than just recharge may offer a relatively easy effective way to evaluate conjunctive use and the impacts of drought on water resources management due to its relative simplicity and constrained groundwater flow system the rincon valley in southern new mexico is well suited to advance the wtf method for groundwater storage measurements and to serve as an example of quantifying groundwater resilience the purpose of this study is to further develop the wtf method to evaluate groundwater resilience by analyzing data from the ebid s groundwater monitoring program to determine the spatial and interannual variability of net storage changes from 2009 to 2016 in the rincon valley shallow alluvium aquifer this study explores these results as an indicator of aquifer resilience and river performance i e net river loss or gain in the context of hydrologic drought later defined and conjunctive use of water for irrigation and offers a new term the groundwater surface water ratio of application later defined this study also examines controls and indicators of resilience by relating net storage and average water table elevation changes with the annual pro rata ebid surface water allotment and total annual metered extractions of groundwater for irrigation 2 materials and methods 2 1 study area the annual surface water supply provided by storage in elephant butte and caballo reservoirs located in the upstream extent of the lower rio grande basin in southern new mexico a primary feature of the u s bureau of reclamation rio grande project has been reduced substantially due to ongoing regional drought elephant butte reservoir is the primary means of storage servicing the rio grande project which is concerned with the irrigation of lands in southern new mexico ebid inclusive of the mesilla and rincon valleys and lands in west texas el paso county water improvement district no 1 it is also an important means of meeting downstream delivery obligations by the u s to mexico as per a 1906 international treaty caballo reservoir located immediately downstream of elephant butte on the rio grande serves principally as a regulating feature for rio grande project seasonal releases in a full supply year irrigation releases from storage for all rio grande project contract beneficiaries begin in march and end in september for a total volume of about 790 000 acre feet 974 4 m cubic meters inclusive of a full pro rata ebid surface water allotment of 3 024 acre feet 36 288 acre inches per irrigated acre 9217 cubic meters per hectare for lands assessed to receive surface water within the ebid a total of 90 640 acres 36 681 ha are assessed to receive surface water throughout the ebid the rincon valley contains about 28 064 acres 11 357 ha of which 18 651 acres 7547 ha are assessed to receive surface water ebid 2016 but on average only about 17 000 acres 6880 ha in the rincon valley are irrigated annually almost all about 95 of these lands are irrigated with a combination of surface water delivered through the ebid on a pro rata basis and groundwater pumped in varying amounts from individual farmer owned wells the rincon valley fig 1 comprises the northern extent of the ebid floodplain elevation above mean sea level at the northern end by caballo dam is about 4160 feet 1268 m and 4100 feet 1250 m at the lower end of the valley which is about 32 miles 51 5 km long the width of the valley floor is constrained from one to two miles 1 6 3 2 km in a classic basin and range province that is characterized by rugged mountain ranges and gently sloping chihuahuan desert plains divided by the riparian corridor of the rio grande the basin is bounded by near vertical faults associated with mountain ranges that are generally aligned in a north south direction with the caballo and doña ana mountains bounding the rincon valley to the east and the black range and sierra de las uvas mountains to the west records from a weather station located at new mexico state university show the average annual precipitation from 1976 to present to be 9 28 in 236 mm 54 of which falls during the summer monsoon months of july september wrcc 2015 using classic methodology described by blaney and criddle 1962 gabin and lesperance 1977 report that peak potential evapotranspiration using alfalfa as a reference crop in the area occurs during july wherein a monthly total of 9 25 in 234 95 mm of water is estimated to be evapotranspired on average and that total annual potential evapotranspiration in the area is estimated to be 49 82 in 1265 43 mm on average local precipitation has traditionally been considered a very small part essentially negligible of the irrigation water budget in this area but this certainly may not be the case in other study areas ebid pro rata surface water allotments for the last eight years table 1 have averaged only 12 9 acre inches per acre 3270 cubic meters per hectare per year about 36 percent of a full allotment climate forecasts concerned with the regional rio grande basin inclusive of watersheds in southern colorado and northern new mexico headwaters of the rio grande suggest that an average of this nature may be more common than not for years to come usbr 2011 rather than focusing on drought as localized above average aridity reflecting local weather variation this study defines hydrologic drought as a circumstance where protracted regional drought impacting upstream upland watersheds leads to a persistent reduction in the volume of surface water in local reservoir storage and therefore consecutive annual shortages of surface water available for local release for the purposes of this study an ebid pro rata surface water allotment that is less than 66 7 percent of a full allotment less than 2 0 acre feet per acre 6096 cubic meters per hectare is considered to reflect significant hydrologic drought conditions very few domestic wells or other municipal and industrial wells exist in the rincon valley the village of hatch the largest urban area in the rincon valley is the primary provider of water for drinking and sanitary purposes and imports potable water via pipeline from an alternative groundwater source known as the nutt hockett basin this groundwater source is located about 12 miles 19 3 km to the southwest of hatch and is hydraulically independent of the rincon valley irrigated agriculture is by far the dominant use of water including extraction of groundwater with or without hydrologic drought conditions in the rincon valley irrigation is predominantly by surface flood application to farmlands that in most cases are regularly laser leveled but does include shallow subsurface drip tape use combined with traditional flood practices in many instances the rincon valley is world renown for the famous hatch brand chile in 2014 new mexico ranked first in the u s for total acreage planted in chile california was second and ranked second just behind california for total onion production nmda 1998 hatch brand chile and other vegetable production particularly onions is a significant component of the local economy hall and skaggs 2003 irrigated agriculture is by far the foremost form of industry and source of income and tax revenue in the rincon valley 2 2 groundwater surface water ratio of application this study introduces a new term the groundwater surface water conjunctive use ratio of application gsra defined as the total volume of groundwater extracted and applied for irrigation per unit time divided by the total volume of surface water diverted and applied for irrigation per unit time within a common river basin and hydraulically interrelated aquifer system the term is specific to water resource settings that are or should be conjunctively used and managed the significance of the gsra as a metric of aquifer resilience is that over time even in the absence of more detailed information specific to net depletion i e evapotranspiration that is typically much more difficult to accurately assess howes et al 2014 the gsra can serve as an indicator of aquifer stress relative to surface water availability and potential recharge the gsra can therefore also serve as a metric for determining steady state conditions i e a circumstance where net change in aquifer storage equals zero other terms have been suggested to characterize aquifer stress but are more concerned with generalized estimates of aquifer longevity in the context of sustainability and not necessarily resilience richey et al 2015a offer the idea of a total groundwater stress ratio defined as the ratio of total storage to the groundwater depletion rate to estimate timescales to depletion by accounting for the buffer capacity of aquifer storage they found that the current state of knowledge of large scale groundwater storage has uncertainty ranges across orders of magnitude that severely limit the characterization of resilience at least in the numerous large regional aquifers they studied around the world this study suggests that the gsra as a metric for groundwater resilience is a potentially practical useful approach for localized management in conjunctive use settings where groundwater storage tends to remain in flux anyway and that a focus on total storage may have limited utility in most irrigation projects since total storage and economically recoverable storage are typically very different things 2 3 hydrogeology the surface waters of the rio grande and the groundwater of the shallow alluvium aquifer of the rincon valley are a highly connected essentially singular resource conover 1954 wilson et al 1981 frenzel and kaehler 1992 winter et al 1998 turney 1999 hawley and kennedy 2004 and others among the most complete hydrogeologic descriptions of the rincon valley and surrounding region is offered by hawley et al 2005 noting that the rio grande is the only significant surface water resource in the region and therefore the main source of recharge conover 1954 king et al 1971 and wilson et al 1981 report that the shallow alluvial deposits associated with the river in the inner valley in this area serve as the ultimate discharge zone for pre development groundwater flow from adjacent basins and uplands hawley et al 2005 stress that the essential hydrogeologic characteristic of the rincon valley in terms of groundwater resources is the absence of any significant basin fill aquifer unit beneath the shallow alluvial fill of the inner valley test drilling of several exploratory wells in the area the deepest to about 2000 feet 610 m document the presence of a very thick estimated about 2500 feet 762 m sequence of fine grained basin floor sediments clays deriving from a prehistoric playa lake below the inner valley fill king et al 1971 wilson et al 1981 with virtually no potential for freshwater production due to very low hydraulic conductivity the upper elevation of this sequence reflects the lower extent of the productive aquifer and lateral extents providing a width of no more than one to two miles 1 6 3 2 km are evidenced by steep vertical faults essentially no aquifer exists in the rincon valley except the shallow alluvium which on average is only about 80 feet 24 m deep and renders a useable average of only about 55 feet 17 m of saturated thickness wilson et al 1981 within the modern floodplain of the rincon valley a 30 40 foot 9 12 m thick gravel layer occupies the lower part of the alluvium and is overlain by thin lenses and layers of sand gravel and clay but is otherwise considered to be mostly homogenous aquifer material wilson et al 1981 with transmissivity averaging about 17 100 feet squared per day 1588 m2 day static depth to water in the valley floodplain alluvium is normally following initial development early 1950s through 1970s from 8 to 15 feet 2 5 m below land surface the north to south flow of groundwater in the rincon valley is at about the same slope as the ground surface about 5 feet per mile 1 m per kilometer wilson et al 1981 further describe the groundwater resources of the rincon valley as a long narrow continuous aquifer comprised of quaternary gravel sand and clay deposits which is entrenched in the red clay of the santa fe group lacustrine facies 2 4 net change in groundwater table elevation within the rincon valley the ebid maintains a network of thirteen 13 instrumented shallow monitoring wells dedicated to tracking shallow groundwater levels in the area relative to the rincon valley spatial extent of about 28 064 acres 11 357 ha the locations of ebid s monitoring wells are described in table 2 and are situated to approximate uniform coverage of the rincon valley each monitoring well features a 2 0 inch 5 1 cm casing and is completed to a total depth of approximately 25 feet 8 m below the soil water interface about 40 feet 12 m below ground surface the bottom 20 feet 6 m of each well is screened and beyond that a blank sump of about 10 feet 3 m occupies the very bottom of each well to accommodate eventual sediment accumulation the screened interval of each well is within about the middle of the average saturated thickness of the aquifer all sites were surveyed to establish appropriate benchmark elevations since 2009 groundwater table elevations measured as a function of pressure head with submersible pressure transducers instrumentation northwest inc model pt2x purchased and installed by the ebid very near within 6 0 in 15 24 cm the bottom of the screen of each of the new monitoring wells have been recorded continuously every thirty 30 minutes and temporarily stored in data loggers campbell scientific inc model cr10x at each site powered with solar and battery backup for monthly data retrieval these sensors were configured with a gauge option to include venting technology to compensate for variable barometric pressure effects precision of 0 05 ebid recently mid 2015 replaced these instruments with simpler more reliable pneumatic bubbler sensors control design inc model cd103 precision of 0 05 paired with remote telemetry units control design inc model cd110 to achieve essentially real time data acquisition the change in instrumentation did not produce any discernible shift in measurement data particularly since in season while irrigation well pumping is underway fluctuations in the local water table are typically several orders of magnitude greater than the measurement error of the instrumentation before and after the change in instrumentation this type of groundwater monitoring program to measure real time fluctuations in the water table is useful for many reasons however this study is concerned with year end interannual december 31 to december 31 groundwater table elevation changes at each monitoring site in the rincon valley at year end groundwater table elevations at and between monitoring wells are subject to minimal influence by nearby irrigation production wells fluctuating cones of depression since very little or no irrigation is expected to be underway or to have occurred for about a month prior the potential for the static elevation of the groundwater table at each monitoring well location to have reached a point of new relative equilibrium will have reached a maximum at this time i e after harvest there is typically more uncertainty in groundwater pumping conditions at the early part of the growing season before the start of the next surface water release beginning mid late april to as late as june 1 in recent years of reduced surface water supply in this study the average december 31 groundwater table elevation at all sites at each year end was compared to total annual groundwater extraction from all metered irrigation production wells nmose 2017 in the rincon valley that are used in conjunction with the total annual ebid pro rata surface water allotment and comparison was also made to the calculated annual net river loss or gain 2 5 net change in groundwater storage a spatial modeling approach utilizing analytical tools available in a geographic information system arcgis v 10 2 environmental systems research institute framework adapted to the rincon valley was used to show where and to what extent year end groundwater table elevation changes and net groundwater storage changes have occurred in recent years it is assumed that each monitoring well location and the year end groundwater elevation data associated with each monitoring well contributes equally to characterizing the collective response of the shallow alluvium aquifer to pumping stress and or recharge healy and cook 2002 report that a basic assumption inherent in the wtf method and critical to its successful application is that specific yield is known and constant over the time period of the wtfs however variation in aquifer properties is generally area and depth dependent the guidance offered by yeh et al 2015 clarifies that the challenges posed by aquifer heterogeneity are opportunities for stochastic approaches to characterizing aquifer properties such as the use of hydraulic tomography nevertheless spatial differences in specific yield and or storage coefficients within the same stratigraphic layer of interest are generally not differentiated between individual cells within a typical groundwater flow model discretization grid in the case of the rincon valley the stratigraphic layer of interest is physically limited to the shallow alluvium because the unconfined shallow alluvium aquifer in the rincon valley is finite and laterally bounded and reported to be largely homogenous wilson et al 1981 this study likewise assumes that specific yield is spatially uniform for this study an average specific yield sy of 0 2 was distributed throughout the shallow alluvium aquifer conover 1954 richardson et al 1972 lizarraga 1978 and wilson et al 1981 each independently reported a sy of at least 20 percent for the shallow alluvium within the lower rio grande basin several previous modeling efforts in the lower rio grande including frenzel and kaehler 1992 hamilton and maddock 1993 lang 1995 weedon and maddock 1999 and papadopulus and associates 2007 each assigned a value of 0 2 for sy to the uppermost model layer reflecting the shallow alluvium aquifer and each assumed that sy is uniform across the uppermost model layer sy is an important aquifer property particularly for purposes of this study concerned with change in aquifer storage this is evident in the following relationship noted by fetter 2001 1 v w s a δ h where vw is the volume of water acre feet or m3 drained from a portion of the aquifer s is the storativity or sy in an unconfined aquifer dimensionless a is the surface area overlying the drained portion of the aquifer acres or hectares and δ h is the change in groundwater elevation or hydraulic head ft or m in the context of aquifer resilience sy is especially important as the volume of water in the aquifer relative to the aquifer volume and if land subsidence is prevalent and collapse of aquifer material pore structure occurs reductions in sy can be expected which limits the capacity of the aquifer to rebound to the extent that δ h is found to be changing over time relative to some baseline elevation then vw can also express the volume of water gained by a portion of the aquifer and therefore relates to recharge and the fundamental premise of the wtf method the basic assumption of the wtf method is that the rise of groundwater level in unconfined aquifers is caused by the response to the infiltration of water rainfall irrigation etc arriving at the groundwater table recharge recharge rate r l time can therefore be quantified as follows healy and cook 2002 2 r s y δ h δ t where δ t is the time of recharge period the flux therefore is reflected by change in aquifer storage which may also be expressed as a volumetric discharge or water use rate by applying eq 2 over the aquifer area this allows the wtf method to account for changes in groundwater storage associated with water use to the extent that pumping stress on the aquifer over time exceeds recharge over time then dewatering of the aquifer occurs and storage is necessarily reduced the inverse is also plausible in which case the aquifer storage would be in a gaining state aquifer storage as with streams can be gaining under recharge conditions and losing under discharge conditions this dynamic can be convoluted in conjunctive use settings because r may reflect either river infiltration recharge flux or groundwater pumping discharge flux and both may be occurring prior wtf applications for characterization of natural recharge through groundwater elevation measurement are extended here to an irrigated agriculture managed aquifer river system where groundwater storage relates directly to conjunctive water use rates summation of volume change at each year end from each monitoring well and associated area in the rincon valley are reported as the calculated net change in storage from the shallow alluvium aquifer for each year and are also reported at each monitoring site relative to december 31 2009 groundwater table conditions in the rincon valley total annual net change in aquifer storage is then compared to the total annual ebid pro rata surface water allotment and total annual groundwater extraction quantification of these relationships in the context of groundwater resilience and conjunctive use are feasible because groundwater extractions combined with the use of available surface water for irrigation are in this study area the predominant variables influencing change in aquifer storage accordingly this study refers to the groundwater surface water conjunctive use ratio of application gsra dimensionless defined previously gsra extends from eq 2 to address the convolution of recharge and discharge associated with conjunctive use as gsra can be considered the ratio of groundwater pumping discharge flux to river infiltration recharge flux or groundwater use to surface water availability and use this study postulates that if the gsra consistently exceeds 1 0 then it is expected that the aquifer s capacity to buffer pumping stress relative to a variable recharge flux volume will eventually be reduced this is not to suggest that the gsra cannot average somewhat greater than 1 0 over time and the resilience of the aquifer still be preserved it is reasonable to expect that an average threshold or range for gsra exists within which groundwater resilience in conjunctive use settings can be maintained such that net change in aquifer storage over time is ultimately equal or close to zero determination of a threshold gsra such that net change in aquifer storage is equal to zero is expected to represent steady state conditions but may not necessarily reveal a managerial target or definitive metric of aquifer resilience this study furthers the wtf method by extending eq 2 building on the work of healy and cook 2002 to quantify interannual groundwater storage vw change over the aquifer area individual area values a that could be attributed to groundwater monitoring wells throughout the rincon valley were discretized with thiessen polygons thiessen 1911 utilizing arcgis spatial analysis software the thiessen method uses a weighing factor for each sampling point to adjust for non uniform sampling point distribution the weighing factor is based on the size of the area within the area of interest the thiessen method was chosen for this study because of its relative simplicity and potential for adaptation elsewhere an imperfect distribution of monitoring wells the narrow physiological features of the rincon valley itself and the resultant irregular geometry and corresponding areas of the polygons produced by the thiessen method in this case is somewhat coarse table 2 this is shown in fig 2 which is a discretization map of the rincon valley as bounded by the lateral extents of the aquifer and includes the names and locations of the several small communities in the valley other spatial analysis methods such as kriging or inverse distance weighting whereby the field is discretized on the basis of pixels or groups of pixels among other could very well be adapted to the purposes of this work although not presented here this study found that kriging methods provided no significant difference from or apparent benefit over the simpler thiessen approach chosen for this study at least with the available data 2 6 river performance gains or losses in river discharge can result from seepage in the streambed or from bank storage evaporation from the water surface and transpiration by vegetation along the river banks discharge in the ebid reach of the rio grande is controlled almost exclusively by irrigation releases from caballo dam crilley et al 2013 in this study it is affirmed that seepage in the streambed is also controlled by the static average year end groundwater table elevation the mass balance equation used for calculating net annual river seepage gain or loss in the rincon valley subreach of the rio grande is as follows simonds and sinclair 2002 q s q ds q us q in q out where qs is the net seepage gain or loss for the subreach acre feet or m3 qds is the discharge measured at the downstream end of the subreach acre feet or m3 qus is the discharge measured at the upstream end of the subreach acre feet or m3 qin is the sum of inflows acre feet or m3 and qout is the sum of outflows acre feet or m3 data were obtained from ebid river gauges at strategic locations along the rio grande within the ebid qds and qus including metered diversion dams for purposes of delivering surface water to ebid farmers qout further the ebid has developed and is continuing to expand a network of weather stations and rain gauges within the immediate area watershed to anticipate flood events but also to serve a storm water capture program qin the data available from ebid s storm water capture program were used for qin however evapotranspiration et was not separately estimated in this study the result is the calculated net annual flux of water gained or lost from the streambed for this reach of the rio grande which is compared to the average annual year end groundwater table elevation in the rincon valley 3 results and discussion 3 1 groundwater elevation and net storage changes table 3 provides a summary of the average annual year end groundwater elevation change taken from year end groundwater elevation measurements at all ebid monitoring wells in the rincon valley and the corresponding calculated net change in aquifer storage totalized for each year during the study period results indicate that the groundwater table elevation in the rincon valley declined an average of 2 3 feet 0 7 m over the course of the study period this translated to an average 4 2 loss of the average saturated thickness of the aquifer relative to about 55 feet 17 m reported by wilson et al 1981 as the average useable thickness between 2014 and 2016 gains in storage were calculated and are an indication of aquifer resilience on the basis that a period of reduced aquifer stress and increased recharge demonstrates that the aquifer can and does remain functional with potential to rebound if conditions conducive to recovery are present this also suggests that change in storage is a function of supply and demand as assumed feasible for conjunctive use which this study suggests is reflected by the gsra nevertheless major losses occurring in 2011 and 2013 had created a dominant deficit effect such that at the end of the study period a cumulative storage loss of 12 524 acre feet 15 448 k m3 was sustained as long as a storage void persists in the aquifer the potential for continued gains will persist fig 3 contains data for the average year end groundwater table elevation and the total annual ebid pro rata surface water allotment delivered to lands in the rincon valley for each year during this study included also is the 2016 surveyed ibwc 2017 average riverbed elevation in the rincon valley assuming that the 2016 average riverbed elevation is representative of the average riverbed elevation for the study period it is revealed that after 2010 the average year end groundwater table elevation had receded well below the base of the riverbed this condition following 2010 will have certainly increased the rate of recharge of available surface water to the aquifer however limited in recharge volume by substantially reduced surface water allotments after 2010 the trend in fig 3 indicates that increases in surface water allotment increase groundwater storage due to recharge along the river and decreases in groundwater pumping when surface water is available this trend reveals the dependence of resilience of aquifer storage on recharge from surface water and shows that the average year end groundwater table elevation correlates well r2 0 83 within a reasonable confidence interval 0 654 r2 1 00 at 95 with the total annual ebid surface water allotment while the surface water allotments in 2009 and 2010 were much greater than subsequent years during the study period the p value calculated in this instance 0 0017 is much lower than 0 05 demonstrating that the effects of substantially reduced surface water allotments in years after 2009 and 2010 are in statistical keeping with the trend on average over the aquifer fig 3 shows a consistent trend additionally the gsra is intended to represent conjunctive use from year to year regardless of spatial or temporal uniformity within a given irrigation season fig 4 presents total annual metered groundwater extractions for irrigation of lands in the rincon valley that are also irrigated with surface water relative to the total annual ebid pro rata surface water allotments delivered in the rincon valley during this study the data indicate that groundwater pumping has been inversely related to surface water use and availability this trend demonstrates the conjunctive use of this system proving that groundwater pumping for irrigation in the rincon valley is essentially a substitute for and strongly correlated with r2 0 87 hydrologic drought impacts on the ebid surface water allotment the calculated p value 0 000747 and confidence interval 0 732 r2 1 00 at 95 found in this instance tends to substantiate the significance of this relationship 2009 and 2010 reflect years when the ebid surface water allotment was much closer to full however subsequent years were dominated by hydrologic drought and elevated pumping levels particularly in 2011 and 2013 even so a variable rate of substitution of groundwater extraction for surface water is apparent on average over the aquifer fig 4 shows a consistent trend and the gsra is intended to represent conjunctive use on an annual basis regardless of spatial or temporal uniformity of applied water for irrigation in a given year fig 5 presents the relationship between the average year end groundwater table elevation and total annual metered groundwater extractions for irrigation and indicates that in season groundwater pumping is as expected well correlated r2 0 80 with the average year end groundwater table elevation increases in groundwater extraction directly result in decreases in groundwater storage within the aquifer the p value 0 002539 and confidence interval 0 608 r2 1 00 at 95 calculated with this relationship is acceptable in comparison fig 3 reveals that the relationship with the ebid surface water allotment is slightly stronger r2 0 83 with slightly more convincing background statistics however the explanatory variables x axis in either case are themselves highly correlated figs 3 and 5 indicate the two primary controls over changes in aquifer storage are the groundwater and surface water use in this conjunctive use managed aquifer fig 5 also shows that aquifer storage resilience is certainly influenced by and may eventually be threatened by groundwater extraction surface water allotments may be considered the driving variable in this system because variable groundwater extraction is largely in response to variable surface water allotments and because surface water allotments are the primary source of aquifer recharge table 4 provides results for the individual thiessen polygon net changes in aquifer storage calculated at each monitoring site during this study notably in 2011 sites rin 2r rin 9r and rin 10r to the north in general experienced substantially greater loss from storage than any other site at any other time during the study period assuming a spatially uniform specific yield the standard deviation across these three regions is about three times greater in 2011 than in other years suggesting that pumping tended to be spatially concentrated in 2011 and in 2013 which reflect years of significant surface water shortage and greatest groundwater extractions fig 4 fig 6 presents net change in aquifer storage in the rincon valley relative to december 31 2009 groundwater table conditions and relative to the total annual ebid surface water allotment for the period of 2011 2016 linear trend and 2009 2016 non linear trend after 2010 a void in aquifer storage had been created as result of reduced recharge and increased groundwater extraction decrease in groundwater storage during 2011 and 2013 and this void in storage allowed for the potential for gains in groundwater storage that were realized particularly in 2014 2015 and 2016 the period of 2009 to 2016 reflects a circumstance where and when the aquifer s buffering capacity or near term resilience to mitigate pumping stress is accounted for in the context of conditions in 2009 and 2010 when the aquifer was at or very near storage capacity because of large net annual gains in the river were calculated for 2009 and 2010 discussed later a non linear trend was evident for the period 2009 2016 and the correlation coefficient is low r2 0 39 apparently because significantly different aquifer conditions are represented in the same plot eventually when if the aquifer returns to a fully recharged state such as conditions observed in 2009 then a non linear trend is expected to best represent net change in aquifer storage relative to surface water allotments the period from 2011 to 2016 was found to approximate linear behavior r2 0 83 suggesting that the hydrology of this system was at that time as of the end of 2011 substantially altered these results suggest that as of the end of 2011 stress on the aquifer from groundwater extraction combined with reduced recharge from surface water shortage may have led to the aquifer being disconnected from the river to one degree or another brunner et al 2009 report that if the groundwater table below a stream is sufficiently deep relative to streambed elevation changes in the groundwater table position do not alter the infiltration rate which is defined as a disconnected system as noted above the riverbed elevation in fig 5 indicates the river was a gaining stream in 2009 and 2010 the river was a losing stream during all other years and the river may have become disconnected while it was a losing stream following full or closer to full consecutive annual ebid surface water allotments the aquifer is expected to rebound and the system would be expected to return to a connected status the resilience of the aquifer therefore changes over time in response to changing surface water allotments and the frequency and duration of hydrologic drought particularly if groundwater extractions for irrigation remain dependent on available surface water in this way the resilience of the aquifer is dependent on the gsra 3 2 groundwater surface water ratio of application the calculated annual gsra for the study period is reported in table 5 and includes total annual metered groundwater pumping from all irrigation wells in the rincon valley that are conjunctively used with surface water actual farm deliveries of surface water in the rincon valley table 1 were used in these computations as expected in keeping with fig 4 2011 and 2013 are years when groundwater extractions were highest combined with particularly low ebid surface water allotments and therefore the highest calculated gsras were observed substantially more groundwater was pumped than surface water was available to irrigate with the computed standard deviation over time 5 69 was about 92 of the mean 6 21 gsra during the study period indicating substantial variation in the annual proportion of groundwater and surface water used to irrigate however the gsra of 2 54 at the end of the study period 2016 having dropped from a high of 17 76 found for 2013 implies that conjunctive use of water for irrigation in the rincon valley may be fluctuating within a reasonable range of system resilience and range of gsra values even though ebid surface water allotments for the last six years majority of this study remained well below half of a full allotment this may point to adaptation of the rincon valley farming community to hydrologic drought fig 7 is a plot of the gsra relative to net change a and cumulative change b in aquifer storage where groundwater table conditions as of december 31 2009 are taken to be a baseline for purposes of this study fig 7a compares gsra values with single year storage changes and suggests that as the gsra increases beyond about 4 63 then net loss from aquifer storage is predicted r2 0 58 with increasing groundwater storage loss as the gsra increases as of 2011 a void in aquifer storage had been created therefore the potential for gains in storage had been established relative to the minor changes in storage calculated in 2009 and 2010 when the aquifer was at capacity 2009 or near capacity 2010 the correlation coefficient in this instance is low and the confidence interval 0 222 r2 0 936 at 95 and p value 0 0283 indicates that this relationship is marginal regardless the gsra broadly captures the groundwater storage change impacts attributed to use of surface and groundwater for irrigation in the rincon valley within a given year and the effects of this water use non uniformity within a given year and from year to year are insignificant compared to impacts on net change in aquifer storage a threshold value or range of gsra values specific to a given surface groundwater system may have utility as a guide to aquifer resilience over time particularly in this system where groundwater extractions tend to be a substitute for limited surface water availability fig 7b presents data and a regression for cumulative net change in aquifer storage as a function of the gsra and reports a non linear relationship such that a gsra found to be 4 63 value for zero net change in storage from fig 7a over time is predicted r2 0 78 to produce a cumulative loss from aquifer storage of about 16 870 acre feet 20 808 k m3 the mean gsra found during the study period 6 21 table 5 is predicted to result in a cumulative net loss from storage of about 19 360 acre feet 23 880 k m3 the actual cumulative net loss from storage calculated for the study period was 12 524 acre feet 15 448 k m3 which fig 7b predicts would be met with a gsra averaging about 2 77 this discrepancy is most likely a reflection of the relatively small dataset limited number of years of available reliable data used in this study uncertainty in the data and regression and the nonlinearity of the trend interestingly however the gsra found for 2012 4 67 table 5 represents a time of the least amount of net change in storage during the study period table 3 and is very close to the threshold gsra of 4 63 required for a change in storage of zero fig 7a the implication of this as applied to fig 7b is that a cumulative net loss from storage at least as large as that calculated through 2012 can be sustained and if net change in storage is thereafter stabilized further losses are minimal then the aquifer will adjust to a new equilibrium the existence of a dynamic equilibrium is in keeping with dynamic recharge flux fluctuations in the proportions of surface and groundwater used to irrigate conjunctive use and therefore the gsra these results are indications that over time management intervention and or incentive to reduce the average gsra perhaps to approximate 1 0 if even temporarily in response to protracted hydrologic drought could eventually be fundamental to system resilience in this way the gsra analysis presented herein can help to inform groundwater resilience 3 3 river performance fig 8 contains data for net annual river loss or gain for the rincon valley reach of the rio grande relative to the average annual year end groundwater table elevation measured at all ebid monitoring sites in the rincon valley during this study fig 8 also identifies the average riverbed elevation as surveyed at the center of the rio grande along the rincon valley reach of the river during the winter when the riverbed was dry of 2016 ibwc 2017 negative change in river volume i e river loss is in part transmitted as recharge to increase groundwater storage positive change in river volume i e river gain and is generally due to discharge from groundwater storage the observed transition shown in fig 8 of the rio grande from a gaining stream to a losing stream is consistent with the previous discussions from figs 3 and 5 as evidenced by the linearity in groundwater elevation response following the transition from a gaining river condition to losing the groundwater system equilibrates within each year due to the constrained aquifer geometry in this case this aids in the evaluation of groundwater resilience and system response to changes in stress through changes in surface and groundwater use from 2011 to 2016 the average year end water table elevation had receded well below the base of the riverbed reaching a low of 4042 9 feet 1232 3 m above mean sea level suggesting that the aquifer may have been in some places disconnected brunner et al 2009 from the river during this period in terms of annual river losses documented for most of the study period 2011 2016 compared with much larger annual groundwater extractions for irrigation relative to groundwater elevations fig 5 for the same period annual groundwater extractions can and at times do occur in volumes well in excess of potential annual recharge from the river this highlights the importance of the alluvium aquifer of the rincon valley as a resource for buffering hydrologic drought the feasibility of conjunctive use in this system and the potential for limits to aquifer resilience dewatering of the aquifer as of 2011 introduced stress to the system such that from 2011 to 2016 net change in storage fig 6 correlates strongly with the annual surface water allotment suggesting that the recharge rate from the river may have reached a maximum during this time the annual gains in storage from 2014 to 2016 are attributed to recharge in keeping with the annual ebid surface water allotment however relatively small the allotments were during this time the size of the allotments is relevant because to the extent that more surface water is available to irrigate with and for a longer duration during the irrigation season then less groundwater is pumped resulting in less stress on the aquifer the annual gains in storage from 2014 to 2016 can most likely be attributed to the lowering gsra values observed during this time period this further affirms the dependence of the alluvium aquifer storage in the rincon valley on the annual ebid surface water allotment and management of water use to maintain low grsa values the rincon valley alluvium aquifer demonstrates losses in response to pumping stress rapidly due to the constrained geometry and hydraulic properties of the aquifer but it is also quick to demonstrate gains in response to recharge which is a measure of a resilient system with a correlation of almost 70 r2 0 68 fig 8 suggests that the net annual flux of water gained or lost from the streambed for this reach of the rio grande may be stabilized i e zero change in river storage when the average year end groundwater table elevation is maintained at least at 4046 3 feet 1233 3 m above mean sea level navd 88 it is important to note that this is a volatile number and depends on a number of external fluxes themselves volatile influencing the system and therefore does not represent a particular managerial target rather these results suggest that there are a range of average year end groundwater table elevations relative to the average riverbed elevation that may help to inform where and when net annual loss from the streambed approaches a maximum recharge rate this has implications for groundwater resilience and also operational efficiency of the river itself 3 4 management implications relative to net change in aquifer storage as shown in fig 6 with a correlation of just over 80 r2 0 83 while dominated by hydrologic drought 2011 2016 during this study a minimum consecutive total annual ebid pro rata surface water allotment applied in the rincon valley of about 12 467 acre feet 15 378 k m3 was calculated as necessary to stabilize the system at least relative to conditions observed from 2011 to 2016 this is only about 0 75 ac ft per acre 2 29 m3 hectare about 25 of a full allotment and is not suggested to represent a long term minimum surface water allotment necessary to maintain system resilience let alone sufficient for the farming community in the rincon valley to remain viable graphically it is apparent from fig 6 that relatively little net change in storage occurred in 2012 or 2014 table 4 which in terms of negligible net storage change is comparable to 2009 and 2010 a time when the aquifer was at or near storage capacity yet the end of 2014 reflects a time when cumulative loss from storage fig 7b was by far the greatest during the study period and actually the greatest for many years decades prior since the early mid 1950 s the obvious cause of this was remarkably low surface water allotments in 2011 and 2013 combined with expansive groundwater extractions in response had rio grande project operations and or upstream conditions been able to adjust to deliver 25 of a full surface water allotment to the ebid in 2011 and 2013 rather than the 11 1 and 9 7 respectively table 1 then aquifer storage changes in the rincon valley during this study would have most likely been different less management goals that target the optimal use of available surface water to facilitate aquifer recharge and that simultaneously or at strategically planned times reduce the stress of groundwater extractions in this system should be explored an unexhaustive account of options include optimization analysis to quantify the potential for less on farm groundwater extraction through increased on farm surface water delivery efficiency by strategic synthetic lining and or piping of select otherwise unlined earthen canals and laterals this should be approached cautiously and with attention to not compromising recharge potential with efforts to modernize conveyance infrastructure it is realized that the existing unlined earthen canals and laterals do serve in part as a vehicle for aquifer recharge while surface water deliveries are underway however the river itself and subsequent on farm flood application of surface water for irrigation may be the predominant source of recharge in this system to the extent that enhanced more efficient conveyance of available surface water for irrigation may reduce groundwater extractions in otherwise problem areas to meet crop requirements then less stress on the aquifer is expected and should be explored sediment removal and channel maintenance may be used to avoid decreases in recharge associated with lower hydraulic conductivity sedimentation further effort could be undertaken to capture and quantify incidental storm water events that normally reach or can be practicably engineered to safely reach the river for diversion and use or strategically impounded and allowed to infiltrate in the interests of aquifer recharge for example storm waters occurring below caballo dam within the ebid are accounted for independent of rio grande project surface water releases from reservoir storage including those for downstream delivery obligations and so may be utilized this way depending on fluid flow complexity aquifer characteristics and water allocation schemes the purposely simple straight forward methodology used in this study may have potential in other conjunctive use settings however additional consideration and limitation may exist for systems that exhibit moderate heterogeneity in specific yield storage coefficients and or hydraulic conductivity including irregular unconstrained and or partially constrained aquifer geometry differing aquifer properties or hydraulically connected aquifers at various depths and unmanaged not reclaimed river and attendant surface water operations among other considerations the methodology presented in this study may serve as a start to characterizing conjunctive use and groundwater resilience in more complicated systems but should be followed by more exhaustive efforts including hydrologic modeling above all hydrologic monitoring and measurement is fundamental to this methodology and to the modeling efforts that may follow 4 conclusions this study further developed the wtf method by quantifying storage changes as a function of annual groundwater and surface water conjunctive use irrigated agriculture managed aquifer river systems this approach was also used to investigate groundwater conjunctive use and resilience with application of data from the ebid s rincon groundwater monitoring program to reveal the spatial and interannual variability of net storage changes from 2009 to 2016 in the rincon valley in the arid lower rio grande basin of south central new mexico and to examine the vulnerabilities of the aquifer to protracted hydrologic drought in this study regression modeling showed that variation in the annual pro rata ebid surface water allotment correlates strongly with year end water table elevations and with total annual groundwater extractions for irrigation this confirms that groundwater pumping for irrigation in the rincon valley is essentially a substitute for hydrologic drought impacts on the annual ebid surface water allotment added evidence that annual flows in the rio grande tend to govern this system was observed in the dewatering of the aquifer as of 2011 which significantly altered the system hydrology i e transition to losing stream such that persistent large net losses from the river recharge to the aquifer occurred for most of the study period from 2011 to 2016 net change in aquifer storage correlated strongly with the annual ebid surface water allotment providing for net gains in aquifer storage from 2014 to 2016 relative to december 31 2009 baseline conditions major storage losses occurring in 2011 and 2013 created a dominant deficit effect such that by the end of the study period a cumulative storage loss of 12 524 acre feet 15 448 k m3 was sustained given an average 4 2 loss of the average useable saturated thickness of the aquifer during the study period if surface water shortages to the ebid remain as they have then the need for an eventual reduction in groundwater depletions is surely unavoidable these results affirm the above noted relationship of lower annual ebid surface water allotments therefore less recharge with greater groundwater extractions for irrigation tended to lower the average year end groundwater elevations which resulted in greater annual net losses from aquifer storage however these results also prove that the reverse gains can be expected and at essentially the same rate in this system the rincon valley alluvium aquifer is quick to demonstrate losses but it is also quick to demonstrate gains this study introduced a new term the gsra as the ratio of the conjunctive surface and groundwater uses and the ratio of fluxes into and out of the aquifer that contribute to changes in storage which has potential for characterizing resilience of surface and groundwater interactions in conjunctive use settings a range of gsra values that are system specific can help to inform groundwater resilience but more should be done to examine the applicability controls and limitations of the gsra the gsra calculated at the end of this study 2 54 relative to a peak gsra of 17 76 calculated for 2013 implies that conjunctive use of water for irrigation in the rincon valley is fluctuating within a range of gsra values on the backdrop of hydrologic drought yet groundwater resilience in this system appears to thus far be preserved lower values of gsra approximating 1 0 may reflect an idealized circumstance e g similar to safe yield and may not be practical in the context of enduring uncertain hydrologic drought conditions in most conjunctive use settings at least not for very long it may however serve as a temporary management metric if groundwater resilience is found to be in or very near a compromised state should this be the case monitoring of gsra as a metric for aquifer resilience and sustainability is expected to be useful the gsra appears to be a transferable metric with potential to promote or at least characterize groundwater resilience knowledge of the aquifer specific range of gsra values and associated hydrologic effects may be determined through the methodology offered by this study as specific to an aquifer of interest and perhaps associated with water resource management alternatives appropriate to a conjunctive use setting of interest acknowledgements the authors wish to thank four anonymous reviewers of a draft of this paper for providing highly constructive input the lead author is especially appreciative of insightful thorough commentary received from the journal of hydrology editor dr timothy l jones former professor of soil physics at new mexico state university provided the lead author with inspiration in this field of study and interest in science generally many years ago this study was supported primarily by the ebid of new mexico but also in part by a graduate student assistantship from the water science and management program at new mexico state university mr gary esslinger general manager of the ebid is thanked for his encouragement and support gratitude is especially owed to mr patrick lopez ebid technology director and mr dennis mccarville ebid gis analyst 
7039,plant water use is an important component in the function of earth s critical zone and this can be examined by decomposing isotope composition of xylem water into contributions from precipitation stored in shallow soil layers and deeper groundwater the usual procedure for estimating the proportional use of groundwater by plants is to sample the isotope composition of soil and groundwater and determine the most probable mixing coefficients from all potential sources here we propose and test a novel method for achieving the same goal without sampling soil water the method is based on analyzing variability in the stem water isotope ratios of several members of a community and the known isotope ratio of groundwater to triangulate the unknown isotope ratio of stored rainwater using a simple water balance model parameterized to produce the best fit between actual and estimated stem water isotope ratios we simulated seasonal variation in the volume and isotope ratio of rainwater storage along with species specific groundwater use ratios the method was applied to eight woody plant species growing on two rocky outcrops in the south china karst estimated average proportional groundwater use over two seasons varied between 14 and 62 and was site dependent for the majority of species groundwater use increased as estimated stored rainwater volume declined the two species with highest groundwater use were taller deciduous or semi deciduous trees with lower wood densities while the new method was inspired by the inability to sample water stored in the rocky outcrops it may have broader use in any environment where the spatial variability of soil water isotope composition is a barrier to estimating average groundwater use ratios the broader adoption of this or equivalent methods would greatly improve the study of the earth s critical zone keywords hydrogen and oxygen isotope new method rocky outcrops karst subtropical china 1 introduction the fate of precipitation at the terrestrial surface is a central issue in the study of earth s critical zone fan 2015 grant and dietrich 2017 at this interface of ground and atmosphere precipitation is divided between the proportion that is returned to the atmosphere feeding back on climate systems and the proportion that becomes streamflow and groundwater providing water for humans and aquatic ecosystems good et al 2015 schlesinger and jasechko 2014 climate and the biological and physical structure of the interface control the partitioning of precipitation but there is debate over how much control is exerted by each factor evaristo et al 2015 kim and jackson 2012 the hydrological balance of woodlands is largely determined by woody plant transpiration which in turn depends on atmospheric conditions potential evapotranspiration pet water availability near the surface and potentially complex interactions with shallow groundwater reservoirs ranging from inhibiting water uptake due to root inundation to subsidizing the local water budget allen et al 2016 zolfaghar et al 2017 the interactions between wooded ecosystems and groundwater are of potentially far reaching consequences for ecosystem health and society as increases in groundwater extraction for agriculture may endanger groundwater dependent ecosystems in some regions eamus et al 2015 whereas deforestation in other regions may increase flood potential and intensity bradshaw et al 2007 many studies have been conducted across a wide range of ecosystems to determine how much groundwater is taken up by woody plants evaristo and mcdonnell 2017 rossatto et al 2012 steggles et al 2017 zencich et al 2002 one of the established methods for estimating groundwater use is the stable isotope analysis of plant xylem water excluding some halophytic and xerophytic plants ellsworth and williams 2007 plants do not fractionate hydrogen and oxygen isotopes during water uptake so that xylem water can be assumed to be a volume weighted mixture of all plant water sources including surficial water and potentially deeper groundwater lin et al 1993 if the isotope ratios of all potential plant water sources are known and they are sufficiently distinct in both δd and δ18o values the proportional contributions from up to three water sources can be inferred asbjornsen et al 2007 ehleringer and dawson 1992 ogle and reynolds 2004 three important challenges exist for the success of isotopic tracing method first representative samples of all water sources must be obtainable second predetermined pools of water that the study seeks to distinguish e g soil water versus groundwater must be isotopically distinct and third samples should be taken repeatedly to be representative of natural fluctuation in available water brunel et al 1995 dawson et al 2002 the first challenge can be constraining in landscapes with scarce soil cover such as on the rocky slopes of uplands or in karst regions where roots draw water from rock fractures hubbert et al 2001 nie et al 2012 querejeta et al 2006 rong et al 2011 the problem here is that without a major excavation effort it is virtually impossible to sample water stored in rock fractures but even if there is soil to sample isotopic variation can be high typically producing a wide margin of error in the estimation of water source contribution the second challenge is not an obstacle in most climate zones where evaporative enrichment of surface water creates a pool of water uniquely different from deeper water sources or groundwater ehleringer et al 1991 but it may be an obstacle in the tropics where high humidity frequent rain and a low contribution of evaporation in evapotranspiration may limit evaporative enrichment of the soil gibson et al 2008 although recent studies in two tropical watersheds determined that soil water and groundwater can still be distinguished in dual isotope space evaristo et al 2016 the third challenge is that the frequent sampling that would be required to estimate seasonally integrated water use is costly and time consuming and therefore rarely done the vast majority of studies capture a limited number of snapshots through time typically focused the hydrologically extremes of the peak rainy season and the end of the dry season evaristo and mcdonnell 2017 this is instructive in terms of bracketing the extremes of plant water use for example highlighting species differences in accessing deeper water sources during drought dawson and pate 1996 or in their ability to switch to shallow water sources after rain west et al 2007 but such limited sampling is insufficient to estimate seasonally integrated patterns of plant water use here we introduce a novel method for collecting and analyzing plant water isotope samples that overcomes all three limitations i e source inaccessibility inconsistent isotopic distinction and limited sample size in a nutshell the method is based on analyzing the joint variation in the stem water isotope ratios of individual plants over time and assuming that the driver of this variation is the near surface water source used by all plants albeit in variable proportions thus we operationalize shallow water as a dynamic water pool that frequently shifts hydrogen and oxygen isotope ratios by evaporative enrichment and mixing stored water with new precipitation inputs and is well mixed if not at the source then during uptake through extensive and intermingled plant root systems to constrain the analysis we also sample precipitation in addition to groundwater as a second feasible plant water source and estimate the evaporative enrichment of stored water based on a simplified version of the craig gordon model craig and gordon 1965 this procedure amounts to substantial time savings not only in terms of obtaining soil samples but also in eliminating the need for water extraction finally by assuming simple soil behaviors sampling efforts can focus on characterizing stem samples more often and for longer periods of time so that seasonal and annual averages of shallow vs groundwater use can be obtained we tested this idea in the south china karst typical of karst regions worldwide soils in this region are thin and plant roots grow into the epikarst the highly weathered skin of the karst bakalowicz 2004 growing along cracks and crevices bonacci et al 2009 stothoff et al 1999 given the structural heterogeneity intrinsic to this landform it is patently impossible to classify plant water sources by depth layers as done in ecosystems where precipitation infiltrates from the top of the soil downwards barnes and allison 1988 in epikarst storage pools for water are composed of a collection of cracks and fissures through which water percolates at variable speeds and solution enhanced cavities that collect water at the interface with impervious rock fig 1 c pockets of slow moving or stagnant water are readily refilled by precipitation and depleted by evapotranspiration this pool is largely disconnected from the conduits that fill water tables that may be perched at the bottom of the epikarst and can issue from springs at the bottom of hill slopes guo et al 2015 jones 2010 schwartz et al 2013 this water pool is replenished through deep fissures including at higher elevation and by slow drip from diffuse discharge points throughout the epikarst the higher residence time of water in the perched water table stabilizes isotope ratios which for this ecosystem is close to the volume weighted isotope ratio of annual precipitation however high volume precipitation events can temporarily move the isotope ratio of spring water a few permille away from the baseflow average based on this model we distinguish two water sources for plants growing on epikarst outcrops one that is highly accessible to woody plant roots frequently recharged by precipitation and subject to evaporative enrichment shallow and another pool that is comparatively static due to slow or infrequent recharge and lack of evaporative enrichment groundwater using a water budget model we simulate the dynamics of the shallow water pool using precipitation volume and isotope ratios as input and estimating the water loss rate and evaporative enrichment by maximizing the fit between estimated and measured isotope ratios in plants we applied the technique to eight woody plant species located across two rocky outcrops in one watershed of the south china karst the goal of the study was to ascertain whether and to what extent the species differed in groundwater use and whether the method for estimating groundwater use produce consistent results across two independently parameterized rocky outcrops additionally in the second year of the study we sought to determine plant response to water limitations by covering one of the outcrops with a transparent plastic sheet thereby preventing its recharge for a month in the late growing season 2 materials and methods 2 1 site description and rainfall manipulation the experimental sites were situated at huanjiang observation and research station for karst ecosystems administrated by the chinese academy of sciences a typical karstic peak cluster depression with an area of 146 1 ha which is located in guangxi province southwest china 24 43 58 9 24 44 48 8 n 108 18 56 9 108 19 58 4 e fig 1a and b climate in the research station is subtropical mountainous monsoon climate with mean annual precipitation of 1390 mm and average annual air temperature of 18 5 c rainfall mostly occurs at the end of april to early september chen et al 2011 about 60 of the hillslopes in this catchment are dominated by shallow soil 10 30 cm on average and loose rocky habitats expansion of these habitats is frequently interrupted by the appearance of isolated rocky outcrops which characterized by thin and little soil on the surface and litter filled cracks fissures and channels internally because of the harshness of the environment the most common vegetation are tussock and scrubland big trees are usually found on the deep soils at the foot of hillslopes or on rocky outcrops and nearby soils nie et al 2011 the study focused on two large isolated dolomite outcrops covered by dense vegetation and dominated by species adapted to rocky habitat plants usually emerge from cracks directly or grow on protuberant rocks with roots grown into cracks outcrop 1 is cube shaped with a rough surface of about 8 m in length and 12 5 m in width outcrop 2 was 10 m in length and 15 m in width both rose approximately 8 m high above the hillslope to create differences in rainfall input in the second year of the study outcrop 2 was covered with a clear plastic sheet from august 2 18 withholding the approximately 57 mm of rain that fell over this period the experiment was intended to last longer but was cut short by strong winds which damaged the cover and the cover was subsequently removed 2 2 sample collection the water of individual rain events was collected for nearly two years between january 2014 and september 2015 following the protocol of the global network of isotopes in precipitation iaea and wmo 2006 when it rained precipitation samples were collected once or twice a day rainfall quantity was measured at a meteorological station located in the same small watershed we also obtained data to calculate daily pet values using the penman monteith equation allen et al 1998 from this station groundwater was collected from a spring almost every two weeks in 2014 from two springs at the experimental station one of the springs was located at the foot of the hill directly below the outcrop 1 and 2 isotope values did not differ much between collection points and over time so we omitted collecting groundwater in 2015 diameter at breast height dbh and height of each plant was measured with rods and tapes we calculated specific leaf area sla as the ratio of leaf area to dry mass about 30 50 fresh clean leaves from the broadleaved species were randomly selected from each plastic zip lock bag and measured by ci 203 cid inc usa to determine leaf area these leaves were subsequently oven dried at 75 c to constant weight the total mass of all the dried leaves was measured and divided by the total leaf number to determine the average leaf dry mass for each sampling time dry mass of the leaves was measured by an electron balance mettler toledo china e 1 mg d 0 1 mg wood density values of bark removed stem were oven dry mass per saturated volume g cm3 the volume was measured by a graduated cylinder eight woody plant species six on outcrop 1 five on outcrop 2 were selected for the study table a1 they comprised deciduous and semi deciduous tree species as well as one evergreen shrub in the understory supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 033 eight woody plant species six on outcrop 1 five on outcrop 2 were selected for the study table a1 they comprised deciduous and semi deciduous tree species as well as one evergreen shrub in the understory stem samples for isotope analysis were taken monthly from april to november in the first year of the study 2014 april 18 may 25 june 29 july 31 august 31 september 26 october 28 and november 30 and from march to september in the second year 2015 march 31 may 7 june 7 august 1 4 11 22 and september 27 the second year contained an interval of higher frequency sampling during the period that outcrop 1 was covered samples were taken on three individuals per species and outcrop stem samples were taken well below the leafed portion of the stem to reduce the risk of back diffusion of evaporatively enriched leaf water schwinning 2008 in addition bark was removed to avoid possible contamination of xylem water by isotopically enriched water in the cortex brunel et al 1995 ehleringer and dawson 1992 samples were immediately placed in a capped vial wrapped in parafilm and placed in a cooler with ice for transportation to the laboratory then they were frozen until further processing 2 3 water extraction and isotope analysis water was extracted from plant stem samples using cryogenic vacuum distillation ehleringer et al 2000 the deuterium and oxygen ratios of precipitation and stem water were measured with a liquid water isotope laser spectroscopy instrument model dlt 100 lgr inc at the key laboratory of agro ecological processes in the institute of subtropical agriculture the chinese academy of science isotope ratios are expressed in delta notation δ as 1 δ d r sample r standard 1 1000 2 δ 18 o r sample r standard 1 1000 where rsample and rstandard are the d h and 18o 16o ratios of the sample and the mean ocean water smow standard respectively the standard deviation for repeat measurement was 0 3 2 4 the water budget model the central assumption of the modeling approach is that all plants on the same outcrop use only two water sources groundwater and well mixed precipitation stored in the cracks and crevices of the outcrop but in variable ratios to constrain the isotopic composition of stored rainwater with known precipitation volumes and isotope ratios we also developed a very simple water budget model to simulate a time series of stored water volume and isotopic composition based on water input output and evaporative enrichment the unknown parameters of the model regulating evaporation e and evapotranspiration et out of the outcrop were fitted to minimize the error between observed and predicted stem water isotope ratios the volume of water stored in a rocky outcrop v mm is updated daily by subtracting daily evapotranspiration et mm out of this pool and adding daily precipitation p mm 3 v t 1 v t e t t p t however water stored in the epikarst cannot exceed a limit v max and cannot be smaller than zero and is reset accordingly when these limits are breached evapotranspiration out of the outcrop may often be limited by the amount of rainwater stored but cannot be higher than potential et pet t following rodriguez iturbe 2000 we make the simplifying assumption that there is a threshold v1 below which et t declines linearly with plant available water 4 if v t v 1 e t t v t v 1 p e t t e l s e e t t p e t t the faction of evaporation e t mm to et t is assumed to increase linearly with the amount of stored rainwater 5 e t ε s v e t t the partitioning of et into transpiration and evaporation is acknowledged to be one of the greatest challenges in hydrology kool et al 2014 and not the goal of our study the ratio of e et varies day by day and by season scott and biederman 2017 soubie et al 2016 since we were only interested here in the comparatively slow effect of evaporative enrichment on water stored in the epikarst we did not expect day by day variation in to be critical however we did consider that seasonal variation in water stored near the surface could change the proportion of e in et and modeled the ratio accordingly as a linear function of v the change in isotope ratio due to evaporation is calculated before new precipitation is added we model evaporative enrichment using a simplified craig gordon model following the procedure described by benettin et al 2018 with e t v as the evaporation fraction to calculate the equilibrium fractionation factors for hydrogen and oxygen we used average daily air temperature from the nearby weather station in the empirical formula given by horita and wesolowski 1994 we furthermore assumed that the isotopic composition of atmospheric vapor was in equilibrium with currently stored rainwater which is the common approximation in the absence of data gibson et al 2008 to estimate the kinetic fractionation factor we assumed that evaporation occurred from a small water body θ 1 transport of water vapor was fully turbulent n 0 5 envisioning that evaporation predominantly occurred from standing water in epikarst fractures this also produced greater prediction accuracy new precipitation with isotope ratios δdrain and δ18 orain mix with the water that remains at the end of the day to give the new isotope ratios for stored rainwater 6 δ d t 1 δ d enriched t v t e t t δ d rain p t v t e t t p t 7 δ 18 o t 1 δ 18 o enriched t v t e t t δ 18 o rain p t v t e t t p t at any point in time individual plants of species x take up a proportion fx t of groundwater and 1 fx t of stored rainwater which through mixing results in the plant isotope ratios of 8 d x t 1 f x t δ d t f x t δ d ground 9 δ 18 o x t 1 f x t δ 18 o t f x t δ 18 o ground the isotope ratios of groundwater were taken to be constant over the simulation interval water samples taken from springs fluctuated between 50 and 40 for δd and between 8 and 6 for δ18o with the extremes being recorded just after heavy rainfall events and likely reflecting the mixing of precipitation into spring flow we used median spring water isotope ratios to estimate the isotope ratio of the pure groundwater pool which was 43 9 for δd and 6 8 for δ18o the proportional uptake of groundwater may vary over time many studies have shown that reduced availability of shallow water during drought periods can drive increased groundwater uptake dawson and pate 1996 nie et al 2011 quesada et al 2008 voltas et al 2015 zencich et al 2002 we apply a simple linear approximation to encapsulate this relationship 10 f x t a x b x v t apart from the species specific parameters ax and bx this set of equations has only four unknowns the threshold v1 that regulates water loss from the outcrop by et the parameters governing the proportion of e in et εand s and the storage capacity of the outcrop vmax 2 5 parameter estimation the objective was to find parameter values that minimized the sum of squares for the difference between predicted and observed stem water isotope ratios the two outcrops were parametrized separately but parameters were optimized to minimize the prediction error for all plants and sampling dates on an outcrop simultaneously we initialized the simulation without stored rainwater on the first day of 2014 a day in the middle of the dry season since the first stem water samples were collected in mid april 2014 the model had more than 100 days in run up time which proved to be enough for achieving a close fit starting with the first round of samples random combinations of parameter values were picked from initially wide ranges table 1 to produce a 635 day time series of the volume and isotope ratio of stored rainwater for each combination we extracted a vector of values that corresponded to the days that stem samples were taken using only those values we systematically searched for the combination of ax and bx values eq 10 that minimized the sum of squared differences between actual and predicted stem water isotope ratios i e the sse across all plant samples and for both hydrogen and oxygen isotope ratios with only four parameter values used in the water budget model the optimization algorithm converged quickly after a few thousand interactions the optimization procedure was implemented in microsoft visual c 2015 express edition available upon request rather than reporting indicators for the overall goodness of fit we present p values and standard errors of parameters ax and bx as well as r2 values separately for species and outcrop these statistical parameters were calculated by multivariate regression analysis in spss version 23 armonk ny ibm corp specifically the regression model was 11 y x a x δ b x v δ where yx is the difference in the δd or δ18 o values between species x stem samples and the stored rainwater pool as estimated by the model δis the difference in the in the δd or δ18 o values between stored rainwater and groundwater v is the volume of stored rainwater as estimated by the model and ax and bx are the same parameters as in eq 10 eq 11 was derived from substituting eq 10 into eqs 8 and 9 and substituting the raw isotope ratios with the permille difference to the isotope ratio of groundwater we emphasize that the ax and bx values obtained by the global optimization and by species specific regression analysis were in fact the same since the global optimization included the minimization of the sum of squared errors of prediction for all species individually to compare average groundwater use proportions between species we also evaluated the univariate regression model 12 y x p x δ and compared px values by two sample t tests 3 results from january to december the study area received 1247 mm in 2014 and 1681 mm in 2015 about 60 of precipitation was received in the wet season from may to september the isotope ratios of rainwater varied seasonally with more negative values during the wet seasons and less negative or positive values during the dry seasons fig 2 there was also considerable variation between rainfall events within season air temperatures varied between roughly 5 in january and 30 c in july and august the local meteoric water line lmwl fell slightly above the global line with an offset of 13 instead of 11 rozanski et al 1993 fig 3 after removing three outliers water extracted from all stem samples plotted below the lmwl and outcrop 1 had noticeably more enriched samples than outcrop 2 the water balance parameters of the optimized simulation model are shown in table 1 along with their initial ranges the procedure generated apparently distinct solutions for the two outcrops resulting in a larger amount of stored water on outcrop 2 and a greater average daily ratio of evaporation to stored rainwater 0 29 compared to 0 25 on outcrop 1 the overall effect was to render the isotope ratio of stored rainwater on outcrop 2 less responsive more buffered to rainfall input fig a3 the water balance parameters of the optimized simulation model are shown in table 1 along with their initial ranges the procedure generated apparently distinct solutions for the two outcrops resulting in a larger amount of stored water on outcrop 2 and a greater average daily ratio of evaporation to stored rainwater 0 29 compared to 0 25 on outcrop 1 the overall effect was to render the isotope ratio of stored rainwater on outcrop 2 less responsive more buffered to rainfall input fig a3 the estimated proportions of groundwater use varied among species between a low of 14 for pllo on outcrop 2 and a high of 62 for saro on outcrop 1 table 2 the fit between predicted and observed values fell on a range of r2 values but was no lower than 0 7 groundwater use proportions were statistically well separated and we may characterize them as falling into 3 groups species with groundwater proportions of 30 cebi and didu on outcrop 1 pahe and pllo on outcrop 2 those with intermediate groundwater use of 31 50 pito on outcrop 1 cebi didu and rasi outcrop2 and those with use proportions well above 50 rasi saro and steu on outcrop 1 two species that occurred on both outcrops had significantly higher groundwater use proportions on outcrop 2 cebi and didu but groundwater use was a lower for rasi on outcrop 2 overall there was lower groundwater use by trees on outcrop 2 in six out of eleven cases groundwater use was significantly negatively affected by the predicted amount of stored rainwater i e parameter bx had negative sign meaning that proportional groundwater use declined as stored rainwater increased in two cases the effect was significantly positive closer inspection revealed that the positive effect may have been an artefact produced by stem water isotope ratios being close to the isotope ratio of groundwater but slightly more enriched than either of the two water sources at a time when rainwater storage was very low thus evaporative enrichment in inside stems under low flow conditions may interfere with the estimation of groundwater use trends klöcking and haberlandt 2002 schmidt et al 2011 although no plant samples were taken during the winter dry season to verify the model predicted greater isotopic differences between stem water and stored rainwater during these times for two reasons first rainwater is more enriched in the dry season and more different from groundwater fig 2 second there is less rainwater stored in the epikarst for plants to take up thus if plants were transpiring at all only the evergreens the model predicted that they would be using more groundwater 4 discussion 4 1 species differences the groundwater use proportions were statistically well differentiated among species between the averages of 14 and 62 table 2 ground water use proportions of this magnitude have been documented for species in many other ecosystems both in karst gu et al 2015 kukowski et al 2013 querejeta et al 2007 rong et al 2011 schwinning 2008 and non karst regions beyer et al 2016 ehleringer et al 1991 leng et al 2013 west et al 2007 it is often understood to be a component of ecological niche separation peñuelas et al 2011 silvertown et al 2015 and indicative of enhanced to ecosystem function lang et al 2014 the differentiation of water use between vegetation components for example between herbaceous and woody plants is critical to the representation of ecohydrological processes guswa et al 2002 naturally there has been a strong interest to extend generalizations to different classes of woody plants for example to deciduous v evergreen plants shrub v trees peek et al 2005 querejeta et al 2007 west et al 2012 research to date has not supported such generalizations however for example in one study conducted on the yucatan peninsula also a karst region six species of woody plants used different water sources irrespective of whether plants were evergreen or deciduous querejeta et al 2007 in a study conducted in the brazilian cerrado rossatto et al 2012 documented differences in the water sources of grasses herbs and trees but found none between evergreen and deciduous trees in our study too the degree of groundwater use did not correlate with the usual woody plant classifications the evergreen or semi deciduous species didu pito rasi and steu had groundwater uptake proportions between 30 and 58 and the deciduous species cebi pahe and pllo and saro had proportions between 14 and 62 of the two tallest trees one had intermediate groundwater use rasi and the other had the highest groundwater use of all the eight species observed saro the tallest species had the highest groundwater use saro and steu except pllo which had the lowest groundwater use tables 1 and 2 however saro and steu had by far the largest leaves and low wood densities suggesting a high transpiration and growth capacity and relatively low drought tolerance gleason et al 2016 both species are shallow soil endemics he et al 2012 huang et al 2014 wang et al 1998 which are often characterized by strong tap root development nie et al 2014 poot and lambers 2008 renton and poot 2014 thus leaf and wood characteristics may be better indicators of groundwater use as they signal adaptation to consistently high water availability the study also found apparent differences in plasticity of water source utilization in some species the species cebi didu and pllo on outcrop 2 displayed the strongest tendencies to increase groundwater use as stored rainwater ran low while pahe exhibited none table 2 fig 4 there are many examples of woody plant species substituting shallow with deeper water for transpiration during drought especially in seasonally dry ecosystems evaristo et al 2016 nie et al 2011 the degree of water source plasticity is either adaptive or site dependent ehleringer and dawson 1992 williams and ehleringer 2000 as an adaptation the ability to switch between water sources has costs one of which is the cost of maintaining a dimorphic root system consisting both shallow and deep tap roots torres et al 2002 this investment may simply not pay off for all species in a community in karst regions especially it is also quite likely that root access to groundwater varies from site to site and from tree to tree since the degree and pattern of rock fracturing can vary greatly across space hu et al 2015 tokumoto et al 2014 yang et al 2016 and root development through fractured rock could be highly individualistic this may explain why all the three species that occurred on both outcrops differed significantly in groundwater use proportions despite the variability between individual trees documented in fig 4 the analysis highlighted significant differences between species in ground water use this is all the more remarkable because the species were members of a small community confined by the limited space of an outcrop rising above a mountain slope in general the south china karst has high tree diversity li et al 2013 this study suggests that even just one specific element of the karst landscape the rocky outcrop has the capacity to support several species with contrasting water use 4 2 evaluation of the measurement and analysis method we tested an alternative analysis method for plant and water isotope data to overcome the sampling limitations of rock dominated ecosystems the method was based on estimating rather than sampling the isotope composition of stored rainwater in the absence of known values for the parameters of a water budget model we used repeatedly measured plant water isotope ratios to constrain the parameters of the model the four parameter values that governed the water budget model produced unique optima on both outcrops that minimized the sum of square errors of the prediction fig a2 two more parameters were used to describe the groundwater use for each individual species the fit of individual species stem water isotope ratios to the two source model was generally good and produced significant parameter estimates we tested an alternative analysis method for plant and water isotope data to overcome the sampling limitations of rock dominated ecosystems the method was based on estimating rather than sampling the isotope composition of stored rainwater in the absence of known values for the parameters of a water budget model we used repeatedly measured plant water isotope ratios to constrain the parameters of the model the four parameter values that governed the water budget model produced unique optima on both outcrops that minimized the sum of square errors of the prediction fig a2 two more parameters were used to describe the groundwater use for each individual species the fit of individual species stem water isotope ratios to the two source model was generally good and produced significant parameter estimates to some extent the overall good fit between the data and the model is expected given that model parameters were based on minimizing prediction error on the other hand we could not take for granted a priori that one simulated time series would necessarily fit all species on one outcrop reasonably well fig 4 for example the existence of a theoretical third independently varying water source used by some but not all species could have produced inexplicable variation and worsened the model fit however the fit for the δ18o data was visibly worse than for the δd data fig a4 in part this stems from the optimization procedure which was weighted towards fitting the δd values which had much greater spread while we could have given prediction errors equal weighting we decided not to do so over concerns that oxygen could have been fractionated by processes other than evaporation it is well documented that oxygen in water can exchange with the oxygen in the calcium carbonate of clay materials that are typically lodged at the bottom fractures meißner et al 2014 newberry et al 2017 oerter et al 2014 this exchange could have buffered variation in oxygen isotope ratios relative to variation in δd some researchers prefer not to use oxygen isotopes in water sourcing for this reason hu et al 2015 sprenger et al 2015 yang et al 2016 but we decided to use both elements since the estimated groundwater use values were consistent between fitting the model only with only δd versus both δd and δ18o values however the fit for the δ18o data was visibly worse than for the δd data fig a4 in part this stems from the optimization procedure which was weighted towards fitting the δd values which had much greater spread while we could have given prediction errors equal weighting we decided not to do so over concerns that oxygen could have been fractionated by processes other than evaporation it is well documented that oxygen in water can exchange with the oxygen in the calcium carbonate of clay materials that are typically lodged at the bottom fractures meißner et al 2014 newberry et al 2017 oerter et al 2014 this exchange could have buffered variation in oxygen isotope ratios relative to variation in δd some researchers prefer not to use oxygen isotopes in water sourcing for this reason hu et al 2015 sprenger et al 2015 yang et al 2016 but we decided to use both elements since the estimated groundwater use values were consistent between fitting the model only with only δd versus both δd and δ18o values two periods appeared to produce greater discrepancy between observed and modeled δd values fig 4 one occurred on outcrop 1 in august 2015 this was the period in which the outcrop was covered by a plastic sheet to exclude rain by comparison outcrop 2 which was not covered showed less discrepancy with the model prediction over the same period it is highly probable that the cover was not 100 effective in excluding rain so that trees on outcrop 1 received unequal quantities of rainwater input rainfall δd values during this time ranged from 30 to 70 and most stem water δd values also fell into this range related to this observation we consider the rainfall manipulation experiment to have been ineffective and omit further discussion of the third goal of the study accordingly on outcrop 2 the first stem samples collected in 2015 were far from the predicted isotope ratio of stem water and groundwater but generally similar to the last recorded stem water isotope ratios from the previous year it seems likely that plants had not yet begun to take up water but it is notable that plants on outcrop 1 did not display this discrepancy this discrepancy on outcrop 2 might be related to the phenologically delay by personal observation an alternative analysis approach for rocky habitats had previously been introduced by nie and coworkers nie et al 2011 nie et al 2012 in it the elusive isotope composition of stored rainwater was approximated as the running average for antecedent rainwater thus assuming no evaporative enrichment this method was successful in terms of demonstrating the water use diversity of karst species but groundwater use proportions could only be considered rough estimates due to uncertainties associated with averaging the isotope ratios of antecedent rainwater and although evaporative enrichment had a relatively small influence on stored rainwater in the present model it was still significant in producing a better fit ignoring enrichment would have systematically biased groundwater use estimates furthermore the approach we used here is a departure from the snap shot approach which seeks to interpret stem water isotope data separately for each sampling date and species instead we analyzed the entire two season data set jointly on the assumption that at any time all species have access to the same two water sources and within species there is continuity in groundwater uptake i e no sudden changes in groundwater consumption are expected this diminishes the problem of lack of isotopic separation between water sources which may occur by chance on one sampling date but not repeatedly given the variability in the isotope ratios of precipitation overall we believe that this approach can yield more robust estimates of seasonally integrated groundwater use provided the two source approximation is justified in general it is challenging to estimate the proportional use of water sources through isotope tracer techniques even where soil samples can be taken the isotope ratios of near surface water sources are highly variable in space due to uneven infiltration and shading differences in soil temperature and many other environmental factors that influence isotope fractionation this variability is integrated to some extent by the plants themselves since they take up water from a large soil volume across this heterogeneity individual plant values are further integrated by sampling multiple individuals to obtain a population average here we have taken one step further by assuming there is an integrated community average of near surface soil water that all members of the community use to varying degrees the new analysis method may be applicable to other environments it helps to have a relatively simple structure of plant available water pools and transparent recharge processes beyond this more complex models rothfuss and javaux 2017 sprenger et al 2016 could conceivably be parameterized in part by optimizing the fit with observed stem sample isotope ratios as was done here the key is the triangulation of dominant plant water sources through the joint analysis of stem water isotope ratios across the species of a community as opposed to developing separate models for each species 5 conclusion species rich plant communities are typically composed of many species with contrasting water use patterns that vary through time and space the methods currently employed to examine plant water sources are too costly and time consuming to adequately integrate plant water use at the landscape level a critical need for advancing the study of earth s critical zone we developed and tested a greatly simplified sampling and analysis protocol which produced well differentiated estimates of proportional groundwater use for eight species over two growing seasons whether it can be extended to other ecosystems is a matter of future examination however insights derived from the application of static snapshot mixing models may have already reached their potential novel approaches are now needed that couple isotope data to dynamic process models the south china karst is in desperate need of guidelines for forest restoration the recovery of critical ecosystem services such as flood control requires knowledge of species interactions with the hydrological cycle our results suggest that woody plants growing on rocky outcrops vary greatly in proportional groundwater use preference in initial restoration should be placed on fast growing species that use the greatest amount of groundwater over the long run a diverse community containing a spectrum of water use patterns is the end goal acknowledgements this research was supported by the national key basic research and development plan of china 2015cb452703 the national natural science foundation of china 31570428 the young scholars of western china for y n the national key research and development program of china 2016yfc0502402 and the president s international fellowship initiative 2016vbd005 of the chinese academy of sciences 
7039,plant water use is an important component in the function of earth s critical zone and this can be examined by decomposing isotope composition of xylem water into contributions from precipitation stored in shallow soil layers and deeper groundwater the usual procedure for estimating the proportional use of groundwater by plants is to sample the isotope composition of soil and groundwater and determine the most probable mixing coefficients from all potential sources here we propose and test a novel method for achieving the same goal without sampling soil water the method is based on analyzing variability in the stem water isotope ratios of several members of a community and the known isotope ratio of groundwater to triangulate the unknown isotope ratio of stored rainwater using a simple water balance model parameterized to produce the best fit between actual and estimated stem water isotope ratios we simulated seasonal variation in the volume and isotope ratio of rainwater storage along with species specific groundwater use ratios the method was applied to eight woody plant species growing on two rocky outcrops in the south china karst estimated average proportional groundwater use over two seasons varied between 14 and 62 and was site dependent for the majority of species groundwater use increased as estimated stored rainwater volume declined the two species with highest groundwater use were taller deciduous or semi deciduous trees with lower wood densities while the new method was inspired by the inability to sample water stored in the rocky outcrops it may have broader use in any environment where the spatial variability of soil water isotope composition is a barrier to estimating average groundwater use ratios the broader adoption of this or equivalent methods would greatly improve the study of the earth s critical zone keywords hydrogen and oxygen isotope new method rocky outcrops karst subtropical china 1 introduction the fate of precipitation at the terrestrial surface is a central issue in the study of earth s critical zone fan 2015 grant and dietrich 2017 at this interface of ground and atmosphere precipitation is divided between the proportion that is returned to the atmosphere feeding back on climate systems and the proportion that becomes streamflow and groundwater providing water for humans and aquatic ecosystems good et al 2015 schlesinger and jasechko 2014 climate and the biological and physical structure of the interface control the partitioning of precipitation but there is debate over how much control is exerted by each factor evaristo et al 2015 kim and jackson 2012 the hydrological balance of woodlands is largely determined by woody plant transpiration which in turn depends on atmospheric conditions potential evapotranspiration pet water availability near the surface and potentially complex interactions with shallow groundwater reservoirs ranging from inhibiting water uptake due to root inundation to subsidizing the local water budget allen et al 2016 zolfaghar et al 2017 the interactions between wooded ecosystems and groundwater are of potentially far reaching consequences for ecosystem health and society as increases in groundwater extraction for agriculture may endanger groundwater dependent ecosystems in some regions eamus et al 2015 whereas deforestation in other regions may increase flood potential and intensity bradshaw et al 2007 many studies have been conducted across a wide range of ecosystems to determine how much groundwater is taken up by woody plants evaristo and mcdonnell 2017 rossatto et al 2012 steggles et al 2017 zencich et al 2002 one of the established methods for estimating groundwater use is the stable isotope analysis of plant xylem water excluding some halophytic and xerophytic plants ellsworth and williams 2007 plants do not fractionate hydrogen and oxygen isotopes during water uptake so that xylem water can be assumed to be a volume weighted mixture of all plant water sources including surficial water and potentially deeper groundwater lin et al 1993 if the isotope ratios of all potential plant water sources are known and they are sufficiently distinct in both δd and δ18o values the proportional contributions from up to three water sources can be inferred asbjornsen et al 2007 ehleringer and dawson 1992 ogle and reynolds 2004 three important challenges exist for the success of isotopic tracing method first representative samples of all water sources must be obtainable second predetermined pools of water that the study seeks to distinguish e g soil water versus groundwater must be isotopically distinct and third samples should be taken repeatedly to be representative of natural fluctuation in available water brunel et al 1995 dawson et al 2002 the first challenge can be constraining in landscapes with scarce soil cover such as on the rocky slopes of uplands or in karst regions where roots draw water from rock fractures hubbert et al 2001 nie et al 2012 querejeta et al 2006 rong et al 2011 the problem here is that without a major excavation effort it is virtually impossible to sample water stored in rock fractures but even if there is soil to sample isotopic variation can be high typically producing a wide margin of error in the estimation of water source contribution the second challenge is not an obstacle in most climate zones where evaporative enrichment of surface water creates a pool of water uniquely different from deeper water sources or groundwater ehleringer et al 1991 but it may be an obstacle in the tropics where high humidity frequent rain and a low contribution of evaporation in evapotranspiration may limit evaporative enrichment of the soil gibson et al 2008 although recent studies in two tropical watersheds determined that soil water and groundwater can still be distinguished in dual isotope space evaristo et al 2016 the third challenge is that the frequent sampling that would be required to estimate seasonally integrated water use is costly and time consuming and therefore rarely done the vast majority of studies capture a limited number of snapshots through time typically focused the hydrologically extremes of the peak rainy season and the end of the dry season evaristo and mcdonnell 2017 this is instructive in terms of bracketing the extremes of plant water use for example highlighting species differences in accessing deeper water sources during drought dawson and pate 1996 or in their ability to switch to shallow water sources after rain west et al 2007 but such limited sampling is insufficient to estimate seasonally integrated patterns of plant water use here we introduce a novel method for collecting and analyzing plant water isotope samples that overcomes all three limitations i e source inaccessibility inconsistent isotopic distinction and limited sample size in a nutshell the method is based on analyzing the joint variation in the stem water isotope ratios of individual plants over time and assuming that the driver of this variation is the near surface water source used by all plants albeit in variable proportions thus we operationalize shallow water as a dynamic water pool that frequently shifts hydrogen and oxygen isotope ratios by evaporative enrichment and mixing stored water with new precipitation inputs and is well mixed if not at the source then during uptake through extensive and intermingled plant root systems to constrain the analysis we also sample precipitation in addition to groundwater as a second feasible plant water source and estimate the evaporative enrichment of stored water based on a simplified version of the craig gordon model craig and gordon 1965 this procedure amounts to substantial time savings not only in terms of obtaining soil samples but also in eliminating the need for water extraction finally by assuming simple soil behaviors sampling efforts can focus on characterizing stem samples more often and for longer periods of time so that seasonal and annual averages of shallow vs groundwater use can be obtained we tested this idea in the south china karst typical of karst regions worldwide soils in this region are thin and plant roots grow into the epikarst the highly weathered skin of the karst bakalowicz 2004 growing along cracks and crevices bonacci et al 2009 stothoff et al 1999 given the structural heterogeneity intrinsic to this landform it is patently impossible to classify plant water sources by depth layers as done in ecosystems where precipitation infiltrates from the top of the soil downwards barnes and allison 1988 in epikarst storage pools for water are composed of a collection of cracks and fissures through which water percolates at variable speeds and solution enhanced cavities that collect water at the interface with impervious rock fig 1 c pockets of slow moving or stagnant water are readily refilled by precipitation and depleted by evapotranspiration this pool is largely disconnected from the conduits that fill water tables that may be perched at the bottom of the epikarst and can issue from springs at the bottom of hill slopes guo et al 2015 jones 2010 schwartz et al 2013 this water pool is replenished through deep fissures including at higher elevation and by slow drip from diffuse discharge points throughout the epikarst the higher residence time of water in the perched water table stabilizes isotope ratios which for this ecosystem is close to the volume weighted isotope ratio of annual precipitation however high volume precipitation events can temporarily move the isotope ratio of spring water a few permille away from the baseflow average based on this model we distinguish two water sources for plants growing on epikarst outcrops one that is highly accessible to woody plant roots frequently recharged by precipitation and subject to evaporative enrichment shallow and another pool that is comparatively static due to slow or infrequent recharge and lack of evaporative enrichment groundwater using a water budget model we simulate the dynamics of the shallow water pool using precipitation volume and isotope ratios as input and estimating the water loss rate and evaporative enrichment by maximizing the fit between estimated and measured isotope ratios in plants we applied the technique to eight woody plant species located across two rocky outcrops in one watershed of the south china karst the goal of the study was to ascertain whether and to what extent the species differed in groundwater use and whether the method for estimating groundwater use produce consistent results across two independently parameterized rocky outcrops additionally in the second year of the study we sought to determine plant response to water limitations by covering one of the outcrops with a transparent plastic sheet thereby preventing its recharge for a month in the late growing season 2 materials and methods 2 1 site description and rainfall manipulation the experimental sites were situated at huanjiang observation and research station for karst ecosystems administrated by the chinese academy of sciences a typical karstic peak cluster depression with an area of 146 1 ha which is located in guangxi province southwest china 24 43 58 9 24 44 48 8 n 108 18 56 9 108 19 58 4 e fig 1a and b climate in the research station is subtropical mountainous monsoon climate with mean annual precipitation of 1390 mm and average annual air temperature of 18 5 c rainfall mostly occurs at the end of april to early september chen et al 2011 about 60 of the hillslopes in this catchment are dominated by shallow soil 10 30 cm on average and loose rocky habitats expansion of these habitats is frequently interrupted by the appearance of isolated rocky outcrops which characterized by thin and little soil on the surface and litter filled cracks fissures and channels internally because of the harshness of the environment the most common vegetation are tussock and scrubland big trees are usually found on the deep soils at the foot of hillslopes or on rocky outcrops and nearby soils nie et al 2011 the study focused on two large isolated dolomite outcrops covered by dense vegetation and dominated by species adapted to rocky habitat plants usually emerge from cracks directly or grow on protuberant rocks with roots grown into cracks outcrop 1 is cube shaped with a rough surface of about 8 m in length and 12 5 m in width outcrop 2 was 10 m in length and 15 m in width both rose approximately 8 m high above the hillslope to create differences in rainfall input in the second year of the study outcrop 2 was covered with a clear plastic sheet from august 2 18 withholding the approximately 57 mm of rain that fell over this period the experiment was intended to last longer but was cut short by strong winds which damaged the cover and the cover was subsequently removed 2 2 sample collection the water of individual rain events was collected for nearly two years between january 2014 and september 2015 following the protocol of the global network of isotopes in precipitation iaea and wmo 2006 when it rained precipitation samples were collected once or twice a day rainfall quantity was measured at a meteorological station located in the same small watershed we also obtained data to calculate daily pet values using the penman monteith equation allen et al 1998 from this station groundwater was collected from a spring almost every two weeks in 2014 from two springs at the experimental station one of the springs was located at the foot of the hill directly below the outcrop 1 and 2 isotope values did not differ much between collection points and over time so we omitted collecting groundwater in 2015 diameter at breast height dbh and height of each plant was measured with rods and tapes we calculated specific leaf area sla as the ratio of leaf area to dry mass about 30 50 fresh clean leaves from the broadleaved species were randomly selected from each plastic zip lock bag and measured by ci 203 cid inc usa to determine leaf area these leaves were subsequently oven dried at 75 c to constant weight the total mass of all the dried leaves was measured and divided by the total leaf number to determine the average leaf dry mass for each sampling time dry mass of the leaves was measured by an electron balance mettler toledo china e 1 mg d 0 1 mg wood density values of bark removed stem were oven dry mass per saturated volume g cm3 the volume was measured by a graduated cylinder eight woody plant species six on outcrop 1 five on outcrop 2 were selected for the study table a1 they comprised deciduous and semi deciduous tree species as well as one evergreen shrub in the understory supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 033 eight woody plant species six on outcrop 1 five on outcrop 2 were selected for the study table a1 they comprised deciduous and semi deciduous tree species as well as one evergreen shrub in the understory stem samples for isotope analysis were taken monthly from april to november in the first year of the study 2014 april 18 may 25 june 29 july 31 august 31 september 26 october 28 and november 30 and from march to september in the second year 2015 march 31 may 7 june 7 august 1 4 11 22 and september 27 the second year contained an interval of higher frequency sampling during the period that outcrop 1 was covered samples were taken on three individuals per species and outcrop stem samples were taken well below the leafed portion of the stem to reduce the risk of back diffusion of evaporatively enriched leaf water schwinning 2008 in addition bark was removed to avoid possible contamination of xylem water by isotopically enriched water in the cortex brunel et al 1995 ehleringer and dawson 1992 samples were immediately placed in a capped vial wrapped in parafilm and placed in a cooler with ice for transportation to the laboratory then they were frozen until further processing 2 3 water extraction and isotope analysis water was extracted from plant stem samples using cryogenic vacuum distillation ehleringer et al 2000 the deuterium and oxygen ratios of precipitation and stem water were measured with a liquid water isotope laser spectroscopy instrument model dlt 100 lgr inc at the key laboratory of agro ecological processes in the institute of subtropical agriculture the chinese academy of science isotope ratios are expressed in delta notation δ as 1 δ d r sample r standard 1 1000 2 δ 18 o r sample r standard 1 1000 where rsample and rstandard are the d h and 18o 16o ratios of the sample and the mean ocean water smow standard respectively the standard deviation for repeat measurement was 0 3 2 4 the water budget model the central assumption of the modeling approach is that all plants on the same outcrop use only two water sources groundwater and well mixed precipitation stored in the cracks and crevices of the outcrop but in variable ratios to constrain the isotopic composition of stored rainwater with known precipitation volumes and isotope ratios we also developed a very simple water budget model to simulate a time series of stored water volume and isotopic composition based on water input output and evaporative enrichment the unknown parameters of the model regulating evaporation e and evapotranspiration et out of the outcrop were fitted to minimize the error between observed and predicted stem water isotope ratios the volume of water stored in a rocky outcrop v mm is updated daily by subtracting daily evapotranspiration et mm out of this pool and adding daily precipitation p mm 3 v t 1 v t e t t p t however water stored in the epikarst cannot exceed a limit v max and cannot be smaller than zero and is reset accordingly when these limits are breached evapotranspiration out of the outcrop may often be limited by the amount of rainwater stored but cannot be higher than potential et pet t following rodriguez iturbe 2000 we make the simplifying assumption that there is a threshold v1 below which et t declines linearly with plant available water 4 if v t v 1 e t t v t v 1 p e t t e l s e e t t p e t t the faction of evaporation e t mm to et t is assumed to increase linearly with the amount of stored rainwater 5 e t ε s v e t t the partitioning of et into transpiration and evaporation is acknowledged to be one of the greatest challenges in hydrology kool et al 2014 and not the goal of our study the ratio of e et varies day by day and by season scott and biederman 2017 soubie et al 2016 since we were only interested here in the comparatively slow effect of evaporative enrichment on water stored in the epikarst we did not expect day by day variation in to be critical however we did consider that seasonal variation in water stored near the surface could change the proportion of e in et and modeled the ratio accordingly as a linear function of v the change in isotope ratio due to evaporation is calculated before new precipitation is added we model evaporative enrichment using a simplified craig gordon model following the procedure described by benettin et al 2018 with e t v as the evaporation fraction to calculate the equilibrium fractionation factors for hydrogen and oxygen we used average daily air temperature from the nearby weather station in the empirical formula given by horita and wesolowski 1994 we furthermore assumed that the isotopic composition of atmospheric vapor was in equilibrium with currently stored rainwater which is the common approximation in the absence of data gibson et al 2008 to estimate the kinetic fractionation factor we assumed that evaporation occurred from a small water body θ 1 transport of water vapor was fully turbulent n 0 5 envisioning that evaporation predominantly occurred from standing water in epikarst fractures this also produced greater prediction accuracy new precipitation with isotope ratios δdrain and δ18 orain mix with the water that remains at the end of the day to give the new isotope ratios for stored rainwater 6 δ d t 1 δ d enriched t v t e t t δ d rain p t v t e t t p t 7 δ 18 o t 1 δ 18 o enriched t v t e t t δ 18 o rain p t v t e t t p t at any point in time individual plants of species x take up a proportion fx t of groundwater and 1 fx t of stored rainwater which through mixing results in the plant isotope ratios of 8 d x t 1 f x t δ d t f x t δ d ground 9 δ 18 o x t 1 f x t δ 18 o t f x t δ 18 o ground the isotope ratios of groundwater were taken to be constant over the simulation interval water samples taken from springs fluctuated between 50 and 40 for δd and between 8 and 6 for δ18o with the extremes being recorded just after heavy rainfall events and likely reflecting the mixing of precipitation into spring flow we used median spring water isotope ratios to estimate the isotope ratio of the pure groundwater pool which was 43 9 for δd and 6 8 for δ18o the proportional uptake of groundwater may vary over time many studies have shown that reduced availability of shallow water during drought periods can drive increased groundwater uptake dawson and pate 1996 nie et al 2011 quesada et al 2008 voltas et al 2015 zencich et al 2002 we apply a simple linear approximation to encapsulate this relationship 10 f x t a x b x v t apart from the species specific parameters ax and bx this set of equations has only four unknowns the threshold v1 that regulates water loss from the outcrop by et the parameters governing the proportion of e in et εand s and the storage capacity of the outcrop vmax 2 5 parameter estimation the objective was to find parameter values that minimized the sum of squares for the difference between predicted and observed stem water isotope ratios the two outcrops were parametrized separately but parameters were optimized to minimize the prediction error for all plants and sampling dates on an outcrop simultaneously we initialized the simulation without stored rainwater on the first day of 2014 a day in the middle of the dry season since the first stem water samples were collected in mid april 2014 the model had more than 100 days in run up time which proved to be enough for achieving a close fit starting with the first round of samples random combinations of parameter values were picked from initially wide ranges table 1 to produce a 635 day time series of the volume and isotope ratio of stored rainwater for each combination we extracted a vector of values that corresponded to the days that stem samples were taken using only those values we systematically searched for the combination of ax and bx values eq 10 that minimized the sum of squared differences between actual and predicted stem water isotope ratios i e the sse across all plant samples and for both hydrogen and oxygen isotope ratios with only four parameter values used in the water budget model the optimization algorithm converged quickly after a few thousand interactions the optimization procedure was implemented in microsoft visual c 2015 express edition available upon request rather than reporting indicators for the overall goodness of fit we present p values and standard errors of parameters ax and bx as well as r2 values separately for species and outcrop these statistical parameters were calculated by multivariate regression analysis in spss version 23 armonk ny ibm corp specifically the regression model was 11 y x a x δ b x v δ where yx is the difference in the δd or δ18 o values between species x stem samples and the stored rainwater pool as estimated by the model δis the difference in the in the δd or δ18 o values between stored rainwater and groundwater v is the volume of stored rainwater as estimated by the model and ax and bx are the same parameters as in eq 10 eq 11 was derived from substituting eq 10 into eqs 8 and 9 and substituting the raw isotope ratios with the permille difference to the isotope ratio of groundwater we emphasize that the ax and bx values obtained by the global optimization and by species specific regression analysis were in fact the same since the global optimization included the minimization of the sum of squared errors of prediction for all species individually to compare average groundwater use proportions between species we also evaluated the univariate regression model 12 y x p x δ and compared px values by two sample t tests 3 results from january to december the study area received 1247 mm in 2014 and 1681 mm in 2015 about 60 of precipitation was received in the wet season from may to september the isotope ratios of rainwater varied seasonally with more negative values during the wet seasons and less negative or positive values during the dry seasons fig 2 there was also considerable variation between rainfall events within season air temperatures varied between roughly 5 in january and 30 c in july and august the local meteoric water line lmwl fell slightly above the global line with an offset of 13 instead of 11 rozanski et al 1993 fig 3 after removing three outliers water extracted from all stem samples plotted below the lmwl and outcrop 1 had noticeably more enriched samples than outcrop 2 the water balance parameters of the optimized simulation model are shown in table 1 along with their initial ranges the procedure generated apparently distinct solutions for the two outcrops resulting in a larger amount of stored water on outcrop 2 and a greater average daily ratio of evaporation to stored rainwater 0 29 compared to 0 25 on outcrop 1 the overall effect was to render the isotope ratio of stored rainwater on outcrop 2 less responsive more buffered to rainfall input fig a3 the water balance parameters of the optimized simulation model are shown in table 1 along with their initial ranges the procedure generated apparently distinct solutions for the two outcrops resulting in a larger amount of stored water on outcrop 2 and a greater average daily ratio of evaporation to stored rainwater 0 29 compared to 0 25 on outcrop 1 the overall effect was to render the isotope ratio of stored rainwater on outcrop 2 less responsive more buffered to rainfall input fig a3 the estimated proportions of groundwater use varied among species between a low of 14 for pllo on outcrop 2 and a high of 62 for saro on outcrop 1 table 2 the fit between predicted and observed values fell on a range of r2 values but was no lower than 0 7 groundwater use proportions were statistically well separated and we may characterize them as falling into 3 groups species with groundwater proportions of 30 cebi and didu on outcrop 1 pahe and pllo on outcrop 2 those with intermediate groundwater use of 31 50 pito on outcrop 1 cebi didu and rasi outcrop2 and those with use proportions well above 50 rasi saro and steu on outcrop 1 two species that occurred on both outcrops had significantly higher groundwater use proportions on outcrop 2 cebi and didu but groundwater use was a lower for rasi on outcrop 2 overall there was lower groundwater use by trees on outcrop 2 in six out of eleven cases groundwater use was significantly negatively affected by the predicted amount of stored rainwater i e parameter bx had negative sign meaning that proportional groundwater use declined as stored rainwater increased in two cases the effect was significantly positive closer inspection revealed that the positive effect may have been an artefact produced by stem water isotope ratios being close to the isotope ratio of groundwater but slightly more enriched than either of the two water sources at a time when rainwater storage was very low thus evaporative enrichment in inside stems under low flow conditions may interfere with the estimation of groundwater use trends klöcking and haberlandt 2002 schmidt et al 2011 although no plant samples were taken during the winter dry season to verify the model predicted greater isotopic differences between stem water and stored rainwater during these times for two reasons first rainwater is more enriched in the dry season and more different from groundwater fig 2 second there is less rainwater stored in the epikarst for plants to take up thus if plants were transpiring at all only the evergreens the model predicted that they would be using more groundwater 4 discussion 4 1 species differences the groundwater use proportions were statistically well differentiated among species between the averages of 14 and 62 table 2 ground water use proportions of this magnitude have been documented for species in many other ecosystems both in karst gu et al 2015 kukowski et al 2013 querejeta et al 2007 rong et al 2011 schwinning 2008 and non karst regions beyer et al 2016 ehleringer et al 1991 leng et al 2013 west et al 2007 it is often understood to be a component of ecological niche separation peñuelas et al 2011 silvertown et al 2015 and indicative of enhanced to ecosystem function lang et al 2014 the differentiation of water use between vegetation components for example between herbaceous and woody plants is critical to the representation of ecohydrological processes guswa et al 2002 naturally there has been a strong interest to extend generalizations to different classes of woody plants for example to deciduous v evergreen plants shrub v trees peek et al 2005 querejeta et al 2007 west et al 2012 research to date has not supported such generalizations however for example in one study conducted on the yucatan peninsula also a karst region six species of woody plants used different water sources irrespective of whether plants were evergreen or deciduous querejeta et al 2007 in a study conducted in the brazilian cerrado rossatto et al 2012 documented differences in the water sources of grasses herbs and trees but found none between evergreen and deciduous trees in our study too the degree of groundwater use did not correlate with the usual woody plant classifications the evergreen or semi deciduous species didu pito rasi and steu had groundwater uptake proportions between 30 and 58 and the deciduous species cebi pahe and pllo and saro had proportions between 14 and 62 of the two tallest trees one had intermediate groundwater use rasi and the other had the highest groundwater use of all the eight species observed saro the tallest species had the highest groundwater use saro and steu except pllo which had the lowest groundwater use tables 1 and 2 however saro and steu had by far the largest leaves and low wood densities suggesting a high transpiration and growth capacity and relatively low drought tolerance gleason et al 2016 both species are shallow soil endemics he et al 2012 huang et al 2014 wang et al 1998 which are often characterized by strong tap root development nie et al 2014 poot and lambers 2008 renton and poot 2014 thus leaf and wood characteristics may be better indicators of groundwater use as they signal adaptation to consistently high water availability the study also found apparent differences in plasticity of water source utilization in some species the species cebi didu and pllo on outcrop 2 displayed the strongest tendencies to increase groundwater use as stored rainwater ran low while pahe exhibited none table 2 fig 4 there are many examples of woody plant species substituting shallow with deeper water for transpiration during drought especially in seasonally dry ecosystems evaristo et al 2016 nie et al 2011 the degree of water source plasticity is either adaptive or site dependent ehleringer and dawson 1992 williams and ehleringer 2000 as an adaptation the ability to switch between water sources has costs one of which is the cost of maintaining a dimorphic root system consisting both shallow and deep tap roots torres et al 2002 this investment may simply not pay off for all species in a community in karst regions especially it is also quite likely that root access to groundwater varies from site to site and from tree to tree since the degree and pattern of rock fracturing can vary greatly across space hu et al 2015 tokumoto et al 2014 yang et al 2016 and root development through fractured rock could be highly individualistic this may explain why all the three species that occurred on both outcrops differed significantly in groundwater use proportions despite the variability between individual trees documented in fig 4 the analysis highlighted significant differences between species in ground water use this is all the more remarkable because the species were members of a small community confined by the limited space of an outcrop rising above a mountain slope in general the south china karst has high tree diversity li et al 2013 this study suggests that even just one specific element of the karst landscape the rocky outcrop has the capacity to support several species with contrasting water use 4 2 evaluation of the measurement and analysis method we tested an alternative analysis method for plant and water isotope data to overcome the sampling limitations of rock dominated ecosystems the method was based on estimating rather than sampling the isotope composition of stored rainwater in the absence of known values for the parameters of a water budget model we used repeatedly measured plant water isotope ratios to constrain the parameters of the model the four parameter values that governed the water budget model produced unique optima on both outcrops that minimized the sum of square errors of the prediction fig a2 two more parameters were used to describe the groundwater use for each individual species the fit of individual species stem water isotope ratios to the two source model was generally good and produced significant parameter estimates we tested an alternative analysis method for plant and water isotope data to overcome the sampling limitations of rock dominated ecosystems the method was based on estimating rather than sampling the isotope composition of stored rainwater in the absence of known values for the parameters of a water budget model we used repeatedly measured plant water isotope ratios to constrain the parameters of the model the four parameter values that governed the water budget model produced unique optima on both outcrops that minimized the sum of square errors of the prediction fig a2 two more parameters were used to describe the groundwater use for each individual species the fit of individual species stem water isotope ratios to the two source model was generally good and produced significant parameter estimates to some extent the overall good fit between the data and the model is expected given that model parameters were based on minimizing prediction error on the other hand we could not take for granted a priori that one simulated time series would necessarily fit all species on one outcrop reasonably well fig 4 for example the existence of a theoretical third independently varying water source used by some but not all species could have produced inexplicable variation and worsened the model fit however the fit for the δ18o data was visibly worse than for the δd data fig a4 in part this stems from the optimization procedure which was weighted towards fitting the δd values which had much greater spread while we could have given prediction errors equal weighting we decided not to do so over concerns that oxygen could have been fractionated by processes other than evaporation it is well documented that oxygen in water can exchange with the oxygen in the calcium carbonate of clay materials that are typically lodged at the bottom fractures meißner et al 2014 newberry et al 2017 oerter et al 2014 this exchange could have buffered variation in oxygen isotope ratios relative to variation in δd some researchers prefer not to use oxygen isotopes in water sourcing for this reason hu et al 2015 sprenger et al 2015 yang et al 2016 but we decided to use both elements since the estimated groundwater use values were consistent between fitting the model only with only δd versus both δd and δ18o values however the fit for the δ18o data was visibly worse than for the δd data fig a4 in part this stems from the optimization procedure which was weighted towards fitting the δd values which had much greater spread while we could have given prediction errors equal weighting we decided not to do so over concerns that oxygen could have been fractionated by processes other than evaporation it is well documented that oxygen in water can exchange with the oxygen in the calcium carbonate of clay materials that are typically lodged at the bottom fractures meißner et al 2014 newberry et al 2017 oerter et al 2014 this exchange could have buffered variation in oxygen isotope ratios relative to variation in δd some researchers prefer not to use oxygen isotopes in water sourcing for this reason hu et al 2015 sprenger et al 2015 yang et al 2016 but we decided to use both elements since the estimated groundwater use values were consistent between fitting the model only with only δd versus both δd and δ18o values two periods appeared to produce greater discrepancy between observed and modeled δd values fig 4 one occurred on outcrop 1 in august 2015 this was the period in which the outcrop was covered by a plastic sheet to exclude rain by comparison outcrop 2 which was not covered showed less discrepancy with the model prediction over the same period it is highly probable that the cover was not 100 effective in excluding rain so that trees on outcrop 1 received unequal quantities of rainwater input rainfall δd values during this time ranged from 30 to 70 and most stem water δd values also fell into this range related to this observation we consider the rainfall manipulation experiment to have been ineffective and omit further discussion of the third goal of the study accordingly on outcrop 2 the first stem samples collected in 2015 were far from the predicted isotope ratio of stem water and groundwater but generally similar to the last recorded stem water isotope ratios from the previous year it seems likely that plants had not yet begun to take up water but it is notable that plants on outcrop 1 did not display this discrepancy this discrepancy on outcrop 2 might be related to the phenologically delay by personal observation an alternative analysis approach for rocky habitats had previously been introduced by nie and coworkers nie et al 2011 nie et al 2012 in it the elusive isotope composition of stored rainwater was approximated as the running average for antecedent rainwater thus assuming no evaporative enrichment this method was successful in terms of demonstrating the water use diversity of karst species but groundwater use proportions could only be considered rough estimates due to uncertainties associated with averaging the isotope ratios of antecedent rainwater and although evaporative enrichment had a relatively small influence on stored rainwater in the present model it was still significant in producing a better fit ignoring enrichment would have systematically biased groundwater use estimates furthermore the approach we used here is a departure from the snap shot approach which seeks to interpret stem water isotope data separately for each sampling date and species instead we analyzed the entire two season data set jointly on the assumption that at any time all species have access to the same two water sources and within species there is continuity in groundwater uptake i e no sudden changes in groundwater consumption are expected this diminishes the problem of lack of isotopic separation between water sources which may occur by chance on one sampling date but not repeatedly given the variability in the isotope ratios of precipitation overall we believe that this approach can yield more robust estimates of seasonally integrated groundwater use provided the two source approximation is justified in general it is challenging to estimate the proportional use of water sources through isotope tracer techniques even where soil samples can be taken the isotope ratios of near surface water sources are highly variable in space due to uneven infiltration and shading differences in soil temperature and many other environmental factors that influence isotope fractionation this variability is integrated to some extent by the plants themselves since they take up water from a large soil volume across this heterogeneity individual plant values are further integrated by sampling multiple individuals to obtain a population average here we have taken one step further by assuming there is an integrated community average of near surface soil water that all members of the community use to varying degrees the new analysis method may be applicable to other environments it helps to have a relatively simple structure of plant available water pools and transparent recharge processes beyond this more complex models rothfuss and javaux 2017 sprenger et al 2016 could conceivably be parameterized in part by optimizing the fit with observed stem sample isotope ratios as was done here the key is the triangulation of dominant plant water sources through the joint analysis of stem water isotope ratios across the species of a community as opposed to developing separate models for each species 5 conclusion species rich plant communities are typically composed of many species with contrasting water use patterns that vary through time and space the methods currently employed to examine plant water sources are too costly and time consuming to adequately integrate plant water use at the landscape level a critical need for advancing the study of earth s critical zone we developed and tested a greatly simplified sampling and analysis protocol which produced well differentiated estimates of proportional groundwater use for eight species over two growing seasons whether it can be extended to other ecosystems is a matter of future examination however insights derived from the application of static snapshot mixing models may have already reached their potential novel approaches are now needed that couple isotope data to dynamic process models the south china karst is in desperate need of guidelines for forest restoration the recovery of critical ecosystem services such as flood control requires knowledge of species interactions with the hydrological cycle our results suggest that woody plants growing on rocky outcrops vary greatly in proportional groundwater use preference in initial restoration should be placed on fast growing species that use the greatest amount of groundwater over the long run a diverse community containing a spectrum of water use patterns is the end goal acknowledgements this research was supported by the national key basic research and development plan of china 2015cb452703 the national natural science foundation of china 31570428 the young scholars of western china for y n the national key research and development program of china 2016yfc0502402 and the president s international fellowship initiative 2016vbd005 of the chinese academy of sciences 
